[2024-03-13 10:54:19,084] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 10:54:19,091] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 10:54:19,162] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 10:54:19,175] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
5000
4497
5000
4497
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 10:54:38,375] [INFO] [comm.py:637:init_distributed] cdb=None
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
5000
4497
[2024-03-13 10:54:38,388] [INFO] [comm.py:637:init_distributed] cdb=None
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 10:54:38,482] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 10:54:38,482] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-13 10:54:38,538] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 10:54:38,825][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f3532985090>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 10:55:09,810][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-13 10:55:09,814] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-13 10:55:10,022][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f0d003f4790>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 10:55:10,028][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f05c7714ca0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 10:55:10,030][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f5eb7ba8cd0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 10:55:43,393] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-13 10:55:43,394] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-13 10:55:43,510] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-13 10:55:43,511] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 10:55:43,511] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 101.34 GB, percent = 10.1%
[2024-03-13 10:55:43,627] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-13 10:55:43,628] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 10:55:43,628] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 99.09 GB, percent = 9.8%
[2024-03-13 10:55:43,629] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f3532984eb0>
[2024-03-13 10:55:43,630] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-13 10:55:43,631] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-13 10:55:43,632] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-03-13 10:55:43,633] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-13 10:55:43,634] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-13 10:55:43,634] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-13 10:55:43,634] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-13 10:55:43,634] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-13 10:55:43,634] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.97764587402344, 'logps/chosen': -37.25732421875, 'logits/rejected': -2.988147020339966, 'logits/chosen': -2.862048864364624, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.70320129394531, 'logps/chosen': -36.42850875854492, 'logits/rejected': -2.903564214706421, 'logits/chosen': -2.8116133213043213, 'epoch': 0.01}
{'loss': 0.6929, 'learning_rate': 2e-07, 'rewards/chosen': -0.0007799384766258299, 'rewards/rejected': 0.0014891261234879494, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0022690652403980494, 'logps/rejected': -37.088340759277344, 'logps/chosen': -42.113197326660156, 'logits/rejected': -2.8205695152282715, 'logits/chosen': -2.8978123664855957, 'epoch': 0.02}
{'loss': 0.6898, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': 0.003478526370599866, 'rewards/rejected': -0.00034478915040381253, 'rewards/accuracies': 0.5, 'rewards/margins': 0.003823315491899848, 'logps/rejected': -37.516780853271484, 'logps/chosen': -33.76583480834961, 'logits/rejected': -2.9109251499176025, 'logits/chosen': -2.89607834815979, 'epoch': 0.03}
{'loss': 0.6785, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': 0.009850622154772282, 'rewards/rejected': -0.013922108337283134, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.02377272956073284, 'logps/rejected': -53.8202018737793, 'logps/chosen': -32.23497009277344, 'logits/rejected': -3.042910575866699, 'logits/chosen': -2.624208450317383, 'epoch': 0.03}
{'loss': 0.6172, 'learning_rate': 4e-07, 'rewards/chosen': 0.03932541608810425, 'rewards/rejected': -0.10977952182292938, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.14910492300987244, 'logps/rejected': -43.79914093017578, 'logps/chosen': -38.3016242980957, 'logits/rejected': -2.8623149394989014, 'logits/chosen': -2.853828191757202, 'epoch': 0.04}
{'loss': 0.5472, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.021860551089048386, 'rewards/rejected': -0.32487982511520386, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.34674039483070374, 'logps/rejected': -42.94183349609375, 'logps/chosen': -42.44392776489258, 'logits/rejected': -2.8299167156219482, 'logits/chosen': -2.9400126934051514, 'epoch': 0.05}
{'loss': 0.49, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.03430885076522827, 'rewards/rejected': -0.4507864713668823, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.485095351934433, 'logps/rejected': -36.71097183227539, 'logps/chosen': -44.98051071166992, 'logits/rejected': -2.851001024246216, 'logits/chosen': -2.9825353622436523, 'epoch': 0.05}
{'loss': 0.4736, 'learning_rate': 6e-07, 'rewards/chosen': -0.02833222970366478, 'rewards/rejected': -0.7814510464668274, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.7531188130378723, 'logps/rejected': -46.54513931274414, 'logps/chosen': -37.995582580566406, 'logits/rejected': -3.0022172927856445, 'logits/chosen': -2.8493218421936035, 'epoch': 0.06}
{'loss': 0.3294, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': -0.21565213799476624, 'rewards/rejected': -1.659425139427185, 'rewards/accuracies': 0.9375, 'rewards/margins': 1.4437729120254517, 'logps/rejected': -49.09502029418945, 'logps/chosen': -43.48343276977539, 'logits/rejected': -2.812769889831543, 'logits/chosen': -2.9676613807678223, 'epoch': 0.07}
{'loss': 0.2872, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': -0.2373681664466858, 'rewards/rejected': -1.7768125534057617, 'rewards/accuracies': 0.75, 'rewards/margins': 1.5394442081451416, 'logps/rejected': -53.63917541503906, 'logps/chosen': -48.959434509277344, 'logits/rejected': -2.9121851921081543, 'logits/chosen': -3.0184104442596436, 'epoch': 0.07}
{'loss': 0.2893, 'learning_rate': 8e-07, 'rewards/chosen': -0.2970702648162842, 'rewards/rejected': -2.1833455562591553, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.8862754106521606, 'logps/rejected': -51.4091796875, 'logps/chosen': -38.23870849609375, 'logits/rejected': -2.9122605323791504, 'logits/chosen': -2.9573891162872314, 'epoch': 0.08}
{'loss': 0.2178, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': -0.3749895393848419, 'rewards/rejected': -4.340465545654297, 'rewards/accuracies': 1.0, 'rewards/margins': 3.9654760360717773, 'logps/rejected': -65.13618469238281, 'logps/chosen': -44.235904693603516, 'logits/rejected': -2.934032440185547, 'logits/chosen': -2.8644495010375977, 'epoch': 0.09}
{'loss': 0.2344, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': -1.019273281097412, 'rewards/rejected': -5.6739606857299805, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.654687404632568, 'logps/rejected': -72.7320327758789, 'logps/chosen': -44.41579055786133, 'logits/rejected': -2.991641044616699, 'logits/chosen': -2.8872485160827637, 'epoch': 0.09}
{'loss': 0.2416, 'learning_rate': 1e-06, 'rewards/chosen': -0.7670806050300598, 'rewards/rejected': -6.015442848205566, 'rewards/accuracies': 1.0, 'rewards/margins': 5.2483625411987305, 'logps/rejected': -76.39031982421875, 'logps/chosen': -45.95541763305664, 'logits/rejected': -2.9184911251068115, 'logits/chosen': -2.8884167671203613, 'epoch': 0.1}
{'loss': 0.1911, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -2.14866042137146, 'rewards/rejected': -7.193514823913574, 'rewards/accuracies': 0.875, 'rewards/margins': 5.044854164123535, 'logps/rejected': -82.14789581298828, 'logps/chosen': -44.998321533203125, 'logits/rejected': -3.0130980014801025, 'logits/chosen': -2.8445379734039307, 'epoch': 0.11}
{'loss': 0.1896, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -2.4239883422851562, 'rewards/rejected': -8.566479682922363, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.142490386962891, 'logps/rejected': -88.47740936279297, 'logps/chosen': -53.37044143676758, 'logits/rejected': -2.971543073654175, 'logits/chosen': -2.985304355621338, 'epoch': 0.11}
{'loss': 0.1799, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -1.8282911777496338, 'rewards/rejected': -5.941686630249023, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.113395690917969, 'logps/rejected': -62.608787536621094, 'logps/chosen': -43.07887649536133, 'logits/rejected': -2.9485955238342285, 'logits/chosen': -3.039005994796753, 'epoch': 0.12}
{'loss': 0.1555, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -1.5892013311386108, 'rewards/rejected': -6.938886642456055, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.3496856689453125, 'logps/rejected': -72.32536315917969, 'logps/chosen': -43.291175842285156, 'logits/rejected': -2.9752068519592285, 'logits/chosen': -2.983875274658203, 'epoch': 0.13}
{'loss': 0.2205, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.5941985845565796, 'rewards/rejected': -8.043131828308105, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.448933124542236, 'logps/rejected': -83.86426544189453, 'logps/chosen': -44.411746978759766, 'logits/rejected': -3.022540330886841, 'logits/chosen': -3.0793275833129883, 'epoch': 0.13}
{'loss': 0.1286, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -1.7128838300704956, 'rewards/rejected': -7.998345851898193, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.285461902618408, 'logps/rejected': -82.90167236328125, 'logps/chosen': -48.03968811035156, 'logits/rejected': -2.952456474304199, 'logits/chosen': -2.957099199295044, 'epoch': 0.14}
{'loss': 0.1309, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -1.440880537033081, 'rewards/rejected': -9.275030136108398, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.834149360656738, 'logps/rejected': -101.53486633300781, 'logps/chosen': -39.85533142089844, 'logits/rejected': -3.0458006858825684, 'logits/chosen': -2.7942864894866943, 'epoch': 0.15}
{'loss': 0.3743, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -2.218824625015259, 'rewards/rejected': -8.56123161315918, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.342406272888184, 'logps/rejected': -84.881591796875, 'logps/chosen': -54.53841018676758, 'logits/rejected': -2.881683111190796, 'logits/chosen': -2.9612679481506348, 'epoch': 0.15}
{'loss': 0.2337, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -1.6860358715057373, 'rewards/rejected': -8.14725399017334, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.461216926574707, 'logps/rejected': -82.2844009399414, 'logps/chosen': -41.54248046875, 'logits/rejected': -3.0053224563598633, 'logits/chosen': -2.9090771675109863, 'epoch': 0.16}
{'loss': 0.1102, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -2.135446548461914, 'rewards/rejected': -8.848196029663086, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.712749481201172, 'logps/rejected': -83.39808654785156, 'logps/chosen': -54.35846710205078, 'logits/rejected': -2.973658800125122, 'logits/chosen': -3.0478274822235107, 'epoch': 0.17}
{'loss': 0.1978, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -1.5923975706100464, 'rewards/rejected': -8.996806144714355, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.4044084548950195, 'logps/rejected': -96.0135498046875, 'logps/chosen': -49.380393981933594, 'logits/rejected': -3.029282331466675, 'logits/chosen': -2.926449775695801, 'epoch': 0.18}
{'loss': 0.1828, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -1.706801414489746, 'rewards/rejected': -9.023037910461426, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.316237926483154, 'logps/rejected': -82.96395111083984, 'logps/chosen': -54.54573059082031, 'logits/rejected': -2.9150638580322266, 'logits/chosen': -2.994663715362549, 'epoch': 0.18}
{'loss': 0.3123, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -2.1365084648132324, 'rewards/rejected': -8.816131591796875, 'rewards/accuracies': 0.875, 'rewards/margins': 6.679623603820801, 'logps/rejected': -81.49161529541016, 'logps/chosen': -47.49713134765625, 'logits/rejected': -3.005488395690918, 'logits/chosen': -3.0173609256744385, 'epoch': 0.19}
{'loss': 0.3294, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -1.918818473815918, 'rewards/rejected': -8.718550682067871, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.799731731414795, 'logps/rejected': -83.96578216552734, 'logps/chosen': -48.2578125, 'logits/rejected': -3.0160269737243652, 'logits/chosen': -3.0590107440948486, 'epoch': 0.2}
{'loss': 0.0924, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -1.64459228515625, 'rewards/rejected': -9.218019485473633, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.573427677154541, 'logps/rejected': -87.63511657714844, 'logps/chosen': -48.35261535644531, 'logits/rejected': -2.993406295776367, 'logits/chosen': -3.041184425354004, 'epoch': 0.2}
{'loss': 0.1818, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -1.6316685676574707, 'rewards/rejected': -10.660682678222656, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.029014587402344, 'logps/rejected': -98.11903381347656, 'logps/chosen': -46.33251190185547, 'logits/rejected': -3.0561604499816895, 'logits/chosen': -2.98168683052063, 'epoch': 0.21}
{'loss': 0.1653, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -2.123455047607422, 'rewards/rejected': -9.74443531036377, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.6209797859191895, 'logps/rejected': -90.32322692871094, 'logps/chosen': -50.58677673339844, 'logits/rejected': -3.0127992630004883, 'logits/chosen': -3.0096726417541504, 'epoch': 0.22}
{'loss': 0.2088, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -2.9857773780822754, 'rewards/rejected': -10.416388511657715, 'rewards/accuracies': 0.875, 'rewards/margins': 7.430610656738281, 'logps/rejected': -95.23277282714844, 'logps/chosen': -51.948280334472656, 'logits/rejected': -3.057253122329712, 'logits/chosen': -3.0217082500457764, 'epoch': 0.22}
{'loss': 0.4111, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -2.85888409614563, 'rewards/rejected': -8.98076343536377, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.121879577636719, 'logps/rejected': -86.04261016845703, 'logps/chosen': -50.159629821777344, 'logits/rejected': -3.1149182319641113, 'logits/chosen': -3.01544451713562, 'epoch': 0.23}
{'loss': 0.547, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -3.772906541824341, 'rewards/rejected': -8.633944511413574, 'rewards/accuracies': 0.75, 'rewards/margins': 4.861037731170654, 'logps/rejected': -88.14483642578125, 'logps/chosen': -73.01014709472656, 'logits/rejected': -2.98750638961792, 'logits/chosen': -3.103292942047119, 'epoch': 0.24}
{'loss': 0.3504, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -2.6339616775512695, 'rewards/rejected': -9.736831665039062, 'rewards/accuracies': 0.8125, 'rewards/margins': 7.102870941162109, 'logps/rejected': -86.65438842773438, 'logps/chosen': -47.471553802490234, 'logits/rejected': -3.0965073108673096, 'logits/chosen': -3.0901660919189453, 'epoch': 0.24}
{'loss': 0.2814, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -2.8980038166046143, 'rewards/rejected': -11.002480506896973, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.104476928710938, 'logps/rejected': -97.16282653808594, 'logps/chosen': -51.39897537231445, 'logits/rejected': -3.04783296585083, 'logits/chosen': -2.984668254852295, 'epoch': 0.25}
{'loss': 0.3547, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -2.919080972671509, 'rewards/rejected': -9.740215301513672, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.821134567260742, 'logps/rejected': -89.97845458984375, 'logps/chosen': -58.218021392822266, 'logits/rejected': -3.0043094158172607, 'logits/chosen': -3.1203055381774902, 'epoch': 0.26}
{'loss': 0.1564, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -2.8693714141845703, 'rewards/rejected': -11.47055721282959, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.60118579864502, 'logps/rejected': -100.96289825439453, 'logps/chosen': -51.47926330566406, 'logits/rejected': -3.1044201850891113, 'logits/chosen': -2.978705883026123, 'epoch': 0.26}
{'loss': 0.327, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -4.077651500701904, 'rewards/rejected': -9.5614595413208, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.48380708694458, 'logps/rejected': -89.0092544555664, 'logps/chosen': -76.99778747558594, 'logits/rejected': -2.920306444168091, 'logits/chosen': -3.2305009365081787, 'epoch': 0.27}
{'loss': 0.2371, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -3.8260557651519775, 'rewards/rejected': -10.98141098022461, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.1553544998168945, 'logps/rejected': -95.76195526123047, 'logps/chosen': -60.57093048095703, 'logits/rejected': -3.006049394607544, 'logits/chosen': -3.0357871055603027, 'epoch': 0.28}
{'loss': 0.0907, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -4.605159282684326, 'rewards/rejected': -12.13209342956543, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.526934623718262, 'logps/rejected': -102.90906524658203, 'logps/chosen': -57.764442443847656, 'logits/rejected': -3.1051127910614014, 'logits/chosen': -2.97847056388855, 'epoch': 0.28}
{'loss': 0.1388, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -3.238069534301758, 'rewards/rejected': -11.843765258789062, 'rewards/accuracies': 1.0, 'rewards/margins': 8.605695724487305, 'logps/rejected': -101.39143371582031, 'logps/chosen': -52.061180114746094, 'logits/rejected': -3.08482027053833, 'logits/chosen': -2.9843058586120605, 'epoch': 0.29}
{'loss': 0.1125, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -2.9984116554260254, 'rewards/rejected': -10.207080841064453, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.208668231964111, 'logps/rejected': -91.46255493164062, 'logps/chosen': -49.10483169555664, 'logits/rejected': -3.066004753112793, 'logits/chosen': -3.0658323764801025, 'epoch': 0.3}
{'loss': 0.1167, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -1.8884631395339966, 'rewards/rejected': -11.004737854003906, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.1162748336792, 'logps/rejected': -96.02169799804688, 'logps/chosen': -46.63326644897461, 'logits/rejected': -2.9807932376861572, 'logits/chosen': -2.9959652423858643, 'epoch': 0.3}
{'loss': 0.1253, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -2.1702675819396973, 'rewards/rejected': -11.081090927124023, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.910822868347168, 'logps/rejected': -105.17497253417969, 'logps/chosen': -44.430599212646484, 'logits/rejected': -3.140702962875366, 'logits/chosen': -3.00176739692688, 'epoch': 0.31}
{'loss': 0.1715, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -1.332770824432373, 'rewards/rejected': -10.65831184387207, 'rewards/accuracies': 1.0, 'rewards/margins': 9.325540542602539, 'logps/rejected': -98.84477996826172, 'logps/chosen': -41.94966125488281, 'logits/rejected': -3.1733779907226562, 'logits/chosen': -2.9601426124572754, 'epoch': 0.32}
{'loss': 0.2617, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -2.3942670822143555, 'rewards/rejected': -10.767152786254883, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.372884750366211, 'logps/rejected': -91.43388366699219, 'logps/chosen': -46.61696243286133, 'logits/rejected': -3.091331720352173, 'logits/chosen': -3.1061112880706787, 'epoch': 0.32}
{'loss': 0.2086, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -1.3756649494171143, 'rewards/rejected': -10.814250946044922, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.43858528137207, 'logps/rejected': -98.22411346435547, 'logps/chosen': -44.22930908203125, 'logits/rejected': -3.0018861293792725, 'logits/chosen': -3.0259976387023926, 'epoch': 0.33}
{'loss': 0.1841, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -0.9638951420783997, 'rewards/rejected': -8.90195083618164, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.938055038452148, 'logps/rejected': -90.62117004394531, 'logps/chosen': -39.13078308105469, 'logits/rejected': -3.1327433586120605, 'logits/chosen': -2.9717531204223633, 'epoch': 0.34}
{'loss': 0.2078, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -1.3218066692352295, 'rewards/rejected': -9.453597068786621, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.131789207458496, 'logps/rejected': -87.33721923828125, 'logps/chosen': -45.118003845214844, 'logits/rejected': -3.070495843887329, 'logits/chosen': -3.1171441078186035, 'epoch': 0.34}
{'loss': 0.3847, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -0.1255347579717636, 'rewards/rejected': -7.965979099273682, 'rewards/accuracies': 0.875, 'rewards/margins': 7.840444564819336, 'logps/rejected': -76.80685424804688, 'logps/chosen': -45.15413284301758, 'logits/rejected': -3.006164073944092, 'logits/chosen': -3.134568214416504, 'epoch': 0.35}
{'loss': 0.2283, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -0.9421225190162659, 'rewards/rejected': -10.058370590209961, 'rewards/accuracies': 0.84375, 'rewards/margins': 9.11624813079834, 'logps/rejected': -95.77225494384766, 'logps/chosen': -52.840782165527344, 'logits/rejected': -3.069856882095337, 'logits/chosen': -3.0669264793395996, 'epoch': 0.36}
{'loss': 0.3095, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -2.4936795234680176, 'rewards/rejected': -10.629019737243652, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.135339736938477, 'logps/rejected': -98.67779541015625, 'logps/chosen': -56.64744186401367, 'logits/rejected': -2.9158120155334473, 'logits/chosen': -3.0139925479888916, 'epoch': 0.36}
{'loss': 0.1265, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -1.5973317623138428, 'rewards/rejected': -8.250258445739746, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.652926445007324, 'logps/rejected': -77.9028091430664, 'logps/chosen': -46.383663177490234, 'logits/rejected': -3.0122499465942383, 'logits/chosen': -3.1047396659851074, 'epoch': 0.37}
{'loss': 0.2548, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -2.435694694519043, 'rewards/rejected': -10.182268142700195, 'rewards/accuracies': 0.875, 'rewards/margins': 7.746572494506836, 'logps/rejected': -89.71924591064453, 'logps/chosen': -46.72138977050781, 'logits/rejected': -3.0665557384490967, 'logits/chosen': -2.979785919189453, 'epoch': 0.38}
{'loss': 0.1039, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -2.2444939613342285, 'rewards/rejected': -9.332976341247559, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.08848237991333, 'logps/rejected': -90.17671966552734, 'logps/chosen': -44.237728118896484, 'logits/rejected': -3.1292130947113037, 'logits/chosen': -2.978912830352783, 'epoch': 0.38}
{'loss': 0.1156, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -2.441235303878784, 'rewards/rejected': -12.192370414733887, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.751134872436523, 'logps/rejected': -109.3502197265625, 'logps/chosen': -49.200687408447266, 'logits/rejected': -3.1318459510803223, 'logits/chosen': -2.9913489818573, 'epoch': 0.39}
{'loss': 0.3151, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -2.564354419708252, 'rewards/rejected': -10.072637557983398, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.5082831382751465, 'logps/rejected': -83.38409423828125, 'logps/chosen': -46.24212646484375, 'logits/rejected': -2.999884605407715, 'logits/chosen': -3.092540979385376, 'epoch': 0.4}
{'loss': 0.1967, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -1.5189824104309082, 'rewards/rejected': -11.980123519897461, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.461140632629395, 'logps/rejected': -105.961181640625, 'logps/chosen': -41.86314010620117, 'logits/rejected': -3.046208381652832, 'logits/chosen': -2.982210397720337, 'epoch': 0.4}
{'loss': 0.2548, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -2.466984510421753, 'rewards/rejected': -11.027246475219727, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.560261726379395, 'logps/rejected': -90.97765350341797, 'logps/chosen': -50.0342903137207, 'logits/rejected': -2.9643959999084473, 'logits/chosen': -3.1021568775177, 'epoch': 0.41}
{'loss': 0.1981, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -1.4587428569793701, 'rewards/rejected': -12.58392333984375, 'rewards/accuracies': 1.0, 'rewards/margins': 11.1251802444458, 'logps/rejected': -107.94671630859375, 'logps/chosen': -39.204532623291016, 'logits/rejected': -3.1256139278411865, 'logits/chosen': -2.959578275680542, 'epoch': 0.42}
{'loss': 0.2054, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -3.4364120960235596, 'rewards/rejected': -11.996732711791992, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.560321807861328, 'logps/rejected': -102.17982482910156, 'logps/chosen': -51.855796813964844, 'logits/rejected': -3.086198329925537, 'logits/chosen': -3.0506205558776855, 'epoch': 0.42}
{'loss': 0.4202, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -2.397865056991577, 'rewards/rejected': -10.564689636230469, 'rewards/accuracies': 0.8125, 'rewards/margins': 8.166824340820312, 'logps/rejected': -88.75574493408203, 'logps/chosen': -44.736392974853516, 'logits/rejected': -3.0755157470703125, 'logits/chosen': -3.0600600242614746, 'epoch': 0.43}
{'loss': 0.386, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -0.8331799507141113, 'rewards/rejected': -14.131898880004883, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.298718452453613, 'logps/rejected': -110.76545715332031, 'logps/chosen': -41.91912078857422, 'logits/rejected': -2.980236530303955, 'logits/chosen': -2.989405632019043, 'epoch': 0.44}
{'loss': 0.2927, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -2.5900535583496094, 'rewards/rejected': -12.649190902709961, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.059137344360352, 'logps/rejected': -101.6288833618164, 'logps/chosen': -48.9105224609375, 'logits/rejected': -2.9683923721313477, 'logits/chosen': -3.033295154571533, 'epoch': 0.44}
{'loss': 0.1489, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -4.049834251403809, 'rewards/rejected': -13.858560562133789, 'rewards/accuracies': 0.875, 'rewards/margins': 9.80872631072998, 'logps/rejected': -117.25328063964844, 'logps/chosen': -59.83488464355469, 'logits/rejected': -3.1107449531555176, 'logits/chosen': -2.9212846755981445, 'epoch': 0.45}
{'loss': 0.114, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -2.7836508750915527, 'rewards/rejected': -12.35073471069336, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.567082405090332, 'logps/rejected': -105.77177429199219, 'logps/chosen': -55.07078552246094, 'logits/rejected': -2.9671359062194824, 'logits/chosen': -3.004568099975586, 'epoch': 0.46}
{'loss': 0.1902, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -3.9806406497955322, 'rewards/rejected': -14.775978088378906, 'rewards/accuracies': 0.84375, 'rewards/margins': 10.79533863067627, 'logps/rejected': -117.6981201171875, 'logps/chosen': -60.519317626953125, 'logits/rejected': -2.9769434928894043, 'logits/chosen': -2.910116672515869, 'epoch': 0.46}
{'loss': 0.1694, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -2.8687705993652344, 'rewards/rejected': -13.501922607421875, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.63315200805664, 'logps/rejected': -106.8868408203125, 'logps/chosen': -50.52436065673828, 'logits/rejected': -2.963013172149658, 'logits/chosen': -2.9470503330230713, 'epoch': 0.47}
{'loss': 0.375, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -4.458430290222168, 'rewards/rejected': -11.47330093383789, 'rewards/accuracies': 0.71875, 'rewards/margins': 7.014871120452881, 'logps/rejected': -96.029541015625, 'logps/chosen': -63.210655212402344, 'logits/rejected': -2.929560422897339, 'logits/chosen': -3.118546962738037, 'epoch': 0.48}
{'loss': 0.1176, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -3.165292978286743, 'rewards/rejected': -13.805851936340332, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.640559196472168, 'logps/rejected': -110.68484497070312, 'logps/chosen': -50.79012680053711, 'logits/rejected': -2.9597225189208984, 'logits/chosen': -2.9634149074554443, 'epoch': 0.49}
{'loss': 0.1748, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -3.9169042110443115, 'rewards/rejected': -15.67795181274414, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.761046409606934, 'logps/rejected': -126.26998138427734, 'logps/chosen': -52.09494400024414, 'logits/rejected': -3.1566238403320312, 'logits/chosen': -2.887040138244629, 'epoch': 0.49}
{'loss': 0.0903, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -3.2156636714935303, 'rewards/rejected': -17.89277458190918, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.677107810974121, 'logps/rejected': -138.7405548095703, 'logps/chosen': -47.67665100097656, 'logits/rejected': -3.07242488861084, 'logits/chosen': -2.797851800918579, 'epoch': 0.5}
{'loss': 0.2738, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -3.334062099456787, 'rewards/rejected': -15.615445137023926, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.28138256072998, 'logps/rejected': -124.1590805053711, 'logps/chosen': -63.406349182128906, 'logits/rejected': -2.88596773147583, 'logits/chosen': -3.04282546043396, 'epoch': 0.51}
{'loss': 0.2202, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -3.941349506378174, 'rewards/rejected': -14.979496955871582, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.03814697265625, 'logps/rejected': -111.55488586425781, 'logps/chosen': -60.504425048828125, 'logits/rejected': -2.9644057750701904, 'logits/chosen': -3.0645971298217773, 'epoch': 0.51}
{'loss': 0.1146, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -3.399280309677124, 'rewards/rejected': -14.774842262268066, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.375560760498047, 'logps/rejected': -113.81775665283203, 'logps/chosen': -61.70862579345703, 'logits/rejected': -2.889441967010498, 'logits/chosen': -3.001920223236084, 'epoch': 0.52}
{'loss': 0.1165, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -5.079278945922852, 'rewards/rejected': -14.074934005737305, 'rewards/accuracies': 0.875, 'rewards/margins': 8.995655059814453, 'logps/rejected': -104.36839294433594, 'logps/chosen': -69.21086883544922, 'logits/rejected': -2.862617254257202, 'logits/chosen': -3.0810070037841797, 'epoch': 0.53}
{'loss': 0.0811, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -3.7877390384674072, 'rewards/rejected': -13.040178298950195, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.25243854522705, 'logps/rejected': -103.10306549072266, 'logps/chosen': -52.4337043762207, 'logits/rejected': -3.0031814575195312, 'logits/chosen': -2.9273722171783447, 'epoch': 0.53}
{'loss': 0.2016, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -3.541409969329834, 'rewards/rejected': -13.115328788757324, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.573917388916016, 'logps/rejected': -101.55326843261719, 'logps/chosen': -53.23393249511719, 'logits/rejected': -3.005457639694214, 'logits/chosen': -2.9870011806488037, 'epoch': 0.54}
{'loss': 0.1871, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -3.3156864643096924, 'rewards/rejected': -14.746832847595215, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.431147575378418, 'logps/rejected': -111.01502990722656, 'logps/chosen': -58.44268035888672, 'logits/rejected': -2.8484303951263428, 'logits/chosen': -3.062065601348877, 'epoch': 0.55}
{'loss': 0.1678, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -3.5358314514160156, 'rewards/rejected': -14.79968547821045, 'rewards/accuracies': 0.875, 'rewards/margins': 11.263854026794434, 'logps/rejected': -108.96015930175781, 'logps/chosen': -57.29125213623047, 'logits/rejected': -2.894658088684082, 'logits/chosen': -3.027236223220825, 'epoch': 0.55}
{'loss': 0.0969, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -3.4224693775177, 'rewards/rejected': -14.624444007873535, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.201973915100098, 'logps/rejected': -112.17182922363281, 'logps/chosen': -55.26757049560547, 'logits/rejected': -2.9816606044769287, 'logits/chosen': -2.9811668395996094, 'epoch': 0.56}
{'loss': 0.1345, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -5.328228950500488, 'rewards/rejected': -17.776351928710938, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.44812297821045, 'logps/rejected': -136.4293212890625, 'logps/chosen': -69.5140609741211, 'logits/rejected': -2.8824539184570312, 'logits/chosen': -2.9412989616394043, 'epoch': 0.57}
{'loss': 0.1483, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -3.7246718406677246, 'rewards/rejected': -16.455339431762695, 'rewards/accuracies': 1.0, 'rewards/margins': 12.730669021606445, 'logps/rejected': -124.82183837890625, 'logps/chosen': -57.79347229003906, 'logits/rejected': -2.912531614303589, 'logits/chosen': -3.0375607013702393, 'epoch': 0.57}
{'loss': 0.124, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -3.679378032684326, 'rewards/rejected': -16.145692825317383, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.466314315795898, 'logps/rejected': -121.27594757080078, 'logps/chosen': -60.15818786621094, 'logits/rejected': -2.9523138999938965, 'logits/chosen': -3.0178706645965576, 'epoch': 0.58}
{'loss': 0.2464, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -2.838283061981201, 'rewards/rejected': -15.51563835144043, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.67735481262207, 'logps/rejected': -117.76445007324219, 'logps/chosen': -50.71211242675781, 'logits/rejected': -2.9818460941314697, 'logits/chosen': -2.959214210510254, 'epoch': 0.59}
{'loss': 0.5035, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -4.892804145812988, 'rewards/rejected': -15.110291481018066, 'rewards/accuracies': 0.84375, 'rewards/margins': 10.217490196228027, 'logps/rejected': -113.05996704101562, 'logps/chosen': -61.15021514892578, 'logits/rejected': -2.963243007659912, 'logits/chosen': -3.0259146690368652, 'epoch': 0.59}
{'loss': 0.4173, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -4.66101598739624, 'rewards/rejected': -16.135452270507812, 'rewards/accuracies': 0.875, 'rewards/margins': 11.474437713623047, 'logps/rejected': -120.74305725097656, 'logps/chosen': -57.33006286621094, 'logits/rejected': -2.9883484840393066, 'logits/chosen': -2.9277381896972656, 'epoch': 0.6}
{'loss': 0.2464, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -4.901097297668457, 'rewards/rejected': -14.794979095458984, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.893882751464844, 'logps/rejected': -113.4704360961914, 'logps/chosen': -67.29777526855469, 'logits/rejected': -2.9031152725219727, 'logits/chosen': -3.0100340843200684, 'epoch': 0.61}
{'loss': 0.1193, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -5.176901340484619, 'rewards/rejected': -15.571812629699707, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.394911766052246, 'logps/rejected': -111.69830322265625, 'logps/chosen': -71.65951538085938, 'logits/rejected': -2.7794480323791504, 'logits/chosen': -3.0090649127960205, 'epoch': 0.61}
{'loss': 0.161, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -5.558825492858887, 'rewards/rejected': -20.260332107543945, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.701506614685059, 'logps/rejected': -160.28346252441406, 'logps/chosen': -59.27085494995117, 'logits/rejected': -3.167867422103882, 'logits/chosen': -2.6590964794158936, 'epoch': 0.62}
{'loss': 0.0649, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -5.849717617034912, 'rewards/rejected': -17.668214797973633, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.818496704101562, 'logps/rejected': -131.25177001953125, 'logps/chosen': -66.51238250732422, 'logits/rejected': -2.9768741130828857, 'logits/chosen': -3.005643129348755, 'epoch': 0.63}
{'loss': 0.4454, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -5.666341781616211, 'rewards/rejected': -19.302268981933594, 'rewards/accuracies': 1.0, 'rewards/margins': 13.6359281539917, 'logps/rejected': -147.7739715576172, 'logps/chosen': -70.82086944580078, 'logits/rejected': -2.8855600357055664, 'logits/chosen': -2.926504135131836, 'epoch': 0.63}
{'loss': 0.1889, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -6.172381401062012, 'rewards/rejected': -15.873920440673828, 'rewards/accuracies': 0.84375, 'rewards/margins': 9.7015380859375, 'logps/rejected': -114.45333862304688, 'logps/chosen': -69.65010070800781, 'logits/rejected': -2.870793342590332, 'logits/chosen': -2.984365701675415, 'epoch': 0.64}
{'loss': 0.1663, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -5.159528732299805, 'rewards/rejected': -16.01620864868164, 'rewards/accuracies': 0.875, 'rewards/margins': 10.85667896270752, 'logps/rejected': -120.29447937011719, 'logps/chosen': -59.69709777832031, 'logits/rejected': -3.0199942588806152, 'logits/chosen': -2.9285075664520264, 'epoch': 0.65}
{'loss': 0.295, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -4.407805442810059, 'rewards/rejected': -18.02259063720703, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.614785194396973, 'logps/rejected': -132.29039001464844, 'logps/chosen': -54.68834686279297, 'logits/rejected': -2.9968953132629395, 'logits/chosen': -2.9049062728881836, 'epoch': 0.65}
{'loss': 0.1527, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -5.351248741149902, 'rewards/rejected': -21.395540237426758, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.04429054260254, 'logps/rejected': -157.61630249023438, 'logps/chosen': -63.706443786621094, 'logits/rejected': -2.924532651901245, 'logits/chosen': -2.845731496810913, 'epoch': 0.66}
{'loss': 0.5175, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -4.842276096343994, 'rewards/rejected': -15.334758758544922, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.49248218536377, 'logps/rejected': -112.17753601074219, 'logps/chosen': -67.1242904663086, 'logits/rejected': -2.867084503173828, 'logits/chosen': -2.9975380897521973, 'epoch': 0.67}
{'loss': 0.2392, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -5.822269916534424, 'rewards/rejected': -17.70471954345703, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.882450103759766, 'logps/rejected': -135.16433715820312, 'logps/chosen': -73.2764663696289, 'logits/rejected': -2.915379524230957, 'logits/chosen': -2.996445655822754, 'epoch': 0.67}
{'loss': 0.4699, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -4.3714141845703125, 'rewards/rejected': -15.717046737670898, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.345633506774902, 'logps/rejected': -117.56291961669922, 'logps/chosen': -58.33641052246094, 'logits/rejected': -2.8970515727996826, 'logits/chosen': -2.9623100757598877, 'epoch': 0.68}
{'loss': 0.3214, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -5.2736124992370605, 'rewards/rejected': -14.99133586883545, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.717723846435547, 'logps/rejected': -116.295166015625, 'logps/chosen': -67.53680419921875, 'logits/rejected': -2.8367836475372314, 'logits/chosen': -3.0071473121643066, 'epoch': 0.69}
{'loss': 0.3027, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -3.2540929317474365, 'rewards/rejected': -16.94778060913086, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.693685531616211, 'logps/rejected': -128.16122436523438, 'logps/chosen': -47.08221435546875, 'logits/rejected': -3.0031068325042725, 'logits/chosen': -2.7568373680114746, 'epoch': 0.69}
{'loss': 0.2976, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -4.285763263702393, 'rewards/rejected': -15.34600830078125, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.060246467590332, 'logps/rejected': -117.2864990234375, 'logps/chosen': -56.628623962402344, 'logits/rejected': -2.9710142612457275, 'logits/chosen': -2.890324354171753, 'epoch': 0.7}
{'loss': 0.1217, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -4.559391975402832, 'rewards/rejected': -16.69470977783203, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.1353178024292, 'logps/rejected': -127.52631378173828, 'logps/chosen': -63.29016876220703, 'logits/rejected': -2.949787139892578, 'logits/chosen': -2.951594352722168, 'epoch': 0.71}
{'loss': 0.1458, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -2.144700050354004, 'rewards/rejected': -18.79766082763672, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.65296173095703, 'logps/rejected': -143.58290100097656, 'logps/chosen': -44.77164077758789, 'logits/rejected': -3.0278141498565674, 'logits/chosen': -2.762301445007324, 'epoch': 0.71}
{'loss': 0.1721, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -2.667708158493042, 'rewards/rejected': -15.906631469726562, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.238924026489258, 'logps/rejected': -118.11225891113281, 'logps/chosen': -49.19002151489258, 'logits/rejected': -2.9257898330688477, 'logits/chosen': -2.88213849067688, 'epoch': 0.72}
{'loss': 0.299, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -3.954232931137085, 'rewards/rejected': -16.795530319213867, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.841299057006836, 'logps/rejected': -132.2880859375, 'logps/chosen': -53.4769172668457, 'logits/rejected': -2.998755931854248, 'logits/chosen': -2.8183257579803467, 'epoch': 0.73}
{'loss': 0.2356, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -3.3902087211608887, 'rewards/rejected': -15.28669261932373, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.896483421325684, 'logps/rejected': -116.08081817626953, 'logps/chosen': -61.82415008544922, 'logits/rejected': -2.7599804401397705, 'logits/chosen': -2.985431432723999, 'epoch': 0.73}
{'loss': 0.1937, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -3.505523681640625, 'rewards/rejected': -14.971315383911133, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.465791702270508, 'logps/rejected': -119.26853942871094, 'logps/chosen': -49.97525405883789, 'logits/rejected': -3.012160301208496, 'logits/chosen': -2.8190548419952393, 'epoch': 0.74}
{'loss': 0.1247, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -2.69767427444458, 'rewards/rejected': -15.597599029541016, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.899925231933594, 'logps/rejected': -129.6155548095703, 'logps/chosen': -53.616268157958984, 'logits/rejected': -2.943955421447754, 'logits/chosen': -2.904492139816284, 'epoch': 0.75}
{'loss': 0.3338, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -4.9444074630737305, 'rewards/rejected': -16.92803955078125, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.983631134033203, 'logps/rejected': -126.69146728515625, 'logps/chosen': -65.7823486328125, 'logits/rejected': -2.8722336292266846, 'logits/chosen': -2.935380220413208, 'epoch': 0.75}
{'loss': 0.1325, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -3.535686492919922, 'rewards/rejected': -13.782474517822266, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.246786117553711, 'logps/rejected': -109.94991302490234, 'logps/chosen': -54.0244140625, 'logits/rejected': -3.0149455070495605, 'logits/chosen': -2.940425157546997, 'epoch': 0.76}
{'loss': 0.142, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -3.3895699977874756, 'rewards/rejected': -15.994270324707031, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.60469913482666, 'logps/rejected': -126.23296356201172, 'logps/chosen': -49.71055603027344, 'logits/rejected': -3.065056324005127, 'logits/chosen': -2.8288636207580566, 'epoch': 0.77}
{'loss': 0.1374, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -4.732815265655518, 'rewards/rejected': -15.345746040344238, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.612932205200195, 'logps/rejected': -123.0375747680664, 'logps/chosen': -77.37483978271484, 'logits/rejected': -2.894754409790039, 'logits/chosen': -3.0308032035827637, 'epoch': 0.77}
{'loss': 0.1676, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -3.326446771621704, 'rewards/rejected': -12.820196151733398, 'rewards/accuracies': 0.875, 'rewards/margins': 9.493746757507324, 'logps/rejected': -106.36072540283203, 'logps/chosen': -54.76873779296875, 'logits/rejected': -2.9673655033111572, 'logits/chosen': -2.9173367023468018, 'epoch': 0.78}
{'loss': 0.1488, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -4.694423198699951, 'rewards/rejected': -18.477975845336914, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.783554077148438, 'logps/rejected': -143.90150451660156, 'logps/chosen': -64.9166030883789, 'logits/rejected': -2.935220241546631, 'logits/chosen': -2.82025408744812, 'epoch': 0.79}
{'loss': 0.3854, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -4.2652435302734375, 'rewards/rejected': -17.639995574951172, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.374752044677734, 'logps/rejected': -133.59268188476562, 'logps/chosen': -59.53521728515625, 'logits/rejected': -2.910146474838257, 'logits/chosen': -2.901261806488037, 'epoch': 0.8}
{'loss': 0.1737, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -4.38667106628418, 'rewards/rejected': -15.518838882446289, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.13216781616211, 'logps/rejected': -123.7867431640625, 'logps/chosen': -65.41991424560547, 'logits/rejected': -2.8932204246520996, 'logits/chosen': -2.967059850692749, 'epoch': 0.8}
{'loss': 0.1723, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -2.902930736541748, 'rewards/rejected': -11.941099166870117, 'rewards/accuracies': 0.875, 'rewards/margins': 9.038168907165527, 'logps/rejected': -97.72403717041016, 'logps/chosen': -50.352806091308594, 'logits/rejected': -2.9698915481567383, 'logits/chosen': -3.007561206817627, 'epoch': 0.81}
{'loss': 0.2831, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -5.07426643371582, 'rewards/rejected': -14.870025634765625, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.795761108398438, 'logps/rejected': -112.22538757324219, 'logps/chosen': -61.09401321411133, 'logits/rejected': -2.9315218925476074, 'logits/chosen': -2.996044874191284, 'epoch': 0.82}
{'loss': 0.1478, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -5.103986740112305, 'rewards/rejected': -15.714380264282227, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.610392570495605, 'logps/rejected': -123.73651123046875, 'logps/chosen': -62.419578552246094, 'logits/rejected': -3.032003402709961, 'logits/chosen': -2.885479211807251, 'epoch': 0.82}
{'loss': 0.1471, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -2.6825740337371826, 'rewards/rejected': -15.10921859741211, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.426644325256348, 'logps/rejected': -112.38469696044922, 'logps/chosen': -46.40235900878906, 'logits/rejected': -2.910783290863037, 'logits/chosen': -2.938370704650879, 'epoch': 0.83}
{'loss': 0.2586, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -2.521061897277832, 'rewards/rejected': -15.772544860839844, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.251481056213379, 'logps/rejected': -120.12611389160156, 'logps/chosen': -49.280784606933594, 'logits/rejected': -2.990206718444824, 'logits/chosen': -2.8967137336730957, 'epoch': 0.84}
{'loss': 0.1616, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -3.5807809829711914, 'rewards/rejected': -14.896127700805664, 'rewards/accuracies': 0.875, 'rewards/margins': 11.315347671508789, 'logps/rejected': -113.53160858154297, 'logps/chosen': -53.499359130859375, 'logits/rejected': -2.952389717102051, 'logits/chosen': -2.9316792488098145, 'epoch': 0.84}
{'loss': 0.13, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -3.9292943477630615, 'rewards/rejected': -14.922782897949219, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.993488311767578, 'logps/rejected': -112.86697387695312, 'logps/chosen': -58.743492126464844, 'logits/rejected': -2.9348175525665283, 'logits/chosen': -2.9935710430145264, 'epoch': 0.85}
{'loss': 0.2661, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -4.350470542907715, 'rewards/rejected': -17.170835494995117, 'rewards/accuracies': 0.8125, 'rewards/margins': 12.820363998413086, 'logps/rejected': -134.3130645751953, 'logps/chosen': -59.76301574707031, 'logits/rejected': -2.9743599891662598, 'logits/chosen': -2.8802132606506348, 'epoch': 0.86}
{'loss': 0.1971, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -3.6645545959472656, 'rewards/rejected': -15.626612663269043, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.962057113647461, 'logps/rejected': -113.75666809082031, 'logps/chosen': -53.0778694152832, 'logits/rejected': -2.9603333473205566, 'logits/chosen': -2.964643955230713, 'epoch': 0.86}
{'loss': 0.2446, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -3.5888757705688477, 'rewards/rejected': -15.771533966064453, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.182657241821289, 'logps/rejected': -125.37373352050781, 'logps/chosen': -51.23952102661133, 'logits/rejected': -3.0079457759857178, 'logits/chosen': -2.814079523086548, 'epoch': 0.87}
{'loss': 0.1421, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -2.7348623275756836, 'rewards/rejected': -15.399604797363281, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.66474437713623, 'logps/rejected': -119.3783187866211, 'logps/chosen': -56.08869934082031, 'logits/rejected': -2.889026641845703, 'logits/chosen': -2.9777867794036865, 'epoch': 0.88}
{'loss': 0.2535, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -5.0891571044921875, 'rewards/rejected': -15.893758773803711, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.804601669311523, 'logps/rejected': -131.59996032714844, 'logps/chosen': -60.217567443847656, 'logits/rejected': -3.099696397781372, 'logits/chosen': -2.84706449508667, 'epoch': 0.88}
{'loss': 0.1322, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -5.29176139831543, 'rewards/rejected': -17.440288543701172, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.148530006408691, 'logps/rejected': -129.83782958984375, 'logps/chosen': -72.23310089111328, 'logits/rejected': -2.886885166168213, 'logits/chosen': -2.9846627712249756, 'epoch': 0.89}
{'loss': 0.2759, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -4.21162223815918, 'rewards/rejected': -16.504467010498047, 'rewards/accuracies': 0.84375, 'rewards/margins': 12.292845726013184, 'logps/rejected': -133.17152404785156, 'logps/chosen': -58.337791442871094, 'logits/rejected': -3.0131680965423584, 'logits/chosen': -2.910966157913208, 'epoch': 0.9}
{'loss': 0.0674, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -3.564877986907959, 'rewards/rejected': -14.952570915222168, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.387691497802734, 'logps/rejected': -118.98306274414062, 'logps/chosen': -63.310150146484375, 'logits/rejected': -2.864779233932495, 'logits/chosen': -2.9082891941070557, 'epoch': 0.9}
{'loss': 0.1458, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -2.5927278995513916, 'rewards/rejected': -14.759028434753418, 'rewards/accuracies': 0.875, 'rewards/margins': 12.166299819946289, 'logps/rejected': -119.90005493164062, 'logps/chosen': -47.87721252441406, 'logits/rejected': -3.008983850479126, 'logits/chosen': -2.8557987213134766, 'epoch': 0.91}
{'loss': 0.0759, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -4.431453704833984, 'rewards/rejected': -15.936905860900879, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.505451202392578, 'logps/rejected': -123.75313568115234, 'logps/chosen': -68.8768539428711, 'logits/rejected': -2.9086382389068604, 'logits/chosen': -2.9504129886627197, 'epoch': 0.92}
{'loss': 0.1677, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -3.9513354301452637, 'rewards/rejected': -15.907464981079102, 'rewards/accuracies': 1.0, 'rewards/margins': 11.956130027770996, 'logps/rejected': -114.30119323730469, 'logps/chosen': -66.5252456665039, 'logits/rejected': -2.760728597640991, 'logits/chosen': -3.0642707347869873, 'epoch': 0.92}
{'loss': 0.1443, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -3.2193868160247803, 'rewards/rejected': -14.06552791595459, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.846141815185547, 'logps/rejected': -110.22540283203125, 'logps/chosen': -56.25907897949219, 'logits/rejected': -2.95942759513855, 'logits/chosen': -2.9572365283966064, 'epoch': 0.93}
{'loss': 0.2702, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -4.812610626220703, 'rewards/rejected': -16.956565856933594, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.14395523071289, 'logps/rejected': -129.66421508789062, 'logps/chosen': -62.5687370300293, 'logits/rejected': -2.9515597820281982, 'logits/chosen': -2.884514808654785, 'epoch': 0.94}
{'loss': 0.3651, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -5.909591197967529, 'rewards/rejected': -15.01756763458252, 'rewards/accuracies': 0.84375, 'rewards/margins': 9.107977867126465, 'logps/rejected': -109.85547637939453, 'logps/chosen': -76.54360961914062, 'logits/rejected': -2.7923946380615234, 'logits/chosen': -3.1495814323425293, 'epoch': 0.94}
{'loss': 0.4205, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -4.549585342407227, 'rewards/rejected': -15.580612182617188, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.031025886535645, 'logps/rejected': -113.86223602294922, 'logps/chosen': -59.98524856567383, 'logits/rejected': -2.887465476989746, 'logits/chosen': -2.9947824478149414, 'epoch': 0.95}
{'loss': 0.1666, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -2.9629933834075928, 'rewards/rejected': -14.487360954284668, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.524368286132812, 'logps/rejected': -111.6705322265625, 'logps/chosen': -44.90910339355469, 'logits/rejected': -2.9713103771209717, 'logits/chosen': -2.880526304244995, 'epoch': 0.96}
{'loss': 0.1765, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -3.5510506629943848, 'rewards/rejected': -16.625253677368164, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.074202537536621, 'logps/rejected': -132.64321899414062, 'logps/chosen': -49.707130432128906, 'logits/rejected': -3.106499671936035, 'logits/chosen': -2.8206112384796143, 'epoch': 0.96}
{'loss': 0.2366, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -4.5526885986328125, 'rewards/rejected': -13.792024612426758, 'rewards/accuracies': 0.875, 'rewards/margins': 9.239335060119629, 'logps/rejected': -112.74357604980469, 'logps/chosen': -67.24591064453125, 'logits/rejected': -2.8571176528930664, 'logits/chosen': -2.9424240589141846, 'epoch': 0.97}
{'loss': 0.0742, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -2.457303047180176, 'rewards/rejected': -15.696340560913086, 'rewards/accuracies': 0.96875, 'rewards/margins': 13.239036560058594, 'logps/rejected': -117.9846420288086, 'logps/chosen': -50.33931350708008, 'logits/rejected': -2.900740146636963, 'logits/chosen': -2.889103889465332, 'epoch': 0.98}
{'loss': 0.3728, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -5.147608757019043, 'rewards/rejected': -15.8955717086792, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.747962951660156, 'logps/rejected': -117.19380187988281, 'logps/chosen': -70.51205444335938, 'logits/rejected': -2.8601460456848145, 'logits/chosen': -2.9918148517608643, 'epoch': 0.98}
{'loss': 0.1732, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -3.8588850498199463, 'rewards/rejected': -15.890473365783691, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.031587600708008, 'logps/rejected': -122.548828125, 'logps/chosen': -54.25579071044922, 'logits/rejected': -2.9777212142944336, 'logits/chosen': -2.875340700149536, 'epoch': 0.99}
{'loss': 0.2582, 'learning_rate': 0.0, 'rewards/chosen': -3.487783193588257, 'rewards/rejected': -15.45012092590332, 'rewards/accuracies': 0.84375, 'rewards/margins': 11.962337493896484, 'logps/rejected': -114.55536651611328, 'logps/chosen': -52.989768981933594, 'logits/rejected': -2.949795961380005, 'logits/chosen': -2.8996872901916504, 'epoch': 1.0}
{'train_runtime': 1166.962, 'train_samples_per_second': 16.276, 'train_steps_per_second': 0.127, 'train_loss': 0.24376903690800472, 'epoch': 1.0}
