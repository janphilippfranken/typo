[2024-03-13 11:29:30,095] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 11:29:30,143] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 11:29:30,212] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 11:29:30,236] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 11:29:48,055] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 11:29:48,165] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 11:29:48,165] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 11:29:48,217] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 11:29:48,397] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 11:29:48,428][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f82f5facaf0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 11:30:19,171][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-13 11:30:19,177] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-13 11:30:19,360][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f1b6cb04700>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 11:30:19,372][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f07755a8820>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 11:30:19,397][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f9996d50970>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 11:30:52,844] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-13 11:30:52,846] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-13 11:30:52,961] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-13 11:30:52,962] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 11:30:52,962] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 101.77 GB, percent = 10.1%
[2024-03-13 11:30:53,080] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-13 11:30:53,080] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 11:30:53,081] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 99.72 GB, percent = 9.9%
[2024-03-13 11:30:53,081] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f82f5fac430>
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-13 11:30:53,082] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-13 11:30:53,083] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-13 11:30:53,084] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-13 11:30:53,085] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-13 11:30:53,086] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-13 11:30:53,086] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-13 11:30:53,086] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -8.57713508605957, 'logps/chosen': -5.945191860198975, 'logits/rejected': -3.310513734817505, 'logits/chosen': -3.178420305252075, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -6.4359612464904785, 'logps/chosen': -5.295842170715332, 'logits/rejected': -3.21756649017334, 'logits/chosen': -3.114837646484375, 'epoch': 0.01}
{'loss': 0.6955, 'learning_rate': 2e-07, 'rewards/chosen': -0.02143908478319645, 'rewards/rejected': 0.018468286842107773, 'rewards/accuracies': 0.375, 'rewards/margins': -0.03990737348794937, 'logps/rejected': -4.248577117919922, 'logps/chosen': -7.31996488571167, 'logits/rejected': -3.087852716445923, 'logits/chosen': -3.1919779777526855, 'epoch': 0.02}
{'loss': 0.6925, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': -0.01226066704839468, 'rewards/rejected': -0.00735230278223753, 'rewards/accuracies': 0.5, 'rewards/margins': -0.004908363800495863, 'logps/rejected': -5.186363220214844, 'logps/chosen': -4.611718654632568, 'logits/rejected': -3.208810806274414, 'logits/chosen': -3.2112057209014893, 'epoch': 0.03}
{'loss': 0.698, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': -0.004524160176515579, 'rewards/rejected': 0.014535492286086082, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.01905965246260166, 'logps/rejected': -8.367176055908203, 'logps/chosen': -3.7725770473480225, 'logits/rejected': -3.3256330490112305, 'logits/chosen': -2.8925161361694336, 'epoch': 0.03}
{'loss': 0.6921, 'learning_rate': 4e-07, 'rewards/chosen': 0.013067252933979034, 'rewards/rejected': 0.012010468170046806, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.0010567856952548027, 'logps/rejected': -7.331973552703857, 'logps/chosen': -5.62086820602417, 'logits/rejected': -3.1279356479644775, 'logits/chosen': -3.151447057723999, 'epoch': 0.04}
{'loss': 0.6893, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.02141685038805008, 'rewards/rejected': -0.0075162360444664955, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.028933081775903702, 'logps/rejected': -5.325196266174316, 'logps/chosen': -6.137363910675049, 'logits/rejected': -3.100104808807373, 'logits/chosen': -3.219912052154541, 'epoch': 0.05}
{'loss': 0.6872, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.040644071996212006, 'rewards/rejected': -0.01623550057411194, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.05687958002090454, 'logps/rejected': -4.808432579040527, 'logps/chosen': -6.783090591430664, 'logits/rejected': -3.131654977798462, 'logits/chosen': -3.293210744857788, 'epoch': 0.05}
{'loss': 0.7509, 'learning_rate': 6e-07, 'rewards/chosen': -0.024788720533251762, 'rewards/rejected': -0.017220309004187584, 'rewards/accuracies': 0.46875, 'rewards/margins': -0.00756840780377388, 'logps/rejected': -5.493081092834473, 'logps/chosen': -6.540979862213135, 'logits/rejected': -3.2947347164154053, 'logits/chosen': -3.1316215991973877, 'epoch': 0.06}
{'loss': 0.6552, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.017148355022072792, 'rewards/rejected': -0.04020697623491287, 'rewards/accuracies': 0.625, 'rewards/margins': 0.057355333119630814, 'logps/rejected': -7.157723426818848, 'logps/chosen': -7.359156608581543, 'logits/rejected': -3.044940948486328, 'logits/chosen': -3.2496490478515625, 'epoch': 0.07}
{'loss': 0.6807, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': 0.051997359842061996, 'rewards/rejected': -0.07802017033100128, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.13001753389835358, 'logps/rejected': -7.297728061676025, 'logps/chosen': -8.841547012329102, 'logits/rejected': -3.132624626159668, 'logits/chosen': -3.248063325881958, 'epoch': 0.07}
{'loss': 0.6794, 'learning_rate': 8e-07, 'rewards/chosen': -0.012906340882182121, 'rewards/rejected': -0.010406922549009323, 'rewards/accuracies': 0.625, 'rewards/margins': -0.0024994350969791412, 'logps/rejected': -5.510324954986572, 'logps/chosen': -4.778346061706543, 'logits/rejected': -3.160045623779297, 'logits/chosen': -3.225773811340332, 'epoch': 0.08}
{'loss': 0.5881, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': 0.05108675733208656, 'rewards/rejected': -0.2479599118232727, 'rewards/accuracies': 0.75, 'rewards/margins': 0.29904666543006897, 'logps/rejected': -7.3800530433654785, 'logps/chosen': -7.055026531219482, 'logits/rejected': -3.2055764198303223, 'logits/chosen': -3.081295967102051, 'epoch': 0.09}
{'loss': 0.7357, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': 0.09820085018873215, 'rewards/rejected': -0.4258621633052826, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.524062991142273, 'logps/rejected': -10.399076461791992, 'logps/chosen': -6.070132255554199, 'logits/rejected': -3.241431474685669, 'logits/chosen': -3.1084859371185303, 'epoch': 0.09}
{'loss': 0.5382, 'learning_rate': 1e-06, 'rewards/chosen': 0.15005412697792053, 'rewards/rejected': -0.4633292853832245, 'rewards/accuracies': 0.875, 'rewards/margins': 0.613383412361145, 'logps/rejected': -9.729019165039062, 'logps/chosen': -7.133559703826904, 'logits/rejected': -3.1278605461120605, 'logits/chosen': -3.0904459953308105, 'epoch': 0.1}
{'loss': 0.5478, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -0.08785531669855118, 'rewards/rejected': -0.6791239380836487, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.5912686586380005, 'logps/rejected': -8.157629013061523, 'logps/chosen': -4.157989501953125, 'logits/rejected': -3.2701950073242188, 'logits/chosen': -3.053668975830078, 'epoch': 0.11}
{'loss': 0.5492, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -0.12361212074756622, 'rewards/rejected': -0.9246834516525269, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.8010714650154114, 'logps/rejected': -7.328880786895752, 'logps/chosen': -7.567786693572998, 'logits/rejected': -3.2159149646759033, 'logits/chosen': -3.212430953979492, 'epoch': 0.11}
{'loss': 0.6886, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -0.35698166489601135, 'rewards/rejected': -1.7158149480819702, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.3588333129882812, 'logps/rejected': -7.054203987121582, 'logps/chosen': -6.731112480163574, 'logits/rejected': -3.19551682472229, 'logits/chosen': -3.2683701515197754, 'epoch': 0.12}
{'loss': 0.7053, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -0.16697384417057037, 'rewards/rejected': -3.3565449714660645, 'rewards/accuracies': 0.8125, 'rewards/margins': 3.189570903778076, 'logps/rejected': -10.578690528869629, 'logps/chosen': -5.715066432952881, 'logits/rejected': -3.2218244075775146, 'logits/chosen': -3.228534698486328, 'epoch': 0.13}
{'loss': 0.4747, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.426198273897171, 'rewards/rejected': -4.508845329284668, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.082647323608398, 'logps/rejected': -14.553428649902344, 'logps/chosen': -5.610670566558838, 'logits/rejected': -3.2561821937561035, 'logits/chosen': -3.2932512760162354, 'epoch': 0.13}
{'loss': 0.4384, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -0.7987493872642517, 'rewards/rejected': -4.686810493469238, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.8880608081817627, 'logps/rejected': -14.25427532196045, 'logps/chosen': -7.106419563293457, 'logits/rejected': -3.1889548301696777, 'logits/chosen': -3.1592066287994385, 'epoch': 0.14}
{'loss': 0.2656, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -0.6489933729171753, 'rewards/rejected': -7.467225074768066, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.818232536315918, 'logps/rejected': -23.05059051513672, 'logps/chosen': -5.19874382019043, 'logits/rejected': -3.298877477645874, 'logits/chosen': -2.967052459716797, 'epoch': 0.15}
{'loss': 0.8159, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -1.973386526107788, 'rewards/rejected': -8.373924255371094, 'rewards/accuracies': 0.78125, 'rewards/margins': 6.400538444519043, 'logps/rejected': -20.6052188873291, 'logps/chosen': -10.526016235351562, 'logits/rejected': -3.110250234603882, 'logits/chosen': -3.180525064468384, 'epoch': 0.15}
{'loss': 0.4512, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -1.878973126411438, 'rewards/rejected': -8.732404708862305, 'rewards/accuracies': 0.875, 'rewards/margins': 6.853431701660156, 'logps/rejected': -19.90711784362793, 'logps/chosen': -7.260841369628906, 'logits/rejected': -3.266934871673584, 'logits/chosen': -3.111752510070801, 'epoch': 0.16}
{'loss': 0.1753, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -3.697901725769043, 'rewards/rejected': -11.662735939025879, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.964835166931152, 'logps/rejected': -24.23417854309082, 'logps/chosen': -13.527889251708984, 'logits/rejected': -3.2066900730133057, 'logits/chosen': -3.284421443939209, 'epoch': 0.17}
{'loss': 0.5164, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -3.2243754863739014, 'rewards/rejected': -15.667993545532227, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.443617820739746, 'logps/rejected': -34.643150329589844, 'logps/chosen': -11.22037410736084, 'logits/rejected': -3.2284512519836426, 'logits/chosen': -3.116410970687866, 'epoch': 0.18}
{'loss': 0.2819, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -4.0851545333862305, 'rewards/rejected': -15.2311429977417, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.145988464355469, 'logps/rejected': -31.043603897094727, 'logps/chosen': -14.115217208862305, 'logits/rejected': -3.1299798488616943, 'logits/chosen': -3.189938545227051, 'epoch': 0.18}
{'loss': 0.8581, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -5.018722057342529, 'rewards/rejected': -19.008811950683594, 'rewards/accuracies': 0.875, 'rewards/margins': 13.990091323852539, 'logps/rejected': -36.34511184692383, 'logps/chosen': -12.796018600463867, 'logits/rejected': -3.2467751502990723, 'logits/chosen': -3.226065158843994, 'epoch': 0.19}
{'loss': 1.1519, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -7.889955520629883, 'rewards/rejected': -17.874441146850586, 'rewards/accuracies': 0.8125, 'rewards/margins': 9.984484672546387, 'logps/rejected': -36.51203536987305, 'logps/chosen': -19.251846313476562, 'logits/rejected': -3.241046667098999, 'logits/chosen': -3.2795209884643555, 'epoch': 0.2}
{'loss': 0.3103, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -7.032405376434326, 'rewards/rejected': -21.018856048583984, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.9864501953125, 'logps/rejected': -42.05115509033203, 'logps/chosen': -17.895599365234375, 'logits/rejected': -3.231387138366699, 'logits/chosen': -3.2542061805725098, 'epoch': 0.2}
{'loss': 0.8269, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -5.737223148345947, 'rewards/rejected': -26.451351165771484, 'rewards/accuracies': 0.90625, 'rewards/margins': 20.714126586914062, 'logps/rejected': -50.125423431396484, 'logps/chosen': -16.805904388427734, 'logits/rejected': -3.2956902980804443, 'logits/chosen': -3.1391453742980957, 'epoch': 0.21}
{'loss': 0.7421, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -8.70273208618164, 'rewards/rejected': -21.719030380249023, 'rewards/accuracies': 0.8125, 'rewards/margins': 13.016298294067383, 'logps/rejected': -42.41766357421875, 'logps/chosen': -20.835966110229492, 'logits/rejected': -3.219698905944824, 'logits/chosen': -3.2079572677612305, 'epoch': 0.22}
{'loss': 0.6616, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -10.100945472717285, 'rewards/rejected': -22.781850814819336, 'rewards/accuracies': 0.875, 'rewards/margins': 12.680907249450684, 'logps/rejected': -44.23759841918945, 'logps/chosen': -22.01809310913086, 'logits/rejected': -3.262965679168701, 'logits/chosen': -3.2136452198028564, 'epoch': 0.22}
{'loss': 0.795, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -10.471834182739258, 'rewards/rejected': -23.36946678161621, 'rewards/accuracies': 0.875, 'rewards/margins': 12.897632598876953, 'logps/rejected': -45.687679290771484, 'logps/chosen': -22.779529571533203, 'logits/rejected': -3.330620050430298, 'logits/chosen': -3.188062906265259, 'epoch': 0.23}
{'loss': 1.1638, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -13.83172607421875, 'rewards/rejected': -21.305248260498047, 'rewards/accuracies': 0.625, 'rewards/margins': 7.473518371582031, 'logps/rejected': -42.859230041503906, 'logps/chosen': -34.526920318603516, 'logits/rejected': -3.1620731353759766, 'logits/chosen': -3.2791688442230225, 'epoch': 0.24}
{'loss': 0.4269, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -9.272635459899902, 'rewards/rejected': -24.874794006347656, 'rewards/accuracies': 0.875, 'rewards/margins': 15.602157592773438, 'logps/rejected': -45.640953063964844, 'logps/chosen': -20.126605987548828, 'logits/rejected': -3.2931995391845703, 'logits/chosen': -3.2680726051330566, 'epoch': 0.24}
{'loss': 0.5024, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -9.029104232788086, 'rewards/rejected': -31.252674102783203, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.22357177734375, 'logps/rejected': -59.6656608581543, 'logps/chosen': -21.48937225341797, 'logits/rejected': -3.211282968521118, 'logits/chosen': -3.105217933654785, 'epoch': 0.25}
{'loss': 0.8039, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -13.277021408081055, 'rewards/rejected': -27.362138748168945, 'rewards/accuracies': 0.875, 'rewards/margins': 14.085119247436523, 'logps/rejected': -52.263389587402344, 'logps/chosen': -30.261789321899414, 'logits/rejected': -3.1530508995056152, 'logits/chosen': -3.269972085952759, 'epoch': 0.26}
{'loss': 0.6837, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -10.457337379455566, 'rewards/rejected': -28.737293243408203, 'rewards/accuracies': 0.96875, 'rewards/margins': 18.279956817626953, 'logps/rejected': -54.112815856933594, 'logps/chosen': -23.36505889892578, 'logits/rejected': -3.290696859359741, 'logits/chosen': -3.1138691902160645, 'epoch': 0.26}
{'loss': 0.8873, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -16.781747817993164, 'rewards/rejected': -26.969436645507812, 'rewards/accuracies': 0.78125, 'rewards/margins': 10.187688827514648, 'logps/rejected': -52.77762222290039, 'logps/chosen': -39.426025390625, 'logits/rejected': -3.0334956645965576, 'logits/chosen': -3.369894027709961, 'epoch': 0.27}
{'loss': 0.6524, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -14.025938034057617, 'rewards/rejected': -28.04220199584961, 'rewards/accuracies': 0.90625, 'rewards/margins': 14.01626205444336, 'logps/rejected': -52.77139663696289, 'logps/chosen': -31.077024459838867, 'logits/rejected': -3.1503705978393555, 'logits/chosen': -3.1702890396118164, 'epoch': 0.28}
{'loss': 0.3933, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -14.09184455871582, 'rewards/rejected': -32.97166442871094, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.879823684692383, 'logps/rejected': -61.431480407714844, 'logps/chosen': -29.54236602783203, 'logits/rejected': -3.2727699279785156, 'logits/chosen': -3.0760574340820312, 'epoch': 0.28}
{'loss': 0.4281, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -13.881631851196289, 'rewards/rejected': -35.156795501708984, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.27515983581543, 'logps/rejected': -65.50961303710938, 'logps/chosen': -29.130325317382812, 'logits/rejected': -3.2299039363861084, 'logits/chosen': -3.0684995651245117, 'epoch': 0.29}
{'loss': 0.8426, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -13.518814086914062, 'rewards/rejected': -30.207630157470703, 'rewards/accuracies': 0.84375, 'rewards/margins': 16.688812255859375, 'logps/rejected': -59.12516403198242, 'logps/chosen': -27.03286361694336, 'logits/rejected': -3.2320709228515625, 'logits/chosen': -3.192941427230835, 'epoch': 0.3}
{'loss': 0.2808, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -12.444780349731445, 'rewards/rejected': -34.80915069580078, 'rewards/accuracies': 0.9375, 'rewards/margins': 22.364368438720703, 'logps/rejected': -64.22885131835938, 'logps/chosen': -27.571767807006836, 'logits/rejected': -3.1069626808166504, 'logits/chosen': -3.0840494632720947, 'epoch': 0.3}
{'loss': 0.318, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -13.36874008178711, 'rewards/rejected': -39.19456100463867, 'rewards/accuracies': 0.78125, 'rewards/margins': 25.825815200805664, 'logps/rejected': -74.55538940429688, 'logps/chosen': -28.34781265258789, 'logits/rejected': -3.296091318130493, 'logits/chosen': -3.106781482696533, 'epoch': 0.31}
{'loss': 0.2076, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -13.306814193725586, 'rewards/rejected': -38.65548324584961, 'rewards/accuracies': 0.96875, 'rewards/margins': 25.348670959472656, 'logps/rejected': -71.04402160644531, 'logps/chosen': -27.904151916503906, 'logits/rejected': -3.356398820877075, 'logits/chosen': -3.072652816772461, 'epoch': 0.32}
{'loss': 0.3147, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -16.097673416137695, 'rewards/rejected': -38.719215393066406, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.62154197692871, 'logps/rejected': -69.89129638671875, 'logps/chosen': -31.521764755249023, 'logits/rejected': -3.25253963470459, 'logits/chosen': -3.2463674545288086, 'epoch': 0.32}
{'loss': 0.5426, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -15.470739364624023, 'rewards/rejected': -42.32182312011719, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.85108184814453, 'logps/rejected': -77.06202697753906, 'logps/chosen': -31.435619354248047, 'logits/rejected': -3.182490825653076, 'logits/chosen': -3.1686453819274902, 'epoch': 0.33}
{'loss': 0.6548, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -15.748114585876465, 'rewards/rejected': -37.800697326660156, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.052581787109375, 'logps/rejected': -70.8958740234375, 'logps/chosen': -32.32441711425781, 'logits/rejected': -3.3462657928466797, 'logits/chosen': -3.130012035369873, 'epoch': 0.34}
{'loss': 0.2644, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -15.858928680419922, 'rewards/rejected': -34.504512786865234, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.64558219909668, 'logps/rejected': -64.50555419921875, 'logps/chosen': -32.33138656616211, 'logits/rejected': -3.2876598834991455, 'logits/chosen': -3.301649808883667, 'epoch': 0.34}
{'loss': 0.7894, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -15.860346794128418, 'rewards/rejected': -34.57769012451172, 'rewards/accuracies': 0.75, 'rewards/margins': 18.71734619140625, 'logps/rejected': -62.58256530761719, 'logps/chosen': -35.032012939453125, 'logits/rejected': -3.1992597579956055, 'logits/chosen': -3.3091237545013428, 'epoch': 0.35}
{'loss': 0.4821, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -17.734222412109375, 'rewards/rejected': -38.741756439208984, 'rewards/accuracies': 0.84375, 'rewards/margins': 21.007537841796875, 'logps/rejected': -69.93755340576172, 'logps/chosen': -36.96120071411133, 'logits/rejected': -3.2612318992614746, 'logits/chosen': -3.225853443145752, 'epoch': 0.36}
{'loss': 0.9307, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -19.58441925048828, 'rewards/rejected': -41.683841705322266, 'rewards/accuracies': 0.96875, 'rewards/margins': 22.09942054748535, 'logps/rejected': -75.04345703125, 'logps/chosen': -41.130706787109375, 'logits/rejected': -3.088820457458496, 'logits/chosen': -3.1628384590148926, 'epoch': 0.36}
{'loss': 0.3037, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -16.269084930419922, 'rewards/rejected': -30.526134490966797, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.257049560546875, 'logps/rejected': -54.493064880371094, 'logps/chosen': -34.50702667236328, 'logits/rejected': -3.199679374694824, 'logits/chosen': -3.2696545124053955, 'epoch': 0.37}
{'loss': 0.3246, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -17.808521270751953, 'rewards/rejected': -37.43891525268555, 'rewards/accuracies': 0.84375, 'rewards/margins': 19.630395889282227, 'logps/rejected': -68.56344604492188, 'logps/chosen': -33.976402282714844, 'logits/rejected': -3.273068428039551, 'logits/chosen': -3.124558687210083, 'epoch': 0.38}
{'loss': 0.4238, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -19.122943878173828, 'rewards/rejected': -35.40259552001953, 'rewards/accuracies': 0.875, 'rewards/margins': 16.27964973449707, 'logps/rejected': -65.15373992919922, 'logps/chosen': -36.54960250854492, 'logits/rejected': -3.3439884185791016, 'logits/chosen': -3.137002468109131, 'epoch': 0.38}
{'loss': 0.5029, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -18.66661834716797, 'rewards/rejected': -41.29825973510742, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.631643295288086, 'logps/rejected': -75.70450592041016, 'logps/chosen': -37.417381286621094, 'logits/rejected': -3.3664257526397705, 'logits/chosen': -3.1580262184143066, 'epoch': 0.39}
{'loss': 0.513, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -17.75851821899414, 'rewards/rejected': -32.7801399230957, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.021621704101562, 'logps/rejected': -57.890899658203125, 'logps/chosen': -35.501930236816406, 'logits/rejected': -3.207170009613037, 'logits/chosen': -3.2868711948394775, 'epoch': 0.4}
{'loss': 0.406, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -15.736035346984863, 'rewards/rejected': -36.76013946533203, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.02410316467285, 'logps/rejected': -68.59908294677734, 'logps/chosen': -31.12938117980957, 'logits/rejected': -3.2848031520843506, 'logits/chosen': -3.1583492755889893, 'epoch': 0.4}
{'loss': 0.4078, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -16.332382202148438, 'rewards/rejected': -33.129085540771484, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.796703338623047, 'logps/rejected': -59.295867919921875, 'logps/chosen': -33.76025390625, 'logits/rejected': -3.205143928527832, 'logits/chosen': -3.321873664855957, 'epoch': 0.41}
{'loss': 0.7613, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -14.23238468170166, 'rewards/rejected': -36.21821212768555, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.985828399658203, 'logps/rejected': -68.45327758789062, 'logps/chosen': -29.54557991027832, 'logits/rejected': -3.402911424636841, 'logits/chosen': -3.172985315322876, 'epoch': 0.42}
{'loss': 0.415, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -16.09746551513672, 'rewards/rejected': -33.455596923828125, 'rewards/accuracies': 0.75, 'rewards/margins': 17.358131408691406, 'logps/rejected': -61.92293930053711, 'logps/chosen': -31.329200744628906, 'logits/rejected': -3.386842727661133, 'logits/chosen': -3.302065849304199, 'epoch': 0.42}
{'loss': 0.5444, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -14.258748054504395, 'rewards/rejected': -28.298818588256836, 'rewards/accuracies': 0.78125, 'rewards/margins': 14.040071487426758, 'logps/rejected': -52.56583023071289, 'logps/chosen': -29.48454475402832, 'logits/rejected': -3.3644919395446777, 'logits/chosen': -3.3019704818725586, 'epoch': 0.43}
{'loss': 0.4472, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -13.727726936340332, 'rewards/rejected': -39.09938049316406, 'rewards/accuracies': 0.9375, 'rewards/margins': 25.37165641784668, 'logps/rejected': -71.11430358886719, 'logps/chosen': -27.37874984741211, 'logits/rejected': -3.256932258605957, 'logits/chosen': -3.213122844696045, 'epoch': 0.44}
{'loss': 0.6302, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -15.181404113769531, 'rewards/rejected': -35.16070556640625, 'rewards/accuracies': 0.90625, 'rewards/margins': 19.979299545288086, 'logps/rejected': -63.417537689208984, 'logps/chosen': -30.719863891601562, 'logits/rejected': -3.264831304550171, 'logits/chosen': -3.266436815261841, 'epoch': 0.44}
{'loss': 0.3505, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -15.263143539428711, 'rewards/rejected': -34.14546203613281, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.88231658935547, 'logps/rejected': -67.2691879272461, 'logps/chosen': -32.3353385925293, 'logits/rejected': -3.416287660598755, 'logits/chosen': -3.1436922550201416, 'epoch': 0.45}
{'loss': 0.1946, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -14.640953063964844, 'rewards/rejected': -33.29550552368164, 'rewards/accuracies': 0.84375, 'rewards/margins': 18.654552459716797, 'logps/rejected': -62.795135498046875, 'logps/chosen': -31.287494659423828, 'logits/rejected': -3.2677605152130127, 'logits/chosen': -3.2583377361297607, 'epoch': 0.46}
{'loss': 0.6305, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -16.7513484954834, 'rewards/rejected': -37.173545837402344, 'rewards/accuracies': 0.8125, 'rewards/margins': 20.42220115661621, 'logps/rejected': -68.72357940673828, 'logps/chosen': -35.88086700439453, 'logits/rejected': -3.2867891788482666, 'logits/chosen': -3.132920265197754, 'epoch': 0.46}
{'loss': 0.3025, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -13.290136337280273, 'rewards/rejected': -34.54508590698242, 'rewards/accuracies': 0.90625, 'rewards/margins': 21.254947662353516, 'logps/rejected': -62.0011100769043, 'logps/chosen': -27.867361068725586, 'logits/rejected': -3.2528722286224365, 'logits/chosen': -3.1966774463653564, 'epoch': 0.47}
{'loss': 0.6402, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -15.891088485717773, 'rewards/rejected': -31.684207916259766, 'rewards/accuracies': 0.6875, 'rewards/margins': 15.79311752319336, 'logps/rejected': -57.362640380859375, 'logps/chosen': -32.50008773803711, 'logits/rejected': -3.205561637878418, 'logits/chosen': -3.389146327972412, 'epoch': 0.48}
{'loss': 0.2065, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -13.07403564453125, 'rewards/rejected': -35.00642776489258, 'rewards/accuracies': 0.9375, 'rewards/margins': 21.932388305664062, 'logps/rejected': -66.01715087890625, 'logps/chosen': -26.470895767211914, 'logits/rejected': -3.2489373683929443, 'logits/chosen': -3.2031447887420654, 'epoch': 0.49}
{'loss': 0.4948, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -13.207223892211914, 'rewards/rejected': -36.315284729003906, 'rewards/accuracies': 0.90625, 'rewards/margins': 23.108062744140625, 'logps/rejected': -67.699462890625, 'logps/chosen': -26.615602493286133, 'logits/rejected': -3.4736673831939697, 'logits/chosen': -3.10339093208313, 'epoch': 0.49}
{'loss': 0.1929, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -13.810800552368164, 'rewards/rejected': -40.971744537353516, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.160945892333984, 'logps/rejected': -78.12166595458984, 'logps/chosen': -26.918651580810547, 'logits/rejected': -3.382230043411255, 'logits/chosen': -2.9730069637298584, 'epoch': 0.5}
{'loss': 0.503, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -14.707639694213867, 'rewards/rejected': -38.36577606201172, 'rewards/accuracies': 0.9375, 'rewards/margins': 23.65813636779785, 'logps/rejected': -71.09481811523438, 'logps/chosen': -36.028995513916016, 'logits/rejected': -3.1350362300872803, 'logits/chosen': -3.26474666595459, 'epoch': 0.51}
{'loss': 0.2672, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -14.725403785705566, 'rewards/rejected': -36.94038772583008, 'rewards/accuracies': 0.96875, 'rewards/margins': 22.214982986450195, 'logps/rejected': -66.14363098144531, 'logps/chosen': -32.276615142822266, 'logits/rejected': -3.2432234287261963, 'logits/chosen': -3.314116954803467, 'epoch': 0.51}
{'loss': 0.478, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -15.831159591674805, 'rewards/rejected': -39.9084587097168, 'rewards/accuracies': 0.90625, 'rewards/margins': 24.07729721069336, 'logps/rejected': -71.98413848876953, 'logps/chosen': -34.28848648071289, 'logits/rejected': -3.1334633827209473, 'logits/chosen': -3.2191386222839355, 'epoch': 0.52}
{'loss': 0.4912, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -18.301790237426758, 'rewards/rejected': -37.35166549682617, 'rewards/accuracies': 0.90625, 'rewards/margins': 19.049875259399414, 'logps/rejected': -66.9188461303711, 'logps/chosen': -40.0212516784668, 'logits/rejected': -3.106614351272583, 'logits/chosen': -3.313960313796997, 'epoch': 0.53}
{'loss': 0.3395, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -14.962090492248535, 'rewards/rejected': -33.37300491333008, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.41091537475586, 'logps/rejected': -61.13134765625, 'logps/chosen': -29.02849578857422, 'logits/rejected': -3.259449005126953, 'logits/chosen': -3.1246724128723145, 'epoch': 0.53}
{'loss': 0.5231, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -16.202587127685547, 'rewards/rejected': -35.35862731933594, 'rewards/accuracies': 0.84375, 'rewards/margins': 19.156042098999023, 'logps/rejected': -66.83834075927734, 'logps/chosen': -33.74790573120117, 'logits/rejected': -3.264582872390747, 'logits/chosen': -3.191986083984375, 'epoch': 0.54}
{'loss': 0.6374, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -16.830955505371094, 'rewards/rejected': -41.44552230834961, 'rewards/accuracies': 0.9375, 'rewards/margins': 24.614566802978516, 'logps/rejected': -74.24604797363281, 'logps/chosen': -36.27662658691406, 'logits/rejected': -3.0541491508483887, 'logits/chosen': -3.2500855922698975, 'epoch': 0.55}
{'loss': 0.2009, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -17.070560455322266, 'rewards/rejected': -43.86470031738281, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.794139862060547, 'logps/rejected': -78.29390716552734, 'logps/chosen': -34.05417251586914, 'logits/rejected': -3.123178005218506, 'logits/chosen': -3.213834047317505, 'epoch': 0.55}
{'loss': 0.1567, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -15.18625259399414, 'rewards/rejected': -42.00288009643555, 'rewards/accuracies': 0.875, 'rewards/margins': 26.816625595092773, 'logps/rejected': -76.09708404541016, 'logps/chosen': -30.599966049194336, 'logits/rejected': -3.224029541015625, 'logits/chosen': -3.1421117782592773, 'epoch': 0.56}
{'loss': 0.2207, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -20.149028778076172, 'rewards/rejected': -49.55644989013672, 'rewards/accuracies': 0.9375, 'rewards/margins': 29.40742301940918, 'logps/rejected': -89.5694580078125, 'logps/chosen': -42.06757354736328, 'logits/rejected': -3.1115477085113525, 'logits/chosen': -3.1189663410186768, 'epoch': 0.57}
{'loss': 0.359, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -17.99057388305664, 'rewards/rejected': -47.2352180480957, 'rewards/accuracies': 1.0, 'rewards/margins': 29.244644165039062, 'logps/rejected': -85.67695617675781, 'logps/chosen': -37.20952224731445, 'logits/rejected': -3.123682975769043, 'logits/chosen': -3.202188491821289, 'epoch': 0.57}
{'loss': 0.3666, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -20.690948486328125, 'rewards/rejected': -48.46914291381836, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.778196334838867, 'logps/rejected': -86.9434814453125, 'logps/chosen': -40.777278900146484, 'logits/rejected': -3.175389051437378, 'logits/chosen': -3.1820414066314697, 'epoch': 0.58}
{'loss': 0.5428, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -17.964630126953125, 'rewards/rejected': -45.259788513183594, 'rewards/accuracies': 0.875, 'rewards/margins': 27.29515838623047, 'logps/rejected': -82.40205383300781, 'logps/chosen': -36.10914611816406, 'logits/rejected': -3.205923080444336, 'logits/chosen': -3.108488082885742, 'epoch': 0.59}
{'loss': 1.5979, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -22.315574645996094, 'rewards/rejected': -44.55243682861328, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.23686408996582, 'logps/rejected': -80.79234313964844, 'logps/chosen': -41.977054595947266, 'logits/rejected': -3.2052273750305176, 'logits/chosen': -3.2173001766204834, 'epoch': 0.59}
{'loss': 0.6766, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -20.000791549682617, 'rewards/rejected': -48.01261520385742, 'rewards/accuracies': 0.90625, 'rewards/margins': 28.01181983947754, 'logps/rejected': -84.90613555908203, 'logps/chosen': -38.24607849121094, 'logits/rejected': -3.2239155769348145, 'logits/chosen': -3.079550266265869, 'epoch': 0.6}
{'loss': 0.8239, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -25.49553871154785, 'rewards/rejected': -45.772972106933594, 'rewards/accuracies': 0.84375, 'rewards/margins': 20.277433395385742, 'logps/rejected': -81.12771606445312, 'logps/chosen': -49.641700744628906, 'logits/rejected': -3.123258590698242, 'logits/chosen': -3.184340000152588, 'epoch': 0.61}
{'loss': 0.4113, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -26.150066375732422, 'rewards/rejected': -45.62348175048828, 'rewards/accuracies': 0.875, 'rewards/margins': 19.473413467407227, 'logps/rejected': -80.25577545166016, 'logps/chosen': -51.96638870239258, 'logits/rejected': -2.9611001014709473, 'logits/chosen': -3.176948308944702, 'epoch': 0.61}
{'loss': 0.4135, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -20.700515747070312, 'rewards/rejected': -52.734466552734375, 'rewards/accuracies': 0.9375, 'rewards/margins': 32.03395080566406, 'logps/rejected': -99.78617095947266, 'logps/chosen': -38.903770446777344, 'logits/rejected': -3.434000253677368, 'logits/chosen': -2.7319066524505615, 'epoch': 0.62}
{'loss': 0.3405, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -23.923442840576172, 'rewards/rejected': -47.576568603515625, 'rewards/accuracies': 0.8125, 'rewards/margins': 23.653133392333984, 'logps/rejected': -85.6530990600586, 'logps/chosen': -45.57748031616211, 'logits/rejected': -3.185652494430542, 'logits/chosen': -3.175405979156494, 'epoch': 0.63}
{'loss': 0.7035, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -23.65315055847168, 'rewards/rejected': -53.844261169433594, 'rewards/accuracies': 0.96875, 'rewards/margins': 30.19110870361328, 'logps/rejected': -98.40742492675781, 'logps/chosen': -45.042510986328125, 'logits/rejected': -3.1018106937408447, 'logits/chosen': -3.0751309394836426, 'epoch': 0.63}
{'loss': 0.2825, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -23.357669830322266, 'rewards/rejected': -47.52908706665039, 'rewards/accuracies': 0.8125, 'rewards/margins': 24.17141342163086, 'logps/rejected': -83.58544921875, 'logps/chosen': -43.88852310180664, 'logits/rejected': -3.0581936836242676, 'logits/chosen': -3.1600561141967773, 'epoch': 0.64}
{'loss': 0.1658, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -19.255556106567383, 'rewards/rejected': -44.079383850097656, 'rewards/accuracies': 0.84375, 'rewards/margins': 24.823829650878906, 'logps/rejected': -79.68083953857422, 'logps/chosen': -37.992347717285156, 'logits/rejected': -3.241731882095337, 'logits/chosen': -3.078444719314575, 'epoch': 0.65}
{'loss': 0.4877, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -21.87856101989746, 'rewards/rejected': -49.574012756347656, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.695453643798828, 'logps/rejected': -90.3855972290039, 'logps/chosen': -41.250057220458984, 'logits/rejected': -3.209904670715332, 'logits/chosen': -3.0552611351013184, 'epoch': 0.65}
{'loss': 0.2265, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -20.084800720214844, 'rewards/rejected': -57.150482177734375, 'rewards/accuracies': 0.96875, 'rewards/margins': 37.065673828125, 'logps/rejected': -102.76164245605469, 'logps/chosen': -40.281558990478516, 'logits/rejected': -3.1456198692321777, 'logits/chosen': -2.9983911514282227, 'epoch': 0.66}
{'loss': 1.107, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -21.594661712646484, 'rewards/rejected': -44.06476593017578, 'rewards/accuracies': 0.9375, 'rewards/margins': 22.470109939575195, 'logps/rejected': -79.18360137939453, 'logps/chosen': -44.32570266723633, 'logits/rejected': -3.0699236392974854, 'logits/chosen': -3.170846700668335, 'epoch': 0.67}
{'loss': 0.7583, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -22.750986099243164, 'rewards/rejected': -51.40542221069336, 'rewards/accuracies': 0.875, 'rewards/margins': 28.654436111450195, 'logps/rejected': -92.10746765136719, 'logps/chosen': -45.052886962890625, 'logits/rejected': -3.114182710647583, 'logits/chosen': -3.1668593883514404, 'epoch': 0.67}
{'loss': 0.3899, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -20.72113037109375, 'rewards/rejected': -47.67415237426758, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.953020095825195, 'logps/rejected': -84.58805847167969, 'logps/chosen': -40.413124084472656, 'logits/rejected': -3.0998148918151855, 'logits/chosen': -3.1316254138946533, 'epoch': 0.68}
{'loss': 0.4355, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -22.332538604736328, 'rewards/rejected': -45.084312438964844, 'rewards/accuracies': 0.78125, 'rewards/margins': 22.751768112182617, 'logps/rejected': -79.73458862304688, 'logps/chosen': -43.97941589355469, 'logits/rejected': -3.034783363342285, 'logits/chosen': -3.207364082336426, 'epoch': 0.69}
{'loss': 0.5548, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -16.29901885986328, 'rewards/rejected': -45.46007537841797, 'rewards/accuracies': 0.90625, 'rewards/margins': 29.161056518554688, 'logps/rejected': -81.9197006225586, 'logps/chosen': -31.158193588256836, 'logits/rejected': -3.2277307510375977, 'logits/chosen': -2.8591103553771973, 'epoch': 0.69}
{'loss': 1.173, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -17.32494354248047, 'rewards/rejected': -43.77313232421875, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.44818687438965, 'logps/rejected': -80.58021545410156, 'logps/chosen': -35.72001647949219, 'logits/rejected': -3.1950531005859375, 'logits/chosen': -3.040412664413452, 'epoch': 0.7}
{'loss': 0.2577, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -21.837831497192383, 'rewards/rejected': -48.98577117919922, 'rewards/accuracies': 0.90625, 'rewards/margins': 27.147937774658203, 'logps/rejected': -87.64605712890625, 'logps/chosen': -43.01600646972656, 'logits/rejected': -3.169358015060425, 'logits/chosen': -3.110299825668335, 'epoch': 0.71}
{'loss': 0.1199, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -14.530381202697754, 'rewards/rejected': -54.40574264526367, 'rewards/accuracies': 0.96875, 'rewards/margins': 39.875362396240234, 'logps/rejected': -97.84205627441406, 'logps/chosen': -28.68883514404297, 'logits/rejected': -3.2582359313964844, 'logits/chosen': -2.8638830184936523, 'epoch': 0.71}
{'loss': 0.3822, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -17.059158325195312, 'rewards/rejected': -46.04552459716797, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.98636817932129, 'logps/rejected': -81.65486145019531, 'logps/chosen': -34.41413497924805, 'logits/rejected': -3.120600700378418, 'logits/chosen': -3.015377998352051, 'epoch': 0.72}
{'loss': 0.4945, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -17.0816650390625, 'rewards/rejected': -48.83218765258789, 'rewards/accuracies': 0.9375, 'rewards/margins': 31.750520706176758, 'logps/rejected': -88.62298583984375, 'logps/chosen': -34.39348220825195, 'logits/rejected': -3.213468551635742, 'logits/chosen': -2.9242284297943115, 'epoch': 0.73}
{'loss': 0.7651, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -18.789480209350586, 'rewards/rejected': -47.62042236328125, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.8309383392334, 'logps/rejected': -85.54499053955078, 'logps/chosen': -40.217254638671875, 'logits/rejected': -2.92781925201416, 'logits/chosen': -3.1533408164978027, 'epoch': 0.73}
{'loss': 0.7413, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -18.06770133972168, 'rewards/rejected': -45.659542083740234, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.591838836669922, 'logps/rejected': -82.89228820800781, 'logps/chosen': -34.8216667175293, 'logits/rejected': -3.2342538833618164, 'logits/chosen': -2.944915533065796, 'epoch': 0.74}
{'loss': 0.306, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -18.6998348236084, 'rewards/rejected': -49.03826141357422, 'rewards/accuracies': 0.96875, 'rewards/margins': 30.33843231201172, 'logps/rejected': -90.49845886230469, 'logps/chosen': -36.62471389770508, 'logits/rejected': -3.147400379180908, 'logits/chosen': -3.0637896060943604, 'epoch': 0.75}
{'loss': 0.5483, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -21.924400329589844, 'rewards/rejected': -51.52484130859375, 'rewards/accuracies': 0.96875, 'rewards/margins': 29.600440979003906, 'logps/rejected': -92.26670837402344, 'logps/chosen': -44.074188232421875, 'logits/rejected': -3.0570385456085205, 'logits/chosen': -3.085702896118164, 'epoch': 0.75}
{'loss': 0.3639, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -19.789405822753906, 'rewards/rejected': -44.814090728759766, 'rewards/accuracies': 0.9375, 'rewards/margins': 25.024688720703125, 'logps/rejected': -80.53331756591797, 'logps/chosen': -38.181541442871094, 'logits/rejected': -3.232964277267456, 'logits/chosen': -3.108736753463745, 'epoch': 0.76}
{'loss': 0.325, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -17.79673194885254, 'rewards/rejected': -47.069175720214844, 'rewards/accuracies': 0.90625, 'rewards/margins': 29.272443771362305, 'logps/rejected': -85.10173034667969, 'logps/chosen': -33.34326934814453, 'logits/rejected': -3.304811954498291, 'logits/chosen': -2.9621193408966064, 'epoch': 0.77}
{'loss': 0.4968, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -22.51413917541504, 'rewards/rejected': -47.689876556396484, 'rewards/accuracies': 0.875, 'rewards/margins': 25.175735473632812, 'logps/rejected': -86.00080871582031, 'logps/chosen': -45.618919372558594, 'logits/rejected': -3.0868239402770996, 'logits/chosen': -3.2008376121520996, 'epoch': 0.77}
{'loss': 0.4816, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -18.968507766723633, 'rewards/rejected': -39.83409118652344, 'rewards/accuracies': 0.875, 'rewards/margins': 20.86558723449707, 'logps/rejected': -73.1275863647461, 'logps/chosen': -37.733741760253906, 'logits/rejected': -3.16331148147583, 'logits/chosen': -3.072723865509033, 'epoch': 0.78}
{'loss': 0.3792, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -22.35222625732422, 'rewards/rejected': -53.05561065673828, 'rewards/accuracies': 0.84375, 'rewards/margins': 30.703388214111328, 'logps/rejected': -98.19912719726562, 'logps/chosen': -44.33237075805664, 'logits/rejected': -3.145141124725342, 'logits/chosen': -2.934774875640869, 'epoch': 0.79}
{'loss': 0.7976, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -20.198822021484375, 'rewards/rejected': -50.71229553222656, 'rewards/accuracies': 0.9375, 'rewards/margins': 30.513477325439453, 'logps/rejected': -92.29949188232422, 'logps/chosen': -40.28424835205078, 'logits/rejected': -3.1113481521606445, 'logits/chosen': -3.071098804473877, 'epoch': 0.8}
{'loss': 0.3175, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -23.37108612060547, 'rewards/rejected': -50.34925079345703, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.978164672851562, 'logps/rejected': -90.11624908447266, 'logps/chosen': -46.704612731933594, 'logits/rejected': -3.089951992034912, 'logits/chosen': -3.1174588203430176, 'epoch': 0.8}
{'loss': 0.4866, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -17.703632354736328, 'rewards/rejected': -38.347843170166016, 'rewards/accuracies': 0.90625, 'rewards/margins': 20.644208908081055, 'logps/rejected': -69.5272216796875, 'logps/chosen': -35.096858978271484, 'logits/rejected': -3.166801929473877, 'logits/chosen': -3.177725315093994, 'epoch': 0.81}
{'loss': 0.6007, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -22.198740005493164, 'rewards/rejected': -43.64189910888672, 'rewards/accuracies': 0.90625, 'rewards/margins': 21.443157196044922, 'logps/rejected': -78.78352355957031, 'logps/chosen': -43.764766693115234, 'logits/rejected': -3.129502058029175, 'logits/chosen': -3.1637980937957764, 'epoch': 0.82}
{'loss': 0.1996, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -23.687835693359375, 'rewards/rejected': -48.34355926513672, 'rewards/accuracies': 0.90625, 'rewards/margins': 24.655723571777344, 'logps/rejected': -88.56156921386719, 'logps/chosen': -45.18107604980469, 'logits/rejected': -3.22880482673645, 'logits/chosen': -3.020887851715088, 'epoch': 0.82}
{'loss': 0.4402, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -19.512535095214844, 'rewards/rejected': -46.0125732421875, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.500038146972656, 'logps/rejected': -81.59519958496094, 'logps/chosen': -37.24110412597656, 'logits/rejected': -3.1172592639923096, 'logits/chosen': -3.0892417430877686, 'epoch': 0.83}
{'loss': 0.4282, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -17.7728271484375, 'rewards/rejected': -47.213985443115234, 'rewards/accuracies': 0.9375, 'rewards/margins': 29.4411563873291, 'logps/rejected': -85.55714416503906, 'logps/chosen': -35.28535079956055, 'logits/rejected': -3.1877546310424805, 'logits/chosen': -3.0336923599243164, 'epoch': 0.84}
{'loss': 0.3017, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -19.420560836791992, 'rewards/rejected': -47.11521911621094, 'rewards/accuracies': 0.84375, 'rewards/margins': 27.694658279418945, 'logps/rejected': -85.25267028808594, 'logps/chosen': -37.95811462402344, 'logits/rejected': -3.14054274559021, 'logits/chosen': -3.063967704772949, 'epoch': 0.84}
{'loss': 0.6127, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -20.368520736694336, 'rewards/rejected': -42.00663375854492, 'rewards/accuracies': 0.875, 'rewards/margins': 21.638111114501953, 'logps/rejected': -77.41856384277344, 'logps/chosen': -41.07807922363281, 'logits/rejected': -3.107976198196411, 'logits/chosen': -3.1600446701049805, 'epoch': 0.85}
{'loss': 0.2861, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -20.028120040893555, 'rewards/rejected': -47.16737747192383, 'rewards/accuracies': 0.875, 'rewards/margins': 27.139253616333008, 'logps/rejected': -87.31743621826172, 'logps/chosen': -38.81196212768555, 'logits/rejected': -3.1835079193115234, 'logits/chosen': -3.014749526977539, 'epoch': 0.86}
{'loss': 0.2838, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -18.756038665771484, 'rewards/rejected': -44.902896881103516, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.146860122680664, 'logps/rejected': -81.01761627197266, 'logps/chosen': -35.90255355834961, 'logits/rejected': -3.158052444458008, 'logits/chosen': -3.129037618637085, 'epoch': 0.86}
{'loss': 0.7703, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -19.617828369140625, 'rewards/rejected': -47.407875061035156, 'rewards/accuracies': 0.96875, 'rewards/margins': 27.7900447845459, 'logps/rejected': -85.35781860351562, 'logps/chosen': -36.80289077758789, 'logits/rejected': -3.217123508453369, 'logits/chosen': -2.9502789974212646, 'epoch': 0.87}
{'loss': 0.3057, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -17.691471099853516, 'rewards/rejected': -48.330039978027344, 'rewards/accuracies': 0.90625, 'rewards/margins': 30.63856315612793, 'logps/rejected': -87.22360229492188, 'logps/chosen': -36.294986724853516, 'logits/rejected': -3.0855765342712402, 'logits/chosen': -3.1378865242004395, 'epoch': 0.88}
