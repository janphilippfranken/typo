[2024-03-13 14:43:23,656] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 14:43:23,674] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 14:43:23,710] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-13 14:43:23,725] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 14:43:43,303] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 14:43:43,475] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 14:43:43,500] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 14:43:43,500] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-13 14:43:43,730] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-13 14:43:43,743][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f4d6fd19960>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 14:44:14,825][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-13 14:44:14,828] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-13 14:44:15,014][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7fc3c26f42b0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 14:44:15,014][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f4455be42b0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 14:44:15,014][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f8cf04f84c0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-13 14:44:50,158] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-13 14:44:50,159] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-13 14:44:50,278] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-13 14:44:50,279] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 14:44:50,279] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 87.48 GB, percent = 8.7%
[2024-03-13 14:44:50,389] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-13 14:44:50,389] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-13 14:44:50,390] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 86.29 GB, percent = 8.6%
[2024-03-13 14:44:50,390] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4d6fd19fc0>
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-13 14:44:50,391] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-13 14:44:50,392] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-13 14:44:50,393] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-13 14:44:50,394] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-13 14:44:50,394] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.97764587402344, 'logps/chosen': -37.25732421875, 'logits/rejected': -2.988147020339966, 'logits/chosen': -2.862048864364624, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.70320129394531, 'logps/chosen': -36.42850875854492, 'logits/rejected': -2.903564214706421, 'logits/chosen': -2.8116133213043213, 'epoch': 0.01}
{'loss': 0.6935, 'learning_rate': 2e-07, 'rewards/chosen': 0.013471479527652264, 'rewards/rejected': 0.009774129837751389, 'rewards/accuracies': 0.5, 'rewards/margins': 0.003697348525747657, 'logps/rejected': -37.08182144165039, 'logps/chosen': -42.090049743652344, 'logits/rejected': -2.820896625518799, 'logits/chosen': -2.8976030349731445, 'epoch': 0.02}
{'loss': 0.6746, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': -0.0018717874772846699, 'rewards/rejected': -0.018355602398514748, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.016483813524246216, 'logps/rejected': -37.54127883911133, 'logps/chosen': -33.7859001159668, 'logits/rejected': -2.911038637161255, 'logits/chosen': -2.895606517791748, 'epoch': 0.03}
{'loss': 0.6378, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': 0.03342445567250252, 'rewards/rejected': -0.11980605870485306, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.15323051810264587, 'logps/rejected': -53.92174530029297, 'logps/chosen': -32.23647689819336, 'logits/rejected': -3.0430009365081787, 'logits/chosen': -2.624472141265869, 'epoch': 0.03}
{'loss': 0.4797, 'learning_rate': 4e-07, 'rewards/chosen': 0.17243197560310364, 'rewards/rejected': -0.3971404433250427, 'rewards/accuracies': 0.90625, 'rewards/margins': 0.5695724487304688, 'logps/rejected': -43.81758117675781, 'logps/chosen': -38.25191879272461, 'logits/rejected': -2.8624534606933594, 'logits/chosen': -2.854015588760376, 'epoch': 0.04}
{'loss': 0.3462, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.08240517973899841, 'rewards/rejected': -1.1049230098724365, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.1873281002044678, 'logps/rejected': -42.895896911621094, 'logps/chosen': -42.43551254272461, 'logits/rejected': -2.828514575958252, 'logits/chosen': -2.93886661529541, 'epoch': 0.05}
{'loss': 0.2942, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.0012231990694999695, 'rewards/rejected': -1.5657269954681396, 'rewards/accuracies': 0.875, 'rewards/margins': 1.5669503211975098, 'logps/rejected': -36.69378662109375, 'logps/chosen': -45.150306701660156, 'logits/rejected': -2.846816301345825, 'logits/chosen': -2.9795472621917725, 'epoch': 0.05}
{'loss': 0.311, 'learning_rate': 6e-07, 'rewards/chosen': -0.07775275409221649, 'rewards/rejected': -2.621506690979004, 'rewards/accuracies': 0.84375, 'rewards/margins': 2.5437538623809814, 'logps/rejected': -46.38290023803711, 'logps/chosen': -37.96499252319336, 'logits/rejected': -2.997952699661255, 'logits/chosen': -2.8456501960754395, 'epoch': 0.06}
{'loss': 0.2497, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': -0.28826701641082764, 'rewards/rejected': -4.720604419708252, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.432337284088135, 'logps/rejected': -47.5416145324707, 'logps/chosen': -42.81698226928711, 'logits/rejected': -2.8061771392822266, 'logits/chosen': -2.9631595611572266, 'epoch': 0.07}
{'loss': 0.2308, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': -0.4502689838409424, 'rewards/rejected': -4.994568824768066, 'rewards/accuracies': 0.78125, 'rewards/margins': 4.544299602508545, 'logps/rejected': -51.89020919799805, 'logps/chosen': -48.41584014892578, 'logits/rejected': -2.9064857959747314, 'logits/chosen': -3.0141587257385254, 'epoch': 0.07}
{'loss': 0.2441, 'learning_rate': 8e-07, 'rewards/chosen': -0.3405133783817291, 'rewards/rejected': -5.941910743713379, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.601397514343262, 'logps/rejected': -48.98089599609375, 'logps/chosen': -37.239810943603516, 'logits/rejected': -2.907428503036499, 'logits/chosen': -2.9531023502349854, 'epoch': 0.08}
{'loss': 0.1488, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': -0.02111878991127014, 'rewards/rejected': -9.570388793945312, 'rewards/accuracies': 1.0, 'rewards/margins': 9.549270629882812, 'logps/rejected': -57.10584259033203, 'logps/chosen': -42.39112854003906, 'logits/rejected': -2.9448623657226562, 'logits/chosen': -2.864344358444214, 'epoch': 0.09}
{'loss': 0.2727, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': -0.96868896484375, 'rewards/rejected': -11.35579776763916, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.38710880279541, 'logps/rejected': -60.584800720214844, 'logps/chosen': -40.70326232910156, 'logits/rejected': -2.998389482498169, 'logits/chosen': -2.8878889083862305, 'epoch': 0.09}
{'loss': 0.2389, 'learning_rate': 1e-06, 'rewards/chosen': -1.0435549020767212, 'rewards/rejected': -12.380393028259277, 'rewards/accuracies': 1.0, 'rewards/margins': 11.336838722229004, 'logps/rejected': -63.9993896484375, 'logps/chosen': -43.61081314086914, 'logits/rejected': -2.9248523712158203, 'logits/chosen': -2.883063793182373, 'epoch': 0.1}
{'loss': 0.2637, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -3.55668044090271, 'rewards/rejected': -15.635332107543945, 'rewards/accuracies': 0.875, 'rewards/margins': 12.07865047454834, 'logps/rejected': -68.5165023803711, 'logps/chosen': -39.33599853515625, 'logits/rejected': -3.0283801555633545, 'logits/chosen': -2.846747875213623, 'epoch': 0.11}
{'loss': 0.3801, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -4.144388675689697, 'rewards/rejected': -17.786584854125977, 'rewards/accuracies': 1.0, 'rewards/margins': 13.642195701599121, 'logps/rejected': -71.05442810058594, 'logps/chosen': -47.17105484008789, 'logits/rejected': -2.978701591491699, 'logits/chosen': -2.9833621978759766, 'epoch': 0.11}
{'loss': 0.1844, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -3.1788792610168457, 'rewards/rejected': -12.127742767333984, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.948863983154297, 'logps/rejected': -50.2257080078125, 'logps/chosen': -38.47867965698242, 'logits/rejected': -2.9461796283721924, 'logits/chosen': -3.026942491531372, 'epoch': 0.12}
{'loss': 0.1299, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -2.028200626373291, 'rewards/rejected': -13.485179901123047, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.456979751586914, 'logps/rejected': -56.89547348022461, 'logps/chosen': -38.24259567260742, 'logits/rejected': -2.976133346557617, 'logits/chosen': -2.985598087310791, 'epoch': 0.13}
{'loss': 0.257, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.013360992074012756, 'rewards/rejected': -14.843122482299805, 'rewards/accuracies': 0.96875, 'rewards/margins': 14.829761505126953, 'logps/rejected': -64.85306549072266, 'logps/chosen': -41.459842681884766, 'logits/rejected': -3.032200336456299, 'logits/chosen': -3.0863263607025146, 'epoch': 0.13}
{'loss': 0.1591, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -2.4371774196624756, 'rewards/rejected': -15.848824501037598, 'rewards/accuracies': 0.90625, 'rewards/margins': 13.411645889282227, 'logps/rejected': -65.55110931396484, 'logps/chosen': -42.95695114135742, 'logits/rejected': -2.965919017791748, 'logits/chosen': -2.9710144996643066, 'epoch': 0.14}
{'loss': 0.1413, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -2.3583765029907227, 'rewards/rejected': -18.088638305664062, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.730262756347656, 'logps/rejected': -81.00062561035156, 'logps/chosen': -36.02003860473633, 'logits/rejected': -3.055943727493286, 'logits/chosen': -2.7910492420196533, 'epoch': 0.15}
{'loss': 0.8902, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -2.182131767272949, 'rewards/rejected': -15.490227699279785, 'rewards/accuracies': 0.875, 'rewards/margins': 13.308096885681152, 'logps/rejected': -64.20433807373047, 'logps/chosen': -46.561614990234375, 'logits/rejected': -2.9016218185424805, 'logits/chosen': -2.9897148609161377, 'epoch': 0.15}
{'loss': 0.4782, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -1.8850536346435547, 'rewards/rejected': -15.175092697143555, 'rewards/accuracies': 0.875, 'rewards/margins': 13.2900390625, 'logps/rejected': -63.22684097290039, 'logps/chosen': -35.805233001708984, 'logits/rejected': -3.0224311351776123, 'logits/chosen': -2.9142138957977295, 'epoch': 0.16}
{'loss': 0.3244, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -2.1818015575408936, 'rewards/rejected': -15.910420417785645, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.728620529174805, 'logps/rejected': -61.88628005981445, 'logps/chosen': -46.79808807373047, 'logits/rejected': -2.981534481048584, 'logits/chosen': -3.061818838119507, 'epoch': 0.17}
{'loss': 0.3774, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -1.4374899864196777, 'rewards/rejected': -16.855558395385742, 'rewards/accuracies': 0.9375, 'rewards/margins': 15.41806697845459, 'logps/rejected': -75.10887908935547, 'logps/chosen': -43.471961975097656, 'logits/rejected': -3.0292534828186035, 'logits/chosen': -2.9407033920288086, 'epoch': 0.18}
{'loss': 0.3264, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -1.5535095930099487, 'rewards/rejected': -16.479904174804688, 'rewards/accuracies': 0.9375, 'rewards/margins': 14.926395416259766, 'logps/rejected': -61.39148712158203, 'logps/chosen': -48.23102569580078, 'logits/rejected': -2.925187826156616, 'logits/chosen': -3.0084078311920166, 'epoch': 0.18}
{'loss': 0.6679, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -2.583479642868042, 'rewards/rejected': -17.19774627685547, 'rewards/accuracies': 0.875, 'rewards/margins': 14.614266395568848, 'logps/rejected': -61.979164123535156, 'logps/chosen': -40.50527572631836, 'logits/rejected': -3.0133137702941895, 'logits/chosen': -3.0298378467559814, 'epoch': 0.19}
{'loss': 0.8766, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -3.6282167434692383, 'rewards/rejected': -16.116418838500977, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.488202095031738, 'logps/rejected': -63.39649200439453, 'logps/chosen': -43.846885681152344, 'logits/rejected': -3.0209336280822754, 'logits/chosen': -3.069974422454834, 'epoch': 0.2}
{'loss': 0.1099, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -2.3566479682922363, 'rewards/rejected': -18.54717445373535, 'rewards/accuracies': 0.96875, 'rewards/margins': 16.19052505493164, 'logps/rejected': -68.04096984863281, 'logps/chosen': -43.49629211425781, 'logits/rejected': -2.9897921085357666, 'logits/chosen': -3.0353474617004395, 'epoch': 0.2}
{'loss': 0.2756, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -3.1393399238586426, 'rewards/rejected': -22.424739837646484, 'rewards/accuracies': 0.9375, 'rewards/margins': 19.285400390625, 'logps/rejected': -76.8509521484375, 'logps/chosen': -42.6589469909668, 'logits/rejected': -3.04726243019104, 'logits/chosen': -2.9447407722473145, 'epoch': 0.21}
{'loss': 0.1591, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -1.8824365139007568, 'rewards/rejected': -17.887224197387695, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.00478744506836, 'logps/rejected': -67.15422821044922, 'logps/chosen': -42.658695220947266, 'logits/rejected': -2.987982749938965, 'logits/chosen': -2.9990081787109375, 'epoch': 0.22}
{'loss': 1.1967, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -3.8177285194396973, 'rewards/rejected': -19.131349563598633, 'rewards/accuracies': 0.875, 'rewards/margins': 15.313620567321777, 'logps/rejected': -70.48133850097656, 'logps/chosen': -42.473289489746094, 'logits/rejected': -3.0344462394714355, 'logits/chosen': -3.0053982734680176, 'epoch': 0.22}
{'loss': 0.7438, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -5.255476474761963, 'rewards/rejected': -19.0325870513916, 'rewards/accuracies': 0.84375, 'rewards/margins': 13.77711009979248, 'logps/rejected': -68.32820892333984, 'logps/chosen': -43.37303161621094, 'logits/rejected': -3.095978260040283, 'logits/chosen': -2.9947075843811035, 'epoch': 0.23}
{'loss': 1.4762, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -8.988127708435059, 'rewards/rejected': -19.396522521972656, 'rewards/accuracies': 0.78125, 'rewards/margins': 10.408393859863281, 'logps/rejected': -72.6844253540039, 'logps/chosen': -66.98580169677734, 'logits/rejected': -2.981606960296631, 'logits/chosen': -3.086245536804199, 'epoch': 0.24}
{'loss': 0.9465, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -5.313898086547852, 'rewards/rejected': -21.428001403808594, 'rewards/accuracies': 0.875, 'rewards/margins': 16.114103317260742, 'logps/rejected': -68.5816650390625, 'logps/chosen': -41.893028259277344, 'logits/rejected': -3.0999197959899902, 'logits/chosen': -3.0928473472595215, 'epoch': 0.24}
{'loss': 0.3756, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -4.988526821136475, 'rewards/rejected': -24.902477264404297, 'rewards/accuracies': 0.90625, 'rewards/margins': 19.913949966430664, 'logps/rejected': -77.72538757324219, 'logps/chosen': -44.035423278808594, 'logits/rejected': -3.0539259910583496, 'logits/chosen': -2.984434127807617, 'epoch': 0.25}
{'loss': 0.8182, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -5.918549060821533, 'rewards/rejected': -21.009906768798828, 'rewards/accuracies': 0.875, 'rewards/margins': 15.091358184814453, 'logps/rejected': -71.2915267944336, 'logps/chosen': -52.07768249511719, 'logits/rejected': -3.020815372467041, 'logits/chosen': -3.13454008102417, 'epoch': 0.26}
{'loss': 0.2676, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -3.6666202545166016, 'rewards/rejected': -24.893829345703125, 'rewards/accuracies': 0.96875, 'rewards/margins': 21.227209091186523, 'logps/rejected': -79.17272186279297, 'logps/chosen': -42.37043762207031, 'logits/rejected': -3.136749267578125, 'logits/chosen': -3.0158982276916504, 'epoch': 0.26}
{'loss': 0.5749, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -7.079242706298828, 'rewards/rejected': -20.18077850341797, 'rewards/accuracies': 0.8125, 'rewards/margins': 13.101534843444824, 'logps/rejected': -70.03164672851562, 'logps/chosen': -66.72273254394531, 'logits/rejected': -2.979804277420044, 'logits/chosen': -3.282147169113159, 'epoch': 0.27}
{'loss': 0.6548, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -8.341915130615234, 'rewards/rejected': -22.277996063232422, 'rewards/accuracies': 0.9375, 'rewards/margins': 13.93608283996582, 'logps/rejected': -72.68061828613281, 'logps/chosen': -53.357669830322266, 'logits/rejected': -3.056974172592163, 'logits/chosen': -3.07707142829895, 'epoch': 0.28}
{'loss': 0.0768, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -8.177804946899414, 'rewards/rejected': -26.48198890686035, 'rewards/accuracies': 0.96875, 'rewards/margins': 18.304183959960938, 'logps/rejected': -80.08000946044922, 'logps/chosen': -46.421226501464844, 'logits/rejected': -3.162919044494629, 'logits/chosen': -3.0252838134765625, 'epoch': 0.28}
{'loss': 0.4872, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -6.0862627029418945, 'rewards/rejected': -26.168678283691406, 'rewards/accuracies': 0.96875, 'rewards/margins': 20.082416534423828, 'logps/rejected': -79.55644226074219, 'logps/chosen': -44.56549072265625, 'logits/rejected': -3.139570474624634, 'logits/chosen': -3.0231471061706543, 'epoch': 0.29}
{'loss': 0.2901, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -6.848890781402588, 'rewards/rejected': -25.041336059570312, 'rewards/accuracies': 0.9375, 'rewards/margins': 18.192445755004883, 'logps/rejected': -76.20049285888672, 'logps/chosen': -43.89689636230469, 'logits/rejected': -3.127002000808716, 'logits/chosen': -3.1082773208618164, 'epoch': 0.3}
{'loss': 0.1875, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -2.889601230621338, 'rewards/rejected': -25.467098236083984, 'rewards/accuracies': 0.96875, 'rewards/margins': 22.577495574951172, 'logps/rejected': -77.37957763671875, 'logps/chosen': -41.31895065307617, 'logits/rejected': -3.04531192779541, 'logits/chosen': -3.0413360595703125, 'epoch': 0.3}
{'loss': 0.3369, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -4.799842834472656, 'rewards/rejected': -28.315837860107422, 'rewards/accuracies': 0.875, 'rewards/margins': 23.515995025634766, 'logps/rejected': -90.22071075439453, 'logps/chosen': -40.436180114746094, 'logits/rejected': -3.1764214038848877, 'logits/chosen': -3.0282013416290283, 'epoch': 0.31}
{'loss': 0.2072, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -2.8396782875061035, 'rewards/rejected': -26.15377426147461, 'rewards/accuracies': 1.0, 'rewards/margins': 23.314096450805664, 'logps/rejected': -82.9157485961914, 'logps/chosen': -39.342491149902344, 'logits/rejected': -3.2098660469055176, 'logits/chosen': -2.9860854148864746, 'epoch': 0.32}
{'loss': 0.8884, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -4.320837020874023, 'rewards/rejected': -27.029935836791992, 'rewards/accuracies': 0.90625, 'rewards/margins': 22.7091007232666, 'logps/rejected': -76.21231842041016, 'logps/chosen': -40.8182487487793, 'logits/rejected': -3.1290128231048584, 'logits/chosen': -3.1304945945739746, 'epoch': 0.32}
{'loss': 0.4997, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -2.8091983795166016, 'rewards/rejected': -28.304418563842773, 'rewards/accuracies': 1.0, 'rewards/margins': 25.495222091674805, 'logps/rejected': -84.58775329589844, 'logps/chosen': -41.3641242980957, 'logits/rejected': -3.0507314205169678, 'logits/chosen': -3.056711435317993, 'epoch': 0.33}
{'loss': 0.248, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -3.3258655071258545, 'rewards/rejected': -23.865985870361328, 'rewards/accuracies': 0.96875, 'rewards/margins': 20.54012107849121, 'logps/rejected': -80.20569610595703, 'logps/chosen': -39.06254577636719, 'logits/rejected': -3.171682357788086, 'logits/chosen': -3.0131072998046875, 'epoch': 0.34}
{'loss': 1.0107, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -1.5522609949111938, 'rewards/rejected': -21.68659019470215, 'rewards/accuracies': 0.96875, 'rewards/margins': 20.134328842163086, 'logps/rejected': -71.05007934570312, 'logps/chosen': -40.72648620605469, 'logits/rejected': -3.11271333694458, 'logits/chosen': -3.152794361114502, 'epoch': 0.34}
{'loss': 0.9907, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -0.018082886934280396, 'rewards/rejected': -19.994531631469727, 'rewards/accuracies': 0.84375, 'rewards/margins': 19.97644805908203, 'logps/rejected': -65.54058074951172, 'logps/chosen': -44.55228805541992, 'logits/rejected': -3.056520462036133, 'logits/chosen': -3.1639204025268555, 'epoch': 0.35}
{'loss': 0.6214, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -0.8160110712051392, 'rewards/rejected': -22.690576553344727, 'rewards/accuracies': 0.84375, 'rewards/margins': 21.87456512451172, 'logps/rejected': -77.89551544189453, 'logps/chosen': -49.2958984375, 'logits/rejected': -3.111813545227051, 'logits/chosen': -3.0985498428344727, 'epoch': 0.36}
{'loss': 1.0199, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -4.281005859375, 'rewards/rejected': -25.768409729003906, 'rewards/accuracies': 0.9375, 'rewards/margins': 21.487403869628906, 'logps/rejected': -82.34471130371094, 'logps/chosen': -50.29476547241211, 'logits/rejected': -2.968271493911743, 'logits/chosen': -3.0476927757263184, 'epoch': 0.36}
{'loss': 0.3061, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -1.1488550901412964, 'rewards/rejected': -16.824726104736328, 'rewards/accuracies': 0.96875, 'rewards/margins': 15.675870895385742, 'logps/rejected': -60.68683624267578, 'logps/chosen': -40.03822326660156, 'logits/rejected': -3.047224998474121, 'logits/chosen': -3.1280674934387207, 'epoch': 0.37}
{'loss': 0.458, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -3.6129074096679688, 'rewards/rejected': -22.478363037109375, 'rewards/accuracies': 0.875, 'rewards/margins': 18.86545753479004, 'logps/rejected': -70.91986083984375, 'logps/chosen': -39.70420837402344, 'logits/rejected': -3.0949928760528564, 'logits/chosen': -3.0092568397521973, 'epoch': 0.38}
{'loss': 0.2233, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -4.112432479858398, 'rewards/rejected': -21.21904182434082, 'rewards/accuracies': 0.875, 'rewards/margins': 17.106609344482422, 'logps/rejected': -73.82475280761719, 'logps/chosen': -38.890167236328125, 'logits/rejected': -3.134183406829834, 'logits/chosen': -2.9928033351898193, 'epoch': 0.38}
{'loss': 0.299, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -3.96293306350708, 'rewards/rejected': -27.319917678833008, 'rewards/accuracies': 0.96875, 'rewards/margins': 23.356985092163086, 'logps/rejected': -87.41681671142578, 'logps/chosen': -42.65583801269531, 'logits/rejected': -3.1428070068359375, 'logits/chosen': -3.009507179260254, 'epoch': 0.39}
{'loss': 1.1758, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -1.171135663986206, 'rewards/rejected': -18.07569122314453, 'rewards/accuracies': 0.875, 'rewards/margins': 16.904556274414062, 'logps/rejected': -58.84332275390625, 'logps/chosen': -35.09340286254883, 'logits/rejected': -3.036726951599121, 'logits/chosen': -3.122180461883545, 'epoch': 0.4}
{'loss': 0.3903, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -0.7928784489631653, 'rewards/rejected': -24.969507217407227, 'rewards/accuracies': 0.9375, 'rewards/margins': 24.176626205444336, 'logps/rejected': -81.73127746582031, 'logps/chosen': -35.400909423828125, 'logits/rejected': -3.0844359397888184, 'logits/chosen': -3.0128703117370605, 'epoch': 0.4}
{'loss': 0.8391, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -3.9458305835723877, 'rewards/rejected': -20.386316299438477, 'rewards/accuracies': 0.90625, 'rewards/margins': 16.440486907958984, 'logps/rejected': -64.96472930908203, 'logps/chosen': -43.33626937866211, 'logits/rejected': -3.015500068664551, 'logits/chosen': -3.1196932792663574, 'epoch': 0.41}
{'loss': 0.709, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -2.9602904319763184, 'rewards/rejected': -26.461851119995117, 'rewards/accuracies': 0.9375, 'rewards/margins': 23.50156021118164, 'logps/rejected': -82.82975769042969, 'logps/chosen': -36.139801025390625, 'logits/rejected': -3.1414384841918945, 'logits/chosen': -2.976783275604248, 'epoch': 0.42}
{'loss': 0.5468, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -6.922067642211914, 'rewards/rejected': -25.555261611938477, 'rewards/accuracies': 0.8125, 'rewards/margins': 18.633195877075195, 'logps/rejected': -78.70368194580078, 'logps/chosen': -44.56240463256836, 'logits/rejected': -3.1030142307281494, 'logits/chosen': -3.0648789405822754, 'epoch': 0.42}
{'loss': 0.685, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -4.635524749755859, 'rewards/rejected': -21.931882858276367, 'rewards/accuracies': 0.84375, 'rewards/margins': 17.296358108520508, 'logps/rejected': -67.26355743408203, 'logps/chosen': -39.36924362182617, 'logits/rejected': -3.0656356811523438, 'logits/chosen': -3.051677942276001, 'epoch': 0.43}
{'loss': 0.8911, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -2.6791739463806152, 'rewards/rejected': -28.83011817932129, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.15094566345215, 'logps/rejected': -81.2918472290039, 'logps/chosen': -41.58060836791992, 'logits/rejected': -3.0146846771240234, 'logits/chosen': -3.021407127380371, 'epoch': 0.44}
{'loss': 0.8733, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -6.325076103210449, 'rewards/rejected': -27.591163635253906, 'rewards/accuracies': 0.90625, 'rewards/margins': 21.26608657836914, 'logps/rejected': -77.79887390136719, 'logps/chosen': -44.99607849121094, 'logits/rejected': -2.9740116596221924, 'logits/chosen': -3.0292160511016846, 'epoch': 0.44}
{'loss': 0.2473, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -7.932180404663086, 'rewards/rejected': -27.65603256225586, 'rewards/accuracies': 0.875, 'rewards/margins': 19.723854064941406, 'logps/rejected': -87.4690933227539, 'logps/chosen': -50.917396545410156, 'logits/rejected': -3.0927529335021973, 'logits/chosen': -2.9121594429016113, 'epoch': 0.45}
{'loss': 0.1714, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -5.357817649841309, 'rewards/rejected': -24.528621673583984, 'rewards/accuracies': 0.84375, 'rewards/margins': 19.170804977416992, 'logps/rejected': -79.05900573730469, 'logps/chosen': -48.80656433105469, 'logits/rejected': -2.948695659637451, 'logits/chosen': -2.9738545417785645, 'epoch': 0.46}
{'loss': 0.1944, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -7.21874475479126, 'rewards/rejected': -31.469295501708984, 'rewards/accuracies': 0.90625, 'rewards/margins': 24.250547409057617, 'logps/rejected': -88.77436065673828, 'logps/chosen': -50.92861557006836, 'logits/rejected': -2.9814605712890625, 'logits/chosen': -2.9063992500305176, 'epoch': 0.46}
{'loss': 0.3204, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -4.789366245269775, 'rewards/rejected': -26.856338500976562, 'rewards/accuracies': 0.9375, 'rewards/margins': 22.066972732543945, 'logps/rejected': -77.7434310913086, 'logps/chosen': -43.02245330810547, 'logits/rejected': -2.95998477935791, 'logits/chosen': -2.945699453353882, 'epoch': 0.47}
{'loss': 0.7689, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -7.2055864334106445, 'rewards/rejected': -23.654335021972656, 'rewards/accuracies': 0.75, 'rewards/margins': 16.448749542236328, 'logps/rejected': -72.4549560546875, 'logps/chosen': -51.212196350097656, 'logits/rejected': -2.9359915256500244, 'logits/chosen': -3.1188528537750244, 'epoch': 0.48}
{'loss': 0.4425, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -4.6112961769104, 'rewards/rejected': -24.634716033935547, 'rewards/accuracies': 0.8125, 'rewards/margins': 20.02341651916504, 'logps/rejected': -76.84803009033203, 'logps/chosen': -41.55123519897461, 'logits/rejected': -2.946030855178833, 'logits/chosen': -2.9466910362243652, 'epoch': 0.49}
{'loss': 0.5032, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -5.7014689445495605, 'rewards/rejected': -28.968055725097656, 'rewards/accuracies': 0.90625, 'rewards/margins': 23.266586303710938, 'logps/rejected': -89.26315307617188, 'logps/chosen': -40.65536880493164, 'logits/rejected': -3.1124415397644043, 'logits/chosen': -2.8754868507385254, 'epoch': 0.49}
{'loss': 0.1288, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -3.210432767868042, 'rewards/rejected': -36.595970153808594, 'rewards/accuracies': 1.0, 'rewards/margins': 33.385536193847656, 'logps/rejected': -101.556640625, 'logps/chosen': -36.18466567993164, 'logits/rejected': -3.0688211917877197, 'logits/chosen': -2.8138537406921387, 'epoch': 0.5}
{'loss': 0.7726, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -2.5989084243774414, 'rewards/rejected': -29.351469039916992, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.752561569213867, 'logps/rejected': -88.01253509521484, 'logps/chosen': -50.44877243041992, 'logits/rejected': -2.896217107772827, 'logits/chosen': -3.0312771797180176, 'epoch': 0.51}
{'loss': 0.4653, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -5.085336685180664, 'rewards/rejected': -28.570606231689453, 'rewards/accuracies': 0.9375, 'rewards/margins': 23.485267639160156, 'logps/rejected': -77.4725570678711, 'logps/chosen': -48.06243896484375, 'logits/rejected': -2.948315382003784, 'logits/chosen': -3.0465810298919678, 'epoch': 0.51}
{'loss': 0.2412, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -3.090102195739746, 'rewards/rejected': -28.33122444152832, 'rewards/accuracies': 1.0, 'rewards/margins': 25.241119384765625, 'logps/rejected': -80.41671752929688, 'logps/chosen': -49.12665939331055, 'logits/rejected': -2.902646541595459, 'logits/chosen': -3.012411594390869, 'epoch': 0.52}
{'loss': 0.3101, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -7.025451183319092, 'rewards/rejected': -27.00635528564453, 'rewards/accuracies': 0.90625, 'rewards/margins': 19.98090362548828, 'logps/rejected': -72.57422637939453, 'logps/chosen': -53.850830078125, 'logits/rejected': -2.8752822875976562, 'logits/chosen': -3.0648725032806396, 'epoch': 0.53}
{'loss': 0.3568, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -3.716198444366455, 'rewards/rejected': -22.940683364868164, 'rewards/accuracies': 0.96875, 'rewards/margins': 19.224483489990234, 'logps/rejected': -70.67459106445312, 'logps/chosen': -38.80385971069336, 'logits/rejected': -3.0003061294555664, 'logits/chosen': -2.936633586883545, 'epoch': 0.53}
{'loss': 0.292, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -3.3590803146362305, 'rewards/rejected': -24.28285789489746, 'rewards/accuracies': 0.875, 'rewards/margins': 20.923776626586914, 'logps/rejected': -70.66641998291016, 'logps/chosen': -40.325565338134766, 'logits/rejected': -2.9839704036712646, 'logits/chosen': -2.9654793739318848, 'epoch': 0.54}
{'loss': 0.5465, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -3.0277316570281982, 'rewards/rejected': -27.523746490478516, 'rewards/accuracies': 0.9375, 'rewards/margins': 24.496013641357422, 'logps/rejected': -76.60050201416016, 'logps/chosen': -46.18958282470703, 'logits/rejected': -2.8588058948516846, 'logits/chosen': -3.0529325008392334, 'epoch': 0.55}
{'loss': 0.4521, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -2.0256614685058594, 'rewards/rejected': -26.720361709594727, 'rewards/accuracies': 0.90625, 'rewards/margins': 24.694698333740234, 'logps/rejected': -73.13368225097656, 'logps/chosen': -42.505897521972656, 'logits/rejected': -2.9146766662597656, 'logits/chosen': -3.0240767002105713, 'epoch': 0.55}
{'loss': 0.5022, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -4.752467155456543, 'rewards/rejected': -29.311687469482422, 'rewards/accuracies': 0.875, 'rewards/margins': 24.559219360351562, 'logps/rejected': -80.92344665527344, 'logps/chosen': -44.94446563720703, 'logits/rejected': -2.9646618366241455, 'logits/chosen': -2.960822105407715, 'epoch': 0.56}
{'loss': 0.4188, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -8.00526237487793, 'rewards/rejected': -35.6005859375, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.595325469970703, 'logps/rejected': -98.40553283691406, 'logps/chosen': -54.308998107910156, 'logits/rejected': -2.8796722888946533, 'logits/chosen': -2.9258182048797607, 'epoch': 0.57}
{'loss': 0.246, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -4.894248008728027, 'rewards/rejected': -35.89181900024414, 'rewards/accuracies': 1.0, 'rewards/margins': 30.997570037841797, 'logps/rejected': -93.81916046142578, 'logps/chosen': -46.161903381347656, 'logits/rejected': -2.9124836921691895, 'logits/chosen': -3.022728681564331, 'epoch': 0.57}
{'loss': 0.1898, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -7.485721588134766, 'rewards/rejected': -33.79977798461914, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.314058303833008, 'logps/rejected': -88.8328857421875, 'logps/chosen': -52.45518112182617, 'logits/rejected': -2.932546854019165, 'logits/chosen': -2.9907782077789307, 'epoch': 0.58}
{'loss': 0.4183, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -4.792535305023193, 'rewards/rejected': -32.202152252197266, 'rewards/accuracies': 0.90625, 'rewards/margins': 27.409618377685547, 'logps/rejected': -86.18934631347656, 'logps/chosen': -43.36717224121094, 'logits/rejected': -2.9651451110839844, 'logits/chosen': -2.9475581645965576, 'epoch': 0.59}
{'loss': 2.1596, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -9.348249435424805, 'rewards/rejected': -33.17952346801758, 'rewards/accuracies': 0.90625, 'rewards/margins': 23.83127784729004, 'logps/rejected': -84.90782165527344, 'logps/chosen': -50.04084777832031, 'logits/rejected': -2.9412479400634766, 'logits/chosen': -2.999049663543701, 'epoch': 0.59}
{'loss': 0.5324, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -7.631068229675293, 'rewards/rejected': -34.519996643066406, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.88892936706543, 'logps/rejected': -89.38007354736328, 'logps/chosen': -44.92650604248047, 'logits/rejected': -2.9540185928344727, 'logits/chosen': -2.898623466491699, 'epoch': 0.6}
{'loss': 0.5562, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -10.59827995300293, 'rewards/rejected': -32.26045608520508, 'rewards/accuracies': 0.875, 'rewards/margins': 21.66217613220215, 'logps/rejected': -85.58190155029297, 'logps/chosen': -57.93268585205078, 'logits/rejected': -2.888681411743164, 'logits/chosen': -2.9831814765930176, 'epoch': 0.61}
{'loss': 0.3573, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -9.759283065795898, 'rewards/rejected': -33.35157775878906, 'rewards/accuracies': 0.90625, 'rewards/margins': 23.592294692993164, 'logps/rejected': -81.48434448242188, 'logps/chosen': -59.71684265136719, 'logits/rejected': -2.762678861618042, 'logits/chosen': -2.9753644466400146, 'epoch': 0.61}
{'loss': 0.3027, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -9.159265518188477, 'rewards/rejected': -41.53200912475586, 'rewards/accuracies': 0.9375, 'rewards/margins': 32.37274169921875, 'logps/rejected': -118.31324005126953, 'logps/chosen': -44.56139373779297, 'logits/rejected': -3.090020179748535, 'logits/chosen': -2.6148855686187744, 'epoch': 0.62}
{'loss': 0.0927, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -10.83751106262207, 'rewards/rejected': -37.08085250854492, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.243337631225586, 'logps/rejected': -95.88333892822266, 'logps/chosen': -52.74595260620117, 'logits/rejected': -2.9068801403045654, 'logits/chosen': -2.9360134601593018, 'epoch': 0.63}
{'loss': 0.7838, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -11.496940612792969, 'rewards/rejected': -40.93838119506836, 'rewards/accuracies': 0.9375, 'rewards/margins': 29.441436767578125, 'logps/rejected': -109.74601745605469, 'logps/chosen': -58.91336441040039, 'logits/rejected': -2.8607773780822754, 'logits/chosen': -2.883139133453369, 'epoch': 0.63}
{'loss': 0.3002, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -11.216605186462402, 'rewards/rejected': -33.34714889526367, 'rewards/accuracies': 0.875, 'rewards/margins': 22.13054656982422, 'logps/rejected': -82.72254180908203, 'logps/chosen': -54.811912536621094, 'logits/rejected': -2.8288750648498535, 'logits/chosen': -2.946150302886963, 'epoch': 0.64}
{'loss': 0.4526, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -11.033795356750488, 'rewards/rejected': -34.16502380371094, 'rewards/accuracies': 0.90625, 'rewards/margins': 23.131227493286133, 'logps/rejected': -89.0206298828125, 'logps/chosen': -49.66201400756836, 'logits/rejected': -2.9509010314941406, 'logits/chosen': -2.8615922927856445, 'epoch': 0.65}
{'loss': 0.9181, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -10.55370807647705, 'rewards/rejected': -38.94377517700195, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.39006805419922, 'logps/rejected': -97.8114013671875, 'logps/chosen': -47.72604751586914, 'logits/rejected': -2.930649518966675, 'logits/chosen': -2.8488576412200928, 'epoch': 0.65}
{'loss': 0.5865, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -11.642707824707031, 'rewards/rejected': -46.101627349853516, 'rewards/accuracies': 0.96875, 'rewards/margins': 34.45892333984375, 'logps/rejected': -116.49807739257812, 'logps/chosen': -53.58263397216797, 'logits/rejected': -2.885261058807373, 'logits/chosen': -2.792080879211426, 'epoch': 0.66}
{'loss': 1.6787, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -11.086210250854492, 'rewards/rejected': -35.83256530761719, 'rewards/accuracies': 0.96875, 'rewards/margins': 24.746356964111328, 'logps/rejected': -86.693115234375, 'logps/chosen': -58.75034713745117, 'logits/rejected': -2.8109679222106934, 'logits/chosen': -2.935300827026367, 'epoch': 0.67}
{'loss': 0.2424, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -13.249916076660156, 'rewards/rejected': -41.67361068725586, 'rewards/accuracies': 0.96875, 'rewards/margins': 28.423696517944336, 'logps/rejected': -106.17446899414062, 'logps/chosen': -63.09355545043945, 'logits/rejected': -2.878425359725952, 'logits/chosen': -2.946613073348999, 'epoch': 0.67}
{'loss': 1.4275, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -12.003293991088867, 'rewards/rejected': -36.49015808105469, 'rewards/accuracies': 0.90625, 'rewards/margins': 24.48686408996582, 'logps/rejected': -91.10648345947266, 'logps/chosen': -53.62690353393555, 'logits/rejected': -2.850698947906494, 'logits/chosen': -2.9007930755615234, 'epoch': 0.68}
{'loss': 1.1506, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -14.322120666503906, 'rewards/rejected': -34.89731216430664, 'rewards/accuracies': 0.875, 'rewards/margins': 20.575193405151367, 'logps/rejected': -91.19180297851562, 'logps/chosen': -61.62891387939453, 'logits/rejected': -2.7804014682769775, 'logits/chosen': -2.9404122829437256, 'epoch': 0.69}
{'loss': 0.7654, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -7.899022579193115, 'rewards/rejected': -38.860198974609375, 'rewards/accuracies': 0.9375, 'rewards/margins': 30.9611759185791, 'logps/rejected': -98.93690490722656, 'logps/chosen': -42.09606170654297, 'logits/rejected': -2.9387094974517822, 'logits/chosen': -2.693103075027466, 'epoch': 0.69}
{'loss': 0.7903, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -11.02197551727295, 'rewards/rejected': -37.41264724731445, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.390670776367188, 'logps/rejected': -94.00308227539062, 'logps/chosen': -50.94548797607422, 'logits/rejected': -2.9206156730651855, 'logits/chosen': -2.8363845348358154, 'epoch': 0.7}
{'loss': 0.5634, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -12.267939567565918, 'rewards/rejected': -38.913265228271484, 'rewards/accuracies': 0.875, 'rewards/margins': 26.64532470703125, 'logps/rejected': -99.64315032958984, 'logps/chosen': -58.018836975097656, 'logits/rejected': -2.898165464401245, 'logits/chosen': -2.8788540363311768, 'epoch': 0.71}
{'loss': 0.5314, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -6.957767486572266, 'rewards/rejected': -43.19159698486328, 'rewards/accuracies': 0.9375, 'rewards/margins': 36.233829498291016, 'logps/rejected': -111.29688262939453, 'logps/chosen': -43.9878044128418, 'logits/rejected': -2.984673500061035, 'logits/chosen': -2.6983392238616943, 'epoch': 0.71}
{'loss': 0.2816, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -9.56729507446289, 'rewards/rejected': -37.81556701660156, 'rewards/accuracies': 0.96875, 'rewards/margins': 28.248268127441406, 'logps/rejected': -92.60133361816406, 'logps/chosen': -49.51904296875, 'logits/rejected': -2.8834667205810547, 'logits/chosen': -2.823631525039673, 'epoch': 0.72}
{'loss': 0.9632, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -12.600381851196289, 'rewards/rejected': -40.11842727661133, 'rewards/accuracies': 0.84375, 'rewards/margins': 27.518049240112305, 'logps/rejected': -105.62247467041016, 'logps/chosen': -51.706298828125, 'logits/rejected': -2.95953631401062, 'logits/chosen': -2.757047414779663, 'epoch': 0.73}
{'loss': 0.9162, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -9.42795181274414, 'rewards/rejected': -37.29892349243164, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.8709716796875, 'logps/rejected': -92.93152618408203, 'logps/chosen': -58.341609954833984, 'logits/rejected': -2.757596969604492, 'logits/chosen': -2.9421029090881348, 'epoch': 0.73}
{'loss': 0.6061, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -11.207430839538574, 'rewards/rejected': -37.3167839050293, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.109355926513672, 'logps/rejected': -97.72167205810547, 'logps/chosen': -48.458251953125, 'logits/rejected': -2.977942943572998, 'logits/chosen': -2.7622852325439453, 'epoch': 0.74}
{'loss': 0.5544, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -9.306711196899414, 'rewards/rejected': -39.317352294921875, 'rewards/accuracies': 0.9375, 'rewards/margins': 30.010644912719727, 'logps/rejected': -107.79521942138672, 'logps/chosen': -53.42319869995117, 'logits/rejected': -2.920508861541748, 'logits/chosen': -2.8699262142181396, 'epoch': 0.75}
{'loss': 1.1712, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -14.525328636169434, 'rewards/rejected': -43.0302619934082, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.504932403564453, 'logps/rejected': -103.52308654785156, 'logps/chosen': -61.81077575683594, 'logits/rejected': -2.8547379970550537, 'logits/chosen': -2.890692949295044, 'epoch': 0.75}
{'loss': 0.5763, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -12.185301780700684, 'rewards/rejected': -38.77342224121094, 'rewards/accuracies': 0.9375, 'rewards/margins': 26.588125228881836, 'logps/rejected': -96.42816162109375, 'logps/chosen': -53.75355911254883, 'logits/rejected': -3.0005133152008057, 'logits/chosen': -2.913954973220825, 'epoch': 0.76}
{'loss': 0.5746, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -11.520118713378906, 'rewards/rejected': -40.52099609375, 'rewards/accuracies': 0.90625, 'rewards/margins': 29.000873565673828, 'logps/rejected': -104.14875030517578, 'logps/chosen': -49.22002410888672, 'logits/rejected': -3.0498764514923096, 'logits/chosen': -2.779855251312256, 'epoch': 0.77}
{'loss': 0.3511, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -12.661273956298828, 'rewards/rejected': -40.10450744628906, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.443233489990234, 'logps/rejected': -103.60101318359375, 'logps/chosen': -71.79830169677734, 'logits/rejected': -2.897522449493408, 'logits/chosen': -3.004049777984619, 'epoch': 0.77}
{'loss': 0.4385, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -8.683131217956543, 'rewards/rejected': -31.58197021484375, 'rewards/accuracies': 0.84375, 'rewards/margins': 22.89883804321289, 'logps/rejected': -87.37686157226562, 'logps/chosen': -50.54097366333008, 'logits/rejected': -2.964393377304077, 'logits/chosen': -2.8933651447296143, 'epoch': 0.78}
{'loss': 0.472, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -13.86570930480957, 'rewards/rejected': -45.556434631347656, 'rewards/accuracies': 0.875, 'rewards/margins': 31.690725326538086, 'logps/rejected': -116.59222412109375, 'logps/chosen': -61.252647399902344, 'logits/rejected': -2.94730281829834, 'logits/chosen': -2.781644344329834, 'epoch': 0.79}
{'loss': 1.5127, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -13.155553817749023, 'rewards/rejected': -44.5810661315918, 'rewards/accuracies': 0.9375, 'rewards/margins': 31.425518035888672, 'logps/rejected': -109.0799331665039, 'logps/chosen': -57.002647399902344, 'logits/rejected': -2.912243604660034, 'logits/chosen': -2.880728244781494, 'epoch': 0.8}
{'loss': 0.2592, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -12.724349021911621, 'rewards/rejected': -39.83222961425781, 'rewards/accuracies': 0.875, 'rewards/margins': 27.107879638671875, 'logps/rejected': -103.09573364257812, 'logps/chosen': -61.66419982910156, 'logits/rejected': -2.9033772945404053, 'logits/chosen': -2.9469404220581055, 'epoch': 0.8}
{'loss': 0.3862, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -9.376426696777344, 'rewards/rejected': -30.6014461517334, 'rewards/accuracies': 0.875, 'rewards/margins': 21.225017547607422, 'logps/rejected': -81.73489379882812, 'logps/chosen': -49.23303985595703, 'logits/rejected': -2.9738426208496094, 'logits/chosen': -2.987029552459717, 'epoch': 0.81}
{'loss': 1.0851, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -14.63090705871582, 'rewards/rejected': -35.894569396972656, 'rewards/accuracies': 0.90625, 'rewards/margins': 21.26366424560547, 'logps/rejected': -89.1532211303711, 'logps/chosen': -56.623985290527344, 'logits/rejected': -2.9251480102539062, 'logits/chosen': -2.9630255699157715, 'epoch': 0.82}
{'loss': 0.2613, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -15.969557762145996, 'rewards/rejected': -41.32524871826172, 'rewards/accuracies': 0.90625, 'rewards/margins': 25.355690002441406, 'logps/rejected': -104.20068359375, 'logps/chosen': -59.71329116821289, 'logits/rejected': -3.0317447185516357, 'logits/chosen': -2.863617420196533, 'epoch': 0.82}
{'loss': 0.3317, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -9.109947204589844, 'rewards/rejected': -37.02717971801758, 'rewards/accuracies': 0.90625, 'rewards/margins': 27.9172306060791, 'logps/rejected': -89.73457336425781, 'logps/chosen': -46.00369644165039, 'logits/rejected': -2.915465831756592, 'logits/chosen': -2.910094976425171, 'epoch': 0.83}
{'loss': 1.094, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -9.408257484436035, 'rewards/rejected': -39.3345832824707, 'rewards/accuracies': 0.96875, 'rewards/margins': 29.926326751708984, 'logps/rejected': -97.45567321777344, 'logps/chosen': -50.115840911865234, 'logits/rejected': -2.987938642501831, 'logits/chosen': -2.88032865524292, 'epoch': 0.84}
{'loss': 0.487, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -11.92577838897705, 'rewards/rejected': -37.15018081665039, 'rewards/accuracies': 0.8125, 'rewards/margins': 25.224403381347656, 'logps/rejected': -92.12266540527344, 'logps/chosen': -52.63227462768555, 'logits/rejected': -2.9711880683898926, 'logits/chosen': -2.9155595302581787, 'epoch': 0.84}
{'loss': 0.221, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -12.005701065063477, 'rewards/rejected': -38.21915817260742, 'rewards/accuracies': 0.84375, 'rewards/margins': 26.213455200195312, 'logps/rejected': -92.85186004638672, 'logps/chosen': -56.24802017211914, 'logits/rejected': -2.9504549503326416, 'logits/chosen': -2.986450433731079, 'epoch': 0.85}
{'loss': 0.5224, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -13.024380683898926, 'rewards/rejected': -42.73112106323242, 'rewards/accuracies': 0.84375, 'rewards/margins': 29.706737518310547, 'logps/rejected': -109.50335693359375, 'logps/chosen': -56.616920471191406, 'logits/rejected': -2.9752726554870605, 'logits/chosen': -2.8509087562561035, 'epoch': 0.86}
{'loss': 0.7172, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -12.194540023803711, 'rewards/rejected': -38.5711784362793, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.376636505126953, 'logps/rejected': -90.72528839111328, 'logps/chosen': -52.175872802734375, 'logits/rejected': -2.960832357406616, 'logits/chosen': -2.947218656539917, 'epoch': 0.86}
{'loss': 0.9537, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -10.86363697052002, 'rewards/rejected': -38.99378967285156, 'rewards/accuracies': 0.9375, 'rewards/margins': 28.130146026611328, 'logps/rejected': -102.22147369384766, 'logps/chosen': -48.81462478637695, 'logits/rejected': -3.0210001468658447, 'logits/chosen': -2.796251058578491, 'epoch': 0.87}
{'loss': 0.9116, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -8.082751274108887, 'rewards/rejected': -39.423797607421875, 'rewards/accuracies': 0.90625, 'rewards/margins': 31.341045379638672, 'logps/rejected': -98.69999694824219, 'logps/chosen': -53.961181640625, 'logits/rejected': -2.9018192291259766, 'logits/chosen': -2.9627561569213867, 'epoch': 0.88}
{'loss': 0.7138, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -15.553766250610352, 'rewards/rejected': -39.51551818847656, 'rewards/accuracies': 0.84375, 'rewards/margins': 23.961753845214844, 'logps/rejected': -108.5819091796875, 'logps/chosen': -56.99144744873047, 'logits/rejected': -3.0907421112060547, 'logits/chosen': -2.826340436935425, 'epoch': 0.88}
{'loss': 0.4344, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -15.544349670410156, 'rewards/rejected': -42.1431999206543, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.59885025024414, 'logps/rejected': -102.8409652709961, 'logps/chosen': -67.98050689697266, 'logits/rejected': -2.8980793952941895, 'logits/chosen': -2.965454578399658, 'epoch': 0.89}
{'loss': 0.5457, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -12.046713829040527, 'rewards/rejected': -41.50371551513672, 'rewards/accuracies': 0.875, 'rewards/margins': 29.457000732421875, 'logps/rejected': -109.9402084350586, 'logps/chosen': -54.489280700683594, 'logits/rejected': -3.0239758491516113, 'logits/chosen': -2.903987169265747, 'epoch': 0.9}
{'loss': 0.1129, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -10.385663986206055, 'rewards/rejected': -37.921714782714844, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.536054611206055, 'logps/rejected': -98.39408874511719, 'logps/chosen': -60.322425842285156, 'logits/rejected': -2.8734240531921387, 'logits/chosen': -2.88818359375, 'epoch': 0.9}
{'loss': 0.2726, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -8.079630851745605, 'rewards/rejected': -36.2214469909668, 'rewards/accuracies': 0.90625, 'rewards/margins': 28.141817092895508, 'logps/rejected': -97.84983825683594, 'logps/chosen': -46.455902099609375, 'logits/rejected': -3.0039491653442383, 'logits/chosen': -2.8252978324890137, 'epoch': 0.91}
{'loss': 0.202, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -12.319018363952637, 'rewards/rejected': -39.11036682128906, 'rewards/accuracies': 0.90625, 'rewards/margins': 26.79134750366211, 'logps/rejected': -99.94055938720703, 'logps/chosen': -64.31819152832031, 'logits/rejected': -2.9255120754241943, 'logits/chosen': -2.9352269172668457, 'epoch': 0.92}
{'loss': 0.4265, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -11.650424003601074, 'rewards/rejected': -39.455387115478516, 'rewards/accuracies': 0.96875, 'rewards/margins': 27.804964065551758, 'logps/rejected': -91.12869262695312, 'logps/chosen': -63.41203689575195, 'logits/rejected': -2.771569013595581, 'logits/chosen': -3.0500454902648926, 'epoch': 0.92}
{'loss': 0.7926, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -9.459781646728516, 'rewards/rejected': -33.06856918334961, 'rewards/accuracies': 0.875, 'rewards/margins': 23.608783721923828, 'logps/rejected': -87.1385726928711, 'logps/chosen': -53.676124572753906, 'logits/rejected': -2.9566690921783447, 'logits/chosen': -2.9347949028015137, 'epoch': 0.93}
{'loss': 0.6073, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -13.015970230102539, 'rewards/rejected': -40.299766540527344, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.28380012512207, 'logps/rejected': -102.45249938964844, 'logps/chosen': -57.09992599487305, 'logits/rejected': -2.9654154777526855, 'logits/chosen': -2.8712620735168457, 'epoch': 0.94}
{'loss': 1.3451, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -16.97456932067871, 'rewards/rejected': -38.10558319091797, 'rewards/accuracies': 0.875, 'rewards/margins': 21.131017684936523, 'logps/rejected': -89.20419311523438, 'logps/chosen': -71.24504089355469, 'logits/rejected': -2.8014464378356934, 'logits/chosen': -3.136564016342163, 'epoch': 0.94}
{'loss': 1.551, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -11.837307929992676, 'rewards/rejected': -37.172027587890625, 'rewards/accuracies': 0.9375, 'rewards/margins': 25.334716796875, 'logps/rejected': -89.06208038330078, 'logps/chosen': -54.147762298583984, 'logits/rejected': -2.8878233432769775, 'logits/chosen': -2.9825973510742188, 'epoch': 0.95}
{'loss': 0.4021, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -9.704383850097656, 'rewards/rejected': -36.26866912841797, 'rewards/accuracies': 0.96875, 'rewards/margins': 26.56428337097168, 'logps/rejected': -91.0461196899414, 'logps/chosen': -43.95754623413086, 'logits/rejected': -2.983919620513916, 'logits/chosen': -2.872262954711914, 'epoch': 0.96}
{'loss': 0.6049, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -11.331907272338867, 'rewards/rejected': -40.21329116821289, 'rewards/accuracies': 0.96875, 'rewards/margins': 28.88138198852539, 'logps/rejected': -106.96451568603516, 'logps/chosen': -48.14031982421875, 'logits/rejected': -3.1109111309051514, 'logits/chosen': -2.7995612621307373, 'epoch': 0.96}
{'loss': 0.5925, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -13.126220703125, 'rewards/rejected': -33.34664535522461, 'rewards/accuracies': 0.84375, 'rewards/margins': 20.220422744750977, 'logps/rejected': -91.42152404785156, 'logps/chosen': -63.23421096801758, 'logits/rejected': -2.877012252807617, 'logits/chosen': -2.9344594478607178, 'epoch': 0.97}
{'loss': 0.2073, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -6.491403579711914, 'rewards/rejected': -37.93288803100586, 'rewards/accuracies': 0.96875, 'rewards/margins': 31.441484451293945, 'logps/rejected': -93.69277954101562, 'logps/chosen': -47.32623291015625, 'logits/rejected': -2.9069623947143555, 'logits/chosen': -2.8639819622039795, 'epoch': 0.98}
{'loss': 0.8244, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -13.188333511352539, 'rewards/rejected': -37.69381332397461, 'rewards/accuracies': 0.875, 'rewards/margins': 24.50547981262207, 'logps/rejected': -91.56423950195312, 'logps/chosen': -63.61449432373047, 'logits/rejected': -2.879427909851074, 'logits/chosen': -2.9824647903442383, 'epoch': 0.98}
{'loss': 0.7378, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -10.584383964538574, 'rewards/rejected': -37.79738998413086, 'rewards/accuracies': 0.9375, 'rewards/margins': 27.213003158569336, 'logps/rejected': -97.09273529052734, 'logps/chosen': -50.0819091796875, 'logits/rejected': -2.9928555488586426, 'logits/chosen': -2.8604214191436768, 'epoch': 0.99}
{'loss': 1.386, 'learning_rate': 0.0, 'rewards/chosen': -11.770275115966797, 'rewards/rejected': -36.848480224609375, 'rewards/accuracies': 0.8125, 'rewards/margins': 25.07820701599121, 'logps/rejected': -89.9454574584961, 'logps/chosen': -52.365535736083984, 'logits/rejected': -2.956179141998291, 'logits/chosen': -2.877392530441284, 'epoch': 1.0}
{'train_runtime': 1165.8182, 'train_samples_per_second': 16.292, 'train_steps_per_second': 0.127, 'train_loss': 0.5615743448504725, 'epoch': 1.0}
