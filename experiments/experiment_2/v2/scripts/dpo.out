[2024-03-12 16:17:42,239] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 16:17:42,267] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 16:17:42,311] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 16:17:42,335] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 16:18:00,802] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-12 16:18:00,802] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 16:18:01,038] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-12 16:18:01,053][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f58bd943f10>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
5000
4497
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 16:18:01,320] [INFO] [comm.py:637:init_distributed] cdb=None
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 16:18:01,415] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-12 16:18:32,159][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-12 16:18:32,163] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-12 16:18:32,324][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f56221c0970>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 16:18:32,334][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7fea454c0a60>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 16:18:32,337][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f38ed9bbfa0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 16:19:08,306] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-12 16:19:08,308] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-12 16:19:08,428] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-12 16:19:08,429] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-12 16:19:08,430] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 101.12 GB, percent = 10.0%
[2024-03-12 16:19:08,548] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-12 16:19:08,549] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-12 16:19:08,549] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 98.76 GB, percent = 9.8%
[2024-03-12 16:19:08,550] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-12 16:19:08,550] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f58bd943d00>
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-12 16:19:08,551] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-12 16:19:08,552] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-12 16:19:08,553] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-12 16:19:08,554] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-12 16:19:08,554] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.97764587402344, 'logps/chosen': -37.25732421875, 'logits/rejected': -2.988147020339966, 'logits/chosen': -2.862048864364624, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -42.70320129394531, 'logps/chosen': -36.42850875854492, 'logits/rejected': -2.903564214706421, 'logits/chosen': -2.8116133213043213, 'epoch': 0.01}
{'loss': 0.693, 'learning_rate': 2e-07, 'rewards/chosen': -0.00038996923831291497, 'rewards/rejected': 0.0007445630617439747, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0011345326201990247, 'logps/rejected': -37.088340759277344, 'logps/chosen': -42.113197326660156, 'logits/rejected': -2.8205695152282715, 'logits/chosen': -2.8978123664855957, 'epoch': 0.02}
{'loss': 0.6904, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': -0.0013235778314992785, 'rewards/rejected': 0.00012168008834123611, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.0014452573377639055, 'logps/rejected': -37.51383972167969, 'logps/chosen': -33.79646301269531, 'logits/rejected': -2.911297559738159, 'logits/chosen': -2.8963029384613037, 'epoch': 0.03}
{'loss': 0.6851, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': 0.005574584472924471, 'rewards/rejected': -0.003278899472206831, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.008853483013808727, 'logps/rejected': -53.78338623046875, 'logps/chosen': -32.228477478027344, 'logits/rejected': -3.0426743030548096, 'logits/chosen': -2.6237716674804688, 'epoch': 0.03}
{'loss': 0.6531, 'learning_rate': 4e-07, 'rewards/chosen': 0.023651480674743652, 'rewards/rejected': -0.054268695414066315, 'rewards/accuracies': 0.875, 'rewards/margins': 0.07792017608880997, 'logps/rejected': -43.79293441772461, 'logps/chosen': -38.26173400878906, 'logits/rejected': -2.8624751567840576, 'logits/chosen': -2.8541009426116943, 'epoch': 0.04}
{'loss': 0.613, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.011599504388868809, 'rewards/rejected': -0.16725654900074005, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.17885605990886688, 'logps/rejected': -42.98999786376953, 'logps/chosen': -42.43724060058594, 'logits/rejected': -2.8301193714141846, 'logits/chosen': -2.9401140213012695, 'epoch': 0.05}
{'loss': 0.5784, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.017571013420820236, 'rewards/rejected': -0.2210216075181961, 'rewards/accuracies': 0.875, 'rewards/margins': 0.23859263956546783, 'logps/rejected': -36.66725540161133, 'logps/chosen': -44.97634506225586, 'logits/rejected': -2.851675033569336, 'logits/chosen': -2.983025312423706, 'epoch': 0.05}
{'loss': 0.5629, 'learning_rate': 6e-07, 'rewards/chosen': -0.011584113352000713, 'rewards/rejected': -0.3933399021625519, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.3817557692527771, 'logps/rejected': -46.571285247802734, 'logps/chosen': -37.969757080078125, 'logits/rejected': -3.003220796585083, 'logits/chosen': -2.850189685821533, 'epoch': 0.06}
{'loss': 0.4362, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': -0.10644958168268204, 'rewards/rejected': -0.8423684239387512, 'rewards/accuracies': 0.90625, 'rewards/margins': 0.7359188199043274, 'logps/rejected': -49.221580505371094, 'logps/chosen': -43.46967315673828, 'logits/rejected': -2.8160080909729004, 'logits/chosen': -2.9700610637664795, 'epoch': 0.07}
{'loss': 0.3873, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': -0.12415028363466263, 'rewards/rejected': -0.9288488030433655, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.8046985864639282, 'logps/rejected': -54.04359436035156, 'logps/chosen': -49.01409912109375, 'logits/rejected': -2.913532257080078, 'logits/chosen': -3.019498586654663, 'epoch': 0.07}
{'loss': 0.362, 'learning_rate': 8e-07, 'rewards/chosen': -0.18207760155200958, 'rewards/rejected': -1.1545917987823486, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.9725140929222107, 'logps/rejected': -52.03836441040039, 'logps/chosen': -38.57413864135742, 'logits/rejected': -2.9137797355651855, 'logits/chosen': -2.9583370685577393, 'epoch': 0.08}
{'loss': 0.2868, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': -0.250446617603302, 'rewards/rejected': -2.5829102993011475, 'rewards/accuracies': 0.96875, 'rewards/margins': 2.3324637413024902, 'logps/rejected': -69.2629623413086, 'logps/chosen': -44.86542510986328, 'logits/rejected': -2.927741527557373, 'logits/chosen': -2.863417148590088, 'epoch': 0.09}
{'loss': 0.2693, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': -0.6957855820655823, 'rewards/rejected': -3.5023739337921143, 'rewards/accuracies': 0.9375, 'rewards/margins': 2.806588649749756, 'logps/rejected': -79.38597106933594, 'logps/chosen': -46.277278900146484, 'logits/rejected': -2.988877773284912, 'logits/chosen': -2.8851029872894287, 'epoch': 0.09}
{'loss': 0.2819, 'learning_rate': 1e-06, 'rewards/chosen': -0.5469342470169067, 'rewards/rejected': -3.714759349822998, 'rewards/accuracies': 0.96875, 'rewards/margins': 3.167825222015381, 'logps/rejected': -83.46070098876953, 'logps/chosen': -47.589359283447266, 'logits/rejected': -2.914217948913574, 'logits/chosen': -2.8864805698394775, 'epoch': 0.1}
{'loss': 0.2122, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -1.4988516569137573, 'rewards/rejected': -4.649669170379639, 'rewards/accuracies': 0.875, 'rewards/margins': 3.150817632675171, 'logps/rejected': -92.677001953125, 'logps/chosen': -49.24353790283203, 'logits/rejected': -3.0028862953186035, 'logits/chosen': -2.835387945175171, 'epoch': 0.11}
{'loss': 0.2, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -1.7936179637908936, 'rewards/rejected': -5.753881454467773, 'rewards/accuracies': 0.875, 'rewards/margins': 3.960263729095459, 'logps/rejected': -103.183837890625, 'logps/chosen': -59.186683654785156, 'logits/rejected': -2.9639203548431396, 'logits/chosen': -2.9766438007354736, 'epoch': 0.11}
{'loss': 0.1967, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -1.4359691143035889, 'rewards/rejected': -4.272895812988281, 'rewards/accuracies': 0.9375, 'rewards/margins': 2.8369269371032715, 'logps/rejected': -75.62931823730469, 'logps/chosen': -48.297119140625, 'logits/rejected': -2.931622266769409, 'logits/chosen': -3.0212881565093994, 'epoch': 0.12}
{'loss': 0.2022, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -1.5687371492385864, 'rewards/rejected': -5.2693023681640625, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.7005655765533447, 'logps/rejected': -90.3239517211914, 'logps/chosen': -51.03253173828125, 'logits/rejected': -2.93267822265625, 'logits/chosen': -2.947584629058838, 'epoch': 0.13}
{'loss': 0.2671, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.9698560237884521, 'rewards/rejected': -6.33133602142334, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.36147928237915, 'logps/rejected': -106.96195983886719, 'logps/chosen': -51.139312744140625, 'logits/rejected': -2.9708070755004883, 'logits/chosen': -3.024401903152466, 'epoch': 0.13}
{'loss': 0.147, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -1.9205669164657593, 'rewards/rejected': -6.512172698974609, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.591606140136719, 'logps/rejected': -108.03166198730469, 'logps/chosen': -58.680938720703125, 'logits/rejected': -2.8894762992858887, 'logits/chosen': -2.899066686630249, 'epoch': 0.14}
{'loss': 0.1437, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -1.8819624185562134, 'rewards/rejected': -8.088086128234863, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.2061238288879395, 'logps/rejected': -136.04058837890625, 'logps/chosen': -51.470550537109375, 'logits/rejected': -2.9877443313598633, 'logits/chosen': -2.7497196197509766, 'epoch': 0.15}
{'loss': 0.183, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -1.9574110507965088, 'rewards/rejected': -7.170116424560547, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.212705135345459, 'logps/rejected': -113.776611328125, 'logps/chosen': -63.01840591430664, 'logits/rejected': -2.818455457687378, 'logits/chosen': -2.912177085876465, 'epoch': 0.15}
{'loss': 0.2259, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -1.8204848766326904, 'rewards/rejected': -6.718147277832031, 'rewards/accuracies': 0.875, 'rewards/margins': 4.897662162780762, 'logps/rejected': -108.72960662841797, 'logps/chosen': -51.31714630126953, 'logits/rejected': -2.9467201232910156, 'logits/chosen': -2.8501250743865967, 'epoch': 0.16}
{'loss': 0.1297, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -1.7931091785430908, 'rewards/rejected': -6.758697509765625, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.9655890464782715, 'logps/rejected': -106.74407958984375, 'logps/chosen': -61.61232376098633, 'logits/rejected': -2.90191912651062, 'logits/chosen': -2.998149871826172, 'epoch': 0.17}
{'loss': 0.1751, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -1.5130702257156372, 'rewards/rejected': -7.48331356048584, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.970242977142334, 'logps/rejected': -125.86263275146484, 'logps/chosen': -56.54910659790039, 'logits/rejected': -2.9592480659484863, 'logits/chosen': -2.86698317527771, 'epoch': 0.18}
{'loss': 0.1672, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -1.5850396156311035, 'rewards/rejected': -6.892705917358398, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.307666301727295, 'logps/rejected': -106.77581787109375, 'logps/chosen': -61.86211395263672, 'logits/rejected': -2.852217435836792, 'logits/chosen': -2.949507713317871, 'epoch': 0.18}
{'loss': 0.2319, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -1.1605671644210815, 'rewards/rejected': -6.378478527069092, 'rewards/accuracies': 0.875, 'rewards/margins': 5.2179107666015625, 'logps/rejected': -101.19573211669922, 'logps/chosen': -48.420265197753906, 'logits/rejected': -2.944352149963379, 'logits/chosen': -2.958024740219116, 'epoch': 0.19}
{'loss': 0.2547, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -1.563646674156189, 'rewards/rejected': -6.092595100402832, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.528948783874512, 'logps/rejected': -101.29898834228516, 'logps/chosen': -54.30018615722656, 'logits/rejected': -2.9525094032287598, 'logits/chosen': -3.0018510818481445, 'epoch': 0.2}
{'loss': 0.1042, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -1.6340171098709106, 'rewards/rejected': -7.002604007720947, 'rewards/accuracies': 0.96875, 'rewards/margins': 5.368587017059326, 'logps/rejected': -111.571044921875, 'logps/chosen': -56.469825744628906, 'logits/rejected': -2.925868511199951, 'logits/chosen': -2.9859859943389893, 'epoch': 0.2}
{'loss': 0.15, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -1.7053875923156738, 'rewards/rejected': -8.171528816223145, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.466141223907471, 'logps/rejected': -126.53089904785156, 'logps/chosen': -55.228050231933594, 'logits/rejected': -2.9591386318206787, 'logits/chosen': -2.8904335498809814, 'epoch': 0.21}
{'loss': 0.1059, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -1.7483068704605103, 'rewards/rejected': -7.525571823120117, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.7772650718688965, 'logps/rejected': -116.85676574707031, 'logps/chosen': -57.45256423950195, 'logits/rejected': -2.893169641494751, 'logits/chosen': -2.9021503925323486, 'epoch': 0.22}
{'loss': 0.1615, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -2.534395694732666, 'rewards/rejected': -8.23696231842041, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.702565670013428, 'logps/rejected': -125.52045440673828, 'logps/chosen': -62.36334991455078, 'logits/rejected': -2.9494469165802, 'logits/chosen': -2.925847053527832, 'epoch': 0.22}
{'loss': 0.284, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -3.2001543045043945, 'rewards/rejected': -7.639952182769775, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.439798831939697, 'logps/rejected': -117.53832244873047, 'logps/chosen': -67.86674499511719, 'logits/rejected': -3.005824565887451, 'logits/chosen': -2.9181809425354004, 'epoch': 0.23}
{'loss': 0.3804, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -4.033145904541016, 'rewards/rejected': -7.614102840423584, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.580955982208252, 'logps/rejected': -121.11613464355469, 'logps/chosen': -94.47708129882812, 'logits/rejected': -2.8899879455566406, 'logits/chosen': -3.021808385848999, 'epoch': 0.24}
{'loss': 0.2246, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -3.268031358718872, 'rewards/rejected': -8.275489807128906, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.00745964050293, 'logps/rejected': -120.72513580322266, 'logps/chosen': -66.9820556640625, 'logits/rejected': -2.9980123043060303, 'logits/chosen': -2.990455150604248, 'epoch': 0.24}
{'loss': 0.219, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -3.3069424629211426, 'rewards/rejected': -9.416650772094727, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.109707832336426, 'logps/rejected': -136.3169403076172, 'logps/chosen': -69.97838592529297, 'logits/rejected': -2.9316461086273193, 'logits/chosen': -2.87251877784729, 'epoch': 0.25}
{'loss': 0.2625, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -2.9366159439086914, 'rewards/rejected': -8.255773544311523, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.319157600402832, 'logps/rejected': -123.83511352539062, 'logps/chosen': -72.98876953125, 'logits/rejected': -2.8802852630615234, 'logits/chosen': -3.0067176818847656, 'epoch': 0.26}
{'loss': 0.1248, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -2.6727592945098877, 'rewards/rejected': -9.362931251525879, 'rewards/accuracies': 1.0, 'rewards/margins': 6.690171241760254, 'logps/rejected': -137.2394256591797, 'logps/chosen': -63.8599967956543, 'logits/rejected': -3.005420207977295, 'logits/chosen': -2.866682529449463, 'epoch': 0.26}
{'loss': 0.3099, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -2.981698989868164, 'rewards/rejected': -6.97003173828125, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.988333225250244, 'logps/rejected': -110.90228271484375, 'logps/chosen': -86.426513671875, 'logits/rejected': -2.791099786758423, 'logits/chosen': -3.105463743209839, 'epoch': 0.27}
{'loss': 0.1781, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -3.0307936668395996, 'rewards/rejected': -8.967557907104492, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.936763763427734, 'logps/rejected': -130.53048706054688, 'logps/chosen': -71.74858093261719, 'logits/rejected': -2.9136388301849365, 'logits/chosen': -2.9325716495513916, 'epoch': 0.28}
{'loss': 0.1102, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -3.696837902069092, 'rewards/rejected': -10.320067405700684, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.623229503631592, 'logps/rejected': -145.44927978515625, 'logps/chosen': -71.70703125, 'logits/rejected': -2.98765230178833, 'logits/chosen': -2.8572769165039062, 'epoch': 0.28}
{'loss': 0.1345, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -3.4231879711151123, 'rewards/rejected': -10.753983497619629, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.330796241760254, 'logps/rejected': -149.7124786376953, 'logps/chosen': -70.10271453857422, 'logits/rejected': -2.9703829288482666, 'logits/chosen': -2.8759632110595703, 'epoch': 0.29}
{'loss': 0.1468, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -3.373746871948242, 'rewards/rejected': -9.337940216064453, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.964193344116211, 'logps/rejected': -133.80654907226562, 'logps/chosen': -67.85023498535156, 'logits/rejected': -2.963592529296875, 'logits/chosen': -2.948761463165283, 'epoch': 0.3}
{'loss': 0.1004, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -2.7466893196105957, 'rewards/rejected': -10.05448055267334, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.307791233062744, 'logps/rejected': -141.54281616210938, 'logps/chosen': -64.65784454345703, 'logits/rejected': -2.8884220123291016, 'logits/chosen': -2.8917503356933594, 'epoch': 0.3}
{'loss': 0.1218, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -2.996001720428467, 'rewards/rejected': -10.233562469482422, 'rewards/accuracies': 0.875, 'rewards/margins': 7.23756217956543, 'logps/rejected': -152.10516357421875, 'logps/chosen': -63.539276123046875, 'logits/rejected': -3.051989793777466, 'logits/chosen': -2.9075372219085693, 'epoch': 0.31}
{'loss': 0.1577, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -2.578343629837036, 'rewards/rejected': -10.18024730682373, 'rewards/accuracies': 1.0, 'rewards/margins': 7.601902961730957, 'logps/rejected': -147.3556671142578, 'logps/chosen': -61.069244384765625, 'logits/rejected': -3.108503818511963, 'logits/chosen': -2.8837597370147705, 'epoch': 0.32}
{'loss': 0.2068, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -2.4582483768463135, 'rewards/rejected': -8.972562789916992, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.514315605163574, 'logps/rejected': -127.3237533569336, 'logps/chosen': -59.22810745239258, 'logits/rejected': -2.995305061340332, 'logits/chosen': -3.0003445148468018, 'epoch': 0.32}
{'loss': 0.2094, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -1.8930096626281738, 'rewards/rejected': -9.01496696472168, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.121957778930664, 'logps/rejected': -134.3025360107422, 'logps/chosen': -56.28107833862305, 'logits/rejected': -2.9433345794677734, 'logits/chosen': -2.9448134899139404, 'epoch': 0.33}
{'loss': 0.1545, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -1.8786226511001587, 'rewards/rejected': -8.124692916870117, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.246069431304932, 'logps/rejected': -127.35835266113281, 'logps/chosen': -53.0975341796875, 'logits/rejected': -3.077488422393799, 'logits/chosen': -2.8944926261901855, 'epoch': 0.34}
{'loss': 0.1662, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -1.9806115627288818, 'rewards/rejected': -8.015122413635254, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.034510135650635, 'logps/rejected': -120.22045135498047, 'logps/chosen': -58.315086364746094, 'logits/rejected': -3.0199995040893555, 'logits/chosen': -3.0384671688079834, 'epoch': 0.34}
{'loss': 0.2568, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -1.0406591892242432, 'rewards/rejected': -6.769021034240723, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.7283616065979, 'logps/rejected': -104.66717529296875, 'logps/chosen': -54.93305206298828, 'logits/rejected': -2.9513659477233887, 'logits/chosen': -3.063718557357788, 'epoch': 0.35}
{'loss': 0.1676, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -1.6053268909454346, 'rewards/rejected': -8.159465789794922, 'rewards/accuracies': 0.875, 'rewards/margins': 6.554138660430908, 'logps/rejected': -127.07505798339844, 'logps/chosen': -64.18343353271484, 'logits/rejected': -3.016906499862671, 'logits/chosen': -3.0047099590301514, 'epoch': 0.36}
{'loss': 0.2176, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -2.1584606170654297, 'rewards/rejected': -7.789788722991943, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.631328582763672, 'logps/rejected': -123.43058013916016, 'logps/chosen': -65.76365661621094, 'logits/rejected': -2.8691649436950684, 'logits/chosen': -2.96346116065979, 'epoch': 0.36}
{'loss': 0.1311, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -1.0762887001037598, 'rewards/rejected': -5.851513862609863, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.7752251625061035, 'logps/rejected': -95.16665649414062, 'logps/chosen': -49.159889221191406, 'logits/rejected': -2.962791919708252, 'logits/chosen': -3.043544292449951, 'epoch': 0.37}
{'loss': 0.1649, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -1.6122233867645264, 'rewards/rejected': -7.35589075088501, 'rewards/accuracies': 0.875, 'rewards/margins': 5.7436676025390625, 'logps/rejected': -112.36681365966797, 'logps/chosen': -50.6651496887207, 'logits/rejected': -3.022665023803711, 'logits/chosen': -2.9314687252044678, 'epoch': 0.38}
{'loss': 0.1076, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -1.3024014234542847, 'rewards/rejected': -6.475128173828125, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.172727108001709, 'logps/rejected': -108.26311492919922, 'logps/chosen': -46.03927230834961, 'logits/rejected': -3.0870094299316406, 'logits/chosen': -2.925947427749634, 'epoch': 0.38}
{'loss': 0.0891, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -2.0238406658172607, 'rewards/rejected': -9.29905891418457, 'rewards/accuracies': 1.0, 'rewards/margins': 7.2752180099487305, 'logps/rejected': -141.3789520263672, 'logps/chosen': -57.23291778564453, 'logits/rejected': -3.1058807373046875, 'logits/chosen': -2.9502642154693604, 'epoch': 0.39}
{'loss': 0.2072, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -1.3294446468353271, 'rewards/rejected': -6.965609550476074, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.636165142059326, 'logps/rejected': -102.677001953125, 'logps/chosen': -46.71479415893555, 'logits/rejected': -2.943911075592041, 'logits/chosen': -3.0104269981384277, 'epoch': 0.4}
{'loss': 0.1558, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -1.2327189445495605, 'rewards/rejected': -8.671867370605469, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.43914794921875, 'logps/rejected': -132.77923583984375, 'logps/chosen': -46.59541320800781, 'logits/rejected': -3.004643678665161, 'logits/chosen': -2.9230833053588867, 'epoch': 0.4}
{'loss': 0.1722, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -1.989241600036621, 'rewards/rejected': -8.280677795410156, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.291436195373535, 'logps/rejected': -118.64820861816406, 'logps/chosen': -57.59178161621094, 'logits/rejected': -2.915269613265991, 'logits/chosen': -3.0222761631011963, 'epoch': 0.41}
{'loss': 0.1564, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -1.7132573127746582, 'rewards/rejected': -9.99158000946045, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.27832317352295, 'logps/rejected': -144.9429168701172, 'logps/chosen': -49.04338836669922, 'logits/rejected': -3.0930652618408203, 'logits/chosen': -2.886701822280884, 'epoch': 0.42}
{'loss': 0.1689, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -3.1119284629821777, 'rewards/rejected': -9.911569595336914, 'rewards/accuracies': 0.875, 'rewards/margins': 6.799640655517578, 'logps/rejected': -141.3118438720703, 'logps/chosen': -65.79302215576172, 'logits/rejected': -3.041698932647705, 'logits/chosen': -2.983851909637451, 'epoch': 0.42}
{'loss': 0.2537, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -2.4204461574554443, 'rewards/rejected': -9.253520011901855, 'rewards/accuracies': 0.875, 'rewards/margins': 6.833073616027832, 'logps/rejected': -128.46749877929688, 'logps/chosen': -56.95152282714844, 'logits/rejected': -3.036054849624634, 'logits/chosen': -2.9860918521881104, 'epoch': 0.43}
{'loss': 0.2635, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -1.8096327781677246, 'rewards/rejected': -11.770363807678223, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.96073055267334, 'logps/rejected': -157.80958557128906, 'logps/chosen': -55.849544525146484, 'logits/rejected': -2.9011199474334717, 'logits/chosen': -2.86055850982666, 'epoch': 0.44}
{'loss': 0.1766, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -3.156034469604492, 'rewards/rejected': -11.75082015991211, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.594786643981934, 'logps/rejected': -155.89114379882812, 'logps/chosen': -67.52059936523438, 'logits/rejected': -2.910041093826294, 'logits/chosen': -2.9251224994659424, 'epoch': 0.44}
{'loss': 0.1336, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -4.201650142669678, 'rewards/rejected': -12.4407377243042, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.239087104797363, 'logps/rejected': -172.36785888671875, 'logps/chosen': -81.60221099853516, 'logits/rejected': -3.0747711658477783, 'logits/chosen': -2.8533995151519775, 'epoch': 0.45}
{'loss': 0.0975, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -3.6168112754821777, 'rewards/rejected': -11.72583293914795, 'rewards/accuracies': 0.875, 'rewards/margins': 8.109021186828613, 'logps/rejected': -161.27642822265625, 'logps/chosen': -77.32064056396484, 'logits/rejected': -2.903616189956665, 'logits/chosen': -2.895846128463745, 'epoch': 0.46}
{'loss': 0.1449, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -4.302074909210205, 'rewards/rejected': -13.916996002197266, 'rewards/accuracies': 0.84375, 'rewards/margins': 9.614921569824219, 'logps/rejected': -182.98817443847656, 'logps/chosen': -83.63687133789062, 'logits/rejected': -2.937093496322632, 'logits/chosen': -2.8071703910827637, 'epoch': 0.46}
{'loss': 0.1194, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -3.2888171672821045, 'rewards/rejected': -12.730972290039062, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.442154884338379, 'logps/rejected': -166.6869354248047, 'logps/chosen': -69.06867218017578, 'logits/rejected': -2.8822174072265625, 'logits/chosen': -2.7939059734344482, 'epoch': 0.47}
{'loss': 0.2783, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -4.268893241882324, 'rewards/rejected': -10.474615097045898, 'rewards/accuracies': 0.8125, 'rewards/margins': 6.205722332000732, 'logps/rejected': -143.40921020507812, 'logps/chosen': -83.60743713378906, 'logits/rejected': -2.819796085357666, 'logits/chosen': -2.964571952819824, 'epoch': 0.48}
{'loss': 0.1151, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -3.8991737365722656, 'rewards/rejected': -12.553988456726074, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.654813766479492, 'logps/rejected': -167.19546508789062, 'logps/chosen': -73.95540618896484, 'logits/rejected': -2.8950634002685547, 'logits/chosen': -2.845226526260376, 'epoch': 0.49}
{'loss': 0.1141, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -3.9094934463500977, 'rewards/rejected': -14.846017837524414, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.936524391174316, 'logps/rejected': -196.34039306640625, 'logps/chosen': -71.6053466796875, 'logits/rejected': -3.1020665168762207, 'logits/chosen': -2.772671937942505, 'epoch': 0.49}
{'loss': 0.0675, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -3.3160934448242188, 'rewards/rejected': -16.016294479370117, 'rewards/accuracies': 1.0, 'rewards/margins': 12.700202941894531, 'logps/rejected': -209.4396209716797, 'logps/chosen': -64.75926208496094, 'logits/rejected': -3.0344936847686768, 'logits/chosen': -2.6855950355529785, 'epoch': 0.5}
{'loss': 0.2096, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -3.7078933715820312, 'rewards/rejected': -14.272648811340332, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.564754486083984, 'logps/rejected': -188.808349609375, 'logps/chosen': -83.81497955322266, 'logits/rejected': -2.850196599960327, 'logits/chosen': -2.961670160293579, 'epoch': 0.51}
{'loss': 0.1368, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -3.8164761066436768, 'rewards/rejected': -13.639426231384277, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.82295036315918, 'logps/rejected': -173.05166625976562, 'logps/chosen': -78.96243286132812, 'logits/rejected': -2.9165735244750977, 'logits/chosen': -2.978646993637085, 'epoch': 0.51}
{'loss': 0.1233, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -3.7016139030456543, 'rewards/rejected': -13.785244941711426, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.083630561828613, 'logps/rejected': -177.7959747314453, 'logps/chosen': -81.72836303710938, 'logits/rejected': -2.8394744396209717, 'logits/chosen': -2.914231538772583, 'epoch': 0.52}
{'loss': 0.0672, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -4.532203674316406, 'rewards/rejected': -12.626788139343262, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.094585418701172, 'logps/rejected': -160.26161193847656, 'logps/chosen': -89.13651275634766, 'logits/rejected': -2.809406280517578, 'logits/chosen': -2.9867794513702393, 'epoch': 0.53}
{'loss': 0.0664, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -4.204013824462891, 'rewards/rejected': -14.031692504882812, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.827677726745605, 'logps/rejected': -178.21910095214844, 'logps/chosen': -75.53514862060547, 'logits/rejected': -2.9399254322052, 'logits/chosen': -2.8303403854370117, 'epoch': 0.53}
{'loss': 0.1274, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -4.321269989013672, 'rewards/rejected': -14.274312973022461, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.953042984008789, 'logps/rejected': -178.71975708007812, 'logps/chosen': -78.73957824707031, 'logits/rejected': -2.9595508575439453, 'logits/chosen': -2.889169454574585, 'epoch': 0.54}
{'loss': 0.2089, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -2.9405436515808105, 'rewards/rejected': -14.05803394317627, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.1174898147583, 'logps/rejected': -177.8612060546875, 'logps/chosen': -71.26969146728516, 'logits/rejected': -2.7834219932556152, 'logits/chosen': -2.951655387878418, 'epoch': 0.55}
{'loss': 0.126, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -3.6159157752990723, 'rewards/rejected': -13.443666458129883, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.827751159667969, 'logps/rejected': -169.3983917236328, 'logps/chosen': -75.77124786376953, 'logits/rejected': -2.8363847732543945, 'logits/chosen': -2.9281303882598877, 'epoch': 0.55}
{'loss': 0.09, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -5.78716516494751, 'rewards/rejected': -16.336109161376953, 'rewards/accuracies': 0.875, 'rewards/margins': 10.548944473266602, 'logps/rejected': -202.4107208251953, 'logps/chosen': -96.0268783569336, 'logits/rejected': -2.9354944229125977, 'logits/chosen': -2.8969643115997314, 'epoch': 0.56}
{'loss': 0.1358, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -6.172476768493652, 'rewards/rejected': -18.141298294067383, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.968823432922363, 'logps/rejected': -228.96055603027344, 'logps/chosen': -104.5976791381836, 'logits/rejected': -2.873523712158203, 'logits/chosen': -2.8812479972839355, 'epoch': 0.57}
{'loss': 0.1166, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -5.128287315368652, 'rewards/rejected': -16.715730667114258, 'rewards/accuracies': 1.0, 'rewards/margins': 11.587443351745605, 'logps/rejected': -209.70245361328125, 'logps/chosen': -90.45298767089844, 'logits/rejected': -2.903876781463623, 'logits/chosen': -2.9895894527435303, 'epoch': 0.57}
{'loss': 0.2153, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -4.348057746887207, 'rewards/rejected': -15.371891975402832, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.023833274841309, 'logps/rejected': -194.2664031982422, 'logps/chosen': -85.24186706542969, 'logits/rejected': -2.9514000415802, 'logits/chosen': -2.9729886054992676, 'epoch': 0.58}
{'loss': 0.1145, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -3.2393455505371094, 'rewards/rejected': -13.54577922821045, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.306434631347656, 'logps/rejected': -175.64404296875, 'logps/chosen': -68.91415405273438, 'logits/rejected': -2.9771368503570557, 'logits/chosen': -2.91780686378479, 'epoch': 0.59}
{'loss': 0.2809, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -5.104106903076172, 'rewards/rejected': -13.2545166015625, 'rewards/accuracies': 0.875, 'rewards/margins': 8.150410652160645, 'logps/rejected': -170.05368041992188, 'logps/chosen': -87.72726440429688, 'logits/rejected': -2.9508557319641113, 'logits/chosen': -2.980379581451416, 'epoch': 0.59}
{'loss': 0.2512, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -4.27925443649292, 'rewards/rejected': -13.221956253051758, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.94270133972168, 'logps/rejected': -172.28536987304688, 'logps/chosen': -76.81752014160156, 'logits/rejected': -2.988844633102417, 'logits/chosen': -2.887800931930542, 'epoch': 0.6}
{'loss': 0.2178, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -4.736300945281982, 'rewards/rejected': -10.941699028015137, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.2053985595703125, 'logps/rejected': -148.9125213623047, 'logps/chosen': -90.15528869628906, 'logits/rejected': -2.886287212371826, 'logits/chosen': -2.961230993270874, 'epoch': 0.61}
{'loss': 0.1241, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -4.729950904846191, 'rewards/rejected': -10.929917335510254, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.199965476989746, 'logps/rejected': -143.13839721679688, 'logps/chosen': -93.07453155517578, 'logits/rejected': -2.78608775138855, 'logits/chosen': -2.9723129272460938, 'epoch': 0.61}
{'loss': 0.1314, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -4.313679218292236, 'rewards/rejected': -13.820404052734375, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.506725311279297, 'logps/rejected': -197.18582153320312, 'logps/chosen': -74.613525390625, 'logits/rejected': -3.2254607677459717, 'logits/chosen': -2.683096408843994, 'epoch': 0.62}
{'loss': 0.0724, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -3.896963596343994, 'rewards/rejected': -11.412422180175781, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.515459060668945, 'logps/rejected': -157.034912109375, 'logps/chosen': -76.23342895507812, 'logits/rejected': -3.0043649673461914, 'logits/chosen': -3.0001397132873535, 'epoch': 0.63}
{'loss': 0.267, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -3.5950231552124023, 'rewards/rejected': -13.004730224609375, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.409708023071289, 'logps/rejected': -181.3099365234375, 'logps/chosen': -78.43938446044922, 'logits/rejected': -2.895143508911133, 'logits/chosen': -2.9070234298706055, 'epoch': 0.63}
{'loss': 0.1307, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -3.394111156463623, 'rewards/rejected': -9.700583457946777, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.3064727783203125, 'logps/rejected': -132.08958435058594, 'logps/chosen': -72.72929382324219, 'logits/rejected': -2.883554220199585, 'logits/chosen': -2.967447280883789, 'epoch': 0.64}
{'loss': 0.1171, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -2.9357752799987793, 'rewards/rejected': -9.982834815979004, 'rewards/accuracies': 0.875, 'rewards/margins': 7.047059059143066, 'logps/rejected': -140.0417938232422, 'logps/chosen': -63.25720977783203, 'logits/rejected': -3.0451974868774414, 'logits/chosen': -2.936392307281494, 'epoch': 0.65}
{'loss': 0.1932, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -2.5480244159698486, 'rewards/rejected': -11.078252792358398, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.530228614807129, 'logps/rejected': -152.9599609375, 'logps/chosen': -58.12957000732422, 'logits/rejected': -3.0166430473327637, 'logits/chosen': -2.906398057937622, 'epoch': 0.65}
{'loss': 0.1123, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -2.784621238708496, 'rewards/rejected': -12.645594596862793, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.86097240447998, 'logps/rejected': -177.09454345703125, 'logps/chosen': -64.7964096069336, 'logits/rejected': -2.968226432800293, 'logits/chosen': -2.852290391921997, 'epoch': 0.66}
{'loss': 0.2198, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -2.311579704284668, 'rewards/rejected': -9.090755462646484, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.779175281524658, 'logps/rejected': -126.41129302978516, 'logps/chosen': -66.02870178222656, 'logits/rejected': -2.905543565750122, 'logits/chosen': -3.0111160278320312, 'epoch': 0.67}
{'loss': 0.173, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -2.993854284286499, 'rewards/rejected': -10.86719036102295, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.873337745666504, 'logps/rejected': -155.31263732910156, 'logps/chosen': -74.10364532470703, 'logits/rejected': -2.934962749481201, 'logits/chosen': -2.9916319847106934, 'epoch': 0.67}
{'loss': 0.2515, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -2.152548313140869, 'rewards/rejected': -9.778097152709961, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.62554931640625, 'logps/rejected': -136.75865173339844, 'logps/chosen': -58.00482177734375, 'logits/rejected': -2.909008502960205, 'logits/chosen': -2.950568437576294, 'epoch': 0.68}
{'loss': 0.1413, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -2.7395389080047607, 'rewards/rejected': -9.626827239990234, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.8872880935668945, 'logps/rejected': -137.6067657470703, 'logps/chosen': -68.56413269042969, 'logits/rejected': -2.8640737533569336, 'logits/chosen': -3.0082578659057617, 'epoch': 0.69}
{'loss': 0.1908, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -2.106767177581787, 'rewards/rejected': -11.087345123291016, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.980579376220703, 'logps/rejected': -154.2957763671875, 'logps/chosen': -51.879417419433594, 'logits/rejected': -3.036653518676758, 'logits/chosen': -2.7654480934143066, 'epoch': 0.69}
{'loss': 0.1951, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -2.3189809322357178, 'rewards/rejected': -9.374837875366211, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.0558576583862305, 'logps/rejected': -134.30482482910156, 'logps/chosen': -58.38962173461914, 'logits/rejected': -2.9992470741271973, 'logits/chosen': -2.897120714187622, 'epoch': 0.7}
{'loss': 0.1404, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -3.028928279876709, 'rewards/rejected': -11.167015075683594, 'rewards/accuracies': 0.875, 'rewards/margins': 8.138087272644043, 'logps/rejected': -155.72293090820312, 'logps/chosen': -70.7824935913086, 'logits/rejected': -2.9735465049743652, 'logits/chosen': -2.9537198543548584, 'epoch': 0.71}
{'loss': 0.0633, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -1.548241138458252, 'rewards/rejected': -12.92820930480957, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.37996768951416, 'logps/rejected': -178.8766632080078, 'logps/chosen': -49.53055191040039, 'logits/rejected': -3.069540023803711, 'logits/chosen': -2.7728710174560547, 'epoch': 0.71}
{'loss': 0.127, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -1.7502171993255615, 'rewards/rejected': -11.423285484313965, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.673067092895508, 'logps/rejected': -152.81195068359375, 'logps/chosen': -53.3536491394043, 'logits/rejected': -2.943986654281616, 'logits/chosen': -2.871929168701172, 'epoch': 0.72}
{'loss': 0.1325, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -2.51134991645813, 'rewards/rejected': -11.894328117370605, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.382977485656738, 'logps/rejected': -167.25369262695312, 'logps/chosen': -58.81925582885742, 'logits/rejected': -3.0103397369384766, 'logits/chosen': -2.815577268600464, 'epoch': 0.73}
{'loss': 0.1743, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -2.0623772144317627, 'rewards/rejected': -10.501032829284668, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.438655853271484, 'logps/rejected': -144.6576690673828, 'logps/chosen': -65.49687194824219, 'logits/rejected': -2.7443315982818604, 'logits/chosen': -2.941396951675415, 'epoch': 0.73}
{'loss': 0.1274, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -2.9711437225341797, 'rewards/rejected': -11.217328071594238, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.246184349060059, 'logps/rejected': -156.58523559570312, 'logps/chosen': -62.15907287597656, 'logits/rejected': -3.0296666622161865, 'logits/chosen': -2.810760974884033, 'epoch': 0.74}
{'loss': 0.1033, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -1.6853301525115967, 'rewards/rejected': -11.075647354125977, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.3903169631958, 'logps/rejected': -162.384033203125, 'logps/chosen': -56.981204986572266, 'logits/rejected': -2.9361844062805176, 'logits/chosen': -2.8888983726501465, 'epoch': 0.75}
{'loss': 0.1578, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -3.8779489994049072, 'rewards/rejected': -13.034774780273438, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.156826972961426, 'logps/rejected': -172.39903259277344, 'logps/chosen': -79.83979797363281, 'logits/rejected': -2.889378070831299, 'logits/chosen': -2.9280943870544434, 'epoch': 0.75}
{'loss': 0.079, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -2.72121524810791, 'rewards/rejected': -10.498708724975586, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.777493953704834, 'logps/rejected': -146.02462768554688, 'logps/chosen': -63.55813217163086, 'logits/rejected': -3.0093178749084473, 'logits/chosen': -2.919712781906128, 'epoch': 0.76}
{'loss': 0.1138, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -3.3039660453796387, 'rewards/rejected': -13.107029914855957, 'rewards/accuracies': 0.875, 'rewards/margins': 9.80306339263916, 'logps/rejected': -177.3319091796875, 'logps/chosen': -65.8023681640625, 'logits/rejected': -3.070645570755005, 'logits/chosen': -2.828152656555176, 'epoch': 0.77}
{'loss': 0.0856, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -3.4602062702178955, 'rewards/rejected': -12.100034713745117, 'rewards/accuracies': 1.0, 'rewards/margins': 8.639827728271484, 'logps/rejected': -167.30918884277344, 'logps/chosen': -88.31282806396484, 'logits/rejected': -2.878934860229492, 'logits/chosen': -2.9851081371307373, 'epoch': 0.77}
{'loss': 0.1062, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -2.656832695007324, 'rewards/rejected': -10.709695816040039, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.052862167358398, 'logps/rejected': -149.35670471191406, 'logps/chosen': -64.704833984375, 'logits/rejected': -2.9448986053466797, 'logits/chosen': -2.8760862350463867, 'epoch': 0.78}
{'loss': 0.1269, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -4.209417819976807, 'rewards/rejected': -14.398408889770508, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.188993453979492, 'logps/rejected': -195.49571228027344, 'logps/chosen': -83.53866577148438, 'logits/rejected': -2.9467227458953857, 'logits/chosen': -2.804732322692871, 'epoch': 0.79}
{'loss': 0.2251, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -3.2380588054656982, 'rewards/rejected': -13.339298248291016, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.101238250732422, 'logps/rejected': -178.78565979003906, 'logps/chosen': -70.58959197998047, 'logits/rejected': -2.905561923980713, 'logits/chosen': -2.8716156482696533, 'epoch': 0.8}
{'loss': 0.1541, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -3.9874801635742188, 'rewards/rejected': -13.160680770874023, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.173200607299805, 'logps/rejected': -177.7993621826172, 'logps/chosen': -83.36135864257812, 'logits/rejected': -2.8863883018493652, 'logits/chosen': -2.9418649673461914, 'epoch': 0.8}
{'loss': 0.1191, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -2.789522647857666, 'rewards/rejected': -9.871057510375977, 'rewards/accuracies': 0.875, 'rewards/margins': 7.081534385681152, 'logps/rejected': -136.72911071777344, 'logps/chosen': -63.733375549316406, 'logits/rejected': -2.9323277473449707, 'logits/chosen': -2.9532690048217773, 'epoch': 0.81}
{'loss': 0.201, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -4.660849571228027, 'rewards/rejected': -12.011123657226562, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.350272178649902, 'logps/rejected': -157.9864959716797, 'logps/chosen': -82.33119201660156, 'logits/rejected': -2.914163589477539, 'logits/chosen': -2.9531452655792236, 'epoch': 0.82}
{'loss': 0.1045, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -4.741881370544434, 'rewards/rejected': -12.965476989746094, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.22359561920166, 'logps/rejected': -174.81939697265625, 'logps/chosen': -84.31844329833984, 'logits/rejected': -3.0246689319610596, 'logits/chosen': -2.865999698638916, 'epoch': 0.82}
{'loss': 0.1217, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -2.6703684329986572, 'rewards/rejected': -12.50522232055664, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.834854125976562, 'logps/rejected': -161.89083862304688, 'logps/chosen': -59.69317626953125, 'logits/rejected': -2.896716594696045, 'logits/chosen': -2.8812081813812256, 'epoch': 0.83}
{'loss': 0.1351, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -2.798887252807617, 'rewards/rejected': -12.793928146362305, 'rewards/accuracies': 1.0, 'rewards/margins': 9.995041847229004, 'logps/rejected': -169.20269775390625, 'logps/chosen': -64.66434478759766, 'logits/rejected': -2.979891777038574, 'logits/chosen': -2.8720736503601074, 'epoch': 0.84}
{'loss': 0.0957, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -2.810641050338745, 'rewards/rejected': -11.995205879211426, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.184564590454102, 'logps/rejected': -159.00302124023438, 'logps/chosen': -63.70186233520508, 'logits/rejected': -2.937218427658081, 'logits/chosen': -2.888704538345337, 'epoch': 0.84}
{'loss': 0.117, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -4.1188836097717285, 'rewards/rejected': -12.62327766418457, 'rewards/accuracies': 0.875, 'rewards/margins': 8.504395484924316, 'logps/rejected': -164.48585510253906, 'logps/chosen': -80.28585815429688, 'logits/rejected': -2.9136343002319336, 'logits/chosen': -2.9405767917633057, 'epoch': 0.85}
{'loss': 0.2383, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -4.775301933288574, 'rewards/rejected': -15.403251647949219, 'rewards/accuracies': 0.78125, 'rewards/margins': 10.627948760986328, 'logps/rejected': -202.49139404296875, 'logps/chosen': -85.76368713378906, 'logits/rejected': -2.9830169677734375, 'logits/chosen': -2.8729019165039062, 'epoch': 0.86}
{'loss': 0.0991, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -3.514087677001953, 'rewards/rejected': -13.169849395751953, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.655762672424316, 'logps/rejected': -167.32211303710938, 'logps/chosen': -69.89598083496094, 'logits/rejected': -2.9551289081573486, 'logits/chosen': -2.934957504272461, 'epoch': 0.86}
{'loss': 0.1387, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -3.6821420192718506, 'rewards/rejected': -13.550822257995605, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.868680000305176, 'logps/rejected': -182.02427673339844, 'logps/chosen': -70.11656188964844, 'logits/rejected': -2.9945383071899414, 'logits/chosen': -2.78528094291687, 'epoch': 0.87}
{'loss': 0.1154, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -2.9873857498168945, 'rewards/rejected': -11.895647048950195, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.9082612991333, 'logps/rejected': -161.33677673339844, 'logps/chosen': -72.28823852539062, 'logits/rejected': -2.8630385398864746, 'logits/chosen': -2.9367876052856445, 'epoch': 0.88}
{'loss': 0.1642, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -4.330494403839111, 'rewards/rejected': -13.264461517333984, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.933967590332031, 'logps/rejected': -184.7758026123047, 'logps/chosen': -78.07672882080078, 'logits/rejected': -3.075124502182007, 'logits/chosen': -2.8375136852264404, 'epoch': 0.88}
{'loss': 0.0803, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -4.2793169021606445, 'rewards/rejected': -14.37944221496582, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.10012435913086, 'logps/rejected': -186.4307861328125, 'logps/chosen': -88.56746673583984, 'logits/rejected': -2.8799915313720703, 'logits/chosen': -2.9532926082611084, 'epoch': 0.89}
{'loss': 0.1605, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -4.056773662567139, 'rewards/rejected': -13.763837814331055, 'rewards/accuracies': 0.875, 'rewards/margins': 9.707063674926758, 'logps/rejected': -188.28753662109375, 'logps/chosen': -77.847412109375, 'logits/rejected': -2.993230104446411, 'logits/chosen': -2.866598606109619, 'epoch': 0.9}
{'loss': 0.0659, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -3.344757080078125, 'rewards/rejected': -12.176371574401855, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.83161449432373, 'logps/rejected': -165.98391723632812, 'logps/chosen': -78.93333435058594, 'logits/rejected': -2.830700635910034, 'logits/chosen': -2.8520312309265137, 'epoch': 0.9}
{'loss': 0.0958, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -3.008788824081421, 'rewards/rejected': -12.82851791381836, 'rewards/accuracies': 0.875, 'rewards/margins': 9.819729804992676, 'logps/rejected': -174.39010620117188, 'logps/chosen': -65.00146484375, 'logits/rejected': -3.0031609535217285, 'logits/chosen': -2.8203940391540527, 'epoch': 0.91}
{'loss': 0.0884, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -3.7044272422790527, 'rewards/rejected': -12.601083755493164, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.896656036376953, 'logps/rejected': -170.07943725585938, 'logps/chosen': -83.76386260986328, 'logits/rejected': -2.8808212280273438, 'logits/chosen': -2.8934922218322754, 'epoch': 0.92}
{'loss': 0.1262, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -3.395528793334961, 'rewards/rejected': -12.31815242767334, 'rewards/accuracies': 1.0, 'rewards/margins': 8.922623634338379, 'logps/rejected': -157.94537353515625, 'logps/chosen': -80.7238540649414, 'logits/rejected': -2.7129154205322266, 'logits/chosen': -2.993516445159912, 'epoch': 0.92}
{'loss': 0.1242, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -2.468132495880127, 'rewards/rejected': -11.47186279296875, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.003730773925781, 'logps/rejected': -154.61639404296875, 'logps/chosen': -64.84347534179688, 'logits/rejected': -2.9325859546661377, 'logits/chosen': -2.8955860137939453, 'epoch': 0.93}
{'loss': 0.162, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -3.9253993034362793, 'rewards/rejected': -14.056160926818848, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.130763053894043, 'logps/rejected': -185.44300842285156, 'logps/chosen': -77.7596664428711, 'logits/rejected': -2.9282073974609375, 'logits/chosen': -2.8318614959716797, 'epoch': 0.94}
{'loss': 0.2194, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -4.964413642883301, 'rewards/rejected': -11.901887893676758, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.937473297119141, 'logps/rejected': -153.78651428222656, 'logps/chosen': -96.6397933959961, 'logits/rejected': -2.747751474380493, 'logits/chosen': -3.0771446228027344, 'epoch': 0.94}
{'loss': 0.2325, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -4.085716724395752, 'rewards/rejected': -12.31325912475586, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.22754192352295, 'logps/rejected': -159.09176635742188, 'logps/chosen': -78.09449005126953, 'logits/rejected': -2.8689441680908203, 'logits/chosen': -2.951486587524414, 'epoch': 0.95}
{'loss': 0.0963, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -3.128498077392578, 'rewards/rejected': -12.45727825164795, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.328780174255371, 'logps/rejected': -163.80653381347656, 'logps/chosen': -61.37911605834961, 'logits/rejected': -2.932874917984009, 'logits/chosen': -2.8255648612976074, 'epoch': 0.96}
{'loss': 0.1397, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -3.6086246967315674, 'rewards/rejected': -13.835952758789062, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.227328300476074, 'logps/rejected': -187.87646484375, 'logps/chosen': -68.03812408447266, 'logits/rejected': -3.120310068130493, 'logits/chosen': -2.8119397163391113, 'epoch': 0.96}
{'loss': 0.1689, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -3.9589738845825195, 'rewards/rejected': -11.187649726867676, 'rewards/accuracies': 0.875, 'rewards/margins': 7.22867488861084, 'logps/rejected': -155.65994262695312, 'logps/chosen': -84.07221984863281, 'logits/rejected': -2.8031504154205322, 'logits/chosen': -2.8659567832946777, 'epoch': 0.97}
{'loss': 0.0558, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -2.7947256565093994, 'rewards/rejected': -13.147550582885742, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.352825164794922, 'logps/rejected': -170.9784393310547, 'logps/chosen': -66.00006103515625, 'logits/rejected': -2.9068686962127686, 'logits/chosen': -2.8586227893829346, 'epoch': 0.98}
{'loss': 0.2963, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -4.3479437828063965, 'rewards/rejected': -12.902389526367188, 'rewards/accuracies': 0.875, 'rewards/margins': 8.554445266723633, 'logps/rejected': -166.73983764648438, 'logps/chosen': -88.25345611572266, 'logits/rejected': -2.8155651092529297, 'logits/chosen': -2.91770076751709, 'epoch': 0.98}
{'loss': 0.1453, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -3.3851935863494873, 'rewards/rejected': -12.942683219909668, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.557489395141602, 'logps/rejected': -172.52328491210938, 'logps/chosen': -68.81329345703125, 'logits/rejected': -2.9467720985412598, 'logits/chosen': -2.8184640407562256, 'epoch': 0.99}
{'loss': 0.1769, 'learning_rate': 0.0, 'rewards/chosen': -3.9542951583862305, 'rewards/rejected': -13.545209884643555, 'rewards/accuracies': 0.84375, 'rewards/margins': 9.59091567993164, 'logps/rejected': -172.75686645507812, 'logps/chosen': -75.09380340576172, 'logits/rejected': -2.958751678466797, 'logits/chosen': -2.896043300628662, 'epoch': 1.0}
{'train_runtime': 1166.2769, 'train_samples_per_second': 16.286, 'train_steps_per_second': 0.127, 'train_loss': 0.19731284635191834, 'epoch': 1.0}
