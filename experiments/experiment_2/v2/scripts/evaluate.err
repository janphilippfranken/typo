Processing examples: 0it [00:00, ?it/s]
Processed prompts:   0%|          | 0/1000 [00:00<?, ?it/s][A
Processed prompts:   0%|          | 1/1000 [00:07<2:13:06,  7.99s/it][A
Processed prompts:   0%|          | 2/1000 [00:19<2:44:44,  9.90s/it][A
Processed prompts:  26%|██▌       | 257/1000 [00:27<00:58, 12.73it/s][A
Processed prompts:  26%|██▌       | 259/1000 [00:38<01:43,  7.16it/s][A
Processed prompts:  51%|█████▏    | 513/1000 [00:47<00:33, 14.69it/s][A
Processed prompts:  52%|█████▏    | 516/1000 [00:58<00:52,  9.14it/s][A
Processed prompts:  77%|███████▋  | 769/1000 [01:05<00:14, 15.69it/s][A
Processed prompts:  77%|███████▋  | 772/1000 [01:16<00:21, 10.37it/s][AProcessed prompts: 100%|██████████| 1000/1000 [01:16<00:00, 13.11it/s]
Processing examples: 500it [01:16,  6.52it/s]Processing examples: 500it [01:16,  6.52it/s]
ERROR: Cannot find key: start_example=0
Usage: evaluate.py <group|command|value>
  available groups:      json | fire | hydra | np | random | List | Optional |
                         Tuple | Dict | Sequence | torch | transformers |
                         copy | CONSTITUTIONS
  available commands:    DictConfig | tqdm | load_dataset |
                         VLLMInferenceModel | Dataset | dataclass |
                         get_first_question | format_responses |
                         format_example | tokenize_func | shuffle_principles |
                         format_example_dpo |
                         DataCollatorForSupervisedDataset | sft_preprocess |
                         main
  available values:      EOS_TOKEN | BOS_TOKEN | IGNORE_INDEX |
                         PROMPT_GENERATION_ITERATION_0 | PROMPT_TRAINING |
                         SYSTEM_MESSAGE | GPT4_WIN_RATE | HELPFUL_PRINCIPLE |
                         NOT_HELPFUL_PRINCIPLE | HARMLESS_PRINCIPLE |
                         NOT_HARMLESS_PRINCIPLE

For detailed information on this command, run:
  evaluate.py --help
