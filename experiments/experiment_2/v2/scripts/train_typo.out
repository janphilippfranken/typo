{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 17:04:34,361][root][INFO] - beta: 0.5
[2024-03-12 17:04:34,361][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6595339775085449, train/raw-loss = 0.6508449912071228, train/logprobs = tensor([[-0.5562, -0.9049],
        [-0.4910, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01737789809703827
Epoch 0, Step 65: train/loss = 0.5927573442459106, train/raw-loss = 0.5858203172683716, train/logprobs = tensor([[-0.4065, -2.3866],
        [-0.4046, -1.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013873998075723648
Epoch 0, Step 66: train/loss = 0.6361945867538452, train/raw-loss = 0.6275323629379272, train/logprobs = tensor([[-0.6666, -1.2229],
        [-0.6758, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017324360087513924
Epoch 0, Step 67: train/loss = 0.6163390874862671, train/raw-loss = 0.6090889573097229, train/logprobs = tensor([[-0.4552, -1.6499],
        [-0.4394, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014500229619443417
Epoch 0, Step 68: train/loss = 0.6276490688323975, train/raw-loss = 0.6199324727058411, train/logprobs = tensor([[-0.5321, -0.8143],
        [-0.6268, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015433276072144508
Epoch 0, Step 69: train/loss = 0.6449480056762695, train/raw-loss = 0.6370118856430054, train/logprobs = tensor([[-0.6262, -0.8781],
        [-0.6382, -0.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015872227028012276
Epoch 0, Step 70: train/loss = 0.611026406288147, train/raw-loss = 0.6039124727249146, train/logprobs = tensor([[-0.5832, -1.5756],
        [-0.5852, -1.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014227917417883873
Epoch 0, Step 71: train/loss = 0.6197028160095215, train/raw-loss = 0.6122317314147949, train/logprobs = tensor([[-0.5080, -1.2079],
        [-0.5327, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014942264184355736
Epoch 0, Step 72: train/loss = 0.6468616127967834, train/raw-loss = 0.639045238494873, train/logprobs = tensor([[-0.5472, -1.3627],
        [-0.5530, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015632782131433487
Epoch 0, Step 73: train/loss = 0.6837710738182068, train/raw-loss = 0.6752433776855469, train/logprobs = tensor([[-0.5545, -1.0882],
        [-0.5397, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017055440694093704
Epoch 0, Step 74: train/loss = 0.6554746627807617, train/raw-loss = 0.6464395523071289, train/logprobs = tensor([[-0.6132, -0.9834],
        [-0.5829, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018070148304104805
Epoch 0, Step 75: train/loss = 0.6114093065261841, train/raw-loss = 0.6051760315895081, train/logprobs = tensor([[-0.4143, -1.3277],
        [-0.4391, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012466603890061378
Epoch 0, Step 76: train/loss = 0.5505601167678833, train/raw-loss = 0.5437288880348206, train/logprobs = tensor([[-0.4658, -2.4575],
        [-0.5003, -1.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013662369921803474
Epoch 0, Step 77: train/loss = 0.6120796203613281, train/raw-loss = 0.6039711236953735, train/logprobs = tensor([[-0.6573, -1.0155],
        [-0.6931, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016217056661844254
Epoch 0, Step 78: train/loss = 0.658980131149292, train/raw-loss = 0.6505047678947449, train/logprobs = tensor([[-0.6896, -0.9505],
        [-0.6835, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016950814053416252
Epoch 0, Step 79: train/loss = 0.5831806659698486, train/raw-loss = 0.5756399631500244, train/logprobs = tensor([[-0.5681, -2.3964],
        [-0.5729, -1.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015081340447068214
Epoch 0, Step 80: train/loss = 0.6333619952201843, train/raw-loss = 0.6244115829467773, train/logprobs = tensor([[-0.7447, -1.0118],
        [-0.7349, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017900867387652397
Epoch 0, Step 81: train/loss = 0.5763986110687256, train/raw-loss = 0.5708928108215332, train/logprobs = tensor([[-0.5281, -2.5021],
        [-0.5213, -1.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011011745780706406
Epoch 0, Step 82: train/loss = 0.6567485928535461, train/raw-loss = 0.647275984287262, train/logprobs = tensor([[-0.6930, -1.1125],
        [-0.6217, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018945258110761642
Epoch 0, Step 83: train/loss = 0.692142903804779, train/raw-loss = 0.6819387078285217, train/logprobs = tensor([[-1.5389, -1.6582],
        [-1.4932, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02040839195251465
Epoch 0, Step 84: train/loss = 0.6481224298477173, train/raw-loss = 0.6386806964874268, train/logprobs = tensor([[-0.6082, -0.9778],
        [-0.5918, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018883639946579933
Epoch 0, Step 85: train/loss = 0.5664697885513306, train/raw-loss = 0.5583192706108093, train/logprobs = tensor([[-0.5909, -2.0255],
        [-0.5805, -1.3627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016301006078720093
Epoch 0, Step 86: train/loss = 0.6344488859176636, train/raw-loss = 0.6258936524391174, train/logprobs = tensor([[-0.5671, -0.9173],
        [-0.5965, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017110394313931465
Epoch 0, Step 87: train/loss = 0.6132493019104004, train/raw-loss = 0.6051691770553589, train/logprobs = tensor([[-0.6376, -1.0316],
        [-0.7065, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01616032049059868
Epoch 0, Step 88: train/loss = 0.6197066903114319, train/raw-loss = 0.6102849841117859, train/logprobs = tensor([[-1.0040, -2.1792],
        [-0.9360, -1.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018843453377485275
Epoch 0, Step 89: train/loss = 0.6452921032905579, train/raw-loss = 0.6362826824188232, train/logprobs = tensor([[-0.5688, -0.9970],
        [-0.5565, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01801871508359909
Epoch 0, Step 90: train/loss = 0.6353575587272644, train/raw-loss = 0.6269485354423523, train/logprobs = tensor([[-0.4659, -1.0627],
        [-0.4727, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016818154603242874
Epoch 0, Step 91: train/loss = 0.4520282447338104, train/raw-loss = 0.4455314874649048, train/logprobs = tensor([[-0.4698, -2.7822],
        [-0.5086, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012993560172617435
Epoch 0, Step 92: train/loss = 0.6596973538398743, train/raw-loss = 0.6494871377944946, train/logprobs = tensor([[-0.6954, -1.0887],
        [-0.6941, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0204203762114048
Epoch 0, Step 93: train/loss = 0.5983526706695557, train/raw-loss = 0.5902403593063354, train/logprobs = tensor([[-0.5670, -1.4546],
        [-0.5582, -0.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01622459478676319
Epoch 0, Step 94: train/loss = 0.5971679091453552, train/raw-loss = 0.5885693430900574, train/logprobs = tensor([[-0.6802, -1.8464],
        [-0.7736, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017197135835886
Epoch 0, Step 95: train/loss = 0.6327857971191406, train/raw-loss = 0.625861406326294, train/logprobs = tensor([[-0.5266, -1.0181],
        [-0.5227, -0.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013848744332790375
Epoch 0, Step 96: train/loss = 0.7045453190803528, train/raw-loss = 0.6830568313598633, train/logprobs = tensor([[-0.5993, -0.8912],
        [-0.5837, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04297705739736557
Epoch 0, Step 97: train/loss = 0.5811583995819092, train/raw-loss = 0.5630441308021545, train/logprobs = tensor([[-0.6323, -1.9362],
        [-0.6149, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03622858226299286
Epoch 0, Step 98: train/loss = 0.6273726224899292, train/raw-loss = 0.6135720610618591, train/logprobs = tensor([[-0.3824, -0.9754],
        [-0.3305, -0.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027601085603237152
Epoch 0, Step 99: train/loss = 0.6400129199028015, train/raw-loss = 0.6251468658447266, train/logprobs = tensor([[-0.5287, -1.0410],
        [-0.5072, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029732119292020798
Epoch 0, Step 100: train/loss = 0.5560652017593384, train/raw-loss = 0.5409526824951172, train/logprobs = tensor([[-0.6792, -2.7729],
        [-0.6620, -1.3534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030225014314055443
Epoch 0, Step 101: train/loss = 0.6121407151222229, train/raw-loss = 0.5867656469345093, train/logprobs = tensor([[-0.9542, -1.8322],
        [-0.9254, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050750117748975754
Epoch 0, Step 102: train/loss = 0.5954349637031555, train/raw-loss = 0.5783603191375732, train/logprobs = tensor([[-0.4949, -1.3503],
        [-0.4908, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03414931893348694
Epoch 0, Step 103: train/loss = 0.5679900646209717, train/raw-loss = 0.5532916784286499, train/logprobs = tensor([[-0.6327, -1.7116],
        [-0.5487, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029396846890449524
Epoch 0, Step 104: train/loss = 0.4635242223739624, train/raw-loss = 0.44392919540405273, train/logprobs = tensor([[-0.7918, -4.5019],
        [-0.6597, -2.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03919002413749695
Epoch 0, Step 105: train/loss = 0.6155394315719604, train/raw-loss = 0.5976642370223999, train/logprobs = tensor([[-0.6748, -1.1901],
        [-0.6246, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03575032204389572
Epoch 0, Step 106: train/loss = 0.46723443269729614, train/raw-loss = 0.45224472880363464, train/logprobs = tensor([[-0.6775, -4.3874],
        [-0.6223, -2.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029979504644870758
Epoch 0, Step 107: train/loss = 0.6197147369384766, train/raw-loss = 0.5974997878074646, train/logprobs = tensor([[-0.7184, -1.5301],
        [-0.6786, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044429805129766464
Epoch 0, Step 108: train/loss = 0.6733201146125793, train/raw-loss = 0.6616962552070618, train/logprobs = tensor([[-0.5300, -0.6592],
        [-0.4649, -0.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023247767239809036
Epoch 0, Step 109: train/loss = 0.617694616317749, train/raw-loss = 0.6017425060272217, train/logprobs = tensor([[-0.6366, -1.2748],
        [-0.5529, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03190426528453827
Epoch 0, Step 110: train/loss = 0.5549579858779907, train/raw-loss = 0.5392438769340515, train/logprobs = tensor([[-0.6588, -2.9422],
        [-0.5486, -1.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0314282588660717
Epoch 0, Step 111: train/loss = 0.5878292322158813, train/raw-loss = 0.5752263069152832, train/logprobs = tensor([[-0.4346, -1.5011],
        [-0.4149, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02520587295293808
Epoch 0, Step 112: train/loss = 0.6109278798103333, train/raw-loss = 0.5952564477920532, train/logprobs = tensor([[-0.6275, -1.1024],
        [-0.5957, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031342763453722
Epoch 0, Step 113: train/loss = 0.647152841091156, train/raw-loss = 0.6244320869445801, train/logprobs = tensor([[-0.6479, -1.2748],
        [-0.5757, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04544142633676529
Epoch 0, Step 114: train/loss = 0.6162281632423401, train/raw-loss = 0.5981323719024658, train/logprobs = tensor([[-0.5632, -1.0635],
        [-0.5372, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03619162738323212
Epoch 0, Step 115: train/loss = 0.6276603937149048, train/raw-loss = 0.612922728061676, train/logprobs = tensor([[-0.5626, -1.1603],
        [-0.5302, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02947520837187767
Epoch 0, Step 116: train/loss = 0.5802294015884399, train/raw-loss = 0.5607624650001526, train/logprobs = tensor([[-0.6675, -2.0477],
        [-0.6109, -1.2777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893386945128441
Epoch 0, Step 117: train/loss = 0.6333152651786804, train/raw-loss = 0.6166841983795166, train/logprobs = tensor([[-0.4843, -1.7610],
        [-0.4611, -1.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033262185752391815
Epoch 0, Step 118: train/loss = 0.5067126750946045, train/raw-loss = 0.4929126501083374, train/logprobs = tensor([[-0.6575, -3.1873],
        [-0.5740, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027600180357694626
Epoch 0, Step 119: train/loss = 0.5854249000549316, train/raw-loss = 0.5648069381713867, train/logprobs = tensor([[-0.6146, -1.6826],
        [-0.5679, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041235871613025665
Epoch 0, Step 120: train/loss = 0.5357391834259033, train/raw-loss = 0.5164735913276672, train/logprobs = tensor([[-0.7811, -2.6264],
        [-0.7644, -1.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03853124752640724
Epoch 0, Step 121: train/loss = 0.6197870969772339, train/raw-loss = 0.6042582988739014, train/logprobs = tensor([[-0.4998, -1.2309],
        [-0.4447, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03105759806931019
Epoch 0, Step 122: train/loss = 0.5543208122253418, train/raw-loss = 0.5361959934234619, train/logprobs = tensor([[-0.8426, -1.9397],
        [-0.7434, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036249641329050064
Epoch 0, Step 123: train/loss = 0.6811236143112183, train/raw-loss = 0.6638092994689941, train/logprobs = tensor([[-0.5321, -0.7935],
        [-0.5073, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03462870419025421
Epoch 0, Step 124: train/loss = 0.5975993871688843, train/raw-loss = 0.5779905319213867, train/logprobs = tensor([[-0.7880, -1.6054],
        [-0.7078, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03921777755022049
Epoch 0, Step 125: train/loss = 0.5531665086746216, train/raw-loss = 0.5345370769500732, train/logprobs = tensor([[-0.6997, -3.1731],
        [-0.6288, -2.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037258829921483994
Epoch 0, Step 126: train/loss = 0.6459938883781433, train/raw-loss = 0.625038743019104, train/logprobs = tensor([[-0.6736, -1.2027],
        [-0.5702, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04191030561923981
Epoch 0, Step 127: train/loss = 0.6282777786254883, train/raw-loss = 0.6098669767379761, train/logprobs = tensor([[-0.5083, -1.4868],
        [-0.4446, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036821696907281876
Epoch 0, Step 128: train/loss = 0.7046265602111816, train/raw-loss = 0.6508023142814636, train/logprobs = tensor([[-0.8183, -1.0315],
        [-0.7767, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764852166175842
Epoch 0, Step 129: train/loss = 0.5809559226036072, train/raw-loss = 0.5115790963172913, train/logprobs = tensor([[-0.7342, -2.8393],
        [-0.6285, -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138753741979599
Epoch 0, Step 130: train/loss = 0.6866241693496704, train/raw-loss = 0.6234531402587891, train/logprobs = tensor([[-0.5336, -1.1537],
        [-0.4663, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12634210288524628
Epoch 0, Step 131: train/loss = 0.5670933723449707, train/raw-loss = 0.49695420265197754, train/logprobs = tensor([[-0.7670, -4.0792],
        [-0.6779, -2.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402783989906311
Epoch 0, Step 132: train/loss = 0.5907756686210632, train/raw-loss = 0.5263326168060303, train/logprobs = tensor([[-0.7845, -2.3463],
        [-0.6346, -1.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1288861334323883
Epoch 0, Step 133: train/loss = 0.6037569046020508, train/raw-loss = 0.5374609231948853, train/logprobs = tensor([[-0.6437, -2.4052],
        [-0.5573, -1.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325920820236206
Epoch 0, Step 134: train/loss = 0.6161435842514038, train/raw-loss = 0.5553247928619385, train/logprobs = tensor([[-0.7451, -1.6630],
        [-0.6180, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12163765728473663
Epoch 0, Step 135: train/loss = 0.6569089889526367, train/raw-loss = 0.5903446674346924, train/logprobs = tensor([[-0.5162, -1.4858],
        [-0.3926, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331285536289215
Epoch 0, Step 136: train/loss = 0.583716094493866, train/raw-loss = 0.521047055721283, train/logprobs = tensor([[-0.4393, -2.1171],
        [-0.3929, -1.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12533797323703766
Epoch 0, Step 137: train/loss = 0.6548623442649841, train/raw-loss = 0.5942800045013428, train/logprobs = tensor([[-0.4372, -1.3335],
        [-0.4014, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12116469442844391
Epoch 0, Step 138: train/loss = 0.6080087423324585, train/raw-loss = 0.5383071303367615, train/logprobs = tensor([[-0.4367, -1.7088],
        [-0.3620, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940322399139404
Epoch 0, Step 139: train/loss = 0.5850917100906372, train/raw-loss = 0.5195049047470093, train/logprobs = tensor([[-0.6121, -2.3661],
        [-0.4928, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13117346167564392
Epoch 0, Step 140: train/loss = 0.6403047442436218, train/raw-loss = 0.578818678855896, train/logprobs = tensor([[-0.7768, -1.7583],
        [-0.6560, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12297205626964569
Epoch 0, Step 141: train/loss = 0.6457594037055969, train/raw-loss = 0.5799267292022705, train/logprobs = tensor([[-0.9123, -1.9123],
        [-0.6702, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13166546821594238
Epoch 0, Step 142: train/loss = 0.6679819822311401, train/raw-loss = 0.6089566349983215, train/logprobs = tensor([[-0.5580, -1.2220],
        [-0.4745, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11805067956447601
Epoch 0, Step 143: train/loss = 0.6904636025428772, train/raw-loss = 0.6320945024490356, train/logprobs = tensor([[-0.7413, -1.5543],
        [-0.5851, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673817038536072
Epoch 0, Step 144: train/loss = 0.5210893750190735, train/raw-loss = 0.463204562664032, train/logprobs = tensor([[-0.5733, -3.9370],
        [-0.4947, -2.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11576960980892181
Epoch 0, Step 145: train/loss = 0.6639440059661865, train/raw-loss = 0.6098159551620483, train/logprobs = tensor([[-0.6391, -1.5305],
        [-0.5574, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825621336698532
Epoch 0, Step 146: train/loss = 0.6021127700805664, train/raw-loss = 0.5414738655090332, train/logprobs = tensor([[-0.6397, -2.7655],
        [-0.5122, -1.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212778314948082
Epoch 0, Step 147: train/loss = 0.6649810671806335, train/raw-loss = 0.6057419776916504, train/logprobs = tensor([[-0.6184, -1.1885],
        [-0.5125, -0.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847814917564392
Epoch 0, Step 148: train/loss = 0.7441940307617188, train/raw-loss = 0.6778267621994019, train/logprobs = tensor([[-1.5144, -1.8525],
        [-1.1185, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13273465633392334
Epoch 0, Step 149: train/loss = 0.6791809797286987, train/raw-loss = 0.6265060901641846, train/logprobs = tensor([[-0.6288, -1.2693],
        [-0.5190, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10534968972206116
Epoch 0, Step 150: train/loss = 0.5897508859634399, train/raw-loss = 0.5307213664054871, train/logprobs = tensor([[-0.8156, -3.5241],
        [-0.7216, -1.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11805908381938934
Epoch 0, Step 151: train/loss = 0.640901505947113, train/raw-loss = 0.5784685611724854, train/logprobs = tensor([[-0.6672, -1.8480],
        [-0.5248, -1.1263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12486584484577179
Epoch 0, Step 152: train/loss = 0.6662625670433044, train/raw-loss = 0.5989516973495483, train/logprobs = tensor([[-0.8296, -1.3935],
        [-0.7564, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13462162017822266
Epoch 0, Step 153: train/loss = 0.6368663907051086, train/raw-loss = 0.5656025409698486, train/logprobs = tensor([[-0.6126, -2.0363],
        [-0.5028, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14252761006355286
Epoch 0, Step 154: train/loss = 0.6919113397598267, train/raw-loss = 0.6356090307235718, train/logprobs = tensor([[-0.7426, -1.6127],
        [-0.6421, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11260456591844559
Epoch 0, Step 155: train/loss = 0.6042823791503906, train/raw-loss = 0.5517324209213257, train/logprobs = tensor([[-0.5925, -2.9012],
        [-0.5004, -1.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10510003566741943
Epoch 0, Step 156: train/loss = 0.698574423789978, train/raw-loss = 0.650261402130127, train/logprobs = tensor([[-0.6321, -0.7569],
        [-0.5682, -0.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09662608802318573
Epoch 0, Step 157: train/loss = 0.7302263975143433, train/raw-loss = 0.6856082081794739, train/logprobs = tensor([[-0.7339, -0.7948],
        [-0.6445, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08923637866973877
Epoch 0, Step 158: train/loss = 0.7002525329589844, train/raw-loss = 0.6427555084228516, train/logprobs = tensor([[-0.6911, -1.2094],
        [-0.4827, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11499404907226562
Epoch 0, Step 159: train/loss = 0.7205624580383301, train/raw-loss = 0.6659785509109497, train/logprobs = tensor([[-0.8538, -1.0457],
        [-0.7103, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916788130998611
Epoch 0, Step 160: train/loss = 0.5719666481018066, train/raw-loss = 0.5189914107322693, train/logprobs = tensor([[-1.0925, -2.2931],
        [-0.8448, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595039278268814
Epoch 0, Step 161: train/loss = 0.6532944440841675, train/raw-loss = 0.6170110702514648, train/logprobs = tensor([[-0.6654, -1.2932],
        [-0.5541, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07256677746772766
Epoch 0, Step 162: train/loss = 0.596363365650177, train/raw-loss = 0.5557636618614197, train/logprobs = tensor([[-0.5760, -3.0250],
        [-0.5042, -1.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119934797286987
Epoch 0, Step 163: train/loss = 0.5839418172836304, train/raw-loss = 0.5341551303863525, train/logprobs = tensor([[-0.5745, -2.1089],
        [-0.4354, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957345575094223
Epoch 0, Step 164: train/loss = 0.5944604873657227, train/raw-loss = 0.5541094541549683, train/logprobs = tensor([[-0.6688, -1.8418],
        [-0.5198, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08070216327905655
Epoch 0, Step 165: train/loss = 0.5809198021888733, train/raw-loss = 0.5304595828056335, train/logprobs = tensor([[-0.6519, -2.1802],
        [-0.4904, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10092032700777054
Epoch 0, Step 166: train/loss = 0.4595656096935272, train/raw-loss = 0.40854009985923767, train/logprobs = tensor([[-0.6391, -6.7852],
        [-0.4457, -3.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10205113142728806
Epoch 0, Step 167: train/loss = 0.6545225381851196, train/raw-loss = 0.6047526001930237, train/logprobs = tensor([[-0.7256, -1.4412],
        [-0.5666, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09953999519348145
Epoch 0, Step 168: train/loss = 0.6224721670150757, train/raw-loss = 0.5765143632888794, train/logprobs = tensor([[-0.7044, -1.5327],
        [-0.5495, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09191549569368362
Epoch 0, Step 169: train/loss = 0.685905396938324, train/raw-loss = 0.6458964347839355, train/logprobs = tensor([[-0.7913, -1.3331],
        [-0.7236, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800180733203888
Epoch 0, Step 170: train/loss = 0.6169699430465698, train/raw-loss = 0.5680656433105469, train/logprobs = tensor([[-0.5921, -1.7003],
        [-0.5556, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780861437320709
Epoch 0, Step 171: train/loss = 0.6750718355178833, train/raw-loss = 0.6284482479095459, train/logprobs = tensor([[-0.6499, -1.3514],
        [-0.5116, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09324730932712555
Epoch 0, Step 172: train/loss = 0.537665605545044, train/raw-loss = 0.4885171055793762, train/logprobs = tensor([[-0.6406, -2.6048],
        [-0.5742, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09829698503017426
Epoch 0, Step 173: train/loss = 0.5602319240570068, train/raw-loss = 0.5137815475463867, train/logprobs = tensor([[-0.6204, -2.4713],
        [-0.5404, -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0929008424282074
Epoch 0, Step 174: train/loss = 0.5648767352104187, train/raw-loss = 0.517996609210968, train/logprobs = tensor([[-0.6815, -2.0681],
        [-0.5551, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09376029670238495
Epoch 0, Step 175: train/loss = 0.4783077538013458, train/raw-loss = 0.4285045564174652, train/logprobs = tensor([[-0.5094, -3.5954],
        [-0.4054, -1.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09960637986660004
Epoch 0, Step 176: train/loss = 0.6325520873069763, train/raw-loss = 0.5771771669387817, train/logprobs = tensor([[-0.7310, -1.6621],
        [-0.4961, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11074985563755035
Epoch 0, Step 177: train/loss = 0.6139777302742004, train/raw-loss = 0.5602802038192749, train/logprobs = tensor([[-1.0608, -2.5072],
        [-0.6297, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739508271217346
Epoch 0, Step 178: train/loss = 0.6430885791778564, train/raw-loss = 0.5954577922821045, train/logprobs = tensor([[-0.8569, -2.4296],
        [-0.7469, -1.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526151418685913
Epoch 0, Step 179: train/loss = 0.6278781294822693, train/raw-loss = 0.5817197561264038, train/logprobs = tensor([[-0.6564, -2.4753],
        [-0.4986, -1.6459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09231676161289215
Epoch 0, Step 180: train/loss = 0.7277982234954834, train/raw-loss = 0.6815450191497803, train/logprobs = tensor([[-0.8396, -0.9036],
        [-0.6394, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09250642359256744
Epoch 0, Step 181: train/loss = 0.7383598685264587, train/raw-loss = 0.6886352300643921, train/logprobs = tensor([[-2.8063, -4.1149],
        [-1.9110, -2.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994492694735527
Epoch 0, Step 182: train/loss = 0.6550987362861633, train/raw-loss = 0.6105433702468872, train/logprobs = tensor([[-0.5359, -1.2488],
        [-0.4580, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911072462797165
Epoch 0, Step 183: train/loss = 0.6125368475914001, train/raw-loss = 0.5633059144020081, train/logprobs = tensor([[-0.7098, -1.7517],
        [-0.5930, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09846189618110657
Epoch 0, Step 184: train/loss = 0.5319207906723022, train/raw-loss = 0.484667032957077, train/logprobs = tensor([[-1.1930, -4.2031],
        [-1.1682, -2.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09450747072696686
Epoch 0, Step 185: train/loss = 0.6136468052864075, train/raw-loss = 0.5679298043251038, train/logprobs = tensor([[-0.8526, -2.1051],
        [-0.6701, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09143396466970444
Epoch 0, Step 186: train/loss = 0.6279382109642029, train/raw-loss = 0.5694505572319031, train/logprobs = tensor([[-0.8128, -1.6580],
        [-0.7145, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169753447175026
Epoch 0, Step 187: train/loss = 0.6088998317718506, train/raw-loss = 0.5658746361732483, train/logprobs = tensor([[-0.6051, -2.3226],
        [-0.4880, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605033159255981
Epoch 0, Step 188: train/loss = 0.5396251082420349, train/raw-loss = 0.4909122586250305, train/logprobs = tensor([[-0.8564, -4.1431],
        [-0.6081, -2.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974256843328476
Epoch 0, Step 189: train/loss = 0.6880757212638855, train/raw-loss = 0.6517988443374634, train/logprobs = tensor([[-0.6009, -0.8932],
        [-0.5072, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07255382090806961
Epoch 0, Step 190: train/loss = 0.5685102343559265, train/raw-loss = 0.5274640321731567, train/logprobs = tensor([[-0.8256, -3.6794],
        [-0.6151, -1.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209246397018433
Epoch 0, Step 191: train/loss = 0.6603981852531433, train/raw-loss = 0.6119563579559326, train/logprobs = tensor([[-0.6880, -1.1597],
        [-0.5963, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09688369929790497
Epoch 0, Step 192: train/loss = 0.6138941049575806, train/raw-loss = 0.551566481590271, train/logprobs = tensor([[-0.7531, -1.5653],
        [-0.5591, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12465524673461914
Epoch 0, Step 193: train/loss = 0.5383752584457397, train/raw-loss = 0.46832388639450073, train/logprobs = tensor([[-0.7766, -3.1784],
        [-0.6425, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140102818608284
Epoch 0, Step 194: train/loss = 0.5284738540649414, train/raw-loss = 0.4641493558883667, train/logprobs = tensor([[-0.8833, -3.8502],
        [-0.7277, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864895164966583
Epoch 0, Step 195: train/loss = 0.556664228439331, train/raw-loss = 0.4960746765136719, train/logprobs = tensor([[-0.8249, -3.4632],
        [-0.6090, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12117911875247955
Epoch 0, Step 196: train/loss = 0.6316990256309509, train/raw-loss = 0.5721396207809448, train/logprobs = tensor([[-0.7086, -1.5595],
        [-0.5831, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11911876499652863
Epoch 0, Step 197: train/loss = 0.5782368183135986, train/raw-loss = 0.5176199674606323, train/logprobs = tensor([[-0.7027, -2.4264],
        [-0.5062, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123367190361023
Epoch 0, Step 198: train/loss = 0.6094987988471985, train/raw-loss = 0.5484496355056763, train/logprobs = tensor([[-0.6777, -1.8193],
        [-0.5526, -0.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12209834903478622
Epoch 0, Step 199: train/loss = 0.5098035931587219, train/raw-loss = 0.4442095160484314, train/logprobs = tensor([[-0.5112, -2.3361],
        [-0.3757, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311882883310318
Epoch 0, Step 200: train/loss = 0.5345304012298584, train/raw-loss = 0.4809991717338562, train/logprobs = tensor([[-0.8825, -2.3136],
        [-0.6731, -0.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10706239938735962
Epoch 0, Step 201: train/loss = 0.5282528400421143, train/raw-loss = 0.45878246426582336, train/logprobs = tensor([[-0.8970, -3.3541],
        [-0.6802, -1.3329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13894081115722656
Epoch 0, Step 202: train/loss = 0.6492443680763245, train/raw-loss = 0.5925478935241699, train/logprobs = tensor([[-0.6961, -1.1703],
        [-0.6771, -0.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11339297890663147
Epoch 0, Step 203: train/loss = 0.6410850882530212, train/raw-loss = 0.5771498680114746, train/logprobs = tensor([[-0.7772, -2.7693],
        [-0.4623, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278703510761261
Epoch 0, Step 204: train/loss = 0.5607624053955078, train/raw-loss = 0.5051839351654053, train/logprobs = tensor([[-0.9198, -2.1151],
        [-0.7322, -0.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11115691810846329
Epoch 0, Step 205: train/loss = 0.49483630061149597, train/raw-loss = 0.4314178228378296, train/logprobs = tensor([[-0.5619, -2.4954],
        [-0.5092, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12683698534965515
Epoch 0, Step 206: train/loss = 0.41141608357429504, train/raw-loss = 0.35075312852859497, train/logprobs = tensor([[-0.6166, -5.5434],
        [-0.5241, -1.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12132591009140015
Epoch 0, Step 207: train/loss = 0.5228309035301208, train/raw-loss = 0.4624094069004059, train/logprobs = tensor([[-0.9516, -2.3887],
        [-0.7815, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12084294855594635
Epoch 0, Step 208: train/loss = 0.5385544300079346, train/raw-loss = 0.479568213224411, train/logprobs = tensor([[-0.7794, -3.4693],
        [-0.5414, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11797235906124115
Epoch 0, Step 209: train/loss = 0.5971866250038147, train/raw-loss = 0.5299596786499023, train/logprobs = tensor([[-0.7662, -2.1345],
        [-0.6212, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344539374113083
Epoch 0, Step 210: train/loss = 0.5858274698257446, train/raw-loss = 0.5315545797348022, train/logprobs = tensor([[-0.6985, -1.7163],
        [-0.5626, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10854572802782059
Epoch 0, Step 211: train/loss = 0.6270730495452881, train/raw-loss = 0.5702162384986877, train/logprobs = tensor([[-1.0727, -4.1237],
        [-1.0417, -1.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11371354758739471
Epoch 0, Step 212: train/loss = 0.6531166434288025, train/raw-loss = 0.5999425649642944, train/logprobs = tensor([[-0.5691, -1.3434],
        [-0.4540, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10634806007146835
Epoch 0, Step 213: train/loss = 0.6577930450439453, train/raw-loss = 0.5950160026550293, train/logprobs = tensor([[-0.7005, -1.3626],
        [-0.5107, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12555406987667084
Epoch 0, Step 214: train/loss = 0.575851321220398, train/raw-loss = 0.5107259750366211, train/logprobs = tensor([[-0.6301, -2.9328],
        [-0.5682, -1.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13025058805942535
Epoch 0, Step 215: train/loss = 0.5447430610656738, train/raw-loss = 0.48360681533813477, train/logprobs = tensor([[-0.9494, -2.8744],
        [-0.8638, -1.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227252870798111
Epoch 0, Step 216: train/loss = 0.6614170074462891, train/raw-loss = 0.6079082489013672, train/logprobs = tensor([[-0.8232, -1.2732],
        [-0.5317, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10701749473810196
Epoch 0, Step 217: train/loss = 0.5238572359085083, train/raw-loss = 0.46467527747154236, train/logprobs = tensor([[-0.6015, -2.5563],
        [-0.5105, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11836397647857666
Epoch 0, Step 218: train/loss = 0.7124668955802917, train/raw-loss = 0.6671017408370972, train/logprobs = tensor([[-0.6248, -0.7925],
        [-0.5264, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073023498058319
Epoch 0, Step 219: train/loss = 0.6131756901741028, train/raw-loss = 0.5558228492736816, train/logprobs = tensor([[-0.6774, -1.7830],
        [-0.5565, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1147056519985199
Epoch 0, Step 220: train/loss = 0.4694804847240448, train/raw-loss = 0.41178566217422485, train/logprobs = tensor([[-1.1353, -3.7931],
        [-0.8831, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538964509963989
Epoch 0, Step 221: train/loss = 0.5617299675941467, train/raw-loss = 0.5076228380203247, train/logprobs = tensor([[-0.4845, -4.0297],
        [-0.4250, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1082143634557724
Epoch 0, Step 222: train/loss = 0.6060787439346313, train/raw-loss = 0.5515013933181763, train/logprobs = tensor([[-0.6863, -2.1250],
        [-0.5178, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10915482044219971
Epoch 0, Step 223: train/loss = 0.6159099340438843, train/raw-loss = 0.5589629411697388, train/logprobs = tensor([[-0.8505, -2.1553],
        [-0.6408, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11389392614364624
Epoch 0, Step 224: train/loss = 0.6031640768051147, train/raw-loss = 0.5474555492401123, train/logprobs = tensor([[-0.7293, -1.5371],
        [-0.6538, -0.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11141693592071533
Epoch 0, Step 225: train/loss = 0.6114176511764526, train/raw-loss = 0.5628024935722351, train/logprobs = tensor([[-0.6212, -1.5176],
        [-0.4468, -0.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09723034501075745
Epoch 0, Step 226: train/loss = 0.8840024471282959, train/raw-loss = 0.829714298248291, train/logprobs = tensor([[-2.1849, -3.4096],
        [-0.6783, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10857649147510529
Epoch 0, Step 227: train/loss = 0.5199018120765686, train/raw-loss = 0.4529726505279541, train/logprobs = tensor([[-1.0608, -3.4613],
        [-0.5633, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13385824859142303
Epoch 0, Step 228: train/loss = 0.5754919052124023, train/raw-loss = 0.5297325849533081, train/logprobs = tensor([[-0.5815, -2.0773],
        [-0.4373, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09151865541934967
Epoch 0, Step 229: train/loss = 0.4740554690361023, train/raw-loss = 0.4180166721343994, train/logprobs = tensor([[-0.9470, -5.3260],
        [-0.8166, -2.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11207757145166397
Epoch 0, Step 230: train/loss = 0.48399829864501953, train/raw-loss = 0.4274170994758606, train/logprobs = tensor([[-1.1675, -3.3532],
        [-1.0521, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316238343715668
Epoch 0, Step 231: train/loss = 0.4553701877593994, train/raw-loss = 0.40448808670043945, train/logprobs = tensor([[-0.6780, -4.3543],
        [-0.6810, -0.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1017642542719841
Epoch 0, Step 232: train/loss = 0.5781553983688354, train/raw-loss = 0.5242915153503418, train/logprobs = tensor([[-0.6234, -2.4815],
        [-0.5750, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10772772878408432
Epoch 0, Step 233: train/loss = 0.6381224989891052, train/raw-loss = 0.5842419266700745, train/logprobs = tensor([[-1.2840, -5.2240],
        [-0.8259, -1.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776111483573914
Epoch 0, Step 234: train/loss = 0.6512942910194397, train/raw-loss = 0.6002216339111328, train/logprobs = tensor([[-0.6061, -1.1390],
        [-0.4890, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214526951313019
Epoch 0, Step 235: train/loss = 0.5132653713226318, train/raw-loss = 0.4568015933036804, train/logprobs = tensor([[-0.9917, -4.4997],
        [-0.5750, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11292758584022522
Epoch 0, Step 236: train/loss = 0.6234656572341919, train/raw-loss = 0.5632724761962891, train/logprobs = tensor([[-0.7412, -1.9856],
        [-0.6146, -1.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038636207580566
Epoch 0, Step 237: train/loss = 0.553550124168396, train/raw-loss = 0.5013327598571777, train/logprobs = tensor([[-0.7584, -2.0901],
        [-0.6532, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10443463921546936
Epoch 0, Step 238: train/loss = 0.5073143839836121, train/raw-loss = 0.4571039080619812, train/logprobs = tensor([[-0.5880, -2.5926],
        [-0.4951, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10042093694210052
Epoch 0, Step 239: train/loss = 0.671549916267395, train/raw-loss = 0.6224350929260254, train/logprobs = tensor([[-0.8259, -1.1328],
        [-0.5683, -0.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09822957962751389
Epoch 0, Step 240: train/loss = 0.6414719820022583, train/raw-loss = 0.5808683037757874, train/logprobs = tensor([[-1.1136, -2.5744],
        [-1.0697, -1.3701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120728194713593
Epoch 0, Step 241: train/loss = 0.5338026285171509, train/raw-loss = 0.4778754413127899, train/logprobs = tensor([[-0.5565, -1.9406],
        [-0.5220, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11185438930988312
Epoch 0, Step 242: train/loss = 0.6586037874221802, train/raw-loss = 0.607784628868103, train/logprobs = tensor([[-0.5837, -1.0421],
        [-0.4083, -0.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10163818299770355
Epoch 0, Step 243: train/loss = 0.6710735559463501, train/raw-loss = 0.6238260269165039, train/logprobs = tensor([[-0.8168, -1.1891],
        [-0.5059, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09449508786201477
Epoch 0, Step 244: train/loss = 0.5155724287033081, train/raw-loss = 0.45705360174179077, train/logprobs = tensor([[-1.0545, -3.8010],
        [-0.6937, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11703765392303467
Epoch 0, Step 245: train/loss = 0.5659320950508118, train/raw-loss = 0.509590208530426, train/logprobs = tensor([[-1.0921, -2.3911],
        [-0.6480, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268376559019089
Epoch 0, Step 246: train/loss = 0.48630064725875854, train/raw-loss = 0.4287833571434021, train/logprobs = tensor([[-0.6739, -3.9461],
        [-0.6728, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11503459513187408
Epoch 0, Step 247: train/loss = 0.5895606875419617, train/raw-loss = 0.5336179137229919, train/logprobs = tensor([[-0.9678, -2.5518],
        [-0.7397, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188540607690811
Epoch 0, Step 248: train/loss = 0.6252986788749695, train/raw-loss = 0.5784711241722107, train/logprobs = tensor([[-0.6675, -1.9316],
        [-0.6795, -1.3210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0936550498008728
Epoch 0, Step 249: train/loss = 0.5576127767562866, train/raw-loss = 0.5078161358833313, train/logprobs = tensor([[-0.4840, -2.3027],
        [-0.5063, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09959334135055542
Epoch 0, Step 250: train/loss = 0.5384417772293091, train/raw-loss = 0.4815751314163208, train/logprobs = tensor([[-1.2273, -4.3864],
        [-0.5852, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11373329162597656
Epoch 0, Step 251: train/loss = 0.44245630502700806, train/raw-loss = 0.38499847054481506, train/logprobs = tensor([[-0.6577, -2.9855],
        [-0.6384, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1149156391620636
Epoch 0, Step 252: train/loss = 0.5903768539428711, train/raw-loss = 0.5410356521606445, train/logprobs = tensor([[-0.4970, -1.6467],
        [-0.4106, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868235886096954
Epoch 0, Step 253: train/loss = 0.7350332736968994, train/raw-loss = 0.6871984004974365, train/logprobs = tensor([[-0.7720, -0.6352],
        [-0.6311, -0.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956697165966034
Epoch 0, Step 254: train/loss = 0.5036976933479309, train/raw-loss = 0.44983047246932983, train/logprobs = tensor([[-0.7722, -3.3359],
        [-0.5885, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10773445665836334
Epoch 0, Step 255: train/loss = 0.5966665744781494, train/raw-loss = 0.5409376621246338, train/logprobs = tensor([[-1.1044, -2.6094],
        [-0.8929, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11145775765180588
Epoch 0, Step 256: train/loss = 0.6878990530967712, train/raw-loss = 0.646673321723938, train/logprobs = tensor([[-0.5758, -0.8756],
        [-0.4357, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245154470205307
Epoch 0, Step 257: train/loss = 0.6732048988342285, train/raw-loss = 0.6254039406776428, train/logprobs = tensor([[-0.7809, -1.2617],
        [-0.6007, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.095601886510849
Epoch 0, Step 258: train/loss = 0.4013896584510803, train/raw-loss = 0.34608110785484314, train/logprobs = tensor([[-0.9284, -3.4018],
        [-0.9503, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11061719059944153
Epoch 0, Step 259: train/loss = 0.5581095814704895, train/raw-loss = 0.5146297216415405, train/logprobs = tensor([[-0.5926, -3.7871],
        [-0.5164, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08695979416370392
Epoch 0, Step 260: train/loss = 0.47346651554107666, train/raw-loss = 0.42425060272216797, train/logprobs = tensor([[-0.5328, -4.6550],
        [-0.4682, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843183308839798
Epoch 0, Step 261: train/loss = 0.5131011009216309, train/raw-loss = 0.4536224901676178, train/logprobs = tensor([[-0.8229, -2.2296],
        [-0.8453, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11895723640918732
Epoch 0, Step 262: train/loss = 0.5854861736297607, train/raw-loss = 0.5327243208885193, train/logprobs = tensor([[-0.7092, -2.4984],
        [-0.6177, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552369803190231
Epoch 0, Step 263: train/loss = 0.6424791812896729, train/raw-loss = 0.5863530039787292, train/logprobs = tensor([[-1.3132, -2.1051],
        [-1.0641, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11225231736898422
Epoch 0, Step 264: train/loss = 0.6298127770423889, train/raw-loss = 0.5834060907363892, train/logprobs = tensor([[-0.7534, -1.4128],
        [-0.6742, -0.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09281343966722488
Epoch 0, Step 265: train/loss = 0.683170735836029, train/raw-loss = 0.6355187892913818, train/logprobs = tensor([[-0.8969, -1.3399],
        [-0.6491, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530390053987503
Epoch 0, Step 266: train/loss = 0.4597669243812561, train/raw-loss = 0.4052525758743286, train/logprobs = tensor([[-1.0242, -3.4908],
        [-1.0191, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902871191501617
Epoch 0, Step 267: train/loss = 0.5023714303970337, train/raw-loss = 0.4498223662376404, train/logprobs = tensor([[-0.6977, -2.4360],
        [-0.5568, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10509806871414185
Epoch 0, Step 268: train/loss = 0.5320757627487183, train/raw-loss = 0.48633694648742676, train/logprobs = tensor([[-0.6638, -5.0953],
        [-0.6585, -1.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09147760272026062
Epoch 0, Step 269: train/loss = 0.5452837944030762, train/raw-loss = 0.4944620430469513, train/logprobs = tensor([[-0.7980, -3.9638],
        [-0.7016, -1.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10164351761341095
Epoch 0, Step 270: train/loss = 0.5345134139060974, train/raw-loss = 0.48264971375465393, train/logprobs = tensor([[-0.4138, -2.1217],
        [-0.3533, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1037273183465004
Epoch 0, Step 271: train/loss = 0.5441092848777771, train/raw-loss = 0.49218130111694336, train/logprobs = tensor([[-0.7979, -2.1624],
        [-0.6632, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385598242282867
Epoch 0, Step 272: train/loss = 0.7086414694786072, train/raw-loss = 0.6619646549224854, train/logprobs = tensor([[-0.6178, -0.8474],
        [-0.5513, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335361421108246
Epoch 0, Step 273: train/loss = 0.6058681607246399, train/raw-loss = 0.5572568774223328, train/logprobs = tensor([[-0.4715, -1.2785],
        [-0.4925, -0.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09722250699996948
Epoch 0, Step 274: train/loss = 0.6246079206466675, train/raw-loss = 0.573030948638916, train/logprobs = tensor([[-0.5790, -1.6523],
        [-0.4900, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10315395891666412
Epoch 0, Step 275: train/loss = 0.5209708213806152, train/raw-loss = 0.4787684381008148, train/logprobs = tensor([[-0.4877, -1.8535],
        [-0.4398, -0.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08440461754798889
Epoch 0, Step 276: train/loss = 0.5831415057182312, train/raw-loss = 0.5294452905654907, train/logprobs = tensor([[-1.2527, -2.6167],
        [-1.0599, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739235579967499
Epoch 0, Step 277: train/loss = 0.6453189849853516, train/raw-loss = 0.5874301195144653, train/logprobs = tensor([[-0.7832, -1.2226],
        [-0.7566, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577769368886948
Epoch 0, Step 278: train/loss = 0.5862230062484741, train/raw-loss = 0.5302728414535522, train/logprobs = tensor([[-0.7938, -1.4293],
        [-0.7186, -0.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190026998519897
Epoch 0, Step 279: train/loss = 0.4580496847629547, train/raw-loss = 0.4032188355922699, train/logprobs = tensor([[-1.0199, -4.2210],
        [-0.7453, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10966168344020844
Epoch 0, Step 280: train/loss = 0.5320385694503784, train/raw-loss = 0.4797557294368744, train/logprobs = tensor([[-0.8075, -4.4179],
        [-0.6310, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456569492816925
Epoch 0, Step 281: train/loss = 0.6022338271141052, train/raw-loss = 0.555004358291626, train/logprobs = tensor([[-0.5591, -1.1965],
        [-0.4824, -0.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445888549089432
Epoch 0, Step 282: train/loss = 0.607042670249939, train/raw-loss = 0.5384592413902283, train/logprobs = tensor([[-1.2465, -3.2417],
        [-0.8128, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13716687262058258
Epoch 0, Step 283: train/loss = 0.5488379001617432, train/raw-loss = 0.49795886874198914, train/logprobs = tensor([[-0.7723, -2.2470],
        [-0.6185, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175793617963791
Epoch 0, Step 284: train/loss = 0.5975539684295654, train/raw-loss = 0.5458458065986633, train/logprobs = tensor([[-0.4868, -1.3668],
        [-0.4871, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034163162112236
Epoch 0, Step 285: train/loss = 0.6223431825637817, train/raw-loss = 0.573598325252533, train/logprobs = tensor([[-0.5789, -1.1686],
        [-0.5722, -0.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09748966991901398
Epoch 0, Step 286: train/loss = 0.5492600202560425, train/raw-loss = 0.5028667449951172, train/logprobs = tensor([[-0.4147, -1.7763],
        [-0.3448, -0.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927867442369461
Epoch 0, Step 287: train/loss = 0.532850444316864, train/raw-loss = 0.4777159094810486, train/logprobs = tensor([[-0.7721, -3.8054],
        [-0.7526, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11026903986930847
Epoch 0, Step 288: train/loss = 0.5706228613853455, train/raw-loss = 0.5197845697402954, train/logprobs = tensor([[-0.5725, -1.6727],
        [-0.6064, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10167653858661652
Epoch 0, Step 289: train/loss = 0.5430316925048828, train/raw-loss = 0.4861411154270172, train/logprobs = tensor([[-0.8274, -3.1474],
        [-0.7390, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11378110945224762
Epoch 0, Step 290: train/loss = 0.5358476638793945, train/raw-loss = 0.4869697093963623, train/logprobs = tensor([[-0.5646, -2.9064],
        [-0.5352, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09775592386722565
Epoch 0, Step 291: train/loss = 0.48549413681030273, train/raw-loss = 0.43331828713417053, train/logprobs = tensor([[-0.7081, -2.1828],
        [-0.7609, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.104351706802845
Epoch 0, Step 292: train/loss = 0.5750811696052551, train/raw-loss = 0.5276319980621338, train/logprobs = tensor([[-0.6073, -1.3770],
        [-0.6802, -0.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09489835798740387
Epoch 0, Step 293: train/loss = 0.5724096298217773, train/raw-loss = 0.5160204172134399, train/logprobs = tensor([[-0.7763, -2.2149],
        [-0.7046, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127784326672554
Epoch 0, Step 294: train/loss = 0.5714069604873657, train/raw-loss = 0.5196864604949951, train/logprobs = tensor([[-0.8972, -1.6753],
        [-0.7725, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10344085097312927
Epoch 0, Step 295: train/loss = 0.5494601726531982, train/raw-loss = 0.4934781491756439, train/logprobs = tensor([[-1.3893, -2.8889],
        [-1.2558, -1.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11196400225162506
Epoch 0, Step 296: train/loss = 0.5893237590789795, train/raw-loss = 0.5392370223999023, train/logprobs = tensor([[-0.6810, -1.8910],
        [-0.6400, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017350316047668
Epoch 0, Step 297: train/loss = 0.48571550846099854, train/raw-loss = 0.4355560839176178, train/logprobs = tensor([[-0.6237, -3.3614],
        [-0.6601, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003188043832779
Epoch 0, Step 298: train/loss = 0.5617954134941101, train/raw-loss = 0.5145425200462341, train/logprobs = tensor([[-0.5491, -1.5187],
        [-0.6792, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0945056900382042
Epoch 0, Step 299: train/loss = 0.4795074462890625, train/raw-loss = 0.43060874938964844, train/logprobs = tensor([[-0.9928, -2.9707],
        [-0.9847, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779739379882812
Epoch 0, Step 300: train/loss = 0.5341558456420898, train/raw-loss = 0.4871475100517273, train/logprobs = tensor([[-0.7420, -2.3911],
        [-0.7729, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401663392782211
Epoch 0, Step 301: train/loss = 0.5869651436805725, train/raw-loss = 0.5346145033836365, train/logprobs = tensor([[-0.6384, -1.2781],
        [-0.5976, -0.4031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470129549503326
Epoch 0, Step 302: train/loss = 0.5113179683685303, train/raw-loss = 0.460438072681427, train/logprobs = tensor([[-0.6466, -2.2341],
        [-0.6002, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175967961549759
Epoch 0, Step 303: train/loss = 0.4723210334777832, train/raw-loss = 0.42120227217674255, train/logprobs = tensor([[-0.5407, -2.6163],
        [-0.5666, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10223758965730667
Epoch 0, Step 304: train/loss = 0.5703436732292175, train/raw-loss = 0.5192397832870483, train/logprobs = tensor([[-0.6374, -1.7135],
        [-0.6296, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10220779478549957
Epoch 0, Step 305: train/loss = 0.566116213798523, train/raw-loss = 0.5109736919403076, train/logprobs = tensor([[-0.8689, -2.7615],
        [-0.5371, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028511822223663
Epoch 0, Step 306: train/loss = 0.5966755747795105, train/raw-loss = 0.5468078851699829, train/logprobs = tensor([[-0.8045, -3.5091],
        [-0.6759, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997353196144104
Epoch 0, Step 307: train/loss = 0.574435293674469, train/raw-loss = 0.521045446395874, train/logprobs = tensor([[-0.8355, -4.0076],
        [-0.8372, -1.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10677981376647949
Epoch 0, Step 308: train/loss = 0.6070351600646973, train/raw-loss = 0.5580998659133911, train/logprobs = tensor([[-0.6955, -1.3804],
        [-0.6470, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09787063300609589
Epoch 0, Step 309: train/loss = 0.6179558038711548, train/raw-loss = 0.5705127716064453, train/logprobs = tensor([[-0.5182, -1.3150],
        [-0.4602, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09488606452941895
Epoch 0, Step 310: train/loss = 0.4250282645225525, train/raw-loss = 0.36873748898506165, train/logprobs = tensor([[-0.6680, -4.0832],
        [-0.5455, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258158087730408
Epoch 0, Step 311: train/loss = 0.5727789998054504, train/raw-loss = 0.5242340564727783, train/logprobs = tensor([[-0.5655, -2.5242],
        [-0.6041, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708994626998901
Epoch 0, Step 312: train/loss = 0.6053004860877991, train/raw-loss = 0.5610640048980713, train/logprobs = tensor([[-0.6593, -3.3203],
        [-0.5246, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884728878736496
Epoch 0, Step 313: train/loss = 0.514297604560852, train/raw-loss = 0.45819228887557983, train/logprobs = tensor([[-0.6298, -2.3194],
        [-0.6236, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11221054196357727
Epoch 0, Step 314: train/loss = 0.6449005603790283, train/raw-loss = 0.5981168150901794, train/logprobs = tensor([[-0.6079, -0.8683],
        [-0.6214, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356747567653656
Epoch 0, Step 315: train/loss = 0.6068011522293091, train/raw-loss = 0.551621675491333, train/logprobs = tensor([[-1.8262, -3.5792],
        [-1.3759, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11035898327827454
Epoch 0, Step 316: train/loss = 0.710845947265625, train/raw-loss = 0.6719553470611572, train/logprobs = tensor([[-0.7377, -0.6828],
        [-0.7357, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07778122276067734
Epoch 0, Step 317: train/loss = 0.4538058638572693, train/raw-loss = 0.40234246850013733, train/logprobs = tensor([[-0.4766, -4.3855],
        [-0.4915, -1.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10292679071426392
Epoch 0, Step 318: train/loss = 0.47572481632232666, train/raw-loss = 0.424604207277298, train/logprobs = tensor([[-0.7397, -2.6881],
        [-0.7498, -0.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1022411584854126
Epoch 0, Step 319: train/loss = 0.5038726329803467, train/raw-loss = 0.4515189230442047, train/logprobs = tensor([[-0.5425, -2.6819],
        [-0.5685, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470733791589737
Epoch 0, Step 320: train/loss = 0.5384807586669922, train/raw-loss = 0.49270251393318176, train/logprobs = tensor([[-0.8057, -2.5716],
        [-0.6657, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09155643731355667
Epoch 0, Step 321: train/loss = 0.5634372234344482, train/raw-loss = 0.5212448835372925, train/logprobs = tensor([[-0.6275, -1.6879],
        [-0.6089, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438466489315033
Epoch 0, Step 322: train/loss = 0.47237181663513184, train/raw-loss = 0.4264025092124939, train/logprobs = tensor([[-1.0180, -3.9167],
        [-0.9040, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09193859249353409
Epoch 0, Step 323: train/loss = 0.5206960439682007, train/raw-loss = 0.4763430058956146, train/logprobs = tensor([[-0.4119, -2.2458],
        [-0.4368, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08870596438646317
Epoch 0, Step 324: train/loss = 0.39310920238494873, train/raw-loss = 0.3395349383354187, train/logprobs = tensor([[-0.7847, -5.1866],
        [-0.6685, -1.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714854300022125
Epoch 0, Step 325: train/loss = 0.6373192667961121, train/raw-loss = 0.595417320728302, train/logprobs = tensor([[-0.5997, -1.1207],
        [-0.5664, -0.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380384743213654
Epoch 0, Step 326: train/loss = 0.43625566363334656, train/raw-loss = 0.3861100673675537, train/logprobs = tensor([[-0.8955, -4.7619],
        [-1.0263, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1002911776304245
Epoch 0, Step 327: train/loss = 0.7282470464706421, train/raw-loss = 0.678020715713501, train/logprobs = tensor([[-0.8332, -1.0495],
        [-0.6346, -0.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10045281797647476
Epoch 0, Step 328: train/loss = 0.6289274096488953, train/raw-loss = 0.5874164700508118, train/logprobs = tensor([[-0.8279, -1.6717],
        [-0.8142, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08302199840545654
Epoch 0, Step 329: train/loss = 0.6209645867347717, train/raw-loss = 0.5714305639266968, train/logprobs = tensor([[-1.0681, -1.5439],
        [-0.8671, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09906802326440811
Epoch 0, Step 330: train/loss = 0.37390345335006714, train/raw-loss = 0.32446378469467163, train/logprobs = tensor([[-0.6707, -4.2274],
        [-0.6510, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09887929260730743
Epoch 0, Step 331: train/loss = 0.49174702167510986, train/raw-loss = 0.4506138265132904, train/logprobs = tensor([[-0.6202, -3.9284],
        [-0.6101, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08226637542247772
Epoch 0, Step 332: train/loss = 0.4426844120025635, train/raw-loss = 0.391315221786499, train/logprobs = tensor([[-0.7727, -3.5435],
        [-0.8926, -1.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273841768503189
Epoch 0, Step 333: train/loss = 0.5332008600234985, train/raw-loss = 0.48444491624832153, train/logprobs = tensor([[-0.7559, -2.7678],
        [-0.6157, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09751195460557938
Epoch 0, Step 334: train/loss = 0.6578266620635986, train/raw-loss = 0.6164852380752563, train/logprobs = tensor([[-0.7318, -0.9181],
        [-0.6423, -0.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268287777900696
Epoch 0, Step 335: train/loss = 0.4754661023616791, train/raw-loss = 0.4289434254169464, train/logprobs = tensor([[-0.6436, -2.2718],
        [-0.5661, -0.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09304534643888474
Epoch 0, Step 336: train/loss = 0.5497026443481445, train/raw-loss = 0.5023619532585144, train/logprobs = tensor([[-0.5459, -1.6659],
        [-0.6034, -0.6379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468135982751846
Epoch 0, Step 337: train/loss = 0.5309405326843262, train/raw-loss = 0.480701744556427, train/logprobs = tensor([[-0.8602, -2.1090],
        [-0.8629, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10047763586044312
Epoch 0, Step 338: train/loss = 0.5446065664291382, train/raw-loss = 0.49729156494140625, train/logprobs = tensor([[-0.5525, -1.6185],
        [-0.5640, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09462998807430267
Epoch 0, Step 339: train/loss = 0.48440200090408325, train/raw-loss = 0.4397781491279602, train/logprobs = tensor([[-0.3720, -4.1164],
        [-0.3994, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924776315689087
Epoch 0, Step 340: train/loss = 0.6167072057723999, train/raw-loss = 0.5753881335258484, train/logprobs = tensor([[-0.7766, -1.3435],
        [-0.7251, -0.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08263810724020004
Epoch 0, Step 341: train/loss = 0.41689205169677734, train/raw-loss = 0.3682015538215637, train/logprobs = tensor([[-0.6038, -3.0916],
        [-0.6798, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09738096594810486
Epoch 0, Step 342: train/loss = 0.5190495848655701, train/raw-loss = 0.4771333336830139, train/logprobs = tensor([[-0.5567, -2.6381],
        [-0.6120, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838325023651123
Epoch 0, Step 343: train/loss = 0.6022127866744995, train/raw-loss = 0.5593593120574951, train/logprobs = tensor([[-0.6542, -2.0258],
        [-0.6753, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08570696413516998
Epoch 0, Step 344: train/loss = 0.4442852735519409, train/raw-loss = 0.39538145065307617, train/logprobs = tensor([[-0.9241, -5.3788],
        [-0.8097, -1.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780767560005188
Epoch 0, Step 345: train/loss = 0.49996647238731384, train/raw-loss = 0.4544225037097931, train/logprobs = tensor([[-1.1206, -3.7130],
        [-1.1413, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09108792990446091
Epoch 0, Step 346: train/loss = 0.5264341831207275, train/raw-loss = 0.4770044684410095, train/logprobs = tensor([[-0.7738, -3.6792],
        [-0.7323, -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09885939210653305
Epoch 0, Step 347: train/loss = 0.5260098576545715, train/raw-loss = 0.4802776277065277, train/logprobs = tensor([[-0.6042, -4.2164],
        [-0.6357, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09146440029144287
Epoch 0, Step 348: train/loss = 0.5457789897918701, train/raw-loss = 0.5053784251213074, train/logprobs = tensor([[-0.7271, -2.9946],
        [-0.7887, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0808010846376419
Epoch 0, Step 349: train/loss = 0.4335830807685852, train/raw-loss = 0.38162481784820557, train/logprobs = tensor([[-0.6881, -2.7348],
        [-0.7413, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391651093959808
Epoch 0, Step 350: train/loss = 0.6197946071624756, train/raw-loss = 0.5682455897331238, train/logprobs = tensor([[-1.2084, -2.4326],
        [-0.9932, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309812426567078
Epoch 0, Step 351: train/loss = 0.5441430807113647, train/raw-loss = 0.49635523557662964, train/logprobs = tensor([[-0.7268, -2.4275],
        [-0.7265, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09557566046714783
Epoch 0, Step 352: train/loss = 0.47603458166122437, train/raw-loss = 0.4310411214828491, train/logprobs = tensor([[-0.5118, -3.5065],
        [-0.5984, -0.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08998695760965347
Epoch 0, Step 353: train/loss = 0.4168551564216614, train/raw-loss = 0.3691442012786865, train/logprobs = tensor([[-0.7105, -4.3127],
        [-0.8495, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954219326376915
Epoch 0, Step 354: train/loss = 0.6428890228271484, train/raw-loss = 0.6030555367469788, train/logprobs = tensor([[-0.4831, -0.9562],
        [-0.5109, -0.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07966701686382294
Epoch 0, Step 355: train/loss = 0.5257806777954102, train/raw-loss = 0.48191967606544495, train/logprobs = tensor([[-0.7276, -2.4891],
        [-0.7926, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772195875644684
Epoch 0, Step 356: train/loss = 0.6317158937454224, train/raw-loss = 0.5875234603881836, train/logprobs = tensor([[-0.5041, -1.0724],
        [-0.4918, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08838489651679993
Epoch 0, Step 357: train/loss = 0.6703314781188965, train/raw-loss = 0.6224720478057861, train/logprobs = tensor([[-1.7998, -2.4182],
        [-1.4082, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09571892023086548
Epoch 0, Step 358: train/loss = 0.5418346524238586, train/raw-loss = 0.5031014680862427, train/logprobs = tensor([[-0.5219, -3.8615],
        [-0.4979, -1.2704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774664357304573
Epoch 0, Step 359: train/loss = 0.5930720567703247, train/raw-loss = 0.5461965203285217, train/logprobs = tensor([[-0.8998, -1.8452],
        [-0.8490, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09375109523534775
Epoch 0, Step 360: train/loss = 0.5502147674560547, train/raw-loss = 0.5033124089241028, train/logprobs = tensor([[-0.8860, -2.5037],
        [-0.8278, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09380465000867844
Epoch 0, Step 361: train/loss = 0.5821542739868164, train/raw-loss = 0.5333777666091919, train/logprobs = tensor([[-0.6088, -1.1890],
        [-0.6905, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09755301475524902
Epoch 0, Step 362: train/loss = 0.6099370121955872, train/raw-loss = 0.569390058517456, train/logprobs = tensor([[-0.6650, -1.6795],
        [-0.6678, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08109385520219803
Epoch 0, Step 363: train/loss = 0.7489016056060791, train/raw-loss = 0.7112535238265991, train/logprobs = tensor([[-1.2366, -1.1310],
        [-0.8790, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07529618591070175
Epoch 0, Step 364: train/loss = 0.41948848962783813, train/raw-loss = 0.3768860697746277, train/logprobs = tensor([[-0.4062, -5.1033],
        [-0.5325, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852048248052597
Epoch 0, Step 365: train/loss = 0.4598665237426758, train/raw-loss = 0.41330477595329285, train/logprobs = tensor([[-0.5433, -2.4947],
        [-0.5972, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09312346577644348
Epoch 0, Step 366: train/loss = 0.5484704971313477, train/raw-loss = 0.504844605922699, train/logprobs = tensor([[-0.5839, -2.4702],
        [-0.5961, -0.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08725177496671677
Epoch 0, Step 367: train/loss = 0.45316192507743835, train/raw-loss = 0.4093054533004761, train/logprobs = tensor([[-0.5794, -3.1906],
        [-0.6875, -0.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771301805973053
Epoch 0, Step 368: train/loss = 0.5028402805328369, train/raw-loss = 0.4587370753288269, train/logprobs = tensor([[-0.4246, -2.3188],
        [-0.4337, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882064551115036
Epoch 0, Step 369: train/loss = 0.5138723254203796, train/raw-loss = 0.47296860814094543, train/logprobs = tensor([[-0.4534, -1.8766],
        [-0.5289, -0.6484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08180742710828781
Epoch 0, Step 370: train/loss = 0.6505556106567383, train/raw-loss = 0.6134589910507202, train/logprobs = tensor([[-0.3990, -0.8395],
        [-0.4163, -0.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07419313490390778
Epoch 0, Step 371: train/loss = 0.514262318611145, train/raw-loss = 0.47438833117485046, train/logprobs = tensor([[-0.4290, -2.9709],
        [-0.4613, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07974792271852493
Epoch 0, Step 372: train/loss = 0.4630841314792633, train/raw-loss = 0.41973423957824707, train/logprobs = tensor([[-0.5639, -3.0362],
        [-0.5417, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08669984340667725
Epoch 0, Step 373: train/loss = 0.545886754989624, train/raw-loss = 0.5013887882232666, train/logprobs = tensor([[-0.7640, -4.1995],
        [-0.6905, -1.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899588882923126
Epoch 0, Step 374: train/loss = 0.5467888116836548, train/raw-loss = 0.5041437149047852, train/logprobs = tensor([[-0.3170, -2.1715],
        [-0.3528, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529027551412582
Epoch 0, Step 375: train/loss = 0.5232180953025818, train/raw-loss = 0.47495609521865845, train/logprobs = tensor([[-0.7321, -1.5886],
        [-0.9306, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0965239629149437
Epoch 0, Step 376: train/loss = 0.44274598360061646, train/raw-loss = 0.39470797777175903, train/logprobs = tensor([[-0.6225, -4.3191],
        [-0.8156, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09607598930597305
Epoch 0, Step 377: train/loss = 0.5879814624786377, train/raw-loss = 0.5436182022094727, train/logprobs = tensor([[-0.6503, -2.5208],
        [-0.5781, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0887264534831047
Epoch 0, Step 378: train/loss = 0.5540543794631958, train/raw-loss = 0.5127465724945068, train/logprobs = tensor([[-0.7094, -3.4073],
        [-0.6884, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261565119028091
Epoch 0, Step 379: train/loss = 0.6166815161705017, train/raw-loss = 0.5766898989677429, train/logprobs = tensor([[-0.9527, -2.0196],
        [-0.8267, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0799831748008728
Epoch 0, Step 380: train/loss = 0.5374978184700012, train/raw-loss = 0.4939371347427368, train/logprobs = tensor([[-0.6051, -1.7780],
        [-0.6437, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08712142705917358
Epoch 0, Step 381: train/loss = 0.46138501167297363, train/raw-loss = 0.41298675537109375, train/logprobs = tensor([[-0.6758, -3.8025],
        [-0.8767, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679650515317917
Epoch 0, Step 382: train/loss = 0.41663646697998047, train/raw-loss = 0.3708500564098358, train/logprobs = tensor([[-0.5549, -3.4211],
        [-0.5967, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157292544841766
Epoch 0, Step 383: train/loss = 0.45939570665359497, train/raw-loss = 0.4095727205276489, train/logprobs = tensor([[-0.4670, -2.4059],
        [-0.6085, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09964605420827866
Epoch 0, Step 384: train/loss = 0.5157966613769531, train/raw-loss = 0.4635620713233948, train/logprobs = tensor([[-0.8164, -5.6022],
        [-0.9009, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044691950082779
Epoch 0, Step 385: train/loss = 0.6054333448410034, train/raw-loss = 0.5461717844009399, train/logprobs = tensor([[-1.1741, -2.0131],
        [-0.9954, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852309107780457
Epoch 0, Step 386: train/loss = 0.7302956581115723, train/raw-loss = 0.690273106098175, train/logprobs = tensor([[-0.8873, -0.8483],
        [-0.6741, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08004511147737503
Epoch 0, Step 387: train/loss = 0.5011193156242371, train/raw-loss = 0.45203277468681335, train/logprobs = tensor([[-0.6463, -4.6161],
        [-0.8411, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817319363355637
Epoch 0, Step 388: train/loss = 0.5611264705657959, train/raw-loss = 0.5037537813186646, train/logprobs = tensor([[-0.7170, -2.1836],
        [-0.7727, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11474534869194031
Epoch 0, Step 389: train/loss = 0.4753066301345825, train/raw-loss = 0.4172440469264984, train/logprobs = tensor([[-0.5959, -2.3889],
        [-0.6683, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11612509191036224
Epoch 0, Step 390: train/loss = 0.4714601933956146, train/raw-loss = 0.4156070947647095, train/logprobs = tensor([[-1.0123, -2.5622],
        [-1.3129, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1117062121629715
Epoch 0, Step 391: train/loss = 0.5468771457672119, train/raw-loss = 0.49918049573898315, train/logprobs = tensor([[-0.4907, -1.8349],
        [-0.5197, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539321810007095
Epoch 0, Step 392: train/loss = 0.46150532364845276, train/raw-loss = 0.41571375727653503, train/logprobs = tensor([[-0.4786, -3.2447],
        [-0.6363, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09158311039209366
Epoch 0, Step 393: train/loss = 0.5746825337409973, train/raw-loss = 0.5190917253494263, train/logprobs = tensor([[-0.7411, -1.8596],
        [-0.6302, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11118161678314209
Epoch 0, Step 394: train/loss = 0.4353579878807068, train/raw-loss = 0.3853805363178253, train/logprobs = tensor([[-0.8603, -6.0665],
        [-0.8392, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995490312576294
Epoch 0, Step 395: train/loss = 0.5070009827613831, train/raw-loss = 0.4656221866607666, train/logprobs = tensor([[-0.6830, -5.5216],
        [-0.4636, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08275751024484634
Epoch 0, Step 396: train/loss = 0.5500911474227905, train/raw-loss = 0.5011996030807495, train/logprobs = tensor([[-0.7398, -1.9192],
        [-0.7500, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09778305888175964
Epoch 0, Step 397: train/loss = 0.5729977488517761, train/raw-loss = 0.5251118540763855, train/logprobs = tensor([[-0.4818, -2.1513],
        [-0.4602, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577173739671707
Epoch 0, Step 398: train/loss = 0.42127013206481934, train/raw-loss = 0.3683270514011383, train/logprobs = tensor([[-0.5818, -3.3653],
        [-0.7087, -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588615387678146
Epoch 0, Step 399: train/loss = 0.5859387516975403, train/raw-loss = 0.5362653732299805, train/logprobs = tensor([[-0.8203, -1.4279],
        [-0.9552, -0.7159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934671223163605
Epoch 0, Step 400: train/loss = 0.5820416212081909, train/raw-loss = 0.5403212308883667, train/logprobs = tensor([[-0.5239, -1.3122],
        [-0.5689, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0834406390786171
Epoch 0, Step 401: train/loss = 0.441895991563797, train/raw-loss = 0.39524245262145996, train/logprobs = tensor([[-0.7816, -3.4218],
        [-0.8316, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09330709278583527
Epoch 0, Step 402: train/loss = 0.4595089256763458, train/raw-loss = 0.40921977162361145, train/logprobs = tensor([[-0.6900, -3.2689],
        [-0.6855, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10057833790779114
Epoch 0, Step 403: train/loss = 0.5485504865646362, train/raw-loss = 0.5116667747497559, train/logprobs = tensor([[-0.3320, -1.7219],
        [-0.3631, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07376745343208313
Epoch 0, Step 404: train/loss = 0.647965669631958, train/raw-loss = 0.6054877638816833, train/logprobs = tensor([[-0.5743, -1.2468],
        [-0.5076, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08495573699474335
Epoch 0, Step 405: train/loss = 0.5753060579299927, train/raw-loss = 0.5333876609802246, train/logprobs = tensor([[-0.4627, -3.1879],
        [-0.5278, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383671939373016
Epoch 0, Step 406: train/loss = 0.5453386306762695, train/raw-loss = 0.4976384937763214, train/logprobs = tensor([[-0.5666, -2.1617],
        [-0.5878, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954003781080246
Epoch 0, Step 407: train/loss = 0.6096456050872803, train/raw-loss = 0.5726037621498108, train/logprobs = tensor([[-0.5134, -1.0720],
        [-0.5139, -0.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07408380508422852
Epoch 0, Step 408: train/loss = 0.6033334732055664, train/raw-loss = 0.5528188943862915, train/logprobs = tensor([[-0.6066, -1.1776],
        [-0.8275, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102929174900055
Epoch 0, Step 409: train/loss = 0.33799493312835693, train/raw-loss = 0.28417113423347473, train/logprobs = tensor([[-0.8614, -4.8234],
        [-1.1714, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764756053686142
Epoch 0, Step 410: train/loss = 0.5921513438224792, train/raw-loss = 0.5456377863883972, train/logprobs = tensor([[-0.5818, -2.0784],
        [-0.5429, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09302709996700287
Epoch 0, Step 411: train/loss = 0.5565301775932312, train/raw-loss = 0.49988657236099243, train/logprobs = tensor([[-0.4969, -1.5468],
        [-0.5689, -0.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328719556331635
Epoch 0, Step 412: train/loss = 0.6011875867843628, train/raw-loss = 0.5546039342880249, train/logprobs = tensor([[-0.4676, -1.4213],
        [-0.5728, -0.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09316735714673996
Epoch 0, Step 413: train/loss = 0.5685167908668518, train/raw-loss = 0.5272809267044067, train/logprobs = tensor([[-0.7626, -3.9867],
        [-0.6381, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247168362140656
Epoch 0, Step 414: train/loss = 0.5121913552284241, train/raw-loss = 0.4696904122829437, train/logprobs = tensor([[-0.4276, -1.7272],
        [-0.5499, -0.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500190079212189
Epoch 0, Step 415: train/loss = 0.4881972670555115, train/raw-loss = 0.44004738330841064, train/logprobs = tensor([[-0.7613, -3.9839],
        [-0.8013, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09629984200000763
Epoch 0, Step 416: train/loss = 0.6263325214385986, train/raw-loss = 0.5785076022148132, train/logprobs = tensor([[-0.7315, -1.4038],
        [-0.6825, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564992785453796
Epoch 0, Step 417: train/loss = 0.4538487195968628, train/raw-loss = 0.39546048641204834, train/logprobs = tensor([[-0.6126, -3.9342],
        [-0.9001, -0.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677640676498413
Epoch 0, Step 418: train/loss = 0.43391650915145874, train/raw-loss = 0.38379958271980286, train/logprobs = tensor([[-0.6146, -2.5668],
        [-0.8984, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10023380815982819
Epoch 0, Step 419: train/loss = 0.4751545190811157, train/raw-loss = 0.42307353019714355, train/logprobs = tensor([[-0.8807, -3.2711],
        [-0.8919, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10416197776794434
Epoch 0, Step 420: train/loss = 0.5078010559082031, train/raw-loss = 0.4542735815048218, train/logprobs = tensor([[-0.7219, -3.0064],
        [-0.8327, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10705491155385971
Epoch 0, Step 421: train/loss = 0.4348289966583252, train/raw-loss = 0.37906575202941895, train/logprobs = tensor([[-0.6789, -2.3595],
        [-0.9889, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11152651906013489
Epoch 0, Step 422: train/loss = 0.4302098751068115, train/raw-loss = 0.37120795249938965, train/logprobs = tensor([[-0.9862, -4.1328],
        [-1.0192, -1.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800381541252136
Epoch 0, Step 423: train/loss = 0.5387288331985474, train/raw-loss = 0.4892420172691345, train/logprobs = tensor([[-0.5881, -3.1003],
        [-0.5689, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09897364675998688
Epoch 0, Step 424: train/loss = 0.4093133509159088, train/raw-loss = 0.3587999939918518, train/logprobs = tensor([[-0.6001, -4.2627],
        [-0.7494, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102676600217819
Epoch 0, Step 425: train/loss = 0.8815168142318726, train/raw-loss = 0.8377902507781982, train/logprobs = tensor([[-1.9900, -3.0592],
        [-0.6542, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08745329082012177
Epoch 0, Step 426: train/loss = 0.48171374201774597, train/raw-loss = 0.4201832413673401, train/logprobs = tensor([[-0.8628, -2.5169],
        [-0.9958, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306109815835953
Epoch 0, Step 427: train/loss = 0.43356823921203613, train/raw-loss = 0.384021520614624, train/logprobs = tensor([[-0.5868, -2.8048],
        [-0.6639, -0.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909345209598541
Epoch 0, Step 428: train/loss = 0.7401179075241089, train/raw-loss = 0.6877748966217041, train/logprobs = tensor([[-0.9793, -1.1511],
        [-0.6297, -0.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468608140945435
Epoch 0, Step 429: train/loss = 0.41644373536109924, train/raw-loss = 0.36960646510124207, train/logprobs = tensor([[-0.5930, -3.0416],
        [-0.7268, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09367453306913376
Epoch 0, Step 430: train/loss = 0.5366755127906799, train/raw-loss = 0.4914320707321167, train/logprobs = tensor([[-0.6357, -3.1398],
        [-0.6362, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048691391944885
Epoch 0, Step 431: train/loss = 0.5175375938415527, train/raw-loss = 0.46776384115219116, train/logprobs = tensor([[-0.6937, -1.5462],
        [-0.7975, -0.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954751282930374
Epoch 0, Step 432: train/loss = 0.6056917309761047, train/raw-loss = 0.5509551167488098, train/logprobs = tensor([[-0.7300, -1.1993],
        [-0.8598, -0.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094733476638794
Epoch 0, Step 433: train/loss = 0.5770606398582458, train/raw-loss = 0.5311151742935181, train/logprobs = tensor([[-0.6289, -1.5554],
        [-0.6920, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918908640742302
Epoch 0, Step 434: train/loss = 0.3916500210762024, train/raw-loss = 0.32848674058914185, train/logprobs = tensor([[-0.7721, -4.3291],
        [-0.8121, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1263265460729599
Epoch 0, Step 435: train/loss = 0.5757242441177368, train/raw-loss = 0.5124008059501648, train/logprobs = tensor([[-1.3755, -2.7959],
        [-0.9102, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664690613746643
Epoch 0, Step 436: train/loss = 0.4605693221092224, train/raw-loss = 0.4037739038467407, train/logprobs = tensor([[-0.8095, -4.1016],
        [-1.0293, -1.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359082907438278
Epoch 0, Step 437: train/loss = 0.4742501974105835, train/raw-loss = 0.4203924834728241, train/logprobs = tensor([[-0.6747, -3.4124],
        [-0.7643, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771539807319641
Epoch 0, Step 438: train/loss = 0.5123944878578186, train/raw-loss = 0.46152710914611816, train/logprobs = tensor([[-0.5113, -2.4547],
        [-0.6049, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10173475742340088
Epoch 0, Step 439: train/loss = 0.5925569534301758, train/raw-loss = 0.5481501817703247, train/logprobs = tensor([[-0.4858, -1.1850],
        [-0.5695, -0.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881355822086334
Epoch 0, Step 440: train/loss = 0.6023077964782715, train/raw-loss = 0.5502928495407104, train/logprobs = tensor([[-0.8052, -1.7217],
        [-0.6402, -0.5659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10402992367744446
Epoch 0, Step 441: train/loss = 0.6869369745254517, train/raw-loss = 0.6391153931617737, train/logprobs = tensor([[-1.0301, -1.5741],
        [-0.6468, -0.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564316272735596
Epoch 0, Step 442: train/loss = 0.6365477442741394, train/raw-loss = 0.5845437049865723, train/logprobs = tensor([[-0.5116, -1.0468],
        [-0.5433, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10400819033384323
Epoch 0, Step 443: train/loss = 0.7595463991165161, train/raw-loss = 0.7098841071128845, train/logprobs = tensor([[-1.6084, -1.3781],
        [-0.9960, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932462126016617
Epoch 0, Step 444: train/loss = 0.5051301717758179, train/raw-loss = 0.44482558965682983, train/logprobs = tensor([[-0.9077, -2.5161],
        [-0.7039, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060914933681488
Epoch 0, Step 445: train/loss = 0.4580199122428894, train/raw-loss = 0.39890456199645996, train/logprobs = tensor([[-0.5961, -2.9263],
        [-0.7500, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11823077499866486
Epoch 0, Step 446: train/loss = 0.5472389459609985, train/raw-loss = 0.4980558156967163, train/logprobs = tensor([[-0.8885, -2.1815],
        [-0.7760, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09836629033088684
Epoch 0, Step 447: train/loss = 0.4157528281211853, train/raw-loss = 0.35694295167922974, train/logprobs = tensor([[-0.9644, -5.6268],
        [-0.8068, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761980503797531
Epoch 0, Step 448: train/loss = 0.4136549234390259, train/raw-loss = 0.3593357503414154, train/logprobs = tensor([[-0.6069, -5.2138],
        [-0.7554, -1.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10863829404115677
Epoch 0, Step 449: train/loss = 0.6281401515007019, train/raw-loss = 0.5794149041175842, train/logprobs = tensor([[-0.7788, -1.8180],
        [-0.7508, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745050221681595
Epoch 0, Step 450: train/loss = 0.6190938353538513, train/raw-loss = 0.5627087354660034, train/logprobs = tensor([[-0.9886, -1.8599],
        [-1.0522, -0.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11277014762163162
Epoch 0, Step 451: train/loss = 0.5637950897216797, train/raw-loss = 0.5116860270500183, train/logprobs = tensor([[-0.7721, -1.5818],
        [-0.8149, -0.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421810299158096
Epoch 0, Step 452: train/loss = 0.3779583275318146, train/raw-loss = 0.32338178157806396, train/logprobs = tensor([[-0.7080, -6.3062],
        [-0.9990, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10915318131446838
Epoch 0, Step 453: train/loss = 0.3844817876815796, train/raw-loss = 0.33739009499549866, train/logprobs = tensor([[-0.6141, -4.4349],
        [-0.8420, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09418337047100067
Epoch 0, Step 454: train/loss = 0.5666701793670654, train/raw-loss = 0.5252513885498047, train/logprobs = tensor([[-0.3863, -2.5779],
        [-0.4528, -0.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283764123916626
Epoch 0, Step 455: train/loss = 0.40673181414604187, train/raw-loss = 0.35759711265563965, train/logprobs = tensor([[-0.6496, -3.5680],
        [-0.8440, -0.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09826936572790146
Epoch 0, Step 456: train/loss = 0.6539332866668701, train/raw-loss = 0.5943425893783569, train/logprobs = tensor([[-0.8112, -1.3216],
        [-0.8457, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191813200712204
Epoch 0, Step 457: train/loss = 0.4476422667503357, train/raw-loss = 0.38914012908935547, train/logprobs = tensor([[-0.5409, -2.6612],
        [-0.8332, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11700433492660522
Epoch 0, Step 458: train/loss = 0.41254207491874695, train/raw-loss = 0.35800766944885254, train/logprobs = tensor([[-0.5526, -4.5705],
        [-0.7730, -0.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906875133514404
Epoch 0, Step 459: train/loss = 0.4521925449371338, train/raw-loss = 0.39516681432724, train/logprobs = tensor([[-0.6996, -2.7901],
        [-0.8002, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11405139416456223
Epoch 0, Step 460: train/loss = 0.49627038836479187, train/raw-loss = 0.44132137298583984, train/logprobs = tensor([[-0.7279, -3.1435],
        [-0.8031, -0.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989812016487122
Epoch 0, Step 461: train/loss = 0.4889552593231201, train/raw-loss = 0.4338013529777527, train/logprobs = tensor([[-0.9801, -3.0433],
        [-0.9209, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11030785739421844
Epoch 0, Step 462: train/loss = 0.5369173288345337, train/raw-loss = 0.4796433448791504, train/logprobs = tensor([[-0.8174, -1.8030],
        [-0.9245, -0.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11454794555902481
Epoch 0, Step 463: train/loss = 0.5122326016426086, train/raw-loss = 0.45919427275657654, train/logprobs = tensor([[-0.8299, -1.9929],
        [-1.0459, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607659816741943
Epoch 0, Step 464: train/loss = 0.39363664388656616, train/raw-loss = 0.33558332920074463, train/logprobs = tensor([[-0.5209, -4.2224],
        [-0.8483, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11610669642686844
Epoch 0, Step 465: train/loss = 0.5484817624092102, train/raw-loss = 0.4945240616798401, train/logprobs = tensor([[-0.5903, -1.5294],
        [-0.8808, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10791533440351486
Epoch 0, Step 466: train/loss = 0.606337308883667, train/raw-loss = 0.5535300970077515, train/logprobs = tensor([[-0.9659, -2.4222],
        [-0.9593, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10561443865299225
Epoch 0, Step 467: train/loss = 0.5435971021652222, train/raw-loss = 0.49372828006744385, train/logprobs = tensor([[-0.8602, -2.3641],
        [-0.7310, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09973762184381485
Epoch 0, Step 468: train/loss = 0.32770609855651855, train/raw-loss = 0.25943538546562195, train/logprobs = tensor([[-0.6711, -3.6416],
        [-1.2005, -0.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365414261817932
Epoch 0, Step 469: train/loss = 0.5842825174331665, train/raw-loss = 0.5390906929969788, train/logprobs = tensor([[-0.5362, -1.5348],
        [-0.8238, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038375318050385
Epoch 0, Step 470: train/loss = 0.6094321608543396, train/raw-loss = 0.5497743487358093, train/logprobs = tensor([[-0.8643, -2.2599],
        [-0.6070, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11931560188531876
Epoch 0, Step 471: train/loss = 0.3603827953338623, train/raw-loss = 0.3065406084060669, train/logprobs = tensor([[-0.4505, -4.2608],
        [-0.6517, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10768435895442963
Epoch 0, Step 472: train/loss = 0.5215674638748169, train/raw-loss = 0.4696100652217865, train/logprobs = tensor([[-0.4902, -3.3311],
        [-0.6330, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391488671302795
Epoch 0, Step 473: train/loss = 0.4668745994567871, train/raw-loss = 0.41072309017181396, train/logprobs = tensor([[-1.0340, -4.7695],
        [-0.8391, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11230310797691345
Epoch 0, Step 474: train/loss = 0.486875057220459, train/raw-loss = 0.4388096034526825, train/logprobs = tensor([[-0.5754, -2.7122],
        [-0.7438, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613087773323059
Epoch 0, Step 475: train/loss = 0.3861556053161621, train/raw-loss = 0.325361967086792, train/logprobs = tensor([[-0.6913, -4.4234],
        [-0.7864, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158725410699844
Epoch 0, Step 476: train/loss = 0.5389968752861023, train/raw-loss = 0.482355535030365, train/logprobs = tensor([[-0.4587, -1.7587],
        [-0.4666, -0.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328260600566864
Epoch 0, Step 477: train/loss = 0.45221126079559326, train/raw-loss = 0.3876926600933075, train/logprobs = tensor([[-0.5849, -3.7931],
        [-0.6459, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290372908115387
Epoch 0, Step 478: train/loss = 0.37630945444107056, train/raw-loss = 0.3201305866241455, train/logprobs = tensor([[-0.7706, -5.7791],
        [-0.8015, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235778778791428
Epoch 0, Step 479: train/loss = 0.5238257050514221, train/raw-loss = 0.47945865988731384, train/logprobs = tensor([[-0.3606, -3.7820],
        [-0.5182, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08873412758111954
Epoch 0, Step 480: train/loss = 0.6644719839096069, train/raw-loss = 0.6199797987937927, train/logprobs = tensor([[-0.4578, -1.0424],
        [-0.5320, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08898423612117767
Epoch 0, Step 481: train/loss = 0.33472269773483276, train/raw-loss = 0.2656341791152954, train/logprobs = tensor([[-0.8762, -5.3543],
        [-1.1200, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13817709684371948
Epoch 0, Step 482: train/loss = 0.549685537815094, train/raw-loss = 0.49916398525238037, train/logprobs = tensor([[-0.7736, -1.4735],
        [-0.9680, -0.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104309022426605
Epoch 0, Step 483: train/loss = 0.49699556827545166, train/raw-loss = 0.4457601308822632, train/logprobs = tensor([[-0.5419, -3.4031],
        [-0.7533, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247081518173218
Epoch 0, Step 484: train/loss = 0.5072156190872192, train/raw-loss = 0.44386857748031616, train/logprobs = tensor([[-0.5609, -2.4598],
        [-0.7188, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12669412791728973
Epoch 0, Step 485: train/loss = 0.3358796238899231, train/raw-loss = 0.2702786922454834, train/logprobs = tensor([[-0.9823, -6.2783],
        [-1.3847, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13120190799236298
Epoch 0, Step 486: train/loss = 0.6344178915023804, train/raw-loss = 0.5847676396369934, train/logprobs = tensor([[-0.5160, -1.0856],
        [-0.6617, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930042922496796
Epoch 0, Step 487: train/loss = 0.5030266046524048, train/raw-loss = 0.4500575065612793, train/logprobs = tensor([[-0.8824, -3.0583],
        [-0.9641, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593830049037933
Epoch 0, Step 488: train/loss = 0.49246975779533386, train/raw-loss = 0.43714842200279236, train/logprobs = tensor([[-0.6003, -4.5712],
        [-0.6871, -1.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106426864862442
Epoch 0, Step 489: train/loss = 0.4316609501838684, train/raw-loss = 0.36765921115875244, train/logprobs = tensor([[-0.5463, -5.8997],
        [-1.0119, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12800350785255432
Epoch 0, Step 490: train/loss = 0.5570404529571533, train/raw-loss = 0.49054378271102905, train/logprobs = tensor([[-0.5361, -1.5842],
        [-0.7228, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13299328088760376
Epoch 0, Step 491: train/loss = 0.4568900465965271, train/raw-loss = 0.39224040508270264, train/logprobs = tensor([[-0.8823, -4.4213],
        [-1.2919, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292993426322937
Epoch 0, Step 492: train/loss = 0.4465050995349884, train/raw-loss = 0.3852788507938385, train/logprobs = tensor([[-0.8305, -4.3796],
        [-1.1672, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12245252728462219
Epoch 0, Step 493: train/loss = 0.6193459033966064, train/raw-loss = 0.5677841901779175, train/logprobs = tensor([[-0.4183, -1.4645],
        [-0.4383, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10312344878911972
Epoch 0, Step 494: train/loss = 0.5039402842521667, train/raw-loss = 0.4390164017677307, train/logprobs = tensor([[-0.8089, -1.8953],
        [-1.2047, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12984783947467804
Epoch 0, Step 495: train/loss = 0.4770529270172119, train/raw-loss = 0.4211932420730591, train/logprobs = tensor([[-0.4802, -4.0167],
        [-0.7269, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171942949295044
Epoch 0, Step 496: train/loss = 0.4953124523162842, train/raw-loss = 0.43521761894226074, train/logprobs = tensor([[-0.6023, -3.1067],
        [-0.6550, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12018973380327225
Epoch 0, Step 497: train/loss = 0.5348603129386902, train/raw-loss = 0.48818477988243103, train/logprobs = tensor([[-0.4779, -1.4132],
        [-0.6440, -0.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335105121135712
Epoch 0, Step 498: train/loss = 0.38657695055007935, train/raw-loss = 0.31819891929626465, train/logprobs = tensor([[-0.6362, -2.8092],
        [-0.9121, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13675612211227417
Epoch 0, Step 499: train/loss = 0.46369239687919617, train/raw-loss = 0.4062117636203766, train/logprobs = tensor([[-0.6238, -3.7381],
        [-0.8720, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11496123671531677
Epoch 0, Step 500: train/loss = 0.5619960427284241, train/raw-loss = 0.508880615234375, train/logprobs = tensor([[-0.6452, -2.5560],
        [-0.8382, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10623091459274292
Epoch 0, Step 501: train/loss = 0.4789556860923767, train/raw-loss = 0.4191094934940338, train/logprobs = tensor([[-0.7519, -4.4898],
        [-0.7111, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11969243735074997
Epoch 0, Step 502: train/loss = 0.37558093667030334, train/raw-loss = 0.3140372037887573, train/logprobs = tensor([[-0.5461, -2.5259],
        [-1.0677, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12308742105960846
Epoch 0, Step 503: train/loss = 0.6802493929862976, train/raw-loss = 0.6351269483566284, train/logprobs = tensor([[-0.6253, -1.0711],
        [-0.5255, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902448296546936
Epoch 0, Step 504: train/loss = 0.45491641759872437, train/raw-loss = 0.40171951055526733, train/logprobs = tensor([[-0.4783, -3.4464],
        [-0.6015, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10639379918575287
Epoch 0, Step 505: train/loss = 0.41608864068984985, train/raw-loss = 0.35594600439071655, train/logprobs = tensor([[-0.5932, -6.1732],
        [-0.9765, -1.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12028522789478302
Epoch 0, Step 506: train/loss = 0.5835317373275757, train/raw-loss = 0.5318467617034912, train/logprobs = tensor([[-0.6025, -1.5943],
        [-0.6631, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336986184120178
Epoch 0, Step 507: train/loss = 0.5395828485488892, train/raw-loss = 0.47734493017196655, train/logprobs = tensor([[-0.9016, -5.6516],
        [-0.8827, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12447577714920044
Epoch 0, Step 508: train/loss = 0.5229870676994324, train/raw-loss = 0.4678240120410919, train/logprobs = tensor([[-0.6270, -2.0585],
        [-0.7967, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11032609641551971
Epoch 0, Step 509: train/loss = 0.5842413902282715, train/raw-loss = 0.5263558626174927, train/logprobs = tensor([[-0.6677, -1.7450],
        [-0.6342, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577105522155762
Epoch 0, Step 510: train/loss = 0.4980774223804474, train/raw-loss = 0.43867912888526917, train/logprobs = tensor([[-0.7421, -3.4084],
        [-0.9565, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879660189151764
Epoch 0, Step 511: train/loss = 0.5294386148452759, train/raw-loss = 0.4737713932991028, train/logprobs = tensor([[-0.7687, -3.1293],
        [-0.7860, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.111334428191185
Epoch 0, Step 512: train/loss = 0.48661381006240845, train/raw-loss = 0.43501991033554077, train/logprobs = tensor([[-0.7035, -2.1405],
        [-1.1259, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10318779200315475
Epoch 0, Step 513: train/loss = 0.5167331695556641, train/raw-loss = 0.4609888792037964, train/logprobs = tensor([[-0.4121, -3.1046],
        [-0.5657, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148851364850998
Epoch 0, Step 514: train/loss = 0.3949582278728485, train/raw-loss = 0.327493816614151, train/logprobs = tensor([[-0.6180, -4.4621],
        [-1.0047, -1.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13492880761623383
Epoch 0, Step 515: train/loss = 0.7236988544464111, train/raw-loss = 0.6726341843605042, train/logprobs = tensor([[-0.5022, -0.5704],
        [-0.5735, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10212923586368561
Epoch 0, Step 516: train/loss = 0.43896484375, train/raw-loss = 0.37669050693511963, train/logprobs = tensor([[-0.7200, -2.7645],
        [-1.1410, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454868853092194
Epoch 0, Step 517: train/loss = 0.4679880142211914, train/raw-loss = 0.41029617190361023, train/logprobs = tensor([[-0.5770, -2.3853],
        [-0.7768, -0.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538368463516235
Epoch 0, Step 518: train/loss = 0.3955345153808594, train/raw-loss = 0.3349156677722931, train/logprobs = tensor([[-0.7536, -5.4033],
        [-1.4966, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123771011829376
Epoch 0, Step 519: train/loss = 0.38262271881103516, train/raw-loss = 0.3164352476596832, train/logprobs = tensor([[-0.8717, -3.8131],
        [-0.9934, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13237500190734863
Epoch 0, Step 520: train/loss = 0.7377150058746338, train/raw-loss = 0.6875808238983154, train/logprobs = tensor([[-0.9410, -0.9884],
        [-0.7601, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10026831179857254
Epoch 0, Step 521: train/loss = 0.4915510416030884, train/raw-loss = 0.4432221055030823, train/logprobs = tensor([[-0.3503, -2.5061],
        [-0.5158, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665790945291519
Epoch 0, Step 522: train/loss = 0.6017014980316162, train/raw-loss = 0.5458199381828308, train/logprobs = tensor([[-1.2185, -3.2035],
        [-0.8603, -0.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176317930221558
Epoch 0, Step 523: train/loss = 0.5415088534355164, train/raw-loss = 0.4873151183128357, train/logprobs = tensor([[-0.4990, -2.1117],
        [-0.5980, -0.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838750004768372
Epoch 0, Step 524: train/loss = 0.3447754979133606, train/raw-loss = 0.28071922063827515, train/logprobs = tensor([[-0.4429, -6.2106],
        [-0.8011, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281125843524933
Epoch 0, Step 525: train/loss = 0.5562321543693542, train/raw-loss = 0.495495468378067, train/logprobs = tensor([[-0.6268, -1.8773],
        [-0.7989, -0.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147340178489685
Epoch 0, Step 526: train/loss = 0.5010148882865906, train/raw-loss = 0.45276516675949097, train/logprobs = tensor([[-0.3739, -1.8066],
        [-0.6237, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649936854839325
Epoch 0, Step 527: train/loss = 0.30596724152565, train/raw-loss = 0.2483852058649063, train/logprobs = tensor([[-0.5510, -4.2320],
        [-1.0002, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11516405642032623
Epoch 0, Step 528: train/loss = 0.4007560610771179, train/raw-loss = 0.34882909059524536, train/logprobs = tensor([[-0.3488, -5.6525],
        [-0.4573, -1.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385395586490631
Epoch 0, Step 529: train/loss = 0.4453606903553009, train/raw-loss = 0.3837413191795349, train/logprobs = tensor([[-0.6403, -4.4739],
        [-0.8956, -1.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12323874235153198
Epoch 0, Step 530: train/loss = 0.6055235862731934, train/raw-loss = 0.5417060852050781, train/logprobs = tensor([[-0.5815, -1.7059],
        [-0.9961, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12763497233390808
Epoch 0, Step 531: train/loss = 0.573779821395874, train/raw-loss = 0.5212974548339844, train/logprobs = tensor([[-0.4014, -1.4093],
        [-0.5792, -0.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10496463626623154
Epoch 0, Step 532: train/loss = 0.5254902839660645, train/raw-loss = 0.465556800365448, train/logprobs = tensor([[-0.5941, -2.9492],
        [-0.9584, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986692994832993
Epoch 0, Step 533: train/loss = 0.4704049527645111, train/raw-loss = 0.4043024182319641, train/logprobs = tensor([[-0.8066, -3.6051],
        [-0.8987, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13220512866973877
Epoch 0, Step 534: train/loss = 0.548578143119812, train/raw-loss = 0.4878012239933014, train/logprobs = tensor([[-0.4688, -2.4049],
        [-0.6839, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12155386805534363
Epoch 0, Step 535: train/loss = 0.3926476836204529, train/raw-loss = 0.31891268491744995, train/logprobs = tensor([[-0.8127, -4.0124],
        [-1.2668, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14746993780136108
Epoch 0, Step 536: train/loss = 0.43803155422210693, train/raw-loss = 0.38019323348999023, train/logprobs = tensor([[-0.6407, -2.5149],
        [-0.8481, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156766265630722
Epoch 0, Step 537: train/loss = 0.4202148914337158, train/raw-loss = 0.3625583052635193, train/logprobs = tensor([[-0.6296, -2.4181],
        [-1.0663, -0.8266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11531323939561844
Epoch 0, Step 538: train/loss = 0.41899991035461426, train/raw-loss = 0.3536562919616699, train/logprobs = tensor([[-0.7551, -4.4090],
        [-0.7196, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13068729639053345
Epoch 0, Step 539: train/loss = 0.4827713370323181, train/raw-loss = 0.43316951394081116, train/logprobs = tensor([[-0.4155, -3.3728],
        [-0.6188, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09920356422662735
Epoch 0, Step 540: train/loss = 0.5192973613739014, train/raw-loss = 0.4570976197719574, train/logprobs = tensor([[-0.6484, -2.7914],
        [-1.0597, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12439948320388794
Epoch 0, Step 541: train/loss = 0.36517640948295593, train/raw-loss = 0.30128100514411926, train/logprobs = tensor([[-0.7938, -5.6552],
        [-1.3511, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12779085338115692
Epoch 0, Step 542: train/loss = 0.4302339553833008, train/raw-loss = 0.378318190574646, train/logprobs = tensor([[-0.6436, -2.8385],
        [-0.9119, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10383143275976181
Epoch 0, Step 543: train/loss = 0.44549331068992615, train/raw-loss = 0.3888793885707855, train/logprobs = tensor([[-0.5840, -4.7876],
        [-0.7288, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322788894176483
Epoch 0, Step 544: train/loss = 0.5307246446609497, train/raw-loss = 0.4665057957172394, train/logprobs = tensor([[-0.6161, -2.0022],
        [-0.8014, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12843769788742065
Epoch 0, Step 545: train/loss = 0.4136557877063751, train/raw-loss = 0.35440096259117126, train/logprobs = tensor([[-0.5990, -3.0152],
        [-1.1668, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11850961297750473
Epoch 0, Step 546: train/loss = 0.447388619184494, train/raw-loss = 0.3924388885498047, train/logprobs = tensor([[-0.4493, -2.8332],
        [-0.7182, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989940166473389
Epoch 0, Step 547: train/loss = 0.43203359842300415, train/raw-loss = 0.37257468700408936, train/logprobs = tensor([[-0.6400, -4.3604],
        [-0.8435, -1.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11891774088144302
Epoch 0, Step 548: train/loss = 0.5612760782241821, train/raw-loss = 0.5053055286407471, train/logprobs = tensor([[-0.4673, -1.2664],
        [-0.7304, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119411438703537
Epoch 0, Step 549: train/loss = 0.5106179118156433, train/raw-loss = 0.4501801133155823, train/logprobs = tensor([[-0.8587, -2.0835],
        [-1.2410, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12087558209896088
Epoch 0, Step 550: train/loss = 0.40471574664115906, train/raw-loss = 0.33593878149986267, train/logprobs = tensor([[-0.9743, -4.3335],
        [-1.3964, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13755391538143158
Epoch 0, Step 551: train/loss = 0.5569808483123779, train/raw-loss = 0.5003354549407959, train/logprobs = tensor([[-0.6132, -1.7530],
        [-0.8048, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329082399606705
Epoch 0, Step 552: train/loss = 0.4046757221221924, train/raw-loss = 0.3449155390262604, train/logprobs = tensor([[-0.6535, -2.8855],
        [-1.1627, -0.8287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11952041834592819
Epoch 0, Step 553: train/loss = 0.45752695202827454, train/raw-loss = 0.39990702271461487, train/logprobs = tensor([[-0.4593, -2.7581],
        [-0.7964, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11523985862731934
Epoch 0, Step 554: train/loss = 0.41428515315055847, train/raw-loss = 0.3596438765525818, train/logprobs = tensor([[-0.4935, -4.2594],
        [-0.7123, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10928256809711456
Epoch 0, Step 555: train/loss = 0.4720635712146759, train/raw-loss = 0.4164195954799652, train/logprobs = tensor([[-0.9552, -3.0640],
        [-0.9138, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11128799617290497
Epoch 0, Step 556: train/loss = 0.44123852252960205, train/raw-loss = 0.38080859184265137, train/logprobs = tensor([[-0.4409, -3.8829],
        [-0.7090, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085986137390137
Epoch 0, Step 557: train/loss = 0.4573506712913513, train/raw-loss = 0.39194586873054504, train/logprobs = tensor([[-0.8001, -3.6777],
        [-1.2040, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080960512161255
Epoch 0, Step 558: train/loss = 0.6512486338615417, train/raw-loss = 0.5903737545013428, train/logprobs = tensor([[-0.6540, -1.0975],
        [-0.8453, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12174971401691437
Epoch 0, Step 559: train/loss = 0.47281521558761597, train/raw-loss = 0.41270050406455994, train/logprobs = tensor([[-0.6196, -2.8313],
        [-0.6817, -0.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12022938579320908
Epoch 0, Step 560: train/loss = 0.5639251470565796, train/raw-loss = 0.5175379514694214, train/logprobs = tensor([[-0.3569, -1.8334],
        [-0.4210, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277445077896118
Epoch 0, Step 561: train/loss = 0.5074011087417603, train/raw-loss = 0.44757914543151855, train/logprobs = tensor([[-0.5265, -1.9955],
        [-0.9464, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11964397132396698
Epoch 0, Step 562: train/loss = 0.45778995752334595, train/raw-loss = 0.3973223567008972, train/logprobs = tensor([[-0.6549, -3.5606],
        [-1.0059, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12093524634838104
Epoch 0, Step 563: train/loss = 0.5096004605293274, train/raw-loss = 0.4603796601295471, train/logprobs = tensor([[-0.4423, -3.1207],
        [-0.6139, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09844156354665756
Epoch 0, Step 564: train/loss = 0.5326915979385376, train/raw-loss = 0.4701142907142639, train/logprobs = tensor([[-0.6096, -1.6173],
        [-0.9322, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12515464425086975
Epoch 0, Step 565: train/loss = 0.4065752327442169, train/raw-loss = 0.34081265330314636, train/logprobs = tensor([[-0.8978, -3.1509],
        [-1.4263, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13152511417865753
Epoch 0, Step 566: train/loss = 0.4962497055530548, train/raw-loss = 0.4390227198600769, train/logprobs = tensor([[-0.4772, -6.5095],
        [-0.6713, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11445394158363342
Epoch 0, Step 567: train/loss = 0.39021578431129456, train/raw-loss = 0.32869499921798706, train/logprobs = tensor([[-0.5278, -3.2440],
        [-1.0497, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1230415552854538
Epoch 0, Step 568: train/loss = 0.5645754337310791, train/raw-loss = 0.49863389134407043, train/logprobs = tensor([[-0.5468, -2.8646],
        [-0.9661, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13188311457633972
Epoch 0, Step 569: train/loss = 0.38864070177078247, train/raw-loss = 0.3169782757759094, train/logprobs = tensor([[-0.7888, -2.3183],
        [-1.4759, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1433248519897461
Epoch 0, Step 570: train/loss = 0.6864564418792725, train/raw-loss = 0.6236531138420105, train/logprobs = tensor([[-1.3954, -2.2779],
        [-0.9317, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12560659646987915
Epoch 0, Step 571: train/loss = 0.4402146339416504, train/raw-loss = 0.382146954536438, train/logprobs = tensor([[-0.6111, -3.6153],
        [-0.6548, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11613535135984421
Epoch 0, Step 572: train/loss = 0.4423215091228485, train/raw-loss = 0.3866252899169922, train/logprobs = tensor([[-0.3911, -2.6927],
        [-0.5168, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139251291751862
Epoch 0, Step 573: train/loss = 0.4013734757900238, train/raw-loss = 0.33903059363365173, train/logprobs = tensor([[-0.5424, -3.5230],
        [-0.7238, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468574196100235
Epoch 0, Step 574: train/loss = 0.5821865200996399, train/raw-loss = 0.5283291339874268, train/logprobs = tensor([[-0.4864, -1.2991],
        [-0.6949, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771483182907104
Epoch 0, Step 575: train/loss = 0.3969101309776306, train/raw-loss = 0.33101195096969604, train/logprobs = tensor([[-0.5760, -3.7471],
        [-1.1275, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13179636001586914
Epoch 0, Step 576: train/loss = 0.5432723164558411, train/raw-loss = 0.47101154923439026, train/logprobs = tensor([[-0.8374, -1.6796],
        [-1.1578, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14452148973941803
Epoch 0, Step 577: train/loss = 0.6277743577957153, train/raw-loss = 0.560666024684906, train/logprobs = tensor([[-0.7221, -1.5132],
        [-1.0006, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13421662151813507
Epoch 0, Step 578: train/loss = 0.381067156791687, train/raw-loss = 0.31509798765182495, train/logprobs = tensor([[-0.7236, -3.9628],
        [-1.3030, -0.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13193835318088531
Epoch 0, Step 579: train/loss = 0.4261380434036255, train/raw-loss = 0.371077299118042, train/logprobs = tensor([[-0.7660, -4.4066],
        [-1.0555, -1.3869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012149602174759
Epoch 0, Step 580: train/loss = 0.4442921280860901, train/raw-loss = 0.39413559436798096, train/logprobs = tensor([[-0.9476, -5.3406],
        [-0.9136, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003129780292511
Epoch 0, Step 581: train/loss = 0.39867451786994934, train/raw-loss = 0.339620441198349, train/logprobs = tensor([[-0.6581, -6.4070],
        [-1.0956, -1.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181081235408783
Epoch 0, Step 582: train/loss = 0.5409149527549744, train/raw-loss = 0.4878883361816406, train/logprobs = tensor([[-0.6125, -1.6396],
        [-1.0260, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10605326294898987
Epoch 0, Step 583: train/loss = 0.554196298122406, train/raw-loss = 0.4996754229068756, train/logprobs = tensor([[-0.7793, -2.1552],
        [-0.7845, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904181003570557
Epoch 0, Step 584: train/loss = 0.5229305624961853, train/raw-loss = 0.472721666097641, train/logprobs = tensor([[-0.4857, -1.8919],
        [-0.7820, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10041777044534683
Epoch 0, Step 585: train/loss = 0.5702122449874878, train/raw-loss = 0.5184305906295776, train/logprobs = tensor([[-0.3160, -1.9963],
        [-0.4830, -0.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10356328636407852
Epoch 0, Step 586: train/loss = 0.45924705266952515, train/raw-loss = 0.3932218551635742, train/logprobs = tensor([[-0.7240, -1.8877],
        [-1.2392, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320505142211914
Epoch 0, Step 587: train/loss = 0.5509663820266724, train/raw-loss = 0.4983280897140503, train/logprobs = tensor([[-0.6418, -1.4142],
        [-0.9063, -0.6669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10527659952640533
Epoch 0, Step 588: train/loss = 0.4179811179637909, train/raw-loss = 0.3642147481441498, train/logprobs = tensor([[-0.7409, -4.6610],
        [-1.3000, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10753268748521805
Epoch 0, Step 589: train/loss = 0.43337276577949524, train/raw-loss = 0.3716535270214081, train/logprobs = tensor([[-0.6072, -3.0926],
        [-1.0442, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12343855947256088
Epoch 0, Step 590: train/loss = 0.3594777584075928, train/raw-loss = 0.305778443813324, train/logprobs = tensor([[-0.5091, -4.2148],
        [-0.7580, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739868134260178
Epoch 0, Step 591: train/loss = 0.682927131652832, train/raw-loss = 0.62749844789505, train/logprobs = tensor([[-0.6255, -0.7499],
        [-0.7210, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085724830627441
Epoch 0, Step 592: train/loss = 0.5302996039390564, train/raw-loss = 0.4752616286277771, train/logprobs = tensor([[-0.5551, -1.7343],
        [-0.8161, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11007586121559143
Epoch 0, Step 593: train/loss = 0.4733348786830902, train/raw-loss = 0.41630983352661133, train/logprobs = tensor([[-0.5048, -2.5274],
        [-0.8359, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11405009031295776
Epoch 0, Step 594: train/loss = 0.3687072992324829, train/raw-loss = 0.3009668290615082, train/logprobs = tensor([[-0.6706, -3.0451],
        [-1.0476, -0.6168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354808807373047
Epoch 0, Step 595: train/loss = 0.5500103831291199, train/raw-loss = 0.49353790283203125, train/logprobs = tensor([[-0.5434, -1.7490],
        [-0.7562, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11294494569301605
Epoch 0, Step 596: train/loss = 0.4876314699649811, train/raw-loss = 0.43153122067451477, train/logprobs = tensor([[-0.6854, -3.9460],
        [-0.9640, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220049113035202
Epoch 0, Step 597: train/loss = 0.6587950587272644, train/raw-loss = 0.6044582724571228, train/logprobs = tensor([[-0.6127, -0.8741],
        [-0.9175, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10867352783679962
Epoch 0, Step 598: train/loss = 0.4554094076156616, train/raw-loss = 0.3878158926963806, train/logprobs = tensor([[-0.9554, -3.1469],
        [-0.9647, -0.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351870596408844
Epoch 0, Step 599: train/loss = 0.46128469705581665, train/raw-loss = 0.40042200684547424, train/logprobs = tensor([[-0.4884, -3.8353],
        [-0.7713, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172537297010422
Epoch 0, Step 600: train/loss = 0.497627317905426, train/raw-loss = 0.4402577877044678, train/logprobs = tensor([[-0.4554, -2.6536],
        [-0.6789, -0.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11473901569843292
Epoch 0, Step 601: train/loss = 0.4934535026550293, train/raw-loss = 0.43286052346229553, train/logprobs = tensor([[-0.8536, -2.0806],
        [-1.2503, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12118600308895111
Epoch 0, Step 602: train/loss = 0.5291256904602051, train/raw-loss = 0.4610389471054077, train/logprobs = tensor([[-0.8994, -2.4230],
        [-1.0055, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13617344200611115
Epoch 0, Step 603: train/loss = 0.33674341440200806, train/raw-loss = 0.2760522663593292, train/logprobs = tensor([[-0.5201, -5.2365],
        [-0.9289, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12138233333826065
Epoch 0, Step 604: train/loss = 0.5573862195014954, train/raw-loss = 0.5029492974281311, train/logprobs = tensor([[-0.3788, -1.3980],
        [-0.6136, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088738664984703
Epoch 0, Step 605: train/loss = 0.546795129776001, train/raw-loss = 0.4918239712715149, train/logprobs = tensor([[-0.6604, -1.0013],
        [-1.2383, -0.6056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10994230210781097
Epoch 0, Step 606: train/loss = 0.4928049147129059, train/raw-loss = 0.4382849931716919, train/logprobs = tensor([[-0.6073, -1.9381],
        [-0.7359, -0.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10903981328010559
Epoch 0, Step 607: train/loss = 0.461725652217865, train/raw-loss = 0.3965553641319275, train/logprobs = tensor([[-0.6541, -2.7414],
        [-0.8665, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303405612707138
Epoch 0, Step 608: train/loss = 0.4709005355834961, train/raw-loss = 0.4087215065956116, train/logprobs = tensor([[-0.5391, -2.4671],
        [-1.0429, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12435799092054367
Epoch 0, Step 609: train/loss = 0.3834240436553955, train/raw-loss = 0.3214310109615326, train/logprobs = tensor([[-0.8018, -5.4121],
        [-1.3405, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12398602068424225
Epoch 0, Step 610: train/loss = 0.30782386660575867, train/raw-loss = 0.22971829771995544, train/logprobs = tensor([[-1.0044, -6.3652],
        [-1.5882, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15621116757392883
Epoch 0, Step 611: train/loss = 0.33117297291755676, train/raw-loss = 0.2773197889328003, train/logprobs = tensor([[-0.4809, -3.6884],
        [-0.7886, -0.8959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10770633071660995
Epoch 0, Step 612: train/loss = 0.5831588506698608, train/raw-loss = 0.5189308524131775, train/logprobs = tensor([[-0.6444, -3.2980],
        [-0.8989, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12845611572265625
Epoch 0, Step 613: train/loss = 0.611838698387146, train/raw-loss = 0.5499969720840454, train/logprobs = tensor([[-0.6889, -1.6967],
        [-0.9063, -0.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12368340790271759
Epoch 0, Step 614: train/loss = 0.49012213945388794, train/raw-loss = 0.4258181154727936, train/logprobs = tensor([[-0.6366, -2.0680],
        [-0.8604, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12860798835754395
Epoch 0, Step 615: train/loss = 0.4917745292186737, train/raw-loss = 0.4256749749183655, train/logprobs = tensor([[-0.5906, -2.0687],
        [-1.0445, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13219904899597168
Epoch 0, Step 616: train/loss = 0.6624202728271484, train/raw-loss = 0.6068377494812012, train/logprobs = tensor([[-0.4636, -0.8924],
        [-0.7043, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111651062965393
Epoch 0, Step 617: train/loss = 0.49602010846138, train/raw-loss = 0.44544506072998047, train/logprobs = tensor([[-0.6351, -3.5996],
        [-0.8247, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115014761686325
Epoch 0, Step 618: train/loss = 0.45971715450286865, train/raw-loss = 0.399647980928421, train/logprobs = tensor([[-0.4939, -2.4094],
        [-0.9342, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12013830244541168
Epoch 0, Step 619: train/loss = 0.3901647925376892, train/raw-loss = 0.3335845172405243, train/logprobs = tensor([[-0.4545, -4.1664],
        [-0.8103, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316054314374924
Epoch 0, Step 620: train/loss = 0.40323567390441895, train/raw-loss = 0.33587634563446045, train/logprobs = tensor([[-0.7413, -3.0408],
        [-1.2441, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347186416387558
Epoch 0, Step 621: train/loss = 0.6295264363288879, train/raw-loss = 0.5757195949554443, train/logprobs = tensor([[-0.6455, -0.8082],
        [-0.9055, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076137125492096
Epoch 0, Step 622: train/loss = 0.4850446581840515, train/raw-loss = 0.4257812201976776, train/logprobs = tensor([[-0.4129, -4.3039],
        [-0.8468, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852685362100601
Epoch 0, Step 623: train/loss = 0.43262979388237, train/raw-loss = 0.37616464495658875, train/logprobs = tensor([[-0.5538, -4.4970],
        [-0.9127, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129302978515625
Epoch 0, Step 624: train/loss = 0.4907877743244171, train/raw-loss = 0.4287048280239105, train/logprobs = tensor([[-0.5136, -2.7272],
        [-0.9982, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12416590005159378
Epoch 0, Step 625: train/loss = 0.5155597925186157, train/raw-loss = 0.4513527750968933, train/logprobs = tensor([[-0.5754, -3.7902],
        [-0.7396, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284140795469284
Epoch 0, Step 626: train/loss = 0.5065264701843262, train/raw-loss = 0.4493105411529541, train/logprobs = tensor([[-0.5117, -1.9824],
        [-0.8266, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11443179845809937
Epoch 0, Step 627: train/loss = 0.4865766763687134, train/raw-loss = 0.42350104451179504, train/logprobs = tensor([[-0.4268, -1.9070],
        [-0.9281, -0.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12615126371383667
Epoch 0, Step 628: train/loss = 0.4563972055912018, train/raw-loss = 0.3960806727409363, train/logprobs = tensor([[-0.4342, -2.1971],
        [-0.9055, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12063302099704742
Epoch 0, Step 629: train/loss = 0.5176552534103394, train/raw-loss = 0.46026909351348877, train/logprobs = tensor([[-0.3690, -1.6524],
        [-0.6936, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11477229744195938
Epoch 0, Step 630: train/loss = 0.4423956274986267, train/raw-loss = 0.38691651821136475, train/logprobs = tensor([[-0.4004, -3.2049],
        [-0.6232, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095824092626572
Epoch 0, Step 631: train/loss = 0.3415951728820801, train/raw-loss = 0.27714088559150696, train/logprobs = tensor([[-1.0867, -4.5762],
        [-1.4750, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12890858948230743
Epoch 0, Step 632: train/loss = 0.5062520503997803, train/raw-loss = 0.43021321296691895, train/logprobs = tensor([[-0.7770, -3.4022],
        [-1.0064, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15207764506340027
Epoch 0, Step 633: train/loss = 0.3892144560813904, train/raw-loss = 0.3281022906303406, train/logprobs = tensor([[-0.7089, -4.2125],
        [-1.0189, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12222439795732498
Epoch 0, Step 634: train/loss = 0.42010486125946045, train/raw-loss = 0.35298341512680054, train/logprobs = tensor([[-0.4544, -3.4038],
        [-1.0245, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13424289226531982
Epoch 0, Step 635: train/loss = 0.39608055353164673, train/raw-loss = 0.3342825174331665, train/logprobs = tensor([[-0.4987, -4.0323],
        [-0.9997, -1.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12359601259231567
Epoch 0, Step 636: train/loss = 0.511740505695343, train/raw-loss = 0.4555206894874573, train/logprobs = tensor([[-0.5119, -2.8417],
        [-0.7335, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124396026134491
Epoch 0, Step 637: train/loss = 0.4447268843650818, train/raw-loss = 0.39276450872421265, train/logprobs = tensor([[-0.5937, -3.6373],
        [-0.8121, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039247065782547
Epoch 0, Step 638: train/loss = 0.6485823392868042, train/raw-loss = 0.5910062193870544, train/logprobs = tensor([[-0.4952, -0.9963],
        [-0.6562, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11515223979949951
Epoch 0, Step 639: train/loss = 0.4678291082382202, train/raw-loss = 0.40123164653778076, train/logprobs = tensor([[-0.7940, -3.0228],
        [-1.0938, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331949532032013
Epoch 0, Step 640: train/loss = 0.41653716564178467, train/raw-loss = 0.36198535561561584, train/logprobs = tensor([[-0.5047, -4.5012],
        [-0.7149, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10910354554653168
Epoch 0, Step 641: train/loss = 0.6407105922698975, train/raw-loss = 0.5805869102478027, train/logprobs = tensor([[-1.2106, -2.9250],
        [-0.9463, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12024745345115662
Epoch 0, Step 642: train/loss = 0.4329933524131775, train/raw-loss = 0.37080103158950806, train/logprobs = tensor([[-0.8367, -3.4085],
        [-1.0070, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12438467144966125
Epoch 0, Step 643: train/loss = 0.34823721647262573, train/raw-loss = 0.2845541834831238, train/logprobs = tensor([[-0.5088, -5.0202],
        [-0.9126, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12736597657203674
Epoch 0, Step 644: train/loss = 0.5756590366363525, train/raw-loss = 0.5091684460639954, train/logprobs = tensor([[-0.9106, -1.1351],
        [-1.3063, -0.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13298116624355316
Epoch 0, Step 645: train/loss = 0.4553712010383606, train/raw-loss = 0.4003069996833801, train/logprobs = tensor([[-1.0361, -4.9938],
        [-1.5783, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012838035821915
Epoch 0, Step 646: train/loss = 0.617845892906189, train/raw-loss = 0.557601809501648, train/logprobs = tensor([[-0.5128, -1.0107],
        [-0.8300, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12048804759979248
Epoch 0, Step 647: train/loss = 0.5046639442443848, train/raw-loss = 0.4468464255332947, train/logprobs = tensor([[-0.5573, -2.5702],
        [-0.8996, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156349629163742
Epoch 0, Step 648: train/loss = 0.4402892291545868, train/raw-loss = 0.37796473503112793, train/logprobs = tensor([[-0.5877, -4.2212],
        [-1.0486, -1.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12464895099401474
Epoch 0, Step 649: train/loss = 0.29500648379325867, train/raw-loss = 0.2322263866662979, train/logprobs = tensor([[-0.5635, -5.7803],
        [-1.3194, -0.9574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255601942539215
Epoch 0, Step 650: train/loss = 0.3553558588027954, train/raw-loss = 0.2920669615268707, train/logprobs = tensor([[-0.5704, -5.3947],
        [-1.0620, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12657779455184937
Epoch 0, Step 651: train/loss = 0.32016241550445557, train/raw-loss = 0.2544800639152527, train/logprobs = tensor([[-0.8341, -4.6700],
        [-1.2907, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13136467337608337
Epoch 0, Step 652: train/loss = 0.4065367579460144, train/raw-loss = 0.3600344657897949, train/logprobs = tensor([[-0.9514, -6.6816],
        [-1.1411, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09300459921360016
Epoch 0, Step 653: train/loss = 0.497457891702652, train/raw-loss = 0.44518741965293884, train/logprobs = tensor([[-0.6778, -2.4944],
        [-0.9943, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10454092919826508
Epoch 0, Step 654: train/loss = 0.6185864210128784, train/raw-loss = 0.5661417841911316, train/logprobs = tensor([[-0.5668, -2.0389],
        [-0.6206, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10488917678594589
Epoch 0, Step 655: train/loss = 0.41198596358299255, train/raw-loss = 0.33834442496299744, train/logprobs = tensor([[-0.8210, -3.2312],
        [-1.3879, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14728309214115143
Epoch 0, Step 656: train/loss = 0.3052012622356415, train/raw-loss = 0.2391863763332367, train/logprobs = tensor([[-0.9771, -7.6336],
        [-1.3231, -1.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13202977180480957
Epoch 0, Step 657: train/loss = 0.3787851929664612, train/raw-loss = 0.32303059101104736, train/logprobs = tensor([[-0.5849, -4.7103],
        [-0.9671, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11150917410850525
Epoch 0, Step 658: train/loss = 0.5044440031051636, train/raw-loss = 0.43664413690567017, train/logprobs = tensor([[-0.8745, -3.1050],
        [-1.1206, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355997920036316
Epoch 0, Step 659: train/loss = 0.3024001717567444, train/raw-loss = 0.23228541016578674, train/logprobs = tensor([[-0.4914, -4.5505],
        [-1.0456, -0.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14022955298423767
Epoch 0, Step 660: train/loss = 0.6044066548347473, train/raw-loss = 0.5426191687583923, train/logprobs = tensor([[-0.7400, -1.9692],
        [-0.7014, -0.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12357494235038757
Epoch 0, Step 661: train/loss = 0.4505969285964966, train/raw-loss = 0.3863622546195984, train/logprobs = tensor([[-0.5301, -3.9588],
        [-0.9650, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12846937775611877
Epoch 0, Step 662: train/loss = 0.5770695209503174, train/raw-loss = 0.5280402302742004, train/logprobs = tensor([[-0.5841, -1.4698],
        [-0.7244, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09805851429700851
Epoch 0, Step 663: train/loss = 0.47223329544067383, train/raw-loss = 0.4145417809486389, train/logprobs = tensor([[-0.9053, -5.2893],
        [-0.8095, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538301408290863
Epoch 0, Step 664: train/loss = 0.4818410575389862, train/raw-loss = 0.4233974814414978, train/logprobs = tensor([[-0.6440, -2.1780],
        [-1.0025, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11688704788684845
Epoch 0, Step 665: train/loss = 0.5349439382553101, train/raw-loss = 0.4679737091064453, train/logprobs = tensor([[-0.9071, -1.7737],
        [-0.9959, -0.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13394047319889069
Epoch 0, Step 666: train/loss = 0.4448220729827881, train/raw-loss = 0.38279980421066284, train/logprobs = tensor([[-0.7195, -3.6590],
        [-1.3100, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12404447793960571
