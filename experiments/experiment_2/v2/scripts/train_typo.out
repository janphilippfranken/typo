{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 22:00:44,672][root][INFO] - beta: 0.1
[2024-03-12 22:00:44,672][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6507846117019653, train/raw-loss = 0.6490479111671448, train/logprobs = tensor([[-0.5553, -0.9087],
        [-0.4920, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01736677996814251
Epoch 0, Step 65: train/loss = 0.5868374705314636, train/raw-loss = 0.5854456424713135, train/logprobs = tensor([[-0.4080, -2.3943],
        [-0.4064, -1.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013918440788984299
Epoch 0, Step 66: train/loss = 0.6289633512496948, train/raw-loss = 0.6272355318069458, train/logprobs = tensor([[-0.6682, -1.2258],
        [-0.6753, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01727842167019844
Epoch 0, Step 67: train/loss = 0.6093969345092773, train/raw-loss = 0.607939600944519, train/logprobs = tensor([[-0.4559, -1.6532],
        [-0.4385, -1.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01457318663597107
Epoch 0, Step 68: train/loss = 0.6216741800308228, train/raw-loss = 0.6201486587524414, train/logprobs = tensor([[-0.5314, -0.8145],
        [-0.6266, -0.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015255148522555828
Epoch 0, Step 69: train/loss = 0.6382630467414856, train/raw-loss = 0.6366813778877258, train/logprobs = tensor([[-0.6248, -0.8802],
        [-0.6370, -0.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015816107392311096
Epoch 0, Step 70: train/loss = 0.6046648025512695, train/raw-loss = 0.6032372117042542, train/logprobs = tensor([[-0.5841, -1.5781],
        [-0.5841, -1.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014275925233960152
Epoch 0, Step 71: train/loss = 0.6147713661193848, train/raw-loss = 0.6132846474647522, train/logprobs = tensor([[-0.5103, -1.2050],
        [-0.5328, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014867503196001053
Epoch 0, Step 72: train/loss = 0.6391158103942871, train/raw-loss = 0.6375483274459839, train/logprobs = tensor([[-0.5469, -1.3675],
        [-0.5528, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015675779432058334
Epoch 0, Step 73: train/loss = 0.6764936447143555, train/raw-loss = 0.6747894287109375, train/logprobs = tensor([[-0.5537, -1.0901],
        [-0.5393, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017042528837919235
Epoch 0, Step 74: train/loss = 0.6480963230133057, train/raw-loss = 0.6462950110435486, train/logprobs = tensor([[-0.6132, -0.9831],
        [-0.5848, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018013156950473785
Epoch 0, Step 75: train/loss = 0.6070234775543213, train/raw-loss = 0.6057731509208679, train/logprobs = tensor([[-0.4139, -1.3276],
        [-0.4380, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012502728030085564
Epoch 0, Step 76: train/loss = 0.5455330014228821, train/raw-loss = 0.5441782474517822, train/logprobs = tensor([[-0.4643, -2.4569],
        [-0.4999, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013547578826546669
Epoch 0, Step 77: train/loss = 0.6063554883003235, train/raw-loss = 0.6047415733337402, train/logprobs = tensor([[-0.6565, -1.0122],
        [-0.6908, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016139311715960503
Epoch 0, Step 78: train/loss = 0.6519066691398621, train/raw-loss = 0.6502258777618408, train/logprobs = tensor([[-0.6888, -0.9514],
        [-0.6836, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016807660460472107
Epoch 0, Step 79: train/loss = 0.5772328972816467, train/raw-loss = 0.5757297873497009, train/logprobs = tensor([[-0.5675, -2.4031],
        [-0.5723, -1.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015031412243843079
Epoch 0, Step 80: train/loss = 0.6270461082458496, train/raw-loss = 0.6252567768096924, train/logprobs = tensor([[-0.7446, -1.0084],
        [-0.7351, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01789328083395958
Epoch 0, Step 81: train/loss = 0.5716840028762817, train/raw-loss = 0.5705827474594116, train/logprobs = tensor([[-0.5279, -2.5048],
        [-0.5218, -1.7375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011013010516762733
Epoch 0, Step 82: train/loss = 0.6486656069755554, train/raw-loss = 0.6467872858047485, train/logprobs = tensor([[-0.6923, -1.1149],
        [-0.6226, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01878390833735466
Epoch 0, Step 83: train/loss = 0.683257520198822, train/raw-loss = 0.6812446117401123, train/logprobs = tensor([[-1.5427, -1.6639],
        [-1.4890, -1.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02012951672077179
Epoch 0, Step 84: train/loss = 0.6410017013549805, train/raw-loss = 0.6391083002090454, train/logprobs = tensor([[-0.6086, -0.9797],
        [-0.5876, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018933841958642006
Epoch 0, Step 85: train/loss = 0.5624460577964783, train/raw-loss = 0.5608250498771667, train/logprobs = tensor([[-0.5891, -2.0098],
        [-0.5801, -1.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016210347414016724
Epoch 0, Step 86: train/loss = 0.6284708380699158, train/raw-loss = 0.6267504692077637, train/logprobs = tensor([[-0.5688, -0.9162],
        [-0.5949, -0.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017202898859977722
Epoch 0, Step 87: train/loss = 0.6067649126052856, train/raw-loss = 0.6051578521728516, train/logprobs = tensor([[-0.6367, -1.0340],
        [-0.7057, -0.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016069965437054634
Epoch 0, Step 88: train/loss = 0.6137086153030396, train/raw-loss = 0.611836850643158, train/logprobs = tensor([[-1.0054, -2.1731],
        [-0.9346, -1.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018717050552368164
Epoch 0, Step 89: train/loss = 0.6381853818893433, train/raw-loss = 0.6363908052444458, train/logprobs = tensor([[-0.5698, -0.9951],
        [-0.5564, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017945202067494392
Epoch 0, Step 90: train/loss = 0.6289997696876526, train/raw-loss = 0.6273231506347656, train/logprobs = tensor([[-0.4658, -1.0590],
        [-0.4742, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016766251996159554
Epoch 0, Step 91: train/loss = 0.4476001560688019, train/raw-loss = 0.4463074207305908, train/logprobs = tensor([[-0.4704, -2.7814],
        [-0.5084, -1.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012927279807627201
Epoch 0, Step 92: train/loss = 0.6520987749099731, train/raw-loss = 0.6500625610351562, train/logprobs = tensor([[-0.6948, -1.0883],
        [-0.6947, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020361850038170815
Epoch 0, Step 93: train/loss = 0.590849757194519, train/raw-loss = 0.5892488956451416, train/logprobs = tensor([[-0.5657, -1.4603],
        [-0.5577, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016008488833904266
Epoch 0, Step 94: train/loss = 0.5898365378379822, train/raw-loss = 0.5881245732307434, train/logprobs = tensor([[-0.6766, -1.8463],
        [-0.7738, -1.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01711907610297203
Epoch 0, Step 95: train/loss = 0.6279889941215515, train/raw-loss = 0.6266092658042908, train/logprobs = tensor([[-0.5267, -1.0140],
        [-0.5227, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013797451741993427
Epoch 0, Step 96: train/loss = 0.6891582012176514, train/raw-loss = 0.6837301850318909, train/logprobs = tensor([[-0.6062, -0.9076],
        [-0.5876, -0.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054279156029224396
Epoch 0, Step 97: train/loss = 0.5707126259803772, train/raw-loss = 0.5661445260047913, train/logprobs = tensor([[-0.6425, -1.9612],
        [-0.6175, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04568079113960266
Epoch 0, Step 98: train/loss = 0.6150745749473572, train/raw-loss = 0.6116935014724731, train/logprobs = tensor([[-0.3874, -0.9948],
        [-0.3299, -0.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03381064534187317
Epoch 0, Step 99: train/loss = 0.6296662092208862, train/raw-loss = 0.6261261701583862, train/logprobs = tensor([[-0.5308, -1.0520],
        [-0.5068, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0354008749127388
Epoch 0, Step 100: train/loss = 0.5464789867401123, train/raw-loss = 0.5426733493804932, train/logprobs = tensor([[-0.6833, -2.8378],
        [-0.6521, -1.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03805619105696678
Epoch 0, Step 101: train/loss = 0.5956326127052307, train/raw-loss = 0.5891669988632202, train/logprobs = tensor([[-0.9682, -1.8568],
        [-0.9272, -1.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06465598940849304
Epoch 0, Step 102: train/loss = 0.5831016898155212, train/raw-loss = 0.5786948800086975, train/logprobs = tensor([[-0.5007, -1.3650],
        [-0.4888, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04406805336475372
Epoch 0, Step 103: train/loss = 0.559036135673523, train/raw-loss = 0.5552841424942017, train/logprobs = tensor([[-0.6358, -1.7403],
        [-0.5484, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03751998767256737
Epoch 0, Step 104: train/loss = 0.4508384168148041, train/raw-loss = 0.4458114504814148, train/logprobs = tensor([[-0.8015, -4.5321],
        [-0.6593, -2.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05026962235569954
Epoch 0, Step 105: train/loss = 0.6034975647926331, train/raw-loss = 0.5988556146621704, train/logprobs = tensor([[-0.6800, -1.2201],
        [-0.6160, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04641947150230408
Epoch 0, Step 106: train/loss = 0.45707967877388, train/raw-loss = 0.453285813331604, train/logprobs = tensor([[-0.6852, -4.4684],
        [-0.6201, -2.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037938449531793594
Epoch 0, Step 107: train/loss = 0.6047887802124023, train/raw-loss = 0.5991354584693909, train/logprobs = tensor([[-0.7242, -1.5454],
        [-0.6804, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05653341859579086
Epoch 0, Step 108: train/loss = 0.6645090579986572, train/raw-loss = 0.6615773439407349, train/logprobs = tensor([[-0.5296, -0.6624],
        [-0.4648, -0.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029317403212189674
Epoch 0, Step 109: train/loss = 0.6073334217071533, train/raw-loss = 0.6033211946487427, train/logprobs = tensor([[-0.6403, -1.2868],
        [-0.5548, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040123023092746735
Epoch 0, Step 110: train/loss = 0.5435794591903687, train/raw-loss = 0.539391040802002, train/logprobs = tensor([[-0.6679, -2.9832],
        [-0.5460, -1.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04188476502895355
Epoch 0, Step 111: train/loss = 0.5767547488212585, train/raw-loss = 0.5737195014953613, train/logprobs = tensor([[-0.4382, -1.5263],
        [-0.4234, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030352158471941948
Epoch 0, Step 112: train/loss = 0.6026514172554016, train/raw-loss = 0.5987823009490967, train/logprobs = tensor([[-0.6345, -1.1162],
        [-0.5908, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038691695779561996
Epoch 0, Step 113: train/loss = 0.6324023604393005, train/raw-loss = 0.6267088651657104, train/logprobs = tensor([[-0.6528, -1.2957],
        [-0.5744, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05693454295396805
Epoch 0, Step 114: train/loss = 0.6040812134742737, train/raw-loss = 0.5994457006454468, train/logprobs = tensor([[-0.5679, -1.0783],
        [-0.5353, -0.6186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04635544493794441
Epoch 0, Step 115: train/loss = 0.6175928711891174, train/raw-loss = 0.6139797568321228, train/logprobs = tensor([[-0.5751, -1.1815],
        [-0.5396, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03613104298710823
Epoch 0, Step 116: train/loss = 0.5622681379318237, train/raw-loss = 0.5572155714035034, train/logprobs = tensor([[-0.6735, -2.0948],
        [-0.6122, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050525713711977005
Epoch 0, Step 117: train/loss = 0.6234111785888672, train/raw-loss = 0.6192725300788879, train/logprobs = tensor([[-0.4886, -1.7851],
        [-0.4612, -1.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04138614609837532
Epoch 0, Step 118: train/loss = 0.4970095455646515, train/raw-loss = 0.4935479164123535, train/logprobs = tensor([[-0.6598, -3.2225],
        [-0.5708, -1.3796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034616097807884216
Epoch 0, Step 119: train/loss = 0.5688883066177368, train/raw-loss = 0.5637581944465637, train/logprobs = tensor([[-0.6193, -1.7123],
        [-0.5645, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0513014942407608
Epoch 0, Step 120: train/loss = 0.5237961411476135, train/raw-loss = 0.5190548300743103, train/logprobs = tensor([[-0.7862, -2.6592],
        [-0.7600, -1.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047413118183612823
Epoch 0, Step 121: train/loss = 0.6089950799942017, train/raw-loss = 0.6052944660186768, train/logprobs = tensor([[-0.5047, -1.2510],
        [-0.4492, -0.7691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03700613975524902
Epoch 0, Step 122: train/loss = 0.5454292297363281, train/raw-loss = 0.540632426738739, train/logprobs = tensor([[-0.8541, -1.9730],
        [-0.7367, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04796778783202171
Epoch 0, Step 123: train/loss = 0.6694985628128052, train/raw-loss = 0.6649014353752136, train/logprobs = tensor([[-0.5347, -0.8017],
        [-0.5089, -0.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04597072675824165
Epoch 0, Step 124: train/loss = 0.5862933397293091, train/raw-loss = 0.5812265872955322, train/logprobs = tensor([[-0.7999, -1.6263],
        [-0.7102, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050667114555835724
Epoch 0, Step 125: train/loss = 0.5435522198677063, train/raw-loss = 0.5387548804283142, train/logprobs = tensor([[-0.7141, -3.2543],
        [-0.6326, -2.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04797331243753433
Epoch 0, Step 126: train/loss = 0.6326649188995361, train/raw-loss = 0.6274271011352539, train/logprobs = tensor([[-0.6834, -1.2244],
        [-0.5701, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052378565073013306
Epoch 0, Step 127: train/loss = 0.6145248413085938, train/raw-loss = 0.6103113889694214, train/logprobs = tensor([[-0.5137, -1.5119],
        [-0.4483, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04213397204875946
Epoch 0, Step 128: train/loss = 0.6677537560462952, train/raw-loss = 0.657264232635498, train/logprobs = tensor([[-0.8527, -1.0594],
        [-0.8002, -0.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10489614307880402
Epoch 0, Step 129: train/loss = 0.5302417278289795, train/raw-loss = 0.5189944505691528, train/logprobs = tensor([[-0.7522, -2.9517],
        [-0.6427, -1.8002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11247274279594421
Epoch 0, Step 130: train/loss = 0.6328884959220886, train/raw-loss = 0.6246880292892456, train/logprobs = tensor([[-0.5458, -1.1830],
        [-0.4771, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08200481534004211
Epoch 0, Step 131: train/loss = 0.5136717557907104, train/raw-loss = 0.5035476684570312, train/logprobs = tensor([[-0.7821, -4.1945],
        [-0.7000, -2.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10124041140079498
Epoch 0, Step 132: train/loss = 0.5495558977127075, train/raw-loss = 0.5393264293670654, train/logprobs = tensor([[-0.8113, -2.4192],
        [-0.6464, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229451209306717
Epoch 0, Step 133: train/loss = 0.5631492137908936, train/raw-loss = 0.5530778169631958, train/logprobs = tensor([[-0.6562, -2.4664],
        [-0.5623, -1.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10071414709091187
Epoch 0, Step 134: train/loss = 0.5735405683517456, train/raw-loss = 0.5649099349975586, train/logprobs = tensor([[-0.7718, -1.7202],
        [-0.6290, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08630652725696564
Epoch 0, Step 135: train/loss = 0.606726348400116, train/raw-loss = 0.5982346534729004, train/logprobs = tensor([[-0.5283, -1.5230],
        [-0.3977, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08491724729537964
Epoch 0, Step 136: train/loss = 0.5346441268920898, train/raw-loss = 0.528393030166626, train/logprobs = tensor([[-0.4453, -2.1923],
        [-0.3971, -1.3263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06251136213541031
Epoch 0, Step 137: train/loss = 0.6032107472419739, train/raw-loss = 0.5960061550140381, train/logprobs = tensor([[-0.4480, -1.3869],
        [-0.4097, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07204605638980865
Epoch 0, Step 138: train/loss = 0.5545004606246948, train/raw-loss = 0.546109676361084, train/logprobs = tensor([[-0.4439, -1.7761],
        [-0.3653, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08390706032514572
Epoch 0, Step 139: train/loss = 0.537452757358551, train/raw-loss = 0.5279146432876587, train/logprobs = tensor([[-0.6307, -2.4630],
        [-0.5013, -1.4407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09538139402866364
Epoch 0, Step 140: train/loss = 0.5944633483886719, train/raw-loss = 0.5841116309165955, train/logprobs = tensor([[-0.7943, -1.8136],
        [-0.6760, -1.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10351724922657013
Epoch 0, Step 141: train/loss = 0.5974938869476318, train/raw-loss = 0.5861510038375854, train/logprobs = tensor([[-0.9338, -1.9839],
        [-0.6970, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342831701040268
Epoch 0, Step 142: train/loss = 0.6248834133148193, train/raw-loss = 0.615633487701416, train/logprobs = tensor([[-0.5694, -1.2588],
        [-0.4821, -0.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0924992710351944
Epoch 0, Step 143: train/loss = 0.64568030834198, train/raw-loss = 0.6373879909515381, train/logprobs = tensor([[-0.7637, -1.6045],
        [-0.6012, -1.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0829240083694458
Epoch 0, Step 144: train/loss = 0.48390746116638184, train/raw-loss = 0.47573283314704895, train/logprobs = tensor([[-0.5810, -4.0447],
        [-0.4969, -2.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174599707126617
Epoch 0, Step 145: train/loss = 0.6226330399513245, train/raw-loss = 0.6153507828712463, train/logprobs = tensor([[-0.6613, -1.5575],
        [-0.5742, -1.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07282233983278275
Epoch 0, Step 146: train/loss = 0.5590167045593262, train/raw-loss = 0.5489232540130615, train/logprobs = tensor([[-0.6561, -2.8740],
        [-0.5272, -1.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10093400627374649
Epoch 0, Step 147: train/loss = 0.6167504191398621, train/raw-loss = 0.6085224151611328, train/logprobs = tensor([[-0.6317, -1.2375],
        [-0.5273, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08228066563606262
Epoch 0, Step 148: train/loss = 0.6991143226623535, train/raw-loss = 0.685641884803772, train/logprobs = tensor([[-1.5790, -1.9034],
        [-1.1933, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347244679927826
Epoch 0, Step 149: train/loss = 0.6420785188674927, train/raw-loss = 0.6314484477043152, train/logprobs = tensor([[-0.6451, -1.3170],
        [-0.5359, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630098730325699
Epoch 0, Step 150: train/loss = 0.5497560501098633, train/raw-loss = 0.5371724963188171, train/logprobs = tensor([[-0.8370, -3.5912],
        [-0.7323, -2.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12583591043949127
Epoch 0, Step 151: train/loss = 0.5954630970954895, train/raw-loss = 0.5846341252326965, train/logprobs = tensor([[-0.6864, -1.9147],
        [-0.5421, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10828957706689835
Epoch 0, Step 152: train/loss = 0.6147996187210083, train/raw-loss = 0.6028674840927124, train/logprobs = tensor([[-0.8588, -1.4400],
        [-0.7718, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932103335857391
Epoch 0, Step 153: train/loss = 0.5816831588745117, train/raw-loss = 0.5711114406585693, train/logprobs = tensor([[-0.6284, -2.1309],
        [-0.5167, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057172492146492
Epoch 0, Step 154: train/loss = 0.6535446047782898, train/raw-loss = 0.6430394649505615, train/logprobs = tensor([[-0.7625, -1.6498],
        [-0.6587, -1.3250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10505207628011703
Epoch 0, Step 155: train/loss = 0.5640436410903931, train/raw-loss = 0.5551891922950745, train/logprobs = tensor([[-0.6044, -2.9903],
        [-0.5106, -1.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854492008686066
Epoch 0, Step 156: train/loss = 0.6621188521385193, train/raw-loss = 0.6530760526657104, train/logprobs = tensor([[-0.6455, -0.7826],
        [-0.5741, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904284417629242
Epoch 0, Step 157: train/loss = 0.6971845030784607, train/raw-loss = 0.6858580112457275, train/logprobs = tensor([[-0.7548, -0.8175],
        [-0.6663, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11326473951339722
Epoch 0, Step 158: train/loss = 0.6587287187576294, train/raw-loss = 0.647781491279602, train/logprobs = tensor([[-0.7136, -1.2526],
        [-0.5114, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10947231948375702
Epoch 0, Step 159: train/loss = 0.6805225610733032, train/raw-loss = 0.6693812608718872, train/logprobs = tensor([[-0.8778, -1.0708],
        [-0.7236, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11141352355480194
Epoch 0, Step 160: train/loss = 0.5603493452072144, train/raw-loss = 0.5464816093444824, train/logprobs = tensor([[-1.1613, -2.3965],
        [-0.8854, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138677179813385
Epoch 0, Step 161: train/loss = 0.6352677345275879, train/raw-loss = 0.625105619430542, train/logprobs = tensor([[-0.6936, -1.3678],
        [-0.5789, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10162122547626495
Epoch 0, Step 162: train/loss = 0.5775282979011536, train/raw-loss = 0.5678273439407349, train/logprobs = tensor([[-0.6028, -3.1993],
        [-0.5204, -2.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09701002389192581
Epoch 0, Step 163: train/loss = 0.5588434934616089, train/raw-loss = 0.5482051372528076, train/logprobs = tensor([[-0.6084, -2.2718],
        [-0.4475, -1.3248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10638339072465897
Epoch 0, Step 164: train/loss = 0.5868522524833679, train/raw-loss = 0.5771498680114746, train/logprobs = tensor([[-0.7077, -1.9281],
        [-0.5567, -1.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09702365845441818
Epoch 0, Step 165: train/loss = 0.5621830224990845, train/raw-loss = 0.5513636469841003, train/logprobs = tensor([[-0.6934, -2.2974],
        [-0.5174, -1.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081932932138443
Epoch 0, Step 166: train/loss = 0.43492114543914795, train/raw-loss = 0.4254749119281769, train/logprobs = tensor([[-0.6745, -7.0388],
        [-0.4628, -4.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446247667074203
Epoch 0, Step 167: train/loss = 0.6245443224906921, train/raw-loss = 0.6139938831329346, train/logprobs = tensor([[-0.7566, -1.5271],
        [-0.5965, -0.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10550452768802643
Epoch 0, Step 168: train/loss = 0.6050469875335693, train/raw-loss = 0.5947678089141846, train/logprobs = tensor([[-0.7442, -1.6402],
        [-0.5547, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10279135406017303
Epoch 0, Step 169: train/loss = 0.6598926186561584, train/raw-loss = 0.6493449211120605, train/logprobs = tensor([[-0.8445, -1.3904],
        [-0.7500, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10547655820846558
Epoch 0, Step 170: train/loss = 0.5924457311630249, train/raw-loss = 0.5826017260551453, train/logprobs = tensor([[-0.6294, -1.7888],
        [-0.5730, -1.1934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843987226486206
Epoch 0, Step 171: train/loss = 0.644003689289093, train/raw-loss = 0.6332042813301086, train/logprobs = tensor([[-0.6866, -1.4486],
        [-0.5411, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10799367725849152
Epoch 0, Step 172: train/loss = 0.5055865049362183, train/raw-loss = 0.49570339918136597, train/logprobs = tensor([[-0.6658, -2.7474],
        [-0.5871, -1.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0988309234380722
Epoch 0, Step 173: train/loss = 0.5491083860397339, train/raw-loss = 0.540279746055603, train/logprobs = tensor([[-0.6506, -2.5958],
        [-0.5533, -1.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08828650414943695
Epoch 0, Step 174: train/loss = 0.5473759770393372, train/raw-loss = 0.5368157625198364, train/logprobs = tensor([[-0.7175, -2.1608],
        [-0.5488, -1.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10560246556997299
Epoch 0, Step 175: train/loss = 0.44666096568107605, train/raw-loss = 0.4382029175758362, train/logprobs = tensor([[-0.5350, -3.8510],
        [-0.4055, -2.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08458063751459122
Epoch 0, Step 176: train/loss = 0.6034680604934692, train/raw-loss = 0.5916761159896851, train/logprobs = tensor([[-0.7717, -1.7570],
        [-0.5070, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11791949719190598
Epoch 0, Step 177: train/loss = 0.5831134915351868, train/raw-loss = 0.5702415108680725, train/logprobs = tensor([[-1.1428, -2.6883],
        [-0.6861, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12871994078159332
Epoch 0, Step 178: train/loss = 0.6153149604797363, train/raw-loss = 0.6029694080352783, train/logprobs = tensor([[-0.8997, -2.6032],
        [-0.7771, -1.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12345568090677261
Epoch 0, Step 179: train/loss = 0.6010997295379639, train/raw-loss = 0.5906488299369812, train/logprobs = tensor([[-0.6829, -2.5896],
        [-0.5348, -1.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10450854897499084
Epoch 0, Step 180: train/loss = 0.6906407475471497, train/raw-loss = 0.6783801317214966, train/logprobs = tensor([[-0.8824, -0.9606],
        [-0.7053, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260632961988449
Epoch 0, Step 181: train/loss = 0.6981476545333862, train/raw-loss = 0.6871820688247681, train/logprobs = tensor([[-2.8747, -4.2804],
        [-2.0003, -2.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10965554416179657
Epoch 0, Step 182: train/loss = 0.6240995526313782, train/raw-loss = 0.6134840846061707, train/logprobs = tensor([[-0.5548, -1.3235],
        [-0.4724, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106154665350914
Epoch 0, Step 183: train/loss = 0.5932259559631348, train/raw-loss = 0.5824763774871826, train/logprobs = tensor([[-0.7443, -1.8463],
        [-0.6121, -1.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10749606043100357
Epoch 0, Step 184: train/loss = 0.5116315484046936, train/raw-loss = 0.5003741979598999, train/logprobs = tensor([[-1.2462, -4.5061],
        [-1.2206, -3.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11257392168045044
Epoch 0, Step 185: train/loss = 0.6025784611701965, train/raw-loss = 0.5909203290939331, train/logprobs = tensor([[-0.8915, -2.1938],
        [-0.7116, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11658145487308502
Epoch 0, Step 186: train/loss = 0.5900552272796631, train/raw-loss = 0.5761386156082153, train/logprobs = tensor([[-0.8648, -1.7682],
        [-0.7515, -1.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13916659355163574
Epoch 0, Step 187: train/loss = 0.5903924703598022, train/raw-loss = 0.5812495350837708, train/logprobs = tensor([[-0.6293, -2.4314],
        [-0.5118, -1.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09142959117889404
Epoch 0, Step 188: train/loss = 0.5306928157806396, train/raw-loss = 0.5194472074508667, train/logprobs = tensor([[-0.9064, -4.3113],
        [-0.6605, -2.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11245664209127426
Epoch 0, Step 189: train/loss = 0.6666325926780701, train/raw-loss = 0.6570384502410889, train/logprobs = tensor([[-0.6307, -0.9378],
        [-0.5153, -0.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09594074636697769
Epoch 0, Step 190: train/loss = 0.5517359972000122, train/raw-loss = 0.5408386588096619, train/logprobs = tensor([[-0.8581, -3.8579],
        [-0.6336, -2.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10897321254014969
Epoch 0, Step 191: train/loss = 0.6362143158912659, train/raw-loss = 0.6261775493621826, train/logprobs = tensor([[-0.7185, -1.2028],
        [-0.6201, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10036803781986237
Epoch 0, Step 192: train/loss = 0.563012957572937, train/raw-loss = 0.5484970808029175, train/logprobs = tensor([[-0.8287, -1.8184],
        [-0.5783, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14515917003154755
Epoch 0, Step 193: train/loss = 0.4745361804962158, train/raw-loss = 0.45961225032806396, train/logprobs = tensor([[-0.8570, -3.6684],
        [-0.6459, -1.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14923951029777527
Epoch 0, Step 194: train/loss = 0.49341803789138794, train/raw-loss = 0.4781319499015808, train/logprobs = tensor([[-0.9975, -4.3135],
        [-0.7514, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15286092460155487
Epoch 0, Step 195: train/loss = 0.5057522654533386, train/raw-loss = 0.48993533849716187, train/logprobs = tensor([[-0.9200, -3.9026],
        [-0.6495, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15816956758499146
Epoch 0, Step 196: train/loss = 0.5835891962051392, train/raw-loss = 0.5692942142486572, train/logprobs = tensor([[-0.7898, -1.8065],
        [-0.5992, -0.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14294955134391785
Epoch 0, Step 197: train/loss = 0.5329548120498657, train/raw-loss = 0.519587516784668, train/logprobs = tensor([[-0.7790, -2.7781],
        [-0.5178, -1.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13367252051830292
Epoch 0, Step 198: train/loss = 0.5734363198280334, train/raw-loss = 0.5596885681152344, train/logprobs = tensor([[-0.7436, -2.0393],
        [-0.5301, -0.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13747788965702057
Epoch 0, Step 199: train/loss = 0.4441002905368805, train/raw-loss = 0.4323643445968628, train/logprobs = tensor([[-0.5879, -2.7806],
        [-0.3746, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11735963821411133
Epoch 0, Step 200: train/loss = 0.5013294219970703, train/raw-loss = 0.4879101514816284, train/logprobs = tensor([[-0.9555, -2.5639],
        [-0.6272, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13419291377067566
Epoch 0, Step 201: train/loss = 0.4988391399383545, train/raw-loss = 0.4816139340400696, train/logprobs = tensor([[-1.0494, -3.8305],
        [-0.6728, -1.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17225174605846405
Epoch 0, Step 202: train/loss = 0.6004230976104736, train/raw-loss = 0.5877236723899841, train/logprobs = tensor([[-0.7645, -1.3375],
        [-0.6586, -0.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269938200712204
Epoch 0, Step 203: train/loss = 0.5940486192703247, train/raw-loss = 0.5792352557182312, train/logprobs = tensor([[-0.8827, -3.2944],
        [-0.5578, -1.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14813360571861267
Epoch 0, Step 204: train/loss = 0.511354923248291, train/raw-loss = 0.49996694922447205, train/logprobs = tensor([[-1.0085, -2.4153],
        [-0.7293, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11387991160154343
Epoch 0, Step 205: train/loss = 0.4406280517578125, train/raw-loss = 0.42953333258628845, train/logprobs = tensor([[-0.6152, -2.8107],
        [-0.5040, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11094704270362854
Epoch 0, Step 206: train/loss = 0.3605079650878906, train/raw-loss = 0.3493274450302124, train/logprobs = tensor([[-0.6767, -6.1808],
        [-0.5042, -1.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11180557310581207
Epoch 0, Step 207: train/loss = 0.4771196246147156, train/raw-loss = 0.46320223808288574, train/logprobs = tensor([[-1.0650, -2.7203],
        [-0.8367, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391737461090088
Epoch 0, Step 208: train/loss = 0.4855506122112274, train/raw-loss = 0.4731961488723755, train/logprobs = tensor([[-0.8770, -3.9185],
        [-0.5422, -1.3594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12354425340890884
Epoch 0, Step 209: train/loss = 0.5430084466934204, train/raw-loss = 0.52748042345047, train/logprobs = tensor([[-0.8735, -2.5052],
        [-0.6616, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15528011322021484
Epoch 0, Step 210: train/loss = 0.5431500673294067, train/raw-loss = 0.5317830443382263, train/logprobs = tensor([[-0.7674, -1.8970],
        [-0.5815, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1136704534292221
Epoch 0, Step 211: train/loss = 0.5853126645088196, train/raw-loss = 0.5702881813049316, train/logprobs = tensor([[-1.2556, -4.5904],
        [-1.1646, -2.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15024434030056
Epoch 0, Step 212: train/loss = 0.6064376831054688, train/raw-loss = 0.5935981869697571, train/logprobs = tensor([[-0.6157, -1.5709],
        [-0.4764, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12839511036872864
Epoch 0, Step 213: train/loss = 0.619826078414917, train/raw-loss = 0.6043851971626282, train/logprobs = tensor([[-0.7920, -1.5478],
        [-0.5333, -0.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15440890192985535
Epoch 0, Step 214: train/loss = 0.5180633068084717, train/raw-loss = 0.5043087005615234, train/logprobs = tensor([[-0.7080, -3.3347],
        [-0.6032, -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13754591345787048
Epoch 0, Step 215: train/loss = 0.500126302242279, train/raw-loss = 0.48300400376319885, train/logprobs = tensor([[-1.0493, -3.3703],
        [-0.9134, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17122329771518707
Epoch 0, Step 216: train/loss = 0.60737144947052, train/raw-loss = 0.5924773216247559, train/logprobs = tensor([[-0.9253, -1.5579],
        [-0.5049, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14894112944602966
Epoch 0, Step 217: train/loss = 0.47824886441230774, train/raw-loss = 0.4639767110347748, train/logprobs = tensor([[-0.7008, -2.9800],
        [-0.5089, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14272132515907288
Epoch 0, Step 218: train/loss = 0.6768020391464233, train/raw-loss = 0.6651203036308289, train/logprobs = tensor([[-0.7065, -0.8970],
        [-0.5563, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11681728065013885
Epoch 0, Step 219: train/loss = 0.5679187178611755, train/raw-loss = 0.5561954975128174, train/logprobs = tensor([[-0.7739, -2.1026],
        [-0.5704, -0.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11723237484693527
Epoch 0, Step 220: train/loss = 0.449951171875, train/raw-loss = 0.4346381723880768, train/logprobs = tensor([[-1.2856, -4.3020],
        [-0.8261, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15313014388084412
Epoch 0, Step 221: train/loss = 0.5123238563537598, train/raw-loss = 0.5030608773231506, train/logprobs = tensor([[-0.5275, -4.5287],
        [-0.4218, -1.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09262978285551071
Epoch 0, Step 222: train/loss = 0.5674881339073181, train/raw-loss = 0.5553956627845764, train/logprobs = tensor([[-0.7708, -2.3647],
        [-0.5261, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12092442810535431
Epoch 0, Step 223: train/loss = 0.5730890035629272, train/raw-loss = 0.5602996349334717, train/logprobs = tensor([[-0.9749, -2.4367],
        [-0.6790, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12789402902126312
Epoch 0, Step 224: train/loss = 0.5632803440093994, train/raw-loss = 0.5459644794464111, train/logprobs = tensor([[-0.8290, -1.8732],
        [-0.6569, -0.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731584668159485
Epoch 0, Step 225: train/loss = 0.5875870585441589, train/raw-loss = 0.5752750635147095, train/logprobs = tensor([[-0.7421, -1.8477],
        [-0.4092, -0.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12311926484107971
Epoch 0, Step 226: train/loss = 0.9752983450889587, train/raw-loss = 0.9610904455184937, train/logprobs = tensor([[-2.6095, -3.8983],
        [-0.6913, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14207875728607178
Epoch 0, Step 227: train/loss = 0.49905240535736084, train/raw-loss = 0.48103058338165283, train/logprobs = tensor([[-1.2758, -4.0668],
        [-0.5575, -1.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802181750535965
Epoch 0, Step 228: train/loss = 0.5558629035949707, train/raw-loss = 0.5432162880897522, train/logprobs = tensor([[-0.6711, -2.4126],
        [-0.4138, -1.2924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264665424823761
Epoch 0, Step 229: train/loss = 0.4173045754432678, train/raw-loss = 0.40056297183036804, train/logprobs = tensor([[-1.0769, -6.0053],
        [-0.9035, -2.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16741591691970825
Epoch 0, Step 230: train/loss = 0.44375038146972656, train/raw-loss = 0.42628151178359985, train/logprobs = tensor([[-1.3263, -3.9379],
        [-1.1692, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17468832433223724
Epoch 0, Step 231: train/loss = 0.42689648270606995, train/raw-loss = 0.4128013849258423, train/logprobs = tensor([[-0.7419, -4.8787],
        [-0.6562, -0.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140951007604599
Epoch 0, Step 232: train/loss = 0.5260074138641357, train/raw-loss = 0.5128424167633057, train/logprobs = tensor([[-0.6864, -2.8103],
        [-0.5953, -1.4511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316498965024948
Epoch 0, Step 233: train/loss = 0.6469256281852722, train/raw-loss = 0.6323473453521729, train/logprobs = tensor([[-1.4776, -5.8141],
        [-0.8087, -1.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14578241109848022
Epoch 0, Step 234: train/loss = 0.6144022345542908, train/raw-loss = 0.6019427180290222, train/logprobs = tensor([[-0.6953, -1.3013],
        [-0.5050, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12459519505500793
Epoch 0, Step 235: train/loss = 0.4851318299770355, train/raw-loss = 0.46984273195266724, train/logprobs = tensor([[-1.1385, -5.2176],
        [-0.5468, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15289075672626495
Epoch 0, Step 236: train/loss = 0.5795222520828247, train/raw-loss = 0.5613933205604553, train/logprobs = tensor([[-0.8212, -2.4290],
        [-0.6275, -1.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181289404630661
Epoch 0, Step 237: train/loss = 0.5189272165298462, train/raw-loss = 0.5014771223068237, train/logprobs = tensor([[-0.8334, -2.5047],
        [-0.6530, -0.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17450116574764252
Epoch 0, Step 238: train/loss = 0.4665762782096863, train/raw-loss = 0.4529939293861389, train/logprobs = tensor([[-0.6611, -3.0190],
        [-0.4753, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358233541250229
Epoch 0, Step 239: train/loss = 0.6536808609962463, train/raw-loss = 0.6400497555732727, train/logprobs = tensor([[-0.9231, -1.2919],
        [-0.5505, -0.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13631165027618408
Epoch 0, Step 240: train/loss = 0.6187273263931274, train/raw-loss = 0.5993738770484924, train/logprobs = tensor([[-1.2969, -3.0659],
        [-1.1473, -1.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1935345083475113
Epoch 0, Step 241: train/loss = 0.48597252368927, train/raw-loss = 0.47107386589050293, train/logprobs = tensor([[-0.6046, -2.2498],
        [-0.5338, -0.7700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14898662269115448
Epoch 0, Step 242: train/loss = 0.6129247546195984, train/raw-loss = 0.5999996066093445, train/logprobs = tensor([[-0.6567, -1.2330],
        [-0.4052, -0.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12925153970718384
Epoch 0, Step 243: train/loss = 0.6359827518463135, train/raw-loss = 0.6214067339897156, train/logprobs = tensor([[-0.9295, -1.3767],
        [-0.5181, -0.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14575979113578796
Epoch 0, Step 244: train/loss = 0.5117909908294678, train/raw-loss = 0.49398672580718994, train/logprobs = tensor([[-1.2033, -4.5241],
        [-0.6346, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17804260551929474
Epoch 0, Step 245: train/loss = 0.5440744757652283, train/raw-loss = 0.5281810164451599, train/logprobs = tensor([[-1.2855, -2.9261],
        [-0.5944, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15893419086933136
Epoch 0, Step 246: train/loss = 0.4436659812927246, train/raw-loss = 0.4283899664878845, train/logprobs = tensor([[-0.7504, -4.6823],
        [-0.6718, -1.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527605801820755
Epoch 0, Step 247: train/loss = 0.550045371055603, train/raw-loss = 0.5321703553199768, train/logprobs = tensor([[-1.0690, -2.9216],
        [-0.7452, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1787502020597458
Epoch 0, Step 248: train/loss = 0.5995940566062927, train/raw-loss = 0.5846191644668579, train/logprobs = tensor([[-0.7488, -2.1336],
        [-0.7004, -1.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14974910020828247
Epoch 0, Step 249: train/loss = 0.514427900314331, train/raw-loss = 0.5013235807418823, train/logprobs = tensor([[-0.5183, -2.6992],
        [-0.5108, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13104292750358582
Epoch 0, Step 250: train/loss = 0.518081545829773, train/raw-loss = 0.5028581619262695, train/logprobs = tensor([[-1.4225, -5.2562],
        [-0.5668, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15223386883735657
Epoch 0, Step 251: train/loss = 0.3912521302700043, train/raw-loss = 0.3771932125091553, train/logprobs = tensor([[-0.7316, -3.5459],
        [-0.5945, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14058902859687805
Epoch 0, Step 252: train/loss = 0.5501816868782043, train/raw-loss = 0.535927414894104, train/logprobs = tensor([[-0.5722, -1.9246],
        [-0.4476, -0.7344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425427347421646
Epoch 0, Step 253: train/loss = 0.7137455940246582, train/raw-loss = 0.6997398138046265, train/logprobs = tensor([[-0.8739, -0.7490],
        [-0.6512, -0.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1400575488805771
Epoch 0, Step 254: train/loss = 0.4589157998561859, train/raw-loss = 0.4443281292915344, train/logprobs = tensor([[-0.8817, -3.9760],
        [-0.5566, -1.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14587649703025818
Epoch 0, Step 255: train/loss = 0.5680442452430725, train/raw-loss = 0.5511466860771179, train/logprobs = tensor([[-1.2096, -3.0054],
        [-0.8993, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897578537464142
Epoch 0, Step 256: train/loss = 0.6647152304649353, train/raw-loss = 0.6520214080810547, train/logprobs = tensor([[-0.6375, -0.9829],
        [-0.4377, -0.5566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12693801522254944
Epoch 0, Step 257: train/loss = 0.6455086469650269, train/raw-loss = 0.6313149929046631, train/logprobs = tensor([[-0.8772, -1.5253],
        [-0.6050, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14193642139434814
Epoch 0, Step 258: train/loss = 0.3840653896331787, train/raw-loss = 0.3674732744693756, train/logprobs = tensor([[-1.1452, -4.1243],
        [-0.9175, -1.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16592121124267578
Epoch 0, Step 259: train/loss = 0.5252575874328613, train/raw-loss = 0.5120862722396851, train/logprobs = tensor([[-0.6583, -4.0856],
        [-0.4808, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13171346485614777
Epoch 0, Step 260: train/loss = 0.44222208857536316, train/raw-loss = 0.4294879138469696, train/logprobs = tensor([[-0.6196, -5.0058],
        [-0.4638, -1.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12734168767929077
Epoch 0, Step 261: train/loss = 0.4649988114833832, train/raw-loss = 0.448341429233551, train/logprobs = tensor([[-0.9233, -2.6495],
        [-0.8178, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16657370328903198
Epoch 0, Step 262: train/loss = 0.552963376045227, train/raw-loss = 0.5349148511886597, train/logprobs = tensor([[-0.8163, -2.8663],
        [-0.6694, -1.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18048492074012756
Epoch 0, Step 263: train/loss = 0.6169649958610535, train/raw-loss = 0.5983380079269409, train/logprobs = tensor([[-1.5593, -2.5482],
        [-1.2186, -1.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627044558525085
Epoch 0, Step 264: train/loss = 0.6007639765739441, train/raw-loss = 0.5843809247016907, train/logprobs = tensor([[-0.8211, -1.6270],
        [-0.7030, -0.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638302206993103
Epoch 0, Step 265: train/loss = 0.6466147303581238, train/raw-loss = 0.6314541697502136, train/logprobs = tensor([[-1.0061, -1.5291],
        [-0.6491, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151605486869812
Epoch 0, Step 266: train/loss = 0.42304402589797974, train/raw-loss = 0.40615057945251465, train/logprobs = tensor([[-1.1738, -4.3143],
        [-0.9724, -1.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16893494129180908
Epoch 0, Step 267: train/loss = 0.4607231914997101, train/raw-loss = 0.44720426201820374, train/logprobs = tensor([[-0.7837, -3.0368],
        [-0.5297, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351887732744217
Epoch 0, Step 268: train/loss = 0.508448600769043, train/raw-loss = 0.4929197132587433, train/logprobs = tensor([[-0.7285, -5.5761],
        [-0.6805, -1.8931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15528887510299683
Epoch 0, Step 269: train/loss = 0.5072134137153625, train/raw-loss = 0.49302127957344055, train/logprobs = tensor([[-0.8633, -4.2269],
        [-0.7133, -1.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419210433959961
Epoch 0, Step 270: train/loss = 0.4789140820503235, train/raw-loss = 0.4671846032142639, train/logprobs = tensor([[-0.4663, -2.6405],
        [-0.3483, -0.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11729446053504944
Epoch 0, Step 271: train/loss = 0.5071280002593994, train/raw-loss = 0.492581844329834, train/logprobs = tensor([[-0.9116, -2.5299],
        [-0.6772, -0.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14546136558055878
Epoch 0, Step 272: train/loss = 0.6563460826873779, train/raw-loss = 0.6424349546432495, train/logprobs = tensor([[-0.6799, -0.9717],
        [-0.5551, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13911154866218567
Epoch 0, Step 273: train/loss = 0.5627530813217163, train/raw-loss = 0.5491751432418823, train/logprobs = tensor([[-0.5348, -1.5553],
        [-0.5131, -0.7581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13577929139137268
Epoch 0, Step 274: train/loss = 0.5857061147689819, train/raw-loss = 0.5700360536575317, train/logprobs = tensor([[-0.6712, -1.9839],
        [-0.5128, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15670078992843628
Epoch 0, Step 275: train/loss = 0.47041285037994385, train/raw-loss = 0.45940935611724854, train/logprobs = tensor([[-0.5397, -2.2611],
        [-0.4226, -0.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003461480140686
Epoch 0, Step 276: train/loss = 0.5619533658027649, train/raw-loss = 0.5426270365715027, train/logprobs = tensor([[-1.4383, -2.9780],
        [-1.1370, -1.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1932632476091385
Epoch 0, Step 277: train/loss = 0.5990520119667053, train/raw-loss = 0.5798462629318237, train/logprobs = tensor([[-0.8993, -1.4356],
        [-0.8239, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1920575499534607
Epoch 0, Step 278: train/loss = 0.5331288576126099, train/raw-loss = 0.5153595805168152, train/logprobs = tensor([[-0.9303, -1.8658],
        [-0.6712, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17769275605678558
Epoch 0, Step 279: train/loss = 0.425454318523407, train/raw-loss = 0.40848082304000854, train/logprobs = tensor([[-1.1283, -4.7281],
        [-0.6918, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1697346270084381
Epoch 0, Step 280: train/loss = 0.5136576890945435, train/raw-loss = 0.4987697899341583, train/logprobs = tensor([[-0.9376, -4.7213],
        [-0.6241, -1.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14887945353984833
Epoch 0, Step 281: train/loss = 0.5437225103378296, train/raw-loss = 0.5308494567871094, train/logprobs = tensor([[-0.6233, -1.4544],
        [-0.4620, -0.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12873026728630066
Epoch 0, Step 282: train/loss = 0.5818098783493042, train/raw-loss = 0.5577335953712463, train/logprobs = tensor([[-1.5291, -3.9409],
        [-0.9150, -1.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24076268076896667
Epoch 0, Step 283: train/loss = 0.49380433559417725, train/raw-loss = 0.4804230034351349, train/logprobs = tensor([[-0.8988, -2.7344],
        [-0.6047, -0.9726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13381345570087433
Epoch 0, Step 284: train/loss = 0.534843921661377, train/raw-loss = 0.5233834981918335, train/logprobs = tensor([[-0.5307, -1.6611],
        [-0.4586, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11460424959659576
Epoch 0, Step 285: train/loss = 0.5796807408332825, train/raw-loss = 0.5633898973464966, train/logprobs = tensor([[-0.6502, -1.3962],
        [-0.5534, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16290836036205292
Epoch 0, Step 286: train/loss = 0.5061261653900146, train/raw-loss = 0.49385690689086914, train/logprobs = tensor([[-0.4603, -2.0565],
        [-0.3429, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12269245088100433
Epoch 0, Step 287: train/loss = 0.4970301389694214, train/raw-loss = 0.47870224714279175, train/logprobs = tensor([[-0.8825, -4.4694],
        [-0.7691, -1.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327893316745758
Epoch 0, Step 288: train/loss = 0.521357536315918, train/raw-loss = 0.5076227188110352, train/logprobs = tensor([[-0.6341, -2.0252],
        [-0.5908, -0.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13734830915927887
Epoch 0, Step 289: train/loss = 0.5162221193313599, train/raw-loss = 0.5016108751296997, train/logprobs = tensor([[-0.9313, -3.5715],
        [-0.6989, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1461123824119568
Epoch 0, Step 290: train/loss = 0.5123559832572937, train/raw-loss = 0.4959142804145813, train/logprobs = tensor([[-0.6275, -3.3531],
        [-0.5892, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16441693902015686
Epoch 0, Step 291: train/loss = 0.4275659918785095, train/raw-loss = 0.41339603066444397, train/logprobs = tensor([[-0.7893, -2.8274],
        [-0.7220, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14169953763484955
Epoch 0, Step 292: train/loss = 0.5308491587638855, train/raw-loss = 0.5147432088851929, train/logprobs = tensor([[-0.6804, -1.7505],
        [-0.6600, -0.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16105955839157104
Epoch 0, Step 293: train/loss = 0.5288839340209961, train/raw-loss = 0.5127524137496948, train/logprobs = tensor([[-0.8654, -2.6387],
        [-0.7629, -1.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16131529211997986
Epoch 0, Step 294: train/loss = 0.5492722988128662, train/raw-loss = 0.534205436706543, train/logprobs = tensor([[-1.0749, -2.2066],
        [-0.7281, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066814422607422
Epoch 0, Step 295: train/loss = 0.5234569311141968, train/raw-loss = 0.5053478479385376, train/logprobs = tensor([[-1.8211, -3.5871],
        [-1.7172, -1.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18109150230884552
Epoch 0, Step 296: train/loss = 0.5593643188476562, train/raw-loss = 0.5469193458557129, train/logprobs = tensor([[-0.8124, -2.2091],
        [-0.6706, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12444932758808136
Epoch 0, Step 297: train/loss = 0.43921542167663574, train/raw-loss = 0.42423325777053833, train/logprobs = tensor([[-0.6821, -3.9893],
        [-0.6600, -1.1909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14982178807258606
Epoch 0, Step 298: train/loss = 0.5100660920143127, train/raw-loss = 0.49917471408843994, train/logprobs = tensor([[-0.6477, -1.9007],
        [-0.6521, -0.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1089136153459549
Epoch 0, Step 299: train/loss = 0.47102490067481995, train/raw-loss = 0.45607316493988037, train/logprobs = tensor([[-1.1256, -3.4199],
        [-0.8873, -0.7056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14951764047145844
Epoch 0, Step 300: train/loss = 0.4989055395126343, train/raw-loss = 0.48303818702697754, train/logprobs = tensor([[-0.8272, -3.0267],
        [-0.8234, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15867352485656738
Epoch 0, Step 301: train/loss = 0.5560900568962097, train/raw-loss = 0.5416039228439331, train/logprobs = tensor([[-0.7265, -1.4977],
        [-0.5874, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.144861102104187
Epoch 0, Step 302: train/loss = 0.46224647760391235, train/raw-loss = 0.447209894657135, train/logprobs = tensor([[-0.7133, -2.7017],
        [-0.6212, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1503656506538391
Epoch 0, Step 303: train/loss = 0.42041152715682983, train/raw-loss = 0.40506041049957275, train/logprobs = tensor([[-0.6142, -3.3566],
        [-0.6078, -0.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15351104736328125
Epoch 0, Step 304: train/loss = 0.516688346862793, train/raw-loss = 0.502517819404602, train/logprobs = tensor([[-0.6958, -2.0216],
        [-0.6378, -0.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417052447795868
Epoch 0, Step 305: train/loss = 0.5319678783416748, train/raw-loss = 0.517065703868866, train/logprobs = tensor([[-1.0687, -3.4042],
        [-0.5410, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14902213215827942
Epoch 0, Step 306: train/loss = 0.5558229684829712, train/raw-loss = 0.5386074781417847, train/logprobs = tensor([[-0.8888, -3.7748],
        [-0.7189, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17215459048748016
Epoch 0, Step 307: train/loss = 0.5323981642723083, train/raw-loss = 0.5143265724182129, train/logprobs = tensor([[-0.9436, -4.2826],
        [-0.9031, -1.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18071609735488892
Epoch 0, Step 308: train/loss = 0.5600006580352783, train/raw-loss = 0.5455929040908813, train/logprobs = tensor([[-0.7820, -1.6667],
        [-0.6397, -0.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14407767355442047
Epoch 0, Step 309: train/loss = 0.562493085861206, train/raw-loss = 0.5496978163719177, train/logprobs = tensor([[-0.5858, -1.7989],
        [-0.4677, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279524564743042
Epoch 0, Step 310: train/loss = 0.38528114557266235, train/raw-loss = 0.37002766132354736, train/logprobs = tensor([[-0.7859, -5.0239],
        [-0.5289, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525345891714096
Epoch 0, Step 311: train/loss = 0.5274844765663147, train/raw-loss = 0.5130749940872192, train/logprobs = tensor([[-0.6271, -3.0019],
        [-0.5988, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14409467577934265
Epoch 0, Step 312: train/loss = 0.567371129989624, train/raw-loss = 0.552665114402771, train/logprobs = tensor([[-0.7281, -3.5241],
        [-0.4842, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14705955982208252
Epoch 0, Step 313: train/loss = 0.4770231246948242, train/raw-loss = 0.46103835105895996, train/logprobs = tensor([[-0.7252, -2.7917],
        [-0.6742, -1.3533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1598476767539978
Epoch 0, Step 314: train/loss = 0.601930558681488, train/raw-loss = 0.5877935290336609, train/logprobs = tensor([[-0.7025, -1.0903],
        [-0.5613, -0.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1413702368736267
Epoch 0, Step 315: train/loss = 0.5693402290344238, train/raw-loss = 0.5526013374328613, train/logprobs = tensor([[-2.2675, -4.2753],
        [-1.6965, -2.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16738897562026978
Epoch 0, Step 316: train/loss = 0.6888229846954346, train/raw-loss = 0.6719751954078674, train/logprobs = tensor([[-0.8301, -0.7954],
        [-0.8332, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16847801208496094
Epoch 0, Step 317: train/loss = 0.4114646911621094, train/raw-loss = 0.3988111913204193, train/logprobs = tensor([[-0.5187, -5.1719],
        [-0.4898, -1.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12653496861457825
Epoch 0, Step 318: train/loss = 0.44517746567726135, train/raw-loss = 0.4313066601753235, train/logprobs = tensor([[-0.8456, -3.2364],
        [-0.7341, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13870811462402344
Epoch 0, Step 319: train/loss = 0.45362719893455505, train/raw-loss = 0.4405462145805359, train/logprobs = tensor([[-0.6209, -3.1275],
        [-0.5890, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080978393554688
Epoch 0, Step 320: train/loss = 0.503750205039978, train/raw-loss = 0.4892151355743408, train/logprobs = tensor([[-0.9429, -3.1050],
        [-0.6555, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1453506201505661
Epoch 0, Step 321: train/loss = 0.5264275670051575, train/raw-loss = 0.5139763355255127, train/logprobs = tensor([[-0.6979, -1.9031],
        [-0.6035, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12451232969760895
Epoch 0, Step 322: train/loss = 0.450216680765152, train/raw-loss = 0.43593844771385193, train/logprobs = tensor([[-1.1128, -4.4389],
        [-0.8755, -1.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427822858095169
Epoch 0, Step 323: train/loss = 0.4929780960083008, train/raw-loss = 0.4800218939781189, train/logprobs = tensor([[-0.4811, -2.5709],
        [-0.4508, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12956227362155914
Epoch 0, Step 324: train/loss = 0.3548738360404968, train/raw-loss = 0.34095582365989685, train/logprobs = tensor([[-0.8781, -5.8880],
        [-0.6591, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13917987048625946
Epoch 0, Step 325: train/loss = 0.5920760035514832, train/raw-loss = 0.5776787996292114, train/logprobs = tensor([[-0.6880, -1.3561],
        [-0.6102, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14397239685058594
Epoch 0, Step 326: train/loss = 0.39054521918296814, train/raw-loss = 0.3751985430717468, train/logprobs = tensor([[-0.9455, -5.2418],
        [-0.9318, -1.7026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534668356180191
Epoch 0, Step 327: train/loss = 0.7038426995277405, train/raw-loss = 0.6820328235626221, train/logprobs = tensor([[-0.9898, -1.2345],
        [-0.7143, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21809861063957214
Epoch 0, Step 328: train/loss = 0.6049032211303711, train/raw-loss = 0.5899537205696106, train/logprobs = tensor([[-0.9539, -1.9053],
        [-0.9082, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949464797973633
Epoch 0, Step 329: train/loss = 0.5955625772476196, train/raw-loss = 0.5797337293624878, train/logprobs = tensor([[-1.1923, -1.8307],
        [-0.8940, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15828834474086761
Epoch 0, Step 330: train/loss = 0.3411308526992798, train/raw-loss = 0.32692867517471313, train/logprobs = tensor([[-0.7771, -4.9927],
        [-0.6627, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14202174544334412
Epoch 0, Step 331: train/loss = 0.45718517899513245, train/raw-loss = 0.445024311542511, train/logprobs = tensor([[-0.6887, -4.2861],
        [-0.6282, -1.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12160845100879669
Epoch 0, Step 332: train/loss = 0.40713751316070557, train/raw-loss = 0.39085590839385986, train/logprobs = tensor([[-0.8753, -4.4383],
        [-0.8992, -1.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16281598806381226
Epoch 0, Step 333: train/loss = 0.5016406774520874, train/raw-loss = 0.487771213054657, train/logprobs = tensor([[-0.8697, -3.0543],
        [-0.6006, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13869449496269226
Epoch 0, Step 334: train/loss = 0.625205397605896, train/raw-loss = 0.6122938990592957, train/logprobs = tensor([[-0.8135, -1.0543],
        [-0.6517, -0.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12911540269851685
Epoch 0, Step 335: train/loss = 0.4229804277420044, train/raw-loss = 0.4083004593849182, train/logprobs = tensor([[-0.7224, -2.7794],
        [-0.5719, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14679956436157227
Epoch 0, Step 336: train/loss = 0.5046124458312988, train/raw-loss = 0.4893009662628174, train/logprobs = tensor([[-0.6142, -1.9490],
        [-0.6153, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15311434864997864
Epoch 0, Step 337: train/loss = 0.4908713102340698, train/raw-loss = 0.4751344323158264, train/logprobs = tensor([[-0.9940, -2.5374],
        [-0.8430, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1573687195777893
Epoch 0, Step 338: train/loss = 0.47305968403816223, train/raw-loss = 0.4598711431026459, train/logprobs = tensor([[-0.6057, -1.9490],
        [-0.5599, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13188540935516357
Epoch 0, Step 339: train/loss = 0.4457307457923889, train/raw-loss = 0.4330672025680542, train/logprobs = tensor([[-0.4130, -4.5976],
        [-0.4057, -1.6656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12663526833057404
Epoch 0, Step 340: train/loss = 0.6171137094497681, train/raw-loss = 0.6035995483398438, train/logprobs = tensor([[-0.9371, -1.6498],
        [-0.6787, -0.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13514122366905212
Epoch 0, Step 341: train/loss = 0.3738638162612915, train/raw-loss = 0.3600747883319855, train/logprobs = tensor([[-0.6869, -3.5864],
        [-0.6920, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13789014518260956
Epoch 0, Step 342: train/loss = 0.4887261688709259, train/raw-loss = 0.474861204624176, train/logprobs = tensor([[-0.6226, -3.0344],
        [-0.6409, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386493295431137
Epoch 0, Step 343: train/loss = 0.5699464082717896, train/raw-loss = 0.5566689968109131, train/logprobs = tensor([[-0.7555, -2.3445],
        [-0.6984, -1.4109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13277368247509003
Epoch 0, Step 344: train/loss = 0.4285150170326233, train/raw-loss = 0.41385358572006226, train/logprobs = tensor([[-1.0486, -6.2399],
        [-0.8524, -1.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14661435782909393
Epoch 0, Step 345: train/loss = 0.49452000856399536, train/raw-loss = 0.47911614179611206, train/logprobs = tensor([[-1.2759, -4.3687],
        [-1.0849, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1540387123823166
Epoch 0, Step 346: train/loss = 0.512413501739502, train/raw-loss = 0.49479857087135315, train/logprobs = tensor([[-0.8669, -4.1622],
        [-0.7573, -1.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1761496663093567
Epoch 0, Step 347: train/loss = 0.4976855516433716, train/raw-loss = 0.4845406413078308, train/logprobs = tensor([[-0.6812, -4.5952],
        [-0.6750, -1.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314493715763092
Epoch 0, Step 348: train/loss = 0.49981188774108887, train/raw-loss = 0.4868166148662567, train/logprobs = tensor([[-0.7775, -3.5815],
        [-0.7830, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12995295226573944
Epoch 0, Step 349: train/loss = 0.38089117407798767, train/raw-loss = 0.3652501702308655, train/logprobs = tensor([[-0.7683, -3.5320],
        [-0.6994, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15641003847122192
Epoch 0, Step 350: train/loss = 0.58186936378479, train/raw-loss = 0.5632081031799316, train/logprobs = tensor([[-1.4647, -2.9266],
        [-1.1614, -1.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18661239743232727
Epoch 0, Step 351: train/loss = 0.511236846446991, train/raw-loss = 0.495467871427536, train/logprobs = tensor([[-0.8416, -2.9119],
        [-0.7600, -1.2235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15768998861312866
Epoch 0, Step 352: train/loss = 0.42615312337875366, train/raw-loss = 0.4143897294998169, train/logprobs = tensor([[-0.5136, -4.0885],
        [-0.5953, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1176336333155632
Epoch 0, Step 353: train/loss = 0.3825960159301758, train/raw-loss = 0.36782872676849365, train/logprobs = tensor([[-0.7653, -4.7960],
        [-0.8532, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14767318964004517
Epoch 0, Step 354: train/loss = 0.6081593036651611, train/raw-loss = 0.5960040092468262, train/logprobs = tensor([[-0.5197, -1.0690],
        [-0.5500, -0.6420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12155358493328094
Epoch 0, Step 355: train/loss = 0.4987029433250427, train/raw-loss = 0.4825271964073181, train/logprobs = tensor([[-0.7537, -2.6338],
        [-0.8172, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617574691772461
Epoch 0, Step 356: train/loss = 0.5929983854293823, train/raw-loss = 0.579404354095459, train/logprobs = tensor([[-0.5540, -1.2212],
        [-0.5206, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13594044744968414
Epoch 0, Step 357: train/loss = 0.6374661922454834, train/raw-loss = 0.6184731721878052, train/logprobs = tensor([[-2.0973, -2.7751],
        [-1.7760, -1.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18993014097213745
Epoch 0, Step 358: train/loss = 0.517898678779602, train/raw-loss = 0.5062238574028015, train/logprobs = tensor([[-0.5888, -4.2184],
        [-0.5126, -1.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11674834042787552
Epoch 0, Step 359: train/loss = 0.5742223858833313, train/raw-loss = 0.5591016411781311, train/logprobs = tensor([[-1.0365, -2.2676],
        [-0.8796, -0.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15120775997638702
Epoch 0, Step 360: train/loss = 0.5259695649147034, train/raw-loss = 0.5090487599372864, train/logprobs = tensor([[-0.9666, -2.7871],
        [-0.8906, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1692078709602356
Epoch 0, Step 361: train/loss = 0.5402679443359375, train/raw-loss = 0.525429368019104, train/logprobs = tensor([[-0.6890, -1.4011],
        [-0.7245, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1483851671218872
Epoch 0, Step 362: train/loss = 0.5735852122306824, train/raw-loss = 0.5603017210960388, train/logprobs = tensor([[-0.7247, -1.9307],
        [-0.7284, -0.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13283514976501465
Epoch 0, Step 363: train/loss = 0.7269947528839111, train/raw-loss = 0.71358323097229, train/logprobs = tensor([[-1.3537, -1.2403],
        [-0.9114, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13411571085453033
Epoch 0, Step 364: train/loss = 0.3740006387233734, train/raw-loss = 0.3621782660484314, train/logprobs = tensor([[-0.4488, -5.5715],
        [-0.5667, -1.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11822348833084106
Epoch 0, Step 365: train/loss = 0.41557222604751587, train/raw-loss = 0.4026545584201813, train/logprobs = tensor([[-0.6015, -2.8289],
        [-0.6252, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1291765719652176
Epoch 0, Step 366: train/loss = 0.5112998485565186, train/raw-loss = 0.4968547821044922, train/logprobs = tensor([[-0.6546, -2.9927],
        [-0.6251, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444505900144577
Epoch 0, Step 367: train/loss = 0.4165937006473541, train/raw-loss = 0.40379273891448975, train/logprobs = tensor([[-0.6109, -3.7605],
        [-0.7071, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12800973653793335
Epoch 0, Step 368: train/loss = 0.46958261728286743, train/raw-loss = 0.4552065134048462, train/logprobs = tensor([[-0.4601, -2.7985],
        [-0.4755, -1.2004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14376109838485718
Epoch 0, Step 369: train/loss = 0.4759241044521332, train/raw-loss = 0.4621327519416809, train/logprobs = tensor([[-0.4681, -2.0729],
        [-0.5539, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379132866859436
Epoch 0, Step 370: train/loss = 0.6292226314544678, train/raw-loss = 0.6180607676506042, train/logprobs = tensor([[-0.4510, -0.8629],
        [-0.4466, -0.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161879450082779
Epoch 0, Step 371: train/loss = 0.47294366359710693, train/raw-loss = 0.461464524269104, train/logprobs = tensor([[-0.4359, -3.5831],
        [-0.4658, -1.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11479123681783676
Epoch 0, Step 372: train/loss = 0.4212833046913147, train/raw-loss = 0.4095590114593506, train/logprobs = tensor([[-0.5874, -3.5276],
        [-0.5874, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11724326759576797
Epoch 0, Step 373: train/loss = 0.5289305448532104, train/raw-loss = 0.5114047527313232, train/logprobs = tensor([[-0.9222, -4.6366],
        [-0.7636, -1.5694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17525716125965118
Epoch 0, Step 374: train/loss = 0.5091553926467896, train/raw-loss = 0.49811041355133057, train/logprobs = tensor([[-0.3492, -2.5365],
        [-0.3593, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11045025289058685
Epoch 0, Step 375: train/loss = 0.48605427145957947, train/raw-loss = 0.4703443944454193, train/logprobs = tensor([[-0.8224, -1.7271],
        [-0.9596, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15709853172302246
Epoch 0, Step 376: train/loss = 0.4040853977203369, train/raw-loss = 0.38809120655059814, train/logprobs = tensor([[-0.6874, -4.9761],
        [-0.8764, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15994203090667725
Epoch 0, Step 377: train/loss = 0.556576132774353, train/raw-loss = 0.5399085283279419, train/logprobs = tensor([[-0.7007, -3.1319],
        [-0.6228, -0.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16667614877223969
Epoch 0, Step 378: train/loss = 0.5228514075279236, train/raw-loss = 0.5099409222602844, train/logprobs = tensor([[-0.7767, -3.7785],
        [-0.7336, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12910450994968414
Epoch 0, Step 379: train/loss = 0.5967152118682861, train/raw-loss = 0.5810300707817078, train/logprobs = tensor([[-1.0112, -2.3222],
        [-0.9519, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15685150027275085
Epoch 0, Step 380: train/loss = 0.4953801929950714, train/raw-loss = 0.47972965240478516, train/logprobs = tensor([[-0.6647, -2.1121],
        [-0.6661, -0.7296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15650531649589539
Epoch 0, Step 381: train/loss = 0.4259941577911377, train/raw-loss = 0.41070711612701416, train/logprobs = tensor([[-0.7314, -3.9878],
        [-0.8943, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15287062525749207
Epoch 0, Step 382: train/loss = 0.37328580021858215, train/raw-loss = 0.361835241317749, train/logprobs = tensor([[-0.6690, -4.0327],
        [-0.6118, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1145055890083313
Epoch 0, Step 383: train/loss = 0.4018975496292114, train/raw-loss = 0.38759520649909973, train/logprobs = tensor([[-0.5134, -2.8827],
        [-0.6399, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14302368462085724
Epoch 0, Step 384: train/loss = 0.4584715664386749, train/raw-loss = 0.4414411783218384, train/logprobs = tensor([[-0.8248, -6.0116],
        [-1.0274, -1.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17030397057533264
Epoch 0, Step 385: train/loss = 0.5474456548690796, train/raw-loss = 0.5260058641433716, train/logprobs = tensor([[-1.2787, -2.3654],
        [-1.1282, -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21439774334430695
Epoch 0, Step 386: train/loss = 0.6693909764289856, train/raw-loss = 0.6521110534667969, train/logprobs = tensor([[-0.9016, -0.9592],
        [-0.8456, -0.7139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17279939353466034
Epoch 0, Step 387: train/loss = 0.472903311252594, train/raw-loss = 0.45585548877716064, train/logprobs = tensor([[-0.7199, -5.3025],
        [-0.9018, -1.1755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17047801613807678
Epoch 0, Step 388: train/loss = 0.512286365032196, train/raw-loss = 0.4924895167350769, train/logprobs = tensor([[-0.7967, -2.4767],
        [-0.9114, -1.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1979687362909317
Epoch 0, Step 389: train/loss = 0.42148178815841675, train/raw-loss = 0.4045273959636688, train/logprobs = tensor([[-0.6609, -2.8665],
        [-0.7514, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16954392194747925
Epoch 0, Step 390: train/loss = 0.44598060846328735, train/raw-loss = 0.427362322807312, train/logprobs = tensor([[-1.1759, -2.8234],
        [-1.4183, -1.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1861824095249176
Epoch 0, Step 391: train/loss = 0.49838513135910034, train/raw-loss = 0.48249951004981995, train/logprobs = tensor([[-0.5006, -2.1523],
        [-0.5389, -0.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588565707206726
Epoch 0, Step 392: train/loss = 0.4131140112876892, train/raw-loss = 0.39960917830467224, train/logprobs = tensor([[-0.5156, -3.4604],
        [-0.6667, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350483000278473
Epoch 0, Step 393: train/loss = 0.5330139994621277, train/raw-loss = 0.5153740644454956, train/logprobs = tensor([[-0.9208, -2.3446],
        [-0.6881, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17639923095703125
Epoch 0, Step 394: train/loss = 0.4185732305049896, train/raw-loss = 0.40198254585266113, train/logprobs = tensor([[-0.9889, -7.1128],
        [-0.8785, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16590642929077148
Epoch 0, Step 395: train/loss = 0.48197177052497864, train/raw-loss = 0.4688137471675873, train/logprobs = tensor([[-0.7678, -6.1160],
        [-0.5139, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13158054649829865
Epoch 0, Step 396: train/loss = 0.5314904451370239, train/raw-loss = 0.5149797201156616, train/logprobs = tensor([[-0.8182, -2.1241],
        [-0.8051, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16510708630084991
Epoch 0, Step 397: train/loss = 0.5174302458763123, train/raw-loss = 0.5024538040161133, train/logprobs = tensor([[-0.5319, -2.5922],
        [-0.4944, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14976446330547333
Epoch 0, Step 398: train/loss = 0.3624560236930847, train/raw-loss = 0.3469862937927246, train/logprobs = tensor([[-0.6105, -4.0836],
        [-0.7564, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546977460384369
Epoch 0, Step 399: train/loss = 0.5724078416824341, train/raw-loss = 0.5528101921081543, train/logprobs = tensor([[-0.9187, -1.4913],
        [-1.0299, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1959761083126068
Epoch 0, Step 400: train/loss = 0.5457866787910461, train/raw-loss = 0.5322234034538269, train/logprobs = tensor([[-0.5533, -1.4422],
        [-0.6208, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356327086687088
Epoch 0, Step 401: train/loss = 0.418043315410614, train/raw-loss = 0.4020841717720032, train/logprobs = tensor([[-0.9542, -4.0151],
        [-0.9374, -1.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15959158539772034
Epoch 0, Step 402: train/loss = 0.4154130816459656, train/raw-loss = 0.3995341658592224, train/logprobs = tensor([[-0.7245, -3.7903],
        [-0.7326, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1587890088558197
Epoch 0, Step 403: train/loss = 0.5175602436065674, train/raw-loss = 0.5071929693222046, train/logprobs = tensor([[-0.3490, -1.9268],
        [-0.3874, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1036723330616951
Epoch 0, Step 404: train/loss = 0.6291654706001282, train/raw-loss = 0.614564061164856, train/logprobs = tensor([[-0.6150, -1.2836],
        [-0.5912, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14601342380046844
Epoch 0, Step 405: train/loss = 0.5356548428535461, train/raw-loss = 0.5234512090682983, train/logprobs = tensor([[-0.5064, -3.6022],
        [-0.5988, -0.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12203633785247803
Epoch 0, Step 406: train/loss = 0.520392894744873, train/raw-loss = 0.5067019462585449, train/logprobs = tensor([[-0.6187, -2.3525],
        [-0.5957, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13690976798534393
Epoch 0, Step 407: train/loss = 0.5724089741706848, train/raw-loss = 0.56166672706604, train/logprobs = tensor([[-0.5411, -1.1835],
        [-0.5688, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10742245614528656
Epoch 0, Step 408: train/loss = 0.5544359683990479, train/raw-loss = 0.5391354560852051, train/logprobs = tensor([[-0.6254, -1.2386],
        [-0.8832, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15300440788269043
Epoch 0, Step 409: train/loss = 0.296326220035553, train/raw-loss = 0.2799168825149536, train/logprobs = tensor([[-0.9083, -5.1069],
        [-1.2712, -1.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16409343481063843
Epoch 0, Step 410: train/loss = 0.5549511313438416, train/raw-loss = 0.5385209321975708, train/logprobs = tensor([[-0.5989, -2.1582],
        [-0.6095, -1.2818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16430196166038513
Epoch 0, Step 411: train/loss = 0.4963938593864441, train/raw-loss = 0.47856324911117554, train/logprobs = tensor([[-0.5400, -1.9774],
        [-0.6279, -0.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17830601334571838
Epoch 0, Step 412: train/loss = 0.5534520149230957, train/raw-loss = 0.5399609804153442, train/logprobs = tensor([[-0.4980, -1.6782],
        [-0.6193, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13490986824035645
Epoch 0, Step 413: train/loss = 0.5358949899673462, train/raw-loss = 0.5217247009277344, train/logprobs = tensor([[-0.7986, -4.2355],
        [-0.7209, -1.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14170309901237488
Epoch 0, Step 414: train/loss = 0.4659895896911621, train/raw-loss = 0.45396673679351807, train/logprobs = tensor([[-0.4302, -1.9416],
        [-0.5999, -0.5015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12022878229618073
Epoch 0, Step 415: train/loss = 0.4377661347389221, train/raw-loss = 0.4229108691215515, train/logprobs = tensor([[-0.8322, -4.3984],
        [-0.9520, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14855262637138367
Epoch 0, Step 416: train/loss = 0.5874060988426208, train/raw-loss = 0.5672809481620789, train/logprobs = tensor([[-0.7737, -1.6412],
        [-0.7775, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20125164091587067
Epoch 0, Step 417: train/loss = 0.39930111169815063, train/raw-loss = 0.38138240575790405, train/logprobs = tensor([[-0.6981, -4.8420],
        [-1.0017, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1791868954896927
Epoch 0, Step 418: train/loss = 0.39604514837265015, train/raw-loss = 0.37904196977615356, train/logprobs = tensor([[-0.6677, -2.8237],
        [-0.9951, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17003139853477478
Epoch 0, Step 419: train/loss = 0.48001906275749207, train/raw-loss = 0.4626234769821167, train/logprobs = tensor([[-1.0460, -3.1716],
        [-0.9561, -1.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17395560443401337
Epoch 0, Step 420: train/loss = 0.47263702750205994, train/raw-loss = 0.4541092813014984, train/logprobs = tensor([[-0.8001, -3.2812],
        [-0.9048, -0.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852772831916809
Epoch 0, Step 421: train/loss = 0.3715912699699402, train/raw-loss = 0.3515332043170929, train/logprobs = tensor([[-0.6991, -2.7724],
        [-1.0612, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005806714296341
Epoch 0, Step 422: train/loss = 0.37628209590911865, train/raw-loss = 0.35415035486221313, train/logprobs = tensor([[-1.0928, -4.8408],
        [-1.1578, -1.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22131767868995667
Epoch 0, Step 423: train/loss = 0.491050660610199, train/raw-loss = 0.47476691007614136, train/logprobs = tensor([[-0.6617, -3.3226],
        [-0.6330, -0.7371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16283777356147766
Epoch 0, Step 424: train/loss = 0.37064895033836365, train/raw-loss = 0.35464170575141907, train/logprobs = tensor([[-0.6936, -4.5751],
        [-0.8519, -1.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16007253527641296
Epoch 0, Step 425: train/loss = 0.8265984058380127, train/raw-loss = 0.8115839958190918, train/logprobs = tensor([[-2.0251, -3.3919],
        [-0.8161, -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15014341473579407
Epoch 0, Step 426: train/loss = 0.4145628809928894, train/raw-loss = 0.39374440908432007, train/logprobs = tensor([[-0.9302, -3.2011],
        [-1.0893, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2081843614578247
Epoch 0, Step 427: train/loss = 0.39267176389694214, train/raw-loss = 0.3736773431301117, train/logprobs = tensor([[-0.6152, -3.0247],
        [-0.7548, -0.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18994387984275818
Epoch 0, Step 428: train/loss = 0.7726643085479736, train/raw-loss = 0.7536977529525757, train/logprobs = tensor([[-1.3039, -1.3997],
        [-0.7065, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1896657645702362
Epoch 0, Step 429: train/loss = 0.3749120831489563, train/raw-loss = 0.35944679379463196, train/logprobs = tensor([[-0.6214, -3.0997],
        [-0.8405, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546524167060852
Epoch 0, Step 430: train/loss = 0.4987453818321228, train/raw-loss = 0.4833627939224243, train/logprobs = tensor([[-0.6954, -3.4654],
        [-0.6884, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15382595360279083
Epoch 0, Step 431: train/loss = 0.45621412992477417, train/raw-loss = 0.43829894065856934, train/logprobs = tensor([[-0.6984, -1.7355],
        [-0.8624, -0.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17915159463882446
Epoch 0, Step 432: train/loss = 0.5508927702903748, train/raw-loss = 0.5311679840087891, train/logprobs = tensor([[-0.7666, -1.3412],
        [-1.0147, -0.7297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19724799692630768
Epoch 0, Step 433: train/loss = 0.5313056707382202, train/raw-loss = 0.5164228081703186, train/logprobs = tensor([[-0.7423, -1.8755],
        [-0.7460, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488284319639206
Epoch 0, Step 434: train/loss = 0.3346051871776581, train/raw-loss = 0.3136351406574249, train/logprobs = tensor([[-0.9204, -5.2282],
        [-0.9479, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20970025658607483
Epoch 0, Step 435: train/loss = 0.5298373103141785, train/raw-loss = 0.5065934062004089, train/logprobs = tensor([[-1.5801, -3.4960],
        [-1.0586, -1.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23243921995162964
Epoch 0, Step 436: train/loss = 0.43005645275115967, train/raw-loss = 0.41185811161994934, train/logprobs = tensor([[-0.9034, -4.3368],
        [-1.1163, -1.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18198372423648834
Epoch 0, Step 437: train/loss = 0.4297521710395813, train/raw-loss = 0.4104640483856201, train/logprobs = tensor([[-0.7186, -3.6498],
        [-0.8755, -1.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19288146495819092
Epoch 0, Step 438: train/loss = 0.47627004981040955, train/raw-loss = 0.46068280935287476, train/logprobs = tensor([[-0.5439, -2.7537],
        [-0.6559, -0.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155872642993927
Epoch 0, Step 439: train/loss = 0.5586715340614319, train/raw-loss = 0.5421876907348633, train/logprobs = tensor([[-0.5471, -1.2880],
        [-0.6244, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16483783721923828
Epoch 0, Step 440: train/loss = 0.6053633689880371, train/raw-loss = 0.5881779789924622, train/logprobs = tensor([[-1.0076, -2.0091],
        [-0.6493, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1718536913394928
Epoch 0, Step 441: train/loss = 0.6490359306335449, train/raw-loss = 0.6335495710372925, train/logprobs = tensor([[-1.1216, -1.7517],
        [-0.7330, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15486344695091248
Epoch 0, Step 442: train/loss = 0.5714638829231262, train/raw-loss = 0.5503993034362793, train/logprobs = tensor([[-0.5474, -1.2964],
        [-0.6408, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2106456309556961
Epoch 0, Step 443: train/loss = 0.7363954782485962, train/raw-loss = 0.7177073955535889, train/logprobs = tensor([[-1.8471, -1.5872],
        [-1.2843, -0.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18688073754310608
Epoch 0, Step 444: train/loss = 0.4605630040168762, train/raw-loss = 0.44039469957351685, train/logprobs = tensor([[-1.1191, -2.9377],
        [-0.8182, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20168304443359375
Epoch 0, Step 445: train/loss = 0.4157160222530365, train/raw-loss = 0.3977051079273224, train/logprobs = tensor([[-0.7440, -3.6863],
        [-0.8037, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801091432571411
Epoch 0, Step 446: train/loss = 0.5024426579475403, train/raw-loss = 0.48559415340423584, train/logprobs = tensor([[-0.9701, -2.5048],
        [-0.8624, -0.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1684853434562683
Epoch 0, Step 447: train/loss = 0.3762878179550171, train/raw-loss = 0.35773715376853943, train/logprobs = tensor([[-1.1048, -6.1354],
        [-0.8744, -1.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18550680577754974
Epoch 0, Step 448: train/loss = 0.35785171389579773, train/raw-loss = 0.3400864005088806, train/logprobs = tensor([[-0.6515, -5.9040],
        [-0.8502, -1.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1776534616947174
Epoch 0, Step 449: train/loss = 0.6120983362197876, train/raw-loss = 0.5956836342811584, train/logprobs = tensor([[-0.8741, -1.9607],
        [-0.7967, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16414684057235718
Epoch 0, Step 450: train/loss = 0.574672520160675, train/raw-loss = 0.5545769333839417, train/logprobs = tensor([[-1.0551, -2.0998],
        [-1.1355, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20095571875572205
Epoch 0, Step 451: train/loss = 0.5037062168121338, train/raw-loss = 0.48356857895851135, train/logprobs = tensor([[-0.8076, -1.7485],
        [-0.9491, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2013765126466751
Epoch 0, Step 452: train/loss = 0.34763920307159424, train/raw-loss = 0.32928597927093506, train/logprobs = tensor([[-0.8080, -6.9222],
        [-1.0976, -1.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18353202939033508
Epoch 0, Step 453: train/loss = 0.3388252258300781, train/raw-loss = 0.3227706253528595, train/logprobs = tensor([[-0.6535, -4.7474],
        [-1.0028, -1.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16054627299308777
Epoch 0, Step 454: train/loss = 0.5337122082710266, train/raw-loss = 0.5208795070648193, train/logprobs = tensor([[-0.4050, -2.8744],
        [-0.4680, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12832680344581604
Epoch 0, Step 455: train/loss = 0.36305883526802063, train/raw-loss = 0.34569767117500305, train/logprobs = tensor([[-0.7741, -3.9874],
        [-1.0432, -0.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17361167073249817
Epoch 0, Step 456: train/loss = 0.596183180809021, train/raw-loss = 0.5716149210929871, train/logprobs = tensor([[-0.9145, -1.6021],
        [-1.0461, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24568235874176025
Epoch 0, Step 457: train/loss = 0.39381104707717896, train/raw-loss = 0.3729609549045563, train/logprobs = tensor([[-0.5889, -3.1382],
        [-0.9276, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2085011899471283
Epoch 0, Step 458: train/loss = 0.37233006954193115, train/raw-loss = 0.3539402186870575, train/logprobs = tensor([[-0.6461, -5.7108],
        [-0.8417, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18389810621738434
Epoch 0, Step 459: train/loss = 0.3976415693759918, train/raw-loss = 0.3777531087398529, train/logprobs = tensor([[-0.7590, -3.2510],
        [-0.9137, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1988845020532608
Epoch 0, Step 460: train/loss = 0.4444735050201416, train/raw-loss = 0.4249347746372223, train/logprobs = tensor([[-0.7670, -3.6621],
        [-0.8904, -0.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19538770616054535
Epoch 0, Step 461: train/loss = 0.43750202655792236, train/raw-loss = 0.4198760390281677, train/logprobs = tensor([[-1.1225, -3.6553],
        [-1.0296, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1762601137161255
Epoch 0, Step 462: train/loss = 0.4579097032546997, train/raw-loss = 0.43743807077407837, train/logprobs = tensor([[-0.8872, -2.1804],
        [-1.1236, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20471568405628204
Epoch 0, Step 463: train/loss = 0.4688812792301178, train/raw-loss = 0.449527770280838, train/logprobs = tensor([[-0.8861, -2.3764],
        [-1.2920, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19353514909744263
Epoch 0, Step 464: train/loss = 0.34210121631622314, train/raw-loss = 0.321769654750824, train/logprobs = tensor([[-0.5615, -4.6251],
        [-0.9599, -1.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033156007528305
Epoch 0, Step 465: train/loss = 0.486467182636261, train/raw-loss = 0.4679263234138489, train/logprobs = tensor([[-0.6221, -1.8330],
        [-1.0113, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1854083389043808
Epoch 0, Step 466: train/loss = 0.5841493606567383, train/raw-loss = 0.5661897659301758, train/logprobs = tensor([[-1.1688, -2.5726],
        [-1.0883, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179595947265625
Epoch 0, Step 467: train/loss = 0.5492713451385498, train/raw-loss = 0.5324731469154358, train/logprobs = tensor([[-1.0069, -2.6388],
        [-0.7977, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16798172891139984
Epoch 0, Step 468: train/loss = 0.2369726598262787, train/raw-loss = 0.2146310806274414, train/logprobs = tensor([[-0.6716, -4.3411],
        [-1.4061, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341565787792206
Epoch 0, Step 469: train/loss = 0.5539023280143738, train/raw-loss = 0.53752201795578, train/logprobs = tensor([[-0.5408, -1.9100],
        [-0.9056, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16380327939987183
Epoch 0, Step 470: train/loss = 0.5394605398178101, train/raw-loss = 0.5182484984397888, train/logprobs = tensor([[-0.8043, -2.3996],
        [-0.6647, -1.1498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21212026476860046
Epoch 0, Step 471: train/loss = 0.3203747272491455, train/raw-loss = 0.30485114455223083, train/logprobs = tensor([[-0.4817, -4.7817],
        [-0.7107, -1.3068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15523600578308105
Epoch 0, Step 472: train/loss = 0.46896347403526306, train/raw-loss = 0.452426552772522, train/logprobs = tensor([[-0.5396, -3.6185],
        [-0.7450, -0.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16536898910999298
Epoch 0, Step 473: train/loss = 0.44296640157699585, train/raw-loss = 0.4222753942012787, train/logprobs = tensor([[-1.2400, -5.5662],
        [-0.9799, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20691008865833282
Epoch 0, Step 474: train/loss = 0.44245123863220215, train/raw-loss = 0.4252609312534332, train/logprobs = tensor([[-0.6138, -2.9590],
        [-0.8700, -0.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17190346121788025
Epoch 0, Step 475: train/loss = 0.3283664882183075, train/raw-loss = 0.3089386820793152, train/logprobs = tensor([[-0.7933, -5.1449],
        [-0.9234, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19427798688411713
Epoch 0, Step 476: train/loss = 0.4595634937286377, train/raw-loss = 0.4438020884990692, train/logprobs = tensor([[-0.4998, -2.3354],
        [-0.5167, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15761443972587585
Epoch 0, Step 477: train/loss = 0.44397637248039246, train/raw-loss = 0.42291271686553955, train/logprobs = tensor([[-0.6583, -4.3039],
        [-0.7307, -1.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21063627302646637
Epoch 0, Step 478: train/loss = 0.31173989176750183, train/raw-loss = 0.2918442487716675, train/logprobs = tensor([[-0.9016, -7.3277],
        [-0.9789, -1.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19895657896995544
Epoch 0, Step 479: train/loss = 0.4932135045528412, train/raw-loss = 0.48054930567741394, train/logprobs = tensor([[-0.3870, -3.8395],
        [-0.5643, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664173543453217
Epoch 0, Step 480: train/loss = 0.6134299635887146, train/raw-loss = 0.5971425175666809, train/logprobs = tensor([[-0.4866, -1.2545],
        [-0.6424, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16287432610988617
Epoch 0, Step 481: train/loss = 0.28337448835372925, train/raw-loss = 0.25973421335220337, train/logprobs = tensor([[-0.9377, -5.6471],
        [-1.2703, -1.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23640288412570953
Epoch 0, Step 482: train/loss = 0.5004186034202576, train/raw-loss = 0.48174023628234863, train/logprobs = tensor([[-0.7099, -1.3762],
        [-1.1453, -0.6435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18678317964076996
Epoch 0, Step 483: train/loss = 0.4475820064544678, train/raw-loss = 0.430078387260437, train/logprobs = tensor([[-0.5059, -3.6666],
        [-0.8638, -0.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17503641545772552
Epoch 0, Step 484: train/loss = 0.4453350901603699, train/raw-loss = 0.42595452070236206, train/logprobs = tensor([[-0.6055, -2.8572],
        [-0.8576, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1938057541847229
Epoch 0, Step 485: train/loss = 0.2539274990558624, train/raw-loss = 0.232118159532547, train/logprobs = tensor([[-1.0724, -7.1095],
        [-1.7068, -1.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21809369325637817
Epoch 0, Step 486: train/loss = 0.6030678749084473, train/raw-loss = 0.587594747543335, train/logprobs = tensor([[-0.5082, -1.1558],
        [-0.7428, -0.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15473173558712006
Epoch 0, Step 487: train/loss = 0.48797279596328735, train/raw-loss = 0.4721446633338928, train/logprobs = tensor([[-1.0329, -3.3090],
        [-1.0998, -0.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15828098356723785
Epoch 0, Step 488: train/loss = 0.4385949671268463, train/raw-loss = 0.42041221261024475, train/logprobs = tensor([[-0.6323, -5.2030],
        [-0.7945, -1.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18182745575904846
Epoch 0, Step 489: train/loss = 0.3512103855609894, train/raw-loss = 0.33151644468307495, train/logprobs = tensor([[-0.6123, -6.0923],
        [-1.1959, -1.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1969394087791443
Epoch 0, Step 490: train/loss = 0.470414400100708, train/raw-loss = 0.4465329647064209, train/logprobs = tensor([[-0.6406, -1.9970],
        [-0.9010, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23881429433822632
Epoch 0, Step 491: train/loss = 0.3644714951515198, train/raw-loss = 0.34199678897857666, train/logprobs = tensor([[-0.9301, -5.0288],
        [-1.5616, -1.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247469425201416
Epoch 0, Step 492: train/loss = 0.38071271777153015, train/raw-loss = 0.3617851138114929, train/logprobs = tensor([[-0.8683, -4.5733],
        [-1.3537, -1.2132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18927603960037231
Epoch 0, Step 493: train/loss = 0.5713583827018738, train/raw-loss = 0.5538370013237, train/logprobs = tensor([[-0.5228, -1.9107],
        [-0.5132, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752135455608368
Epoch 0, Step 494: train/loss = 0.4423936605453491, train/raw-loss = 0.41868090629577637, train/logprobs = tensor([[-0.9518, -2.2701],
        [-1.4131, -1.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23712772130966187
Epoch 0, Step 495: train/loss = 0.42477482557296753, train/raw-loss = 0.4082890748977661, train/logprobs = tensor([[-0.5131, -4.8043],
        [-0.8388, -0.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16485725343227386
Epoch 0, Step 496: train/loss = 0.4288175106048584, train/raw-loss = 0.41009166836738586, train/logprobs = tensor([[-0.6818, -3.8752],
        [-0.7784, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18725816905498505
Epoch 0, Step 497: train/loss = 0.49311763048171997, train/raw-loss = 0.4769801199436188, train/logprobs = tensor([[-0.5107, -1.5859],
        [-0.7401, -0.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16137486696243286
Epoch 0, Step 498: train/loss = 0.294108510017395, train/raw-loss = 0.2723889648914337, train/logprobs = tensor([[-0.7335, -3.5559],
        [-1.0740, -0.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21719561517238617
Epoch 0, Step 499: train/loss = 0.3964220881462097, train/raw-loss = 0.3781093657016754, train/logprobs = tensor([[-0.6805, -4.1143],
        [-1.0595, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1831270009279251
Epoch 0, Step 500: train/loss = 0.5224621295928955, train/raw-loss = 0.5032250881195068, train/logprobs = tensor([[-0.6926, -2.7450],
        [-1.0080, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19237075746059418
Epoch 0, Step 501: train/loss = 0.43163758516311646, train/raw-loss = 0.413001149892807, train/logprobs = tensor([[-0.8604, -5.0625],
        [-0.8565, -1.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863642930984497
Epoch 0, Step 502: train/loss = 0.2829097807407379, train/raw-loss = 0.26114240288734436, train/logprobs = tensor([[-0.5933, -2.9898],
        [-1.3021, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21767371892929077
Epoch 0, Step 503: train/loss = 0.6511731147766113, train/raw-loss = 0.6363070011138916, train/logprobs = tensor([[-0.6735, -1.1360],
        [-0.5783, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14866101741790771
Epoch 0, Step 504: train/loss = 0.41168808937072754, train/raw-loss = 0.39622098207473755, train/logprobs = tensor([[-0.5427, -3.9014],
        [-0.6596, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15467135608196259
Epoch 0, Step 505: train/loss = 0.35095199942588806, train/raw-loss = 0.33260732889175415, train/logprobs = tensor([[-0.7105, -6.1265],
        [-1.1848, -1.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18344683945178986
Epoch 0, Step 506: train/loss = 0.5257288217544556, train/raw-loss = 0.5089938640594482, train/logprobs = tensor([[-0.6159, -1.9566],
        [-0.7380, -0.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1673494279384613
Epoch 0, Step 507: train/loss = 0.4868534207344055, train/raw-loss = 0.46476417779922485, train/logprobs = tensor([[-0.9867, -6.9405],
        [-1.1906, -1.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22089236974716187
Epoch 0, Step 508: train/loss = 0.45316895842552185, train/raw-loss = 0.43387705087661743, train/logprobs = tensor([[-0.6678, -2.7020],
        [-0.9718, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.192919060587883
Epoch 0, Step 509: train/loss = 0.5504931211471558, train/raw-loss = 0.5291532278060913, train/logprobs = tensor([[-0.7645, -2.0738],
        [-0.8250, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21339866518974304
Epoch 0, Step 510: train/loss = 0.44674256443977356, train/raw-loss = 0.4271700382232666, train/logprobs = tensor([[-0.7784, -4.3632],
        [-1.4055, -1.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572485983371735
Epoch 0, Step 511: train/loss = 0.4879724681377411, train/raw-loss = 0.4684992730617523, train/logprobs = tensor([[-0.8804, -4.0504],
        [-0.9575, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19473235309123993
Epoch 0, Step 512: train/loss = 0.4530077278614044, train/raw-loss = 0.43443870544433594, train/logprobs = tensor([[-0.7300, -2.4573],
        [-1.3462, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18569061160087585
Epoch 0, Step 513: train/loss = 0.4831606149673462, train/raw-loss = 0.46492519974708557, train/logprobs = tensor([[-0.4272, -3.6601],
        [-0.6695, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18235407769680023
Epoch 0, Step 514: train/loss = 0.33391180634498596, train/raw-loss = 0.31024685502052307, train/logprobs = tensor([[-0.5891, -4.8195],
        [-1.2206, -1.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23664948344230652
Epoch 0, Step 515: train/loss = 0.6954227089881897, train/raw-loss = 0.6756563782691956, train/logprobs = tensor([[-0.5243, -0.5781],
        [-0.7172, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19766324758529663
Epoch 0, Step 516: train/loss = 0.37742388248443604, train/raw-loss = 0.35463806986808777, train/logprobs = tensor([[-0.8163, -3.3625],
        [-1.3742, -1.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22785808145999908
Epoch 0, Step 517: train/loss = 0.4218032956123352, train/raw-loss = 0.4032338857650757, train/logprobs = tensor([[-0.6077, -2.6521],
        [-0.9199, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18569447100162506
Epoch 0, Step 518: train/loss = 0.3184319734573364, train/raw-loss = 0.2968920171260834, train/logprobs = tensor([[-0.8010, -6.2147],
        [-1.8859, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21539947390556335
Epoch 0, Step 519: train/loss = 0.3204573094844818, train/raw-loss = 0.29943984746932983, train/logprobs = tensor([[-0.9931, -4.7482],
        [-1.1664, -1.2224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21017475426197052
Epoch 0, Step 520: train/loss = 0.748077929019928, train/raw-loss = 0.731319010257721, train/logprobs = tensor([[-1.1839, -1.1268],
        [-0.9187, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16758881509304047
Epoch 0, Step 521: train/loss = 0.43267709016799927, train/raw-loss = 0.4174381494522095, train/logprobs = tensor([[-0.3560, -2.8203],
        [-0.6538, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15238915383815765
Epoch 0, Step 522: train/loss = 0.5867112278938293, train/raw-loss = 0.5677344799041748, train/logprobs = tensor([[-1.5560, -3.9377],
        [-1.0462, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18976758420467377
Epoch 0, Step 523: train/loss = 0.49041783809661865, train/raw-loss = 0.47093766927719116, train/logprobs = tensor([[-0.5659, -2.4823],
        [-0.7169, -0.8274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19480204582214355
Epoch 0, Step 524: train/loss = 0.2637895345687866, train/raw-loss = 0.2431526631116867, train/logprobs = tensor([[-0.4774, -7.0002],
        [-0.9702, -1.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2063688039779663
Epoch 0, Step 525: train/loss = 0.5074930191040039, train/raw-loss = 0.4867951273918152, train/logprobs = tensor([[-0.7296, -2.1683],
        [-0.9679, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20697906613349915
Epoch 0, Step 526: train/loss = 0.4573809504508972, train/raw-loss = 0.442929208278656, train/logprobs = tensor([[-0.4070, -2.0895],
        [-0.7571, -0.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14451755583286285
Epoch 0, Step 527: train/loss = 0.2314266860485077, train/raw-loss = 0.21041028201580048, train/logprobs = tensor([[-0.5557, -4.7596],
        [-1.2837, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2101641446352005
Epoch 0, Step 528: train/loss = 0.3492122292518616, train/raw-loss = 0.3336101770401001, train/logprobs = tensor([[-0.3683, -6.3017],
        [-0.5659, -1.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15602032840251923
Epoch 0, Step 529: train/loss = 0.37544718384742737, train/raw-loss = 0.3541524410247803, train/logprobs = tensor([[-0.6816, -4.9136],
        [-1.1760, -2.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21294789016246796
Epoch 0, Step 530: train/loss = 0.5614238977432251, train/raw-loss = 0.5389704704284668, train/logprobs = tensor([[-0.5767, -1.7770],
        [-1.2550, -1.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22453486919403076
Epoch 0, Step 531: train/loss = 0.5230998992919922, train/raw-loss = 0.5058209896087646, train/logprobs = tensor([[-0.4464, -1.8009],
        [-0.6483, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727885901927948
Epoch 0, Step 532: train/loss = 0.4658520221710205, train/raw-loss = 0.4444272518157959, train/logprobs = tensor([[-0.6286, -3.1802],
        [-1.1965, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2142477184534073
Epoch 0, Step 533: train/loss = 0.4166383147239685, train/raw-loss = 0.3937567472457886, train/logprobs = tensor([[-0.9258, -4.4688],
        [-1.0331, -1.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22881551086902618
Epoch 0, Step 534: train/loss = 0.4911231994628906, train/raw-loss = 0.470960795879364, train/logprobs = tensor([[-0.4995, -2.6272],
        [-0.8222, -1.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20162418484687805
Epoch 0, Step 535: train/loss = 0.31992802023887634, train/raw-loss = 0.2945324182510376, train/logprobs = tensor([[-0.9304, -4.8010],
        [-1.6127, -1.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2539561688899994
Epoch 0, Step 536: train/loss = 0.35710081458091736, train/raw-loss = 0.3363160490989685, train/logprobs = tensor([[-0.8022, -3.3440],
        [-1.0337, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20784786343574524
Epoch 0, Step 537: train/loss = 0.369221031665802, train/raw-loss = 0.3485483229160309, train/logprobs = tensor([[-0.7109, -2.5518],
        [-1.3534, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20672707259655
Epoch 0, Step 538: train/loss = 0.3478066325187683, train/raw-loss = 0.3254830241203308, train/logprobs = tensor([[-0.8735, -5.5299],
        [-0.8903, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22323612868785858
Epoch 0, Step 539: train/loss = 0.4343005418777466, train/raw-loss = 0.4181019067764282, train/logprobs = tensor([[-0.4706, -3.8341],
        [-0.7465, -1.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1619861125946045
Epoch 0, Step 540: train/loss = 0.46057194471359253, train/raw-loss = 0.439848929643631, train/logprobs = tensor([[-0.7364, -3.1784],
        [-1.2654, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20723049342632294
Epoch 0, Step 541: train/loss = 0.28206828236579895, train/raw-loss = 0.25958386063575745, train/logprobs = tensor([[-0.7938, -6.1793],
        [-1.6348, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248440980911255
Epoch 0, Step 542: train/loss = 0.37827396392822266, train/raw-loss = 0.36059120297431946, train/logprobs = tensor([[-0.6976, -2.8447],
        [-1.1191, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17682777345180511
Epoch 0, Step 543: train/loss = 0.40718621015548706, train/raw-loss = 0.3891046345233917, train/logprobs = tensor([[-0.5818, -5.5703],
        [-0.8751, -1.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18081581592559814
Epoch 0, Step 544: train/loss = 0.47887682914733887, train/raw-loss = 0.45672017335891724, train/logprobs = tensor([[-0.6692, -2.4523],
        [-1.0048, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22156623005867004
Epoch 0, Step 545: train/loss = 0.3274470865726471, train/raw-loss = 0.30754393339157104, train/logprobs = tensor([[-0.6853, -3.8257],
        [-1.4706, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903147220611572
Epoch 0, Step 546: train/loss = 0.3837524652481079, train/raw-loss = 0.3654348850250244, train/logprobs = tensor([[-0.4643, -3.4091],
        [-0.8512, -0.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1831761598587036
Epoch 0, Step 547: train/loss = 0.3845891058444977, train/raw-loss = 0.3651735186576843, train/logprobs = tensor([[-0.7180, -4.7814],
        [-1.0121, -1.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19415590167045593
Epoch 0, Step 548: train/loss = 0.5257995128631592, train/raw-loss = 0.5071625709533691, train/logprobs = tensor([[-0.5068, -1.4090],
        [-0.8630, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18636956810951233
Epoch 0, Step 549: train/loss = 0.4398377537727356, train/raw-loss = 0.41768187284469604, train/logprobs = tensor([[-0.9380, -2.5422],
        [-1.5712, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215588092803955
Epoch 0, Step 550: train/loss = 0.33921322226524353, train/raw-loss = 0.31536856293678284, train/logprobs = tensor([[-1.1689, -5.2895],
        [-1.8307, -1.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23844683170318604
Epoch 0, Step 551: train/loss = 0.5150634050369263, train/raw-loss = 0.4936547577381134, train/logprobs = tensor([[-0.6728, -2.1530],
        [-1.0793, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21408690512180328
Epoch 0, Step 552: train/loss = 0.3226163983345032, train/raw-loss = 0.3027154207229614, train/logprobs = tensor([[-0.7958, -3.3128],
        [-1.5286, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19900920987129211
Epoch 0, Step 553: train/loss = 0.39245516061782837, train/raw-loss = 0.37148281931877136, train/logprobs = tensor([[-0.5072, -3.4832],
        [-1.0297, -1.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20972318947315216
Epoch 0, Step 554: train/loss = 0.349619060754776, train/raw-loss = 0.3306024670600891, train/logprobs = tensor([[-0.4963, -5.2563],
        [-0.8841, -1.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19016602635383606
Epoch 0, Step 555: train/loss = 0.4274314045906067, train/raw-loss = 0.4060848355293274, train/logprobs = tensor([[-1.0731, -3.4513],
        [-1.1345, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2134658545255661
Epoch 0, Step 556: train/loss = 0.39938437938690186, train/raw-loss = 0.3812316656112671, train/logprobs = tensor([[-0.4803, -4.1861],
        [-0.8596, -1.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18152740597724915
Epoch 0, Step 557: train/loss = 0.36912795901298523, train/raw-loss = 0.34768375754356384, train/logprobs = tensor([[-0.8245, -4.0338],
        [-1.5400, -1.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21444204449653625
Epoch 0, Step 558: train/loss = 0.6361275911331177, train/raw-loss = 0.6123586893081665, train/logprobs = tensor([[-0.8344, -1.3685],
        [-1.0133, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23768925666809082
Epoch 0, Step 559: train/loss = 0.4147484302520752, train/raw-loss = 0.3954477310180664, train/logprobs = tensor([[-0.8036, -4.0280],
        [-0.8402, -0.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19300740957260132
Epoch 0, Step 560: train/loss = 0.5396925210952759, train/raw-loss = 0.5222935080528259, train/logprobs = tensor([[-0.3847, -2.2156],
        [-0.5489, -0.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17398998141288757
Epoch 0, Step 561: train/loss = 0.4527612328529358, train/raw-loss = 0.4312068521976471, train/logprobs = tensor([[-0.6453, -2.3386],
        [-1.1411, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2155439704656601
Epoch 0, Step 562: train/loss = 0.38692614436149597, train/raw-loss = 0.36512917280197144, train/logprobs = tensor([[-0.7240, -4.0003],
        [-1.2727, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21796941757202148
Epoch 0, Step 563: train/loss = 0.46425551176071167, train/raw-loss = 0.446907639503479, train/logprobs = tensor([[-0.5347, -3.6056],
        [-0.7935, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347879707813263
Epoch 0, Step 564: train/loss = 0.45625725388526917, train/raw-loss = 0.43278419971466064, train/logprobs = tensor([[-0.6283, -2.0226],
        [-1.1705, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23473063111305237
Epoch 0, Step 565: train/loss = 0.3945823311805725, train/raw-loss = 0.3698034882545471, train/logprobs = tensor([[-0.9845, -3.3255],
        [-1.9660, -2.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24778835475444794
Epoch 0, Step 566: train/loss = 0.4514833092689514, train/raw-loss = 0.43106719851493835, train/logprobs = tensor([[-0.5539, -6.8853],
        [-0.8500, -1.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20416133105754852
Epoch 0, Step 567: train/loss = 0.31613051891326904, train/raw-loss = 0.292863667011261, train/logprobs = tensor([[-0.5416, -3.8959],
        [-1.4395, -1.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23266851902008057
Epoch 0, Step 568: train/loss = 0.5255874991416931, train/raw-loss = 0.5028260946273804, train/logprobs = tensor([[-0.5811, -3.1892],
        [-1.2370, -1.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.227614164352417
Epoch 0, Step 569: train/loss = 0.31586378812789917, train/raw-loss = 0.2878917455673218, train/logprobs = tensor([[-0.9171, -2.8722],
        [-1.9227, -1.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27972036600112915
Epoch 0, Step 570: train/loss = 0.7002482414245605, train/raw-loss = 0.6773952841758728, train/logprobs = tensor([[-1.7804, -2.8616],
        [-1.1798, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285301685333252
Epoch 0, Step 571: train/loss = 0.3920133709907532, train/raw-loss = 0.37349236011505127, train/logprobs = tensor([[-0.7140, -4.0772],
        [-0.8055, -1.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18521027266979218
Epoch 0, Step 572: train/loss = 0.39424872398376465, train/raw-loss = 0.3761652112007141, train/logprobs = tensor([[-0.5070, -3.8071],
        [-0.6311, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1808350533246994
Epoch 0, Step 573: train/loss = 0.32114940881729126, train/raw-loss = 0.3010304570198059, train/logprobs = tensor([[-0.5483, -4.2012],
        [-0.8741, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011898308992386
Epoch 0, Step 574: train/loss = 0.5526784062385559, train/raw-loss = 0.5342450141906738, train/logprobs = tensor([[-0.5056, -1.4672],
        [-0.8513, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18433374166488647
Epoch 0, Step 575: train/loss = 0.3231434226036072, train/raw-loss = 0.29913580417633057, train/logprobs = tensor([[-0.6284, -4.4645],
        [-1.4930, -1.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24007651209831238
Epoch 0, Step 576: train/loss = 0.47788572311401367, train/raw-loss = 0.45341962575912476, train/logprobs = tensor([[-1.0466, -2.0623],
        [-1.4708, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24466122686862946
Epoch 0, Step 577: train/loss = 0.5890481472015381, train/raw-loss = 0.5639081597328186, train/logprobs = tensor([[-0.8833, -1.9328],
        [-1.3343, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513999044895172
Epoch 0, Step 578: train/loss = 0.28856927156448364, train/raw-loss = 0.263618141412735, train/logprobs = tensor([[-0.8363, -4.8420],
        [-1.7211, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495114505290985
Epoch 0, Step 579: train/loss = 0.4281182885169983, train/raw-loss = 0.4059569239616394, train/logprobs = tensor([[-0.8553, -4.6854],
        [-1.4124, -2.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22161340713500977
Epoch 0, Step 580: train/loss = 0.3500896692276001, train/raw-loss = 0.33208349347114563, train/logprobs = tensor([[-0.8225, -6.3180],
        [-1.1923, -1.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18006163835525513
Epoch 0, Step 581: train/loss = 0.3208397626876831, train/raw-loss = 0.2983521521091461, train/logprobs = tensor([[-0.6444, -6.7299],
        [-1.5055, -2.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248762547969818
Epoch 0, Step 582: train/loss = 0.4702964425086975, train/raw-loss = 0.45046791434288025, train/logprobs = tensor([[-0.5791, -2.0583],
        [-1.3009, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19828487932682037
Epoch 0, Step 583: train/loss = 0.5263820290565491, train/raw-loss = 0.5078693628311157, train/logprobs = tensor([[-0.7748, -2.3042],
        [-0.9917, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18512645363807678
Epoch 0, Step 584: train/loss = 0.5093482732772827, train/raw-loss = 0.49024540185928345, train/logprobs = tensor([[-0.4935, -2.0794],
        [-1.0599, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1910286545753479
Epoch 0, Step 585: train/loss = 0.5349738597869873, train/raw-loss = 0.5160019397735596, train/logprobs = tensor([[-0.3650, -2.5245],
        [-0.6512, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897190809249878
Epoch 0, Step 586: train/loss = 0.39261946082115173, train/raw-loss = 0.36728939414024353, train/logprobs = tensor([[-0.8569, -2.1513],
        [-1.6966, -1.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533004581928253
Epoch 0, Step 587: train/loss = 0.5100947022438049, train/raw-loss = 0.4900490641593933, train/logprobs = tensor([[-0.7586, -1.6325],
        [-1.3096, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20045635104179382
Epoch 0, Step 588: train/loss = 0.36283808946609497, train/raw-loss = 0.34372785687446594, train/logprobs = tensor([[-0.8036, -5.2546],
        [-1.6665, -1.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19110223650932312
Epoch 0, Step 589: train/loss = 0.37415996193885803, train/raw-loss = 0.34948262572288513, train/logprobs = tensor([[-0.7713, -3.9330],
        [-1.3672, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24677351117134094
Epoch 0, Step 590: train/loss = 0.30970311164855957, train/raw-loss = 0.29200491309165955, train/logprobs = tensor([[-0.6003, -4.9304],
        [-1.0244, -1.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17698197066783905
Epoch 0, Step 591: train/loss = 0.6171622276306152, train/raw-loss = 0.5935047268867493, train/logprobs = tensor([[-0.6927, -0.9329],
        [-0.9712, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23657438158988953
Epoch 0, Step 592: train/loss = 0.478733628988266, train/raw-loss = 0.4580763876438141, train/logprobs = tensor([[-0.5764, -2.2478],
        [-1.0334, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20657242834568024
Epoch 0, Step 593: train/loss = 0.41808533668518066, train/raw-loss = 0.3968678414821625, train/logprobs = tensor([[-0.6150, -2.9382],
        [-1.0429, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21217530965805054
Epoch 0, Step 594: train/loss = 0.2887023985385895, train/raw-loss = 0.2653159201145172, train/logprobs = tensor([[-0.7363, -3.7997],
        [-1.3221, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2338647097349167
Epoch 0, Step 595: train/loss = 0.4944762885570526, train/raw-loss = 0.47384393215179443, train/logprobs = tensor([[-0.6266, -2.2906],
        [-1.0036, -1.4406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2063237726688385
Epoch 0, Step 596: train/loss = 0.4292800724506378, train/raw-loss = 0.40729203820228577, train/logprobs = tensor([[-0.7073, -4.4856],
        [-1.2212, -1.6669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21988020837306976
Epoch 0, Step 597: train/loss = 0.613518238067627, train/raw-loss = 0.5912609100341797, train/logprobs = tensor([[-0.6166, -0.9945],
        [-1.2182, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2225738763809204
Epoch 0, Step 598: train/loss = 0.4111137092113495, train/raw-loss = 0.38957786560058594, train/logprobs = tensor([[-1.1578, -3.4620],
        [-1.1782, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2153584361076355
Epoch 0, Step 599: train/loss = 0.4248844087123871, train/raw-loss = 0.4053782820701599, train/logprobs = tensor([[-0.5324, -4.2107],
        [-1.0407, -1.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19506166875362396
Epoch 0, Step 600: train/loss = 0.44399166107177734, train/raw-loss = 0.42188912630081177, train/logprobs = tensor([[-0.5402, -2.8892],
        [-0.8436, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2210250049829483
Epoch 0, Step 601: train/loss = 0.45176368951797485, train/raw-loss = 0.4292236566543579, train/logprobs = tensor([[-1.0682, -2.4790],
        [-1.6133, -1.4211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22540056705474854
Epoch 0, Step 602: train/loss = 0.4677314758300781, train/raw-loss = 0.442742258310318, train/logprobs = tensor([[-0.9849, -3.0571],
        [-1.3491, -1.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498922199010849
Epoch 0, Step 603: train/loss = 0.27146732807159424, train/raw-loss = 0.24962177872657776, train/logprobs = tensor([[-0.5365, -5.5981],
        [-1.2482, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21845553815364838
Epoch 0, Step 604: train/loss = 0.520799458026886, train/raw-loss = 0.5015531182289124, train/logprobs = tensor([[-0.4479, -1.7802],
        [-0.7579, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19246318936347961
Epoch 0, Step 605: train/loss = 0.47684144973754883, train/raw-loss = 0.4584580063819885, train/logprobs = tensor([[-0.7172, -1.1942],
        [-1.6141, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838342845439911
Epoch 0, Step 606: train/loss = 0.4107789993286133, train/raw-loss = 0.39087581634521484, train/logprobs = tensor([[-0.6669, -2.4674],
        [-0.9372, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903185963630676
Epoch 0, Step 607: train/loss = 0.3683418929576874, train/raw-loss = 0.34400203824043274, train/logprobs = tensor([[-0.7588, -3.2476],
        [-1.0965, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2433984875679016
Epoch 0, Step 608: train/loss = 0.4348384737968445, train/raw-loss = 0.410427987575531, train/logprobs = tensor([[-0.6184, -2.9868],
        [-1.3892, -1.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24410459399223328
Epoch 0, Step 609: train/loss = 0.30682575702667236, train/raw-loss = 0.281994491815567, train/logprobs = tensor([[-0.9210, -6.1206],
        [-1.8079, -1.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24831271171569824
Epoch 0, Step 610: train/loss = 0.25697073340415955, train/raw-loss = 0.22811496257781982, train/logprobs = tensor([[-1.3930, -7.0917],
        [-2.1197, -1.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28855758905410767
Epoch 0, Step 611: train/loss = 0.27108561992645264, train/raw-loss = 0.2524135708808899, train/logprobs = tensor([[-0.5165, -4.2519],
        [-0.9629, -1.3294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1867203712463379
Epoch 0, Step 612: train/loss = 0.5059148073196411, train/raw-loss = 0.48175814747810364, train/logprobs = tensor([[-0.8110, -3.3411],
        [-1.2507, -1.1953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24156686663627625
Epoch 0, Step 613: train/loss = 0.5624604225158691, train/raw-loss = 0.537696123123169, train/logprobs = tensor([[-0.7907, -2.0551],
        [-1.2281, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24764269590377808
Epoch 0, Step 614: train/loss = 0.4160417914390564, train/raw-loss = 0.3923320174217224, train/logprobs = tensor([[-0.7600, -2.4282],
        [-1.1552, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23709793388843536
Epoch 0, Step 615: train/loss = 0.4312894940376282, train/raw-loss = 0.406374454498291, train/logprobs = tensor([[-0.7239, -2.3104],
        [-1.4519, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24915005266666412
Epoch 0, Step 616: train/loss = 0.6420807838439941, train/raw-loss = 0.6194756627082825, train/logprobs = tensor([[-0.5536, -1.0591],
        [-0.9599, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.226051464676857
Epoch 0, Step 617: train/loss = 0.4184095561504364, train/raw-loss = 0.40049827098846436, train/logprobs = tensor([[-0.6927, -3.6503],
        [-1.0741, -1.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17911297082901
Epoch 0, Step 618: train/loss = 0.392046719789505, train/raw-loss = 0.3694061040878296, train/logprobs = tensor([[-0.5183, -2.9180],
        [-1.2100, -1.3808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22640614211559296
Epoch 0, Step 619: train/loss = 0.3451520800590515, train/raw-loss = 0.32610201835632324, train/logprobs = tensor([[-0.4944, -4.7275],
        [-1.0163, -1.2699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19050061702728271
Epoch 0, Step 620: train/loss = 0.30079880356788635, train/raw-loss = 0.27598491311073303, train/logprobs = tensor([[-0.8741, -3.9540],
        [-1.6775, -0.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24813871085643768
Epoch 0, Step 621: train/loss = 0.5536173582077026, train/raw-loss = 0.5348682403564453, train/logprobs = tensor([[-0.7323, -1.0240],
        [-1.2761, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749171495437622
Epoch 0, Step 622: train/loss = 0.44387513399124146, train/raw-loss = 0.4218144118785858, train/logprobs = tensor([[-0.4814, -4.7045],
        [-1.1418, -1.3301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22060734033584595
Epoch 0, Step 623: train/loss = 0.4036959111690521, train/raw-loss = 0.38372763991355896, train/logprobs = tensor([[-0.5809, -4.9434],
        [-1.1996, -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19968281686306
Epoch 0, Step 624: train/loss = 0.43957728147506714, train/raw-loss = 0.4174467921257019, train/logprobs = tensor([[-0.5909, -2.9058],
        [-1.3160, -1.3741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213049829006195
Epoch 0, Step 625: train/loss = 0.48770612478256226, train/raw-loss = 0.4655117094516754, train/logprobs = tensor([[-0.7344, -4.3084],
        [-1.0067, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22194381058216095
Epoch 0, Step 626: train/loss = 0.4505873918533325, train/raw-loss = 0.4300091564655304, train/logprobs = tensor([[-0.5536, -2.2022],
        [-1.0840, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20578250288963318
Epoch 0, Step 627: train/loss = 0.40616580843925476, train/raw-loss = 0.3840482831001282, train/logprobs = tensor([[-0.4832, -2.5445],
        [-1.1859, -0.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22117549180984497
Epoch 0, Step 628: train/loss = 0.36898618936538696, train/raw-loss = 0.34553056955337524, train/logprobs = tensor([[-0.4705, -2.5998],
        [-1.2778, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2345559000968933
Epoch 0, Step 629: train/loss = 0.47212374210357666, train/raw-loss = 0.4525385797023773, train/logprobs = tensor([[-0.4423, -2.0361],
        [-0.8964, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19585148990154266
Epoch 0, Step 630: train/loss = 0.3800443112850189, train/raw-loss = 0.3623256981372833, train/logprobs = tensor([[-0.4348, -3.5342],
        [-0.7743, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17718613147735596
Epoch 0, Step 631: train/loss = 0.2221251279115677, train/raw-loss = 0.19748638570308685, train/logprobs = tensor([[-1.0423, -5.0552],
        [-2.0028, -1.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24638745188713074
Epoch 0, Step 632: train/loss = 0.44989973306655884, train/raw-loss = 0.4260714054107666, train/logprobs = tensor([[-0.8743, -4.2398],
        [-1.2515, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23828324675559998
Epoch 0, Step 633: train/loss = 0.3562757074832916, train/raw-loss = 0.33406761288642883, train/logprobs = tensor([[-0.9114, -4.7837],
        [-1.2848, -2.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22208084166049957
Epoch 0, Step 634: train/loss = 0.36449605226516724, train/raw-loss = 0.3406756520271301, train/logprobs = tensor([[-0.4115, -4.2678],
        [-1.4393, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23820388317108154
Epoch 0, Step 635: train/loss = 0.33124521374702454, train/raw-loss = 0.3075713813304901, train/logprobs = tensor([[-0.5727, -4.4539],
        [-1.3251, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23673807084560394
Epoch 0, Step 636: train/loss = 0.4663332998752594, train/raw-loss = 0.4457930028438568, train/logprobs = tensor([[-0.5733, -3.0475],
        [-1.0134, -1.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054031491279602
Epoch 0, Step 637: train/loss = 0.4044402241706848, train/raw-loss = 0.3857131004333496, train/logprobs = tensor([[-0.6629, -4.2320],
        [-1.0646, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18727105855941772
Epoch 0, Step 638: train/loss = 0.5758378505706787, train/raw-loss = 0.5541733503341675, train/logprobs = tensor([[-0.5302, -1.2161],
        [-0.9237, -0.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21664488315582275
Epoch 0, Step 639: train/loss = 0.41077399253845215, train/raw-loss = 0.38515806198120117, train/logprobs = tensor([[-0.8688, -3.5635],
        [-1.4881, -1.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25615909695625305
Epoch 0, Step 640: train/loss = 0.3675079643726349, train/raw-loss = 0.34677398204803467, train/logprobs = tensor([[-0.6312, -5.2464],
        [-0.9529, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20733991265296936
Epoch 0, Step 641: train/loss = 0.6588281989097595, train/raw-loss = 0.6352660655975342, train/logprobs = tensor([[-1.3954, -3.3627],
        [-1.3997, -1.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23562142252922058
Epoch 0, Step 642: train/loss = 0.3896535634994507, train/raw-loss = 0.3654434382915497, train/logprobs = tensor([[-1.2256, -4.6754],
        [-1.5149, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24210122227668762
Epoch 0, Step 643: train/loss = 0.2877311408519745, train/raw-loss = 0.26608189940452576, train/logprobs = tensor([[-0.5973, -5.8344],
        [-1.1074, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21649231016635895
Epoch 0, Step 644: train/loss = 0.47982656955718994, train/raw-loss = 0.4545673131942749, train/logprobs = tensor([[-1.0707, -1.4186],
        [-1.8085, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25259238481521606
Epoch 0, Step 645: train/loss = 0.3988396227359772, train/raw-loss = 0.3782042860984802, train/logprobs = tensor([[-1.0482, -5.5445],
        [-1.9379, -1.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20635344088077545
Epoch 0, Step 646: train/loss = 0.5418781638145447, train/raw-loss = 0.5186110138893127, train/logprobs = tensor([[-0.7193, -1.3550],
        [-1.2134, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23267129063606262
Epoch 0, Step 647: train/loss = 0.4290727972984314, train/raw-loss = 0.40697765350341797, train/logprobs = tensor([[-0.6468, -3.3771],
        [-1.3144, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209516316652298
Epoch 0, Step 648: train/loss = 0.3552185893058777, train/raw-loss = 0.33078938722610474, train/logprobs = tensor([[-0.6661, -5.1927],
        [-1.4788, -1.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2442919909954071
Epoch 0, Step 649: train/loss = 0.19346725940704346, train/raw-loss = 0.16838276386260986, train/logprobs = tensor([[-0.6317, -6.6807],
        [-1.7550, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508450746536255
Epoch 0, Step 650: train/loss = 0.27644985914230347, train/raw-loss = 0.25330036878585815, train/logprobs = tensor([[-0.7187, -6.5466],
        [-1.4790, -1.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23149514198303223
Epoch 0, Step 651: train/loss = 0.25615745782852173, train/raw-loss = 0.2308163046836853, train/logprobs = tensor([[-1.0758, -5.7830],
        [-1.8538, -1.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534114122390747
Epoch 0, Step 652: train/loss = 0.28433066606521606, train/raw-loss = 0.2679825723171234, train/logprobs = tensor([[-0.8507, -7.1439],
        [-1.5600, -1.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16348087787628174
Epoch 0, Step 653: train/loss = 0.4733860492706299, train/raw-loss = 0.4534241557121277, train/logprobs = tensor([[-0.8980, -3.0813],
        [-1.3578, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19961851835250854
Epoch 0, Step 654: train/loss = 0.5971726775169373, train/raw-loss = 0.5753331780433655, train/logprobs = tensor([[-0.6791, -2.2993],
        [-0.8801, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2183951437473297
Epoch 0, Step 655: train/loss = 0.31646817922592163, train/raw-loss = 0.2881544530391693, train/logprobs = tensor([[-1.0896, -3.9681],
        [-1.9446, -1.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831374406814575
Epoch 0, Step 656: train/loss = 0.21719232201576233, train/raw-loss = 0.19378885626792908, train/logprobs = tensor([[-1.0757, -8.1236],
        [-1.7518, -2.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340347319841385
Epoch 0, Step 657: train/loss = 0.3238420784473419, train/raw-loss = 0.3053562045097351, train/logprobs = tensor([[-0.6413, -5.1794],
        [-1.2162, -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18485866487026215
Epoch 0, Step 658: train/loss = 0.479667991399765, train/raw-loss = 0.4533420205116272, train/logprobs = tensor([[-1.2573, -3.8398],
        [-1.4792, -1.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632595896720886
Epoch 0, Step 659: train/loss = 0.20856739580631256, train/raw-loss = 0.18449342250823975, train/logprobs = tensor([[-0.5995, -5.7784],
        [-1.5432, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2407398372888565
Epoch 0, Step 660: train/loss = 0.5544072985649109, train/raw-loss = 0.5309391617774963, train/logprobs = tensor([[-0.8399, -2.3413],
        [-0.9617, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23468123376369476
Epoch 0, Step 661: train/loss = 0.3777580261230469, train/raw-loss = 0.354565292596817, train/logprobs = tensor([[-0.6153, -4.7740],
        [-1.3159, -1.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23192709684371948
Epoch 0, Step 662: train/loss = 0.5387123227119446, train/raw-loss = 0.5190256834030151, train/logprobs = tensor([[-0.6903, -1.7986],
        [-0.9575, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19686615467071533
Epoch 0, Step 663: train/loss = 0.4061940312385559, train/raw-loss = 0.3827895224094391, train/logprobs = tensor([[-1.1085, -6.2226],
        [-1.1308, -1.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340449094772339
Epoch 0, Step 664: train/loss = 0.39014187455177307, train/raw-loss = 0.3680275082588196, train/logprobs = tensor([[-0.7793, -2.7658],
        [-1.4009, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22114354372024536
Epoch 0, Step 665: train/loss = 0.4180728495121002, train/raw-loss = 0.3938734531402588, train/logprobs = tensor([[-1.1855, -2.5073],
        [-1.3263, -0.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24199414253234863
Epoch 0, Step 666: train/loss = 0.38954392075538635, train/raw-loss = 0.36646613478660583, train/logprobs = tensor([[-0.9863, -4.5590],
        [-1.8082, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23077799379825592
Epoch 0, Step 667: train/loss = 0.39742329716682434, train/raw-loss = 0.3728794455528259, train/logprobs = tensor([[-0.7787, -4.2281],
        [-1.6720, -1.1131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24543853104114532
Epoch 0, Step 668: train/loss = 0.5354431867599487, train/raw-loss = 0.5103548765182495, train/logprobs = tensor([[-0.7938, -1.6518],
        [-1.3042, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25088340044021606
Epoch 0, Step 669: train/loss = 0.2824589014053345, train/raw-loss = 0.26229578256607056, train/logprobs = tensor([[-0.6044, -5.5150],
        [-1.2991, -0.7615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20163124799728394
Epoch 0, Step 670: train/loss = 0.3730062246322632, train/raw-loss = 0.35176271200180054, train/logprobs = tensor([[-1.0278, -6.0579],
        [-1.2639, -1.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2124355286359787
Epoch 0, Step 671: train/loss = 0.42888444662094116, train/raw-loss = 0.40698280930519104, train/logprobs = tensor([[-1.0493, -3.8319],
        [-1.0699, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2190164476633072
Epoch 0, Step 672: train/loss = 0.5049808621406555, train/raw-loss = 0.483480840921402, train/logprobs = tensor([[-0.8303, -3.6646],
        [-1.4814, -1.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.215000182390213
Epoch 0, Step 673: train/loss = 0.3617020547389984, train/raw-loss = 0.3367827534675598, train/logprobs = tensor([[-0.5792, -3.9089],
        [-1.2528, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24919289350509644
Epoch 0, Step 674: train/loss = 0.3593445420265198, train/raw-loss = 0.3386957347393036, train/logprobs = tensor([[-0.4263, -2.5249],
        [-1.1205, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20648808777332306
Epoch 0, Step 675: train/loss = 0.29118695855140686, train/raw-loss = 0.2628072500228882, train/logprobs = tensor([[-0.6750, -3.5374],
        [-1.7279, -1.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837972342967987
Epoch 0, Step 676: train/loss = 0.31091922521591187, train/raw-loss = 0.2897772192955017, train/logprobs = tensor([[-0.6235, -6.9307],
        [-1.3507, -1.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21141983568668365
Epoch 0, Step 677: train/loss = 0.37919116020202637, train/raw-loss = 0.3516157567501068, train/logprobs = tensor([[-0.4607, -3.5402],
        [-1.1959, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757538855075836
Epoch 0, Step 678: train/loss = 0.2977791428565979, train/raw-loss = 0.2694162428379059, train/logprobs = tensor([[-0.6696, -5.1648],
        [-1.7221, -1.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28362900018692017
Epoch 0, Step 679: train/loss = 0.29883110523223877, train/raw-loss = 0.2740660011768341, train/logprobs = tensor([[-1.0552, -4.5784],
        [-1.5021, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24765104055404663
Epoch 0, Step 680: train/loss = 0.3673142194747925, train/raw-loss = 0.34573954343795776, train/logprobs = tensor([[-0.7958, -5.3501],
        [-1.2362, -0.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21574661135673523
Epoch 0, Step 681: train/loss = 0.31257063150405884, train/raw-loss = 0.2869020998477936, train/logprobs = tensor([[-0.5525, -3.7664],
        [-1.4732, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25668561458587646
Epoch 0, Step 682: train/loss = 0.4737180173397064, train/raw-loss = 0.44654712080955505, train/logprobs = tensor([[-1.1800, -3.3432],
        [-1.2475, -0.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2717088460922241
Epoch 0, Step 683: train/loss = 0.5153976678848267, train/raw-loss = 0.488493412733078, train/logprobs = tensor([[-1.0193, -2.2639],
        [-1.7394, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26904234290122986
Epoch 0, Step 684: train/loss = 0.34726035594940186, train/raw-loss = 0.32574665546417236, train/logprobs = tensor([[-0.6704, -4.1556],
        [-1.2990, -1.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21513718366622925
Epoch 0, Step 685: train/loss = 0.4033403694629669, train/raw-loss = 0.38062068819999695, train/logprobs = tensor([[-0.6095, -3.8253],
        [-1.2094, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22719699144363403
Epoch 0, Step 686: train/loss = 0.45771193504333496, train/raw-loss = 0.4273526668548584, train/logprobs = tensor([[-1.4880, -3.1739],
        [-1.8123, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30359309911727905
Epoch 0, Step 687: train/loss = 0.3903222382068634, train/raw-loss = 0.37068232893943787, train/logprobs = tensor([[-1.0649, -4.0942],
        [-1.3024, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19639907777309418
Epoch 0, Step 688: train/loss = 0.17823255062103271, train/raw-loss = 0.15199719369411469, train/logprobs = tensor([[-0.6307, -6.5052],
        [-1.7107, -1.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623538374900818
Epoch 0, Step 689: train/loss = 0.3260160982608795, train/raw-loss = 0.30463799834251404, train/logprobs = tensor([[-0.7487, -5.3601],
        [-1.5668, -1.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21378082036972046
Epoch 0, Step 690: train/loss = 0.49563175439834595, train/raw-loss = 0.47872990369796753, train/logprobs = tensor([[-0.3798, -3.7634],
        [-0.7088, -1.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16901853680610657
Epoch 0, Step 691: train/loss = 0.23653936386108398, train/raw-loss = 0.2076377123594284, train/logprobs = tensor([[-0.8357, -5.6078],
        [-2.4029, -1.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28901657462120056
Epoch 0, Step 692: train/loss = 0.37486448884010315, train/raw-loss = 0.35260143876075745, train/logprobs = tensor([[-0.5243, -3.1091],
        [-1.1056, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22263076901435852
Epoch 0, Step 693: train/loss = 0.40941858291625977, train/raw-loss = 0.38823240995407104, train/logprobs = tensor([[-0.7711, -3.2664],
        [-1.2416, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21186164021492004
Epoch 0, Step 694: train/loss = 0.31347209215164185, train/raw-loss = 0.29107779264450073, train/logprobs = tensor([[-0.8262, -5.4166],
        [-1.2649, -1.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22394296526908875
Epoch 0, Step 695: train/loss = 0.5127824544906616, train/raw-loss = 0.4887646436691284, train/logprobs = tensor([[-0.6833, -2.0085],
        [-1.4813, -1.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2401784062385559
Epoch 0, Step 696: train/loss = 0.39415284991264343, train/raw-loss = 0.3696560263633728, train/logprobs = tensor([[-0.7026, -3.6761],
        [-1.8413, -1.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449682056903839
Epoch 0, Step 697: train/loss = 0.3794269859790802, train/raw-loss = 0.35694536566734314, train/logprobs = tensor([[-0.4765, -2.7168],
        [-1.0810, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22481593489646912
Epoch 0, Step 698: train/loss = 0.42851343750953674, train/raw-loss = 0.4053451120853424, train/logprobs = tensor([[-0.7773, -3.3672],
        [-1.7607, -1.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23168334364891052
Epoch 0, Step 699: train/loss = 0.22360357642173767, train/raw-loss = 0.1983412206172943, train/logprobs = tensor([[-0.9005, -6.0310],
        [-2.1595, -2.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252623587846756
Epoch 0, Step 700: train/loss = 0.3589046597480774, train/raw-loss = 0.3344653248786926, train/logprobs = tensor([[-0.9492, -6.5481],
        [-1.4452, -1.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24439337849617004
Epoch 0, Step 701: train/loss = 0.31576570868492126, train/raw-loss = 0.29189592599868774, train/logprobs = tensor([[-0.8596, -4.8354],
        [-1.3200, -1.2976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2386978417634964
Epoch 0, Step 702: train/loss = 0.43015429377555847, train/raw-loss = 0.40801987051963806, train/logprobs = tensor([[-0.5728, -2.4812],
        [-1.2035, -1.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213442325592041
Epoch 0, Step 703: train/loss = 0.5179182887077332, train/raw-loss = 0.4952353537082672, train/logprobs = tensor([[-0.7538, -2.3122],
        [-1.3785, -1.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22682936489582062
Epoch 0, Step 704: train/loss = 0.26579946279525757, train/raw-loss = 0.24027779698371887, train/logprobs = tensor([[-1.4384, -8.8003],
        [-2.3979, -2.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25521668791770935
Epoch 0, Step 705: train/loss = 0.1871768981218338, train/raw-loss = 0.160677969455719, train/logprobs = tensor([[-1.0899, -5.8190],
        [-2.0872, -1.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26498931646347046
Epoch 0, Step 706: train/loss = 0.4275479316711426, train/raw-loss = 0.40919771790504456, train/logprobs = tensor([[-0.5797, -4.2831],
        [-0.8629, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1835024654865265
Epoch 0, Step 707: train/loss = 0.3703622817993164, train/raw-loss = 0.34398284554481506, train/logprobs = tensor([[-0.8543, -4.1117],
        [-1.5735, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637943923473358
Epoch 0, Step 708: train/loss = 0.41962242126464844, train/raw-loss = 0.3964776396751404, train/logprobs = tensor([[-0.7502, -4.4931],
        [-1.1508, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23144793510437012
Epoch 0, Step 709: train/loss = 0.11991730332374573, train/raw-loss = 0.0929187685251236, train/logprobs = tensor([[-0.8934, -7.4726],
        [-2.6533, -2.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699853181838989
Epoch 0, Step 710: train/loss = 0.2918049693107605, train/raw-loss = 0.26368242502212524, train/logprobs = tensor([[-1.0773, -5.1689],
        [-1.8799, -1.6380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28122562170028687
Epoch 0, Step 711: train/loss = 0.4388507604598999, train/raw-loss = 0.416437566280365, train/logprobs = tensor([[-0.5789, -2.6428],
        [-1.2814, -0.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22413170337677002
Epoch 0, Step 712: train/loss = 0.37359559535980225, train/raw-loss = 0.35103878378868103, train/logprobs = tensor([[-0.8844, -4.1678],
        [-1.8002, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255680412054062
Epoch 0, Step 713: train/loss = 0.31586647033691406, train/raw-loss = 0.28895020484924316, train/logprobs = tensor([[-1.0168, -6.0150],
        [-1.6758, -1.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.269162654876709
Epoch 0, Step 714: train/loss = 0.4741113781929016, train/raw-loss = 0.4513683319091797, train/logprobs = tensor([[-0.8259, -5.1642],
        [-1.5425, -1.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22743061184883118
Epoch 0, Step 715: train/loss = 0.2693932056427002, train/raw-loss = 0.24664613604545593, train/logprobs = tensor([[-0.8786, -7.6988],
        [-1.2876, -2.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22747072577476501
Epoch 0, Step 716: train/loss = 0.5130399465560913, train/raw-loss = 0.48713934421539307, train/logprobs = tensor([[-0.7686, -1.9086],
        [-1.4000, -1.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25900593400001526
Epoch 0, Step 717: train/loss = 0.4099472463130951, train/raw-loss = 0.38609346747398376, train/logprobs = tensor([[-0.7655, -3.8951],
        [-1.9216, -1.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23853762447834015
Epoch 0, Step 718: train/loss = 0.49858108162879944, train/raw-loss = 0.4739045798778534, train/logprobs = tensor([[-1.5761, -3.8959],
        [-1.6643, -1.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2467651069164276
Epoch 0, Step 719: train/loss = 0.4134925603866577, train/raw-loss = 0.3917389214038849, train/logprobs = tensor([[-0.5453, -2.7985],
        [-0.9623, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21753662824630737
Epoch 0, Step 720: train/loss = 0.30043280124664307, train/raw-loss = 0.27334633469581604, train/logprobs = tensor([[-0.8526, -4.1266],
        [-1.7721, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708647549152374
Epoch 0, Step 721: train/loss = 0.38890397548675537, train/raw-loss = 0.36143508553504944, train/logprobs = tensor([[-0.9385, -3.9347],
        [-1.4322, -1.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.274688720703125
Epoch 0, Step 722: train/loss = 0.7270416021347046, train/raw-loss = 0.7020689845085144, train/logprobs = tensor([[-0.6368, -0.6682],
        [-1.0815, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24972650408744812
Epoch 0, Step 723: train/loss = 0.2972545027732849, train/raw-loss = 0.2636336386203766, train/logprobs = tensor([[-1.2074, -4.4362],
        [-1.9938, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362087607383728
Epoch 0, Step 724: train/loss = 0.2731724679470062, train/raw-loss = 0.25291991233825684, train/logprobs = tensor([[-0.6078, -6.3307],
        [-1.4853, -1.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20252548158168793
Epoch 0, Step 725: train/loss = 0.5976799726486206, train/raw-loss = 0.5736566185951233, train/logprobs = tensor([[-1.5503, -3.2511],
        [-1.1426, -1.1191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24023345112800598
Epoch 0, Step 726: train/loss = 0.24149590730667114, train/raw-loss = 0.2189832180738449, train/logprobs = tensor([[-0.5265, -7.1757],
        [-1.1376, -1.2336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22512692213058472
Epoch 0, Step 727: train/loss = 0.5124354958534241, train/raw-loss = 0.4890780448913574, train/logprobs = tensor([[-1.3472, -4.9395],
        [-1.2578, -1.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23357437551021576
Epoch 0, Step 728: train/loss = 0.1776798665523529, train/raw-loss = 0.1535748839378357, train/logprobs = tensor([[-0.9582, -9.1809],
        [-2.1487, -1.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24104981124401093
Epoch 0, Step 729: train/loss = 0.5485575199127197, train/raw-loss = 0.5230037569999695, train/logprobs = tensor([[-1.6457, -3.0118],
        [-1.6754, -1.4011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255537211894989
Epoch 0, Step 730: train/loss = 0.4689309597015381, train/raw-loss = 0.45038336515426636, train/logprobs = tensor([[-0.4333, -2.5370],
        [-0.7617, -1.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1854761391878128
Epoch 0, Step 731: train/loss = 0.46537455916404724, train/raw-loss = 0.4421912133693695, train/logprobs = tensor([[-0.7521, -2.9116],
        [-1.0942, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318331003189087
Epoch 0, Step 732: train/loss = 0.40275150537490845, train/raw-loss = 0.378606915473938, train/logprobs = tensor([[-0.6039, -3.4209],
        [-1.3786, -1.8409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24144625663757324
Epoch 0, Step 733: train/loss = 0.3695085048675537, train/raw-loss = 0.3474047780036926, train/logprobs = tensor([[-0.5710, -4.2269],
        [-1.2508, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22103722393512726
Epoch 0, Step 734: train/loss = 0.39253681898117065, train/raw-loss = 0.3676226735115051, train/logprobs = tensor([[-0.9504, -3.2499],
        [-1.6284, -1.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24914173781871796
Epoch 0, Step 735: train/loss = 0.7071908712387085, train/raw-loss = 0.6806043386459351, train/logprobs = tensor([[-1.1184, -1.5607],
        [-0.9778, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26586613059043884
Epoch 0, Step 736: train/loss = 0.6230772137641907, train/raw-loss = 0.6047260165214539, train/logprobs = tensor([[-0.4418, -1.2508],
        [-0.8592, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18351206183433533
Epoch 0, Step 737: train/loss = 0.21814590692520142, train/raw-loss = 0.19007161259651184, train/logprobs = tensor([[-0.9762, -4.2387],
        [-2.3278, -1.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28074315190315247
Epoch 0, Step 738: train/loss = 0.566594660282135, train/raw-loss = 0.5410955548286438, train/logprobs = tensor([[-0.6361, -2.2812],
        [-1.7816, -1.2026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549908757209778
Epoch 0, Step 739: train/loss = 0.32917413115501404, train/raw-loss = 0.30609264969825745, train/logprobs = tensor([[-1.2096, -4.2105],
        [-2.6205, -1.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2308148741722107
Epoch 0, Step 740: train/loss = 0.1987268179655075, train/raw-loss = 0.17533130943775177, train/logprobs = tensor([[-0.9895, -5.7144],
        [-1.8333, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23395505547523499
Epoch 0, Step 741: train/loss = 0.18243426084518433, train/raw-loss = 0.1514529287815094, train/logprobs = tensor([[-1.0355, -8.0858],
        [-2.2876, -1.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098132014274597
Epoch 0, Step 742: train/loss = 0.43503761291503906, train/raw-loss = 0.4105560779571533, train/logprobs = tensor([[-0.6105, -3.1086],
        [-1.1913, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24481512606143951
Epoch 0, Step 743: train/loss = 0.2857091426849365, train/raw-loss = 0.26357364654541016, train/logprobs = tensor([[-1.2772, -7.7938],
        [-1.9871, -1.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213548719882965
Epoch 0, Step 744: train/loss = 0.5640916228294373, train/raw-loss = 0.542171835899353, train/logprobs = tensor([[-0.7685, -1.3773],
        [-1.0124, -0.8296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21919843554496765
Epoch 0, Step 745: train/loss = 0.367047518491745, train/raw-loss = 0.34552112221717834, train/logprobs = tensor([[-0.5841, -3.7686],
        [-0.9288, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21526426076889038
Epoch 0, Step 746: train/loss = 0.6336408853530884, train/raw-loss = 0.60930335521698, train/logprobs = tensor([[-0.7838, -0.9130],
        [-1.2068, -0.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24337518215179443
Epoch 0, Step 747: train/loss = 0.4333687722682953, train/raw-loss = 0.41234704852104187, train/logprobs = tensor([[-0.6771, -2.5387],
        [-0.9740, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21021738648414612
Epoch 0, Step 748: train/loss = 0.47057873010635376, train/raw-loss = 0.44900739192962646, train/logprobs = tensor([[-0.5017, -1.7251],
        [-1.3498, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21571314334869385
Epoch 0, Step 749: train/loss = 0.4685212969779968, train/raw-loss = 0.4433934986591339, train/logprobs = tensor([[-1.1302, -4.4403],
        [-1.6099, -1.5310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512781620025635
Epoch 0, Step 750: train/loss = 0.3712872266769409, train/raw-loss = 0.3471148610115051, train/logprobs = tensor([[-0.9172, -4.4428],
        [-2.5638, -2.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24172362685203552
Epoch 0, Step 751: train/loss = 0.5683057904243469, train/raw-loss = 0.5434856414794922, train/logprobs = tensor([[-0.7064, -3.5970],
        [-1.1887, -1.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2482016384601593
Epoch 0, Step 752: train/loss = 0.49041345715522766, train/raw-loss = 0.469272255897522, train/logprobs = tensor([[-0.5556, -3.6970],
        [-1.1038, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21141201257705688
Epoch 0, Step 753: train/loss = 0.31980445981025696, train/raw-loss = 0.2962624728679657, train/logprobs = tensor([[-0.7685, -3.7760],
        [-1.2145, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23541969060897827
Epoch 0, Step 754: train/loss = 0.33868739008903503, train/raw-loss = 0.3144446909427643, train/logprobs = tensor([[-0.7728, -3.5515],
        [-1.4971, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24242687225341797
Epoch 0, Step 755: train/loss = 0.2834749221801758, train/raw-loss = 0.256875216960907, train/logprobs = tensor([[-1.0688, -6.6872],
        [-2.0835, -2.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26599714159965515
Epoch 0, Step 756: train/loss = 0.3778361976146698, train/raw-loss = 0.35503628849983215, train/logprobs = tensor([[-1.2284, -5.2207],
        [-1.7513, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22799935936927795
Epoch 0, Step 757: train/loss = 0.48714300990104675, train/raw-loss = 0.45858222246170044, train/logprobs = tensor([[-0.7803, -4.2253],
        [-1.2763, -1.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856082618236542
Epoch 0, Step 758: train/loss = 0.31609004735946655, train/raw-loss = 0.2940126657485962, train/logprobs = tensor([[-0.6308, -5.6630],
        [-1.3877, -2.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2207740843296051
Epoch 0, Step 759: train/loss = 0.38802334666252136, train/raw-loss = 0.36436936259269714, train/logprobs = tensor([[-0.8760, -4.3751],
        [-1.3497, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23653963208198547
Epoch 0, Step 760: train/loss = 0.4782526195049286, train/raw-loss = 0.45266395807266235, train/logprobs = tensor([[-1.5212, -3.8106],
        [-1.8186, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25588667392730713
Epoch 0, Step 761: train/loss = 0.668145477771759, train/raw-loss = 0.6424068212509155, train/logprobs = tensor([[-1.6388, -1.7475],
        [-1.8608, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25738608837127686
Epoch 0, Step 762: train/loss = 0.4144699275493622, train/raw-loss = 0.38790085911750793, train/logprobs = tensor([[-0.7271, -3.5793],
        [-1.4845, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26569026708602905
Epoch 0, Step 763: train/loss = 0.3582543730735779, train/raw-loss = 0.32895952463150024, train/logprobs = tensor([[-1.0192, -3.2875],
        [-1.7498, -1.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29294872283935547
Epoch 0, Step 764: train/loss = 0.4686506688594818, train/raw-loss = 0.44651806354522705, train/logprobs = tensor([[-0.6960, -1.9206],
        [-1.4517, -1.2361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22132635116577148
Epoch 0, Step 765: train/loss = 0.38166171312332153, train/raw-loss = 0.35686761140823364, train/logprobs = tensor([[-0.7603, -5.9632],
        [-1.6522, -1.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2479408085346222
Epoch 0, Step 766: train/loss = 0.2378707230091095, train/raw-loss = 0.21011658012866974, train/logprobs = tensor([[-1.0331, -4.5810],
        [-1.7945, -1.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27754151821136475
Epoch 0, Step 767: train/loss = 0.5400009751319885, train/raw-loss = 0.5165691375732422, train/logprobs = tensor([[-0.7580, -2.2815],
        [-1.0961, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23431813716888428
Epoch 0, Step 768: train/loss = 0.6234598159790039, train/raw-loss = 0.6033535003662109, train/logprobs = tensor([[-0.6721, -1.1899],
        [-0.8907, -1.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20106324553489685
Epoch 0, Step 769: train/loss = 0.3383585512638092, train/raw-loss = 0.3128391206264496, train/logprobs = tensor([[-1.0371, -3.6496],
        [-1.6668, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551942467689514
Epoch 0, Step 770: train/loss = 0.4258727431297302, train/raw-loss = 0.4047204554080963, train/logprobs = tensor([[-0.6020, -2.4834],
        [-0.9665, -1.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21152272820472717
Epoch 0, Step 771: train/loss = 0.2642841637134552, train/raw-loss = 0.24382752180099487, train/logprobs = tensor([[-0.7274, -5.5116],
        [-1.1241, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045663446187973
Epoch 0, Step 772: train/loss = 0.2660965621471405, train/raw-loss = 0.2415461540222168, train/logprobs = tensor([[-1.1585, -4.3358],
        [-1.6713, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24550414085388184
Epoch 0, Step 773: train/loss = 0.4379807710647583, train/raw-loss = 0.4126519560813904, train/logprobs = tensor([[-1.2397, -4.1763],
        [-1.3845, -1.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25328779220581055
Epoch 0, Step 774: train/loss = 0.46538811922073364, train/raw-loss = 0.4423626661300659, train/logprobs = tensor([[-1.6268, -3.6625],
        [-1.5349, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23025476932525635
Epoch 0, Step 775: train/loss = 0.7796933650970459, train/raw-loss = 0.7548760175704956, train/logprobs = tensor([[-3.2324, -8.8862],
        [-1.7326, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24817386269569397
Epoch 0, Step 776: train/loss = 0.28445136547088623, train/raw-loss = 0.2641402781009674, train/logprobs = tensor([[-0.9226, -5.2137],
        [-1.4169, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20311108231544495
Epoch 0, Step 777: train/loss = 0.43901917338371277, train/raw-loss = 0.41910111904144287, train/logprobs = tensor([[-0.5991, -2.3931],
        [-1.0711, -0.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1991804540157318
Epoch 0, Step 778: train/loss = 0.3655458688735962, train/raw-loss = 0.3417730927467346, train/logprobs = tensor([[-0.7997, -4.2209],
        [-1.2192, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23772771656513214
Epoch 0, Step 779: train/loss = 0.4683462381362915, train/raw-loss = 0.44676318764686584, train/logprobs = tensor([[-1.0046, -4.6170],
        [-0.9161, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158307433128357
Epoch 0, Step 780: train/loss = 0.5564631223678589, train/raw-loss = 0.534439206123352, train/logprobs = tensor([[-0.7717, -2.5296],
        [-0.7823, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2202388197183609
Epoch 0, Step 781: train/loss = 0.4282580018043518, train/raw-loss = 0.40267980098724365, train/logprobs = tensor([[-1.1550, -3.3158],
        [-1.6874, -1.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557818293571472
Epoch 0, Step 782: train/loss = 0.4017331898212433, train/raw-loss = 0.3712907135486603, train/logprobs = tensor([[-2.0365, -7.9820],
        [-1.7862, -1.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3044247031211853
Epoch 0, Step 783: train/loss = 0.2581842839717865, train/raw-loss = 0.2350773811340332, train/logprobs = tensor([[-0.7731, -4.8531],
        [-1.2723, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2310689389705658
Epoch 0, Step 784: train/loss = 0.21230699121952057, train/raw-loss = 0.1889287680387497, train/logprobs = tensor([[ -0.9592, -11.1149],
        [ -1.6084,  -1.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23378227651119232
Epoch 0, Step 785: train/loss = 0.47379714250564575, train/raw-loss = 0.45841705799102783, train/logprobs = tensor([[-0.4399, -3.4355],
        [-0.5733, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15380080044269562
Epoch 0, Step 786: train/loss = 0.2746661603450775, train/raw-loss = 0.25192874670028687, train/logprobs = tensor([[-0.8165, -6.9214],
        [-1.0737, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273739129304886
Epoch 0, Step 787: train/loss = 0.47639545798301697, train/raw-loss = 0.4540535509586334, train/logprobs = tensor([[-0.7771, -2.7404],
        [-1.1712, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341912984848022
Epoch 0, Step 788: train/loss = 0.34991246461868286, train/raw-loss = 0.3259001672267914, train/logprobs = tensor([[-0.8481, -7.6096],
        [-1.2856, -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24012307822704315
Epoch 0, Step 789: train/loss = 0.6089140772819519, train/raw-loss = 0.5883580446243286, train/logprobs = tensor([[-1.0651, -1.9261],
        [-0.9353, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20556068420410156
Epoch 0, Step 790: train/loss = 0.4638303518295288, train/raw-loss = 0.4395192265510559, train/logprobs = tensor([[-0.7655, -3.2521],
        [-1.0419, -0.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24311120808124542
Epoch 0, Step 791: train/loss = 0.568468451499939, train/raw-loss = 0.5442361831665039, train/logprobs = tensor([[-1.2217, -1.7821],
        [-1.4731, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24232269823551178
Epoch 0, Step 792: train/loss = 0.35746875405311584, train/raw-loss = 0.3335145115852356, train/logprobs = tensor([[-0.9515, -3.9669],
        [-1.4401, -0.9718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395424246788025
Epoch 0, Step 793: train/loss = 0.4411056637763977, train/raw-loss = 0.4158715605735779, train/logprobs = tensor([[-0.9529, -6.5627],
        [-1.3871, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25234103202819824
Epoch 0, Step 794: train/loss = 0.277978777885437, train/raw-loss = 0.25030115246772766, train/logprobs = tensor([[-0.9031, -6.0768],
        [-1.5298, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767762541770935
Epoch 0, Step 795: train/loss = 0.35574501752853394, train/raw-loss = 0.33543047308921814, train/logprobs = tensor([[-1.0937, -4.2913],
        [-1.2913, -1.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2031455636024475
Epoch 0, Step 796: train/loss = 0.2827967405319214, train/raw-loss = 0.2593905031681061, train/logprobs = tensor([[-1.0355, -7.1363],
        [-1.4744, -1.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23406222462654114
Epoch 0, Step 797: train/loss = 0.4024195373058319, train/raw-loss = 0.381378710269928, train/logprobs = tensor([[-0.5539, -2.1370],
        [-0.9377, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21040832996368408
Epoch 0, Step 798: train/loss = 0.45169612765312195, train/raw-loss = 0.42926353216171265, train/logprobs = tensor([[-0.9207, -5.8677],
        [-1.0880, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22432592511177063
Epoch 0, Step 799: train/loss = 0.4716903865337372, train/raw-loss = 0.44655293226242065, train/logprobs = tensor([[-1.4403, -6.2489],
        [-1.6784, -1.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513749897480011
Epoch 0, Step 800: train/loss = 0.6570996046066284, train/raw-loss = 0.632830798625946, train/logprobs = tensor([[-1.5487, -2.5798],
        [-1.4068, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24268850684165955
Epoch 0, Step 801: train/loss = 0.20490562915802002, train/raw-loss = 0.17644605040550232, train/logprobs = tensor([[-1.2135, -8.9815],
        [-2.0041, -2.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845954895019531
Epoch 0, Step 802: train/loss = 0.4016435742378235, train/raw-loss = 0.3828932046890259, train/logprobs = tensor([[-0.8353, -2.8184],
        [-1.0876, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1875039041042328
Epoch 0, Step 803: train/loss = 0.3399465084075928, train/raw-loss = 0.3206014633178711, train/logprobs = tensor([[-0.8536, -4.7495],
        [-1.3057, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19345037639141083
Epoch 0, Step 804: train/loss = 0.47840583324432373, train/raw-loss = 0.45370474457740784, train/logprobs = tensor([[-0.9751, -4.0082],
        [-1.3834, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24701084196567535
Epoch 0, Step 805: train/loss = 0.4406631290912628, train/raw-loss = 0.4190106987953186, train/logprobs = tensor([[-0.6079, -3.1282],
        [-0.9925, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21652454137802124
Epoch 0, Step 806: train/loss = 0.34579944610595703, train/raw-loss = 0.320781946182251, train/logprobs = tensor([[-1.1028, -5.6890],
        [-1.5239, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25017493963241577
Epoch 0, Step 807: train/loss = 0.30045053362846375, train/raw-loss = 0.2766861915588379, train/logprobs = tensor([[-0.9750, -7.7519],
        [-1.2434, -1.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23764356970787048
Epoch 0, Step 808: train/loss = 0.2851715385913849, train/raw-loss = 0.26523879170417786, train/logprobs = tensor([[-0.7855, -4.6908],
        [-1.2637, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19932758808135986
Epoch 0, Step 809: train/loss = 0.3194412887096405, train/raw-loss = 0.2968222200870514, train/logprobs = tensor([[-0.9176, -6.1196],
        [-1.4059, -0.7986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22619102895259857
Epoch 0, Step 810: train/loss = 0.27172064781188965, train/raw-loss = 0.24725660681724548, train/logprobs = tensor([[-0.8126, -5.6222],
        [-1.3402, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446405291557312
Epoch 0, Step 811: train/loss = 0.47262340784072876, train/raw-loss = 0.4457389712333679, train/logprobs = tensor([[-0.8871, -4.2533],
        [-1.2814, -1.5649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688441574573517
Epoch 0, Step 812: train/loss = 0.5266697406768799, train/raw-loss = 0.5055234432220459, train/logprobs = tensor([[-0.9704, -2.4759],
        [-1.2559, -1.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21146273612976074
Epoch 0, Step 813: train/loss = 0.5038206577301025, train/raw-loss = 0.4810473322868347, train/logprobs = tensor([[-1.1472, -2.1677],
        [-1.0197, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.227733314037323
Epoch 0, Step 814: train/loss = 0.19885966181755066, train/raw-loss = 0.17677758634090424, train/logprobs = tensor([[-1.0557, -6.3186],
        [-2.2872, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22082066535949707
Epoch 0, Step 815: train/loss = 0.41340598464012146, train/raw-loss = 0.39125773310661316, train/logprobs = tensor([[-0.9279, -3.1824],
        [-1.0536, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.221482515335083
Epoch 0, Step 816: train/loss = 0.28196030855178833, train/raw-loss = 0.26633182168006897, train/logprobs = tensor([[-0.5939, -9.0104],
        [-0.7168, -1.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15628501772880554
Epoch 0, Step 817: train/loss = 0.3430999517440796, train/raw-loss = 0.31807780265808105, train/logprobs = tensor([[-1.1481, -5.8737],
        [-1.6541, -1.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25022125244140625
Epoch 0, Step 818: train/loss = 0.29637765884399414, train/raw-loss = 0.27448588609695435, train/logprobs = tensor([[-0.8348, -8.5400],
        [-1.3700, -2.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2189178317785263
Epoch 0, Step 819: train/loss = 0.33461081981658936, train/raw-loss = 0.31659969687461853, train/logprobs = tensor([[-0.4397, -5.3878],
        [-0.8899, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801111251115799
Epoch 0, Step 820: train/loss = 0.35367730259895325, train/raw-loss = 0.32886481285095215, train/logprobs = tensor([[-1.1514, -4.5082],
        [-1.4125, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24812504649162292
Epoch 0, Step 821: train/loss = 0.375491738319397, train/raw-loss = 0.3513956367969513, train/logprobs = tensor([[-0.9525, -3.5268],
        [-1.5502, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24096116423606873
Epoch 0, Step 822: train/loss = 0.4555836617946625, train/raw-loss = 0.4366863965988159, train/logprobs = tensor([[-0.8856, -3.2479],
        [-1.0893, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188973069190979
Epoch 0, Step 823: train/loss = 0.5390819907188416, train/raw-loss = 0.5185950398445129, train/logprobs = tensor([[-1.5504, -5.6351],
        [-1.0768, -2.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20486924052238464
Epoch 0, Step 824: train/loss = 0.2844924032688141, train/raw-loss = 0.2626985013484955, train/logprobs = tensor([[-0.6508, -6.1467],
        [-1.3096, -1.2830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21793878078460693
Epoch 0, Step 825: train/loss = 0.6698912382125854, train/raw-loss = 0.6453880071640015, train/logprobs = tensor([[-1.3279, -0.8962],
        [-1.7098, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24503245949745178
Epoch 0, Step 826: train/loss = 0.33537420630455017, train/raw-loss = 0.3107949495315552, train/logprobs = tensor([[-1.1494, -4.2103],
        [-1.6810, -1.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24579283595085144
Epoch 0, Step 827: train/loss = 0.397877037525177, train/raw-loss = 0.377565860748291, train/logprobs = tensor([[-0.6792, -3.5460],
        [-0.8166, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20311149954795837
Epoch 0, Step 828: train/loss = 0.26780158281326294, train/raw-loss = 0.24064132571220398, train/logprobs = tensor([[-1.1220, -4.0965],
        [-1.9649, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716026306152344
Epoch 0, Step 829: train/loss = 0.5401862263679504, train/raw-loss = 0.5141632556915283, train/logprobs = tensor([[-1.4571, -4.6298],
        [-1.4708, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602301239967346
Epoch 0, Step 830: train/loss = 0.3954356014728546, train/raw-loss = 0.37666359543800354, train/logprobs = tensor([[-0.5425, -6.2752],
        [-0.7806, -1.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1877199411392212
Epoch 0, Step 831: train/loss = 0.2796304523944855, train/raw-loss = 0.2605106830596924, train/logprobs = tensor([[-0.5607, -2.7153],
        [-1.3109, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19119742512702942
Epoch 0, Step 832: train/loss = 0.34061485528945923, train/raw-loss = 0.31786733865737915, train/logprobs = tensor([[-1.0295, -3.4571],
        [-1.7053, -0.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22747530043125153
Epoch 0, Step 833: train/loss = 0.6011524796485901, train/raw-loss = 0.5738007426261902, train/logprobs = tensor([[-1.0373, -1.5199],
        [-1.1068, -0.8717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2735171616077423
Epoch 0, Step 834: train/loss = 0.310383141040802, train/raw-loss = 0.285515159368515, train/logprobs = tensor([[-1.4623, -6.7641],
        [-1.8506, -1.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2486799657344818
Epoch 0, Step 835: train/loss = 0.7166078090667725, train/raw-loss = 0.6941055059432983, train/logprobs = tensor([[-1.3253, -4.2207],
        [-1.7045, -2.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22502338886260986
Epoch 0, Step 836: train/loss = 0.39950382709503174, train/raw-loss = 0.37622734904289246, train/logprobs = tensor([[-0.8471, -5.2148],
        [-1.3988, -1.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23276488482952118
Epoch 0, Step 837: train/loss = 0.3304279148578644, train/raw-loss = 0.30741575360298157, train/logprobs = tensor([[-0.6647, -3.8636],
        [-1.0075, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23012149333953857
Epoch 0, Step 838: train/loss = 0.39491093158721924, train/raw-loss = 0.37299954891204834, train/logprobs = tensor([[-1.1240, -5.1016],
        [-1.2073, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21911348402500153
Epoch 0, Step 839: train/loss = 0.276636004447937, train/raw-loss = 0.25661253929138184, train/logprobs = tensor([[-0.8282, -5.0031],
        [-1.4507, -1.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20023462176322937
Epoch 0, Step 840: train/loss = 0.29311832785606384, train/raw-loss = 0.26606395840644836, train/logprobs = tensor([[-0.9144, -7.3466],
        [-1.8116, -1.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27054363489151
Epoch 0, Step 841: train/loss = 0.49727708101272583, train/raw-loss = 0.47381269931793213, train/logprobs = tensor([[-0.8494, -2.9237],
        [-1.2979, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23464347422122955
Epoch 0, Step 842: train/loss = 0.34247392416000366, train/raw-loss = 0.32090437412261963, train/logprobs = tensor([[-0.7185, -6.4117],
        [-1.6422, -1.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21569551527500153
Epoch 0, Step 843: train/loss = 0.3942524790763855, train/raw-loss = 0.36929410696029663, train/logprobs = tensor([[-1.4861, -5.6781],
        [-1.3066, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24958404898643494
Epoch 0, Step 844: train/loss = 0.47299644351005554, train/raw-loss = 0.44872182607650757, train/logprobs = tensor([[-1.8514, -5.8313],
        [-1.5363, -1.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24274632334709167
Epoch 0, Step 845: train/loss = 0.3079913854598999, train/raw-loss = 0.28300490975379944, train/logprobs = tensor([[-1.1376, -7.1105],
        [-1.8819, -1.8272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24986499547958374
Epoch 0, Step 846: train/loss = 0.2954297661781311, train/raw-loss = 0.2784247398376465, train/logprobs = tensor([[-0.6552, -9.5458],
        [-1.0910, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17005036771297455
Epoch 0, Step 847: train/loss = 0.40276604890823364, train/raw-loss = 0.3815479278564453, train/logprobs = tensor([[-1.0873, -4.7305],
        [-1.3609, -1.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21218106150627136
Epoch 0, Step 848: train/loss = 0.21633344888687134, train/raw-loss = 0.18917599320411682, train/logprobs = tensor([[-1.0514, -5.4260],
        [-2.1753, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715747356414795
Epoch 0, Step 849: train/loss = 0.2522088289260864, train/raw-loss = 0.22777432203292847, train/logprobs = tensor([[-1.6464, -9.2436],
        [-2.1054, -1.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24434523284435272
Epoch 0, Step 850: train/loss = 0.41355079412460327, train/raw-loss = 0.3904877305030823, train/logprobs = tensor([[-0.7295, -4.8792],
        [-1.0356, -1.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306307852268219
Epoch 0, Step 851: train/loss = 0.327928751707077, train/raw-loss = 0.3039557933807373, train/logprobs = tensor([[-1.2135, -6.4617],
        [-1.8479, -1.2521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23972946405410767
Epoch 0, Step 852: train/loss = 0.335529088973999, train/raw-loss = 0.31325942277908325, train/logprobs = tensor([[-0.7201, -4.6344],
        [-1.4156, -1.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22269678115844727
Epoch 0, Step 853: train/loss = 0.5563465356826782, train/raw-loss = 0.5340681076049805, train/logprobs = tensor([[-1.6661, -4.2466],
        [-1.7135, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2227843999862671
Epoch 0, Step 854: train/loss = 0.3336217403411865, train/raw-loss = 0.30825844407081604, train/logprobs = tensor([[-1.0666, -6.2160],
        [-1.6660, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536328136920929
Epoch 0, Step 855: train/loss = 0.3655547499656677, train/raw-loss = 0.34370940923690796, train/logprobs = tensor([[-0.9375, -4.9267],
        [-1.5225, -2.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21845343708992004
Epoch 0, Step 856: train/loss = 0.2504115700721741, train/raw-loss = 0.2240401655435562, train/logprobs = tensor([[-1.0344, -5.0880],
        [-1.8633, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26371410489082336
Epoch 0, Step 857: train/loss = 0.29914212226867676, train/raw-loss = 0.27160030603408813, train/logprobs = tensor([[-1.0227, -6.7816],
        [-1.7363, -1.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2754184305667877
Epoch 0, Step 858: train/loss = 0.6122230291366577, train/raw-loss = 0.5865814685821533, train/logprobs = tensor([[-2.5447, -3.7993],
        [-1.7920, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25641563534736633
Epoch 0, Step 859: train/loss = 0.42418423295021057, train/raw-loss = 0.4014585018157959, train/logprobs = tensor([[-1.0249, -4.4535],
        [-1.7957, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22725734114646912
Epoch 0, Step 860: train/loss = 0.4025256037712097, train/raw-loss = 0.37957149744033813, train/logprobs = tensor([[-1.1075, -4.7840],
        [-1.3900, -1.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22954092919826508
Epoch 0, Step 861: train/loss = 0.5201106667518616, train/raw-loss = 0.494973361492157, train/logprobs = tensor([[-1.2749, -4.4889],
        [-1.2748, -1.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513730525970459
Epoch 0, Step 862: train/loss = 0.3448261320590973, train/raw-loss = 0.3186064660549164, train/logprobs = tensor([[-1.2245, -7.2162],
        [-1.3620, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26219671964645386
Epoch 0, Step 863: train/loss = 0.5455111861228943, train/raw-loss = 0.5211873054504395, train/logprobs = tensor([[-1.5193, -4.7256],
        [-1.3837, -0.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24323920905590057
Epoch 0, Step 864: train/loss = 0.6516417860984802, train/raw-loss = 0.6259217262268066, train/logprobs = tensor([[-1.6731, -2.7510],
        [-1.4935, -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572008967399597
Epoch 0, Step 865: train/loss = 0.29928892850875854, train/raw-loss = 0.27311456203460693, train/logprobs = tensor([[-1.0600, -3.5990],
        [-1.9069, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2617439031600952
Epoch 0, Step 866: train/loss = 0.2642216682434082, train/raw-loss = 0.24052023887634277, train/logprobs = tensor([[-0.8471, -6.5591],
        [-1.1746, -1.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23701399564743042
Epoch 0, Step 867: train/loss = 0.5329115390777588, train/raw-loss = 0.5071475505828857, train/logprobs = tensor([[-0.9874, -3.0965],
        [-1.5523, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576390504837036
Epoch 0, Step 868: train/loss = 0.419197678565979, train/raw-loss = 0.3888213634490967, train/logprobs = tensor([[-1.2612, -2.4322],
        [-1.8927, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303763210773468
Epoch 0, Step 869: train/loss = 0.3265167474746704, train/raw-loss = 0.3004482686519623, train/logprobs = tensor([[-1.1776, -2.3621],
        [-2.2202, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26068490743637085
Epoch 0, Step 870: train/loss = 0.4015454649925232, train/raw-loss = 0.37655267119407654, train/logprobs = tensor([[-1.2412, -7.2263],
        [-1.7220, -1.9726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24992793798446655
Epoch 0, Step 871: train/loss = 0.31175529956817627, train/raw-loss = 0.29017046093940735, train/logprobs = tensor([[-0.7429, -5.7720],
        [-1.1358, -1.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158484309911728
Epoch 0, Step 872: train/loss = 0.45048198103904724, train/raw-loss = 0.43028783798217773, train/logprobs = tensor([[-0.5401, -3.8446],
        [-0.7451, -1.2933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20194190740585327
Epoch 0, Step 873: train/loss = 0.38700416684150696, train/raw-loss = 0.36601361632347107, train/logprobs = tensor([[-1.1564, -3.9649],
        [-1.5142, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20990559458732605
Epoch 0, Step 874: train/loss = 0.27959948778152466, train/raw-loss = 0.2502274513244629, train/logprobs = tensor([[-1.4616, -6.9698],
        [-2.3097, -1.1686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937203645706177
Epoch 0, Step 875: train/loss = 0.6007137894630432, train/raw-loss = 0.5757243633270264, train/logprobs = tensor([[-1.2033, -1.5536],
        [-2.1477, -1.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24989387392997742
Epoch 0, Step 876: train/loss = 0.35101330280303955, train/raw-loss = 0.3326926529407501, train/logprobs = tensor([[-0.5741, -7.0805],
        [-1.0320, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18320630490779877
Epoch 0, Step 877: train/loss = 0.3539212644100189, train/raw-loss = 0.32587572932243347, train/logprobs = tensor([[-1.6352, -5.8224],
        [-2.9065, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804553210735321
Epoch 0, Step 878: train/loss = 0.728873610496521, train/raw-loss = 0.7031848430633545, train/logprobs = tensor([[-2.9386, -5.9656],
        [-1.8405, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568879723548889
Epoch 0, Step 879: train/loss = 0.2670671343803406, train/raw-loss = 0.24399057030677795, train/logprobs = tensor([[-0.6440, -8.6112],
        [-1.4085, -1.8886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076561093330383
Epoch 0, Step 880: train/loss = 0.2976977527141571, train/raw-loss = 0.2750644087791443, train/logprobs = tensor([[-0.8709, -5.3360],
        [-1.4312, -1.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263336181640625
Epoch 0, Step 881: train/loss = 0.44785991311073303, train/raw-loss = 0.42467001080513, train/logprobs = tensor([[-0.7715, -4.7846],
        [-1.1146, -1.4406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23189902305603027
Epoch 0, Step 882: train/loss = 0.5443979501724243, train/raw-loss = 0.5188075304031372, train/logprobs = tensor([[-1.1533, -2.6902],
        [-1.2320, -1.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559041976928711
Epoch 0, Step 883: train/loss = 0.2889041006565094, train/raw-loss = 0.2618386745452881, train/logprobs = tensor([[-1.5163, -4.5981],
        [-2.3846, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27065417170524597
Epoch 0, Step 884: train/loss = 0.37346985936164856, train/raw-loss = 0.3472670614719391, train/logprobs = tensor([[-0.9882, -4.8843],
        [-1.3670, -1.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26202771067619324
Epoch 0, Step 885: train/loss = 0.3162119388580322, train/raw-loss = 0.2885626256465912, train/logprobs = tensor([[-1.5679, -6.8233],
        [-1.6916, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27649298310279846
Epoch 0, Step 886: train/loss = 0.4619147777557373, train/raw-loss = 0.4366040825843811, train/logprobs = tensor([[-0.9067, -3.2248],
        [-1.4508, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25310730934143066
Epoch 0, Step 887: train/loss = 0.419914186000824, train/raw-loss = 0.3967481255531311, train/logprobs = tensor([[-1.0055, -5.3351],
        [-1.3780, -1.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23166055977344513
Epoch 0, Step 888: train/loss = 0.1891295313835144, train/raw-loss = 0.16444946825504303, train/logprobs = tensor([[-0.9456, -6.5102],
        [-1.8610, -1.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24680058658123016
Epoch 0, Step 889: train/loss = 0.34838658571243286, train/raw-loss = 0.3204832971096039, train/logprobs = tensor([[-1.0727, -4.0360],
        [-1.6376, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790326774120331
Epoch 0, Step 890: train/loss = 0.3452033996582031, train/raw-loss = 0.31758183240890503, train/logprobs = tensor([[-1.0804, -4.1030],
        [-1.4868, -1.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2762157917022705
Epoch 0, Step 891: train/loss = 0.2643664479255676, train/raw-loss = 0.24314087629318237, train/logprobs = tensor([[-1.0134, -6.4025],
        [-1.5838, -1.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122558057308197
Epoch 0, Step 892: train/loss = 0.35152411460876465, train/raw-loss = 0.3266181945800781, train/logprobs = tensor([[-0.9451, -4.8015],
        [-1.3971, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24905917048454285
Epoch 0, Step 893: train/loss = 0.40725722908973694, train/raw-loss = 0.3843246102333069, train/logprobs = tensor([[-1.0729, -4.6221],
        [-1.4476, -1.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22932618856430054
Epoch 0, Step 894: train/loss = 0.30296024680137634, train/raw-loss = 0.2770422101020813, train/logprobs = tensor([[-0.9364, -7.5250],
        [-1.5660, -1.6602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591805160045624
Epoch 0, Step 895: train/loss = 0.4220491647720337, train/raw-loss = 0.39754748344421387, train/logprobs = tensor([[-0.8348, -5.8748],
        [-1.6947, -2.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.245016947388649
Epoch 0, Step 896: train/loss = 0.4815361797809601, train/raw-loss = 0.4564400613307953, train/logprobs = tensor([[-1.2836, -2.9233],
        [-1.4093, -1.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2509610652923584
Epoch 0, Step 897: train/loss = 0.41912370920181274, train/raw-loss = 0.386982262134552, train/logprobs = tensor([[-1.2866, -3.9191],
        [-2.0015, -1.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3214152157306671
Epoch 0, Step 898: train/loss = 0.46481409668922424, train/raw-loss = 0.4410936236381531, train/logprobs = tensor([[-0.9682, -1.6190],
        [-1.6174, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23720501363277435
Epoch 0, Step 899: train/loss = 0.3735077977180481, train/raw-loss = 0.3465145528316498, train/logprobs = tensor([[-0.9123, -4.9531],
        [-1.4654, -1.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26993227005004883
Epoch 0, Step 900: train/loss = 0.2701967656612396, train/raw-loss = 0.24266159534454346, train/logprobs = tensor([[ -1.7713, -10.7190],
        [ -2.1421,  -2.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27535146474838257
Epoch 0, Step 901: train/loss = 0.28801366686820984, train/raw-loss = 0.2633501887321472, train/logprobs = tensor([[-0.5067, -4.8060],
        [-1.3179, -1.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246634840965271
Epoch 0, Step 902: train/loss = 0.19795987010002136, train/raw-loss = 0.1735157072544098, train/logprobs = tensor([[-0.8816, -8.0034],
        [-1.8135, -1.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2444416582584381
Epoch 0, Step 903: train/loss = 0.37824758887290955, train/raw-loss = 0.3493867516517639, train/logprobs = tensor([[-1.3548, -4.4843],
        [-2.0171, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886080741882324
Epoch 0, Step 904: train/loss = 0.4341561496257782, train/raw-loss = 0.40985381603240967, train/logprobs = tensor([[-1.8020, -4.8947],
        [-1.9353, -1.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24302314221858978
Epoch 0, Step 905: train/loss = 0.2345786690711975, train/raw-loss = 0.21282847225666046, train/logprobs = tensor([[-0.6110, -7.2714],
        [-1.3781, -2.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21750202775001526
Epoch 0, Step 906: train/loss = 0.5792220830917358, train/raw-loss = 0.5585399866104126, train/logprobs = tensor([[-0.9229, -1.7331],
        [-0.8086, -0.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20682062208652496
Epoch 0, Step 907: train/loss = 0.5781682133674622, train/raw-loss = 0.5516012907028198, train/logprobs = tensor([[-1.0897, -2.1126],
        [-1.0926, -0.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26566898822784424
Epoch 0, Step 908: train/loss = 0.308110773563385, train/raw-loss = 0.28281262516975403, train/logprobs = tensor([[-0.9780, -5.9617],
        [-1.6693, -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529814541339874
Epoch 0, Step 909: train/loss = 0.2999310791492462, train/raw-loss = 0.2699057459831238, train/logprobs = tensor([[-1.8524, -5.0861],
        [-2.5958, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30025342106819153
Epoch 0, Step 910: train/loss = 0.49558568000793457, train/raw-loss = 0.47068411111831665, train/logprobs = tensor([[-1.4172, -4.5756],
        [-1.4473, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2490159124135971
Epoch 0, Step 911: train/loss = 0.24593283236026764, train/raw-loss = 0.22205480933189392, train/logprobs = tensor([[-1.1166, -6.8483],
        [-1.6509, -1.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2387802004814148
Epoch 0, Step 912: train/loss = 0.4249846935272217, train/raw-loss = 0.399669885635376, train/logprobs = tensor([[-1.4846, -5.9165],
        [-1.3434, -1.9063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25314778089523315
Epoch 0, Step 913: train/loss = 0.29223862290382385, train/raw-loss = 0.26579129695892334, train/logprobs = tensor([[-0.9078, -6.6198],
        [-1.8643, -2.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644731402397156
Epoch 0, Step 914: train/loss = 0.4738939106464386, train/raw-loss = 0.4521297514438629, train/logprobs = tensor([[-0.5261, -2.5823],
        [-1.1675, -1.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2176416516304016
Epoch 0, Step 915: train/loss = 0.36360257863998413, train/raw-loss = 0.3378995358943939, train/logprobs = tensor([[-1.0283, -3.9913],
        [-1.5430, -1.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25703075528144836
Epoch 0, Step 916: train/loss = 0.417932391166687, train/raw-loss = 0.39623796939849854, train/logprobs = tensor([[-1.8326, -3.7504],
        [-1.7051, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2169443964958191
Epoch 0, Step 917: train/loss = 0.3729967474937439, train/raw-loss = 0.3465149998664856, train/logprobs = tensor([[-1.3919, -3.7368],
        [-1.8660, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2648178040981293
Epoch 0, Step 918: train/loss = 0.47924894094467163, train/raw-loss = 0.4530831575393677, train/logprobs = tensor([[-0.7396, -2.0740],
        [-1.1451, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26165759563446045
Epoch 0, Step 919: train/loss = 0.4572155177593231, train/raw-loss = 0.43354058265686035, train/logprobs = tensor([[-1.1229, -3.5075],
        [-1.4510, -1.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23674924671649933
Epoch 0, Step 920: train/loss = 0.5977573394775391, train/raw-loss = 0.5724793672561646, train/logprobs = tensor([[-1.2500, -1.0815],
        [-1.6401, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25277942419052124
Epoch 0, Step 921: train/loss = 0.5393294095993042, train/raw-loss = 0.5184953808784485, train/logprobs = tensor([[-0.5979, -2.2184],
        [-1.3510, -1.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20834015309810638
Epoch 0, Step 922: train/loss = 0.45453280210494995, train/raw-loss = 0.43049561977386475, train/logprobs = tensor([[-0.9895, -4.4753],
        [-1.0608, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24037179350852966
Epoch 0, Step 923: train/loss = 0.43051230907440186, train/raw-loss = 0.40226998925209045, train/logprobs = tensor([[-1.5007, -5.2881],
        [-1.6260, -1.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2824229598045349
Epoch 0, Step 924: train/loss = 0.2934276759624481, train/raw-loss = 0.26816824078559875, train/logprobs = tensor([[-1.1301, -6.0120],
        [-1.9413, -2.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525942623615265
Epoch 0, Step 925: train/loss = 0.4632508158683777, train/raw-loss = 0.4436812102794647, train/logprobs = tensor([[-0.6479, -2.3304],
        [-0.8396, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1956959366798401
Epoch 0, Step 926: train/loss = 0.5041244626045227, train/raw-loss = 0.4828457236289978, train/logprobs = tensor([[-0.6018, -2.5244],
        [-0.9412, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21278724074363708
Epoch 0, Step 927: train/loss = 0.533804714679718, train/raw-loss = 0.5070925951004028, train/logprobs = tensor([[-1.7151, -3.8982],
        [-1.4167, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267121285200119
Epoch 0, Step 928: train/loss = 0.3203861117362976, train/raw-loss = 0.29200518131256104, train/logprobs = tensor([[-1.2942, -6.0488],
        [-1.4538, -1.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838095724582672
Epoch 0, Step 929: train/loss = 0.2816624045372009, train/raw-loss = 0.25485336780548096, train/logprobs = tensor([[-0.8316, -4.4570],
        [-1.9839, -2.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26809021830558777
Epoch 0, Step 930: train/loss = 0.41159677505493164, train/raw-loss = 0.3819812536239624, train/logprobs = tensor([[-1.0492, -2.8536],
        [-1.8685, -1.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29615530371665955
Epoch 0, Step 931: train/loss = 0.28468057513237, train/raw-loss = 0.2607339322566986, train/logprobs = tensor([[-0.9397, -4.0483],
        [-1.6393, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23946620523929596
Epoch 0, Step 932: train/loss = 0.3076229989528656, train/raw-loss = 0.27716949582099915, train/logprobs = tensor([[-0.7348, -4.8262],
        [-1.8163, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304534912109375
Epoch 0, Step 933: train/loss = 0.4021245837211609, train/raw-loss = 0.3776354491710663, train/logprobs = tensor([[-0.8553, -2.7896],
        [-1.4852, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24489153921604156
Epoch 0, Step 934: train/loss = 0.4412641227245331, train/raw-loss = 0.4154982566833496, train/logprobs = tensor([[-0.6737, -3.4914],
        [-1.3864, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25765886902809143
Epoch 0, Step 935: train/loss = 0.34434330463409424, train/raw-loss = 0.3135526478290558, train/logprobs = tensor([[-1.2076, -4.4228],
        [-2.1352, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079065978527069
Epoch 0, Step 936: train/loss = 0.4495531916618347, train/raw-loss = 0.4173915982246399, train/logprobs = tensor([[-1.3493, -3.3062],
        [-2.0367, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32161563634872437
Epoch 0, Step 937: train/loss = 0.4627898931503296, train/raw-loss = 0.434542179107666, train/logprobs = tensor([[-1.2022, -4.5997],
        [-1.5198, -1.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2824772000312805
Epoch 0, Step 938: train/loss = 0.2889597415924072, train/raw-loss = 0.2558356821537018, train/logprobs = tensor([[-1.0699, -3.8889],
        [-2.5373, -1.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33124101161956787
Epoch 0, Step 939: train/loss = 0.32058799266815186, train/raw-loss = 0.2940194010734558, train/logprobs = tensor([[-1.2133, -4.6076],
        [-1.4977, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2656857371330261
Epoch 0, Step 940: train/loss = 0.23655882477760315, train/raw-loss = 0.204965740442276, train/logprobs = tensor([[-1.2165, -4.6020],
        [-2.5424, -1.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159307837486267
Epoch 0, Step 941: train/loss = 0.3559950590133667, train/raw-loss = 0.3323898911476135, train/logprobs = tensor([[-1.1897, -4.5027],
        [-1.7267, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23605190217494965
Epoch 0, Step 942: train/loss = 0.393402099609375, train/raw-loss = 0.36209797859191895, train/logprobs = tensor([[-1.4052, -4.6911],
        [-2.2231, -2.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313041090965271
Epoch 0, Step 943: train/loss = 0.3265036642551422, train/raw-loss = 0.29346850514411926, train/logprobs = tensor([[-1.1500, -3.6306],
        [-2.7075, -1.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330351859331131
Epoch 0, Step 944: train/loss = 0.17190659046173096, train/raw-loss = 0.1437799632549286, train/logprobs = tensor([[-1.0013, -8.8001],
        [-2.3784, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28126639127731323
Epoch 0, Step 945: train/loss = 0.4364892542362213, train/raw-loss = 0.4105848968029022, train/logprobs = tensor([[-1.7757, -3.4116],
        [-1.9633, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25904327630996704
Epoch 0, Step 946: train/loss = 0.3297916352748871, train/raw-loss = 0.30211371183395386, train/logprobs = tensor([[-1.2261, -7.4453],
        [-2.1030, -1.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767791748046875
Epoch 0, Step 947: train/loss = 0.6679120063781738, train/raw-loss = 0.6445684432983398, train/logprobs = tensor([[-1.0663, -1.1597],
        [-1.2855, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23343519866466522
Epoch 0, Step 948: train/loss = 0.3716483414173126, train/raw-loss = 0.34116536378860474, train/logprobs = tensor([[-0.9698, -3.5732],
        [-1.7124, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048299252986908
Epoch 0, Step 949: train/loss = 0.4260896146297455, train/raw-loss = 0.395372211933136, train/logprobs = tensor([[-1.2743, -3.6443],
        [-1.8589, -1.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3071739971637726
Epoch 0, Step 950: train/loss = 0.25042223930358887, train/raw-loss = 0.2282283902168274, train/logprobs = tensor([[-0.5799, -4.6415],
        [-1.8179, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22193843126296997
Epoch 0, Step 951: train/loss = 0.4827355146408081, train/raw-loss = 0.45214033126831055, train/logprobs = tensor([[-1.7657, -4.3540],
        [-1.8589, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30595192313194275
Epoch 0, Step 952: train/loss = 0.33320873975753784, train/raw-loss = 0.3124750852584839, train/logprobs = tensor([[-0.5353, -4.7730],
        [-1.1280, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20733612775802612
Epoch 0, Step 953: train/loss = 0.48319733142852783, train/raw-loss = 0.4608842730522156, train/logprobs = tensor([[-1.0074, -2.8142],
        [-1.6028, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22313059866428375
Epoch 0, Step 954: train/loss = 0.43559008836746216, train/raw-loss = 0.41370221972465515, train/logprobs = tensor([[-0.8733, -1.8152],
        [-1.4477, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21887895464897156
Epoch 0, Step 955: train/loss = 0.270222932100296, train/raw-loss = 0.24438506364822388, train/logprobs = tensor([[-1.0540, -7.6629],
        [-1.7215, -2.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583787143230438
Epoch 0, Step 956: train/loss = 0.31890785694122314, train/raw-loss = 0.29517948627471924, train/logprobs = tensor([[-0.7541, -5.2011],
        [-1.5848, -1.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23728352785110474
Epoch 0, Step 957: train/loss = 0.34637653827667236, train/raw-loss = 0.3217616677284241, train/logprobs = tensor([[-1.2585, -5.6103],
        [-1.9752, -2.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24614885449409485
Epoch 0, Step 958: train/loss = 0.3863690495491028, train/raw-loss = 0.36035606265068054, train/logprobs = tensor([[-1.1320, -5.2909],
        [-1.3563, -1.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601301372051239
Epoch 0, Step 959: train/loss = 0.3715977072715759, train/raw-loss = 0.3455367088317871, train/logprobs = tensor([[-0.8202, -4.8101],
        [-1.7958, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2606104016304016
Epoch 0, Step 960: train/loss = 0.46551451086997986, train/raw-loss = 0.4417375922203064, train/logprobs = tensor([[-0.8041, -1.6140],
        [-1.7757, -1.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23776929080486298
Epoch 0, Step 961: train/loss = 0.2288641482591629, train/raw-loss = 0.20224347710609436, train/logprobs = tensor([[-1.3566, -4.8501],
        [-2.6742, -0.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662065327167511
Epoch 0, Step 962: train/loss = 0.45985767245292664, train/raw-loss = 0.434387743473053, train/logprobs = tensor([[-1.7747, -5.1869],
        [-2.6245, -1.8886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2546995282173157
Epoch 0, Step 963: train/loss = 0.4620368480682373, train/raw-loss = 0.43341749906539917, train/logprobs = tensor([[-0.9145, -2.3641],
        [-1.4057, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286193311214447
Epoch 0, Step 964: train/loss = 0.39008069038391113, train/raw-loss = 0.36174607276916504, train/logprobs = tensor([[-1.0938, -3.3741],
        [-1.9776, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833460569381714
Epoch 0, Step 965: train/loss = 0.3179779648780823, train/raw-loss = 0.29689866304397583, train/logprobs = tensor([[-1.0976, -4.9217],
        [-1.8500, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210793137550354
Epoch 0, Step 966: train/loss = 0.33382660150527954, train/raw-loss = 0.30856335163116455, train/logprobs = tensor([[-0.5078, -3.0720],
        [-1.6652, -1.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526325285434723
Epoch 0, Step 967: train/loss = 0.3844611644744873, train/raw-loss = 0.36169588565826416, train/logprobs = tensor([[-0.7240, -2.9722],
        [-1.4878, -0.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22765251994132996
Epoch 0, Step 968: train/loss = 0.42902135848999023, train/raw-loss = 0.40087807178497314, train/logprobs = tensor([[-1.0103, -3.5694],
        [-2.5524, -2.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2814328670501709
Epoch 0, Step 969: train/loss = 0.33484140038490295, train/raw-loss = 0.3011983633041382, train/logprobs = tensor([[-0.7680, -5.4212],
        [-2.4176, -2.2419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33643078804016113
Epoch 0, Step 970: train/loss = 0.39454185962677, train/raw-loss = 0.36998510360717773, train/logprobs = tensor([[-0.7834, -3.1431],
        [-1.5951, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24556738138198853
Epoch 0, Step 971: train/loss = 0.3567664623260498, train/raw-loss = 0.33064258098602295, train/logprobs = tensor([[-0.4404, -4.9362],
        [-1.2904, -1.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26123902201652527
Epoch 0, Step 972: train/loss = 0.4128431975841522, train/raw-loss = 0.38895416259765625, train/logprobs = tensor([[-0.8962, -5.5902],
        [-1.3471, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2388898730278015
Epoch 0, Step 973: train/loss = 0.4940239191055298, train/raw-loss = 0.46848011016845703, train/logprobs = tensor([[-0.8878, -2.4239],
        [-1.7828, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2554382383823395
Epoch 0, Step 974: train/loss = 0.3807212710380554, train/raw-loss = 0.35104891657829285, train/logprobs = tensor([[-1.1463, -4.4294],
        [-1.9305, -2.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29672354459762573
Epoch 0, Step 975: train/loss = 0.2648196220397949, train/raw-loss = 0.2370990663766861, train/logprobs = tensor([[-0.6073, -4.4642],
        [-1.4418, -1.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772054076194763
Epoch 0, Step 976: train/loss = 0.4938039183616638, train/raw-loss = 0.4655221104621887, train/logprobs = tensor([[-0.4852, -3.3945],
        [-1.7305, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28281816840171814
Epoch 0, Step 977: train/loss = 0.4012126326560974, train/raw-loss = 0.3722059726715088, train/logprobs = tensor([[-0.9077, -4.1779],
        [-1.5902, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900661528110504
Epoch 0, Step 978: train/loss = 0.4067695438861847, train/raw-loss = 0.37738704681396484, train/logprobs = tensor([[-1.7862, -4.1351],
        [-2.0409, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938251197338104
Epoch 0, Step 979: train/loss = 0.3613508343696594, train/raw-loss = 0.33518314361572266, train/logprobs = tensor([[-0.7429, -3.3762],
        [-1.6853, -1.3178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616768479347229
Epoch 0, Step 980: train/loss = 0.24007508158683777, train/raw-loss = 0.21512390673160553, train/logprobs = tensor([[-0.7902, -4.5237],
        [-1.5268, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24951189756393433
Epoch 0, Step 981: train/loss = 0.3978154957294464, train/raw-loss = 0.36944395303726196, train/logprobs = tensor([[-1.7478, -6.0777],
        [-2.3971, -2.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28371548652648926
Epoch 0, Step 982: train/loss = 0.31995949149131775, train/raw-loss = 0.2923595905303955, train/logprobs = tensor([[-1.1135, -3.5686],
        [-1.8663, -1.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759989798069
Epoch 0, Step 983: train/loss = 0.3551986813545227, train/raw-loss = 0.32911986112594604, train/logprobs = tensor([[-0.9955, -3.6903],
        [-1.5434, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260788232088089
Epoch 0, Step 984: train/loss = 0.4504368305206299, train/raw-loss = 0.4187437891960144, train/logprobs = tensor([[-0.7154, -2.4163],
        [-1.9441, -1.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169305920600891
Epoch 0, Step 985: train/loss = 0.5129845142364502, train/raw-loss = 0.4895874261856079, train/logprobs = tensor([[-0.8259, -1.7503],
        [-1.2868, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23397153615951538
Epoch 0, Step 986: train/loss = 0.16475169360637665, train/raw-loss = 0.13351139426231384, train/logprobs = tensor([[-0.8897, -7.8630],
        [-2.5569, -2.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124029040336609
Epoch 0, Step 987: train/loss = 0.4567101299762726, train/raw-loss = 0.43469715118408203, train/logprobs = tensor([[-1.3312, -2.6810],
        [-1.6367, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22013017535209656
Epoch 0, Step 988: train/loss = 0.6099801659584045, train/raw-loss = 0.5790382027626038, train/logprobs = tensor([[-1.1055, -2.7563],
        [-3.1102, -2.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094193637371063
Epoch 0, Step 989: train/loss = 0.2597392797470093, train/raw-loss = 0.2291620373725891, train/logprobs = tensor([[-1.2056, -3.4023],
        [-2.1304, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30577218532562256
Epoch 0, Step 990: train/loss = 0.4270899295806885, train/raw-loss = 0.40019744634628296, train/logprobs = tensor([[-0.7649, -3.1473],
        [-1.4146, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268924742937088
Epoch 0, Step 991: train/loss = 0.5250031352043152, train/raw-loss = 0.49895673990249634, train/logprobs = tensor([[-0.7995, -1.5145],
        [-1.2005, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2604635953903198
Epoch 0, Step 992: train/loss = 0.2973201274871826, train/raw-loss = 0.27223360538482666, train/logprobs = tensor([[-0.6075, -4.4880],
        [-1.6355, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508651912212372
Epoch 0, Step 993: train/loss = 0.30738934874534607, train/raw-loss = 0.27610501646995544, train/logprobs = tensor([[-0.7195, -3.3368],
        [-2.0578, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3128434419631958
Epoch 0, Step 994: train/loss = 0.1311146765947342, train/raw-loss = 0.09761609882116318, train/logprobs = tensor([[-1.0067, -5.9933],
        [-2.8566, -1.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3349856734275818
Epoch 0, Step 995: train/loss = 0.185268372297287, train/raw-loss = 0.15913927555084229, train/logprobs = tensor([[-0.6578, -6.0168],
        [-1.6483, -1.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612910270690918
Epoch 0, Step 996: train/loss = 0.4639357924461365, train/raw-loss = 0.43965011835098267, train/logprobs = tensor([[-0.6678, -3.3440],
        [-1.4715, -1.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2428567260503769
Epoch 0, Step 997: train/loss = 0.22598963975906372, train/raw-loss = 0.20132435858249664, train/logprobs = tensor([[-0.8926, -5.9244],
        [-1.5206, -1.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246652752161026
Epoch 0, Step 998: train/loss = 0.2556493282318115, train/raw-loss = 0.2168232798576355, train/logprobs = tensor([[-0.9865, -3.9941],
        [-3.0253, -1.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38826054334640503
Epoch 0, Step 999: train/loss = 0.414162278175354, train/raw-loss = 0.3877173662185669, train/logprobs = tensor([[-0.7680, -2.6790],
        [-2.0110, -1.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644493281841278
Epoch 0, Step 1000: train/loss = 0.4247604012489319, train/raw-loss = 0.3907198905944824, train/logprobs = tensor([[-1.1517, -2.8141],
        [-2.9567, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404054045677185
Epoch 0, Step 1001: train/loss = 0.32858407497406006, train/raw-loss = 0.2980300188064575, train/logprobs = tensor([[-0.8848, -4.3511],
        [-2.0710, -1.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30554044246673584
Epoch 0, Step 1002: train/loss = 0.3917936682701111, train/raw-loss = 0.3549138307571411, train/logprobs = tensor([[-0.7410, -4.4160],
        [-2.3426, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3687981367111206
Epoch 0, Step 1003: train/loss = 0.35735490918159485, train/raw-loss = 0.3251476585865021, train/logprobs = tensor([[-1.6399, -4.6758],
        [-2.2796, -1.4555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.322072297334671
Epoch 0, Step 1004: train/loss = 0.6020662784576416, train/raw-loss = 0.5708433389663696, train/logprobs = tensor([[-0.9011, -1.5300],
        [-1.3143, -1.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31222912669181824
Epoch 0, Step 1005: train/loss = 0.10109396278858185, train/raw-loss = 0.07166525721549988, train/logprobs = tensor([[-0.8851, -7.9135],
        [-2.9083, -1.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942870557308197
Epoch 0, Step 1006: train/loss = 0.5317025184631348, train/raw-loss = 0.5051377415657043, train/logprobs = tensor([[-1.0554, -1.8951],
        [-1.7681, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2656474709510803
Epoch 0, Step 1007: train/loss = 0.5499346256256104, train/raw-loss = 0.5246744155883789, train/logprobs = tensor([[-1.8639, -2.1577],
        [-2.5728, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526020109653473
Epoch 0, Step 1008: train/loss = 0.4022147059440613, train/raw-loss = 0.37519800662994385, train/logprobs = tensor([[-0.8354, -4.4020],
        [-1.7196, -1.7805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27016714215278625
Epoch 0, Step 1009: train/loss = 0.4408216178417206, train/raw-loss = 0.40969303250312805, train/logprobs = tensor([[-0.9557, -5.9778],
        [-2.1610, -1.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31128567457199097
Epoch 0, Step 1010: train/loss = 0.4491737484931946, train/raw-loss = 0.41976234316825867, train/logprobs = tensor([[-1.2213, -3.9676],
        [-1.7118, -1.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29411420226097107
Epoch 0, Step 1011: train/loss = 0.5992766618728638, train/raw-loss = 0.5687253475189209, train/logprobs = tensor([[-0.8002, -2.3882],
        [-1.7773, -2.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055134117603302
Epoch 0, Step 1012: train/loss = 0.21110251545906067, train/raw-loss = 0.18361148238182068, train/logprobs = tensor([[-0.8324, -5.4803],
        [-2.5424, -1.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27491018176078796
Epoch 0, Step 1013: train/loss = 0.09542009979486465, train/raw-loss = 0.058994635939598083, train/logprobs = tensor([[-1.3202, -7.9225],
        [-4.2600, -1.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3642546236515045
Epoch 0, Step 1014: train/loss = 0.3551485240459442, train/raw-loss = 0.3248682916164398, train/logprobs = tensor([[-1.0516, -4.1997],
        [-2.2586, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028022348880768
Epoch 0, Step 1015: train/loss = 0.20401328802108765, train/raw-loss = 0.17496591806411743, train/logprobs = tensor([[-0.6579, -5.0187],
        [-2.7644, -1.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2904738485813141
Epoch 0, Step 1016: train/loss = 0.36252668499946594, train/raw-loss = 0.33297884464263916, train/logprobs = tensor([[-1.0958, -5.4177],
        [-2.2194, -1.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29547855257987976
Epoch 0, Step 1017: train/loss = 0.30441731214523315, train/raw-loss = 0.27269530296325684, train/logprobs = tensor([[-0.8639, -7.0664],
        [-1.9981, -2.2326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172200918197632
Epoch 0, Step 1018: train/loss = 0.4997144043445587, train/raw-loss = 0.4723227918148041, train/logprobs = tensor([[-1.3076, -3.8340],
        [-1.8155, -1.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739163935184479
Epoch 0, Step 1019: train/loss = 0.3329378664493561, train/raw-loss = 0.2967686057090759, train/logprobs = tensor([[-1.5532, -5.1623],
        [-2.7848, -1.9687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3616926074028015
Epoch 0, Step 1020: train/loss = 0.38279083371162415, train/raw-loss = 0.3571612536907196, train/logprobs = tensor([[-1.0426, -5.4230],
        [-1.5387, -2.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25629591941833496
Epoch 0, Step 1021: train/loss = 0.271269291639328, train/raw-loss = 0.24224627017974854, train/logprobs = tensor([[-0.8357, -5.8500],
        [-2.1157, -1.3248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902303636074066
Epoch 0, Step 1022: train/loss = 0.4647435247898102, train/raw-loss = 0.44158896803855896, train/logprobs = tensor([[-0.7285, -1.8528],
        [-1.4691, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23154565691947937
Epoch 0, Step 1023: train/loss = 0.6743443012237549, train/raw-loss = 0.6460745334625244, train/logprobs = tensor([[-0.5690, -2.1787],
        [-1.8016, -2.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28269773721694946
Epoch 0, Step 1024: train/loss = 0.3777901530265808, train/raw-loss = 0.34698495268821716, train/logprobs = tensor([[-1.3479, -5.0356],
        [-2.0970, -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080521821975708
Epoch 0, Step 1025: train/loss = 0.27348563075065613, train/raw-loss = 0.24509243667125702, train/logprobs = tensor([[-1.0047, -4.2703],
        [-2.1249, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28393200039863586
Epoch 0, Step 1026: train/loss = 0.3126458525657654, train/raw-loss = 0.28045427799224854, train/logprobs = tensor([[-1.0316, -4.1061],
        [-2.0619, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219156861305237
Epoch 0, Step 1027: train/loss = 0.6680490970611572, train/raw-loss = 0.6428694725036621, train/logprobs = tensor([[-0.8116, -1.4052],
        [-1.3074, -1.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25179624557495117
Epoch 0, Step 1028: train/loss = 0.3230372369289398, train/raw-loss = 0.3003477454185486, train/logprobs = tensor([[-0.7694, -4.9589],
        [-2.7151, -2.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22689469158649445
Epoch 0, Step 1029: train/loss = 0.532127857208252, train/raw-loss = 0.5069228410720825, train/logprobs = tensor([[-0.5380, -2.4831],
        [-1.3003, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520502209663391
Epoch 0, Step 1030: train/loss = 0.26091089844703674, train/raw-loss = 0.22795364260673523, train/logprobs = tensor([[-0.9737, -5.9581],
        [-2.9520, -2.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295724093914032
Epoch 0, Step 1031: train/loss = 0.347591370344162, train/raw-loss = 0.3169289529323578, train/logprobs = tensor([[-1.0690, -3.1088],
        [-2.2761, -1.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306624174118042
Epoch 0, Step 1032: train/loss = 0.4197879135608673, train/raw-loss = 0.3943214416503906, train/logprobs = tensor([[-0.9411, -2.5690],
        [-2.2811, -1.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25466465950012207
Epoch 0, Step 1033: train/loss = 0.2625502943992615, train/raw-loss = 0.22785386443138123, train/logprobs = tensor([[-1.4247, -5.4536],
        [-3.5263, -1.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34696415066719055
Epoch 0, Step 1034: train/loss = 0.3385092616081238, train/raw-loss = 0.31149792671203613, train/logprobs = tensor([[-0.8650, -2.7860],
        [-1.9904, -1.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701134979724884
Epoch 0, Step 1035: train/loss = 0.42187461256980896, train/raw-loss = 0.38961705565452576, train/logprobs = tensor([[-1.2061, -3.2602],
        [-2.3682, -1.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225756883621216
Epoch 0, Step 1036: train/loss = 0.45076560974121094, train/raw-loss = 0.4211716055870056, train/logprobs = tensor([[-0.8028, -2.9329],
        [-1.8387, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959395945072174
Epoch 0, Step 1037: train/loss = 0.4568250775337219, train/raw-loss = 0.4293580949306488, train/logprobs = tensor([[-0.8375, -2.9530],
        [-2.1732, -2.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746697664260864
Epoch 0, Step 1038: train/loss = 0.3120262026786804, train/raw-loss = 0.28015968203544617, train/logprobs = tensor([[-1.2185, -5.4953],
        [-2.3859, -2.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31866493821144104
Epoch 0, Step 1039: train/loss = 0.28370919823646545, train/raw-loss = 0.2523704767227173, train/logprobs = tensor([[-0.8970, -6.9495],
        [-2.6306, -2.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3133872151374817
Epoch 0, Step 1040: train/loss = 0.4608253538608551, train/raw-loss = 0.4328106939792633, train/logprobs = tensor([[-1.9201, -4.6147],
        [-2.2524, -1.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801465690135956
Epoch 0, Step 1041: train/loss = 0.26792001724243164, train/raw-loss = 0.23475182056427002, train/logprobs = tensor([[-1.0944, -6.6857],
        [-2.4089, -1.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331682026386261
Epoch 0, Step 1042: train/loss = 0.47571080923080444, train/raw-loss = 0.4540005624294281, train/logprobs = tensor([[-0.9948, -3.2426],
        [-1.1434, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21710258722305298
Epoch 0, Step 1043: train/loss = 0.739364743232727, train/raw-loss = 0.7150532007217407, train/logprobs = tensor([[-1.6955, -1.9799],
        [-1.6110, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24311523139476776
Epoch 0, Step 1044: train/loss = 0.5195822715759277, train/raw-loss = 0.49104517698287964, train/logprobs = tensor([[-1.1651, -1.8071],
        [-2.8126, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28537124395370483
Epoch 0, Step 1045: train/loss = 0.34975284337997437, train/raw-loss = 0.3256569504737854, train/logprobs = tensor([[-0.7642, -4.1881],
        [-1.7217, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24095912277698517
Epoch 0, Step 1046: train/loss = 0.3376416265964508, train/raw-loss = 0.30939942598342896, train/logprobs = tensor([[-0.7787, -3.4986],
        [-1.9864, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28242191672325134
Epoch 0, Step 1047: train/loss = 0.4266413450241089, train/raw-loss = 0.393810510635376, train/logprobs = tensor([[-0.9341, -2.2256],
        [-1.6643, -1.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32830825448036194
Epoch 0, Step 1048: train/loss = 0.12172690778970718, train/raw-loss = 0.09079457819461823, train/logprobs = tensor([[-0.8565, -8.6926],
        [-2.6778, -2.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3093233108520508
Epoch 0, Step 1049: train/loss = 0.2664751708507538, train/raw-loss = 0.22951021790504456, train/logprobs = tensor([[-1.1290, -3.9444],
        [-2.8854, -1.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3696494400501251
Epoch 0, Step 1050: train/loss = 0.4830348491668701, train/raw-loss = 0.45746761560440063, train/logprobs = tensor([[-0.6427, -1.5377],
        [-2.0875, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25567230582237244
Epoch 0, Step 1051: train/loss = 0.5589396953582764, train/raw-loss = 0.5373905897140503, train/logprobs = tensor([[-0.7652, -1.8371],
        [-0.8711, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21549081802368164
Epoch 0, Step 1052: train/loss = 0.27247002720832825, train/raw-loss = 0.24589039385318756, train/logprobs = tensor([[-0.7631, -4.2399],
        [-1.7790, -1.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26579636335372925
Epoch 0, Step 1053: train/loss = 0.21069517731666565, train/raw-loss = 0.18596142530441284, train/logprobs = tensor([[-0.9322, -5.3146],
        [-2.3717, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24733754992485046
Epoch 0, Step 1054: train/loss = 0.404323011636734, train/raw-loss = 0.3799653649330139, train/logprobs = tensor([[-1.1149, -2.7804],
        [-1.9137, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24357619881629944
Epoch 0, Step 1055: train/loss = 0.4534721374511719, train/raw-loss = 0.4242837131023407, train/logprobs = tensor([[-1.1964, -3.7029],
        [-2.4556, -2.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2918841242790222
Epoch 0, Step 1056: train/loss = 0.38353827595710754, train/raw-loss = 0.3567039966583252, train/logprobs = tensor([[-0.9186, -3.5652],
        [-1.5603, -1.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26834267377853394
Epoch 0, Step 1057: train/loss = 0.29541775584220886, train/raw-loss = 0.26988786458969116, train/logprobs = tensor([[-0.8826, -5.5054],
        [-2.2445, -1.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25529927015304565
Epoch 0, Step 1058: train/loss = 0.2506375014781952, train/raw-loss = 0.22045831382274628, train/logprobs = tensor([[-0.7473, -4.2124],
        [-2.4633, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3017920255661011
Epoch 0, Step 1059: train/loss = 0.5687764286994934, train/raw-loss = 0.5350505113601685, train/logprobs = tensor([[-0.8177, -1.9257],
        [-1.6150, -1.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33725860714912415
Epoch 0, Step 1060: train/loss = 0.6190518140792847, train/raw-loss = 0.5901057124137878, train/logprobs = tensor([[-1.0749, -2.4171],
        [-1.9930, -1.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894606590270996
Epoch 0, Step 1061: train/loss = 0.4460766911506653, train/raw-loss = 0.4147171974182129, train/logprobs = tensor([[-1.0052, -4.4596],
        [-2.1467, -2.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3135949671268463
Epoch 0, Step 1062: train/loss = 0.34430235624313354, train/raw-loss = 0.31183505058288574, train/logprobs = tensor([[-1.1532, -3.7293],
        [-2.4865, -1.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3246730864048004
Epoch 0, Step 1063: train/loss = 0.6778838634490967, train/raw-loss = 0.6493093967437744, train/logprobs = tensor([[-1.8594, -3.1440],
        [-1.1481, -1.4043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857447564601898
Epoch 0, Step 1064: train/loss = 0.3632185757160187, train/raw-loss = 0.3341127038002014, train/logprobs = tensor([[-0.9547, -6.2912],
        [-2.1127, -2.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29105859994888306
Epoch 0, Step 1065: train/loss = 0.4421294927597046, train/raw-loss = 0.41183990240097046, train/logprobs = tensor([[-0.8081, -2.7170],
        [-1.8270, -1.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30289632081985474
Epoch 0, Step 1066: train/loss = 0.40744298696517944, train/raw-loss = 0.3814970552921295, train/logprobs = tensor([[-1.8424, -4.8113],
        [-2.0041, -1.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25945931673049927
Epoch 0, Step 1067: train/loss = 0.11462492495775223, train/raw-loss = 0.08719999343156815, train/logprobs = tensor([[-1.1787, -9.0759],
        [-3.4279, -1.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27424928545951843
Epoch 0, Step 1068: train/loss = 0.33252838253974915, train/raw-loss = 0.30157509446144104, train/logprobs = tensor([[-0.8401, -3.5667],
        [-2.1728, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3095327317714691
Epoch 0, Step 1069: train/loss = 0.5245583653450012, train/raw-loss = 0.49470698833465576, train/logprobs = tensor([[-1.4563, -5.2685],
        [-1.9623, -1.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29851412773132324
Epoch 0, Step 1070: train/loss = 0.29657045006752014, train/raw-loss = 0.26289546489715576, train/logprobs = tensor([[-0.8275, -4.9511],
        [-2.4213, -2.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3367496430873871
Epoch 0, Step 1071: train/loss = 0.1423160433769226, train/raw-loss = 0.11208070814609528, train/logprobs = tensor([[-0.9882, -7.2053],
        [-3.0442, -1.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3023532032966614
Epoch 0, Step 1072: train/loss = 0.14545941352844238, train/raw-loss = 0.11615247279405594, train/logprobs = tensor([[-0.9175, -7.5839],
        [-2.5532, -1.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29306939244270325
Epoch 0, Step 1073: train/loss = 0.2771643400192261, train/raw-loss = 0.24306651949882507, train/logprobs = tensor([[-1.0276, -4.4643],
        [-2.6093, -2.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34097808599472046
Epoch 0, Step 1074: train/loss = 0.37028735876083374, train/raw-loss = 0.34064507484436035, train/logprobs = tensor([[-0.6357, -5.4201],
        [-1.9880, -2.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964227795600891
Epoch 0, Step 1075: train/loss = 0.3748941719532013, train/raw-loss = 0.34970784187316895, train/logprobs = tensor([[-0.6359, -3.9090],
        [-1.2817, -1.1973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25186318159103394
Epoch 0, Step 1076: train/loss = 0.3893766403198242, train/raw-loss = 0.3527598977088928, train/logprobs = tensor([[-0.7764, -4.4604],
        [-2.1760, -2.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661676347255707
Epoch 0, Step 1077: train/loss = 0.38915395736694336, train/raw-loss = 0.36716729402542114, train/logprobs = tensor([[-0.5230, -3.9194],
        [-1.8723, -1.4499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21986664831638336
Epoch 0, Step 1078: train/loss = 0.46202871203422546, train/raw-loss = 0.43559685349464417, train/logprobs = tensor([[-1.0766, -3.5703],
        [-1.8544, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.264318585395813
Epoch 0, Step 1079: train/loss = 0.21642497181892395, train/raw-loss = 0.18285644054412842, train/logprobs = tensor([[-0.8432, -8.0694],
        [-2.2859, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356853723526001
Epoch 0, Step 1080: train/loss = 0.4104651212692261, train/raw-loss = 0.38391876220703125, train/logprobs = tensor([[-0.9227, -3.1177],
        [-2.1760, -1.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2654635012149811
Epoch 0, Step 1081: train/loss = 0.19434545934200287, train/raw-loss = 0.16694875061511993, train/logprobs = tensor([[-1.5963, -5.8536],
        [-2.4931, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27396687865257263
Epoch 0, Step 1082: train/loss = 0.5844341516494751, train/raw-loss = 0.5589130520820618, train/logprobs = tensor([[-0.5349, -1.3016],
        [-1.7547, -1.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2552110552787781
Epoch 0, Step 1083: train/loss = 0.41667279601097107, train/raw-loss = 0.3807695508003235, train/logprobs = tensor([[-1.2755, -3.3880],
        [-2.6987, -2.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3590323328971863
Epoch 0, Step 1084: train/loss = 0.4109054207801819, train/raw-loss = 0.3841342031955719, train/logprobs = tensor([[-0.6271, -3.3199],
        [-1.8261, -1.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267712265253067
Epoch 0, Step 1085: train/loss = 0.4553126394748688, train/raw-loss = 0.4315415024757385, train/logprobs = tensor([[-0.5349, -2.2614],
        [-1.7211, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23771145939826965
Epoch 0, Step 1086: train/loss = 0.344226598739624, train/raw-loss = 0.3115588128566742, train/logprobs = tensor([[-1.0392, -5.8217],
        [-2.4979, -2.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266777992248535
Epoch 0, Step 1087: train/loss = 0.2940163016319275, train/raw-loss = 0.27222561836242676, train/logprobs = tensor([[-0.7260, -6.4396],
        [-1.4205, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21790684759616852
Epoch 0, Step 1088: train/loss = 0.4232175052165985, train/raw-loss = 0.3941774070262909, train/logprobs = tensor([[-1.4535, -3.4524],
        [-2.0169, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2904015779495239
Epoch 0, Step 1089: train/loss = 0.42711177468299866, train/raw-loss = 0.402662456035614, train/logprobs = tensor([[-0.8362, -2.8801],
        [-1.4557, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24449293315410614
Epoch 0, Step 1090: train/loss = 0.32433831691741943, train/raw-loss = 0.2960836589336395, train/logprobs = tensor([[-0.9686, -4.2067],
        [-2.3464, -1.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28254637122154236
Epoch 0, Step 1091: train/loss = 0.29319125413894653, train/raw-loss = 0.2661468982696533, train/logprobs = tensor([[-0.6508, -3.8689],
        [-2.1920, -2.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27044376730918884
Epoch 0, Step 1092: train/loss = 0.2897365689277649, train/raw-loss = 0.25826573371887207, train/logprobs = tensor([[-1.1487, -4.1789],
        [-2.3350, -1.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31470850110054016
Epoch 0, Step 1093: train/loss = 0.4518297016620636, train/raw-loss = 0.41916340589523315, train/logprobs = tensor([[-0.7978, -4.3604],
        [-2.3768, -2.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32666298747062683
Epoch 0, Step 1094: train/loss = 0.2653677463531494, train/raw-loss = 0.2407248318195343, train/logprobs = tensor([[-0.6864, -2.9634],
        [-1.9309, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464292198419571
Epoch 0, Step 1095: train/loss = 0.554207444190979, train/raw-loss = 0.5225580930709839, train/logprobs = tensor([[-1.3011, -3.3076],
        [-1.8793, -1.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31649380922317505
Epoch 0, Step 1096: train/loss = 0.2731674909591675, train/raw-loss = 0.24629946053028107, train/logprobs = tensor([[-0.9769, -5.1566],
        [-1.9149, -1.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2686803936958313
Epoch 0, Step 1097: train/loss = 0.23065140843391418, train/raw-loss = 0.19503650069236755, train/logprobs = tensor([[-1.1752, -5.1420],
        [-2.5210, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3561490774154663
Epoch 0, Step 1098: train/loss = 0.30970561504364014, train/raw-loss = 0.278158575296402, train/logprobs = tensor([[-0.5895, -7.2838],
        [-2.2876, -1.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3154700696468353
Epoch 0, Step 1099: train/loss = 0.4414825141429901, train/raw-loss = 0.41142502427101135, train/logprobs = tensor([[-0.6928, -1.8323],
        [-2.1973, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005744516849518
Epoch 0, Step 1100: train/loss = 0.32072821259498596, train/raw-loss = 0.2923784554004669, train/logprobs = tensor([[-0.7367, -3.2752],
        [-2.1019, -1.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2834976017475128
Epoch 0, Step 1101: train/loss = 0.23386582732200623, train/raw-loss = 0.2052832990884781, train/logprobs = tensor([[-0.9177, -6.5753],
        [-2.7065, -2.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28582531213760376
Epoch 0, Step 1102: train/loss = 0.3407650589942932, train/raw-loss = 0.317069411277771, train/logprobs = tensor([[-1.2534, -5.1724],
        [-1.6582, -1.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23695646226406097
Epoch 0, Step 1103: train/loss = 0.22953343391418457, train/raw-loss = 0.19948536157608032, train/logprobs = tensor([[-1.1122, -5.7292],
        [-2.5878, -1.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3004809021949768
Epoch 0, Step 1104: train/loss = 0.5587090849876404, train/raw-loss = 0.5310007929801941, train/logprobs = tensor([[-0.9207, -4.0772],
        [-1.6587, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770828306674957
Epoch 0, Step 1105: train/loss = 0.336435467004776, train/raw-loss = 0.3115975260734558, train/logprobs = tensor([[-0.8927, -4.8422],
        [-1.3903, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24837911128997803
Epoch 0, Step 1106: train/loss = 0.33295971155166626, train/raw-loss = 0.300953209400177, train/logprobs = tensor([[-1.5397, -6.6541],
        [-2.3327, -2.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200650215148926
Epoch 0, Step 1107: train/loss = 0.3296104669570923, train/raw-loss = 0.3036091923713684, train/logprobs = tensor([[-0.7672, -4.2084],
        [-1.7708, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600126564502716
Epoch 0, Step 1108: train/loss = 0.38565793633461, train/raw-loss = 0.3619210720062256, train/logprobs = tensor([[-0.7404, -3.2106],
        [-1.6330, -1.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23736867308616638
Epoch 0, Step 1109: train/loss = 0.3048924505710602, train/raw-loss = 0.2777656614780426, train/logprobs = tensor([[-0.8794, -3.4539],
        [-2.0304, -1.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2712678015232086
Epoch 0, Step 1110: train/loss = 0.46990519762039185, train/raw-loss = 0.4459717273712158, train/logprobs = tensor([[-0.9081, -4.3501],
        [-1.4572, -2.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23933467268943787
Epoch 0, Step 1111: train/loss = 0.3575591444969177, train/raw-loss = 0.33047330379486084, train/logprobs = tensor([[-0.9172, -4.9496],
        [-1.6282, -2.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708582580089569
Epoch 0, Step 1112: train/loss = 0.5375559329986572, train/raw-loss = 0.5053674578666687, train/logprobs = tensor([[-2.1026, -5.2401],
        [-2.2542, -2.3019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32188472151756287
Epoch 0, Step 1113: train/loss = 0.5146429538726807, train/raw-loss = 0.4873316287994385, train/logprobs = tensor([[-0.9626, -2.4039],
        [-1.7405, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731136381626129
Epoch 0, Step 1114: train/loss = 0.33207207918167114, train/raw-loss = 0.3071356415748596, train/logprobs = tensor([[-0.9780, -3.1768],
        [-2.0288, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24936443567276
Epoch 0, Step 1115: train/loss = 0.45849335193634033, train/raw-loss = 0.4286786615848541, train/logprobs = tensor([[-0.5078, -2.1259],
        [-1.4109, -1.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29814663529396057
Epoch 0, Step 1116: train/loss = 0.4458484351634979, train/raw-loss = 0.42085590958595276, train/logprobs = tensor([[-0.7739, -2.9255],
        [-1.4402, -1.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24992534518241882
Epoch 0, Step 1117: train/loss = 0.550841748714447, train/raw-loss = 0.5136591196060181, train/logprobs = tensor([[-0.8132, -2.8286],
        [-3.1049, -2.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3718265891075134
Epoch 0, Step 1118: train/loss = 0.5551469326019287, train/raw-loss = 0.533218502998352, train/logprobs = tensor([[-0.4519, -2.6929],
        [-0.9588, -1.3974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21928374469280243
Epoch 0, Step 1119: train/loss = 0.31645721197128296, train/raw-loss = 0.2875061333179474, train/logprobs = tensor([[-0.6466, -5.2336],
        [-2.0389, -1.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895106077194214
Epoch 0, Step 1120: train/loss = 0.13852205872535706, train/raw-loss = 0.10307727009057999, train/logprobs = tensor([[-1.4663, -5.0488],
        [-3.3530, -1.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3544479012489319
Epoch 0, Step 1121: train/loss = 0.305237352848053, train/raw-loss = 0.2732456922531128, train/logprobs = tensor([[-1.0799, -3.9871],
        [-2.8474, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31991660594940186
Epoch 0, Step 1122: train/loss = 0.5261367559432983, train/raw-loss = 0.4958913326263428, train/logprobs = tensor([[-0.8273, -4.2088],
        [-1.8094, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30245476961135864
Epoch 0, Step 1123: train/loss = 0.17747636139392853, train/raw-loss = 0.1476888209581375, train/logprobs = tensor([[-0.7790, -7.9734],
        [-2.7605, -2.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978752553462982
Epoch 0, Step 1124: train/loss = 0.32573235034942627, train/raw-loss = 0.2917509078979492, train/logprobs = tensor([[-1.1070, -6.5348],
        [-2.4726, -2.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3398141860961914
Epoch 0, Step 1125: train/loss = 0.31880614161491394, train/raw-loss = 0.2895590364933014, train/logprobs = tensor([[-0.8110, -3.3216],
        [-1.9251, -1.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2924710512161255
Epoch 0, Step 1126: train/loss = 0.4477565586566925, train/raw-loss = 0.4154680371284485, train/logprobs = tensor([[-1.2478, -4.6300],
        [-2.1103, -2.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228852152824402
Epoch 0, Step 1127: train/loss = 0.36627694964408875, train/raw-loss = 0.3375706672668457, train/logprobs = tensor([[-0.6329, -3.8811],
        [-1.2360, -1.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870628833770752
Epoch 0, Step 1128: train/loss = 0.494811087846756, train/raw-loss = 0.46371012926101685, train/logprobs = tensor([[-1.8473, -2.9361],
        [-1.8815, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3110095262527466
Epoch 0, Step 1129: train/loss = 0.23432070016860962, train/raw-loss = 0.19970789551734924, train/logprobs = tensor([[-1.0851, -4.1735],
        [-2.6927, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461281955242157
Epoch 0, Step 1130: train/loss = 0.45462411642074585, train/raw-loss = 0.4334421753883362, train/logprobs = tensor([[-0.4246, -2.5250],
        [-1.5811, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21181896328926086
Epoch 0, Step 1131: train/loss = 0.32829761505126953, train/raw-loss = 0.3040007948875427, train/logprobs = tensor([[-0.6073, -3.8224],
        [-1.6612, -1.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24296830594539642
Epoch 0, Step 1132: train/loss = 0.5003209114074707, train/raw-loss = 0.46748659014701843, train/logprobs = tensor([[-1.3264, -3.8553],
        [-1.9599, -1.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283431828022003
Epoch 0, Step 1133: train/loss = 0.5941329002380371, train/raw-loss = 0.5659562349319458, train/logprobs = tensor([[-0.9088, -1.2507],
        [-1.4847, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28176698088645935
Epoch 0, Step 1134: train/loss = 0.36039116978645325, train/raw-loss = 0.3287966251373291, train/logprobs = tensor([[-1.7413, -6.3258],
        [-2.5859, -2.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159453272819519
Epoch 0, Step 1135: train/loss = 0.27495822310447693, train/raw-loss = 0.24657878279685974, train/logprobs = tensor([[-0.7314, -4.6226],
        [-1.7779, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837943732738495
Epoch 0, Step 1136: train/loss = 0.3429287374019623, train/raw-loss = 0.3120671510696411, train/logprobs = tensor([[-1.0330, -4.8725],
        [-2.6099, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308616042137146
Epoch 0, Step 1137: train/loss = 0.32787877321243286, train/raw-loss = 0.2960178554058075, train/logprobs = tensor([[-1.4441, -7.1499],
        [-2.2090, -2.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186095654964447
Epoch 0, Step 1138: train/loss = 0.48703643679618835, train/raw-loss = 0.46132218837738037, train/logprobs = tensor([[-0.7416, -2.1552],
        [-1.5109, -1.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571423053741455
Epoch 0, Step 1139: train/loss = 0.322799414396286, train/raw-loss = 0.28347089886665344, train/logprobs = tensor([[-0.8441, -3.1162],
        [-3.0277, -1.6770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39328497648239136
Epoch 0, Step 1140: train/loss = 0.3448234796524048, train/raw-loss = 0.317470908164978, train/logprobs = tensor([[-0.7420, -6.3259],
        [-2.0681, -2.3428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2735258936882019
Epoch 0, Step 1141: train/loss = 0.42828017473220825, train/raw-loss = 0.4002551734447479, train/logprobs = tensor([[-0.6885, -4.5549],
        [-1.7490, -2.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802499830722809
Epoch 0, Step 1142: train/loss = 0.4153842031955719, train/raw-loss = 0.3855868875980377, train/logprobs = tensor([[-0.6067, -2.4884],
        [-2.4877, -2.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979731261730194
Epoch 0, Step 1143: train/loss = 0.49345672130584717, train/raw-loss = 0.4600314795970917, train/logprobs = tensor([[-1.0250, -2.4924],
        [-1.9725, -1.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33425259590148926
Epoch 0, Step 1144: train/loss = 0.4267609715461731, train/raw-loss = 0.3999544680118561, train/logprobs = tensor([[-0.6692, -4.4223],
        [-1.2340, -2.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26806509494781494
Epoch 0, Step 1145: train/loss = 0.2454880177974701, train/raw-loss = 0.21955224871635437, train/logprobs = tensor([[-0.6479, -6.3149],
        [-1.4421, -1.3919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25935763120651245
Epoch 0, Step 1146: train/loss = 0.13990657031536102, train/raw-loss = 0.1041797399520874, train/logprobs = tensor([[ -1.0454, -10.5659],
        [ -2.5062,  -2.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35726839303970337
Epoch 0, Step 1147: train/loss = 0.27322790026664734, train/raw-loss = 0.2368595004081726, train/logprobs = tensor([[-1.2585, -4.8161],
        [-2.7785, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3636840283870697
Epoch 0, Step 1148: train/loss = 0.44005125761032104, train/raw-loss = 0.40568050742149353, train/logprobs = tensor([[-1.0676, -2.4087],
        [-2.5551, -2.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34370744228363037
Epoch 0, Step 1149: train/loss = 0.28764545917510986, train/raw-loss = 0.2557712197303772, train/logprobs = tensor([[-1.2033, -5.1891],
        [-2.5470, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31874215602874756
Epoch 0, Step 1150: train/loss = 0.5076953172683716, train/raw-loss = 0.4713080823421478, train/logprobs = tensor([[-1.2257, -4.3958],
        [-1.1785, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3638717234134674
Epoch 0, Step 1151: train/loss = 0.26209133863449097, train/raw-loss = 0.2291065752506256, train/logprobs = tensor([[-1.3293, -8.1829],
        [-2.8686, -2.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3298477828502655
Epoch 0, Step 1152: train/loss = 0.10061520338058472, train/raw-loss = 0.06591217964887619, train/logprobs = tensor([[-1.0886, -8.3301],
        [-3.2366, -1.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470301330089569
Epoch 0, Step 1153: train/loss = 0.4275228679180145, train/raw-loss = 0.39434316754341125, train/logprobs = tensor([[-0.6788, -2.8438],
        [-1.7493, -1.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331796795129776
Epoch 0, Step 1154: train/loss = 0.3065274655818939, train/raw-loss = 0.27415716648101807, train/logprobs = tensor([[-0.9999, -4.5302],
        [-2.6310, -1.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237032890319824
Epoch 0, Step 1155: train/loss = 0.3001388609409332, train/raw-loss = 0.2750830352306366, train/logprobs = tensor([[-0.7738, -3.8304],
        [-2.2685, -2.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505583167076111
Epoch 0, Step 1156: train/loss = 0.4656136631965637, train/raw-loss = 0.4313327968120575, train/logprobs = tensor([[-0.9586, -2.5821],
        [-2.3476, -2.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34280890226364136
Epoch 0, Step 1157: train/loss = 0.37739798426628113, train/raw-loss = 0.3449934124946594, train/logprobs = tensor([[-1.3186, -6.8601],
        [-1.9471, -4.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240457773208618
Epoch 0, Step 1158: train/loss = 0.1420147866010666, train/raw-loss = 0.1074647456407547, train/logprobs = tensor([[-1.0314, -6.3863],
        [-2.6881, -1.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455004394054413
Epoch 0, Step 1159: train/loss = 0.33578911423683167, train/raw-loss = 0.30750155448913574, train/logprobs = tensor([[-0.8905, -4.4127],
        [-1.3251, -1.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2828756868839264
Epoch 0, Step 1160: train/loss = 0.4596070647239685, train/raw-loss = 0.4319562017917633, train/logprobs = tensor([[-0.9816, -4.1649],
        [-1.7702, -1.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.276508629322052
Epoch 0, Step 1161: train/loss = 0.41987013816833496, train/raw-loss = 0.3866930603981018, train/logprobs = tensor([[-0.8551, -2.8469],
        [-1.9543, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33177050948143005
Epoch 0, Step 1162: train/loss = 0.2822765111923218, train/raw-loss = 0.2487061321735382, train/logprobs = tensor([[-1.1859, -5.8451],
        [-3.0740, -1.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33570411801338196
Epoch 0, Step 1163: train/loss = 0.23176193237304688, train/raw-loss = 0.1946175992488861, train/logprobs = tensor([[-0.8772, -6.4305],
        [-2.1313, -2.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37144309282302856
Epoch 0, Step 1164: train/loss = 0.27650386095046997, train/raw-loss = 0.2467232644557953, train/logprobs = tensor([[-0.8372, -7.4310],
        [-2.2388, -1.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297806054353714
Epoch 0, Step 1165: train/loss = 0.3376360237598419, train/raw-loss = 0.3097771406173706, train/logprobs = tensor([[-1.0305, -5.3208],
        [-1.9923, -1.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785888910293579
Epoch 0, Step 1166: train/loss = 0.24618838727474213, train/raw-loss = 0.2125820517539978, train/logprobs = tensor([[-0.8525, -4.1391],
        [-3.0361, -1.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33606329560279846
Epoch 0, Step 1167: train/loss = 0.4485742747783661, train/raw-loss = 0.4173261523246765, train/logprobs = tensor([[-0.7838, -4.9773],
        [-2.0490, -2.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124811053276062
Epoch 0, Step 1168: train/loss = 0.5025898218154907, train/raw-loss = 0.47518888115882874, train/logprobs = tensor([[-1.1916, -3.0231],
        [-2.0392, -2.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740097939968109
Epoch 0, Step 1169: train/loss = 0.6834949254989624, train/raw-loss = 0.6502553224563599, train/logprobs = tensor([[-2.7113, -5.4297],
        [-2.2134, -1.9784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33239617943763733
Epoch 0, Step 1170: train/loss = 0.2493819296360016, train/raw-loss = 0.22184020280838013, train/logprobs = tensor([[-0.9484, -5.9154],
        [-2.0429, -2.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2754172384738922
Epoch 0, Step 1171: train/loss = 0.535642147064209, train/raw-loss = 0.5038543939590454, train/logprobs = tensor([[-1.3666, -3.5317],
        [-2.3113, -1.4358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31787770986557007
Epoch 0, Step 1172: train/loss = 0.27775827050209045, train/raw-loss = 0.24981778860092163, train/logprobs = tensor([[-0.8691, -8.0957],
        [-1.9857, -2.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27940505743026733
Epoch 0, Step 1173: train/loss = 0.1679309606552124, train/raw-loss = 0.13813866674900055, train/logprobs = tensor([[-1.2190, -6.8429],
        [-2.3869, -1.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29792290925979614
Epoch 0, Step 1174: train/loss = 0.4403367340564728, train/raw-loss = 0.41689738631248474, train/logprobs = tensor([[-0.8571, -2.7275],
        [-1.9045, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23439320921897888
Epoch 0, Step 1175: train/loss = 0.2440330982208252, train/raw-loss = 0.2093539834022522, train/logprobs = tensor([[-1.4027, -5.9979],
        [-2.7327, -1.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3467910587787628
Epoch 0, Step 1176: train/loss = 0.6257518529891968, train/raw-loss = 0.5995960235595703, train/logprobs = tensor([[-0.8067, -1.6027],
        [-1.2630, -1.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615576386451721
Epoch 0, Step 1177: train/loss = 0.44153448939323425, train/raw-loss = 0.4120386242866516, train/logprobs = tensor([[-0.8936, -3.8388],
        [-2.0472, -1.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29495880007743835
Epoch 0, Step 1178: train/loss = 0.6920011043548584, train/raw-loss = 0.6595519781112671, train/logprobs = tensor([[-2.5590, -4.5129],
        [-1.8815, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32449105381965637
Epoch 0, Step 1179: train/loss = 0.37327247858047485, train/raw-loss = 0.34053710103034973, train/logprobs = tensor([[-1.3853, -2.6450],
        [-2.2813, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32735344767570496
Epoch 0, Step 1180: train/loss = 0.4965972602367401, train/raw-loss = 0.4648120105266571, train/logprobs = tensor([[-1.2150, -1.7031],
        [-2.2876, -1.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317852646112442
Epoch 0, Step 1181: train/loss = 0.3322763741016388, train/raw-loss = 0.3072311282157898, train/logprobs = tensor([[-1.1968, -5.5310],
        [-1.8743, -2.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504526674747467
Epoch 0, Step 1182: train/loss = 0.5566319823265076, train/raw-loss = 0.5225964784622192, train/logprobs = tensor([[-1.3372, -5.5006],
        [-2.6798, -2.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403547406196594
Epoch 0, Step 1183: train/loss = 0.5347779989242554, train/raw-loss = 0.5095523595809937, train/logprobs = tensor([[-0.9010, -2.5135],
        [-1.2385, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252256840467453
Epoch 0, Step 1184: train/loss = 0.485799640417099, train/raw-loss = 0.45062291622161865, train/logprobs = tensor([[-1.2986, -3.0057],
        [-2.0824, -0.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35176724195480347
Epoch 0, Step 1185: train/loss = 0.36179983615875244, train/raw-loss = 0.33134984970092773, train/logprobs = tensor([[-0.9252, -4.2335],
        [-2.7724, -1.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30449968576431274
Epoch 0, Step 1186: train/loss = 0.5188828110694885, train/raw-loss = 0.4875354766845703, train/logprobs = tensor([[-0.8720, -4.9550],
        [-1.8306, -2.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31347334384918213
Epoch 0, Step 1187: train/loss = 0.2416452169418335, train/raw-loss = 0.2089100182056427, train/logprobs = tensor([[-1.4470, -6.7868],
        [-2.3170, -2.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32735180854797363
Epoch 0, Step 1188: train/loss = 0.29010123014450073, train/raw-loss = 0.25669044256210327, train/logprobs = tensor([[-1.3604, -5.7620],
        [-2.7284, -3.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341078758239746
Epoch 0, Step 1189: train/loss = 0.3583264648914337, train/raw-loss = 0.3252312242984772, train/logprobs = tensor([[-1.0834, -3.6808],
        [-2.4203, -1.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3309524953365326
Epoch 0, Step 1190: train/loss = 0.40859872102737427, train/raw-loss = 0.37367379665374756, train/logprobs = tensor([[-0.9777, -3.7673],
        [-2.3127, -1.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492492437362671
Epoch 0, Step 1191: train/loss = 0.23267892003059387, train/raw-loss = 0.20372122526168823, train/logprobs = tensor([[-1.1070, -7.0679],
        [-2.4478, -2.3519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28957703709602356
Epoch 0, Step 1192: train/loss = 0.1775001883506775, train/raw-loss = 0.14695695042610168, train/logprobs = tensor([[-0.8076, -8.1135],
        [-2.3044, -3.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30543237924575806
Epoch 0, Step 1193: train/loss = 0.5541501641273499, train/raw-loss = 0.5209507346153259, train/logprobs = tensor([[-1.0137, -2.2916],
        [-2.8047, -2.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33199453353881836
Epoch 0, Step 1194: train/loss = 0.5843879580497742, train/raw-loss = 0.5511804223060608, train/logprobs = tensor([[-1.7690, -4.8280],
        [-1.7957, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33207571506500244
Epoch 0, Step 1195: train/loss = 0.4465793967247009, train/raw-loss = 0.413639098405838, train/logprobs = tensor([[-1.5449, -5.3429],
        [-1.7805, -2.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294033110141754
Epoch 0, Step 1196: train/loss = 0.41193103790283203, train/raw-loss = 0.37971821427345276, train/logprobs = tensor([[-1.9064, -4.8725],
        [-2.4485, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3221281170845032
Epoch 0, Step 1197: train/loss = 0.12682482600212097, train/raw-loss = 0.09477199614048004, train/logprobs = tensor([[-0.9448, -7.0267],
        [-3.3980, -1.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205282986164093
Epoch 0, Step 1198: train/loss = 0.3568603992462158, train/raw-loss = 0.32524675130844116, train/logprobs = tensor([[-1.2438, -4.8168],
        [-2.5770, -1.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31613656878471375
Epoch 0, Step 1199: train/loss = 0.5720469355583191, train/raw-loss = 0.5454067587852478, train/logprobs = tensor([[-0.7940, -1.0416],
        [-1.3403, -0.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26640164852142334
Epoch 0, Step 1200: train/loss = 0.3798157274723053, train/raw-loss = 0.34895482659339905, train/logprobs = tensor([[-1.2064, -4.6136],
        [-1.9704, -2.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30860888957977295
Epoch 0, Step 1201: train/loss = 0.4758666157722473, train/raw-loss = 0.4436841607093811, train/logprobs = tensor([[-0.9761, -2.5574],
        [-2.2555, -1.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218243718147278
Epoch 0, Step 1202: train/loss = 0.13875988125801086, train/raw-loss = 0.10376740247011185, train/logprobs = tensor([[-1.1564, -9.6777],
        [-2.8123, -2.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34992486238479614
Epoch 0, Step 1203: train/loss = 0.2419697344303131, train/raw-loss = 0.20942650735378265, train/logprobs = tensor([[-0.6004, -5.7734],
        [-2.6775, -3.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32543206214904785
Epoch 0, Step 1204: train/loss = 0.3653098940849304, train/raw-loss = 0.3369750678539276, train/logprobs = tensor([[-1.1098, -2.7105],
        [-2.5734, -1.0513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28334811329841614
Epoch 0, Step 1205: train/loss = 0.4354146718978882, train/raw-loss = 0.4020155966281891, train/logprobs = tensor([[-1.3895, -3.5247],
        [-1.8856, -2.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339907228946686
Epoch 0, Step 1206: train/loss = 0.3182859420776367, train/raw-loss = 0.2845594882965088, train/logprobs = tensor([[-1.2530, -4.7353],
        [-2.6270, -2.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.337264746427536
Epoch 0, Step 1207: train/loss = 0.20858234167099, train/raw-loss = 0.17506712675094604, train/logprobs = tensor([[-1.0798, -5.5878],
        [-2.5088, -1.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351520895957947
Epoch 0, Step 1208: train/loss = 0.16740527749061584, train/raw-loss = 0.1330881118774414, train/logprobs = tensor([[-1.1601, -6.0910],
        [-3.3594, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431715667247772
Epoch 0, Step 1209: train/loss = 0.12176978588104248, train/raw-loss = 0.08638983964920044, train/logprobs = tensor([[-1.1465, -4.5763],
        [-3.8115, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35379940271377563
Epoch 0, Step 1210: train/loss = 0.29758623242378235, train/raw-loss = 0.2612398564815521, train/logprobs = tensor([[-0.7881, -4.0113],
        [-2.4929, -1.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634639382362366
Epoch 0, Step 1211: train/loss = 0.22818614542484283, train/raw-loss = 0.19067321717739105, train/logprobs = tensor([[-1.0469, -6.2686],
        [-2.3752, -2.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751293420791626
Epoch 0, Step 1212: train/loss = 0.4685176610946655, train/raw-loss = 0.44038209319114685, train/logprobs = tensor([[-1.1109, -4.9056],
        [-1.8100, -1.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813553810119629
Epoch 0, Step 1213: train/loss = 0.2731594443321228, train/raw-loss = 0.2415717989206314, train/logprobs = tensor([[-1.0908, -5.6046],
        [-2.4415, -1.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158765733242035
Epoch 0, Step 1214: train/loss = 0.4135003387928009, train/raw-loss = 0.38136228919029236, train/logprobs = tensor([[-1.1992, -5.6819],
        [-1.6982, -2.2739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32138028740882874
Epoch 0, Step 1215: train/loss = 0.3448045253753662, train/raw-loss = 0.31142908334732056, train/logprobs = tensor([[-0.9151, -6.3487],
        [-2.7143, -2.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33375412225723267
Epoch 0, Step 1216: train/loss = 0.42398178577423096, train/raw-loss = 0.3894602656364441, train/logprobs = tensor([[-0.8129, -4.7672],
        [-2.1906, -2.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3452155590057373
Epoch 0, Step 1217: train/loss = 0.39459487795829773, train/raw-loss = 0.36363235116004944, train/logprobs = tensor([[-1.9805, -7.4240],
        [-2.7515, -2.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30962520837783813
Epoch 0, Step 1218: train/loss = 0.34494835138320923, train/raw-loss = 0.3118150234222412, train/logprobs = tensor([[-1.0133, -5.0547],
        [-2.3024, -1.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313331604003906
Epoch 0, Step 1219: train/loss = 0.2357918918132782, train/raw-loss = 0.19350102543830872, train/logprobs = tensor([[-1.3136, -8.8838],
        [-3.3948, -2.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4229087233543396
Epoch 0, Step 1220: train/loss = 0.649758517742157, train/raw-loss = 0.6205568313598633, train/logprobs = tensor([[-0.9606, -0.9866],
        [-1.4058, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29201722145080566
Epoch 0, Step 1221: train/loss = 0.30276864767074585, train/raw-loss = 0.27865660190582275, train/logprobs = tensor([[-0.7140, -4.5146],
        [-1.5994, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2411203682422638
Epoch 0, Step 1222: train/loss = 0.4182981848716736, train/raw-loss = 0.38617104291915894, train/logprobs = tensor([[-1.1520, -5.3084],
        [-3.2425, -2.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32127147912979126
Epoch 0, Step 1223: train/loss = 0.2339184284210205, train/raw-loss = 0.20546478033065796, train/logprobs = tensor([[-1.0581, -4.4930],
        [-2.1336, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845364511013031
Epoch 0, Step 1224: train/loss = 0.3965257704257965, train/raw-loss = 0.3728151321411133, train/logprobs = tensor([[-0.4484, -3.6181],
        [-1.2575, -1.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23710599541664124
Epoch 0, Step 1225: train/loss = 0.3691902458667755, train/raw-loss = 0.3410213887691498, train/logprobs = tensor([[-0.9459, -3.9671],
        [-1.5907, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281688392162323
Epoch 0, Step 1226: train/loss = 0.43463781476020813, train/raw-loss = 0.4036966562271118, train/logprobs = tensor([[-1.0918, -4.0907],
        [-1.7089, -2.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094116449356079
Epoch 0, Step 1227: train/loss = 0.6052178144454956, train/raw-loss = 0.5731467604637146, train/logprobs = tensor([[-1.8265, -3.1245],
        [-1.9326, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32071033120155334
Epoch 0, Step 1228: train/loss = 0.5048868656158447, train/raw-loss = 0.4706997275352478, train/logprobs = tensor([[-1.1076, -2.3565],
        [-1.7644, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34187132120132446
Epoch 0, Step 1229: train/loss = 0.32292410731315613, train/raw-loss = 0.29648497700691223, train/logprobs = tensor([[-0.7454, -6.8094],
        [-1.5710, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26439136266708374
Epoch 0, Step 1230: train/loss = 0.5070627927780151, train/raw-loss = 0.47427380084991455, train/logprobs = tensor([[-2.1061, -3.0733],
        [-3.2489, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3278902769088745
Epoch 0, Step 1231: train/loss = 0.37385404109954834, train/raw-loss = 0.34088194370269775, train/logprobs = tensor([[-1.4730, -2.7395],
        [-2.4181, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32972103357315063
Epoch 0, Step 1232: train/loss = 0.9848467111587524, train/raw-loss = 0.960614800453186, train/logprobs = tensor([[-4.5242, -7.0249],
        [-3.2028, -4.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24231895804405212
Epoch 0, Step 1233: train/loss = 0.533388614654541, train/raw-loss = 0.5028953552246094, train/logprobs = tensor([[-0.9262, -2.2027],
        [-1.3668, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049333691596985
Epoch 0, Step 1234: train/loss = 0.3388509750366211, train/raw-loss = 0.30645930767059326, train/logprobs = tensor([[-1.1645, -4.2077],
        [-2.5611, -1.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32391631603240967
Epoch 0, Step 1235: train/loss = 0.7743954062461853, train/raw-loss = 0.7435110807418823, train/logprobs = tensor([[-2.1966, -6.2431],
        [-1.5714, -2.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088436722755432
Epoch 0, Step 1236: train/loss = 0.2839527726173401, train/raw-loss = 0.2514227330684662, train/logprobs = tensor([[-0.7945, -7.8653],
        [-1.6471, -1.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.325300395488739
Epoch 0, Step 1237: train/loss = 0.20529606938362122, train/raw-loss = 0.1754864603281021, train/logprobs = tensor([[-1.1067, -8.2253],
        [-2.9093, -2.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29809606075286865
Epoch 0, Step 1238: train/loss = 0.42682331800460815, train/raw-loss = 0.3945659101009369, train/logprobs = tensor([[-0.9355, -4.5542],
        [-2.1658, -2.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32257407903671265
Epoch 0, Step 1239: train/loss = 0.5538740158081055, train/raw-loss = 0.527413547039032, train/logprobs = tensor([[-1.1471, -4.1741],
        [-1.3426, -1.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2646043598651886
Epoch 0, Step 1240: train/loss = 0.5321878790855408, train/raw-loss = 0.4975370466709137, train/logprobs = tensor([[-1.9294, -6.8757],
        [-3.0606, -2.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.346507728099823
Epoch 0, Step 1241: train/loss = 0.2635248899459839, train/raw-loss = 0.22787325084209442, train/logprobs = tensor([[-1.1539, -4.1410],
        [-3.2001, -1.1540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3565162122249603
Epoch 0, Step 1242: train/loss = 0.3360290825366974, train/raw-loss = 0.3070950508117676, train/logprobs = tensor([[-1.3519, -4.3676],
        [-2.4295, -2.1045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28934013843536377
Epoch 0, Step 1243: train/loss = 0.4313270151615143, train/raw-loss = 0.3974055349826813, train/logprobs = tensor([[-1.0136, -2.6798],
        [-2.3736, -1.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.339214563369751
Epoch 0, Step 1244: train/loss = 0.306828111410141, train/raw-loss = 0.2747083008289337, train/logprobs = tensor([[-1.0503, -3.4341],
        [-2.4478, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3211982846260071
Epoch 0, Step 1245: train/loss = 0.20815454423427582, train/raw-loss = 0.17222629487514496, train/logprobs = tensor([[-0.7836, -5.5510],
        [-3.3285, -2.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592824935913086
Epoch 0, Step 1246: train/loss = 0.16108986735343933, train/raw-loss = 0.12958963215351105, train/logprobs = tensor([[-1.0957, -4.6212],
        [-2.9443, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150023818016052
Epoch 0, Step 1247: train/loss = 0.37510257959365845, train/raw-loss = 0.3385958969593048, train/logprobs = tensor([[-1.6816, -5.3537],
        [-1.9547, -2.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650669753551483
Epoch 0, Step 1248: train/loss = 0.44822123646736145, train/raw-loss = 0.4143826365470886, train/logprobs = tensor([[-0.8892, -2.6533],
        [-2.1130, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33838582038879395
Epoch 0, Step 1249: train/loss = 0.49468743801116943, train/raw-loss = 0.4623514413833618, train/logprobs = tensor([[-1.3485, -2.6174],
        [-2.2715, -1.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3233600854873657
Epoch 0, Step 1250: train/loss = 0.4685194194316864, train/raw-loss = 0.43197768926620483, train/logprobs = tensor([[-1.1000, -3.0430],
        [-2.0586, -2.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36541736125946045
Epoch 0, Step 1251: train/loss = 0.35295727849006653, train/raw-loss = 0.3132280707359314, train/logprobs = tensor([[-0.6922, -5.3667],
        [-2.7588, -1.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972916007041931
Epoch 0, Step 1252: train/loss = 0.1615927666425705, train/raw-loss = 0.11489227414131165, train/logprobs = tensor([[-1.3607, -8.0859],
        [-3.9208, -3.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46700483560562134
Epoch 0, Step 1253: train/loss = 0.32839342951774597, train/raw-loss = 0.2943500578403473, train/logprobs = tensor([[-1.0987, -3.3363],
        [-2.3966, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34043389558792114
Epoch 0, Step 1254: train/loss = 0.4568251371383667, train/raw-loss = 0.42499998211860657, train/logprobs = tensor([[-0.5812, -3.3094],
        [-1.9848, -1.7919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182513415813446
Epoch 0, Step 1255: train/loss = 0.7235128879547119, train/raw-loss = 0.6912259459495544, train/logprobs = tensor([[-0.8816, -1.1619],
        [-1.7374, -1.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228696882724762
Epoch 0, Step 1256: train/loss = 0.24451187252998352, train/raw-loss = 0.21007712185382843, train/logprobs = tensor([[-1.6290, -3.3823],
        [-4.5279, -2.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34434738755226135
Epoch 0, Step 1257: train/loss = 0.4817798137664795, train/raw-loss = 0.44941097497940063, train/logprobs = tensor([[-0.8136, -3.2086],
        [-1.4737, -1.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32368898391723633
Epoch 0, Step 1258: train/loss = 0.26258584856987, train/raw-loss = 0.22897261381149292, train/logprobs = tensor([[-1.1179, -4.4269],
        [-3.0076, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3361324667930603
Epoch 0, Step 1259: train/loss = 0.6163858771324158, train/raw-loss = 0.5789739489555359, train/logprobs = tensor([[-0.8012, -1.6388],
        [-1.9329, -1.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741193413734436
Epoch 0, Step 1260: train/loss = 0.4664834439754486, train/raw-loss = 0.42458802461624146, train/logprobs = tensor([[-1.1516, -9.9261],
        [-2.8223, -3.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41895410418510437
Epoch 0, Step 1261: train/loss = 0.5855265855789185, train/raw-loss = 0.5392305850982666, train/logprobs = tensor([[-1.0779, -3.2635],
        [-3.3229, -2.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46296021342277527
Epoch 0, Step 1262: train/loss = 0.3440611958503723, train/raw-loss = 0.31078484654426575, train/logprobs = tensor([[-1.0301, -4.2888],
        [-2.3485, -2.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33276331424713135
Epoch 0, Step 1263: train/loss = 0.4279979467391968, train/raw-loss = 0.3947749435901642, train/logprobs = tensor([[-1.6558, -5.4817],
        [-2.0818, -1.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322300612926483
Epoch 0, Step 1264: train/loss = 0.24298495054244995, train/raw-loss = 0.21109265089035034, train/logprobs = tensor([[-1.2441, -5.0788],
        [-2.5941, -1.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318922758102417
Epoch 0, Step 1265: train/loss = 0.44544076919555664, train/raw-loss = 0.4063625931739807, train/logprobs = tensor([[-1.1083, -3.1940],
        [-3.0717, -1.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39078187942504883
Epoch 0, Step 1266: train/loss = 0.49997419118881226, train/raw-loss = 0.46910423040390015, train/logprobs = tensor([[-1.9364, -8.7434],
        [-2.4933, -2.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30869999527931213
Epoch 0, Step 1267: train/loss = 0.12541021406650543, train/raw-loss = 0.09007640928030014, train/logprobs = tensor([[-1.0641, -5.7315],
        [-3.6860, -2.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533381223678589
Epoch 0, Step 1268: train/loss = 0.24614888429641724, train/raw-loss = 0.21565283834934235, train/logprobs = tensor([[-1.1325, -8.1599],
        [-3.3624, -1.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049604892730713
Epoch 0, Step 1269: train/loss = 0.3408452868461609, train/raw-loss = 0.3078295588493347, train/logprobs = tensor([[-1.2934, -5.7994],
        [-2.9168, -2.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33015695214271545
Epoch 0, Step 1270: train/loss = 0.43316468596458435, train/raw-loss = 0.4008549749851227, train/logprobs = tensor([[-1.3049, -4.0526],
        [-2.2471, -2.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230971693992615
Epoch 0, Step 1271: train/loss = 0.5180093050003052, train/raw-loss = 0.4902392029762268, train/logprobs = tensor([[-0.9835, -4.6515],
        [-1.5633, -2.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27770113945007324
Epoch 0, Step 1272: train/loss = 0.2841987609863281, train/raw-loss = 0.24854832887649536, train/logprobs = tensor([[-1.3657, -5.4212],
        [-2.9639, -2.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35650429129600525
Epoch 0, Step 1273: train/loss = 0.42651739716529846, train/raw-loss = 0.3887277841567993, train/logprobs = tensor([[-1.3765, -3.4825],
        [-2.0912, -1.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.377896249294281
Epoch 0, Step 1274: train/loss = 0.49207890033721924, train/raw-loss = 0.45538216829299927, train/logprobs = tensor([[-0.6607, -3.4174],
        [-1.7405, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36696720123291016
Epoch 0, Step 1275: train/loss = 0.27600952982902527, train/raw-loss = 0.2369387447834015, train/logprobs = tensor([[-0.6520, -3.2796],
        [-2.7651, -1.1860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39070767164230347
Epoch 0, Step 1276: train/loss = 0.2784495949745178, train/raw-loss = 0.24873606860637665, train/logprobs = tensor([[-1.0065, -9.0908],
        [-2.4040, -2.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2971356511116028
Epoch 0, Step 1277: train/loss = 0.4519285261631012, train/raw-loss = 0.4185516834259033, train/logprobs = tensor([[-1.0219, -2.2363],
        [-2.1536, -1.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33376848697662354
Epoch 0, Step 1278: train/loss = 0.2120681256055832, train/raw-loss = 0.1788150668144226, train/logprobs = tensor([[-0.6432, -5.2116],
        [-2.6505, -2.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3325306475162506
Epoch 0, Step 1279: train/loss = 0.20121806859970093, train/raw-loss = 0.16487422585487366, train/logprobs = tensor([[-1.0613, -6.6279],
        [-3.3829, -1.6791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634384870529175
Epoch 0, Step 1280: train/loss = 0.26620805263519287, train/raw-loss = 0.2270713895559311, train/logprobs = tensor([[-1.0074, -5.5397],
        [-2.7775, -1.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3913666009902954
Epoch 0, Step 1281: train/loss = 0.30412551760673523, train/raw-loss = 0.2660897970199585, train/logprobs = tensor([[-1.0017, -5.3052],
        [-2.3386, -1.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38035714626312256
Epoch 0, Step 1282: train/loss = 0.4660274088382721, train/raw-loss = 0.43860965967178345, train/logprobs = tensor([[-0.6097, -2.9484],
        [-1.4221, -1.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2741777002811432
Epoch 0, Step 1283: train/loss = 0.4266113042831421, train/raw-loss = 0.39654189348220825, train/logprobs = tensor([[-0.6938, -3.0081],
        [-1.7770, -1.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3006935119628906
Epoch 0, Step 1284: train/loss = 0.398165762424469, train/raw-loss = 0.3687400817871094, train/logprobs = tensor([[-0.5662, -4.5644],
        [-1.4297, -1.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29425668716430664
Epoch 0, Step 1285: train/loss = 0.13492365181446075, train/raw-loss = 0.10283710062503815, train/logprobs = tensor([[-1.0033, -8.5018],
        [-3.5972, -2.6245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3208654820919037
Epoch 0, Step 1286: train/loss = 0.19586463272571564, train/raw-loss = 0.16366060078144073, train/logprobs = tensor([[-1.0331, -7.1238],
        [-3.2455, -3.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32204023003578186
Epoch 0, Step 1287: train/loss = 0.37269192934036255, train/raw-loss = 0.33457303047180176, train/logprobs = tensor([[-0.8084, -5.6893],
        [-2.6292, -2.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38118886947631836
Epoch 0, Step 1288: train/loss = 0.7247515320777893, train/raw-loss = 0.690621554851532, train/logprobs = tensor([[-2.1963, -4.0785],
        [-1.7120, -1.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34129998087882996
Epoch 0, Step 1289: train/loss = 0.35491666197776794, train/raw-loss = 0.32502639293670654, train/logprobs = tensor([[-1.3216, -5.1229],
        [-3.0629, -1.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989027500152588
Epoch 0, Step 1290: train/loss = 0.3160943388938904, train/raw-loss = 0.2871939539909363, train/logprobs = tensor([[-1.1926, -5.1033],
        [-2.5404, -1.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890041470527649
Epoch 0, Step 1291: train/loss = 0.3384909927845001, train/raw-loss = 0.307609498500824, train/logprobs = tensor([[ -2.2239, -12.0589],
        [ -3.8986,  -3.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088151812553406
Epoch 0, Step 1292: train/loss = 0.38834190368652344, train/raw-loss = 0.35011810064315796, train/logprobs = tensor([[-1.0119, -6.2026],
        [-3.5670, -3.5771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38223797082901
Epoch 0, Step 1293: train/loss = 0.21135611832141876, train/raw-loss = 0.17628490924835205, train/logprobs = tensor([[-1.0958, -5.7358],
        [-4.3528, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3507119119167328
Epoch 0, Step 1294: train/loss = 0.33923062682151794, train/raw-loss = 0.3021523058414459, train/logprobs = tensor([[-1.6070, -3.7557],
        [-3.5193, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37078332901000977
Epoch 0, Step 1295: train/loss = 0.2996220886707306, train/raw-loss = 0.26802125573158264, train/logprobs = tensor([[-1.1279, -6.1704],
        [-3.5724, -4.5813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160085082054138
Epoch 0, Step 1296: train/loss = 0.17982208728790283, train/raw-loss = 0.14532165229320526, train/logprobs = tensor([[-1.4545, -4.3829],
        [-3.3232, -1.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34500449895858765
Epoch 0, Step 1297: train/loss = 0.34813815355300903, train/raw-loss = 0.3109808564186096, train/logprobs = tensor([[-0.9383, -7.4289],
        [-2.3893, -3.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37157300114631653
Epoch 0, Step 1298: train/loss = 0.3851206302642822, train/raw-loss = 0.3478894531726837, train/logprobs = tensor([[-1.7094, -2.4609],
        [-3.4734, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3723117709159851
Epoch 0, Step 1299: train/loss = 0.23787011206150055, train/raw-loss = 0.20563897490501404, train/logprobs = tensor([[-0.8830, -6.6109],
        [-2.9466, -3.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223114311695099
Epoch 0, Step 1300: train/loss = 0.38693445920944214, train/raw-loss = 0.3499857783317566, train/logprobs = tensor([[-1.2682, -6.6337],
        [-2.5082, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3694867193698883
Epoch 0, Step 1301: train/loss = 0.5565038323402405, train/raw-loss = 0.5136293768882751, train/logprobs = tensor([[-1.2120, -2.8621],
        [-2.3614, -2.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4287448525428772
Epoch 0, Step 1302: train/loss = 0.4536210894584656, train/raw-loss = 0.4201401174068451, train/logprobs = tensor([[-0.7726, -1.9723],
        [-2.0942, -1.4465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348098695278168
Epoch 0, Step 1303: train/loss = 0.4236191213130951, train/raw-loss = 0.39361390471458435, train/logprobs = tensor([[-0.6220, -3.2033],
        [-1.9636, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30005210638046265
Epoch 0, Step 1304: train/loss = 0.4403919577598572, train/raw-loss = 0.40546414256095886, train/logprobs = tensor([[-0.9584, -3.4779],
        [-2.9860, -2.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492784798145294
Epoch 0, Step 1305: train/loss = 0.6018847227096558, train/raw-loss = 0.5658870935440063, train/logprobs = tensor([[-3.2135, -6.7911],
        [-3.2401, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35997578501701355
Epoch 0, Step 1306: train/loss = 0.3346176743507385, train/raw-loss = 0.29951047897338867, train/logprobs = tensor([[-2.3826, -7.6061],
        [-3.2803, -2.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351071834564209
Epoch 0, Step 1307: train/loss = 0.3830680847167969, train/raw-loss = 0.35660111904144287, train/logprobs = tensor([[-1.2394, -2.5396],
        [-2.5161, -0.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26466938853263855
Epoch 0, Step 1308: train/loss = 0.3711094558238983, train/raw-loss = 0.34043964743614197, train/logprobs = tensor([[-0.9340, -5.1565],
        [-2.6815, -1.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066979944705963
Epoch 0, Step 1309: train/loss = 0.29176414012908936, train/raw-loss = 0.26093485951423645, train/logprobs = tensor([[-1.0945, -3.3943],
        [-2.6536, -1.4841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3082927465438843
Epoch 0, Step 1310: train/loss = 0.4022405445575714, train/raw-loss = 0.3685043454170227, train/logprobs = tensor([[-0.8877, -4.0413],
        [-2.4854, -1.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373616933822632
Epoch 0, Step 1311: train/loss = 0.259818434715271, train/raw-loss = 0.22977635264396667, train/logprobs = tensor([[-0.7514, -4.5345],
        [-2.7927, -1.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3004206717014313
Epoch 0, Step 1312: train/loss = 0.43601059913635254, train/raw-loss = 0.40067732334136963, train/logprobs = tensor([[-1.0337, -3.4788],
        [-2.9107, -2.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35333260893821716
Epoch 0, Step 1313: train/loss = 0.9092177748680115, train/raw-loss = 0.872585654258728, train/logprobs = tensor([[-2.4256, -2.6930],
        [-2.1132, -2.3192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3663203716278076
Epoch 0, Step 1314: train/loss = 1.014716386795044, train/raw-loss = 0.9786906838417053, train/logprobs = tensor([[-2.2125, -1.9635],
        [-1.8927, -1.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602563440799713
Epoch 0, Step 1315: train/loss = 0.16251781582832336, train/raw-loss = 0.12799783051013947, train/logprobs = tensor([[ -1.1252, -12.9022],
        [ -3.2771,  -3.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34519994258880615
Epoch 0, Step 1316: train/loss = 0.3567093312740326, train/raw-loss = 0.3247278332710266, train/logprobs = tensor([[-1.1257, -3.2896],
        [-2.5712, -1.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3198150396347046
Epoch 0, Step 1317: train/loss = 0.4315292537212372, train/raw-loss = 0.39548423886299133, train/logprobs = tensor([[-0.8907, -2.7582],
        [-2.8057, -2.1882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36045026779174805
Epoch 0, Step 1318: train/loss = 0.24452853202819824, train/raw-loss = 0.2096809595823288, train/logprobs = tensor([[-1.0322, -6.4444],
        [-2.4468, -2.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34847569465637207
Epoch 0, Step 1319: train/loss = 0.2423345446586609, train/raw-loss = 0.2069559395313263, train/logprobs = tensor([[-0.9773, -4.0605],
        [-3.2822, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35378602147102356
Epoch 0, Step 1320: train/loss = 0.42888087034225464, train/raw-loss = 0.39245569705963135, train/logprobs = tensor([[-1.3778, -5.3526],
        [-3.2402, -2.0188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36425158381462097
Epoch 0, Step 1321: train/loss = 0.5216965079307556, train/raw-loss = 0.4872385263442993, train/logprobs = tensor([[-0.7458, -2.6207],
        [-1.8605, -2.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34457969665527344
Epoch 0, Step 1322: train/loss = 0.3220638930797577, train/raw-loss = 0.28579914569854736, train/logprobs = tensor([[-0.9490, -2.8926],
        [-2.3758, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36264753341674805
Epoch 0, Step 1323: train/loss = 0.4917912781238556, train/raw-loss = 0.46324801445007324, train/logprobs = tensor([[-0.5682, -4.0462],
        [-1.3147, -1.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28543248772621155
Epoch 0, Step 1324: train/loss = 0.34623560309410095, train/raw-loss = 0.3072042465209961, train/logprobs = tensor([[-0.7885, -5.6138],
        [-2.1487, -2.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3903135061264038
Epoch 0, Step 1325: train/loss = 0.5502618551254272, train/raw-loss = 0.5246948599815369, train/logprobs = tensor([[-0.4583, -3.5506],
        [-1.3708, -2.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25566980242729187
Epoch 0, Step 1326: train/loss = 0.3568701446056366, train/raw-loss = 0.32109615206718445, train/logprobs = tensor([[-2.1830, -8.5582],
        [-2.6549, -1.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35774004459381104
Epoch 0, Step 1327: train/loss = 0.5766808986663818, train/raw-loss = 0.5376083850860596, train/logprobs = tensor([[-2.4651, -4.2495],
        [-3.0939, -1.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39072516560554504
Epoch 0, Step 1328: train/loss = 0.2693179249763489, train/raw-loss = 0.23439031839370728, train/logprobs = tensor([[-1.2873, -6.0328],
        [-2.2384, -2.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492761552333832
Epoch 0, Step 1329: train/loss = 0.15887203812599182, train/raw-loss = 0.11745978891849518, train/logprobs = tensor([[-2.0068, -7.0300],
        [-4.3715, -2.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41412243247032166
Epoch 0, Step 1330: train/loss = 0.4914192259311676, train/raw-loss = 0.4538678824901581, train/logprobs = tensor([[-1.6024, -5.9710],
        [-2.2374, -2.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3755134344100952
Epoch 0, Step 1331: train/loss = 0.26179060339927673, train/raw-loss = 0.22098062932491302, train/logprobs = tensor([[-1.6565, -4.0059],
        [-3.4573, -1.4486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4080996513366699
Epoch 0, Step 1332: train/loss = 0.2040422409772873, train/raw-loss = 0.1629490703344345, train/logprobs = tensor([[-1.3032, -5.5449],
        [-3.3532, -1.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109315872192383
Epoch 0, Step 1333: train/loss = 0.44526922702789307, train/raw-loss = 0.4104146361351013, train/logprobs = tensor([[-1.0873, -3.7757],
        [-2.2433, -1.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3485458791255951
Epoch 0, Step 1334: train/loss = 1.0178850889205933, train/raw-loss = 0.9771748781204224, train/logprobs = tensor([[-2.8021, -4.0976],
        [-3.6302, -2.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4071009159088135
Epoch 0, Step 1335: train/loss = 0.43357911705970764, train/raw-loss = 0.40057045221328735, train/logprobs = tensor([[-2.4328, -6.2416],
        [-4.3994, -2.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3300870358943939
Epoch 0, Step 1336: train/loss = 0.25515586137771606, train/raw-loss = 0.21899744868278503, train/logprobs = tensor([[-1.1976, -8.4484],
        [-2.8242, -3.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36158430576324463
Epoch 0, Step 1337: train/loss = 0.4371837079524994, train/raw-loss = 0.41379448771476746, train/logprobs = tensor([[-0.5613, -5.2389],
        [-1.4670, -2.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23389196395874023
Epoch 0, Step 1338: train/loss = 0.26973915100097656, train/raw-loss = 0.22836807370185852, train/logprobs = tensor([[-1.0900, -4.3829],
        [-3.1965, -2.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41371065378189087
Epoch 0, Step 1339: train/loss = 0.2701011896133423, train/raw-loss = 0.2314661741256714, train/logprobs = tensor([[-1.6530, -4.4411],
        [-3.9063, -2.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3863504230976105
Epoch 0, Step 1340: train/loss = 0.18906983733177185, train/raw-loss = 0.15373052656650543, train/logprobs = tensor([[-1.0394, -5.7200],
        [-3.9783, -2.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.353393018245697
Epoch 0, Step 1341: train/loss = 0.2601558566093445, train/raw-loss = 0.2330705225467682, train/logprobs = tensor([[-1.3164, -4.2089],
        [-2.9843, -1.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708534300327301
Epoch 0, Step 1342: train/loss = 0.5911338329315186, train/raw-loss = 0.563977062702179, train/logprobs = tensor([[-1.0916, -3.1998],
        [-1.1632, -1.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27156785130500793
Epoch 0, Step 1343: train/loss = 0.15458625555038452, train/raw-loss = 0.12116706371307373, train/logprobs = tensor([[-1.3779, -4.8869],
        [-3.5789, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33419179916381836
Epoch 0, Step 1344: train/loss = 0.8185861110687256, train/raw-loss = 0.7869027256965637, train/logprobs = tensor([[-2.5063, -5.1456],
        [-1.6030, -1.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31683361530303955
Epoch 0, Step 1345: train/loss = 0.51915442943573, train/raw-loss = 0.48103034496307373, train/logprobs = tensor([[-1.3693, -3.2999],
        [-3.1757, -1.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38124099373817444
Epoch 0, Step 1346: train/loss = 0.4878031015396118, train/raw-loss = 0.44761139154434204, train/logprobs = tensor([[-1.7045, -3.6251],
        [-3.0921, -1.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019169211387634
Epoch 0, Step 1347: train/loss = 0.39176833629608154, train/raw-loss = 0.35971903800964355, train/logprobs = tensor([[-1.3186, -4.1533],
        [-2.9255, -1.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32049286365509033
Epoch 0, Step 1348: train/loss = 0.43816831707954407, train/raw-loss = 0.4107070565223694, train/logprobs = tensor([[-1.1899, -2.6260],
        [-2.7906, -2.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746124565601349
Epoch 0, Step 1349: train/loss = 0.3842010200023651, train/raw-loss = 0.3459536135196686, train/logprobs = tensor([[-1.7392, -4.0852],
        [-3.1362, -1.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38247400522232056
Epoch 0, Step 1350: train/loss = 0.30742642283439636, train/raw-loss = 0.27795925736427307, train/logprobs = tensor([[-0.9479, -8.9835],
        [-2.8276, -3.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29467156529426575
Epoch 0, Step 1351: train/loss = 0.44291579723358154, train/raw-loss = 0.40333911776542664, train/logprobs = tensor([[-1.7459, -3.5916],
        [-3.3469, -2.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3957670331001282
Epoch 0, Step 1352: train/loss = 0.4924047887325287, train/raw-loss = 0.46469545364379883, train/logprobs = tensor([[-0.7012, -2.8694],
        [-1.8321, -2.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770935595035553
Epoch 0, Step 1353: train/loss = 0.550812840461731, train/raw-loss = 0.5237117409706116, train/logprobs = tensor([[-0.9395, -4.2643],
        [-1.4201, -1.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2710109353065491
Epoch 0, Step 1354: train/loss = 0.3558601140975952, train/raw-loss = 0.31679996848106384, train/logprobs = tensor([[-0.8977, -3.1754],
        [-2.8054, -2.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39060139656066895
Epoch 0, Step 1355: train/loss = 0.11233628541231155, train/raw-loss = 0.0831984281539917, train/logprobs = tensor([[-1.1907, -7.9471],
        [-3.3965, -1.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29137855768203735
Epoch 0, Step 1356: train/loss = 0.40274950861930847, train/raw-loss = 0.3724297881126404, train/logprobs = tensor([[-1.7029, -3.4503],
        [-2.7900, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031972348690033
Epoch 0, Step 1357: train/loss = 0.5428436994552612, train/raw-loss = 0.5096393823623657, train/logprobs = tensor([[-0.8015, -1.6800],
        [-1.7506, -1.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320434093475342
Epoch 0, Step 1358: train/loss = 0.21127164363861084, train/raw-loss = 0.17316468060016632, train/logprobs = tensor([[-1.2337, -5.1196],
        [-3.7028, -1.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38106945157051086
Epoch 0, Step 1359: train/loss = 0.5472515821456909, train/raw-loss = 0.5110118389129639, train/logprobs = tensor([[-0.8820, -3.3807],
        [-2.4158, -2.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3623974025249481
Epoch 0, Step 1360: train/loss = 0.23525243997573853, train/raw-loss = 0.2035622000694275, train/logprobs = tensor([[-1.1073, -4.4882],
        [-2.6394, -2.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169024586677551
Epoch 0, Step 1361: train/loss = 0.24094891548156738, train/raw-loss = 0.2045239508152008, train/logprobs = tensor([[-1.1415, -5.4629],
        [-2.8929, -2.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364249587059021
Epoch 0, Step 1362: train/loss = 0.3685610592365265, train/raw-loss = 0.33240142464637756, train/logprobs = tensor([[-1.1193, -4.5357],
        [-3.3946, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615962862968445
Epoch 0, Step 1363: train/loss = 0.48243770003318787, train/raw-loss = 0.45192641019821167, train/logprobs = tensor([[-0.9941, -3.2525],
        [-1.8132, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30511292815208435
Epoch 0, Step 1364: train/loss = 0.35186803340911865, train/raw-loss = 0.31535273790359497, train/logprobs = tensor([[-0.7645, -4.7820],
        [-2.3480, -2.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36515238881111145
Epoch 0, Step 1365: train/loss = 0.34804049134254456, train/raw-loss = 0.31857413053512573, train/logprobs = tensor([[-0.5787, -5.3489],
        [-1.7514, -1.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.294663667678833
Epoch 0, Step 1366: train/loss = 0.49446308612823486, train/raw-loss = 0.4657747745513916, train/logprobs = tensor([[-0.5208, -3.8856],
        [-1.6253, -2.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868824005126953
Epoch 0, Step 1367: train/loss = 0.30516889691352844, train/raw-loss = 0.2725846469402313, train/logprobs = tensor([[-1.0073, -6.2241],
        [-3.1798, -2.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258424699306488
Epoch 0, Step 1368: train/loss = 0.47494715452194214, train/raw-loss = 0.44553929567337036, train/logprobs = tensor([[-0.8993, -2.5938],
        [-2.0572, -1.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29407867789268494
Epoch 0, Step 1369: train/loss = 0.41227516531944275, train/raw-loss = 0.37183111906051636, train/logprobs = tensor([[-0.7843, -2.7281],
        [-4.2195, -2.3710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40444067120552063
Epoch 0, Step 1370: train/loss = 0.4570494294166565, train/raw-loss = 0.4221274256706238, train/logprobs = tensor([[-1.3069, -2.9872],
        [-2.6494, -1.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492201566696167
Epoch 0, Step 1371: train/loss = 0.42274969816207886, train/raw-loss = 0.38831624388694763, train/logprobs = tensor([[-0.8418, -3.9657],
        [-2.7416, -1.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3443344235420227
Epoch 0, Step 1372: train/loss = 0.17433404922485352, train/raw-loss = 0.13790541887283325, train/logprobs = tensor([[-1.1287, -6.8509],
        [-3.7644, -2.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36428630352020264
Epoch 0, Step 1373: train/loss = 0.6624554395675659, train/raw-loss = 0.6338174939155579, train/logprobs = tensor([[-2.1326, -3.3278],
        [-4.2647, -2.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863779366016388
Epoch 0, Step 1374: train/loss = 0.37133753299713135, train/raw-loss = 0.3418467342853546, train/logprobs = tensor([[-0.6162, -4.1946],
        [-2.4461, -2.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2949077785015106
Epoch 0, Step 1375: train/loss = 0.20377510786056519, train/raw-loss = 0.17229080200195312, train/logprobs = tensor([[-1.2605, -7.0828],
        [-2.9905, -1.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31484296917915344
Epoch 0, Step 1376: train/loss = 0.20372045040130615, train/raw-loss = 0.16345103085041046, train/logprobs = tensor([[-1.5487, -5.6669],
        [-4.2586, -1.4352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4026941657066345
Epoch 0, Step 1377: train/loss = 0.4407802224159241, train/raw-loss = 0.4080955982208252, train/logprobs = tensor([[-0.8907, -6.2348],
        [-2.1962, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32684606313705444
Epoch 0, Step 1378: train/loss = 0.39654144644737244, train/raw-loss = 0.3618030250072479, train/logprobs = tensor([[-1.4850, -4.2656],
        [-2.4218, -1.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473843038082123
Epoch 0, Step 1379: train/loss = 0.6876110434532166, train/raw-loss = 0.6469211578369141, train/logprobs = tensor([[-1.6428, -3.5798],
        [-2.9762, -3.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40689846873283386
Epoch 0, Step 1380: train/loss = 0.10268094390630722, train/raw-loss = 0.06100586801767349, train/logprobs = tensor([[-0.7390, -7.2798],
        [-3.3553, -1.7620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4167507588863373
Epoch 0, Step 1381: train/loss = 0.21783548593521118, train/raw-loss = 0.1762072890996933, train/logprobs = tensor([[-1.0572, -8.3679],
        [-2.9339, -2.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.416282057762146
Epoch 0, Step 1382: train/loss = 0.29712575674057007, train/raw-loss = 0.26074010133743286, train/logprobs = tensor([[-1.6901, -7.2659],
        [-2.7885, -2.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36385616660118103
Epoch 0, Step 1383: train/loss = 0.45228058099746704, train/raw-loss = 0.42002955079078674, train/logprobs = tensor([[-1.1424, -5.1141],
        [-3.7072, -2.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225104808807373
Epoch 0, Step 1384: train/loss = 0.4723273813724518, train/raw-loss = 0.43473634123802185, train/logprobs = tensor([[-0.8906, -4.0553],
        [-2.6615, -2.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37591010332107544
Epoch 0, Step 1385: train/loss = 0.3039669990539551, train/raw-loss = 0.2625545561313629, train/logprobs = tensor([[-1.1941, -3.4443],
        [-4.1596, -2.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41412457823753357
Epoch 0, Step 1386: train/loss = 0.1945638656616211, train/raw-loss = 0.15447933971881866, train/logprobs = tensor([[-1.4112, -4.4773],
        [-3.6944, -1.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40084534883499146
Epoch 0, Step 1387: train/loss = 0.49131596088409424, train/raw-loss = 0.4497290253639221, train/logprobs = tensor([[-0.9777, -2.2653],
        [-3.4300, -2.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41586920619010925
Epoch 0, Step 1388: train/loss = 0.2540281116962433, train/raw-loss = 0.22451336681842804, train/logprobs = tensor([[-1.4208, -5.5502],
        [-3.1611, -1.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2951472997665405
Epoch 0, Step 1389: train/loss = 0.5433300733566284, train/raw-loss = 0.5023167133331299, train/logprobs = tensor([[-1.8876, -4.9022],
        [-2.9602, -1.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4101340174674988
Epoch 0, Step 1390: train/loss = 0.34567946195602417, train/raw-loss = 0.31277501583099365, train/logprobs = tensor([[-1.1709, -3.7495],
        [-2.3049, -1.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32904452085494995
Epoch 0, Step 1391: train/loss = 0.43000495433807373, train/raw-loss = 0.3926727771759033, train/logprobs = tensor([[-1.1549, -3.5201],
        [-2.7403, -2.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733217418193817
Epoch 0, Step 1392: train/loss = 0.23063746094703674, train/raw-loss = 0.19742268323898315, train/logprobs = tensor([[-1.1984, -8.1623],
        [-2.6667, -3.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321476876735687
Epoch 0, Step 1393: train/loss = 0.254064679145813, train/raw-loss = 0.2131417691707611, train/logprobs = tensor([[-1.0849, -7.7563],
        [-3.8854, -3.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40922898054122925
Epoch 0, Step 1394: train/loss = 0.40414270758628845, train/raw-loss = 0.3619287610054016, train/logprobs = tensor([[-0.9106, -2.7372],
        [-3.7127, -2.3464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42213934659957886
Epoch 0, Step 1395: train/loss = 0.3274988830089569, train/raw-loss = 0.2843915820121765, train/logprobs = tensor([[-1.0110, -4.9298],
        [-3.2175, -3.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43107330799102783
Epoch 0, Step 1396: train/loss = 0.24477706849575043, train/raw-loss = 0.20188863575458527, train/logprobs = tensor([[-1.4715, -6.1804],
        [-3.5903, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42888444662094116
Epoch 0, Step 1397: train/loss = 0.195179283618927, train/raw-loss = 0.16319900751113892, train/logprobs = tensor([[-1.0413, -9.8389],
        [-2.5758, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31980282068252563
Epoch 0, Step 1398: train/loss = 0.11192145943641663, train/raw-loss = 0.06605507433414459, train/logprobs = tensor([[-1.5328, -6.9308],
        [-4.3560, -2.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45866382122039795
Epoch 0, Step 1399: train/loss = 0.26939576864242554, train/raw-loss = 0.22569818794727325, train/logprobs = tensor([[-0.8254, -4.7965],
        [-4.1358, -2.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4369756877422333
Epoch 0, Step 1400: train/loss = 0.6912188529968262, train/raw-loss = 0.6487838625907898, train/logprobs = tensor([[-1.1225, -8.0455],
        [-3.3115, -3.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42434975504875183
Epoch 0, Step 1401: train/loss = 0.24760587513446808, train/raw-loss = 0.20444676280021667, train/logprobs = tensor([[-1.8788, -7.3690],
        [-4.5798, -3.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43159109354019165
Epoch 0, Step 1402: train/loss = 0.217767134308815, train/raw-loss = 0.1782117336988449, train/logprobs = tensor([[-1.2274, -4.8495],
        [-3.8982, -2.3616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39555397629737854
Epoch 0, Step 1403: train/loss = 0.31945013999938965, train/raw-loss = 0.28669196367263794, train/logprobs = tensor([[-1.8653, -5.4808],
        [-2.9731, -2.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3275814950466156
Epoch 0, Step 1404: train/loss = 0.2720205783843994, train/raw-loss = 0.23805558681488037, train/logprobs = tensor([[-1.1795, -7.4536],
        [-4.0759, -2.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396500051021576
Epoch 0, Step 1405: train/loss = 0.44836169481277466, train/raw-loss = 0.40625283122062683, train/logprobs = tensor([[-1.3060, -6.8835],
        [-3.4048, -2.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4210887849330902
Epoch 0, Step 1406: train/loss = 0.4322652816772461, train/raw-loss = 0.3993564248085022, train/logprobs = tensor([[-0.7017, -2.5387],
        [-2.5060, -2.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32908833026885986
Epoch 0, Step 1407: train/loss = 0.24974021315574646, train/raw-loss = 0.2176341712474823, train/logprobs = tensor([[-1.3592, -7.3819],
        [-2.8373, -1.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32106050848960876
Epoch 0, Step 1408: train/loss = 0.08923197537660599, train/raw-loss = 0.055149778723716736, train/logprobs = tensor([[ -0.9582, -10.9655],
        [ -3.5271,  -3.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3408220112323761
Epoch 0, Step 1409: train/loss = 0.5353180170059204, train/raw-loss = 0.49492180347442627, train/logprobs = tensor([[-0.9264, -1.9680],
        [-2.5719, -2.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40396255254745483
Epoch 0, Step 1410: train/loss = 0.31890159845352173, train/raw-loss = 0.27978432178497314, train/logprobs = tensor([[-0.9845, -5.6442],
        [-3.9989, -1.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3911725580692291
Epoch 0, Step 1411: train/loss = 0.5419183969497681, train/raw-loss = 0.494537889957428, train/logprobs = tensor([[-0.5863, -4.1914],
        [-2.8207, -3.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.473804771900177
Epoch 0, Step 1412: train/loss = 0.28247568011283875, train/raw-loss = 0.2455245852470398, train/logprobs = tensor([[-0.8548, -3.1855],
        [-4.1181, -2.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36951103806495667
Epoch 0, Step 1413: train/loss = 0.2511265277862549, train/raw-loss = 0.21819999814033508, train/logprobs = tensor([[-1.1140, -4.7864],
        [-3.0310, -2.0600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3292652666568756
Epoch 0, Step 1414: train/loss = 0.5560132265090942, train/raw-loss = 0.5252741575241089, train/logprobs = tensor([[-0.8032, -3.9680],
        [-1.9570, -3.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30739080905914307
Epoch 0, Step 1415: train/loss = 0.4708452820777893, train/raw-loss = 0.44376784563064575, train/logprobs = tensor([[-0.8578, -1.9770],
        [-2.0995, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707747220993042
Epoch 0, Step 1416: train/loss = 0.29874759912490845, train/raw-loss = 0.2631135880947113, train/logprobs = tensor([[-1.4059, -9.2384],
        [-3.6350, -4.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35634034872055054
Epoch 0, Step 1417: train/loss = 0.13933782279491425, train/raw-loss = 0.10338357090950012, train/logprobs = tensor([[-0.7217, -8.7885],
        [-2.7884, -2.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35954245924949646
Epoch 0, Step 1418: train/loss = 0.3458164930343628, train/raw-loss = 0.3087039589881897, train/logprobs = tensor([[-1.2418, -3.8332],
        [-2.9438, -2.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3711254596710205
Epoch 0, Step 1419: train/loss = 0.6043144464492798, train/raw-loss = 0.5757471919059753, train/logprobs = tensor([[-0.6264, -2.0529],
        [-2.1507, -1.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28567278385162354
Epoch 0, Step 1420: train/loss = 0.15070809423923492, train/raw-loss = 0.11318156868219376, train/logprobs = tensor([[-0.7481, -4.8034],
        [-3.2136, -1.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37526530027389526
Epoch 0, Step 1421: train/loss = 0.5076725482940674, train/raw-loss = 0.47344842553138733, train/logprobs = tensor([[-0.9556, -3.3248],
        [-2.6489, -2.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3422410488128662
Epoch 0, Step 1422: train/loss = 0.5398078560829163, train/raw-loss = 0.5141290426254272, train/logprobs = tensor([[-0.4744, -1.7517],
        [-1.6349, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256788432598114
Epoch 0, Step 1423: train/loss = 0.36586612462997437, train/raw-loss = 0.3315114974975586, train/logprobs = tensor([[-0.7050, -3.8810],
        [-2.4349, -2.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3435465395450592
Epoch 0, Step 1424: train/loss = 0.06631265580654144, train/raw-loss = 0.022253025323152542, train/logprobs = tensor([[-1.1799, -9.4863],
        [-5.1476, -2.0038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.440596342086792
Epoch 0, Step 1425: train/loss = 0.26183897256851196, train/raw-loss = 0.22906358540058136, train/logprobs = tensor([[-1.4841, -6.2173],
        [-3.0819, -3.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32775411009788513
Epoch 0, Step 1426: train/loss = 0.2355206310749054, train/raw-loss = 0.19962826371192932, train/logprobs = tensor([[-1.3048, -9.3609],
        [-3.9840, -3.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35892361402511597
Epoch 0, Step 1427: train/loss = 0.4149814546108246, train/raw-loss = 0.37926536798477173, train/logprobs = tensor([[-1.1925, -3.0650],
        [-2.9649, -1.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35716119408607483
Epoch 0, Step 1428: train/loss = 0.2529008388519287, train/raw-loss = 0.21155843138694763, train/logprobs = tensor([[-1.0828, -6.3466],
        [-3.4574, -2.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.413424015045166
Epoch 0, Step 1429: train/loss = 0.1844949573278427, train/raw-loss = 0.14663560688495636, train/logprobs = tensor([[-1.1402, -7.5680],
        [-3.8256, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3785935342311859
Epoch 0, Step 1430: train/loss = 0.3843529224395752, train/raw-loss = 0.35056546330451965, train/logprobs = tensor([[-1.5584, -6.7531],
        [-4.0026, -4.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33787477016448975
Epoch 0, Step 1431: train/loss = 0.09893424808979034, train/raw-loss = 0.05677926167845726, train/logprobs = tensor([[ -1.1081, -13.7067],
        [ -4.1910,  -5.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.421549916267395
Epoch 0, Step 1432: train/loss = 0.8499225378036499, train/raw-loss = 0.8045215606689453, train/logprobs = tensor([[-0.8076, -6.1142],
        [-4.4097, -4.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540100693702698
Epoch 0, Step 1433: train/loss = 0.3237549662590027, train/raw-loss = 0.28905224800109863, train/logprobs = tensor([[-0.8288, -3.8969],
        [-3.6425, -1.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470269441604614
Epoch 0, Step 1434: train/loss = 0.2400120496749878, train/raw-loss = 0.20095430314540863, train/logprobs = tensor([[-0.9224, -5.3884],
        [-4.2968, -2.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905775249004364
Epoch 0, Step 1435: train/loss = 0.5580912232398987, train/raw-loss = 0.5060235261917114, train/logprobs = tensor([[-1.1968, -7.9342],
        [-4.9652, -3.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5206766128540039
Epoch 0, Step 1436: train/loss = 0.4745437800884247, train/raw-loss = 0.4433642327785492, train/logprobs = tensor([[ -2.4705, -12.2262],
        [ -3.0239,  -3.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117953836917877
Epoch 0, Step 1437: train/loss = 0.34421414136886597, train/raw-loss = 0.31146010756492615, train/logprobs = tensor([[-0.7573, -9.3345],
        [-3.1833, -2.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32754069566726685
Epoch 0, Step 1438: train/loss = 0.11493600904941559, train/raw-loss = 0.08213314414024353, train/logprobs = tensor([[ -1.4206, -10.3928],
        [ -4.8216,  -2.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3280285894870758
Epoch 0, Step 1439: train/loss = 0.3214893341064453, train/raw-loss = 0.2931749224662781, train/logprobs = tensor([[-0.9758, -3.8822],
        [-4.0295, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28314435482025146
Epoch 0, Step 1440: train/loss = 0.40218570828437805, train/raw-loss = 0.3646615445613861, train/logprobs = tensor([[-0.8918, -5.1000],
        [-3.2769, -1.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37524163722991943
Epoch 0, Step 1441: train/loss = 0.6005634069442749, train/raw-loss = 0.5658764839172363, train/logprobs = tensor([[-1.3418, -2.3817],
        [-2.7274, -1.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34686875343322754
Epoch 0, Step 1442: train/loss = 0.06914718449115753, train/raw-loss = 0.03180132806301117, train/logprobs = tensor([[-1.6020, -8.3336],
        [-4.9769, -1.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37345853447914124
Epoch 0, Step 1443: train/loss = 0.7195379137992859, train/raw-loss = 0.681745171546936, train/logprobs = tensor([[-1.7064, -5.0162],
        [-2.2796, -3.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3779270648956299
Epoch 0, Step 1444: train/loss = 0.21601566672325134, train/raw-loss = 0.17115458846092224, train/logprobs = tensor([[-1.3681, -5.1949],
        [-4.6206, -1.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44861090183258057
Epoch 0, Step 1445: train/loss = 0.6004451513290405, train/raw-loss = 0.5635488033294678, train/logprobs = tensor([[-0.4811, -3.4160],
        [-2.5790, -3.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36896368861198425
Epoch 0, Step 1446: train/loss = 0.5107875466346741, train/raw-loss = 0.47315192222595215, train/logprobs = tensor([[-1.9742, -9.1934],
        [-3.1541, -2.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37635597586631775
Epoch 0, Step 1447: train/loss = 0.32995671033859253, train/raw-loss = 0.2958971858024597, train/logprobs = tensor([[-1.7183, -5.8667],
        [-2.9343, -2.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3405948579311371
Epoch 0, Step 1448: train/loss = 0.2665068507194519, train/raw-loss = 0.22831520438194275, train/logprobs = tensor([[-1.5671, -5.3762],
        [-2.8917, -2.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38191622495651245
Epoch 0, Step 1449: train/loss = 0.4498198926448822, train/raw-loss = 0.4105006754398346, train/logprobs = tensor([[-0.8780, -5.9699],
        [-3.1864, -2.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931921720504761
Epoch 0, Step 1450: train/loss = 0.31423288583755493, train/raw-loss = 0.2683190703392029, train/logprobs = tensor([[-0.7330, -4.6475],
        [-3.1938, -2.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4591382145881653
Epoch 0, Step 1451: train/loss = 0.2727600932121277, train/raw-loss = 0.2327999770641327, train/logprobs = tensor([[-0.9931, -6.6172],
        [-3.8208, -2.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3996012210845947
Epoch 0, Step 1452: train/loss = 0.5270650386810303, train/raw-loss = 0.4813184440135956, train/logprobs = tensor([[-0.8536, -7.6015],
        [-4.4322, -3.4988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4574664235115051
Epoch 0, Step 1453: train/loss = 0.16734275221824646, train/raw-loss = 0.1277170479297638, train/logprobs = tensor([[-1.2311, -6.0083],
        [-3.6832, -1.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39625704288482666
Epoch 0, Step 1454: train/loss = 0.3317607641220093, train/raw-loss = 0.29594528675079346, train/logprobs = tensor([[-1.1731, -5.4125],
        [-4.6335, -3.1792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358154833316803
Epoch 0, Step 1455: train/loss = 0.16867537796497345, train/raw-loss = 0.13096877932548523, train/logprobs = tensor([[-0.7281, -6.6911],
        [-5.0884, -4.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3770659863948822
Epoch 0, Step 1456: train/loss = 0.3761288821697235, train/raw-loss = 0.34597867727279663, train/logprobs = tensor([[-1.2044, -7.5808],
        [-3.2082, -3.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015021085739136
Epoch 0, Step 1457: train/loss = 0.27684295177459717, train/raw-loss = 0.24203194677829742, train/logprobs = tensor([[-1.1523, -5.9955],
        [-3.8026, -3.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3481099009513855
Epoch 0, Step 1458: train/loss = 0.5959894061088562, train/raw-loss = 0.5564409494400024, train/logprobs = tensor([[-1.2650, -2.0703],
        [-3.4970, -2.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39548423886299133
Epoch 0, Step 1459: train/loss = 0.17365053296089172, train/raw-loss = 0.12749513983726501, train/logprobs = tensor([[-1.0334, -8.8733],
        [-5.2750, -3.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4615539014339447
Epoch 0, Step 1460: train/loss = 0.24487830698490143, train/raw-loss = 0.20974987745285034, train/logprobs = tensor([[-1.9709, -7.8537],
        [-3.8785, -1.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35128429532051086
Epoch 0, Step 1461: train/loss = 0.6121107339859009, train/raw-loss = 0.5662873983383179, train/logprobs = tensor([[-1.1725, -3.1728],
        [-4.5457, -3.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4582335352897644
Epoch 0, Step 1462: train/loss = 0.38526636362075806, train/raw-loss = 0.33650362491607666, train/logprobs = tensor([[-1.1477, -4.3410],
        [-4.1946, -2.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4876273572444916
Epoch 0, Step 1463: train/loss = 0.20516850054264069, train/raw-loss = 0.1681327521800995, train/logprobs = tensor([[-1.3692, -5.4687],
        [-4.9203, -2.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703574240207672
Epoch 0, Step 1464: train/loss = 0.4842413067817688, train/raw-loss = 0.4393348693847656, train/logprobs = tensor([[-0.9898, -4.5641],
        [-4.0666, -2.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44906461238861084
Epoch 0, Step 1465: train/loss = 0.23020979762077332, train/raw-loss = 0.19769330322742462, train/logprobs = tensor([[-1.5088, -6.7957],
        [-4.7806, -3.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251650333404541
Epoch 0, Step 1466: train/loss = 0.3312222361564636, train/raw-loss = 0.29539042711257935, train/logprobs = tensor([[-0.9758, -5.3177],
        [-2.5471, -2.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358318030834198
Epoch 0, Step 1467: train/loss = 0.24719390273094177, train/raw-loss = 0.21077629923820496, train/logprobs = tensor([[-1.3244, -9.6799],
        [-4.2433, -2.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364175945520401
Epoch 0, Step 1468: train/loss = 0.5169064998626709, train/raw-loss = 0.480537474155426, train/logprobs = tensor([[-2.0695, -7.7477],
        [-4.2067, -3.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363690584897995
Epoch 0, Step 1469: train/loss = 0.35517963767051697, train/raw-loss = 0.3180188536643982, train/logprobs = tensor([[-0.7449, -4.9777],
        [-2.3060, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37160778045654297
Epoch 0, Step 1470: train/loss = 0.12582498788833618, train/raw-loss = 0.08063334226608276, train/logprobs = tensor([[-1.3255, -5.6092],
        [-3.9612, -2.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.451916366815567
Epoch 0, Step 1471: train/loss = 0.4735087752342224, train/raw-loss = 0.43127259612083435, train/logprobs = tensor([[-0.8647, -3.1905],
        [-3.3346, -2.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4223616123199463
Epoch 0, Step 1472: train/loss = 0.2728922963142395, train/raw-loss = 0.24379897117614746, train/logprobs = tensor([[-0.8374, -9.0467],
        [-2.3499, -2.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29093313217163086
Epoch 0, Step 1473: train/loss = 0.2485874742269516, train/raw-loss = 0.20477521419525146, train/logprobs = tensor([[-1.1837, -5.3701],
        [-3.9750, -2.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4381225109100342
Epoch 0, Step 1474: train/loss = 0.2738470733165741, train/raw-loss = 0.23333878815174103, train/logprobs = tensor([[-1.2790, -5.3760],
        [-3.5840, -3.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050827920436859
Epoch 0, Step 1475: train/loss = 0.3437662124633789, train/raw-loss = 0.3088602125644684, train/logprobs = tensor([[-1.1845, -3.1847],
        [-3.1727, -1.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490600883960724
Epoch 0, Step 1476: train/loss = 0.38099798560142517, train/raw-loss = 0.3430721163749695, train/logprobs = tensor([[-1.7074, -4.9371],
        [-3.6994, -4.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3792589604854584
Epoch 0, Step 1477: train/loss = 0.15464025735855103, train/raw-loss = 0.11877778172492981, train/logprobs = tensor([[-1.6730, -6.7230],
        [-4.1219, -2.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586246967315674
Epoch 0, Step 1478: train/loss = 0.6849800944328308, train/raw-loss = 0.6456136703491211, train/logprobs = tensor([[-0.8762, -1.4575],
        [-3.3877, -2.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39366424083709717
Epoch 0, Step 1479: train/loss = 0.49513763189315796, train/raw-loss = 0.44251587986946106, train/logprobs = tensor([[-0.9706, -3.5590],
        [-3.8201, -3.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5262175798416138
Epoch 0, Step 1480: train/loss = 0.5301531553268433, train/raw-loss = 0.4912106692790985, train/logprobs = tensor([[-1.2336, -5.4904],
        [-5.0639, -2.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894250988960266
Epoch 0, Step 1481: train/loss = 0.3192980885505676, train/raw-loss = 0.2849242389202118, train/logprobs = tensor([[-1.2972, -5.1776],
        [-3.2161, -2.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34373846650123596
Epoch 0, Step 1482: train/loss = 0.2628958523273468, train/raw-loss = 0.22655774652957916, train/logprobs = tensor([[-1.1025, -7.2748],
        [-3.6974, -3.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3633812367916107
Epoch 0, Step 1483: train/loss = 0.3096352517604828, train/raw-loss = 0.2733185291290283, train/logprobs = tensor([[-0.9489, -4.3880],
        [-4.6613, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3631671965122223
Epoch 0, Step 1484: train/loss = 0.1466006636619568, train/raw-loss = 0.10555262863636017, train/logprobs = tensor([[-0.6918, -6.2494],
        [-3.8522, -2.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4104803800582886
Epoch 0, Step 1485: train/loss = 0.5455307960510254, train/raw-loss = 0.510362446308136, train/logprobs = tensor([[-1.1325, -3.6375],
        [-2.2038, -2.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3516835868358612
Epoch 0, Step 1486: train/loss = 0.5847530961036682, train/raw-loss = 0.5459166765213013, train/logprobs = tensor([[-1.5927, -3.1402],
        [-2.5445, -2.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38836419582366943
Epoch 0, Step 1487: train/loss = 0.21151041984558105, train/raw-loss = 0.17947529256343842, train/logprobs = tensor([[-2.1417, -6.8210],
        [-3.7419, -1.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320351243019104
Epoch 0, Step 1488: train/loss = 0.5184179544448853, train/raw-loss = 0.4763106107711792, train/logprobs = tensor([[-0.5920, -2.3178],
        [-2.8819, -2.6016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.421073853969574
Epoch 0, Step 1489: train/loss = 0.46238526701927185, train/raw-loss = 0.4313993752002716, train/logprobs = tensor([[-1.2792, -4.3812],
        [-2.8907, -2.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30985891819000244
Epoch 0, Step 1490: train/loss = 0.38338178396224976, train/raw-loss = 0.3489806056022644, train/logprobs = tensor([[-0.7930, -3.9868],
        [-3.1544, -1.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3440117835998535
Epoch 0, Step 1491: train/loss = 0.2653750777244568, train/raw-loss = 0.2245265245437622, train/logprobs = tensor([[-1.8733, -7.8186],
        [-4.2739, -2.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40848541259765625
Epoch 0, Step 1492: train/loss = 0.40113264322280884, train/raw-loss = 0.3630421757698059, train/logprobs = tensor([[-1.0843, -3.9508],
        [-3.6166, -2.8931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3809046447277069
Epoch 0, Step 1493: train/loss = 0.2816759943962097, train/raw-loss = 0.24389943480491638, train/logprobs = tensor([[-1.1276, -4.3497],
        [-4.3550, -1.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37776562571525574
Epoch 0, Step 1494: train/loss = 0.16518232226371765, train/raw-loss = 0.11294477432966232, train/logprobs = tensor([[-0.9561, -6.0266],
        [-4.6900, -2.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5223754644393921
Epoch 0, Step 1495: train/loss = 0.22792406380176544, train/raw-loss = 0.1832183599472046, train/logprobs = tensor([[-0.7802, -7.6797],
        [-4.0722, -3.3822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4470571279525757
Epoch 0, Step 1496: train/loss = 0.20262782275676727, train/raw-loss = 0.17019006609916687, train/logprobs = tensor([[-1.2163, -6.7403],
        [-2.9663, -1.5566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32437756657600403
Epoch 0, Step 1497: train/loss = 0.34487202763557434, train/raw-loss = 0.3158952593803406, train/logprobs = tensor([[-0.8799, -4.0171],
        [-2.8735, -2.2406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28976765275001526
Epoch 0, Step 1498: train/loss = 0.3102209270000458, train/raw-loss = 0.2686302959918976, train/logprobs = tensor([[-0.9212, -4.0092],
        [-4.9234, -1.7314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41590616106987
Epoch 0, Step 1499: train/loss = 0.42949169874191284, train/raw-loss = 0.39559268951416016, train/logprobs = tensor([[-1.7822, -3.8964],
        [-3.6637, -2.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3389902114868164
Epoch 0, Step 1500: train/loss = 0.5106266736984253, train/raw-loss = 0.4889628291130066, train/logprobs = tensor([[-0.4983, -4.0972],
        [-1.1390, -2.3637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21663829684257507
Epoch 0, Step 1501: train/loss = 0.2443327158689499, train/raw-loss = 0.1946064680814743, train/logprobs = tensor([[-0.8472, -6.0271],
        [-5.2259, -2.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4972623288631439
Epoch 0, Step 1502: train/loss = 0.07538463175296783, train/raw-loss = 0.03089594841003418, train/logprobs = tensor([[-1.4057, -7.7300],
        [-5.0057, -2.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44488683342933655
Epoch 0, Step 1503: train/loss = 0.48669856786727905, train/raw-loss = 0.44413769245147705, train/logprobs = tensor([[-1.6212, -4.3687],
        [-4.4642, -2.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42560863494873047
Epoch 0, Step 1504: train/loss = 0.28345680236816406, train/raw-loss = 0.24587172269821167, train/logprobs = tensor([[-0.9153, -5.6094],
        [-3.3246, -2.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3758505582809448
Epoch 0, Step 1505: train/loss = 0.21012647449970245, train/raw-loss = 0.17455340921878815, train/logprobs = tensor([[-1.2206, -6.1585],
        [-3.9047, -1.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35573068261146545
Epoch 0, Step 1506: train/loss = 0.1151077002286911, train/raw-loss = 0.07801972329616547, train/logprobs = tensor([[-0.9834, -5.8003],
        [-4.4621, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37087976932525635
Epoch 0, Step 1507: train/loss = 0.37273716926574707, train/raw-loss = 0.32744356989860535, train/logprobs = tensor([[-0.7942, -3.3332],
        [-3.0070, -1.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4529361128807068
Epoch 0, Step 1508: train/loss = 0.39740705490112305, train/raw-loss = 0.3614948093891144, train/logprobs = tensor([[-1.5104, -4.9075],
        [-2.9829, -2.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35912221670150757
Epoch 0, Step 1509: train/loss = 0.48769351840019226, train/raw-loss = 0.4545729160308838, train/logprobs = tensor([[-1.1767, -2.7244],
        [-2.8541, -1.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3312057852745056
Epoch 0, Step 1510: train/loss = 0.4558326005935669, train/raw-loss = 0.4156651496887207, train/logprobs = tensor([[-0.8456, -6.6207],
        [-2.5479, -2.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40167468786239624
Epoch 0, Step 1511: train/loss = 0.10932555794715881, train/raw-loss = 0.07623283565044403, train/logprobs = tensor([[-1.4762, -8.0616],
        [-3.7076, -2.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33092719316482544
Epoch 0, Step 1512: train/loss = 0.41026151180267334, train/raw-loss = 0.37165406346321106, train/logprobs = tensor([[-0.9452, -3.8800],
        [-3.1433, -2.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3860744833946228
Epoch 0, Step 1513: train/loss = 0.25105080008506775, train/raw-loss = 0.21483653783798218, train/logprobs = tensor([[-0.8369, -5.2407],
        [-3.1877, -1.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36214274168014526
Epoch 0, Step 1514: train/loss = 0.565775990486145, train/raw-loss = 0.5308752059936523, train/logprobs = tensor([[-2.2962, -9.0754],
        [-3.1033, -2.2757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490084409713745
Epoch 0, Step 1515: train/loss = 0.1620904505252838, train/raw-loss = 0.12804938852787018, train/logprobs = tensor([[-1.0581, -5.2344],
        [-4.2694, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34041059017181396
Epoch 0, Step 1516: train/loss = 0.6791123151779175, train/raw-loss = 0.6539199948310852, train/logprobs = tensor([[-0.9249, -1.0231],
        [-2.6398, -1.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25192323327064514
Epoch 0, Step 1517: train/loss = 0.16166415810585022, train/raw-loss = 0.1278422325849533, train/logprobs = tensor([[ -1.4303, -11.1865],
        [ -4.7137,  -4.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33821913599967957
Epoch 0, Step 1518: train/loss = 0.4975039064884186, train/raw-loss = 0.46855494379997253, train/logprobs = tensor([[-2.7480, -4.8681],
        [-2.8774, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28948959708213806
Epoch 0, Step 1519: train/loss = 0.5409074425697327, train/raw-loss = 0.5028727650642395, train/logprobs = tensor([[-1.1459, -3.2680],
        [-3.0092, -2.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3803471326828003
Epoch 0, Step 1520: train/loss = 0.13443365693092346, train/raw-loss = 0.09273338317871094, train/logprobs = tensor([[-1.0228, -7.9328],
        [-4.7879, -2.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41700273752212524
Epoch 0, Step 1521: train/loss = 0.4178779721260071, train/raw-loss = 0.38701751828193665, train/logprobs = tensor([[-2.6322, -3.5832],
        [-3.9822, -2.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086046576499939
Epoch 0, Step 1522: train/loss = 0.4407055974006653, train/raw-loss = 0.4150519371032715, train/logprobs = tensor([[ -2.4906, -11.0140],
        [ -3.6587,  -3.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256536602973938
Epoch 0, Step 1523: train/loss = 0.0881364718079567, train/raw-loss = 0.0537705197930336, train/logprobs = tensor([[-1.1972, -6.1829],
        [-5.2618, -2.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34365949034690857
Epoch 0, Step 1524: train/loss = 0.2883906960487366, train/raw-loss = 0.2488059401512146, train/logprobs = tensor([[-1.3022, -4.3006],
        [-3.8382, -2.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3958475589752197
Epoch 0, Step 1525: train/loss = 0.8695401549339294, train/raw-loss = 0.8271806240081787, train/logprobs = tensor([[-1.0091, -1.0962],
        [-2.8690, -2.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4235957860946655
Epoch 0, Step 1526: train/loss = 0.4972711503505707, train/raw-loss = 0.46465185284614563, train/logprobs = tensor([[-0.9420, -3.9065],
        [-2.7968, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32619330286979675
Epoch 0, Step 1527: train/loss = 0.31987592577934265, train/raw-loss = 0.27863937616348267, train/logprobs = tensor([[-1.8194, -3.6011],
        [-3.4324, -2.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4123651385307312
Epoch 0, Step 1528: train/loss = 0.18005114793777466, train/raw-loss = 0.14034628868103027, train/logprobs = tensor([[-0.7921, -5.8121],
        [-4.3466, -2.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39704862236976624
Epoch 0, Step 1529: train/loss = 0.4843360483646393, train/raw-loss = 0.43917012214660645, train/logprobs = tensor([[-1.3814, -4.4736],
        [-4.1909, -2.7753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4516592025756836
Epoch 0, Step 1530: train/loss = 0.20297250151634216, train/raw-loss = 0.1610395312309265, train/logprobs = tensor([[-1.3182, -6.0653],
        [-4.9299, -1.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4193297326564789
Epoch 0, Step 1531: train/loss = 0.40827125310897827, train/raw-loss = 0.3674163520336151, train/logprobs = tensor([[-1.0410, -5.8749],
        [-3.3368, -2.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40854859352111816
Epoch 0, Step 1532: train/loss = 0.4248436689376831, train/raw-loss = 0.3843609094619751, train/logprobs = tensor([[-1.2679, -4.3696],
        [-2.6430, -2.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40482771396636963
Epoch 0, Step 1533: train/loss = 0.25555288791656494, train/raw-loss = 0.2247764766216278, train/logprobs = tensor([[-0.4971, -4.7843],
        [-2.8636, -2.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077639937400818
Epoch 0, Step 1534: train/loss = 0.3157167136669159, train/raw-loss = 0.2827741503715515, train/logprobs = tensor([[-2.2607, -7.1962],
        [-3.3109, -2.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294258415699005
Epoch 0, Step 1535: train/loss = 0.46312180161476135, train/raw-loss = 0.42031222581863403, train/logprobs = tensor([[-1.0597, -3.3858],
        [-3.6426, -3.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42809540033340454
Epoch 0, Step 1536: train/loss = 0.31088492274284363, train/raw-loss = 0.28202903270721436, train/logprobs = tensor([[-0.8913, -7.0818],
        [-2.6862, -2.3104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2885591685771942
Epoch 0, Step 1537: train/loss = 0.341269850730896, train/raw-loss = 0.30305904150009155, train/logprobs = tensor([[-1.7572, -3.9641],
        [-2.9152, -1.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38210803270339966
Epoch 0, Step 1538: train/loss = 0.28998303413391113, train/raw-loss = 0.25102582573890686, train/logprobs = tensor([[-0.9279, -6.6922],
        [-3.7025, -3.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3895722031593323
Epoch 0, Step 1539: train/loss = 0.4702209234237671, train/raw-loss = 0.4266926050186157, train/logprobs = tensor([[-1.0933, -3.6445],
        [-2.7061, -3.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4352830648422241
Epoch 0, Step 1540: train/loss = 0.3235546946525574, train/raw-loss = 0.28429386019706726, train/logprobs = tensor([[-1.6433, -5.6624],
        [-4.0559, -2.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3926079571247101
Epoch 0, Step 1541: train/loss = 0.11874094605445862, train/raw-loss = 0.08285229653120041, train/logprobs = tensor([[ -1.1339, -11.5172],
        [ -3.8731,  -3.1230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35888656973838806
Epoch 0, Step 1542: train/loss = 0.6204734444618225, train/raw-loss = 0.5872872471809387, train/logprobs = tensor([[-1.4203, -1.2775],
        [-2.3338, -1.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3318617045879364
Epoch 0, Step 1543: train/loss = 0.4736994504928589, train/raw-loss = 0.43467646837234497, train/logprobs = tensor([[-0.9917, -3.1616],
        [-4.2626, -2.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39022988080978394
Epoch 0, Step 1544: train/loss = 0.3157680034637451, train/raw-loss = 0.2750049829483032, train/logprobs = tensor([[-1.4973, -6.7244],
        [-5.1695, -2.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4076306223869324
Epoch 0, Step 1545: train/loss = 0.34551531076431274, train/raw-loss = 0.30847862362861633, train/logprobs = tensor([[-1.6084, -4.6286],
        [-3.5150, -1.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37036678194999695
Epoch 0, Step 1546: train/loss = 0.4622385501861572, train/raw-loss = 0.4235913157463074, train/logprobs = tensor([[-1.1062, -3.5149],
        [-3.3278, -2.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38647207617759705
Epoch 0, Step 1547: train/loss = 0.49262765049934387, train/raw-loss = 0.4555492103099823, train/logprobs = tensor([[-1.1044, -3.2290],
        [-3.3072, -2.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3707846701145172
Epoch 0, Step 1548: train/loss = 0.4028077721595764, train/raw-loss = 0.3680518865585327, train/logprobs = tensor([[-0.7639, -5.6520],
        [-2.4829, -3.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3475587069988251
Epoch 0, Step 1549: train/loss = 0.4739398956298828, train/raw-loss = 0.4405241906642914, train/logprobs = tensor([[-0.7085, -3.4921],
        [-2.9830, -2.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341572880744934
Epoch 0, Step 1550: train/loss = 0.5333487391471863, train/raw-loss = 0.5005752444267273, train/logprobs = tensor([[-1.0437, -2.4408],
        [-2.7301, -2.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32773464918136597
Epoch 0, Step 1551: train/loss = 0.15200075507164001, train/raw-loss = 0.11626069247722626, train/logprobs = tensor([[-0.9498, -6.2306],
        [-3.3308, -2.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3574005663394928
Epoch 0, Step 1552: train/loss = 0.2866740822792053, train/raw-loss = 0.25084084272384644, train/logprobs = tensor([[ -1.1300, -11.2877],
        [ -3.4926,  -4.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3583321273326874
Epoch 0, Step 1553: train/loss = 0.2851298153400421, train/raw-loss = 0.24688734114170074, train/logprobs = tensor([[-1.4511, -5.4703],
        [-3.2135, -2.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38242489099502563
Epoch 0, Step 1554: train/loss = 0.5216913819313049, train/raw-loss = 0.48499763011932373, train/logprobs = tensor([[-1.3634, -3.3955],
        [-3.1849, -2.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36693766713142395
Epoch 0, Step 1555: train/loss = 0.261819988489151, train/raw-loss = 0.22831827402114868, train/logprobs = tensor([[-1.6728, -5.1577],
        [-4.2445, -2.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3350173830986023
Epoch 0, Step 1556: train/loss = 0.31448253989219666, train/raw-loss = 0.2802123725414276, train/logprobs = tensor([[-0.7182, -8.9062],
        [-2.4149, -3.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34270158410072327
Epoch 0, Step 1557: train/loss = 0.25777187943458557, train/raw-loss = 0.22747038304805756, train/logprobs = tensor([[-1.0333, -7.2952],
        [-2.6358, -1.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3030149042606354
Epoch 0, Step 1558: train/loss = 0.22402037680149078, train/raw-loss = 0.18699075281620026, train/logprobs = tensor([[-0.9731, -9.2509],
        [-3.6987, -2.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37029626965522766
Epoch 0, Step 1559: train/loss = 0.3760008215904236, train/raw-loss = 0.34209102392196655, train/logprobs = tensor([[-1.9257, -4.3337],
        [-4.2637, -1.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33909809589385986
Epoch 0, Step 1560: train/loss = 0.13791295886039734, train/raw-loss = 0.10424210131168365, train/logprobs = tensor([[-1.2980, -7.7731],
        [-3.0577, -1.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33670860528945923
Epoch 0, Step 1561: train/loss = 0.20231246948242188, train/raw-loss = 0.15494917333126068, train/logprobs = tensor([[-1.8900, -5.9654],
        [-5.7933, -3.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47363317012786865
Epoch 0, Step 1562: train/loss = 0.43421781063079834, train/raw-loss = 0.3961629569530487, train/logprobs = tensor([[-3.4212, -9.9530],
        [-4.0699, -2.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38054877519607544
Epoch 0, Step 1563: train/loss = 0.5614893436431885, train/raw-loss = 0.516506552696228, train/logprobs = tensor([[-1.3125, -2.2424],
        [-3.3647, -2.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4498271942138672
Epoch 0, Step 1564: train/loss = 0.3254846930503845, train/raw-loss = 0.29218152165412903, train/logprobs = tensor([[-1.1399, -5.2452],
        [-4.5139, -2.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330315947532654
Epoch 0, Step 1565: train/loss = 0.5564122796058655, train/raw-loss = 0.5221390724182129, train/logprobs = tensor([[-1.6266, -2.6022],
        [-3.1384, -2.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427315652370453
Epoch 0, Step 1566: train/loss = 0.20413920283317566, train/raw-loss = 0.1608041375875473, train/logprobs = tensor([[-1.0279, -6.9213],
        [-4.4687, -3.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43335065245628357
Epoch 0, Step 1567: train/loss = 0.5749531984329224, train/raw-loss = 0.5394760370254517, train/logprobs = tensor([[-0.9094, -3.7969],
        [-2.4339, -1.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35477155447006226
Epoch 0, Step 1568: train/loss = 0.4619184732437134, train/raw-loss = 0.42211395502090454, train/logprobs = tensor([[-2.7588, -9.9183],
        [-3.9771, -2.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980451226234436
Epoch 0, Step 1569: train/loss = 0.3952467143535614, train/raw-loss = 0.3552809953689575, train/logprobs = tensor([[-1.8790, -4.2380],
        [-3.1039, -1.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39965707063674927
Epoch 0, Step 1570: train/loss = 0.3564235270023346, train/raw-loss = 0.31969812512397766, train/logprobs = tensor([[-1.4175, -4.4094],
        [-3.2349, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672538101673126
Epoch 0, Step 1571: train/loss = 0.38289952278137207, train/raw-loss = 0.3462519347667694, train/logprobs = tensor([[-1.2610, -3.3647],
        [-2.8418, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3664757311344147
Epoch 0, Step 1572: train/loss = 0.2059178501367569, train/raw-loss = 0.1688876450061798, train/logprobs = tensor([[-1.0967, -5.5435],
        [-3.6574, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703020513057709
Epoch 0, Step 1573: train/loss = 0.14970183372497559, train/raw-loss = 0.11874596029520035, train/logprobs = tensor([[-1.1938, -6.5070],
        [-4.1566, -1.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30955877900123596
Epoch 0, Step 1574: train/loss = 0.3147725462913513, train/raw-loss = 0.27575206756591797, train/logprobs = tensor([[-0.9602, -6.0420],
        [-4.1829, -2.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3902047872543335
Epoch 0, Step 1575: train/loss = 0.28478148579597473, train/raw-loss = 0.2493780255317688, train/logprobs = tensor([[-1.6483, -4.9914],
        [-3.9187, -2.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354034423828125
Epoch 0, Step 1576: train/loss = 0.7492879629135132, train/raw-loss = 0.7171099781990051, train/logprobs = tensor([[-0.8530, -1.2136],
        [-1.6626, -1.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217800259590149
Epoch 0, Step 1577: train/loss = 0.4776841998100281, train/raw-loss = 0.4365472197532654, train/logprobs = tensor([[-1.1288, -2.5094],
        [-2.9862, -2.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4113699793815613
Epoch 0, Step 1578: train/loss = 0.20096254348754883, train/raw-loss = 0.17438296973705292, train/logprobs = tensor([[ -1.7247, -11.1016],
        [ -2.9912,  -1.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26579561829566956
Epoch 0, Step 1579: train/loss = 0.4698082506656647, train/raw-loss = 0.4315391778945923, train/logprobs = tensor([[-1.0311, -5.3974],
        [-3.4724, -2.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3826908767223358
Epoch 0, Step 1580: train/loss = 0.22974124550819397, train/raw-loss = 0.19296912848949432, train/logprobs = tensor([[-0.7714, -3.9579],
        [-3.2449, -2.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3677210509777069
Epoch 0, Step 1581: train/loss = 0.10782027244567871, train/raw-loss = 0.0662299171090126, train/logprobs = tensor([[-1.8000, -4.9540],
        [-4.9886, -1.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41590362787246704
Epoch 0, Step 1582: train/loss = 0.13073772192001343, train/raw-loss = 0.09940409660339355, train/logprobs = tensor([[ -1.7192, -10.4532],
        [ -4.0362,  -1.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31333625316619873
Epoch 0, Step 1583: train/loss = 0.4516717195510864, train/raw-loss = 0.41070497035980225, train/logprobs = tensor([[-1.4408, -7.3957],
        [-5.3093, -3.4090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40966761112213135
Epoch 0, Step 1584: train/loss = 0.1264556646347046, train/raw-loss = 0.09402541816234589, train/logprobs = tensor([[-1.2827, -7.6623],
        [-3.5572, -1.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3243024945259094
Epoch 0, Step 1585: train/loss = 0.1435687243938446, train/raw-loss = 0.09621977806091309, train/logprobs = tensor([[-1.6164, -5.3808],
        [-4.2257, -2.3687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4734894633293152
Epoch 0, Step 1586: train/loss = 0.2508232891559601, train/raw-loss = 0.21128302812576294, train/logprobs = tensor([[-1.2410, -7.2471],
        [-3.8805, -1.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39540255069732666
Epoch 0, Step 1587: train/loss = 0.08390486240386963, train/raw-loss = 0.04152952879667282, train/logprobs = tensor([[-1.3451, -6.4579],
        [-4.4530, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42375338077545166
Epoch 0, Step 1588: train/loss = 0.22940191626548767, train/raw-loss = 0.2031266987323761, train/logprobs = tensor([[-0.7899, -5.4829],
        [-2.6685, -1.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2627522051334381
Epoch 0, Step 1589: train/loss = 0.30346599221229553, train/raw-loss = 0.2695814371109009, train/logprobs = tensor([[-1.2408, -6.8284],
        [-3.0407, -2.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3388453722000122
Epoch 0, Step 1590: train/loss = 0.31706303358078003, train/raw-loss = 0.28864341974258423, train/logprobs = tensor([[-1.1403, -7.5889],
        [-1.7062, -1.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28419622778892517
Epoch 0, Step 1591: train/loss = 0.2326246201992035, train/raw-loss = 0.1931810826063156, train/logprobs = tensor([[-1.0167, -7.0586],
        [-4.1088, -4.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3944353759288788
Epoch 0, Step 1592: train/loss = 0.29766178131103516, train/raw-loss = 0.2558383643627167, train/logprobs = tensor([[-1.3291, -4.5204],
        [-3.0757, -1.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41823437809944153
Epoch 0, Step 1593: train/loss = 0.2465732991695404, train/raw-loss = 0.20920522511005402, train/logprobs = tensor([[-1.3190, -7.0215],
        [-3.5172, -2.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37368059158325195
Epoch 0, Step 1594: train/loss = 0.15036404132843018, train/raw-loss = 0.10823472589254379, train/logprobs = tensor([[-1.3472, -6.0175],
        [-3.7975, -2.3440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4212931990623474
Epoch 0, Step 1595: train/loss = 0.1967964470386505, train/raw-loss = 0.15842945873737335, train/logprobs = tensor([[-1.2388, -5.0643],
        [-3.3677, -2.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836698830127716
Epoch 0, Step 1596: train/loss = 0.25966620445251465, train/raw-loss = 0.2154317945241928, train/logprobs = tensor([[-1.2916, -8.8120],
        [-4.6685, -2.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4423443078994751
Epoch 0, Step 1597: train/loss = 0.1660616546869278, train/raw-loss = 0.1330389380455017, train/logprobs = tensor([[-1.8487, -7.6620],
        [-4.3444, -2.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330227255821228
Epoch 0, Step 1598: train/loss = 0.27288225293159485, train/raw-loss = 0.24181969463825226, train/logprobs = tensor([[-1.4243, -8.6073],
        [-2.9870, -1.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106255531311035
Epoch 0, Step 1599: train/loss = 0.09326670318841934, train/raw-loss = 0.04884948953986168, train/logprobs = tensor([[ -1.1215, -10.6921],
        [ -4.3281,  -3.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4441721439361572
Epoch 0, Step 1600: train/loss = 0.3491494357585907, train/raw-loss = 0.31416764855384827, train/logprobs = tensor([[-2.0377, -8.2853],
        [-2.8612, -2.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3498181104660034
Epoch 0, Step 1601: train/loss = 0.07306689023971558, train/raw-loss = 0.03386532515287399, train/logprobs = tensor([[ -0.8824, -12.4255],
        [ -4.0847,  -4.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39201563596725464
Epoch 0, Step 1602: train/loss = 0.1509184092283249, train/raw-loss = 0.11010028421878815, train/logprobs = tensor([[-0.8520, -6.4443],
        [-3.1025, -2.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081812798976898
Epoch 0, Step 1603: train/loss = 0.4863777756690979, train/raw-loss = 0.4523419141769409, train/logprobs = tensor([[-0.6593, -3.6982],
        [-2.8646, -2.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34035855531692505
Epoch 0, Step 1604: train/loss = 0.18264687061309814, train/raw-loss = 0.149422287940979, train/logprobs = tensor([[-0.9197, -8.1640],
        [-2.6447, -4.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322458863258362
Epoch 0, Step 1605: train/loss = 0.4727904200553894, train/raw-loss = 0.43693989515304565, train/logprobs = tensor([[-1.2856, -5.0871],
        [-2.6440, -1.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3585055470466614
Epoch 0, Step 1606: train/loss = 0.192918062210083, train/raw-loss = 0.16213545203208923, train/logprobs = tensor([[-1.1259, -9.0256],
        [-3.2865, -3.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30782610177993774
Epoch 0, Step 1607: train/loss = 0.21168911457061768, train/raw-loss = 0.1733647733926773, train/logprobs = tensor([[-1.4045, -4.8090],
        [-3.2072, -2.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38324329257011414
Epoch 0, Step 1608: train/loss = 0.32425498962402344, train/raw-loss = 0.28416526317596436, train/logprobs = tensor([[-1.5683, -9.4943],
        [-3.6155, -3.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40089690685272217
Epoch 0, Step 1609: train/loss = 0.35145699977874756, train/raw-loss = 0.3163279891014099, train/logprobs = tensor([[-1.6176, -8.7992],
        [-3.0239, -3.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3512897491455078
Epoch 0, Step 1610: train/loss = 0.534018874168396, train/raw-loss = 0.4981415569782257, train/logprobs = tensor([[-1.9064, -5.0487],
        [-2.4699, -1.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35877344012260437
Epoch 0, Step 1611: train/loss = 0.3200782835483551, train/raw-loss = 0.28337615728378296, train/logprobs = tensor([[-1.5696, -3.3016],
        [-3.5868, -1.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36702123284339905
Epoch 0, Step 1612: train/loss = 0.21386711299419403, train/raw-loss = 0.17559754848480225, train/logprobs = tensor([[-1.3696, -7.4676],
        [-4.0023, -1.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.382695734500885
Epoch 0, Step 1613: train/loss = 0.6258061528205872, train/raw-loss = 0.584433376789093, train/logprobs = tensor([[-1.0612, -2.3582],
        [-2.4817, -2.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41372835636138916
Epoch 0, Step 1614: train/loss = 0.28942638635635376, train/raw-loss = 0.2543521821498871, train/logprobs = tensor([[-2.5863, -8.5899],
        [-4.1801, -3.3402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35074231028556824
Epoch 0, Step 1615: train/loss = 0.40378475189208984, train/raw-loss = 0.37101492285728455, train/logprobs = tensor([[-1.0538, -7.6977],
        [-2.5064, -3.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276982605457306
Epoch 0, Step 1616: train/loss = 0.4326079487800598, train/raw-loss = 0.39681851863861084, train/logprobs = tensor([[-1.0686, -5.6777],
        [-4.0083, -3.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578944802284241
Epoch 0, Step 1617: train/loss = 0.32833370566368103, train/raw-loss = 0.3007276654243469, train/logprobs = tensor([[-1.2159, -4.5887],
        [-2.6648, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760603427886963
Epoch 0, Step 1618: train/loss = 0.38631218671798706, train/raw-loss = 0.35062772035598755, train/logprobs = tensor([[-1.0548, -3.3865],
        [-2.6377, -2.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568446636199951
Epoch 0, Step 1619: train/loss = 0.16972750425338745, train/raw-loss = 0.1385563611984253, train/logprobs = tensor([[-1.1149, -7.4091],
        [-2.7264, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117113709449768
Epoch 0, Step 1620: train/loss = 0.2895994782447815, train/raw-loss = 0.2526395320892334, train/logprobs = tensor([[-1.1280, -4.8927],
        [-3.1561, -2.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36959943175315857
Epoch 0, Step 1621: train/loss = 0.243461012840271, train/raw-loss = 0.20579203963279724, train/logprobs = tensor([[-1.5303, -5.1579],
        [-3.6431, -1.6442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37668970227241516
Epoch 0, Step 1622: train/loss = 0.1788710057735443, train/raw-loss = 0.1432240754365921, train/logprobs = tensor([[-1.6586, -9.0928],
        [-3.7163, -2.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35646939277648926
Epoch 0, Step 1623: train/loss = 0.42794889211654663, train/raw-loss = 0.39272087812423706, train/logprobs = tensor([[-0.7786, -4.0931],
        [-2.5649, -2.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35228022933006287
Epoch 0, Step 1624: train/loss = 0.13150160014629364, train/raw-loss = 0.09902063012123108, train/logprobs = tensor([[-1.1128, -4.5425],
        [-3.7270, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3248097002506256
Epoch 0, Step 1625: train/loss = 0.1817476749420166, train/raw-loss = 0.14033828675746918, train/logprobs = tensor([[-1.3519, -7.1237],
        [-3.9352, -1.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41409391164779663
Epoch 0, Step 1626: train/loss = 0.463175505399704, train/raw-loss = 0.43500903248786926, train/logprobs = tensor([[-2.0386, -3.2287],
        [-3.2419, -1.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2816649079322815
Epoch 0, Step 1627: train/loss = 0.3703288733959198, train/raw-loss = 0.33677875995635986, train/logprobs = tensor([[-2.0865, -4.8088],
        [-3.5479, -2.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3355012834072113
Epoch 0, Step 1628: train/loss = 0.1829274296760559, train/raw-loss = 0.15599045157432556, train/logprobs = tensor([[-1.1737, -8.2801],
        [-2.4035, -2.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693696618080139
Epoch 0, Step 1629: train/loss = 0.44404661655426025, train/raw-loss = 0.4092252850532532, train/logprobs = tensor([[-1.4394, -4.9389],
        [-2.9870, -1.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34821367263793945
Epoch 0, Step 1630: train/loss = 0.41406017541885376, train/raw-loss = 0.3750593066215515, train/logprobs = tensor([[-1.0713, -2.5907],
        [-3.6360, -2.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39000871777534485
Epoch 0, Step 1631: train/loss = 0.10979492962360382, train/raw-loss = 0.07319945842027664, train/logprobs = tensor([[-0.9555, -9.7800],
        [-3.0137, -2.2314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659546375274658
Epoch 0, Step 1632: train/loss = 0.2560099959373474, train/raw-loss = 0.21620237827301025, train/logprobs = tensor([[-1.1408, -9.6121],
        [-3.3226, -2.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980761170387268
Epoch 0, Step 1633: train/loss = 0.3201707899570465, train/raw-loss = 0.2916075885295868, train/logprobs = tensor([[-1.5168, -6.2951],
        [-4.1677, -1.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28563207387924194
Epoch 0, Step 1634: train/loss = 0.44761109352111816, train/raw-loss = 0.4001992344856262, train/logprobs = tensor([[-1.7132, -4.4505],
        [-3.7605, -2.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47411876916885376
Epoch 0, Step 1635: train/loss = 0.3330141305923462, train/raw-loss = 0.287322074174881, train/logprobs = tensor([[-0.8652, -8.1980],
        [-4.8153, -3.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4569205641746521
Epoch 0, Step 1636: train/loss = 0.2208835780620575, train/raw-loss = 0.17469555139541626, train/logprobs = tensor([[-0.9630, -6.9977],
        [-3.1156, -1.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4618802070617676
Epoch 0, Step 1637: train/loss = 0.32210221886634827, train/raw-loss = 0.28628629446029663, train/logprobs = tensor([[-1.3874, -7.9793],
        [-4.3034, -3.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581594228744507
Epoch 0, Step 1638: train/loss = 0.23398596048355103, train/raw-loss = 0.1985996663570404, train/logprobs = tensor([[-1.3411, -7.5333],
        [-3.8735, -3.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35386306047439575
Epoch 0, Step 1639: train/loss = 0.44424283504486084, train/raw-loss = 0.4150004982948303, train/logprobs = tensor([[-1.7474, -8.0698],
        [-2.0709, -1.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2924236059188843
Epoch 0, Step 1640: train/loss = 0.23035013675689697, train/raw-loss = 0.19429272413253784, train/logprobs = tensor([[-1.1144, -8.6080],
        [-2.9204, -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36057421565055847
Epoch 0, Step 1641: train/loss = 0.24815592169761658, train/raw-loss = 0.21956847608089447, train/logprobs = tensor([[-0.6054, -6.9529],
        [-3.0714, -2.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28587448596954346
Epoch 0, Step 1642: train/loss = 0.19530542194843292, train/raw-loss = 0.15685689449310303, train/logprobs = tensor([[-1.0235, -7.6365],
        [-4.3029, -4.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844851851463318
Epoch 0, Step 1643: train/loss = 0.318933367729187, train/raw-loss = 0.2905321717262268, train/logprobs = tensor([[-1.8993, -8.7124],
        [-4.0373, -2.3936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840119004249573
Epoch 0, Step 1644: train/loss = 0.37141430377960205, train/raw-loss = 0.33350813388824463, train/logprobs = tensor([[-1.8173, -6.1400],
        [-3.6780, -2.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37906160950660706
Epoch 0, Step 1645: train/loss = 0.14116214215755463, train/raw-loss = 0.10783980786800385, train/logprobs = tensor([[ -1.2990, -12.9247],
        [ -3.6373,  -1.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33322322368621826
Epoch 0, Step 1646: train/loss = 0.5307746529579163, train/raw-loss = 0.4933316707611084, train/logprobs = tensor([[-1.6329, -3.4217],
        [-2.5353, -1.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37442976236343384
Epoch 0, Step 1647: train/loss = 0.2646392583847046, train/raw-loss = 0.23219667375087738, train/logprobs = tensor([[-0.9869, -3.6001],
        [-2.7562, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244258463382721
Epoch 0, Step 1648: train/loss = 0.30306389927864075, train/raw-loss = 0.26611965894699097, train/logprobs = tensor([[-1.0004, -3.3393],
        [-2.9646, -1.3629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3694421648979187
Epoch 0, Step 1649: train/loss = 0.2966291010379791, train/raw-loss = 0.2571844160556793, train/logprobs = tensor([[-0.9568, -7.7727],
        [-3.2277, -2.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3944469094276428
Epoch 0, Step 1650: train/loss = 0.3584458529949188, train/raw-loss = 0.32490676641464233, train/logprobs = tensor([[-1.1143, -5.8121],
        [-2.7961, -2.3435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33539095520973206
Epoch 0, Step 1651: train/loss = 0.1700100153684616, train/raw-loss = 0.1352684199810028, train/logprobs = tensor([[-0.8686, -5.9708],
        [-3.1939, -1.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474158048629761
Epoch 0, Step 1652: train/loss = 0.5534424185752869, train/raw-loss = 0.5171054005622864, train/logprobs = tensor([[-0.7600, -3.7630],
        [-2.4833, -2.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363370418548584
Epoch 0, Step 1653: train/loss = 0.25301405787467957, train/raw-loss = 0.2121932953596115, train/logprobs = tensor([[-0.9908, -5.6604],
        [-3.0979, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4082077145576477
Epoch 0, Step 1654: train/loss = 0.31218647956848145, train/raw-loss = 0.2756527066230774, train/logprobs = tensor([[-1.7027, -8.1916],
        [-3.0276, -2.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3653377592563629
Epoch 0, Step 1655: train/loss = 0.2255178838968277, train/raw-loss = 0.18316355347633362, train/logprobs = tensor([[-0.8235, -8.8816],
        [-3.1694, -2.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42354321479797363
Epoch 0, Step 1656: train/loss = 0.17346984148025513, train/raw-loss = 0.13289351761341095, train/logprobs = tensor([[-0.8834, -4.7915],
        [-4.2048, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4057632088661194
Epoch 0, Step 1657: train/loss = 0.41765648126602173, train/raw-loss = 0.3738862872123718, train/logprobs = tensor([[-1.3379, -3.4268],
        [-4.0850, -2.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43770214915275574
Epoch 0, Step 1658: train/loss = 0.5221769213676453, train/raw-loss = 0.4887109696865082, train/logprobs = tensor([[-1.1379, -3.7443],
        [-3.3524, -3.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346594572067261
Epoch 0, Step 1659: train/loss = 0.20471985638141632, train/raw-loss = 0.1615167260169983, train/logprobs = tensor([[-1.5764, -4.6747],
        [-4.7673, -2.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43203145265579224
Epoch 0, Step 1660: train/loss = 0.16880559921264648, train/raw-loss = 0.1374429315328598, train/logprobs = tensor([[-1.5786, -7.9955],
        [-3.5269, -1.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3136267066001892
Epoch 0, Step 1661: train/loss = 0.6847876310348511, train/raw-loss = 0.6500575542449951, train/logprobs = tensor([[-1.4759, -2.4272],
        [-2.4338, -2.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.347300261259079
Epoch 0, Step 1662: train/loss = 0.1867973804473877, train/raw-loss = 0.15148523449897766, train/logprobs = tensor([[-1.3462, -8.2553],
        [-4.1268, -2.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3531213402748108
Epoch 0, Step 1663: train/loss = 0.25291258096694946, train/raw-loss = 0.22124892473220825, train/logprobs = tensor([[-1.7654, -3.8973],
        [-4.0418, -1.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31663671135902405
Epoch 0, Step 1664: train/loss = 0.3085198402404785, train/raw-loss = 0.2650221884250641, train/logprobs = tensor([[-1.2847, -3.1902],
        [-3.6848, -1.7753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4349764287471771
Epoch 0, Step 1665: train/loss = 0.2565220892429352, train/raw-loss = 0.22061149775981903, train/logprobs = tensor([[-2.0847, -5.7904],
        [-4.0792, -2.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35910579562187195
Epoch 0, Step 1666: train/loss = 0.35191142559051514, train/raw-loss = 0.32362061738967896, train/logprobs = tensor([[-1.4321, -4.4176],
        [-2.9538, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28290843963623047
Epoch 0, Step 1667: train/loss = 0.16269105672836304, train/raw-loss = 0.13225267827510834, train/logprobs = tensor([[-0.9058, -7.6503],
        [-2.9930, -1.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30438387393951416
Epoch 0, Step 1668: train/loss = 0.48197948932647705, train/raw-loss = 0.4583916664123535, train/logprobs = tensor([[-1.1069, -4.2321],
        [-1.1959, -1.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23587848246097565
Epoch 0, Step 1669: train/loss = 0.10718145221471786, train/raw-loss = 0.07015270739793777, train/logprobs = tensor([[-1.1342, -8.1228],
        [-3.8915, -2.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37028738856315613
Epoch 0, Step 1670: train/loss = 0.06301625818014145, train/raw-loss = 0.030668480321764946, train/logprobs = tensor([[-1.2146, -9.3089],
        [-4.8609, -1.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32347777485847473
Epoch 0, Step 1671: train/loss = 0.2782467305660248, train/raw-loss = 0.2491578459739685, train/logprobs = tensor([[-2.4149, -5.7219],
        [-3.7918, -2.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29088863730430603
Epoch 0, Step 1672: train/loss = 0.3436093032360077, train/raw-loss = 0.3094080984592438, train/logprobs = tensor([[-1.6340, -4.7759],
        [-3.2553, -1.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3420120179653168
Epoch 0, Step 1673: train/loss = 0.27746817469596863, train/raw-loss = 0.23941582441329956, train/logprobs = tensor([[-1.2691, -4.6227],
        [-2.8992, -1.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3805236518383026
