{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 18:39:31,209][root][INFO] - beta: 1.0
[2024-03-12 18:39:31,209][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-both/checkpoint-296/', 'cache_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-both/checkpoint-296/'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Epoch 0, Step 0: train/loss = 0.6906275749206543, train/raw-loss = 0.6906275749206543, train/logprobs = tensor([[-0.1049, -0.1331],
        [-0.1084, -0.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6912062168121338, train/raw-loss = 0.6912062168121338, train/logprobs = tensor([[-0.0788, -0.0940],
        [-0.0814, -0.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.689285159111023, train/raw-loss = 0.689285159111023, train/logprobs = tensor([[-0.0779, -0.1086],
        [-0.0825, -0.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.694538414478302, train/raw-loss = 0.694538414478302, train/logprobs = tensor([[-0.1757, -0.1054],
        [-0.1697, -0.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6935521364212036, train/raw-loss = 0.6935521364212036, train/logprobs = tensor([[-0.0945, -0.0362],
        [-0.0959, -0.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.691057562828064, train/raw-loss = 0.691057562828064, train/logprobs = tensor([[-0.0548, -0.1075],
        [-0.0576, -0.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6930809020996094, train/raw-loss = 0.6930809020996094, train/logprobs = tensor([[-0.0707, -0.0980],
        [-0.0729, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6906139850616455, train/raw-loss = 0.6906139850616455, train/logprobs = tensor([[-0.0788, -0.0582],
        [-0.0876, -0.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6817048788070679, train/raw-loss = 0.6817048788070679, train/logprobs = tensor([[-0.0937, -0.2764],
        [-0.0996, -0.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6899797916412354, train/raw-loss = 0.6899797916412354, train/logprobs = tensor([[-0.1041, -0.1174],
        [-0.1094, -0.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6957104206085205, train/raw-loss = 0.6957104206085205, train/logprobs = tensor([[-0.0770, -0.2344],
        [-0.0718, -0.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6825586557388306, train/raw-loss = 0.6825586557388306, train/logprobs = tensor([[-0.0754, -0.2170],
        [-0.0744, -0.1722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6793380975723267, train/raw-loss = 0.6793380975723267, train/logprobs = tensor([[-0.1402, -0.3160],
        [-0.1463, -0.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6908765435218811, train/raw-loss = 0.6908765435218811, train/logprobs = tensor([[-0.0414, -0.0619],
        [-0.0434, -0.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6913654208183289, train/raw-loss = 0.6913654208183289, train/logprobs = tensor([[-0.0684, -0.0806],
        [-0.0719, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6903812289237976, train/raw-loss = 0.6903812289237976, train/logprobs = tensor([[-0.0400, -0.0625],
        [-0.0493, -0.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6910890936851501, train/raw-loss = 0.6910890936851501, train/logprobs = tensor([[-0.0933, -0.0939],
        [-0.0960, -0.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6903483867645264, train/raw-loss = 0.6903483867645264, train/logprobs = tensor([[-0.1814, -0.1121],
        [-0.1771, -0.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6910480260848999, train/raw-loss = 0.6910480260848999, train/logprobs = tensor([[-0.1146, -0.0814],
        [-0.1151, -0.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6924335956573486, train/raw-loss = 0.6924335956573486, train/logprobs = tensor([[-0.0704, -0.0451],
        [-0.0715, -0.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6969028115272522, train/raw-loss = 0.6969028115272522, train/logprobs = tensor([[-0.2700, -0.0442],
        [-0.2647, -0.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6933315396308899, train/raw-loss = 0.6933315396308899, train/logprobs = tensor([[-0.3072, -0.0487],
        [-0.2929, -0.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6917641162872314, train/raw-loss = 0.6917641162872314, train/logprobs = tensor([[-0.2080, -0.1371],
        [-0.2091, -0.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6919781565666199, train/raw-loss = 0.6919781565666199, train/logprobs = tensor([[-0.0618, -0.0790],
        [-0.0636, -0.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6923743486404419, train/raw-loss = 0.6923743486404419, train/logprobs = tensor([[-0.0949, -0.0598],
        [-0.0946, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6914557218551636, train/raw-loss = 0.6914557218551636, train/logprobs = tensor([[-0.1477, -0.0539],
        [-0.1528, -0.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.691846489906311, train/raw-loss = 0.691846489906311, train/logprobs = tensor([[-0.0906, -0.1216],
        [-0.0888, -0.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6858680248260498, train/raw-loss = 0.6858680248260498, train/logprobs = tensor([[-0.1228, -0.2207],
        [-0.1330, -0.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6910855770111084, train/raw-loss = 0.6910855770111084, train/logprobs = tensor([[-0.0929, -0.0822],
        [-0.0959, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6926475763320923, train/raw-loss = 0.6926475763320923, train/logprobs = tensor([[-0.0560, -0.0857],
        [-0.0532, -0.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6819225549697876, train/raw-loss = 0.6819225549697876, train/logprobs = tensor([[-0.0816, -0.1786],
        [-0.0902, -0.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.693026065826416, train/raw-loss = 0.693026065826416, train/logprobs = tensor([[-0.0858, -0.1226],
        [-0.0887, -0.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6950878500938416, train/raw-loss = 0.6950878500938416, train/logprobs = tensor([[-0.0495, -0.0918],
        [-0.0523, -0.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6929644346237183, train/raw-loss = 0.6929644346237183, train/logprobs = tensor([[-0.1489, -0.1187],
        [-0.1495, -0.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6883277297019958, train/raw-loss = 0.6883277297019958, train/logprobs = tensor([[-0.1693, -0.1706],
        [-0.1681, -0.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6898608803749084, train/raw-loss = 0.6898608803749084, train/logprobs = tensor([[-0.1098, -0.1552],
        [-0.1093, -0.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6912087798118591, train/raw-loss = 0.6912087798118591, train/logprobs = tensor([[-0.1697, -0.1007],
        [-0.1723, -0.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.679940938949585, train/raw-loss = 0.679940938949585, train/logprobs = tensor([[-0.1011, -0.2688],
        [-0.1285, -0.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.693029522895813, train/raw-loss = 0.693029522895813, train/logprobs = tensor([[-0.0760, -0.0955],
        [-0.0828, -0.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6923582553863525, train/raw-loss = 0.6923582553863525, train/logprobs = tensor([[-0.0658, -0.0778],
        [-0.0629, -0.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6923428773880005, train/raw-loss = 0.6923428773880005, train/logprobs = tensor([[-0.1138, -0.0644],
        [-0.1156, -0.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6896645426750183, train/raw-loss = 0.6896645426750183, train/logprobs = tensor([[-0.1252, -0.0888],
        [-0.1294, -0.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6866625547409058, train/raw-loss = 0.6866625547409058, train/logprobs = tensor([[-0.1639, -0.0512],
        [-0.1808, -0.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6731882095336914, train/raw-loss = 0.6731882095336914, train/logprobs = tensor([[-0.1106, -0.3254],
        [-0.1210, -0.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6949629187583923, train/raw-loss = 0.6949629187583923, train/logprobs = tensor([[-0.0734, -0.0732],
        [-0.0625, -0.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6925082206726074, train/raw-loss = 0.6925082206726074, train/logprobs = tensor([[-0.3388, -0.0954],
        [-0.3352, -0.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.690887451171875, train/raw-loss = 0.690887451171875, train/logprobs = tensor([[-0.1615, -0.0628],
        [-0.1635, -0.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6928563117980957, train/raw-loss = 0.6928563117980957, train/logprobs = tensor([[-0.1676, -0.0415],
        [-0.1672, -0.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6973150372505188, train/raw-loss = 0.6973150372505188, train/logprobs = tensor([[-0.1033, -0.1012],
        [-0.1002, -0.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6926056742668152, train/raw-loss = 0.6926056742668152, train/logprobs = tensor([[-0.0826, -0.1529],
        [-0.0876, -0.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6892089247703552, train/raw-loss = 0.6892089247703552, train/logprobs = tensor([[-0.0961, -0.1502],
        [-0.0992, -0.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6937375664710999, train/raw-loss = 0.6937375664710999, train/logprobs = tensor([[-0.1026, -0.0654],
        [-0.1009, -0.0660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6936778426170349, train/raw-loss = 0.6936778426170349, train/logprobs = tensor([[-0.0961, -0.1142],
        [-0.0924, -0.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6918796300888062, train/raw-loss = 0.6918796300888062, train/logprobs = tensor([[-0.0907, -0.0358],
        [-0.0969, -0.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.692629873752594, train/raw-loss = 0.692629873752594, train/logprobs = tensor([[-0.0862, -0.1409],
        [-0.0833, -0.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6918533444404602, train/raw-loss = 0.6918533444404602, train/logprobs = tensor([[-0.0706, -0.0409],
        [-0.0758, -0.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6954129934310913, train/raw-loss = 0.6954129934310913, train/logprobs = tensor([[-0.0992, -0.1275],
        [-0.1073, -0.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.684982419013977, train/raw-loss = 0.684982419013977, train/logprobs = tensor([[-0.0822, -0.1388],
        [-0.0847, -0.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6874104738235474, train/raw-loss = 0.6874104738235474, train/logprobs = tensor([[-0.0906, -0.0919],
        [-0.0920, -0.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.691057562828064, train/raw-loss = 0.691057562828064, train/logprobs = tensor([[-0.0527, -0.0992],
        [-0.0555, -0.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6904677748680115, train/raw-loss = 0.6904677748680115, train/logprobs = tensor([[-0.0614, -0.1197],
        [-0.0619, -0.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6943770051002502, train/raw-loss = 0.6943770051002502, train/logprobs = tensor([[-0.1069, -0.0795],
        [-0.1024, -0.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6756585240364075, train/raw-loss = 0.6756585240364075, train/logprobs = tensor([[-0.0788, -0.2881],
        [-0.0771, -0.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6931130290031433, train/raw-loss = 0.6931130290031433, train/logprobs = tensor([[-0.1236, -0.0731],
        [-0.1255, -0.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.692533552646637, train/raw-loss = 0.6919451951980591, train/logprobs = tensor([[-0.0802, -0.1949],
        [-0.0805, -0.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005883239209651947
Epoch 0, Step 65: train/loss = 0.6575896739959717, train/raw-loss = 0.6569080948829651, train/logprobs = tensor([[-0.1252, -0.3851],
        [-0.1247, -0.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006815865635871887
Epoch 0, Step 66: train/loss = 0.6922500729560852, train/raw-loss = 0.6917062997817993, train/logprobs = tensor([[-0.0496, -0.0801],
        [-0.0502, -0.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005437659565359354
Epoch 0, Step 67: train/loss = 0.6903775334358215, train/raw-loss = 0.6897441744804382, train/logprobs = tensor([[-0.0881, -0.0870],
        [-0.0907, -0.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006333582568913698
Epoch 0, Step 68: train/loss = 0.6907352209091187, train/raw-loss = 0.690088152885437, train/logprobs = tensor([[-0.0768, -0.1084],
        [-0.0832, -0.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006470305961556733
Epoch 0, Step 69: train/loss = 0.6915425062179565, train/raw-loss = 0.6908974647521973, train/logprobs = tensor([[-0.0882, -0.0580],
        [-0.0925, -0.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006450130604207516
Epoch 0, Step 70: train/loss = 0.6908620595932007, train/raw-loss = 0.690156102180481, train/logprobs = tensor([[-0.0641, -0.1702],
        [-0.0663, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007059295894578099
Epoch 0, Step 71: train/loss = 0.6921127438545227, train/raw-loss = 0.6913999915122986, train/logprobs = tensor([[-0.1375, -0.0826],
        [-0.1416, -0.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007127512944862247
Epoch 0, Step 72: train/loss = 0.6897604465484619, train/raw-loss = 0.689134418964386, train/logprobs = tensor([[-0.1028, -0.1156],
        [-0.1032, -0.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006260740337893367
Epoch 0, Step 73: train/loss = 0.6940164566040039, train/raw-loss = 0.6933958530426025, train/logprobs = tensor([[-0.0775, -0.0750],
        [-0.0723, -0.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006206295220181346
Epoch 0, Step 74: train/loss = 0.6899714469909668, train/raw-loss = 0.6893863677978516, train/logprobs = tensor([[-0.0905, -0.1041],
        [-0.0959, -0.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005850295419804752
Epoch 0, Step 75: train/loss = 0.6912798881530762, train/raw-loss = 0.6906335353851318, train/logprobs = tensor([[-0.1950, -0.0696],
        [-0.2032, -0.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006463098106905818
Epoch 0, Step 76: train/loss = 0.6703238487243652, train/raw-loss = 0.6697500944137573, train/logprobs = tensor([[-0.0529, -0.2456],
        [-0.0519, -0.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005737100727856159
Epoch 0, Step 77: train/loss = 0.6916836500167847, train/raw-loss = 0.6910430788993835, train/logprobs = tensor([[-0.1170, -0.0828],
        [-0.1236, -0.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405629683285952
Epoch 0, Step 78: train/loss = 0.6907507181167603, train/raw-loss = 0.6902254819869995, train/logprobs = tensor([[-0.0722, -0.1308],
        [-0.0724, -0.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005252741975709796
Epoch 0, Step 79: train/loss = 0.675168514251709, train/raw-loss = 0.6745582222938538, train/logprobs = tensor([[-0.0770, -0.2482],
        [-0.0817, -0.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006103232735767961
Epoch 0, Step 80: train/loss = 0.6921684741973877, train/raw-loss = 0.6915329098701477, train/logprobs = tensor([[-0.1026, -0.0316],
        [-0.1017, -0.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006356158992275596
Epoch 0, Step 81: train/loss = 0.6877351999282837, train/raw-loss = 0.6871361136436462, train/logprobs = tensor([[-0.1211, -0.1657],
        [-0.1226, -0.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005990065401419997
Epoch 0, Step 82: train/loss = 0.689528226852417, train/raw-loss = 0.6889997124671936, train/logprobs = tensor([[-0.1206, -0.2333],
        [-0.1133, -0.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000528465723618865
Epoch 0, Step 83: train/loss = 0.6940674781799316, train/raw-loss = 0.6935333013534546, train/logprobs = tensor([[-0.0865, -0.1380],
        [-0.0838, -0.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005342393415048718
Epoch 0, Step 84: train/loss = 0.6862318515777588, train/raw-loss = 0.685613751411438, train/logprobs = tensor([[-0.0649, -0.0608],
        [-0.0769, -0.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006180249620229006
Epoch 0, Step 85: train/loss = 0.6874402761459351, train/raw-loss = 0.6867677569389343, train/logprobs = tensor([[-0.0703, -0.1342],
        [-0.0796, -0.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006725186249241233
Epoch 0, Step 86: train/loss = 0.6912344098091125, train/raw-loss = 0.6906501650810242, train/logprobs = tensor([[-0.0852, -0.0890],
        [-0.0837, -0.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005843036924488842
Epoch 0, Step 87: train/loss = 0.6899940371513367, train/raw-loss = 0.6893492937088013, train/logprobs = tensor([[-0.1138, -0.1444],
        [-0.1184, -0.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006447756313718855
Epoch 0, Step 88: train/loss = 0.6740212440490723, train/raw-loss = 0.6734548807144165, train/logprobs = tensor([[-0.0896, -0.2430],
        [-0.1030, -0.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005663955816999078
Epoch 0, Step 89: train/loss = 0.6903659701347351, train/raw-loss = 0.6897249817848206, train/logprobs = tensor([[-0.0874, -0.1113],
        [-0.0897, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006409119814634323
Epoch 0, Step 90: train/loss = 0.691120445728302, train/raw-loss = 0.6904714107513428, train/logprobs = tensor([[-0.0350, -0.1234],
        [-0.0363, -0.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006490874802693725
Epoch 0, Step 91: train/loss = 0.6915087699890137, train/raw-loss = 0.6907855272293091, train/logprobs = tensor([[-0.1074, -0.1933],
        [-0.1012, -0.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00072317267768085
Epoch 0, Step 92: train/loss = 0.6902852058410645, train/raw-loss = 0.6896255612373352, train/logprobs = tensor([[-0.1185, -0.1161],
        [-0.1223, -0.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006596696330234408
Epoch 0, Step 93: train/loss = 0.6803017258644104, train/raw-loss = 0.6796457767486572, train/logprobs = tensor([[-0.0567, -0.2216],
        [-0.0668, -0.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006559346220456064
Epoch 0, Step 94: train/loss = 0.6895900368690491, train/raw-loss = 0.6889292001724243, train/logprobs = tensor([[-0.2505, -0.1617],
        [-0.2548, -0.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006607716786675155
Epoch 0, Step 95: train/loss = 0.6940301060676575, train/raw-loss = 0.693476140499115, train/logprobs = tensor([[-0.0688, -0.0593],
        [-0.0652, -0.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005539772682823241
Epoch 0, Step 96: train/loss = 0.7010075449943542, train/raw-loss = 0.6938573122024536, train/logprobs = tensor([[-0.1172, -0.0948],
        [-0.1147, -0.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007150289602577686
Epoch 0, Step 97: train/loss = 0.6924108266830444, train/raw-loss = 0.6863982677459717, train/logprobs = tensor([[-0.0430, -0.1122],
        [-0.0473, -0.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060126218013465405
Epoch 0, Step 98: train/loss = 0.7022326588630676, train/raw-loss = 0.6926226615905762, train/logprobs = tensor([[-0.1314, -0.0576],
        [-0.1364, -0.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009609995409846306
Epoch 0, Step 99: train/loss = 0.7012999057769775, train/raw-loss = 0.6915931701660156, train/logprobs = tensor([[-0.1349, -0.0850],
        [-0.1305, -0.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009706725366413593
Epoch 0, Step 100: train/loss = 0.6866930723190308, train/raw-loss = 0.6770707368850708, train/logprobs = tensor([[-0.0584, -0.1110],
        [-0.0713, -0.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009622383862733841
Epoch 0, Step 101: train/loss = 0.6935884952545166, train/raw-loss = 0.6882867217063904, train/logprobs = tensor([[-0.0895, -0.1616],
        [-0.0970, -0.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005301774945110083
Epoch 0, Step 102: train/loss = 0.6988521814346313, train/raw-loss = 0.6912610530853271, train/logprobs = tensor([[-0.0395, -0.0547],
        [-0.0403, -0.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00759112136438489
Epoch 0, Step 103: train/loss = 0.6971176266670227, train/raw-loss = 0.6897392272949219, train/logprobs = tensor([[-0.1006, -0.0515],
        [-0.1037, -0.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007378346752375364
Epoch 0, Step 104: train/loss = 0.682257890701294, train/raw-loss = 0.6737287044525146, train/logprobs = tensor([[-0.2147, -0.2101],
        [-0.2324, -0.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008529184386134148
Epoch 0, Step 105: train/loss = 0.6976781487464905, train/raw-loss = 0.6885185241699219, train/logprobs = tensor([[-0.0548, -0.1479],
        [-0.0533, -0.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009159655310213566
Epoch 0, Step 106: train/loss = 0.6721128821372986, train/raw-loss = 0.6633027195930481, train/logprobs = tensor([[-0.0977, -0.4624],
        [-0.1138, -0.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008810171857476234
Epoch 0, Step 107: train/loss = 0.693164587020874, train/raw-loss = 0.6853485107421875, train/logprobs = tensor([[-0.0923, -0.1496],
        [-0.0990, -0.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007816026918590069
Epoch 0, Step 108: train/loss = 0.6984689831733704, train/raw-loss = 0.6914716362953186, train/logprobs = tensor([[-0.0639, -0.0630],
        [-0.0648, -0.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0069973343051970005
Epoch 0, Step 109: train/loss = 0.700059175491333, train/raw-loss = 0.6923285722732544, train/logprobs = tensor([[-0.1148, -0.0934],
        [-0.1275, -0.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007730599492788315
Epoch 0, Step 110: train/loss = 0.6706602573394775, train/raw-loss = 0.6629658341407776, train/logprobs = tensor([[-0.1179, -0.2485],
        [-0.1256, -0.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007694477215409279
Epoch 0, Step 111: train/loss = 0.6980581879615784, train/raw-loss = 0.6906751990318298, train/logprobs = tensor([[-0.0694, -0.0846],
        [-0.0694, -0.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073830243200063705
Epoch 0, Step 112: train/loss = 0.7068431377410889, train/raw-loss = 0.6961851716041565, train/logprobs = tensor([[-0.0515, -0.0819],
        [-0.0543, -0.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01065790094435215
Epoch 0, Step 113: train/loss = 0.6956291198730469, train/raw-loss = 0.6873157024383545, train/logprobs = tensor([[-0.1034, -0.1150],
        [-0.1055, -0.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008313441649079323
Epoch 0, Step 114: train/loss = 0.697032630443573, train/raw-loss = 0.6906012892723083, train/logprobs = tensor([[-0.1249, -0.0578],
        [-0.1336, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006431335583329201
Epoch 0, Step 115: train/loss = 0.6987172365188599, train/raw-loss = 0.6875969767570496, train/logprobs = tensor([[-0.1376, -0.0759],
        [-0.1429, -0.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011120254173874855
Epoch 0, Step 116: train/loss = 0.6942490339279175, train/raw-loss = 0.6881260871887207, train/logprobs = tensor([[-0.0994, -0.1830],
        [-0.0978, -0.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006122974678874016
Epoch 0, Step 117: train/loss = 0.6996302008628845, train/raw-loss = 0.6900413036346436, train/logprobs = tensor([[-0.0686, -0.0695],
        [-0.0770, -0.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009588929824531078
Epoch 0, Step 118: train/loss = 0.6996650695800781, train/raw-loss = 0.688248872756958, train/logprobs = tensor([[-0.0909, -0.0675],
        [-0.0974, -0.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011416209861636162
Epoch 0, Step 119: train/loss = 0.7005141377449036, train/raw-loss = 0.6910983920097351, train/logprobs = tensor([[-0.0624, -0.0939],
        [-0.0675, -0.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009415755979716778
Epoch 0, Step 120: train/loss = 0.7022147178649902, train/raw-loss = 0.6928786039352417, train/logprobs = tensor([[-0.0862, -0.0920],
        [-0.0903, -0.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009336069226264954
Epoch 0, Step 121: train/loss = 0.6898189783096313, train/raw-loss = 0.6829937696456909, train/logprobs = tensor([[-0.0954, -0.1385],
        [-0.0976, -0.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006825202144682407
Epoch 0, Step 122: train/loss = 0.6754169464111328, train/raw-loss = 0.6680656671524048, train/logprobs = tensor([[-0.2064, -0.1129],
        [-0.2881, -0.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007351346779614687
Epoch 0, Step 123: train/loss = 0.6978164315223694, train/raw-loss = 0.691106379032135, train/logprobs = tensor([[-0.0544, -0.0638],
        [-0.0551, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006710045970976353
Epoch 0, Step 124: train/loss = 0.6972208023071289, train/raw-loss = 0.6917261481285095, train/logprobs = tensor([[-0.0789, -0.1081],
        [-0.0796, -0.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005494636483490467
Epoch 0, Step 125: train/loss = 0.6933596134185791, train/raw-loss = 0.6866258382797241, train/logprobs = tensor([[-0.1290, -0.2056],
        [-0.1341, -0.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006733776535838842
Epoch 0, Step 126: train/loss = 0.6964836120605469, train/raw-loss = 0.6900075674057007, train/logprobs = tensor([[-0.0528, -0.1482],
        [-0.0612, -0.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064760372042655945
Epoch 0, Step 127: train/loss = 0.6972440481185913, train/raw-loss = 0.6892588138580322, train/logprobs = tensor([[-0.1710, -0.1058],
        [-0.1756, -0.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007985291071236134
Epoch 0, Step 128: train/loss = 0.787605345249176, train/raw-loss = 0.690864086151123, train/logprobs = tensor([[-0.0557, -0.0612],
        [-0.0600, -0.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09674125909805298
Epoch 0, Step 129: train/loss = 0.9497076272964478, train/raw-loss = 0.6865311861038208, train/logprobs = tensor([[-0.0839, -0.1243],
        [-0.0899, -0.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26317644119262695
Epoch 0, Step 130: train/loss = 1.1139318943023682, train/raw-loss = 0.6915526390075684, train/logprobs = tensor([[-0.0847, -0.0589],
        [-0.0896, -0.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42237919569015503
Epoch 0, Step 131: train/loss = 1.0140182971954346, train/raw-loss = 0.6624844074249268, train/logprobs = tensor([[-0.1770, -0.2517],
        [-0.1978, -0.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351533979177475
Epoch 0, Step 132: train/loss = 0.8809372186660767, train/raw-loss = 0.6673175692558289, train/logprobs = tensor([[-0.1079, -0.4146],
        [-0.1130, -0.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21361960470676422
Epoch 0, Step 133: train/loss = 0.9824994802474976, train/raw-loss = 0.6921594142913818, train/logprobs = tensor([[-0.0523, -0.1160],
        [-0.0516, -0.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29034003615379333
Epoch 0, Step 134: train/loss = 1.1133695840835571, train/raw-loss = 0.6873100399971008, train/logprobs = tensor([[-0.0793, -0.0955],
        [-0.0784, -0.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4260596036911011
Epoch 0, Step 135: train/loss = 1.2429873943328857, train/raw-loss = 0.6950982809066772, train/logprobs = tensor([[-0.0536, -0.1132],
        [-0.0547, -0.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5478891730308533
Epoch 0, Step 136: train/loss = 1.2873520851135254, train/raw-loss = 0.6760857105255127, train/logprobs = tensor([[-0.0569, -0.2205],
        [-0.0671, -0.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6112663745880127
Epoch 0, Step 137: train/loss = 1.132623553276062, train/raw-loss = 0.6893314719200134, train/logprobs = tensor([[-0.1034, -0.1108],
        [-0.1070, -0.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44329214096069336
Epoch 0, Step 138: train/loss = 1.1012790203094482, train/raw-loss = 0.6864480972290039, train/logprobs = tensor([[-0.0644, -0.0976],
        [-0.0709, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4148309826850891
Epoch 0, Step 139: train/loss = 0.962364912033081, train/raw-loss = 0.6742243766784668, train/logprobs = tensor([[-0.0774, -0.3360],
        [-0.0835, -0.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28814050555229187
Epoch 0, Step 140: train/loss = 0.8775067329406738, train/raw-loss = 0.6848964691162109, train/logprobs = tensor([[-0.0360, -0.1975],
        [-0.0425, -0.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926102340221405
Epoch 0, Step 141: train/loss = 0.8660060167312622, train/raw-loss = 0.6880874037742615, train/logprobs = tensor([[-0.0828, -0.1200],
        [-0.0895, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17791862785816193
Epoch 0, Step 142: train/loss = 0.9638024568557739, train/raw-loss = 0.6896594762802124, train/logprobs = tensor([[-0.0949, -0.1022],
        [-0.0961, -0.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27414295077323914
Epoch 0, Step 143: train/loss = 1.1247553825378418, train/raw-loss = 0.6961508989334106, train/logprobs = tensor([[-0.1013, -0.1003],
        [-0.1038, -0.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4286044239997864
Epoch 0, Step 144: train/loss = 1.0347890853881836, train/raw-loss = 0.6752323508262634, train/logprobs = tensor([[-0.0988, -0.2069],
        [-0.1051, -0.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35955679416656494
Epoch 0, Step 145: train/loss = 1.058329701423645, train/raw-loss = 0.6912955045700073, train/logprobs = tensor([[-0.0892, -0.0329],
        [-0.0930, -0.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36703410744667053
Epoch 0, Step 146: train/loss = 0.8616405725479126, train/raw-loss = 0.6766502857208252, train/logprobs = tensor([[-0.0485, -0.1565],
        [-0.0526, -0.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1849902868270874
Epoch 0, Step 147: train/loss = 1.1546167135238647, train/raw-loss = 0.688737690448761, train/logprobs = tensor([[-0.0889, -0.0740],
        [-0.0974, -0.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4658791124820709
Epoch 0, Step 148: train/loss = 0.8153725266456604, train/raw-loss = 0.6886678338050842, train/logprobs = tensor([[-0.1587, -0.1173],
        [-0.1675, -0.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12670475244522095
Epoch 0, Step 149: train/loss = 0.8062106966972351, train/raw-loss = 0.6871055960655212, train/logprobs = tensor([[-0.0619, -0.0683],
        [-0.0693, -0.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11910512298345566
Epoch 0, Step 150: train/loss = 0.8146765232086182, train/raw-loss = 0.6721314191818237, train/logprobs = tensor([[-0.0918, -0.1532],
        [-0.0988, -0.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14254510402679443
Epoch 0, Step 151: train/loss = 0.8967114090919495, train/raw-loss = 0.6867403984069824, train/logprobs = tensor([[-0.0546, -0.1295],
        [-0.0590, -0.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20997101068496704
Epoch 0, Step 152: train/loss = 0.8806570172309875, train/raw-loss = 0.6904215812683105, train/logprobs = tensor([[-0.1013, -0.0934],
        [-0.1038, -0.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190235435962677
Epoch 0, Step 153: train/loss = 1.0721617937088013, train/raw-loss = 0.6783086657524109, train/logprobs = tensor([[-0.0790, -0.1495],
        [-0.0860, -0.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3938531279563904
Epoch 0, Step 154: train/loss = 0.9417614340782166, train/raw-loss = 0.6930503249168396, train/logprobs = tensor([[-0.0865, -0.1061],
        [-0.0899, -0.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24871109426021576
Epoch 0, Step 155: train/loss = 0.9388036727905273, train/raw-loss = 0.6878305673599243, train/logprobs = tensor([[-0.1138, -0.0766],
        [-0.1172, -0.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250973105430603
Epoch 0, Step 156: train/loss = 0.8621808290481567, train/raw-loss = 0.6884081363677979, train/logprobs = tensor([[-0.0696, -0.1168],
        [-0.0714, -0.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17377275228500366
Epoch 0, Step 157: train/loss = 0.7233001589775085, train/raw-loss = 0.6911842823028564, train/logprobs = tensor([[-0.0715, -0.1397],
        [-0.0730, -0.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321158841252327
Epoch 0, Step 158: train/loss = 0.8561444282531738, train/raw-loss = 0.6890169382095337, train/logprobs = tensor([[-0.0864, -0.1089],
        [-0.0984, -0.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671275794506073
Epoch 0, Step 159: train/loss = 0.8258323669433594, train/raw-loss = 0.6916093230247498, train/logprobs = tensor([[-0.1039, -0.1264],
        [-0.1040, -0.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13422299921512604
Epoch 0, Step 160: train/loss = 0.7866519689559937, train/raw-loss = 0.6870343685150146, train/logprobs = tensor([[-0.1664, -0.1090],
        [-0.1648, -0.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996176153421402
Epoch 0, Step 161: train/loss = 0.7935782670974731, train/raw-loss = 0.6892862319946289, train/logprobs = tensor([[-0.0963, -0.2352],
        [-0.0986, -0.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10429201275110245
Epoch 0, Step 162: train/loss = 0.8300460577011108, train/raw-loss = 0.6546111106872559, train/logprobs = tensor([[-0.0784, -0.4048],
        [-0.0818, -0.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17543496191501617
Epoch 0, Step 163: train/loss = 0.8795323371887207, train/raw-loss = 0.6810337901115417, train/logprobs = tensor([[-0.0544, -0.1368],
        [-0.0596, -0.0929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19849848747253418
Epoch 0, Step 164: train/loss = 0.8472835421562195, train/raw-loss = 0.6740095019340515, train/logprobs = tensor([[-0.1004, -0.2079],
        [-0.1095, -0.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17327408492565155
Epoch 0, Step 165: train/loss = 0.9513243436813354, train/raw-loss = 0.6809848546981812, train/logprobs = tensor([[-0.1166, -0.1021],
        [-0.1345, -0.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703394293785095
Epoch 0, Step 166: train/loss = 1.0102519989013672, train/raw-loss = 0.6371161937713623, train/logprobs = tensor([[-0.1158, -0.4013],
        [-0.1275, -0.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731358051300049
Epoch 0, Step 167: train/loss = 0.8863092660903931, train/raw-loss = 0.686668872833252, train/logprobs = tensor([[-0.0539, -0.1248],
        [-0.0559, -0.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996404081583023
Epoch 0, Step 168: train/loss = 0.8606948852539062, train/raw-loss = 0.6819556951522827, train/logprobs = tensor([[-0.0991, -0.1153],
        [-0.1354, -0.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17873919010162354
Epoch 0, Step 169: train/loss = 0.7837793827056885, train/raw-loss = 0.6889367699623108, train/logprobs = tensor([[-0.1242, -0.0912],
        [-0.1346, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484262764453888
Epoch 0, Step 170: train/loss = 0.9886307120323181, train/raw-loss = 0.6901514530181885, train/logprobs = tensor([[-0.1046, -0.0735],
        [-0.1022, -0.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29847922921180725
Epoch 0, Step 171: train/loss = 0.820117175579071, train/raw-loss = 0.6886789798736572, train/logprobs = tensor([[-0.0864, -0.0696],
        [-0.0969, -0.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13143818080425262
Epoch 0, Step 172: train/loss = 0.962776243686676, train/raw-loss = 0.6780771017074585, train/logprobs = tensor([[-0.0660, -0.1797],
        [-0.0714, -0.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846991717815399
Epoch 0, Step 173: train/loss = 1.035639762878418, train/raw-loss = 0.6655359268188477, train/logprobs = tensor([[-0.2740, -0.2353],
        [-0.2902, -0.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701038360595703
Epoch 0, Step 174: train/loss = 0.8698316812515259, train/raw-loss = 0.6818364858627319, train/logprobs = tensor([[-0.0682, -0.2226],
        [-0.0804, -0.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18799513578414917
Epoch 0, Step 175: train/loss = 1.0721008777618408, train/raw-loss = 0.6639330387115479, train/logprobs = tensor([[-0.0906, -0.2174],
        [-0.1060, -0.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081678092479706
Epoch 0, Step 176: train/loss = 0.8736059665679932, train/raw-loss = 0.6763859987258911, train/logprobs = tensor([[-0.0958, -0.1905],
        [-0.1061, -0.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19721993803977966
Epoch 0, Step 177: train/loss = 0.8669079542160034, train/raw-loss = 0.6795737743377686, train/logprobs = tensor([[-0.0646, -0.2054],
        [-0.0683, -0.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18733417987823486
Epoch 0, Step 178: train/loss = 0.7972373962402344, train/raw-loss = 0.6767755150794983, train/logprobs = tensor([[-0.0799, -0.3575],
        [-0.0903, -0.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12046189606189728
Epoch 0, Step 179: train/loss = 0.9238188862800598, train/raw-loss = 0.6864286661148071, train/logprobs = tensor([[-0.1118, -0.0719],
        [-0.1196, -0.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23739022016525269
Epoch 0, Step 180: train/loss = 0.7523050308227539, train/raw-loss = 0.6906198859214783, train/logprobs = tensor([[-0.1207, -0.1924],
        [-0.1270, -0.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06168515980243683
Epoch 0, Step 181: train/loss = 0.8722714781761169, train/raw-loss = 0.6858773231506348, train/logprobs = tensor([[-0.1337, -0.0833],
        [-0.1377, -0.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863941252231598
Epoch 0, Step 182: train/loss = 0.9210904836654663, train/raw-loss = 0.6925549507141113, train/logprobs = tensor([[-0.0834, -0.0328],
        [-0.0803, -0.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.228535458445549
Epoch 0, Step 183: train/loss = 0.9554580450057983, train/raw-loss = 0.6904430389404297, train/logprobs = tensor([[-0.1005, -0.0511],
        [-0.1075, -0.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26501497626304626
Epoch 0, Step 184: train/loss = 0.9252590537071228, train/raw-loss = 0.6660988926887512, train/logprobs = tensor([[-0.1161, -0.2444],
        [-0.1194, -0.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591601312160492
Epoch 0, Step 185: train/loss = 0.7613793611526489, train/raw-loss = 0.67319655418396, train/logprobs = tensor([[-0.0812, -0.2185],
        [-0.1062, -0.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08818291127681732
Epoch 0, Step 186: train/loss = 0.8280707597732544, train/raw-loss = 0.6878877878189087, train/logprobs = tensor([[-0.0796, -0.1071],
        [-0.0823, -0.0886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14018294215202332
Epoch 0, Step 187: train/loss = 0.9939314723014832, train/raw-loss = 0.6818985939025879, train/logprobs = tensor([[-0.0531, -0.1350],
        [-0.0547, -0.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31203287839889526
Epoch 0, Step 188: train/loss = 0.8642441034317017, train/raw-loss = 0.6627442240715027, train/logprobs = tensor([[-0.0954, -0.5691],
        [-0.1092, -0.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014998197555542
Epoch 0, Step 189: train/loss = 0.7440577745437622, train/raw-loss = 0.6902071237564087, train/logprobs = tensor([[-0.0830, -0.1095],
        [-0.0852, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053850673139095306
Epoch 0, Step 190: train/loss = 0.795671820640564, train/raw-loss = 0.6663179993629456, train/logprobs = tensor([[-0.1110, -0.2431],
        [-0.1213, -0.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293538361787796
Epoch 0, Step 191: train/loss = 0.868948221206665, train/raw-loss = 0.690491259098053, train/logprobs = tensor([[-0.0928, -0.0384],
        [-0.1028, -0.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17845702171325684
Epoch 0, Step 192: train/loss = 0.8291025161743164, train/raw-loss = 0.6856091022491455, train/logprobs = tensor([[-0.1388, -0.0503],
        [-0.1525, -0.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434934437274933
Epoch 0, Step 193: train/loss = 0.8352952599525452, train/raw-loss = 0.6737264394760132, train/logprobs = tensor([[-0.1429, -0.1352],
        [-0.1570, -0.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1615687608718872
Epoch 0, Step 194: train/loss = 0.8149759769439697, train/raw-loss = 0.669701099395752, train/logprobs = tensor([[-0.0795, -0.1468],
        [-0.0935, -0.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14527489244937897
Epoch 0, Step 195: train/loss = 0.8145977258682251, train/raw-loss = 0.6855627298355103, train/logprobs = tensor([[-0.0854, -0.1394],
        [-0.0867, -0.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12903496623039246
Epoch 0, Step 196: train/loss = 0.7960124015808105, train/raw-loss = 0.6804576516151428, train/logprobs = tensor([[-0.1437, -0.1392],
        [-0.1582, -0.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11555475741624832
Epoch 0, Step 197: train/loss = 0.8579359650611877, train/raw-loss = 0.6944056749343872, train/logprobs = tensor([[-0.0893, -0.4257],
        [-0.1007, -0.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16353029012680054
Epoch 0, Step 198: train/loss = 0.8280438184738159, train/raw-loss = 0.68989098072052, train/logprobs = tensor([[-0.1214, -0.1104],
        [-0.1305, -0.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13815288245677948
Epoch 0, Step 199: train/loss = 0.8909881711006165, train/raw-loss = 0.6817386746406555, train/logprobs = tensor([[-0.0332, -0.0922],
        [-0.0422, -0.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20924949645996094
Epoch 0, Step 200: train/loss = 0.7865331172943115, train/raw-loss = 0.669680655002594, train/logprobs = tensor([[-0.1211, -0.1676],
        [-0.1429, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685243248939514
Epoch 0, Step 201: train/loss = 0.7995238304138184, train/raw-loss = 0.6527637243270874, train/logprobs = tensor([[-0.1215, -0.1972],
        [-0.1467, -0.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14676015079021454
Epoch 0, Step 202: train/loss = 0.8068312406539917, train/raw-loss = 0.6878392696380615, train/logprobs = tensor([[-0.1027, -0.1011],
        [-0.1053, -0.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11899203062057495
Epoch 0, Step 203: train/loss = 0.834453821182251, train/raw-loss = 0.6843893527984619, train/logprobs = tensor([[-0.0662, -0.0940],
        [-0.0711, -0.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15006445348262787
Epoch 0, Step 204: train/loss = 0.842858612537384, train/raw-loss = 0.6749482750892639, train/logprobs = tensor([[-0.0963, -0.1716],
        [-0.1407, -0.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1679103821516037
Epoch 0, Step 205: train/loss = 0.8969257473945618, train/raw-loss = 0.6769693493843079, train/logprobs = tensor([[-0.0980, -0.1457],
        [-0.1080, -0.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2199564278125763
Epoch 0, Step 206: train/loss = 0.8439210653305054, train/raw-loss = 0.6447993516921997, train/logprobs = tensor([[-0.0660, -0.6055],
        [-0.0752, -0.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19912174344062805
Epoch 0, Step 207: train/loss = 0.8433406949043274, train/raw-loss = 0.6792612075805664, train/logprobs = tensor([[-0.0846, -0.1066],
        [-0.1019, -0.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640794724225998
Epoch 0, Step 208: train/loss = 0.8335564136505127, train/raw-loss = 0.6612021923065186, train/logprobs = tensor([[-0.0612, -0.2317],
        [-0.0624, -0.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17235422134399414
Epoch 0, Step 209: train/loss = 0.8179819583892822, train/raw-loss = 0.6815448999404907, train/logprobs = tensor([[-0.1040, -0.0653],
        [-0.1378, -0.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13643701374530792
Epoch 0, Step 210: train/loss = 0.8638560771942139, train/raw-loss = 0.6842560768127441, train/logprobs = tensor([[-0.0657, -0.1021],
        [-0.0691, -0.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17960000038146973
Epoch 0, Step 211: train/loss = 0.7668957114219666, train/raw-loss = 0.6623411178588867, train/logprobs = tensor([[-0.0451, -0.3175],
        [-0.0523, -0.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10455458611249924
Epoch 0, Step 212: train/loss = 0.811069667339325, train/raw-loss = 0.6919745206832886, train/logprobs = tensor([[-0.0618, -0.0695],
        [-0.0610, -0.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11909511685371399
Epoch 0, Step 213: train/loss = 0.8018483519554138, train/raw-loss = 0.6897100806236267, train/logprobs = tensor([[-0.0807, -0.1574],
        [-0.0784, -0.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121383011341095
Epoch 0, Step 214: train/loss = 0.8618901968002319, train/raw-loss = 0.6719226837158203, train/logprobs = tensor([[-0.0742, -0.1865],
        [-0.0781, -0.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18996748328208923
Epoch 0, Step 215: train/loss = 0.7924250364303589, train/raw-loss = 0.6799924969673157, train/logprobs = tensor([[-0.1424, -0.1005],
        [-0.1746, -0.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243253946304321
Epoch 0, Step 216: train/loss = 0.7681412100791931, train/raw-loss = 0.6795942783355713, train/logprobs = tensor([[-0.1335, -0.1513],
        [-0.1469, -0.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854696899652481
Epoch 0, Step 217: train/loss = 0.8000791668891907, train/raw-loss = 0.6776578426361084, train/logprobs = tensor([[-0.1893, -0.1785],
        [-0.1973, -0.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1224212646484375
Epoch 0, Step 218: train/loss = 0.7580358982086182, train/raw-loss = 0.6844898462295532, train/logprobs = tensor([[-0.1612, -0.0893],
        [-0.1733, -0.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07354611158370972
Epoch 0, Step 219: train/loss = 0.8311488628387451, train/raw-loss = 0.6797962188720703, train/logprobs = tensor([[-0.0727, -0.0876],
        [-0.0885, -0.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513526886701584
Epoch 0, Step 220: train/loss = 0.7901326417922974, train/raw-loss = 0.6667612791061401, train/logprobs = tensor([[-0.2112, -0.2042],
        [-0.2351, -0.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12337136268615723
Epoch 0, Step 221: train/loss = 0.8633924722671509, train/raw-loss = 0.662894606590271, train/logprobs = tensor([[-0.0700, -0.2149],
        [-0.0873, -0.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2004978209733963
Epoch 0, Step 222: train/loss = 0.8072798252105713, train/raw-loss = 0.6718391180038452, train/logprobs = tensor([[-0.1267, -0.1525],
        [-0.1681, -0.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13544075191020966
Epoch 0, Step 223: train/loss = 0.8019415140151978, train/raw-loss = 0.6685830354690552, train/logprobs = tensor([[-0.0734, -0.2538],
        [-0.0769, -0.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13335853815078735
Epoch 0, Step 224: train/loss = 0.787460207939148, train/raw-loss = 0.6834043264389038, train/logprobs = tensor([[-0.0536, -0.0665],
        [-0.0685, -0.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10405585169792175
Epoch 0, Step 225: train/loss = 0.7972161769866943, train/raw-loss = 0.6838169693946838, train/logprobs = tensor([[-0.0813, -0.0557],
        [-0.0892, -0.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11339914798736572
Epoch 0, Step 226: train/loss = 0.7684104442596436, train/raw-loss = 0.6519280672073364, train/logprobs = tensor([[-0.0591, -0.2398],
        [-0.0862, -0.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11648236960172653
Epoch 0, Step 227: train/loss = 0.7921205759048462, train/raw-loss = 0.6560847163200378, train/logprobs = tensor([[-0.1268, -0.1685],
        [-0.1904, -0.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13603582978248596
Epoch 0, Step 228: train/loss = 0.8424156308174133, train/raw-loss = 0.6888600587844849, train/logprobs = tensor([[-0.0508, -0.2146],
        [-0.0497, -0.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15355557203292847
Epoch 0, Step 229: train/loss = 0.7709071040153503, train/raw-loss = 0.6344867944717407, train/logprobs = tensor([[-0.0563, -0.4719],
        [-0.0665, -0.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13642027974128723
Epoch 0, Step 230: train/loss = 0.8020879030227661, train/raw-loss = 0.6698839664459229, train/logprobs = tensor([[-0.0581, -0.1448],
        [-0.0695, -0.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13220390677452087
Epoch 0, Step 231: train/loss = 0.7969441413879395, train/raw-loss = 0.6763489246368408, train/logprobs = tensor([[-0.0761, -0.1115],
        [-0.0985, -0.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12059521675109863
Epoch 0, Step 232: train/loss = 0.8112216591835022, train/raw-loss = 0.6549817323684692, train/logprobs = tensor([[-0.1031, -0.2633],
        [-0.1061, -0.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15623997151851654
Epoch 0, Step 233: train/loss = 0.7710660696029663, train/raw-loss = 0.6405686140060425, train/logprobs = tensor([[-0.1044, -0.3773],
        [-0.1137, -0.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1304975301027298
Epoch 0, Step 234: train/loss = 0.8528560400009155, train/raw-loss = 0.6849303245544434, train/logprobs = tensor([[-0.0872, -0.1836],
        [-0.0966, -0.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16792574524879456
Epoch 0, Step 235: train/loss = 0.7864055633544922, train/raw-loss = 0.6688099503517151, train/logprobs = tensor([[-0.0563, -0.5327],
        [-0.0803, -0.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11759565025568008
Epoch 0, Step 236: train/loss = 0.7808728218078613, train/raw-loss = 0.6827750205993652, train/logprobs = tensor([[-0.0505, -0.1459],
        [-0.0560, -0.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09809784591197968
Epoch 0, Step 237: train/loss = 0.7574382424354553, train/raw-loss = 0.6868667006492615, train/logprobs = tensor([[-0.0657, -0.2132],
        [-0.0597, -0.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07057145982980728
Epoch 0, Step 238: train/loss = 0.8330535292625427, train/raw-loss = 0.6710885763168335, train/logprobs = tensor([[-0.1034, -0.1840],
        [-0.1303, -0.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196493804454803
Epoch 0, Step 239: train/loss = 0.7565175294876099, train/raw-loss = 0.685401439666748, train/logprobs = tensor([[-0.1009, -0.1744],
        [-0.1110, -0.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0711161270737648
Epoch 0, Step 240: train/loss = 0.7377965450286865, train/raw-loss = 0.6798794269561768, train/logprobs = tensor([[-0.0787, -0.3617],
        [-0.0778, -0.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791721120476723
Epoch 0, Step 241: train/loss = 0.836479902267456, train/raw-loss = 0.680574357509613, train/logprobs = tensor([[-0.0427, -0.1344],
        [-0.0492, -0.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15590554475784302
Epoch 0, Step 242: train/loss = 0.795881986618042, train/raw-loss = 0.6857390403747559, train/logprobs = tensor([[-0.0432, -0.1626],
        [-0.0492, -0.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11014290153980255
Epoch 0, Step 243: train/loss = 0.7553790807723999, train/raw-loss = 0.689286470413208, train/logprobs = tensor([[-0.1127, -0.1080],
        [-0.1147, -0.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06609262526035309
Epoch 0, Step 244: train/loss = 0.7658462524414062, train/raw-loss = 0.6594865322113037, train/logprobs = tensor([[-0.1118, -0.2364],
        [-0.1367, -0.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10635973513126373
Epoch 0, Step 245: train/loss = 0.7671583890914917, train/raw-loss = 0.6728586554527283, train/logprobs = tensor([[-0.0598, -0.4119],
        [-0.0853, -0.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09429974853992462
Epoch 0, Step 246: train/loss = 0.8057123422622681, train/raw-loss = 0.6707545518875122, train/logprobs = tensor([[-0.0700, -0.1179],
        [-0.0933, -0.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349577158689499
Epoch 0, Step 247: train/loss = 0.7519099116325378, train/raw-loss = 0.6617230176925659, train/logprobs = tensor([[-0.1327, -0.1077],
        [-0.2116, -0.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09018686413764954
Epoch 0, Step 248: train/loss = 0.7794781923294067, train/raw-loss = 0.684660792350769, train/logprobs = tensor([[-0.0735, -0.2510],
        [-0.0929, -0.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0948173850774765
Epoch 0, Step 249: train/loss = 0.8262717723846436, train/raw-loss = 0.6750588417053223, train/logprobs = tensor([[-0.0857, -0.1123],
        [-0.0965, -0.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15121296048164368
Epoch 0, Step 250: train/loss = 0.8368074297904968, train/raw-loss = 0.6737022399902344, train/logprobs = tensor([[-0.0716, -0.1705],
        [-0.1086, -0.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16310511529445648
Epoch 0, Step 251: train/loss = 0.8027727603912354, train/raw-loss = 0.6796659231185913, train/logprobs = tensor([[-0.0728, -0.2016],
        [-0.0863, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12310688942670822
Epoch 0, Step 252: train/loss = 0.8202223777770996, train/raw-loss = 0.6918540000915527, train/logprobs = tensor([[-0.0563, -0.0817],
        [-0.0585, -0.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836839258670807
Epoch 0, Step 253: train/loss = 0.7853147983551025, train/raw-loss = 0.6899595260620117, train/logprobs = tensor([[-0.2004, -0.0734],
        [-0.2171, -0.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09535536915063858
Epoch 0, Step 254: train/loss = 0.7939156293869019, train/raw-loss = 0.6704201698303223, train/logprobs = tensor([[-0.1160, -0.1784],
        [-0.1536, -0.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12349549680948257
Epoch 0, Step 255: train/loss = 0.7873322367668152, train/raw-loss = 0.6843811273574829, train/logprobs = tensor([[-0.1187, -0.1299],
        [-0.1256, -0.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295116901397705
Epoch 0, Step 256: train/loss = 0.7387600541114807, train/raw-loss = 0.6888518333435059, train/logprobs = tensor([[-0.1522, -0.1746],
        [-0.1670, -0.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04990827292203903
Epoch 0, Step 257: train/loss = 0.7589384317398071, train/raw-loss = 0.6769539713859558, train/logprobs = tensor([[-0.0643, -0.1274],
        [-0.0767, -0.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819844901561737
Epoch 0, Step 258: train/loss = 0.7897363901138306, train/raw-loss = 0.6583300232887268, train/logprobs = tensor([[-0.0795, -0.1998],
        [-0.1165, -0.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13140633702278137
Epoch 0, Step 259: train/loss = 0.7049969434738159, train/raw-loss = 0.6299036741256714, train/logprobs = tensor([[-0.0898, -0.4247],
        [-0.1111, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07509323954582214
Epoch 0, Step 260: train/loss = 0.7805784940719604, train/raw-loss = 0.6376365423202515, train/logprobs = tensor([[-0.1106, -0.3913],
        [-0.1212, -0.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14294199645519257
Epoch 0, Step 261: train/loss = 0.7510499954223633, train/raw-loss = 0.6712971329689026, train/logprobs = tensor([[-0.0922, -0.2241],
        [-0.1036, -0.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07975287735462189
Epoch 0, Step 262: train/loss = 0.7615002393722534, train/raw-loss = 0.6486269235610962, train/logprobs = tensor([[-0.0524, -0.2817],
        [-0.0722, -0.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128733903169632
Epoch 0, Step 263: train/loss = 0.7139475345611572, train/raw-loss = 0.6708755493164062, train/logprobs = tensor([[-0.1254, -0.1235],
        [-0.1443, -0.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04307199642062187
Epoch 0, Step 264: train/loss = 0.7209938168525696, train/raw-loss = 0.6723244786262512, train/logprobs = tensor([[-0.1031, -0.1304],
        [-0.1310, -0.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048669349402189255
Epoch 0, Step 265: train/loss = 0.7388173341751099, train/raw-loss = 0.6876809597015381, train/logprobs = tensor([[-0.0572, -0.1031],
        [-0.0600, -0.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05113634094595909
Epoch 0, Step 266: train/loss = 0.7528460621833801, train/raw-loss = 0.6685003638267517, train/logprobs = tensor([[-0.1362, -0.1700],
        [-0.1879, -0.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08434571325778961
Epoch 0, Step 267: train/loss = 0.828650951385498, train/raw-loss = 0.6673296093940735, train/logprobs = tensor([[-0.1073, -0.2444],
        [-0.1107, -0.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16132137179374695
Epoch 0, Step 268: train/loss = 0.759822428226471, train/raw-loss = 0.6357437372207642, train/logprobs = tensor([[-0.0389, -0.4166],
        [-0.0452, -0.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407870590686798
Epoch 0, Step 269: train/loss = 0.7643145322799683, train/raw-loss = 0.6432585716247559, train/logprobs = tensor([[-0.1370, -0.3642],
        [-0.1510, -0.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12105594575405121
Epoch 0, Step 270: train/loss = 0.8751053810119629, train/raw-loss = 0.6756811141967773, train/logprobs = tensor([[-0.0816, -0.1407],
        [-0.0858, -0.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19942425191402435
Epoch 0, Step 271: train/loss = 0.7394601106643677, train/raw-loss = 0.670760989189148, train/logprobs = tensor([[-0.0757, -0.1420],
        [-0.1064, -0.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06869900226593018
Epoch 0, Step 272: train/loss = 0.7531483769416809, train/raw-loss = 0.6868469715118408, train/logprobs = tensor([[-0.0802, -0.0408],
        [-0.1015, -0.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06630134582519531
Epoch 0, Step 273: train/loss = 0.7822318077087402, train/raw-loss = 0.6851323843002319, train/logprobs = tensor([[-0.0805, -0.1171],
        [-0.0824, -0.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09709949791431427
Epoch 0, Step 274: train/loss = 0.7846351861953735, train/raw-loss = 0.6862032413482666, train/logprobs = tensor([[-0.0754, -0.1105],
        [-0.0931, -0.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843198210000992
Epoch 0, Step 275: train/loss = 0.8243216276168823, train/raw-loss = 0.6818180084228516, train/logprobs = tensor([[-0.0961, -0.0931],
        [-0.1127, -0.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142503559589386
Epoch 0, Step 276: train/loss = 0.8062247633934021, train/raw-loss = 0.6823402643203735, train/logprobs = tensor([[-0.1659, -0.1577],
        [-0.1855, -0.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12388449162244797
Epoch 0, Step 277: train/loss = 0.7565571069717407, train/raw-loss = 0.6787751913070679, train/logprobs = tensor([[-0.1004, -0.2032],
        [-0.1066, -0.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07778192311525345
Epoch 0, Step 278: train/loss = 0.7574350833892822, train/raw-loss = 0.6755114793777466, train/logprobs = tensor([[-0.1252, -0.1252],
        [-0.1477, -0.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192367106676102
Epoch 0, Step 279: train/loss = 0.7312880754470825, train/raw-loss = 0.6500185132026672, train/logprobs = tensor([[-0.1024, -0.1648],
        [-0.2025, -0.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08126956224441528
Epoch 0, Step 280: train/loss = 0.7545664310455322, train/raw-loss = 0.662002682685852, train/logprobs = tensor([[-0.0859, -0.2584],
        [-0.0874, -0.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256374835968018
Epoch 0, Step 281: train/loss = 0.7685117125511169, train/raw-loss = 0.6820629239082336, train/logprobs = tensor([[-0.0532, -0.1472],
        [-0.0552, -0.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0864487737417221
Epoch 0, Step 282: train/loss = 0.7551148533821106, train/raw-loss = 0.6732050180435181, train/logprobs = tensor([[-0.1382, -0.1934],
        [-0.1627, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190983533859253
Epoch 0, Step 283: train/loss = 0.8065569400787354, train/raw-loss = 0.6546686887741089, train/logprobs = tensor([[-0.0467, -0.3270],
        [-0.0785, -0.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15188828110694885
Epoch 0, Step 284: train/loss = 0.8259609341621399, train/raw-loss = 0.6923109889030457, train/logprobs = tensor([[-0.0760, -0.1287],
        [-0.0837, -0.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364994525909424
Epoch 0, Step 285: train/loss = 0.7461417317390442, train/raw-loss = 0.6893113255500793, train/logprobs = tensor([[-0.0693, -0.1285],
        [-0.0794, -0.1230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05683040991425514
Epoch 0, Step 286: train/loss = 0.8144756555557251, train/raw-loss = 0.6756184101104736, train/logprobs = tensor([[-0.0498, -0.1677],
        [-0.0529, -0.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885723054409027
Epoch 0, Step 287: train/loss = 0.7580726146697998, train/raw-loss = 0.6871259212493896, train/logprobs = tensor([[-0.0920, -0.3032],
        [-0.0941, -0.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094662636518478
Epoch 0, Step 288: train/loss = 0.7645928859710693, train/raw-loss = 0.6469238996505737, train/logprobs = tensor([[-0.1227, -0.3034],
        [-0.1465, -0.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11766896396875381
Epoch 0, Step 289: train/loss = 0.773769199848175, train/raw-loss = 0.6854813098907471, train/logprobs = tensor([[-0.0715, -0.1575],
        [-0.0716, -0.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08828790485858917
Epoch 0, Step 290: train/loss = 0.785232663154602, train/raw-loss = 0.6849216818809509, train/logprobs = tensor([[-0.0792, -0.0998],
        [-0.0902, -0.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10031096637248993
Epoch 0, Step 291: train/loss = 0.7623511552810669, train/raw-loss = 0.6669172644615173, train/logprobs = tensor([[-0.1284, -0.1571],
        [-0.1553, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09543392807245255
Epoch 0, Step 292: train/loss = 0.750984787940979, train/raw-loss = 0.6852604746818542, train/logprobs = tensor([[-0.0675, -0.2251],
        [-0.0707, -0.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06572424620389938
Epoch 0, Step 293: train/loss = 0.7550734877586365, train/raw-loss = 0.6768200397491455, train/logprobs = tensor([[-0.0436, -0.0988],
        [-0.0610, -0.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07825351506471634
Epoch 0, Step 294: train/loss = 0.7556161880493164, train/raw-loss = 0.6672343015670776, train/logprobs = tensor([[-0.1517, -0.1589],
        [-0.2123, -0.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08838193863630295
Epoch 0, Step 295: train/loss = 0.7530313730239868, train/raw-loss = 0.6471349000930786, train/logprobs = tensor([[-0.0522, -0.2959],
        [-0.0674, -0.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058964803814888
Epoch 0, Step 296: train/loss = 0.7521399259567261, train/raw-loss = 0.6486372947692871, train/logprobs = tensor([[-0.0858, -0.3161],
        [-0.1147, -0.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350269079208374
Epoch 0, Step 297: train/loss = 0.742455244064331, train/raw-loss = 0.6472569108009338, train/logprobs = tensor([[-0.0780, -0.3231],
        [-0.0889, -0.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519831836223602
Epoch 0, Step 298: train/loss = 0.7970137000083923, train/raw-loss = 0.6823975443840027, train/logprobs = tensor([[-0.0912, -0.1389],
        [-0.1137, -0.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11461615562438965
Epoch 0, Step 299: train/loss = 0.7281826734542847, train/raw-loss = 0.6629139184951782, train/logprobs = tensor([[-0.1149, -0.1353],
        [-0.1531, -0.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06526876240968704
Epoch 0, Step 300: train/loss = 0.7206933498382568, train/raw-loss = 0.6549772024154663, train/logprobs = tensor([[-0.0891, -0.2018],
        [-0.1334, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06571612507104874
Epoch 0, Step 301: train/loss = 0.7513374090194702, train/raw-loss = 0.6841639876365662, train/logprobs = tensor([[-0.1209, -0.0951],
        [-0.1508, -0.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06717344373464584
Epoch 0, Step 302: train/loss = 0.7614449262619019, train/raw-loss = 0.6728063821792603, train/logprobs = tensor([[-0.1234, -0.2139],
        [-0.1315, -0.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08863859623670578
Epoch 0, Step 303: train/loss = 0.7814884185791016, train/raw-loss = 0.6729689836502075, train/logprobs = tensor([[-0.0844, -0.1791],
        [-0.1099, -0.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10851947218179703
Epoch 0, Step 304: train/loss = 0.7609118223190308, train/raw-loss = 0.6887852549552917, train/logprobs = tensor([[-0.0881, -0.1279],
        [-0.0956, -0.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07212647050619125
Epoch 0, Step 305: train/loss = 0.7317962646484375, train/raw-loss = 0.6405588984489441, train/logprobs = tensor([[-0.1108, -0.3030],
        [-0.1358, -0.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09123732149600983
Epoch 0, Step 306: train/loss = 0.6882006525993347, train/raw-loss = 0.6291564106941223, train/logprobs = tensor([[-0.0770, -0.3780],
        [-0.0987, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05904422700405121
Epoch 0, Step 307: train/loss = 0.7106040716171265, train/raw-loss = 0.6476422548294067, train/logprobs = tensor([[-0.1356, -0.3003],
        [-0.1515, -0.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06296180933713913
Epoch 0, Step 308: train/loss = 0.7456730604171753, train/raw-loss = 0.6737319231033325, train/logprobs = tensor([[-0.1082, -0.3177],
        [-0.1419, -0.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719410851597786
Epoch 0, Step 309: train/loss = 0.8069050312042236, train/raw-loss = 0.6934803128242493, train/logprobs = tensor([[-0.0784, -0.1275],
        [-0.0880, -0.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342476308345795
Epoch 0, Step 310: train/loss = 0.7667679786682129, train/raw-loss = 0.6431261301040649, train/logprobs = tensor([[-0.0534, -0.2604],
        [-0.0734, -0.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364182621240616
Epoch 0, Step 311: train/loss = 0.7576890587806702, train/raw-loss = 0.6912841796875, train/logprobs = tensor([[-0.0490, -0.2502],
        [-0.0599, -0.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640487909317017
Epoch 0, Step 312: train/loss = 0.6843520402908325, train/raw-loss = 0.6388784646987915, train/logprobs = tensor([[-0.0526, -0.3006],
        [-0.0910, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04547365754842758
Epoch 0, Step 313: train/loss = 0.7740733027458191, train/raw-loss = 0.6569513082504272, train/logprobs = tensor([[-0.0693, -0.2028],
        [-0.0862, -0.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11712196469306946
Epoch 0, Step 314: train/loss = 0.7408865690231323, train/raw-loss = 0.683936595916748, train/logprobs = tensor([[-0.1042, -0.1261],
        [-0.1270, -0.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05695003271102905
Epoch 0, Step 315: train/loss = 0.7644193768501282, train/raw-loss = 0.6660321950912476, train/logprobs = tensor([[-0.2055, -0.2397],
        [-0.2500, -0.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09838713705539703
Epoch 0, Step 316: train/loss = 0.7207997441291809, train/raw-loss = 0.6911864876747131, train/logprobs = tensor([[-0.0442, -0.0703],
        [-0.0464, -0.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029613252729177475
Epoch 0, Step 317: train/loss = 0.8040534853935242, train/raw-loss = 0.6718271374702454, train/logprobs = tensor([[-0.0750, -0.1502],
        [-0.0837, -0.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322263479232788
Epoch 0, Step 318: train/loss = 0.7883090972900391, train/raw-loss = 0.6736752986907959, train/logprobs = tensor([[-0.0811, -0.1077],
        [-0.0897, -0.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11463379859924316
Epoch 0, Step 319: train/loss = 0.7913984060287476, train/raw-loss = 0.6812000274658203, train/logprobs = tensor([[-0.0534, -0.1131],
        [-0.0603, -0.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11019830405712128
Epoch 0, Step 320: train/loss = 0.720146656036377, train/raw-loss = 0.6481572389602661, train/logprobs = tensor([[-0.0830, -0.2110],
        [-0.1148, -0.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07198943942785263
Epoch 0, Step 321: train/loss = 0.7477099299430847, train/raw-loss = 0.6821297407150269, train/logprobs = tensor([[-0.0746, -0.1969],
        [-0.0903, -0.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06558011472225189
Epoch 0, Step 322: train/loss = 0.7500120997428894, train/raw-loss = 0.6644091606140137, train/logprobs = tensor([[-0.1697, -0.3553],
        [-0.1809, -0.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08560290932655334
Epoch 0, Step 323: train/loss = 0.7332362532615662, train/raw-loss = 0.651403546333313, train/logprobs = tensor([[-0.0601, -0.3647],
        [-0.0735, -0.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08183270692825317
Epoch 0, Step 324: train/loss = 0.7368494868278503, train/raw-loss = 0.6217437982559204, train/logprobs = tensor([[-0.0848, -0.5662],
        [-0.0924, -0.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11510567367076874
Epoch 0, Step 325: train/loss = 0.7488878965377808, train/raw-loss = 0.6851372718811035, train/logprobs = tensor([[-0.0601, -0.1594],
        [-0.0754, -0.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06375059485435486
Epoch 0, Step 326: train/loss = 0.7177315950393677, train/raw-loss = 0.6341609954833984, train/logprobs = tensor([[-0.1056, -0.4052],
        [-0.1092, -0.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08357056975364685
Epoch 0, Step 327: train/loss = 0.7216252684593201, train/raw-loss = 0.691042959690094, train/logprobs = tensor([[-0.0588, -0.0882],
        [-0.0586, -0.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03058236464858055
Epoch 0, Step 328: train/loss = 0.7554792165756226, train/raw-loss = 0.7001385688781738, train/logprobs = tensor([[-0.0805, -0.0686],
        [-0.0872, -0.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055340640246868134
Epoch 0, Step 329: train/loss = 0.751857340335846, train/raw-loss = 0.6790847778320312, train/logprobs = tensor([[-0.1384, -0.1381],
        [-0.1520, -0.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07277253270149231
Epoch 0, Step 330: train/loss = 0.6687451004981995, train/raw-loss = 0.580836296081543, train/logprobs = tensor([[-0.0719, -0.6329],
        [-0.0950, -0.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879087820649147
Epoch 0, Step 331: train/loss = 0.7173232436180115, train/raw-loss = 0.6270681619644165, train/logprobs = tensor([[-0.0752, -0.3461],
        [-0.1175, -0.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025508910417557
Epoch 0, Step 332: train/loss = 0.7460787892341614, train/raw-loss = 0.6607988476753235, train/logprobs = tensor([[-0.1331, -0.3206],
        [-0.1665, -0.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852799043059349
Epoch 0, Step 333: train/loss = 0.7591672539710999, train/raw-loss = 0.6758838891983032, train/logprobs = tensor([[-0.0579, -0.3437],
        [-0.0629, -0.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08328332006931305
Epoch 0, Step 334: train/loss = 0.7172926068305969, train/raw-loss = 0.6746821999549866, train/logprobs = tensor([[-0.0413, -0.0899],
        [-0.0708, -0.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04261040687561035
Epoch 0, Step 335: train/loss = 0.7562016248703003, train/raw-loss = 0.6620368957519531, train/logprobs = tensor([[-0.0640, -0.2008],
        [-0.0844, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416475147008896
Epoch 0, Step 336: train/loss = 0.7456011176109314, train/raw-loss = 0.6662359833717346, train/logprobs = tensor([[-0.1408, -0.2198],
        [-0.1591, -0.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07936514168977737
Epoch 0, Step 337: train/loss = 0.7185842990875244, train/raw-loss = 0.672240674495697, train/logprobs = tensor([[-0.0536, -0.1203],
        [-0.0836, -0.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046343546360731125
Epoch 0, Step 338: train/loss = 0.7595630884170532, train/raw-loss = 0.6698722243309021, train/logprobs = tensor([[-0.0818, -0.1160],
        [-0.1160, -0.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969089388847351
Epoch 0, Step 339: train/loss = 0.7784878015518188, train/raw-loss = 0.6610482931137085, train/logprobs = tensor([[-0.0413, -0.2343],
        [-0.0522, -0.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11743959784507751
Epoch 0, Step 340: train/loss = 0.7520805597305298, train/raw-loss = 0.6820216178894043, train/logprobs = tensor([[-0.0779, -0.0953],
        [-0.0869, -0.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07005894184112549
Epoch 0, Step 341: train/loss = 0.7157642245292664, train/raw-loss = 0.6191084384918213, train/logprobs = tensor([[-0.0557, -0.4231],
        [-0.0960, -0.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665578603744507
Epoch 0, Step 342: train/loss = 0.6979255676269531, train/raw-loss = 0.6326351761817932, train/logprobs = tensor([[-0.0986, -0.3566],
        [-0.1176, -0.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652904063463211
Epoch 0, Step 343: train/loss = 0.7240607738494873, train/raw-loss = 0.6710978746414185, train/logprobs = tensor([[-0.0813, -0.2375],
        [-0.1010, -0.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05296284332871437
Epoch 0, Step 344: train/loss = 0.7113147377967834, train/raw-loss = 0.6255353689193726, train/logprobs = tensor([[-0.1008, -0.7382],
        [-0.1291, -0.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08577939122915268
Epoch 0, Step 345: train/loss = 0.7159334421157837, train/raw-loss = 0.6594799757003784, train/logprobs = tensor([[-0.1162, -0.1445],
        [-0.1563, -0.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05645344778895378
Epoch 0, Step 346: train/loss = 0.7406904101371765, train/raw-loss = 0.66478431224823, train/logprobs = tensor([[-0.0959, -0.1895],
        [-0.1050, -0.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07590606808662415
Epoch 0, Step 347: train/loss = 0.712361752986908, train/raw-loss = 0.616135835647583, train/logprobs = tensor([[-0.0457, -0.3846],
        [-0.0796, -0.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622595459222794
Epoch 0, Step 348: train/loss = 0.7233773469924927, train/raw-loss = 0.6477935314178467, train/logprobs = tensor([[-0.0541, -0.2686],
        [-0.0809, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07558374106884003
Epoch 0, Step 349: train/loss = 0.726176381111145, train/raw-loss = 0.6506094932556152, train/logprobs = tensor([[-0.0625, -0.3087],
        [-0.0885, -0.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07556688040494919
Epoch 0, Step 350: train/loss = 0.7167723178863525, train/raw-loss = 0.6701926589012146, train/logprobs = tensor([[-0.0913, -0.2958],
        [-0.0983, -0.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657961428165436
Epoch 0, Step 351: train/loss = 0.7506795525550842, train/raw-loss = 0.6735683679580688, train/logprobs = tensor([[-0.0689, -0.1264],
        [-0.0931, -0.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711117714643478
Epoch 0, Step 352: train/loss = 0.7277833223342896, train/raw-loss = 0.616788923740387, train/logprobs = tensor([[-0.0928, -0.4671],
        [-0.0991, -0.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11099439859390259
Epoch 0, Step 353: train/loss = 0.6783185005187988, train/raw-loss = 0.6020781397819519, train/logprobs = tensor([[-0.0699, -0.5802],
        [-0.0925, -0.1712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07624033838510513
Epoch 0, Step 354: train/loss = 0.7478476762771606, train/raw-loss = 0.6789264678955078, train/logprobs = tensor([[-0.1138, -0.0998],
        [-0.1354, -0.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06892119348049164
Epoch 0, Step 355: train/loss = 0.7146583795547485, train/raw-loss = 0.6513595581054688, train/logprobs = tensor([[-0.1116, -0.2449],
        [-0.1166, -0.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06329887360334396
Epoch 0, Step 356: train/loss = 0.7309027910232544, train/raw-loss = 0.6717754602432251, train/logprobs = tensor([[-0.0904, -0.2099],
        [-0.1008, -0.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05912736803293228
Epoch 0, Step 357: train/loss = 0.7171448469161987, train/raw-loss = 0.6814050078392029, train/logprobs = tensor([[-0.0876, -0.2938],
        [-0.0900, -0.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03573985770344734
Epoch 0, Step 358: train/loss = 0.6763072609901428, train/raw-loss = 0.6069274544715881, train/logprobs = tensor([[-0.0862, -0.4192],
        [-0.1566, -0.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0693797916173935
Epoch 0, Step 359: train/loss = 0.7336694002151489, train/raw-loss = 0.6609458923339844, train/logprobs = tensor([[-0.1447, -0.1539],
        [-0.1936, -0.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07272350043058395
Epoch 0, Step 360: train/loss = 0.7022460699081421, train/raw-loss = 0.644239068031311, train/logprobs = tensor([[-0.0674, -0.2224],
        [-0.1402, -0.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0580068938434124
Epoch 0, Step 361: train/loss = 0.7463082075119019, train/raw-loss = 0.670222818851471, train/logprobs = tensor([[-0.1305, -0.1106],
        [-0.1825, -0.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07608535885810852
Epoch 0, Step 362: train/loss = 0.705644965171814, train/raw-loss = 0.6624007821083069, train/logprobs = tensor([[-0.1072, -0.2063],
        [-0.1313, -0.0996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04324418678879738
Epoch 0, Step 363: train/loss = 0.7362552285194397, train/raw-loss = 0.6841516494750977, train/logprobs = tensor([[-0.0560, -0.0437],
        [-0.0830, -0.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052103519439697266
Epoch 0, Step 364: train/loss = 0.6687420606613159, train/raw-loss = 0.5707830786705017, train/logprobs = tensor([[-0.1138, -1.4434],
        [-0.1224, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0979589968919754
Epoch 0, Step 365: train/loss = 0.7494274973869324, train/raw-loss = 0.6523553729057312, train/logprobs = tensor([[-0.0510, -0.2502],
        [-0.0645, -0.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09707212448120117
Epoch 0, Step 366: train/loss = 0.7121379375457764, train/raw-loss = 0.6600658297538757, train/logprobs = tensor([[-0.0870, -0.1766],
        [-0.1314, -0.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05207209289073944
Epoch 0, Step 367: train/loss = 0.7169418334960938, train/raw-loss = 0.6397823095321655, train/logprobs = tensor([[-0.0703, -0.2995],
        [-0.0962, -0.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07715952396392822
Epoch 0, Step 368: train/loss = 0.777024507522583, train/raw-loss = 0.6767399311065674, train/logprobs = tensor([[-0.0620, -0.2483],
        [-0.0648, -0.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028450191020966
Epoch 0, Step 369: train/loss = 0.7360563278198242, train/raw-loss = 0.6601638197898865, train/logprobs = tensor([[-0.0643, -0.1759],
        [-0.0889, -0.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07589253783226013
Epoch 0, Step 370: train/loss = 0.7405721545219421, train/raw-loss = 0.6855514049530029, train/logprobs = tensor([[-0.0523, -0.1075],
        [-0.0578, -0.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055020805448293686
Epoch 0, Step 371: train/loss = 0.7661906480789185, train/raw-loss = 0.6800012588500977, train/logprobs = tensor([[-0.0819, -0.4244],
        [-0.0982, -0.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08618935942649841
Epoch 0, Step 372: train/loss = 0.7756443023681641, train/raw-loss = 0.6527023315429688, train/logprobs = tensor([[-0.0557, -0.2690],
        [-0.0825, -0.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294191122055054
Epoch 0, Step 373: train/loss = 0.6343472003936768, train/raw-loss = 0.5792477130889893, train/logprobs = tensor([[-0.1251, -0.6757],
        [-0.1676, -0.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055099524557590485
Epoch 0, Step 374: train/loss = 0.7752785086631775, train/raw-loss = 0.6715102791786194, train/logprobs = tensor([[-0.0525, -0.2160],
        [-0.0648, -0.1392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10376827418804169
Epoch 0, Step 375: train/loss = 0.7294672131538391, train/raw-loss = 0.6669521331787109, train/logprobs = tensor([[-0.1468, -0.1726],
        [-0.1565, -0.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06251505017280579
Epoch 0, Step 376: train/loss = 0.6684250831604004, train/raw-loss = 0.5840315818786621, train/logprobs = tensor([[-0.0663, -0.7400],
        [-0.0988, -0.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08439358323812485
Epoch 0, Step 377: train/loss = 0.7257217764854431, train/raw-loss = 0.661888837814331, train/logprobs = tensor([[-0.0463, -0.2800],
        [-0.0497, -0.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06383294612169266
Epoch 0, Step 378: train/loss = 0.6715608835220337, train/raw-loss = 0.6096602082252502, train/logprobs = tensor([[-0.0751, -0.4095],
        [-0.1218, -0.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061900682747364044
Epoch 0, Step 379: train/loss = 0.7367357611656189, train/raw-loss = 0.6715559959411621, train/logprobs = tensor([[-0.0612, -0.0836],
        [-0.0935, -0.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06517979502677917
Epoch 0, Step 380: train/loss = 0.72251296043396, train/raw-loss = 0.6684104800224304, train/logprobs = tensor([[-0.0872, -0.2234],
        [-0.1045, -0.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054102472960948944
Epoch 0, Step 381: train/loss = 0.6897714138031006, train/raw-loss = 0.6342341899871826, train/logprobs = tensor([[-0.0842, -0.6605],
        [-0.0850, -0.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05553717166185379
Epoch 0, Step 382: train/loss = 0.771422803401947, train/raw-loss = 0.6685497164726257, train/logprobs = tensor([[-0.0997, -0.1381],
        [-0.1055, -0.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1028730496764183
Epoch 0, Step 383: train/loss = 0.7514641284942627, train/raw-loss = 0.6487448811531067, train/logprobs = tensor([[-0.1632, -0.3125],
        [-0.1771, -0.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271920263767242
Epoch 0, Step 384: train/loss = 0.6125104427337646, train/raw-loss = 0.5391420125961304, train/logprobs = tensor([[-0.1017, -1.0692],
        [-0.1167, -0.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336845993995667
Epoch 0, Step 385: train/loss = 0.7057539820671082, train/raw-loss = 0.6644034385681152, train/logprobs = tensor([[-0.1063, -0.1313],
        [-0.1452, -0.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04135054349899292
Epoch 0, Step 386: train/loss = 0.7169579267501831, train/raw-loss = 0.6877595782279968, train/logprobs = tensor([[-0.0726, -0.1047],
        [-0.0776, -0.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02919839136302471
Epoch 0, Step 387: train/loss = 0.6108202934265137, train/raw-loss = 0.5567888617515564, train/logprobs = tensor([[-0.1004, -1.1393],
        [-0.1478, -0.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05403144285082817
Epoch 0, Step 388: train/loss = 0.7197042107582092, train/raw-loss = 0.6519425511360168, train/logprobs = tensor([[-0.1613, -0.2719],
        [-0.1610, -0.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776165962219238
Epoch 0, Step 389: train/loss = 0.6915674805641174, train/raw-loss = 0.5980627536773682, train/logprobs = tensor([[-0.1665, -0.5350],
        [-0.1721, -0.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350471198558807
Epoch 0, Step 390: train/loss = 0.6990529298782349, train/raw-loss = 0.6384434700012207, train/logprobs = tensor([[-0.1620, -0.2895],
        [-0.2254, -0.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06060954928398132
Epoch 0, Step 391: train/loss = 0.7113052010536194, train/raw-loss = 0.643612265586853, train/logprobs = tensor([[-0.0737, -0.3707],
        [-0.0955, -0.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06769294291734695
Epoch 0, Step 392: train/loss = 0.7602139711380005, train/raw-loss = 0.673180341720581, train/logprobs = tensor([[-0.0903, -0.4029],
        [-0.1110, -0.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703361451625824
Epoch 0, Step 393: train/loss = 0.7600632905960083, train/raw-loss = 0.6749380230903625, train/logprobs = tensor([[-0.1619, -0.2740],
        [-0.1581, -0.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08512533456087112
Epoch 0, Step 394: train/loss = 0.6377034187316895, train/raw-loss = 0.5479815006256104, train/logprobs = tensor([[-0.0813, -0.8331],
        [-0.1378, -0.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08972195535898209
Epoch 0, Step 395: train/loss = 0.6488966345787048, train/raw-loss = 0.5672418475151062, train/logprobs = tensor([[-0.0640, -0.8038],
        [-0.0995, -0.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08165480941534042
Epoch 0, Step 396: train/loss = 0.7172008752822876, train/raw-loss = 0.6439217329025269, train/logprobs = tensor([[-0.0673, -0.3881],
        [-0.0875, -0.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327915728092194
Epoch 0, Step 397: train/loss = 0.7599610090255737, train/raw-loss = 0.6717935800552368, train/logprobs = tensor([[-0.0986, -0.2752],
        [-0.1206, -0.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08816733956336975
Epoch 0, Step 398: train/loss = 0.6870119571685791, train/raw-loss = 0.5929809808731079, train/logprobs = tensor([[-0.0571, -0.6604],
        [-0.0644, -0.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940309688448906
Epoch 0, Step 399: train/loss = 0.7068871855735779, train/raw-loss = 0.6618385910987854, train/logprobs = tensor([[-0.1150, -0.1217],
        [-0.1763, -0.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045048657804727554
Epoch 0, Step 400: train/loss = 0.7231671810150146, train/raw-loss = 0.6681742072105408, train/logprobs = tensor([[-0.1043, -0.1210],
        [-0.1393, -0.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054992981255054474
Epoch 0, Step 401: train/loss = 0.695075273513794, train/raw-loss = 0.6340820789337158, train/logprobs = tensor([[-0.1087, -0.3402],
        [-0.1545, -0.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06099318712949753
Epoch 0, Step 402: train/loss = 0.6566143035888672, train/raw-loss = 0.5804957151412964, train/logprobs = tensor([[-0.1165, -0.6250],
        [-0.1468, -0.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611861079931259
Epoch 0, Step 403: train/loss = 0.7301954030990601, train/raw-loss = 0.6552785634994507, train/logprobs = tensor([[-0.0585, -0.1642],
        [-0.1020, -0.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07491686940193176
Epoch 0, Step 404: train/loss = 0.7242032885551453, train/raw-loss = 0.6563315391540527, train/logprobs = tensor([[-0.1416, -0.2696],
        [-0.1668, -0.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06787175685167313
Epoch 0, Step 405: train/loss = 0.6963703632354736, train/raw-loss = 0.6113787889480591, train/logprobs = tensor([[-0.0757, -0.4611],
        [-0.0926, -0.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499158173799515
Epoch 0, Step 406: train/loss = 0.7194953560829163, train/raw-loss = 0.6458883285522461, train/logprobs = tensor([[-0.0573, -0.4684],
        [-0.0858, -0.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07360701262950897
Epoch 0, Step 407: train/loss = 0.7400363683700562, train/raw-loss = 0.6686648726463318, train/logprobs = tensor([[-0.0673, -0.1552],
        [-0.0774, -0.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137151062488556
Epoch 0, Step 408: train/loss = 0.7347457408905029, train/raw-loss = 0.6694931387901306, train/logprobs = tensor([[-0.0866, -0.1661],
        [-0.1218, -0.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652526319026947
Epoch 0, Step 409: train/loss = 0.640444815158844, train/raw-loss = 0.5418351292610168, train/logprobs = tensor([[-0.1906, -0.9276],
        [-0.2216, -0.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09860967099666595
Epoch 0, Step 410: train/loss = 0.7168797254562378, train/raw-loss = 0.6534744501113892, train/logprobs = tensor([[-0.1759, -0.3938],
        [-0.1870, -0.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06340521574020386
Epoch 0, Step 411: train/loss = 0.7590770125389099, train/raw-loss = 0.6753614544868469, train/logprobs = tensor([[-0.1010, -0.1899],
        [-0.1110, -0.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371558785438538
Epoch 0, Step 412: train/loss = 0.7388131618499756, train/raw-loss = 0.6651420593261719, train/logprobs = tensor([[-0.0901, -0.1683],
        [-0.1076, -0.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0736711174249649
Epoch 0, Step 413: train/loss = 0.6259273290634155, train/raw-loss = 0.5753147602081299, train/logprobs = tensor([[-0.0580, -0.8200],
        [-0.0847, -0.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05061252415180206
Epoch 0, Step 414: train/loss = 0.7373014092445374, train/raw-loss = 0.6486464142799377, train/logprobs = tensor([[-0.0529, -0.2657],
        [-0.0736, -0.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08865498006343842
Epoch 0, Step 415: train/loss = 0.6694234609603882, train/raw-loss = 0.5934416055679321, train/logprobs = tensor([[-0.1473, -0.7848],
        [-0.1462, -0.2822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07598181068897247
Epoch 0, Step 416: train/loss = 0.7139904499053955, train/raw-loss = 0.6689246892929077, train/logprobs = tensor([[-0.0654, -0.3412],
        [-0.0672, -0.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045065756887197495
Epoch 0, Step 417: train/loss = 0.6393128633499146, train/raw-loss = 0.5474960803985596, train/logprobs = tensor([[-0.1314, -1.0859],
        [-0.1299, -0.0903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181679785251617
Epoch 0, Step 418: train/loss = 0.6538794040679932, train/raw-loss = 0.5568876266479492, train/logprobs = tensor([[-0.1287, -0.6175],
        [-0.2438, -0.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699175506830215
Epoch 0, Step 419: train/loss = 0.6664952039718628, train/raw-loss = 0.5880939960479736, train/logprobs = tensor([[-0.1463, -0.5891],
        [-0.1755, -0.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840121537446976
Epoch 0, Step 420: train/loss = 0.6627580523490906, train/raw-loss = 0.5827268958091736, train/logprobs = tensor([[-0.1140, -0.7606],
        [-0.1176, -0.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08003110438585281
Epoch 0, Step 421: train/loss = 0.6900031566619873, train/raw-loss = 0.6101524233818054, train/logprobs = tensor([[-0.0812, -0.4686],
        [-0.1502, -0.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985071837902069
Epoch 0, Step 422: train/loss = 0.7212632894515991, train/raw-loss = 0.6301966309547424, train/logprobs = tensor([[-0.1749, -0.5671],
        [-0.2295, -0.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910666286945343
Epoch 0, Step 423: train/loss = 0.665846049785614, train/raw-loss = 0.5773665904998779, train/logprobs = tensor([[-0.0780, -0.8407],
        [-0.1234, -0.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08847947418689728
Epoch 0, Step 424: train/loss = 0.7519816160202026, train/raw-loss = 0.6604043841362, train/logprobs = tensor([[-0.0874, -0.6407],
        [-0.0919, -0.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157725423574448
Epoch 0, Step 425: train/loss = 0.7345746159553528, train/raw-loss = 0.6599094271659851, train/logprobs = tensor([[-0.2095, -0.4457],
        [-0.0568, -0.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07466518878936768
Epoch 0, Step 426: train/loss = 0.7105180621147156, train/raw-loss = 0.6144264340400696, train/logprobs = tensor([[-0.1067, -0.4383],
        [-0.1196, -0.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609156101942062
Epoch 0, Step 427: train/loss = 0.6662733554840088, train/raw-loss = 0.5940203070640564, train/logprobs = tensor([[-0.0361, -0.6001],
        [-0.0633, -0.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07225301116704941
Epoch 0, Step 428: train/loss = 0.754587709903717, train/raw-loss = 0.681067943572998, train/logprobs = tensor([[-0.0904, -0.1655],
        [-0.0964, -0.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07351979613304138
Epoch 0, Step 429: train/loss = 0.637115478515625, train/raw-loss = 0.5589377284049988, train/logprobs = tensor([[-0.0403, -0.6690],
        [-0.1040, -0.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817775011062622
Epoch 0, Step 430: train/loss = 0.6843246221542358, train/raw-loss = 0.6057560443878174, train/logprobs = tensor([[-0.1331, -0.6519],
        [-0.1239, -0.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07856862246990204
Epoch 0, Step 431: train/loss = 0.7153955698013306, train/raw-loss = 0.6514027714729309, train/logprobs = tensor([[-0.0987, -0.2386],
        [-0.1351, -0.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06399285793304443
Epoch 0, Step 432: train/loss = 0.7062272429466248, train/raw-loss = 0.6365566849708557, train/logprobs = tensor([[-0.1063, -0.2754],
        [-0.1758, -0.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06967060267925262
Epoch 0, Step 433: train/loss = 0.7607002854347229, train/raw-loss = 0.6615949869155884, train/logprobs = tensor([[-0.2094, -0.2260],
        [-0.2525, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991053432226181
Epoch 0, Step 434: train/loss = 0.6563717722892761, train/raw-loss = 0.5497459769248962, train/logprobs = tensor([[-0.1559, -1.0461],
        [-0.1379, -0.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10662578046321869
Epoch 0, Step 435: train/loss = 0.7251936197280884, train/raw-loss = 0.6366952657699585, train/logprobs = tensor([[-0.1361, -0.4221],
        [-0.1532, -0.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08849841356277466
Epoch 0, Step 436: train/loss = 0.6528067588806152, train/raw-loss = 0.5611892938613892, train/logprobs = tensor([[-0.1095, -1.2125],
        [-0.1705, -0.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09161749482154846
Epoch 0, Step 437: train/loss = 0.663133978843689, train/raw-loss = 0.5851868391036987, train/logprobs = tensor([[-0.1046, -0.9454],
        [-0.1215, -0.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07794718444347382
Epoch 0, Step 438: train/loss = 0.7179028987884521, train/raw-loss = 0.6326035857200623, train/logprobs = tensor([[-0.1124, -0.3373],
        [-0.1236, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529935032129288
Epoch 0, Step 439: train/loss = 0.7298496961593628, train/raw-loss = 0.671042799949646, train/logprobs = tensor([[-0.0602, -0.0906],
        [-0.1009, -0.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05880685895681381
Epoch 0, Step 440: train/loss = 0.7173302173614502, train/raw-loss = 0.6390430927276611, train/logprobs = tensor([[-0.1187, -0.3887],
        [-0.0837, -0.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07828712463378906
Epoch 0, Step 441: train/loss = 0.7516660690307617, train/raw-loss = 0.6777088642120361, train/logprobs = tensor([[-0.1381, -0.1176],
        [-0.1239, -0.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07395724952220917
Epoch 0, Step 442: train/loss = 0.726915180683136, train/raw-loss = 0.6660016775131226, train/logprobs = tensor([[-0.1016, -0.2517],
        [-0.1249, -0.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06091350317001343
Epoch 0, Step 443: train/loss = 0.7671934962272644, train/raw-loss = 0.6995352506637573, train/logprobs = tensor([[-0.2078, -0.0953],
        [-0.1521, -0.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765823811292648
Epoch 0, Step 444: train/loss = 0.7103456854820251, train/raw-loss = 0.6283107995986938, train/logprobs = tensor([[-0.1311, -0.4990],
        [-0.0803, -0.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08203491568565369
Epoch 0, Step 445: train/loss = 0.7265073657035828, train/raw-loss = 0.6219382286071777, train/logprobs = tensor([[-0.1398, -0.3673],
        [-0.1499, -0.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456910729408264
Epoch 0, Step 446: train/loss = 0.6883452534675598, train/raw-loss = 0.6166072487831116, train/logprobs = tensor([[-0.1858, -0.3779],
        [-0.2066, -0.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07173800468444824
Epoch 0, Step 447: train/loss = 0.6226248741149902, train/raw-loss = 0.5159168839454651, train/logprobs = tensor([[-0.1596, -1.3351],
        [-0.1502, -0.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670800507068634
Epoch 0, Step 448: train/loss = 0.5937381982803345, train/raw-loss = 0.5003601908683777, train/logprobs = tensor([[-0.1239, -1.5902],
        [-0.1711, -0.2527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09337808191776276
Epoch 0, Step 449: train/loss = 0.6647058129310608, train/raw-loss = 0.602523922920227, train/logprobs = tensor([[-0.1392, -0.6080],
        [-0.1946, -0.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06218186020851135
Epoch 0, Step 450: train/loss = 0.6971994042396545, train/raw-loss = 0.6333004832267761, train/logprobs = tensor([[-0.2051, -0.4966],
        [-0.1299, -0.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063898965716362
Epoch 0, Step 451: train/loss = 0.7112447023391724, train/raw-loss = 0.6435856819152832, train/logprobs = tensor([[-0.0811, -0.4233],
        [-0.0700, -0.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765904277563095
Epoch 0, Step 452: train/loss = 0.5394365787506104, train/raw-loss = 0.46269723773002625, train/logprobs = tensor([[-0.2119, -1.9804],
        [-0.2724, -0.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07673928141593933
Epoch 0, Step 453: train/loss = 0.5555536150932312, train/raw-loss = 0.46109628677368164, train/logprobs = tensor([[-0.0702, -1.8503],
        [-0.1226, -0.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445736557245255
Epoch 0, Step 454: train/loss = 0.6894091963768005, train/raw-loss = 0.6138858795166016, train/logprobs = tensor([[-0.0604, -0.4504],
        [-0.0937, -0.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07552334666252136
Epoch 0, Step 455: train/loss = 0.5940943956375122, train/raw-loss = 0.5230139493942261, train/logprobs = tensor([[-0.1064, -0.9681],
        [-0.1222, -0.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07108041644096375
Epoch 0, Step 456: train/loss = 0.7386414408683777, train/raw-loss = 0.6546204090118408, train/logprobs = tensor([[-0.2786, -0.4691],
        [-0.1567, -0.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08402105420827866
Epoch 0, Step 457: train/loss = 0.6484769582748413, train/raw-loss = 0.5625091195106506, train/logprobs = tensor([[-0.1059, -0.6821],
        [-0.1446, -0.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08596780896186829
Epoch 0, Step 458: train/loss = 0.6052688956260681, train/raw-loss = 0.5254086256027222, train/logprobs = tensor([[-0.0646, -1.3467],
        [-0.0845, -0.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07986022531986237
Epoch 0, Step 459: train/loss = 0.6671053171157837, train/raw-loss = 0.5830317735671997, train/logprobs = tensor([[-0.1075, -0.6334],
        [-0.1749, -0.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08407354354858398
Epoch 0, Step 460: train/loss = 0.6140908598899841, train/raw-loss = 0.5369197726249695, train/logprobs = tensor([[-0.1505, -1.3433],
        [-0.1659, -0.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07717107981443405
Epoch 0, Step 461: train/loss = 0.6919957399368286, train/raw-loss = 0.5972705483436584, train/logprobs = tensor([[-0.2576, -0.7071],
        [-0.1226, -0.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947251245379448
Epoch 0, Step 462: train/loss = 0.7002030611038208, train/raw-loss = 0.6320477724075317, train/logprobs = tensor([[-0.2196, -0.3984],
        [-0.1834, -0.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06815529614686966
Epoch 0, Step 463: train/loss = 0.6933128833770752, train/raw-loss = 0.6075513362884521, train/logprobs = tensor([[-0.0923, -0.3791],
        [-0.2000, -0.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08576156944036484
Epoch 0, Step 464: train/loss = 0.633455216884613, train/raw-loss = 0.5354041457176208, train/logprobs = tensor([[-0.1275, -1.5299],
        [-0.1266, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980510488152504
Epoch 0, Step 465: train/loss = 0.6915878057479858, train/raw-loss = 0.6276025772094727, train/logprobs = tensor([[-0.1090, -0.5145],
        [-0.1367, -0.2336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063985176384449
Epoch 0, Step 466: train/loss = 0.7193362712860107, train/raw-loss = 0.6479660868644714, train/logprobs = tensor([[-0.3402, -0.4983],
        [-0.1973, -0.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137012481689453
Epoch 0, Step 467: train/loss = 0.7063193917274475, train/raw-loss = 0.613132655620575, train/logprobs = tensor([[-0.1517, -0.6035],
        [-0.1255, -0.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318676590919495
Epoch 0, Step 468: train/loss = 0.5963478684425354, train/raw-loss = 0.4891369342803955, train/logprobs = tensor([[-0.1177, -1.2133],
        [-0.1733, -0.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10721094161272049
Epoch 0, Step 469: train/loss = 0.6927357912063599, train/raw-loss = 0.6371479630470276, train/logprobs = tensor([[-0.1164, -0.3542],
        [-0.1416, -0.1347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055587805807590485
Epoch 0, Step 470: train/loss = 0.6498473882675171, train/raw-loss = 0.5842499136924744, train/logprobs = tensor([[-0.0859, -0.7597],
        [-0.0950, -0.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06559757888317108
Epoch 0, Step 471: train/loss = 0.6208963990211487, train/raw-loss = 0.5120783448219299, train/logprobs = tensor([[-0.0631, -1.0060],
        [-0.1044, -0.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10881803929805756
Epoch 0, Step 472: train/loss = 0.6310505867004395, train/raw-loss = 0.5607872009277344, train/logprobs = tensor([[-0.1191, -1.0848],
        [-0.1462, -0.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07026335597038269
Epoch 0, Step 473: train/loss = 0.6051174402236938, train/raw-loss = 0.5165231823921204, train/logprobs = tensor([[-0.2277, -1.3670],
        [-0.1275, -0.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885942131280899
Epoch 0, Step 474: train/loss = 0.6116127967834473, train/raw-loss = 0.5490741729736328, train/logprobs = tensor([[-0.0834, -0.7834],
        [-0.1094, -0.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06253863871097565
Epoch 0, Step 475: train/loss = 0.6032173037528992, train/raw-loss = 0.49962976574897766, train/logprobs = tensor([[-0.1875, -1.3095],
        [-0.2240, -0.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358750820159912
Epoch 0, Step 476: train/loss = 0.7372997403144836, train/raw-loss = 0.6471647620201111, train/logprobs = tensor([[-0.1222, -0.2699],
        [-0.1124, -0.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09013499319553375
Epoch 0, Step 477: train/loss = 0.61164391040802, train/raw-loss = 0.5287854671478271, train/logprobs = tensor([[-0.0891, -1.6158],
        [-0.0624, -0.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08285842090845108
Epoch 0, Step 478: train/loss = 0.5626974105834961, train/raw-loss = 0.47598347067832947, train/logprobs = tensor([[-0.1674, -1.9255],
        [-0.1553, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08671391010284424
Epoch 0, Step 479: train/loss = 0.6907860040664673, train/raw-loss = 0.5667182207107544, train/logprobs = tensor([[-0.0390, -1.2005],
        [-0.0872, -0.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1240677535533905
Epoch 0, Step 480: train/loss = 0.7481690049171448, train/raw-loss = 0.679984986782074, train/logprobs = tensor([[-0.1890, -0.1744],
        [-0.2252, -0.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06818398833274841
Epoch 0, Step 481: train/loss = 0.5726971626281738, train/raw-loss = 0.46505269408226013, train/logprobs = tensor([[-0.2130, -2.6412],
        [-0.2306, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076444536447525
Epoch 0, Step 482: train/loss = 0.7143820524215698, train/raw-loss = 0.6459799408912659, train/logprobs = tensor([[-0.2299, -0.4434],
        [-0.1838, -0.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06840214878320694
Epoch 0, Step 483: train/loss = 0.6173744201660156, train/raw-loss = 0.5325707197189331, train/logprobs = tensor([[-0.0715, -1.6384],
        [-0.1031, -0.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08480371534824371
Epoch 0, Step 484: train/loss = 0.6540873646736145, train/raw-loss = 0.5575718879699707, train/logprobs = tensor([[-0.1153, -0.8422],
        [-0.1424, -0.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09651544690132141
Epoch 0, Step 485: train/loss = 0.5884990692138672, train/raw-loss = 0.4722248315811157, train/logprobs = tensor([[-0.2960, -2.9324],
        [-0.3074, -0.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11627423763275146
Epoch 0, Step 486: train/loss = 0.7259281873703003, train/raw-loss = 0.6331697702407837, train/logprobs = tensor([[-0.1695, -0.3245],
        [-0.1876, -0.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927584171295166
Epoch 0, Step 487: train/loss = 0.6778306365013123, train/raw-loss = 0.5721402168273926, train/logprobs = tensor([[-0.2415, -0.7066],
        [-0.3424, -0.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569041967391968
Epoch 0, Step 488: train/loss = 0.6074224710464478, train/raw-loss = 0.49869945645332336, train/logprobs = tensor([[-0.1922, -2.6247],
        [-0.2461, -0.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10872302949428558
Epoch 0, Step 489: train/loss = 0.6255070567131042, train/raw-loss = 0.521660327911377, train/logprobs = tensor([[-0.3110, -3.4696],
        [-0.2493, -0.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038467064499855
Epoch 0, Step 490: train/loss = 0.6990624070167542, train/raw-loss = 0.6137596964836121, train/logprobs = tensor([[-0.2188, -0.5914],
        [-0.1854, -0.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08530270308256149
Epoch 0, Step 491: train/loss = 0.6077260971069336, train/raw-loss = 0.5163379907608032, train/logprobs = tensor([[-0.1969, -2.6000],
        [-0.2478, -0.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09138811379671097
Epoch 0, Step 492: train/loss = 0.6091132164001465, train/raw-loss = 0.49900633096694946, train/logprobs = tensor([[-0.1646, -2.7599],
        [-0.1762, -0.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1101069301366806
Epoch 0, Step 493: train/loss = 0.681005597114563, train/raw-loss = 0.6057508587837219, train/logprobs = tensor([[-0.0823, -0.6211],
        [-0.0473, -0.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07525476813316345
Epoch 0, Step 494: train/loss = 0.7026504874229431, train/raw-loss = 0.611463189125061, train/logprobs = tensor([[-0.2758, -0.6330],
        [-0.1433, -0.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911872386932373
Epoch 0, Step 495: train/loss = 0.6215921640396118, train/raw-loss = 0.5226726531982422, train/logprobs = tensor([[-0.1486, -1.2907],
        [-0.1277, -0.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09891954809427261
Epoch 0, Step 496: train/loss = 0.646591305732727, train/raw-loss = 0.536597728729248, train/logprobs = tensor([[-0.1420, -1.3649],
        [-0.1637, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099935919046402
Epoch 0, Step 497: train/loss = 0.6845043301582336, train/raw-loss = 0.6071007251739502, train/logprobs = tensor([[-0.0856, -0.4774],
        [-0.0888, -0.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07740354537963867
Epoch 0, Step 498: train/loss = 0.6683310270309448, train/raw-loss = 0.5569472908973694, train/logprobs = tensor([[-0.1593, -0.6666],
        [-0.2202, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138375848531723
Epoch 0, Step 499: train/loss = 0.6078344583511353, train/raw-loss = 0.5098448395729065, train/logprobs = tensor([[-0.1751, -1.5431],
        [-0.1710, -0.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09798960387706757
Epoch 0, Step 500: train/loss = 0.6823614239692688, train/raw-loss = 0.5996458530426025, train/logprobs = tensor([[-0.2206, -1.0874],
        [-0.1883, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08271554857492447
Epoch 0, Step 501: train/loss = 0.5793190598487854, train/raw-loss = 0.45380446314811707, train/logprobs = tensor([[-0.1709, -2.0321],
        [-0.1444, -0.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12551456689834595
Epoch 0, Step 502: train/loss = 0.6770140528678894, train/raw-loss = 0.5783522725105286, train/logprobs = tensor([[-0.0997, -0.6840],
        [-0.1138, -0.1838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09866178035736084
Epoch 0, Step 503: train/loss = 0.7235589027404785, train/raw-loss = 0.6569705009460449, train/logprobs = tensor([[-0.0853, -0.1970],
        [-0.0897, -0.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0665884017944336
Epoch 0, Step 504: train/loss = 0.6050724387168884, train/raw-loss = 0.49135154485702515, train/logprobs = tensor([[-0.1170, -1.2407],
        [-0.1028, -0.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137208566069603
Epoch 0, Step 505: train/loss = 0.6203992366790771, train/raw-loss = 0.4992494583129883, train/logprobs = tensor([[-0.1717, -4.2653],
        [-0.1634, -2.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12114977836608887
Epoch 0, Step 506: train/loss = 0.7184193134307861, train/raw-loss = 0.6229203343391418, train/logprobs = tensor([[-0.1412, -0.5714],
        [-0.1135, -0.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09549892693758011
Epoch 0, Step 507: train/loss = 0.6206402778625488, train/raw-loss = 0.5067707300186157, train/logprobs = tensor([[-0.1884, -2.9065],
        [-0.0954, -0.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11386953294277191
Epoch 0, Step 508: train/loss = 0.6682177782058716, train/raw-loss = 0.5911307334899902, train/logprobs = tensor([[-0.1903, -0.4813],
        [-0.2420, -0.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07708705961704254
Epoch 0, Step 509: train/loss = 0.7009077072143555, train/raw-loss = 0.6051519513130188, train/logprobs = tensor([[-0.1121, -0.6626],
        [-0.1162, -0.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09575574100017548
Epoch 0, Step 510: train/loss = 0.6647490859031677, train/raw-loss = 0.5433536171913147, train/logprobs = tensor([[-0.2320, -1.4902],
        [-0.2034, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12139545381069183
Epoch 0, Step 511: train/loss = 0.6714991331100464, train/raw-loss = 0.573715329170227, train/logprobs = tensor([[-0.2125, -0.9378],
        [-0.1018, -0.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09778381139039993
Epoch 0, Step 512: train/loss = 0.6293048858642578, train/raw-loss = 0.5330033898353577, train/logprobs = tensor([[-0.1564, -0.7297],
        [-0.3449, -0.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09630151838064194
Epoch 0, Step 513: train/loss = 0.5973376035690308, train/raw-loss = 0.5091533660888672, train/logprobs = tensor([[-0.1105, -1.5785],
        [-0.1326, -0.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08818426728248596
Epoch 0, Step 514: train/loss = 0.6102309823036194, train/raw-loss = 0.4871683418750763, train/logprobs = tensor([[-0.2467, -2.9546],
        [-0.1504, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306264042854309
Epoch 0, Step 515: train/loss = 0.7435375452041626, train/raw-loss = 0.6889479756355286, train/logprobs = tensor([[-0.0682, -0.1040],
        [-0.0670, -0.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05458962172269821
Epoch 0, Step 516: train/loss = 0.6429189443588257, train/raw-loss = 0.5223133563995361, train/logprobs = tensor([[-0.3428, -1.4705],
        [-0.1715, -0.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060557305812836
Epoch 0, Step 517: train/loss = 0.6694893836975098, train/raw-loss = 0.5687040686607361, train/logprobs = tensor([[-0.1156, -0.6314],
        [-0.1509, -0.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078530013561249
Epoch 0, Step 518: train/loss = 0.5566956996917725, train/raw-loss = 0.457536906003952, train/logprobs = tensor([[-0.1514, -3.1727],
        [-0.2080, -0.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09915879368782043
Epoch 0, Step 519: train/loss = 0.612288773059845, train/raw-loss = 0.47864189743995667, train/logprobs = tensor([[-0.2846, -1.6127],
        [-0.2544, -0.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364684581756592
Epoch 0, Step 520: train/loss = 0.7647991180419922, train/raw-loss = 0.6541664600372314, train/logprobs = tensor([[-0.2191, -0.4923],
        [-0.0498, -0.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11063265800476074
Epoch 0, Step 521: train/loss = 0.6347862482070923, train/raw-loss = 0.5231895446777344, train/logprobs = tensor([[-0.0418, -1.1581],
        [-0.0847, -0.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11159671097993851
Epoch 0, Step 522: train/loss = 0.7217260003089905, train/raw-loss = 0.5901410579681396, train/logprobs = tensor([[-0.7399, -2.0026],
        [-0.2307, -0.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13158497214317322
Epoch 0, Step 523: train/loss = 0.6737966537475586, train/raw-loss = 0.5832557678222656, train/logprobs = tensor([[-0.1181, -0.9007],
        [-0.1221, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09054091572761536
Epoch 0, Step 524: train/loss = 0.5702507495880127, train/raw-loss = 0.42788469791412354, train/logprobs = tensor([[-0.0823, -3.9282],
        [-0.1350, -0.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14236608147621155
Epoch 0, Step 525: train/loss = 0.6718727350234985, train/raw-loss = 0.5859817266464233, train/logprobs = tensor([[-0.1772, -0.6833],
        [-0.1877, -0.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0858910009264946
Epoch 0, Step 526: train/loss = 0.6861770749092102, train/raw-loss = 0.5497213006019592, train/logprobs = tensor([[-0.0795, -0.9266],
        [-0.0959, -0.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364557445049286
Epoch 0, Step 527: train/loss = 0.533814549446106, train/raw-loss = 0.4212278127670288, train/logprobs = tensor([[-0.1494, -1.9901],
        [-0.1735, -0.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258674412965775
Epoch 0, Step 528: train/loss = 0.6544827222824097, train/raw-loss = 0.5187901258468628, train/logprobs = tensor([[-0.0928, -3.2465],
        [-0.0985, -1.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356925368309021
Epoch 0, Step 529: train/loss = 0.595754861831665, train/raw-loss = 0.48476582765579224, train/logprobs = tensor([[-0.1503, -3.5058],
        [-0.1355, -0.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098901927471161
Epoch 0, Step 530: train/loss = 0.6298063397407532, train/raw-loss = 0.5503507256507874, train/logprobs = tensor([[-0.0822, -0.9336],
        [-0.1690, -0.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07945562154054642
Epoch 0, Step 531: train/loss = 0.6920017004013062, train/raw-loss = 0.5995453596115112, train/logprobs = tensor([[-0.0827, -0.6815],
        [-0.0906, -0.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09245625883340836
Epoch 0, Step 532: train/loss = 0.6282326579093933, train/raw-loss = 0.5535398721694946, train/logprobs = tensor([[-0.1423, -1.6276],
        [-0.1999, -0.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07469280064105988
Epoch 0, Step 533: train/loss = 0.6970875859260559, train/raw-loss = 0.5721933841705322, train/logprobs = tensor([[-0.2406, -2.1367],
        [-0.2365, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489418685436249
Epoch 0, Step 534: train/loss = 0.7143409848213196, train/raw-loss = 0.6086876392364502, train/logprobs = tensor([[-0.1221, -1.1541],
        [-0.1647, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056533232331276
Epoch 0, Step 535: train/loss = 0.5903462767601013, train/raw-loss = 0.4526815414428711, train/logprobs = tensor([[-0.3075, -2.4639],
        [-0.1668, -0.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376647651195526
Epoch 0, Step 536: train/loss = 0.5636131167411804, train/raw-loss = 0.457316130399704, train/logprobs = tensor([[-0.1625, -1.4269],
        [-0.1822, -0.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10629695653915405
Epoch 0, Step 537: train/loss = 0.624046802520752, train/raw-loss = 0.5105554461479187, train/logprobs = tensor([[-0.3522, -1.2446],
        [-0.3603, -0.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11349136382341385
Epoch 0, Step 538: train/loss = 0.6974906921386719, train/raw-loss = 0.5762948989868164, train/logprobs = tensor([[-0.2469, -1.1387],
        [-0.2098, -0.3987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12119574844837189
Epoch 0, Step 539: train/loss = 0.6210107207298279, train/raw-loss = 0.5166332721710205, train/logprobs = tensor([[-0.1242, -1.9164],
        [-0.1485, -0.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10437750816345215
Epoch 0, Step 540: train/loss = 0.6614557504653931, train/raw-loss = 0.5500879287719727, train/logprobs = tensor([[-0.1900, -1.1996],
        [-0.1132, -0.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11136780679225922
Epoch 0, Step 541: train/loss = 0.5616505742073059, train/raw-loss = 0.45414304733276367, train/logprobs = tensor([[-0.2386, -3.0635],
        [-0.2147, -0.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10750749707221985
Epoch 0, Step 542: train/loss = 0.6008116006851196, train/raw-loss = 0.475233793258667, train/logprobs = tensor([[-0.2274, -1.4856],
        [-0.1716, -0.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12557776272296906
Epoch 0, Step 543: train/loss = 0.5658382177352905, train/raw-loss = 0.42935246229171753, train/logprobs = tensor([[-0.1931, -2.7464],
        [-0.2359, -0.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364857703447342
Epoch 0, Step 544: train/loss = 0.6565755605697632, train/raw-loss = 0.5658837556838989, train/logprobs = tensor([[-0.1687, -0.7539],
        [-0.1891, -0.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09069183468818665
Epoch 0, Step 545: train/loss = 0.650773286819458, train/raw-loss = 0.5113422274589539, train/logprobs = tensor([[-0.2477, -1.8270],
        [-0.2457, -0.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13943104445934296
Epoch 0, Step 546: train/loss = 0.6002681851387024, train/raw-loss = 0.49239760637283325, train/logprobs = tensor([[-0.2269, -1.2613],
        [-0.2489, -0.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787057876586914
Epoch 0, Step 547: train/loss = 0.6118324995040894, train/raw-loss = 0.492310106754303, train/logprobs = tensor([[-0.2203, -2.6891],
        [-0.2481, -0.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11952241510152817
Epoch 0, Step 548: train/loss = 0.6960943937301636, train/raw-loss = 0.5890578031539917, train/logprobs = tensor([[-0.1298, -0.6632],
        [-0.1679, -0.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10703666508197784
Epoch 0, Step 549: train/loss = 0.6897691488265991, train/raw-loss = 0.5816875696182251, train/logprobs = tensor([[-0.4454, -0.6422],
        [-0.4365, -0.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1080816239118576
Epoch 0, Step 550: train/loss = 0.53628009557724, train/raw-loss = 0.4009469747543335, train/logprobs = tensor([[-0.3559, -2.9957],
        [-0.2715, -0.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1353331208229065
Epoch 0, Step 551: train/loss = 0.6246945858001709, train/raw-loss = 0.5360783338546753, train/logprobs = tensor([[-0.0742, -0.6122],
        [-0.2987, -0.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08861619234085083
Epoch 0, Step 552: train/loss = 0.6424459218978882, train/raw-loss = 0.4696390628814697, train/logprobs = tensor([[-0.3194, -2.1866],
        [-0.2624, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17280688881874084
Epoch 0, Step 553: train/loss = 0.6642006039619446, train/raw-loss = 0.5339503884315491, train/logprobs = tensor([[-0.1138, -2.3202],
        [-0.1364, -1.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302502155303955
Epoch 0, Step 554: train/loss = 0.5461552143096924, train/raw-loss = 0.4400501847267151, train/logprobs = tensor([[-0.0954, -1.8219],
        [-0.1115, -0.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610505938529968
Epoch 0, Step 555: train/loss = 0.5466466546058655, train/raw-loss = 0.4303749203681946, train/logprobs = tensor([[-0.3063, -2.4815],
        [-0.2555, -0.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11627170443534851
Epoch 0, Step 556: train/loss = 0.5487297773361206, train/raw-loss = 0.4106174409389496, train/logprobs = tensor([[-0.1181, -2.8692],
        [-0.1610, -0.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13811235129833221
Epoch 0, Step 557: train/loss = 0.6628462672233582, train/raw-loss = 0.5110110640525818, train/logprobs = tensor([[-0.4321, -2.5403],
        [-0.3159, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15183517336845398
Epoch 0, Step 558: train/loss = 0.7052815556526184, train/raw-loss = 0.6206851005554199, train/logprobs = tensor([[-0.2692, -0.5504],
        [-0.2096, -0.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08459646254777908
Epoch 0, Step 559: train/loss = 0.622801661491394, train/raw-loss = 0.5063165426254272, train/logprobs = tensor([[-0.2579, -1.3659],
        [-0.2161, -0.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1164851039648056
Epoch 0, Step 560: train/loss = 0.6607677340507507, train/raw-loss = 0.5557411313056946, train/logprobs = tensor([[-0.1273, -1.0422],
        [-0.1136, -0.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10502657294273376
Epoch 0, Step 561: train/loss = 0.6360518932342529, train/raw-loss = 0.5444545745849609, train/logprobs = tensor([[-0.2895, -1.1369],
        [-0.3197, -0.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0915973111987114
Epoch 0, Step 562: train/loss = 0.6026861071586609, train/raw-loss = 0.49781423807144165, train/logprobs = tensor([[-0.2602, -2.7011],
        [-0.2043, -0.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10487187653779984
Epoch 0, Step 563: train/loss = 0.60724276304245, train/raw-loss = 0.5040876865386963, train/logprobs = tensor([[-0.1772, -1.9176],
        [-0.1403, -0.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10315503925085068
Epoch 0, Step 564: train/loss = 0.6566929221153259, train/raw-loss = 0.5539805889129639, train/logprobs = tensor([[-0.1307, -0.8076],
        [-0.1501, -0.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271227359771729
Epoch 0, Step 565: train/loss = 0.6553853750228882, train/raw-loss = 0.5329031348228455, train/logprobs = tensor([[-0.3635, -1.0022],
        [-0.4354, -0.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12248219549655914
Epoch 0, Step 566: train/loss = 0.6175076365470886, train/raw-loss = 0.48970162868499756, train/logprobs = tensor([[-0.2774, -5.1283],
        [-0.1925, -2.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12780599296092987
Epoch 0, Step 567: train/loss = 0.6019480228424072, train/raw-loss = 0.49370938539505005, train/logprobs = tensor([[-0.3418, -1.5735],
        [-0.2829, -0.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10823868215084076
Epoch 0, Step 568: train/loss = 0.6346207857131958, train/raw-loss = 0.5411708354949951, train/logprobs = tensor([[-0.0973, -1.7004],
        [-0.2071, -0.1927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09344996511936188
Epoch 0, Step 569: train/loss = 0.6538354158401489, train/raw-loss = 0.5226417183876038, train/logprobs = tensor([[-0.2174, -1.1534],
        [-0.2515, -0.3189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13119372725486755
Epoch 0, Step 570: train/loss = 0.84217369556427, train/raw-loss = 0.7410839796066284, train/logprobs = tensor([[-0.9444, -1.2751],
        [-0.1571, -0.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10108979046344757
Epoch 0, Step 571: train/loss = 0.7120769619941711, train/raw-loss = 0.5663033127784729, train/logprobs = tensor([[-0.2927, -2.3805],
        [-0.3176, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14577364921569824
Epoch 0, Step 572: train/loss = 0.6408891677856445, train/raw-loss = 0.5049585103988647, train/logprobs = tensor([[-0.1110, -1.4077],
        [-0.1270, -0.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13593068718910217
Epoch 0, Step 573: train/loss = 0.5686032176017761, train/raw-loss = 0.4498351812362671, train/logprobs = tensor([[-0.1511, -1.7693],
        [-0.1691, -0.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876799911260605
Epoch 0, Step 574: train/loss = 0.6820593476295471, train/raw-loss = 0.5697883367538452, train/logprobs = tensor([[-0.1397, -0.6645],
        [-0.2412, -0.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227108538150787
Epoch 0, Step 575: train/loss = 0.5929832458496094, train/raw-loss = 0.4990476369857788, train/logprobs = tensor([[-0.0807, -2.4579],
        [-0.1194, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09393559396266937
Epoch 0, Step 576: train/loss = 0.7120360136032104, train/raw-loss = 0.5905050039291382, train/logprobs = tensor([[-0.3217, -0.7792],
        [-0.2783, -0.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12153097987174988
Epoch 0, Step 577: train/loss = 0.7477806210517883, train/raw-loss = 0.6146805286407471, train/logprobs = tensor([[-0.2880, -0.7204],
        [-0.2508, -0.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13310007750988007
Epoch 0, Step 578: train/loss = 0.5697857737541199, train/raw-loss = 0.4501456320285797, train/logprobs = tensor([[-0.2183, -2.4566],
        [-0.3034, -0.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11964009702205658
Epoch 0, Step 579: train/loss = 0.5279049873352051, train/raw-loss = 0.43196094036102295, train/logprobs = tensor([[-0.1462, -4.0429],
        [-0.2051, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09594406187534332
Epoch 0, Step 580: train/loss = 0.5261135101318359, train/raw-loss = 0.4187391400337219, train/logprobs = tensor([[-0.0987, -3.1487],
        [-0.2475, -0.1104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073744148015976
Epoch 0, Step 581: train/loss = 0.5208367109298706, train/raw-loss = 0.42201486229896545, train/logprobs = tensor([[-0.1653, -5.0165],
        [-0.1869, -0.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09882187843322754
Epoch 0, Step 582: train/loss = 0.6928020119667053, train/raw-loss = 0.5693497657775879, train/logprobs = tensor([[-0.3337, -1.0859],
        [-0.2359, -0.2173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12345222383737564
Epoch 0, Step 583: train/loss = 0.6869436502456665, train/raw-loss = 0.574700117111206, train/logprobs = tensor([[-0.1168, -0.7091],
        [-0.1432, -0.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11224359273910522
Epoch 0, Step 584: train/loss = 0.607528567314148, train/raw-loss = 0.52106773853302, train/logprobs = tensor([[-0.1160, -1.1488],
        [-0.1710, -0.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646079897880554
Epoch 0, Step 585: train/loss = 0.6588309407234192, train/raw-loss = 0.566779613494873, train/logprobs = tensor([[-0.1018, -0.9500],
        [-0.1625, -0.1152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09205131977796555
Epoch 0, Step 586: train/loss = 0.6376513838768005, train/raw-loss = 0.5218534469604492, train/logprobs = tensor([[-0.1617, -1.2021],
        [-0.2035, -0.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579792946577072
Epoch 0, Step 587: train/loss = 0.6766608953475952, train/raw-loss = 0.5560650825500488, train/logprobs = tensor([[-0.4118, -1.0094],
        [-0.3048, -0.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12059581279754639
Epoch 0, Step 588: train/loss = 0.6359484195709229, train/raw-loss = 0.502949595451355, train/logprobs = tensor([[-0.5311, -4.0358],
        [-0.3382, -0.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13299880921840668
Epoch 0, Step 589: train/loss = 0.5844851732254028, train/raw-loss = 0.4832395017147064, train/logprobs = tensor([[-0.2159, -2.0507],
        [-0.1746, -0.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10124564170837402
Epoch 0, Step 590: train/loss = 0.5389801263809204, train/raw-loss = 0.39783716201782227, train/logprobs = tensor([[-0.2118, -2.0147],
        [-0.2707, -0.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14114294946193695
Epoch 0, Step 591: train/loss = 0.7150474786758423, train/raw-loss = 0.6533104181289673, train/logprobs = tensor([[-0.0901, -0.3143],
        [-0.0730, -0.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06173710525035858
Epoch 0, Step 592: train/loss = 0.6568058729171753, train/raw-loss = 0.543371319770813, train/logprobs = tensor([[-0.2163, -0.9662],
        [-0.1658, -0.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1134345531463623
Epoch 0, Step 593: train/loss = 0.5812825560569763, train/raw-loss = 0.4620963931083679, train/logprobs = tensor([[-0.1376, -1.8233],
        [-0.1711, -0.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11918618530035019
Epoch 0, Step 594: train/loss = 0.5875953435897827, train/raw-loss = 0.4430137872695923, train/logprobs = tensor([[-0.1555, -1.4876],
        [-0.1984, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.144581601023674
Epoch 0, Step 595: train/loss = 0.6943374872207642, train/raw-loss = 0.5950290560722351, train/logprobs = tensor([[-0.0830, -1.0876],
        [-0.1063, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930837154388428
Epoch 0, Step 596: train/loss = 0.5793046951293945, train/raw-loss = 0.482252299785614, train/logprobs = tensor([[-0.2495, -3.2553],
        [-0.3439, -0.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09705241769552231
Epoch 0, Step 597: train/loss = 0.7048916220664978, train/raw-loss = 0.6210169792175293, train/logprobs = tensor([[-0.3688, -0.4296],
        [-0.3780, -0.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838746577501297
Epoch 0, Step 598: train/loss = 0.5777341723442078, train/raw-loss = 0.4474438428878784, train/logprobs = tensor([[-0.1783, -1.5438],
        [-0.2111, -0.0929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13029032945632935
Epoch 0, Step 599: train/loss = 0.5911750793457031, train/raw-loss = 0.471109002828598, train/logprobs = tensor([[-0.1576, -2.4947],
        [-0.1857, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12006603181362152
Epoch 0, Step 600: train/loss = 0.6409938335418701, train/raw-loss = 0.5164931416511536, train/logprobs = tensor([[-0.1985, -1.4740],
        [-0.2143, -0.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450065463781357
Epoch 0, Step 601: train/loss = 0.6469473838806152, train/raw-loss = 0.5357584953308105, train/logprobs = tensor([[-0.3675, -1.0646],
        [-0.3920, -0.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11118882894515991
Epoch 0, Step 602: train/loss = 0.701629102230072, train/raw-loss = 0.588030219078064, train/logprobs = tensor([[-0.4212, -1.4862],
        [-0.2375, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359889805316925
Epoch 0, Step 603: train/loss = 0.5461764335632324, train/raw-loss = 0.4188610911369324, train/logprobs = tensor([[-0.1358, -4.2841],
        [-0.2071, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12731540203094482
Epoch 0, Step 604: train/loss = 0.708167552947998, train/raw-loss = 0.6217049360275269, train/logprobs = tensor([[-0.1156, -0.3845],
        [-0.1646, -0.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646254241466522
Epoch 0, Step 605: train/loss = 0.7232271432876587, train/raw-loss = 0.5993010997772217, train/logprobs = tensor([[-0.3153, -0.5266],
        [-0.3074, -0.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1239260733127594
Epoch 0, Step 606: train/loss = 0.5884192585945129, train/raw-loss = 0.47887521982192993, train/logprobs = tensor([[-0.2080, -1.3574],
        [-0.2098, -0.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954400897026062
Epoch 0, Step 607: train/loss = 0.6362266540527344, train/raw-loss = 0.49186134338378906, train/logprobs = tensor([[-0.1714, -1.6148],
        [-0.2267, -0.5038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14436526596546173
Epoch 0, Step 608: train/loss = 0.6224638819694519, train/raw-loss = 0.4926917254924774, train/logprobs = tensor([[-0.4139, -1.3710],
        [-0.4944, -0.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1297721415758133
Epoch 0, Step 609: train/loss = 0.5666070580482483, train/raw-loss = 0.4420293867588043, train/logprobs = tensor([[-0.2981, -3.9938],
        [-0.3692, -0.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12457767128944397
Epoch 0, Step 610: train/loss = 0.4998294711112976, train/raw-loss = 0.3598586320877075, train/logprobs = tensor([[-0.5066, -4.6665],
        [-0.4906, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1399708092212677
Epoch 0, Step 611: train/loss = 0.5097699165344238, train/raw-loss = 0.3819159269332886, train/logprobs = tensor([[-0.1803, -2.3320],
        [-0.3035, -0.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12785395979881287
Epoch 0, Step 612: train/loss = 0.6228145956993103, train/raw-loss = 0.5218727588653564, train/logprobs = tensor([[-0.1996, -2.2629],
        [-0.3415, -0.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10094187408685684
Epoch 0, Step 613: train/loss = 0.7145732641220093, train/raw-loss = 0.6167594194412231, train/logprobs = tensor([[-0.2666, -0.4921],
        [-0.2994, -0.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09781379252672195
Epoch 0, Step 614: train/loss = 0.6144335269927979, train/raw-loss = 0.5094126462936401, train/logprobs = tensor([[-0.2944, -1.2960],
        [-0.3229, -0.2857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1050209105014801
Epoch 0, Step 615: train/loss = 0.6449973583221436, train/raw-loss = 0.521976113319397, train/logprobs = tensor([[-0.2151, -1.0245],
        [-0.2951, -0.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12302125990390778
Epoch 0, Step 616: train/loss = 0.7452588081359863, train/raw-loss = 0.6503623723983765, train/logprobs = tensor([[-0.1190, -0.3917],
        [-0.1590, -0.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09489646553993225
Epoch 0, Step 617: train/loss = 0.6449371576309204, train/raw-loss = 0.5022141337394714, train/logprobs = tensor([[-0.2872, -3.9405],
        [-0.4117, -0.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14272303879261017
Epoch 0, Step 618: train/loss = 0.6011128425598145, train/raw-loss = 0.48633429408073425, train/logprobs = tensor([[-0.1317, -1.1661],
        [-0.2782, -0.1546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114778533577919
Epoch 0, Step 619: train/loss = 0.5174761414527893, train/raw-loss = 0.4006994664669037, train/logprobs = tensor([[-0.0959, -2.4940],
        [-0.1988, -0.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677663773298264
Epoch 0, Step 620: train/loss = 0.5767988562583923, train/raw-loss = 0.4642050266265869, train/logprobs = tensor([[-0.3661, -1.8553],
        [-0.3489, -0.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11259377747774124
Epoch 0, Step 621: train/loss = 0.7514203190803528, train/raw-loss = 0.6425251960754395, train/logprobs = tensor([[-0.1293, -0.2839],
        [-0.1872, -0.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889516770839691
Epoch 0, Step 622: train/loss = 0.5821034908294678, train/raw-loss = 0.4805191159248352, train/logprobs = tensor([[-0.0609, -2.6364],
        [-0.1796, -0.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10158438235521317
Epoch 0, Step 623: train/loss = 0.5717741250991821, train/raw-loss = 0.45692235231399536, train/logprobs = tensor([[-0.1555, -3.6144],
        [-0.1993, -0.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485172808170319
Epoch 0, Step 624: train/loss = 0.5876636505126953, train/raw-loss = 0.48771172761917114, train/logprobs = tensor([[-0.1220, -2.0846],
        [-0.1955, -0.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995190799236298
Epoch 0, Step 625: train/loss = 0.5939624309539795, train/raw-loss = 0.46784406900405884, train/logprobs = tensor([[-0.4155, -2.9546],
        [-0.3862, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12611836194992065
Epoch 0, Step 626: train/loss = 0.6468772292137146, train/raw-loss = 0.5306400060653687, train/logprobs = tensor([[-0.1345, -1.3913],
        [-0.1067, -0.3391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11623728275299072
Epoch 0, Step 627: train/loss = 0.6330057382583618, train/raw-loss = 0.5301523208618164, train/logprobs = tensor([[-0.0977, -1.0881],
        [-0.1612, -0.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10285346210002899
Epoch 0, Step 628: train/loss = 0.6487229466438293, train/raw-loss = 0.5342172980308533, train/logprobs = tensor([[-0.1591, -0.9036],
        [-0.2861, -0.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11450566351413727
Epoch 0, Step 629: train/loss = 0.6972280740737915, train/raw-loss = 0.5790210366249084, train/logprobs = tensor([[-0.0903, -0.6973],
        [-0.1611, -0.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11820700764656067
Epoch 0, Step 630: train/loss = 0.5780830979347229, train/raw-loss = 0.44397619366645813, train/logprobs = tensor([[-0.1230, -2.1276],
        [-0.1880, -0.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13410688936710358
Epoch 0, Step 631: train/loss = 0.47259026765823364, train/raw-loss = 0.3313125669956207, train/logprobs = tensor([[-0.1963, -3.5178],
        [-0.4141, -0.2989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1412777304649353
Epoch 0, Step 632: train/loss = 0.6136046648025513, train/raw-loss = 0.5011354684829712, train/logprobs = tensor([[-0.1485, -1.4100],
        [-0.2145, -0.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246924102306366
Epoch 0, Step 633: train/loss = 0.6639130115509033, train/raw-loss = 0.5356984734535217, train/logprobs = tensor([[-0.3709, -2.7279],
        [-0.2896, -1.1782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282145082950592
Epoch 0, Step 634: train/loss = 0.5860779881477356, train/raw-loss = 0.4506893754005432, train/logprobs = tensor([[-0.4004, -1.7718],
        [-0.4159, -0.2982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1353885978460312
Epoch 0, Step 635: train/loss = 0.5562033653259277, train/raw-loss = 0.43971043825149536, train/logprobs = tensor([[-0.1620, -3.3119],
        [-0.2334, -0.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11649294197559357
Epoch 0, Step 636: train/loss = 0.579988956451416, train/raw-loss = 0.48160889744758606, train/logprobs = tensor([[-0.1381, -1.9713],
        [-0.2448, -0.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09838001430034637
Epoch 0, Step 637: train/loss = 0.5874395370483398, train/raw-loss = 0.4748418927192688, train/logprobs = tensor([[-0.2027, -2.4004],
        [-0.2905, -0.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11259761452674866
Epoch 0, Step 638: train/loss = 0.6947177052497864, train/raw-loss = 0.6173953413963318, train/logprobs = tensor([[-0.0809, -0.5648],
        [-0.0918, -0.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773223266005516
Epoch 0, Step 639: train/loss = 0.6330788135528564, train/raw-loss = 0.4859486520290375, train/logprobs = tensor([[-0.4617, -2.4067],
        [-0.3053, -0.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471301019191742
Epoch 0, Step 640: train/loss = 0.7270213961601257, train/raw-loss = 0.5892651081085205, train/logprobs = tensor([[-0.5892, -2.7458],
        [-0.1503, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13775630295276642
Epoch 0, Step 641: train/loss = 0.7090098857879639, train/raw-loss = 0.592885434627533, train/logprobs = tensor([[-0.5690, -1.9457],
        [-0.4241, -0.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1161244660615921
Epoch 0, Step 642: train/loss = 0.5913451910018921, train/raw-loss = 0.47095662355422974, train/logprobs = tensor([[-0.2684, -1.4091],
        [-0.3201, -0.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038859724998474
Epoch 0, Step 643: train/loss = 0.48308855295181274, train/raw-loss = 0.365540474653244, train/logprobs = tensor([[-0.1309, -3.7699],
        [-0.2054, -0.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754810810089111
Epoch 0, Step 644: train/loss = 0.7040445804595947, train/raw-loss = 0.589457094669342, train/logprobs = tensor([[-0.5126, -0.8132],
        [-0.4927, -0.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458750069141388
Epoch 0, Step 645: train/loss = 0.6136390566825867, train/raw-loss = 0.47578492760658264, train/logprobs = tensor([[-0.2164, -3.2057],
        [-0.2746, -0.0603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13785414397716522
Epoch 0, Step 646: train/loss = 0.7209872007369995, train/raw-loss = 0.5995612144470215, train/logprobs = tensor([[-0.1875, -0.6264],
        [-0.2330, -0.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12142594903707504
Epoch 0, Step 647: train/loss = 0.6317095756530762, train/raw-loss = 0.5203182697296143, train/logprobs = tensor([[-0.1067, -1.2822],
        [-0.2758, -0.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139123886823654
Epoch 0, Step 648: train/loss = 0.5559984445571899, train/raw-loss = 0.45099228620529175, train/logprobs = tensor([[-0.1132, -3.3948],
        [-0.2643, -0.5302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10500616580247879
Epoch 0, Step 649: train/loss = 0.44205746054649353, train/raw-loss = 0.3090285062789917, train/logprobs = tensor([[-0.0887, -4.1891],
        [-0.3947, -0.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1330289989709854
Epoch 0, Step 650: train/loss = 0.5379844307899475, train/raw-loss = 0.41004258394241333, train/logprobs = tensor([[-0.1729, -2.9813],
        [-0.2918, -0.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12794189155101776
Epoch 0, Step 651: train/loss = 0.5064215660095215, train/raw-loss = 0.35826507210731506, train/logprobs = tensor([[-0.2617, -2.5163],
        [-0.4354, -0.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14815649390220642
Epoch 0, Step 652: train/loss = 0.496642529964447, train/raw-loss = 0.3841264843940735, train/logprobs = tensor([[-0.1524, -4.9496],
        [-0.4267, -0.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11251607537269592
Epoch 0, Step 653: train/loss = 0.6602606177330017, train/raw-loss = 0.54642254114151, train/logprobs = tensor([[-0.3599, -1.3594],
        [-0.4028, -0.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11383813619613647
Epoch 0, Step 654: train/loss = 0.6454380750656128, train/raw-loss = 0.5732856392860413, train/logprobs = tensor([[-0.0732, -1.1995],
        [-0.1825, -0.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07215243577957153
Epoch 0, Step 655: train/loss = 0.6364946961402893, train/raw-loss = 0.4775332808494568, train/logprobs = tensor([[-0.2842, -1.6662],
        [-0.3987, -0.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589614301919937
Epoch 0, Step 656: train/loss = 0.4483567476272583, train/raw-loss = 0.3046456277370453, train/logprobs = tensor([[-0.5147, -6.7925],
        [-0.6579, -0.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.143711119890213
Epoch 0, Step 657: train/loss = 0.49954143166542053, train/raw-loss = 0.370442271232605, train/logprobs = tensor([[-0.2126, -4.9569],
        [-0.3022, -0.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12909914553165436
Epoch 0, Step 658: train/loss = 0.5803570747375488, train/raw-loss = 0.4788559675216675, train/logprobs = tensor([[-0.2529, -1.8836],
        [-0.3534, -0.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10150106996297836
Epoch 0, Step 659: train/loss = 0.4913847744464874, train/raw-loss = 0.34225353598594666, train/logprobs = tensor([[-0.2102, -2.3717],
        [-0.2678, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14913125336170197
Epoch 0, Step 660: train/loss = 0.6595914363861084, train/raw-loss = 0.5747661590576172, train/logprobs = tensor([[-0.2353, -0.8686],
        [-0.2347, -0.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0848253145813942
Epoch 0, Step 661: train/loss = 0.5734866857528687, train/raw-loss = 0.4583756923675537, train/logprobs = tensor([[-0.0586, -1.8152],
        [-0.1486, -0.3024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11511094868183136
Epoch 0, Step 662: train/loss = 0.6904508471488953, train/raw-loss = 0.5997787117958069, train/logprobs = tensor([[-0.0595, -0.5267],
        [-0.2051, -0.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906720906496048
Epoch 0, Step 663: train/loss = 0.5294061899185181, train/raw-loss = 0.40259772539138794, train/logprobs = tensor([[-0.4454, -3.7708],
        [-0.4568, -0.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12680846452713013
Epoch 0, Step 664: train/loss = 0.6547712683677673, train/raw-loss = 0.5369189977645874, train/logprobs = tensor([[-0.1610, -1.0709],
        [-0.2192, -0.3616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785233020782471
Epoch 0, Step 665: train/loss = 0.7434349656105042, train/raw-loss = 0.6101399064064026, train/logprobs = tensor([[-0.3778, -0.6806],
        [-0.3212, -0.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329508900642395
Epoch 0, Step 666: train/loss = 0.5817407369613647, train/raw-loss = 0.45963484048843384, train/logprobs = tensor([[-0.1382, -1.9186],
        [-0.3993, -0.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12210595607757568
Epoch 0, Step 667: train/loss = 0.5825656652450562, train/raw-loss = 0.46791404485702515, train/logprobs = tensor([[-0.2921, -2.2505],
        [-0.5011, -0.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114651620388031
Epoch 0, Step 668: train/loss = 0.6916682124137878, train/raw-loss = 0.5954511165618896, train/logprobs = tensor([[-0.2759, -0.5868],
        [-0.3702, -0.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09621710330247879
Epoch 0, Step 669: train/loss = 0.5087952017784119, train/raw-loss = 0.39095407724380493, train/logprobs = tensor([[-0.2029, -2.3869],
        [-0.4615, -0.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784115433692932
Epoch 0, Step 670: train/loss = 0.4778692126274109, train/raw-loss = 0.3843531906604767, train/logprobs = tensor([[-0.0706, -2.9414],
        [-0.3204, -0.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935160368680954
Epoch 0, Step 671: train/loss = 0.5523011088371277, train/raw-loss = 0.4434437155723572, train/logprobs = tensor([[-0.3151, -2.1140],
        [-0.2472, -0.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088574230670929
Epoch 0, Step 672: train/loss = 0.5936974287033081, train/raw-loss = 0.48447442054748535, train/logprobs = tensor([[-0.0686, -1.7555],
        [-0.1827, -0.3366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10922297835350037
Epoch 0, Step 673: train/loss = 0.6578117609024048, train/raw-loss = 0.5409416556358337, train/logprobs = tensor([[-0.1452, -1.7707],
        [-0.5252, -0.2868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11687012016773224
Epoch 0, Step 674: train/loss = 0.5897754430770874, train/raw-loss = 0.4872114360332489, train/logprobs = tensor([[-0.0874, -1.2704],
        [-0.3584, -0.4618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10256394743919373
Epoch 0, Step 675: train/loss = 0.6506174802780151, train/raw-loss = 0.5269179344177246, train/logprobs = tensor([[-0.1214, -1.0526],
        [-0.2701, -0.3562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12369947880506516
Epoch 0, Step 676: train/loss = 0.4995588958263397, train/raw-loss = 0.3726174831390381, train/logprobs = tensor([[-0.2300, -5.6961],
        [-0.3381, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12694142758846283
Epoch 0, Step 677: train/loss = 0.594768762588501, train/raw-loss = 0.4841786324977875, train/logprobs = tensor([[-0.0944, -1.6221],
        [-0.1815, -0.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11059010028839111
Epoch 0, Step 678: train/loss = 0.5352594256401062, train/raw-loss = 0.41634446382522583, train/logprobs = tensor([[-0.2348, -4.5061],
        [-0.3888, -1.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11891496926546097
Epoch 0, Step 679: train/loss = 0.5268292427062988, train/raw-loss = 0.39926037192344666, train/logprobs = tensor([[-0.3870, -2.0458],
        [-0.4032, -0.1909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12756888568401337
Epoch 0, Step 680: train/loss = 0.5297861695289612, train/raw-loss = 0.4088236689567566, train/logprobs = tensor([[-0.1409, -2.3899],
        [-0.4023, -0.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12096251547336578
Epoch 0, Step 681: train/loss = 0.5893940329551697, train/raw-loss = 0.47992372512817383, train/logprobs = tensor([[-0.1107, -1.5366],
        [-0.3278, -0.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10947029292583466
Epoch 0, Step 682: train/loss = 0.7266470193862915, train/raw-loss = 0.5920487642288208, train/logprobs = tensor([[-0.5596, -0.9546],
        [-0.3590, -0.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13459822535514832
Epoch 0, Step 683: train/loss = 0.6339413523674011, train/raw-loss = 0.519996702671051, train/logprobs = tensor([[-0.3184, -1.2620],
        [-0.4422, -0.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11394467204809189
Epoch 0, Step 684: train/loss = 0.5947594046592712, train/raw-loss = 0.475721150636673, train/logprobs = tensor([[-0.0858, -3.0318],
        [-0.3758, -0.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903825402259827
Epoch 0, Step 685: train/loss = 0.6064750552177429, train/raw-loss = 0.48498332500457764, train/logprobs = tensor([[-0.1324, -1.5171],
        [-0.3170, -0.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12149171531200409
Epoch 0, Step 686: train/loss = 0.6178876161575317, train/raw-loss = 0.4936584234237671, train/logprobs = tensor([[-0.2425, -1.0666],
        [-0.4086, -0.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12422920763492584
Epoch 0, Step 687: train/loss = 0.56410813331604, train/raw-loss = 0.4430329203605652, train/logprobs = tensor([[-0.4463, -2.2763],
        [-0.5730, -0.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12107517570257187
Epoch 0, Step 688: train/loss = 0.5131434202194214, train/raw-loss = 0.36534202098846436, train/logprobs = tensor([[-0.3582, -3.2077],
        [-0.5568, -0.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14780139923095703
Epoch 0, Step 689: train/loss = 0.5214711427688599, train/raw-loss = 0.4135805666446686, train/logprobs = tensor([[-0.1148, -3.9855],
        [-0.2673, -0.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10789057612419128
Epoch 0, Step 690: train/loss = 0.5993876457214355, train/raw-loss = 0.5130453109741211, train/logprobs = tensor([[-0.0704, -1.4935],
        [-0.1622, -0.1782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08634233474731445
Epoch 0, Step 691: train/loss = 0.5048286318778992, train/raw-loss = 0.38915836811065674, train/logprobs = tensor([[-0.1842, -4.1305],
        [-0.6697, -0.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567026376724243
Epoch 0, Step 692: train/loss = 0.6217916011810303, train/raw-loss = 0.5053709745407104, train/logprobs = tensor([[-0.1507, -1.1668],
        [-0.3044, -0.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11642059683799744
Epoch 0, Step 693: train/loss = 0.6288185119628906, train/raw-loss = 0.5031439065933228, train/logprobs = tensor([[-0.2369, -1.4020],
        [-0.4135, -0.2549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12567459046840668
Epoch 0, Step 694: train/loss = 0.4683292508125305, train/raw-loss = 0.32725533843040466, train/logprobs = tensor([[-0.1076, -4.1251],
        [-0.4186, -0.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14107391238212585
Epoch 0, Step 695: train/loss = 0.7431392669677734, train/raw-loss = 0.6379479169845581, train/logprobs = tensor([[-0.0548, -0.5451],
        [-0.2988, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519134998321533
Epoch 0, Step 696: train/loss = 0.5999923348426819, train/raw-loss = 0.48292234539985657, train/logprobs = tensor([[-0.2867, -3.3327],
        [-0.4740, -1.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1170700266957283
Epoch 0, Step 697: train/loss = 0.6127240657806396, train/raw-loss = 0.5236203670501709, train/logprobs = tensor([[-0.1829, -0.9154],
        [-0.3030, -0.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08910371363162994
Epoch 0, Step 698: train/loss = 0.6062737703323364, train/raw-loss = 0.5020169019699097, train/logprobs = tensor([[-0.3031, -1.2757],
        [-0.4914, -0.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10425694286823273
Epoch 0, Step 699: train/loss = 0.5125517249107361, train/raw-loss = 0.3831595182418823, train/logprobs = tensor([[-0.3081, -3.9734],
        [-0.7187, -0.4459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12939220666885376
Epoch 0, Step 700: train/loss = 0.5470595955848694, train/raw-loss = 0.4210261404514313, train/logprobs = tensor([[-0.2453, -2.6472],
        [-0.2600, -0.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260334551334381
Epoch 0, Step 701: train/loss = 0.5372516512870789, train/raw-loss = 0.407953143119812, train/logprobs = tensor([[-0.3234, -2.6866],
        [-0.6281, -0.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12929850816726685
Epoch 0, Step 702: train/loss = 0.640056848526001, train/raw-loss = 0.5515817403793335, train/logprobs = tensor([[-0.1211, -1.0135],
        [-0.2724, -0.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08847509324550629
Epoch 0, Step 703: train/loss = 0.6913264989852905, train/raw-loss = 0.5676712989807129, train/logprobs = tensor([[-0.2547, -1.1213],
        [-0.4439, -0.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12365522980690002
Epoch 0, Step 704: train/loss = 0.4393745958805084, train/raw-loss = 0.3003840744495392, train/logprobs = tensor([[-0.3418, -7.6034],
        [-0.7488, -0.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13899055123329163
Epoch 0, Step 705: train/loss = 0.5145447254180908, train/raw-loss = 0.35949259996414185, train/logprobs = tensor([[-0.4585, -2.7252],
        [-0.7303, -0.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15505214035511017
Epoch 0, Step 706: train/loss = 0.5521048903465271, train/raw-loss = 0.4580112099647522, train/logprobs = tensor([[-0.1013, -2.2940],
        [-0.1977, -0.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09409365803003311
Epoch 0, Step 707: train/loss = 0.5790629982948303, train/raw-loss = 0.4564882814884186, train/logprobs = tensor([[-0.1993, -1.3690],
        [-0.4360, -0.1126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12257471680641174
Epoch 0, Step 708: train/loss = 0.5486342310905457, train/raw-loss = 0.4474833607673645, train/logprobs = tensor([[-0.0913, -1.8244],
        [-0.1691, -0.1535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115087032318115
Epoch 0, Step 709: train/loss = 0.3921763002872467, train/raw-loss = 0.26183590292930603, train/logprobs = tensor([[-0.1920, -4.7854],
        [-0.6977, -0.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13034042716026306
Epoch 0, Step 710: train/loss = 0.4751109480857849, train/raw-loss = 0.33570870757102966, train/logprobs = tensor([[-0.0982, -2.4329],
        [-0.4728, -0.5044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940224051475525
Epoch 0, Step 711: train/loss = 0.6269959211349487, train/raw-loss = 0.5094311833381653, train/logprobs = tensor([[-0.2294, -1.9436],
        [-0.3807, -0.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756472289562225
Epoch 0, Step 712: train/loss = 0.5980138778686523, train/raw-loss = 0.4755533039569855, train/logprobs = tensor([[-0.2235, -1.7230],
        [-0.5773, -0.3670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246064096689224
Epoch 0, Step 713: train/loss = 0.49108970165252686, train/raw-loss = 0.37314310669898987, train/logprobs = tensor([[-0.3453, -5.3304],
        [-0.4693, -0.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1179465502500534
Epoch 0, Step 714: train/loss = 0.6395824551582336, train/raw-loss = 0.5170682072639465, train/logprobs = tensor([[-0.2515, -2.1309],
        [-0.4810, -0.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1225142627954483
Epoch 0, Step 715: train/loss = 0.5601093173027039, train/raw-loss = 0.4039302468299866, train/logprobs = tensor([[-0.3605, -4.3278],
        [-0.5380, -0.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1561790555715561
Epoch 0, Step 716: train/loss = 0.6848416924476624, train/raw-loss = 0.5806184411048889, train/logprobs = tensor([[-0.1734, -0.9142],
        [-0.3974, -0.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422320663928986
Epoch 0, Step 717: train/loss = 0.5466926097869873, train/raw-loss = 0.4442178010940552, train/logprobs = tensor([[-0.1936, -3.2636],
        [-0.6326, -0.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247476398944855
Epoch 0, Step 718: train/loss = 0.7041126489639282, train/raw-loss = 0.5934921503067017, train/logprobs = tensor([[-0.5087, -1.1468],
        [-0.6481, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062051355838776
Epoch 0, Step 719: train/loss = 0.6570625305175781, train/raw-loss = 0.5545676946640015, train/logprobs = tensor([[-0.0811, -0.7677],
        [-0.2895, -0.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249485075473785
Epoch 0, Step 720: train/loss = 0.5905019044876099, train/raw-loss = 0.4708121418952942, train/logprobs = tensor([[-0.2677, -1.3263],
        [-0.4638, -0.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11968976259231567
Epoch 0, Step 721: train/loss = 0.5719789266586304, train/raw-loss = 0.4424351453781128, train/logprobs = tensor([[-0.2241, -1.8573],
        [-0.3654, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12954378128051758
Epoch 0, Step 722: train/loss = 0.7338681221008301, train/raw-loss = 0.6556233167648315, train/logprobs = tensor([[-0.1360, -0.2097],
        [-0.2152, -0.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824471592903137
Epoch 0, Step 723: train/loss = 0.5820611119270325, train/raw-loss = 0.435688316822052, train/logprobs = tensor([[-0.4167, -2.0201],
        [-0.4884, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14637276530265808
Epoch 0, Step 724: train/loss = 0.5343079566955566, train/raw-loss = 0.39869070053100586, train/logprobs = tensor([[-0.0676, -5.1295],
        [-0.4276, -0.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356172263622284
Epoch 0, Step 725: train/loss = 0.6451283097267151, train/raw-loss = 0.5435391068458557, train/logprobs = tensor([[-0.3057, -2.1306],
        [-0.4108, -0.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10158917307853699
Epoch 0, Step 726: train/loss = 0.5076595544815063, train/raw-loss = 0.3802589178085327, train/logprobs = tensor([[-0.1267, -3.1095],
        [-0.2984, -0.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12740060687065125
Epoch 0, Step 727: train/loss = 0.6318109035491943, train/raw-loss = 0.520074188709259, train/logprobs = tensor([[-0.5565, -2.0786],
        [-0.4368, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11173674464225769
Epoch 0, Step 728: train/loss = 0.41988039016723633, train/raw-loss = 0.2867036461830139, train/logprobs = tensor([[-0.1240, -6.6904],
        [-0.5216, -1.0579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13317672908306122
Epoch 0, Step 729: train/loss = 0.7119969129562378, train/raw-loss = 0.5991724729537964, train/logprobs = tensor([[-0.4361, -0.7346],
        [-0.4278, -0.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282441765069962
Epoch 0, Step 730: train/loss = 0.6674591898918152, train/raw-loss = 0.5595651865005493, train/logprobs = tensor([[-0.1389, -0.6634],
        [-0.3112, -0.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10789396613836288
Epoch 0, Step 731: train/loss = 0.6171842813491821, train/raw-loss = 0.5060190558433533, train/logprobs = tensor([[-0.0969, -1.3228],
        [-0.3075, -0.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11116526275873184
Epoch 0, Step 732: train/loss = 0.7914860248565674, train/raw-loss = 0.675991415977478, train/logprobs = tensor([[-0.2031, -0.4403],
        [-0.4316, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11549463868141174
Epoch 0, Step 733: train/loss = 0.6245338320732117, train/raw-loss = 0.5024416446685791, train/logprobs = tensor([[-0.1467, -2.1966],
        [-0.2093, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12209222465753555
Epoch 0, Step 734: train/loss = 0.6791863441467285, train/raw-loss = 0.5599573850631714, train/logprobs = tensor([[-0.3377, -1.4212],
        [-0.4831, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11922897398471832
Epoch 0, Step 735: train/loss = 0.769711971282959, train/raw-loss = 0.6817148327827454, train/logprobs = tensor([[-0.2012, -0.2995],
        [-0.3379, -0.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799712359905243
Epoch 0, Step 736: train/loss = 0.7409684658050537, train/raw-loss = 0.6595569849014282, train/logprobs = tensor([[-0.0604, -0.4447],
        [-0.2356, -0.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08141142129898071
Epoch 0, Step 737: train/loss = 0.5928507447242737, train/raw-loss = 0.4679478704929352, train/logprobs = tensor([[-0.2086, -1.7891],
        [-0.5004, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12490290403366089
Epoch 0, Step 738: train/loss = 0.6991074681282043, train/raw-loss = 0.6027939915657043, train/logprobs = tensor([[-0.1935, -0.5941],
        [-0.6534, -0.5880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09631345421075821
Epoch 0, Step 739: train/loss = 0.5203471779823303, train/raw-loss = 0.386532187461853, train/logprobs = tensor([[-0.4318, -2.1653],
        [-1.1094, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13381502032279968
Epoch 0, Step 740: train/loss = 0.40184807777404785, train/raw-loss = 0.2584395408630371, train/logprobs = tensor([[-0.0747, -2.9623],
        [-0.5412, -0.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14340850710868835
Epoch 0, Step 741: train/loss = 0.496113657951355, train/raw-loss = 0.3106391727924347, train/logprobs = tensor([[-0.3028, -3.9703],
        [-0.4390, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18547450006008148
Epoch 0, Step 742: train/loss = 0.5998057126998901, train/raw-loss = 0.5138989686965942, train/logprobs = tensor([[-0.0426, -1.0184],
        [-0.1767, -0.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0859067440032959
Epoch 0, Step 743: train/loss = 0.5031219124794006, train/raw-loss = 0.3778177499771118, train/logprobs = tensor([[-0.3047, -6.7599],
        [-0.6092, -0.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12530416250228882
Epoch 0, Step 744: train/loss = 0.6921818256378174, train/raw-loss = 0.6128839254379272, train/logprobs = tensor([[-0.0993, -0.2939],
        [-0.3441, -0.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07929791510105133
Epoch 0, Step 745: train/loss = 0.5171699523925781, train/raw-loss = 0.3913742005825043, train/logprobs = tensor([[-0.2112, -2.3484],
        [-0.4471, -0.3354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12579572200775146
Epoch 0, Step 746: train/loss = 0.7104536294937134, train/raw-loss = 0.634918212890625, train/logprobs = tensor([[-0.4176, -0.4032],
        [-0.5777, -0.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07553538680076599
Epoch 0, Step 747: train/loss = 0.6191750168800354, train/raw-loss = 0.5237101316452026, train/logprobs = tensor([[-0.0948, -1.1431],
        [-0.1683, -0.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09546493738889694
Epoch 0, Step 748: train/loss = 0.7105879187583923, train/raw-loss = 0.6211018562316895, train/logprobs = tensor([[-0.0667, -0.4569],
        [-0.4412, -0.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08948606997728348
Epoch 0, Step 749: train/loss = 0.5833014249801636, train/raw-loss = 0.47024965286254883, train/logprobs = tensor([[-0.3056, -2.2578],
        [-0.4213, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11305177956819534
Epoch 0, Step 750: train/loss = 0.5577882528305054, train/raw-loss = 0.4394097626209259, train/logprobs = tensor([[-0.2550, -1.9256],
        [-0.9497, -0.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11837845295667648
Epoch 0, Step 751: train/loss = 0.6448979377746582, train/raw-loss = 0.5517175197601318, train/logprobs = tensor([[-0.2841, -1.5971],
        [-0.3763, -0.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318041801452637
Epoch 0, Step 752: train/loss = 0.6779950857162476, train/raw-loss = 0.5552306175231934, train/logprobs = tensor([[-0.1336, -1.8326],
        [-0.3331, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122764453291893
Epoch 0, Step 753: train/loss = 0.6528810858726501, train/raw-loss = 0.5277057886123657, train/logprobs = tensor([[-0.0881, -0.9155],
        [-0.2972, -0.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517525255680084
Epoch 0, Step 754: train/loss = 0.6178617477416992, train/raw-loss = 0.48212772607803345, train/logprobs = tensor([[-0.1708, -1.3626],
        [-0.3835, -0.4362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13573400676250458
Epoch 0, Step 755: train/loss = 0.4923795461654663, train/raw-loss = 0.34125274419784546, train/logprobs = tensor([[-0.1836, -4.6638],
        [-0.7812, -0.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15112683176994324
Epoch 0, Step 756: train/loss = 0.6158404350280762, train/raw-loss = 0.4964825212955475, train/logprobs = tensor([[-0.3276, -1.9878],
        [-0.5438, -0.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193578839302063
Epoch 0, Step 757: train/loss = 0.6207022666931152, train/raw-loss = 0.5248371958732605, train/logprobs = tensor([[-0.1150, -1.8254],
        [-0.3728, -0.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09586504101753235
Epoch 0, Step 758: train/loss = 0.6021978855133057, train/raw-loss = 0.47082704305648804, train/logprobs = tensor([[-0.1564, -4.4543],
        [-0.2705, -1.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13137087225914001
Epoch 0, Step 759: train/loss = 0.5891603231430054, train/raw-loss = 0.48238205909729004, train/logprobs = tensor([[-0.1674, -1.8081],
        [-0.2638, -0.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10677825659513474
Epoch 0, Step 760: train/loss = 0.5681856870651245, train/raw-loss = 0.4591357409954071, train/logprobs = tensor([[-0.2740, -2.0862],
        [-0.5821, -0.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904992371797562
Epoch 0, Step 761: train/loss = 0.6698421835899353, train/raw-loss = 0.5854403376579285, train/logprobs = tensor([[-0.6771, -0.8820],
        [-0.8241, -0.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08440182358026505
Epoch 0, Step 762: train/loss = 0.6202006340026855, train/raw-loss = 0.48924389481544495, train/logprobs = tensor([[-0.2135, -1.2658],
        [-0.3722, -0.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1309567242860794
Epoch 0, Step 763: train/loss = 0.7442061901092529, train/raw-loss = 0.6035527586936951, train/logprobs = tensor([[-0.3187, -0.9570],
        [-0.6743, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14065343141555786
Epoch 0, Step 764: train/loss = 0.6625238060951233, train/raw-loss = 0.5744627714157104, train/logprobs = tensor([[-0.1478, -0.7756],
        [-0.4532, -0.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08806101232767105
Epoch 0, Step 765: train/loss = 0.5100571513175964, train/raw-loss = 0.3994346857070923, train/logprobs = tensor([[-0.1670, -3.5769],
        [-0.6930, -0.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062246561050415
Epoch 0, Step 766: train/loss = 0.573796808719635, train/raw-loss = 0.4068383574485779, train/logprobs = tensor([[-0.2906, -1.9413],
        [-0.7531, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16695842146873474
Epoch 0, Step 767: train/loss = 0.6958264112472534, train/raw-loss = 0.5724769234657288, train/logprobs = tensor([[-0.1716, -0.9938],
        [-0.2008, -0.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12334945797920227
Epoch 0, Step 768: train/loss = 0.7356848120689392, train/raw-loss = 0.646866500377655, train/logprobs = tensor([[-0.1725, -0.4035],
        [-0.3283, -0.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881834149360657
Epoch 0, Step 769: train/loss = 0.6301978826522827, train/raw-loss = 0.5192404985427856, train/logprobs = tensor([[-0.2332, -1.4298],
        [-0.4048, -0.4114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095736175775528
Epoch 0, Step 770: train/loss = 0.707573413848877, train/raw-loss = 0.6075997948646545, train/logprobs = tensor([[-0.1025, -0.7610],
        [-0.2757, -0.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09997367113828659
Epoch 0, Step 771: train/loss = 0.5424546003341675, train/raw-loss = 0.44185692071914673, train/logprobs = tensor([[-0.1310, -3.2396],
        [-0.4863, -0.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10059766471385956
Epoch 0, Step 772: train/loss = 0.5091763138771057, train/raw-loss = 0.3724924325942993, train/logprobs = tensor([[-0.1830, -1.8315],
        [-0.7167, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1366838961839676
Epoch 0, Step 773: train/loss = 0.5945902466773987, train/raw-loss = 0.49826779961586, train/logprobs = tensor([[-0.0676, -1.6287],
        [-0.3394, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632246196269989
Epoch 0, Step 774: train/loss = 0.5851532816886902, train/raw-loss = 0.48327746987342834, train/logprobs = tensor([[-0.3765, -1.2541],
        [-0.4474, -0.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10187583416700363
Epoch 0, Step 775: train/loss = 0.505412220954895, train/raw-loss = 0.3577232360839844, train/logprobs = tensor([[-0.8120, -4.4518],
        [-1.4283, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14768896996974945
Epoch 0, Step 776: train/loss = 0.4481735825538635, train/raw-loss = 0.33226412534713745, train/logprobs = tensor([[-0.0998, -4.5509],
        [-0.9105, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11590947955846786
Epoch 0, Step 777: train/loss = 0.5738767385482788, train/raw-loss = 0.4803190231323242, train/logprobs = tensor([[-0.0985, -1.2304],
        [-0.3998, -0.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09355770796537399
Epoch 0, Step 778: train/loss = 0.574856162071228, train/raw-loss = 0.4477246403694153, train/logprobs = tensor([[-0.2185, -1.9621],
        [-0.4726, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12713156640529633
Epoch 0, Step 779: train/loss = 0.6597433090209961, train/raw-loss = 0.5475811958312988, train/logprobs = tensor([[-0.1977, -3.1656],
        [-0.3069, -0.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11216206848621368
Epoch 0, Step 780: train/loss = 0.774932861328125, train/raw-loss = 0.6827152967453003, train/logprobs = tensor([[-0.1738, -0.8689],
        [-0.3255, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0922175943851471
Epoch 0, Step 781: train/loss = 0.6460472345352173, train/raw-loss = 0.5287638902664185, train/logprobs = tensor([[-0.1945, -1.4000],
        [-0.5585, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728335171937943
Epoch 0, Step 782: train/loss = 0.5121537446975708, train/raw-loss = 0.3654785752296448, train/logprobs = tensor([[-0.3445, -3.8402],
        [-0.5507, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14667515456676483
Epoch 0, Step 783: train/loss = 0.5405682921409607, train/raw-loss = 0.40222445130348206, train/logprobs = tensor([[-0.1801, -2.0599],
        [-0.4861, -0.3184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13834385573863983
Epoch 0, Step 784: train/loss = 0.43993011116981506, train/raw-loss = 0.30062800645828247, train/logprobs = tensor([[-0.2276, -6.8794],
        [-0.5860, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393020898103714
Epoch 0, Step 785: train/loss = 0.6800609827041626, train/raw-loss = 0.5718573331832886, train/logprobs = tensor([[-0.1216, -1.6552],
        [-0.3890, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10820364207029343
Epoch 0, Step 786: train/loss = 0.5186610221862793, train/raw-loss = 0.3886054456233978, train/logprobs = tensor([[-0.1629, -3.9879],
        [-0.3264, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13005557656288147
Epoch 0, Step 787: train/loss = 0.6796737313270569, train/raw-loss = 0.5742110013961792, train/logprobs = tensor([[-0.1669, -0.6857],
        [-0.3930, -0.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10546275228261948
Epoch 0, Step 788: train/loss = 0.506897509098053, train/raw-loss = 0.3645174205303192, train/logprobs = tensor([[-0.1983, -4.7363],
        [-0.4805, -0.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14238008856773376
Epoch 0, Step 789: train/loss = 0.7248194813728333, train/raw-loss = 0.6448052525520325, train/logprobs = tensor([[-0.1918, -0.4691],
        [-0.4754, -0.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08001422882080078
Epoch 0, Step 790: train/loss = 0.5999965667724609, train/raw-loss = 0.5108256340026855, train/logprobs = tensor([[-0.1065, -1.1929],
        [-0.2123, -0.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08917093276977539
Epoch 0, Step 791: train/loss = 0.7227237224578857, train/raw-loss = 0.6464512348175049, train/logprobs = tensor([[-0.1875, -0.2228],
        [-0.4441, -0.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07627250254154205
Epoch 0, Step 792: train/loss = 0.5896985530853271, train/raw-loss = 0.45453327894210815, train/logprobs = tensor([[-0.2622, -2.6840],
        [-0.7069, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13516530394554138
Epoch 0, Step 793: train/loss = 0.5602770447731018, train/raw-loss = 0.4639514684677124, train/logprobs = tensor([[-0.1802, -4.9793],
        [-0.5801, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632561355829239
Epoch 0, Step 794: train/loss = 0.5034612417221069, train/raw-loss = 0.3729272186756134, train/logprobs = tensor([[-0.2852, -2.1335],
        [-0.5348, -0.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13053400814533234
Epoch 0, Step 795: train/loss = 0.5825803279876709, train/raw-loss = 0.439467191696167, train/logprobs = tensor([[-0.4251, -2.2030],
        [-0.5038, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431131511926651
Epoch 0, Step 796: train/loss = 0.4939342737197876, train/raw-loss = 0.3553006649017334, train/logprobs = tensor([[-0.3074, -4.1131],
        [-0.5005, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138633593916893
Epoch 0, Step 797: train/loss = 0.6075804829597473, train/raw-loss = 0.5261883735656738, train/logprobs = tensor([[-0.1311, -0.7709],
        [-0.2891, -0.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139213919639587
Epoch 0, Step 798: train/loss = 0.5531501173973083, train/raw-loss = 0.4541073441505432, train/logprobs = tensor([[-0.2279, -2.7314],
        [-0.2515, -0.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09904278814792633
Epoch 0, Step 799: train/loss = 0.578304648399353, train/raw-loss = 0.43698495626449585, train/logprobs = tensor([[-0.2927, -3.1346],
        [-0.5053, -0.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14131972193717957
Epoch 0, Step 800: train/loss = 0.6663016676902771, train/raw-loss = 0.5834661722183228, train/logprobs = tensor([[-0.3642, -0.8727],
        [-0.5068, -0.3168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283546566963196
Epoch 0, Step 801: train/loss = 0.42418205738067627, train/raw-loss = 0.28257474303245544, train/logprobs = tensor([[-0.3871, -5.7730],
        [-0.6060, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1416073590517044
Epoch 0, Step 802: train/loss = 0.5813794732093811, train/raw-loss = 0.48804163932800293, train/logprobs = tensor([[-0.2032, -1.2634],
        [-0.3617, -0.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333784133195877
Epoch 0, Step 803: train/loss = 0.6555188894271851, train/raw-loss = 0.5212463140487671, train/logprobs = tensor([[-0.2461, -2.3420],
        [-0.5763, -1.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13427256047725677
Epoch 0, Step 804: train/loss = 0.5760888457298279, train/raw-loss = 0.46053987741470337, train/logprobs = tensor([[-0.1757, -2.0085],
        [-0.3737, -0.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11554896831512451
Epoch 0, Step 805: train/loss = 0.6139601469039917, train/raw-loss = 0.5315445065498352, train/logprobs = tensor([[-0.0848, -1.4469],
        [-0.2331, -0.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08241564780473709
Epoch 0, Step 806: train/loss = 0.5047798156738281, train/raw-loss = 0.37851274013519287, train/logprobs = tensor([[-0.2995, -4.7116],
        [-0.7266, -1.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12626707553863525
Epoch 0, Step 807: train/loss = 0.4876105785369873, train/raw-loss = 0.3493688404560089, train/logprobs = tensor([[-0.3107, -5.5804],
        [-0.4176, -0.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138241708278656
Epoch 0, Step 808: train/loss = 0.6155091524124146, train/raw-loss = 0.49616923928260803, train/logprobs = tensor([[-0.1458, -1.9612],
        [-0.5511, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11933988332748413
Epoch 0, Step 809: train/loss = 0.5084541440010071, train/raw-loss = 0.38810762763023376, train/logprobs = tensor([[-0.1104, -3.4794],
        [-0.3405, -0.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12034652382135391
Epoch 0, Step 810: train/loss = 0.684744119644165, train/raw-loss = 0.5634797215461731, train/logprobs = tensor([[-0.2547, -1.5007],
        [-0.5019, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12126440554857254
Epoch 0, Step 811: train/loss = 0.6332375407218933, train/raw-loss = 0.5231301188468933, train/logprobs = tensor([[-0.1269, -2.3783],
        [-0.4360, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1101074293255806
Epoch 0, Step 812: train/loss = 0.6507114768028259, train/raw-loss = 0.5564417243003845, train/logprobs = tensor([[-0.1435, -1.5746],
        [-0.5964, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942697525024414
Epoch 0, Step 813: train/loss = 0.6886985301971436, train/raw-loss = 0.569949209690094, train/logprobs = tensor([[-0.3246, -0.7748],
        [-0.3042, -0.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11874932050704956
Epoch 0, Step 814: train/loss = 0.4040459394454956, train/raw-loss = 0.2952043116092682, train/logprobs = tensor([[-0.1237, -2.7015],
        [-1.0555, -0.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884162038564682
Epoch 0, Step 815: train/loss = 0.6964197158813477, train/raw-loss = 0.5739563703536987, train/logprobs = tensor([[-0.1833, -1.4068],
        [-0.2740, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246333062648773
Epoch 0, Step 816: train/loss = 0.5126080513000488, train/raw-loss = 0.3792881369590759, train/logprobs = tensor([[-0.1188, -4.8867],
        [-0.2287, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333198994398117
Epoch 0, Step 817: train/loss = 0.5470231771469116, train/raw-loss = 0.4274764657020569, train/logprobs = tensor([[-0.4256, -5.0967],
        [-0.5562, -0.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11954669654369354
Epoch 0, Step 818: train/loss = 0.46173009276390076, train/raw-loss = 0.33671844005584717, train/logprobs = tensor([[-0.2542, -8.3033],
        [-0.5147, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1250116378068924
Epoch 0, Step 819: train/loss = 0.503635823726654, train/raw-loss = 0.38422122597694397, train/logprobs = tensor([[-0.1445, -3.1147],
        [-0.3299, -0.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11941461265087128
Epoch 0, Step 820: train/loss = 0.545742928981781, train/raw-loss = 0.4422847330570221, train/logprobs = tensor([[-0.3182, -1.5149],
        [-0.6283, -0.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10345820337533951
Epoch 0, Step 821: train/loss = 0.5676960945129395, train/raw-loss = 0.4444274306297302, train/logprobs = tensor([[-0.2125, -1.3610],
        [-0.6355, -0.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12326866388320923
Epoch 0, Step 822: train/loss = 0.6528180837631226, train/raw-loss = 0.5388959646224976, train/logprobs = tensor([[-0.1600, -1.5870],
        [-0.3090, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1139221116900444
Epoch 0, Step 823: train/loss = 0.5235066413879395, train/raw-loss = 0.40378862619400024, train/logprobs = tensor([[-0.1449, -4.1706],
        [-0.3550, -0.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11971799284219742
Epoch 0, Step 824: train/loss = 0.5237990021705627, train/raw-loss = 0.39197206497192383, train/logprobs = tensor([[-0.2001, -4.6174],
        [-0.4968, -0.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13182692229747772
Epoch 0, Step 825: train/loss = 0.7686456441879272, train/raw-loss = 0.7012054920196533, train/logprobs = tensor([[-0.1919, -0.1349],
        [-0.2167, -0.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06744010746479034
Epoch 0, Step 826: train/loss = 0.5876319408416748, train/raw-loss = 0.47481146454811096, train/logprobs = tensor([[-0.2108, -1.0394],
        [-0.6170, -0.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282047629356384
Epoch 0, Step 827: train/loss = 0.5586195588111877, train/raw-loss = 0.4489591121673584, train/logprobs = tensor([[-0.0917, -1.7043],
        [-0.2110, -0.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10966047644615173
Epoch 0, Step 828: train/loss = 0.5632342100143433, train/raw-loss = 0.4200704097747803, train/logprobs = tensor([[-0.3534, -1.5144],
        [-0.9232, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431637704372406
Epoch 0, Step 829: train/loss = 0.6049100160598755, train/raw-loss = 0.5093078017234802, train/logprobs = tensor([[-0.4366, -2.0260],
        [-0.3826, -0.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09560218453407288
Epoch 0, Step 830: train/loss = 0.632662296295166, train/raw-loss = 0.5240462422370911, train/logprobs = tensor([[-0.1427, -2.7417],
        [-0.3147, -0.3690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10861609131097794
Epoch 0, Step 831: train/loss = 0.6316882371902466, train/raw-loss = 0.5282331705093384, train/logprobs = tensor([[-0.1295, -0.9737],
        [-0.3103, -0.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10345509648323059
Epoch 0, Step 832: train/loss = 0.5706216096878052, train/raw-loss = 0.43241485953330994, train/logprobs = tensor([[-0.2426, -1.3196],
        [-0.6781, -0.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13820680975914001
Epoch 0, Step 833: train/loss = 0.6730949878692627, train/raw-loss = 0.60616135597229, train/logprobs = tensor([[-0.1765, -0.4183],
        [-0.4042, -0.2472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06693359464406967
Epoch 0, Step 834: train/loss = 0.4689699411392212, train/raw-loss = 0.3226485252380371, train/logprobs = tensor([[-0.2891, -4.9155],
        [-0.6424, -0.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14632143080234528
Epoch 0, Step 835: train/loss = 0.5683050751686096, train/raw-loss = 0.5028203725814819, train/logprobs = tensor([[-0.0684, -3.6956],
        [-0.4757, -0.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06548469513654709
Epoch 0, Step 836: train/loss = 0.5370429754257202, train/raw-loss = 0.4199868440628052, train/logprobs = tensor([[-0.2721, -4.1565],
        [-0.5322, -0.3036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11705610156059265
Epoch 0, Step 837: train/loss = 0.6536568999290466, train/raw-loss = 0.5254354476928711, train/logprobs = tensor([[-0.1569, -1.1674],
        [-0.2790, -0.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12822148203849792
Epoch 0, Step 838: train/loss = 0.6025452613830566, train/raw-loss = 0.4608588218688965, train/logprobs = tensor([[-0.4519, -1.9601],
        [-0.4604, -0.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14168637990951538
Epoch 0, Step 839: train/loss = 0.46627098321914673, train/raw-loss = 0.3408457934856415, train/logprobs = tensor([[-0.1790, -3.6873],
        [-0.5053, -0.3600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12542514503002167
Epoch 0, Step 840: train/loss = 0.5146563053131104, train/raw-loss = 0.3629859387874603, train/logprobs = tensor([[-0.3416, -3.8236],
        [-0.4962, -0.3180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15167038142681122
Epoch 0, Step 841: train/loss = 0.6605825424194336, train/raw-loss = 0.5452772378921509, train/logprobs = tensor([[-0.2583, -0.7556],
        [-0.4196, -0.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11530538648366928
Epoch 0, Step 842: train/loss = 0.5683280825614929, train/raw-loss = 0.43362370133399963, train/logprobs = tensor([[-0.2504, -4.9571],
        [-0.4049, -0.3279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13470439612865448
Epoch 0, Step 843: train/loss = 0.5286495089530945, train/raw-loss = 0.41187170147895813, train/logprobs = tensor([[-0.4023, -2.4853],
        [-0.4508, -0.1546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677776277065277
Epoch 0, Step 844: train/loss = 0.5344690680503845, train/raw-loss = 0.40798285603523254, train/logprobs = tensor([[-0.6158, -4.3553],
        [-0.6012, -0.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12648621201515198
Epoch 0, Step 845: train/loss = 0.47926831245422363, train/raw-loss = 0.3279825747013092, train/logprobs = tensor([[-0.2278, -6.3585],
        [-0.6856, -0.2371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15128572285175323
Epoch 0, Step 846: train/loss = 0.47856834530830383, train/raw-loss = 0.34094536304473877, train/logprobs = tensor([[-0.1880, -6.6510],
        [-0.3823, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13762296736240387
Epoch 0, Step 847: train/loss = 0.5763485431671143, train/raw-loss = 0.4453563392162323, train/logprobs = tensor([[-0.5856, -2.5837],
        [-0.6494, -0.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099217414855957
Epoch 0, Step 848: train/loss = 0.49932318925857544, train/raw-loss = 0.35085946321487427, train/logprobs = tensor([[-0.2592, -3.3488],
        [-0.6642, -1.0408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484636813402176
Epoch 0, Step 849: train/loss = 0.45634526014328003, train/raw-loss = 0.32455646991729736, train/logprobs = tensor([[-0.5480, -3.6278],
        [-0.9369, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13178879022598267
Epoch 0, Step 850: train/loss = 0.5889854431152344, train/raw-loss = 0.4630946218967438, train/logprobs = tensor([[-0.2462, -1.8180],
        [-0.4548, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258908212184906
Epoch 0, Step 851: train/loss = 0.4566182792186737, train/raw-loss = 0.33297693729400635, train/logprobs = tensor([[-0.2974, -3.0556],
        [-0.8149, -0.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364137172698975
Epoch 0, Step 852: train/loss = 0.5414810180664062, train/raw-loss = 0.42101192474365234, train/logprobs = tensor([[-0.1418, -2.4755],
        [-0.3885, -0.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1204690933227539
Epoch 0, Step 853: train/loss = 0.6287562251091003, train/raw-loss = 0.5110074877738953, train/logprobs = tensor([[-0.2914, -2.0010],
        [-0.6706, -0.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11774873733520508
Epoch 0, Step 854: train/loss = 0.5781988501548767, train/raw-loss = 0.44793033599853516, train/logprobs = tensor([[-0.2391, -2.2321],
        [-0.5210, -0.2952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026854395866394
Epoch 0, Step 855: train/loss = 0.5001619458198547, train/raw-loss = 0.39613860845565796, train/logprobs = tensor([[-0.0821, -3.3615],
        [-0.6452, -0.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10402331501245499
Epoch 0, Step 856: train/loss = 0.5241110324859619, train/raw-loss = 0.3754100501537323, train/logprobs = tensor([[-0.2130, -2.0186],
        [-0.6517, -0.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1487009972333908
Epoch 0, Step 857: train/loss = 0.5425155758857727, train/raw-loss = 0.3916197717189789, train/logprobs = tensor([[-0.3324, -4.0005],
        [-0.5892, -0.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15089578926563263
Epoch 0, Step 858: train/loss = 0.8920246362686157, train/raw-loss = 0.7437214255332947, train/logprobs = tensor([[-1.1249, -1.4895],
        [-0.4515, -0.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14830324053764343
Epoch 0, Step 859: train/loss = 0.5091678500175476, train/raw-loss = 0.3908015191555023, train/logprobs = tensor([[-0.4339, -2.2222],
        [-0.7671, -0.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1183663085103035
Epoch 0, Step 860: train/loss = 0.562700092792511, train/raw-loss = 0.4465867280960083, train/logprobs = tensor([[-0.1337, -2.9121],
        [-0.4388, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11611337959766388
Epoch 0, Step 861: train/loss = 0.6171661615371704, train/raw-loss = 0.5018960237503052, train/logprobs = tensor([[-0.2876, -3.2863],
        [-0.4702, -0.2498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11527015268802643
Epoch 0, Step 862: train/loss = 0.5046379566192627, train/raw-loss = 0.35841891169548035, train/logprobs = tensor([[-0.2585, -4.1350],
        [-0.3421, -0.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14621903002262115
Epoch 0, Step 863: train/loss = 0.6897342205047607, train/raw-loss = 0.5357853174209595, train/logprobs = tensor([[-0.5305, -2.2874],
        [-0.4262, -0.3171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15394887328147888
Epoch 0, Step 864: train/loss = 0.7050571441650391, train/raw-loss = 0.6026121973991394, train/logprobs = tensor([[-0.4010, -0.9602],
        [-0.3674, -0.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10244493186473846
Epoch 0, Step 865: train/loss = 0.56741863489151, train/raw-loss = 0.4490339756011963, train/logprobs = tensor([[-0.2515, -1.2885],
        [-0.5717, -0.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11838465929031372
Epoch 0, Step 866: train/loss = 0.4367094039916992, train/raw-loss = 0.30043089389801025, train/logprobs = tensor([[-0.2151, -5.0794],
        [-0.3582, -0.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13627851009368896
Epoch 0, Step 867: train/loss = 0.6352609395980835, train/raw-loss = 0.5399442911148071, train/logprobs = tensor([[-0.2941, -1.0501],
        [-0.5497, -0.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09531655162572861
Epoch 0, Step 868: train/loss = 0.7110629081726074, train/raw-loss = 0.6031573414802551, train/logprobs = tensor([[-0.3682, -0.7670],
        [-0.3252, -0.2820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10790558904409409
Epoch 0, Step 869: train/loss = 0.6485806703567505, train/raw-loss = 0.5057733058929443, train/logprobs = tensor([[-0.3709, -0.8629],
        [-1.0193, -0.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14280736446380615
Epoch 0, Step 870: train/loss = 0.5125586986541748, train/raw-loss = 0.40941762924194336, train/logprobs = tensor([[-0.3199, -4.4718],
        [-0.7751, -0.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314108431339264
Epoch 0, Step 871: train/loss = 0.5275716185569763, train/raw-loss = 0.4024122655391693, train/logprobs = tensor([[-0.0830, -2.5010],
        [-0.2675, -0.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1251593679189682
Epoch 0, Step 872: train/loss = 0.5916475057601929, train/raw-loss = 0.49648579955101013, train/logprobs = tensor([[-0.0841, -1.7773],
        [-0.1852, -0.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09516166895627975
Epoch 0, Step 873: train/loss = 0.5286285877227783, train/raw-loss = 0.40939557552337646, train/logprobs = tensor([[-0.3124, -2.4510],
        [-0.5230, -0.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11923305690288544
Epoch 0, Step 874: train/loss = 0.4822900891304016, train/raw-loss = 0.3347229063510895, train/logprobs = tensor([[-0.3896, -3.8697],
        [-0.6886, -0.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14756721258163452
Epoch 0, Step 875: train/loss = 0.6909703612327576, train/raw-loss = 0.6111273765563965, train/logprobs = tensor([[-0.1763, -0.3625],
        [-0.3168, -0.1163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0798429548740387
Epoch 0, Step 876: train/loss = 0.5573792457580566, train/raw-loss = 0.4124222993850708, train/logprobs = tensor([[-0.1509, -4.6343],
        [-0.3550, -0.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14495694637298584
Epoch 0, Step 877: train/loss = 0.5034629106521606, train/raw-loss = 0.3710312843322754, train/logprobs = tensor([[-0.3560, -2.4984],
        [-0.8416, -0.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13243161141872406
Epoch 0, Step 878: train/loss = 0.5988559126853943, train/raw-loss = 0.46112918853759766, train/logprobs = tensor([[-1.1475, -2.7427],
        [-0.8467, -0.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13772672414779663
Epoch 0, Step 879: train/loss = 0.47852370142936707, train/raw-loss = 0.3373716473579407, train/logprobs = tensor([[-0.1991, -5.9772],
        [-0.3710, -0.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411520540714264
Epoch 0, Step 880: train/loss = 0.5037508010864258, train/raw-loss = 0.3685864210128784, train/logprobs = tensor([[-0.1552, -2.5939],
        [-0.3719, -0.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13516439497470856
Epoch 0, Step 881: train/loss = 0.6004186272621155, train/raw-loss = 0.5037129521369934, train/logprobs = tensor([[-0.1617, -2.1819],
        [-0.2168, -0.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09670563787221909
Epoch 0, Step 882: train/loss = 0.6847713589668274, train/raw-loss = 0.5828457474708557, train/logprobs = tensor([[-0.3093, -1.3162],
        [-0.3299, -0.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10192563384771347
Epoch 0, Step 883: train/loss = 0.5398113131523132, train/raw-loss = 0.39252060651779175, train/logprobs = tensor([[-0.1029, -1.5045],
        [-0.8747, -0.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472906768321991
Epoch 0, Step 884: train/loss = 0.4804139733314514, train/raw-loss = 0.3518158197402954, train/logprobs = tensor([[-0.2073, -2.3720],
        [-0.4216, -0.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1285981684923172
Epoch 0, Step 885: train/loss = 0.527849018573761, train/raw-loss = 0.39049288630485535, train/logprobs = tensor([[-0.6318, -3.8056],
        [-0.6168, -0.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13735614717006683
Epoch 0, Step 886: train/loss = 0.6190176010131836, train/raw-loss = 0.5267982482910156, train/logprobs = tensor([[-0.1187, -1.2482],
        [-0.3836, -0.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09221937507390976
Epoch 0, Step 887: train/loss = 0.5908244848251343, train/raw-loss = 0.4740920066833496, train/logprobs = tensor([[-0.3293, -3.0023],
        [-0.3960, -0.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673244833946228
Epoch 0, Step 888: train/loss = 0.4481687545776367, train/raw-loss = 0.3126469850540161, train/logprobs = tensor([[-0.1183, -2.8120],
        [-0.4794, -0.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355217695236206
Epoch 0, Step 889: train/loss = 0.6153869032859802, train/raw-loss = 0.4924057126045227, train/logprobs = tensor([[-0.2843, -1.4261],
        [-0.4830, -0.3810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12298119068145752
Epoch 0, Step 890: train/loss = 0.5043181777000427, train/raw-loss = 0.3829057812690735, train/logprobs = tensor([[-0.1926, -1.9795],
        [-0.7664, -0.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141241133213043
Epoch 0, Step 891: train/loss = 0.5012485980987549, train/raw-loss = 0.368320107460022, train/logprobs = tensor([[-0.3370, -4.8580],
        [-0.5640, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1329285204410553
Epoch 0, Step 892: train/loss = 0.5057569742202759, train/raw-loss = 0.39810264110565186, train/logprobs = tensor([[-0.0840, -1.8604],
        [-0.3421, -0.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10765433311462402
Epoch 0, Step 893: train/loss = 0.5739405155181885, train/raw-loss = 0.4588891565799713, train/logprobs = tensor([[-0.3268, -1.8412],
        [-0.4937, -0.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11505131423473358
Epoch 0, Step 894: train/loss = 0.505352258682251, train/raw-loss = 0.3358604609966278, train/logprobs = tensor([[-0.2360, -3.9129],
        [-0.5937, -0.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16949184238910675
Epoch 0, Step 895: train/loss = 0.5617876052856445, train/raw-loss = 0.4551439583301544, train/logprobs = tensor([[-0.2556, -6.1664],
        [-0.3701, -0.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10664365440607071
Epoch 0, Step 896: train/loss = 0.5998876690864563, train/raw-loss = 0.5169214606285095, train/logprobs = tensor([[-0.1267, -1.4876],
        [-0.2385, -0.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08296624571084976
Epoch 0, Step 897: train/loss = 0.6095799207687378, train/raw-loss = 0.5078027248382568, train/logprobs = tensor([[-0.3293, -0.9606],
        [-0.4953, -0.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10177719593048096
Epoch 0, Step 898: train/loss = 0.6214596033096313, train/raw-loss = 0.533263623714447, train/logprobs = tensor([[-0.1970, -0.7659],
        [-0.4118, -0.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08819597214460373
Epoch 0, Step 899: train/loss = 0.6114801168441772, train/raw-loss = 0.48455142974853516, train/logprobs = tensor([[-0.3098, -4.5352],
        [-0.2677, -1.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12692871689796448
Epoch 0, Step 900: train/loss = 0.4098292291164398, train/raw-loss = 0.2746136486530304, train/logprobs = tensor([[-0.6749, -8.4606],
        [-0.9517, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13521556556224823
Epoch 0, Step 901: train/loss = 0.5032698512077332, train/raw-loss = 0.37787917256355286, train/logprobs = tensor([[-0.1244, -2.8605],
        [-0.3393, -0.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1253906786441803
Epoch 0, Step 902: train/loss = 0.41745489835739136, train/raw-loss = 0.2922701835632324, train/logprobs = tensor([[-0.2527, -4.0310],
        [-0.5080, -0.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12518471479415894
Epoch 0, Step 903: train/loss = 0.5468006134033203, train/raw-loss = 0.4086452126502991, train/logprobs = tensor([[-0.4131, -1.8615],
        [-0.6741, -0.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13815537095069885
Epoch 0, Step 904: train/loss = 0.5768353939056396, train/raw-loss = 0.4768020212650299, train/logprobs = tensor([[-1.0869, -3.6654],
        [-0.7451, -0.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10003334283828735
Epoch 0, Step 905: train/loss = 0.45734384655952454, train/raw-loss = 0.34392741322517395, train/logprobs = tensor([[-0.1544, -4.7469],
        [-0.3107, -0.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11341649293899536
Epoch 0, Step 906: train/loss = 0.7224242091178894, train/raw-loss = 0.6507186889648438, train/logprobs = tensor([[-0.1776, -0.2865],
        [-0.1368, -0.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07170550525188446
Epoch 0, Step 907: train/loss = 0.6448084712028503, train/raw-loss = 0.5695804953575134, train/logprobs = tensor([[-0.3351, -0.9635],
        [-0.4293, -0.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07522793114185333
Epoch 0, Step 908: train/loss = 0.4913749098777771, train/raw-loss = 0.37305116653442383, train/logprobs = tensor([[-0.2477, -3.0477],
        [-0.3588, -0.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11832376569509506
Epoch 0, Step 909: train/loss = 0.5728811025619507, train/raw-loss = 0.4241906702518463, train/logprobs = tensor([[-0.4908, -1.8966],
        [-0.6882, -0.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14869040250778198
Epoch 0, Step 910: train/loss = 0.6328387260437012, train/raw-loss = 0.5233219861984253, train/logprobs = tensor([[-0.3990, -2.9616],
        [-0.4458, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951673984527588
Epoch 0, Step 911: train/loss = 0.4383202791213989, train/raw-loss = 0.29472604393959045, train/logprobs = tensor([[-0.3934, -4.7963],
        [-0.6926, -0.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14359423518180847
Epoch 0, Step 912: train/loss = 0.6105346083641052, train/raw-loss = 0.4869459271430969, train/logprobs = tensor([[-0.3246, -2.7651],
        [-0.1317, -0.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1235886886715889
Epoch 0, Step 913: train/loss = 0.4855799078941345, train/raw-loss = 0.3671005368232727, train/logprobs = tensor([[-0.3050, -4.0827],
        [-0.5158, -0.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847939342260361
Epoch 0, Step 914: train/loss = 0.625220775604248, train/raw-loss = 0.5058794021606445, train/logprobs = tensor([[-0.1825, -1.1144],
        [-0.4067, -0.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11934138834476471
Epoch 0, Step 915: train/loss = 0.5589421391487122, train/raw-loss = 0.4628870487213135, train/logprobs = tensor([[-0.1962, -2.0918],
        [-0.3576, -0.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605510532855988
Epoch 0, Step 916: train/loss = 0.5625739097595215, train/raw-loss = 0.4494890570640564, train/logprobs = tensor([[-0.4445, -1.8139],
        [-0.6610, -0.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11308485269546509
Epoch 0, Step 917: train/loss = 0.5912834405899048, train/raw-loss = 0.47613221406936646, train/logprobs = tensor([[-0.3139, -1.3341],
        [-0.4124, -0.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11515121161937714
Epoch 0, Step 918: train/loss = 0.6458121538162231, train/raw-loss = 0.5630248785018921, train/logprobs = tensor([[-0.1306, -0.7515],
        [-0.2345, -0.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08278721570968628
Epoch 0, Step 919: train/loss = 0.5326821208000183, train/raw-loss = 0.4356834590435028, train/logprobs = tensor([[-0.1685, -1.6163],
        [-0.4480, -0.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0969986543059349
Epoch 0, Step 920: train/loss = 0.732261061668396, train/raw-loss = 0.6590040326118469, train/logprobs = tensor([[-0.3447, -0.3410],
        [-0.4048, -0.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07325700670480728
Epoch 0, Step 921: train/loss = 0.6612277030944824, train/raw-loss = 0.568110466003418, train/logprobs = tensor([[-0.2925, -1.4073],
        [-0.3907, -0.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09311725199222565
Epoch 0, Step 922: train/loss = 0.5339658260345459, train/raw-loss = 0.4284385144710541, train/logprobs = tensor([[-0.2070, -2.7613],
        [-0.2350, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552731901407242
Epoch 0, Step 923: train/loss = 0.5147799253463745, train/raw-loss = 0.41600513458251953, train/logprobs = tensor([[-0.4469, -3.0621],
        [-0.4694, -0.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09877479076385498
Epoch 0, Step 924: train/loss = 0.46321168541908264, train/raw-loss = 0.362154096364975, train/logprobs = tensor([[-0.2838, -5.0358],
        [-0.7833, -0.2686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10105758160352707
Epoch 0, Step 925: train/loss = 0.686015248298645, train/raw-loss = 0.5981400012969971, train/logprobs = tensor([[-0.2033, -0.6000],
        [-0.3069, -0.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08787518739700317
Epoch 0, Step 926: train/loss = 0.6542806625366211, train/raw-loss = 0.5647351145744324, train/logprobs = tensor([[-0.1209, -1.0795],
        [-0.2433, -0.3888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08954553306102753
Epoch 0, Step 927: train/loss = 0.6098247170448303, train/raw-loss = 0.49472394585609436, train/logprobs = tensor([[-0.4365, -1.8047],
        [-0.3024, -0.2193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11510076373815536
Epoch 0, Step 928: train/loss = 0.5124524831771851, train/raw-loss = 0.396149218082428, train/logprobs = tensor([[-0.3404, -3.9619],
        [-0.3443, -0.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11630330234766006
Epoch 0, Step 929: train/loss = 0.4322980046272278, train/raw-loss = 0.32525280117988586, train/logprobs = tensor([[-0.1695, -2.3323],
        [-0.7499, -0.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10704521834850311
Epoch 0, Step 930: train/loss = 0.6782124042510986, train/raw-loss = 0.5739267468452454, train/logprobs = tensor([[-0.2102, -0.7361],
        [-0.3350, -0.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10428563505411148
Epoch 0, Step 931: train/loss = 0.4422700107097626, train/raw-loss = 0.3595573604106903, train/logprobs = tensor([[-0.1277, -1.6709],
        [-0.4912, -0.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08271265774965286
Epoch 0, Step 932: train/loss = 0.583518922328949, train/raw-loss = 0.45904847979545593, train/logprobs = tensor([[-0.3710, -1.7147],
        [-0.5310, -0.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12447045743465424
Epoch 0, Step 933: train/loss = 0.5428732633590698, train/raw-loss = 0.45306330919265747, train/logprobs = tensor([[-0.2007, -1.4081],
        [-0.3918, -0.2223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08980994671583176
Epoch 0, Step 934: train/loss = 0.5951495170593262, train/raw-loss = 0.5088271498680115, train/logprobs = tensor([[-0.0971, -1.6722],
        [-0.2394, -0.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08632233738899231
Epoch 0, Step 935: train/loss = 0.549731433391571, train/raw-loss = 0.4085010886192322, train/logprobs = tensor([[-0.3296, -2.4484],
        [-0.4847, -0.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14123035967350006
Epoch 0, Step 936: train/loss = 0.5650305151939392, train/raw-loss = 0.4590710401535034, train/logprobs = tensor([[-0.1985, -1.6376],
        [-0.4619, -0.2651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595950484275818
Epoch 0, Step 937: train/loss = 0.5811755657196045, train/raw-loss = 0.49219977855682373, train/logprobs = tensor([[-0.2740, -1.5924],
        [-0.2954, -0.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08897580206394196
Epoch 0, Step 938: train/loss = 0.5724461674690247, train/raw-loss = 0.42987459897994995, train/logprobs = tensor([[-0.2665, -1.6933],
        [-0.6241, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425715535879135
Epoch 0, Step 939: train/loss = 0.6047137975692749, train/raw-loss = 0.4968799650669098, train/logprobs = tensor([[-0.2928, -1.4805],
        [-0.4306, -0.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10783378779888153
Epoch 0, Step 940: train/loss = 0.5092116594314575, train/raw-loss = 0.37940943241119385, train/logprobs = tensor([[-0.1531, -2.2225],
        [-0.6364, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12980221211910248
Epoch 0, Step 941: train/loss = 0.527961790561676, train/raw-loss = 0.4146674871444702, train/logprobs = tensor([[-0.4801, -4.3040],
        [-0.7058, -0.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329430341720581
Epoch 0, Step 942: train/loss = 0.6046659350395203, train/raw-loss = 0.5003778338432312, train/logprobs = tensor([[-0.3276, -1.5822],
        [-0.4333, -0.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10428810119628906
Epoch 0, Step 943: train/loss = 0.5781739950180054, train/raw-loss = 0.4558805525302887, train/logprobs = tensor([[-0.4152, -1.7623],
        [-0.5927, -0.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12229344248771667
Epoch 0, Step 944: train/loss = 0.40874195098876953, train/raw-loss = 0.26671460270881653, train/logprobs = tensor([[-0.2866, -3.7228],
        [-0.7279, -0.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14202731847763062
Epoch 0, Step 945: train/loss = 0.48915231227874756, train/raw-loss = 0.40238386392593384, train/logprobs = tensor([[-0.1963, -2.2591],
        [-0.3609, -0.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08676843345165253
Epoch 0, Step 946: train/loss = 0.47693347930908203, train/raw-loss = 0.3736996054649353, train/logprobs = tensor([[-0.2392, -2.9497],
        [-0.5369, -0.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10323391854763031
Epoch 0, Step 947: train/loss = 0.7259313464164734, train/raw-loss = 0.6566917300224304, train/logprobs = tensor([[-0.2088, -0.4041],
        [-0.1989, -0.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06923966109752655
Epoch 0, Step 948: train/loss = 0.5799590349197388, train/raw-loss = 0.46824565529823303, train/logprobs = tensor([[-0.1989, -1.7584],
        [-0.2964, -0.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171331256628036
Epoch 0, Step 949: train/loss = 0.5709991455078125, train/raw-loss = 0.46790841221809387, train/logprobs = tensor([[-0.2233, -1.7050],
        [-0.4087, -0.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309074819087982
Epoch 0, Step 950: train/loss = 0.5258394479751587, train/raw-loss = 0.3856979012489319, train/logprobs = tensor([[-0.1373, -1.9846],
        [-0.4518, -0.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1401415914297104
Epoch 0, Step 951: train/loss = 0.5685816407203674, train/raw-loss = 0.4492855370044708, train/logprobs = tensor([[-0.5965, -2.1769],
        [-0.7506, -0.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192961186170578
Epoch 0, Step 952: train/loss = 0.590084969997406, train/raw-loss = 0.49228349328041077, train/logprobs = tensor([[-0.1495, -2.5221],
        [-0.1214, -0.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780143946409225
Epoch 0, Step 953: train/loss = 0.6570217609405518, train/raw-loss = 0.5548840165138245, train/logprobs = tensor([[-0.3068, -0.7982],
        [-0.3617, -0.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10213777422904968
Epoch 0, Step 954: train/loss = 0.5989563465118408, train/raw-loss = 0.5275343060493469, train/logprobs = tensor([[-0.1150, -0.7908],
        [-0.3125, -0.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07142206281423569
Epoch 0, Step 955: train/loss = 0.4417266249656677, train/raw-loss = 0.3503688871860504, train/logprobs = tensor([[-0.1669, -4.6001],
        [-0.3656, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09135770797729492
Epoch 0, Step 956: train/loss = 0.4956143796443939, train/raw-loss = 0.39108431339263916, train/logprobs = tensor([[-0.2185, -2.3481],
        [-0.4955, -0.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453008115291595
Epoch 0, Step 957: train/loss = 0.582199215888977, train/raw-loss = 0.4681653082370758, train/logprobs = tensor([[-0.4167, -4.6804],
        [-0.4301, -1.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11403387784957886
Epoch 0, Step 958: train/loss = 0.5761353373527527, train/raw-loss = 0.46898093819618225, train/logprobs = tensor([[-0.2517, -2.5214],
        [-0.3409, -0.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10715440660715103
Epoch 0, Step 959: train/loss = 0.49272939562797546, train/raw-loss = 0.3941763937473297, train/logprobs = tensor([[-0.1202, -2.6652],
        [-0.4443, -0.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855300188064575
Epoch 0, Step 960: train/loss = 0.632004976272583, train/raw-loss = 0.5437142848968506, train/logprobs = tensor([[-0.1491, -0.6686],
        [-0.4274, -0.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882907584309578
Epoch 0, Step 961: train/loss = 0.5117870569229126, train/raw-loss = 0.3942461609840393, train/logprobs = tensor([[-0.2554, -1.7830],
        [-0.5658, -0.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754082143306732
Epoch 0, Step 962: train/loss = 0.5628159046173096, train/raw-loss = 0.45210888981819153, train/logprobs = tensor([[-0.4775, -3.1350],
        [-0.5706, -0.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11070699244737625
Epoch 0, Step 963: train/loss = 0.6215118169784546, train/raw-loss = 0.5279611349105835, train/logprobs = tensor([[-0.1874, -0.9605],
        [-0.3570, -0.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09355071932077408
Epoch 0, Step 964: train/loss = 0.5768049955368042, train/raw-loss = 0.4657459855079651, train/logprobs = tensor([[-0.2466, -1.6477],
        [-0.4787, -0.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11105898022651672
Epoch 0, Step 965: train/loss = 0.558096170425415, train/raw-loss = 0.44684016704559326, train/logprobs = tensor([[-0.4897, -3.2168],
        [-0.5200, -0.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11125597357749939
Epoch 0, Step 966: train/loss = 0.5940444469451904, train/raw-loss = 0.503351092338562, train/logprobs = tensor([[-0.1516, -1.7043],
        [-0.3870, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09069330245256424
Epoch 0, Step 967: train/loss = 0.5970010757446289, train/raw-loss = 0.5317864418029785, train/logprobs = tensor([[-0.1086, -0.7798],
        [-0.2964, -0.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06521463394165039
Epoch 0, Step 968: train/loss = 0.5285879373550415, train/raw-loss = 0.43456992506980896, train/logprobs = tensor([[-0.3291, -2.2232],
        [-0.8462, -0.2063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401800483465195
Epoch 0, Step 969: train/loss = 0.5557420253753662, train/raw-loss = 0.46655431389808655, train/logprobs = tensor([[-0.3160, -4.0420],
        [-0.5018, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08918775618076324
Epoch 0, Step 970: train/loss = 0.5752734541893005, train/raw-loss = 0.47718244791030884, train/logprobs = tensor([[-0.2526, -1.4205],
        [-0.3471, -0.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09809097647666931
Epoch 0, Step 971: train/loss = 0.5386256575584412, train/raw-loss = 0.4403069019317627, train/logprobs = tensor([[-0.0614, -2.4883],
        [-0.1892, -0.2709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09831878542900085
Epoch 0, Step 972: train/loss = 0.6130682826042175, train/raw-loss = 0.5281786918640137, train/logprobs = tensor([[-0.3630, -3.1145],
        [-0.2096, -0.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08488959819078445
Epoch 0, Step 973: train/loss = 0.6096807718276978, train/raw-loss = 0.5312310457229614, train/logprobs = tensor([[-0.1162, -1.5847],
        [-0.2214, -0.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07844974845647812
Epoch 0, Step 974: train/loss = 0.5931320190429688, train/raw-loss = 0.4642174243927002, train/logprobs = tensor([[-0.3613, -1.9260],
        [-0.6319, -0.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12891459465026855
Epoch 0, Step 975: train/loss = 0.5322924852371216, train/raw-loss = 0.42452532052993774, train/logprobs = tensor([[-0.1452, -1.7869],
        [-0.2881, -0.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776716470718384
Epoch 0, Step 976: train/loss = 0.631058394908905, train/raw-loss = 0.5213431119918823, train/logprobs = tensor([[-0.2391, -2.4501],
        [-0.3900, -0.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10971532762050629
Epoch 0, Step 977: train/loss = 0.5703840255737305, train/raw-loss = 0.47701793909072876, train/logprobs = tensor([[-0.1638, -2.0036],
        [-0.3036, -0.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933661237359047
Epoch 0, Step 978: train/loss = 0.5792656540870667, train/raw-loss = 0.4808690547943115, train/logprobs = tensor([[-0.4812, -1.8206],
        [-0.3999, -0.2889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09839658439159393
Epoch 0, Step 979: train/loss = 0.6129430532455444, train/raw-loss = 0.5179067850112915, train/logprobs = tensor([[-0.1668, -1.4855],
        [-0.3021, -0.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09503630548715591
Epoch 0, Step 980: train/loss = 0.47280335426330566, train/raw-loss = 0.3686583638191223, train/logprobs = tensor([[-0.2800, -2.3372],
        [-0.3412, -0.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10414499789476395
Epoch 0, Step 981: train/loss = 0.5132578611373901, train/raw-loss = 0.40675288438796997, train/logprobs = tensor([[-0.2306, -2.9718],
        [-0.3860, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10650499910116196
Epoch 0, Step 982: train/loss = 0.5121733546257019, train/raw-loss = 0.43139198422431946, train/logprobs = tensor([[-0.1675, -1.2394],
        [-0.3142, -0.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08078134804964066
Epoch 0, Step 983: train/loss = 0.5323218107223511, train/raw-loss = 0.4527626037597656, train/logprobs = tensor([[-0.2040, -2.0524],
        [-0.3780, -0.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07955922931432724
Epoch 0, Step 984: train/loss = 0.6373737454414368, train/raw-loss = 0.5466058850288391, train/logprobs = tensor([[-0.2536, -0.9106],
        [-0.3653, -0.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09076789021492004
Epoch 0, Step 985: train/loss = 0.6327126026153564, train/raw-loss = 0.5651580095291138, train/logprobs = tensor([[-0.1692, -0.6818],
        [-0.3178, -0.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06755458563566208
Epoch 0, Step 986: train/loss = 0.4537002742290497, train/raw-loss = 0.3148458003997803, train/logprobs = tensor([[-0.2999, -4.6819],
        [-0.5848, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885444402694702
Epoch 0, Step 987: train/loss = 0.8392804265022278, train/raw-loss = 0.7275296449661255, train/logprobs = tensor([[-1.0237, -0.8081],
        [-0.5032, -0.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11175073683261871
Epoch 0, Step 988: train/loss = 0.6066886186599731, train/raw-loss = 0.5134341716766357, train/logprobs = tensor([[-0.1539, -1.4692],
        [-0.4643, -0.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0932544618844986
Epoch 0, Step 989: train/loss = 0.5218893885612488, train/raw-loss = 0.4237191379070282, train/logprobs = tensor([[-0.1819, -1.4757],
        [-0.4461, -0.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817025065422058
Epoch 0, Step 990: train/loss = 0.5999542474746704, train/raw-loss = 0.5030266046524048, train/logprobs = tensor([[-0.1470, -1.3724],
        [-0.1914, -0.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0969276875257492
Epoch 0, Step 991: train/loss = 0.6516807079315186, train/raw-loss = 0.5903185606002808, train/logprobs = tensor([[-0.1948, -0.6236],
        [-0.2043, -0.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061362139880657196
Epoch 0, Step 992: train/loss = 0.5611687898635864, train/raw-loss = 0.44890570640563965, train/logprobs = tensor([[-0.1588, -1.8063],
        [-0.2356, -0.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11226308345794678
Epoch 0, Step 993: train/loss = 0.5232903361320496, train/raw-loss = 0.4241839647293091, train/logprobs = tensor([[-0.2288, -1.4377],
        [-0.5383, -0.2049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09910635650157928
Epoch 0, Step 994: train/loss = 0.4710824489593506, train/raw-loss = 0.30511078238487244, train/logprobs = tensor([[-0.5487, -2.8841],
        [-0.8235, -0.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16597169637680054
Epoch 0, Step 995: train/loss = 0.46424105763435364, train/raw-loss = 0.348371684551239, train/logprobs = tensor([[-0.2282, -2.7857],
        [-0.4494, -0.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11586937308311462
Epoch 0, Step 996: train/loss = 0.5829204320907593, train/raw-loss = 0.5101531744003296, train/logprobs = tensor([[-0.1077, -2.6288],
        [-0.3227, -0.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276725023984909
Epoch 0, Step 997: train/loss = 0.5349748134613037, train/raw-loss = 0.4094173014163971, train/logprobs = tensor([[-0.3258, -3.4229],
        [-0.3554, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12555745244026184
Epoch 0, Step 998: train/loss = 0.6185480952262878, train/raw-loss = 0.47803521156311035, train/logprobs = tensor([[-0.3021, -1.1637],
        [-0.5956, -0.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14051291346549988
Epoch 0, Step 999: train/loss = 0.5843412280082703, train/raw-loss = 0.5125695466995239, train/logprobs = tensor([[-0.3030, -1.2589],
        [-0.5750, -0.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07177171111106873
Epoch 0, Step 1000: train/loss = 0.5933476686477661, train/raw-loss = 0.47193074226379395, train/logprobs = tensor([[-0.2985, -0.8490],
        [-0.8902, -0.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141695618629456
Epoch 0, Step 1001: train/loss = 0.6067657470703125, train/raw-loss = 0.4941534399986267, train/logprobs = tensor([[-0.3180, -2.0498],
        [-0.5087, -0.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1126122772693634
Epoch 0, Step 1002: train/loss = 0.5997370481491089, train/raw-loss = 0.4882389307022095, train/logprobs = tensor([[-0.2978, -3.3591],
        [-0.5092, -0.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149808764457703
Epoch 0, Step 1003: train/loss = 0.5020955801010132, train/raw-loss = 0.3914673626422882, train/logprobs = tensor([[-0.2365, -2.2298],
        [-0.5692, -0.5104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062824726104736
Epoch 0, Step 1004: train/loss = 0.6966745853424072, train/raw-loss = 0.6286289691925049, train/logprobs = tensor([[-0.2103, -0.4743],
        [-0.1957, -0.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804561614990234
Epoch 0, Step 1005: train/loss = 0.3581022620201111, train/raw-loss = 0.2486805021762848, train/logprobs = tensor([[-0.1844, -4.8337],
        [-0.6217, -0.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10942180454730988
Epoch 0, Step 1006: train/loss = 0.6254040002822876, train/raw-loss = 0.5456688404083252, train/logprobs = tensor([[-0.2538, -0.8515],
        [-0.3564, -0.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07973521202802658
Epoch 0, Step 1007: train/loss = 0.7480021715164185, train/raw-loss = 0.6622467637062073, train/logprobs = tensor([[-1.1446, -1.0293],
        [-0.7980, -0.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08575528860092163
Epoch 0, Step 1008: train/loss = 0.539818525314331, train/raw-loss = 0.42865437269210815, train/logprobs = tensor([[-0.2814, -3.9312],
        [-0.2814, -0.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111641526222229
Epoch 0, Step 1009: train/loss = 0.58112633228302, train/raw-loss = 0.4997336268424988, train/logprobs = tensor([[-0.1456, -3.3105],
        [-0.4581, -0.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139271289110184
Epoch 0, Step 1010: train/loss = 0.5851463079452515, train/raw-loss = 0.49071720242500305, train/logprobs = tensor([[-0.1370, -2.3079],
        [-0.3489, -0.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09442907571792603
Epoch 0, Step 1011: train/loss = 0.6137787103652954, train/raw-loss = 0.5175362825393677, train/logprobs = tensor([[-0.2930, -1.0449],
        [-0.3978, -0.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09624238312244415
Epoch 0, Step 1012: train/loss = 0.4751395583152771, train/raw-loss = 0.33675095438957214, train/logprobs = tensor([[-0.2589, -2.9235],
        [-0.6525, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13838866353034973
Epoch 0, Step 1013: train/loss = 0.47158941626548767, train/raw-loss = 0.31930771470069885, train/logprobs = tensor([[-0.8678, -4.6315],
        [-0.9558, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522817313671112
Epoch 0, Step 1014: train/loss = 0.5606330037117004, train/raw-loss = 0.4364564120769501, train/logprobs = tensor([[-0.3561, -2.0076],
        [-0.5172, -0.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12417660653591156
Epoch 0, Step 1015: train/loss = 0.515914797782898, train/raw-loss = 0.39852243661880493, train/logprobs = tensor([[-0.1840, -2.3987],
        [-0.5876, -0.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11739233881235123
Epoch 0, Step 1016: train/loss = 0.5617914795875549, train/raw-loss = 0.4716567099094391, train/logprobs = tensor([[-0.2891, -3.2695],
        [-0.4623, -0.1921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09013477712869644
Epoch 0, Step 1017: train/loss = 0.5187245011329651, train/raw-loss = 0.3971761167049408, train/logprobs = tensor([[-0.1872, -4.1166],
        [-0.3762, -0.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12154841423034668
Epoch 0, Step 1018: train/loss = 0.5444979667663574, train/raw-loss = 0.43518680334091187, train/logprobs = tensor([[-0.2567, -1.3633],
        [-0.6451, -0.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10931119322776794
Epoch 0, Step 1019: train/loss = 0.5081714987754822, train/raw-loss = 0.401583731174469, train/logprobs = tensor([[-0.3343, -2.3506],
        [-0.4516, -0.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658775269985199
Epoch 0, Step 1020: train/loss = 0.5057165622711182, train/raw-loss = 0.4050058126449585, train/logprobs = tensor([[-0.1748, -4.0184],
        [-0.3245, -0.3176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10071071982383728
Epoch 0, Step 1021: train/loss = 0.4866151511669159, train/raw-loss = 0.37567734718322754, train/logprobs = tensor([[-0.4596, -4.3376],
        [-0.5810, -0.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11093775928020477
Epoch 0, Step 1022: train/loss = 0.595432460308075, train/raw-loss = 0.523999810218811, train/logprobs = tensor([[-0.2567, -0.9050],
        [-0.3410, -0.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0714327022433281
Epoch 0, Step 1023: train/loss = 0.5364377498626709, train/raw-loss = 0.4629511833190918, train/logprobs = tensor([[-0.2117, -1.4915],
        [-0.3367, -0.1860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0734865665435791
Epoch 0, Step 1024: train/loss = 0.5278632640838623, train/raw-loss = 0.4302356541156769, train/logprobs = tensor([[-0.1764, -2.1374],
        [-0.3484, -0.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09762758016586304
Epoch 0, Step 1025: train/loss = 0.5122560262680054, train/raw-loss = 0.4027721881866455, train/logprobs = tensor([[-0.4143, -2.8970],
        [-0.3999, -0.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948383808135986
Epoch 0, Step 1026: train/loss = 0.5432980060577393, train/raw-loss = 0.4169872999191284, train/logprobs = tensor([[-0.1999, -2.1371],
        [-0.4574, -0.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12631070613861084
Epoch 0, Step 1027: train/loss = 0.706000566482544, train/raw-loss = 0.658177375793457, train/logprobs = tensor([[-0.1090, -0.2071],
        [-0.2504, -0.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04782310500741005
Epoch 0, Step 1028: train/loss = 0.3952826261520386, train/raw-loss = 0.31994450092315674, train/logprobs = tensor([[-0.1569, -4.0197],
        [-0.7125, -0.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07533814013004303
Epoch 0, Step 1029: train/loss = 0.6206629872322083, train/raw-loss = 0.5303337574005127, train/logprobs = tensor([[-0.2885, -1.6268],
        [-0.2322, -0.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09032916277647018
Epoch 0, Step 1030: train/loss = 0.4959750175476074, train/raw-loss = 0.3890242576599121, train/logprobs = tensor([[-0.3414, -5.4453],
        [-0.6681, -0.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1069507747888565
Epoch 0, Step 1031: train/loss = 0.5982791185379028, train/raw-loss = 0.5139102339744568, train/logprobs = tensor([[-0.2187, -1.2655],
        [-0.4601, -0.3456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08436890691518784
Epoch 0, Step 1032: train/loss = 0.5510581135749817, train/raw-loss = 0.48087191581726074, train/logprobs = tensor([[-0.2874, -1.5995],
        [-0.5593, -0.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07018622756004333
Epoch 0, Step 1033: train/loss = 0.47199746966362, train/raw-loss = 0.3310299515724182, train/logprobs = tensor([[-0.3421, -3.2989],
        [-0.8745, -0.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14096751809120178
Epoch 0, Step 1034: train/loss = 0.5334835648536682, train/raw-loss = 0.41841524839401245, train/logprobs = tensor([[-0.2976, -1.8607],
        [-0.5290, -0.2822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11506831645965576
Epoch 0, Step 1035: train/loss = 0.6104404330253601, train/raw-loss = 0.4931500554084778, train/logprobs = tensor([[-0.4913, -1.6770],
        [-0.6004, -0.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11729037761688232
Epoch 0, Step 1036: train/loss = 0.6454821228981018, train/raw-loss = 0.5467550158500671, train/logprobs = tensor([[-0.1751, -1.9606],
        [-0.3170, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09872715175151825
Epoch 0, Step 1037: train/loss = 0.6294893622398376, train/raw-loss = 0.5183849930763245, train/logprobs = tensor([[-0.2871, -3.7560],
        [-0.4818, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11110438406467438
Epoch 0, Step 1038: train/loss = 0.5252772569656372, train/raw-loss = 0.41423842310905457, train/logprobs = tensor([[-0.4737, -2.0033],
        [-0.6102, -0.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11103881895542145
Epoch 0, Step 1039: train/loss = 0.46870023012161255, train/raw-loss = 0.36234092712402344, train/logprobs = tensor([[-0.1931, -8.6739],
        [-0.6116, -0.2155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10635930299758911
Epoch 0, Step 1040: train/loss = 0.6099116802215576, train/raw-loss = 0.5101867914199829, train/logprobs = tensor([[-0.1304, -1.1465],
        [-0.3520, -0.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09972488135099411
Epoch 0, Step 1041: train/loss = 0.5216342806816101, train/raw-loss = 0.3695313632488251, train/logprobs = tensor([[-0.3728, -4.9101],
        [-0.3570, -0.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15210288763046265
Epoch 0, Step 1042: train/loss = 0.5464053153991699, train/raw-loss = 0.4591478705406189, train/logprobs = tensor([[-0.2670, -1.4666],
        [-0.3960, -0.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0872574895620346
Epoch 0, Step 1043: train/loss = 0.7302215695381165, train/raw-loss = 0.6215075850486755, train/logprobs = tensor([[-0.5195, -0.8442],
        [-0.3877, -0.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1087140291929245
Epoch 0, Step 1044: train/loss = 0.6176791191101074, train/raw-loss = 0.5178007483482361, train/logprobs = tensor([[-0.1235, -0.8712],
        [-0.7576, -0.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09987832605838776
Epoch 0, Step 1045: train/loss = 0.5343042016029358, train/raw-loss = 0.4446066617965698, train/logprobs = tensor([[-0.1774, -2.6890],
        [-0.4054, -0.1591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969753980636597
Epoch 0, Step 1046: train/loss = 0.5724210739135742, train/raw-loss = 0.456440806388855, train/logprobs = tensor([[-0.1737, -2.1976],
        [-0.4354, -0.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11598026007413864
Epoch 0, Step 1047: train/loss = 0.6183220744132996, train/raw-loss = 0.5312154293060303, train/logprobs = tensor([[-0.1019, -0.9783],
        [-0.1877, -0.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0871066302061081
Epoch 0, Step 1048: train/loss = 0.38388776779174805, train/raw-loss = 0.2690860331058502, train/logprobs = tensor([[-0.0936, -6.5385],
        [-0.5410, -0.0344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11480173468589783
Epoch 0, Step 1049: train/loss = 0.47758495807647705, train/raw-loss = 0.3714963495731354, train/logprobs = tensor([[-0.1154, -2.2678],
        [-0.4873, -0.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10608860850334167
Epoch 0, Step 1050: train/loss = 0.6260486245155334, train/raw-loss = 0.5195075869560242, train/logprobs = tensor([[-0.2464, -1.0056],
        [-0.4607, -0.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10654103755950928
Epoch 0, Step 1051: train/loss = 0.6381504535675049, train/raw-loss = 0.5846461057662964, train/logprobs = tensor([[-0.0604, -0.5787],
        [-0.1140, -0.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05350435525178909
Epoch 0, Step 1052: train/loss = 0.5243752002716064, train/raw-loss = 0.42024242877960205, train/logprobs = tensor([[-0.1805, -1.9979],
        [-0.4135, -0.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10413277894258499
Epoch 0, Step 1053: train/loss = 0.47229528427124023, train/raw-loss = 0.3523397445678711, train/logprobs = tensor([[-0.3994, -3.2425],
        [-0.6667, -0.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11995556950569153
Epoch 0, Step 1054: train/loss = 0.6656933426856995, train/raw-loss = 0.5748429894447327, train/logprobs = tensor([[-0.4615, -1.0288],
        [-0.3469, -0.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0908503383398056
Epoch 0, Step 1055: train/loss = 0.6150400638580322, train/raw-loss = 0.5106730461120605, train/logprobs = tensor([[-0.3060, -3.1956],
        [-0.5063, -0.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436701774597168
Epoch 0, Step 1056: train/loss = 0.5795003175735474, train/raw-loss = 0.46231257915496826, train/logprobs = tensor([[-0.3157, -2.8131],
        [-0.3529, -0.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1171877384185791
Epoch 0, Step 1057: train/loss = 0.4719211161136627, train/raw-loss = 0.3595845699310303, train/logprobs = tensor([[-0.1566, -4.1278],
        [-0.4735, -0.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11233656853437424
Epoch 0, Step 1058: train/loss = 0.47291332483291626, train/raw-loss = 0.36641180515289307, train/logprobs = tensor([[-0.1943, -2.1028],
        [-0.6409, -0.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1065015196800232
Epoch 0, Step 1059: train/loss = 0.6483532190322876, train/raw-loss = 0.5813691020011902, train/logprobs = tensor([[-0.2666, -0.6044],
        [-0.3339, -0.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698411703109741
Epoch 0, Step 1060: train/loss = 0.6630678772926331, train/raw-loss = 0.5633678436279297, train/logprobs = tensor([[-0.2053, -1.0313],
        [-0.4145, -0.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09970006346702576
Epoch 0, Step 1061: train/loss = 0.6036792397499084, train/raw-loss = 0.47989410161972046, train/logprobs = tensor([[-0.2334, -2.8970],
        [-0.4428, -1.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1237851232290268
Epoch 0, Step 1062: train/loss = 0.5652294158935547, train/raw-loss = 0.4286652207374573, train/logprobs = tensor([[-0.3328, -1.8384],
        [-0.7328, -0.3062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365641951560974
Epoch 0, Step 1063: train/loss = 0.6319531202316284, train/raw-loss = 0.5544195175170898, train/logprobs = tensor([[-0.2304, -0.8543],
        [-0.3731, -0.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07753361761569977
Epoch 0, Step 1064: train/loss = 0.517033576965332, train/raw-loss = 0.41958558559417725, train/logprobs = tensor([[-0.2783, -3.5606],
        [-0.3878, -0.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974479615688324
Epoch 0, Step 1065: train/loss = 0.637872576713562, train/raw-loss = 0.5535597205162048, train/logprobs = tensor([[-0.1772, -0.8180],
        [-0.3879, -0.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08431289345026016
Epoch 0, Step 1066: train/loss = 0.5626999139785767, train/raw-loss = 0.47260645031929016, train/logprobs = tensor([[-0.2536, -2.5012],
        [-0.1837, -0.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009341895580292
Epoch 0, Step 1067: train/loss = 0.4124423563480377, train/raw-loss = 0.24723920226097107, train/logprobs = tensor([[-0.2169, -6.2841],
        [-0.5420, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16520312428474426
Epoch 0, Step 1068: train/loss = 0.5245380997657776, train/raw-loss = 0.4260084629058838, train/logprobs = tensor([[-0.3488, -2.0919],
        [-0.5964, -0.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0985296219587326
Epoch 0, Step 1069: train/loss = 0.610926628112793, train/raw-loss = 0.474725604057312, train/logprobs = tensor([[-0.5268, -3.9902],
        [-0.3715, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13620103895664215
Epoch 0, Step 1070: train/loss = 0.4662873446941376, train/raw-loss = 0.3431794345378876, train/logprobs = tensor([[-0.4709, -3.5550],
        [-0.6846, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1231079250574112
Epoch 0, Step 1071: train/loss = 0.3662446439266205, train/raw-loss = 0.2551327049732208, train/logprobs = tensor([[-0.2037, -3.4853],
        [-0.5920, -0.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11111194640398026
Epoch 0, Step 1072: train/loss = 0.3649372160434723, train/raw-loss = 0.239397332072258, train/logprobs = tensor([[-0.1443, -5.8949],
        [-0.5932, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255398988723755
Epoch 0, Step 1073: train/loss = 0.569054901599884, train/raw-loss = 0.4307153522968292, train/logprobs = tensor([[-0.2104, -4.5351],
        [-0.3774, -1.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383395493030548
Epoch 0, Step 1074: train/loss = 0.5025799870491028, train/raw-loss = 0.40857434272766113, train/logprobs = tensor([[-0.1425, -3.0986],
        [-0.4403, -0.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09400563687086105
Epoch 0, Step 1075: train/loss = 0.5456911325454712, train/raw-loss = 0.4400782883167267, train/logprobs = tensor([[-0.1600, -2.4064],
        [-0.4168, -0.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056128665804863
Epoch 0, Step 1076: train/loss = 0.6205095648765564, train/raw-loss = 0.48881766200065613, train/logprobs = tensor([[-0.2061, -1.9251],
        [-0.3126, -0.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13169188797473907
Epoch 0, Step 1077: train/loss = 0.5916491746902466, train/raw-loss = 0.4781150817871094, train/logprobs = tensor([[-0.2607, -1.0837],
        [-0.4572, -0.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11353416740894318
Epoch 0, Step 1078: train/loss = 0.5451734066009521, train/raw-loss = 0.46850576996803284, train/logprobs = tensor([[-0.4327, -1.6388],
        [-0.5520, -0.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0766676664352417
Epoch 0, Step 1079: train/loss = 0.49255603551864624, train/raw-loss = 0.3402877748012543, train/logprobs = tensor([[-0.4647, -4.2517],
        [-0.6895, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15226823091506958
Epoch 0, Step 1080: train/loss = 0.6802566051483154, train/raw-loss = 0.5671108365058899, train/logprobs = tensor([[-0.4430, -1.8792],
        [-0.4092, -0.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11314576864242554
Epoch 0, Step 1081: train/loss = 0.4828566312789917, train/raw-loss = 0.3306151330471039, train/logprobs = tensor([[-0.7759, -3.5838],
        [-0.6891, -0.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522415578365326
Epoch 0, Step 1082: train/loss = 0.6808038353919983, train/raw-loss = 0.6007064580917358, train/logprobs = tensor([[-0.2180, -0.5773],
        [-0.2998, -0.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08009737730026245
Epoch 0, Step 1083: train/loss = 0.6002846956253052, train/raw-loss = 0.4992671608924866, train/logprobs = tensor([[-0.2982, -1.4498],
        [-0.4636, -0.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10101756453514099
Epoch 0, Step 1084: train/loss = 0.5575976371765137, train/raw-loss = 0.4562879204750061, train/logprobs = tensor([[-0.1802, -2.6460],
        [-0.2969, -0.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130975395441055
Epoch 0, Step 1085: train/loss = 0.6183127164840698, train/raw-loss = 0.5253236293792725, train/logprobs = tensor([[-0.3975, -2.5184],
        [-0.3711, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09298914670944214
Epoch 0, Step 1086: train/loss = 0.527766227722168, train/raw-loss = 0.40289169549942017, train/logprobs = tensor([[-0.3723, -3.7736],
        [-0.5103, -0.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12487451732158661
Epoch 0, Step 1087: train/loss = 0.5281915664672852, train/raw-loss = 0.42466306686401367, train/logprobs = tensor([[-0.1088, -3.2059],
        [-0.3756, -0.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10352849960327148
Epoch 0, Step 1088: train/loss = 0.5737868547439575, train/raw-loss = 0.46690502762794495, train/logprobs = tensor([[-0.3306, -1.0629],
        [-0.6083, -0.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10688183456659317
Epoch 0, Step 1089: train/loss = 0.5556085705757141, train/raw-loss = 0.47453150153160095, train/logprobs = tensor([[-0.2485, -1.7127],
        [-0.2232, -0.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08107706159353256
Epoch 0, Step 1090: train/loss = 0.4909448027610779, train/raw-loss = 0.3758479654788971, train/logprobs = tensor([[-0.2134, -2.1501],
        [-0.8271, -0.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11509684473276138
Epoch 0, Step 1091: train/loss = 0.41178274154663086, train/raw-loss = 0.32635021209716797, train/logprobs = tensor([[-0.0585, -2.7168],
        [-0.3989, -0.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08543252944946289
Epoch 0, Step 1092: train/loss = 0.46567660570144653, train/raw-loss = 0.3621213734149933, train/logprobs = tensor([[-0.4629, -2.5681],
        [-0.6810, -0.4720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355523228645325
Epoch 0, Step 1093: train/loss = 0.5547912120819092, train/raw-loss = 0.445100873708725, train/logprobs = tensor([[-0.2730, -2.2079],
        [-0.5002, -0.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10969033092260361
Epoch 0, Step 1094: train/loss = 0.5440807938575745, train/raw-loss = 0.4536154270172119, train/logprobs = tensor([[-0.0941, -1.1735],
        [-0.2868, -0.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09046537429094315
Epoch 0, Step 1095: train/loss = 0.6390751600265503, train/raw-loss = 0.5336613655090332, train/logprobs = tensor([[-0.2534, -2.3853],
        [-0.2965, -0.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10541381686925888
Epoch 0, Step 1096: train/loss = 0.5212454199790955, train/raw-loss = 0.3861493468284607, train/logprobs = tensor([[-0.5382, -5.3121],
        [-0.4748, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13509604334831238
Epoch 0, Step 1097: train/loss = 0.49181854724884033, train/raw-loss = 0.37018483877182007, train/logprobs = tensor([[-0.3797, -2.0657],
        [-0.5958, -0.2040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12163373082876205
Epoch 0, Step 1098: train/loss = 0.5190708637237549, train/raw-loss = 0.40101420879364014, train/logprobs = tensor([[-0.2615, -4.3872],
        [-0.4737, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11805665493011475
Epoch 0, Step 1099: train/loss = 0.6739275455474854, train/raw-loss = 0.5691643953323364, train/logprobs = tensor([[-0.1484, -0.8965],
        [-0.3309, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047632098197937
Epoch 0, Step 1100: train/loss = 0.5163556337356567, train/raw-loss = 0.4159240126609802, train/logprobs = tensor([[-0.3004, -2.3235],
        [-0.5605, -0.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10043160617351532
Epoch 0, Step 1101: train/loss = 0.46250277757644653, train/raw-loss = 0.36291393637657166, train/logprobs = tensor([[-0.2009, -5.9982],
        [-0.4843, -0.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09958885610103607
Epoch 0, Step 1102: train/loss = 0.5794338583946228, train/raw-loss = 0.43872910737991333, train/logprobs = tensor([[-0.7110, -3.4856],
        [-0.4057, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14070472121238708
Epoch 0, Step 1103: train/loss = 0.46853139996528625, train/raw-loss = 0.33122366666793823, train/logprobs = tensor([[-0.5658, -4.8173],
        [-0.6337, -0.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13730771839618683
Epoch 0, Step 1104: train/loss = 0.6601296067237854, train/raw-loss = 0.5750160217285156, train/logprobs = tensor([[-0.3003, -2.8605],
        [-0.3302, -0.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08511361479759216
Epoch 0, Step 1105: train/loss = 0.5353377461433411, train/raw-loss = 0.4291677176952362, train/logprobs = tensor([[-0.3089, -2.3193],
        [-0.2318, -0.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617002099752426
Epoch 0, Step 1106: train/loss = 0.5885542631149292, train/raw-loss = 0.44738394021987915, train/logprobs = tensor([[-0.8070, -4.2171],
        [-0.5526, -0.2144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14117029309272766
Epoch 0, Step 1107: train/loss = 0.5208483934402466, train/raw-loss = 0.3950425982475281, train/logprobs = tensor([[-0.2621, -3.3105],
        [-0.3948, -0.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258057951927185
Epoch 0, Step 1108: train/loss = 0.5040417909622192, train/raw-loss = 0.41179436445236206, train/logprobs = tensor([[-0.1703, -2.5233],
        [-0.2392, -0.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09224739670753479
Epoch 0, Step 1109: train/loss = 0.5341992974281311, train/raw-loss = 0.43524405360221863, train/logprobs = tensor([[-0.4946, -2.6175],
        [-0.5619, -0.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09895522892475128
Epoch 0, Step 1110: train/loss = 0.5892535448074341, train/raw-loss = 0.5048408508300781, train/logprobs = tensor([[-0.2595, -3.6278],
        [-0.2470, -0.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08441267907619476
Epoch 0, Step 1111: train/loss = 0.5169187784194946, train/raw-loss = 0.4028312563896179, train/logprobs = tensor([[-0.4037, -4.2507],
        [-0.3821, -0.3748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11408760398626328
Epoch 0, Step 1112: train/loss = 0.5632300972938538, train/raw-loss = 0.46327507495880127, train/logprobs = tensor([[-0.4696, -5.1515],
        [-0.6726, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995505213737488
Epoch 0, Step 1113: train/loss = 0.6401892900466919, train/raw-loss = 0.5558468103408813, train/logprobs = tensor([[-0.1947, -0.8607],
        [-0.2898, -0.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08434244990348816
Epoch 0, Step 1114: train/loss = 0.5600138902664185, train/raw-loss = 0.4371064305305481, train/logprobs = tensor([[-0.2954, -1.5596],
        [-0.4613, -0.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12290745228528976
Epoch 0, Step 1115: train/loss = 0.5936435461044312, train/raw-loss = 0.5052066445350647, train/logprobs = tensor([[-0.1346, -1.4125],
        [-0.2036, -0.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843687921762466
Epoch 0, Step 1116: train/loss = 0.6473761796951294, train/raw-loss = 0.5588063597679138, train/logprobs = tensor([[-0.2771, -1.5202],
        [-0.4893, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08856978267431259
Epoch 0, Step 1117: train/loss = 0.6109368801116943, train/raw-loss = 0.5117707252502441, train/logprobs = tensor([[-0.3309, -1.4941],
        [-0.6188, -0.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09916608035564423
Epoch 0, Step 1118: train/loss = 0.6256079077720642, train/raw-loss = 0.5336652994155884, train/logprobs = tensor([[-0.1680, -1.2475],
        [-0.2076, -0.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194259345531464
Epoch 0, Step 1119: train/loss = 0.5548993349075317, train/raw-loss = 0.4432165324687958, train/logprobs = tensor([[-0.1764, -3.1778],
        [-0.4069, -0.4613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11168279498815536
Epoch 0, Step 1120: train/loss = 0.49462926387786865, train/raw-loss = 0.33840444684028625, train/logprobs = tensor([[-0.6110, -3.2248],
        [-0.8776, -0.5029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562248319387436
Epoch 0, Step 1121: train/loss = 0.5771341919898987, train/raw-loss = 0.42784446477890015, train/logprobs = tensor([[-0.4962, -2.1554],
        [-0.6849, -0.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14928969740867615
Epoch 0, Step 1122: train/loss = 0.6197372674942017, train/raw-loss = 0.5291621685028076, train/logprobs = tensor([[-0.1394, -1.5201],
        [-0.4061, -0.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09057508409023285
Epoch 0, Step 1123: train/loss = 0.4283265471458435, train/raw-loss = 0.28354987502098083, train/logprobs = tensor([[-0.4977, -5.5109],
        [-0.6756, -0.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14477668702602386
Epoch 0, Step 1124: train/loss = 0.467218279838562, train/raw-loss = 0.3658362030982971, train/logprobs = tensor([[-0.2269, -6.9755],
        [-0.4810, -1.2727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138210654258728
Epoch 0, Step 1125: train/loss = 0.49780282378196716, train/raw-loss = 0.3808954954147339, train/logprobs = tensor([[-0.3173, -2.2789],
        [-0.4332, -0.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11690735071897507
Epoch 0, Step 1126: train/loss = 0.5959426760673523, train/raw-loss = 0.4759976863861084, train/logprobs = tensor([[-0.4082, -5.3768],
        [-0.5289, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199449896812439
Epoch 0, Step 1127: train/loss = 0.5370133519172668, train/raw-loss = 0.42962759733200073, train/logprobs = tensor([[-0.2059, -1.7572],
        [-0.2390, -0.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10738574713468552
Epoch 0, Step 1128: train/loss = 0.6893362402915955, train/raw-loss = 0.5618571639060974, train/logprobs = tensor([[-0.9188, -1.6821],
        [-0.6044, -0.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12747910618782043
Epoch 0, Step 1129: train/loss = 0.4988769590854645, train/raw-loss = 0.37045717239379883, train/logprobs = tensor([[-0.2514, -2.5273],
        [-0.6266, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12841977179050446
Epoch 0, Step 1130: train/loss = 0.61266028881073, train/raw-loss = 0.4954105317592621, train/logprobs = tensor([[-0.1377, -1.6526],
        [-0.2449, -0.2339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1172497570514679
Epoch 0, Step 1131: train/loss = 0.47740891575813293, train/raw-loss = 0.4013311564922333, train/logprobs = tensor([[-0.0669, -2.8280],
        [-0.2091, -0.3681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07607779651880264
Epoch 0, Step 1132: train/loss = 0.5932870507240295, train/raw-loss = 0.4962581992149353, train/logprobs = tensor([[-0.2012, -2.8240],
        [-0.3527, -0.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09702887386083603
Epoch 0, Step 1133: train/loss = 0.6648685336112976, train/raw-loss = 0.583335816860199, train/logprobs = tensor([[-0.1877, -0.7129],
        [-0.2929, -0.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08153265714645386
Epoch 0, Step 1134: train/loss = 0.5235001444816589, train/raw-loss = 0.4228244423866272, train/logprobs = tensor([[-0.4923, -4.3987],
        [-0.5072, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10067571699619293
Epoch 0, Step 1135: train/loss = 0.5333505272865295, train/raw-loss = 0.42745035886764526, train/logprobs = tensor([[-0.1682, -2.1563],
        [-0.3731, -0.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10590014606714249
Epoch 0, Step 1136: train/loss = 0.5052245855331421, train/raw-loss = 0.40308281779289246, train/logprobs = tensor([[-0.1498, -4.3076],
        [-0.4308, -0.4396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214173793792725
Epoch 0, Step 1137: train/loss = 0.5011078119277954, train/raw-loss = 0.4125465154647827, train/logprobs = tensor([[-0.3105, -3.7347],
        [-0.5879, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885612815618515
Epoch 0, Step 1138: train/loss = 0.6348119974136353, train/raw-loss = 0.5581521987915039, train/logprobs = tensor([[-0.2117, -0.7027],
        [-0.3113, -0.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07665979862213135
Epoch 0, Step 1139: train/loss = 0.5700348019599915, train/raw-loss = 0.43550729751586914, train/logprobs = tensor([[-0.3246, -1.7810],
        [-0.5709, -0.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13452748954296112
Epoch 0, Step 1140: train/loss = 0.5401462316513062, train/raw-loss = 0.4189442992210388, train/logprobs = tensor([[-0.3434, -4.7931],
        [-0.4669, -0.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120190262794495
Epoch 0, Step 1141: train/loss = 0.5270430445671082, train/raw-loss = 0.40022656321525574, train/logprobs = tensor([[-0.1617, -3.7124],
        [-0.3678, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12681646645069122
Epoch 0, Step 1142: train/loss = 0.5250006914138794, train/raw-loss = 0.4377185106277466, train/logprobs = tensor([[-0.3119, -1.7086],
        [-0.6848, -0.4081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08728215098381042
Epoch 0, Step 1143: train/loss = 0.6354079246520996, train/raw-loss = 0.5513690114021301, train/logprobs = tensor([[-0.2434, -0.6498],
        [-0.4144, -0.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08403889834880829
Epoch 0, Step 1144: train/loss = 0.5090818405151367, train/raw-loss = 0.404411643743515, train/logprobs = tensor([[-0.1247, -2.8407],
        [-0.1087, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10467015951871872
Epoch 0, Step 1145: train/loss = 0.41680675745010376, train/raw-loss = 0.3116370439529419, train/logprobs = tensor([[-0.1866, -4.0326],
        [-0.2758, -0.3272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10516972839832306
Epoch 0, Step 1146: train/loss = 0.40585005283355713, train/raw-loss = 0.24414534866809845, train/logprobs = tensor([[-0.3374, -7.6490],
        [-0.5642, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16170470416545868
Epoch 0, Step 1147: train/loss = 0.4775712788105011, train/raw-loss = 0.32668817043304443, train/logprobs = tensor([[-0.4519, -3.1356],
        [-0.6696, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15088312327861786
Epoch 0, Step 1148: train/loss = 0.5744085311889648, train/raw-loss = 0.4795738458633423, train/logprobs = tensor([[-0.3037, -1.1886],
        [-0.4696, -0.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483468532562256
Epoch 0, Step 1149: train/loss = 0.5176453590393066, train/raw-loss = 0.38174763321876526, train/logprobs = tensor([[-0.3577, -2.8059],
        [-0.5148, -0.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.135897696018219
Epoch 0, Step 1150: train/loss = 0.6238369345664978, train/raw-loss = 0.5107735991477966, train/logprobs = tensor([[-0.4560, -2.2027],
        [-0.2239, -0.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11306335031986237
Epoch 0, Step 1151: train/loss = 0.4916728138923645, train/raw-loss = 0.33516883850097656, train/logprobs = tensor([[-0.5159, -6.2445],
        [-0.8780, -0.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15650396049022675
Epoch 0, Step 1152: train/loss = 0.4049929976463318, train/raw-loss = 0.2422594130039215, train/logprobs = tensor([[-0.3026, -5.8169],
        [-0.6799, -0.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16273358464241028
Epoch 0, Step 1153: train/loss = 0.5799717903137207, train/raw-loss = 0.4982244372367859, train/logprobs = tensor([[-0.1796, -1.5805],
        [-0.2788, -0.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174736797809601
Epoch 0, Step 1154: train/loss = 0.5968047976493835, train/raw-loss = 0.4920581579208374, train/logprobs = tensor([[-0.3129, -2.5155],
        [-0.2496, -0.4116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10474667698144913
Epoch 0, Step 1155: train/loss = 0.5528725981712341, train/raw-loss = 0.4482154846191406, train/logprobs = tensor([[-0.2572, -2.6341],
        [-0.4960, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10465706884860992
Epoch 0, Step 1156: train/loss = 0.6194093227386475, train/raw-loss = 0.5073312520980835, train/logprobs = tensor([[-0.3238, -0.8605],
        [-0.6352, -0.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11207811534404755
Epoch 0, Step 1157: train/loss = 0.5830695629119873, train/raw-loss = 0.46938976645469666, train/logprobs = tensor([[-0.3875, -4.6353],
        [-0.3186, -2.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367980390787125
Epoch 0, Step 1158: train/loss = 0.4759599268436432, train/raw-loss = 0.3377309739589691, train/logprobs = tensor([[-0.2994, -2.7710],
        [-0.5678, -0.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1382288932800293
Epoch 0, Step 1159: train/loss = 0.523910403251648, train/raw-loss = 0.41743820905685425, train/logprobs = tensor([[-0.2069, -2.0623],
        [-0.3630, -0.4218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10647216439247131
Epoch 0, Step 1160: train/loss = 0.645346462726593, train/raw-loss = 0.5566980838775635, train/logprobs = tensor([[-0.2651, -1.1126],
        [-0.3104, -0.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08864837139844894
Epoch 0, Step 1161: train/loss = 0.5706462860107422, train/raw-loss = 0.47233548760414124, train/logprobs = tensor([[-0.2139, -1.1604],
        [-0.4116, -0.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09831078350543976
Epoch 0, Step 1162: train/loss = 0.49790000915527344, train/raw-loss = 0.37401852011680603, train/logprobs = tensor([[-0.1809, -4.1009],
        [-0.6572, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12388148903846741
Epoch 0, Step 1163: train/loss = 0.6015378832817078, train/raw-loss = 0.45557740330696106, train/logprobs = tensor([[-0.2455, -5.3138],
        [-0.3695, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1459605097770691
Epoch 0, Step 1164: train/loss = 0.5296908617019653, train/raw-loss = 0.4331241846084595, train/logprobs = tensor([[-0.2402, -4.5359],
        [-0.3950, -0.2880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09656663984060287
Epoch 0, Step 1165: train/loss = 0.4985293447971344, train/raw-loss = 0.40379637479782104, train/logprobs = tensor([[-0.1152, -2.3989],
        [-0.3545, -0.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473292529582977
Epoch 0, Step 1166: train/loss = 0.5329846143722534, train/raw-loss = 0.3914584517478943, train/logprobs = tensor([[-0.4274, -1.8036],
        [-0.7610, -0.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14152614772319794
Epoch 0, Step 1167: train/loss = 0.5582530498504639, train/raw-loss = 0.4705321192741394, train/logprobs = tensor([[-0.1887, -2.9974],
        [-0.2934, -0.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772096037864685
Epoch 0, Step 1168: train/loss = 0.5698617100715637, train/raw-loss = 0.4915584921836853, train/logprobs = tensor([[-0.4979, -2.6779],
        [-0.5874, -0.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830321788787842
Epoch 0, Step 1169: train/loss = 0.8167431950569153, train/raw-loss = 0.6504021286964417, train/logprobs = tensor([[-2.0518, -3.8481],
        [-1.0719, -0.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16634109616279602
Epoch 0, Step 1170: train/loss = 0.41619622707366943, train/raw-loss = 0.3108224868774414, train/logprobs = tensor([[-0.1311, -4.5508],
        [-0.4349, -0.4357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10537372529506683
Epoch 0, Step 1171: train/loss = 0.639803409576416, train/raw-loss = 0.5677699446678162, train/logprobs = tensor([[-0.3183, -0.9189],
        [-0.4866, -0.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07203346490859985
Epoch 0, Step 1172: train/loss = 0.4356779456138611, train/raw-loss = 0.3177819848060608, train/logprobs = tensor([[-0.3111, -6.5919],
        [-0.6069, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11789596080780029
Epoch 0, Step 1173: train/loss = 0.37340474128723145, train/raw-loss = 0.2589590847492218, train/logprobs = tensor([[-0.2986, -5.5019],
        [-0.6095, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11444562673568726
Epoch 0, Step 1174: train/loss = 0.627488374710083, train/raw-loss = 0.5414741635322571, train/logprobs = tensor([[-0.4030, -1.2128],
        [-0.4912, -0.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08601419627666473
Epoch 0, Step 1175: train/loss = 0.4967048168182373, train/raw-loss = 0.3565020263195038, train/logprobs = tensor([[-0.5258, -3.2923],
        [-0.6564, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14020280539989471
Epoch 0, Step 1176: train/loss = 0.6100335717201233, train/raw-loss = 0.5482280850410461, train/logprobs = tensor([[-0.1062, -0.5888],
        [-0.3970, -0.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06180548667907715
Epoch 0, Step 1177: train/loss = 0.6325753331184387, train/raw-loss = 0.5230631232261658, train/logprobs = tensor([[-0.2686, -2.9525],
        [-0.2787, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951221734285355
Epoch 0, Step 1178: train/loss = 0.7145275473594666, train/raw-loss = 0.5688152313232422, train/logprobs = tensor([[-1.1143, -2.5110],
        [-0.3849, -0.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14571231603622437
Epoch 0, Step 1179: train/loss = 0.7509135007858276, train/raw-loss = 0.5676637887954712, train/logprobs = tensor([[-0.6001, -1.3053],
        [-0.4132, -0.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18324974179267883
Epoch 0, Step 1180: train/loss = 0.6428496241569519, train/raw-loss = 0.5459834337234497, train/logprobs = tensor([[-0.3422, -1.0221],
        [-0.5486, -0.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968661904335022
Epoch 0, Step 1181: train/loss = 0.537272572517395, train/raw-loss = 0.38617604970932007, train/logprobs = tensor([[-0.7692, -4.4995],
        [-0.3993, -0.4029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15109655261039734
Epoch 0, Step 1182: train/loss = 0.5817098021507263, train/raw-loss = 0.5054681301116943, train/logprobs = tensor([[-0.3365, -2.8073],
        [-0.6070, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07624167203903198
Epoch 0, Step 1183: train/loss = 0.6367045640945435, train/raw-loss = 0.5579022765159607, train/logprobs = tensor([[-0.3628, -1.7376],
        [-0.3193, -0.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07880231738090515
Epoch 0, Step 1184: train/loss = 0.6350560188293457, train/raw-loss = 0.5132851600646973, train/logprobs = tensor([[-0.2720, -1.7816],
        [-0.4600, -0.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177084386348724
Epoch 0, Step 1185: train/loss = 0.5316221714019775, train/raw-loss = 0.40356963872909546, train/logprobs = tensor([[-0.3648, -3.3369],
        [-0.7175, -0.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280525028705597
Epoch 0, Step 1186: train/loss = 0.5859870910644531, train/raw-loss = 0.5025120973587036, train/logprobs = tensor([[-0.2045, -2.2955],
        [-0.2867, -0.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08347497880458832
Epoch 0, Step 1187: train/loss = 0.5742672681808472, train/raw-loss = 0.4406317472457886, train/logprobs = tensor([[-0.5403, -4.0542],
        [-0.8593, -1.3825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336355209350586
Epoch 0, Step 1188: train/loss = 0.4935750961303711, train/raw-loss = 0.3723639249801636, train/logprobs = tensor([[-0.7561, -2.7448],
        [-0.9707, -0.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121117115020752
Epoch 0, Step 1189: train/loss = 0.5073320865631104, train/raw-loss = 0.38827401399612427, train/logprobs = tensor([[-0.1572, -1.7881],
        [-0.4389, -0.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11905810981988907
Epoch 0, Step 1190: train/loss = 0.5470154881477356, train/raw-loss = 0.4383646845817566, train/logprobs = tensor([[-0.2615, -1.6201],
        [-0.4560, -0.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10865083336830139
Epoch 0, Step 1191: train/loss = 0.4785369634628296, train/raw-loss = 0.33759599924087524, train/logprobs = tensor([[-0.2848, -5.3778],
        [-0.4929, -0.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14094096422195435
Epoch 0, Step 1192: train/loss = 0.4005497097969055, train/raw-loss = 0.2770300507545471, train/logprobs = tensor([[-0.3001, -7.6458],
        [-0.4432, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1235196590423584
Epoch 0, Step 1193: train/loss = 0.6167128086090088, train/raw-loss = 0.4670598804950714, train/logprobs = tensor([[-0.2558, -1.2707],
        [-0.6871, -0.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14965295791625977
Epoch 0, Step 1194: train/loss = 0.5936218500137329, train/raw-loss = 0.4792536795139313, train/logprobs = tensor([[-0.5950, -3.6315],
        [-0.2631, -0.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11436820775270462
Epoch 0, Step 1195: train/loss = 0.5670088529586792, train/raw-loss = 0.4419902265071869, train/logprobs = tensor([[-0.7923, -4.3700],
        [-0.6926, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12501861155033112
Epoch 0, Step 1196: train/loss = 0.5525499582290649, train/raw-loss = 0.42208465933799744, train/logprobs = tensor([[-0.4651, -4.3484],
        [-0.3354, -0.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1304652839899063
Epoch 0, Step 1197: train/loss = 0.3874194622039795, train/raw-loss = 0.2698213756084442, train/logprobs = tensor([[-0.2641, -3.5505],
        [-0.6404, -0.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11759807169437408
Epoch 0, Step 1198: train/loss = 0.5499799847602844, train/raw-loss = 0.4264967143535614, train/logprobs = tensor([[-0.5392, -3.9543],
        [-0.7053, -0.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12348322570323944
Epoch 0, Step 1199: train/loss = 0.7392363548278809, train/raw-loss = 0.6469586491584778, train/logprobs = tensor([[-0.2598, -0.3968],
        [-0.2614, -0.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0922776311635971
Epoch 0, Step 1200: train/loss = 0.5640255212783813, train/raw-loss = 0.47373166680336, train/logprobs = tensor([[-0.2713, -2.1604],
        [-0.3163, -0.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09029383212327957
Epoch 0, Step 1201: train/loss = 0.638839840888977, train/raw-loss = 0.5584348440170288, train/logprobs = tensor([[-0.2627, -1.1089],
        [-0.3625, -0.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08040495961904526
Epoch 0, Step 1202: train/loss = 0.41131049394607544, train/raw-loss = 0.27820149064064026, train/logprobs = tensor([[-0.3321, -6.5479],
        [-0.4137, -0.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13310901820659637
Epoch 0, Step 1203: train/loss = 0.4889848232269287, train/raw-loss = 0.36606866121292114, train/logprobs = tensor([[-0.3006, -5.9725],
        [-0.5736, -1.4888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12291614711284637
Epoch 0, Step 1204: train/loss = 0.5998983383178711, train/raw-loss = 0.5031585693359375, train/logprobs = tensor([[-0.6976, -1.2948],
        [-0.5804, -0.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09673981368541718
Epoch 0, Step 1205: train/loss = 0.6305148601531982, train/raw-loss = 0.5098643898963928, train/logprobs = tensor([[-0.4226, -1.8843],
        [-0.3439, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12065049260854721
Epoch 0, Step 1206: train/loss = 0.5795262455940247, train/raw-loss = 0.466722309589386, train/logprobs = tensor([[-0.3114, -3.6074],
        [-0.2956, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11280393600463867
Epoch 0, Step 1207: train/loss = 0.5014818906784058, train/raw-loss = 0.35704970359802246, train/logprobs = tensor([[-0.4982, -2.9935],
        [-0.6549, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444322019815445
Epoch 0, Step 1208: train/loss = 0.43751591444015503, train/raw-loss = 0.3059031069278717, train/logprobs = tensor([[-0.2093, -3.4304],
        [-0.5533, -0.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13161279261112213
Epoch 0, Step 1209: train/loss = 0.4865241050720215, train/raw-loss = 0.34486228227615356, train/logprobs = tensor([[-0.6873, -2.3034],
        [-1.2162, -0.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14166182279586792
Epoch 0, Step 1210: train/loss = 0.5568898320198059, train/raw-loss = 0.4073646068572998, train/logprobs = tensor([[-0.3306, -2.1908],
        [-0.5255, -0.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1495252251625061
Epoch 0, Step 1211: train/loss = 0.45456254482269287, train/raw-loss = 0.31055185198783875, train/logprobs = tensor([[-0.6090, -4.3147],
        [-0.6494, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14401070773601532
Epoch 0, Step 1212: train/loss = 0.6034055948257446, train/raw-loss = 0.507868230342865, train/logprobs = tensor([[-0.3971, -3.2253],
        [-0.3493, -0.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09553731977939606
Epoch 0, Step 1213: train/loss = 0.4752799868583679, train/raw-loss = 0.3598613142967224, train/logprobs = tensor([[-0.3165, -3.1074],
        [-0.4665, -0.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1154186949133873
Epoch 0, Step 1214: train/loss = 0.5513853430747986, train/raw-loss = 0.418317049741745, train/logprobs = tensor([[-0.2599, -3.6167],
        [-0.4411, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1330682933330536
Epoch 0, Step 1215: train/loss = 0.5597633123397827, train/raw-loss = 0.43243277072906494, train/logprobs = tensor([[-0.4119, -5.2370],
        [-0.4753, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12733054161071777
Epoch 0, Step 1216: train/loss = 0.5423367619514465, train/raw-loss = 0.42957228422164917, train/logprobs = tensor([[-0.1654, -4.4133],
        [-0.3693, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11276451498270035
Epoch 0, Step 1217: train/loss = 0.5463044047355652, train/raw-loss = 0.43610066175460815, train/logprobs = tensor([[-0.5524, -6.5540],
        [-0.7502, -2.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11020372807979584
Epoch 0, Step 1218: train/loss = 0.5112735033035278, train/raw-loss = 0.40550610423088074, train/logprobs = tensor([[-0.3257, -2.8275],
        [-0.4258, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057673916220665
Epoch 0, Step 1219: train/loss = 0.48107513785362244, train/raw-loss = 0.3508174419403076, train/logprobs = tensor([[-0.2809, -4.9606],
        [-0.6421, -0.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302577257156372
Epoch 0, Step 1220: train/loss = 0.7509053945541382, train/raw-loss = 0.6871098279953003, train/logprobs = tensor([[-0.3133, -0.3111],
        [-0.2280, -0.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06379563361406326
Epoch 0, Step 1221: train/loss = 0.4899550974369049, train/raw-loss = 0.39798885583877563, train/logprobs = tensor([[-0.1610, -3.7488],
        [-0.2477, -0.3203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09196622669696808
Epoch 0, Step 1222: train/loss = 0.5990079641342163, train/raw-loss = 0.5042420625686646, train/logprobs = tensor([[-0.2136, -5.5453],
        [-0.4246, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09476585686206818
Epoch 0, Step 1223: train/loss = 0.4655948281288147, train/raw-loss = 0.3509020209312439, train/logprobs = tensor([[-0.4551, -3.1809],
        [-0.5959, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114692822098732
Epoch 0, Step 1224: train/loss = 0.5746840238571167, train/raw-loss = 0.47635728120803833, train/logprobs = tensor([[-0.1170, -1.5659],
        [-0.2021, -0.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09832677990198135
Epoch 0, Step 1225: train/loss = 0.5358266234397888, train/raw-loss = 0.445442795753479, train/logprobs = tensor([[-0.2366, -2.1581],
        [-0.3529, -0.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038382023572922
Epoch 0, Step 1226: train/loss = 0.6262006759643555, train/raw-loss = 0.5194480419158936, train/logprobs = tensor([[-0.6755, -1.8978],
        [-0.5228, -0.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10675261914730072
Epoch 0, Step 1227: train/loss = 0.588829517364502, train/raw-loss = 0.48051875829696655, train/logprobs = tensor([[-0.3710, -1.4407],
        [-0.4380, -0.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10831073671579361
Epoch 0, Step 1228: train/loss = 0.6542003750801086, train/raw-loss = 0.5413014888763428, train/logprobs = tensor([[-0.3242, -1.1878],
        [-0.3380, -0.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289893835783005
Epoch 0, Step 1229: train/loss = 0.4831482470035553, train/raw-loss = 0.37033611536026, train/logprobs = tensor([[-0.1930, -4.2984],
        [-0.3303, -0.2821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128121167421341
Epoch 0, Step 1230: train/loss = 0.7115052342414856, train/raw-loss = 0.6055019497871399, train/logprobs = tensor([[-0.7286, -1.6143],
        [-0.6738, -0.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060032919049263
Epoch 0, Step 1231: train/loss = 0.5775083899497986, train/raw-loss = 0.450722336769104, train/logprobs = tensor([[-0.4787, -1.5111],
        [-0.6868, -0.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12678605318069458
Epoch 0, Step 1232: train/loss = 0.8513339757919312, train/raw-loss = 0.7686137557029724, train/logprobs = tensor([[-1.0484, -5.9327],
        [-0.0749, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08272016048431396
Epoch 0, Step 1233: train/loss = 0.6583574414253235, train/raw-loss = 0.5390855073928833, train/logprobs = tensor([[-0.2648, -1.0970],
        [-0.3003, -0.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11927197873592377
Epoch 0, Step 1234: train/loss = 0.5642046928405762, train/raw-loss = 0.4548582434654236, train/logprobs = tensor([[-0.3483, -1.8632],
        [-0.6781, -0.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1093464344739914
Epoch 0, Step 1235: train/loss = 0.7534040212631226, train/raw-loss = 0.646581768989563, train/logprobs = tensor([[-0.9097, -5.9900],
        [-0.3441, -0.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10682228207588196
Epoch 0, Step 1236: train/loss = 0.4549548327922821, train/raw-loss = 0.35626405477523804, train/logprobs = tensor([[-0.1189, -3.1734],
        [-0.2623, -0.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09869077801704407
Epoch 0, Step 1237: train/loss = 0.4499310553073883, train/raw-loss = 0.34584686160087585, train/logprobs = tensor([[-0.4019, -7.1213],
        [-0.5648, -0.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10408419370651245
Epoch 0, Step 1238: train/loss = 0.5604103803634644, train/raw-loss = 0.42520594596862793, train/logprobs = tensor([[-0.3655, -4.3096],
        [-0.5411, -1.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13520438969135284
Epoch 0, Step 1239: train/loss = 0.5577096939086914, train/raw-loss = 0.48273447155952454, train/logprobs = tensor([[-0.1159, -1.7488],
        [-0.1749, -0.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07497524470090866
Epoch 0, Step 1240: train/loss = 0.6006100177764893, train/raw-loss = 0.4879547655582428, train/logprobs = tensor([[-0.5149, -5.4122],
        [-0.6270, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11265524476766586
Epoch 0, Step 1241: train/loss = 0.572412371635437, train/raw-loss = 0.45207351446151733, train/logprobs = tensor([[-0.2143, -1.9488],
        [-0.4938, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12033888697624207
Epoch 0, Step 1242: train/loss = 0.5354493856430054, train/raw-loss = 0.408526211977005, train/logprobs = tensor([[-0.4653, -4.1064],
        [-0.4759, -0.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12692317366600037
Epoch 0, Step 1243: train/loss = 0.5866104960441589, train/raw-loss = 0.48753437399864197, train/logprobs = tensor([[-0.4164, -1.5280],
        [-0.5745, -0.3255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09907611459493637
Epoch 0, Step 1244: train/loss = 0.5572375059127808, train/raw-loss = 0.4402966797351837, train/logprobs = tensor([[-0.2566, -1.5087],
        [-0.4294, -0.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694083362817764
Epoch 0, Step 1245: train/loss = 0.4719310700893402, train/raw-loss = 0.34201329946517944, train/logprobs = tensor([[-0.2434, -4.0254],
        [-0.5962, -0.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12991775572299957
Epoch 0, Step 1246: train/loss = 0.4230744242668152, train/raw-loss = 0.289532333612442, train/logprobs = tensor([[-0.4725, -2.9929],
        [-0.6969, -0.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13354209065437317
Epoch 0, Step 1247: train/loss = 0.5317907333374023, train/raw-loss = 0.41442131996154785, train/logprobs = tensor([[-0.2631, -3.6784],
        [-0.3621, -0.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11736944317817688
Epoch 0, Step 1248: train/loss = 0.6244912147521973, train/raw-loss = 0.5159658193588257, train/logprobs = tensor([[-0.1416, -1.1761],
        [-0.4381, -0.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10852544009685516
Epoch 0, Step 1249: train/loss = 0.6736335754394531, train/raw-loss = 0.5817998051643372, train/logprobs = tensor([[-0.4821, -0.9062],
        [-0.4589, -0.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09183380007743835
Epoch 0, Step 1250: train/loss = 0.6024349927902222, train/raw-loss = 0.49530524015426636, train/logprobs = tensor([[-0.3251, -1.4726],
        [-0.3752, -0.2889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10712970048189163
Epoch 0, Step 1251: train/loss = 0.5201538801193237, train/raw-loss = 0.4086887836456299, train/logprobs = tensor([[-0.2441, -2.9361],
        [-0.4796, -0.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11146514117717743
Epoch 0, Step 1252: train/loss = 0.40147262811660767, train/raw-loss = 0.2767660915851593, train/logprobs = tensor([[-0.1509, -6.2066],
        [-0.7671, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12470655143260956
Epoch 0, Step 1253: train/loss = 0.5328963398933411, train/raw-loss = 0.4333781898021698, train/logprobs = tensor([[-0.1942, -1.7910],
        [-0.4207, -0.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09951814264059067
Epoch 0, Step 1254: train/loss = 0.544154167175293, train/raw-loss = 0.4295661449432373, train/logprobs = tensor([[-0.1739, -2.4175],
        [-0.2852, -0.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458802968263626
Epoch 0, Step 1255: train/loss = 0.6904804110527039, train/raw-loss = 0.6217164993286133, train/logprobs = tensor([[-0.1205, -0.3157],
        [-0.2749, -0.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876392662525177
Epoch 0, Step 1256: train/loss = 0.43574947118759155, train/raw-loss = 0.3157327175140381, train/logprobs = tensor([[-0.9574, -3.0034],
        [-1.4133, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12001678347587585
Epoch 0, Step 1257: train/loss = 0.5763066411018372, train/raw-loss = 0.4953520596027374, train/logprobs = tensor([[-0.1882, -1.0583],
        [-0.3939, -0.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08095458149909973
Epoch 0, Step 1258: train/loss = 0.4950621426105499, train/raw-loss = 0.39378178119659424, train/logprobs = tensor([[-0.4522, -2.0766],
        [-0.8621, -0.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012803465127945
Epoch 0, Step 1259: train/loss = 0.652117908000946, train/raw-loss = 0.5665068626403809, train/logprobs = tensor([[-0.1550, -0.8325],
        [-0.2768, -0.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08561103790998459
Epoch 0, Step 1260: train/loss = 0.5300559997558594, train/raw-loss = 0.4144418239593506, train/logprobs = tensor([[-0.5042, -7.0714],
        [-0.9121, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11561417579650879
Epoch 0, Step 1261: train/loss = 0.6318895816802979, train/raw-loss = 0.5031192898750305, train/logprobs = tensor([[-0.2197, -2.3220],
        [-0.4918, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12877032160758972
Epoch 0, Step 1262: train/loss = 0.5051189661026001, train/raw-loss = 0.37615543603897095, train/logprobs = tensor([[-0.2862, -3.8397],
        [-0.4359, -0.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12896354496479034
Epoch 0, Step 1263: train/loss = 0.5528923869132996, train/raw-loss = 0.46760913729667664, train/logprobs = tensor([[-0.1944, -1.5850],
        [-0.4873, -0.3633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08528325706720352
Epoch 0, Step 1264: train/loss = 0.4774034321308136, train/raw-loss = 0.3547053933143616, train/logprobs = tensor([[-0.5394, -2.6639],
        [-0.6733, -0.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1226980909705162
Epoch 0, Step 1265: train/loss = 0.5549063086509705, train/raw-loss = 0.4216534495353699, train/logprobs = tensor([[-0.2424, -1.6187],
        [-0.7144, -0.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13325288891792297
Epoch 0, Step 1266: train/loss = 0.6499892473220825, train/raw-loss = 0.515864372253418, train/logprobs = tensor([[-0.8446, -3.9766],
        [-0.4788, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13412491977214813
Epoch 0, Step 1267: train/loss = 0.43987664580345154, train/raw-loss = 0.2740715742111206, train/logprobs = tensor([[-0.5773, -4.8189],
        [-0.8274, -0.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16580510139465332
Epoch 0, Step 1268: train/loss = 0.4437984228134155, train/raw-loss = 0.3118671178817749, train/logprobs = tensor([[-0.3678, -5.4373],
        [-0.8609, -0.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13193131983280182
Epoch 0, Step 1269: train/loss = 0.5101028680801392, train/raw-loss = 0.3759740889072418, train/logprobs = tensor([[-0.6441, -3.3765],
        [-1.1351, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13412873446941376
Epoch 0, Step 1270: train/loss = 0.6081902980804443, train/raw-loss = 0.4875768721103668, train/logprobs = tensor([[-0.4538, -3.1520],
        [-0.3807, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1206134557723999
Epoch 0, Step 1271: train/loss = 0.631348192691803, train/raw-loss = 0.5522017478942871, train/logprobs = tensor([[-0.1885, -1.0573],
        [-0.3006, -0.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07914645224809647
Epoch 0, Step 1272: train/loss = 0.4811352491378784, train/raw-loss = 0.35058021545410156, train/logprobs = tensor([[-0.4033, -2.3929],
        [-0.8146, -0.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13055504858493805
Epoch 0, Step 1273: train/loss = 0.5868803262710571, train/raw-loss = 0.45301446318626404, train/logprobs = tensor([[-0.3975, -1.8622],
        [-0.6468, -0.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338658630847931
Epoch 0, Step 1274: train/loss = 0.6449014544487, train/raw-loss = 0.5281636118888855, train/logprobs = tensor([[-0.1898, -2.9862],
        [-0.3157, -2.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673785001039505
Epoch 0, Step 1275: train/loss = 0.5528061985969543, train/raw-loss = 0.4347756505012512, train/logprobs = tensor([[-0.2457, -1.6320],
        [-0.4882, -0.2461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11803054064512253
Epoch 0, Step 1276: train/loss = 0.44384533166885376, train/raw-loss = 0.3289451003074646, train/logprobs = tensor([[-0.2446, -7.6869],
        [-0.6022, -1.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11490020155906677
Epoch 0, Step 1277: train/loss = 0.6499687433242798, train/raw-loss = 0.5485928654670715, train/logprobs = tensor([[-0.2924, -0.9739],
        [-0.2828, -0.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10137589275836945
Epoch 0, Step 1278: train/loss = 0.4264187216758728, train/raw-loss = 0.30082806944847107, train/logprobs = tensor([[-0.1802, -4.7684],
        [-0.4152, -0.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12559066712856293
Epoch 0, Step 1279: train/loss = 0.43604204058647156, train/raw-loss = 0.26917383074760437, train/logprobs = tensor([[-0.2658, -3.7599],
        [-0.7967, -0.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16686822474002838
Epoch 0, Step 1280: train/loss = 0.4878818392753601, train/raw-loss = 0.35990339517593384, train/logprobs = tensor([[-0.3145, -3.7860],
        [-0.5259, -0.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12797842919826508
Epoch 0, Step 1281: train/loss = 0.48893991112709045, train/raw-loss = 0.39030587673187256, train/logprobs = tensor([[-0.4373, -4.4490],
        [-0.4954, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0986340269446373
Epoch 0, Step 1282: train/loss = 0.578092098236084, train/raw-loss = 0.49835628271102905, train/logprobs = tensor([[-0.1801, -1.4140],
        [-0.3305, -0.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07973584532737732
Epoch 0, Step 1283: train/loss = 0.5894438028335571, train/raw-loss = 0.5006596446037292, train/logprobs = tensor([[-0.1563, -1.5863],
        [-0.2624, -0.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878420293331146
Epoch 0, Step 1284: train/loss = 0.5955638885498047, train/raw-loss = 0.4873290956020355, train/logprobs = tensor([[-0.2402, -2.7561],
        [-0.1996, -0.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10823481529951096
Epoch 0, Step 1285: train/loss = 0.3464479446411133, train/raw-loss = 0.2402190864086151, train/logprobs = tensor([[-0.1502, -5.7420],
        [-0.7941, -0.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622888803482056
Epoch 0, Step 1286: train/loss = 0.38008084893226624, train/raw-loss = 0.27281227707862854, train/logprobs = tensor([[-0.2006, -4.6893],
        [-0.6224, -0.6447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072685644030571
Epoch 0, Step 1287: train/loss = 0.5163919925689697, train/raw-loss = 0.4188461899757385, train/logprobs = tensor([[-0.1210, -4.1171],
        [-0.4004, -0.6201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09754586964845657
Epoch 0, Step 1288: train/loss = 0.6569599509239197, train/raw-loss = 0.5588904023170471, train/logprobs = tensor([[-0.4173, -1.2048],
        [-0.3247, -0.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09806948155164719
Epoch 0, Step 1289: train/loss = 0.5300859808921814, train/raw-loss = 0.428886741399765, train/logprobs = tensor([[-0.4138, -4.2900],
        [-0.6718, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10119921714067459
Epoch 0, Step 1290: train/loss = 0.5206223130226135, train/raw-loss = 0.4034971594810486, train/logprobs = tensor([[-0.3091, -2.6302],
        [-0.5701, -0.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11712515354156494
Epoch 0, Step 1291: train/loss = 0.45957067608833313, train/raw-loss = 0.29775968194007874, train/logprobs = tensor([[ -0.9270, -11.7359],
        [ -1.0905,  -2.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16181102395057678
Epoch 0, Step 1292: train/loss = 0.5190836191177368, train/raw-loss = 0.40591928362846375, train/logprobs = tensor([[-0.3380, -4.0063],
        [-0.6761, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316436529159546
Epoch 0, Step 1293: train/loss = 0.5503986477851868, train/raw-loss = 0.3571750819683075, train/logprobs = tensor([[-0.7479, -4.1935],
        [-1.1678, -0.3026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19322353601455688
Epoch 0, Step 1294: train/loss = 0.6222769618034363, train/raw-loss = 0.49564817547798157, train/logprobs = tensor([[-0.6933, -2.8414],
        [-0.9504, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266288310289383
Epoch 0, Step 1295: train/loss = 0.46542298793792725, train/raw-loss = 0.3559412658214569, train/logprobs = tensor([[-0.2065, -6.0827],
        [-0.7945, -1.2623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948170721530914
Epoch 0, Step 1296: train/loss = 0.4666539430618286, train/raw-loss = 0.30965280532836914, train/logprobs = tensor([[-0.5404, -2.9196],
        [-0.9546, -0.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1570010930299759
Epoch 0, Step 1297: train/loss = 0.4956567883491516, train/raw-loss = 0.3925169110298157, train/logprobs = tensor([[-0.3365, -5.3453],
        [-0.6388, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10313985496759415
Epoch 0, Step 1298: train/loss = 0.6528521180152893, train/raw-loss = 0.524235725402832, train/logprobs = tensor([[-0.2535, -0.9589],
        [-0.6462, -0.4359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12861643731594086
Epoch 0, Step 1299: train/loss = 0.45586103200912476, train/raw-loss = 0.31783100962638855, train/logprobs = tensor([[-0.2175, -6.5507],
        [-0.6399, -1.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380300521850586
Epoch 0, Step 1300: train/loss = 0.5927152633666992, train/raw-loss = 0.47002112865448, train/logprobs = tensor([[-0.4540, -3.4742],
        [-0.6504, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12269414961338043
Epoch 0, Step 1301: train/loss = 0.6149553060531616, train/raw-loss = 0.5082249641418457, train/logprobs = tensor([[-0.1889, -1.0114],
        [-0.3720, -0.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673034936189651
Epoch 0, Step 1302: train/loss = 0.5868200063705444, train/raw-loss = 0.5021945238113403, train/logprobs = tensor([[-0.1892, -0.8857],
        [-0.5012, -0.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08462543040513992
Epoch 0, Step 1303: train/loss = 0.58393394947052, train/raw-loss = 0.4921628534793854, train/logprobs = tensor([[-0.2000, -2.1989],
        [-0.4221, -0.1906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177109599113464
Epoch 0, Step 1304: train/loss = 0.6184238195419312, train/raw-loss = 0.5293207168579102, train/logprobs = tensor([[-0.2225, -4.0697],
        [-0.4102, -1.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0891030952334404
Epoch 0, Step 1305: train/loss = 0.45460185408592224, train/raw-loss = 0.3305142819881439, train/logprobs = tensor([[-0.5864, -4.2394],
        [-1.1565, -0.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12408759444952011
Epoch 0, Step 1306: train/loss = 0.4667949080467224, train/raw-loss = 0.32226869463920593, train/logprobs = tensor([[-0.9556, -4.6144],
        [-0.8843, -0.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14452619850635529
Epoch 0, Step 1307: train/loss = 0.6835511922836304, train/raw-loss = 0.5976163744926453, train/logprobs = tensor([[-0.5093, -0.3985],
        [-0.6174, -0.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08593489229679108
Epoch 0, Step 1308: train/loss = 0.6214777231216431, train/raw-loss = 0.522584080696106, train/logprobs = tensor([[-0.5901, -1.8804],
        [-0.8129, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0988936573266983
Epoch 0, Step 1309: train/loss = 0.5220537185668945, train/raw-loss = 0.43016552925109863, train/logprobs = tensor([[-0.2363, -1.2023],
        [-0.5652, -0.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918881744146347
Epoch 0, Step 1310: train/loss = 0.5895437598228455, train/raw-loss = 0.4671979248523712, train/logprobs = tensor([[-0.2542, -2.4580],
        [-0.4141, -0.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12234581261873245
Epoch 0, Step 1311: train/loss = 0.4494873583316803, train/raw-loss = 0.34845513105392456, train/logprobs = tensor([[-0.2486, -4.3031],
        [-0.7200, -0.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10103223472833633
Epoch 0, Step 1312: train/loss = 0.5236121416091919, train/raw-loss = 0.40066638588905334, train/logprobs = tensor([[-0.1879, -2.1967],
        [-0.5240, -0.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294577807188034
Epoch 0, Step 1313: train/loss = 0.7915965914726257, train/raw-loss = 0.7050094604492188, train/logprobs = tensor([[-0.6880, -0.8015],
        [-0.3946, -0.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08658711612224579
Epoch 0, Step 1314: train/loss = 0.7465218901634216, train/raw-loss = 0.6275843381881714, train/logprobs = tensor([[-0.6076, -1.2850],
        [-0.3757, -0.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11893756687641144
Epoch 0, Step 1315: train/loss = 0.4475606679916382, train/raw-loss = 0.33756542205810547, train/logprobs = tensor([[ -0.2373, -11.5438],
        [ -0.6706,  -2.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10999523103237152
Epoch 0, Step 1316: train/loss = 0.6515877842903137, train/raw-loss = 0.5452821254730225, train/logprobs = tensor([[-0.3237, -1.5059],
        [-0.6125, -0.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630571097135544
Epoch 0, Step 1317: train/loss = 0.6510295867919922, train/raw-loss = 0.5348042249679565, train/logprobs = tensor([[-0.2706, -1.2868],
        [-0.6643, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11622543632984161
Epoch 0, Step 1318: train/loss = 0.4944814145565033, train/raw-loss = 0.3730047941207886, train/logprobs = tensor([[-0.3585, -6.8087],
        [-0.6955, -1.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147659063339233
Epoch 0, Step 1319: train/loss = 0.4872381091117859, train/raw-loss = 0.3585225045681, train/logprobs = tensor([[-0.3084, -3.5639],
        [-0.7069, -0.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287156194448471
Epoch 0, Step 1320: train/loss = 0.5434767603874207, train/raw-loss = 0.4222734570503235, train/logprobs = tensor([[-0.4091, -3.0641],
        [-0.8562, -0.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120328098535538
Epoch 0, Step 1321: train/loss = 0.6218594312667847, train/raw-loss = 0.5214345455169678, train/logprobs = tensor([[-0.1985, -1.4716],
        [-0.3173, -0.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1004248782992363
Epoch 0, Step 1322: train/loss = 0.55153489112854, train/raw-loss = 0.4484974145889282, train/logprobs = tensor([[-0.1802, -2.1467],
        [-0.3987, -0.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1030375212430954
Epoch 0, Step 1323: train/loss = 0.60121089220047, train/raw-loss = 0.5289931893348694, train/logprobs = tensor([[-0.3992, -2.7867],
        [-0.2068, -0.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07221772521734238
Epoch 0, Step 1324: train/loss = 0.5728119611740112, train/raw-loss = 0.4661787450313568, train/logprobs = tensor([[-0.2991, -3.4973],
        [-0.4061, -0.2670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10663323104381561
Epoch 0, Step 1325: train/loss = 0.5521870851516724, train/raw-loss = 0.49203813076019287, train/logprobs = tensor([[-0.0970, -1.9636],
        [-0.1119, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06014901399612427
Epoch 0, Step 1326: train/loss = 0.5279149413108826, train/raw-loss = 0.3885985016822815, train/logprobs = tensor([[-0.6731, -3.0981],
        [-0.7926, -0.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13931645452976227
Epoch 0, Step 1327: train/loss = 0.7370144128799438, train/raw-loss = 0.6013327836990356, train/logprobs = tensor([[-1.2695, -3.4699],
        [-0.5991, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13568159937858582
Epoch 0, Step 1328: train/loss = 0.5224901437759399, train/raw-loss = 0.3921450674533844, train/logprobs = tensor([[-0.4386, -2.8085],
        [-0.4939, -0.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13034507632255554
Epoch 0, Step 1329: train/loss = 0.394093781709671, train/raw-loss = 0.24910223484039307, train/logprobs = tensor([[-0.3365, -3.9264],
        [-0.9548, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14499156177043915
Epoch 0, Step 1330: train/loss = 0.600777268409729, train/raw-loss = 0.48835882544517517, train/logprobs = tensor([[-0.5876, -4.1112],
        [-0.5133, -0.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11241849511861801
Epoch 0, Step 1331: train/loss = 0.4786593019962311, train/raw-loss = 0.3649349808692932, train/logprobs = tensor([[-0.2188, -1.6708],
        [-0.7135, -0.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11372430622577667
Epoch 0, Step 1332: train/loss = 0.44011569023132324, train/raw-loss = 0.28459829092025757, train/logprobs = tensor([[-0.3723, -2.4686],
        [-0.9292, -0.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15551741421222687
Epoch 0, Step 1333: train/loss = 0.5426814556121826, train/raw-loss = 0.45624279975891113, train/logprobs = tensor([[-0.2104, -2.6710],
        [-0.4285, -0.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08643867075443268
Epoch 0, Step 1334: train/loss = 0.46215367317199707, train/raw-loss = 0.33452489972114563, train/logprobs = tensor([[-0.2761, -2.6409],
        [-0.8892, -0.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12762877345085144
Epoch 0, Step 1335: train/loss = 0.5492952466011047, train/raw-loss = 0.38215145468711853, train/logprobs = tensor([[-0.9118, -2.3783],
        [-1.5728, -0.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671438068151474
Epoch 0, Step 1336: train/loss = 0.5656669735908508, train/raw-loss = 0.455077588558197, train/logprobs = tensor([[-0.2985, -7.3269],
        [-0.4432, -1.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11058942973613739
Epoch 0, Step 1337: train/loss = 0.5564533472061157, train/raw-loss = 0.48652184009552, train/logprobs = tensor([[-0.1275, -4.4837],
        [-0.3802, -2.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0699315220117569
Epoch 0, Step 1338: train/loss = 0.5047609806060791, train/raw-loss = 0.34873056411743164, train/logprobs = tensor([[-0.4710, -3.2904],
        [-0.8144, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15603038668632507
Epoch 0, Step 1339: train/loss = 0.5272054672241211, train/raw-loss = 0.371631383895874, train/logprobs = tensor([[-0.6823, -2.2946],
        [-1.4222, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1555740386247635
Epoch 0, Step 1340: train/loss = 0.38407599925994873, train/raw-loss = 0.23464974761009216, train/logprobs = tensor([[-0.5099, -4.0490],
        [-1.2422, -0.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14942625164985657
Epoch 0, Step 1341: train/loss = 0.44369569420814514, train/raw-loss = 0.3553665578365326, train/logprobs = tensor([[-0.2305, -2.6045],
        [-0.7605, -0.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08832914382219315
Epoch 0, Step 1342: train/loss = 0.6951148509979248, train/raw-loss = 0.6023281216621399, train/logprobs = tensor([[-0.2971, -0.9902],
        [-0.2186, -0.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927867740392685
Epoch 0, Step 1343: train/loss = 0.451940655708313, train/raw-loss = 0.32117486000061035, train/logprobs = tensor([[-0.5684, -1.9851],
        [-1.3040, -0.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13076579570770264
Epoch 0, Step 1344: train/loss = 0.6088373064994812, train/raw-loss = 0.5169949531555176, train/logprobs = tensor([[-0.2397, -1.2790],
        [-0.2740, -0.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09184235334396362
Epoch 0, Step 1345: train/loss = 0.6762034296989441, train/raw-loss = 0.5359221696853638, train/logprobs = tensor([[-0.4690, -1.8977],
        [-0.6630, -0.3164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14028121531009674
Epoch 0, Step 1346: train/loss = 0.5777803659439087, train/raw-loss = 0.46853387355804443, train/logprobs = tensor([[-0.3167, -1.2616],
        [-0.5382, -0.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10924653708934784
Epoch 0, Step 1347: train/loss = 0.607465922832489, train/raw-loss = 0.4712727963924408, train/logprobs = tensor([[-0.5673, -1.5261],
        [-0.8667, -0.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13619312644004822
Epoch 0, Step 1348: train/loss = 0.513588011264801, train/raw-loss = 0.4449010491371155, train/logprobs = tensor([[-0.3760, -1.7625],
        [-0.7341, -0.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06868693232536316
Epoch 0, Step 1349: train/loss = 0.5798749923706055, train/raw-loss = 0.49030330777168274, train/logprobs = tensor([[-0.7128, -1.2913],
        [-0.8849, -0.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957168459892273
Epoch 0, Step 1350: train/loss = 0.44548341631889343, train/raw-loss = 0.327339768409729, train/logprobs = tensor([[-0.3643, -7.2662],
        [-0.8363, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11814363300800323
Epoch 0, Step 1351: train/loss = 0.5491998195648193, train/raw-loss = 0.4579271078109741, train/logprobs = tensor([[-0.1900, -1.3840],
        [-0.4810, -0.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09127267450094223
Epoch 0, Step 1352: train/loss = 0.633924126625061, train/raw-loss = 0.5401506423950195, train/logprobs = tensor([[-0.5014, -1.2656],
        [-0.3979, -0.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09377343952655792
Epoch 0, Step 1353: train/loss = 0.5706702470779419, train/raw-loss = 0.501664400100708, train/logprobs = tensor([[-0.0811, -3.1700],
        [-0.3811, -0.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06900584697723389
Epoch 0, Step 1354: train/loss = 0.5635219812393188, train/raw-loss = 0.43107694387435913, train/logprobs = tensor([[-0.4490, -1.1889],
        [-1.1285, -0.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324450820684433
Epoch 0, Step 1355: train/loss = 0.3151666820049286, train/raw-loss = 0.1981535404920578, train/logprobs = tensor([[-0.1361, -5.7548],
        [-0.7187, -0.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1170131266117096
Epoch 0, Step 1356: train/loss = 0.5775023102760315, train/raw-loss = 0.48973438143730164, train/logprobs = tensor([[-0.4618, -2.8662],
        [-0.5032, -0.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08776794373989105
Epoch 0, Step 1357: train/loss = 0.6399660706520081, train/raw-loss = 0.543412983417511, train/logprobs = tensor([[-0.3126, -1.2950],
        [-0.4731, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09655308723449707
Epoch 0, Step 1358: train/loss = 0.4795295000076294, train/raw-loss = 0.3534051477909088, train/logprobs = tensor([[-0.1589, -2.8783],
        [-0.6884, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1261243224143982
Epoch 0, Step 1359: train/loss = 0.5968644618988037, train/raw-loss = 0.4817814826965332, train/logprobs = tensor([[-0.2330, -1.8372],
        [-0.5434, -0.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150829941034317
Epoch 0, Step 1360: train/loss = 0.4189385771751404, train/raw-loss = 0.32711973786354065, train/logprobs = tensor([[-0.4015, -2.3482],
        [-0.8079, -0.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181886911392212
Epoch 0, Step 1361: train/loss = 0.5036580562591553, train/raw-loss = 0.3883492946624756, train/logprobs = tensor([[-0.3595, -2.6900],
        [-0.4717, -0.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11530880630016327
Epoch 0, Step 1362: train/loss = 0.5113083720207214, train/raw-loss = 0.3754637837409973, train/logprobs = tensor([[-0.2641, -1.6294],
        [-1.0719, -0.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13584458827972412
Epoch 0, Step 1363: train/loss = 0.6124739646911621, train/raw-loss = 0.5382910966873169, train/logprobs = tensor([[-0.1435, -0.8308],
        [-0.4601, -0.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.074182890355587
Epoch 0, Step 1364: train/loss = 0.5588467121124268, train/raw-loss = 0.4573642909526825, train/logprobs = tensor([[-0.1655, -2.1174],
        [-0.3684, -0.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10148243606090546
Epoch 0, Step 1365: train/loss = 0.46581459045410156, train/raw-loss = 0.35524672269821167, train/logprobs = tensor([[-0.1453, -3.7104],
        [-0.3523, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11056787520647049
Epoch 0, Step 1366: train/loss = 0.5490506887435913, train/raw-loss = 0.4748658537864685, train/logprobs = tensor([[-0.1066, -3.0685],
        [-0.4057, -0.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741848573088646
Epoch 0, Step 1367: train/loss = 0.44892919063568115, train/raw-loss = 0.3275224268436432, train/logprobs = tensor([[-0.2908, -4.1979],
        [-1.1483, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12140674889087677
Epoch 0, Step 1368: train/loss = 0.6204757690429688, train/raw-loss = 0.5374767780303955, train/logprobs = tensor([[-0.2659, -1.8605],
        [-0.3753, -0.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08299892395734787
Epoch 0, Step 1369: train/loss = 0.566838264465332, train/raw-loss = 0.4203343987464905, train/logprobs = tensor([[-0.2206, -1.7402],
        [-1.1607, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14650389552116394
Epoch 0, Step 1370: train/loss = 0.6294273734092712, train/raw-loss = 0.5117884874343872, train/logprobs = tensor([[-0.3679, -1.5742],
        [-0.4578, -0.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11763888597488403
Epoch 0, Step 1371: train/loss = 0.5358093976974487, train/raw-loss = 0.43866926431655884, train/logprobs = tensor([[-0.2194, -2.8741],
        [-0.4610, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0971401110291481
Epoch 0, Step 1372: train/loss = 0.4859301745891571, train/raw-loss = 0.3795119524002075, train/logprobs = tensor([[-0.3664, -4.2013],
        [-0.8729, -0.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10641822963953018
Epoch 0, Step 1373: train/loss = 0.6215130686759949, train/raw-loss = 0.5237178802490234, train/logprobs = tensor([[-0.4942, -2.0415],
        [-1.1311, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779518842697144
Epoch 0, Step 1374: train/loss = 0.5420840382575989, train/raw-loss = 0.4301547706127167, train/logprobs = tensor([[-0.2205, -2.5307],
        [-0.9277, -0.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119292676448822
Epoch 0, Step 1375: train/loss = 0.4329511523246765, train/raw-loss = 0.3209642171859741, train/logprobs = tensor([[-0.2816, -4.6356],
        [-0.5803, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11198696494102478
Epoch 0, Step 1376: train/loss = 0.3851366937160492, train/raw-loss = 0.27267202734947205, train/logprobs = tensor([[-0.5907, -2.4212],
        [-1.6216, -0.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246468126773834
Epoch 0, Step 1377: train/loss = 0.5474953651428223, train/raw-loss = 0.45422908663749695, train/logprobs = tensor([[-0.1766, -3.0113],
        [-0.4531, -0.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09326626360416412
Epoch 0, Step 1378: train/loss = 0.5711051225662231, train/raw-loss = 0.4780731797218323, train/logprobs = tensor([[-0.1866, -1.8461],
        [-0.6845, -0.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09303198754787445
Epoch 0, Step 1379: train/loss = 0.5116409659385681, train/raw-loss = 0.399370938539505, train/logprobs = tensor([[-0.5224, -1.4243],
        [-1.1594, -0.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227001249790192
Epoch 0, Step 1380: train/loss = 0.4518297016620636, train/raw-loss = 0.28217726945877075, train/logprobs = tensor([[-0.3782, -5.8458],
        [-0.5709, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16965244710445404
Epoch 0, Step 1381: train/loss = 0.5651330351829529, train/raw-loss = 0.43699321150779724, train/logprobs = tensor([[-0.2249, -6.5025],
        [-0.7136, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12813985347747803
Epoch 0, Step 1382: train/loss = 0.4866618514060974, train/raw-loss = 0.36751410365104675, train/logprobs = tensor([[-0.3823, -2.4595],
        [-0.9641, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11914774775505066
Epoch 0, Step 1383: train/loss = 0.43859273195266724, train/raw-loss = 0.3114791214466095, train/logprobs = tensor([[-0.3710, -3.4718],
        [-0.8585, -0.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12711358070373535
Epoch 0, Step 1384: train/loss = 0.792695164680481, train/raw-loss = 0.690256655216217, train/logprobs = tensor([[-0.4059, -2.0643],
        [-0.5705, -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1024385467171669
Epoch 0, Step 1385: train/loss = 0.5479571223258972, train/raw-loss = 0.3754756450653076, train/logprobs = tensor([[-0.6240, -1.9782],
        [-1.0663, -0.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1724814474582672
Epoch 0, Step 1386: train/loss = 0.5500468015670776, train/raw-loss = 0.4133412837982178, train/logprobs = tensor([[-0.2417, -1.0699],
        [-1.1863, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13670554757118225
Epoch 0, Step 1387: train/loss = 0.6118223667144775, train/raw-loss = 0.47823566198349, train/logprobs = tensor([[-0.5831, -1.2188],
        [-0.8762, -0.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13358671963214874
Epoch 0, Step 1388: train/loss = 0.3778448700904846, train/raw-loss = 0.25498688220977783, train/logprobs = tensor([[-0.3072, -3.0766],
        [-1.3314, -0.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12285798788070679
Epoch 0, Step 1389: train/loss = 0.5341155529022217, train/raw-loss = 0.3975968360900879, train/logprobs = tensor([[-0.5151, -2.8383],
        [-0.8912, -0.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365187168121338
Epoch 0, Step 1390: train/loss = 0.6463460922241211, train/raw-loss = 0.5503815412521362, train/logprobs = tensor([[-0.1479, -0.9012],
        [-0.4965, -0.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09596462547779083
Epoch 0, Step 1391: train/loss = 0.5312823057174683, train/raw-loss = 0.4390331506729126, train/logprobs = tensor([[-0.1514, -2.0964],
        [-0.4034, -0.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09224914014339447
Epoch 0, Step 1392: train/loss = 0.446370929479599, train/raw-loss = 0.3290223777294159, train/logprobs = tensor([[-0.3553, -6.4574],
        [-0.8031, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1173485517501831
Epoch 0, Step 1393: train/loss = 0.41063860058784485, train/raw-loss = 0.2615548372268677, train/logprobs = tensor([[-0.2479, -5.8554],
        [-0.9537, -0.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14908373355865479
Epoch 0, Step 1394: train/loss = 0.5702370405197144, train/raw-loss = 0.43875646591186523, train/logprobs = tensor([[-0.3581, -1.2279],
        [-0.8052, -0.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13148057460784912
Epoch 0, Step 1395: train/loss = 0.5015804171562195, train/raw-loss = 0.3883768916130066, train/logprobs = tensor([[-0.3368, -2.1394],
        [-0.6383, -0.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11320357769727707
Epoch 0, Step 1396: train/loss = 0.4775922894477844, train/raw-loss = 0.32285553216934204, train/logprobs = tensor([[-0.3837, -4.5649],
        [-0.7525, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547367125749588
Epoch 0, Step 1397: train/loss = 0.3618910312652588, train/raw-loss = 0.26628488302230835, train/logprobs = tensor([[-0.1679, -7.6335],
        [-0.5577, -0.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09560615569353104
Epoch 0, Step 1398: train/loss = 0.42257997393608093, train/raw-loss = 0.2645479142665863, train/logprobs = tensor([[-0.6220, -3.3219],
        [-1.3213, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803202986717224
Epoch 0, Step 1399: train/loss = 0.5350747108459473, train/raw-loss = 0.3672317564487457, train/logprobs = tensor([[-0.5412, -3.2973],
        [-1.1689, -0.4216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16784296929836273
Epoch 0, Step 1400: train/loss = 0.5441076159477234, train/raw-loss = 0.41198182106018066, train/logprobs = tensor([[-0.2213, -7.1126],
        [-0.7543, -0.3945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13212579488754272
Epoch 0, Step 1401: train/loss = 0.48552730679512024, train/raw-loss = 0.35881078243255615, train/logprobs = tensor([[-0.2829, -3.2170],
        [-0.8639, -0.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1267165243625641
Epoch 0, Step 1402: train/loss = 0.4928140938282013, train/raw-loss = 0.3676410913467407, train/logprobs = tensor([[-0.2429, -2.8933],
        [-0.5897, -0.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517298758029938
Epoch 0, Step 1403: train/loss = 0.4856000542640686, train/raw-loss = 0.3586270213127136, train/logprobs = tensor([[-0.9207, -4.4096],
        [-1.0319, -1.4133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269729882478714
Epoch 0, Step 1404: train/loss = 0.44424861669540405, train/raw-loss = 0.3363124132156372, train/logprobs = tensor([[-0.2314, -9.4861],
        [-0.7883, -0.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10793621838092804
Epoch 0, Step 1405: train/loss = 0.546697735786438, train/raw-loss = 0.44858628511428833, train/logprobs = tensor([[-0.3880, -4.3140],
        [-0.5893, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09811142832040787
Epoch 0, Step 1406: train/loss = 0.5823909044265747, train/raw-loss = 0.48339563608169556, train/logprobs = tensor([[-0.1379, -1.3471],
        [-0.4685, -0.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09899522364139557
Epoch 0, Step 1407: train/loss = 0.5439333915710449, train/raw-loss = 0.3973613381385803, train/logprobs = tensor([[-0.6778, -7.3746],
        [-0.6807, -1.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465720385313034
Epoch 0, Step 1408: train/loss = 0.33029255270957947, train/raw-loss = 0.18916764855384827, train/logprobs = tensor([[ -0.1863, -10.2900],
        [ -1.0341,  -0.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411249041557312
Epoch 0, Step 1409: train/loss = 0.6362184882164001, train/raw-loss = 0.5378470420837402, train/logprobs = tensor([[-0.1695, -0.8142],
        [-0.5046, -0.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09837143123149872
Epoch 0, Step 1410: train/loss = 0.4806426465511322, train/raw-loss = 0.33231228590011597, train/logprobs = tensor([[-0.2749, -2.7215],
        [-0.8436, -0.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14833036065101624
Epoch 0, Step 1411: train/loss = 0.6219184398651123, train/raw-loss = 0.5310219526290894, train/logprobs = tensor([[-0.3372, -2.0818],
        [-0.5959, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09089651703834534
Epoch 0, Step 1412: train/loss = 0.6235864162445068, train/raw-loss = 0.4686862826347351, train/logprobs = tensor([[-0.2344, -1.1949],
        [-1.0158, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15490016341209412
Epoch 0, Step 1413: train/loss = 0.46190139651298523, train/raw-loss = 0.36716049909591675, train/logprobs = tensor([[-0.2539, -2.7627],
        [-0.5385, -0.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474094212055206
Epoch 0, Step 1414: train/loss = 0.5612989068031311, train/raw-loss = 0.45362770557403564, train/logprobs = tensor([[-0.2010, -3.4739],
        [-0.7387, -0.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10767118632793427
Epoch 0, Step 1415: train/loss = 0.5982570648193359, train/raw-loss = 0.5102569460868835, train/logprobs = tensor([[-0.2264, -1.2900],
        [-0.5327, -0.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08800007402896881
Epoch 0, Step 1416: train/loss = 0.41559746861457825, train/raw-loss = 0.2928284704685211, train/logprobs = tensor([[-0.3256, -7.4407],
        [-0.9441, -1.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12276896834373474
Epoch 0, Step 1417: train/loss = 0.47643160820007324, train/raw-loss = 0.337342768907547, train/logprobs = tensor([[-0.5341, -6.6279],
        [-0.8379, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13908880949020386
Epoch 0, Step 1418: train/loss = 0.5341018438339233, train/raw-loss = 0.4260917901992798, train/logprobs = tensor([[-0.2985, -2.7336],
        [-0.6880, -1.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10801008343696594
Epoch 0, Step 1419: train/loss = 0.6274976134300232, train/raw-loss = 0.541907548904419, train/logprobs = tensor([[-0.0828, -1.0746],
        [-0.3118, -0.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08559008687734604
Epoch 0, Step 1420: train/loss = 0.48464709520339966, train/raw-loss = 0.370665580034256, train/logprobs = tensor([[-0.2617, -2.7728],
        [-0.7311, -0.3155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11398152261972427
Epoch 0, Step 1421: train/loss = 0.5942449569702148, train/raw-loss = 0.5030457973480225, train/logprobs = tensor([[-0.2472, -3.0235],
        [-0.7799, -0.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09119918942451477
Epoch 0, Step 1422: train/loss = 0.6708636283874512, train/raw-loss = 0.5909571051597595, train/logprobs = tensor([[-0.2093, -0.9393],
        [-0.3948, -0.2625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07990647852420807
Epoch 0, Step 1423: train/loss = 0.5612104535102844, train/raw-loss = 0.4599168002605438, train/logprobs = tensor([[-0.3230, -2.0933],
        [-0.6661, -0.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10129364579916
Epoch 0, Step 1424: train/loss = 0.3318522572517395, train/raw-loss = 0.17530113458633423, train/logprobs = tensor([[-0.4127, -8.8682],
        [-1.3743, -1.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15655112266540527
Epoch 0, Step 1425: train/loss = 0.4010693430900574, train/raw-loss = 0.2551042437553406, train/logprobs = tensor([[-0.8460, -5.7822],
        [-1.0797, -0.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.145965114235878
Epoch 0, Step 1426: train/loss = 0.49852895736694336, train/raw-loss = 0.3486890196800232, train/logprobs = tensor([[-0.6275, -9.0200],
        [-0.6831, -0.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14983993768692017
Epoch 0, Step 1427: train/loss = 0.7011728286743164, train/raw-loss = 0.5604165196418762, train/logprobs = tensor([[-0.3037, -1.1701],
        [-0.7459, -0.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14075636863708496
Epoch 0, Step 1428: train/loss = 0.4755391478538513, train/raw-loss = 0.37779614329338074, train/logprobs = tensor([[-0.2464, -3.5421],
        [-0.8167, -0.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977429747581482
Epoch 0, Step 1429: train/loss = 0.5122519135475159, train/raw-loss = 0.37517619132995605, train/logprobs = tensor([[-0.1643, -4.2143],
        [-0.5667, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13707570731639862
Epoch 0, Step 1430: train/loss = 0.44085556268692017, train/raw-loss = 0.3190273344516754, train/logprobs = tensor([[-0.5537, -4.0311],
        [-1.1819, -0.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12182820588350296
Epoch 0, Step 1431: train/loss = 0.4858858287334442, train/raw-loss = 0.3486216962337494, train/logprobs = tensor([[ -0.6095, -11.1354],
        [ -1.0349,  -1.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13726414740085602
Epoch 0, Step 1432: train/loss = 0.683840274810791, train/raw-loss = 0.5466984510421753, train/logprobs = tensor([[-0.4090, -4.7575],
        [-1.1384, -1.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13714183866977692
Epoch 0, Step 1433: train/loss = 0.4988937973976135, train/raw-loss = 0.3874439597129822, train/logprobs = tensor([[-0.1173, -1.9159],
        [-0.9440, -0.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11144981533288956
Epoch 0, Step 1434: train/loss = 0.48004209995269775, train/raw-loss = 0.30905988812446594, train/logprobs = tensor([[-0.6667, -3.2331],
        [-1.0453, -0.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1709822118282318
Epoch 0, Step 1435: train/loss = 0.48608624935150146, train/raw-loss = 0.3029983639717102, train/logprobs = tensor([[-0.4607, -4.8391],
        [-1.2032, -0.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18308790028095245
Epoch 0, Step 1436: train/loss = 0.5579582452774048, train/raw-loss = 0.43380966782569885, train/logprobs = tensor([[-0.9769, -7.7845],
        [-1.0225, -0.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12414857745170593
Epoch 0, Step 1437: train/loss = 0.5243832468986511, train/raw-loss = 0.4338553845882416, train/logprobs = tensor([[-0.2334, -4.8733],
        [-0.6387, -1.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09052783995866776
Epoch 0, Step 1438: train/loss = 0.3118875026702881, train/raw-loss = 0.16114889085292816, train/logprobs = tensor([[-0.7915, -9.2672],
        [-1.8142, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15073861181735992
Epoch 0, Step 1439: train/loss = 0.47879597544670105, train/raw-loss = 0.3804859519004822, train/logprobs = tensor([[-0.4939, -2.8579],
        [-1.2494, -0.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09831003844738007
Epoch 0, Step 1440: train/loss = 0.5366287231445312, train/raw-loss = 0.40158185362815857, train/logprobs = tensor([[-0.3920, -2.6012],
        [-1.0491, -0.3250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350468248128891
Epoch 0, Step 1441: train/loss = 0.7028377056121826, train/raw-loss = 0.5789781808853149, train/logprobs = tensor([[-0.5075, -1.5562],
        [-1.0019, -0.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12385956943035126
Epoch 0, Step 1442: train/loss = 0.33200231194496155, train/raw-loss = 0.17014576494693756, train/logprobs = tensor([[-0.6258, -3.5286],
        [-1.9914, -0.5091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1618565320968628
Epoch 0, Step 1443: train/loss = 0.7139860391616821, train/raw-loss = 0.5909099578857422, train/logprobs = tensor([[-0.6334, -1.4793],
        [-0.7624, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12307605147361755
Epoch 0, Step 1444: train/loss = 0.48742231726646423, train/raw-loss = 0.31443148851394653, train/logprobs = tensor([[-0.6549, -2.8532],
        [-1.4682, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1729907989501953
Epoch 0, Step 1445: train/loss = 0.5407528877258301, train/raw-loss = 0.431297242641449, train/logprobs = tensor([[-0.1724, -2.2284],
        [-0.5453, -1.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10945563018321991
Epoch 0, Step 1446: train/loss = 0.5853878855705261, train/raw-loss = 0.4517771005630493, train/logprobs = tensor([[-1.0069, -8.8580],
        [-1.2644, -1.3277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133610799908638
Epoch 0, Step 1447: train/loss = 0.6769559979438782, train/raw-loss = 0.5586398839950562, train/logprobs = tensor([[-1.0732, -3.5916],
        [-0.5275, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11831611394882202
Epoch 0, Step 1448: train/loss = 0.49073874950408936, train/raw-loss = 0.3855546712875366, train/logprobs = tensor([[-0.2438, -1.9143],
        [-0.6911, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10518411546945572
Epoch 0, Step 1449: train/loss = 0.5488592982292175, train/raw-loss = 0.45212042331695557, train/logprobs = tensor([[-0.1826, -3.7088],
        [-0.8110, -2.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09673891961574554
Epoch 0, Step 1450: train/loss = 0.5649199485778809, train/raw-loss = 0.4617920517921448, train/logprobs = tensor([[-0.1481, -1.6498],
        [-0.5423, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10312794148921967
Epoch 0, Step 1451: train/loss = 0.5009612441062927, train/raw-loss = 0.37800464034080505, train/logprobs = tensor([[-0.4722, -3.3766],
        [-1.2544, -0.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12295660376548767
Epoch 0, Step 1452: train/loss = 0.6094882488250732, train/raw-loss = 0.47647902369499207, train/logprobs = tensor([[-0.4213, -6.7034],
        [-0.9918, -3.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13300924003124237
Epoch 0, Step 1453: train/loss = 0.47755739092826843, train/raw-loss = 0.35303837060928345, train/logprobs = tensor([[-0.2892, -2.6839],
        [-0.7949, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1245189905166626
Epoch 0, Step 1454: train/loss = 0.47603508830070496, train/raw-loss = 0.32514622807502747, train/logprobs = tensor([[-0.6400, -3.6344],
        [-1.2650, -0.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508888602256775
Epoch 0, Step 1455: train/loss = 0.4303702712059021, train/raw-loss = 0.2598874568939209, train/logprobs = tensor([[-0.6073, -6.2282],
        [-1.8024, -2.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704827845096588
Epoch 0, Step 1456: train/loss = 0.6512144804000854, train/raw-loss = 0.5318856239318848, train/logprobs = tensor([[-0.6156, -5.9251],
        [-0.9738, -1.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932890117168427
Epoch 0, Step 1457: train/loss = 0.46166157722473145, train/raw-loss = 0.3266714811325073, train/logprobs = tensor([[-0.4126, -6.0193],
        [-0.9475, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13499006628990173
Epoch 0, Step 1458: train/loss = 0.7176023125648499, train/raw-loss = 0.5974331498146057, train/logprobs = tensor([[-0.2946, -0.4708],
        [-0.8021, -0.5031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12016916275024414
Epoch 0, Step 1459: train/loss = 0.4047185480594635, train/raw-loss = 0.23277689516544342, train/logprobs = tensor([[-0.1921, -6.8210],
        [-1.1787, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17194165289402008
Epoch 0, Step 1460: train/loss = 0.42241013050079346, train/raw-loss = 0.3072746694087982, train/logprobs = tensor([[-0.4177, -5.4440],
        [-1.1041, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11513546109199524
Epoch 0, Step 1461: train/loss = 0.5992526412010193, train/raw-loss = 0.4597978889942169, train/logprobs = tensor([[-0.4497, -1.3540],
        [-1.3458, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1394547075033188
Epoch 0, Step 1462: train/loss = 0.4892970621585846, train/raw-loss = 0.3528588116168976, train/logprobs = tensor([[-0.1747, -2.0771],
        [-1.1043, -0.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.136438250541687
Epoch 0, Step 1463: train/loss = 0.4691900312900543, train/raw-loss = 0.27477964758872986, train/logprobs = tensor([[-1.1846, -3.2740],
        [-1.9413, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19441035389900208
Epoch 0, Step 1464: train/loss = 0.5331484079360962, train/raw-loss = 0.40613746643066406, train/logprobs = tensor([[-0.1280, -3.2616],
        [-0.6051, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12701097130775452
Epoch 0, Step 1465: train/loss = 0.43632787466049194, train/raw-loss = 0.3122262954711914, train/logprobs = tensor([[-0.7850, -4.9415],
        [-1.8634, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12410159409046173
Epoch 0, Step 1466: train/loss = 0.5690730810165405, train/raw-loss = 0.46168380975723267, train/logprobs = tensor([[-0.3307, -3.5551],
        [-0.5518, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10738929361104965
Epoch 0, Step 1467: train/loss = 0.43314385414123535, train/raw-loss = 0.2956145405769348, train/logprobs = tensor([[-0.6209, -8.3375],
        [-1.3703, -1.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13752931356430054
Epoch 0, Step 1468: train/loss = 0.5873781442642212, train/raw-loss = 0.45561525225639343, train/logprobs = tensor([[-1.3094, -4.6264],
        [-1.5780, -0.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13176286220550537
Epoch 0, Step 1469: train/loss = 0.5311548709869385, train/raw-loss = 0.4384768009185791, train/logprobs = tensor([[-0.2724, -1.5474],
        [-0.5681, -0.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0926780104637146
Epoch 0, Step 1470: train/loss = 0.43907326459884644, train/raw-loss = 0.2773517370223999, train/logprobs = tensor([[-0.4702, -3.1256],
        [-0.8641, -0.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16172152757644653
Epoch 0, Step 1471: train/loss = 0.6617048978805542, train/raw-loss = 0.5358771085739136, train/logprobs = tensor([[-0.1610, -1.1331],
        [-0.8834, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12582774460315704
Epoch 0, Step 1472: train/loss = 0.4006534814834595, train/raw-loss = 0.28042072057724, train/logprobs = tensor([[-0.1836, -7.5442],
        [-0.9961, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12023277580738068
Epoch 0, Step 1473: train/loss = 0.4173436164855957, train/raw-loss = 0.29053711891174316, train/logprobs = tensor([[-0.2209, -2.3237],
        [-1.2488, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12680651247501373
Epoch 0, Step 1474: train/loss = 0.7004584074020386, train/raw-loss = 0.5787057876586914, train/logprobs = tensor([[-0.2485, -1.6316],
        [-0.7446, -1.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12175262719392776
Epoch 0, Step 1475: train/loss = 0.5288587808609009, train/raw-loss = 0.3973162770271301, train/logprobs = tensor([[-0.2910, -1.3577],
        [-1.0641, -0.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13154250383377075
Epoch 0, Step 1476: train/loss = 0.5667409300804138, train/raw-loss = 0.4247884452342987, train/logprobs = tensor([[-0.4903, -4.0116],
        [-0.5568, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419525146484375
Epoch 0, Step 1477: train/loss = 0.4063555598258972, train/raw-loss = 0.2328295260667801, train/logprobs = tensor([[-0.5174, -3.6609],
        [-1.7898, -0.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17352604866027832
Epoch 0, Step 1478: train/loss = 0.6781878471374512, train/raw-loss = 0.5576601624488831, train/logprobs = tensor([[-0.1905, -0.5717],
        [-0.7079, -0.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12052765488624573
Epoch 0, Step 1479: train/loss = 0.6306249499320984, train/raw-loss = 0.4773581326007843, train/logprobs = tensor([[-0.4953, -1.7113],
        [-0.9685, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15326684713363647
Epoch 0, Step 1480: train/loss = 0.4285261631011963, train/raw-loss = 0.29016000032424927, train/logprobs = tensor([[-0.6342, -3.1101],
        [-1.4984, -0.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383662074804306
Epoch 0, Step 1481: train/loss = 0.5484869480133057, train/raw-loss = 0.3740829825401306, train/logprobs = tensor([[-0.5281, -4.2996],
        [-1.2438, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17440398037433624
Epoch 0, Step 1482: train/loss = 0.41473668813705444, train/raw-loss = 0.28441691398620605, train/logprobs = tensor([[-0.4342, -7.2156],
        [-1.0936, -0.1739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303197294473648
Epoch 0, Step 1483: train/loss = 0.5478525161743164, train/raw-loss = 0.3970315456390381, train/logprobs = tensor([[-0.3865, -3.1128],
        [-1.1110, -0.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508210152387619
Epoch 0, Step 1484: train/loss = 0.4764319658279419, train/raw-loss = 0.3131965398788452, train/logprobs = tensor([[-0.2206, -4.2394],
        [-0.6761, -0.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16323544085025787
Epoch 0, Step 1485: train/loss = 0.5913665890693665, train/raw-loss = 0.4885549545288086, train/logprobs = tensor([[-0.4209, -1.5813],
        [-0.9176, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281167179346085
Epoch 0, Step 1486: train/loss = 0.6626287698745728, train/raw-loss = 0.5576189160346985, train/logprobs = tensor([[-0.5091, -1.2579],
        [-0.4438, -0.4805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10500982403755188
Epoch 0, Step 1487: train/loss = 0.45238515734672546, train/raw-loss = 0.3318314552307129, train/logprobs = tensor([[-0.3925, -1.5387],
        [-2.0285, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12055373936891556
Epoch 0, Step 1488: train/loss = 0.6407332420349121, train/raw-loss = 0.533379852771759, train/logprobs = tensor([[-0.1912, -0.9284],
        [-0.6300, -0.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073533445596695
Epoch 0, Step 1489: train/loss = 0.49124592542648315, train/raw-loss = 0.3724250793457031, train/logprobs = tensor([[-0.7111, -2.9074],
        [-1.1113, -0.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11882083863019943
Epoch 0, Step 1490: train/loss = 0.4990827441215515, train/raw-loss = 0.38046473264694214, train/logprobs = tensor([[-0.2931, -2.9216],
        [-0.7010, -0.3211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11861801147460938
Epoch 0, Step 1491: train/loss = 0.4022003710269928, train/raw-loss = 0.2098671793937683, train/logprobs = tensor([[-1.0115, -5.0910],
        [-1.6369, -0.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1923331916332245
Epoch 0, Step 1492: train/loss = 0.5484834909439087, train/raw-loss = 0.4043830335140228, train/logprobs = tensor([[-0.2582, -3.7904],
        [-0.9214, -0.5325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14410047233104706
Epoch 0, Step 1493: train/loss = 0.49142560362815857, train/raw-loss = 0.35230642557144165, train/logprobs = tensor([[-0.3371, -2.0187],
        [-1.3048, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391191929578781
Epoch 0, Step 1494: train/loss = 0.4534365236759186, train/raw-loss = 0.2734838128089905, train/logprobs = tensor([[-0.3375, -2.9537],
        [-1.1484, -0.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17995275557041168
Epoch 0, Step 1495: train/loss = 0.4471191465854645, train/raw-loss = 0.28635454177856445, train/logprobs = tensor([[-0.3971, -4.8908],
        [-0.9750, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16076460480690002
Epoch 0, Step 1496: train/loss = 0.4275631606578827, train/raw-loss = 0.30764272809028625, train/logprobs = tensor([[-0.2021, -2.4526],
        [-1.1862, -0.3503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11992043256759644
Epoch 0, Step 1497: train/loss = 0.4743685722351074, train/raw-loss = 0.3472804129123688, train/logprobs = tensor([[-0.2126, -2.3541],
        [-0.5618, -0.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12708815932273865
Epoch 0, Step 1498: train/loss = 0.5384413599967957, train/raw-loss = 0.40140223503112793, train/logprobs = tensor([[-0.6368, -1.5348],
        [-1.3638, -0.3958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13703913986682892
Epoch 0, Step 1499: train/loss = 0.4623033404350281, train/raw-loss = 0.3479684591293335, train/logprobs = tensor([[-0.2087, -1.5357],
        [-1.6607, -0.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1143348440527916
Epoch 0, Step 1500: train/loss = 0.5460620522499084, train/raw-loss = 0.4680808186531067, train/logprobs = tensor([[-0.1005, -2.5693],
        [-0.3246, -0.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07798123359680176
Epoch 0, Step 1501: train/loss = 0.42766767740249634, train/raw-loss = 0.2101798951625824, train/logprobs = tensor([[-0.6198, -3.6990],
        [-1.5855, -0.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21748778223991394
Epoch 0, Step 1502: train/loss = 0.3184538185596466, train/raw-loss = 0.1583021879196167, train/logprobs = tensor([[-0.4774, -4.7294],
        [-1.5190, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1601516306400299
Epoch 0, Step 1503: train/loss = 0.6326423287391663, train/raw-loss = 0.4645964503288269, train/logprobs = tensor([[-1.1203, -3.3367],
        [-1.6701, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16804592311382294
Epoch 0, Step 1504: train/loss = 0.546688437461853, train/raw-loss = 0.42400941252708435, train/logprobs = tensor([[-0.3849, -3.8770],
        [-0.9653, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267901003360748
Epoch 0, Step 1505: train/loss = 0.4890977144241333, train/raw-loss = 0.34541675448417664, train/logprobs = tensor([[-0.3668, -3.3923],
        [-1.2009, -0.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14368097484111786
Epoch 0, Step 1506: train/loss = 0.35070571303367615, train/raw-loss = 0.19278854131698608, train/logprobs = tensor([[-0.3710, -4.0322],
        [-1.4682, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15791718661785126
Epoch 0, Step 1507: train/loss = 0.5646650791168213, train/raw-loss = 0.4222526550292969, train/logprobs = tensor([[-0.2355, -1.9668],
        [-0.6186, -0.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424124538898468
Epoch 0, Step 1508: train/loss = 0.6556325554847717, train/raw-loss = 0.4833003282546997, train/logprobs = tensor([[-0.5654, -3.1375],
        [-1.3394, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17233216762542725
Epoch 0, Step 1509: train/loss = 0.5618014335632324, train/raw-loss = 0.46350207924842834, train/logprobs = tensor([[-0.2491, -1.1474],
        [-1.2044, -0.3586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09829931706190109
Epoch 0, Step 1510: train/loss = 0.5164975523948669, train/raw-loss = 0.38169556856155396, train/logprobs = tensor([[-0.2970, -4.7280],
        [-0.6184, -0.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1348019540309906
Epoch 0, Step 1511: train/loss = 0.4287216365337372, train/raw-loss = 0.3221551179885864, train/logprobs = tensor([[-0.4233, -4.4567],
        [-0.8962, -2.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656651854515076
Epoch 0, Step 1512: train/loss = 0.5588902831077576, train/raw-loss = 0.4201737642288208, train/logprobs = tensor([[-0.3761, -1.4474],
        [-0.9919, -0.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13871648907661438
Epoch 0, Step 1513: train/loss = 0.4563453793525696, train/raw-loss = 0.3104614317417145, train/logprobs = tensor([[-0.2804, -3.9910],
        [-0.9126, -0.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1458839625120163
Epoch 0, Step 1514: train/loss = 0.6044063568115234, train/raw-loss = 0.4921194016933441, train/logprobs = tensor([[-0.4052, -7.3609],
        [-1.3319, -1.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11228696256875992
Epoch 0, Step 1515: train/loss = 0.36756065487861633, train/raw-loss = 0.20503011345863342, train/logprobs = tensor([[-0.4776, -3.6033],
        [-1.9640, -0.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1625305414199829
Epoch 0, Step 1516: train/loss = 0.7010155320167542, train/raw-loss = 0.6101740598678589, train/logprobs = tensor([[-0.4803, -0.6072],
        [-1.1164, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09084146469831467
Epoch 0, Step 1517: train/loss = 0.34443339705467224, train/raw-loss = 0.2007160186767578, train/logprobs = tensor([[ -0.3371, -10.7268],
        [ -1.6324,  -2.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14371737837791443
Epoch 0, Step 1518: train/loss = 0.5757297277450562, train/raw-loss = 0.4785411059856415, train/logprobs = tensor([[-0.4674, -1.5863],
        [-1.1723, -0.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718859195709229
Epoch 0, Step 1519: train/loss = 0.6801977753639221, train/raw-loss = 0.5336849689483643, train/logprobs = tensor([[-0.1399, -1.5601],
        [-0.8383, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14651283621788025
Epoch 0, Step 1520: train/loss = 0.4192502498626709, train/raw-loss = 0.23795637488365173, train/logprobs = tensor([[-0.6174, -7.5013],
        [-1.6460, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18129384517669678
Epoch 0, Step 1521: train/loss = 0.5610311031341553, train/raw-loss = 0.44078177213668823, train/logprobs = tensor([[-0.7461, -2.1192],
        [-1.1799, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12024939060211182
Epoch 0, Step 1522: train/loss = 0.40410229563713074, train/raw-loss = 0.31157776713371277, train/logprobs = tensor([[-0.6312, -6.6324],
        [-1.4770, -1.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09252451360225677
Epoch 0, Step 1523: train/loss = 0.35491180419921875, train/raw-loss = 0.1964903175830841, train/logprobs = tensor([[-1.1793, -6.3038],
        [-2.3012, -1.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15842150151729584
Epoch 0, Step 1524: train/loss = 0.528120219707489, train/raw-loss = 0.37552428245544434, train/logprobs = tensor([[-0.4927, -2.5314],
        [-1.0223, -0.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525959074497223
Epoch 0, Step 1525: train/loss = 0.7030287981033325, train/raw-loss = 0.5666151642799377, train/logprobs = tensor([[-0.2753, -0.4514],
        [-0.8333, -0.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364136040210724
Epoch 0, Step 1526: train/loss = 0.6056949496269226, train/raw-loss = 0.48128098249435425, train/logprobs = tensor([[-0.1891, -2.7220],
        [-0.9175, -1.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12441395223140717
Epoch 0, Step 1527: train/loss = 0.606069028377533, train/raw-loss = 0.45788607001304626, train/logprobs = tensor([[-0.5887, -1.1123],
        [-0.9756, -0.3354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1481829583644867
Epoch 0, Step 1528: train/loss = 0.4099065065383911, train/raw-loss = 0.21874934434890747, train/logprobs = tensor([[-0.2713, -3.6492],
        [-1.1769, -0.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19115716218948364
Epoch 0, Step 1529: train/loss = 0.5770153999328613, train/raw-loss = 0.4108772277832031, train/logprobs = tensor([[-0.2709, -2.4428],
        [-0.9551, -0.6807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1661381721496582
Epoch 0, Step 1530: train/loss = 0.3518625497817993, train/raw-loss = 0.2240210324525833, train/logprobs = tensor([[-0.1890, -2.8341],
        [-1.8859, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12784148752689362
Epoch 0, Step 1531: train/loss = 0.523931622505188, train/raw-loss = 0.39526042342185974, train/logprobs = tensor([[-0.1338, -3.2170],
        [-0.6041, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12867119908332825
Epoch 0, Step 1532: train/loss = 0.6506344079971313, train/raw-loss = 0.48686695098876953, train/logprobs = tensor([[-0.4633, -3.1413],
        [-0.7877, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16376744210720062
Epoch 0, Step 1533: train/loss = 0.43969839811325073, train/raw-loss = 0.30863577127456665, train/logprobs = tensor([[-0.1570, -3.9547],
        [-0.9316, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13106264173984528
Epoch 0, Step 1534: train/loss = 0.4434348940849304, train/raw-loss = 0.334922194480896, train/logprobs = tensor([[-0.3464, -3.3546],
        [-0.9114, -0.3286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10851268470287323
Epoch 0, Step 1535: train/loss = 0.5805104374885559, train/raw-loss = 0.44126707315444946, train/logprobs = tensor([[-0.4347, -1.1793],
        [-1.0148, -0.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13924334943294525
Epoch 0, Step 1536: train/loss = 0.4642469584941864, train/raw-loss = 0.3378787040710449, train/logprobs = tensor([[-0.2777, -4.0807],
        [-0.8873, -1.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12636825442314148
Epoch 0, Step 1537: train/loss = 0.5203567147254944, train/raw-loss = 0.4039229154586792, train/logprobs = tensor([[-0.6483, -1.7855],
        [-1.0218, -0.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11643381416797638
Epoch 0, Step 1538: train/loss = 0.4807228446006775, train/raw-loss = 0.3644718527793884, train/logprobs = tensor([[-0.1443, -4.2788],
        [-0.9384, -2.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11625099927186966
Epoch 0, Step 1539: train/loss = 0.6383168697357178, train/raw-loss = 0.48265960812568665, train/logprobs = tensor([[-0.4445, -1.7636],
        [-0.6721, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15565726161003113
Epoch 0, Step 1540: train/loss = 0.5494557619094849, train/raw-loss = 0.40405601263046265, train/logprobs = tensor([[-0.5725, -2.8570],
        [-1.5273, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14539974927902222
Epoch 0, Step 1541: train/loss = 0.325712651014328, train/raw-loss = 0.17401857674121857, train/logprobs = tensor([[-0.2567, -8.4872],
        [-1.4370, -1.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15169405937194824
Epoch 0, Step 1542: train/loss = 0.7364929914474487, train/raw-loss = 0.6129248142242432, train/logprobs = tensor([[-0.4233, -0.3959],
        [-1.1578, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12356817722320557
Epoch 0, Step 1543: train/loss = 0.6068212389945984, train/raw-loss = 0.47730451822280884, train/logprobs = tensor([[-0.1131, -1.6842],
        [-1.0881, -1.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12951670587062836
Epoch 0, Step 1544: train/loss = 0.46615976095199585, train/raw-loss = 0.3073921203613281, train/logprobs = tensor([[-0.7649, -5.2146],
        [-1.5073, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15876765549182892
Epoch 0, Step 1545: train/loss = 0.564669668674469, train/raw-loss = 0.41338056325912476, train/logprobs = tensor([[-0.5345, -2.3355],
        [-0.9245, -0.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15128906071186066
Epoch 0, Step 1546: train/loss = 0.5911864042282104, train/raw-loss = 0.4597835838794708, train/logprobs = tensor([[-0.1875, -2.1280],
        [-1.0753, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13140279054641724
Epoch 0, Step 1547: train/loss = 0.6218591332435608, train/raw-loss = 0.5023348331451416, train/logprobs = tensor([[-0.3011, -1.6479],
        [-1.0026, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11952430009841919
Epoch 0, Step 1548: train/loss = 0.5210320949554443, train/raw-loss = 0.41582658886909485, train/logprobs = tensor([[-0.1785, -4.3641],
        [-0.5888, -1.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052054911851883
Epoch 0, Step 1549: train/loss = 0.6032249927520752, train/raw-loss = 0.48194724321365356, train/logprobs = tensor([[-0.2864, -1.4483],
        [-1.0366, -0.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12127774208784103
Epoch 0, Step 1550: train/loss = 0.5513348579406738, train/raw-loss = 0.43124353885650635, train/logprobs = tensor([[-0.3864, -1.6083],
        [-1.1723, -0.7844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12009131908416748
Epoch 0, Step 1551: train/loss = 0.42146405577659607, train/raw-loss = 0.28049176931381226, train/logprobs = tensor([[-0.2983, -4.0445],
        [-0.8575, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1409722864627838
Epoch 0, Step 1552: train/loss = 0.488436222076416, train/raw-loss = 0.36066770553588867, train/logprobs = tensor([[-0.3404, -7.8780],
        [-1.1847, -1.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12776851654052734
Epoch 0, Step 1553: train/loss = 0.4613302946090698, train/raw-loss = 0.3338596224784851, train/logprobs = tensor([[-0.3386, -2.6926],
        [-1.3448, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12747064232826233
Epoch 0, Step 1554: train/loss = 0.5962523818016052, train/raw-loss = 0.5000244379043579, train/logprobs = tensor([[-0.2668, -1.0627],
        [-0.9598, -0.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0962279886007309
Epoch 0, Step 1555: train/loss = 0.4293552041053772, train/raw-loss = 0.3049866557121277, train/logprobs = tensor([[-0.3146, -4.0682],
        [-1.3766, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1243685632944107
Epoch 0, Step 1556: train/loss = 0.5492141246795654, train/raw-loss = 0.4250102639198303, train/logprobs = tensor([[-0.2707, -6.9123],
        [-0.5780, -1.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12420384585857391
Epoch 0, Step 1557: train/loss = 0.4542364776134491, train/raw-loss = 0.33808577060699463, train/logprobs = tensor([[-0.2671, -3.0304],
        [-0.9768, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11615071445703506
Epoch 0, Step 1558: train/loss = 0.44971853494644165, train/raw-loss = 0.29527002573013306, train/logprobs = tensor([[-0.3842, -6.7621],
        [-1.0992, -2.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1544484794139862
Epoch 0, Step 1559: train/loss = 0.5109716653823853, train/raw-loss = 0.3729652166366577, train/logprobs = tensor([[-0.5806, -2.7323],
        [-1.6378, -0.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13800646364688873
Epoch 0, Step 1560: train/loss = 0.48056018352508545, train/raw-loss = 0.3722825050354004, train/logprobs = tensor([[-0.3348, -3.4467],
        [-0.7028, -0.4345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10827763378620148
Epoch 0, Step 1561: train/loss = 0.42145609855651855, train/raw-loss = 0.2146606743335724, train/logprobs = tensor([[-0.6740, -3.5695],
        [-1.8541, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20679539442062378
Epoch 0, Step 1562: train/loss = 0.5117840766906738, train/raw-loss = 0.34967929124832153, train/logprobs = tensor([[-1.1064, -6.0266],
        [-1.6438, -2.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1621048003435135
Epoch 0, Step 1563: train/loss = 0.6797698736190796, train/raw-loss = 0.5149506330490112, train/logprobs = tensor([[-0.7586, -1.3114],
        [-1.3765, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16481919586658478
Epoch 0, Step 1564: train/loss = 0.43997031450271606, train/raw-loss = 0.2760166823863983, train/logprobs = tensor([[-0.8455, -5.1456],
        [-1.8983, -1.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16395363211631775
Epoch 0, Step 1565: train/loss = 0.6159696578979492, train/raw-loss = 0.5132367014884949, train/logprobs = tensor([[-0.2073, -0.5433],
        [-0.7497, -0.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273296386003494
Epoch 0, Step 1566: train/loss = 0.4725072979927063, train/raw-loss = 0.3016469478607178, train/logprobs = tensor([[-0.6093, -4.5341],
        [-1.3568, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17086033523082733
Epoch 0, Step 1567: train/loss = 0.6636849045753479, train/raw-loss = 0.558080792427063, train/logprobs = tensor([[-0.1585, -1.6926],
        [-0.6036, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056041419506073
Epoch 0, Step 1568: train/loss = 0.4351661205291748, train/raw-loss = 0.33183741569519043, train/logprobs = tensor([[-0.1960, -4.4401],
        [-0.9446, -1.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10332871228456497
Epoch 0, Step 1569: train/loss = 0.6086490154266357, train/raw-loss = 0.49807658791542053, train/logprobs = tensor([[-0.5596, -0.9979],
        [-0.9972, -0.3776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057247221469879
Epoch 0, Step 1570: train/loss = 0.5284026861190796, train/raw-loss = 0.4290299117565155, train/logprobs = tensor([[-0.1900, -1.8249],
        [-0.7783, -0.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09937277436256409
Epoch 0, Step 1571: train/loss = 0.5145748257637024, train/raw-loss = 0.4064865708351135, train/logprobs = tensor([[-0.3470, -2.0530],
        [-1.0946, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10808825492858887
Epoch 0, Step 1572: train/loss = 0.41569238901138306, train/raw-loss = 0.305450975894928, train/logprobs = tensor([[-0.1805, -2.6814],
        [-1.0226, -0.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11024142801761627
Epoch 0, Step 1573: train/loss = 0.3917137384414673, train/raw-loss = 0.28804993629455566, train/logprobs = tensor([[-0.2994, -3.8309],
        [-1.3141, -0.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10366383194923401
Epoch 0, Step 1574: train/loss = 0.6281012892723083, train/raw-loss = 0.49936017394065857, train/logprobs = tensor([[-0.2906, -1.1377],
        [-0.9772, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287410855293274
Epoch 0, Step 1575: train/loss = 0.5806695222854614, train/raw-loss = 0.39986586570739746, train/logprobs = tensor([[-0.6689, -2.7061],
        [-1.4029, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18080365657806396
Epoch 0, Step 1576: train/loss = 0.7231684923171997, train/raw-loss = 0.6610796451568604, train/logprobs = tensor([[-0.1902, -0.1928],
        [-0.3178, -0.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06208880990743637
Epoch 0, Step 1577: train/loss = 0.7139086723327637, train/raw-loss = 0.601272463798523, train/logprobs = tensor([[-0.3661, -0.5657],
        [-0.6349, -0.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11263620108366013
Epoch 0, Step 1578: train/loss = 0.3107760548591614, train/raw-loss = 0.20954491198062897, train/logprobs = tensor([[-0.1664, -8.8259],
        [-1.0550, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10123114287853241
Epoch 0, Step 1579: train/loss = 0.47464579343795776, train/raw-loss = 0.3243510127067566, train/logprobs = tensor([[-0.4443, -4.2448],
        [-1.3572, -0.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502947360277176
Epoch 0, Step 1580: train/loss = 0.47012561559677124, train/raw-loss = 0.3417571187019348, train/logprobs = tensor([[-0.3716, -2.3632],
        [-0.8711, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836849689483643
Epoch 0, Step 1581: train/loss = 0.35614001750946045, train/raw-loss = 0.21372181177139282, train/logprobs = tensor([[-0.1054, -1.9757],
        [-1.7361, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14241817593574524
Epoch 0, Step 1582: train/loss = 0.32501333951950073, train/raw-loss = 0.19544732570648193, train/logprobs = tensor([[-0.3879, -8.1225],
        [-1.6840, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295659840106964
Epoch 0, Step 1583: train/loss = 0.5049170255661011, train/raw-loss = 0.3450838029384613, train/logprobs = tensor([[-0.3704, -6.5772],
        [-1.9353, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15983323752880096
Epoch 0, Step 1584: train/loss = 0.5203378200531006, train/raw-loss = 0.3459346294403076, train/logprobs = tensor([[-1.1457, -3.5462],
        [-1.8004, -0.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17440320551395416
Epoch 0, Step 1585: train/loss = 0.4696841239929199, train/raw-loss = 0.34930264949798584, train/logprobs = tensor([[-0.2324, -1.5993],
        [-0.9062, -0.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038149684667587
Epoch 0, Step 1586: train/loss = 0.43676337599754333, train/raw-loss = 0.29363787174224854, train/logprobs = tensor([[-0.3297, -4.3126],
        [-1.3043, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431255042552948
Epoch 0, Step 1587: train/loss = 0.39944976568222046, train/raw-loss = 0.23403891921043396, train/logprobs = tensor([[-0.4478, -3.4662],
        [-1.1857, -0.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654108315706253
Epoch 0, Step 1588: train/loss = 0.4565243124961853, train/raw-loss = 0.3179423213005066, train/logprobs = tensor([[-0.2123, -3.6905],
        [-1.1047, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13858196139335632
Epoch 0, Step 1589: train/loss = 0.5215750932693481, train/raw-loss = 0.38580501079559326, train/logprobs = tensor([[-0.3302, -3.8345],
        [-0.9573, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13577012717723846
Epoch 0, Step 1590: train/loss = 0.42326104640960693, train/raw-loss = 0.3155139982700348, train/logprobs = tensor([[-0.2244, -5.1631],
        [-0.6835, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10774704068899155
Epoch 0, Step 1591: train/loss = 0.46215319633483887, train/raw-loss = 0.31572315096855164, train/logprobs = tensor([[-0.3579, -3.8279],
        [-1.0070, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14643003046512604
Epoch 0, Step 1592: train/loss = 0.5523324012756348, train/raw-loss = 0.42137521505355835, train/logprobs = tensor([[-0.4024, -1.7529],
        [-0.8376, -0.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13095718622207642
Epoch 0, Step 1593: train/loss = 0.4977419674396515, train/raw-loss = 0.34730541706085205, train/logprobs = tensor([[-0.4181, -3.7707],
        [-1.1106, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15043658018112183
Epoch 0, Step 1594: train/loss = 0.5094146728515625, train/raw-loss = 0.3709529638290405, train/logprobs = tensor([[-0.4048, -2.0460],
        [-0.9162, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13846167922019958
Epoch 0, Step 1595: train/loss = 0.6063520908355713, train/raw-loss = 0.4681573510169983, train/logprobs = tensor([[-0.1557, -1.6624],
        [-0.7659, -1.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13819476962089539
Epoch 0, Step 1596: train/loss = 0.4982036352157593, train/raw-loss = 0.3505745232105255, train/logprobs = tensor([[-0.5569, -7.6404],
        [-1.1721, -0.4434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14762908220291138
Epoch 0, Step 1597: train/loss = 0.4231744110584259, train/raw-loss = 0.2797093689441681, train/logprobs = tensor([[-0.5517, -4.8254],
        [-1.4536, -1.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434650421142578
Epoch 0, Step 1598: train/loss = 0.5258105993270874, train/raw-loss = 0.39031729102134705, train/logprobs = tensor([[-0.8749, -8.0936],
        [-1.0952, -2.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13549333810806274
Epoch 0, Step 1599: train/loss = 0.49099498987197876, train/raw-loss = 0.3007679581642151, train/logprobs = tensor([[-0.6382, -7.2713],
        [-1.1830, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19022703170776367
Epoch 0, Step 1600: train/loss = 0.4791530668735504, train/raw-loss = 0.3690585196018219, train/logprobs = tensor([[-0.6123, -4.4999],
        [-0.5553, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1100945696234703
Epoch 0, Step 1601: train/loss = 0.33940163254737854, train/raw-loss = 0.18263499438762665, train/logprobs = tensor([[ -0.3822, -10.9375],
        [ -1.1159,  -1.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15676665306091309
Epoch 0, Step 1602: train/loss = 0.4982714056968689, train/raw-loss = 0.3511442542076111, train/logprobs = tensor([[-0.2994, -3.2181],
        [-0.7296, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471271514892578
Epoch 0, Step 1603: train/loss = 0.5311996936798096, train/raw-loss = 0.43843376636505127, train/logprobs = tensor([[-0.2063, -2.2624],
        [-0.6978, -1.0161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09276589751243591
Epoch 0, Step 1604: train/loss = 0.4276588559150696, train/raw-loss = 0.3068713843822479, train/logprobs = tensor([[-0.4330, -8.6597],
        [-0.7865, -4.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12078747153282166
Epoch 0, Step 1605: train/loss = 0.48975464701652527, train/raw-loss = 0.36419862508773804, train/logprobs = tensor([[-0.2576, -2.3974],
        [-1.0249, -0.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12555602192878723
Epoch 0, Step 1606: train/loss = 0.3415580987930298, train/raw-loss = 0.22135551273822784, train/logprobs = tensor([[-0.2737, -5.3562],
        [-1.2522, -2.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12020258605480194
Epoch 0, Step 1607: train/loss = 0.6011168360710144, train/raw-loss = 0.49912047386169434, train/logprobs = tensor([[-0.3820, -1.8314],
        [-0.9206, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10199637711048126
Epoch 0, Step 1608: train/loss = 0.5222803950309753, train/raw-loss = 0.38766032457351685, train/logprobs = tensor([[-0.4458, -5.9308],
        [-0.7310, -1.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13462013006210327
Epoch 0, Step 1609: train/loss = 0.45786309242248535, train/raw-loss = 0.34005218744277954, train/logprobs = tensor([[-0.3820, -4.7397],
        [-0.9811, -1.2284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11781089007854462
Epoch 0, Step 1610: train/loss = 0.59809410572052, train/raw-loss = 0.49154242873191833, train/logprobs = tensor([[-0.6038, -2.5790],
        [-0.6752, -0.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10655167698860168
Epoch 0, Step 1611: train/loss = 0.5071162581443787, train/raw-loss = 0.3688901662826538, train/logprobs = tensor([[-0.4912, -1.6569],
        [-1.2018, -0.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13822606205940247
Epoch 0, Step 1612: train/loss = 0.4272913336753845, train/raw-loss = 0.2760508060455322, train/logprobs = tensor([[-0.2856, -4.0996],
        [-1.0046, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15124055743217468
Epoch 0, Step 1613: train/loss = 0.7265872955322266, train/raw-loss = 0.6376993656158447, train/logprobs = tensor([[-0.3140, -0.3792],
        [-0.5907, -0.3542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08888792991638184
Epoch 0, Step 1614: train/loss = 0.47875040769577026, train/raw-loss = 0.300128698348999, train/logprobs = tensor([[-0.5734, -7.0247],
        [-1.0158, -1.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17862175405025482
Epoch 0, Step 1615: train/loss = 0.49503612518310547, train/raw-loss = 0.35428592562675476, train/logprobs = tensor([[-0.2256, -3.8346],
        [-0.7126, -1.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1407501995563507
Epoch 0, Step 1616: train/loss = 0.5384521484375, train/raw-loss = 0.41572338342666626, train/logprobs = tensor([[-0.5199, -3.6840],
        [-1.0872, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12272877246141434
Epoch 0, Step 1617: train/loss = 0.4744938015937805, train/raw-loss = 0.36990708112716675, train/logprobs = tensor([[-0.0772, -2.4247],
        [-0.9148, -0.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10458673536777496
Epoch 0, Step 1618: train/loss = 0.5352895855903625, train/raw-loss = 0.4278582036495209, train/logprobs = tensor([[-0.1775, -1.4104],
        [-0.9844, -0.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10743136703968048
Epoch 0, Step 1619: train/loss = 0.4392203688621521, train/raw-loss = 0.3035106360912323, train/logprobs = tensor([[-0.3851, -4.4840],
        [-0.7716, -0.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357097327709198
Epoch 0, Step 1620: train/loss = 0.49705982208251953, train/raw-loss = 0.37974509596824646, train/logprobs = tensor([[-0.2992, -2.0413],
        [-0.8501, -0.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11731471121311188
Epoch 0, Step 1621: train/loss = 0.6026490330696106, train/raw-loss = 0.49551108479499817, train/logprobs = tensor([[-0.4356, -1.0409],
        [-0.8412, -0.3737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10713797062635422
Epoch 0, Step 1622: train/loss = 0.3475819528102875, train/raw-loss = 0.21436762809753418, train/logprobs = tensor([[-0.4687, -7.3175],
        [-1.9103, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332143247127533
Epoch 0, Step 1623: train/loss = 0.5710943341255188, train/raw-loss = 0.4441674053668976, train/logprobs = tensor([[-0.3852, -1.8357],
        [-0.7342, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126926988363266
Epoch 0, Step 1624: train/loss = 0.3696008622646332, train/raw-loss = 0.2619622051715851, train/logprobs = tensor([[-0.1895, -3.6003],
        [-0.9311, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076386570930481
Epoch 0, Step 1625: train/loss = 0.4697803854942322, train/raw-loss = 0.31041181087493896, train/logprobs = tensor([[-0.4968, -3.5419],
        [-1.0493, -0.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1593685895204544
Epoch 0, Step 1626: train/loss = 0.5146570205688477, train/raw-loss = 0.38687974214553833, train/logprobs = tensor([[-0.2448, -1.1973],
        [-1.0232, -0.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1277773231267929
Epoch 0, Step 1627: train/loss = 0.5217025279998779, train/raw-loss = 0.3953026831150055, train/logprobs = tensor([[-0.5100, -2.0533],
        [-0.8411, -0.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12639981508255005
Epoch 0, Step 1628: train/loss = 0.3819815218448639, train/raw-loss = 0.2666739821434021, train/logprobs = tensor([[-0.4152, -4.7350],
        [-0.9658, -0.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11530756205320358
Epoch 0, Step 1629: train/loss = 0.5873016119003296, train/raw-loss = 0.49006083607673645, train/logprobs = tensor([[-0.3336, -1.9399],
        [-0.6234, -0.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09724079817533493
Epoch 0, Step 1630: train/loss = 0.5766011476516724, train/raw-loss = 0.4423956573009491, train/logprobs = tensor([[-0.1738, -1.3287],
        [-0.9135, -0.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13420549035072327
Epoch 0, Step 1631: train/loss = 0.4261813163757324, train/raw-loss = 0.2902830243110657, train/logprobs = tensor([[-0.2234, -5.3562],
        [-0.6819, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13589830696582794
Epoch 0, Step 1632: train/loss = 0.48156169056892395, train/raw-loss = 0.3337385058403015, train/logprobs = tensor([[-0.2732, -6.4010],
        [-0.6916, -1.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14782315492630005
Epoch 0, Step 1633: train/loss = 0.5078905820846558, train/raw-loss = 0.3796391487121582, train/logprobs = tensor([[-0.7784, -3.8554],
        [-1.4970, -0.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12825144827365875
Epoch 0, Step 1634: train/loss = 0.5507498383522034, train/raw-loss = 0.395158588886261, train/logprobs = tensor([[-0.4007, -1.9488],
        [-1.1477, -0.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15559121966362
Epoch 0, Step 1635: train/loss = 0.5819474458694458, train/raw-loss = 0.3852797746658325, train/logprobs = tensor([[-0.4119, -6.1272],
        [-1.1213, -1.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19666774570941925
Epoch 0, Step 1636: train/loss = 0.4596247673034668, train/raw-loss = 0.34308838844299316, train/logprobs = tensor([[-0.1814, -2.7417],
        [-0.7485, -0.3696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11653634905815125
Epoch 0, Step 1637: train/loss = 0.5105658769607544, train/raw-loss = 0.35010993480682373, train/logprobs = tensor([[-0.4656, -7.3557],
        [-1.1579, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16045595705509186
Epoch 0, Step 1638: train/loss = 0.5099793076515198, train/raw-loss = 0.3652617633342743, train/logprobs = tensor([[-0.5328, -5.7666],
        [-1.2935, -1.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1447175145149231
Epoch 0, Step 1639: train/loss = 0.4455915689468384, train/raw-loss = 0.3375967741012573, train/logprobs = tensor([[-0.4701, -6.7023],
        [-0.9908, -0.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10799477994441986
Epoch 0, Step 1640: train/loss = 0.4981541931629181, train/raw-loss = 0.37293940782546997, train/logprobs = tensor([[-0.2268, -2.3097],
        [-0.8100, -0.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12521478533744812
Epoch 0, Step 1641: train/loss = 0.42574402689933777, train/raw-loss = 0.30833378434181213, train/logprobs = tensor([[-0.1942, -7.7765],
        [-0.6788, -0.2790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11741023510694504
Epoch 0, Step 1642: train/loss = 0.43606036901474, train/raw-loss = 0.2715846300125122, train/logprobs = tensor([[-0.3036, -6.2193],
        [-1.0889, -2.8901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644757091999054
Epoch 0, Step 1643: train/loss = 0.523339033126831, train/raw-loss = 0.36876630783081055, train/logprobs = tensor([[-0.9062, -6.8999],
        [-1.1277, -2.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545727401971817
Epoch 0, Step 1644: train/loss = 0.5265001058578491, train/raw-loss = 0.37980180978775024, train/logprobs = tensor([[-0.7790, -2.8506],
        [-1.0785, -0.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14669832587242126
Epoch 0, Step 1645: train/loss = 0.30629462003707886, train/raw-loss = 0.15597742795944214, train/logprobs = tensor([[ -0.3672, -10.0748],
        [ -1.4952,  -3.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1503172069787979
Epoch 0, Step 1646: train/loss = 0.6180090308189392, train/raw-loss = 0.5039849877357483, train/logprobs = tensor([[-0.5034, -1.9458],
        [-0.4655, -0.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11402403563261032
Epoch 0, Step 1647: train/loss = 0.5263288617134094, train/raw-loss = 0.4380302131175995, train/logprobs = tensor([[-0.1018, -1.1588],
        [-0.7105, -0.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08829864859580994
Epoch 0, Step 1648: train/loss = 0.4774789810180664, train/raw-loss = 0.3532540202140808, train/logprobs = tensor([[-0.1655, -2.2264],
        [-0.8294, -0.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12422493100166321
Epoch 0, Step 1649: train/loss = 0.5348526835441589, train/raw-loss = 0.4166775345802307, train/logprobs = tensor([[-0.3534, -6.4540],
        [-0.8787, -1.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817516386508942
Epoch 0, Step 1650: train/loss = 0.4740603566169739, train/raw-loss = 0.35904955863952637, train/logprobs = tensor([[-0.2578, -4.0702],
        [-0.7467, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150108128786087
Epoch 0, Step 1651: train/loss = 0.505833625793457, train/raw-loss = 0.35680049657821655, train/logprobs = tensor([[-0.2982, -2.5947],
        [-0.8116, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14903312921524048
Epoch 0, Step 1652: train/loss = 0.6402288675308228, train/raw-loss = 0.5655809640884399, train/logprobs = tensor([[-0.1732, -3.2228],
        [-0.3402, -0.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07464786618947983
Epoch 0, Step 1653: train/loss = 0.506614625453949, train/raw-loss = 0.3377167582511902, train/logprobs = tensor([[-0.2873, -3.0175],
        [-0.6930, -0.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1688978374004364
Epoch 0, Step 1654: train/loss = 0.4659879803657532, train/raw-loss = 0.35802385210990906, train/logprobs = tensor([[-0.6100, -6.6337],
        [-1.2647, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10796412825584412
Epoch 0, Step 1655: train/loss = 0.43217596411705017, train/raw-loss = 0.29071250557899475, train/logprobs = tensor([[-0.3058, -7.6327],
        [-0.7291, -0.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14146344363689423
Epoch 0, Step 1656: train/loss = 0.48743805289268494, train/raw-loss = 0.3633780777454376, train/logprobs = tensor([[-0.3269, -1.5868],
        [-1.1078, -0.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1240599974989891
Epoch 0, Step 1657: train/loss = 0.5901639461517334, train/raw-loss = 0.47157031297683716, train/logprobs = tensor([[-0.2813, -0.5998],
        [-1.7586, -0.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11859364062547684
Epoch 0, Step 1658: train/loss = 0.5856893062591553, train/raw-loss = 0.4921343922615051, train/logprobs = tensor([[-0.6143, -3.3509],
        [-1.3188, -1.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09355494379997253
Epoch 0, Step 1659: train/loss = 0.4771946668624878, train/raw-loss = 0.3238653242588043, train/logprobs = tensor([[-0.5531, -2.7679],
        [-1.1925, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15332937240600586
Epoch 0, Step 1660: train/loss = 0.39073920249938965, train/raw-loss = 0.2592121660709381, train/logprobs = tensor([[-0.2642, -5.3003],
        [-1.0239, -0.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13152703642845154
Epoch 0, Step 1661: train/loss = 0.6542354226112366, train/raw-loss = 0.5542647838592529, train/logprobs = tensor([[-0.2884, -1.0797],
        [-0.5466, -0.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09997058659791946
Epoch 0, Step 1662: train/loss = 0.4321507215499878, train/raw-loss = 0.26582860946655273, train/logprobs = tensor([[-0.4192, -5.3033],
        [-1.3312, -2.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16632211208343506
Epoch 0, Step 1663: train/loss = 0.419416218996048, train/raw-loss = 0.31702685356140137, train/logprobs = tensor([[-0.3788, -2.0044],
        [-1.6615, -0.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10238935798406601
Epoch 0, Step 1664: train/loss = 0.61878502368927, train/raw-loss = 0.47783583402633667, train/logprobs = tensor([[-0.2407, -0.8918],
        [-0.8139, -0.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14094923436641693
Epoch 0, Step 1665: train/loss = 0.5174287557601929, train/raw-loss = 0.38828718662261963, train/logprobs = tensor([[-0.5749, -2.3311],
        [-0.7322, -0.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12914155423641205
Epoch 0, Step 1666: train/loss = 0.5131699442863464, train/raw-loss = 0.4151618480682373, train/logprobs = tensor([[-0.5689, -1.9607],
        [-1.1325, -0.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09800811111927032
Epoch 0, Step 1667: train/loss = 0.3540794849395752, train/raw-loss = 0.24719229340553284, train/logprobs = tensor([[-0.2417, -6.6131],
        [-0.8514, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10688719153404236
Epoch 0, Step 1668: train/loss = 0.5637637376785278, train/raw-loss = 0.4962012767791748, train/logprobs = tensor([[-0.3260, -2.3448],
        [-0.2000, -0.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06756249070167542
Epoch 0, Step 1669: train/loss = 0.3386847972869873, train/raw-loss = 0.20343326032161713, train/logprobs = tensor([[-0.1852, -5.1726],
        [-1.0008, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13525155186653137
Epoch 0, Step 1670: train/loss = 0.3244952857494354, train/raw-loss = 0.16755473613739014, train/logprobs = tensor([[-0.4856, -5.5623],
        [-1.5859, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15694056451320648
Epoch 0, Step 1671: train/loss = 0.4298170804977417, train/raw-loss = 0.3269917368888855, train/logprobs = tensor([[-0.6691, -3.2225],
        [-1.2928, -0.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1028253436088562
Epoch 0, Step 1672: train/loss = 0.5605111718177795, train/raw-loss = 0.39118337631225586, train/logprobs = tensor([[-0.5027, -3.9397],
        [-0.9027, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1693277806043625
Epoch 0, Step 1673: train/loss = 0.4266829490661621, train/raw-loss = 0.3207981586456299, train/logprobs = tensor([[-0.1935, -2.6937],
        [-0.7544, -0.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588476806879044
Epoch 0, Step 1674: train/loss = 0.5390391945838928, train/raw-loss = 0.4234289824962616, train/logprobs = tensor([[-0.7180, -4.2276],
        [-0.4510, -0.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11561018973588943
Epoch 0, Step 1675: train/loss = 0.3811325430870056, train/raw-loss = 0.2595776915550232, train/logprobs = tensor([[-0.5927, -4.3269],
        [-1.0643, -0.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12155485898256302
Epoch 0, Step 1676: train/loss = 0.5083763599395752, train/raw-loss = 0.3553205132484436, train/logprobs = tensor([[-0.6514, -2.7640],
        [-1.3701, -0.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1530558466911316
Epoch 0, Step 1677: train/loss = 0.4101788103580475, train/raw-loss = 0.3245307505130768, train/logprobs = tensor([[-0.3646, -4.0937],
        [-0.9941, -0.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08564803749322891
Epoch 0, Step 1678: train/loss = 0.496009886264801, train/raw-loss = 0.37915921211242676, train/logprobs = tensor([[-0.4426, -1.4731],
        [-1.2789, -0.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685068905353546
Epoch 0, Step 1679: train/loss = 0.602225661277771, train/raw-loss = 0.4738577902317047, train/logprobs = tensor([[-0.4004, -1.0745],
        [-0.9325, -0.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836788594722748
Epoch 0, Step 1680: train/loss = 0.5793108344078064, train/raw-loss = 0.44353076815605164, train/logprobs = tensor([[-0.3620, -1.5533],
        [-0.7532, -0.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13578003644943237
Epoch 0, Step 1681: train/loss = 0.4770813584327698, train/raw-loss = 0.34785300493240356, train/logprobs = tensor([[ -0.7404, -10.9145],
        [ -1.0447,  -2.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12922832369804382
Epoch 0, Step 1682: train/loss = 0.5264174342155457, train/raw-loss = 0.39904478192329407, train/logprobs = tensor([[-0.3229, -3.7534],
        [-0.8984, -0.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12737266719341278
Epoch 0, Step 1683: train/loss = 0.4633614420890808, train/raw-loss = 0.349880576133728, train/logprobs = tensor([[-0.7544, -2.2067],
        [-1.3069, -0.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1134808361530304
Epoch 0, Step 1684: train/loss = 0.7012176513671875, train/raw-loss = 0.6182718276977539, train/logprobs = tensor([[-0.3511, -0.8939],
        [-0.6861, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08294589072465897
Epoch 0, Step 1685: train/loss = 0.5326228141784668, train/raw-loss = 0.39753836393356323, train/logprobs = tensor([[-0.2228, -2.7165],
        [-0.5365, -0.4711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13508446514606476
Epoch 0, Step 1686: train/loss = 0.3924342393875122, train/raw-loss = 0.26388972997665405, train/logprobs = tensor([[-0.4684, -9.0704],
        [-1.1957, -2.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12854452431201935
Epoch 0, Step 1687: train/loss = 0.5191513299942017, train/raw-loss = 0.38190650939941406, train/logprobs = tensor([[-0.3031, -4.4107],
        [-1.0206, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1372448354959488
Epoch 0, Step 1688: train/loss = 0.4725415110588074, train/raw-loss = 0.3537609279155731, train/logprobs = tensor([[-0.3638, -3.7781],
        [-0.9895, -0.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11878059804439545
Epoch 0, Step 1689: train/loss = 0.5665350556373596, train/raw-loss = 0.4428875744342804, train/logprobs = tensor([[-0.1875, -3.3030],
        [-0.7264, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364745140075684
Epoch 0, Step 1690: train/loss = 0.5307830572128296, train/raw-loss = 0.41638702154159546, train/logprobs = tensor([[-0.3181, -2.2753],
        [-0.7204, -0.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11439603567123413
Epoch 0, Step 1691: train/loss = 0.5901912450790405, train/raw-loss = 0.5024551153182983, train/logprobs = tensor([[-0.3846, -2.7246],
        [-0.5444, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08773612976074219
Epoch 0, Step 1692: train/loss = 0.5044283270835876, train/raw-loss = 0.3554821014404297, train/logprobs = tensor([[-0.6220, -2.2028],
        [-1.4978, -0.4298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14894625544548035
Epoch 0, Step 1693: train/loss = 0.5305435657501221, train/raw-loss = 0.4014705717563629, train/logprobs = tensor([[-0.4829, -2.6928],
        [-0.8057, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12907300889492035
Epoch 0, Step 1694: train/loss = 0.44202446937561035, train/raw-loss = 0.3071507215499878, train/logprobs = tensor([[-0.1535, -2.5767],
        [-0.9452, -0.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13487377762794495
Epoch 0, Step 1695: train/loss = 0.6918575763702393, train/raw-loss = 0.6110912561416626, train/logprobs = tensor([[-0.4454, -1.3941],
        [-0.5139, -0.6180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08076632767915726
Epoch 0, Step 1696: train/loss = 0.5561726093292236, train/raw-loss = 0.4566662311553955, train/logprobs = tensor([[-0.6369, -3.0493],
        [-0.7201, -0.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09950637072324753
Epoch 0, Step 1697: train/loss = 0.6300117373466492, train/raw-loss = 0.5433485507965088, train/logprobs = tensor([[-0.1234, -0.6541],
        [-0.4002, -0.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08666319400072098
Epoch 0, Step 1698: train/loss = 0.5835857391357422, train/raw-loss = 0.4731222987174988, train/logprobs = tensor([[-0.6120, -1.9246],
        [-0.4794, -0.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1104634553194046
Epoch 0, Step 1699: train/loss = 0.507536768913269, train/raw-loss = 0.4001229405403137, train/logprobs = tensor([[-0.4486, -3.4926],
        [-0.8486, -0.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10741384327411652
Epoch 0, Step 1700: train/loss = 0.5456981062889099, train/raw-loss = 0.41983023285865784, train/logprobs = tensor([[-0.4466, -2.0567],
        [-0.7300, -0.3845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12586785852909088
Epoch 0, Step 1701: train/loss = 0.5692957639694214, train/raw-loss = 0.4375911355018616, train/logprobs = tensor([[-0.9061, -2.5282],
        [-1.2577, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1317046880722046
Epoch 0, Step 1702: train/loss = 0.5555076599121094, train/raw-loss = 0.4316627085208893, train/logprobs = tensor([[-0.2728, -1.8574],
        [-0.6901, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238449290394783
Epoch 0, Step 1703: train/loss = 0.49455949664115906, train/raw-loss = 0.36026984453201294, train/logprobs = tensor([[-0.3300, -5.8413],
        [-1.0302, -1.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13428963720798492
Epoch 0, Step 1704: train/loss = 0.4159691631793976, train/raw-loss = 0.2716081142425537, train/logprobs = tensor([[-0.1835, -4.0826],
        [-0.8735, -0.3038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14436101913452148
Epoch 0, Step 1705: train/loss = 0.47002172470092773, train/raw-loss = 0.3570721745491028, train/logprobs = tensor([[-0.1641, -7.3736],
        [-0.8456, -1.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11294955015182495
Epoch 0, Step 1706: train/loss = 0.4625219702720642, train/raw-loss = 0.31536561250686646, train/logprobs = tensor([[-0.2113, -3.1863],
        [-1.1270, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14715635776519775
Epoch 0, Step 1707: train/loss = 0.5009474754333496, train/raw-loss = 0.3652549684047699, train/logprobs = tensor([[-0.2426, -1.8425],
        [-0.8351, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13569247722625732
Epoch 0, Step 1708: train/loss = 0.4504525065422058, train/raw-loss = 0.3563305139541626, train/logprobs = tensor([[-0.4607, -2.2043],
        [-1.0408, -0.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0941220298409462
Epoch 0, Step 1709: train/loss = 0.5322741270065308, train/raw-loss = 0.41665345430374146, train/logprobs = tensor([[-0.3400, -2.9636],
        [-0.5390, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156206876039505
Epoch 0, Step 1710: train/loss = 0.5498826503753662, train/raw-loss = 0.42131659388542175, train/logprobs = tensor([[-0.3296, -2.6101],
        [-0.8358, -0.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12856608629226685
Epoch 0, Step 1711: train/loss = 0.40240705013275146, train/raw-loss = 0.2559994161128998, train/logprobs = tensor([[-0.1409, -5.3101],
        [-0.8618, -0.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14640763401985168
Epoch 0, Step 1712: train/loss = 0.3673655390739441, train/raw-loss = 0.24159321188926697, train/logprobs = tensor([[-0.1913, -8.3124],
        [-0.6788, -0.1892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12577232718467712
Epoch 0, Step 1713: train/loss = 0.49031174182891846, train/raw-loss = 0.32168298959732056, train/logprobs = tensor([[-0.4874, -3.4623],
        [-1.2443, -0.5858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1686287373304367
Epoch 0, Step 1714: train/loss = 0.6471128463745117, train/raw-loss = 0.5678547024726868, train/logprobs = tensor([[-0.1659, -0.5139],
        [-0.3731, -0.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07925812155008316
Epoch 0, Step 1715: train/loss = 0.5549190044403076, train/raw-loss = 0.4609067440032959, train/logprobs = tensor([[-0.4278, -2.5659],
        [-0.6157, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401223063468933
Epoch 0, Step 1716: train/loss = 0.5796675682067871, train/raw-loss = 0.47690001130104065, train/logprobs = tensor([[-0.5466, -2.0558],
        [-0.6309, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10276754945516586
Epoch 0, Step 1717: train/loss = 0.5064176321029663, train/raw-loss = 0.40777915716171265, train/logprobs = tensor([[-0.3129, -6.2097],
        [-0.9104, -2.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09863849729299545
Epoch 0, Step 1718: train/loss = 0.4923664331436157, train/raw-loss = 0.38938257098197937, train/logprobs = tensor([[-0.2049, -2.2511],
        [-0.8203, -0.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10298384726047516
Epoch 0, Step 1719: train/loss = 0.4656047821044922, train/raw-loss = 0.2832675576210022, train/logprobs = tensor([[-0.4135, -4.9056],
        [-1.1913, -0.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18233723938465118
Epoch 0, Step 1720: train/loss = 0.7885185480117798, train/raw-loss = 0.6881569623947144, train/logprobs = tensor([[-0.6799, -0.8392],
        [-0.5484, -0.1224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10036148875951767
Epoch 0, Step 1721: train/loss = 0.40993696451187134, train/raw-loss = 0.24896690249443054, train/logprobs = tensor([[-0.8018, -8.2448],
        [-1.3492, -0.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.160970076918602
Epoch 0, Step 1722: train/loss = 0.40812668204307556, train/raw-loss = 0.22547873854637146, train/logprobs = tensor([[-0.6534, -3.7282],
        [-1.4329, -0.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1826479434967041
Epoch 0, Step 1723: train/loss = 0.4851871132850647, train/raw-loss = 0.3629135489463806, train/logprobs = tensor([[-0.3856, -3.5838],
        [-1.3176, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227356433868408
Epoch 0, Step 1724: train/loss = 0.37198418378829956, train/raw-loss = 0.246613547205925, train/logprobs = tensor([[-0.3306, -5.4760],
        [-0.7681, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12537062168121338
Epoch 0, Step 1725: train/loss = 0.5420911312103271, train/raw-loss = 0.4103543162345886, train/logprobs = tensor([[-0.3514, -5.5291],
        [-0.9604, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13173678517341614
Epoch 0, Step 1726: train/loss = 0.3745149075984955, train/raw-loss = 0.2141236960887909, train/logprobs = tensor([[-0.5904, -5.4347],
        [-1.1843, -0.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603911966085434
Epoch 0, Step 1727: train/loss = 0.4657052159309387, train/raw-loss = 0.3413154184818268, train/logprobs = tensor([[-0.3704, -2.8299],
        [-0.8589, -0.5543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12438981980085373
Epoch 0, Step 1728: train/loss = 0.615621030330658, train/raw-loss = 0.5458406209945679, train/logprobs = tensor([[-0.2648, -1.8145],
        [-0.2360, -0.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06978042423725128
Epoch 0, Step 1729: train/loss = 0.39998090267181396, train/raw-loss = 0.257804811000824, train/logprobs = tensor([[-0.4525, -4.5885],
        [-0.9524, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14217610657215118
Epoch 0, Step 1730: train/loss = 0.7047932147979736, train/raw-loss = 0.5690894722938538, train/logprobs = tensor([[-0.6011, -0.9672],
        [-0.7504, -0.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357036978006363
Epoch 0, Step 1731: train/loss = 0.6393675208091736, train/raw-loss = 0.5346096754074097, train/logprobs = tensor([[-0.1458, -1.8838],
        [-0.7336, -0.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10475784540176392
Epoch 0, Step 1732: train/loss = 0.4972408413887024, train/raw-loss = 0.38299787044525146, train/logprobs = tensor([[-0.3093, -4.5329],
        [-0.9759, -1.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11424295604228973
Epoch 0, Step 1733: train/loss = 0.5084999799728394, train/raw-loss = 0.41273653507232666, train/logprobs = tensor([[-0.1183, -2.3430],
        [-0.4850, -0.2552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0957634449005127
Epoch 0, Step 1734: train/loss = 0.5127278566360474, train/raw-loss = 0.4139682352542877, train/logprobs = tensor([[-0.2961, -3.1499],
        [-0.4540, -0.2821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09875959157943726
Epoch 0, Step 1735: train/loss = 0.3410932123661041, train/raw-loss = 0.1974835842847824, train/logprobs = tensor([[-0.2811, -5.9104],
        [-1.4218, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14360959827899933
Epoch 0, Step 1736: train/loss = 0.42250555753707886, train/raw-loss = 0.2737605571746826, train/logprobs = tensor([[-0.5333, -5.4657],
        [-1.0352, -0.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14874501526355743
Epoch 0, Step 1737: train/loss = 0.4248691201210022, train/raw-loss = 0.24614325165748596, train/logprobs = tensor([[-0.3797, -6.7459],
        [-1.7261, -2.4866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17872586846351624
Epoch 0, Step 1738: train/loss = 0.4905875325202942, train/raw-loss = 0.369717538356781, train/logprobs = tensor([[-0.6295, -3.5415],
        [-0.9400, -0.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12087002396583557
Epoch 0, Step 1739: train/loss = 0.5171992778778076, train/raw-loss = 0.38281333446502686, train/logprobs = tensor([[-0.3232, -2.3013],
        [-0.5636, -0.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13438600301742554
Epoch 0, Step 1740: train/loss = 0.42545032501220703, train/raw-loss = 0.3026350736618042, train/logprobs = tensor([[-0.3418, -4.1150],
        [-1.3838, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12281527370214462
Epoch 0, Step 1741: train/loss = 0.5317270159721375, train/raw-loss = 0.41264909505844116, train/logprobs = tensor([[-0.4870, -4.1781],
        [-1.2267, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11907792091369629
Epoch 0, Step 1742: train/loss = 0.4668140411376953, train/raw-loss = 0.35313838720321655, train/logprobs = tensor([[-0.3739, -2.9868],
        [-1.1098, -0.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367565393447876
Epoch 0, Step 1743: train/loss = 0.6918043494224548, train/raw-loss = 0.59377121925354, train/logprobs = tensor([[-0.2654, -1.0905],
        [-0.6067, -0.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803308546543121
Epoch 0, Step 1744: train/loss = 0.7085240483283997, train/raw-loss = 0.5866732597351074, train/logprobs = tensor([[-0.8698, -2.2361],
        [-0.6972, -0.2563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12185074388980865
Epoch 0, Step 1745: train/loss = 0.5379645228385925, train/raw-loss = 0.4451141953468323, train/logprobs = tensor([[-0.2143, -2.6683],
        [-0.6610, -0.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09285033494234085
Epoch 0, Step 1746: train/loss = 0.5688846111297607, train/raw-loss = 0.47341179847717285, train/logprobs = tensor([[-0.1533, -1.3197],
        [-0.4798, -0.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09547284990549088
Epoch 0, Step 1747: train/loss = 0.5783520936965942, train/raw-loss = 0.4962949752807617, train/logprobs = tensor([[-0.4327, -0.7853],
        [-0.8645, -0.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08205711841583252
Epoch 0, Step 1748: train/loss = 0.6367465257644653, train/raw-loss = 0.4936038553714752, train/logprobs = tensor([[-0.6006, -1.0528],
        [-1.2829, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431427001953125
Epoch 0, Step 1749: train/loss = 0.5195292830467224, train/raw-loss = 0.4186657965183258, train/logprobs = tensor([[-0.1737, -1.6730],
        [-0.9596, -0.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1008635014295578
Epoch 0, Step 1750: train/loss = 0.3801669478416443, train/raw-loss = 0.23823340237140656, train/logprobs = tensor([[ -0.5148, -10.1389],
        [ -1.4211,  -3.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14193354547023773
Epoch 0, Step 1751: train/loss = 0.5155812501907349, train/raw-loss = 0.4162728190422058, train/logprobs = tensor([[-0.4209, -5.2446],
        [-0.6626, -2.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930845350027084
Epoch 0, Step 1752: train/loss = 0.412995845079422, train/raw-loss = 0.3045825660228729, train/logprobs = tensor([[-0.2542, -9.0221],
        [-0.8526, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10841327905654907
Epoch 0, Step 1753: train/loss = 0.37094828486442566, train/raw-loss = 0.23184332251548767, train/logprobs = tensor([[-0.5237, -7.3354],
        [-1.1258, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391049474477768
Epoch 0, Step 1754: train/loss = 0.3541021943092346, train/raw-loss = 0.15885835886001587, train/logprobs = tensor([[-0.5535, -6.3558],
        [-1.6778, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19524383544921875
Epoch 0, Step 1755: train/loss = 0.4756682217121124, train/raw-loss = 0.36142516136169434, train/logprobs = tensor([[-0.3601, -3.0564],
        [-1.0653, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11424306035041809
Epoch 0, Step 1756: train/loss = 0.5561226606369019, train/raw-loss = 0.4246363043785095, train/logprobs = tensor([[-0.7676, -2.3461],
        [-1.0222, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13148634135723114
Epoch 0, Step 1757: train/loss = 0.6714291572570801, train/raw-loss = 0.5730944871902466, train/logprobs = tensor([[-0.2111, -0.4310],
        [-0.7809, -0.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0983346551656723
Epoch 0, Step 1758: train/loss = 0.44139736890792847, train/raw-loss = 0.3181823790073395, train/logprobs = tensor([[-0.2355, -4.9248],
        [-0.6840, -0.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1232149675488472
Epoch 0, Step 1759: train/loss = 0.578603982925415, train/raw-loss = 0.4846334457397461, train/logprobs = tensor([[-0.2285, -1.5138],
        [-0.8742, -0.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397055953741074
Epoch 0, Step 1760: train/loss = 0.660921573638916, train/raw-loss = 0.5363163352012634, train/logprobs = tensor([[-0.9933, -6.4075],
        [-1.4316, -1.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12460525333881378
Epoch 0, Step 1761: train/loss = 0.3934413194656372, train/raw-loss = 0.2678951025009155, train/logprobs = tensor([[-0.3932, -3.2353],
        [-0.8208, -0.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12554620206356049
Epoch 0, Step 1762: train/loss = 0.5188043117523193, train/raw-loss = 0.39030203223228455, train/logprobs = tensor([[-0.2690, -4.2947],
        [-0.8674, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12850229442119598
Epoch 0, Step 1763: train/loss = 0.6023146510124207, train/raw-loss = 0.45746684074401855, train/logprobs = tensor([[-0.7712, -3.7507],
        [-0.4782, -0.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1448478102684021
Epoch 0, Step 1764: train/loss = 0.40473806858062744, train/raw-loss = 0.27718430757522583, train/logprobs = tensor([[-0.2428, -4.2249],
        [-0.6623, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1275537610054016
Epoch 0, Step 1765: train/loss = 0.5985927581787109, train/raw-loss = 0.47396665811538696, train/logprobs = tensor([[-0.1799, -2.2245],
        [-0.5284, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12462610006332397
Epoch 0, Step 1766: train/loss = 0.4090481996536255, train/raw-loss = 0.29202884435653687, train/logprobs = tensor([[-0.3048, -5.6985],
        [-1.3494, -1.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11701938509941101
Epoch 0, Step 1767: train/loss = 0.43667325377464294, train/raw-loss = 0.3143807649612427, train/logprobs = tensor([[ -0.2339, -10.1652],
        [ -0.5777,  -2.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12229251116514206
Epoch 0, Step 1768: train/loss = 0.461935818195343, train/raw-loss = 0.3190777599811554, train/logprobs = tensor([[-0.4745, -3.1483],
        [-1.3252, -1.0874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14285805821418762
Epoch 0, Step 1769: train/loss = 0.4174923896789551, train/raw-loss = 0.2925877571105957, train/logprobs = tensor([[-0.7258, -3.4334],
        [-1.4288, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12490466982126236
Epoch 0, Step 1770: train/loss = 0.37704822421073914, train/raw-loss = 0.25723960995674133, train/logprobs = tensor([[ -0.7829, -10.4505],
        [ -1.2611,  -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1198086142539978
Epoch 0, Step 1771: train/loss = 0.5533609390258789, train/raw-loss = 0.42981183528900146, train/logprobs = tensor([[-0.5942, -2.6300],
        [-1.0692, -0.6616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12354908883571625
Epoch 0, Step 1772: train/loss = 0.3784003257751465, train/raw-loss = 0.285530686378479, train/logprobs = tensor([[-0.3465, -3.0263],
        [-0.8721, -0.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09286961704492569
Epoch 0, Step 1773: train/loss = 0.3851485848426819, train/raw-loss = 0.2555252015590668, train/logprobs = tensor([[-0.2381, -5.8417],
        [-0.8101, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12962336838245392
Epoch 0, Step 1774: train/loss = 0.5913617014884949, train/raw-loss = 0.4742501378059387, train/logprobs = tensor([[-0.5149, -1.2697],
        [-0.9727, -0.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11711158603429794
Epoch 0, Step 1775: train/loss = 0.5529131293296814, train/raw-loss = 0.4322167634963989, train/logprobs = tensor([[-0.2572, -1.5379],
        [-0.9130, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12069635838270187
Epoch 0, Step 1776: train/loss = 0.43340593576431274, train/raw-loss = 0.2991083860397339, train/logprobs = tensor([[-0.1934, -4.0576],
        [-0.8668, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13429756462574005
Epoch 0, Step 1777: train/loss = 0.5584210753440857, train/raw-loss = 0.40039581060409546, train/logprobs = tensor([[-0.2863, -2.1387],
        [-0.7428, -0.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15802523493766785
Epoch 0, Step 1778: train/loss = 0.6500341296195984, train/raw-loss = 0.5040205717086792, train/logprobs = tensor([[-0.6911, -1.4115],
        [-1.0814, -0.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1460135579109192
Epoch 0, Step 1779: train/loss = 0.5857869386672974, train/raw-loss = 0.4463384747505188, train/logprobs = tensor([[-0.3317, -5.8787],
        [-0.6664, -1.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13944847881793976
Epoch 0, Step 1780: train/loss = 0.6006594896316528, train/raw-loss = 0.4752907156944275, train/logprobs = tensor([[-0.2289, -3.7173],
        [-0.4741, -2.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12536880373954773
Epoch 0, Step 1781: train/loss = 0.5332356095314026, train/raw-loss = 0.39374300837516785, train/logprobs = tensor([[-0.3887, -2.3386],
        [-0.9961, -0.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13949260115623474
Epoch 0, Step 1782: train/loss = 0.35772767663002014, train/raw-loss = 0.24238157272338867, train/logprobs = tensor([[-0.1997, -4.3598],
        [-0.6593, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11534610390663147
Epoch 0, Step 1783: train/loss = 0.49286049604415894, train/raw-loss = 0.35931360721588135, train/logprobs = tensor([[-0.4835, -2.7083],
        [-1.1972, -0.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335468888282776
Epoch 0, Step 1784: train/loss = 0.6191819906234741, train/raw-loss = 0.5012617111206055, train/logprobs = tensor([[-0.5072, -1.6002],
        [-0.8209, -0.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11792028695344925
Epoch 0, Step 1785: train/loss = 0.6165393590927124, train/raw-loss = 0.5233125686645508, train/logprobs = tensor([[-0.1277, -1.1934],
        [-0.4208, -0.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322673082351685
Epoch 0, Step 1786: train/loss = 0.5688997507095337, train/raw-loss = 0.4710266590118408, train/logprobs = tensor([[-0.1786, -1.7575],
        [-0.5375, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09787307679653168
Epoch 0, Step 1787: train/loss = 0.582866370677948, train/raw-loss = 0.44466179609298706, train/logprobs = tensor([[-0.7472, -1.5739],
        [-1.2252, -0.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13820457458496094
Epoch 0, Step 1788: train/loss = 0.5531933903694153, train/raw-loss = 0.4520164728164673, train/logprobs = tensor([[-0.2229, -1.9818],
        [-0.4773, -0.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101176917552948
Epoch 0, Step 1789: train/loss = 0.49017244577407837, train/raw-loss = 0.3580944836139679, train/logprobs = tensor([[-0.5846, -3.5592],
        [-0.8960, -0.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13207797706127167
Epoch 0, Step 1790: train/loss = 0.39239928126335144, train/raw-loss = 0.26798534393310547, train/logprobs = tensor([[-0.2964, -4.9706],
        [-1.0112, -1.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12441393733024597
Epoch 0, Step 1791: train/loss = 0.5959006547927856, train/raw-loss = 0.4872128963470459, train/logprobs = tensor([[-0.4350, -1.1731],
        [-0.9497, -0.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10868775844573975
Epoch 0, Step 1792: train/loss = 0.6052330136299133, train/raw-loss = 0.4453306198120117, train/logprobs = tensor([[-0.3116, -1.7856],
        [-0.9048, -0.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15990234911441803
Epoch 0, Step 1793: train/loss = 0.40886932611465454, train/raw-loss = 0.28277695178985596, train/logprobs = tensor([[-0.3259, -4.6672],
        [-0.8941, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260923594236374
Epoch 0, Step 1794: train/loss = 0.42139962315559387, train/raw-loss = 0.32665231823921204, train/logprobs = tensor([[-0.3465, -2.1282],
        [-1.1220, -0.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474729746580124
Epoch 0, Step 1795: train/loss = 0.3990991711616516, train/raw-loss = 0.25334760546684265, train/logprobs = tensor([[ -0.5441, -10.7068],
        [ -1.4757,  -1.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14575158059597015
Epoch 0, Step 1796: train/loss = 0.5990318059921265, train/raw-loss = 0.5102738738059998, train/logprobs = tensor([[-0.2613, -1.1374],
        [-0.5903, -0.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08875791728496552
Epoch 0, Step 1797: train/loss = 0.4251459836959839, train/raw-loss = 0.31309258937835693, train/logprobs = tensor([[-0.5419, -5.1201],
        [-1.2182, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11205340176820755
Epoch 0, Step 1798: train/loss = 0.46125328540802, train/raw-loss = 0.2822287678718567, train/logprobs = tensor([[-0.6164, -8.3069],
        [-1.6280, -1.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17902451753616333
Epoch 0, Step 1799: train/loss = 0.4496680796146393, train/raw-loss = 0.3541980981826782, train/logprobs = tensor([[-0.3586, -2.7971],
        [-0.9303, -0.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09546996653079987
Epoch 0, Step 1800: train/loss = 0.35237258672714233, train/raw-loss = 0.2182224839925766, train/logprobs = tensor([[-0.3780, -7.0488],
        [-1.2726, -0.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13415010273456573
Epoch 0, Step 1801: train/loss = 0.4165876507759094, train/raw-loss = 0.29299187660217285, train/logprobs = tensor([[-0.3084, -3.4564],
        [-1.0281, -0.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12359577417373657
Epoch 0, Step 1802: train/loss = 0.5791357755661011, train/raw-loss = 0.4625740945339203, train/logprobs = tensor([[-0.6848, -3.9082],
        [-0.7936, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.116561658680439
Epoch 0, Step 1803: train/loss = 0.5135395526885986, train/raw-loss = 0.36427703499794006, train/logprobs = tensor([[-0.5362, -5.1778],
        [-0.9033, -1.5472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14926256239414215
Epoch 0, Step 1804: train/loss = 0.5544165968894958, train/raw-loss = 0.453186571598053, train/logprobs = tensor([[-0.5183, -2.1944],
        [-0.7436, -0.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10123002529144287
Epoch 0, Step 1805: train/loss = 0.5767824649810791, train/raw-loss = 0.4433639645576477, train/logprobs = tensor([[-0.4219, -2.2174],
        [-0.9689, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1334184855222702
Epoch 0, Step 1806: train/loss = 0.3927743136882782, train/raw-loss = 0.2803284525871277, train/logprobs = tensor([[-0.1134, -2.5546],
        [-1.1870, -0.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11244586110115051
Epoch 0, Step 1807: train/loss = 0.6416090726852417, train/raw-loss = 0.5364464521408081, train/logprobs = tensor([[-0.3607, -2.0409],
        [-0.5685, -0.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1051625907421112
Epoch 0, Step 1808: train/loss = 0.4337383210659027, train/raw-loss = 0.32531681656837463, train/logprobs = tensor([[-0.1556, -3.6258],
        [-0.7346, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10842151194810867
Epoch 0, Step 1809: train/loss = 0.44882866740226746, train/raw-loss = 0.34337174892425537, train/logprobs = tensor([[-0.3194, -6.6160],
        [-0.7837, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10545691847801208
Epoch 0, Step 1810: train/loss = 0.5068744421005249, train/raw-loss = 0.42050445079803467, train/logprobs = tensor([[-0.4166, -1.5231],
        [-1.1584, -0.2702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08636994659900665
Epoch 0, Step 1811: train/loss = 0.523120641708374, train/raw-loss = 0.40247827768325806, train/logprobs = tensor([[-0.6385, -6.3787],
        [-0.8407, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12064234912395477
Epoch 0, Step 1812: train/loss = 0.3199174702167511, train/raw-loss = 0.15835338830947876, train/logprobs = tensor([[-0.8394, -6.8016],
        [-1.8288, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16156409680843353
Epoch 0, Step 1813: train/loss = 0.36388152837753296, train/raw-loss = 0.23029232025146484, train/logprobs = tensor([[-0.4502, -7.7665],
        [-1.0176, -3.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13358920812606812
Epoch 0, Step 1814: train/loss = 0.4894152879714966, train/raw-loss = 0.3323402404785156, train/logprobs = tensor([[-0.2697, -2.6399],
        [-0.7537, -0.6646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15707506239414215
Epoch 0, Step 1815: train/loss = 0.37273281812667847, train/raw-loss = 0.260865718126297, train/logprobs = tensor([[-0.3961, -9.0862],
        [-0.7807, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11186709254980087
Epoch 0, Step 1816: train/loss = 0.44826048612594604, train/raw-loss = 0.33030804991722107, train/logprobs = tensor([[-0.2094, -3.0095],
        [-0.4985, -0.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11795245856046677
Epoch 0, Step 1817: train/loss = 0.6653822660446167, train/raw-loss = 0.5973420143127441, train/logprobs = tensor([[-0.3766, -0.5920],
        [-0.4849, -0.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804029643535614
Epoch 0, Step 1818: train/loss = 0.3600500226020813, train/raw-loss = 0.2099417746067047, train/logprobs = tensor([[-0.3497, -7.4536],
        [-1.4112, -1.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15010826289653778
Epoch 0, Step 1819: train/loss = 0.43150126934051514, train/raw-loss = 0.32716062664985657, train/logprobs = tensor([[-0.1964, -3.5647],
        [-0.6497, -0.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434065014123917
Epoch 0, Step 1820: train/loss = 0.49758827686309814, train/raw-loss = 0.3970142602920532, train/logprobs = tensor([[-0.1193, -2.0120],
        [-0.6699, -0.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005740612745285
Epoch 0, Step 1821: train/loss = 0.4416637718677521, train/raw-loss = 0.30557066202163696, train/logprobs = tensor([[-0.2286, -3.8754],
        [-0.7941, -0.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13609308004379272
Epoch 0, Step 1822: train/loss = 0.5768155455589294, train/raw-loss = 0.442859947681427, train/logprobs = tensor([[-0.4218, -2.2598],
        [-0.5935, -0.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13395561277866364
Epoch 0, Step 1823: train/loss = 0.5383201241493225, train/raw-loss = 0.3842730224132538, train/logprobs = tensor([[-0.3141, -2.4655],
        [-1.1957, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15404710173606873
Epoch 0, Step 1824: train/loss = 0.4926697611808777, train/raw-loss = 0.38495147228240967, train/logprobs = tensor([[-0.1861, -1.8631],
        [-0.7638, -0.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771829634904861
Epoch 0, Step 1825: train/loss = 0.4892180562019348, train/raw-loss = 0.3465832471847534, train/logprobs = tensor([[-0.5481, -3.0280],
        [-1.3590, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142634779214859
Epoch 0, Step 1826: train/loss = 0.45596593618392944, train/raw-loss = 0.34674951434135437, train/logprobs = tensor([[-0.6449, -3.0381],
        [-0.9950, -0.5886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10921643674373627
Epoch 0, Step 1827: train/loss = 0.44783815741539, train/raw-loss = 0.3308601975440979, train/logprobs = tensor([[-0.2534, -1.5079],
        [-1.0456, -0.2586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169779822230339
Epoch 0, Step 1828: train/loss = 0.3536377549171448, train/raw-loss = 0.20806971192359924, train/logprobs = tensor([[-0.3692, -5.2664],
        [-1.4165, -0.3622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14556801319122314
Epoch 0, Step 1829: train/loss = 0.5073158740997314, train/raw-loss = 0.4161316156387329, train/logprobs = tensor([[-0.2208, -1.9967],
        [-0.4098, -0.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09118430316448212
Epoch 0, Step 1830: train/loss = 0.5055109262466431, train/raw-loss = 0.4252092242240906, train/logprobs = tensor([[-0.1917, -1.8904],
        [-0.4072, -0.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0803016945719719
Epoch 0, Step 1831: train/loss = 0.7323079705238342, train/raw-loss = 0.6316889524459839, train/logprobs = tensor([[-0.2505, -0.4066],
        [-0.4116, -0.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10061904788017273
Epoch 0, Step 1832: train/loss = 0.47078853845596313, train/raw-loss = 0.3694155216217041, train/logprobs = tensor([[-0.0533, -3.5221],
        [-0.3449, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10137299448251724
Epoch 0, Step 1833: train/loss = 0.6795697808265686, train/raw-loss = 0.5826516151428223, train/logprobs = tensor([[-0.2262, -1.1400],
        [-0.3516, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09691815823316574
Epoch 0, Step 1834: train/loss = 0.5838133096694946, train/raw-loss = 0.4678300619125366, train/logprobs = tensor([[-0.4494, -2.9604],
        [-0.5837, -0.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11598321050405502
Epoch 0, Step 1835: train/loss = 0.3266998529434204, train/raw-loss = 0.2185165286064148, train/logprobs = tensor([[-0.3087, -9.9449],
        [-0.6874, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10818328708410263
Epoch 0, Step 1836: train/loss = 0.4126112759113312, train/raw-loss = 0.2024078518152237, train/logprobs = tensor([[-0.3885, -4.8628],
        [-1.2549, -0.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21020342409610748
Epoch 0, Step 1837: train/loss = 0.504853367805481, train/raw-loss = 0.393553227186203, train/logprobs = tensor([[-0.4320, -3.2862],
        [-0.7143, -0.2737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11130013316869736
Epoch 0, Step 1838: train/loss = 0.5440265536308289, train/raw-loss = 0.4297105073928833, train/logprobs = tensor([[-0.5184, -2.3459],
        [-0.3892, -0.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11431607604026794
Epoch 0, Step 1839: train/loss = 0.43983712792396545, train/raw-loss = 0.295021116733551, train/logprobs = tensor([[-0.3229, -3.0179],
        [-0.7742, -0.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14481601119041443
Epoch 0, Step 1840: train/loss = 0.3299092650413513, train/raw-loss = 0.1739635467529297, train/logprobs = tensor([[-0.4099, -8.3414],
        [-1.3457, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15594571828842163
Epoch 0, Step 1841: train/loss = 0.48249292373657227, train/raw-loss = 0.3800170421600342, train/logprobs = tensor([[-0.2433, -2.2700],
        [-0.7663, -0.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247589647769928
Epoch 0, Step 1842: train/loss = 0.49381470680236816, train/raw-loss = 0.3840096592903137, train/logprobs = tensor([[-0.5197, -5.3352],
        [-1.0266, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10980504751205444
Epoch 0, Step 1843: train/loss = 0.33789488673210144, train/raw-loss = 0.20107245445251465, train/logprobs = tensor([[-0.4043, -8.9792],
        [-1.3720, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368224173784256
Epoch 0, Step 1844: train/loss = 0.48078763484954834, train/raw-loss = 0.34202831983566284, train/logprobs = tensor([[-0.5079, -1.8158],
        [-1.6196, -0.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13875934481620789
Epoch 0, Step 1845: train/loss = 0.42340293526649475, train/raw-loss = 0.2598790228366852, train/logprobs = tensor([[-0.7359, -6.3733],
        [-1.1333, -1.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16352392733097076
Epoch 0, Step 1846: train/loss = 0.5682647228240967, train/raw-loss = 0.47485461831092834, train/logprobs = tensor([[-0.1425, -2.4129],
        [-0.7116, -0.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341014176607132
Epoch 0, Step 1847: train/loss = 0.4613179564476013, train/raw-loss = 0.30513808131217957, train/logprobs = tensor([[-0.5064, -3.6708],
        [-1.2258, -0.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15617984533309937
Epoch 0, Step 1848: train/loss = 0.5339800119400024, train/raw-loss = 0.46306779980659485, train/logprobs = tensor([[-0.0932, -0.7022],
        [-0.9442, -0.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07091227173805237
Epoch 0, Step 1849: train/loss = 0.5643917322158813, train/raw-loss = 0.49176985025405884, train/logprobs = tensor([[-0.1208, -2.1290],
        [-0.4755, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07262186706066132
Epoch 0, Step 1850: train/loss = 0.3200148344039917, train/raw-loss = 0.1949852854013443, train/logprobs = tensor([[-0.3037, -4.8733],
        [-0.9967, -0.2385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1250295490026474
Epoch 0, Step 1851: train/loss = 0.3400265872478485, train/raw-loss = 0.1842796504497528, train/logprobs = tensor([[-0.2605, -4.8979],
        [-1.0417, -0.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557469367980957
Epoch 0, Step 1852: train/loss = 0.3430720865726471, train/raw-loss = 0.19919192790985107, train/logprobs = tensor([[ -0.5560, -10.7516],
        [ -1.3922,  -2.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1438801884651184
Epoch 0, Step 1853: train/loss = 0.523531436920166, train/raw-loss = 0.43852943181991577, train/logprobs = tensor([[-0.3531, -3.5929],
        [-0.7742, -0.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500196784734726
Epoch 0, Step 1854: train/loss = 0.8725704550743103, train/raw-loss = 0.7616549730300903, train/logprobs = tensor([[-1.9791, -5.4372],
        [-0.6324, -1.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11091551184654236
Epoch 0, Step 1855: train/loss = 0.3979625105857849, train/raw-loss = 0.2516525387763977, train/logprobs = tensor([[-0.4830, -9.0967],
        [-1.0646, -2.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14630994200706482
Epoch 0, Step 1856: train/loss = 0.35164397954940796, train/raw-loss = 0.21374575793743134, train/logprobs = tensor([[-0.5273, -5.8558],
        [-1.1080, -0.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13789822161197662
Epoch 0, Step 1857: train/loss = 0.4137954115867615, train/raw-loss = 0.2876078486442566, train/logprobs = tensor([[-0.4829, -2.8722],
        [-1.1445, -0.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12618757784366608
Epoch 0, Step 1858: train/loss = 0.5587143898010254, train/raw-loss = 0.4390473961830139, train/logprobs = tensor([[-0.4398, -1.4294],
        [-0.7276, -0.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966702342033386
Epoch 0, Step 1859: train/loss = 0.5149828791618347, train/raw-loss = 0.414900004863739, train/logprobs = tensor([[-0.3903, -2.2441],
        [-0.7864, -0.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10008285939693451
Epoch 0, Step 1860: train/loss = 0.5318149924278259, train/raw-loss = 0.4306204915046692, train/logprobs = tensor([[-0.5377, -2.3290],
        [-1.0691, -0.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10119450092315674
Epoch 0, Step 1861: train/loss = 0.33986157178878784, train/raw-loss = 0.21830835938453674, train/logprobs = tensor([[-0.3240, -9.4439],
        [-0.9850, -2.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1215532198548317
Epoch 0, Step 1862: train/loss = 0.5845961570739746, train/raw-loss = 0.471566379070282, train/logprobs = tensor([[-0.1567, -3.7348],
        [-0.5506, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11302979290485382
Epoch 0, Step 1863: train/loss = 0.5479959845542908, train/raw-loss = 0.4100116789340973, train/logprobs = tensor([[-0.7198, -2.3450],
        [-1.2023, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13798433542251587
Epoch 0, Step 1864: train/loss = 0.3736863136291504, train/raw-loss = 0.25004521012306213, train/logprobs = tensor([[-0.4442, -4.8798],
        [-1.2686, -0.1579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364112585783005
Epoch 0, Step 1865: train/loss = 0.6552651524543762, train/raw-loss = 0.5428884029388428, train/logprobs = tensor([[-0.1402, -2.4270],
        [-0.3249, -0.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11237668991088867
Epoch 0, Step 1866: train/loss = 0.5579322576522827, train/raw-loss = 0.4422094225883484, train/logprobs = tensor([[-0.5844, -2.6000],
        [-0.8491, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11572286486625671
Epoch 0, Step 1867: train/loss = 0.5045570731163025, train/raw-loss = 0.3906506896018982, train/logprobs = tensor([[-0.4735, -1.8563],
        [-1.2347, -0.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11390643566846848
Epoch 0, Step 1868: train/loss = 0.6694360971450806, train/raw-loss = 0.5708068609237671, train/logprobs = tensor([[-0.5273, -1.0852],
        [-0.5173, -0.2755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09862926602363586
Epoch 0, Step 1869: train/loss = 0.4519706964492798, train/raw-loss = 0.295805424451828, train/logprobs = tensor([[-0.8987, -5.2443],
        [-2.4717, -2.3825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15616527199745178
Epoch 0, Step 1870: train/loss = 0.335241436958313, train/raw-loss = 0.22095999121665955, train/logprobs = tensor([[-0.4098, -2.7335],
        [-1.7868, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11428149044513702
Epoch 0, Step 1871: train/loss = 0.49411410093307495, train/raw-loss = 0.37567153573036194, train/logprobs = tensor([[-0.1736, -5.8092],
        [-0.4869, -0.2886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11844256520271301
Epoch 0, Step 1872: train/loss = 0.7510964870452881, train/raw-loss = 0.6728821396827698, train/logprobs = tensor([[-0.2254, -0.4561],
        [-0.1570, -0.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07821431010961533
Epoch 0, Step 1873: train/loss = 0.6044086813926697, train/raw-loss = 0.5179460644721985, train/logprobs = tensor([[-0.5518, -1.5035],
        [-1.1321, -0.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646263182163239
Epoch 0, Step 1874: train/loss = 0.35128509998321533, train/raw-loss = 0.23188604414463043, train/logprobs = tensor([[-0.3076, -6.1867],
        [-0.8046, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193990409374237
Epoch 0, Step 1875: train/loss = 0.5594943761825562, train/raw-loss = 0.46132320165634155, train/logprobs = tensor([[-0.2457, -2.8299],
        [-0.7287, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817114472389221
Epoch 0, Step 1876: train/loss = 0.481595516204834, train/raw-loss = 0.3863242268562317, train/logprobs = tensor([[-0.2151, -5.9110],
        [-0.7407, -2.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09527130424976349
Epoch 0, Step 1877: train/loss = 0.4333304762840271, train/raw-loss = 0.2681620121002197, train/logprobs = tensor([[-0.6976, -7.9455],
        [-1.7093, -2.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1651684194803238
Epoch 0, Step 1878: train/loss = 0.4550057053565979, train/raw-loss = 0.32111257314682007, train/logprobs = tensor([[-0.1398, -5.7620],
        [-0.8831, -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13389308750629425
Epoch 0, Step 1879: train/loss = 0.43158119916915894, train/raw-loss = 0.2588520646095276, train/logprobs = tensor([[-0.5423, -6.4973],
        [-1.1242, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17272908985614777
Epoch 0, Step 1880: train/loss = 0.5622572898864746, train/raw-loss = 0.45066404342651367, train/logprobs = tensor([[-0.6421, -2.8068],
        [-0.9439, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11159324645996094
Epoch 0, Step 1881: train/loss = 0.49237382411956787, train/raw-loss = 0.3840702772140503, train/logprobs = tensor([[-0.5930, -2.0524],
        [-0.8531, -0.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10830353200435638
Epoch 0, Step 1882: train/loss = 0.44320619106292725, train/raw-loss = 0.28304633498191833, train/logprobs = tensor([[-0.8226, -4.4753],
        [-1.5946, -0.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1601598858833313
Epoch 0, Step 1883: train/loss = 0.5723332762718201, train/raw-loss = 0.4309254288673401, train/logprobs = tensor([[-0.5390, -1.7223],
        [-0.9563, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14140786230564117
Epoch 0, Step 1884: train/loss = 0.5150531530380249, train/raw-loss = 0.3517875075340271, train/logprobs = tensor([[-1.1008, -7.3715],
        [-1.3516, -0.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16326561570167542
Epoch 0, Step 1885: train/loss = 0.4925076961517334, train/raw-loss = 0.3626725673675537, train/logprobs = tensor([[-0.3934, -4.4281],
        [-0.5751, -0.3890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1298351287841797
Epoch 0, Step 1886: train/loss = 0.5200143456459045, train/raw-loss = 0.3687360882759094, train/logprobs = tensor([[-0.4932, -5.0052],
        [-1.3855, -2.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15127824246883392
Epoch 0, Step 1887: train/loss = 0.617591381072998, train/raw-loss = 0.46199801564216614, train/logprobs = tensor([[-0.4392, -0.8212],
        [-1.0533, -0.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1555933952331543
Epoch 0, Step 1888: train/loss = 0.7462103962898254, train/raw-loss = 0.6714699268341064, train/logprobs = tensor([[-0.2459, -0.4206],
        [-0.2536, -0.3289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07474038749933243
Epoch 0, Step 1889: train/loss = 0.4070374667644501, train/raw-loss = 0.28421199321746826, train/logprobs = tensor([[-0.4291, -3.2220],
        [-0.9379, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12282545119524002
Epoch 0, Step 1890: train/loss = 0.5610458254814148, train/raw-loss = 0.4244248569011688, train/logprobs = tensor([[-0.5517, -2.3426],
        [-0.8764, -0.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13662096858024597
Epoch 0, Step 1891: train/loss = 0.6628642082214355, train/raw-loss = 0.5414881706237793, train/logprobs = tensor([[-0.9854, -3.9351],
        [-0.7636, -0.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137604504823685
Epoch 0, Step 1892: train/loss = 0.626023530960083, train/raw-loss = 0.502023458480835, train/logprobs = tensor([[-0.2954, -2.0560],
        [-0.5976, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12400011718273163
Epoch 0, Step 1893: train/loss = 0.5633803009986877, train/raw-loss = 0.46284019947052, train/logprobs = tensor([[-0.6516, -1.7795],
        [-0.9685, -0.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10054009407758713
Epoch 0, Step 1894: train/loss = 0.5890915393829346, train/raw-loss = 0.46352431178092957, train/logprobs = tensor([[-0.1875, -1.5010],
        [-0.5234, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12556719779968262
Epoch 0, Step 1895: train/loss = 0.5486868619918823, train/raw-loss = 0.4788355827331543, train/logprobs = tensor([[-0.2355, -3.8409],
        [-0.4004, -0.5426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06985124945640564
Epoch 0, Step 1896: train/loss = 0.3926440477371216, train/raw-loss = 0.2595958411693573, train/logprobs = tensor([[-0.3717, -7.7173],
        [-1.3554, -1.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1330481916666031
Epoch 0, Step 1897: train/loss = 0.3635522723197937, train/raw-loss = 0.22232256829738617, train/logprobs = tensor([[-0.2141, -6.4129],
        [-0.7862, -2.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14122970402240753
Epoch 0, Step 1898: train/loss = 0.5585160255432129, train/raw-loss = 0.4538338780403137, train/logprobs = tensor([[-0.5646, -4.8503],
        [-0.5073, -0.2785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468217730522156
Epoch 0, Step 1899: train/loss = 0.4284280836582184, train/raw-loss = 0.279171347618103, train/logprobs = tensor([[-0.6101, -3.9981],
        [-1.4578, -0.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14925673604011536
Epoch 0, Step 1900: train/loss = 0.3964294195175171, train/raw-loss = 0.28550952672958374, train/logprobs = tensor([[-0.2927, -2.5565],
        [-1.1418, -0.2850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11091990768909454
Epoch 0, Step 1901: train/loss = 0.5213126540184021, train/raw-loss = 0.3589784502983093, train/logprobs = tensor([[-0.8157, -3.3433],
        [-1.2003, -0.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16233420372009277
Epoch 0, Step 1902: train/loss = 0.566701352596283, train/raw-loss = 0.4519498348236084, train/logprobs = tensor([[-0.3856, -1.6688],
        [-0.8773, -0.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11475153267383575
Epoch 0, Step 1903: train/loss = 0.45040208101272583, train/raw-loss = 0.3446989059448242, train/logprobs = tensor([[-0.4172, -3.2665],
        [-1.0261, -1.2478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10570318251848221
Epoch 0, Step 1904: train/loss = 0.40712225437164307, train/raw-loss = 0.308438241481781, train/logprobs = tensor([[-0.4738, -6.4930],
        [-0.8906, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868402779102325
Epoch 0, Step 1905: train/loss = 0.4124504625797272, train/raw-loss = 0.32581469416618347, train/logprobs = tensor([[-0.3601, -6.1212],
        [-0.8700, -2.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08663573116064072
Epoch 0, Step 1906: train/loss = 0.5497141480445862, train/raw-loss = 0.41216251254081726, train/logprobs = tensor([[-0.7916, -1.8453],
        [-1.0388, -0.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1375516653060913
Epoch 0, Step 1907: train/loss = 0.45960700511932373, train/raw-loss = 0.3513595163822174, train/logprobs = tensor([[-0.2986, -4.3762],
        [-0.6226, -0.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10824750363826752
Epoch 0, Step 1908: train/loss = 0.5898734331130981, train/raw-loss = 0.5010697841644287, train/logprobs = tensor([[-0.4243, -4.2672],
        [-0.4582, -2.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08880370855331421
Epoch 0, Step 1909: train/loss = 0.4907205402851105, train/raw-loss = 0.307450532913208, train/logprobs = tensor([[-0.4279, -4.4230],
        [-1.3650, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327003717422485
Epoch 0, Step 1910: train/loss = 0.45068907737731934, train/raw-loss = 0.3476795554161072, train/logprobs = tensor([[-0.1334, -4.3537],
        [-0.8201, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10300952196121216
Epoch 0, Step 1911: train/loss = 0.4307251274585724, train/raw-loss = 0.2719786763191223, train/logprobs = tensor([[-0.6641, -5.7743],
        [-1.5511, -0.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15874643623828888
Epoch 0, Step 1912: train/loss = 0.5600510239601135, train/raw-loss = 0.4201250672340393, train/logprobs = tensor([[-0.5287, -1.5395],
        [-1.0239, -0.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13992595672607422
Epoch 0, Step 1913: train/loss = 0.44815152883529663, train/raw-loss = 0.2962304651737213, train/logprobs = tensor([[-0.5486, -2.0988],
        [-1.4719, -0.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15192106366157532
Epoch 0, Step 1914: train/loss = 0.3081602454185486, train/raw-loss = 0.17484891414642334, train/logprobs = tensor([[-0.3076, -8.2053],
        [-1.6352, -1.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13331134617328644
Epoch 0, Step 1915: train/loss = 0.3582429587841034, train/raw-loss = 0.22012034058570862, train/logprobs = tensor([[-0.2263, -6.1636],
        [-1.1340, -2.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13812261819839478
Epoch 0, Step 1916: train/loss = 0.6388174295425415, train/raw-loss = 0.4799365997314453, train/logprobs = tensor([[-0.3300, -2.1578],
        [-0.7330, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588808298110962
Epoch 0, Step 1917: train/loss = 0.6973151564598083, train/raw-loss = 0.6112676858901978, train/logprobs = tensor([[-0.3310, -1.3603],
        [-0.6761, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0860474482178688
Epoch 0, Step 1918: train/loss = 0.46516746282577515, train/raw-loss = 0.28064537048339844, train/logprobs = tensor([[-0.2828, -3.7527],
        [-1.2742, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1845221221446991
Epoch 0, Step 1919: train/loss = 0.3363792896270752, train/raw-loss = 0.20172910392284393, train/logprobs = tensor([[-0.5551, -4.7721],
        [-1.3398, -0.2223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13465020060539246
Epoch 0, Step 1920: train/loss = 0.39606520533561707, train/raw-loss = 0.2737773060798645, train/logprobs = tensor([[-0.2460, -3.5817],
        [-1.0796, -0.3279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12228790670633316
Epoch 0, Step 1921: train/loss = 0.4476865828037262, train/raw-loss = 0.29951903223991394, train/logprobs = tensor([[ -0.5085, -10.1820],
        [ -1.2015,  -2.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14816758036613464
Epoch 0, Step 1922: train/loss = 0.3756043314933777, train/raw-loss = 0.18273629248142242, train/logprobs = tensor([[-0.5558, -5.5625],
        [-1.4193, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19286803901195526
Epoch 0, Step 1923: train/loss = 0.4327021837234497, train/raw-loss = 0.31662067770957947, train/logprobs = tensor([[-0.4511, -7.5978],
        [-0.8808, -1.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11608150601387024
Epoch 0, Step 1924: train/loss = 0.4177343547344208, train/raw-loss = 0.27071261405944824, train/logprobs = tensor([[-0.3220, -4.2264],
        [-0.7707, -0.3443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14702174067497253
Epoch 0, Step 1925: train/loss = 0.4737505614757538, train/raw-loss = 0.3610049784183502, train/logprobs = tensor([[-0.3374, -7.5034],
        [-1.0249, -1.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11274558305740356
Epoch 0, Step 1926: train/loss = 0.5386754870414734, train/raw-loss = 0.3923811912536621, train/logprobs = tensor([[-0.5241, -2.8974],
        [-0.9720, -0.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14629428088665009
Epoch 0, Step 1927: train/loss = 0.37705934047698975, train/raw-loss = 0.25210660696029663, train/logprobs = tensor([[-0.4660, -4.2360],
        [-0.7819, -0.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12495274841785431
Epoch 0, Step 1928: train/loss = 0.49739187955856323, train/raw-loss = 0.38407403230667114, train/logprobs = tensor([[-0.2766, -4.0850],
        [-0.9006, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11331786215305328
Epoch 0, Step 1929: train/loss = 0.42304307222366333, train/raw-loss = 0.3153015971183777, train/logprobs = tensor([[-0.1978, -3.5782],
        [-0.8352, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10774146020412445
Epoch 0, Step 1930: train/loss = 0.5913764834403992, train/raw-loss = 0.5052603483200073, train/logprobs = tensor([[-0.2004, -2.3156],
        [-0.3369, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08611612021923065
Epoch 0, Step 1931: train/loss = 0.6531804800033569, train/raw-loss = 0.5548322200775146, train/logprobs = tensor([[-0.3248, -1.3532],
        [-0.7957, -0.4919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0983482301235199
Epoch 0, Step 1932: train/loss = 0.6899712085723877, train/raw-loss = 0.5713794231414795, train/logprobs = tensor([[-0.3901, -2.3826],
        [-1.0826, -0.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11859174072742462
Epoch 0, Step 1933: train/loss = 0.5468403697013855, train/raw-loss = 0.45990484952926636, train/logprobs = tensor([[-0.2347, -1.4717],
        [-0.6257, -0.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693550527095795
Epoch 0, Step 1934: train/loss = 0.5930179953575134, train/raw-loss = 0.5018060207366943, train/logprobs = tensor([[-0.2011, -1.2994],
        [-0.3351, -0.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09121193736791611
Epoch 0, Step 1935: train/loss = 0.371304452419281, train/raw-loss = 0.23913311958312988, train/logprobs = tensor([[-0.6587, -4.2486],
        [-1.2493, -0.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13217134773731232
Epoch 0, Step 1936: train/loss = 0.41054877638816833, train/raw-loss = 0.2789582908153534, train/logprobs = tensor([[-0.3897, -6.5830],
        [-0.7567, -0.5096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13159047067165375
Epoch 0, Step 1937: train/loss = 0.6636660695075989, train/raw-loss = 0.5812996625900269, train/logprobs = tensor([[-0.2908, -0.5932],
        [-0.5493, -0.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08236636221408844
Epoch 0, Step 1938: train/loss = 0.5815126895904541, train/raw-loss = 0.47069570422172546, train/logprobs = tensor([[-0.9273, -3.8244],
        [-0.7742, -0.4090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11081700026988983
Epoch 0, Step 1939: train/loss = 0.5731022953987122, train/raw-loss = 0.47640061378479004, train/logprobs = tensor([[-0.3092, -1.8379],
        [-0.6127, -0.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09670169651508331
Epoch 0, Step 1940: train/loss = 0.521548867225647, train/raw-loss = 0.4325485825538635, train/logprobs = tensor([[-0.2207, -3.6086],
        [-0.8387, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08900028467178345
Epoch 0, Step 1941: train/loss = 0.7078851461410522, train/raw-loss = 0.5851197242736816, train/logprobs = tensor([[-0.4198, -0.7260],
        [-0.7682, -0.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1227654293179512
Epoch 0, Step 1942: train/loss = 0.5306465029716492, train/raw-loss = 0.3498392701148987, train/logprobs = tensor([[-0.6043, -3.8786],
        [-1.4291, -0.2645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1808072030544281
Epoch 0, Step 1943: train/loss = 0.45033174753189087, train/raw-loss = 0.29708051681518555, train/logprobs = tensor([[-0.2971, -4.4349],
        [-0.8183, -0.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15325124561786652
Epoch 0, Step 1944: train/loss = 0.5785627365112305, train/raw-loss = 0.4903434216976166, train/logprobs = tensor([[-0.4368, -1.8136],
        [-0.6436, -0.4208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08821925520896912
Epoch 0, Step 1945: train/loss = 0.5458145141601562, train/raw-loss = 0.45345771312713623, train/logprobs = tensor([[-0.2221, -1.9047],
        [-0.6763, -0.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09235679358243942
Epoch 0, Step 1946: train/loss = 0.6897706985473633, train/raw-loss = 0.524715781211853, train/logprobs = tensor([[-1.0904, -4.3238],
        [-0.6767, -1.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16505485773086548
Epoch 0, Step 1947: train/loss = 0.6858683824539185, train/raw-loss = 0.6026579141616821, train/logprobs = tensor([[-0.3910, -0.7856],
        [-0.4235, -0.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08321047574281693
Epoch 0, Step 1948: train/loss = 0.4643045961856842, train/raw-loss = 0.3515351116657257, train/logprobs = tensor([[-0.1821, -3.8692],
        [-0.4004, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11276943981647491
Epoch 0, Step 1949: train/loss = 0.49287787079811096, train/raw-loss = 0.37912917137145996, train/logprobs = tensor([[-0.2157, -3.4988],
        [-0.4661, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137486919760704
Epoch 0, Step 1950: train/loss = 0.3791866898536682, train/raw-loss = 0.2907501757144928, train/logprobs = tensor([[-0.1215, -4.8557],
        [-0.6740, -2.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884365439414978
Epoch 0, Step 1951: train/loss = 0.46401816606521606, train/raw-loss = 0.2894960939884186, train/logprobs = tensor([[-0.6097, -3.5598],
        [-1.5356, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17452210187911987
Epoch 0, Step 1952: train/loss = 0.4811868667602539, train/raw-loss = 0.3535849452018738, train/logprobs = tensor([[-0.4019, -2.0492],
        [-1.4455, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12760189175605774
Epoch 0, Step 1953: train/loss = 0.40198051929473877, train/raw-loss = 0.30678868293762207, train/logprobs = tensor([[-0.3582, -4.8353],
        [-0.8553, -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519185870885849
Epoch 0, Step 1954: train/loss = 0.36341872811317444, train/raw-loss = 0.24331040680408478, train/logprobs = tensor([[-0.3784, -6.8092],
        [-1.0416, -1.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12010829150676727
Epoch 0, Step 1955: train/loss = 0.45079725980758667, train/raw-loss = 0.30123135447502136, train/logprobs = tensor([[-0.4577, -4.9490],
        [-0.9662, -1.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1495659351348877
Epoch 0, Step 1956: train/loss = 0.5934638381004333, train/raw-loss = 0.43800392746925354, train/logprobs = tensor([[-0.2346, -5.0274],
        [-0.8374, -3.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15545988082885742
Epoch 0, Step 1957: train/loss = 0.5124396681785583, train/raw-loss = 0.35782790184020996, train/logprobs = tensor([[-0.2332, -3.7589],
        [-1.4225, -0.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15461178123950958
Epoch 0, Step 1958: train/loss = 0.3267492353916168, train/raw-loss = 0.17557752132415771, train/logprobs = tensor([[-0.4421, -9.4495],
        [-1.2180, -3.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1511717438697815
Epoch 0, Step 1959: train/loss = 0.40321096777915955, train/raw-loss = 0.2400090992450714, train/logprobs = tensor([[-0.2135, -6.2953],
        [-1.2786, -0.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16320186853408813
Epoch 0, Step 1960: train/loss = 0.41495227813720703, train/raw-loss = 0.282110333442688, train/logprobs = tensor([[-0.3495, -5.2335],
        [-1.2361, -1.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13284191489219666
Epoch 0, Step 1961: train/loss = 0.37025371193885803, train/raw-loss = 0.24733828008174896, train/logprobs = tensor([[-0.5225, -5.2078],
        [-1.0472, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12291541695594788
Epoch 0, Step 1962: train/loss = 0.6922522187232971, train/raw-loss = 0.5844050645828247, train/logprobs = tensor([[-0.2182, -0.7942],
        [-0.5176, -0.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10784711688756943
Epoch 0, Step 1963: train/loss = 0.49780207872390747, train/raw-loss = 0.37081077694892883, train/logprobs = tensor([[-0.4117, -4.7814],
        [-0.7291, -0.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12699134647846222
Epoch 0, Step 1964: train/loss = 0.4536899924278259, train/raw-loss = 0.33299970626831055, train/logprobs = tensor([[-0.1967, -3.6556],
        [-0.7177, -0.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12069030106067657
Epoch 0, Step 1965: train/loss = 0.6446942687034607, train/raw-loss = 0.5620985627174377, train/logprobs = tensor([[-0.2377, -0.7390],
        [-0.5655, -0.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08259565383195877
Epoch 0, Step 1966: train/loss = 0.3282717168331146, train/raw-loss = 0.1861279010772705, train/logprobs = tensor([[ -0.1945, -14.4290],
        [ -0.8224,  -1.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14214381575584412
Epoch 0, Step 1967: train/loss = 0.5655018091201782, train/raw-loss = 0.426848828792572, train/logprobs = tensor([[-0.7376, -4.2812],
        [-0.7340, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386529803276062
Epoch 0, Step 1968: train/loss = 0.6544320583343506, train/raw-loss = 0.5061216354370117, train/logprobs = tensor([[-0.9379, -3.4767],
        [-1.2833, -0.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14831039309501648
Epoch 0, Step 1969: train/loss = 0.3759884834289551, train/raw-loss = 0.2479337900876999, train/logprobs = tensor([[-0.2832, -9.2593],
        [-1.3130, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280546933412552
Epoch 0, Step 1970: train/loss = 0.45167577266693115, train/raw-loss = 0.315211683511734, train/logprobs = tensor([[-0.4162, -6.2806],
        [-0.6631, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13646408915519714
Epoch 0, Step 1971: train/loss = 0.4525347650051117, train/raw-loss = 0.32037118077278137, train/logprobs = tensor([[-0.2669, -3.2434],
        [-0.8613, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13216358423233032
Epoch 0, Step 1972: train/loss = 0.43469730019569397, train/raw-loss = 0.28761985898017883, train/logprobs = tensor([[-0.3270, -3.1861],
        [-1.2450, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14707744121551514
Epoch 0, Step 1973: train/loss = 0.4434380531311035, train/raw-loss = 0.31237268447875977, train/logprobs = tensor([[-0.3336, -3.5009],
        [-1.8690, -0.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13106541335582733
Epoch 0, Step 1974: train/loss = 0.41434234380722046, train/raw-loss = 0.2761746346950531, train/logprobs = tensor([[-0.1436, -4.5123],
        [-1.0486, -0.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13816770911216736
Epoch 0, Step 1975: train/loss = 0.6547576785087585, train/raw-loss = 0.5457298159599304, train/logprobs = tensor([[-0.3430, -1.9828],
        [-0.7716, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902786254882812
Epoch 0, Step 1976: train/loss = 0.4477982521057129, train/raw-loss = 0.318966269493103, train/logprobs = tensor([[-0.4811, -5.2021],
        [-0.9001, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12883201241493225
Epoch 0, Step 1977: train/loss = 0.27129268646240234, train/raw-loss = 0.14723679423332214, train/logprobs = tensor([[ -0.2646, -12.5847],
        [ -1.6869,  -3.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124055877327919
Epoch 0, Step 1978: train/loss = 0.4561501741409302, train/raw-loss = 0.2959187626838684, train/logprobs = tensor([[-0.2498, -4.7307],
        [-0.6891, -0.9984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16023141145706177
Epoch 0, Step 1979: train/loss = 0.5241442322731018, train/raw-loss = 0.3989047408103943, train/logprobs = tensor([[-0.2646, -3.3979],
        [-0.8405, -0.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12523949146270752
Epoch 0, Step 1980: train/loss = 0.44839948415756226, train/raw-loss = 0.31386464834213257, train/logprobs = tensor([[-0.8005, -4.2438],
        [-1.0797, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1345348209142685
Epoch 0, Step 1981: train/loss = 0.4030163884162903, train/raw-loss = 0.2305137813091278, train/logprobs = tensor([[-0.7035, -6.4455],
        [-1.5617, -1.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17250263690948486
Epoch 0, Step 1982: train/loss = 0.546906054019928, train/raw-loss = 0.43128693103790283, train/logprobs = tensor([[-0.3876, -1.4047],
        [-0.8320, -0.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11561913788318634
Epoch 0, Step 1983: train/loss = 0.5934619307518005, train/raw-loss = 0.5111687779426575, train/logprobs = tensor([[-0.1985, -0.9244],
        [-0.7327, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229318261146545
Epoch 0, Step 1984: train/loss = 0.3329077959060669, train/raw-loss = 0.21007132530212402, train/logprobs = tensor([[-0.3830, -5.4965],
        [-1.1218, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12283648550510406
Epoch 0, Step 1985: train/loss = 0.537153422832489, train/raw-loss = 0.4022220969200134, train/logprobs = tensor([[-0.4672, -3.4328],
        [-0.9521, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13493134081363678
Epoch 0, Step 1986: train/loss = 0.6727839708328247, train/raw-loss = 0.5594081878662109, train/logprobs = tensor([[-0.5596, -2.9539],
        [-0.6697, -1.3438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11337581276893616
Epoch 0, Step 1987: train/loss = 0.5351641774177551, train/raw-loss = 0.41640421748161316, train/logprobs = tensor([[-0.5728, -4.1258],
        [-0.9582, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11875998228788376
Epoch 0, Step 1988: train/loss = 0.5732296705245972, train/raw-loss = 0.4943524897098541, train/logprobs = tensor([[-0.1822, -3.1958],
        [-0.4232, -0.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07887718081474304
Epoch 0, Step 1989: train/loss = 0.46527451276779175, train/raw-loss = 0.3748863935470581, train/logprobs = tensor([[-0.2908, -2.5031],
        [-0.5578, -0.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038814902305603
Epoch 0, Step 1990: train/loss = 0.38204964995384216, train/raw-loss = 0.22545821964740753, train/logprobs = tensor([[ -0.3315, -11.8592],
        [ -0.9579,  -2.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15659144520759583
Epoch 0, Step 1991: train/loss = 0.49293822050094604, train/raw-loss = 0.3408912122249603, train/logprobs = tensor([[-0.6745, -5.0248],
        [-1.4292, -1.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1520470380783081
Epoch 0, Step 1992: train/loss = 0.6056201457977295, train/raw-loss = 0.4380400776863098, train/logprobs = tensor([[-0.4430, -3.4184],
        [-0.8682, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16758011281490326
Epoch 0, Step 1993: train/loss = 0.498396098613739, train/raw-loss = 0.3673982322216034, train/logprobs = tensor([[-0.2620, -2.5347],
        [-0.7379, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099788129329681
Epoch 0, Step 1994: train/loss = 0.494377076625824, train/raw-loss = 0.3919644355773926, train/logprobs = tensor([[-0.4656, -2.6641],
        [-1.1190, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10241265594959259
Epoch 0, Step 1995: train/loss = 0.4105842709541321, train/raw-loss = 0.28354328870773315, train/logprobs = tensor([[-0.4501, -3.2040],
        [-1.3293, -0.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12704096734523773
Epoch 0, Step 1996: train/loss = 0.5479403138160706, train/raw-loss = 0.44180065393447876, train/logprobs = tensor([[-1.1652, -1.5981],
        [-1.5723, -0.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1061396449804306
Epoch 0, Step 1997: train/loss = 0.5178036689758301, train/raw-loss = 0.385422945022583, train/logprobs = tensor([[-0.3633, -4.0054],
        [-0.9192, -0.9168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13238072395324707
Epoch 0, Step 1998: train/loss = 0.6036710739135742, train/raw-loss = 0.5224992632865906, train/logprobs = tensor([[-0.2511, -1.2792],
        [-0.6121, -0.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08117177337408066
Epoch 0, Step 1999: train/loss = 0.7149055004119873, train/raw-loss = 0.640356183052063, train/logprobs = tensor([[-0.8815, -1.6212],
        [-0.3281, -0.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0745493695139885
Epoch 0, Step 2000: train/loss = 0.5812326669692993, train/raw-loss = 0.4778326451778412, train/logprobs = tensor([[-0.4305, -2.1542],
        [-0.3873, -0.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10340003669261932
Epoch 0, Step 2001: train/loss = 0.5806452631950378, train/raw-loss = 0.4737400412559509, train/logprobs = tensor([[-0.3163, -1.2853],
        [-0.6138, -0.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10690522938966751
Epoch 0, Step 2002: train/loss = 0.39904630184173584, train/raw-loss = 0.28332507610321045, train/logprobs = tensor([[-0.7381, -5.9017],
        [-1.0371, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1157212182879448
Epoch 0, Step 2003: train/loss = 0.4696381986141205, train/raw-loss = 0.3140299618244171, train/logprobs = tensor([[-0.7754, -3.2925],
        [-1.4238, -0.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15560825169086456
Epoch 0, Step 2004: train/loss = 0.36620602011680603, train/raw-loss = 0.2316616177558899, train/logprobs = tensor([[-0.1467, -8.3539],
        [-0.8153, -1.3645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13454441726207733
Epoch 0, Step 2005: train/loss = 0.32361191511154175, train/raw-loss = 0.17252910137176514, train/logprobs = tensor([[-0.1239, -5.9980],
        [-1.3922, -0.4913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15108278393745422
Epoch 0, Step 2006: train/loss = 0.4361827075481415, train/raw-loss = 0.3313395380973816, train/logprobs = tensor([[-0.2707, -9.7732],
        [-0.6846, -2.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484318435192108
Epoch 0, Step 2007: train/loss = 0.5639634132385254, train/raw-loss = 0.4482654333114624, train/logprobs = tensor([[-0.2240, -1.1654],
        [-0.6218, -0.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569791287183762
Epoch 0, Step 2008: train/loss = 0.49934476613998413, train/raw-loss = 0.412899911403656, train/logprobs = tensor([[-0.3383, -4.3316],
        [-1.1201, -1.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08644481748342514
Epoch 0, Step 2009: train/loss = 0.6508110761642456, train/raw-loss = 0.5164423584938049, train/logprobs = tensor([[-0.6111, -4.3718],
        [-0.5008, -2.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343686729669571
Epoch 0, Step 2010: train/loss = 0.4297710061073303, train/raw-loss = 0.29279422760009766, train/logprobs = tensor([[-0.5175, -5.2290],
        [-1.0774, -0.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13697679340839386
Epoch 0, Step 2011: train/loss = 0.4266253411769867, train/raw-loss = 0.2954256236553192, train/logprobs = tensor([[-0.2350, -2.6869],
        [-0.8575, -0.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13119971752166748
Epoch 0, Step 2012: train/loss = 0.5175679922103882, train/raw-loss = 0.3974725008010864, train/logprobs = tensor([[-0.1968, -2.9469],
        [-0.6628, -0.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12009546905755997
Epoch 0, Step 2013: train/loss = 0.6334186792373657, train/raw-loss = 0.5279423594474792, train/logprobs = tensor([[-0.2065, -0.7251],
        [-0.4780, -0.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10547633469104767
Epoch 0, Step 2014: train/loss = 0.5423662662506104, train/raw-loss = 0.3696097731590271, train/logprobs = tensor([[-1.0621, -4.8113],
        [-2.0124, -1.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17275649309158325
Epoch 0, Step 2015: train/loss = 0.5879720449447632, train/raw-loss = 0.49811458587646484, train/logprobs = tensor([[-0.1655, -1.2488],
        [-0.3610, -0.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08985745906829834
Epoch 0, Step 2016: train/loss = 0.5282853841781616, train/raw-loss = 0.3784751892089844, train/logprobs = tensor([[-0.7713, -3.4058],
        [-1.1140, -0.5035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14981018006801605
Epoch 0, Step 2017: train/loss = 0.39399781823158264, train/raw-loss = 0.2555945813655853, train/logprobs = tensor([[-0.4934, -5.9351],
        [-0.7969, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13840323686599731
Epoch 0, Step 2018: train/loss = 0.3932236135005951, train/raw-loss = 0.250353068113327, train/logprobs = tensor([[-0.3985, -6.5385],
        [-1.2488, -0.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14287054538726807
Epoch 0, Step 2019: train/loss = 0.45250457525253296, train/raw-loss = 0.3382083475589752, train/logprobs = tensor([[-0.2146, -2.9584],
        [-0.5389, -0.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11429625004529953
Epoch 0, Step 2020: train/loss = 0.7714259624481201, train/raw-loss = 0.6766502857208252, train/logprobs = tensor([[-0.6938, -1.1974],
        [-0.2824, -0.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09477566927671432
Epoch 0, Step 2021: train/loss = 0.6078817248344421, train/raw-loss = 0.4888688623905182, train/logprobs = tensor([[-0.2625, -3.9065],
        [-0.4526, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11901283264160156
Epoch 0, Step 2022: train/loss = 0.6176502704620361, train/raw-loss = 0.4757203757762909, train/logprobs = tensor([[-0.8684, -1.8551],
        [-1.4847, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14192986488342285
Epoch 0, Step 2023: train/loss = 0.4395115375518799, train/raw-loss = 0.2901783585548401, train/logprobs = tensor([[-0.6039, -3.4428],
        [-1.6653, -0.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1493331789970398
Epoch 0, Step 2024: train/loss = 0.3380429744720459, train/raw-loss = 0.18728378415107727, train/logprobs = tensor([[-0.2581, -7.0016],
        [-0.9498, -0.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15075920522212982
Epoch 0, Step 2025: train/loss = 0.5177413821220398, train/raw-loss = 0.42384132742881775, train/logprobs = tensor([[-0.3212, -4.0371],
        [-0.9429, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09390003234148026
Epoch 0, Step 2026: train/loss = 0.37535449862480164, train/raw-loss = 0.2500115633010864, train/logprobs = tensor([[-0.1789, -4.6253],
        [-0.7875, -0.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1253429502248764
Epoch 0, Step 2027: train/loss = 0.48657089471817017, train/raw-loss = 0.3506324291229248, train/logprobs = tensor([[-0.1344, -2.4086],
        [-0.3839, -0.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13593846559524536
Epoch 0, Step 2028: train/loss = 0.44067496061325073, train/raw-loss = 0.3372611403465271, train/logprobs = tensor([[-0.1396, -3.6843],
        [-0.8850, -0.6266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10341382771730423
Epoch 0, Step 2029: train/loss = 0.610923707485199, train/raw-loss = 0.5139197111129761, train/logprobs = tensor([[-0.1706, -0.8164],
        [-0.4759, -0.2110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0970039814710617
Epoch 0, Step 2030: train/loss = 0.38984906673431396, train/raw-loss = 0.2740713357925415, train/logprobs = tensor([[-0.1356, -3.9005],
        [-1.0579, -0.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577770859003067
Epoch 0, Step 2031: train/loss = 0.7333637475967407, train/raw-loss = 0.6622847318649292, train/logprobs = tensor([[-0.2091, -0.3248],
        [-0.3822, -0.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107903063297272
Epoch 0, Step 2032: train/loss = 0.45028388500213623, train/raw-loss = 0.3345930576324463, train/logprobs = tensor([[-0.7661, -3.3080],
        [-1.2831, -0.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569084227085114
Epoch 0, Step 2033: train/loss = 0.8077341318130493, train/raw-loss = 0.7050581574440002, train/logprobs = tensor([[-0.7835, -0.8227],
        [-0.3721, -0.1662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10267598181962967
Epoch 0, Step 2034: train/loss = 0.5285311341285706, train/raw-loss = 0.41704192757606506, train/logprobs = tensor([[-0.3453, -2.3020],
        [-0.7897, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114891916513443
Epoch 0, Step 2035: train/loss = 0.555410623550415, train/raw-loss = 0.4624049663543701, train/logprobs = tensor([[-0.7677, -2.5708],
        [-0.8647, -0.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09300564229488373
Epoch 0, Step 2036: train/loss = 0.38204526901245117, train/raw-loss = 0.2190721035003662, train/logprobs = tensor([[-0.2891, -8.3826],
        [-0.8359, -0.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16297316551208496
Epoch 0, Step 2037: train/loss = 0.427237331867218, train/raw-loss = 0.30611956119537354, train/logprobs = tensor([[-0.3270, -5.2838],
        [-0.4463, -0.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12111780792474747
Epoch 0, Step 2038: train/loss = 0.5648484230041504, train/raw-loss = 0.3972993493080139, train/logprobs = tensor([[-0.3074, -3.5958],
        [-0.7299, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16754907369613647
Epoch 0, Step 2039: train/loss = 0.4616583585739136, train/raw-loss = 0.35162585973739624, train/logprobs = tensor([[-0.5949, -2.6720],
        [-1.1607, -0.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003250628709793
Epoch 0, Step 2040: train/loss = 0.5006489157676697, train/raw-loss = 0.3975263833999634, train/logprobs = tensor([[-0.3302, -2.2397],
        [-0.8251, -0.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10312256217002869
Epoch 0, Step 2041: train/loss = 0.3781869411468506, train/raw-loss = 0.24936814606189728, train/logprobs = tensor([[-0.5282, -6.2188],
        [-1.7862, -1.3788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1288188248872757
Epoch 0, Step 2042: train/loss = 0.39414483308792114, train/raw-loss = 0.2611210346221924, train/logprobs = tensor([[-0.3053, -4.9139],
        [-1.0025, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13302381336688995
Epoch 0, Step 2043: train/loss = 0.49903151392936707, train/raw-loss = 0.3964637517929077, train/logprobs = tensor([[-0.3380, -6.7580],
        [-0.9018, -1.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10256773233413696
Epoch 0, Step 2044: train/loss = 0.7391020059585571, train/raw-loss = 0.5549521446228027, train/logprobs = tensor([[-1.4796, -2.5049],
        [-1.5880, -0.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18414989113807678
Epoch 0, Step 2045: train/loss = 0.6216639876365662, train/raw-loss = 0.5538756847381592, train/logprobs = tensor([[-0.2065, -0.6464],
        [-0.4571, -0.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0677882581949234
Epoch 0, Step 2046: train/loss = 0.3437274992465973, train/raw-loss = 0.24289530515670776, train/logprobs = tensor([[-0.0925, -6.3379],
        [-0.3881, -1.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10083216428756714
Epoch 0, Step 2047: train/loss = 0.4775320589542389, train/raw-loss = 0.29797565937042236, train/logprobs = tensor([[-1.4959, -3.6925],
        [-2.2915, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17955639958381653
Epoch 0, Step 2048: train/loss = 0.42545217275619507, train/raw-loss = 0.32640111446380615, train/logprobs = tensor([[-0.2024, -5.4829],
        [-0.5983, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09905104339122772
Epoch 0, Step 2049: train/loss = 0.46098846197128296, train/raw-loss = 0.32120829820632935, train/logprobs = tensor([[-0.6476, -3.2640],
        [-1.0594, -0.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.139780193567276
Epoch 0, Step 2050: train/loss = 0.40123921632766724, train/raw-loss = 0.24534058570861816, train/logprobs = tensor([[-0.2292, -4.0423],
        [-0.7782, -0.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15589861571788788
Epoch 0, Step 2051: train/loss = 0.4459170699119568, train/raw-loss = 0.3270890712738037, train/logprobs = tensor([[-0.1761, -5.9611],
        [-0.5483, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11882804334163666
Epoch 0, Step 2052: train/loss = 0.5493268966674805, train/raw-loss = 0.39185571670532227, train/logprobs = tensor([[-0.4432, -1.7972],
        [-1.4714, -0.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574711948633194
Epoch 0, Step 2053: train/loss = 0.6165134906768799, train/raw-loss = 0.4813916087150574, train/logprobs = tensor([[-0.8525, -2.3308],
        [-0.7742, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351219266653061
Epoch 0, Step 2054: train/loss = 0.612877607345581, train/raw-loss = 0.481155663728714, train/logprobs = tensor([[-0.3593, -1.0865],
        [-0.7144, -0.2752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13172195851802826
Epoch 0, Step 2055: train/loss = 0.49338579177856445, train/raw-loss = 0.3881364166736603, train/logprobs = tensor([[-0.5303, -3.9380],
        [-0.5978, -0.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10524937510490417
Epoch 0, Step 2056: train/loss = 0.553385317325592, train/raw-loss = 0.43363621830940247, train/logprobs = tensor([[-0.5391, -1.3810],
        [-1.1861, -0.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11974908411502838
Epoch 0, Step 2057: train/loss = 0.5528526306152344, train/raw-loss = 0.43464332818984985, train/logprobs = tensor([[-0.2049, -1.2884],
        [-0.8589, -0.3472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11820929497480392
Epoch 0, Step 2058: train/loss = 0.36180901527404785, train/raw-loss = 0.1859661191701889, train/logprobs = tensor([[-0.4605, -6.3813],
        [-1.6173, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17584288120269775
Epoch 0, Step 2059: train/loss = 0.4525919556617737, train/raw-loss = 0.3035144805908203, train/logprobs = tensor([[-0.4083, -6.6872],
        [-1.1743, -1.2191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14907750487327576
Epoch 0, Step 2060: train/loss = 0.4943809509277344, train/raw-loss = 0.3765229880809784, train/logprobs = tensor([[-0.4289, -2.0159],
        [-0.8690, -0.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785794794559479
Epoch 0, Step 2061: train/loss = 0.515026330947876, train/raw-loss = 0.39846545457839966, train/logprobs = tensor([[-0.3184, -3.9470],
        [-1.0396, -0.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11656089127063751
Epoch 0, Step 2062: train/loss = 0.4754214882850647, train/raw-loss = 0.3105319142341614, train/logprobs = tensor([[-0.4057, -2.4866],
        [-1.2245, -0.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16488955914974213
Epoch 0, Step 2063: train/loss = 0.46081405878067017, train/raw-loss = 0.3447040319442749, train/logprobs = tensor([[-0.2494, -1.8366],
        [-1.0776, -0.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11610999703407288
Epoch 0, Step 2064: train/loss = 0.668597936630249, train/raw-loss = 0.51515793800354, train/logprobs = tensor([[-0.8700, -1.8023],
        [-0.9772, -0.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15343999862670898
Epoch 0, Step 2065: train/loss = 0.36561211943626404, train/raw-loss = 0.25202685594558716, train/logprobs = tensor([[-0.3206, -8.1186],
        [-0.8817, -1.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11358527839183807
Epoch 0, Step 2066: train/loss = 0.49638283252716064, train/raw-loss = 0.3848220109939575, train/logprobs = tensor([[-0.2586, -2.3757],
        [-0.8515, -0.4988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11156082898378372
Epoch 0, Step 2067: train/loss = 0.5622983574867249, train/raw-loss = 0.4617282450199127, train/logprobs = tensor([[-0.3858, -3.2989],
        [-0.5952, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10057010501623154
Epoch 0, Step 2068: train/loss = 0.5391267538070679, train/raw-loss = 0.4381999373435974, train/logprobs = tensor([[-0.1620, -1.8694],
        [-0.8394, -0.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10092685371637344
Epoch 0, Step 2069: train/loss = 0.5774363279342651, train/raw-loss = 0.4649195075035095, train/logprobs = tensor([[-0.2166, -2.8089],
        [-0.6167, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11251682043075562
Epoch 0, Step 2070: train/loss = 0.2984643578529358, train/raw-loss = 0.14886008203029633, train/logprobs = tensor([[-0.8848, -8.2560],
        [-1.9865, -1.5542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14960427582263947
Epoch 0, Step 2071: train/loss = 0.557163417339325, train/raw-loss = 0.44022291898727417, train/logprobs = tensor([[-0.3258, -1.8104],
        [-0.6746, -0.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694049835205078
Epoch 0, Step 2072: train/loss = 0.4359472095966339, train/raw-loss = 0.27816852927207947, train/logprobs = tensor([[-0.1478, -3.9389],
        [-0.9336, -0.0597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15777871012687683
Epoch 0, Step 2073: train/loss = 0.4672943949699402, train/raw-loss = 0.32130861282348633, train/logprobs = tensor([[-0.3299, -2.3271],
        [-1.1409, -0.5155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14598579704761505
Epoch 0, Step 2074: train/loss = 0.5921992063522339, train/raw-loss = 0.48682916164398193, train/logprobs = tensor([[-0.3622, -1.2517],
        [-0.8063, -0.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10537002980709076
Epoch 0, Step 2075: train/loss = 0.5939140915870667, train/raw-loss = 0.46279817819595337, train/logprobs = tensor([[-0.2812, -1.6898],
        [-0.7951, -0.5550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311158984899521
Epoch 0, Step 2076: train/loss = 0.39787304401397705, train/raw-loss = 0.2596551775932312, train/logprobs = tensor([[-0.6526, -6.6519],
        [-1.3237, -1.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13821786642074585
Epoch 0, Step 2077: train/loss = 0.43049904704093933, train/raw-loss = 0.303394079208374, train/logprobs = tensor([[-0.3106, -5.7376],
        [-0.7077, -0.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271049678325653
Epoch 0, Step 2078: train/loss = 0.41615474224090576, train/raw-loss = 0.3037552237510681, train/logprobs = tensor([[-0.2798, -2.6629],
        [-1.2298, -0.4608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11239948868751526
Epoch 0, Step 2079: train/loss = 0.5140936970710754, train/raw-loss = 0.3838787376880646, train/logprobs = tensor([[-0.2500, -2.9294],
        [-0.6993, -0.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13021495938301086
Epoch 0, Step 2080: train/loss = 0.38832664489746094, train/raw-loss = 0.2458377480506897, train/logprobs = tensor([[-0.4962, -3.5813],
        [-1.3086, -0.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14248886704444885
Epoch 0, Step 2081: train/loss = 0.45049646496772766, train/raw-loss = 0.2972659766674042, train/logprobs = tensor([[-0.5292, -2.3909],
        [-1.8114, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15323051810264587
Epoch 0, Step 2082: train/loss = 0.4270913004875183, train/raw-loss = 0.26032620668411255, train/logprobs = tensor([[-0.5638, -8.3240],
        [-1.2937, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16676509380340576
Epoch 0, Step 2083: train/loss = 0.5701799392700195, train/raw-loss = 0.4562123417854309, train/logprobs = tensor([[-0.4213, -1.1708],
        [-1.1865, -0.4211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11396755278110504
Epoch 0, Step 2084: train/loss = 0.375112384557724, train/raw-loss = 0.22073344886302948, train/logprobs = tensor([[-0.4754, -6.6773],
        [-1.4979, -0.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543789505958557
Epoch 0, Step 2085: train/loss = 0.529658854007721, train/raw-loss = 0.4616791307926178, train/logprobs = tensor([[-1.1219, -3.3362],
        [-1.2029, -0.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06797972321510315
Epoch 0, Step 2086: train/loss = 0.5306762456893921, train/raw-loss = 0.434333473443985, train/logprobs = tensor([[-0.1344, -1.7951],
        [-0.3489, -0.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09634274989366531
Epoch 0, Step 2087: train/loss = 0.3214694857597351, train/raw-loss = 0.14613720774650574, train/logprobs = tensor([[ -0.5124, -12.0587],
        [ -1.4831,  -2.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17533227801322937
Epoch 0, Step 2088: train/loss = 0.5434636473655701, train/raw-loss = 0.4346357583999634, train/logprobs = tensor([[-0.2795, -8.0189],
        [-1.1186, -2.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882792621850967
Epoch 0, Step 2089: train/loss = 0.6422586441040039, train/raw-loss = 0.5359476804733276, train/logprobs = tensor([[-0.7700, -2.1318],
        [-0.4992, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10631100088357925
Epoch 0, Step 2090: train/loss = 0.7353965044021606, train/raw-loss = 0.6294575333595276, train/logprobs = tensor([[-0.8727, -1.6793],
        [-0.4351, -0.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593895614147186
Epoch 0, Step 2091: train/loss = 0.5074495673179626, train/raw-loss = 0.4070765972137451, train/logprobs = tensor([[-0.2428, -2.6509],
        [-0.7391, -0.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10037298500537872
Epoch 0, Step 2092: train/loss = 0.3358440399169922, train/raw-loss = 0.17564159631729126, train/logprobs = tensor([[-0.3603, -6.0379],
        [-1.2412, -0.1554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16020245850086212
Epoch 0, Step 2093: train/loss = 0.5945547819137573, train/raw-loss = 0.4830726981163025, train/logprobs = tensor([[-0.8553, -4.4453],
        [-0.6427, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148212850093842
Epoch 0, Step 2094: train/loss = 0.424102783203125, train/raw-loss = 0.2904318869113922, train/logprobs = tensor([[-0.2012, -5.2704],
        [-1.0945, -1.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336708664894104
Epoch 0, Step 2095: train/loss = 0.5650736093521118, train/raw-loss = 0.4413531720638275, train/logprobs = tensor([[-0.5050, -2.7293],
        [-1.4266, -0.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1237204372882843
Epoch 0, Step 2096: train/loss = 0.5575330257415771, train/raw-loss = 0.4376712739467621, train/logprobs = tensor([[-0.5065, -7.0750],
        [-0.9109, -2.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986178159713745
Epoch 0, Step 2097: train/loss = 0.5770451426506042, train/raw-loss = 0.45269712805747986, train/logprobs = tensor([[-0.3179, -6.2182],
        [-0.5567, -1.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1243479996919632
Epoch 0, Step 2098: train/loss = 0.3456764817237854, train/raw-loss = 0.1878964900970459, train/logprobs = tensor([[-0.6504, -6.7343],
        [-1.2682, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1577799916267395
Epoch 0, Step 2099: train/loss = 0.4351133108139038, train/raw-loss = 0.32029038667678833, train/logprobs = tensor([[-0.3946, -3.6207],
        [-0.6874, -0.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11482291668653488
Epoch 0, Step 2100: train/loss = 0.6001695394515991, train/raw-loss = 0.471929132938385, train/logprobs = tensor([[-0.4627, -1.1445],
        [-0.9379, -0.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282404214143753
Epoch 0, Step 2101: train/loss = 0.6609813570976257, train/raw-loss = 0.5487968325614929, train/logprobs = tensor([[-0.2622, -2.1775],
        [-0.8184, -1.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11218450963497162
Epoch 0, Step 2102: train/loss = 0.4257356524467468, train/raw-loss = 0.3199848234653473, train/logprobs = tensor([[-0.4357, -5.1822],
        [-0.6295, -0.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10575080662965775
Epoch 0, Step 2103: train/loss = 0.45498889684677124, train/raw-loss = 0.33010202646255493, train/logprobs = tensor([[-0.3669, -3.4351],
        [-0.7869, -0.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248868852853775
Epoch 0, Step 2104: train/loss = 0.5594771504402161, train/raw-loss = 0.4577406942844391, train/logprobs = tensor([[-0.1703, -1.1482],
        [-0.7273, -0.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10173645615577698
Epoch 0, Step 2105: train/loss = 0.5407077670097351, train/raw-loss = 0.4187721610069275, train/logprobs = tensor([[-0.2669, -2.6518],
        [-0.9919, -1.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12193556129932404
Epoch 0, Step 2106: train/loss = 0.6317933797836304, train/raw-loss = 0.5475454330444336, train/logprobs = tensor([[-0.1889, -1.0300],
        [-0.4493, -0.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08424792438745499
Epoch 0, Step 2107: train/loss = 0.5771094560623169, train/raw-loss = 0.4753131866455078, train/logprobs = tensor([[-0.7684, -2.2724],
        [-1.0284, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10179629921913147
Epoch 0, Step 2108: train/loss = 0.3789801299571991, train/raw-loss = 0.26680585741996765, train/logprobs = tensor([[-0.1898, -7.2834],
        [-0.7839, -0.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11217425763607025
Epoch 0, Step 2109: train/loss = 0.4855997562408447, train/raw-loss = 0.381664514541626, train/logprobs = tensor([[ -0.1811, -10.3503],
        [ -0.8320,  -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10393521934747696
Epoch 0, Step 2110: train/loss = 0.6092584133148193, train/raw-loss = 0.48951977491378784, train/logprobs = tensor([[-1.5718, -4.7687],
        [-1.3790, -2.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11973866820335388
Epoch 0, Step 2111: train/loss = 0.5012468695640564, train/raw-loss = 0.36055684089660645, train/logprobs = tensor([[-0.3604, -3.2760],
        [-0.9897, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14068999886512756
Epoch 0, Step 2112: train/loss = 0.5058063268661499, train/raw-loss = 0.3543597161769867, train/logprobs = tensor([[-0.3103, -2.8702],
        [-1.0730, -0.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514466255903244
Epoch 0, Step 2113: train/loss = 0.49997788667678833, train/raw-loss = 0.34457647800445557, train/logprobs = tensor([[-0.3829, -7.7394],
        [-1.3234, -1.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15540140867233276
Epoch 0, Step 2114: train/loss = 0.3867805302143097, train/raw-loss = 0.2514808177947998, train/logprobs = tensor([[-0.3546, -6.0541],
        [-0.9443, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13529974222183228
Epoch 0, Step 2115: train/loss = 0.27881255745887756, train/raw-loss = 0.14918503165245056, train/logprobs = tensor([[-0.2456, -6.3903],
        [-1.4504, -0.9987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1296275407075882
Epoch 0, Step 2116: train/loss = 0.3663073480129242, train/raw-loss = 0.22094282507896423, train/logprobs = tensor([[-0.7850, -5.8509],
        [-1.9577, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14536452293395996
Epoch 0, Step 2117: train/loss = 0.6128106117248535, train/raw-loss = 0.5158379077911377, train/logprobs = tensor([[-0.1346, -4.2528],
        [-0.5528, -0.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09697271138429642
Epoch 0, Step 2118: train/loss = 0.4710105061531067, train/raw-loss = 0.34217798709869385, train/logprobs = tensor([[-0.3363, -6.6157],
        [-0.8177, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12883248925209045
Epoch 0, Step 2119: train/loss = 0.42547348141670227, train/raw-loss = 0.2910587191581726, train/logprobs = tensor([[-0.3702, -2.5369],
        [-1.1386, -0.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13441473245620728
Epoch 0, Step 2120: train/loss = 0.9647022485733032, train/raw-loss = 0.8554556965827942, train/logprobs = tensor([[-2.1328, -1.4111],
        [-1.0494, -0.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10924656689167023
Epoch 0, Step 2121: train/loss = 0.6196298003196716, train/raw-loss = 0.5078153610229492, train/logprobs = tensor([[-0.7075, -1.9799],
        [-0.8097, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1118144541978836
Epoch 0, Step 2122: train/loss = 0.37306827306747437, train/raw-loss = 0.25908124446868896, train/logprobs = tensor([[-0.1426, -2.5765],
        [-1.6769, -0.3078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11398700624704361
Epoch 0, Step 2123: train/loss = 0.5006080865859985, train/raw-loss = 0.3873816132545471, train/logprobs = tensor([[-0.8581, -3.5919],
        [-1.0054, -0.3155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322647333145142
Epoch 0, Step 2124: train/loss = 0.4294443428516388, train/raw-loss = 0.27580028772354126, train/logprobs = tensor([[-0.4640, -3.9798],
        [-1.0374, -0.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15364408493041992
Epoch 0, Step 2125: train/loss = 0.43546175956726074, train/raw-loss = 0.3161658048629761, train/logprobs = tensor([[-0.5592, -2.3125],
        [-1.0512, -0.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11929593980312347
Epoch 0, Step 2126: train/loss = 0.5211809873580933, train/raw-loss = 0.38861170411109924, train/logprobs = tensor([[-0.2859, -1.8001],
        [-1.1335, -0.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13256928324699402
Epoch 0, Step 2127: train/loss = 0.5187512636184692, train/raw-loss = 0.32148662209510803, train/logprobs = tensor([[-1.2917, -6.8695],
        [-1.5003, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1972646713256836
Epoch 0, Step 2128: train/loss = 0.4589056074619293, train/raw-loss = 0.34655487537384033, train/logprobs = tensor([[-0.8113, -5.8456],
        [-1.2282, -0.2820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235073953866959
Epoch 0, Step 2129: train/loss = 0.5148050785064697, train/raw-loss = 0.4086143374443054, train/logprobs = tensor([[-0.2309, -4.2306],
        [-0.5766, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10619072616100311
Epoch 0, Step 2130: train/loss = 0.46110373735427856, train/raw-loss = 0.35485178232192993, train/logprobs = tensor([[-0.3594, -2.2134],
        [-1.1745, -0.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10625198483467102
Epoch 0, Step 2131: train/loss = 0.4821750819683075, train/raw-loss = 0.3698888421058655, train/logprobs = tensor([[-0.2175, -2.2628],
        [-0.5346, -0.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11228625476360321
Epoch 0, Step 2132: train/loss = 0.5013077855110168, train/raw-loss = 0.3422914743423462, train/logprobs = tensor([[-0.4611, -4.3176],
        [-1.0818, -0.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15901634097099304
Epoch 0, Step 2133: train/loss = 0.46845197677612305, train/raw-loss = 0.34558966755867004, train/logprobs = tensor([[-0.4084, -3.9555],
        [-0.7981, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12286226451396942
Epoch 0, Step 2134: train/loss = 0.519503653049469, train/raw-loss = 0.35819461941719055, train/logprobs = tensor([[-0.7995, -4.9168],
        [-1.2320, -0.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16130906343460083
Epoch 0, Step 2135: train/loss = 0.5222744345664978, train/raw-loss = 0.3965166211128235, train/logprobs = tensor([[-0.4361, -4.9348],
        [-1.0312, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1257578283548355
Epoch 0, Step 2136: train/loss = 0.49998268485069275, train/raw-loss = 0.3094075322151184, train/logprobs = tensor([[-0.4265, -4.7363],
        [-0.9155, -1.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19057518243789673
Epoch 0, Step 2137: train/loss = 0.4530022144317627, train/raw-loss = 0.3029857873916626, train/logprobs = tensor([[-0.3182, -2.8583],
        [-1.2314, -0.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1500164419412613
Epoch 0, Step 2138: train/loss = 0.2990291118621826, train/raw-loss = 0.15661856532096863, train/logprobs = tensor([[-0.6350, -5.3373],
        [-2.2209, -1.3484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424105316400528
Epoch 0, Step 2139: train/loss = 0.4230848550796509, train/raw-loss = 0.29995542764663696, train/logprobs = tensor([[-0.1910, -5.3635],
        [-1.0056, -1.2014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12312944233417511
Epoch 0, Step 2140: train/loss = 0.44872528314590454, train/raw-loss = 0.34137195348739624, train/logprobs = tensor([[-0.5039, -4.2971],
        [-1.1309, -1.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073533371090889
Epoch 0, Step 2141: train/loss = 0.5399149656295776, train/raw-loss = 0.4188460409641266, train/logprobs = tensor([[-0.2199, -2.4422],
        [-0.4583, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12106893956661224
Epoch 0, Step 2142: train/loss = 0.3503253161907196, train/raw-loss = 0.21123269200325012, train/logprobs = tensor([[-0.5350, -4.3920],
        [-1.7261, -0.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13909262418746948
Epoch 0, Step 2143: train/loss = 0.5435095429420471, train/raw-loss = 0.42201268672943115, train/logprobs = tensor([[-0.2962, -2.5168],
        [-0.6159, -0.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12149688601493835
Epoch 0, Step 2144: train/loss = 0.5324084758758545, train/raw-loss = 0.41151314973831177, train/logprobs = tensor([[-0.3679, -2.1439],
        [-0.6316, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12089533358812332
Epoch 0, Step 2145: train/loss = 0.607537567615509, train/raw-loss = 0.5129278302192688, train/logprobs = tensor([[-0.1658, -0.8484],
        [-0.4401, -0.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09460976719856262
Epoch 0, Step 2146: train/loss = 0.4877900779247284, train/raw-loss = 0.3772953748703003, train/logprobs = tensor([[-0.4494, -1.2014],
        [-1.0979, -0.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1104947179555893
Epoch 0, Step 2147: train/loss = 0.3342583477497101, train/raw-loss = 0.20124249160289764, train/logprobs = tensor([[-0.8499, -4.1500],
        [-1.9607, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13301585614681244
Epoch 0, Step 2148: train/loss = 0.2931399941444397, train/raw-loss = 0.14454033970832825, train/logprobs = tensor([[-4.0878e-01, -4.1547e+00],
        [-1.7126e+00, -2.8276e-03]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14859966933727264
Epoch 0, Step 2149: train/loss = 0.5167348980903625, train/raw-loss = 0.3982505202293396, train/logprobs = tensor([[-0.1901, -3.9754],
        [-0.7666, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11848438531160355
Epoch 0, Step 2150: train/loss = 0.6121687889099121, train/raw-loss = 0.4745265245437622, train/logprobs = tensor([[-1.4463, -3.5187],
        [-1.1498, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376422643661499
Epoch 0, Step 2151: train/loss = 0.5723670721054077, train/raw-loss = 0.5029850006103516, train/logprobs = tensor([[-0.2966, -7.1539],
        [-0.4568, -3.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06938209384679794
Epoch 0, Step 2152: train/loss = 0.5337672233581543, train/raw-loss = 0.44193458557128906, train/logprobs = tensor([[-0.2421, -1.5690],
        [-0.4986, -0.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09183259308338165
Epoch 0, Step 2153: train/loss = 0.49912911653518677, train/raw-loss = 0.3553133010864258, train/logprobs = tensor([[-0.5889, -2.9366],
        [-1.4162, -0.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14381584525108337
Epoch 0, Step 2154: train/loss = 0.4939284026622772, train/raw-loss = 0.3587600588798523, train/logprobs = tensor([[-0.7178, -2.5724],
        [-1.2705, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13516835868358612
Epoch 0, Step 2155: train/loss = 0.35538750886917114, train/raw-loss = 0.21875818073749542, train/logprobs = tensor([[ -0.3126, -10.4360],
        [ -1.1075,  -2.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13662932813167572
Epoch 0, Step 2156: train/loss = 0.551034688949585, train/raw-loss = 0.4593677520751953, train/logprobs = tensor([[-0.2323, -4.0380],
        [-0.7301, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166692942380905
Epoch 0, Step 2157: train/loss = 0.36776667833328247, train/raw-loss = 0.20250549912452698, train/logprobs = tensor([[-0.7722, -5.9100],
        [-1.5683, -1.0727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1652611494064331
Epoch 0, Step 2158: train/loss = 0.596454381942749, train/raw-loss = 0.4599485695362091, train/logprobs = tensor([[-0.6366, -6.9371],
        [-1.2626, -2.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365058422088623
Epoch 0, Step 2159: train/loss = 0.7656832933425903, train/raw-loss = 0.5727561712265015, train/logprobs = tensor([[-1.6104, -6.4557],
        [-1.6529, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19292715191841125
Epoch 0, Step 2160: train/loss = 0.45865169167518616, train/raw-loss = 0.3259669542312622, train/logprobs = tensor([[-0.3325, -3.5935],
        [-0.9121, -0.2887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13268476724624634
Epoch 0, Step 2161: train/loss = 0.3769831657409668, train/raw-loss = 0.24243170022964478, train/logprobs = tensor([[-0.9770, -5.1259],
        [-1.2922, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13455148041248322
Epoch 0, Step 2162: train/loss = 0.5300160050392151, train/raw-loss = 0.37739014625549316, train/logprobs = tensor([[-0.3851, -2.3692],
        [-1.0692, -0.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526258885860443
Epoch 0, Step 2163: train/loss = 0.5709130764007568, train/raw-loss = 0.42904818058013916, train/logprobs = tensor([[-0.5450, -2.4977],
        [-0.8512, -0.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418648660182953
Epoch 0, Step 2164: train/loss = 0.32196396589279175, train/raw-loss = 0.21155278384685516, train/logprobs = tensor([[ -0.1732, -10.2688],
        [ -1.5777,  -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11041118204593658
Epoch 0, Step 2165: train/loss = 0.595708429813385, train/raw-loss = 0.4837774634361267, train/logprobs = tensor([[-0.2984, -1.3653],
        [-0.5912, -0.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11193094402551651
Epoch 0, Step 2166: train/loss = 0.5409023761749268, train/raw-loss = 0.44052648544311523, train/logprobs = tensor([[-0.4157, -5.6472],
        [-0.7376, -1.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10037586092948914
Epoch 0, Step 2167: train/loss = 0.6374013423919678, train/raw-loss = 0.548046886920929, train/logprobs = tensor([[-0.3562, -0.3818],
        [-0.8087, -0.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08935439586639404
Epoch 0, Step 2168: train/loss = 0.45483845472335815, train/raw-loss = 0.32196104526519775, train/logprobs = tensor([[-0.4803, -4.6960],
        [-0.7027, -0.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132877379655838
Epoch 0, Step 2169: train/loss = 0.5966876149177551, train/raw-loss = 0.490988552570343, train/logprobs = tensor([[-0.4113, -1.8003],
        [-1.3838, -0.5488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569901019334793
Epoch 0, Step 2170: train/loss = 0.4217352867126465, train/raw-loss = 0.26433080434799194, train/logprobs = tensor([[-0.9878, -6.6285],
        [-1.8345, -1.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15740446746349335
Epoch 0, Step 2171: train/loss = 0.6382290124893188, train/raw-loss = 0.5449303388595581, train/logprobs = tensor([[-0.3786, -1.4026],
        [-0.3489, -0.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09329863637685776
Epoch 0, Step 2172: train/loss = 0.6489481925964355, train/raw-loss = 0.570281982421875, train/logprobs = tensor([[-0.1578, -1.8517],
        [-0.2434, -0.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07866615802049637
Epoch 0, Step 2173: train/loss = 0.5679157376289368, train/raw-loss = 0.45669227838516235, train/logprobs = tensor([[-0.5191, -2.0812],
        [-0.8420, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11122345924377441
Epoch 0, Step 2174: train/loss = 0.550250768661499, train/raw-loss = 0.4493175446987152, train/logprobs = tensor([[-0.2874, -2.1362],
        [-0.5581, -0.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10093317180871964
Epoch 0, Step 2175: train/loss = 0.43172213435173035, train/raw-loss = 0.2903653383255005, train/logprobs = tensor([[-0.4484, -4.2527],
        [-1.0998, -0.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14135684072971344
Epoch 0, Step 2176: train/loss = 0.5600161552429199, train/raw-loss = 0.4309559166431427, train/logprobs = tensor([[-1.5393, -6.9513],
        [-1.2245, -0.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12906023859977722
Epoch 0, Step 2177: train/loss = 0.5331953167915344, train/raw-loss = 0.41040462255477905, train/logprobs = tensor([[-0.5461, -4.6656],
        [-0.6257, -0.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12279070913791656
Epoch 0, Step 2178: train/loss = 0.425742506980896, train/raw-loss = 0.2916226387023926, train/logprobs = tensor([[-0.4438, -8.0006],
        [-0.5620, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341198831796646
Epoch 0, Step 2179: train/loss = 0.5706377029418945, train/raw-loss = 0.47689640522003174, train/logprobs = tensor([[-0.3328, -0.9154],
        [-0.7064, -0.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0937412902712822
Epoch 0, Step 2180: train/loss = 0.49789750576019287, train/raw-loss = 0.40786629915237427, train/logprobs = tensor([[-0.1738, -3.5983],
        [-0.4597, -0.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09003117680549622
Epoch 0, Step 2181: train/loss = 0.35861682891845703, train/raw-loss = 0.197098046541214, train/logprobs = tensor([[-0.3184, -4.0513],
        [-1.5378, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16151876747608185
Epoch 0, Step 2182: train/loss = 0.5956186056137085, train/raw-loss = 0.5098906755447388, train/logprobs = tensor([[-0.2088, -1.2166],
        [-0.6570, -0.3102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08572794497013092
Epoch 0, Step 2183: train/loss = 0.34237343072891235, train/raw-loss = 0.19388380646705627, train/logprobs = tensor([[-0.2938, -4.1217],
        [-1.3210, -0.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484895646572113
Epoch 0, Step 2184: train/loss = 0.7371721863746643, train/raw-loss = 0.608526349067688, train/logprobs = tensor([[-0.4154, -0.5107],
        [-1.3835, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864579260349274
Epoch 0, Step 2185: train/loss = 0.5157384276390076, train/raw-loss = 0.36318784952163696, train/logprobs = tensor([[-0.5763, -2.8510],
        [-1.0746, -0.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152550607919693
Epoch 0, Step 2186: train/loss = 0.41304507851600647, train/raw-loss = 0.28068041801452637, train/logprobs = tensor([[-0.2380, -5.8455],
        [-0.9191, -1.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323646456003189
Epoch 0, Step 2187: train/loss = 0.5640677213668823, train/raw-loss = 0.41903796792030334, train/logprobs = tensor([[-0.5071, -1.5320],
        [-1.6280, -0.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14502975344657898
Epoch 0, Step 2188: train/loss = 0.39881670475006104, train/raw-loss = 0.2463759183883667, train/logprobs = tensor([[-0.3656, -3.5925],
        [-1.3788, -0.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15244083106517792
Epoch 0, Step 2189: train/loss = 0.6042797565460205, train/raw-loss = 0.5258625149726868, train/logprobs = tensor([[-0.2440, -1.2059],
        [-0.4546, -0.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07841722667217255
Epoch 0, Step 2190: train/loss = 0.2738254964351654, train/raw-loss = 0.15592366456985474, train/logprobs = tensor([[ -0.4361, -10.2154],
        [ -1.4351,  -4.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11790185421705246
Epoch 0, Step 2191: train/loss = 0.5838343501091003, train/raw-loss = 0.48976966738700867, train/logprobs = tensor([[-0.2911, -1.4602],
        [-0.6102, -0.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09406466782093048
Epoch 0, Step 2192: train/loss = 0.3848148584365845, train/raw-loss = 0.19417597353458405, train/logprobs = tensor([[-0.9271, -3.4332],
        [-1.8373, -0.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19063887000083923
Epoch 0, Step 2193: train/loss = 0.5110956430435181, train/raw-loss = 0.3963233232498169, train/logprobs = tensor([[-0.1616, -2.9094],
        [-0.7370, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11477233469486237
Epoch 0, Step 2194: train/loss = 0.49547114968299866, train/raw-loss = 0.39431220293045044, train/logprobs = tensor([[-0.5172, -5.1783],
        [-0.8210, -1.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115890204906464
Epoch 0, Step 2195: train/loss = 0.34260427951812744, train/raw-loss = 0.21888983249664307, train/logprobs = tensor([[-0.1098, -7.1589],
        [-0.9340, -2.5265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12371443212032318
Epoch 0, Step 2196: train/loss = 0.6316419243812561, train/raw-loss = 0.566342830657959, train/logprobs = tensor([[-0.1474, -0.6196],
        [-0.3979, -0.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06529904901981354
Epoch 0, Step 2197: train/loss = 0.40500012040138245, train/raw-loss = 0.2381540834903717, train/logprobs = tensor([[-0.4188, -5.7054],
        [-0.8388, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16684600710868835
Epoch 0, Step 2198: train/loss = 0.6177752017974854, train/raw-loss = 0.4677124619483948, train/logprobs = tensor([[-1.5248, -7.4865],
        [-0.9731, -1.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15006278455257416
Epoch 0, Step 2199: train/loss = 0.6386155486106873, train/raw-loss = 0.5646679401397705, train/logprobs = tensor([[-0.3248, -0.9594],
        [-0.3948, -0.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07394760847091675
Epoch 0, Step 2200: train/loss = 0.5258846282958984, train/raw-loss = 0.42449912428855896, train/logprobs = tensor([[-0.2036, -2.4663],
        [-0.7158, -0.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138548910617828
Epoch 0, Step 2201: train/loss = 0.6579862833023071, train/raw-loss = 0.5889780521392822, train/logprobs = tensor([[-0.2848, -0.7681],
        [-0.5194, -0.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06900830566883087
Epoch 0, Step 2202: train/loss = 0.6862443685531616, train/raw-loss = 0.587241530418396, train/logprobs = tensor([[-0.7144, -0.8703],
        [-0.7635, -0.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09900283068418503
Epoch 0, Step 2203: train/loss = 0.4404057264328003, train/raw-loss = 0.26149407029151917, train/logprobs = tensor([[-0.3845, -4.2301],
        [-1.2781, -0.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17891162633895874
Epoch 0, Step 2204: train/loss = 0.4474349021911621, train/raw-loss = 0.33966267108917236, train/logprobs = tensor([[-0.3456, -2.6601],
        [-0.9604, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10777218639850616
Epoch 0, Step 2205: train/loss = 0.44927915930747986, train/raw-loss = 0.304176390171051, train/logprobs = tensor([[-0.2183, -6.3008],
        [-1.3210, -0.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14510275423526764
Epoch 0, Step 2206: train/loss = 0.6490089297294617, train/raw-loss = 0.5628443360328674, train/logprobs = tensor([[-0.6890, -2.1897],
        [-0.7634, -1.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08616463094949722
Epoch 0, Step 2207: train/loss = 0.3145771026611328, train/raw-loss = 0.1986931711435318, train/logprobs = tensor([[-0.2462, -2.8659],
        [-1.2404, -0.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11588393151760101
Epoch 0, Step 2208: train/loss = 0.5684154033660889, train/raw-loss = 0.4526898264884949, train/logprobs = tensor([[-0.4035, -2.6067],
        [-0.7935, -0.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.115725576877594
Epoch 0, Step 2209: train/loss = 0.3957604169845581, train/raw-loss = 0.24813389778137207, train/logprobs = tensor([[-0.8407, -5.6961],
        [-1.3928, -0.7281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14762653410434723
Epoch 0, Step 2210: train/loss = 0.4891205430030823, train/raw-loss = 0.32645028829574585, train/logprobs = tensor([[-0.7844, -3.5494],
        [-1.6457, -1.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16267025470733643
Epoch 0, Step 2211: train/loss = 0.5953043699264526, train/raw-loss = 0.42638224363327026, train/logprobs = tensor([[-0.3877, -4.9564],
        [-1.5330, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16892214119434357
Epoch 0, Step 2212: train/loss = 0.49397462606430054, train/raw-loss = 0.30643776059150696, train/logprobs = tensor([[-0.5098, -6.5037],
        [-1.0279, -1.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18753686547279358
Epoch 0, Step 2213: train/loss = 0.3526304364204407, train/raw-loss = 0.2147960513830185, train/logprobs = tensor([[-0.1956, -4.9401],
        [-0.8831, -1.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137834370136261
Epoch 0, Step 2214: train/loss = 0.3979453444480896, train/raw-loss = 0.23724377155303955, train/logprobs = tensor([[-0.7707, -7.7965],
        [-1.7433, -1.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16070155799388885
Epoch 0, Step 2215: train/loss = 0.43110159039497375, train/raw-loss = 0.302430659532547, train/logprobs = tensor([[-0.4773, -3.9313],
        [-0.8334, -0.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12867094576358795
Epoch 0, Step 2216: train/loss = 0.39471352100372314, train/raw-loss = 0.24096336960792542, train/logprobs = tensor([[-0.7437, -3.3196],
        [-1.8124, -0.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15375018119812012
Epoch 0, Step 2217: train/loss = 1.0057049989700317, train/raw-loss = 0.8369683027267456, train/logprobs = tensor([[-3.0869, -4.5860],
        [-1.9742, -0.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16873674094676971
Epoch 0, Step 2218: train/loss = 0.43876415491104126, train/raw-loss = 0.31948959827423096, train/logprobs = tensor([[-0.4261, -5.3464],
        [-1.0711, -1.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11927458643913269
Epoch 0, Step 2219: train/loss = 0.45596492290496826, train/raw-loss = 0.34706610441207886, train/logprobs = tensor([[-0.7385, -9.1284],
        [-1.1609, -2.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889877378940582
Epoch 0, Step 2220: train/loss = 0.5513553619384766, train/raw-loss = 0.4026522636413574, train/logprobs = tensor([[-0.4900, -3.7483],
        [-1.1694, -1.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14870312809944153
Epoch 0, Step 2221: train/loss = 0.627776563167572, train/raw-loss = 0.4298027753829956, train/logprobs = tensor([[-1.2005, -7.1765],
        [-1.2235, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19797377288341522
Epoch 0, Step 2222: train/loss = 0.4778560400009155, train/raw-loss = 0.36844849586486816, train/logprobs = tensor([[-0.1176, -4.7850],
        [-0.6658, -0.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10940755158662796
Epoch 0, Step 2223: train/loss = 0.434679239988327, train/raw-loss = 0.2870122194290161, train/logprobs = tensor([[-0.5237, -5.6997],
        [-1.5476, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14766699075698853
Epoch 0, Step 2224: train/loss = 0.3171563148498535, train/raw-loss = 0.1694508194923401, train/logprobs = tensor([[-0.4278, -6.9755],
        [-1.7541, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14770549535751343
Epoch 0, Step 2225: train/loss = 0.7387781143188477, train/raw-loss = 0.6223863363265991, train/logprobs = tensor([[-1.2888, -2.2783],
        [-0.6627, -0.4490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11639176309108734
Epoch 0, Step 2226: train/loss = 0.38577383756637573, train/raw-loss = 0.21377944946289062, train/logprobs = tensor([[-0.2921, -7.5869],
        [-0.9647, -1.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719943881034851
Epoch 0, Step 2227: train/loss = 0.44218844175338745, train/raw-loss = 0.3119063675403595, train/logprobs = tensor([[-0.1942, -3.3848],
        [-0.9233, -0.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13028205931186676
Epoch 0, Step 2228: train/loss = 0.4602522850036621, train/raw-loss = 0.3402552306652069, train/logprobs = tensor([[-0.3124, -4.3326],
        [-1.3132, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199970468878746
Epoch 0, Step 2229: train/loss = 0.5187966823577881, train/raw-loss = 0.4034525454044342, train/logprobs = tensor([[-0.2327, -4.0382],
        [-0.4879, -1.0430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11534415930509567
Epoch 0, Step 2230: train/loss = 0.4572913646697998, train/raw-loss = 0.321899950504303, train/logprobs = tensor([[-0.4240, -2.5932],
        [-1.2217, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13539138436317444
Epoch 0, Step 2231: train/loss = 0.4834901690483093, train/raw-loss = 0.37027907371520996, train/logprobs = tensor([[-0.3765, -5.1447],
        [-0.8005, -1.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11321112513542175
Epoch 0, Step 2232: train/loss = 0.47118836641311646, train/raw-loss = 0.28265029191970825, train/logprobs = tensor([[-0.6037, -3.3553],
        [-1.4018, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885380893945694
Epoch 0, Step 2233: train/loss = 0.35263723134994507, train/raw-loss = 0.24240633845329285, train/logprobs = tensor([[-0.7269, -5.9355],
        [-1.0132, -0.3964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11023087054491043
Epoch 0, Step 2234: train/loss = 0.46796926856040955, train/raw-loss = 0.3169421851634979, train/logprobs = tensor([[-0.8036, -3.9047],
        [-1.4277, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15102709829807281
Epoch 0, Step 2235: train/loss = 0.6788222789764404, train/raw-loss = 0.5225630402565002, train/logprobs = tensor([[-1.1237, -2.6614],
        [-1.2872, -0.4846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15625923871994019
Epoch 0, Step 2236: train/loss = 0.4294816255569458, train/raw-loss = 0.3107229173183441, train/logprobs = tensor([[-0.1788, -3.4219],
        [-0.9018, -0.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11875870823860168
Epoch 0, Step 2237: train/loss = 0.46753793954849243, train/raw-loss = 0.3601888418197632, train/logprobs = tensor([[-0.2932, -2.1895],
        [-1.3095, -0.3652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10734909027814865
Epoch 0, Step 2238: train/loss = 0.49522218108177185, train/raw-loss = 0.33072564005851746, train/logprobs = tensor([[-0.8524, -4.5819],
        [-1.4378, -0.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644965261220932
Epoch 0, Step 2239: train/loss = 0.4588989019393921, train/raw-loss = 0.3376780152320862, train/logprobs = tensor([[-0.2364, -7.0518],
        [-0.7949, -1.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12122088670730591
Epoch 0, Step 2240: train/loss = 0.4857097566127777, train/raw-loss = 0.3249777555465698, train/logprobs = tensor([[-0.6110, -5.4941],
        [-0.6546, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16073200106620789
Epoch 0, Step 2241: train/loss = 0.49453824758529663, train/raw-loss = 0.37463822960853577, train/logprobs = tensor([[-0.8297, -2.0996],
        [-1.1227, -0.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11990003287792206
Epoch 0, Step 2242: train/loss = 0.5564389228820801, train/raw-loss = 0.4352944493293762, train/logprobs = tensor([[-0.4920, -5.3920],
        [-1.4801, -2.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12114446610212326
Epoch 0, Step 2243: train/loss = 0.4668313264846802, train/raw-loss = 0.3700910806655884, train/logprobs = tensor([[-0.1895, -3.1801],
        [-0.8660, -0.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09674026072025299
Epoch 0, Step 2244: train/loss = 0.3869047164916992, train/raw-loss = 0.22704274952411652, train/logprobs = tensor([[-0.4755, -6.9963],
        [-0.9561, -1.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15986193716526031
Epoch 0, Step 2245: train/loss = 0.47757190465927124, train/raw-loss = 0.4150737524032593, train/logprobs = tensor([[-0.4253, -3.0450],
        [-0.8278, -0.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06249815225601196
Epoch 0, Step 2246: train/loss = 0.4648476243019104, train/raw-loss = 0.3517422080039978, train/logprobs = tensor([[-0.4281, -3.0997],
        [-0.9909, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1131053939461708
Epoch 0, Step 2247: train/loss = 0.4021928906440735, train/raw-loss = 0.23278093338012695, train/logprobs = tensor([[-0.4303, -2.7209],
        [-1.7385, -0.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16941195726394653
Epoch 0, Step 2248: train/loss = 0.6643074750900269, train/raw-loss = 0.5777315497398376, train/logprobs = tensor([[-0.1670, -0.7012],
        [-0.3785, -0.3947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08657592535018921
Epoch 0, Step 2249: train/loss = 0.4061082601547241, train/raw-loss = 0.2979588210582733, train/logprobs = tensor([[-0.3424, -2.5192],
        [-0.8863, -0.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081494390964508
Epoch 0, Step 2250: train/loss = 0.4020223617553711, train/raw-loss = 0.30041956901550293, train/logprobs = tensor([[-0.1873, -3.2664],
        [-0.9340, -0.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10160279273986816
Epoch 0, Step 2251: train/loss = 0.4570249021053314, train/raw-loss = 0.31851333379745483, train/logprobs = tensor([[-0.1752, -4.1960],
        [-0.7519, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13851158320903778
Epoch 0, Step 2252: train/loss = 0.5832661390304565, train/raw-loss = 0.48800206184387207, train/logprobs = tensor([[-0.4208, -2.1991],
        [-0.4003, -0.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526412189006805
Epoch 0, Step 2253: train/loss = 0.52784264087677, train/raw-loss = 0.4203239679336548, train/logprobs = tensor([[-0.1914, -2.9395],
        [-0.6689, -0.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10751871019601822
Epoch 0, Step 2254: train/loss = 0.6106966733932495, train/raw-loss = 0.5470553040504456, train/logprobs = tensor([[-0.0450, -0.5978],
        [-0.6580, -0.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06364141404628754
Epoch 0, Step 2255: train/loss = 0.2683427333831787, train/raw-loss = 0.1557070016860962, train/logprobs = tensor([[ -0.5331, -11.2175],
        [ -1.7985,  -4.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11263573169708252
Epoch 0, Step 2256: train/loss = 0.5549333691596985, train/raw-loss = 0.4100179672241211, train/logprobs = tensor([[-0.3642, -4.2139],
        [-0.8346, -0.7140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.144915372133255
Epoch 0, Step 2257: train/loss = 0.5933862328529358, train/raw-loss = 0.45943683385849, train/logprobs = tensor([[-0.8396, -2.2249],
        [-0.9818, -0.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339493989944458
Epoch 0, Step 2258: train/loss = 0.47475841641426086, train/raw-loss = 0.37129873037338257, train/logprobs = tensor([[-0.4625, -5.6932],
        [-0.5836, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034596860408783
Epoch 0, Step 2259: train/loss = 0.3670647144317627, train/raw-loss = 0.24067866802215576, train/logprobs = tensor([[-0.3140, -7.5631],
        [-1.0014, -1.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12638607621192932
Epoch 0, Step 2260: train/loss = 0.5870880484580994, train/raw-loss = 0.4870692789554596, train/logprobs = tensor([[-0.2885, -5.1251],
        [-0.9996, -3.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001876205205917
Epoch 0, Step 2261: train/loss = 0.4199092984199524, train/raw-loss = 0.25964367389678955, train/logprobs = tensor([[-0.3521, -4.6300],
        [-1.2984, -0.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16026559472084045
Epoch 0, Step 2262: train/loss = 0.5305807590484619, train/raw-loss = 0.4233408272266388, train/logprobs = tensor([[-0.1899, -1.3504],
        [-0.6925, -0.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10723996162414551
Epoch 0, Step 2263: train/loss = 0.5897738933563232, train/raw-loss = 0.44653522968292236, train/logprobs = tensor([[-0.3337, -2.6174],
        [-0.7430, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14323866367340088
Epoch 0, Step 2264: train/loss = 0.5366429090499878, train/raw-loss = 0.4045214056968689, train/logprobs = tensor([[-0.4020, -5.8897],
        [-0.6166, -1.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321215033531189
Epoch 0, Step 2265: train/loss = 0.3926689028739929, train/raw-loss = 0.2876562178134918, train/logprobs = tensor([[-0.1539, -3.8623],
        [-0.9890, -0.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10501265525817871
Epoch 0, Step 2266: train/loss = 0.32652631402015686, train/raw-loss = 0.2007874846458435, train/logprobs = tensor([[ -0.5996, -10.8975],
        [ -1.3280,  -2.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12573884427547455
Epoch 0, Step 2267: train/loss = 0.6046568155288696, train/raw-loss = 0.5430001020431519, train/logprobs = tensor([[-0.1636, -0.6733],
        [-0.4358, -0.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061656732112169266
Epoch 0, Step 2268: train/loss = 0.40477997064590454, train/raw-loss = 0.2463189661502838, train/logprobs = tensor([[-0.4478, -4.0515],
        [-1.4221, -0.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15846100449562073
Epoch 0, Step 2269: train/loss = 0.5743449926376343, train/raw-loss = 0.4606458246707916, train/logprobs = tensor([[-1.0507, -1.5960],
        [-1.5670, -0.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11369915306568146
Epoch 0, Step 2270: train/loss = 0.45895975828170776, train/raw-loss = 0.3335193991661072, train/logprobs = tensor([[-0.2125, -3.9822],
        [-0.5176, -1.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12544035911560059
Epoch 0, Step 2271: train/loss = 0.4388689398765564, train/raw-loss = 0.3322506844997406, train/logprobs = tensor([[-0.5178, -3.5724],
        [-1.2667, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106618233025074
Epoch 0, Step 2272: train/loss = 0.42445090413093567, train/raw-loss = 0.2892223596572876, train/logprobs = tensor([[-0.7953, -6.7290],
        [-2.3951, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13522851467132568
Epoch 0, Step 2273: train/loss = 0.4997886121273041, train/raw-loss = 0.38844871520996094, train/logprobs = tensor([[-0.5950, -4.8982],
        [-0.7257, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11133989691734314
Epoch 0, Step 2274: train/loss = 0.38426879048347473, train/raw-loss = 0.24750378727912903, train/logprobs = tensor([[-0.1842, -4.1918],
        [-1.0372, -0.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13676497340202332
Epoch 0, Step 2275: train/loss = 0.2921857237815857, train/raw-loss = 0.1563405990600586, train/logprobs = tensor([[-0.4401, -3.7836],
        [-1.7801, -0.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358451545238495
Epoch 0, Step 2276: train/loss = 0.44543540477752686, train/raw-loss = 0.33389386534690857, train/logprobs = tensor([[-0.3244, -3.7672],
        [-1.0932, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11154153943061829
Epoch 0, Step 2277: train/loss = 0.6050008535385132, train/raw-loss = 0.5288859605789185, train/logprobs = tensor([[-0.2071, -1.2313],
        [-0.3738, -0.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611490041017532
Epoch 0, Step 2278: train/loss = 0.4481046199798584, train/raw-loss = 0.3228893578052521, train/logprobs = tensor([[-0.3616, -2.9302],
        [-1.2685, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12521523237228394
Epoch 0, Step 2279: train/loss = 0.42250800132751465, train/raw-loss = 0.32455939054489136, train/logprobs = tensor([[-0.7457, -8.1450],
        [-1.7413, -2.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09794862568378448
Epoch 0, Step 2280: train/loss = 0.5167405009269714, train/raw-loss = 0.42025166749954224, train/logprobs = tensor([[-0.2691, -2.5239],
        [-0.7627, -0.4637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096488818526268
Epoch 0, Step 2281: train/loss = 0.3181378245353699, train/raw-loss = 0.15047438442707062, train/logprobs = tensor([[-0.4776, -4.3760],
        [-1.8138, -0.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16766342520713806
Epoch 0, Step 2282: train/loss = 0.5277812480926514, train/raw-loss = 0.4057263135910034, train/logprobs = tensor([[-0.3520, -3.8597],
        [-0.6752, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12205493450164795
Epoch 0, Step 2283: train/loss = 0.37085580825805664, train/raw-loss = 0.2690845727920532, train/logprobs = tensor([[-0.1726, -4.5713],
        [-0.6066, -0.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10177122056484222
Epoch 0, Step 2284: train/loss = 0.5178635120391846, train/raw-loss = 0.4175741970539093, train/logprobs = tensor([[-0.4253, -3.5363],
        [-0.8733, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028932243585587
Epoch 0, Step 2285: train/loss = 0.4220137894153595, train/raw-loss = 0.29607218503952026, train/logprobs = tensor([[-0.6406, -8.4044],
        [-1.0946, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12594160437583923
Epoch 0, Step 2286: train/loss = 0.3599292039871216, train/raw-loss = 0.2105734944343567, train/logprobs = tensor([[-0.3474, -4.0012],
        [-1.0299, -0.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1493556946516037
Epoch 0, Step 2287: train/loss = 0.7014987468719482, train/raw-loss = 0.5677900910377502, train/logprobs = tensor([[-1.0267, -5.8971],
        [-1.2123, -1.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133708655834198
Epoch 0, Step 2288: train/loss = 0.41661331057548523, train/raw-loss = 0.2729801833629608, train/logprobs = tensor([[-0.5849, -7.4086],
        [-0.8974, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14363312721252441
Epoch 0, Step 2289: train/loss = 0.46266043186187744, train/raw-loss = 0.3695019483566284, train/logprobs = tensor([[-0.2700, -6.9405],
        [-1.3788, -1.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09315848350524902
Epoch 0, Step 2290: train/loss = 0.7664700746536255, train/raw-loss = 0.6291025876998901, train/logprobs = tensor([[-0.8845, -0.8489],
        [-1.7654, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13736748695373535
Epoch 0, Step 2291: train/loss = 0.3449222445487976, train/raw-loss = 0.15143369138240814, train/logprobs = tensor([[-0.2748, -6.3680],
        [-1.3962, -0.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19348853826522827
Epoch 0, Step 2292: train/loss = 0.6365340948104858, train/raw-loss = 0.5216937065124512, train/logprobs = tensor([[-1.2268, -4.2442],
        [-0.7113, -0.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11484035849571228
Epoch 0, Step 2293: train/loss = 0.4644855260848999, train/raw-loss = 0.3054733872413635, train/logprobs = tensor([[-0.7660, -3.6890],
        [-1.5097, -0.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15901212394237518
Epoch 0, Step 2294: train/loss = 0.482441246509552, train/raw-loss = 0.36436524987220764, train/logprobs = tensor([[-0.2565, -7.1171],
        [-0.9043, -1.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11807601153850555
Epoch 0, Step 2295: train/loss = 0.45841696858406067, train/raw-loss = 0.31501680612564087, train/logprobs = tensor([[-0.1490, -3.1059],
        [-1.1971, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434001922607422
Epoch 0, Step 2296: train/loss = 0.6228808164596558, train/raw-loss = 0.5181719064712524, train/logprobs = tensor([[-0.4320, -1.2375],
        [-0.7542, -0.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470890253782272
Epoch 0, Step 2297: train/loss = 0.532646656036377, train/raw-loss = 0.39614230394363403, train/logprobs = tensor([[-0.3315, -2.1316],
        [-0.7138, -0.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13650435209274292
Epoch 0, Step 2298: train/loss = 0.24987056851387024, train/raw-loss = 0.11716291308403015, train/logprobs = tensor([[ -0.4939, -15.3580],
        [ -1.8884,  -3.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327076256275177
Epoch 0, Step 2299: train/loss = 0.5284051895141602, train/raw-loss = 0.4333174228668213, train/logprobs = tensor([[-0.3558, -1.4092],
        [-0.8246, -0.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508773684501648
Epoch 0, Step 2300: train/loss = 0.34948208928108215, train/raw-loss = 0.1945945769548416, train/logprobs = tensor([[-0.5962, -2.9532],
        [-1.5768, -0.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15488751232624054
Epoch 0, Step 2301: train/loss = 0.3645346760749817, train/raw-loss = 0.20101800560951233, train/logprobs = tensor([[-0.1590, -7.1864],
        [-1.3471, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16351668536663055
Epoch 0, Step 2302: train/loss = 0.4629547595977783, train/raw-loss = 0.3710298538208008, train/logprobs = tensor([[-0.1264, -9.2556],
        [-1.0846, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09192490577697754
Epoch 0, Step 2303: train/loss = 0.37089234590530396, train/raw-loss = 0.24465084075927734, train/logprobs = tensor([[-0.4035, -3.4829],
        [-1.3300, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1262415051460266
Epoch 0, Step 2304: train/loss = 0.45483076572418213, train/raw-loss = 0.3177424669265747, train/logprobs = tensor([[-0.5634, -7.1031],
        [-0.8439, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13708829879760742
Epoch 0, Step 2305: train/loss = 0.5800520181655884, train/raw-loss = 0.44119906425476074, train/logprobs = tensor([[-0.5201, -5.3807],
        [-1.0283, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885293900966644
Epoch 0, Step 2306: train/loss = 0.5345890522003174, train/raw-loss = 0.4465780556201935, train/logprobs = tensor([[-0.5678, -2.5955],
        [-0.6402, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08801096677780151
Epoch 0, Step 2307: train/loss = 0.5602700114250183, train/raw-loss = 0.39826399087905884, train/logprobs = tensor([[-0.9811, -5.7146],
        [-2.0250, -1.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16200605034828186
Epoch 0, Step 2308: train/loss = 0.5456520318984985, train/raw-loss = 0.4609864056110382, train/logprobs = tensor([[-0.1309, -3.1511],
        [-0.4123, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08466564118862152
Epoch 0, Step 2309: train/loss = 0.5149863958358765, train/raw-loss = 0.40254640579223633, train/logprobs = tensor([[-1.2375, -5.9373],
        [-1.2243, -1.5727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243996024131775
Epoch 0, Step 2310: train/loss = 0.7763658761978149, train/raw-loss = 0.6484577655792236, train/logprobs = tensor([[-0.4761, -0.4550],
        [-1.0327, -0.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12790805101394653
Epoch 0, Step 2311: train/loss = 0.6135339140892029, train/raw-loss = 0.5413243174552917, train/logprobs = tensor([[-0.1521, -1.3094],
        [-0.2367, -0.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07220958918333054
Epoch 0, Step 2312: train/loss = 0.4613075852394104, train/raw-loss = 0.3436127305030823, train/logprobs = tensor([[-0.1764, -2.7098],
        [-0.8311, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11769482493400574
Epoch 0, Step 2313: train/loss = 0.4968438744544983, train/raw-loss = 0.3682611584663391, train/logprobs = tensor([[-0.3293, -4.7662],
        [-0.7337, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12858276069164276
Epoch 0, Step 2314: train/loss = 0.3332129120826721, train/raw-loss = 0.20400729775428772, train/logprobs = tensor([[-0.4206, -7.4944],
        [-0.9618, -0.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292056441307068
Epoch 0, Step 2315: train/loss = 0.42748865485191345, train/raw-loss = 0.29803869128227234, train/logprobs = tensor([[-0.4817, -4.1989],
        [-1.1552, -0.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294499635696411
Epoch 0, Step 2316: train/loss = 0.5051392316818237, train/raw-loss = 0.38473984599113464, train/logprobs = tensor([[-0.4465, -3.9547],
        [-0.8747, -0.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12039938569068909
Epoch 0, Step 2317: train/loss = 0.3893994688987732, train/raw-loss = 0.27570340037345886, train/logprobs = tensor([[-0.4473, -3.6684],
        [-0.9694, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11369609087705612
Epoch 0, Step 2318: train/loss = 0.5212725400924683, train/raw-loss = 0.42291271686553955, train/logprobs = tensor([[-0.3306, -3.1592],
        [-0.6737, -0.2598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09835980832576752
Epoch 0, Step 2319: train/loss = 0.41193291544914246, train/raw-loss = 0.25572097301483154, train/logprobs = tensor([[-0.4246, -8.2901],
        [-0.8487, -2.3051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562119722366333
Epoch 0, Step 2320: train/loss = 0.5571042895317078, train/raw-loss = 0.4134710431098938, train/logprobs = tensor([[-0.3236, -3.1178],
        [-0.6244, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14363324642181396
Epoch 0, Step 2321: train/loss = 0.5931971073150635, train/raw-loss = 0.4869592785835266, train/logprobs = tensor([[-0.4948, -2.6224],
        [-0.6936, -0.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10623778402805328
Epoch 0, Step 2322: train/loss = 0.38936078548431396, train/raw-loss = 0.2654854953289032, train/logprobs = tensor([[-1.2079, -3.6402],
        [-1.7879, -0.4453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12387526035308838
Epoch 0, Step 2323: train/loss = 0.6650466322898865, train/raw-loss = 0.5940347909927368, train/logprobs = tensor([[-0.2444, -0.5516],
        [-0.4503, -0.3062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07101181894540787
Epoch 0, Step 2324: train/loss = 0.48079514503479004, train/raw-loss = 0.3511333763599396, train/logprobs = tensor([[-0.2790, -5.3422],
        [-0.7992, -0.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12966179847717285
Epoch 0, Step 2325: train/loss = 0.6182473301887512, train/raw-loss = 0.511782169342041, train/logprobs = tensor([[-0.2027, -1.9409],
        [-0.3705, -0.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10646522045135498
Epoch 0, Step 2326: train/loss = 0.3045353591442108, train/raw-loss = 0.16409912705421448, train/logprobs = tensor([[-0.1762, -5.4963],
        [-1.5857, -2.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14043623208999634
Epoch 0, Step 2327: train/loss = 0.5660662651062012, train/raw-loss = 0.44977453351020813, train/logprobs = tensor([[-0.7240, -4.1023],
        [-1.0023, -0.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11629173159599304
Epoch 0, Step 2328: train/loss = 0.574975848197937, train/raw-loss = 0.4146507680416107, train/logprobs = tensor([[-0.1139, -4.2301],
        [-0.7271, -0.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603250652551651
Epoch 0, Step 2329: train/loss = 0.5598089098930359, train/raw-loss = 0.45745649933815, train/logprobs = tensor([[-0.2818, -2.5442],
        [-0.3283, -0.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10235245525836945
Epoch 0, Step 2330: train/loss = 0.44044530391693115, train/raw-loss = 0.33030688762664795, train/logprobs = tensor([[-0.4059, -2.6461],
        [-1.0411, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11013845354318619
Epoch 0, Step 2331: train/loss = 0.6154986619949341, train/raw-loss = 0.5116797089576721, train/logprobs = tensor([[-0.4139, -1.9272],
        [-0.4253, -0.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10381890088319778
Epoch 0, Step 2332: train/loss = 0.4009377956390381, train/raw-loss = 0.28906723856925964, train/logprobs = tensor([[-0.2719, -4.6102],
        [-1.0898, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11187058687210083
Epoch 0, Step 2333: train/loss = 0.5143195986747742, train/raw-loss = 0.38961029052734375, train/logprobs = tensor([[-0.3485, -2.6526],
        [-1.1006, -0.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12470933794975281
Epoch 0, Step 2334: train/loss = 0.5351952910423279, train/raw-loss = 0.41060328483581543, train/logprobs = tensor([[-0.4991, -5.6672],
        [-0.8066, -0.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12459202110767365
Epoch 0, Step 2335: train/loss = 0.28990674018859863, train/raw-loss = 0.0938446968793869, train/logprobs = tensor([[-0.3154, -8.9384],
        [-2.2415, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19606205821037292
Epoch 0, Step 2336: train/loss = 0.4931949973106384, train/raw-loss = 0.3686440587043762, train/logprobs = tensor([[-0.5614, -3.5216],
        [-1.0993, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12455093115568161
Epoch 0, Step 2337: train/loss = 0.2509304881095886, train/raw-loss = 0.10841083526611328, train/logprobs = tensor([[-0.2098, -6.2921],
        [-1.8029, -1.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14251966774463654
Epoch 0, Step 2338: train/loss = 0.5268179178237915, train/raw-loss = 0.3998557925224304, train/logprobs = tensor([[-0.7128, -1.9071],
        [-1.5269, -0.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269621104001999
Epoch 0, Step 2339: train/loss = 0.5577293038368225, train/raw-loss = 0.423808753490448, train/logprobs = tensor([[-0.5549, -1.5131],
        [-1.0359, -0.2015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13392053544521332
Epoch 0, Step 2340: train/loss = 0.5378706455230713, train/raw-loss = 0.41703206300735474, train/logprobs = tensor([[-0.2464, -1.3002],
        [-1.0389, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12083860486745834
Epoch 0, Step 2341: train/loss = 0.8341732025146484, train/raw-loss = 0.7201791405677795, train/logprobs = tensor([[-1.6286, -3.2578],
        [-0.6054, -0.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1139940470457077
Epoch 0, Step 2342: train/loss = 0.6207883358001709, train/raw-loss = 0.49517345428466797, train/logprobs = tensor([[-0.2115, -1.2886],
        [-0.6837, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12561488151550293
Epoch 0, Step 2343: train/loss = 0.4194297790527344, train/raw-loss = 0.25755876302719116, train/logprobs = tensor([[-0.2552, -3.9678],
        [-1.0072, -0.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1618710160255432
Epoch 0, Step 2344: train/loss = 0.36730796098709106, train/raw-loss = 0.23003125190734863, train/logprobs = tensor([[-0.3153, -5.3231],
        [-1.0074, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13727672398090363
Epoch 0, Step 2345: train/loss = 0.4328596293926239, train/raw-loss = 0.2740171551704407, train/logprobs = tensor([[-0.3255, -5.8913],
        [-1.4503, -1.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15884247422218323
Epoch 0, Step 2346: train/loss = 0.4452138841152191, train/raw-loss = 0.3319495916366577, train/logprobs = tensor([[-0.3368, -4.3340],
        [-0.8322, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11326424032449722
Epoch 0, Step 2347: train/loss = 0.42908281087875366, train/raw-loss = 0.27004480361938477, train/logprobs = tensor([[-0.3978, -3.9456],
        [-1.7949, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15903803706169128
Epoch 0, Step 2348: train/loss = 0.39615482091903687, train/raw-loss = 0.24210813641548157, train/logprobs = tensor([[-0.1861, -4.7704],
        [-1.1847, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15404674410820007
Epoch 0, Step 2349: train/loss = 0.8616665601730347, train/raw-loss = 0.7227470874786377, train/logprobs = tensor([[-1.3936, -2.1578],
        [-0.4660, -0.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1389194279909134
Epoch 0, Step 2350: train/loss = 0.5991995930671692, train/raw-loss = 0.511275589466095, train/logprobs = tensor([[-0.7176, -2.3761],
        [-0.3431, -0.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08792401105165482
Epoch 0, Step 2351: train/loss = 0.5238784551620483, train/raw-loss = 0.4530469477176666, train/logprobs = tensor([[-0.1105, -1.4897],
        [-0.5812, -0.1121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07083150744438171
Epoch 0, Step 2352: train/loss = 0.3781486749649048, train/raw-loss = 0.25296881794929504, train/logprobs = tensor([[-0.2192, -5.0836],
        [-0.8903, -0.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517985701560974
Epoch 0, Step 2353: train/loss = 0.5836371779441833, train/raw-loss = 0.48551347851753235, train/logprobs = tensor([[-0.2607, -2.4695],
        [-0.3649, -0.2049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09812367707490921
Epoch 0, Step 2354: train/loss = 0.36685243248939514, train/raw-loss = 0.24088610708713531, train/logprobs = tensor([[-1.0765, -4.0169],
        [-1.7688, -0.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12596631050109863
Epoch 0, Step 2355: train/loss = 0.38851815462112427, train/raw-loss = 0.27044376730918884, train/logprobs = tensor([[-0.2504, -4.7098],
        [-1.2943, -1.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11807436496019363
Epoch 0, Step 2356: train/loss = 0.37292152643203735, train/raw-loss = 0.23015950620174408, train/logprobs = tensor([[-0.3527, -4.8298],
        [-0.8497, -0.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427619904279709
Epoch 0, Step 2357: train/loss = 0.5021596550941467, train/raw-loss = 0.3750510513782501, train/logprobs = tensor([[-0.2583, -1.6637],
        [-0.7660, -0.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271086037158966
Epoch 0, Step 2358: train/loss = 0.48111671209335327, train/raw-loss = 0.3642141819000244, train/logprobs = tensor([[-0.6326, -3.4213],
        [-0.9675, -0.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11690252274274826
Epoch 0, Step 2359: train/loss = 0.37771329283714294, train/raw-loss = 0.2269192636013031, train/logprobs = tensor([[-0.6772, -5.2680],
        [-1.7419, -0.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15079404413700104
Epoch 0, Step 2360: train/loss = 0.43344125151634216, train/raw-loss = 0.3217467665672302, train/logprobs = tensor([[-0.2031, -2.6952],
        [-0.7817, -0.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11169449985027313
Epoch 0, Step 2361: train/loss = 0.47896385192871094, train/raw-loss = 0.3432191014289856, train/logprobs = tensor([[-0.3309, -3.6498],
        [-0.7656, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13574475049972534
Epoch 0, Step 2362: train/loss = 0.4518137574195862, train/raw-loss = 0.33255401253700256, train/logprobs = tensor([[-0.2939, -2.1411],
        [-0.7868, -0.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11925968527793884
Epoch 0, Step 2363: train/loss = 0.49356234073638916, train/raw-loss = 0.38898617029190063, train/logprobs = tensor([[-0.2958, -2.5491],
        [-0.7966, -0.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10457617044448853
Epoch 0, Step 2364: train/loss = 0.5901715755462646, train/raw-loss = 0.4232887327671051, train/logprobs = tensor([[-1.5849, -2.4876],
        [-1.9860, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16688284277915955
Epoch 0, Step 2365: train/loss = 0.3835350573062897, train/raw-loss = 0.30480772256851196, train/logprobs = tensor([[-0.2476, -3.0524],
        [-0.7307, -0.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07872731983661652
Epoch 0, Step 2366: train/loss = 0.5037294626235962, train/raw-loss = 0.39902952313423157, train/logprobs = tensor([[-0.2190, -2.5600],
        [-0.3117, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10469992458820343
Epoch 0, Step 2367: train/loss = 0.4764487147331238, train/raw-loss = 0.3880239725112915, train/logprobs = tensor([[-0.2164, -1.8036],
        [-0.7133, -0.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08842472732067108
Epoch 0, Step 2368: train/loss = 0.3733295798301697, train/raw-loss = 0.2612996995449066, train/logprobs = tensor([[-0.3024, -5.4476],
        [-0.7480, -0.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11202986538410187
Epoch 0, Step 2369: train/loss = 0.5971931219100952, train/raw-loss = 0.47041547298431396, train/logprobs = tensor([[-0.5137, -2.5420],
        [-0.9590, -0.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12677769362926483
Epoch 0, Step 2370: train/loss = 0.3095064163208008, train/raw-loss = 0.16818606853485107, train/logprobs = tensor([[-0.3263, -4.3288],
        [-1.5205, -0.7447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1413203477859497
Epoch 0, Step 2371: train/loss = 0.4053099751472473, train/raw-loss = 0.26618582010269165, train/logprobs = tensor([[-0.5900, -3.0674],
        [-1.4750, -0.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13912418484687805
Epoch 0, Step 2372: train/loss = 0.45754414796829224, train/raw-loss = 0.29140007495880127, train/logprobs = tensor([[-0.1012, -6.4305],
        [-0.9321, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16614405810832977
Epoch 0, Step 2373: train/loss = 0.4124426245689392, train/raw-loss = 0.2920019328594208, train/logprobs = tensor([[-0.3646, -3.3428],
        [-1.0553, -0.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12044071406126022
Epoch 0, Step 2374: train/loss = 0.5132405757904053, train/raw-loss = 0.38005250692367554, train/logprobs = tensor([[-0.3129, -3.9030],
        [-0.5535, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13318808376789093
