{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 18:39:31,209][root][INFO] - beta: 1.0
[2024-03-12 18:39:31,209][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-both/checkpoint-296/', 'cache_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-both/checkpoint-296/'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/sft-typo-both-beta-1.0-1e-6.
Epoch 0, Step 0: train/loss = 0.6906275749206543, train/raw-loss = 0.6906275749206543, train/logprobs = tensor([[-0.1049, -0.1331],
        [-0.1084, -0.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6912062168121338, train/raw-loss = 0.6912062168121338, train/logprobs = tensor([[-0.0788, -0.0940],
        [-0.0814, -0.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.689285159111023, train/raw-loss = 0.689285159111023, train/logprobs = tensor([[-0.0779, -0.1086],
        [-0.0825, -0.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.694538414478302, train/raw-loss = 0.694538414478302, train/logprobs = tensor([[-0.1757, -0.1054],
        [-0.1697, -0.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6935521364212036, train/raw-loss = 0.6935521364212036, train/logprobs = tensor([[-0.0945, -0.0362],
        [-0.0959, -0.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.691057562828064, train/raw-loss = 0.691057562828064, train/logprobs = tensor([[-0.0548, -0.1075],
        [-0.0576, -0.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6930809020996094, train/raw-loss = 0.6930809020996094, train/logprobs = tensor([[-0.0707, -0.0980],
        [-0.0729, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6906139850616455, train/raw-loss = 0.6906139850616455, train/logprobs = tensor([[-0.0788, -0.0582],
        [-0.0876, -0.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6817048788070679, train/raw-loss = 0.6817048788070679, train/logprobs = tensor([[-0.0937, -0.2764],
        [-0.0996, -0.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6899797916412354, train/raw-loss = 0.6899797916412354, train/logprobs = tensor([[-0.1041, -0.1174],
        [-0.1094, -0.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6957104206085205, train/raw-loss = 0.6957104206085205, train/logprobs = tensor([[-0.0770, -0.2344],
        [-0.0718, -0.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6825586557388306, train/raw-loss = 0.6825586557388306, train/logprobs = tensor([[-0.0754, -0.2170],
        [-0.0744, -0.1722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6793380975723267, train/raw-loss = 0.6793380975723267, train/logprobs = tensor([[-0.1402, -0.3160],
        [-0.1463, -0.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6908765435218811, train/raw-loss = 0.6908765435218811, train/logprobs = tensor([[-0.0414, -0.0619],
        [-0.0434, -0.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6913654208183289, train/raw-loss = 0.6913654208183289, train/logprobs = tensor([[-0.0684, -0.0806],
        [-0.0719, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6903812289237976, train/raw-loss = 0.6903812289237976, train/logprobs = tensor([[-0.0400, -0.0625],
        [-0.0493, -0.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6910890936851501, train/raw-loss = 0.6910890936851501, train/logprobs = tensor([[-0.0933, -0.0939],
        [-0.0960, -0.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6903483867645264, train/raw-loss = 0.6903483867645264, train/logprobs = tensor([[-0.1814, -0.1121],
        [-0.1771, -0.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6910480260848999, train/raw-loss = 0.6910480260848999, train/logprobs = tensor([[-0.1146, -0.0814],
        [-0.1151, -0.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6924335956573486, train/raw-loss = 0.6924335956573486, train/logprobs = tensor([[-0.0704, -0.0451],
        [-0.0715, -0.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6969028115272522, train/raw-loss = 0.6969028115272522, train/logprobs = tensor([[-0.2700, -0.0442],
        [-0.2647, -0.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6933315396308899, train/raw-loss = 0.6933315396308899, train/logprobs = tensor([[-0.3072, -0.0487],
        [-0.2929, -0.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6917641162872314, train/raw-loss = 0.6917641162872314, train/logprobs = tensor([[-0.2080, -0.1371],
        [-0.2091, -0.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6919781565666199, train/raw-loss = 0.6919781565666199, train/logprobs = tensor([[-0.0618, -0.0790],
        [-0.0636, -0.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6923743486404419, train/raw-loss = 0.6923743486404419, train/logprobs = tensor([[-0.0949, -0.0598],
        [-0.0946, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6914557218551636, train/raw-loss = 0.6914557218551636, train/logprobs = tensor([[-0.1477, -0.0539],
        [-0.1528, -0.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.691846489906311, train/raw-loss = 0.691846489906311, train/logprobs = tensor([[-0.0906, -0.1216],
        [-0.0888, -0.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6858680248260498, train/raw-loss = 0.6858680248260498, train/logprobs = tensor([[-0.1228, -0.2207],
        [-0.1330, -0.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6910855770111084, train/raw-loss = 0.6910855770111084, train/logprobs = tensor([[-0.0929, -0.0822],
        [-0.0959, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6926475763320923, train/raw-loss = 0.6926475763320923, train/logprobs = tensor([[-0.0560, -0.0857],
        [-0.0532, -0.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6819225549697876, train/raw-loss = 0.6819225549697876, train/logprobs = tensor([[-0.0816, -0.1786],
        [-0.0902, -0.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.693026065826416, train/raw-loss = 0.693026065826416, train/logprobs = tensor([[-0.0858, -0.1226],
        [-0.0887, -0.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6950878500938416, train/raw-loss = 0.6950878500938416, train/logprobs = tensor([[-0.0495, -0.0918],
        [-0.0523, -0.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6929644346237183, train/raw-loss = 0.6929644346237183, train/logprobs = tensor([[-0.1489, -0.1187],
        [-0.1495, -0.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6883277297019958, train/raw-loss = 0.6883277297019958, train/logprobs = tensor([[-0.1693, -0.1706],
        [-0.1681, -0.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6898608803749084, train/raw-loss = 0.6898608803749084, train/logprobs = tensor([[-0.1098, -0.1552],
        [-0.1093, -0.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6912087798118591, train/raw-loss = 0.6912087798118591, train/logprobs = tensor([[-0.1697, -0.1007],
        [-0.1723, -0.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.679940938949585, train/raw-loss = 0.679940938949585, train/logprobs = tensor([[-0.1011, -0.2688],
        [-0.1285, -0.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.693029522895813, train/raw-loss = 0.693029522895813, train/logprobs = tensor([[-0.0760, -0.0955],
        [-0.0828, -0.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6923582553863525, train/raw-loss = 0.6923582553863525, train/logprobs = tensor([[-0.0658, -0.0778],
        [-0.0629, -0.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6923428773880005, train/raw-loss = 0.6923428773880005, train/logprobs = tensor([[-0.1138, -0.0644],
        [-0.1156, -0.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6896645426750183, train/raw-loss = 0.6896645426750183, train/logprobs = tensor([[-0.1252, -0.0888],
        [-0.1294, -0.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6866625547409058, train/raw-loss = 0.6866625547409058, train/logprobs = tensor([[-0.1639, -0.0512],
        [-0.1808, -0.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6731882095336914, train/raw-loss = 0.6731882095336914, train/logprobs = tensor([[-0.1106, -0.3254],
        [-0.1210, -0.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6949629187583923, train/raw-loss = 0.6949629187583923, train/logprobs = tensor([[-0.0734, -0.0732],
        [-0.0625, -0.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6925082206726074, train/raw-loss = 0.6925082206726074, train/logprobs = tensor([[-0.3388, -0.0954],
        [-0.3352, -0.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.690887451171875, train/raw-loss = 0.690887451171875, train/logprobs = tensor([[-0.1615, -0.0628],
        [-0.1635, -0.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6928563117980957, train/raw-loss = 0.6928563117980957, train/logprobs = tensor([[-0.1676, -0.0415],
        [-0.1672, -0.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6973150372505188, train/raw-loss = 0.6973150372505188, train/logprobs = tensor([[-0.1033, -0.1012],
        [-0.1002, -0.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6926056742668152, train/raw-loss = 0.6926056742668152, train/logprobs = tensor([[-0.0826, -0.1529],
        [-0.0876, -0.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6892089247703552, train/raw-loss = 0.6892089247703552, train/logprobs = tensor([[-0.0961, -0.1502],
        [-0.0992, -0.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6937375664710999, train/raw-loss = 0.6937375664710999, train/logprobs = tensor([[-0.1026, -0.0654],
        [-0.1009, -0.0660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6936778426170349, train/raw-loss = 0.6936778426170349, train/logprobs = tensor([[-0.0961, -0.1142],
        [-0.0924, -0.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6918796300888062, train/raw-loss = 0.6918796300888062, train/logprobs = tensor([[-0.0907, -0.0358],
        [-0.0969, -0.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.692629873752594, train/raw-loss = 0.692629873752594, train/logprobs = tensor([[-0.0862, -0.1409],
        [-0.0833, -0.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6918533444404602, train/raw-loss = 0.6918533444404602, train/logprobs = tensor([[-0.0706, -0.0409],
        [-0.0758, -0.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6954129934310913, train/raw-loss = 0.6954129934310913, train/logprobs = tensor([[-0.0992, -0.1275],
        [-0.1073, -0.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.684982419013977, train/raw-loss = 0.684982419013977, train/logprobs = tensor([[-0.0822, -0.1388],
        [-0.0847, -0.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6874104738235474, train/raw-loss = 0.6874104738235474, train/logprobs = tensor([[-0.0906, -0.0919],
        [-0.0920, -0.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.691057562828064, train/raw-loss = 0.691057562828064, train/logprobs = tensor([[-0.0527, -0.0992],
        [-0.0555, -0.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6904677748680115, train/raw-loss = 0.6904677748680115, train/logprobs = tensor([[-0.0614, -0.1197],
        [-0.0619, -0.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6943770051002502, train/raw-loss = 0.6943770051002502, train/logprobs = tensor([[-0.1069, -0.0795],
        [-0.1024, -0.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6756585240364075, train/raw-loss = 0.6756585240364075, train/logprobs = tensor([[-0.0788, -0.2881],
        [-0.0771, -0.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6931130290031433, train/raw-loss = 0.6931130290031433, train/logprobs = tensor([[-0.1236, -0.0731],
        [-0.1255, -0.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.692533552646637, train/raw-loss = 0.6919451951980591, train/logprobs = tensor([[-0.0802, -0.1949],
        [-0.0805, -0.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005883239209651947
Epoch 0, Step 65: train/loss = 0.6575896739959717, train/raw-loss = 0.6569080948829651, train/logprobs = tensor([[-0.1252, -0.3851],
        [-0.1247, -0.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006815865635871887
Epoch 0, Step 66: train/loss = 0.6922500729560852, train/raw-loss = 0.6917062997817993, train/logprobs = tensor([[-0.0496, -0.0801],
        [-0.0502, -0.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005437659565359354
Epoch 0, Step 67: train/loss = 0.6903775334358215, train/raw-loss = 0.6897441744804382, train/logprobs = tensor([[-0.0881, -0.0870],
        [-0.0907, -0.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006333582568913698
Epoch 0, Step 68: train/loss = 0.6907352209091187, train/raw-loss = 0.690088152885437, train/logprobs = tensor([[-0.0768, -0.1084],
        [-0.0832, -0.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006470305961556733
Epoch 0, Step 69: train/loss = 0.6915425062179565, train/raw-loss = 0.6908974647521973, train/logprobs = tensor([[-0.0882, -0.0580],
        [-0.0925, -0.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006450130604207516
Epoch 0, Step 70: train/loss = 0.6908620595932007, train/raw-loss = 0.690156102180481, train/logprobs = tensor([[-0.0641, -0.1702],
        [-0.0663, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007059295894578099
Epoch 0, Step 71: train/loss = 0.6921127438545227, train/raw-loss = 0.6913999915122986, train/logprobs = tensor([[-0.1375, -0.0826],
        [-0.1416, -0.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007127512944862247
Epoch 0, Step 72: train/loss = 0.6897604465484619, train/raw-loss = 0.689134418964386, train/logprobs = tensor([[-0.1028, -0.1156],
        [-0.1032, -0.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006260740337893367
Epoch 0, Step 73: train/loss = 0.6940164566040039, train/raw-loss = 0.6933958530426025, train/logprobs = tensor([[-0.0775, -0.0750],
        [-0.0723, -0.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006206295220181346
Epoch 0, Step 74: train/loss = 0.6899714469909668, train/raw-loss = 0.6893863677978516, train/logprobs = tensor([[-0.0905, -0.1041],
        [-0.0959, -0.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005850295419804752
Epoch 0, Step 75: train/loss = 0.6912798881530762, train/raw-loss = 0.6906335353851318, train/logprobs = tensor([[-0.1950, -0.0696],
        [-0.2032, -0.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006463098106905818
Epoch 0, Step 76: train/loss = 0.6703238487243652, train/raw-loss = 0.6697500944137573, train/logprobs = tensor([[-0.0529, -0.2456],
        [-0.0519, -0.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005737100727856159
Epoch 0, Step 77: train/loss = 0.6916836500167847, train/raw-loss = 0.6910430788993835, train/logprobs = tensor([[-0.1170, -0.0828],
        [-0.1236, -0.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405629683285952
Epoch 0, Step 78: train/loss = 0.6907507181167603, train/raw-loss = 0.6902254819869995, train/logprobs = tensor([[-0.0722, -0.1308],
        [-0.0724, -0.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005252741975709796
Epoch 0, Step 79: train/loss = 0.675168514251709, train/raw-loss = 0.6745582222938538, train/logprobs = tensor([[-0.0770, -0.2482],
        [-0.0817, -0.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006103232735767961
Epoch 0, Step 80: train/loss = 0.6921684741973877, train/raw-loss = 0.6915329098701477, train/logprobs = tensor([[-0.1026, -0.0316],
        [-0.1017, -0.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006356158992275596
Epoch 0, Step 81: train/loss = 0.6877351999282837, train/raw-loss = 0.6871361136436462, train/logprobs = tensor([[-0.1211, -0.1657],
        [-0.1226, -0.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005990065401419997
Epoch 0, Step 82: train/loss = 0.689528226852417, train/raw-loss = 0.6889997124671936, train/logprobs = tensor([[-0.1206, -0.2333],
        [-0.1133, -0.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000528465723618865
Epoch 0, Step 83: train/loss = 0.6940674781799316, train/raw-loss = 0.6935333013534546, train/logprobs = tensor([[-0.0865, -0.1380],
        [-0.0838, -0.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005342393415048718
Epoch 0, Step 84: train/loss = 0.6862318515777588, train/raw-loss = 0.685613751411438, train/logprobs = tensor([[-0.0649, -0.0608],
        [-0.0769, -0.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006180249620229006
Epoch 0, Step 85: train/loss = 0.6874402761459351, train/raw-loss = 0.6867677569389343, train/logprobs = tensor([[-0.0703, -0.1342],
        [-0.0796, -0.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006725186249241233
Epoch 0, Step 86: train/loss = 0.6912344098091125, train/raw-loss = 0.6906501650810242, train/logprobs = tensor([[-0.0852, -0.0890],
        [-0.0837, -0.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005843036924488842
Epoch 0, Step 87: train/loss = 0.6899940371513367, train/raw-loss = 0.6893492937088013, train/logprobs = tensor([[-0.1138, -0.1444],
        [-0.1184, -0.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006447756313718855
Epoch 0, Step 88: train/loss = 0.6740212440490723, train/raw-loss = 0.6734548807144165, train/logprobs = tensor([[-0.0896, -0.2430],
        [-0.1030, -0.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005663955816999078
Epoch 0, Step 89: train/loss = 0.6903659701347351, train/raw-loss = 0.6897249817848206, train/logprobs = tensor([[-0.0874, -0.1113],
        [-0.0897, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006409119814634323
Epoch 0, Step 90: train/loss = 0.691120445728302, train/raw-loss = 0.6904714107513428, train/logprobs = tensor([[-0.0350, -0.1234],
        [-0.0363, -0.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006490874802693725
Epoch 0, Step 91: train/loss = 0.6915087699890137, train/raw-loss = 0.6907855272293091, train/logprobs = tensor([[-0.1074, -0.1933],
        [-0.1012, -0.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00072317267768085
Epoch 0, Step 92: train/loss = 0.6902852058410645, train/raw-loss = 0.6896255612373352, train/logprobs = tensor([[-0.1185, -0.1161],
        [-0.1223, -0.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006596696330234408
Epoch 0, Step 93: train/loss = 0.6803017258644104, train/raw-loss = 0.6796457767486572, train/logprobs = tensor([[-0.0567, -0.2216],
        [-0.0668, -0.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006559346220456064
Epoch 0, Step 94: train/loss = 0.6895900368690491, train/raw-loss = 0.6889292001724243, train/logprobs = tensor([[-0.2505, -0.1617],
        [-0.2548, -0.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006607716786675155
Epoch 0, Step 95: train/loss = 0.6940301060676575, train/raw-loss = 0.693476140499115, train/logprobs = tensor([[-0.0688, -0.0593],
        [-0.0652, -0.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005539772682823241
Epoch 0, Step 96: train/loss = 0.7010075449943542, train/raw-loss = 0.6938573122024536, train/logprobs = tensor([[-0.1172, -0.0948],
        [-0.1147, -0.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007150289602577686
Epoch 0, Step 97: train/loss = 0.6924108266830444, train/raw-loss = 0.6863982677459717, train/logprobs = tensor([[-0.0430, -0.1122],
        [-0.0473, -0.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060126218013465405
Epoch 0, Step 98: train/loss = 0.7022326588630676, train/raw-loss = 0.6926226615905762, train/logprobs = tensor([[-0.1314, -0.0576],
        [-0.1364, -0.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009609995409846306
Epoch 0, Step 99: train/loss = 0.7012999057769775, train/raw-loss = 0.6915931701660156, train/logprobs = tensor([[-0.1349, -0.0850],
        [-0.1305, -0.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009706725366413593
Epoch 0, Step 100: train/loss = 0.6866930723190308, train/raw-loss = 0.6770707368850708, train/logprobs = tensor([[-0.0584, -0.1110],
        [-0.0713, -0.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009622383862733841
Epoch 0, Step 101: train/loss = 0.6935884952545166, train/raw-loss = 0.6882867217063904, train/logprobs = tensor([[-0.0895, -0.1616],
        [-0.0970, -0.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005301774945110083
Epoch 0, Step 102: train/loss = 0.6988521814346313, train/raw-loss = 0.6912610530853271, train/logprobs = tensor([[-0.0395, -0.0547],
        [-0.0403, -0.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00759112136438489
Epoch 0, Step 103: train/loss = 0.6971176266670227, train/raw-loss = 0.6897392272949219, train/logprobs = tensor([[-0.1006, -0.0515],
        [-0.1037, -0.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007378346752375364
Epoch 0, Step 104: train/loss = 0.682257890701294, train/raw-loss = 0.6737287044525146, train/logprobs = tensor([[-0.2147, -0.2101],
        [-0.2324, -0.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008529184386134148
Epoch 0, Step 105: train/loss = 0.6976781487464905, train/raw-loss = 0.6885185241699219, train/logprobs = tensor([[-0.0548, -0.1479],
        [-0.0533, -0.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009159655310213566
Epoch 0, Step 106: train/loss = 0.6721128821372986, train/raw-loss = 0.6633027195930481, train/logprobs = tensor([[-0.0977, -0.4624],
        [-0.1138, -0.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008810171857476234
Epoch 0, Step 107: train/loss = 0.693164587020874, train/raw-loss = 0.6853485107421875, train/logprobs = tensor([[-0.0923, -0.1496],
        [-0.0990, -0.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007816026918590069
Epoch 0, Step 108: train/loss = 0.6984689831733704, train/raw-loss = 0.6914716362953186, train/logprobs = tensor([[-0.0639, -0.0630],
        [-0.0648, -0.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0069973343051970005
Epoch 0, Step 109: train/loss = 0.700059175491333, train/raw-loss = 0.6923285722732544, train/logprobs = tensor([[-0.1148, -0.0934],
        [-0.1275, -0.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007730599492788315
Epoch 0, Step 110: train/loss = 0.6706602573394775, train/raw-loss = 0.6629658341407776, train/logprobs = tensor([[-0.1179, -0.2485],
        [-0.1256, -0.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007694477215409279
Epoch 0, Step 111: train/loss = 0.6980581879615784, train/raw-loss = 0.6906751990318298, train/logprobs = tensor([[-0.0694, -0.0846],
        [-0.0694, -0.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073830243200063705
Epoch 0, Step 112: train/loss = 0.7068431377410889, train/raw-loss = 0.6961851716041565, train/logprobs = tensor([[-0.0515, -0.0819],
        [-0.0543, -0.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01065790094435215
Epoch 0, Step 113: train/loss = 0.6956291198730469, train/raw-loss = 0.6873157024383545, train/logprobs = tensor([[-0.1034, -0.1150],
        [-0.1055, -0.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008313441649079323
Epoch 0, Step 114: train/loss = 0.697032630443573, train/raw-loss = 0.6906012892723083, train/logprobs = tensor([[-0.1249, -0.0578],
        [-0.1336, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006431335583329201
Epoch 0, Step 115: train/loss = 0.6987172365188599, train/raw-loss = 0.6875969767570496, train/logprobs = tensor([[-0.1376, -0.0759],
        [-0.1429, -0.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011120254173874855
Epoch 0, Step 116: train/loss = 0.6942490339279175, train/raw-loss = 0.6881260871887207, train/logprobs = tensor([[-0.0994, -0.1830],
        [-0.0978, -0.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006122974678874016
Epoch 0, Step 117: train/loss = 0.6996302008628845, train/raw-loss = 0.6900413036346436, train/logprobs = tensor([[-0.0686, -0.0695],
        [-0.0770, -0.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009588929824531078
Epoch 0, Step 118: train/loss = 0.6996650695800781, train/raw-loss = 0.688248872756958, train/logprobs = tensor([[-0.0909, -0.0675],
        [-0.0974, -0.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011416209861636162
Epoch 0, Step 119: train/loss = 0.7005141377449036, train/raw-loss = 0.6910983920097351, train/logprobs = tensor([[-0.0624, -0.0939],
        [-0.0675, -0.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009415755979716778
Epoch 0, Step 120: train/loss = 0.7022147178649902, train/raw-loss = 0.6928786039352417, train/logprobs = tensor([[-0.0862, -0.0920],
        [-0.0903, -0.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009336069226264954
Epoch 0, Step 121: train/loss = 0.6898189783096313, train/raw-loss = 0.6829937696456909, train/logprobs = tensor([[-0.0954, -0.1385],
        [-0.0976, -0.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006825202144682407
Epoch 0, Step 122: train/loss = 0.6754169464111328, train/raw-loss = 0.6680656671524048, train/logprobs = tensor([[-0.2064, -0.1129],
        [-0.2881, -0.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007351346779614687
Epoch 0, Step 123: train/loss = 0.6978164315223694, train/raw-loss = 0.691106379032135, train/logprobs = tensor([[-0.0544, -0.0638],
        [-0.0551, -0.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006710045970976353
Epoch 0, Step 124: train/loss = 0.6972208023071289, train/raw-loss = 0.6917261481285095, train/logprobs = tensor([[-0.0789, -0.1081],
        [-0.0796, -0.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005494636483490467
Epoch 0, Step 125: train/loss = 0.6933596134185791, train/raw-loss = 0.6866258382797241, train/logprobs = tensor([[-0.1290, -0.2056],
        [-0.1341, -0.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006733776535838842
Epoch 0, Step 126: train/loss = 0.6964836120605469, train/raw-loss = 0.6900075674057007, train/logprobs = tensor([[-0.0528, -0.1482],
        [-0.0612, -0.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064760372042655945
Epoch 0, Step 127: train/loss = 0.6972440481185913, train/raw-loss = 0.6892588138580322, train/logprobs = tensor([[-0.1710, -0.1058],
        [-0.1756, -0.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007985291071236134
Epoch 0, Step 128: train/loss = 0.787605345249176, train/raw-loss = 0.690864086151123, train/logprobs = tensor([[-0.0557, -0.0612],
        [-0.0600, -0.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09674125909805298
Epoch 0, Step 129: train/loss = 0.9497076272964478, train/raw-loss = 0.6865311861038208, train/logprobs = tensor([[-0.0839, -0.1243],
        [-0.0899, -0.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26317644119262695
Epoch 0, Step 130: train/loss = 1.1139318943023682, train/raw-loss = 0.6915526390075684, train/logprobs = tensor([[-0.0847, -0.0589],
        [-0.0896, -0.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42237919569015503
Epoch 0, Step 131: train/loss = 1.0140182971954346, train/raw-loss = 0.6624844074249268, train/logprobs = tensor([[-0.1770, -0.2517],
        [-0.1978, -0.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351533979177475
Epoch 0, Step 132: train/loss = 0.8809372186660767, train/raw-loss = 0.6673175692558289, train/logprobs = tensor([[-0.1079, -0.4146],
        [-0.1130, -0.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21361960470676422
Epoch 0, Step 133: train/loss = 0.9824994802474976, train/raw-loss = 0.6921594142913818, train/logprobs = tensor([[-0.0523, -0.1160],
        [-0.0516, -0.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29034003615379333
Epoch 0, Step 134: train/loss = 1.1133695840835571, train/raw-loss = 0.6873100399971008, train/logprobs = tensor([[-0.0793, -0.0955],
        [-0.0784, -0.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4260596036911011
Epoch 0, Step 135: train/loss = 1.2429873943328857, train/raw-loss = 0.6950982809066772, train/logprobs = tensor([[-0.0536, -0.1132],
        [-0.0547, -0.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5478891730308533
Epoch 0, Step 136: train/loss = 1.2873520851135254, train/raw-loss = 0.6760857105255127, train/logprobs = tensor([[-0.0569, -0.2205],
        [-0.0671, -0.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6112663745880127
Epoch 0, Step 137: train/loss = 1.132623553276062, train/raw-loss = 0.6893314719200134, train/logprobs = tensor([[-0.1034, -0.1108],
        [-0.1070, -0.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44329214096069336
Epoch 0, Step 138: train/loss = 1.1012790203094482, train/raw-loss = 0.6864480972290039, train/logprobs = tensor([[-0.0644, -0.0976],
        [-0.0709, -0.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4148309826850891
Epoch 0, Step 139: train/loss = 0.962364912033081, train/raw-loss = 0.6742243766784668, train/logprobs = tensor([[-0.0774, -0.3360],
        [-0.0835, -0.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28814050555229187
Epoch 0, Step 140: train/loss = 0.8775067329406738, train/raw-loss = 0.6848964691162109, train/logprobs = tensor([[-0.0360, -0.1975],
        [-0.0425, -0.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926102340221405
Epoch 0, Step 141: train/loss = 0.8660060167312622, train/raw-loss = 0.6880874037742615, train/logprobs = tensor([[-0.0828, -0.1200],
        [-0.0895, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17791862785816193
Epoch 0, Step 142: train/loss = 0.9638024568557739, train/raw-loss = 0.6896594762802124, train/logprobs = tensor([[-0.0949, -0.1022],
        [-0.0961, -0.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27414295077323914
Epoch 0, Step 143: train/loss = 1.1247553825378418, train/raw-loss = 0.6961508989334106, train/logprobs = tensor([[-0.1013, -0.1003],
        [-0.1038, -0.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4286044239997864
Epoch 0, Step 144: train/loss = 1.0347890853881836, train/raw-loss = 0.6752323508262634, train/logprobs = tensor([[-0.0988, -0.2069],
        [-0.1051, -0.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35955679416656494
Epoch 0, Step 145: train/loss = 1.058329701423645, train/raw-loss = 0.6912955045700073, train/logprobs = tensor([[-0.0892, -0.0329],
        [-0.0930, -0.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36703410744667053
Epoch 0, Step 146: train/loss = 0.8616405725479126, train/raw-loss = 0.6766502857208252, train/logprobs = tensor([[-0.0485, -0.1565],
        [-0.0526, -0.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1849902868270874
Epoch 0, Step 147: train/loss = 1.1546167135238647, train/raw-loss = 0.688737690448761, train/logprobs = tensor([[-0.0889, -0.0740],
        [-0.0974, -0.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4658791124820709
Epoch 0, Step 148: train/loss = 0.8153725266456604, train/raw-loss = 0.6886678338050842, train/logprobs = tensor([[-0.1587, -0.1173],
        [-0.1675, -0.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12670475244522095
Epoch 0, Step 149: train/loss = 0.8062106966972351, train/raw-loss = 0.6871055960655212, train/logprobs = tensor([[-0.0619, -0.0683],
        [-0.0693, -0.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11910512298345566
Epoch 0, Step 150: train/loss = 0.8146765232086182, train/raw-loss = 0.6721314191818237, train/logprobs = tensor([[-0.0918, -0.1532],
        [-0.0988, -0.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14254510402679443
Epoch 0, Step 151: train/loss = 0.8967114090919495, train/raw-loss = 0.6867403984069824, train/logprobs = tensor([[-0.0546, -0.1295],
        [-0.0590, -0.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20997101068496704
Epoch 0, Step 152: train/loss = 0.8806570172309875, train/raw-loss = 0.6904215812683105, train/logprobs = tensor([[-0.1013, -0.0934],
        [-0.1038, -0.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190235435962677
Epoch 0, Step 153: train/loss = 1.0721617937088013, train/raw-loss = 0.6783086657524109, train/logprobs = tensor([[-0.0790, -0.1495],
        [-0.0860, -0.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3938531279563904
Epoch 0, Step 154: train/loss = 0.9417614340782166, train/raw-loss = 0.6930503249168396, train/logprobs = tensor([[-0.0865, -0.1061],
        [-0.0899, -0.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24871109426021576
Epoch 0, Step 155: train/loss = 0.9388036727905273, train/raw-loss = 0.6878305673599243, train/logprobs = tensor([[-0.1138, -0.0766],
        [-0.1172, -0.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250973105430603
Epoch 0, Step 156: train/loss = 0.8621808290481567, train/raw-loss = 0.6884081363677979, train/logprobs = tensor([[-0.0696, -0.1168],
        [-0.0714, -0.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17377275228500366
Epoch 0, Step 157: train/loss = 0.7233001589775085, train/raw-loss = 0.6911842823028564, train/logprobs = tensor([[-0.0715, -0.1397],
        [-0.0730, -0.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321158841252327
Epoch 0, Step 158: train/loss = 0.8561444282531738, train/raw-loss = 0.6890169382095337, train/logprobs = tensor([[-0.0864, -0.1089],
        [-0.0984, -0.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671275794506073
Epoch 0, Step 159: train/loss = 0.8258323669433594, train/raw-loss = 0.6916093230247498, train/logprobs = tensor([[-0.1039, -0.1264],
        [-0.1040, -0.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13422299921512604
Epoch 0, Step 160: train/loss = 0.7866519689559937, train/raw-loss = 0.6870343685150146, train/logprobs = tensor([[-0.1664, -0.1090],
        [-0.1648, -0.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996176153421402
Epoch 0, Step 161: train/loss = 0.7935782670974731, train/raw-loss = 0.6892862319946289, train/logprobs = tensor([[-0.0963, -0.2352],
        [-0.0986, -0.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10429201275110245
Epoch 0, Step 162: train/loss = 0.8300460577011108, train/raw-loss = 0.6546111106872559, train/logprobs = tensor([[-0.0784, -0.4048],
        [-0.0818, -0.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17543496191501617
Epoch 0, Step 163: train/loss = 0.8795323371887207, train/raw-loss = 0.6810337901115417, train/logprobs = tensor([[-0.0544, -0.1368],
        [-0.0596, -0.0929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19849848747253418
Epoch 0, Step 164: train/loss = 0.8472835421562195, train/raw-loss = 0.6740095019340515, train/logprobs = tensor([[-0.1004, -0.2079],
        [-0.1095, -0.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17327408492565155
Epoch 0, Step 165: train/loss = 0.9513243436813354, train/raw-loss = 0.6809848546981812, train/logprobs = tensor([[-0.1166, -0.1021],
        [-0.1345, -0.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703394293785095
Epoch 0, Step 166: train/loss = 1.0102519989013672, train/raw-loss = 0.6371161937713623, train/logprobs = tensor([[-0.1158, -0.4013],
        [-0.1275, -0.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731358051300049
Epoch 0, Step 167: train/loss = 0.8863092660903931, train/raw-loss = 0.686668872833252, train/logprobs = tensor([[-0.0539, -0.1248],
        [-0.0559, -0.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996404081583023
Epoch 0, Step 168: train/loss = 0.8606948852539062, train/raw-loss = 0.6819556951522827, train/logprobs = tensor([[-0.0991, -0.1153],
        [-0.1354, -0.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17873919010162354
Epoch 0, Step 169: train/loss = 0.7837793827056885, train/raw-loss = 0.6889367699623108, train/logprobs = tensor([[-0.1242, -0.0912],
        [-0.1346, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484262764453888
Epoch 0, Step 170: train/loss = 0.9886307120323181, train/raw-loss = 0.6901514530181885, train/logprobs = tensor([[-0.1046, -0.0735],
        [-0.1022, -0.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29847922921180725
Epoch 0, Step 171: train/loss = 0.820117175579071, train/raw-loss = 0.6886789798736572, train/logprobs = tensor([[-0.0864, -0.0696],
        [-0.0969, -0.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13143818080425262
Epoch 0, Step 172: train/loss = 0.962776243686676, train/raw-loss = 0.6780771017074585, train/logprobs = tensor([[-0.0660, -0.1797],
        [-0.0714, -0.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846991717815399
Epoch 0, Step 173: train/loss = 1.035639762878418, train/raw-loss = 0.6655359268188477, train/logprobs = tensor([[-0.2740, -0.2353],
        [-0.2902, -0.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701038360595703
Epoch 0, Step 174: train/loss = 0.8698316812515259, train/raw-loss = 0.6818364858627319, train/logprobs = tensor([[-0.0682, -0.2226],
        [-0.0804, -0.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18799513578414917
Epoch 0, Step 175: train/loss = 1.0721008777618408, train/raw-loss = 0.6639330387115479, train/logprobs = tensor([[-0.0906, -0.2174],
        [-0.1060, -0.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081678092479706
Epoch 0, Step 176: train/loss = 0.8736059665679932, train/raw-loss = 0.6763859987258911, train/logprobs = tensor([[-0.0958, -0.1905],
        [-0.1061, -0.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19721993803977966
Epoch 0, Step 177: train/loss = 0.8669079542160034, train/raw-loss = 0.6795737743377686, train/logprobs = tensor([[-0.0646, -0.2054],
        [-0.0683, -0.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18733417987823486
Epoch 0, Step 178: train/loss = 0.7972373962402344, train/raw-loss = 0.6767755150794983, train/logprobs = tensor([[-0.0799, -0.3575],
        [-0.0903, -0.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12046189606189728
Epoch 0, Step 179: train/loss = 0.9238188862800598, train/raw-loss = 0.6864286661148071, train/logprobs = tensor([[-0.1118, -0.0719],
        [-0.1196, -0.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23739022016525269
Epoch 0, Step 180: train/loss = 0.7523050308227539, train/raw-loss = 0.6906198859214783, train/logprobs = tensor([[-0.1207, -0.1924],
        [-0.1270, -0.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06168515980243683
Epoch 0, Step 181: train/loss = 0.8722714781761169, train/raw-loss = 0.6858773231506348, train/logprobs = tensor([[-0.1337, -0.0833],
        [-0.1377, -0.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863941252231598
Epoch 0, Step 182: train/loss = 0.9210904836654663, train/raw-loss = 0.6925549507141113, train/logprobs = tensor([[-0.0834, -0.0328],
        [-0.0803, -0.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.228535458445549
Epoch 0, Step 183: train/loss = 0.9554580450057983, train/raw-loss = 0.6904430389404297, train/logprobs = tensor([[-0.1005, -0.0511],
        [-0.1075, -0.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26501497626304626
Epoch 0, Step 184: train/loss = 0.9252590537071228, train/raw-loss = 0.6660988926887512, train/logprobs = tensor([[-0.1161, -0.2444],
        [-0.1194, -0.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591601312160492
Epoch 0, Step 185: train/loss = 0.7613793611526489, train/raw-loss = 0.67319655418396, train/logprobs = tensor([[-0.0812, -0.2185],
        [-0.1062, -0.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08818291127681732
Epoch 0, Step 186: train/loss = 0.8280707597732544, train/raw-loss = 0.6878877878189087, train/logprobs = tensor([[-0.0796, -0.1071],
        [-0.0823, -0.0886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14018294215202332
Epoch 0, Step 187: train/loss = 0.9939314723014832, train/raw-loss = 0.6818985939025879, train/logprobs = tensor([[-0.0531, -0.1350],
        [-0.0547, -0.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31203287839889526
Epoch 0, Step 188: train/loss = 0.8642441034317017, train/raw-loss = 0.6627442240715027, train/logprobs = tensor([[-0.0954, -0.5691],
        [-0.1092, -0.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014998197555542
Epoch 0, Step 189: train/loss = 0.7440577745437622, train/raw-loss = 0.6902071237564087, train/logprobs = tensor([[-0.0830, -0.1095],
        [-0.0852, -0.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053850673139095306
Epoch 0, Step 190: train/loss = 0.795671820640564, train/raw-loss = 0.6663179993629456, train/logprobs = tensor([[-0.1110, -0.2431],
        [-0.1213, -0.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293538361787796
Epoch 0, Step 191: train/loss = 0.868948221206665, train/raw-loss = 0.690491259098053, train/logprobs = tensor([[-0.0928, -0.0384],
        [-0.1028, -0.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17845702171325684
Epoch 0, Step 192: train/loss = 0.8291025161743164, train/raw-loss = 0.6856091022491455, train/logprobs = tensor([[-0.1388, -0.0503],
        [-0.1525, -0.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434934437274933
Epoch 0, Step 193: train/loss = 0.8352952599525452, train/raw-loss = 0.6737264394760132, train/logprobs = tensor([[-0.1429, -0.1352],
        [-0.1570, -0.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1615687608718872
Epoch 0, Step 194: train/loss = 0.8149759769439697, train/raw-loss = 0.669701099395752, train/logprobs = tensor([[-0.0795, -0.1468],
        [-0.0935, -0.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14527489244937897
Epoch 0, Step 195: train/loss = 0.8145977258682251, train/raw-loss = 0.6855627298355103, train/logprobs = tensor([[-0.0854, -0.1394],
        [-0.0867, -0.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12903496623039246
Epoch 0, Step 196: train/loss = 0.7960124015808105, train/raw-loss = 0.6804576516151428, train/logprobs = tensor([[-0.1437, -0.1392],
        [-0.1582, -0.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11555475741624832
Epoch 0, Step 197: train/loss = 0.8579359650611877, train/raw-loss = 0.6944056749343872, train/logprobs = tensor([[-0.0893, -0.4257],
        [-0.1007, -0.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16353029012680054
Epoch 0, Step 198: train/loss = 0.8280438184738159, train/raw-loss = 0.68989098072052, train/logprobs = tensor([[-0.1214, -0.1104],
        [-0.1305, -0.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13815288245677948
Epoch 0, Step 199: train/loss = 0.8909881711006165, train/raw-loss = 0.6817386746406555, train/logprobs = tensor([[-0.0332, -0.0922],
        [-0.0422, -0.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20924949645996094
Epoch 0, Step 200: train/loss = 0.7865331172943115, train/raw-loss = 0.669680655002594, train/logprobs = tensor([[-0.1211, -0.1676],
        [-0.1429, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685243248939514
Epoch 0, Step 201: train/loss = 0.7995238304138184, train/raw-loss = 0.6527637243270874, train/logprobs = tensor([[-0.1215, -0.1972],
        [-0.1467, -0.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14676015079021454
Epoch 0, Step 202: train/loss = 0.8068312406539917, train/raw-loss = 0.6878392696380615, train/logprobs = tensor([[-0.1027, -0.1011],
        [-0.1053, -0.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11899203062057495
Epoch 0, Step 203: train/loss = 0.834453821182251, train/raw-loss = 0.6843893527984619, train/logprobs = tensor([[-0.0662, -0.0940],
        [-0.0711, -0.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15006445348262787
Epoch 0, Step 204: train/loss = 0.842858612537384, train/raw-loss = 0.6749482750892639, train/logprobs = tensor([[-0.0963, -0.1716],
        [-0.1407, -0.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1679103821516037
Epoch 0, Step 205: train/loss = 0.8969257473945618, train/raw-loss = 0.6769693493843079, train/logprobs = tensor([[-0.0980, -0.1457],
        [-0.1080, -0.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2199564278125763
Epoch 0, Step 206: train/loss = 0.8439210653305054, train/raw-loss = 0.6447993516921997, train/logprobs = tensor([[-0.0660, -0.6055],
        [-0.0752, -0.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19912174344062805
Epoch 0, Step 207: train/loss = 0.8433406949043274, train/raw-loss = 0.6792612075805664, train/logprobs = tensor([[-0.0846, -0.1066],
        [-0.1019, -0.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640794724225998
Epoch 0, Step 208: train/loss = 0.8335564136505127, train/raw-loss = 0.6612021923065186, train/logprobs = tensor([[-0.0612, -0.2317],
        [-0.0624, -0.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17235422134399414
Epoch 0, Step 209: train/loss = 0.8179819583892822, train/raw-loss = 0.6815448999404907, train/logprobs = tensor([[-0.1040, -0.0653],
        [-0.1378, -0.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13643701374530792
Epoch 0, Step 210: train/loss = 0.8638560771942139, train/raw-loss = 0.6842560768127441, train/logprobs = tensor([[-0.0657, -0.1021],
        [-0.0691, -0.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17960000038146973
Epoch 0, Step 211: train/loss = 0.7668957114219666, train/raw-loss = 0.6623411178588867, train/logprobs = tensor([[-0.0451, -0.3175],
        [-0.0523, -0.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10455458611249924
Epoch 0, Step 212: train/loss = 0.811069667339325, train/raw-loss = 0.6919745206832886, train/logprobs = tensor([[-0.0618, -0.0695],
        [-0.0610, -0.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11909511685371399
Epoch 0, Step 213: train/loss = 0.8018483519554138, train/raw-loss = 0.6897100806236267, train/logprobs = tensor([[-0.0807, -0.1574],
        [-0.0784, -0.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121383011341095
Epoch 0, Step 214: train/loss = 0.8618901968002319, train/raw-loss = 0.6719226837158203, train/logprobs = tensor([[-0.0742, -0.1865],
        [-0.0781, -0.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18996748328208923
Epoch 0, Step 215: train/loss = 0.7924250364303589, train/raw-loss = 0.6799924969673157, train/logprobs = tensor([[-0.1424, -0.1005],
        [-0.1746, -0.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243253946304321
Epoch 0, Step 216: train/loss = 0.7681412100791931, train/raw-loss = 0.6795942783355713, train/logprobs = tensor([[-0.1335, -0.1513],
        [-0.1469, -0.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854696899652481
Epoch 0, Step 217: train/loss = 0.8000791668891907, train/raw-loss = 0.6776578426361084, train/logprobs = tensor([[-0.1893, -0.1785],
        [-0.1973, -0.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1224212646484375
Epoch 0, Step 218: train/loss = 0.7580358982086182, train/raw-loss = 0.6844898462295532, train/logprobs = tensor([[-0.1612, -0.0893],
        [-0.1733, -0.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07354611158370972
Epoch 0, Step 219: train/loss = 0.8311488628387451, train/raw-loss = 0.6797962188720703, train/logprobs = tensor([[-0.0727, -0.0876],
        [-0.0885, -0.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513526886701584
Epoch 0, Step 220: train/loss = 0.7901326417922974, train/raw-loss = 0.6667612791061401, train/logprobs = tensor([[-0.2112, -0.2042],
        [-0.2351, -0.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12337136268615723
Epoch 0, Step 221: train/loss = 0.8633924722671509, train/raw-loss = 0.662894606590271, train/logprobs = tensor([[-0.0700, -0.2149],
        [-0.0873, -0.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2004978209733963
Epoch 0, Step 222: train/loss = 0.8072798252105713, train/raw-loss = 0.6718391180038452, train/logprobs = tensor([[-0.1267, -0.1525],
        [-0.1681, -0.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13544075191020966
Epoch 0, Step 223: train/loss = 0.8019415140151978, train/raw-loss = 0.6685830354690552, train/logprobs = tensor([[-0.0734, -0.2538],
        [-0.0769, -0.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13335853815078735
Epoch 0, Step 224: train/loss = 0.787460207939148, train/raw-loss = 0.6834043264389038, train/logprobs = tensor([[-0.0536, -0.0665],
        [-0.0685, -0.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10405585169792175
Epoch 0, Step 225: train/loss = 0.7972161769866943, train/raw-loss = 0.6838169693946838, train/logprobs = tensor([[-0.0813, -0.0557],
        [-0.0892, -0.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11339914798736572
Epoch 0, Step 226: train/loss = 0.7684104442596436, train/raw-loss = 0.6519280672073364, train/logprobs = tensor([[-0.0591, -0.2398],
        [-0.0862, -0.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11648236960172653
Epoch 0, Step 227: train/loss = 0.7921205759048462, train/raw-loss = 0.6560847163200378, train/logprobs = tensor([[-0.1268, -0.1685],
        [-0.1904, -0.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13603582978248596
Epoch 0, Step 228: train/loss = 0.8424156308174133, train/raw-loss = 0.6888600587844849, train/logprobs = tensor([[-0.0508, -0.2146],
        [-0.0497, -0.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15355557203292847
Epoch 0, Step 229: train/loss = 0.7709071040153503, train/raw-loss = 0.6344867944717407, train/logprobs = tensor([[-0.0563, -0.4719],
        [-0.0665, -0.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13642027974128723
Epoch 0, Step 230: train/loss = 0.8020879030227661, train/raw-loss = 0.6698839664459229, train/logprobs = tensor([[-0.0581, -0.1448],
        [-0.0695, -0.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13220390677452087
Epoch 0, Step 231: train/loss = 0.7969441413879395, train/raw-loss = 0.6763489246368408, train/logprobs = tensor([[-0.0761, -0.1115],
        [-0.0985, -0.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12059521675109863
Epoch 0, Step 232: train/loss = 0.8112216591835022, train/raw-loss = 0.6549817323684692, train/logprobs = tensor([[-0.1031, -0.2633],
        [-0.1061, -0.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15623997151851654
Epoch 0, Step 233: train/loss = 0.7710660696029663, train/raw-loss = 0.6405686140060425, train/logprobs = tensor([[-0.1044, -0.3773],
        [-0.1137, -0.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1304975301027298
Epoch 0, Step 234: train/loss = 0.8528560400009155, train/raw-loss = 0.6849303245544434, train/logprobs = tensor([[-0.0872, -0.1836],
        [-0.0966, -0.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16792574524879456
Epoch 0, Step 235: train/loss = 0.7864055633544922, train/raw-loss = 0.6688099503517151, train/logprobs = tensor([[-0.0563, -0.5327],
        [-0.0803, -0.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11759565025568008
Epoch 0, Step 236: train/loss = 0.7808728218078613, train/raw-loss = 0.6827750205993652, train/logprobs = tensor([[-0.0505, -0.1459],
        [-0.0560, -0.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09809784591197968
Epoch 0, Step 237: train/loss = 0.7574382424354553, train/raw-loss = 0.6868667006492615, train/logprobs = tensor([[-0.0657, -0.2132],
        [-0.0597, -0.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07057145982980728
Epoch 0, Step 238: train/loss = 0.8330535292625427, train/raw-loss = 0.6710885763168335, train/logprobs = tensor([[-0.1034, -0.1840],
        [-0.1303, -0.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196493804454803
Epoch 0, Step 239: train/loss = 0.7565175294876099, train/raw-loss = 0.685401439666748, train/logprobs = tensor([[-0.1009, -0.1744],
        [-0.1110, -0.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0711161270737648
Epoch 0, Step 240: train/loss = 0.7377965450286865, train/raw-loss = 0.6798794269561768, train/logprobs = tensor([[-0.0787, -0.3617],
        [-0.0778, -0.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791721120476723
Epoch 0, Step 241: train/loss = 0.836479902267456, train/raw-loss = 0.680574357509613, train/logprobs = tensor([[-0.0427, -0.1344],
        [-0.0492, -0.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15590554475784302
Epoch 0, Step 242: train/loss = 0.795881986618042, train/raw-loss = 0.6857390403747559, train/logprobs = tensor([[-0.0432, -0.1626],
        [-0.0492, -0.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11014290153980255
Epoch 0, Step 243: train/loss = 0.7553790807723999, train/raw-loss = 0.689286470413208, train/logprobs = tensor([[-0.1127, -0.1080],
        [-0.1147, -0.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06609262526035309
Epoch 0, Step 244: train/loss = 0.7658462524414062, train/raw-loss = 0.6594865322113037, train/logprobs = tensor([[-0.1118, -0.2364],
        [-0.1367, -0.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10635973513126373
Epoch 0, Step 245: train/loss = 0.7671583890914917, train/raw-loss = 0.6728586554527283, train/logprobs = tensor([[-0.0598, -0.4119],
        [-0.0853, -0.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09429974853992462
Epoch 0, Step 246: train/loss = 0.8057123422622681, train/raw-loss = 0.6707545518875122, train/logprobs = tensor([[-0.0700, -0.1179],
        [-0.0933, -0.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349577158689499
Epoch 0, Step 247: train/loss = 0.7519099116325378, train/raw-loss = 0.6617230176925659, train/logprobs = tensor([[-0.1327, -0.1077],
        [-0.2116, -0.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09018686413764954
Epoch 0, Step 248: train/loss = 0.7794781923294067, train/raw-loss = 0.684660792350769, train/logprobs = tensor([[-0.0735, -0.2510],
        [-0.0929, -0.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0948173850774765
Epoch 0, Step 249: train/loss = 0.8262717723846436, train/raw-loss = 0.6750588417053223, train/logprobs = tensor([[-0.0857, -0.1123],
        [-0.0965, -0.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15121296048164368
Epoch 0, Step 250: train/loss = 0.8368074297904968, train/raw-loss = 0.6737022399902344, train/logprobs = tensor([[-0.0716, -0.1705],
        [-0.1086, -0.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16310511529445648
Epoch 0, Step 251: train/loss = 0.8027727603912354, train/raw-loss = 0.6796659231185913, train/logprobs = tensor([[-0.0728, -0.2016],
        [-0.0863, -0.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12310688942670822
Epoch 0, Step 252: train/loss = 0.8202223777770996, train/raw-loss = 0.6918540000915527, train/logprobs = tensor([[-0.0563, -0.0817],
        [-0.0585, -0.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836839258670807
Epoch 0, Step 253: train/loss = 0.7853147983551025, train/raw-loss = 0.6899595260620117, train/logprobs = tensor([[-0.2004, -0.0734],
        [-0.2171, -0.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09535536915063858
Epoch 0, Step 254: train/loss = 0.7939156293869019, train/raw-loss = 0.6704201698303223, train/logprobs = tensor([[-0.1160, -0.1784],
        [-0.1536, -0.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12349549680948257
Epoch 0, Step 255: train/loss = 0.7873322367668152, train/raw-loss = 0.6843811273574829, train/logprobs = tensor([[-0.1187, -0.1299],
        [-0.1256, -0.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295116901397705
Epoch 0, Step 256: train/loss = 0.7387600541114807, train/raw-loss = 0.6888518333435059, train/logprobs = tensor([[-0.1522, -0.1746],
        [-0.1670, -0.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04990827292203903
Epoch 0, Step 257: train/loss = 0.7589384317398071, train/raw-loss = 0.6769539713859558, train/logprobs = tensor([[-0.0643, -0.1274],
        [-0.0767, -0.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819844901561737
Epoch 0, Step 258: train/loss = 0.7897363901138306, train/raw-loss = 0.6583300232887268, train/logprobs = tensor([[-0.0795, -0.1998],
        [-0.1165, -0.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13140633702278137
Epoch 0, Step 259: train/loss = 0.7049969434738159, train/raw-loss = 0.6299036741256714, train/logprobs = tensor([[-0.0898, -0.4247],
        [-0.1111, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07509323954582214
Epoch 0, Step 260: train/loss = 0.7805784940719604, train/raw-loss = 0.6376365423202515, train/logprobs = tensor([[-0.1106, -0.3913],
        [-0.1212, -0.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14294199645519257
Epoch 0, Step 261: train/loss = 0.7510499954223633, train/raw-loss = 0.6712971329689026, train/logprobs = tensor([[-0.0922, -0.2241],
        [-0.1036, -0.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07975287735462189
Epoch 0, Step 262: train/loss = 0.7615002393722534, train/raw-loss = 0.6486269235610962, train/logprobs = tensor([[-0.0524, -0.2817],
        [-0.0722, -0.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128733903169632
Epoch 0, Step 263: train/loss = 0.7139475345611572, train/raw-loss = 0.6708755493164062, train/logprobs = tensor([[-0.1254, -0.1235],
        [-0.1443, -0.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04307199642062187
Epoch 0, Step 264: train/loss = 0.7209938168525696, train/raw-loss = 0.6723244786262512, train/logprobs = tensor([[-0.1031, -0.1304],
        [-0.1310, -0.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048669349402189255
Epoch 0, Step 265: train/loss = 0.7388173341751099, train/raw-loss = 0.6876809597015381, train/logprobs = tensor([[-0.0572, -0.1031],
        [-0.0600, -0.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05113634094595909
Epoch 0, Step 266: train/loss = 0.7528460621833801, train/raw-loss = 0.6685003638267517, train/logprobs = tensor([[-0.1362, -0.1700],
        [-0.1879, -0.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08434571325778961
Epoch 0, Step 267: train/loss = 0.828650951385498, train/raw-loss = 0.6673296093940735, train/logprobs = tensor([[-0.1073, -0.2444],
        [-0.1107, -0.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16132137179374695
Epoch 0, Step 268: train/loss = 0.759822428226471, train/raw-loss = 0.6357437372207642, train/logprobs = tensor([[-0.0389, -0.4166],
        [-0.0452, -0.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407870590686798
Epoch 0, Step 269: train/loss = 0.7643145322799683, train/raw-loss = 0.6432585716247559, train/logprobs = tensor([[-0.1370, -0.3642],
        [-0.1510, -0.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12105594575405121
Epoch 0, Step 270: train/loss = 0.8751053810119629, train/raw-loss = 0.6756811141967773, train/logprobs = tensor([[-0.0816, -0.1407],
        [-0.0858, -0.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19942425191402435
Epoch 0, Step 271: train/loss = 0.7394601106643677, train/raw-loss = 0.670760989189148, train/logprobs = tensor([[-0.0757, -0.1420],
        [-0.1064, -0.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06869900226593018
Epoch 0, Step 272: train/loss = 0.7531483769416809, train/raw-loss = 0.6868469715118408, train/logprobs = tensor([[-0.0802, -0.0408],
        [-0.1015, -0.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06630134582519531
Epoch 0, Step 273: train/loss = 0.7822318077087402, train/raw-loss = 0.6851323843002319, train/logprobs = tensor([[-0.0805, -0.1171],
        [-0.0824, -0.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09709949791431427
Epoch 0, Step 274: train/loss = 0.7846351861953735, train/raw-loss = 0.6862032413482666, train/logprobs = tensor([[-0.0754, -0.1105],
        [-0.0931, -0.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843198210000992
Epoch 0, Step 275: train/loss = 0.8243216276168823, train/raw-loss = 0.6818180084228516, train/logprobs = tensor([[-0.0961, -0.0931],
        [-0.1127, -0.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142503559589386
Epoch 0, Step 276: train/loss = 0.8062247633934021, train/raw-loss = 0.6823402643203735, train/logprobs = tensor([[-0.1659, -0.1577],
        [-0.1855, -0.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12388449162244797
Epoch 0, Step 277: train/loss = 0.7565571069717407, train/raw-loss = 0.6787751913070679, train/logprobs = tensor([[-0.1004, -0.2032],
        [-0.1066, -0.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07778192311525345
Epoch 0, Step 278: train/loss = 0.7574350833892822, train/raw-loss = 0.6755114793777466, train/logprobs = tensor([[-0.1252, -0.1252],
        [-0.1477, -0.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192367106676102
Epoch 0, Step 279: train/loss = 0.7312880754470825, train/raw-loss = 0.6500185132026672, train/logprobs = tensor([[-0.1024, -0.1648],
        [-0.2025, -0.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08126956224441528
Epoch 0, Step 280: train/loss = 0.7545664310455322, train/raw-loss = 0.662002682685852, train/logprobs = tensor([[-0.0859, -0.2584],
        [-0.0874, -0.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256374835968018
Epoch 0, Step 281: train/loss = 0.7685117125511169, train/raw-loss = 0.6820629239082336, train/logprobs = tensor([[-0.0532, -0.1472],
        [-0.0552, -0.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0864487737417221
Epoch 0, Step 282: train/loss = 0.7551148533821106, train/raw-loss = 0.6732050180435181, train/logprobs = tensor([[-0.1382, -0.1934],
        [-0.1627, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190983533859253
Epoch 0, Step 283: train/loss = 0.8065569400787354, train/raw-loss = 0.6546686887741089, train/logprobs = tensor([[-0.0467, -0.3270],
        [-0.0785, -0.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15188828110694885
Epoch 0, Step 284: train/loss = 0.8259609341621399, train/raw-loss = 0.6923109889030457, train/logprobs = tensor([[-0.0760, -0.1287],
        [-0.0837, -0.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364994525909424
Epoch 0, Step 285: train/loss = 0.7461417317390442, train/raw-loss = 0.6893113255500793, train/logprobs = tensor([[-0.0693, -0.1285],
        [-0.0794, -0.1230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05683040991425514
Epoch 0, Step 286: train/loss = 0.8144756555557251, train/raw-loss = 0.6756184101104736, train/logprobs = tensor([[-0.0498, -0.1677],
        [-0.0529, -0.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885723054409027
Epoch 0, Step 287: train/loss = 0.7580726146697998, train/raw-loss = 0.6871259212493896, train/logprobs = tensor([[-0.0920, -0.3032],
        [-0.0941, -0.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094662636518478
Epoch 0, Step 288: train/loss = 0.7645928859710693, train/raw-loss = 0.6469238996505737, train/logprobs = tensor([[-0.1227, -0.3034],
        [-0.1465, -0.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11766896396875381
Epoch 0, Step 289: train/loss = 0.773769199848175, train/raw-loss = 0.6854813098907471, train/logprobs = tensor([[-0.0715, -0.1575],
        [-0.0716, -0.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08828790485858917
Epoch 0, Step 290: train/loss = 0.785232663154602, train/raw-loss = 0.6849216818809509, train/logprobs = tensor([[-0.0792, -0.0998],
        [-0.0902, -0.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10031096637248993
Epoch 0, Step 291: train/loss = 0.7623511552810669, train/raw-loss = 0.6669172644615173, train/logprobs = tensor([[-0.1284, -0.1571],
        [-0.1553, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09543392807245255
Epoch 0, Step 292: train/loss = 0.750984787940979, train/raw-loss = 0.6852604746818542, train/logprobs = tensor([[-0.0675, -0.2251],
        [-0.0707, -0.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06572424620389938
Epoch 0, Step 293: train/loss = 0.7550734877586365, train/raw-loss = 0.6768200397491455, train/logprobs = tensor([[-0.0436, -0.0988],
        [-0.0610, -0.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07825351506471634
Epoch 0, Step 294: train/loss = 0.7556161880493164, train/raw-loss = 0.6672343015670776, train/logprobs = tensor([[-0.1517, -0.1589],
        [-0.2123, -0.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08838193863630295
Epoch 0, Step 295: train/loss = 0.7530313730239868, train/raw-loss = 0.6471349000930786, train/logprobs = tensor([[-0.0522, -0.2959],
        [-0.0674, -0.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058964803814888
Epoch 0, Step 296: train/loss = 0.7521399259567261, train/raw-loss = 0.6486372947692871, train/logprobs = tensor([[-0.0858, -0.3161],
        [-0.1147, -0.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350269079208374
Epoch 0, Step 297: train/loss = 0.742455244064331, train/raw-loss = 0.6472569108009338, train/logprobs = tensor([[-0.0780, -0.3231],
        [-0.0889, -0.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519831836223602
Epoch 0, Step 298: train/loss = 0.7970137000083923, train/raw-loss = 0.6823975443840027, train/logprobs = tensor([[-0.0912, -0.1389],
        [-0.1137, -0.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11461615562438965
Epoch 0, Step 299: train/loss = 0.7281826734542847, train/raw-loss = 0.6629139184951782, train/logprobs = tensor([[-0.1149, -0.1353],
        [-0.1531, -0.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06526876240968704
Epoch 0, Step 300: train/loss = 0.7206933498382568, train/raw-loss = 0.6549772024154663, train/logprobs = tensor([[-0.0891, -0.2018],
        [-0.1334, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06571612507104874
Epoch 0, Step 301: train/loss = 0.7513374090194702, train/raw-loss = 0.6841639876365662, train/logprobs = tensor([[-0.1209, -0.0951],
        [-0.1508, -0.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06717344373464584
Epoch 0, Step 302: train/loss = 0.7614449262619019, train/raw-loss = 0.6728063821792603, train/logprobs = tensor([[-0.1234, -0.2139],
        [-0.1315, -0.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08863859623670578
Epoch 0, Step 303: train/loss = 0.7814884185791016, train/raw-loss = 0.6729689836502075, train/logprobs = tensor([[-0.0844, -0.1791],
        [-0.1099, -0.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10851947218179703
Epoch 0, Step 304: train/loss = 0.7609118223190308, train/raw-loss = 0.6887852549552917, train/logprobs = tensor([[-0.0881, -0.1279],
        [-0.0956, -0.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07212647050619125
Epoch 0, Step 305: train/loss = 0.7317962646484375, train/raw-loss = 0.6405588984489441, train/logprobs = tensor([[-0.1108, -0.3030],
        [-0.1358, -0.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09123732149600983
Epoch 0, Step 306: train/loss = 0.6882006525993347, train/raw-loss = 0.6291564106941223, train/logprobs = tensor([[-0.0770, -0.3780],
        [-0.0987, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05904422700405121
Epoch 0, Step 307: train/loss = 0.7106040716171265, train/raw-loss = 0.6476422548294067, train/logprobs = tensor([[-0.1356, -0.3003],
        [-0.1515, -0.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06296180933713913
Epoch 0, Step 308: train/loss = 0.7456730604171753, train/raw-loss = 0.6737319231033325, train/logprobs = tensor([[-0.1082, -0.3177],
        [-0.1419, -0.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719410851597786
Epoch 0, Step 309: train/loss = 0.8069050312042236, train/raw-loss = 0.6934803128242493, train/logprobs = tensor([[-0.0784, -0.1275],
        [-0.0880, -0.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342476308345795
Epoch 0, Step 310: train/loss = 0.7667679786682129, train/raw-loss = 0.6431261301040649, train/logprobs = tensor([[-0.0534, -0.2604],
        [-0.0734, -0.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364182621240616
Epoch 0, Step 311: train/loss = 0.7576890587806702, train/raw-loss = 0.6912841796875, train/logprobs = tensor([[-0.0490, -0.2502],
        [-0.0599, -0.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640487909317017
Epoch 0, Step 312: train/loss = 0.6843520402908325, train/raw-loss = 0.6388784646987915, train/logprobs = tensor([[-0.0526, -0.3006],
        [-0.0910, -0.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04547365754842758
Epoch 0, Step 313: train/loss = 0.7740733027458191, train/raw-loss = 0.6569513082504272, train/logprobs = tensor([[-0.0693, -0.2028],
        [-0.0862, -0.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11712196469306946
Epoch 0, Step 314: train/loss = 0.7408865690231323, train/raw-loss = 0.683936595916748, train/logprobs = tensor([[-0.1042, -0.1261],
        [-0.1270, -0.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05695003271102905
Epoch 0, Step 315: train/loss = 0.7644193768501282, train/raw-loss = 0.6660321950912476, train/logprobs = tensor([[-0.2055, -0.2397],
        [-0.2500, -0.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09838713705539703
Epoch 0, Step 316: train/loss = 0.7207997441291809, train/raw-loss = 0.6911864876747131, train/logprobs = tensor([[-0.0442, -0.0703],
        [-0.0464, -0.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029613252729177475
Epoch 0, Step 317: train/loss = 0.8040534853935242, train/raw-loss = 0.6718271374702454, train/logprobs = tensor([[-0.0750, -0.1502],
        [-0.0837, -0.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322263479232788
Epoch 0, Step 318: train/loss = 0.7883090972900391, train/raw-loss = 0.6736752986907959, train/logprobs = tensor([[-0.0811, -0.1077],
        [-0.0897, -0.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11463379859924316
Epoch 0, Step 319: train/loss = 0.7913984060287476, train/raw-loss = 0.6812000274658203, train/logprobs = tensor([[-0.0534, -0.1131],
        [-0.0603, -0.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11019830405712128
Epoch 0, Step 320: train/loss = 0.720146656036377, train/raw-loss = 0.6481572389602661, train/logprobs = tensor([[-0.0830, -0.2110],
        [-0.1148, -0.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07198943942785263
Epoch 0, Step 321: train/loss = 0.7477099299430847, train/raw-loss = 0.6821297407150269, train/logprobs = tensor([[-0.0746, -0.1969],
        [-0.0903, -0.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06558011472225189
Epoch 0, Step 322: train/loss = 0.7500120997428894, train/raw-loss = 0.6644091606140137, train/logprobs = tensor([[-0.1697, -0.3553],
        [-0.1809, -0.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08560290932655334
Epoch 0, Step 323: train/loss = 0.7332362532615662, train/raw-loss = 0.651403546333313, train/logprobs = tensor([[-0.0601, -0.3647],
        [-0.0735, -0.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08183270692825317
Epoch 0, Step 324: train/loss = 0.7368494868278503, train/raw-loss = 0.6217437982559204, train/logprobs = tensor([[-0.0848, -0.5662],
        [-0.0924, -0.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11510567367076874
Epoch 0, Step 325: train/loss = 0.7488878965377808, train/raw-loss = 0.6851372718811035, train/logprobs = tensor([[-0.0601, -0.1594],
        [-0.0754, -0.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06375059485435486
Epoch 0, Step 326: train/loss = 0.7177315950393677, train/raw-loss = 0.6341609954833984, train/logprobs = tensor([[-0.1056, -0.4052],
        [-0.1092, -0.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08357056975364685
Epoch 0, Step 327: train/loss = 0.7216252684593201, train/raw-loss = 0.691042959690094, train/logprobs = tensor([[-0.0588, -0.0882],
        [-0.0586, -0.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03058236464858055
Epoch 0, Step 328: train/loss = 0.7554792165756226, train/raw-loss = 0.7001385688781738, train/logprobs = tensor([[-0.0805, -0.0686],
        [-0.0872, -0.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055340640246868134
Epoch 0, Step 329: train/loss = 0.751857340335846, train/raw-loss = 0.6790847778320312, train/logprobs = tensor([[-0.1384, -0.1381],
        [-0.1520, -0.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07277253270149231
Epoch 0, Step 330: train/loss = 0.6687451004981995, train/raw-loss = 0.580836296081543, train/logprobs = tensor([[-0.0719, -0.6329],
        [-0.0950, -0.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879087820649147
Epoch 0, Step 331: train/loss = 0.7173232436180115, train/raw-loss = 0.6270681619644165, train/logprobs = tensor([[-0.0752, -0.3461],
        [-0.1175, -0.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025508910417557
Epoch 0, Step 332: train/loss = 0.7460787892341614, train/raw-loss = 0.6607988476753235, train/logprobs = tensor([[-0.1331, -0.3206],
        [-0.1665, -0.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852799043059349
Epoch 0, Step 333: train/loss = 0.7591672539710999, train/raw-loss = 0.6758838891983032, train/logprobs = tensor([[-0.0579, -0.3437],
        [-0.0629, -0.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08328332006931305
Epoch 0, Step 334: train/loss = 0.7172926068305969, train/raw-loss = 0.6746821999549866, train/logprobs = tensor([[-0.0413, -0.0899],
        [-0.0708, -0.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04261040687561035
Epoch 0, Step 335: train/loss = 0.7562016248703003, train/raw-loss = 0.6620368957519531, train/logprobs = tensor([[-0.0640, -0.2008],
        [-0.0844, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416475147008896
Epoch 0, Step 336: train/loss = 0.7456011176109314, train/raw-loss = 0.6662359833717346, train/logprobs = tensor([[-0.1408, -0.2198],
        [-0.1591, -0.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07936514168977737
Epoch 0, Step 337: train/loss = 0.7185842990875244, train/raw-loss = 0.672240674495697, train/logprobs = tensor([[-0.0536, -0.1203],
        [-0.0836, -0.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046343546360731125
Epoch 0, Step 338: train/loss = 0.7595630884170532, train/raw-loss = 0.6698722243309021, train/logprobs = tensor([[-0.0818, -0.1160],
        [-0.1160, -0.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969089388847351
Epoch 0, Step 339: train/loss = 0.7784878015518188, train/raw-loss = 0.6610482931137085, train/logprobs = tensor([[-0.0413, -0.2343],
        [-0.0522, -0.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11743959784507751
Epoch 0, Step 340: train/loss = 0.7520805597305298, train/raw-loss = 0.6820216178894043, train/logprobs = tensor([[-0.0779, -0.0953],
        [-0.0869, -0.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07005894184112549
Epoch 0, Step 341: train/loss = 0.7157642245292664, train/raw-loss = 0.6191084384918213, train/logprobs = tensor([[-0.0557, -0.4231],
        [-0.0960, -0.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665578603744507
Epoch 0, Step 342: train/loss = 0.6979255676269531, train/raw-loss = 0.6326351761817932, train/logprobs = tensor([[-0.0986, -0.3566],
        [-0.1176, -0.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652904063463211
Epoch 0, Step 343: train/loss = 0.7240607738494873, train/raw-loss = 0.6710978746414185, train/logprobs = tensor([[-0.0813, -0.2375],
        [-0.1010, -0.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05296284332871437
Epoch 0, Step 344: train/loss = 0.7113147377967834, train/raw-loss = 0.6255353689193726, train/logprobs = tensor([[-0.1008, -0.7382],
        [-0.1291, -0.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08577939122915268
Epoch 0, Step 345: train/loss = 0.7159334421157837, train/raw-loss = 0.6594799757003784, train/logprobs = tensor([[-0.1162, -0.1445],
        [-0.1563, -0.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05645344778895378
Epoch 0, Step 346: train/loss = 0.7406904101371765, train/raw-loss = 0.66478431224823, train/logprobs = tensor([[-0.0959, -0.1895],
        [-0.1050, -0.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07590606808662415
Epoch 0, Step 347: train/loss = 0.712361752986908, train/raw-loss = 0.616135835647583, train/logprobs = tensor([[-0.0457, -0.3846],
        [-0.0796, -0.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622595459222794
Epoch 0, Step 348: train/loss = 0.7233773469924927, train/raw-loss = 0.6477935314178467, train/logprobs = tensor([[-0.0541, -0.2686],
        [-0.0809, -0.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07558374106884003
Epoch 0, Step 349: train/loss = 0.726176381111145, train/raw-loss = 0.6506094932556152, train/logprobs = tensor([[-0.0625, -0.3087],
        [-0.0885, -0.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07556688040494919
Epoch 0, Step 350: train/loss = 0.7167723178863525, train/raw-loss = 0.6701926589012146, train/logprobs = tensor([[-0.0913, -0.2958],
        [-0.0983, -0.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657961428165436
Epoch 0, Step 351: train/loss = 0.7506795525550842, train/raw-loss = 0.6735683679580688, train/logprobs = tensor([[-0.0689, -0.1264],
        [-0.0931, -0.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711117714643478
Epoch 0, Step 352: train/loss = 0.7277833223342896, train/raw-loss = 0.616788923740387, train/logprobs = tensor([[-0.0928, -0.4671],
        [-0.0991, -0.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11099439859390259
Epoch 0, Step 353: train/loss = 0.6783185005187988, train/raw-loss = 0.6020781397819519, train/logprobs = tensor([[-0.0699, -0.5802],
        [-0.0925, -0.1712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07624033838510513
Epoch 0, Step 354: train/loss = 0.7478476762771606, train/raw-loss = 0.6789264678955078, train/logprobs = tensor([[-0.1138, -0.0998],
        [-0.1354, -0.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06892119348049164
Epoch 0, Step 355: train/loss = 0.7146583795547485, train/raw-loss = 0.6513595581054688, train/logprobs = tensor([[-0.1116, -0.2449],
        [-0.1166, -0.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06329887360334396
Epoch 0, Step 356: train/loss = 0.7309027910232544, train/raw-loss = 0.6717754602432251, train/logprobs = tensor([[-0.0904, -0.2099],
        [-0.1008, -0.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05912736803293228
Epoch 0, Step 357: train/loss = 0.7171448469161987, train/raw-loss = 0.6814050078392029, train/logprobs = tensor([[-0.0876, -0.2938],
        [-0.0900, -0.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03573985770344734
Epoch 0, Step 358: train/loss = 0.6763072609901428, train/raw-loss = 0.6069274544715881, train/logprobs = tensor([[-0.0862, -0.4192],
        [-0.1566, -0.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0693797916173935
Epoch 0, Step 359: train/loss = 0.7336694002151489, train/raw-loss = 0.6609458923339844, train/logprobs = tensor([[-0.1447, -0.1539],
        [-0.1936, -0.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07272350043058395
Epoch 0, Step 360: train/loss = 0.7022460699081421, train/raw-loss = 0.644239068031311, train/logprobs = tensor([[-0.0674, -0.2224],
        [-0.1402, -0.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0580068938434124
Epoch 0, Step 361: train/loss = 0.7463082075119019, train/raw-loss = 0.670222818851471, train/logprobs = tensor([[-0.1305, -0.1106],
        [-0.1825, -0.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07608535885810852
Epoch 0, Step 362: train/loss = 0.705644965171814, train/raw-loss = 0.6624007821083069, train/logprobs = tensor([[-0.1072, -0.2063],
        [-0.1313, -0.0996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04324418678879738
Epoch 0, Step 363: train/loss = 0.7362552285194397, train/raw-loss = 0.6841516494750977, train/logprobs = tensor([[-0.0560, -0.0437],
        [-0.0830, -0.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052103519439697266
Epoch 0, Step 364: train/loss = 0.6687420606613159, train/raw-loss = 0.5707830786705017, train/logprobs = tensor([[-0.1138, -1.4434],
        [-0.1224, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0979589968919754
Epoch 0, Step 365: train/loss = 0.7494274973869324, train/raw-loss = 0.6523553729057312, train/logprobs = tensor([[-0.0510, -0.2502],
        [-0.0645, -0.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09707212448120117
Epoch 0, Step 366: train/loss = 0.7121379375457764, train/raw-loss = 0.6600658297538757, train/logprobs = tensor([[-0.0870, -0.1766],
        [-0.1314, -0.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05207209289073944
Epoch 0, Step 367: train/loss = 0.7169418334960938, train/raw-loss = 0.6397823095321655, train/logprobs = tensor([[-0.0703, -0.2995],
        [-0.0962, -0.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07715952396392822
Epoch 0, Step 368: train/loss = 0.777024507522583, train/raw-loss = 0.6767399311065674, train/logprobs = tensor([[-0.0620, -0.2483],
        [-0.0648, -0.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028450191020966
Epoch 0, Step 369: train/loss = 0.7360563278198242, train/raw-loss = 0.6601638197898865, train/logprobs = tensor([[-0.0643, -0.1759],
        [-0.0889, -0.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07589253783226013
Epoch 0, Step 370: train/loss = 0.7405721545219421, train/raw-loss = 0.6855514049530029, train/logprobs = tensor([[-0.0523, -0.1075],
        [-0.0578, -0.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055020805448293686
Epoch 0, Step 371: train/loss = 0.7661906480789185, train/raw-loss = 0.6800012588500977, train/logprobs = tensor([[-0.0819, -0.4244],
        [-0.0982, -0.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08618935942649841
Epoch 0, Step 372: train/loss = 0.7756443023681641, train/raw-loss = 0.6527023315429688, train/logprobs = tensor([[-0.0557, -0.2690],
        [-0.0825, -0.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294191122055054
Epoch 0, Step 373: train/loss = 0.6343472003936768, train/raw-loss = 0.5792477130889893, train/logprobs = tensor([[-0.1251, -0.6757],
        [-0.1676, -0.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055099524557590485
Epoch 0, Step 374: train/loss = 0.7752785086631775, train/raw-loss = 0.6715102791786194, train/logprobs = tensor([[-0.0525, -0.2160],
        [-0.0648, -0.1392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10376827418804169
Epoch 0, Step 375: train/loss = 0.7294672131538391, train/raw-loss = 0.6669521331787109, train/logprobs = tensor([[-0.1468, -0.1726],
        [-0.1565, -0.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06251505017280579
Epoch 0, Step 376: train/loss = 0.6684250831604004, train/raw-loss = 0.5840315818786621, train/logprobs = tensor([[-0.0663, -0.7400],
        [-0.0988, -0.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08439358323812485
Epoch 0, Step 377: train/loss = 0.7257217764854431, train/raw-loss = 0.661888837814331, train/logprobs = tensor([[-0.0463, -0.2800],
        [-0.0497, -0.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06383294612169266
Epoch 0, Step 378: train/loss = 0.6715608835220337, train/raw-loss = 0.6096602082252502, train/logprobs = tensor([[-0.0751, -0.4095],
        [-0.1218, -0.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061900682747364044
Epoch 0, Step 379: train/loss = 0.7367357611656189, train/raw-loss = 0.6715559959411621, train/logprobs = tensor([[-0.0612, -0.0836],
        [-0.0935, -0.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06517979502677917
Epoch 0, Step 380: train/loss = 0.72251296043396, train/raw-loss = 0.6684104800224304, train/logprobs = tensor([[-0.0872, -0.2234],
        [-0.1045, -0.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054102472960948944
Epoch 0, Step 381: train/loss = 0.6897714138031006, train/raw-loss = 0.6342341899871826, train/logprobs = tensor([[-0.0842, -0.6605],
        [-0.0850, -0.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05553717166185379
Epoch 0, Step 382: train/loss = 0.771422803401947, train/raw-loss = 0.6685497164726257, train/logprobs = tensor([[-0.0997, -0.1381],
        [-0.1055, -0.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1028730496764183
Epoch 0, Step 383: train/loss = 0.7514641284942627, train/raw-loss = 0.6487448811531067, train/logprobs = tensor([[-0.1632, -0.3125],
        [-0.1771, -0.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271920263767242
Epoch 0, Step 384: train/loss = 0.6125104427337646, train/raw-loss = 0.5391420125961304, train/logprobs = tensor([[-0.1017, -1.0692],
        [-0.1167, -0.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336845993995667
Epoch 0, Step 385: train/loss = 0.7057539820671082, train/raw-loss = 0.6644034385681152, train/logprobs = tensor([[-0.1063, -0.1313],
        [-0.1452, -0.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04135054349899292
Epoch 0, Step 386: train/loss = 0.7169579267501831, train/raw-loss = 0.6877595782279968, train/logprobs = tensor([[-0.0726, -0.1047],
        [-0.0776, -0.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02919839136302471
Epoch 0, Step 387: train/loss = 0.6108202934265137, train/raw-loss = 0.5567888617515564, train/logprobs = tensor([[-0.1004, -1.1393],
        [-0.1478, -0.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05403144285082817
Epoch 0, Step 388: train/loss = 0.7197042107582092, train/raw-loss = 0.6519425511360168, train/logprobs = tensor([[-0.1613, -0.2719],
        [-0.1610, -0.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776165962219238
Epoch 0, Step 389: train/loss = 0.6915674805641174, train/raw-loss = 0.5980627536773682, train/logprobs = tensor([[-0.1665, -0.5350],
        [-0.1721, -0.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350471198558807
Epoch 0, Step 390: train/loss = 0.6990529298782349, train/raw-loss = 0.6384434700012207, train/logprobs = tensor([[-0.1620, -0.2895],
        [-0.2254, -0.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06060954928398132
Epoch 0, Step 391: train/loss = 0.7113052010536194, train/raw-loss = 0.643612265586853, train/logprobs = tensor([[-0.0737, -0.3707],
        [-0.0955, -0.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06769294291734695
Epoch 0, Step 392: train/loss = 0.7602139711380005, train/raw-loss = 0.673180341720581, train/logprobs = tensor([[-0.0903, -0.4029],
        [-0.1110, -0.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703361451625824
Epoch 0, Step 393: train/loss = 0.7600632905960083, train/raw-loss = 0.6749380230903625, train/logprobs = tensor([[-0.1619, -0.2740],
        [-0.1581, -0.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08512533456087112
Epoch 0, Step 394: train/loss = 0.6377034187316895, train/raw-loss = 0.5479815006256104, train/logprobs = tensor([[-0.0813, -0.8331],
        [-0.1378, -0.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08972195535898209
Epoch 0, Step 395: train/loss = 0.6488966345787048, train/raw-loss = 0.5672418475151062, train/logprobs = tensor([[-0.0640, -0.8038],
        [-0.0995, -0.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08165480941534042
Epoch 0, Step 396: train/loss = 0.7172008752822876, train/raw-loss = 0.6439217329025269, train/logprobs = tensor([[-0.0673, -0.3881],
        [-0.0875, -0.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327915728092194
Epoch 0, Step 397: train/loss = 0.7599610090255737, train/raw-loss = 0.6717935800552368, train/logprobs = tensor([[-0.0986, -0.2752],
        [-0.1206, -0.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08816733956336975
Epoch 0, Step 398: train/loss = 0.6870119571685791, train/raw-loss = 0.5929809808731079, train/logprobs = tensor([[-0.0571, -0.6604],
        [-0.0644, -0.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940309688448906
Epoch 0, Step 399: train/loss = 0.7068871855735779, train/raw-loss = 0.6618385910987854, train/logprobs = tensor([[-0.1150, -0.1217],
        [-0.1763, -0.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045048657804727554
Epoch 0, Step 400: train/loss = 0.7231671810150146, train/raw-loss = 0.6681742072105408, train/logprobs = tensor([[-0.1043, -0.1210],
        [-0.1393, -0.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054992981255054474
Epoch 0, Step 401: train/loss = 0.695075273513794, train/raw-loss = 0.6340820789337158, train/logprobs = tensor([[-0.1087, -0.3402],
        [-0.1545, -0.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06099318712949753
Epoch 0, Step 402: train/loss = 0.6566143035888672, train/raw-loss = 0.5804957151412964, train/logprobs = tensor([[-0.1165, -0.6250],
        [-0.1468, -0.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611861079931259
Epoch 0, Step 403: train/loss = 0.7301954030990601, train/raw-loss = 0.6552785634994507, train/logprobs = tensor([[-0.0585, -0.1642],
        [-0.1020, -0.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07491686940193176
Epoch 0, Step 404: train/loss = 0.7242032885551453, train/raw-loss = 0.6563315391540527, train/logprobs = tensor([[-0.1416, -0.2696],
        [-0.1668, -0.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06787175685167313
Epoch 0, Step 405: train/loss = 0.6963703632354736, train/raw-loss = 0.6113787889480591, train/logprobs = tensor([[-0.0757, -0.4611],
        [-0.0926, -0.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499158173799515
Epoch 0, Step 406: train/loss = 0.7194953560829163, train/raw-loss = 0.6458883285522461, train/logprobs = tensor([[-0.0573, -0.4684],
        [-0.0858, -0.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07360701262950897
Epoch 0, Step 407: train/loss = 0.7400363683700562, train/raw-loss = 0.6686648726463318, train/logprobs = tensor([[-0.0673, -0.1552],
        [-0.0774, -0.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137151062488556
Epoch 0, Step 408: train/loss = 0.7347457408905029, train/raw-loss = 0.6694931387901306, train/logprobs = tensor([[-0.0866, -0.1661],
        [-0.1218, -0.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652526319026947
Epoch 0, Step 409: train/loss = 0.640444815158844, train/raw-loss = 0.5418351292610168, train/logprobs = tensor([[-0.1906, -0.9276],
        [-0.2216, -0.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09860967099666595
Epoch 0, Step 410: train/loss = 0.7168797254562378, train/raw-loss = 0.6534744501113892, train/logprobs = tensor([[-0.1759, -0.3938],
        [-0.1870, -0.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06340521574020386
Epoch 0, Step 411: train/loss = 0.7590770125389099, train/raw-loss = 0.6753614544868469, train/logprobs = tensor([[-0.1010, -0.1899],
        [-0.1110, -0.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371558785438538
Epoch 0, Step 412: train/loss = 0.7388131618499756, train/raw-loss = 0.6651420593261719, train/logprobs = tensor([[-0.0901, -0.1683],
        [-0.1076, -0.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0736711174249649
Epoch 0, Step 413: train/loss = 0.6259273290634155, train/raw-loss = 0.5753147602081299, train/logprobs = tensor([[-0.0580, -0.8200],
        [-0.0847, -0.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05061252415180206
Epoch 0, Step 414: train/loss = 0.7373014092445374, train/raw-loss = 0.6486464142799377, train/logprobs = tensor([[-0.0529, -0.2657],
        [-0.0736, -0.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08865498006343842
Epoch 0, Step 415: train/loss = 0.6694234609603882, train/raw-loss = 0.5934416055679321, train/logprobs = tensor([[-0.1473, -0.7848],
        [-0.1462, -0.2822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07598181068897247
Epoch 0, Step 416: train/loss = 0.7139904499053955, train/raw-loss = 0.6689246892929077, train/logprobs = tensor([[-0.0654, -0.3412],
        [-0.0672, -0.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045065756887197495
Epoch 0, Step 417: train/loss = 0.6393128633499146, train/raw-loss = 0.5474960803985596, train/logprobs = tensor([[-0.1314, -1.0859],
        [-0.1299, -0.0903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181679785251617
Epoch 0, Step 418: train/loss = 0.6538794040679932, train/raw-loss = 0.5568876266479492, train/logprobs = tensor([[-0.1287, -0.6175],
        [-0.2438, -0.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699175506830215
Epoch 0, Step 419: train/loss = 0.6664952039718628, train/raw-loss = 0.5880939960479736, train/logprobs = tensor([[-0.1463, -0.5891],
        [-0.1755, -0.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840121537446976
Epoch 0, Step 420: train/loss = 0.6627580523490906, train/raw-loss = 0.5827268958091736, train/logprobs = tensor([[-0.1140, -0.7606],
        [-0.1176, -0.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08003110438585281
Epoch 0, Step 421: train/loss = 0.6900031566619873, train/raw-loss = 0.6101524233818054, train/logprobs = tensor([[-0.0812, -0.4686],
        [-0.1502, -0.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985071837902069
Epoch 0, Step 422: train/loss = 0.7212632894515991, train/raw-loss = 0.6301966309547424, train/logprobs = tensor([[-0.1749, -0.5671],
        [-0.2295, -0.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910666286945343
Epoch 0, Step 423: train/loss = 0.665846049785614, train/raw-loss = 0.5773665904998779, train/logprobs = tensor([[-0.0780, -0.8407],
        [-0.1234, -0.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08847947418689728
Epoch 0, Step 424: train/loss = 0.7519816160202026, train/raw-loss = 0.6604043841362, train/logprobs = tensor([[-0.0874, -0.6407],
        [-0.0919, -0.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157725423574448
Epoch 0, Step 425: train/loss = 0.7345746159553528, train/raw-loss = 0.6599094271659851, train/logprobs = tensor([[-0.2095, -0.4457],
        [-0.0568, -0.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07466518878936768
Epoch 0, Step 426: train/loss = 0.7105180621147156, train/raw-loss = 0.6144264340400696, train/logprobs = tensor([[-0.1067, -0.4383],
        [-0.1196, -0.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609156101942062
Epoch 0, Step 427: train/loss = 0.6662733554840088, train/raw-loss = 0.5940203070640564, train/logprobs = tensor([[-0.0361, -0.6001],
        [-0.0633, -0.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07225301116704941
Epoch 0, Step 428: train/loss = 0.754587709903717, train/raw-loss = 0.681067943572998, train/logprobs = tensor([[-0.0904, -0.1655],
        [-0.0964, -0.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07351979613304138
Epoch 0, Step 429: train/loss = 0.637115478515625, train/raw-loss = 0.5589377284049988, train/logprobs = tensor([[-0.0403, -0.6690],
        [-0.1040, -0.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817775011062622
Epoch 0, Step 430: train/loss = 0.6843246221542358, train/raw-loss = 0.6057560443878174, train/logprobs = tensor([[-0.1331, -0.6519],
        [-0.1239, -0.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07856862246990204
Epoch 0, Step 431: train/loss = 0.7153955698013306, train/raw-loss = 0.6514027714729309, train/logprobs = tensor([[-0.0987, -0.2386],
        [-0.1351, -0.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06399285793304443
Epoch 0, Step 432: train/loss = 0.7062272429466248, train/raw-loss = 0.6365566849708557, train/logprobs = tensor([[-0.1063, -0.2754],
        [-0.1758, -0.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06967060267925262
Epoch 0, Step 433: train/loss = 0.7607002854347229, train/raw-loss = 0.6615949869155884, train/logprobs = tensor([[-0.2094, -0.2260],
        [-0.2525, -0.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991053432226181
Epoch 0, Step 434: train/loss = 0.6563717722892761, train/raw-loss = 0.5497459769248962, train/logprobs = tensor([[-0.1559, -1.0461],
        [-0.1379, -0.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10662578046321869
Epoch 0, Step 435: train/loss = 0.7251936197280884, train/raw-loss = 0.6366952657699585, train/logprobs = tensor([[-0.1361, -0.4221],
        [-0.1532, -0.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08849841356277466
Epoch 0, Step 436: train/loss = 0.6528067588806152, train/raw-loss = 0.5611892938613892, train/logprobs = tensor([[-0.1095, -1.2125],
        [-0.1705, -0.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09161749482154846
Epoch 0, Step 437: train/loss = 0.663133978843689, train/raw-loss = 0.5851868391036987, train/logprobs = tensor([[-0.1046, -0.9454],
        [-0.1215, -0.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07794718444347382
Epoch 0, Step 438: train/loss = 0.7179028987884521, train/raw-loss = 0.6326035857200623, train/logprobs = tensor([[-0.1124, -0.3373],
        [-0.1236, -0.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529935032129288
Epoch 0, Step 439: train/loss = 0.7298496961593628, train/raw-loss = 0.671042799949646, train/logprobs = tensor([[-0.0602, -0.0906],
        [-0.1009, -0.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05880685895681381
Epoch 0, Step 440: train/loss = 0.7173302173614502, train/raw-loss = 0.6390430927276611, train/logprobs = tensor([[-0.1187, -0.3887],
        [-0.0837, -0.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07828712463378906
Epoch 0, Step 441: train/loss = 0.7516660690307617, train/raw-loss = 0.6777088642120361, train/logprobs = tensor([[-0.1381, -0.1176],
        [-0.1239, -0.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07395724952220917
Epoch 0, Step 442: train/loss = 0.726915180683136, train/raw-loss = 0.6660016775131226, train/logprobs = tensor([[-0.1016, -0.2517],
        [-0.1249, -0.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06091350317001343
Epoch 0, Step 443: train/loss = 0.7671934962272644, train/raw-loss = 0.6995352506637573, train/logprobs = tensor([[-0.2078, -0.0953],
        [-0.1521, -0.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765823811292648
Epoch 0, Step 444: train/loss = 0.7103456854820251, train/raw-loss = 0.6283107995986938, train/logprobs = tensor([[-0.1311, -0.4990],
        [-0.0803, -0.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08203491568565369
Epoch 0, Step 445: train/loss = 0.7265073657035828, train/raw-loss = 0.6219382286071777, train/logprobs = tensor([[-0.1398, -0.3673],
        [-0.1499, -0.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456910729408264
Epoch 0, Step 446: train/loss = 0.6883452534675598, train/raw-loss = 0.6166072487831116, train/logprobs = tensor([[-0.1858, -0.3779],
        [-0.2066, -0.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07173800468444824
Epoch 0, Step 447: train/loss = 0.6226248741149902, train/raw-loss = 0.5159168839454651, train/logprobs = tensor([[-0.1596, -1.3351],
        [-0.1502, -0.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670800507068634
Epoch 0, Step 448: train/loss = 0.5937381982803345, train/raw-loss = 0.5003601908683777, train/logprobs = tensor([[-0.1239, -1.5902],
        [-0.1711, -0.2527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09337808191776276
Epoch 0, Step 449: train/loss = 0.6647058129310608, train/raw-loss = 0.602523922920227, train/logprobs = tensor([[-0.1392, -0.6080],
        [-0.1946, -0.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06218186020851135
Epoch 0, Step 450: train/loss = 0.6971994042396545, train/raw-loss = 0.6333004832267761, train/logprobs = tensor([[-0.2051, -0.4966],
        [-0.1299, -0.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063898965716362
Epoch 0, Step 451: train/loss = 0.7112447023391724, train/raw-loss = 0.6435856819152832, train/logprobs = tensor([[-0.0811, -0.4233],
        [-0.0700, -0.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765904277563095
Epoch 0, Step 452: train/loss = 0.5394365787506104, train/raw-loss = 0.46269723773002625, train/logprobs = tensor([[-0.2119, -1.9804],
        [-0.2724, -0.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07673928141593933
Epoch 0, Step 453: train/loss = 0.5555536150932312, train/raw-loss = 0.46109628677368164, train/logprobs = tensor([[-0.0702, -1.8503],
        [-0.1226, -0.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445736557245255
Epoch 0, Step 454: train/loss = 0.6894091963768005, train/raw-loss = 0.6138858795166016, train/logprobs = tensor([[-0.0604, -0.4504],
        [-0.0937, -0.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07552334666252136
Epoch 0, Step 455: train/loss = 0.5940943956375122, train/raw-loss = 0.5230139493942261, train/logprobs = tensor([[-0.1064, -0.9681],
        [-0.1222, -0.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07108041644096375
Epoch 0, Step 456: train/loss = 0.7386414408683777, train/raw-loss = 0.6546204090118408, train/logprobs = tensor([[-0.2786, -0.4691],
        [-0.1567, -0.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08402105420827866
Epoch 0, Step 457: train/loss = 0.6484769582748413, train/raw-loss = 0.5625091195106506, train/logprobs = tensor([[-0.1059, -0.6821],
        [-0.1446, -0.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08596780896186829
Epoch 0, Step 458: train/loss = 0.6052688956260681, train/raw-loss = 0.5254086256027222, train/logprobs = tensor([[-0.0646, -1.3467],
        [-0.0845, -0.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07986022531986237
Epoch 0, Step 459: train/loss = 0.6671053171157837, train/raw-loss = 0.5830317735671997, train/logprobs = tensor([[-0.1075, -0.6334],
        [-0.1749, -0.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08407354354858398
Epoch 0, Step 460: train/loss = 0.6140908598899841, train/raw-loss = 0.5369197726249695, train/logprobs = tensor([[-0.1505, -1.3433],
        [-0.1659, -0.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07717107981443405
Epoch 0, Step 461: train/loss = 0.6919957399368286, train/raw-loss = 0.5972705483436584, train/logprobs = tensor([[-0.2576, -0.7071],
        [-0.1226, -0.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947251245379448
Epoch 0, Step 462: train/loss = 0.7002030611038208, train/raw-loss = 0.6320477724075317, train/logprobs = tensor([[-0.2196, -0.3984],
        [-0.1834, -0.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06815529614686966
Epoch 0, Step 463: train/loss = 0.6933128833770752, train/raw-loss = 0.6075513362884521, train/logprobs = tensor([[-0.0923, -0.3791],
        [-0.2000, -0.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08576156944036484
Epoch 0, Step 464: train/loss = 0.633455216884613, train/raw-loss = 0.5354041457176208, train/logprobs = tensor([[-0.1275, -1.5299],
        [-0.1266, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980510488152504
Epoch 0, Step 465: train/loss = 0.6915878057479858, train/raw-loss = 0.6276025772094727, train/logprobs = tensor([[-0.1090, -0.5145],
        [-0.1367, -0.2336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063985176384449
Epoch 0, Step 466: train/loss = 0.7193362712860107, train/raw-loss = 0.6479660868644714, train/logprobs = tensor([[-0.3402, -0.4983],
        [-0.1973, -0.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137012481689453
Epoch 0, Step 467: train/loss = 0.7063193917274475, train/raw-loss = 0.613132655620575, train/logprobs = tensor([[-0.1517, -0.6035],
        [-0.1255, -0.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318676590919495
Epoch 0, Step 468: train/loss = 0.5963478684425354, train/raw-loss = 0.4891369342803955, train/logprobs = tensor([[-0.1177, -1.2133],
        [-0.1733, -0.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10721094161272049
Epoch 0, Step 469: train/loss = 0.6927357912063599, train/raw-loss = 0.6371479630470276, train/logprobs = tensor([[-0.1164, -0.3542],
        [-0.1416, -0.1347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055587805807590485
Epoch 0, Step 470: train/loss = 0.6498473882675171, train/raw-loss = 0.5842499136924744, train/logprobs = tensor([[-0.0859, -0.7597],
        [-0.0950, -0.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06559757888317108
Epoch 0, Step 471: train/loss = 0.6208963990211487, train/raw-loss = 0.5120783448219299, train/logprobs = tensor([[-0.0631, -1.0060],
        [-0.1044, -0.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10881803929805756
Epoch 0, Step 472: train/loss = 0.6310505867004395, train/raw-loss = 0.5607872009277344, train/logprobs = tensor([[-0.1191, -1.0848],
        [-0.1462, -0.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07026335597038269
Epoch 0, Step 473: train/loss = 0.6051174402236938, train/raw-loss = 0.5165231823921204, train/logprobs = tensor([[-0.2277, -1.3670],
        [-0.1275, -0.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885942131280899
Epoch 0, Step 474: train/loss = 0.6116127967834473, train/raw-loss = 0.5490741729736328, train/logprobs = tensor([[-0.0834, -0.7834],
        [-0.1094, -0.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06253863871097565
Epoch 0, Step 475: train/loss = 0.6032173037528992, train/raw-loss = 0.49962976574897766, train/logprobs = tensor([[-0.1875, -1.3095],
        [-0.2240, -0.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358750820159912
Epoch 0, Step 476: train/loss = 0.7372997403144836, train/raw-loss = 0.6471647620201111, train/logprobs = tensor([[-0.1222, -0.2699],
        [-0.1124, -0.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09013499319553375
Epoch 0, Step 477: train/loss = 0.61164391040802, train/raw-loss = 0.5287854671478271, train/logprobs = tensor([[-0.0891, -1.6158],
        [-0.0624, -0.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08285842090845108
Epoch 0, Step 478: train/loss = 0.5626974105834961, train/raw-loss = 0.47598347067832947, train/logprobs = tensor([[-0.1674, -1.9255],
        [-0.1553, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08671391010284424
Epoch 0, Step 479: train/loss = 0.6907860040664673, train/raw-loss = 0.5667182207107544, train/logprobs = tensor([[-0.0390, -1.2005],
        [-0.0872, -0.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1240677535533905
Epoch 0, Step 480: train/loss = 0.7481690049171448, train/raw-loss = 0.679984986782074, train/logprobs = tensor([[-0.1890, -0.1744],
        [-0.2252, -0.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06818398833274841
Epoch 0, Step 481: train/loss = 0.5726971626281738, train/raw-loss = 0.46505269408226013, train/logprobs = tensor([[-0.2130, -2.6412],
        [-0.2306, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076444536447525
Epoch 0, Step 482: train/loss = 0.7143820524215698, train/raw-loss = 0.6459799408912659, train/logprobs = tensor([[-0.2299, -0.4434],
        [-0.1838, -0.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06840214878320694
Epoch 0, Step 483: train/loss = 0.6173744201660156, train/raw-loss = 0.5325707197189331, train/logprobs = tensor([[-0.0715, -1.6384],
        [-0.1031, -0.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08480371534824371
Epoch 0, Step 484: train/loss = 0.6540873646736145, train/raw-loss = 0.5575718879699707, train/logprobs = tensor([[-0.1153, -0.8422],
        [-0.1424, -0.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09651544690132141
Epoch 0, Step 485: train/loss = 0.5884990692138672, train/raw-loss = 0.4722248315811157, train/logprobs = tensor([[-0.2960, -2.9324],
        [-0.3074, -0.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11627423763275146
Epoch 0, Step 486: train/loss = 0.7259281873703003, train/raw-loss = 0.6331697702407837, train/logprobs = tensor([[-0.1695, -0.3245],
        [-0.1876, -0.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927584171295166
Epoch 0, Step 487: train/loss = 0.6778306365013123, train/raw-loss = 0.5721402168273926, train/logprobs = tensor([[-0.2415, -0.7066],
        [-0.3424, -0.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569041967391968
Epoch 0, Step 488: train/loss = 0.6074224710464478, train/raw-loss = 0.49869945645332336, train/logprobs = tensor([[-0.1922, -2.6247],
        [-0.2461, -0.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10872302949428558
Epoch 0, Step 489: train/loss = 0.6255070567131042, train/raw-loss = 0.521660327911377, train/logprobs = tensor([[-0.3110, -3.4696],
        [-0.2493, -0.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038467064499855
Epoch 0, Step 490: train/loss = 0.6990624070167542, train/raw-loss = 0.6137596964836121, train/logprobs = tensor([[-0.2188, -0.5914],
        [-0.1854, -0.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08530270308256149
Epoch 0, Step 491: train/loss = 0.6077260971069336, train/raw-loss = 0.5163379907608032, train/logprobs = tensor([[-0.1969, -2.6000],
        [-0.2478, -0.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09138811379671097
Epoch 0, Step 492: train/loss = 0.6091132164001465, train/raw-loss = 0.49900633096694946, train/logprobs = tensor([[-0.1646, -2.7599],
        [-0.1762, -0.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1101069301366806
Epoch 0, Step 493: train/loss = 0.681005597114563, train/raw-loss = 0.6057508587837219, train/logprobs = tensor([[-0.0823, -0.6211],
        [-0.0473, -0.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07525476813316345
Epoch 0, Step 494: train/loss = 0.7026504874229431, train/raw-loss = 0.611463189125061, train/logprobs = tensor([[-0.2758, -0.6330],
        [-0.1433, -0.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911872386932373
Epoch 0, Step 495: train/loss = 0.6215921640396118, train/raw-loss = 0.5226726531982422, train/logprobs = tensor([[-0.1486, -1.2907],
        [-0.1277, -0.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09891954809427261
Epoch 0, Step 496: train/loss = 0.646591305732727, train/raw-loss = 0.536597728729248, train/logprobs = tensor([[-0.1420, -1.3649],
        [-0.1637, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099935919046402
Epoch 0, Step 497: train/loss = 0.6845043301582336, train/raw-loss = 0.6071007251739502, train/logprobs = tensor([[-0.0856, -0.4774],
        [-0.0888, -0.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07740354537963867
Epoch 0, Step 498: train/loss = 0.6683310270309448, train/raw-loss = 0.5569472908973694, train/logprobs = tensor([[-0.1593, -0.6666],
        [-0.2202, -0.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138375848531723
Epoch 0, Step 499: train/loss = 0.6078344583511353, train/raw-loss = 0.5098448395729065, train/logprobs = tensor([[-0.1751, -1.5431],
        [-0.1710, -0.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09798960387706757
Epoch 0, Step 500: train/loss = 0.6823614239692688, train/raw-loss = 0.5996458530426025, train/logprobs = tensor([[-0.2206, -1.0874],
        [-0.1883, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08271554857492447
Epoch 0, Step 501: train/loss = 0.5793190598487854, train/raw-loss = 0.45380446314811707, train/logprobs = tensor([[-0.1709, -2.0321],
        [-0.1444, -0.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12551456689834595
Epoch 0, Step 502: train/loss = 0.6770140528678894, train/raw-loss = 0.5783522725105286, train/logprobs = tensor([[-0.0997, -0.6840],
        [-0.1138, -0.1838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09866178035736084
Epoch 0, Step 503: train/loss = 0.7235589027404785, train/raw-loss = 0.6569705009460449, train/logprobs = tensor([[-0.0853, -0.1970],
        [-0.0897, -0.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0665884017944336
Epoch 0, Step 504: train/loss = 0.6050724387168884, train/raw-loss = 0.49135154485702515, train/logprobs = tensor([[-0.1170, -1.2407],
        [-0.1028, -0.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137208566069603
Epoch 0, Step 505: train/loss = 0.6203992366790771, train/raw-loss = 0.4992494583129883, train/logprobs = tensor([[-0.1717, -4.2653],
        [-0.1634, -2.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12114977836608887
Epoch 0, Step 506: train/loss = 0.7184193134307861, train/raw-loss = 0.6229203343391418, train/logprobs = tensor([[-0.1412, -0.5714],
        [-0.1135, -0.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09549892693758011
Epoch 0, Step 507: train/loss = 0.6206402778625488, train/raw-loss = 0.5067707300186157, train/logprobs = tensor([[-0.1884, -2.9065],
        [-0.0954, -0.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11386953294277191
Epoch 0, Step 508: train/loss = 0.6682177782058716, train/raw-loss = 0.5911307334899902, train/logprobs = tensor([[-0.1903, -0.4813],
        [-0.2420, -0.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07708705961704254
Epoch 0, Step 509: train/loss = 0.7009077072143555, train/raw-loss = 0.6051519513130188, train/logprobs = tensor([[-0.1121, -0.6626],
        [-0.1162, -0.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09575574100017548
Epoch 0, Step 510: train/loss = 0.6647490859031677, train/raw-loss = 0.5433536171913147, train/logprobs = tensor([[-0.2320, -1.4902],
        [-0.2034, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12139545381069183
Epoch 0, Step 511: train/loss = 0.6714991331100464, train/raw-loss = 0.573715329170227, train/logprobs = tensor([[-0.2125, -0.9378],
        [-0.1018, -0.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09778381139039993
Epoch 0, Step 512: train/loss = 0.6293048858642578, train/raw-loss = 0.5330033898353577, train/logprobs = tensor([[-0.1564, -0.7297],
        [-0.3449, -0.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09630151838064194
Epoch 0, Step 513: train/loss = 0.5973376035690308, train/raw-loss = 0.5091533660888672, train/logprobs = tensor([[-0.1105, -1.5785],
        [-0.1326, -0.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08818426728248596
Epoch 0, Step 514: train/loss = 0.6102309823036194, train/raw-loss = 0.4871683418750763, train/logprobs = tensor([[-0.2467, -2.9546],
        [-0.1504, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306264042854309
Epoch 0, Step 515: train/loss = 0.7435375452041626, train/raw-loss = 0.6889479756355286, train/logprobs = tensor([[-0.0682, -0.1040],
        [-0.0670, -0.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05458962172269821
Epoch 0, Step 516: train/loss = 0.6429189443588257, train/raw-loss = 0.5223133563995361, train/logprobs = tensor([[-0.3428, -1.4705],
        [-0.1715, -0.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060557305812836
Epoch 0, Step 517: train/loss = 0.6694893836975098, train/raw-loss = 0.5687040686607361, train/logprobs = tensor([[-0.1156, -0.6314],
        [-0.1509, -0.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078530013561249
Epoch 0, Step 518: train/loss = 0.5566956996917725, train/raw-loss = 0.457536906003952, train/logprobs = tensor([[-0.1514, -3.1727],
        [-0.2080, -0.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09915879368782043
Epoch 0, Step 519: train/loss = 0.612288773059845, train/raw-loss = 0.47864189743995667, train/logprobs = tensor([[-0.2846, -1.6127],
        [-0.2544, -0.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364684581756592
Epoch 0, Step 520: train/loss = 0.7647991180419922, train/raw-loss = 0.6541664600372314, train/logprobs = tensor([[-0.2191, -0.4923],
        [-0.0498, -0.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11063265800476074
Epoch 0, Step 521: train/loss = 0.6347862482070923, train/raw-loss = 0.5231895446777344, train/logprobs = tensor([[-0.0418, -1.1581],
        [-0.0847, -0.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11159671097993851
Epoch 0, Step 522: train/loss = 0.7217260003089905, train/raw-loss = 0.5901410579681396, train/logprobs = tensor([[-0.7399, -2.0026],
        [-0.2307, -0.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13158497214317322
Epoch 0, Step 523: train/loss = 0.6737966537475586, train/raw-loss = 0.5832557678222656, train/logprobs = tensor([[-0.1181, -0.9007],
        [-0.1221, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09054091572761536
Epoch 0, Step 524: train/loss = 0.5702507495880127, train/raw-loss = 0.42788469791412354, train/logprobs = tensor([[-0.0823, -3.9282],
        [-0.1350, -0.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14236608147621155
Epoch 0, Step 525: train/loss = 0.6718727350234985, train/raw-loss = 0.5859817266464233, train/logprobs = tensor([[-0.1772, -0.6833],
        [-0.1877, -0.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0858910009264946
Epoch 0, Step 526: train/loss = 0.6861770749092102, train/raw-loss = 0.5497213006019592, train/logprobs = tensor([[-0.0795, -0.9266],
        [-0.0959, -0.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364557445049286
Epoch 0, Step 527: train/loss = 0.533814549446106, train/raw-loss = 0.4212278127670288, train/logprobs = tensor([[-0.1494, -1.9901],
        [-0.1735, -0.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258674412965775
Epoch 0, Step 528: train/loss = 0.6544827222824097, train/raw-loss = 0.5187901258468628, train/logprobs = tensor([[-0.0928, -3.2465],
        [-0.0985, -1.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356925368309021
Epoch 0, Step 529: train/loss = 0.595754861831665, train/raw-loss = 0.48476582765579224, train/logprobs = tensor([[-0.1503, -3.5058],
        [-0.1355, -0.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098901927471161
Epoch 0, Step 530: train/loss = 0.6298063397407532, train/raw-loss = 0.5503507256507874, train/logprobs = tensor([[-0.0822, -0.9336],
        [-0.1690, -0.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07945562154054642
Epoch 0, Step 531: train/loss = 0.6920017004013062, train/raw-loss = 0.5995453596115112, train/logprobs = tensor([[-0.0827, -0.6815],
        [-0.0906, -0.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09245625883340836
Epoch 0, Step 532: train/loss = 0.6282326579093933, train/raw-loss = 0.5535398721694946, train/logprobs = tensor([[-0.1423, -1.6276],
        [-0.1999, -0.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07469280064105988
Epoch 0, Step 533: train/loss = 0.6970875859260559, train/raw-loss = 0.5721933841705322, train/logprobs = tensor([[-0.2406, -2.1367],
        [-0.2365, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489418685436249
Epoch 0, Step 534: train/loss = 0.7143409848213196, train/raw-loss = 0.6086876392364502, train/logprobs = tensor([[-0.1221, -1.1541],
        [-0.1647, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056533232331276
Epoch 0, Step 535: train/loss = 0.5903462767601013, train/raw-loss = 0.4526815414428711, train/logprobs = tensor([[-0.3075, -2.4639],
        [-0.1668, -0.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376647651195526
Epoch 0, Step 536: train/loss = 0.5636131167411804, train/raw-loss = 0.457316130399704, train/logprobs = tensor([[-0.1625, -1.4269],
        [-0.1822, -0.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10629695653915405
Epoch 0, Step 537: train/loss = 0.624046802520752, train/raw-loss = 0.5105554461479187, train/logprobs = tensor([[-0.3522, -1.2446],
        [-0.3603, -0.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11349136382341385
