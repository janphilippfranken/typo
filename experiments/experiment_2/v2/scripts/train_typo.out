{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 17:04:34,361][root][INFO] - beta: 0.5
[2024-03-12 17:04:34,361][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.5-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6595339775085449, train/raw-loss = 0.6508449912071228, train/logprobs = tensor([[-0.5562, -0.9049],
        [-0.4910, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01737789809703827
Epoch 0, Step 65: train/loss = 0.5927573442459106, train/raw-loss = 0.5858203172683716, train/logprobs = tensor([[-0.4065, -2.3866],
        [-0.4046, -1.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013873998075723648
Epoch 0, Step 66: train/loss = 0.6361945867538452, train/raw-loss = 0.6275323629379272, train/logprobs = tensor([[-0.6666, -1.2229],
        [-0.6758, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017324360087513924
Epoch 0, Step 67: train/loss = 0.6163390874862671, train/raw-loss = 0.6090889573097229, train/logprobs = tensor([[-0.4552, -1.6499],
        [-0.4394, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014500229619443417
Epoch 0, Step 68: train/loss = 0.6276490688323975, train/raw-loss = 0.6199324727058411, train/logprobs = tensor([[-0.5321, -0.8143],
        [-0.6268, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015433276072144508
Epoch 0, Step 69: train/loss = 0.6449480056762695, train/raw-loss = 0.6370118856430054, train/logprobs = tensor([[-0.6262, -0.8781],
        [-0.6382, -0.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015872227028012276
Epoch 0, Step 70: train/loss = 0.611026406288147, train/raw-loss = 0.6039124727249146, train/logprobs = tensor([[-0.5832, -1.5756],
        [-0.5852, -1.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014227917417883873
Epoch 0, Step 71: train/loss = 0.6197028160095215, train/raw-loss = 0.6122317314147949, train/logprobs = tensor([[-0.5080, -1.2079],
        [-0.5327, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014942264184355736
Epoch 0, Step 72: train/loss = 0.6468616127967834, train/raw-loss = 0.639045238494873, train/logprobs = tensor([[-0.5472, -1.3627],
        [-0.5530, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015632782131433487
Epoch 0, Step 73: train/loss = 0.6837710738182068, train/raw-loss = 0.6752433776855469, train/logprobs = tensor([[-0.5545, -1.0882],
        [-0.5397, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017055440694093704
Epoch 0, Step 74: train/loss = 0.6554746627807617, train/raw-loss = 0.6464395523071289, train/logprobs = tensor([[-0.6132, -0.9834],
        [-0.5829, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018070148304104805
Epoch 0, Step 75: train/loss = 0.6114093065261841, train/raw-loss = 0.6051760315895081, train/logprobs = tensor([[-0.4143, -1.3277],
        [-0.4391, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012466603890061378
Epoch 0, Step 76: train/loss = 0.5505601167678833, train/raw-loss = 0.5437288880348206, train/logprobs = tensor([[-0.4658, -2.4575],
        [-0.5003, -1.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013662369921803474
Epoch 0, Step 77: train/loss = 0.6120796203613281, train/raw-loss = 0.6039711236953735, train/logprobs = tensor([[-0.6573, -1.0155],
        [-0.6931, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016217056661844254
Epoch 0, Step 78: train/loss = 0.658980131149292, train/raw-loss = 0.6505047678947449, train/logprobs = tensor([[-0.6896, -0.9505],
        [-0.6835, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016950814053416252
Epoch 0, Step 79: train/loss = 0.5831806659698486, train/raw-loss = 0.5756399631500244, train/logprobs = tensor([[-0.5681, -2.3964],
        [-0.5729, -1.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015081340447068214
Epoch 0, Step 80: train/loss = 0.6333619952201843, train/raw-loss = 0.6244115829467773, train/logprobs = tensor([[-0.7447, -1.0118],
        [-0.7349, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017900867387652397
Epoch 0, Step 81: train/loss = 0.5763986110687256, train/raw-loss = 0.5708928108215332, train/logprobs = tensor([[-0.5281, -2.5021],
        [-0.5213, -1.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011011745780706406
Epoch 0, Step 82: train/loss = 0.6567485928535461, train/raw-loss = 0.647275984287262, train/logprobs = tensor([[-0.6930, -1.1125],
        [-0.6217, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018945258110761642
Epoch 0, Step 83: train/loss = 0.692142903804779, train/raw-loss = 0.6819387078285217, train/logprobs = tensor([[-1.5389, -1.6582],
        [-1.4932, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02040839195251465
Epoch 0, Step 84: train/loss = 0.6481224298477173, train/raw-loss = 0.6386806964874268, train/logprobs = tensor([[-0.6082, -0.9778],
        [-0.5918, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018883639946579933
Epoch 0, Step 85: train/loss = 0.5664697885513306, train/raw-loss = 0.5583192706108093, train/logprobs = tensor([[-0.5909, -2.0255],
        [-0.5805, -1.3627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016301006078720093
Epoch 0, Step 86: train/loss = 0.6344488859176636, train/raw-loss = 0.6258936524391174, train/logprobs = tensor([[-0.5671, -0.9173],
        [-0.5965, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017110394313931465
Epoch 0, Step 87: train/loss = 0.6132493019104004, train/raw-loss = 0.6051691770553589, train/logprobs = tensor([[-0.6376, -1.0316],
        [-0.7065, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01616032049059868
Epoch 0, Step 88: train/loss = 0.6197066903114319, train/raw-loss = 0.6102849841117859, train/logprobs = tensor([[-1.0040, -2.1792],
        [-0.9360, -1.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018843453377485275
Epoch 0, Step 89: train/loss = 0.6452921032905579, train/raw-loss = 0.6362826824188232, train/logprobs = tensor([[-0.5688, -0.9970],
        [-0.5565, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01801871508359909
Epoch 0, Step 90: train/loss = 0.6353575587272644, train/raw-loss = 0.6269485354423523, train/logprobs = tensor([[-0.4659, -1.0627],
        [-0.4727, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016818154603242874
Epoch 0, Step 91: train/loss = 0.4520282447338104, train/raw-loss = 0.4455314874649048, train/logprobs = tensor([[-0.4698, -2.7822],
        [-0.5086, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012993560172617435
Epoch 0, Step 92: train/loss = 0.6596973538398743, train/raw-loss = 0.6494871377944946, train/logprobs = tensor([[-0.6954, -1.0887],
        [-0.6941, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0204203762114048
Epoch 0, Step 93: train/loss = 0.5983526706695557, train/raw-loss = 0.5902403593063354, train/logprobs = tensor([[-0.5670, -1.4546],
        [-0.5582, -0.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01622459478676319
Epoch 0, Step 94: train/loss = 0.5971679091453552, train/raw-loss = 0.5885693430900574, train/logprobs = tensor([[-0.6802, -1.8464],
        [-0.7736, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017197135835886
Epoch 0, Step 95: train/loss = 0.6327857971191406, train/raw-loss = 0.625861406326294, train/logprobs = tensor([[-0.5266, -1.0181],
        [-0.5227, -0.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013848744332790375
Epoch 0, Step 96: train/loss = 0.7045453190803528, train/raw-loss = 0.6830568313598633, train/logprobs = tensor([[-0.5993, -0.8912],
        [-0.5837, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04297705739736557
Epoch 0, Step 97: train/loss = 0.5811583995819092, train/raw-loss = 0.5630441308021545, train/logprobs = tensor([[-0.6323, -1.9362],
        [-0.6149, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03622858226299286
Epoch 0, Step 98: train/loss = 0.6273726224899292, train/raw-loss = 0.6135720610618591, train/logprobs = tensor([[-0.3824, -0.9754],
        [-0.3305, -0.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027601085603237152
Epoch 0, Step 99: train/loss = 0.6400129199028015, train/raw-loss = 0.6251468658447266, train/logprobs = tensor([[-0.5287, -1.0410],
        [-0.5072, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029732119292020798
Epoch 0, Step 100: train/loss = 0.5560652017593384, train/raw-loss = 0.5409526824951172, train/logprobs = tensor([[-0.6792, -2.7729],
        [-0.6620, -1.3534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030225014314055443
Epoch 0, Step 101: train/loss = 0.6121407151222229, train/raw-loss = 0.5867656469345093, train/logprobs = tensor([[-0.9542, -1.8322],
        [-0.9254, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050750117748975754
Epoch 0, Step 102: train/loss = 0.5954349637031555, train/raw-loss = 0.5783603191375732, train/logprobs = tensor([[-0.4949, -1.3503],
        [-0.4908, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03414931893348694
Epoch 0, Step 103: train/loss = 0.5679900646209717, train/raw-loss = 0.5532916784286499, train/logprobs = tensor([[-0.6327, -1.7116],
        [-0.5487, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029396846890449524
Epoch 0, Step 104: train/loss = 0.4635242223739624, train/raw-loss = 0.44392919540405273, train/logprobs = tensor([[-0.7918, -4.5019],
        [-0.6597, -2.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03919002413749695
Epoch 0, Step 105: train/loss = 0.6155394315719604, train/raw-loss = 0.5976642370223999, train/logprobs = tensor([[-0.6748, -1.1901],
        [-0.6246, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03575032204389572
Epoch 0, Step 106: train/loss = 0.46723443269729614, train/raw-loss = 0.45224472880363464, train/logprobs = tensor([[-0.6775, -4.3874],
        [-0.6223, -2.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029979504644870758
Epoch 0, Step 107: train/loss = 0.6197147369384766, train/raw-loss = 0.5974997878074646, train/logprobs = tensor([[-0.7184, -1.5301],
        [-0.6786, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044429805129766464
Epoch 0, Step 108: train/loss = 0.6733201146125793, train/raw-loss = 0.6616962552070618, train/logprobs = tensor([[-0.5300, -0.6592],
        [-0.4649, -0.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023247767239809036
Epoch 0, Step 109: train/loss = 0.617694616317749, train/raw-loss = 0.6017425060272217, train/logprobs = tensor([[-0.6366, -1.2748],
        [-0.5529, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03190426528453827
Epoch 0, Step 110: train/loss = 0.5549579858779907, train/raw-loss = 0.5392438769340515, train/logprobs = tensor([[-0.6588, -2.9422],
        [-0.5486, -1.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0314282588660717
Epoch 0, Step 111: train/loss = 0.5878292322158813, train/raw-loss = 0.5752263069152832, train/logprobs = tensor([[-0.4346, -1.5011],
        [-0.4149, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02520587295293808
Epoch 0, Step 112: train/loss = 0.6109278798103333, train/raw-loss = 0.5952564477920532, train/logprobs = tensor([[-0.6275, -1.1024],
        [-0.5957, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031342763453722
Epoch 0, Step 113: train/loss = 0.647152841091156, train/raw-loss = 0.6244320869445801, train/logprobs = tensor([[-0.6479, -1.2748],
        [-0.5757, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04544142633676529
Epoch 0, Step 114: train/loss = 0.6162281632423401, train/raw-loss = 0.5981323719024658, train/logprobs = tensor([[-0.5632, -1.0635],
        [-0.5372, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03619162738323212
Epoch 0, Step 115: train/loss = 0.6276603937149048, train/raw-loss = 0.612922728061676, train/logprobs = tensor([[-0.5626, -1.1603],
        [-0.5302, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02947520837187767
Epoch 0, Step 116: train/loss = 0.5802294015884399, train/raw-loss = 0.5607624650001526, train/logprobs = tensor([[-0.6675, -2.0477],
        [-0.6109, -1.2777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893386945128441
Epoch 0, Step 117: train/loss = 0.6333152651786804, train/raw-loss = 0.6166841983795166, train/logprobs = tensor([[-0.4843, -1.7610],
        [-0.4611, -1.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033262185752391815
Epoch 0, Step 118: train/loss = 0.5067126750946045, train/raw-loss = 0.4929126501083374, train/logprobs = tensor([[-0.6575, -3.1873],
        [-0.5740, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027600180357694626
Epoch 0, Step 119: train/loss = 0.5854249000549316, train/raw-loss = 0.5648069381713867, train/logprobs = tensor([[-0.6146, -1.6826],
        [-0.5679, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041235871613025665
Epoch 0, Step 120: train/loss = 0.5357391834259033, train/raw-loss = 0.5164735913276672, train/logprobs = tensor([[-0.7811, -2.6264],
        [-0.7644, -1.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03853124752640724
Epoch 0, Step 121: train/loss = 0.6197870969772339, train/raw-loss = 0.6042582988739014, train/logprobs = tensor([[-0.4998, -1.2309],
        [-0.4447, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03105759806931019
Epoch 0, Step 122: train/loss = 0.5543208122253418, train/raw-loss = 0.5361959934234619, train/logprobs = tensor([[-0.8426, -1.9397],
        [-0.7434, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036249641329050064
Epoch 0, Step 123: train/loss = 0.6811236143112183, train/raw-loss = 0.6638092994689941, train/logprobs = tensor([[-0.5321, -0.7935],
        [-0.5073, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03462870419025421
Epoch 0, Step 124: train/loss = 0.5975993871688843, train/raw-loss = 0.5779905319213867, train/logprobs = tensor([[-0.7880, -1.6054],
        [-0.7078, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03921777755022049
Epoch 0, Step 125: train/loss = 0.5531665086746216, train/raw-loss = 0.5345370769500732, train/logprobs = tensor([[-0.6997, -3.1731],
        [-0.6288, -2.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037258829921483994
Epoch 0, Step 126: train/loss = 0.6459938883781433, train/raw-loss = 0.625038743019104, train/logprobs = tensor([[-0.6736, -1.2027],
        [-0.5702, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04191030561923981
Epoch 0, Step 127: train/loss = 0.6282777786254883, train/raw-loss = 0.6098669767379761, train/logprobs = tensor([[-0.5083, -1.4868],
        [-0.4446, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036821696907281876
Epoch 0, Step 128: train/loss = 0.7046265602111816, train/raw-loss = 0.6508023142814636, train/logprobs = tensor([[-0.8183, -1.0315],
        [-0.7767, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764852166175842
Epoch 0, Step 129: train/loss = 0.5809559226036072, train/raw-loss = 0.5115790963172913, train/logprobs = tensor([[-0.7342, -2.8393],
        [-0.6285, -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138753741979599
Epoch 0, Step 130: train/loss = 0.6866241693496704, train/raw-loss = 0.6234531402587891, train/logprobs = tensor([[-0.5336, -1.1537],
        [-0.4663, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12634210288524628
Epoch 0, Step 131: train/loss = 0.5670933723449707, train/raw-loss = 0.49695420265197754, train/logprobs = tensor([[-0.7670, -4.0792],
        [-0.6779, -2.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402783989906311
Epoch 0, Step 132: train/loss = 0.5907756686210632, train/raw-loss = 0.5263326168060303, train/logprobs = tensor([[-0.7845, -2.3463],
        [-0.6346, -1.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1288861334323883
Epoch 0, Step 133: train/loss = 0.6037569046020508, train/raw-loss = 0.5374609231948853, train/logprobs = tensor([[-0.6437, -2.4052],
        [-0.5573, -1.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325920820236206
Epoch 0, Step 134: train/loss = 0.6161435842514038, train/raw-loss = 0.5553247928619385, train/logprobs = tensor([[-0.7451, -1.6630],
        [-0.6180, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12163765728473663
Epoch 0, Step 135: train/loss = 0.6569089889526367, train/raw-loss = 0.5903446674346924, train/logprobs = tensor([[-0.5162, -1.4858],
        [-0.3926, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331285536289215
Epoch 0, Step 136: train/loss = 0.583716094493866, train/raw-loss = 0.521047055721283, train/logprobs = tensor([[-0.4393, -2.1171],
        [-0.3929, -1.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12533797323703766
Epoch 0, Step 137: train/loss = 0.6548623442649841, train/raw-loss = 0.5942800045013428, train/logprobs = tensor([[-0.4372, -1.3335],
        [-0.4014, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12116469442844391
Epoch 0, Step 138: train/loss = 0.6080087423324585, train/raw-loss = 0.5383071303367615, train/logprobs = tensor([[-0.4367, -1.7088],
        [-0.3620, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940322399139404
Epoch 0, Step 139: train/loss = 0.5850917100906372, train/raw-loss = 0.5195049047470093, train/logprobs = tensor([[-0.6121, -2.3661],
        [-0.4928, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13117346167564392
Epoch 0, Step 140: train/loss = 0.6403047442436218, train/raw-loss = 0.578818678855896, train/logprobs = tensor([[-0.7768, -1.7583],
        [-0.6560, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12297205626964569
Epoch 0, Step 141: train/loss = 0.6457594037055969, train/raw-loss = 0.5799267292022705, train/logprobs = tensor([[-0.9123, -1.9123],
        [-0.6702, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13166546821594238
Epoch 0, Step 142: train/loss = 0.6679819822311401, train/raw-loss = 0.6089566349983215, train/logprobs = tensor([[-0.5580, -1.2220],
        [-0.4745, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11805067956447601
Epoch 0, Step 143: train/loss = 0.6904636025428772, train/raw-loss = 0.6320945024490356, train/logprobs = tensor([[-0.7413, -1.5543],
        [-0.5851, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673817038536072
Epoch 0, Step 144: train/loss = 0.5210893750190735, train/raw-loss = 0.463204562664032, train/logprobs = tensor([[-0.5733, -3.9370],
        [-0.4947, -2.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11576960980892181
Epoch 0, Step 145: train/loss = 0.6639440059661865, train/raw-loss = 0.6098159551620483, train/logprobs = tensor([[-0.6391, -1.5305],
        [-0.5574, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825621336698532
Epoch 0, Step 146: train/loss = 0.6021127700805664, train/raw-loss = 0.5414738655090332, train/logprobs = tensor([[-0.6397, -2.7655],
        [-0.5122, -1.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212778314948082
Epoch 0, Step 147: train/loss = 0.6649810671806335, train/raw-loss = 0.6057419776916504, train/logprobs = tensor([[-0.6184, -1.1885],
        [-0.5125, -0.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847814917564392
Epoch 0, Step 148: train/loss = 0.7441940307617188, train/raw-loss = 0.6778267621994019, train/logprobs = tensor([[-1.5144, -1.8525],
        [-1.1185, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13273465633392334
Epoch 0, Step 149: train/loss = 0.6791809797286987, train/raw-loss = 0.6265060901641846, train/logprobs = tensor([[-0.6288, -1.2693],
        [-0.5190, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10534968972206116
Epoch 0, Step 150: train/loss = 0.5897508859634399, train/raw-loss = 0.5307213664054871, train/logprobs = tensor([[-0.8156, -3.5241],
        [-0.7216, -1.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11805908381938934
Epoch 0, Step 151: train/loss = 0.640901505947113, train/raw-loss = 0.5784685611724854, train/logprobs = tensor([[-0.6672, -1.8480],
        [-0.5248, -1.1263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12486584484577179
Epoch 0, Step 152: train/loss = 0.6662625670433044, train/raw-loss = 0.5989516973495483, train/logprobs = tensor([[-0.8296, -1.3935],
        [-0.7564, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13462162017822266
Epoch 0, Step 153: train/loss = 0.6368663907051086, train/raw-loss = 0.5656025409698486, train/logprobs = tensor([[-0.6126, -2.0363],
        [-0.5028, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14252761006355286
Epoch 0, Step 154: train/loss = 0.6919113397598267, train/raw-loss = 0.6356090307235718, train/logprobs = tensor([[-0.7426, -1.6127],
        [-0.6421, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11260456591844559
Epoch 0, Step 155: train/loss = 0.6042823791503906, train/raw-loss = 0.5517324209213257, train/logprobs = tensor([[-0.5925, -2.9012],
        [-0.5004, -1.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10510003566741943
Epoch 0, Step 156: train/loss = 0.698574423789978, train/raw-loss = 0.650261402130127, train/logprobs = tensor([[-0.6321, -0.7569],
        [-0.5682, -0.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09662608802318573
Epoch 0, Step 157: train/loss = 0.7302263975143433, train/raw-loss = 0.6856082081794739, train/logprobs = tensor([[-0.7339, -0.7948],
        [-0.6445, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08923637866973877
Epoch 0, Step 158: train/loss = 0.7002525329589844, train/raw-loss = 0.6427555084228516, train/logprobs = tensor([[-0.6911, -1.2094],
        [-0.4827, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11499404907226562
Epoch 0, Step 159: train/loss = 0.7205624580383301, train/raw-loss = 0.6659785509109497, train/logprobs = tensor([[-0.8538, -1.0457],
        [-0.7103, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916788130998611
Epoch 0, Step 160: train/loss = 0.5719666481018066, train/raw-loss = 0.5189914107322693, train/logprobs = tensor([[-1.0925, -2.2931],
        [-0.8448, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595039278268814
Epoch 0, Step 161: train/loss = 0.6532944440841675, train/raw-loss = 0.6170110702514648, train/logprobs = tensor([[-0.6654, -1.2932],
        [-0.5541, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07256677746772766
Epoch 0, Step 162: train/loss = 0.596363365650177, train/raw-loss = 0.5557636618614197, train/logprobs = tensor([[-0.5760, -3.0250],
        [-0.5042, -1.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119934797286987
Epoch 0, Step 163: train/loss = 0.5839418172836304, train/raw-loss = 0.5341551303863525, train/logprobs = tensor([[-0.5745, -2.1089],
        [-0.4354, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957345575094223
Epoch 0, Step 164: train/loss = 0.5944604873657227, train/raw-loss = 0.5541094541549683, train/logprobs = tensor([[-0.6688, -1.8418],
        [-0.5198, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08070216327905655
Epoch 0, Step 165: train/loss = 0.5809198021888733, train/raw-loss = 0.5304595828056335, train/logprobs = tensor([[-0.6519, -2.1802],
        [-0.4904, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10092032700777054
Epoch 0, Step 166: train/loss = 0.4595656096935272, train/raw-loss = 0.40854009985923767, train/logprobs = tensor([[-0.6391, -6.7852],
        [-0.4457, -3.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10205113142728806
Epoch 0, Step 167: train/loss = 0.6545225381851196, train/raw-loss = 0.6047526001930237, train/logprobs = tensor([[-0.7256, -1.4412],
        [-0.5666, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09953999519348145
Epoch 0, Step 168: train/loss = 0.6224721670150757, train/raw-loss = 0.5765143632888794, train/logprobs = tensor([[-0.7044, -1.5327],
        [-0.5495, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09191549569368362
Epoch 0, Step 169: train/loss = 0.685905396938324, train/raw-loss = 0.6458964347839355, train/logprobs = tensor([[-0.7913, -1.3331],
        [-0.7236, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800180733203888
Epoch 0, Step 170: train/loss = 0.6169699430465698, train/raw-loss = 0.5680656433105469, train/logprobs = tensor([[-0.5921, -1.7003],
        [-0.5556, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780861437320709
Epoch 0, Step 171: train/loss = 0.6750718355178833, train/raw-loss = 0.6284482479095459, train/logprobs = tensor([[-0.6499, -1.3514],
        [-0.5116, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09324730932712555
Epoch 0, Step 172: train/loss = 0.537665605545044, train/raw-loss = 0.4885171055793762, train/logprobs = tensor([[-0.6406, -2.6048],
        [-0.5742, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09829698503017426
Epoch 0, Step 173: train/loss = 0.5602319240570068, train/raw-loss = 0.5137815475463867, train/logprobs = tensor([[-0.6204, -2.4713],
        [-0.5404, -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0929008424282074
Epoch 0, Step 174: train/loss = 0.5648767352104187, train/raw-loss = 0.517996609210968, train/logprobs = tensor([[-0.6815, -2.0681],
        [-0.5551, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09376029670238495
Epoch 0, Step 175: train/loss = 0.4783077538013458, train/raw-loss = 0.4285045564174652, train/logprobs = tensor([[-0.5094, -3.5954],
        [-0.4054, -1.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09960637986660004
Epoch 0, Step 176: train/loss = 0.6325520873069763, train/raw-loss = 0.5771771669387817, train/logprobs = tensor([[-0.7310, -1.6621],
        [-0.4961, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11074985563755035
Epoch 0, Step 177: train/loss = 0.6139777302742004, train/raw-loss = 0.5602802038192749, train/logprobs = tensor([[-1.0608, -2.5072],
        [-0.6297, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739508271217346
Epoch 0, Step 178: train/loss = 0.6430885791778564, train/raw-loss = 0.5954577922821045, train/logprobs = tensor([[-0.8569, -2.4296],
        [-0.7469, -1.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526151418685913
Epoch 0, Step 179: train/loss = 0.6278781294822693, train/raw-loss = 0.5817197561264038, train/logprobs = tensor([[-0.6564, -2.4753],
        [-0.4986, -1.6459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09231676161289215
Epoch 0, Step 180: train/loss = 0.7277982234954834, train/raw-loss = 0.6815450191497803, train/logprobs = tensor([[-0.8396, -0.9036],
        [-0.6394, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09250642359256744
Epoch 0, Step 181: train/loss = 0.7383598685264587, train/raw-loss = 0.6886352300643921, train/logprobs = tensor([[-2.8063, -4.1149],
        [-1.9110, -2.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994492694735527
Epoch 0, Step 182: train/loss = 0.6550987362861633, train/raw-loss = 0.6105433702468872, train/logprobs = tensor([[-0.5359, -1.2488],
        [-0.4580, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911072462797165
Epoch 0, Step 183: train/loss = 0.6125368475914001, train/raw-loss = 0.5633059144020081, train/logprobs = tensor([[-0.7098, -1.7517],
        [-0.5930, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09846189618110657
Epoch 0, Step 184: train/loss = 0.5319207906723022, train/raw-loss = 0.484667032957077, train/logprobs = tensor([[-1.1930, -4.2031],
        [-1.1682, -2.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09450747072696686
Epoch 0, Step 185: train/loss = 0.6136468052864075, train/raw-loss = 0.5679298043251038, train/logprobs = tensor([[-0.8526, -2.1051],
        [-0.6701, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09143396466970444
Epoch 0, Step 186: train/loss = 0.6279382109642029, train/raw-loss = 0.5694505572319031, train/logprobs = tensor([[-0.8128, -1.6580],
        [-0.7145, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169753447175026
Epoch 0, Step 187: train/loss = 0.6088998317718506, train/raw-loss = 0.5658746361732483, train/logprobs = tensor([[-0.6051, -2.3226],
        [-0.4880, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605033159255981
Epoch 0, Step 188: train/loss = 0.5396251082420349, train/raw-loss = 0.4909122586250305, train/logprobs = tensor([[-0.8564, -4.1431],
        [-0.6081, -2.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974256843328476
Epoch 0, Step 189: train/loss = 0.6880757212638855, train/raw-loss = 0.6517988443374634, train/logprobs = tensor([[-0.6009, -0.8932],
        [-0.5072, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07255382090806961
Epoch 0, Step 190: train/loss = 0.5685102343559265, train/raw-loss = 0.5274640321731567, train/logprobs = tensor([[-0.8256, -3.6794],
        [-0.6151, -1.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209246397018433
Epoch 0, Step 191: train/loss = 0.6603981852531433, train/raw-loss = 0.6119563579559326, train/logprobs = tensor([[-0.6880, -1.1597],
        [-0.5963, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09688369929790497
Epoch 0, Step 192: train/loss = 0.6138941049575806, train/raw-loss = 0.551566481590271, train/logprobs = tensor([[-0.7531, -1.5653],
        [-0.5591, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12465524673461914
Epoch 0, Step 193: train/loss = 0.5383752584457397, train/raw-loss = 0.46832388639450073, train/logprobs = tensor([[-0.7766, -3.1784],
        [-0.6425, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140102818608284
Epoch 0, Step 194: train/loss = 0.5284738540649414, train/raw-loss = 0.4641493558883667, train/logprobs = tensor([[-0.8833, -3.8502],
        [-0.7277, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864895164966583
Epoch 0, Step 195: train/loss = 0.556664228439331, train/raw-loss = 0.4960746765136719, train/logprobs = tensor([[-0.8249, -3.4632],
        [-0.6090, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12117911875247955
Epoch 0, Step 196: train/loss = 0.6316990256309509, train/raw-loss = 0.5721396207809448, train/logprobs = tensor([[-0.7086, -1.5595],
        [-0.5831, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11911876499652863
Epoch 0, Step 197: train/loss = 0.5782368183135986, train/raw-loss = 0.5176199674606323, train/logprobs = tensor([[-0.7027, -2.4264],
        [-0.5062, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123367190361023
Epoch 0, Step 198: train/loss = 0.6094987988471985, train/raw-loss = 0.5484496355056763, train/logprobs = tensor([[-0.6777, -1.8193],
        [-0.5526, -0.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12209834903478622
Epoch 0, Step 199: train/loss = 0.5098035931587219, train/raw-loss = 0.4442095160484314, train/logprobs = tensor([[-0.5112, -2.3361],
        [-0.3757, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311882883310318
Epoch 0, Step 200: train/loss = 0.5345304012298584, train/raw-loss = 0.4809991717338562, train/logprobs = tensor([[-0.8825, -2.3136],
        [-0.6731, -0.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10706239938735962
Epoch 0, Step 201: train/loss = 0.5282528400421143, train/raw-loss = 0.45878246426582336, train/logprobs = tensor([[-0.8970, -3.3541],
        [-0.6802, -1.3329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13894081115722656
Epoch 0, Step 202: train/loss = 0.6492443680763245, train/raw-loss = 0.5925478935241699, train/logprobs = tensor([[-0.6961, -1.1703],
        [-0.6771, -0.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11339297890663147
Epoch 0, Step 203: train/loss = 0.6410850882530212, train/raw-loss = 0.5771498680114746, train/logprobs = tensor([[-0.7772, -2.7693],
        [-0.4623, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278703510761261
Epoch 0, Step 204: train/loss = 0.5607624053955078, train/raw-loss = 0.5051839351654053, train/logprobs = tensor([[-0.9198, -2.1151],
        [-0.7322, -0.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11115691810846329
Epoch 0, Step 205: train/loss = 0.49483630061149597, train/raw-loss = 0.4314178228378296, train/logprobs = tensor([[-0.5619, -2.4954],
        [-0.5092, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12683698534965515
Epoch 0, Step 206: train/loss = 0.41141608357429504, train/raw-loss = 0.35075312852859497, train/logprobs = tensor([[-0.6166, -5.5434],
        [-0.5241, -1.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12132591009140015
Epoch 0, Step 207: train/loss = 0.5228309035301208, train/raw-loss = 0.4624094069004059, train/logprobs = tensor([[-0.9516, -2.3887],
        [-0.7815, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12084294855594635
Epoch 0, Step 208: train/loss = 0.5385544300079346, train/raw-loss = 0.479568213224411, train/logprobs = tensor([[-0.7794, -3.4693],
        [-0.5414, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11797235906124115
Epoch 0, Step 209: train/loss = 0.5971866250038147, train/raw-loss = 0.5299596786499023, train/logprobs = tensor([[-0.7662, -2.1345],
        [-0.6212, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344539374113083
Epoch 0, Step 210: train/loss = 0.5858274698257446, train/raw-loss = 0.5315545797348022, train/logprobs = tensor([[-0.6985, -1.7163],
        [-0.5626, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10854572802782059
Epoch 0, Step 211: train/loss = 0.6270730495452881, train/raw-loss = 0.5702162384986877, train/logprobs = tensor([[-1.0727, -4.1237],
        [-1.0417, -1.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11371354758739471
Epoch 0, Step 212: train/loss = 0.6531166434288025, train/raw-loss = 0.5999425649642944, train/logprobs = tensor([[-0.5691, -1.3434],
        [-0.4540, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10634806007146835
Epoch 0, Step 213: train/loss = 0.6577930450439453, train/raw-loss = 0.5950160026550293, train/logprobs = tensor([[-0.7005, -1.3626],
        [-0.5107, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12555406987667084
Epoch 0, Step 214: train/loss = 0.575851321220398, train/raw-loss = 0.5107259750366211, train/logprobs = tensor([[-0.6301, -2.9328],
        [-0.5682, -1.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13025058805942535
Epoch 0, Step 215: train/loss = 0.5447430610656738, train/raw-loss = 0.48360681533813477, train/logprobs = tensor([[-0.9494, -2.8744],
        [-0.8638, -1.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227252870798111
Epoch 0, Step 216: train/loss = 0.6614170074462891, train/raw-loss = 0.6079082489013672, train/logprobs = tensor([[-0.8232, -1.2732],
        [-0.5317, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10701749473810196
Epoch 0, Step 217: train/loss = 0.5238572359085083, train/raw-loss = 0.46467527747154236, train/logprobs = tensor([[-0.6015, -2.5563],
        [-0.5105, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11836397647857666
Epoch 0, Step 218: train/loss = 0.7124668955802917, train/raw-loss = 0.6671017408370972, train/logprobs = tensor([[-0.6248, -0.7925],
        [-0.5264, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073023498058319
Epoch 0, Step 219: train/loss = 0.6131756901741028, train/raw-loss = 0.5558228492736816, train/logprobs = tensor([[-0.6774, -1.7830],
        [-0.5565, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1147056519985199
Epoch 0, Step 220: train/loss = 0.4694804847240448, train/raw-loss = 0.41178566217422485, train/logprobs = tensor([[-1.1353, -3.7931],
        [-0.8831, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538964509963989
Epoch 0, Step 221: train/loss = 0.5617299675941467, train/raw-loss = 0.5076228380203247, train/logprobs = tensor([[-0.4845, -4.0297],
        [-0.4250, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1082143634557724
Epoch 0, Step 222: train/loss = 0.6060787439346313, train/raw-loss = 0.5515013933181763, train/logprobs = tensor([[-0.6863, -2.1250],
        [-0.5178, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10915482044219971
Epoch 0, Step 223: train/loss = 0.6159099340438843, train/raw-loss = 0.5589629411697388, train/logprobs = tensor([[-0.8505, -2.1553],
        [-0.6408, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11389392614364624
Epoch 0, Step 224: train/loss = 0.6031640768051147, train/raw-loss = 0.5474555492401123, train/logprobs = tensor([[-0.7293, -1.5371],
        [-0.6538, -0.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11141693592071533
Epoch 0, Step 225: train/loss = 0.6114176511764526, train/raw-loss = 0.5628024935722351, train/logprobs = tensor([[-0.6212, -1.5176],
        [-0.4468, -0.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09723034501075745
Epoch 0, Step 226: train/loss = 0.8840024471282959, train/raw-loss = 0.829714298248291, train/logprobs = tensor([[-2.1849, -3.4096],
        [-0.6783, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10857649147510529
Epoch 0, Step 227: train/loss = 0.5199018120765686, train/raw-loss = 0.4529726505279541, train/logprobs = tensor([[-1.0608, -3.4613],
        [-0.5633, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13385824859142303
Epoch 0, Step 228: train/loss = 0.5754919052124023, train/raw-loss = 0.5297325849533081, train/logprobs = tensor([[-0.5815, -2.0773],
        [-0.4373, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09151865541934967
Epoch 0, Step 229: train/loss = 0.4740554690361023, train/raw-loss = 0.4180166721343994, train/logprobs = tensor([[-0.9470, -5.3260],
        [-0.8166, -2.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11207757145166397
Epoch 0, Step 230: train/loss = 0.48399829864501953, train/raw-loss = 0.4274170994758606, train/logprobs = tensor([[-1.1675, -3.3532],
        [-1.0521, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316238343715668
Epoch 0, Step 231: train/loss = 0.4553701877593994, train/raw-loss = 0.40448808670043945, train/logprobs = tensor([[-0.6780, -4.3543],
        [-0.6810, -0.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1017642542719841
Epoch 0, Step 232: train/loss = 0.5781553983688354, train/raw-loss = 0.5242915153503418, train/logprobs = tensor([[-0.6234, -2.4815],
        [-0.5750, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10772772878408432
Epoch 0, Step 233: train/loss = 0.6381224989891052, train/raw-loss = 0.5842419266700745, train/logprobs = tensor([[-1.2840, -5.2240],
        [-0.8259, -1.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776111483573914
Epoch 0, Step 234: train/loss = 0.6512942910194397, train/raw-loss = 0.6002216339111328, train/logprobs = tensor([[-0.6061, -1.1390],
        [-0.4890, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214526951313019
Epoch 0, Step 235: train/loss = 0.5132653713226318, train/raw-loss = 0.4568015933036804, train/logprobs = tensor([[-0.9917, -4.4997],
        [-0.5750, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11292758584022522
Epoch 0, Step 236: train/loss = 0.6234656572341919, train/raw-loss = 0.5632724761962891, train/logprobs = tensor([[-0.7412, -1.9856],
        [-0.6146, -1.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038636207580566
Epoch 0, Step 237: train/loss = 0.553550124168396, train/raw-loss = 0.5013327598571777, train/logprobs = tensor([[-0.7584, -2.0901],
        [-0.6532, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10443463921546936
Epoch 0, Step 238: train/loss = 0.5073143839836121, train/raw-loss = 0.4571039080619812, train/logprobs = tensor([[-0.5880, -2.5926],
        [-0.4951, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10042093694210052
Epoch 0, Step 239: train/loss = 0.671549916267395, train/raw-loss = 0.6224350929260254, train/logprobs = tensor([[-0.8259, -1.1328],
        [-0.5683, -0.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09822957962751389
Epoch 0, Step 240: train/loss = 0.6414719820022583, train/raw-loss = 0.5808683037757874, train/logprobs = tensor([[-1.1136, -2.5744],
        [-1.0697, -1.3701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120728194713593
Epoch 0, Step 241: train/loss = 0.5338026285171509, train/raw-loss = 0.4778754413127899, train/logprobs = tensor([[-0.5565, -1.9406],
        [-0.5220, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11185438930988312
Epoch 0, Step 242: train/loss = 0.6586037874221802, train/raw-loss = 0.607784628868103, train/logprobs = tensor([[-0.5837, -1.0421],
        [-0.4083, -0.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10163818299770355
Epoch 0, Step 243: train/loss = 0.6710735559463501, train/raw-loss = 0.6238260269165039, train/logprobs = tensor([[-0.8168, -1.1891],
        [-0.5059, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09449508786201477
Epoch 0, Step 244: train/loss = 0.5155724287033081, train/raw-loss = 0.45705360174179077, train/logprobs = tensor([[-1.0545, -3.8010],
        [-0.6937, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11703765392303467
Epoch 0, Step 245: train/loss = 0.5659320950508118, train/raw-loss = 0.509590208530426, train/logprobs = tensor([[-1.0921, -2.3911],
        [-0.6480, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268376559019089
Epoch 0, Step 246: train/loss = 0.48630064725875854, train/raw-loss = 0.4287833571434021, train/logprobs = tensor([[-0.6739, -3.9461],
        [-0.6728, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11503459513187408
Epoch 0, Step 247: train/loss = 0.5895606875419617, train/raw-loss = 0.5336179137229919, train/logprobs = tensor([[-0.9678, -2.5518],
        [-0.7397, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188540607690811
Epoch 0, Step 248: train/loss = 0.6252986788749695, train/raw-loss = 0.5784711241722107, train/logprobs = tensor([[-0.6675, -1.9316],
        [-0.6795, -1.3210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0936550498008728
Epoch 0, Step 249: train/loss = 0.5576127767562866, train/raw-loss = 0.5078161358833313, train/logprobs = tensor([[-0.4840, -2.3027],
        [-0.5063, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09959334135055542
Epoch 0, Step 250: train/loss = 0.5384417772293091, train/raw-loss = 0.4815751314163208, train/logprobs = tensor([[-1.2273, -4.3864],
        [-0.5852, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11373329162597656
Epoch 0, Step 251: train/loss = 0.44245630502700806, train/raw-loss = 0.38499847054481506, train/logprobs = tensor([[-0.6577, -2.9855],
        [-0.6384, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1149156391620636
Epoch 0, Step 252: train/loss = 0.5903768539428711, train/raw-loss = 0.5410356521606445, train/logprobs = tensor([[-0.4970, -1.6467],
        [-0.4106, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868235886096954
Epoch 0, Step 253: train/loss = 0.7350332736968994, train/raw-loss = 0.6871984004974365, train/logprobs = tensor([[-0.7720, -0.6352],
        [-0.6311, -0.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956697165966034
Epoch 0, Step 254: train/loss = 0.5036976933479309, train/raw-loss = 0.44983047246932983, train/logprobs = tensor([[-0.7722, -3.3359],
        [-0.5885, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10773445665836334
Epoch 0, Step 255: train/loss = 0.5966665744781494, train/raw-loss = 0.5409376621246338, train/logprobs = tensor([[-1.1044, -2.6094],
        [-0.8929, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11145775765180588
Epoch 0, Step 256: train/loss = 0.6878990530967712, train/raw-loss = 0.646673321723938, train/logprobs = tensor([[-0.5758, -0.8756],
        [-0.4357, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245154470205307
Epoch 0, Step 257: train/loss = 0.6732048988342285, train/raw-loss = 0.6254039406776428, train/logprobs = tensor([[-0.7809, -1.2617],
        [-0.6007, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.095601886510849
Epoch 0, Step 258: train/loss = 0.4013896584510803, train/raw-loss = 0.34608110785484314, train/logprobs = tensor([[-0.9284, -3.4018],
        [-0.9503, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11061719059944153
Epoch 0, Step 259: train/loss = 0.5581095814704895, train/raw-loss = 0.5146297216415405, train/logprobs = tensor([[-0.5926, -3.7871],
        [-0.5164, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08695979416370392
Epoch 0, Step 260: train/loss = 0.47346651554107666, train/raw-loss = 0.42425060272216797, train/logprobs = tensor([[-0.5328, -4.6550],
        [-0.4682, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843183308839798
Epoch 0, Step 261: train/loss = 0.5131011009216309, train/raw-loss = 0.4536224901676178, train/logprobs = tensor([[-0.8229, -2.2296],
        [-0.8453, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11895723640918732
Epoch 0, Step 262: train/loss = 0.5854861736297607, train/raw-loss = 0.5327243208885193, train/logprobs = tensor([[-0.7092, -2.4984],
        [-0.6177, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552369803190231
Epoch 0, Step 263: train/loss = 0.6424791812896729, train/raw-loss = 0.5863530039787292, train/logprobs = tensor([[-1.3132, -2.1051],
        [-1.0641, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11225231736898422
Epoch 0, Step 264: train/loss = 0.6298127770423889, train/raw-loss = 0.5834060907363892, train/logprobs = tensor([[-0.7534, -1.4128],
        [-0.6742, -0.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09281343966722488
Epoch 0, Step 265: train/loss = 0.683170735836029, train/raw-loss = 0.6355187892913818, train/logprobs = tensor([[-0.8969, -1.3399],
        [-0.6491, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530390053987503
Epoch 0, Step 266: train/loss = 0.4597669243812561, train/raw-loss = 0.4052525758743286, train/logprobs = tensor([[-1.0242, -3.4908],
        [-1.0191, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902871191501617
Epoch 0, Step 267: train/loss = 0.5023714303970337, train/raw-loss = 0.4498223662376404, train/logprobs = tensor([[-0.6977, -2.4360],
        [-0.5568, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10509806871414185
Epoch 0, Step 268: train/loss = 0.5320757627487183, train/raw-loss = 0.48633694648742676, train/logprobs = tensor([[-0.6638, -5.0953],
        [-0.6585, -1.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09147760272026062
Epoch 0, Step 269: train/loss = 0.5452837944030762, train/raw-loss = 0.4944620430469513, train/logprobs = tensor([[-0.7980, -3.9638],
        [-0.7016, -1.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10164351761341095
Epoch 0, Step 270: train/loss = 0.5345134139060974, train/raw-loss = 0.48264971375465393, train/logprobs = tensor([[-0.4138, -2.1217],
        [-0.3533, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1037273183465004
Epoch 0, Step 271: train/loss = 0.5441092848777771, train/raw-loss = 0.49218130111694336, train/logprobs = tensor([[-0.7979, -2.1624],
        [-0.6632, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385598242282867
Epoch 0, Step 272: train/loss = 0.7086414694786072, train/raw-loss = 0.6619646549224854, train/logprobs = tensor([[-0.6178, -0.8474],
        [-0.5513, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335361421108246
Epoch 0, Step 273: train/loss = 0.6058681607246399, train/raw-loss = 0.5572568774223328, train/logprobs = tensor([[-0.4715, -1.2785],
        [-0.4925, -0.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09722250699996948
Epoch 0, Step 274: train/loss = 0.6246079206466675, train/raw-loss = 0.573030948638916, train/logprobs = tensor([[-0.5790, -1.6523],
        [-0.4900, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10315395891666412
Epoch 0, Step 275: train/loss = 0.5209708213806152, train/raw-loss = 0.4787684381008148, train/logprobs = tensor([[-0.4877, -1.8535],
        [-0.4398, -0.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08440461754798889
Epoch 0, Step 276: train/loss = 0.5831415057182312, train/raw-loss = 0.5294452905654907, train/logprobs = tensor([[-1.2527, -2.6167],
        [-1.0599, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739235579967499
Epoch 0, Step 277: train/loss = 0.6453189849853516, train/raw-loss = 0.5874301195144653, train/logprobs = tensor([[-0.7832, -1.2226],
        [-0.7566, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577769368886948
Epoch 0, Step 278: train/loss = 0.5862230062484741, train/raw-loss = 0.5302728414535522, train/logprobs = tensor([[-0.7938, -1.4293],
        [-0.7186, -0.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190026998519897
Epoch 0, Step 279: train/loss = 0.4580496847629547, train/raw-loss = 0.4032188355922699, train/logprobs = tensor([[-1.0199, -4.2210],
        [-0.7453, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10966168344020844
Epoch 0, Step 280: train/loss = 0.5320385694503784, train/raw-loss = 0.4797557294368744, train/logprobs = tensor([[-0.8075, -4.4179],
        [-0.6310, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456569492816925
Epoch 0, Step 281: train/loss = 0.6022338271141052, train/raw-loss = 0.555004358291626, train/logprobs = tensor([[-0.5591, -1.1965],
        [-0.4824, -0.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445888549089432
Epoch 0, Step 282: train/loss = 0.607042670249939, train/raw-loss = 0.5384592413902283, train/logprobs = tensor([[-1.2465, -3.2417],
        [-0.8128, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13716687262058258
Epoch 0, Step 283: train/loss = 0.5488379001617432, train/raw-loss = 0.49795886874198914, train/logprobs = tensor([[-0.7723, -2.2470],
        [-0.6185, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175793617963791
Epoch 0, Step 284: train/loss = 0.5975539684295654, train/raw-loss = 0.5458458065986633, train/logprobs = tensor([[-0.4868, -1.3668],
        [-0.4871, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034163162112236
Epoch 0, Step 285: train/loss = 0.6223431825637817, train/raw-loss = 0.573598325252533, train/logprobs = tensor([[-0.5789, -1.1686],
        [-0.5722, -0.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09748966991901398
Epoch 0, Step 286: train/loss = 0.5492600202560425, train/raw-loss = 0.5028667449951172, train/logprobs = tensor([[-0.4147, -1.7763],
        [-0.3448, -0.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927867442369461
Epoch 0, Step 287: train/loss = 0.532850444316864, train/raw-loss = 0.4777159094810486, train/logprobs = tensor([[-0.7721, -3.8054],
        [-0.7526, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11026903986930847
Epoch 0, Step 288: train/loss = 0.5706228613853455, train/raw-loss = 0.5197845697402954, train/logprobs = tensor([[-0.5725, -1.6727],
        [-0.6064, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10167653858661652
Epoch 0, Step 289: train/loss = 0.5430316925048828, train/raw-loss = 0.4861411154270172, train/logprobs = tensor([[-0.8274, -3.1474],
        [-0.7390, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11378110945224762
Epoch 0, Step 290: train/loss = 0.5358476638793945, train/raw-loss = 0.4869697093963623, train/logprobs = tensor([[-0.5646, -2.9064],
        [-0.5352, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09775592386722565
Epoch 0, Step 291: train/loss = 0.48549413681030273, train/raw-loss = 0.43331828713417053, train/logprobs = tensor([[-0.7081, -2.1828],
        [-0.7609, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.104351706802845
Epoch 0, Step 292: train/loss = 0.5750811696052551, train/raw-loss = 0.5276319980621338, train/logprobs = tensor([[-0.6073, -1.3770],
        [-0.6802, -0.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09489835798740387
Epoch 0, Step 293: train/loss = 0.5724096298217773, train/raw-loss = 0.5160204172134399, train/logprobs = tensor([[-0.7763, -2.2149],
        [-0.7046, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127784326672554
Epoch 0, Step 294: train/loss = 0.5714069604873657, train/raw-loss = 0.5196864604949951, train/logprobs = tensor([[-0.8972, -1.6753],
        [-0.7725, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10344085097312927
Epoch 0, Step 295: train/loss = 0.5494601726531982, train/raw-loss = 0.4934781491756439, train/logprobs = tensor([[-1.3893, -2.8889],
        [-1.2558, -1.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11196400225162506
Epoch 0, Step 296: train/loss = 0.5893237590789795, train/raw-loss = 0.5392370223999023, train/logprobs = tensor([[-0.6810, -1.8910],
        [-0.6400, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017350316047668
Epoch 0, Step 297: train/loss = 0.48571550846099854, train/raw-loss = 0.4355560839176178, train/logprobs = tensor([[-0.6237, -3.3614],
        [-0.6601, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003188043832779
Epoch 0, Step 298: train/loss = 0.5617954134941101, train/raw-loss = 0.5145425200462341, train/logprobs = tensor([[-0.5491, -1.5187],
        [-0.6792, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0945056900382042
Epoch 0, Step 299: train/loss = 0.4795074462890625, train/raw-loss = 0.43060874938964844, train/logprobs = tensor([[-0.9928, -2.9707],
        [-0.9847, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779739379882812
Epoch 0, Step 300: train/loss = 0.5341558456420898, train/raw-loss = 0.4871475100517273, train/logprobs = tensor([[-0.7420, -2.3911],
        [-0.7729, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401663392782211
Epoch 0, Step 301: train/loss = 0.5869651436805725, train/raw-loss = 0.5346145033836365, train/logprobs = tensor([[-0.6384, -1.2781],
        [-0.5976, -0.4031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470129549503326
Epoch 0, Step 302: train/loss = 0.5113179683685303, train/raw-loss = 0.460438072681427, train/logprobs = tensor([[-0.6466, -2.2341],
        [-0.6002, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175967961549759
Epoch 0, Step 303: train/loss = 0.4723210334777832, train/raw-loss = 0.42120227217674255, train/logprobs = tensor([[-0.5407, -2.6163],
        [-0.5666, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10223758965730667
Epoch 0, Step 304: train/loss = 0.5703436732292175, train/raw-loss = 0.5192397832870483, train/logprobs = tensor([[-0.6374, -1.7135],
        [-0.6296, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10220779478549957
Epoch 0, Step 305: train/loss = 0.566116213798523, train/raw-loss = 0.5109736919403076, train/logprobs = tensor([[-0.8689, -2.7615],
        [-0.5371, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028511822223663
Epoch 0, Step 306: train/loss = 0.5966755747795105, train/raw-loss = 0.5468078851699829, train/logprobs = tensor([[-0.8045, -3.5091],
        [-0.6759, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997353196144104
Epoch 0, Step 307: train/loss = 0.574435293674469, train/raw-loss = 0.521045446395874, train/logprobs = tensor([[-0.8355, -4.0076],
        [-0.8372, -1.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10677981376647949
Epoch 0, Step 308: train/loss = 0.6070351600646973, train/raw-loss = 0.5580998659133911, train/logprobs = tensor([[-0.6955, -1.3804],
        [-0.6470, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09787063300609589
Epoch 0, Step 309: train/loss = 0.6179558038711548, train/raw-loss = 0.5705127716064453, train/logprobs = tensor([[-0.5182, -1.3150],
        [-0.4602, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09488606452941895
Epoch 0, Step 310: train/loss = 0.4250282645225525, train/raw-loss = 0.36873748898506165, train/logprobs = tensor([[-0.6680, -4.0832],
        [-0.5455, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258158087730408
Epoch 0, Step 311: train/loss = 0.5727789998054504, train/raw-loss = 0.5242340564727783, train/logprobs = tensor([[-0.5655, -2.5242],
        [-0.6041, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708994626998901
Epoch 0, Step 312: train/loss = 0.6053004860877991, train/raw-loss = 0.5610640048980713, train/logprobs = tensor([[-0.6593, -3.3203],
        [-0.5246, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884728878736496
Epoch 0, Step 313: train/loss = 0.514297604560852, train/raw-loss = 0.45819228887557983, train/logprobs = tensor([[-0.6298, -2.3194],
        [-0.6236, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11221054196357727
Epoch 0, Step 314: train/loss = 0.6449005603790283, train/raw-loss = 0.5981168150901794, train/logprobs = tensor([[-0.6079, -0.8683],
        [-0.6214, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356747567653656
Epoch 0, Step 315: train/loss = 0.6068011522293091, train/raw-loss = 0.551621675491333, train/logprobs = tensor([[-1.8262, -3.5792],
        [-1.3759, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11035898327827454
Epoch 0, Step 316: train/loss = 0.710845947265625, train/raw-loss = 0.6719553470611572, train/logprobs = tensor([[-0.7377, -0.6828],
        [-0.7357, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07778122276067734
Epoch 0, Step 317: train/loss = 0.4538058638572693, train/raw-loss = 0.40234246850013733, train/logprobs = tensor([[-0.4766, -4.3855],
        [-0.4915, -1.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10292679071426392
Epoch 0, Step 318: train/loss = 0.47572481632232666, train/raw-loss = 0.424604207277298, train/logprobs = tensor([[-0.7397, -2.6881],
        [-0.7498, -0.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1022411584854126
Epoch 0, Step 319: train/loss = 0.5038726329803467, train/raw-loss = 0.4515189230442047, train/logprobs = tensor([[-0.5425, -2.6819],
        [-0.5685, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470733791589737
Epoch 0, Step 320: train/loss = 0.5384807586669922, train/raw-loss = 0.49270251393318176, train/logprobs = tensor([[-0.8057, -2.5716],
        [-0.6657, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09155643731355667
Epoch 0, Step 321: train/loss = 0.5634372234344482, train/raw-loss = 0.5212448835372925, train/logprobs = tensor([[-0.6275, -1.6879],
        [-0.6089, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438466489315033
Epoch 0, Step 322: train/loss = 0.47237181663513184, train/raw-loss = 0.4264025092124939, train/logprobs = tensor([[-1.0180, -3.9167],
        [-0.9040, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09193859249353409
Epoch 0, Step 323: train/loss = 0.5206960439682007, train/raw-loss = 0.4763430058956146, train/logprobs = tensor([[-0.4119, -2.2458],
        [-0.4368, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08870596438646317
Epoch 0, Step 324: train/loss = 0.39310920238494873, train/raw-loss = 0.3395349383354187, train/logprobs = tensor([[-0.7847, -5.1866],
        [-0.6685, -1.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714854300022125
Epoch 0, Step 325: train/loss = 0.6373192667961121, train/raw-loss = 0.595417320728302, train/logprobs = tensor([[-0.5997, -1.1207],
        [-0.5664, -0.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380384743213654
Epoch 0, Step 326: train/loss = 0.43625566363334656, train/raw-loss = 0.3861100673675537, train/logprobs = tensor([[-0.8955, -4.7619],
        [-1.0263, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1002911776304245
Epoch 0, Step 327: train/loss = 0.7282470464706421, train/raw-loss = 0.678020715713501, train/logprobs = tensor([[-0.8332, -1.0495],
        [-0.6346, -0.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10045281797647476
Epoch 0, Step 328: train/loss = 0.6289274096488953, train/raw-loss = 0.5874164700508118, train/logprobs = tensor([[-0.8279, -1.6717],
        [-0.8142, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08302199840545654
Epoch 0, Step 329: train/loss = 0.6209645867347717, train/raw-loss = 0.5714305639266968, train/logprobs = tensor([[-1.0681, -1.5439],
        [-0.8671, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09906802326440811
Epoch 0, Step 330: train/loss = 0.37390345335006714, train/raw-loss = 0.32446378469467163, train/logprobs = tensor([[-0.6707, -4.2274],
        [-0.6510, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09887929260730743
Epoch 0, Step 331: train/loss = 0.49174702167510986, train/raw-loss = 0.4506138265132904, train/logprobs = tensor([[-0.6202, -3.9284],
        [-0.6101, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08226637542247772
Epoch 0, Step 332: train/loss = 0.4426844120025635, train/raw-loss = 0.391315221786499, train/logprobs = tensor([[-0.7727, -3.5435],
        [-0.8926, -1.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273841768503189
Epoch 0, Step 333: train/loss = 0.5332008600234985, train/raw-loss = 0.48444491624832153, train/logprobs = tensor([[-0.7559, -2.7678],
        [-0.6157, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09751195460557938
Epoch 0, Step 334: train/loss = 0.6578266620635986, train/raw-loss = 0.6164852380752563, train/logprobs = tensor([[-0.7318, -0.9181],
        [-0.6423, -0.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268287777900696
Epoch 0, Step 335: train/loss = 0.4754661023616791, train/raw-loss = 0.4289434254169464, train/logprobs = tensor([[-0.6436, -2.2718],
        [-0.5661, -0.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09304534643888474
Epoch 0, Step 336: train/loss = 0.5497026443481445, train/raw-loss = 0.5023619532585144, train/logprobs = tensor([[-0.5459, -1.6659],
        [-0.6034, -0.6379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468135982751846
Epoch 0, Step 337: train/loss = 0.5309405326843262, train/raw-loss = 0.480701744556427, train/logprobs = tensor([[-0.8602, -2.1090],
        [-0.8629, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10047763586044312
Epoch 0, Step 338: train/loss = 0.5446065664291382, train/raw-loss = 0.49729156494140625, train/logprobs = tensor([[-0.5525, -1.6185],
        [-0.5640, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09462998807430267
Epoch 0, Step 339: train/loss = 0.48440200090408325, train/raw-loss = 0.4397781491279602, train/logprobs = tensor([[-0.3720, -4.1164],
        [-0.3994, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924776315689087
Epoch 0, Step 340: train/loss = 0.6167072057723999, train/raw-loss = 0.5753881335258484, train/logprobs = tensor([[-0.7766, -1.3435],
        [-0.7251, -0.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08263810724020004
Epoch 0, Step 341: train/loss = 0.41689205169677734, train/raw-loss = 0.3682015538215637, train/logprobs = tensor([[-0.6038, -3.0916],
        [-0.6798, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09738096594810486
Epoch 0, Step 342: train/loss = 0.5190495848655701, train/raw-loss = 0.4771333336830139, train/logprobs = tensor([[-0.5567, -2.6381],
        [-0.6120, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838325023651123
Epoch 0, Step 343: train/loss = 0.6022127866744995, train/raw-loss = 0.5593593120574951, train/logprobs = tensor([[-0.6542, -2.0258],
        [-0.6753, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08570696413516998
Epoch 0, Step 344: train/loss = 0.4442852735519409, train/raw-loss = 0.39538145065307617, train/logprobs = tensor([[-0.9241, -5.3788],
        [-0.8097, -1.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780767560005188
Epoch 0, Step 345: train/loss = 0.49996647238731384, train/raw-loss = 0.4544225037097931, train/logprobs = tensor([[-1.1206, -3.7130],
        [-1.1413, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09108792990446091
Epoch 0, Step 346: train/loss = 0.5264341831207275, train/raw-loss = 0.4770044684410095, train/logprobs = tensor([[-0.7738, -3.6792],
        [-0.7323, -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09885939210653305
Epoch 0, Step 347: train/loss = 0.5260098576545715, train/raw-loss = 0.4802776277065277, train/logprobs = tensor([[-0.6042, -4.2164],
        [-0.6357, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09146440029144287
Epoch 0, Step 348: train/loss = 0.5457789897918701, train/raw-loss = 0.5053784251213074, train/logprobs = tensor([[-0.7271, -2.9946],
        [-0.7887, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0808010846376419
Epoch 0, Step 349: train/loss = 0.4335830807685852, train/raw-loss = 0.38162481784820557, train/logprobs = tensor([[-0.6881, -2.7348],
        [-0.7413, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391651093959808
Epoch 0, Step 350: train/loss = 0.6197946071624756, train/raw-loss = 0.5682455897331238, train/logprobs = tensor([[-1.2084, -2.4326],
        [-0.9932, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309812426567078
Epoch 0, Step 351: train/loss = 0.5441430807113647, train/raw-loss = 0.49635523557662964, train/logprobs = tensor([[-0.7268, -2.4275],
        [-0.7265, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09557566046714783
Epoch 0, Step 352: train/loss = 0.47603458166122437, train/raw-loss = 0.4310411214828491, train/logprobs = tensor([[-0.5118, -3.5065],
        [-0.5984, -0.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08998695760965347
Epoch 0, Step 353: train/loss = 0.4168551564216614, train/raw-loss = 0.3691442012786865, train/logprobs = tensor([[-0.7105, -4.3127],
        [-0.8495, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954219326376915
Epoch 0, Step 354: train/loss = 0.6428890228271484, train/raw-loss = 0.6030555367469788, train/logprobs = tensor([[-0.4831, -0.9562],
        [-0.5109, -0.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07966701686382294
Epoch 0, Step 355: train/loss = 0.5257806777954102, train/raw-loss = 0.48191967606544495, train/logprobs = tensor([[-0.7276, -2.4891],
        [-0.7926, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772195875644684
Epoch 0, Step 356: train/loss = 0.6317158937454224, train/raw-loss = 0.5875234603881836, train/logprobs = tensor([[-0.5041, -1.0724],
        [-0.4918, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08838489651679993
Epoch 0, Step 357: train/loss = 0.6703314781188965, train/raw-loss = 0.6224720478057861, train/logprobs = tensor([[-1.7998, -2.4182],
        [-1.4082, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09571892023086548
Epoch 0, Step 358: train/loss = 0.5418346524238586, train/raw-loss = 0.5031014680862427, train/logprobs = tensor([[-0.5219, -3.8615],
        [-0.4979, -1.2704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774664357304573
Epoch 0, Step 359: train/loss = 0.5930720567703247, train/raw-loss = 0.5461965203285217, train/logprobs = tensor([[-0.8998, -1.8452],
        [-0.8490, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09375109523534775
Epoch 0, Step 360: train/loss = 0.5502147674560547, train/raw-loss = 0.5033124089241028, train/logprobs = tensor([[-0.8860, -2.5037],
        [-0.8278, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09380465000867844
Epoch 0, Step 361: train/loss = 0.5821542739868164, train/raw-loss = 0.5333777666091919, train/logprobs = tensor([[-0.6088, -1.1890],
        [-0.6905, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09755301475524902
Epoch 0, Step 362: train/loss = 0.6099370121955872, train/raw-loss = 0.569390058517456, train/logprobs = tensor([[-0.6650, -1.6795],
        [-0.6678, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08109385520219803
Epoch 0, Step 363: train/loss = 0.7489016056060791, train/raw-loss = 0.7112535238265991, train/logprobs = tensor([[-1.2366, -1.1310],
        [-0.8790, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07529618591070175
Epoch 0, Step 364: train/loss = 0.41948848962783813, train/raw-loss = 0.3768860697746277, train/logprobs = tensor([[-0.4062, -5.1033],
        [-0.5325, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852048248052597
Epoch 0, Step 365: train/loss = 0.4598665237426758, train/raw-loss = 0.41330477595329285, train/logprobs = tensor([[-0.5433, -2.4947],
        [-0.5972, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09312346577644348
Epoch 0, Step 366: train/loss = 0.5484704971313477, train/raw-loss = 0.504844605922699, train/logprobs = tensor([[-0.5839, -2.4702],
        [-0.5961, -0.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08725177496671677
Epoch 0, Step 367: train/loss = 0.45316192507743835, train/raw-loss = 0.4093054533004761, train/logprobs = tensor([[-0.5794, -3.1906],
        [-0.6875, -0.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771301805973053
Epoch 0, Step 368: train/loss = 0.5028402805328369, train/raw-loss = 0.4587370753288269, train/logprobs = tensor([[-0.4246, -2.3188],
        [-0.4337, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882064551115036
Epoch 0, Step 369: train/loss = 0.5138723254203796, train/raw-loss = 0.47296860814094543, train/logprobs = tensor([[-0.4534, -1.8766],
        [-0.5289, -0.6484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08180742710828781
Epoch 0, Step 370: train/loss = 0.6505556106567383, train/raw-loss = 0.6134589910507202, train/logprobs = tensor([[-0.3990, -0.8395],
        [-0.4163, -0.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07419313490390778
Epoch 0, Step 371: train/loss = 0.514262318611145, train/raw-loss = 0.47438833117485046, train/logprobs = tensor([[-0.4290, -2.9709],
        [-0.4613, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07974792271852493
Epoch 0, Step 372: train/loss = 0.4630841314792633, train/raw-loss = 0.41973423957824707, train/logprobs = tensor([[-0.5639, -3.0362],
        [-0.5417, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08669984340667725
Epoch 0, Step 373: train/loss = 0.545886754989624, train/raw-loss = 0.5013887882232666, train/logprobs = tensor([[-0.7640, -4.1995],
        [-0.6905, -1.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899588882923126
Epoch 0, Step 374: train/loss = 0.5467888116836548, train/raw-loss = 0.5041437149047852, train/logprobs = tensor([[-0.3170, -2.1715],
        [-0.3528, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529027551412582
Epoch 0, Step 375: train/loss = 0.5232180953025818, train/raw-loss = 0.47495609521865845, train/logprobs = tensor([[-0.7321, -1.5886],
        [-0.9306, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0965239629149437
Epoch 0, Step 376: train/loss = 0.44274598360061646, train/raw-loss = 0.39470797777175903, train/logprobs = tensor([[-0.6225, -4.3191],
        [-0.8156, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09607598930597305
Epoch 0, Step 377: train/loss = 0.5879814624786377, train/raw-loss = 0.5436182022094727, train/logprobs = tensor([[-0.6503, -2.5208],
        [-0.5781, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0887264534831047
Epoch 0, Step 378: train/loss = 0.5540543794631958, train/raw-loss = 0.5127465724945068, train/logprobs = tensor([[-0.7094, -3.4073],
        [-0.6884, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261565119028091
Epoch 0, Step 379: train/loss = 0.6166815161705017, train/raw-loss = 0.5766898989677429, train/logprobs = tensor([[-0.9527, -2.0196],
        [-0.8267, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0799831748008728
Epoch 0, Step 380: train/loss = 0.5374978184700012, train/raw-loss = 0.4939371347427368, train/logprobs = tensor([[-0.6051, -1.7780],
        [-0.6437, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08712142705917358
Epoch 0, Step 381: train/loss = 0.46138501167297363, train/raw-loss = 0.41298675537109375, train/logprobs = tensor([[-0.6758, -3.8025],
        [-0.8767, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679650515317917
Epoch 0, Step 382: train/loss = 0.41663646697998047, train/raw-loss = 0.3708500564098358, train/logprobs = tensor([[-0.5549, -3.4211],
        [-0.5967, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157292544841766
Epoch 0, Step 383: train/loss = 0.45939570665359497, train/raw-loss = 0.4095727205276489, train/logprobs = tensor([[-0.4670, -2.4059],
        [-0.6085, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09964605420827866
Epoch 0, Step 384: train/loss = 0.5157966613769531, train/raw-loss = 0.4635620713233948, train/logprobs = tensor([[-0.8164, -5.6022],
        [-0.9009, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044691950082779
Epoch 0, Step 385: train/loss = 0.6054333448410034, train/raw-loss = 0.5461717844009399, train/logprobs = tensor([[-1.1741, -2.0131],
        [-0.9954, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852309107780457
Epoch 0, Step 386: train/loss = 0.7302956581115723, train/raw-loss = 0.690273106098175, train/logprobs = tensor([[-0.8873, -0.8483],
        [-0.6741, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08004511147737503
Epoch 0, Step 387: train/loss = 0.5011193156242371, train/raw-loss = 0.45203277468681335, train/logprobs = tensor([[-0.6463, -4.6161],
        [-0.8411, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817319363355637
Epoch 0, Step 388: train/loss = 0.5611264705657959, train/raw-loss = 0.5037537813186646, train/logprobs = tensor([[-0.7170, -2.1836],
        [-0.7727, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11474534869194031
Epoch 0, Step 389: train/loss = 0.4753066301345825, train/raw-loss = 0.4172440469264984, train/logprobs = tensor([[-0.5959, -2.3889],
        [-0.6683, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11612509191036224
Epoch 0, Step 390: train/loss = 0.4714601933956146, train/raw-loss = 0.4156070947647095, train/logprobs = tensor([[-1.0123, -2.5622],
        [-1.3129, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1117062121629715
Epoch 0, Step 391: train/loss = 0.5468771457672119, train/raw-loss = 0.49918049573898315, train/logprobs = tensor([[-0.4907, -1.8349],
        [-0.5197, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539321810007095
Epoch 0, Step 392: train/loss = 0.46150532364845276, train/raw-loss = 0.41571375727653503, train/logprobs = tensor([[-0.4786, -3.2447],
        [-0.6363, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09158311039209366
Epoch 0, Step 393: train/loss = 0.5746825337409973, train/raw-loss = 0.5190917253494263, train/logprobs = tensor([[-0.7411, -1.8596],
        [-0.6302, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11118161678314209
Epoch 0, Step 394: train/loss = 0.4353579878807068, train/raw-loss = 0.3853805363178253, train/logprobs = tensor([[-0.8603, -6.0665],
        [-0.8392, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995490312576294
Epoch 0, Step 395: train/loss = 0.5070009827613831, train/raw-loss = 0.4656221866607666, train/logprobs = tensor([[-0.6830, -5.5216],
        [-0.4636, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08275751024484634
Epoch 0, Step 396: train/loss = 0.5500911474227905, train/raw-loss = 0.5011996030807495, train/logprobs = tensor([[-0.7398, -1.9192],
        [-0.7500, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09778305888175964
Epoch 0, Step 397: train/loss = 0.5729977488517761, train/raw-loss = 0.5251118540763855, train/logprobs = tensor([[-0.4818, -2.1513],
        [-0.4602, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577173739671707
Epoch 0, Step 398: train/loss = 0.42127013206481934, train/raw-loss = 0.3683270514011383, train/logprobs = tensor([[-0.5818, -3.3653],
        [-0.7087, -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588615387678146
Epoch 0, Step 399: train/loss = 0.5859387516975403, train/raw-loss = 0.5362653732299805, train/logprobs = tensor([[-0.8203, -1.4279],
        [-0.9552, -0.7159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934671223163605
Epoch 0, Step 400: train/loss = 0.5820416212081909, train/raw-loss = 0.5403212308883667, train/logprobs = tensor([[-0.5239, -1.3122],
        [-0.5689, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0834406390786171
Epoch 0, Step 401: train/loss = 0.441895991563797, train/raw-loss = 0.39524245262145996, train/logprobs = tensor([[-0.7816, -3.4218],
        [-0.8316, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09330709278583527
Epoch 0, Step 402: train/loss = 0.4595089256763458, train/raw-loss = 0.40921977162361145, train/logprobs = tensor([[-0.6900, -3.2689],
        [-0.6855, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10057833790779114
Epoch 0, Step 403: train/loss = 0.5485504865646362, train/raw-loss = 0.5116667747497559, train/logprobs = tensor([[-0.3320, -1.7219],
        [-0.3631, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07376745343208313
Epoch 0, Step 404: train/loss = 0.647965669631958, train/raw-loss = 0.6054877638816833, train/logprobs = tensor([[-0.5743, -1.2468],
        [-0.5076, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08495573699474335
Epoch 0, Step 405: train/loss = 0.5753060579299927, train/raw-loss = 0.5333876609802246, train/logprobs = tensor([[-0.4627, -3.1879],
        [-0.5278, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383671939373016
Epoch 0, Step 406: train/loss = 0.5453386306762695, train/raw-loss = 0.4976384937763214, train/logprobs = tensor([[-0.5666, -2.1617],
        [-0.5878, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954003781080246
Epoch 0, Step 407: train/loss = 0.6096456050872803, train/raw-loss = 0.5726037621498108, train/logprobs = tensor([[-0.5134, -1.0720],
        [-0.5139, -0.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07408380508422852
Epoch 0, Step 408: train/loss = 0.6033334732055664, train/raw-loss = 0.5528188943862915, train/logprobs = tensor([[-0.6066, -1.1776],
        [-0.8275, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102929174900055
Epoch 0, Step 409: train/loss = 0.33799493312835693, train/raw-loss = 0.28417113423347473, train/logprobs = tensor([[-0.8614, -4.8234],
        [-1.1714, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764756053686142
Epoch 0, Step 410: train/loss = 0.5921513438224792, train/raw-loss = 0.5456377863883972, train/logprobs = tensor([[-0.5818, -2.0784],
        [-0.5429, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09302709996700287
Epoch 0, Step 411: train/loss = 0.5565301775932312, train/raw-loss = 0.49988657236099243, train/logprobs = tensor([[-0.4969, -1.5468],
        [-0.5689, -0.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328719556331635
Epoch 0, Step 412: train/loss = 0.6011875867843628, train/raw-loss = 0.5546039342880249, train/logprobs = tensor([[-0.4676, -1.4213],
        [-0.5728, -0.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09316735714673996
Epoch 0, Step 413: train/loss = 0.5685167908668518, train/raw-loss = 0.5272809267044067, train/logprobs = tensor([[-0.7626, -3.9867],
        [-0.6381, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247168362140656
Epoch 0, Step 414: train/loss = 0.5121913552284241, train/raw-loss = 0.4696904122829437, train/logprobs = tensor([[-0.4276, -1.7272],
        [-0.5499, -0.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500190079212189
Epoch 0, Step 415: train/loss = 0.4881972670555115, train/raw-loss = 0.44004738330841064, train/logprobs = tensor([[-0.7613, -3.9839],
        [-0.8013, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09629984200000763
Epoch 0, Step 416: train/loss = 0.6263325214385986, train/raw-loss = 0.5785076022148132, train/logprobs = tensor([[-0.7315, -1.4038],
        [-0.6825, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564992785453796
Epoch 0, Step 417: train/loss = 0.4538487195968628, train/raw-loss = 0.39546048641204834, train/logprobs = tensor([[-0.6126, -3.9342],
        [-0.9001, -0.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677640676498413
Epoch 0, Step 418: train/loss = 0.43391650915145874, train/raw-loss = 0.38379958271980286, train/logprobs = tensor([[-0.6146, -2.5668],
        [-0.8984, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10023380815982819
Epoch 0, Step 419: train/loss = 0.4751545190811157, train/raw-loss = 0.42307353019714355, train/logprobs = tensor([[-0.8807, -3.2711],
        [-0.8919, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10416197776794434
Epoch 0, Step 420: train/loss = 0.5078010559082031, train/raw-loss = 0.4542735815048218, train/logprobs = tensor([[-0.7219, -3.0064],
        [-0.8327, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10705491155385971
Epoch 0, Step 421: train/loss = 0.4348289966583252, train/raw-loss = 0.37906575202941895, train/logprobs = tensor([[-0.6789, -2.3595],
        [-0.9889, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11152651906013489
Epoch 0, Step 422: train/loss = 0.4302098751068115, train/raw-loss = 0.37120795249938965, train/logprobs = tensor([[-0.9862, -4.1328],
        [-1.0192, -1.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800381541252136
Epoch 0, Step 423: train/loss = 0.5387288331985474, train/raw-loss = 0.4892420172691345, train/logprobs = tensor([[-0.5881, -3.1003],
        [-0.5689, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09897364675998688
Epoch 0, Step 424: train/loss = 0.4093133509159088, train/raw-loss = 0.3587999939918518, train/logprobs = tensor([[-0.6001, -4.2627],
        [-0.7494, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102676600217819
Epoch 0, Step 425: train/loss = 0.8815168142318726, train/raw-loss = 0.8377902507781982, train/logprobs = tensor([[-1.9900, -3.0592],
        [-0.6542, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08745329082012177
Epoch 0, Step 426: train/loss = 0.48171374201774597, train/raw-loss = 0.4201832413673401, train/logprobs = tensor([[-0.8628, -2.5169],
        [-0.9958, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306109815835953
Epoch 0, Step 427: train/loss = 0.43356823921203613, train/raw-loss = 0.384021520614624, train/logprobs = tensor([[-0.5868, -2.8048],
        [-0.6639, -0.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909345209598541
Epoch 0, Step 428: train/loss = 0.7401179075241089, train/raw-loss = 0.6877748966217041, train/logprobs = tensor([[-0.9793, -1.1511],
        [-0.6297, -0.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468608140945435
Epoch 0, Step 429: train/loss = 0.41644373536109924, train/raw-loss = 0.36960646510124207, train/logprobs = tensor([[-0.5930, -3.0416],
        [-0.7268, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09367453306913376
Epoch 0, Step 430: train/loss = 0.5366755127906799, train/raw-loss = 0.4914320707321167, train/logprobs = tensor([[-0.6357, -3.1398],
        [-0.6362, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048691391944885
Epoch 0, Step 431: train/loss = 0.5175375938415527, train/raw-loss = 0.46776384115219116, train/logprobs = tensor([[-0.6937, -1.5462],
        [-0.7975, -0.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954751282930374
Epoch 0, Step 432: train/loss = 0.6056917309761047, train/raw-loss = 0.5509551167488098, train/logprobs = tensor([[-0.7300, -1.1993],
        [-0.8598, -0.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094733476638794
Epoch 0, Step 433: train/loss = 0.5770606398582458, train/raw-loss = 0.5311151742935181, train/logprobs = tensor([[-0.6289, -1.5554],
        [-0.6920, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918908640742302
Epoch 0, Step 434: train/loss = 0.3916500210762024, train/raw-loss = 0.32848674058914185, train/logprobs = tensor([[-0.7721, -4.3291],
        [-0.8121, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1263265460729599
Epoch 0, Step 435: train/loss = 0.5757242441177368, train/raw-loss = 0.5124008059501648, train/logprobs = tensor([[-1.3755, -2.7959],
        [-0.9102, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664690613746643
Epoch 0, Step 436: train/loss = 0.4605693221092224, train/raw-loss = 0.4037739038467407, train/logprobs = tensor([[-0.8095, -4.1016],
        [-1.0293, -1.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359082907438278
Epoch 0, Step 437: train/loss = 0.4742501974105835, train/raw-loss = 0.4203924834728241, train/logprobs = tensor([[-0.6747, -3.4124],
        [-0.7643, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771539807319641
Epoch 0, Step 438: train/loss = 0.5123944878578186, train/raw-loss = 0.46152710914611816, train/logprobs = tensor([[-0.5113, -2.4547],
        [-0.6049, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10173475742340088
Epoch 0, Step 439: train/loss = 0.5925569534301758, train/raw-loss = 0.5481501817703247, train/logprobs = tensor([[-0.4858, -1.1850],
        [-0.5695, -0.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881355822086334
Epoch 0, Step 440: train/loss = 0.6023077964782715, train/raw-loss = 0.5502928495407104, train/logprobs = tensor([[-0.8052, -1.7217],
        [-0.6402, -0.5659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10402992367744446
Epoch 0, Step 441: train/loss = 0.6869369745254517, train/raw-loss = 0.6391153931617737, train/logprobs = tensor([[-1.0301, -1.5741],
        [-0.6468, -0.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564316272735596
Epoch 0, Step 442: train/loss = 0.6365477442741394, train/raw-loss = 0.5845437049865723, train/logprobs = tensor([[-0.5116, -1.0468],
        [-0.5433, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10400819033384323
Epoch 0, Step 443: train/loss = 0.7595463991165161, train/raw-loss = 0.7098841071128845, train/logprobs = tensor([[-1.6084, -1.3781],
        [-0.9960, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932462126016617
Epoch 0, Step 444: train/loss = 0.5051301717758179, train/raw-loss = 0.44482558965682983, train/logprobs = tensor([[-0.9077, -2.5161],
        [-0.7039, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060914933681488
Epoch 0, Step 445: train/loss = 0.4580199122428894, train/raw-loss = 0.39890456199645996, train/logprobs = tensor([[-0.5961, -2.9263],
        [-0.7500, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11823077499866486
Epoch 0, Step 446: train/loss = 0.5472389459609985, train/raw-loss = 0.4980558156967163, train/logprobs = tensor([[-0.8885, -2.1815],
        [-0.7760, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09836629033088684
Epoch 0, Step 447: train/loss = 0.4157528281211853, train/raw-loss = 0.35694295167922974, train/logprobs = tensor([[-0.9644, -5.6268],
        [-0.8068, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761980503797531
Epoch 0, Step 448: train/loss = 0.4136549234390259, train/raw-loss = 0.3593357503414154, train/logprobs = tensor([[-0.6069, -5.2138],
        [-0.7554, -1.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10863829404115677
Epoch 0, Step 449: train/loss = 0.6281401515007019, train/raw-loss = 0.5794149041175842, train/logprobs = tensor([[-0.7788, -1.8180],
        [-0.7508, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745050221681595
Epoch 0, Step 450: train/loss = 0.6190938353538513, train/raw-loss = 0.5627087354660034, train/logprobs = tensor([[-0.9886, -1.8599],
        [-1.0522, -0.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11277014762163162
Epoch 0, Step 451: train/loss = 0.5637950897216797, train/raw-loss = 0.5116860270500183, train/logprobs = tensor([[-0.7721, -1.5818],
        [-0.8149, -0.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421810299158096
Epoch 0, Step 452: train/loss = 0.3779583275318146, train/raw-loss = 0.32338178157806396, train/logprobs = tensor([[-0.7080, -6.3062],
        [-0.9990, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10915318131446838
Epoch 0, Step 453: train/loss = 0.3844817876815796, train/raw-loss = 0.33739009499549866, train/logprobs = tensor([[-0.6141, -4.4349],
        [-0.8420, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09418337047100067
Epoch 0, Step 454: train/loss = 0.5666701793670654, train/raw-loss = 0.5252513885498047, train/logprobs = tensor([[-0.3863, -2.5779],
        [-0.4528, -0.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283764123916626
Epoch 0, Step 455: train/loss = 0.40673181414604187, train/raw-loss = 0.35759711265563965, train/logprobs = tensor([[-0.6496, -3.5680],
        [-0.8440, -0.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09826936572790146
Epoch 0, Step 456: train/loss = 0.6539332866668701, train/raw-loss = 0.5943425893783569, train/logprobs = tensor([[-0.8112, -1.3216],
        [-0.8457, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191813200712204
Epoch 0, Step 457: train/loss = 0.4476422667503357, train/raw-loss = 0.38914012908935547, train/logprobs = tensor([[-0.5409, -2.6612],
        [-0.8332, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11700433492660522
Epoch 0, Step 458: train/loss = 0.41254207491874695, train/raw-loss = 0.35800766944885254, train/logprobs = tensor([[-0.5526, -4.5705],
        [-0.7730, -0.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906875133514404
Epoch 0, Step 459: train/loss = 0.4521925449371338, train/raw-loss = 0.39516681432724, train/logprobs = tensor([[-0.6996, -2.7901],
        [-0.8002, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11405139416456223
Epoch 0, Step 460: train/loss = 0.49627038836479187, train/raw-loss = 0.44132137298583984, train/logprobs = tensor([[-0.7279, -3.1435],
        [-0.8031, -0.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989812016487122
Epoch 0, Step 461: train/loss = 0.4889552593231201, train/raw-loss = 0.4338013529777527, train/logprobs = tensor([[-0.9801, -3.0433],
        [-0.9209, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11030785739421844
Epoch 0, Step 462: train/loss = 0.5369173288345337, train/raw-loss = 0.4796433448791504, train/logprobs = tensor([[-0.8174, -1.8030],
        [-0.9245, -0.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11454794555902481
Epoch 0, Step 463: train/loss = 0.5122326016426086, train/raw-loss = 0.45919427275657654, train/logprobs = tensor([[-0.8299, -1.9929],
        [-1.0459, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607659816741943
Epoch 0, Step 464: train/loss = 0.39363664388656616, train/raw-loss = 0.33558332920074463, train/logprobs = tensor([[-0.5209, -4.2224],
        [-0.8483, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11610669642686844
Epoch 0, Step 465: train/loss = 0.5484817624092102, train/raw-loss = 0.4945240616798401, train/logprobs = tensor([[-0.5903, -1.5294],
        [-0.8808, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10791533440351486
Epoch 0, Step 466: train/loss = 0.606337308883667, train/raw-loss = 0.5535300970077515, train/logprobs = tensor([[-0.9659, -2.4222],
        [-0.9593, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10561443865299225
Epoch 0, Step 467: train/loss = 0.5435971021652222, train/raw-loss = 0.49372828006744385, train/logprobs = tensor([[-0.8602, -2.3641],
        [-0.7310, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09973762184381485
Epoch 0, Step 468: train/loss = 0.32770609855651855, train/raw-loss = 0.25943538546562195, train/logprobs = tensor([[-0.6711, -3.6416],
        [-1.2005, -0.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365414261817932
Epoch 0, Step 469: train/loss = 0.5842825174331665, train/raw-loss = 0.5390906929969788, train/logprobs = tensor([[-0.5362, -1.5348],
        [-0.8238, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038375318050385
Epoch 0, Step 470: train/loss = 0.6094321608543396, train/raw-loss = 0.5497743487358093, train/logprobs = tensor([[-0.8643, -2.2599],
        [-0.6070, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11931560188531876
Epoch 0, Step 471: train/loss = 0.3603827953338623, train/raw-loss = 0.3065406084060669, train/logprobs = tensor([[-0.4505, -4.2608],
        [-0.6517, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10768435895442963
Epoch 0, Step 472: train/loss = 0.5215674638748169, train/raw-loss = 0.4696100652217865, train/logprobs = tensor([[-0.4902, -3.3311],
        [-0.6330, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391488671302795
Epoch 0, Step 473: train/loss = 0.4668745994567871, train/raw-loss = 0.41072309017181396, train/logprobs = tensor([[-1.0340, -4.7695],
        [-0.8391, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11230310797691345
Epoch 0, Step 474: train/loss = 0.486875057220459, train/raw-loss = 0.4388096034526825, train/logprobs = tensor([[-0.5754, -2.7122],
        [-0.7438, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613087773323059
Epoch 0, Step 475: train/loss = 0.3861556053161621, train/raw-loss = 0.325361967086792, train/logprobs = tensor([[-0.6913, -4.4234],
        [-0.7864, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158725410699844
Epoch 0, Step 476: train/loss = 0.5389968752861023, train/raw-loss = 0.482355535030365, train/logprobs = tensor([[-0.4587, -1.7587],
        [-0.4666, -0.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328260600566864
Epoch 0, Step 477: train/loss = 0.45221126079559326, train/raw-loss = 0.3876926600933075, train/logprobs = tensor([[-0.5849, -3.7931],
        [-0.6459, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290372908115387
Epoch 0, Step 478: train/loss = 0.37630945444107056, train/raw-loss = 0.3201305866241455, train/logprobs = tensor([[-0.7706, -5.7791],
        [-0.8015, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235778778791428
Epoch 0, Step 479: train/loss = 0.5238257050514221, train/raw-loss = 0.47945865988731384, train/logprobs = tensor([[-0.3606, -3.7820],
        [-0.5182, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08873412758111954
Epoch 0, Step 480: train/loss = 0.6644719839096069, train/raw-loss = 0.6199797987937927, train/logprobs = tensor([[-0.4578, -1.0424],
        [-0.5320, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08898423612117767
Epoch 0, Step 481: train/loss = 0.33472269773483276, train/raw-loss = 0.2656341791152954, train/logprobs = tensor([[-0.8762, -5.3543],
        [-1.1200, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13817709684371948
Epoch 0, Step 482: train/loss = 0.549685537815094, train/raw-loss = 0.49916398525238037, train/logprobs = tensor([[-0.7736, -1.4735],
        [-0.9680, -0.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104309022426605
Epoch 0, Step 483: train/loss = 0.49699556827545166, train/raw-loss = 0.4457601308822632, train/logprobs = tensor([[-0.5419, -3.4031],
        [-0.7533, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247081518173218
Epoch 0, Step 484: train/loss = 0.5072156190872192, train/raw-loss = 0.44386857748031616, train/logprobs = tensor([[-0.5609, -2.4598],
        [-0.7188, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12669412791728973
Epoch 0, Step 485: train/loss = 0.3358796238899231, train/raw-loss = 0.2702786922454834, train/logprobs = tensor([[-0.9823, -6.2783],
        [-1.3847, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13120190799236298
Epoch 0, Step 486: train/loss = 0.6344178915023804, train/raw-loss = 0.5847676396369934, train/logprobs = tensor([[-0.5160, -1.0856],
        [-0.6617, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930042922496796
Epoch 0, Step 487: train/loss = 0.5030266046524048, train/raw-loss = 0.4500575065612793, train/logprobs = tensor([[-0.8824, -3.0583],
        [-0.9641, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593830049037933
Epoch 0, Step 488: train/loss = 0.49246975779533386, train/raw-loss = 0.43714842200279236, train/logprobs = tensor([[-0.6003, -4.5712],
        [-0.6871, -1.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106426864862442
Epoch 0, Step 489: train/loss = 0.4316609501838684, train/raw-loss = 0.36765921115875244, train/logprobs = tensor([[-0.5463, -5.8997],
        [-1.0119, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12800350785255432
Epoch 0, Step 490: train/loss = 0.5570404529571533, train/raw-loss = 0.49054378271102905, train/logprobs = tensor([[-0.5361, -1.5842],
        [-0.7228, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13299328088760376
Epoch 0, Step 491: train/loss = 0.4568900465965271, train/raw-loss = 0.39224040508270264, train/logprobs = tensor([[-0.8823, -4.4213],
        [-1.2919, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292993426322937
Epoch 0, Step 492: train/loss = 0.4465050995349884, train/raw-loss = 0.3852788507938385, train/logprobs = tensor([[-0.8305, -4.3796],
        [-1.1672, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12245252728462219
Epoch 0, Step 493: train/loss = 0.6193459033966064, train/raw-loss = 0.5677841901779175, train/logprobs = tensor([[-0.4183, -1.4645],
        [-0.4383, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10312344878911972
Epoch 0, Step 494: train/loss = 0.5039402842521667, train/raw-loss = 0.4390164017677307, train/logprobs = tensor([[-0.8089, -1.8953],
        [-1.2047, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12984783947467804
Epoch 0, Step 495: train/loss = 0.4770529270172119, train/raw-loss = 0.4211932420730591, train/logprobs = tensor([[-0.4802, -4.0167],
        [-0.7269, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171942949295044
Epoch 0, Step 496: train/loss = 0.4953124523162842, train/raw-loss = 0.43521761894226074, train/logprobs = tensor([[-0.6023, -3.1067],
        [-0.6550, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12018973380327225
Epoch 0, Step 497: train/loss = 0.5348603129386902, train/raw-loss = 0.48818477988243103, train/logprobs = tensor([[-0.4779, -1.4132],
        [-0.6440, -0.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335105121135712
Epoch 0, Step 498: train/loss = 0.38657695055007935, train/raw-loss = 0.31819891929626465, train/logprobs = tensor([[-0.6362, -2.8092],
        [-0.9121, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13675612211227417
Epoch 0, Step 499: train/loss = 0.46369239687919617, train/raw-loss = 0.4062117636203766, train/logprobs = tensor([[-0.6238, -3.7381],
        [-0.8720, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11496123671531677
Epoch 0, Step 500: train/loss = 0.5619960427284241, train/raw-loss = 0.508880615234375, train/logprobs = tensor([[-0.6452, -2.5560],
        [-0.8382, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10623091459274292
Epoch 0, Step 501: train/loss = 0.4789556860923767, train/raw-loss = 0.4191094934940338, train/logprobs = tensor([[-0.7519, -4.4898],
        [-0.7111, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11969243735074997
Epoch 0, Step 502: train/loss = 0.37558093667030334, train/raw-loss = 0.3140372037887573, train/logprobs = tensor([[-0.5461, -2.5259],
        [-1.0677, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12308742105960846
Epoch 0, Step 503: train/loss = 0.6802493929862976, train/raw-loss = 0.6351269483566284, train/logprobs = tensor([[-0.6253, -1.0711],
        [-0.5255, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902448296546936
Epoch 0, Step 504: train/loss = 0.45491641759872437, train/raw-loss = 0.40171951055526733, train/logprobs = tensor([[-0.4783, -3.4464],
        [-0.6015, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10639379918575287
Epoch 0, Step 505: train/loss = 0.41608864068984985, train/raw-loss = 0.35594600439071655, train/logprobs = tensor([[-0.5932, -6.1732],
        [-0.9765, -1.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12028522789478302
Epoch 0, Step 506: train/loss = 0.5835317373275757, train/raw-loss = 0.5318467617034912, train/logprobs = tensor([[-0.6025, -1.5943],
        [-0.6631, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336986184120178
Epoch 0, Step 507: train/loss = 0.5395828485488892, train/raw-loss = 0.47734493017196655, train/logprobs = tensor([[-0.9016, -5.6516],
        [-0.8827, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12447577714920044
Epoch 0, Step 508: train/loss = 0.5229870676994324, train/raw-loss = 0.4678240120410919, train/logprobs = tensor([[-0.6270, -2.0585],
        [-0.7967, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11032609641551971
Epoch 0, Step 509: train/loss = 0.5842413902282715, train/raw-loss = 0.5263558626174927, train/logprobs = tensor([[-0.6677, -1.7450],
        [-0.6342, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577105522155762
Epoch 0, Step 510: train/loss = 0.4980774223804474, train/raw-loss = 0.43867912888526917, train/logprobs = tensor([[-0.7421, -3.4084],
        [-0.9565, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879660189151764
Epoch 0, Step 511: train/loss = 0.5294386148452759, train/raw-loss = 0.4737713932991028, train/logprobs = tensor([[-0.7687, -3.1293],
        [-0.7860, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.111334428191185
Epoch 0, Step 512: train/loss = 0.48661381006240845, train/raw-loss = 0.43501991033554077, train/logprobs = tensor([[-0.7035, -2.1405],
        [-1.1259, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10318779200315475
Epoch 0, Step 513: train/loss = 0.5167331695556641, train/raw-loss = 0.4609888792037964, train/logprobs = tensor([[-0.4121, -3.1046],
        [-0.5657, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148851364850998
Epoch 0, Step 514: train/loss = 0.3949582278728485, train/raw-loss = 0.327493816614151, train/logprobs = tensor([[-0.6180, -4.4621],
        [-1.0047, -1.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13492880761623383
Epoch 0, Step 515: train/loss = 0.7236988544464111, train/raw-loss = 0.6726341843605042, train/logprobs = tensor([[-0.5022, -0.5704],
        [-0.5735, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10212923586368561
Epoch 0, Step 516: train/loss = 0.43896484375, train/raw-loss = 0.37669050693511963, train/logprobs = tensor([[-0.7200, -2.7645],
        [-1.1410, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454868853092194
Epoch 0, Step 517: train/loss = 0.4679880142211914, train/raw-loss = 0.41029617190361023, train/logprobs = tensor([[-0.5770, -2.3853],
        [-0.7768, -0.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538368463516235
Epoch 0, Step 518: train/loss = 0.3955345153808594, train/raw-loss = 0.3349156677722931, train/logprobs = tensor([[-0.7536, -5.4033],
        [-1.4966, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123771011829376
Epoch 0, Step 519: train/loss = 0.38262271881103516, train/raw-loss = 0.3164352476596832, train/logprobs = tensor([[-0.8717, -3.8131],
        [-0.9934, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13237500190734863
Epoch 0, Step 520: train/loss = 0.7377150058746338, train/raw-loss = 0.6875808238983154, train/logprobs = tensor([[-0.9410, -0.9884],
        [-0.7601, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10026831179857254
Epoch 0, Step 521: train/loss = 0.4915510416030884, train/raw-loss = 0.4432221055030823, train/logprobs = tensor([[-0.3503, -2.5061],
        [-0.5158, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665790945291519
Epoch 0, Step 522: train/loss = 0.6017014980316162, train/raw-loss = 0.5458199381828308, train/logprobs = tensor([[-1.2185, -3.2035],
        [-0.8603, -0.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176317930221558
Epoch 0, Step 523: train/loss = 0.5415088534355164, train/raw-loss = 0.4873151183128357, train/logprobs = tensor([[-0.4990, -2.1117],
        [-0.5980, -0.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838750004768372
Epoch 0, Step 524: train/loss = 0.3447754979133606, train/raw-loss = 0.28071922063827515, train/logprobs = tensor([[-0.4429, -6.2106],
        [-0.8011, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281125843524933
Epoch 0, Step 525: train/loss = 0.5562321543693542, train/raw-loss = 0.495495468378067, train/logprobs = tensor([[-0.6268, -1.8773],
        [-0.7989, -0.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147340178489685
Epoch 0, Step 526: train/loss = 0.5010148882865906, train/raw-loss = 0.45276516675949097, train/logprobs = tensor([[-0.3739, -1.8066],
        [-0.6237, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649936854839325
Epoch 0, Step 527: train/loss = 0.30596724152565, train/raw-loss = 0.2483852058649063, train/logprobs = tensor([[-0.5510, -4.2320],
        [-1.0002, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11516405642032623
Epoch 0, Step 528: train/loss = 0.4007560610771179, train/raw-loss = 0.34882909059524536, train/logprobs = tensor([[-0.3488, -5.6525],
        [-0.4573, -1.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385395586490631
Epoch 0, Step 529: train/loss = 0.4453606903553009, train/raw-loss = 0.3837413191795349, train/logprobs = tensor([[-0.6403, -4.4739],
        [-0.8956, -1.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12323874235153198
Epoch 0, Step 530: train/loss = 0.6055235862731934, train/raw-loss = 0.5417060852050781, train/logprobs = tensor([[-0.5815, -1.7059],
        [-0.9961, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12763497233390808
Epoch 0, Step 531: train/loss = 0.573779821395874, train/raw-loss = 0.5212974548339844, train/logprobs = tensor([[-0.4014, -1.4093],
        [-0.5792, -0.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10496463626623154
Epoch 0, Step 532: train/loss = 0.5254902839660645, train/raw-loss = 0.465556800365448, train/logprobs = tensor([[-0.5941, -2.9492],
        [-0.9584, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986692994832993
Epoch 0, Step 533: train/loss = 0.4704049527645111, train/raw-loss = 0.4043024182319641, train/logprobs = tensor([[-0.8066, -3.6051],
        [-0.8987, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13220512866973877
Epoch 0, Step 534: train/loss = 0.548578143119812, train/raw-loss = 0.4878012239933014, train/logprobs = tensor([[-0.4688, -2.4049],
        [-0.6839, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12155386805534363
Epoch 0, Step 535: train/loss = 0.3926476836204529, train/raw-loss = 0.31891268491744995, train/logprobs = tensor([[-0.8127, -4.0124],
        [-1.2668, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14746993780136108
Epoch 0, Step 536: train/loss = 0.43803155422210693, train/raw-loss = 0.38019323348999023, train/logprobs = tensor([[-0.6407, -2.5149],
        [-0.8481, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156766265630722
Epoch 0, Step 537: train/loss = 0.4202148914337158, train/raw-loss = 0.3625583052635193, train/logprobs = tensor([[-0.6296, -2.4181],
        [-1.0663, -0.8266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11531323939561844
Epoch 0, Step 538: train/loss = 0.41899991035461426, train/raw-loss = 0.3536562919616699, train/logprobs = tensor([[-0.7551, -4.4090],
        [-0.7196, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13068729639053345
Epoch 0, Step 539: train/loss = 0.4827713370323181, train/raw-loss = 0.43316951394081116, train/logprobs = tensor([[-0.4155, -3.3728],
        [-0.6188, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09920356422662735
Epoch 0, Step 540: train/loss = 0.5192973613739014, train/raw-loss = 0.4570976197719574, train/logprobs = tensor([[-0.6484, -2.7914],
        [-1.0597, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12439948320388794
Epoch 0, Step 541: train/loss = 0.36517640948295593, train/raw-loss = 0.30128100514411926, train/logprobs = tensor([[-0.7938, -5.6552],
        [-1.3511, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12779085338115692
Epoch 0, Step 542: train/loss = 0.4302339553833008, train/raw-loss = 0.378318190574646, train/logprobs = tensor([[-0.6436, -2.8385],
        [-0.9119, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10383143275976181
Epoch 0, Step 543: train/loss = 0.44549331068992615, train/raw-loss = 0.3888793885707855, train/logprobs = tensor([[-0.5840, -4.7876],
        [-0.7288, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322788894176483
Epoch 0, Step 544: train/loss = 0.5307246446609497, train/raw-loss = 0.4665057957172394, train/logprobs = tensor([[-0.6161, -2.0022],
        [-0.8014, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12843769788742065
Epoch 0, Step 545: train/loss = 0.4136557877063751, train/raw-loss = 0.35440096259117126, train/logprobs = tensor([[-0.5990, -3.0152],
        [-1.1668, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11850961297750473
Epoch 0, Step 546: train/loss = 0.447388619184494, train/raw-loss = 0.3924388885498047, train/logprobs = tensor([[-0.4493, -2.8332],
        [-0.7182, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989940166473389
Epoch 0, Step 547: train/loss = 0.43203359842300415, train/raw-loss = 0.37257468700408936, train/logprobs = tensor([[-0.6400, -4.3604],
        [-0.8435, -1.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11891774088144302
Epoch 0, Step 548: train/loss = 0.5612760782241821, train/raw-loss = 0.5053055286407471, train/logprobs = tensor([[-0.4673, -1.2664],
        [-0.7304, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119411438703537
Epoch 0, Step 549: train/loss = 0.5106179118156433, train/raw-loss = 0.4501801133155823, train/logprobs = tensor([[-0.8587, -2.0835],
        [-1.2410, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12087558209896088
Epoch 0, Step 550: train/loss = 0.40471574664115906, train/raw-loss = 0.33593878149986267, train/logprobs = tensor([[-0.9743, -4.3335],
        [-1.3964, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13755391538143158
Epoch 0, Step 551: train/loss = 0.5569808483123779, train/raw-loss = 0.5003354549407959, train/logprobs = tensor([[-0.6132, -1.7530],
        [-0.8048, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329082399606705
Epoch 0, Step 552: train/loss = 0.4046757221221924, train/raw-loss = 0.3449155390262604, train/logprobs = tensor([[-0.6535, -2.8855],
        [-1.1627, -0.8287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11952041834592819
Epoch 0, Step 553: train/loss = 0.45752695202827454, train/raw-loss = 0.39990702271461487, train/logprobs = tensor([[-0.4593, -2.7581],
        [-0.7964, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11523985862731934
Epoch 0, Step 554: train/loss = 0.41428515315055847, train/raw-loss = 0.3596438765525818, train/logprobs = tensor([[-0.4935, -4.2594],
        [-0.7123, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10928256809711456
Epoch 0, Step 555: train/loss = 0.4720635712146759, train/raw-loss = 0.4164195954799652, train/logprobs = tensor([[-0.9552, -3.0640],
        [-0.9138, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11128799617290497
Epoch 0, Step 556: train/loss = 0.44123852252960205, train/raw-loss = 0.38080859184265137, train/logprobs = tensor([[-0.4409, -3.8829],
        [-0.7090, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085986137390137
Epoch 0, Step 557: train/loss = 0.4573506712913513, train/raw-loss = 0.39194586873054504, train/logprobs = tensor([[-0.8001, -3.6777],
        [-1.2040, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080960512161255
Epoch 0, Step 558: train/loss = 0.6512486338615417, train/raw-loss = 0.5903737545013428, train/logprobs = tensor([[-0.6540, -1.0975],
        [-0.8453, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12174971401691437
Epoch 0, Step 559: train/loss = 0.47281521558761597, train/raw-loss = 0.41270050406455994, train/logprobs = tensor([[-0.6196, -2.8313],
        [-0.6817, -0.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12022938579320908
Epoch 0, Step 560: train/loss = 0.5639251470565796, train/raw-loss = 0.5175379514694214, train/logprobs = tensor([[-0.3569, -1.8334],
        [-0.4210, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277445077896118
Epoch 0, Step 561: train/loss = 0.5074011087417603, train/raw-loss = 0.44757914543151855, train/logprobs = tensor([[-0.5265, -1.9955],
        [-0.9464, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11964397132396698
Epoch 0, Step 562: train/loss = 0.45778995752334595, train/raw-loss = 0.3973223567008972, train/logprobs = tensor([[-0.6549, -3.5606],
        [-1.0059, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12093524634838104
Epoch 0, Step 563: train/loss = 0.5096004605293274, train/raw-loss = 0.4603796601295471, train/logprobs = tensor([[-0.4423, -3.1207],
        [-0.6139, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09844156354665756
Epoch 0, Step 564: train/loss = 0.5326915979385376, train/raw-loss = 0.4701142907142639, train/logprobs = tensor([[-0.6096, -1.6173],
        [-0.9322, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12515464425086975
Epoch 0, Step 565: train/loss = 0.4065752327442169, train/raw-loss = 0.34081265330314636, train/logprobs = tensor([[-0.8978, -3.1509],
        [-1.4263, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13152511417865753
Epoch 0, Step 566: train/loss = 0.4962497055530548, train/raw-loss = 0.4390227198600769, train/logprobs = tensor([[-0.4772, -6.5095],
        [-0.6713, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11445394158363342
Epoch 0, Step 567: train/loss = 0.39021578431129456, train/raw-loss = 0.32869499921798706, train/logprobs = tensor([[-0.5278, -3.2440],
        [-1.0497, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1230415552854538
Epoch 0, Step 568: train/loss = 0.5645754337310791, train/raw-loss = 0.49863389134407043, train/logprobs = tensor([[-0.5468, -2.8646],
        [-0.9661, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13188311457633972
Epoch 0, Step 569: train/loss = 0.38864070177078247, train/raw-loss = 0.3169782757759094, train/logprobs = tensor([[-0.7888, -2.3183],
        [-1.4759, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1433248519897461
Epoch 0, Step 570: train/loss = 0.6864564418792725, train/raw-loss = 0.6236531138420105, train/logprobs = tensor([[-1.3954, -2.2779],
        [-0.9317, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12560659646987915
Epoch 0, Step 571: train/loss = 0.4402146339416504, train/raw-loss = 0.382146954536438, train/logprobs = tensor([[-0.6111, -3.6153],
        [-0.6548, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11613535135984421
Epoch 0, Step 572: train/loss = 0.4423215091228485, train/raw-loss = 0.3866252899169922, train/logprobs = tensor([[-0.3911, -2.6927],
        [-0.5168, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139251291751862
Epoch 0, Step 573: train/loss = 0.4013734757900238, train/raw-loss = 0.33903059363365173, train/logprobs = tensor([[-0.5424, -3.5230],
        [-0.7238, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468574196100235
Epoch 0, Step 574: train/loss = 0.5821865200996399, train/raw-loss = 0.5283291339874268, train/logprobs = tensor([[-0.4864, -1.2991],
        [-0.6949, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771483182907104
Epoch 0, Step 575: train/loss = 0.3969101309776306, train/raw-loss = 0.33101195096969604, train/logprobs = tensor([[-0.5760, -3.7471],
        [-1.1275, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13179636001586914
Epoch 0, Step 576: train/loss = 0.5432723164558411, train/raw-loss = 0.47101154923439026, train/logprobs = tensor([[-0.8374, -1.6796],
        [-1.1578, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14452148973941803
Epoch 0, Step 577: train/loss = 0.6277743577957153, train/raw-loss = 0.560666024684906, train/logprobs = tensor([[-0.7221, -1.5132],
        [-1.0006, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13421662151813507
Epoch 0, Step 578: train/loss = 0.381067156791687, train/raw-loss = 0.31509798765182495, train/logprobs = tensor([[-0.7236, -3.9628],
        [-1.3030, -0.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13193835318088531
Epoch 0, Step 579: train/loss = 0.4261380434036255, train/raw-loss = 0.371077299118042, train/logprobs = tensor([[-0.7660, -4.4066],
        [-1.0555, -1.3869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012149602174759
Epoch 0, Step 580: train/loss = 0.4442921280860901, train/raw-loss = 0.39413559436798096, train/logprobs = tensor([[-0.9476, -5.3406],
        [-0.9136, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003129780292511
Epoch 0, Step 581: train/loss = 0.39867451786994934, train/raw-loss = 0.339620441198349, train/logprobs = tensor([[-0.6581, -6.4070],
        [-1.0956, -1.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181081235408783
Epoch 0, Step 582: train/loss = 0.5409149527549744, train/raw-loss = 0.4878883361816406, train/logprobs = tensor([[-0.6125, -1.6396],
        [-1.0260, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10605326294898987
Epoch 0, Step 583: train/loss = 0.554196298122406, train/raw-loss = 0.4996754229068756, train/logprobs = tensor([[-0.7793, -2.1552],
        [-0.7845, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904181003570557
Epoch 0, Step 584: train/loss = 0.5229305624961853, train/raw-loss = 0.472721666097641, train/logprobs = tensor([[-0.4857, -1.8919],
        [-0.7820, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10041777044534683
Epoch 0, Step 585: train/loss = 0.5702122449874878, train/raw-loss = 0.5184305906295776, train/logprobs = tensor([[-0.3160, -1.9963],
        [-0.4830, -0.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10356328636407852
Epoch 0, Step 586: train/loss = 0.45924705266952515, train/raw-loss = 0.3932218551635742, train/logprobs = tensor([[-0.7240, -1.8877],
        [-1.2392, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320505142211914
Epoch 0, Step 587: train/loss = 0.5509663820266724, train/raw-loss = 0.4983280897140503, train/logprobs = tensor([[-0.6418, -1.4142],
        [-0.9063, -0.6669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10527659952640533
Epoch 0, Step 588: train/loss = 0.4179811179637909, train/raw-loss = 0.3642147481441498, train/logprobs = tensor([[-0.7409, -4.6610],
        [-1.3000, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10753268748521805
Epoch 0, Step 589: train/loss = 0.43337276577949524, train/raw-loss = 0.3716535270214081, train/logprobs = tensor([[-0.6072, -3.0926],
        [-1.0442, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12343855947256088
Epoch 0, Step 590: train/loss = 0.3594777584075928, train/raw-loss = 0.305778443813324, train/logprobs = tensor([[-0.5091, -4.2148],
        [-0.7580, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739868134260178
Epoch 0, Step 591: train/loss = 0.682927131652832, train/raw-loss = 0.62749844789505, train/logprobs = tensor([[-0.6255, -0.7499],
        [-0.7210, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085724830627441
Epoch 0, Step 592: train/loss = 0.5302996039390564, train/raw-loss = 0.4752616286277771, train/logprobs = tensor([[-0.5551, -1.7343],
        [-0.8161, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11007586121559143
Epoch 0, Step 593: train/loss = 0.4733348786830902, train/raw-loss = 0.41630983352661133, train/logprobs = tensor([[-0.5048, -2.5274],
        [-0.8359, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11405009031295776
Epoch 0, Step 594: train/loss = 0.3687072992324829, train/raw-loss = 0.3009668290615082, train/logprobs = tensor([[-0.6706, -3.0451],
        [-1.0476, -0.6168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354808807373047
Epoch 0, Step 595: train/loss = 0.5500103831291199, train/raw-loss = 0.49353790283203125, train/logprobs = tensor([[-0.5434, -1.7490],
        [-0.7562, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11294494569301605
Epoch 0, Step 596: train/loss = 0.4876314699649811, train/raw-loss = 0.43153122067451477, train/logprobs = tensor([[-0.6854, -3.9460],
        [-0.9640, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220049113035202
Epoch 0, Step 597: train/loss = 0.6587950587272644, train/raw-loss = 0.6044582724571228, train/logprobs = tensor([[-0.6127, -0.8741],
        [-0.9175, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10867352783679962
Epoch 0, Step 598: train/loss = 0.4554094076156616, train/raw-loss = 0.3878158926963806, train/logprobs = tensor([[-0.9554, -3.1469],
        [-0.9647, -0.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351870596408844
Epoch 0, Step 599: train/loss = 0.46128469705581665, train/raw-loss = 0.40042200684547424, train/logprobs = tensor([[-0.4884, -3.8353],
        [-0.7713, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172537297010422
Epoch 0, Step 600: train/loss = 0.497627317905426, train/raw-loss = 0.4402577877044678, train/logprobs = tensor([[-0.4554, -2.6536],
        [-0.6789, -0.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11473901569843292
Epoch 0, Step 601: train/loss = 0.4934535026550293, train/raw-loss = 0.43286052346229553, train/logprobs = tensor([[-0.8536, -2.0806],
        [-1.2503, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12118600308895111
Epoch 0, Step 602: train/loss = 0.5291256904602051, train/raw-loss = 0.4610389471054077, train/logprobs = tensor([[-0.8994, -2.4230],
        [-1.0055, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13617344200611115
Epoch 0, Step 603: train/loss = 0.33674341440200806, train/raw-loss = 0.2760522663593292, train/logprobs = tensor([[-0.5201, -5.2365],
        [-0.9289, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12138233333826065
Epoch 0, Step 604: train/loss = 0.5573862195014954, train/raw-loss = 0.5029492974281311, train/logprobs = tensor([[-0.3788, -1.3980],
        [-0.6136, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088738664984703
Epoch 0, Step 605: train/loss = 0.546795129776001, train/raw-loss = 0.4918239712715149, train/logprobs = tensor([[-0.6604, -1.0013],
        [-1.2383, -0.6056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10994230210781097
Epoch 0, Step 606: train/loss = 0.4928049147129059, train/raw-loss = 0.4382849931716919, train/logprobs = tensor([[-0.6073, -1.9381],
        [-0.7359, -0.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10903981328010559
Epoch 0, Step 607: train/loss = 0.461725652217865, train/raw-loss = 0.3965553641319275, train/logprobs = tensor([[-0.6541, -2.7414],
        [-0.8665, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303405612707138
Epoch 0, Step 608: train/loss = 0.4709005355834961, train/raw-loss = 0.4087215065956116, train/logprobs = tensor([[-0.5391, -2.4671],
        [-1.0429, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12435799092054367
Epoch 0, Step 609: train/loss = 0.3834240436553955, train/raw-loss = 0.3214310109615326, train/logprobs = tensor([[-0.8018, -5.4121],
        [-1.3405, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12398602068424225
Epoch 0, Step 610: train/loss = 0.30782386660575867, train/raw-loss = 0.22971829771995544, train/logprobs = tensor([[-1.0044, -6.3652],
        [-1.5882, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15621116757392883
Epoch 0, Step 611: train/loss = 0.33117297291755676, train/raw-loss = 0.2773197889328003, train/logprobs = tensor([[-0.4809, -3.6884],
        [-0.7886, -0.8959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10770633071660995
Epoch 0, Step 612: train/loss = 0.5831588506698608, train/raw-loss = 0.5189308524131775, train/logprobs = tensor([[-0.6444, -3.2980],
        [-0.8989, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12845611572265625
Epoch 0, Step 613: train/loss = 0.611838698387146, train/raw-loss = 0.5499969720840454, train/logprobs = tensor([[-0.6889, -1.6967],
        [-0.9063, -0.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12368340790271759
Epoch 0, Step 614: train/loss = 0.49012213945388794, train/raw-loss = 0.4258181154727936, train/logprobs = tensor([[-0.6366, -2.0680],
        [-0.8604, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12860798835754395
Epoch 0, Step 615: train/loss = 0.4917745292186737, train/raw-loss = 0.4256749749183655, train/logprobs = tensor([[-0.5906, -2.0687],
        [-1.0445, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13219904899597168
Epoch 0, Step 616: train/loss = 0.6624202728271484, train/raw-loss = 0.6068377494812012, train/logprobs = tensor([[-0.4636, -0.8924],
        [-0.7043, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111651062965393
Epoch 0, Step 617: train/loss = 0.49602010846138, train/raw-loss = 0.44544506072998047, train/logprobs = tensor([[-0.6351, -3.5996],
        [-0.8247, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115014761686325
Epoch 0, Step 618: train/loss = 0.45971715450286865, train/raw-loss = 0.399647980928421, train/logprobs = tensor([[-0.4939, -2.4094],
        [-0.9342, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12013830244541168
Epoch 0, Step 619: train/loss = 0.3901647925376892, train/raw-loss = 0.3335845172405243, train/logprobs = tensor([[-0.4545, -4.1664],
        [-0.8103, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316054314374924
Epoch 0, Step 620: train/loss = 0.40323567390441895, train/raw-loss = 0.33587634563446045, train/logprobs = tensor([[-0.7413, -3.0408],
        [-1.2441, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347186416387558
Epoch 0, Step 621: train/loss = 0.6295264363288879, train/raw-loss = 0.5757195949554443, train/logprobs = tensor([[-0.6455, -0.8082],
        [-0.9055, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076137125492096
Epoch 0, Step 622: train/loss = 0.4850446581840515, train/raw-loss = 0.4257812201976776, train/logprobs = tensor([[-0.4129, -4.3039],
        [-0.8468, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852685362100601
Epoch 0, Step 623: train/loss = 0.43262979388237, train/raw-loss = 0.37616464495658875, train/logprobs = tensor([[-0.5538, -4.4970],
        [-0.9127, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129302978515625
Epoch 0, Step 624: train/loss = 0.4907877743244171, train/raw-loss = 0.4287048280239105, train/logprobs = tensor([[-0.5136, -2.7272],
        [-0.9982, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12416590005159378
Epoch 0, Step 625: train/loss = 0.5155597925186157, train/raw-loss = 0.4513527750968933, train/logprobs = tensor([[-0.5754, -3.7902],
        [-0.7396, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284140795469284
Epoch 0, Step 626: train/loss = 0.5065264701843262, train/raw-loss = 0.4493105411529541, train/logprobs = tensor([[-0.5117, -1.9824],
        [-0.8266, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11443179845809937
Epoch 0, Step 627: train/loss = 0.4865766763687134, train/raw-loss = 0.42350104451179504, train/logprobs = tensor([[-0.4268, -1.9070],
        [-0.9281, -0.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12615126371383667
Epoch 0, Step 628: train/loss = 0.4563972055912018, train/raw-loss = 0.3960806727409363, train/logprobs = tensor([[-0.4342, -2.1971],
        [-0.9055, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12063302099704742
Epoch 0, Step 629: train/loss = 0.5176552534103394, train/raw-loss = 0.46026909351348877, train/logprobs = tensor([[-0.3690, -1.6524],
        [-0.6936, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11477229744195938
Epoch 0, Step 630: train/loss = 0.4423956274986267, train/raw-loss = 0.38691651821136475, train/logprobs = tensor([[-0.4004, -3.2049],
        [-0.6232, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095824092626572
Epoch 0, Step 631: train/loss = 0.3415951728820801, train/raw-loss = 0.27714088559150696, train/logprobs = tensor([[-1.0867, -4.5762],
        [-1.4750, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12890858948230743
Epoch 0, Step 632: train/loss = 0.5062520503997803, train/raw-loss = 0.43021321296691895, train/logprobs = tensor([[-0.7770, -3.4022],
        [-1.0064, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15207764506340027
Epoch 0, Step 633: train/loss = 0.3892144560813904, train/raw-loss = 0.3281022906303406, train/logprobs = tensor([[-0.7089, -4.2125],
        [-1.0189, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12222439795732498
Epoch 0, Step 634: train/loss = 0.42010486125946045, train/raw-loss = 0.35298341512680054, train/logprobs = tensor([[-0.4544, -3.4038],
        [-1.0245, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13424289226531982
Epoch 0, Step 635: train/loss = 0.39608055353164673, train/raw-loss = 0.3342825174331665, train/logprobs = tensor([[-0.4987, -4.0323],
        [-0.9997, -1.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12359601259231567
Epoch 0, Step 636: train/loss = 0.511740505695343, train/raw-loss = 0.4555206894874573, train/logprobs = tensor([[-0.5119, -2.8417],
        [-0.7335, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124396026134491
Epoch 0, Step 637: train/loss = 0.4447268843650818, train/raw-loss = 0.39276450872421265, train/logprobs = tensor([[-0.5937, -3.6373],
        [-0.8121, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039247065782547
Epoch 0, Step 638: train/loss = 0.6485823392868042, train/raw-loss = 0.5910062193870544, train/logprobs = tensor([[-0.4952, -0.9963],
        [-0.6562, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11515223979949951
Epoch 0, Step 639: train/loss = 0.4678291082382202, train/raw-loss = 0.40123164653778076, train/logprobs = tensor([[-0.7940, -3.0228],
        [-1.0938, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331949532032013
Epoch 0, Step 640: train/loss = 0.41653716564178467, train/raw-loss = 0.36198535561561584, train/logprobs = tensor([[-0.5047, -4.5012],
        [-0.7149, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10910354554653168
Epoch 0, Step 641: train/loss = 0.6407105922698975, train/raw-loss = 0.5805869102478027, train/logprobs = tensor([[-1.2106, -2.9250],
        [-0.9463, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12024745345115662
Epoch 0, Step 642: train/loss = 0.4329933524131775, train/raw-loss = 0.37080103158950806, train/logprobs = tensor([[-0.8367, -3.4085],
        [-1.0070, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12438467144966125
Epoch 0, Step 643: train/loss = 0.34823721647262573, train/raw-loss = 0.2845541834831238, train/logprobs = tensor([[-0.5088, -5.0202],
        [-0.9126, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12736597657203674
Epoch 0, Step 644: train/loss = 0.5756590366363525, train/raw-loss = 0.5091684460639954, train/logprobs = tensor([[-0.9106, -1.1351],
        [-1.3063, -0.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13298116624355316
Epoch 0, Step 645: train/loss = 0.4553712010383606, train/raw-loss = 0.4003069996833801, train/logprobs = tensor([[-1.0361, -4.9938],
        [-1.5783, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012838035821915
Epoch 0, Step 646: train/loss = 0.617845892906189, train/raw-loss = 0.557601809501648, train/logprobs = tensor([[-0.5128, -1.0107],
        [-0.8300, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12048804759979248
Epoch 0, Step 647: train/loss = 0.5046639442443848, train/raw-loss = 0.4468464255332947, train/logprobs = tensor([[-0.5573, -2.5702],
        [-0.8996, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156349629163742
Epoch 0, Step 648: train/loss = 0.4402892291545868, train/raw-loss = 0.37796473503112793, train/logprobs = tensor([[-0.5877, -4.2212],
        [-1.0486, -1.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12464895099401474
Epoch 0, Step 649: train/loss = 0.29500648379325867, train/raw-loss = 0.2322263866662979, train/logprobs = tensor([[-0.5635, -5.7803],
        [-1.3194, -0.9574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255601942539215
Epoch 0, Step 650: train/loss = 0.3553558588027954, train/raw-loss = 0.2920669615268707, train/logprobs = tensor([[-0.5704, -5.3947],
        [-1.0620, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12657779455184937
Epoch 0, Step 651: train/loss = 0.32016241550445557, train/raw-loss = 0.2544800639152527, train/logprobs = tensor([[-0.8341, -4.6700],
        [-1.2907, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13136467337608337
Epoch 0, Step 652: train/loss = 0.4065367579460144, train/raw-loss = 0.3600344657897949, train/logprobs = tensor([[-0.9514, -6.6816],
        [-1.1411, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09300459921360016
Epoch 0, Step 653: train/loss = 0.497457891702652, train/raw-loss = 0.44518741965293884, train/logprobs = tensor([[-0.6778, -2.4944],
        [-0.9943, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10454092919826508
Epoch 0, Step 654: train/loss = 0.6185864210128784, train/raw-loss = 0.5661417841911316, train/logprobs = tensor([[-0.5668, -2.0389],
        [-0.6206, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10488917678594589
Epoch 0, Step 655: train/loss = 0.41198596358299255, train/raw-loss = 0.33834442496299744, train/logprobs = tensor([[-0.8210, -3.2312],
        [-1.3879, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14728309214115143
Epoch 0, Step 656: train/loss = 0.3052012622356415, train/raw-loss = 0.2391863763332367, train/logprobs = tensor([[-0.9771, -7.6336],
        [-1.3231, -1.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13202977180480957
Epoch 0, Step 657: train/loss = 0.3787851929664612, train/raw-loss = 0.32303059101104736, train/logprobs = tensor([[-0.5849, -4.7103],
        [-0.9671, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11150917410850525
Epoch 0, Step 658: train/loss = 0.5044440031051636, train/raw-loss = 0.43664413690567017, train/logprobs = tensor([[-0.8745, -3.1050],
        [-1.1206, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355997920036316
Epoch 0, Step 659: train/loss = 0.3024001717567444, train/raw-loss = 0.23228541016578674, train/logprobs = tensor([[-0.4914, -4.5505],
        [-1.0456, -0.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14022955298423767
Epoch 0, Step 660: train/loss = 0.6044066548347473, train/raw-loss = 0.5426191687583923, train/logprobs = tensor([[-0.7400, -1.9692],
        [-0.7014, -0.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12357494235038757
Epoch 0, Step 661: train/loss = 0.4505969285964966, train/raw-loss = 0.3863622546195984, train/logprobs = tensor([[-0.5301, -3.9588],
        [-0.9650, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12846937775611877
Epoch 0, Step 662: train/loss = 0.5770695209503174, train/raw-loss = 0.5280402302742004, train/logprobs = tensor([[-0.5841, -1.4698],
        [-0.7244, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09805851429700851
Epoch 0, Step 663: train/loss = 0.47223329544067383, train/raw-loss = 0.4145417809486389, train/logprobs = tensor([[-0.9053, -5.2893],
        [-0.8095, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538301408290863
Epoch 0, Step 664: train/loss = 0.4818410575389862, train/raw-loss = 0.4233974814414978, train/logprobs = tensor([[-0.6440, -2.1780],
        [-1.0025, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11688704788684845
Epoch 0, Step 665: train/loss = 0.5349439382553101, train/raw-loss = 0.4679737091064453, train/logprobs = tensor([[-0.9071, -1.7737],
        [-0.9959, -0.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13394047319889069
Epoch 0, Step 666: train/loss = 0.4448220729827881, train/raw-loss = 0.38279980421066284, train/logprobs = tensor([[-0.7195, -3.6590],
        [-1.3100, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12404447793960571
Epoch 0, Step 667: train/loss = 0.4775713086128235, train/raw-loss = 0.4167878329753876, train/logprobs = tensor([[-0.6108, -3.4337],
        [-1.1163, -0.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12156692147254944
Epoch 0, Step 668: train/loss = 0.5784107446670532, train/raw-loss = 0.5146080255508423, train/logprobs = tensor([[-0.5858, -1.3190],
        [-0.9526, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12760549783706665
Epoch 0, Step 669: train/loss = 0.36682844161987305, train/raw-loss = 0.31019678711891174, train/logprobs = tensor([[-0.5779, -4.6565],
        [-0.9695, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.113263338804245
Epoch 0, Step 670: train/loss = 0.4130256175994873, train/raw-loss = 0.3585139214992523, train/logprobs = tensor([[-0.7822, -4.7877],
        [-0.9674, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902336239814758
Epoch 0, Step 671: train/loss = 0.45087283849716187, train/raw-loss = 0.3952486217021942, train/logprobs = tensor([[-0.7571, -3.1470],
        [-0.8192, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1112484484910965
Epoch 0, Step 672: train/loss = 0.5138558745384216, train/raw-loss = 0.4591507315635681, train/logprobs = tensor([[-0.6574, -3.2382],
        [-1.0036, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10941028594970703
Epoch 0, Step 673: train/loss = 0.46185293793678284, train/raw-loss = 0.39542311429977417, train/logprobs = tensor([[-0.5404, -3.2589],
        [-0.9621, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13285964727401733
Epoch 0, Step 674: train/loss = 0.43982285261154175, train/raw-loss = 0.38282281160354614, train/logprobs = tensor([[-0.3904, -2.3139],
        [-0.8363, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11400005221366882
Epoch 0, Step 675: train/loss = 0.4122691750526428, train/raw-loss = 0.33642128109931946, train/logprobs = tensor([[-0.5702, -2.6500],
        [-1.2285, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15169575810432434
Epoch 0, Step 676: train/loss = 0.3660930395126343, train/raw-loss = 0.306994765996933, train/logprobs = tensor([[-0.4335, -5.9016],
        [-0.9949, -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181965321302414
Epoch 0, Step 677: train/loss = 0.5151551365852356, train/raw-loss = 0.4482767879962921, train/logprobs = tensor([[-0.3961, -2.6299],
        [-0.7511, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13375668227672577
Epoch 0, Step 678: train/loss = 0.3870917558670044, train/raw-loss = 0.3121783137321472, train/logprobs = tensor([[-0.5437, -4.3935],
        [-1.2333, -0.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14982686936855316
Epoch 0, Step 679: train/loss = 0.3382628560066223, train/raw-loss = 0.27527472376823425, train/logprobs = tensor([[-0.8189, -3.8951],
        [-1.1110, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12597627937793732
Epoch 0, Step 680: train/loss = 0.39999908208847046, train/raw-loss = 0.3464960753917694, train/logprobs = tensor([[-0.5754, -4.7302],
        [-0.9142, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700598359107971
Epoch 0, Step 681: train/loss = 0.40616726875305176, train/raw-loss = 0.33975592255592346, train/logprobs = tensor([[-0.4771, -3.0019],
        [-0.9747, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13282272219657898
Epoch 0, Step 682: train/loss = 0.5725617408752441, train/raw-loss = 0.5010347366333008, train/logprobs = tensor([[-0.9576, -2.3428],
        [-0.9073, -0.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14305397868156433
Epoch 0, Step 683: train/loss = 0.5777348279953003, train/raw-loss = 0.5040766000747681, train/logprobs = tensor([[-0.7658, -1.9157],
        [-1.3066, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14731639623641968
Epoch 0, Step 684: train/loss = 0.40319132804870605, train/raw-loss = 0.3463197946548462, train/logprobs = tensor([[-0.5440, -3.9392],
        [-0.9395, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11374302208423615
Epoch 0, Step 685: train/loss = 0.45101723074913025, train/raw-loss = 0.38894161581993103, train/logprobs = tensor([[-0.4904, -3.1461],
        [-0.8864, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12415117025375366
Epoch 0, Step 686: train/loss = 0.5251255035400391, train/raw-loss = 0.44625282287597656, train/logprobs = tensor([[-1.1427, -2.6062],
        [-1.2732, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15774531662464142
Epoch 0, Step 687: train/loss = 0.4675205647945404, train/raw-loss = 0.4176151156425476, train/logprobs = tensor([[-0.7679, -2.8382],
        [-0.9802, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09981092810630798
Epoch 0, Step 688: train/loss = 0.2763516306877136, train/raw-loss = 0.2057899534702301, train/logprobs = tensor([[-0.5156, -5.3154],
        [-1.1310, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14112338423728943
Epoch 0, Step 689: train/loss = 0.37801140546798706, train/raw-loss = 0.3195706009864807, train/logprobs = tensor([[-0.5237, -4.8010],
        [-1.1204, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11688166111707687
Epoch 0, Step 690: train/loss = 0.4918401539325714, train/raw-loss = 0.4449925422668457, train/logprobs = tensor([[-0.3329, -3.2166],
        [-0.5498, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09369523823261261
Epoch 0, Step 691: train/loss = 0.3669666647911072, train/raw-loss = 0.2993198037147522, train/logprobs = tensor([[-0.7330, -4.8031],
        [-1.7097, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13529367744922638
Epoch 0, Step 692: train/loss = 0.41739898920059204, train/raw-loss = 0.3564351201057434, train/logprobs = tensor([[-0.4783, -2.6123],
        [-0.8680, -0.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12192780524492264
Epoch 0, Step 693: train/loss = 0.4439481496810913, train/raw-loss = 0.3874989151954651, train/logprobs = tensor([[-0.5539, -2.5493],
        [-0.8901, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289851367473602
Epoch 0, Step 694: train/loss = 0.3706672787666321, train/raw-loss = 0.3118065595626831, train/logprobs = tensor([[-0.6772, -4.9132],
        [-1.0109, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11772140115499496
Epoch 0, Step 695: train/loss = 0.5831198692321777, train/raw-loss = 0.5180454850196838, train/logprobs = tensor([[-0.6169, -1.6290],
        [-1.0963, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301487386226654
Epoch 0, Step 696: train/loss = 0.4572105407714844, train/raw-loss = 0.3897612690925598, train/logprobs = tensor([[-0.5613, -3.3636],
        [-1.3495, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13489855825901031
Epoch 0, Step 697: train/loss = 0.4581167995929718, train/raw-loss = 0.39719313383102417, train/logprobs = tensor([[-0.3853, -2.0000],
        [-0.7720, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12184736132621765
Epoch 0, Step 698: train/loss = 0.47904524207115173, train/raw-loss = 0.4162925183773041, train/logprobs = tensor([[-0.6053, -2.8101],
        [-1.2091, -0.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12550541758537292
Epoch 0, Step 699: train/loss = 0.30377158522605896, train/raw-loss = 0.23892483115196228, train/logprobs = tensor([[-0.7493, -5.2958],
        [-1.6191, -1.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12969353795051575
Epoch 0, Step 700: train/loss = 0.4442082643508911, train/raw-loss = 0.38069742918014526, train/logprobs = tensor([[-0.8655, -5.5447],
        [-1.0200, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12702171504497528
Epoch 0, Step 701: train/loss = 0.3955204486846924, train/raw-loss = 0.32685500383377075, train/logprobs = tensor([[-0.6824, -4.2962],
        [-0.9996, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13733085989952087
Epoch 0, Step 702: train/loss = 0.4881645441055298, train/raw-loss = 0.4353901743888855, train/logprobs = tensor([[-0.5172, -1.8817],
        [-0.8982, -0.6931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554887354373932
Epoch 0, Step 703: train/loss = 0.5706785917282104, train/raw-loss = 0.5072846412658691, train/logprobs = tensor([[-0.6272, -2.0838],
        [-1.0118, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126787930727005
Epoch 0, Step 704: train/loss = 0.3100520074367523, train/raw-loss = 0.24470433592796326, train/logprobs = tensor([[-0.9637, -7.6715],
        [-1.7253, -1.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13069534301757812
Epoch 0, Step 705: train/loss = 0.2870202660560608, train/raw-loss = 0.21248701214790344, train/logprobs = tensor([[-0.9169, -4.9293],
        [-1.5354, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490665078163147
Epoch 0, Step 706: train/loss = 0.4896240234375, train/raw-loss = 0.44378697872161865, train/logprobs = tensor([[-0.4456, -3.3418],
        [-0.6466, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09167413413524628
Epoch 0, Step 707: train/loss = 0.4273669123649597, train/raw-loss = 0.36121875047683716, train/logprobs = tensor([[-0.6312, -3.4236],
        [-1.0504, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322963535785675
Epoch 0, Step 708: train/loss = 0.46393856406211853, train/raw-loss = 0.4083010256290436, train/logprobs = tensor([[-0.5236, -3.3822],
        [-0.8461, -0.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127511411905289
Epoch 0, Step 709: train/loss = 0.2092444896697998, train/raw-loss = 0.13840511441230774, train/logprobs = tensor([[-0.7104, -6.8535],
        [-1.8481, -1.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14167875051498413
Epoch 0, Step 710: train/loss = 0.3461401164531708, train/raw-loss = 0.28134459257125854, train/logprobs = tensor([[-0.6792, -3.9821],
        [-1.3248, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12959104776382446
Epoch 0, Step 711: train/loss = 0.508905827999115, train/raw-loss = 0.44986361265182495, train/logprobs = tensor([[-0.4696, -2.3540],
        [-0.9621, -0.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11808452755212784
Epoch 0, Step 712: train/loss = 0.44993075728416443, train/raw-loss = 0.3911933898925781, train/logprobs = tensor([[-0.6872, -3.3872],
        [-1.2265, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11747479438781738
Epoch 0, Step 713: train/loss = 0.38573479652404785, train/raw-loss = 0.3234114348888397, train/logprobs = tensor([[-0.7772, -5.1455],
        [-1.1856, -1.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12464664876461029
Epoch 0, Step 714: train/loss = 0.5153264403343201, train/raw-loss = 0.4603109061717987, train/logprobs = tensor([[-0.8010, -4.3517],
        [-0.9782, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003108322620392
Epoch 0, Step 715: train/loss = 0.34040582180023193, train/raw-loss = 0.28245171904563904, train/logprobs = tensor([[-0.5982, -5.8080],
        [-0.8999, -1.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11590825766324997
Epoch 0, Step 716: train/loss = 0.571341872215271, train/raw-loss = 0.5082868337631226, train/logprobs = tensor([[-0.6224, -1.5561],
        [-1.0211, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12611006200313568
Epoch 0, Step 717: train/loss = 0.4733578562736511, train/raw-loss = 0.4156232476234436, train/logprobs = tensor([[-0.6389, -3.4802],
        [-1.3563, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11546925455331802
Epoch 0, Step 718: train/loss = 0.5337159037590027, train/raw-loss = 0.474202960729599, train/logprobs = tensor([[-1.0198, -2.8164],
        [-1.2290, -1.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11902597546577454
Epoch 0, Step 719: train/loss = 0.4996550977230072, train/raw-loss = 0.4432601034641266, train/logprobs = tensor([[-0.4449, -1.9303],
        [-0.7662, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11278997361660004
Epoch 0, Step 720: train/loss = 0.3962084650993347, train/raw-loss = 0.32424071431159973, train/logprobs = tensor([[-0.6460, -3.4099],
        [-1.2327, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14393547177314758
Epoch 0, Step 721: train/loss = 0.464908629655838, train/raw-loss = 0.3859716057777405, train/logprobs = tensor([[-0.7835, -2.9227],
        [-1.0196, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15787404775619507
Epoch 0, Step 722: train/loss = 0.7250324487686157, train/raw-loss = 0.6709490418434143, train/logprobs = tensor([[-0.5789, -0.6747],
        [-0.6778, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10816669464111328
Epoch 0, Step 723: train/loss = 0.40104952454566956, train/raw-loss = 0.31227007508277893, train/logprobs = tensor([[-0.9053, -3.5301],
        [-1.3112, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17755888402462006
Epoch 0, Step 724: train/loss = 0.35647159814834595, train/raw-loss = 0.3009243905544281, train/logprobs = tensor([[-0.5448, -5.5135],
        [-1.0838, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11109444499015808
Epoch 0, Step 725: train/loss = 0.585723340511322, train/raw-loss = 0.5290194749832153, train/logprobs = tensor([[-0.9882, -2.9471],
        [-0.8243, -0.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11340777575969696
Epoch 0, Step 726: train/loss = 0.32460522651672363, train/raw-loss = 0.2661479413509369, train/logprobs = tensor([[-0.4322, -5.9110],
        [-0.8203, -0.8616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169145256280899
Epoch 0, Step 727: train/loss = 0.5608765482902527, train/raw-loss = 0.5017593502998352, train/logprobs = tensor([[-1.0718, -3.9460],
        [-0.8354, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11823435127735138
Epoch 0, Step 728: train/loss = 0.2614513039588928, train/raw-loss = 0.19371725618839264, train/logprobs = tensor([[-0.6849, -8.4824],
        [-1.5896, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13546811044216156
Epoch 0, Step 729: train/loss = 0.6105890274047852, train/raw-loss = 0.5438895225524902, train/logprobs = tensor([[-1.2769, -2.3948],
        [-1.2577, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13339902460575104
Epoch 0, Step 730: train/loss = 0.5223061442375183, train/raw-loss = 0.4717468321323395, train/logprobs = tensor([[-0.3412, -1.8665],
        [-0.5862, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10111860930919647
Epoch 0, Step 731: train/loss = 0.5253206491470337, train/raw-loss = 0.46621444821357727, train/logprobs = tensor([[-0.5747, -2.3076],
        [-0.8195, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11821234226226807
Epoch 0, Step 732: train/loss = 0.5031121969223022, train/raw-loss = 0.4335651695728302, train/logprobs = tensor([[-0.5492, -2.4756],
        [-0.9666, -1.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13909411430358887
Epoch 0, Step 733: train/loss = 0.48400843143463135, train/raw-loss = 0.4312918186187744, train/logprobs = tensor([[-0.5692, -3.7426],
        [-0.8510, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10543324053287506
Epoch 0, Step 734: train/loss = 0.5057253241539001, train/raw-loss = 0.4390465021133423, train/logprobs = tensor([[-0.8060, -2.3921],
        [-1.1585, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13335765898227692
Epoch 0, Step 735: train/loss = 0.7009261846542358, train/raw-loss = 0.6447964906692505, train/logprobs = tensor([[-0.8272, -1.1926],
        [-0.7445, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11225948482751846
Epoch 0, Step 736: train/loss = 0.6525148749351501, train/raw-loss = 0.607729434967041, train/logprobs = tensor([[-0.3671, -1.0242],
        [-0.5859, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957083523273468
Epoch 0, Step 737: train/loss = 0.31768685579299927, train/raw-loss = 0.24375715851783752, train/logprobs = tensor([[-0.6909, -3.3134],
        [-1.6207, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14785940945148468
Epoch 0, Step 738: train/loss = 0.58851557970047, train/raw-loss = 0.5270435810089111, train/logprobs = tensor([[-0.6582, -1.8352],
        [-1.2908, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294389307498932
Epoch 0, Step 739: train/loss = 0.35602009296417236, train/raw-loss = 0.29538029432296753, train/logprobs = tensor([[-1.0762, -3.3987],
        [-1.9693, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12127962708473206
Epoch 0, Step 740: train/loss = 0.2570296823978424, train/raw-loss = 0.1910785436630249, train/logprobs = tensor([[-0.6845, -4.7805],
        [-1.4135, -0.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13190226256847382
Epoch 0, Step 741: train/loss = 0.2824260890483856, train/raw-loss = 0.1973702609539032, train/logprobs = tensor([[-0.7781, -6.8159],
        [-1.5513, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17011168599128723
Epoch 0, Step 742: train/loss = 0.479147344827652, train/raw-loss = 0.42097505927085876, train/logprobs = tensor([[-0.4677, -2.6322],
        [-0.8483, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11634457856416702
Epoch 0, Step 743: train/loss = 0.3373725414276123, train/raw-loss = 0.2766414284706116, train/logprobs = tensor([[-0.9099, -7.0406],
        [-1.5156, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12146222591400146
Epoch 0, Step 744: train/loss = 0.6236791610717773, train/raw-loss = 0.5697966814041138, train/logprobs = tensor([[-0.5404, -0.9070],
        [-0.7717, -0.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776504129171371
Epoch 0, Step 745: train/loss = 0.4226051867008209, train/raw-loss = 0.3656808137893677, train/logprobs = tensor([[-0.3918, -2.7522],
        [-0.7235, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11384876817464828
Epoch 0, Step 746: train/loss = 0.6908285021781921, train/raw-loss = 0.628326416015625, train/logprobs = tensor([[-0.6024, -0.6770],
        [-0.8449, -0.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12500418722629547
Epoch 0, Step 747: train/loss = 0.4890711009502411, train/raw-loss = 0.43828171491622925, train/logprobs = tensor([[-0.5218, -2.1456],
        [-0.7341, -0.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10157869756221771
Epoch 0, Step 748: train/loss = 0.595354437828064, train/raw-loss = 0.5379093885421753, train/logprobs = tensor([[-0.4496, -1.1515],
        [-0.9441, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11488997936248779
Epoch 0, Step 749: train/loss = 0.48858386278152466, train/raw-loss = 0.4264260232448578, train/logprobs = tensor([[-0.8201, -3.7686],
        [-1.2210, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12431572377681732
Epoch 0, Step 750: train/loss = 0.4555532932281494, train/raw-loss = 0.3957996070384979, train/logprobs = tensor([[-0.9058, -4.7767],
        [-1.7876, -1.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11950735747814178
Epoch 0, Step 751: train/loss = 0.5837486982345581, train/raw-loss = 0.5243515372276306, train/logprobs = tensor([[-0.6473, -3.0618],
        [-0.7742, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879437416791916
Epoch 0, Step 752: train/loss = 0.5379617810249329, train/raw-loss = 0.4786856770515442, train/logprobs = tensor([[-0.4496, -3.0461],
        [-0.8697, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11855224519968033
Epoch 0, Step 753: train/loss = 0.3913864493370056, train/raw-loss = 0.3263111710548401, train/logprobs = tensor([[-0.5184, -2.7928],
        [-0.8559, -0.5763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13015057146549225
Epoch 0, Step 754: train/loss = 0.41580748558044434, train/raw-loss = 0.3511671721935272, train/logprobs = tensor([[-0.6757, -2.7933],
        [-1.1489, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12928059697151184
Epoch 0, Step 755: train/loss = 0.37138867378234863, train/raw-loss = 0.2972544729709625, train/logprobs = tensor([[-0.7827, -6.0015],
        [-1.5316, -1.4182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14826838672161102
Epoch 0, Step 756: train/loss = 0.44971776008605957, train/raw-loss = 0.3867156505584717, train/logprobs = tensor([[-0.8756, -4.2655],
        [-1.3401, -0.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260041892528534
Epoch 0, Step 757: train/loss = 0.5466502904891968, train/raw-loss = 0.4771367311477661, train/logprobs = tensor([[-0.5454, -3.8859],
        [-0.9285, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390271782875061
Epoch 0, Step 758: train/loss = 0.36430734395980835, train/raw-loss = 0.30135276913642883, train/logprobs = tensor([[-0.5057, -5.0978],
        [-1.0903, -1.3742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12590914964675903
Epoch 0, Step 759: train/loss = 0.4542863965034485, train/raw-loss = 0.39196571707725525, train/logprobs = tensor([[-0.6184, -3.8264],
        [-0.9080, -0.6272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12464135140180588
Epoch 0, Step 760: train/loss = 0.5352533459663391, train/raw-loss = 0.47718024253845215, train/logprobs = tensor([[-1.0804, -3.3834],
        [-1.1985, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11614616960287094
Epoch 0, Step 761: train/loss = 0.669080913066864, train/raw-loss = 0.6093431115150452, train/logprobs = tensor([[-1.2086, -1.2802],
        [-1.3868, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11947557330131531
Epoch 0, Step 762: train/loss = 0.4859711825847626, train/raw-loss = 0.4167161285877228, train/logprobs = tensor([[-0.5146, -2.7440],
        [-1.0720, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385100781917572
Epoch 0, Step 763: train/loss = 0.42045164108276367, train/raw-loss = 0.34409093856811523, train/logprobs = tensor([[-0.7774, -2.6928],
        [-1.2804, -1.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15272144973278046
Epoch 0, Step 764: train/loss = 0.5534933805465698, train/raw-loss = 0.4961903691291809, train/logprobs = tensor([[-0.6263, -1.4555],
        [-1.0009, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11460595577955246
Epoch 0, Step 765: train/loss = 0.4265405833721161, train/raw-loss = 0.37094154953956604, train/logprobs = tensor([[-0.6914, -5.0469],
        [-1.2577, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119809746742249
Epoch 0, Step 766: train/loss = 0.34039106965065, train/raw-loss = 0.26347947120666504, train/logprobs = tensor([[-0.7405, -3.4008],
        [-1.2904, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15382321178913116
Epoch 0, Step 767: train/loss = 0.576231837272644, train/raw-loss = 0.5052918791770935, train/logprobs = tensor([[-0.5782, -1.7515],
        [-0.8733, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14187994599342346
Epoch 0, Step 768: train/loss = 0.6690263152122498, train/raw-loss = 0.6195744276046753, train/logprobs = tensor([[-0.4649, -0.7916],
        [-0.6542, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09890376031398773
Epoch 0, Step 769: train/loss = 0.43041110038757324, train/raw-loss = 0.3681367039680481, train/logprobs = tensor([[-0.8074, -2.9387],
        [-1.0547, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454890459775925
Epoch 0, Step 770: train/loss = 0.4924014210700989, train/raw-loss = 0.43878814578056335, train/logprobs = tensor([[-0.4413, -1.9088],
        [-0.6836, -0.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10722648352384567
Epoch 0, Step 771: train/loss = 0.3360251784324646, train/raw-loss = 0.27761971950531006, train/logprobs = tensor([[-0.5747, -4.6660],
        [-0.8649, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1168108731508255
Epoch 0, Step 772: train/loss = 0.3417430520057678, train/raw-loss = 0.2758394479751587, train/logprobs = tensor([[-0.9119, -3.6196],
        [-1.2540, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13180723786354065
Epoch 0, Step 773: train/loss = 0.4539331793785095, train/raw-loss = 0.39469605684280396, train/logprobs = tensor([[-0.8703, -3.7291],
        [-1.0082, -1.3245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847421526908875
Epoch 0, Step 774: train/loss = 0.4935281574726105, train/raw-loss = 0.43708252906799316, train/logprobs = tensor([[-0.9918, -2.3289],
        [-1.1307, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289124190807343
Epoch 0, Step 775: train/loss = 0.7464503049850464, train/raw-loss = 0.6812639832496643, train/logprobs = tensor([[-2.5581, -7.6402],
        [-1.3175, -1.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13037249445915222
Epoch 0, Step 776: train/loss = 0.342314213514328, train/raw-loss = 0.2915952205657959, train/logprobs = tensor([[-0.6579, -5.2019],
        [-1.1619, -1.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10143793374300003
Epoch 0, Step 777: train/loss = 0.5063580274581909, train/raw-loss = 0.454446017742157, train/logprobs = tensor([[-0.4889, -2.2745],
        [-0.8697, -0.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382409393787384
Epoch 0, Step 778: train/loss = 0.40211784839630127, train/raw-loss = 0.33643701672554016, train/logprobs = tensor([[-0.6304, -3.6107],
        [-0.9960, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313617080450058
Epoch 0, Step 779: train/loss = 0.5139785408973694, train/raw-loss = 0.45478513836860657, train/logprobs = tensor([[-0.7302, -3.8696],
        [-0.7548, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11838681995868683
Epoch 0, Step 780: train/loss = 0.6075317859649658, train/raw-loss = 0.5570020079612732, train/logprobs = tensor([[-0.5264, -1.7208],
        [-0.5784, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10105951130390167
Epoch 0, Step 781: train/loss = 0.5154014825820923, train/raw-loss = 0.45516079664230347, train/logprobs = tensor([[-0.8329, -2.2768],
        [-1.1679, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12048127502202988
Epoch 0, Step 782: train/loss = 0.4014833867549896, train/raw-loss = 0.32122740149497986, train/logprobs = tensor([[-1.3580, -6.7147],
        [-1.3808, -1.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16051200032234192
Epoch 0, Step 783: train/loss = 0.34515342116355896, train/raw-loss = 0.2775096297264099, train/logprobs = tensor([[-0.5895, -3.8716],
        [-0.9683, -0.5358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13528764247894287
Epoch 0, Step 784: train/loss = 0.28527697920799255, train/raw-loss = 0.22189319133758545, train/logprobs = tensor([[-0.7054, -9.6502],
        [-1.2030, -1.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1267676055431366
Epoch 0, Step 785: train/loss = 0.5246431827545166, train/raw-loss = 0.4815969467163086, train/logprobs = tensor([[-0.3330, -2.5726],
        [-0.4701, -0.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08609245717525482
Epoch 0, Step 786: train/loss = 0.32081329822540283, train/raw-loss = 0.25929415225982666, train/logprobs = tensor([[-0.5402, -6.2426],
        [-0.8076, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12303823232650757
Epoch 0, Step 787: train/loss = 0.5160974264144897, train/raw-loss = 0.4525904655456543, train/logprobs = tensor([[-0.5832, -2.3122],
        [-0.8847, -0.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270138919353485
Epoch 0, Step 788: train/loss = 0.40394216775894165, train/raw-loss = 0.3307424783706665, train/logprobs = tensor([[-0.5964, -6.5441],
        [-0.9813, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14639928936958313
Epoch 0, Step 789: train/loss = 0.6245301365852356, train/raw-loss = 0.5722962021827698, train/logprobs = tensor([[-0.7420, -1.5914],
        [-0.6846, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10446792095899582
Epoch 0, Step 790: train/loss = 0.5310792922973633, train/raw-loss = 0.4641784429550171, train/logprobs = tensor([[-0.6200, -2.3671],
        [-0.7540, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13380169868469238
Epoch 0, Step 791: train/loss = 0.5816248655319214, train/raw-loss = 0.5257478356361389, train/logprobs = tensor([[-0.8656, -1.6906],
        [-1.0621, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11175408214330673
Epoch 0, Step 792: train/loss = 0.42270585894584656, train/raw-loss = 0.3608939051628113, train/logprobs = tensor([[-0.6457, -3.2640],
        [-1.1646, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12362389266490936
Epoch 0, Step 793: train/loss = 0.4965628385543823, train/raw-loss = 0.4301075339317322, train/logprobs = tensor([[-0.7316, -6.2885],
        [-1.0316, -1.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13291063904762268
Epoch 0, Step 794: train/loss = 0.3578307032585144, train/raw-loss = 0.28381550312042236, train/logprobs = tensor([[-0.6519, -4.7256],
        [-1.1327, -0.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14803040027618408
Epoch 0, Step 795: train/loss = 0.4148619771003723, train/raw-loss = 0.3585548400878906, train/logprobs = tensor([[-0.8744, -4.0355],
        [-1.0241, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11261427402496338
Epoch 0, Step 796: train/loss = 0.35259658098220825, train/raw-loss = 0.283538281917572, train/logprobs = tensor([[-0.7377, -6.3854],
        [-1.1477, -1.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13811670243740082
Epoch 0, Step 797: train/loss = 0.5254116654396057, train/raw-loss = 0.4740855395793915, train/logprobs = tensor([[-0.5249, -1.5926],
        [-0.7290, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10265212506055832
Epoch 0, Step 798: train/loss = 0.48040229082107544, train/raw-loss = 0.4249412715435028, train/logprobs = tensor([[-0.6862, -4.8883],
        [-0.7701, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11092199385166168
Epoch 0, Step 799: train/loss = 0.5136857032775879, train/raw-loss = 0.44505858421325684, train/logprobs = tensor([[-1.1648, -5.6658],
        [-1.3133, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13725429773330688
Epoch 0, Step 800: train/loss = 0.6560567617416382, train/raw-loss = 0.6025184988975525, train/logprobs = tensor([[-1.0581, -1.6810],
        [-0.9952, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707651078701019
Epoch 0, Step 801: train/loss = 0.2714182436466217, train/raw-loss = 0.19834281504154205, train/logprobs = tensor([[-0.9449, -7.1136],
        [-1.5653, -1.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14615082740783691
Epoch 0, Step 802: train/loss = 0.4844461977481842, train/raw-loss = 0.43685296177864075, train/logprobs = tensor([[-0.7259, -2.3440],
        [-0.9006, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0951865091919899
Epoch 0, Step 803: train/loss = 0.3929779827594757, train/raw-loss = 0.33958786725997925, train/logprobs = tensor([[-0.6641, -4.1538],
        [-0.9743, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10678030550479889
Epoch 0, Step 804: train/loss = 0.5188606381416321, train/raw-loss = 0.4537019431591034, train/logprobs = tensor([[-0.7078, -3.2755],
        [-1.0299, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13031741976737976
Epoch 0, Step 805: train/loss = 0.5126920938491821, train/raw-loss = 0.45952701568603516, train/logprobs = tensor([[-0.4880, -2.3595],
        [-0.7548, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10633012652397156
Epoch 0, Step 806: train/loss = 0.42330285906791687, train/raw-loss = 0.3557596206665039, train/logprobs = tensor([[-0.8419, -5.3047],
        [-1.1501, -1.2320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13508649170398712
Epoch 0, Step 807: train/loss = 0.3652077317237854, train/raw-loss = 0.3013879656791687, train/logprobs = tensor([[-0.7082, -6.5868],
        [-1.0270, -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12763948738574982
Epoch 0, Step 808: train/loss = 0.36444908380508423, train/raw-loss = 0.308059960603714, train/logprobs = tensor([[-0.5549, -3.8350],
        [-0.9567, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11277826875448227
Epoch 0, Step 809: train/loss = 0.3837156593799591, train/raw-loss = 0.3204154968261719, train/logprobs = tensor([[-0.6131, -5.7976],
        [-1.0058, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12660035490989685
Epoch 0, Step 810: train/loss = 0.3470652997493744, train/raw-loss = 0.27777040004730225, train/logprobs = tensor([[-0.6008, -4.6442],
        [-1.0148, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385897994041443
Epoch 0, Step 811: train/loss = 0.5034144520759583, train/raw-loss = 0.4424801170825958, train/logprobs = tensor([[-0.6316, -3.4151],
        [-0.7884, -0.8931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12186866253614426
Epoch 0, Step 812: train/loss = 0.5674850344657898, train/raw-loss = 0.5143513083457947, train/logprobs = tensor([[-0.7256, -2.2241],
        [-0.9843, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10626740753650665
Epoch 0, Step 813: train/loss = 0.5490714907646179, train/raw-loss = 0.4931919276714325, train/logprobs = tensor([[-0.7652, -1.7577],
        [-0.7604, -0.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11175903677940369
Epoch 0, Step 814: train/loss = 0.2883240282535553, train/raw-loss = 0.23258495330810547, train/logprobs = tensor([[-0.7701, -5.2764],
        [-1.7693, -1.3693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11147813498973846
Epoch 0, Step 815: train/loss = 0.4862672686576843, train/raw-loss = 0.42289769649505615, train/logprobs = tensor([[-0.7367, -2.6027],
        [-0.8158, -0.8249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12673917412757874
Epoch 0, Step 816: train/loss = 0.3224128782749176, train/raw-loss = 0.2715511918067932, train/logprobs = tensor([[-0.3838, -7.0281],
        [-0.5627, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10172337293624878
Epoch 0, Step 817: train/loss = 0.4400211274623871, train/raw-loss = 0.3756786584854126, train/logprobs = tensor([[-0.9197, -4.9766],
        [-1.2614, -1.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12868493795394897
Epoch 0, Step 818: train/loss = 0.33145177364349365, train/raw-loss = 0.26941412687301636, train/logprobs = tensor([[-0.6260, -8.8078],
        [-1.0874, -1.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407528609037399
Epoch 0, Step 819: train/loss = 0.39024484157562256, train/raw-loss = 0.3371511399745941, train/logprobs = tensor([[-0.3509, -4.3423],
        [-0.6938, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10618734359741211
Epoch 0, Step 820: train/loss = 0.4308337867259979, train/raw-loss = 0.36430078744888306, train/logprobs = tensor([[-0.8603, -3.5242],
        [-1.0627, -0.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13306599855422974
Epoch 0, Step 821: train/loss = 0.4604889154434204, train/raw-loss = 0.39840731024742126, train/logprobs = tensor([[-0.6522, -2.5801],
        [-1.1198, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12416330724954605
Epoch 0, Step 822: train/loss = 0.5019047856330872, train/raw-loss = 0.44812890887260437, train/logprobs = tensor([[-0.6918, -2.8224],
        [-0.8631, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10755177587270737
Epoch 0, Step 823: train/loss = 0.5187375545501709, train/raw-loss = 0.4669681191444397, train/logprobs = tensor([[-1.0942, -5.8740],
        [-0.8828, -2.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035388708114624
Epoch 0, Step 824: train/loss = 0.40309756994247437, train/raw-loss = 0.34183812141418457, train/logprobs = tensor([[-0.5351, -5.2280],
        [-0.9478, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12251891195774078
Epoch 0, Step 825: train/loss = 0.7169320583343506, train/raw-loss = 0.6623679399490356, train/logprobs = tensor([[-0.9545, -0.5600],
        [-1.2673, -0.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10912825167179108
Epoch 0, Step 826: train/loss = 0.4258038103580475, train/raw-loss = 0.36028558015823364, train/logprobs = tensor([[-1.0042, -3.6440],
        [-1.2789, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310364007949829
Epoch 0, Step 827: train/loss = 0.45633819699287415, train/raw-loss = 0.403003990650177, train/logprobs = tensor([[-0.4761, -2.6818],
        [-0.6163, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10666850209236145
Epoch 0, Step 828: train/loss = 0.34971094131469727, train/raw-loss = 0.2781299948692322, train/logprobs = tensor([[-0.7834, -3.4168],
        [-1.4459, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431618183851242
Epoch 0, Step 829: train/loss = 0.548180103302002, train/raw-loss = 0.48486948013305664, train/logprobs = tensor([[-0.9815, -3.5617],
        [-1.0311, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12662120163440704
Epoch 0, Step 830: train/loss = 0.4040937125682831, train/raw-loss = 0.3528538942337036, train/logprobs = tensor([[-0.3927, -5.5767],
        [-0.6168, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247963666915894
Epoch 0, Step 831: train/loss = 0.3914126753807068, train/raw-loss = 0.341758131980896, train/logprobs = tensor([[-0.5513, -2.3712],
        [-0.9434, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930912405252457
Epoch 0, Step 832: train/loss = 0.42479413747787476, train/raw-loss = 0.3639858365058899, train/logprobs = tensor([[-0.6775, -2.7078],
        [-1.2877, -0.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12161664664745331
Epoch 0, Step 833: train/loss = 0.6396889686584473, train/raw-loss = 0.5843279361724854, train/logprobs = tensor([[-0.7209, -1.1822],
        [-0.7254, -0.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11072199046611786
Epoch 0, Step 834: train/loss = 0.37704136967658997, train/raw-loss = 0.31296905875205994, train/logprobs = tensor([[-0.9747, -6.2776],
        [-1.3486, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12814459204673767
Epoch 0, Step 835: train/loss = 0.6269410848617554, train/raw-loss = 0.5823651552200317, train/logprobs = tensor([[-0.8911, -3.9335],
        [-0.9012, -1.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08915188908576965
Epoch 0, Step 836: train/loss = 0.4647310972213745, train/raw-loss = 0.40160223841667175, train/logprobs = tensor([[-0.6835, -5.1725],
        [-0.9690, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12625771760940552
Epoch 0, Step 837: train/loss = 0.42431309819221497, train/raw-loss = 0.3666650652885437, train/logprobs = tensor([[-0.4588, -2.7157],
        [-0.7202, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11529605835676193
Epoch 0, Step 838: train/loss = 0.43182677030563354, train/raw-loss = 0.3717533349990845, train/logprobs = tensor([[-0.7169, -3.5237],
        [-0.9399, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12014690041542053
Epoch 0, Step 839: train/loss = 0.3547542691230774, train/raw-loss = 0.30026596784591675, train/logprobs = tensor([[-0.5796, -5.0105],
        [-1.0143, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10897666215896606
Epoch 0, Step 840: train/loss = 0.3819448947906494, train/raw-loss = 0.3087040185928345, train/logprobs = tensor([[-0.6309, -6.3162],
        [-1.2296, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14648178219795227
Epoch 0, Step 841: train/loss = 0.564733624458313, train/raw-loss = 0.502750039100647, train/logprobs = tensor([[-0.6166, -2.2604],
        [-0.8903, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12396705150604248
Epoch 0, Step 842: train/loss = 0.4108407199382782, train/raw-loss = 0.3467087149620056, train/logprobs = tensor([[-0.5047, -5.8379],
        [-1.1929, -1.5806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12826403975486755
Epoch 0, Step 843: train/loss = 0.42135655879974365, train/raw-loss = 0.3578556180000305, train/logprobs = tensor([[-0.9594, -4.1534],
        [-0.9548, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12700194120407104
Epoch 0, Step 844: train/loss = 0.48118847608566284, train/raw-loss = 0.4153609573841095, train/logprobs = tensor([[-1.2877, -5.6339],
        [-1.0897, -1.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13165508210659027
Epoch 0, Step 845: train/loss = 0.3775478005409241, train/raw-loss = 0.31161507964134216, train/logprobs = tensor([[-0.7296, -6.9320],
        [-1.2241, -1.4116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318654716014862
Epoch 0, Step 846: train/loss = 0.35847175121307373, train/raw-loss = 0.30589351058006287, train/logprobs = tensor([[-0.5280, -8.3911],
        [-0.8508, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10515648126602173
Epoch 0, Step 847: train/loss = 0.45257270336151123, train/raw-loss = 0.3944515585899353, train/logprobs = tensor([[-0.8098, -3.9391],
        [-1.0784, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11624228954315186
Epoch 0, Step 848: train/loss = 0.3120464086532593, train/raw-loss = 0.2362913340330124, train/logprobs = tensor([[-0.7907, -5.1221],
        [-1.5270, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515101194381714
Epoch 0, Step 849: train/loss = 0.3196573853492737, train/raw-loss = 0.2545515298843384, train/logprobs = tensor([[-1.2799, -7.9891],
        [-1.5336, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302117258310318
Epoch 0, Step 850: train/loss = 0.45298901200294495, train/raw-loss = 0.3939540386199951, train/logprobs = tensor([[-0.5720, -3.8874],
        [-0.8003, -1.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806996911764145
Epoch 0, Step 851: train/loss = 0.37727320194244385, train/raw-loss = 0.31323641538619995, train/logprobs = tensor([[-0.8657, -6.0005],
        [-1.4299, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12807363271713257
Epoch 0, Step 852: train/loss = 0.4115796685218811, train/raw-loss = 0.3576512038707733, train/logprobs = tensor([[-0.4810, -4.0379],
        [-0.9474, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10785694420337677
Epoch 0, Step 853: train/loss = 0.5805596709251404, train/raw-loss = 0.5278384685516357, train/logprobs = tensor([[-1.0869, -3.7483],
        [-1.3029, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10544252395629883
Epoch 0, Step 854: train/loss = 0.40254396200180054, train/raw-loss = 0.337769091129303, train/logprobs = tensor([[-0.7538, -5.1651],
        [-1.1493, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12954972684383392
Epoch 0, Step 855: train/loss = 0.4268874228000641, train/raw-loss = 0.36852213740348816, train/logprobs = tensor([[-0.7968, -4.9048],
        [-1.1867, -1.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673060059547424
Epoch 0, Step 856: train/loss = 0.3244883120059967, train/raw-loss = 0.2596842646598816, train/logprobs = tensor([[-0.7553, -4.1240],
        [-1.3811, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12960806488990784
Epoch 0, Step 857: train/loss = 0.3921810984611511, train/raw-loss = 0.32115352153778076, train/logprobs = tensor([[-0.6246, -6.1859],
        [-1.2056, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1420551836490631
Epoch 0, Step 858: train/loss = 0.5995825529098511, train/raw-loss = 0.5285816788673401, train/logprobs = tensor([[-1.7219, -2.9382],
        [-1.3022, -0.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14200186729431152
Epoch 0, Step 859: train/loss = 0.3898371458053589, train/raw-loss = 0.33710339665412903, train/logprobs = tensor([[-0.7477, -3.4377],
        [-1.2404, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10546751320362091
Epoch 0, Step 860: train/loss = 0.46370336413383484, train/raw-loss = 0.40488582849502563, train/logprobs = tensor([[-0.7599, -3.7994],
        [-0.9675, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.117635078728199
Epoch 0, Step 861: train/loss = 0.5981593132019043, train/raw-loss = 0.5359736680984497, train/logprobs = tensor([[-0.8825, -3.5608],
        [-0.8086, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124371238052845
Epoch 0, Step 862: train/loss = 0.3851715922355652, train/raw-loss = 0.31567686796188354, train/logprobs = tensor([[-0.7220, -5.9788],
        [-0.9982, -0.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13898950815200806
Epoch 0, Step 863: train/loss = 0.5614662170410156, train/raw-loss = 0.49629688262939453, train/logprobs = tensor([[-0.9635, -3.8516],
        [-0.9698, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303386390209198
Epoch 0, Step 864: train/loss = 0.6838639974594116, train/raw-loss = 0.6243765950202942, train/logprobs = tensor([[-1.2200, -2.1571],
        [-0.9437, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11897482722997665
Epoch 0, Step 865: train/loss = 0.3971481919288635, train/raw-loss = 0.3335117697715759, train/logprobs = tensor([[-0.7486, -2.9854],
        [-1.1488, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272728145122528
Epoch 0, Step 866: train/loss = 0.35565391182899475, train/raw-loss = 0.29618895053863525, train/logprobs = tensor([[-0.6547, -5.8375],
        [-0.8273, -1.2081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.118929922580719
Epoch 0, Step 867: train/loss = 0.5794466733932495, train/raw-loss = 0.522625744342804, train/logprobs = tensor([[-0.6899, -2.4983],
        [-1.0308, -0.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11364196240901947
Epoch 0, Step 868: train/loss = 0.5274302363395691, train/raw-loss = 0.45317065715789795, train/logprobs = tensor([[-0.8704, -1.7161],
        [-1.2467, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1485191434621811
Epoch 0, Step 869: train/loss = 0.4120469093322754, train/raw-loss = 0.3483695387840271, train/logprobs = tensor([[-0.7661, -1.9135],
        [-1.5573, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12735477089881897
Epoch 0, Step 870: train/loss = 0.43294617533683777, train/raw-loss = 0.37875857949256897, train/logprobs = tensor([[-0.8574, -5.8957],
        [-1.2381, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10837523639202118
Epoch 0, Step 871: train/loss = 0.37708285450935364, train/raw-loss = 0.31562334299087524, train/logprobs = tensor([[-0.5096, -5.2614],
        [-0.8839, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12291905283927917
Epoch 0, Step 872: train/loss = 0.5055845379829407, train/raw-loss = 0.45950737595558167, train/logprobs = tensor([[-0.3664, -3.0771],
        [-0.5025, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0921543538570404
Epoch 0, Step 873: train/loss = 0.45120376348495483, train/raw-loss = 0.39769285917282104, train/logprobs = tensor([[-0.8165, -3.8093],
        [-1.0406, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702173411846161
Epoch 0, Step 874: train/loss = 0.3500169813632965, train/raw-loss = 0.2689470648765564, train/logprobs = tensor([[-1.0762, -6.1275],
        [-1.6605, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16213983297348022
Epoch 0, Step 875: train/loss = 0.6334517002105713, train/raw-loss = 0.5817781686782837, train/logprobs = tensor([[-0.8003, -1.0914],
        [-1.0120, -0.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1033470630645752
Epoch 0, Step 876: train/loss = 0.4218893051147461, train/raw-loss = 0.37714219093322754, train/logprobs = tensor([[-0.3854, -6.4862],
        [-0.6634, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08949419111013412
Epoch 0, Step 877: train/loss = 0.4844241738319397, train/raw-loss = 0.41157880425453186, train/logprobs = tensor([[-1.3218, -5.0383],
        [-1.6597, -0.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14569076895713806
Epoch 0, Step 878: train/loss = 0.9953280091285706, train/raw-loss = 0.930637001991272, train/logprobs = tensor([[-2.7061, -4.6658],
        [-1.2392, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293819695711136
Epoch 0, Step 879: train/loss = 0.34048163890838623, train/raw-loss = 0.28144875168800354, train/logprobs = tensor([[-0.4740, -7.8398],
        [-0.9329, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806575953960419
Epoch 0, Step 880: train/loss = 0.3809965252876282, train/raw-loss = 0.3233288526535034, train/logprobs = tensor([[-0.6028, -4.5345],
        [-0.8936, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1153353899717331
Epoch 0, Step 881: train/loss = 0.5185824036598206, train/raw-loss = 0.46328380703926086, train/logprobs = tensor([[-0.5364, -3.8735],
        [-0.7424, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11059708148241043
Epoch 0, Step 882: train/loss = 0.5949369072914124, train/raw-loss = 0.5371236801147461, train/logprobs = tensor([[-0.8040, -1.9299],
        [-0.7285, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11562658846378326
Epoch 0, Step 883: train/loss = 0.39321696758270264, train/raw-loss = 0.3238491117954254, train/logprobs = tensor([[-1.0602, -3.3482],
        [-1.7227, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13873565196990967
Epoch 0, Step 884: train/loss = 0.38638758659362793, train/raw-loss = 0.32242923974990845, train/logprobs = tensor([[-0.6178, -4.2585],
        [-0.9269, -0.8133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12791666388511658
Epoch 0, Step 885: train/loss = 0.3556038737297058, train/raw-loss = 0.2873537540435791, train/logprobs = tensor([[-0.9899, -5.0480],
        [-1.1680, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13650013506412506
Epoch 0, Step 886: train/loss = 0.5389152765274048, train/raw-loss = 0.482003390789032, train/logprobs = tensor([[-0.6372, -2.8304],
        [-0.9074, -0.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11382372677326202
Epoch 0, Step 887: train/loss = 0.48859903216362, train/raw-loss = 0.43131622672080994, train/logprobs = tensor([[-0.6584, -4.2124],
        [-0.9306, -1.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1145656406879425
Epoch 0, Step 888: train/loss = 0.26054635643959045, train/raw-loss = 0.19314786791801453, train/logprobs = tensor([[-0.5843, -5.8105],
        [-1.2913, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13479702174663544
Epoch 0, Step 889: train/loss = 0.4428905248641968, train/raw-loss = 0.37967008352279663, train/logprobs = tensor([[-0.7781, -3.3662],
        [-1.0859, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12644079327583313
Epoch 0, Step 890: train/loss = 0.4140336215496063, train/raw-loss = 0.3448159992694855, train/logprobs = tensor([[-0.7632, -3.0954],
        [-1.1398, -1.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1384352147579193
Epoch 0, Step 891: train/loss = 0.31992024183273315, train/raw-loss = 0.26365596055984497, train/logprobs = tensor([[-0.7254, -5.7202],
        [-1.2247, -1.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11252858489751816
Epoch 0, Step 892: train/loss = 0.39565643668174744, train/raw-loss = 0.32886695861816406, train/logprobs = tensor([[-0.5627, -4.2421],
        [-1.0414, -0.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13357894122600555
Epoch 0, Step 893: train/loss = 0.47756627202033997, train/raw-loss = 0.42207545042037964, train/logprobs = tensor([[-0.7111, -3.8005],
        [-0.9766, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098166555166245
Epoch 0, Step 894: train/loss = 0.3830029368400574, train/raw-loss = 0.314047634601593, train/logprobs = tensor([[-0.6659, -6.8852],
        [-1.0543, -1.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379106193780899
Epoch 0, Step 895: train/loss = 0.47833168506622314, train/raw-loss = 0.4174516201019287, train/logprobs = tensor([[-0.6820, -6.6523],
        [-1.1808, -2.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12176013737916946
Epoch 0, Step 896: train/loss = 0.568181037902832, train/raw-loss = 0.5093498229980469, train/logprobs = tensor([[-0.8543, -2.0342],
        [-0.9564, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11766229569911957
Epoch 0, Step 897: train/loss = 0.49544718861579895, train/raw-loss = 0.42534756660461426, train/logprobs = tensor([[-0.8554, -3.0656],
        [-1.2267, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140199214220047
Epoch 0, Step 898: train/loss = 0.5501120090484619, train/raw-loss = 0.4968465566635132, train/logprobs = tensor([[-0.7068, -1.3056],
        [-0.9865, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10653088986873627
Epoch 0, Step 899: train/loss = 0.46247994899749756, train/raw-loss = 0.39330780506134033, train/logprobs = tensor([[-0.5783, -4.2502],
        [-0.9572, -1.1546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13834431767463684
Epoch 0, Step 900: train/loss = 0.308537095785141, train/raw-loss = 0.24675604701042175, train/logprobs = tensor([[-1.0230, -9.6152],
        [-1.4031, -1.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12356212735176086
Epoch 0, Step 901: train/loss = 0.38904643058776855, train/raw-loss = 0.3306671380996704, train/logprobs = tensor([[-0.3868, -4.1001],
        [-0.8323, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11675857752561569
Epoch 0, Step 902: train/loss = 0.2872856855392456, train/raw-loss = 0.22602033615112305, train/logprobs = tensor([[-0.6594, -6.9795],
        [-1.2296, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12253067642450333
Epoch 0, Step 903: train/loss = 0.39340418577194214, train/raw-loss = 0.3250841200351715, train/logprobs = tensor([[-0.8897, -3.7322],
        [-1.3725, -0.7844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13664010167121887
Epoch 0, Step 904: train/loss = 0.4659431576728821, train/raw-loss = 0.4101341962814331, train/logprobs = tensor([[-1.2301, -4.3344],
        [-1.3534, -1.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161783337593079
Epoch 0, Step 905: train/loss = 0.33654943108558655, train/raw-loss = 0.2823634147644043, train/logprobs = tensor([[-0.4993, -6.7829],
        [-0.8388, -1.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1083720475435257
Epoch 0, Step 906: train/loss = 0.6503252387046814, train/raw-loss = 0.6021557450294495, train/logprobs = tensor([[-0.6335, -1.1644],
        [-0.5348, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09633900225162506
Epoch 0, Step 907: train/loss = 0.6214661598205566, train/raw-loss = 0.568942666053772, train/logprobs = tensor([[-0.7715, -1.3297],
        [-0.7335, -0.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10504703968763351
Epoch 0, Step 908: train/loss = 0.38229894638061523, train/raw-loss = 0.31717973947525024, train/logprobs = tensor([[-0.6265, -4.8731],
        [-1.0867, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.130238339304924
Epoch 0, Step 909: train/loss = 0.36140477657318115, train/raw-loss = 0.2851353883743286, train/logprobs = tensor([[-1.0852, -3.7923],
        [-1.8091, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525387465953827
Epoch 0, Step 910: train/loss = 0.556306004524231, train/raw-loss = 0.49850034713745117, train/logprobs = tensor([[-0.9605, -3.8071],
        [-1.0217, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11561122536659241
Epoch 0, Step 911: train/loss = 0.3103903830051422, train/raw-loss = 0.24727550148963928, train/logprobs = tensor([[-0.7576, -7.3469],
        [-1.0775, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12622982263565063
Epoch 0, Step 912: train/loss = 0.5391530990600586, train/raw-loss = 0.4797897934913635, train/logprobs = tensor([[-1.2094, -5.0731],
        [-0.6120, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872655153274536
Epoch 0, Step 913: train/loss = 0.3803960978984833, train/raw-loss = 0.31525319814682007, train/logprobs = tensor([[-0.7583, -5.8270],
        [-1.2329, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302858144044876
Epoch 0, Step 914: train/loss = 0.5407651662826538, train/raw-loss = 0.485125869512558, train/logprobs = tensor([[-0.3757, -1.9280],
        [-0.7988, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127869784832001
Epoch 0, Step 915: train/loss = 0.44084489345550537, train/raw-loss = 0.3778533637523651, train/logprobs = tensor([[-0.7538, -3.0506],
        [-1.0896, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12598305940628052
Epoch 0, Step 916: train/loss = 0.427714467048645, train/raw-loss = 0.3725048303604126, train/logprobs = tensor([[-1.1005, -2.9928],
        [-1.1740, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11041922122240067
Epoch 0, Step 917: train/loss = 0.4468402564525604, train/raw-loss = 0.3800496459007263, train/logprobs = tensor([[-1.0499, -3.1289],
        [-1.2073, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335812360048294
Epoch 0, Step 918: train/loss = 0.5799541473388672, train/raw-loss = 0.5246522426605225, train/logprobs = tensor([[-0.5525, -1.3426],
        [-0.7521, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11060373485088348
Epoch 0, Step 919: train/loss = 0.5760053992271423, train/raw-loss = 0.5230706334114075, train/logprobs = tensor([[-0.9389, -2.8134],
        [-0.8749, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10586956143379211
Epoch 0, Step 920: train/loss = 0.6434805393218994, train/raw-loss = 0.5938681364059448, train/logprobs = tensor([[-0.7884, -0.7619],
        [-1.0401, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09922485798597336
Epoch 0, Step 921: train/loss = 0.5913382172584534, train/raw-loss = 0.53919517993927, train/logprobs = tensor([[-0.4618, -1.9116],
        [-0.8204, -0.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10428610444068909
Epoch 0, Step 922: train/loss = 0.47829386591911316, train/raw-loss = 0.4182793200016022, train/logprobs = tensor([[-0.6381, -3.8450],
        [-0.6820, -0.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12002909183502197
Epoch 0, Step 923: train/loss = 0.46042779088020325, train/raw-loss = 0.39537423849105835, train/logprobs = tensor([[-0.9724, -3.9104],
        [-0.9420, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301070600748062
Epoch 0, Step 924: train/loss = 0.3509358763694763, train/raw-loss = 0.29302918910980225, train/logprobs = tensor([[-0.6686, -5.6072],
        [-1.3269, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11581332981586456
Epoch 0, Step 925: train/loss = 0.5453476309776306, train/raw-loss = 0.5009299516677856, train/logprobs = tensor([[-0.4609, -1.6820],
        [-0.5434, -0.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08883541822433472
Epoch 0, Step 926: train/loss = 0.5567920207977295, train/raw-loss = 0.507512092590332, train/logprobs = tensor([[-0.4542, -1.9861],
        [-0.6274, -0.7823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855997562408447
Epoch 0, Step 927: train/loss = 0.5880477428436279, train/raw-loss = 0.5207405686378479, train/logprobs = tensor([[-1.2156, -3.2868],
        [-1.0063, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13461434841156006
Epoch 0, Step 928: train/loss = 0.3954012393951416, train/raw-loss = 0.32824188470840454, train/logprobs = tensor([[-0.7641, -5.0395],
        [-0.8745, -1.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343187391757965
Epoch 0, Step 929: train/loss = 0.3590954840183258, train/raw-loss = 0.29879364371299744, train/logprobs = tensor([[-0.5433, -3.6919],
        [-1.2957, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060366570949554
Epoch 0, Step 930: train/loss = 0.5040459632873535, train/raw-loss = 0.4382467269897461, train/logprobs = tensor([[-0.7682, -2.0875],
        [-1.0272, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13159848749637604
Epoch 0, Step 931: train/loss = 0.3875126540660858, train/raw-loss = 0.33684858679771423, train/logprobs = tensor([[-0.6108, -3.0256],
        [-0.9784, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10132817178964615
Epoch 0, Step 932: train/loss = 0.4331468939781189, train/raw-loss = 0.3594834804534912, train/logprobs = tensor([[-0.4912, -3.6392],
        [-1.0987, -0.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14732682704925537
Epoch 0, Step 933: train/loss = 0.48450103402137756, train/raw-loss = 0.43170642852783203, train/logprobs = tensor([[-0.5724, -2.0878],
        [-0.9050, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10558918118476868
Epoch 0, Step 934: train/loss = 0.5237510800361633, train/raw-loss = 0.46377527713775635, train/logprobs = tensor([[-0.5012, -2.6571],
        [-0.8746, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11995159089565277
Epoch 0, Step 935: train/loss = 0.40978479385375977, train/raw-loss = 0.340099036693573, train/logprobs = tensor([[-0.8320, -3.5977],
        [-1.3239, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13937152922153473
Epoch 0, Step 936: train/loss = 0.5169670581817627, train/raw-loss = 0.45016857981681824, train/logprobs = tensor([[-0.8625, -2.5065],
        [-1.1417, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335969865322113
Epoch 0, Step 937: train/loss = 0.530360996723175, train/raw-loss = 0.46692678332328796, train/logprobs = tensor([[-0.7981, -3.4245],
        [-0.9263, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12686842679977417
Epoch 0, Step 938: train/loss = 0.378153920173645, train/raw-loss = 0.2972725033760071, train/logprobs = tensor([[-0.7018, -3.2255],
        [-1.4177, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16176283359527588
Epoch 0, Step 939: train/loss = 0.41915273666381836, train/raw-loss = 0.35752928256988525, train/logprobs = tensor([[-0.8356, -3.9038],
        [-0.8897, -0.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12324699014425278
Epoch 0, Step 940: train/loss = 0.313376784324646, train/raw-loss = 0.23619627952575684, train/logprobs = tensor([[-0.7478, -3.7806],
        [-1.5725, -1.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15436100959777832
Epoch 0, Step 941: train/loss = 0.41773611307144165, train/raw-loss = 0.36454322934150696, train/logprobs = tensor([[-0.6935, -3.7692],
        [-1.1069, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1063857227563858
Epoch 0, Step 942: train/loss = 0.4775644838809967, train/raw-loss = 0.404219388961792, train/logprobs = tensor([[-0.9436, -3.7476],
        [-1.4143, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14669010043144226
Epoch 0, Step 943: train/loss = 0.3853145241737366, train/raw-loss = 0.31485068798065186, train/logprobs = tensor([[-0.7208, -2.8531],
        [-1.5637, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14092768728733063
Epoch 0, Step 944: train/loss = 0.2539418935775757, train/raw-loss = 0.18569687008857727, train/logprobs = tensor([[-0.6440, -7.2081],
        [-1.4830, -1.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13649003207683563
Epoch 0, Step 945: train/loss = 0.5112963914871216, train/raw-loss = 0.4591083526611328, train/logprobs = tensor([[-1.0740, -3.1881],
        [-0.9578, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10437610745429993
Epoch 0, Step 946: train/loss = 0.44167429208755493, train/raw-loss = 0.37675583362579346, train/logprobs = tensor([[-0.7494, -5.7409],
        [-1.1995, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12983697652816772
Epoch 0, Step 947: train/loss = 0.740688681602478, train/raw-loss = 0.6902871131896973, train/logprobs = tensor([[-0.7263, -0.7238],
        [-0.7468, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10080288350582123
Epoch 0, Step 948: train/loss = 0.45332086086273193, train/raw-loss = 0.38210368156433105, train/logprobs = tensor([[-0.6323, -2.7099],
        [-0.9752, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14243437349796295
Epoch 0, Step 949: train/loss = 0.5306804180145264, train/raw-loss = 0.4673798978328705, train/logprobs = tensor([[-0.8820, -2.8545],
        [-1.0657, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126600980758667
Epoch 0, Step 950: train/loss = 0.3449159562587738, train/raw-loss = 0.2859439551830292, train/logprobs = tensor([[-0.4210, -3.4420],
        [-1.1966, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11794402450323105
Epoch 0, Step 951: train/loss = 0.6096891760826111, train/raw-loss = 0.5406314134597778, train/logprobs = tensor([[-1.3953, -3.5674],
        [-1.0191, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1381155252456665
Epoch 0, Step 952: train/loss = 0.4380965530872345, train/raw-loss = 0.3859819173812866, train/logprobs = tensor([[-0.3458, -3.8707],
        [-0.6971, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422925651073456
Epoch 0, Step 953: train/loss = 0.545842170715332, train/raw-loss = 0.48664700984954834, train/logprobs = tensor([[-0.7027, -2.0951],
        [-0.9145, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11839026212692261
Epoch 0, Step 954: train/loss = 0.5346254706382751, train/raw-loss = 0.48216086626052856, train/logprobs = tensor([[-0.6437, -1.4859],
        [-0.8717, -0.4846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10492925345897675
Epoch 0, Step 955: train/loss = 0.37470802664756775, train/raw-loss = 0.30998387932777405, train/logprobs = tensor([[-0.7506, -6.0937],
        [-1.0941, -1.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294482797384262
Epoch 0, Step 956: train/loss = 0.4005720019340515, train/raw-loss = 0.3452010154724121, train/logprobs = tensor([[-0.5021, -3.1227],
        [-0.9343, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11074191331863403
Epoch 0, Step 957: train/loss = 0.4721342921257019, train/raw-loss = 0.41470131278038025, train/logprobs = tensor([[-0.9747, -5.2124],
        [-1.2090, -1.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11486595124006271
Epoch 0, Step 958: train/loss = 0.4850528836250305, train/raw-loss = 0.4249342679977417, train/logprobs = tensor([[-0.7807, -4.6202],
        [-0.7796, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12023715674877167
Epoch 0, Step 959: train/loss = 0.4414548873901367, train/raw-loss = 0.38396894931793213, train/logprobs = tensor([[-0.5772, -3.8447],
        [-0.9911, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11497191339731216
Epoch 0, Step 960: train/loss = 0.5837993025779724, train/raw-loss = 0.5329855680465698, train/logprobs = tensor([[-0.5943, -1.2313],
        [-0.9484, -0.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10162746906280518
Epoch 0, Step 961: train/loss = 0.34925732016563416, train/raw-loss = 0.28488126397132874, train/logprobs = tensor([[-0.8461, -3.5676],
        [-1.5331, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12875208258628845
Epoch 0, Step 962: train/loss = 0.524431586265564, train/raw-loss = 0.46956002712249756, train/logprobs = tensor([[-1.3753, -4.9282],
        [-1.5215, -1.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10974321514368057
Epoch 0, Step 963: train/loss = 0.5183038711547852, train/raw-loss = 0.45902252197265625, train/logprobs = tensor([[-0.5911, -1.6977],
        [-0.8458, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.118562713265419
Epoch 0, Step 964: train/loss = 0.49202510714530945, train/raw-loss = 0.42485931515693665, train/logprobs = tensor([[-0.6891, -2.6804],
        [-1.1072, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343316286802292
Epoch 0, Step 965: train/loss = 0.39726024866104126, train/raw-loss = 0.3418564200401306, train/logprobs = tensor([[-0.8580, -3.9540],
        [-1.2074, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080768704414368
Epoch 0, Step 966: train/loss = 0.4621478021144867, train/raw-loss = 0.4050881564617157, train/logprobs = tensor([[-0.4376, -2.4203],
        [-0.9982, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11411925405263901
Epoch 0, Step 967: train/loss = 0.469921350479126, train/raw-loss = 0.4167712926864624, train/logprobs = tensor([[-0.5034, -2.4219],
        [-0.9345, -0.3922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630012303590775
Epoch 0, Step 968: train/loss = 0.48960912227630615, train/raw-loss = 0.4352552890777588, train/logprobs = tensor([[-0.8801, -2.7076],
        [-1.5595, -1.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10870768129825592
Epoch 0, Step 969: train/loss = 0.3897758424282074, train/raw-loss = 0.31732016801834106, train/logprobs = tensor([[-0.5406, -4.7070],
        [-1.3155, -1.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14491133391857147
Epoch 0, Step 970: train/loss = 0.4776528477668762, train/raw-loss = 0.41854211688041687, train/logprobs = tensor([[-0.5579, -2.4343],
        [-0.8743, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11822154372930527
Epoch 0, Step 971: train/loss = 0.4482513666152954, train/raw-loss = 0.3852165937423706, train/logprobs = tensor([[-0.2982, -4.0236],
        [-0.7248, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126069575548172
Epoch 0, Step 972: train/loss = 0.4826314151287079, train/raw-loss = 0.42704838514328003, train/logprobs = tensor([[-0.6392, -4.7042],
        [-0.8143, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11116611957550049
Epoch 0, Step 973: train/loss = 0.5570079684257507, train/raw-loss = 0.5018119812011719, train/logprobs = tensor([[-0.5810, -2.0242],
        [-0.9205, -0.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11039210855960846
Epoch 0, Step 974: train/loss = 0.4532175064086914, train/raw-loss = 0.38808485865592957, train/logprobs = tensor([[-0.7398, -3.5804],
        [-1.1610, -1.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026534020900726
Epoch 0, Step 975: train/loss = 0.3906935453414917, train/raw-loss = 0.32361942529678345, train/logprobs = tensor([[-0.4713, -3.2218],
        [-0.8114, -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341482698917389
Epoch 0, Step 976: train/loss = 0.5340410470962524, train/raw-loss = 0.4643913507461548, train/logprobs = tensor([[-0.3903, -2.6799],
        [-1.0545, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13929937779903412
Epoch 0, Step 977: train/loss = 0.4955022931098938, train/raw-loss = 0.4321332573890686, train/logprobs = tensor([[-0.7017, -3.2232],
        [-0.9300, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12673808634281158
Epoch 0, Step 978: train/loss = 0.47396397590637207, train/raw-loss = 0.4001099467277527, train/logprobs = tensor([[-1.1652, -3.3053],
        [-1.1802, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14770811796188354
Epoch 0, Step 979: train/loss = 0.4560220539569855, train/raw-loss = 0.40233421325683594, train/logprobs = tensor([[-0.4882, -2.7036],
        [-0.9456, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10737565159797668
Epoch 0, Step 980: train/loss = 0.3397741913795471, train/raw-loss = 0.2805781960487366, train/logprobs = tensor([[-0.5926, -3.4458],
        [-1.0371, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11839199811220169
Epoch 0, Step 981: train/loss = 0.41977187991142273, train/raw-loss = 0.3571687936782837, train/logprobs = tensor([[-0.8837, -4.5948],
        [-1.5292, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252061426639557
Epoch 0, Step 982: train/loss = 0.3872807025909424, train/raw-loss = 0.32559531927108765, train/logprobs = tensor([[-0.6267, -2.8902],
        [-1.0602, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12337081134319305
Epoch 0, Step 983: train/loss = 0.46458402276039124, train/raw-loss = 0.40495049953460693, train/logprobs = tensor([[-0.7747, -2.9683],
        [-0.9800, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11926701664924622
Epoch 0, Step 984: train/loss = 0.4975905120372772, train/raw-loss = 0.428485631942749, train/logprobs = tensor([[-0.4965, -1.9165],
        [-1.1505, -0.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1382097601890564
Epoch 0, Step 985: train/loss = 0.5827673077583313, train/raw-loss = 0.5323977470397949, train/logprobs = tensor([[-0.5998, -1.2826],
        [-0.7830, -0.6727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10073903203010559
Epoch 0, Step 986: train/loss = 0.2676030993461609, train/raw-loss = 0.19973139464855194, train/logprobs = tensor([[-0.6402, -7.2250],
        [-1.4729, -1.4563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357433795928955
Epoch 0, Step 987: train/loss = 0.5743007659912109, train/raw-loss = 0.5185902714729309, train/logprobs = tensor([[-1.1001, -1.9562],
        [-1.0202, -0.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11142100393772125
Epoch 0, Step 988: train/loss = 0.5864768028259277, train/raw-loss = 0.5172407031059265, train/logprobs = tensor([[-0.5916, -2.0180],
        [-1.7932, -1.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13847219944000244
Epoch 0, Step 989: train/loss = 0.40148478746414185, train/raw-loss = 0.33717799186706543, train/logprobs = tensor([[-0.7564, -2.6918],
        [-1.1575, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286136358976364
Epoch 0, Step 990: train/loss = 0.5005088448524475, train/raw-loss = 0.4463041424751282, train/logprobs = tensor([[-0.4847, -2.5450],
        [-0.7279, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10840942710638046
Epoch 0, Step 991: train/loss = 0.5919111967086792, train/raw-loss = 0.5380914211273193, train/logprobs = tensor([[-0.5484, -1.0744],
        [-0.7383, -0.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076396107673645
Epoch 0, Step 992: train/loss = 0.42852187156677246, train/raw-loss = 0.36702683568000793, train/logprobs = tensor([[-0.4728, -3.3972],
        [-0.8540, -0.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12299001961946487
Epoch 0, Step 993: train/loss = 0.39723464846611023, train/raw-loss = 0.33468344807624817, train/logprobs = tensor([[-0.5149, -2.4525],
        [-1.1518, -0.6459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510234117507935
Epoch 0, Step 994: train/loss = 0.276760071516037, train/raw-loss = 0.20303314924240112, train/logprobs = tensor([[-0.7522, -4.6529],
        [-1.5056, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14745381474494934
Epoch 0, Step 995: train/loss = 0.282542884349823, train/raw-loss = 0.2258562445640564, train/logprobs = tensor([[-0.4552, -4.7959],
        [-0.9009, -0.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1133732944726944
Epoch 0, Step 996: train/loss = 0.526976466178894, train/raw-loss = 0.4750064015388489, train/logprobs = tensor([[-0.5102, -3.7468],
        [-0.8442, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10394009947776794
Epoch 0, Step 997: train/loss = 0.33262041211128235, train/raw-loss = 0.27394187450408936, train/logprobs = tensor([[-0.6220, -4.4782],
        [-0.8662, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11735709011554718
Epoch 0, Step 998: train/loss = 0.38588613271713257, train/raw-loss = 0.2977668344974518, train/logprobs = tensor([[-0.5838, -3.1118],
        [-1.5629, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17623858153820038
Epoch 0, Step 999: train/loss = 0.5171263217926025, train/raw-loss = 0.4609064757823944, train/logprobs = tensor([[-0.5519, -1.9115],
        [-1.0447, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243975162506104
Epoch 0, Step 1000: train/loss = 0.5201714038848877, train/raw-loss = 0.44526901841163635, train/logprobs = tensor([[-0.8805, -2.1522],
        [-1.5326, -0.8101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980480074882507
Epoch 0, Step 1001: train/loss = 0.4408367872238159, train/raw-loss = 0.3741830885410309, train/logprobs = tensor([[-0.6066, -3.0455],
        [-1.2062, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333073377609253
Epoch 0, Step 1002: train/loss = 0.4738781452178955, train/raw-loss = 0.39716246724128723, train/logprobs = tensor([[-0.4880, -4.1208],
        [-1.3015, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15343134105205536
Epoch 0, Step 1003: train/loss = 0.45441654324531555, train/raw-loss = 0.38221320509910583, train/logprobs = tensor([[-1.1178, -3.7130],
        [-1.2462, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14440670609474182
Epoch 0, Step 1004: train/loss = 0.6520273089408875, train/raw-loss = 0.5961707830429077, train/logprobs = tensor([[-0.5947, -0.8985],
        [-0.7264, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171300709247589
Epoch 0, Step 1005: train/loss = 0.25893232226371765, train/raw-loss = 0.1934320032596588, train/logprobs = tensor([[-0.7246, -6.7903],
        [-1.4386, -1.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310005784034729
Epoch 0, Step 1006: train/loss = 0.5906839966773987, train/raw-loss = 0.5357011556625366, train/logprobs = tensor([[-0.6937, -1.2695],
        [-1.0205, -0.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10996568948030472
Epoch 0, Step 1007: train/loss = 0.5783094167709351, train/raw-loss = 0.5230735540390015, train/logprobs = tensor([[-1.3522, -1.8153],
        [-1.5060, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11047166585922241
Epoch 0, Step 1008: train/loss = 0.4816805422306061, train/raw-loss = 0.419411301612854, train/logprobs = tensor([[-0.5357, -3.6275],
        [-0.9552, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12453845143318176
Epoch 0, Step 1009: train/loss = 0.4866713285446167, train/raw-loss = 0.42582640051841736, train/logprobs = tensor([[-0.6655, -4.7661],
        [-1.3218, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168990075588226
Epoch 0, Step 1010: train/loss = 0.5131944417953491, train/raw-loss = 0.4491947293281555, train/logprobs = tensor([[-0.8248, -3.4623],
        [-0.8750, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12799955904483795
Epoch 0, Step 1011: train/loss = 0.5861947536468506, train/raw-loss = 0.524125337600708, train/logprobs = tensor([[-0.5161, -1.5510],
        [-1.0306, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12413875758647919
Epoch 0, Step 1012: train/loss = 0.3260542154312134, train/raw-loss = 0.26312512159347534, train/logprobs = tensor([[-0.6170, -4.0391],
        [-1.4243, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12585818767547607
Epoch 0, Step 1013: train/loss = 0.25417569279670715, train/raw-loss = 0.16959109902381897, train/logprobs = tensor([[-0.8528, -6.3600],
        [-2.2671, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691691279411316
Epoch 0, Step 1014: train/loss = 0.4597046673297882, train/raw-loss = 0.394189715385437, train/logprobs = tensor([[-0.7696, -3.2223],
        [-1.1885, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310299187898636
Epoch 0, Step 1015: train/loss = 0.3282929062843323, train/raw-loss = 0.26111432909965515, train/logprobs = tensor([[-0.4891, -4.0529],
        [-1.4603, -0.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13435715436935425
Epoch 0, Step 1016: train/loss = 0.4796483516693115, train/raw-loss = 0.4149521291255951, train/logprobs = tensor([[-0.8389, -4.9195],
        [-1.1814, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12939238548278809
Epoch 0, Step 1017: train/loss = 0.3952266573905945, train/raw-loss = 0.3316623866558075, train/logprobs = tensor([[-0.5675, -5.7777],
        [-0.8952, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12712854146957397
Epoch 0, Step 1018: train/loss = 0.5071083903312683, train/raw-loss = 0.4444028437137604, train/logprobs = tensor([[-0.7495, -3.1229],
        [-1.0379, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12541112303733826
Epoch 0, Step 1019: train/loss = 0.43057355284690857, train/raw-loss = 0.3600865602493286, train/logprobs = tensor([[-0.9780, -4.3829],
        [-1.4192, -1.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14097397029399872
Epoch 0, Step 1020: train/loss = 0.462525874376297, train/raw-loss = 0.40417444705963135, train/logprobs = tensor([[-0.7245, -5.3768],
        [-0.8254, -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11670289933681488
Epoch 0, Step 1021: train/loss = 0.3743891417980194, train/raw-loss = 0.31066665053367615, train/logprobs = tensor([[-0.5515, -4.5440],
        [-1.0980, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12744498252868652
Epoch 0, Step 1022: train/loss = 0.5265564918518066, train/raw-loss = 0.4803667366504669, train/logprobs = tensor([[-0.4780, -1.3109],
        [-0.8947, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09237957745790482
Epoch 0, Step 1023: train/loss = 0.5872967839241028, train/raw-loss = 0.5285919904708862, train/logprobs = tensor([[-0.4999, -1.8623],
        [-1.0632, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11740951985120773
Epoch 0, Step 1024: train/loss = 0.4466254711151123, train/raw-loss = 0.3825364112854004, train/logprobs = tensor([[-0.8309, -3.9504],
        [-1.0259, -0.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12817808985710144
Epoch 0, Step 1025: train/loss = 0.4103167653083801, train/raw-loss = 0.35373371839523315, train/logprobs = tensor([[-0.7191, -3.4663],
        [-1.0997, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316617578268051
Epoch 0, Step 1026: train/loss = 0.3958283066749573, train/raw-loss = 0.32200056314468384, train/logprobs = tensor([[-0.6715, -3.5509],
        [-1.1646, -0.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14765548706054688
Epoch 0, Step 1027: train/loss = 0.6793831586837769, train/raw-loss = 0.6312230825424194, train/logprobs = tensor([[-0.5377, -0.8888],
        [-0.6979, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632015228271484
Epoch 0, Step 1028: train/loss = 0.3962250351905823, train/raw-loss = 0.34698110818862915, train/logprobs = tensor([[-0.7605, -4.4296],
        [-1.5975, -1.6138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09848778694868088
Epoch 0, Step 1029: train/loss = 0.5811353921890259, train/raw-loss = 0.5227484703063965, train/logprobs = tensor([[-0.3867, -1.9798],
        [-0.7119, -0.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677393317222595
Epoch 0, Step 1030: train/loss = 0.38129550218582153, train/raw-loss = 0.3121912479400635, train/logprobs = tensor([[-0.6560, -5.2934],
        [-1.6137, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1382085382938385
Epoch 0, Step 1031: train/loss = 0.48942244052886963, train/raw-loss = 0.43000832200050354, train/logprobs = tensor([[-0.6103, -2.1017],
        [-0.9775, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11882822215557098
Epoch 0, Step 1032: train/loss = 0.5021175742149353, train/raw-loss = 0.44492077827453613, train/logprobs = tensor([[-0.6787, -2.0378],
        [-1.3481, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11439359188079834
Epoch 0, Step 1033: train/loss = 0.3521032929420471, train/raw-loss = 0.2739676833152771, train/logprobs = tensor([[-0.9474, -4.5148],
        [-2.0213, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15627123415470123
Epoch 0, Step 1034: train/loss = 0.4216821789741516, train/raw-loss = 0.3645278215408325, train/logprobs = tensor([[-0.6909, -2.3131],
        [-1.2257, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11430878192186356
Epoch 0, Step 1035: train/loss = 0.5257492065429688, train/raw-loss = 0.45238378643989563, train/logprobs = tensor([[-0.7577, -2.4673],
        [-1.3841, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14673075079917908
Epoch 0, Step 1036: train/loss = 0.5562432408332825, train/raw-loss = 0.496268093585968, train/logprobs = tensor([[-0.5172, -2.0696],
        [-0.9521, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11995034664869308
Epoch 0, Step 1037: train/loss = 0.5415167212486267, train/raw-loss = 0.48137974739074707, train/logprobs = tensor([[-0.5908, -2.8594],
        [-1.1911, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1202739030122757
Epoch 0, Step 1038: train/loss = 0.4219391942024231, train/raw-loss = 0.3506105840206146, train/logprobs = tensor([[-0.8588, -4.4283],
        [-1.2995, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14265719056129456
Epoch 0, Step 1039: train/loss = 0.3491583466529846, train/raw-loss = 0.282793790102005, train/logprobs = tensor([[-0.6889, -7.4116],
        [-1.4151, -2.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13272908329963684
Epoch 0, Step 1040: train/loss = 0.5030180811882019, train/raw-loss = 0.44953668117523193, train/logprobs = tensor([[-1.3045, -3.4626],
        [-1.5145, -1.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1069629043340683
Epoch 0, Step 1041: train/loss = 0.3630061149597168, train/raw-loss = 0.2901504337787628, train/logprobs = tensor([[-0.7830, -5.9942],
        [-1.2953, -1.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14571134746074677
Epoch 0, Step 1042: train/loss = 0.5168450474739075, train/raw-loss = 0.47047650814056396, train/logprobs = tensor([[-0.6840, -2.4947],
        [-0.7099, -0.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09273717552423477
Epoch 0, Step 1043: train/loss = 0.6919453740119934, train/raw-loss = 0.6362152099609375, train/logprobs = tensor([[-1.0794, -1.4176],
        [-0.9103, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114603728055954
Epoch 0, Step 1044: train/loss = 0.5620752573013306, train/raw-loss = 0.5007331967353821, train/logprobs = tensor([[-0.8943, -1.4618],
        [-1.5654, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12268415838479996
Epoch 0, Step 1045: train/loss = 0.457854688167572, train/raw-loss = 0.4033677875995636, train/logprobs = tensor([[-0.5781, -3.3202],
        [-0.9865, -0.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10897380113601685
Epoch 0, Step 1046: train/loss = 0.4425256848335266, train/raw-loss = 0.3789195418357849, train/logprobs = tensor([[-0.5346, -3.4439],
        [-0.9773, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272123008966446
Epoch 0, Step 1047: train/loss = 0.5387721657752991, train/raw-loss = 0.47577881813049316, train/logprobs = tensor([[-0.6142, -1.4474],
        [-1.0000, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12598665058612823
Epoch 0, Step 1048: train/loss = 0.2586812376976013, train/raw-loss = 0.1949346661567688, train/logprobs = tensor([[-0.6090, -7.5433],
        [-1.3252, -1.2846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12749315798282623
Epoch 0, Step 1049: train/loss = 0.3777020573616028, train/raw-loss = 0.30469799041748047, train/logprobs = tensor([[-0.7595, -3.1530],
        [-1.5567, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14600813388824463
Epoch 0, Step 1050: train/loss = 0.5434737801551819, train/raw-loss = 0.4881589114665985, train/logprobs = tensor([[-0.5058, -1.1021],
        [-1.0245, -0.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062975227832794
Epoch 0, Step 1051: train/loss = 0.6248098015785217, train/raw-loss = 0.5822045207023621, train/logprobs = tensor([[-0.5694, -1.1851],
        [-0.6584, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08521059155464172
Epoch 0, Step 1052: train/loss = 0.3936017155647278, train/raw-loss = 0.337978720664978, train/logprobs = tensor([[-0.5524, -3.1724],
        [-0.9374, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1112460047006607
Epoch 0, Step 1053: train/loss = 0.3299283981323242, train/raw-loss = 0.2721458077430725, train/logprobs = tensor([[-0.5667, -4.1317],
        [-1.3141, -0.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11556518077850342
Epoch 0, Step 1054: train/loss = 0.5137481689453125, train/raw-loss = 0.46111956238746643, train/logprobs = tensor([[-0.8848, -1.9752],
        [-1.1512, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052573025226593
Epoch 0, Step 1055: train/loss = 0.5117672681808472, train/raw-loss = 0.4474300146102905, train/logprobs = tensor([[-0.8683, -3.4002],
        [-1.4198, -1.6754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286744475364685
Epoch 0, Step 1056: train/loss = 0.45979389548301697, train/raw-loss = 0.40486666560173035, train/logprobs = tensor([[-0.6576, -3.3961],
        [-0.8494, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10985448956489563
Epoch 0, Step 1057: train/loss = 0.38690653443336487, train/raw-loss = 0.33176758885383606, train/logprobs = tensor([[-0.5261, -5.3409],
        [-1.2357, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11027789115905762
Epoch 0, Step 1058: train/loss = 0.37970349192619324, train/raw-loss = 0.31063708662986755, train/logprobs = tensor([[-0.5631, -3.1163],
        [-1.3058, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13813284039497375
Epoch 0, Step 1059: train/loss = 0.613690972328186, train/raw-loss = 0.5499262809753418, train/logprobs = tensor([[-0.5542, -1.3727],
        [-0.8362, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12752936780452728
Epoch 0, Step 1060: train/loss = 0.5887671709060669, train/raw-loss = 0.5296757221221924, train/logprobs = tensor([[-0.6376, -1.7628],
        [-1.1171, -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11818293482065201
Epoch 0, Step 1061: train/loss = 0.5023555159568787, train/raw-loss = 0.43583032488822937, train/logprobs = tensor([[-0.6745, -4.0131],
        [-1.1922, -1.1825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1330503523349762
Epoch 0, Step 1062: train/loss = 0.4958648681640625, train/raw-loss = 0.42434602975845337, train/logprobs = tensor([[-0.7350, -2.5630],
        [-1.3875, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14303769171237946
Epoch 0, Step 1063: train/loss = 0.5839188694953918, train/raw-loss = 0.5312885046005249, train/logprobs = tensor([[-0.9990, -2.1331],
        [-0.8448, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052607074379921
Epoch 0, Step 1064: train/loss = 0.42245784401893616, train/raw-loss = 0.35678306221961975, train/logprobs = tensor([[-0.6373, -4.8059],
        [-1.1086, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313495635986328
Epoch 0, Step 1065: train/loss = 0.529963493347168, train/raw-loss = 0.4710310697555542, train/logprobs = tensor([[-0.5890, -1.9887],
        [-1.0057, -0.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11786478757858276
Epoch 0, Step 1066: train/loss = 0.4576544761657715, train/raw-loss = 0.4031108021736145, train/logprobs = tensor([[-1.3873, -3.7015],
        [-1.4383, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.109087273478508
Epoch 0, Step 1067: train/loss = 0.23194140195846558, train/raw-loss = 0.1661321520805359, train/logprobs = tensor([[-0.8266, -7.5504],
        [-1.8627, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13161849975585938
Epoch 0, Step 1068: train/loss = 0.43486863374710083, train/raw-loss = 0.3750329613685608, train/logprobs = tensor([[-0.5226, -2.6856],
        [-1.0727, -0.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11967133730649948
Epoch 0, Step 1069: train/loss = 0.5826119184494019, train/raw-loss = 0.5248616337776184, train/logprobs = tensor([[-1.0294, -4.9123],
        [-1.0014, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11550060659646988
Epoch 0, Step 1070: train/loss = 0.37983810901641846, train/raw-loss = 0.3086772561073303, train/logprobs = tensor([[-0.6432, -3.9975],
        [-1.2054, -1.1831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423216611146927
Epoch 0, Step 1071: train/loss = 0.25352275371551514, train/raw-loss = 0.18535341322422028, train/logprobs = tensor([[-0.6482, -5.7092],
        [-1.5974, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13633868098258972
Epoch 0, Step 1072: train/loss = 0.2654446065425873, train/raw-loss = 0.20060360431671143, train/logprobs = tensor([[-0.5891, -6.3165],
        [-1.2995, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12968198955059052
Epoch 0, Step 1073: train/loss = 0.436233252286911, train/raw-loss = 0.36952370405197144, train/logprobs = tensor([[-0.6897, -3.7342],
        [-1.2461, -1.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13341909646987915
Epoch 0, Step 1074: train/loss = 0.44637531042099, train/raw-loss = 0.38516563177108765, train/logprobs = tensor([[-0.5034, -4.6126],
        [-0.9923, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241929769515991
Epoch 0, Step 1075: train/loss = 0.4608314037322998, train/raw-loss = 0.4081203043460846, train/logprobs = tensor([[-0.4803, -3.0623],
        [-0.7190, -0.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1054222583770752
Epoch 0, Step 1076: train/loss = 0.43305137753486633, train/raw-loss = 0.3569220304489136, train/logprobs = tensor([[-0.5142, -3.4267],
        [-1.1906, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15225869417190552
Epoch 0, Step 1077: train/loss = 0.42958617210388184, train/raw-loss = 0.36884650588035583, train/logprobs = tensor([[-0.4549, -3.3197],
        [-1.1005, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147939950227737
Epoch 0, Step 1078: train/loss = 0.5156286954879761, train/raw-loss = 0.4595278203487396, train/logprobs = tensor([[-0.8253, -2.3296],
        [-1.2002, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1122017651796341
Epoch 0, Step 1079: train/loss = 0.32879865169525146, train/raw-loss = 0.2573755383491516, train/logprobs = tensor([[-0.5215, -6.3499],
        [-1.1051, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1428462415933609
Epoch 0, Step 1080: train/loss = 0.5298930406570435, train/raw-loss = 0.47021085023880005, train/logprobs = tensor([[-0.6313, -2.4532],
        [-1.1231, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11936446279287338
Epoch 0, Step 1081: train/loss = 0.31768107414245605, train/raw-loss = 0.25697043538093567, train/logprobs = tensor([[-1.1371, -4.6802],
        [-1.3947, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121421217918396
Epoch 0, Step 1082: train/loss = 0.6448084115982056, train/raw-loss = 0.5886679887771606, train/logprobs = tensor([[-0.6846, -1.0915],
        [-1.0870, -1.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11228082329034805
Epoch 0, Step 1083: train/loss = 0.5450102090835571, train/raw-loss = 0.47104889154434204, train/logprobs = tensor([[-0.8418, -2.6567],
        [-1.3107, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14792269468307495
Epoch 0, Step 1084: train/loss = 0.4925195574760437, train/raw-loss = 0.4323060214519501, train/logprobs = tensor([[-0.4822, -2.7676],
        [-0.9221, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12042714655399323
Epoch 0, Step 1085: train/loss = 0.5338851809501648, train/raw-loss = 0.4818188548088074, train/logprobs = tensor([[-0.6075, -2.1429],
        [-0.9926, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10413266718387604
Epoch 0, Step 1086: train/loss = 0.41818559169769287, train/raw-loss = 0.3527633249759674, train/logprobs = tensor([[-0.6474, -4.8770],
        [-1.1960, -1.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308445781469345
Epoch 0, Step 1087: train/loss = 0.38968873023986816, train/raw-loss = 0.3389938473701477, train/logprobs = tensor([[-0.5598, -4.7842],
        [-0.7469, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013898029923439
Epoch 0, Step 1088: train/loss = 0.5158719420433044, train/raw-loss = 0.45468759536743164, train/logprobs = tensor([[-0.9669, -2.3321],
        [-1.2309, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122368723154068
Epoch 0, Step 1089: train/loss = 0.5245727896690369, train/raw-loss = 0.47523266077041626, train/logprobs = tensor([[-0.6699, -2.1549],
        [-0.8218, -0.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868032485246658
Epoch 0, Step 1090: train/loss = 0.3688351809978485, train/raw-loss = 0.3086218237876892, train/logprobs = tensor([[-0.5051, -3.3340],
        [-1.3580, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.120426706969738
Epoch 0, Step 1091: train/loss = 0.375235915184021, train/raw-loss = 0.32096993923187256, train/logprobs = tensor([[-0.5148, -3.0760],
        [-1.1605, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10853201150894165
Epoch 0, Step 1092: train/loss = 0.42393121123313904, train/raw-loss = 0.3610779047012329, train/logprobs = tensor([[-0.7327, -2.6892],
        [-1.1540, -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12570667266845703
Epoch 0, Step 1093: train/loss = 0.4983504116535187, train/raw-loss = 0.4287804663181305, train/logprobs = tensor([[-0.6881, -3.3774],
        [-1.3651, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13913989067077637
Epoch 0, Step 1094: train/loss = 0.43180856108665466, train/raw-loss = 0.3749511241912842, train/logprobs = tensor([[-0.5404, -1.9803],
        [-1.0056, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11371485888957977
Epoch 0, Step 1095: train/loss = 0.5686022043228149, train/raw-loss = 0.5021180510520935, train/logprobs = tensor([[-0.9007, -2.5620],
        [-1.0577, -0.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13296832144260406
Epoch 0, Step 1096: train/loss = 0.38873282074928284, train/raw-loss = 0.32598698139190674, train/logprobs = tensor([[-0.6849, -4.2160],
        [-1.0876, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12549163401126862
Epoch 0, Step 1097: train/loss = 0.3586430251598358, train/raw-loss = 0.2895100712776184, train/logprobs = tensor([[-0.8174, -4.0447],
        [-1.2615, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13826590776443481
Epoch 0, Step 1098: train/loss = 0.38526248931884766, train/raw-loss = 0.3256196677684784, train/logprobs = tensor([[-0.4107, -5.9869],
        [-1.1167, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192857027053833
Epoch 0, Step 1099: train/loss = 0.5141030550003052, train/raw-loss = 0.4461776316165924, train/logprobs = tensor([[-0.5601, -1.3554],
        [-1.3352, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13585081696510315
Epoch 0, Step 1100: train/loss = 0.4260355532169342, train/raw-loss = 0.367601215839386, train/logprobs = tensor([[-0.5850, -3.0381],
        [-1.0725, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1168687492609024
Epoch 0, Step 1101: train/loss = 0.3441788852214813, train/raw-loss = 0.2869839072227478, train/logprobs = tensor([[-0.5966, -5.9517],
        [-1.5058, -1.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11438996344804764
Epoch 0, Step 1102: train/loss = 0.42105454206466675, train/raw-loss = 0.36805230379104614, train/logprobs = tensor([[-0.9721, -4.3172],
        [-1.0029, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10600443929433823
Epoch 0, Step 1103: train/loss = 0.3354228436946869, train/raw-loss = 0.27672815322875977, train/logprobs = tensor([[-0.8229, -4.9874],
        [-1.3385, -0.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11738939583301544
Epoch 0, Step 1104: train/loss = 0.607048749923706, train/raw-loss = 0.5508698225021362, train/logprobs = tensor([[-0.8002, -4.1648],
        [-0.9427, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235789954662323
Epoch 0, Step 1105: train/loss = 0.4375694692134857, train/raw-loss = 0.3845325708389282, train/logprobs = tensor([[-0.7839, -3.7638],
        [-0.7723, -0.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607384890317917
Epoch 0, Step 1106: train/loss = 0.4032093286514282, train/raw-loss = 0.33403682708740234, train/logprobs = tensor([[-1.0364, -5.2676],
        [-1.2658, -1.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13834494352340698
Epoch 0, Step 1107: train/loss = 0.41176021099090576, train/raw-loss = 0.35575586557388306, train/logprobs = tensor([[-0.6024, -3.6177],
        [-0.9485, -0.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11200868338346481
Epoch 0, Step 1108: train/loss = 0.4422224760055542, train/raw-loss = 0.3919452428817749, train/logprobs = tensor([[-0.5252, -2.6800],
        [-0.9555, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055457055568695
Epoch 0, Step 1109: train/loss = 0.46942973136901855, train/raw-loss = 0.41124555468559265, train/logprobs = tensor([[-0.5951, -2.5039],
        [-1.0466, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11636830866336823
Epoch 0, Step 1110: train/loss = 0.538360595703125, train/raw-loss = 0.48656731843948364, train/logprobs = tensor([[-0.5736, -3.6562],
        [-0.7231, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035865843296051
Epoch 0, Step 1111: train/loss = 0.4147428870201111, train/raw-loss = 0.35719501972198486, train/logprobs = tensor([[-0.6250, -4.3324],
        [-0.8269, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11509570479393005
Epoch 0, Step 1112: train/loss = 0.5832686424255371, train/raw-loss = 0.5186927914619446, train/logprobs = tensor([[-1.3442, -4.4954],
        [-1.2581, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12915171682834625
Epoch 0, Step 1113: train/loss = 0.5761435031890869, train/raw-loss = 0.516846776008606, train/logprobs = tensor([[-0.6300, -1.6203],
        [-0.9307, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11859352886676788
Epoch 0, Step 1114: train/loss = 0.43720006942749023, train/raw-loss = 0.3831291198730469, train/logprobs = tensor([[-0.7111, -2.2656],
        [-1.1231, -0.5232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10814186930656433
Epoch 0, Step 1115: train/loss = 0.5385125279426575, train/raw-loss = 0.4780835807323456, train/logprobs = tensor([[-0.3973, -1.6275],
        [-0.7108, -0.5749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085787951946259
Epoch 0, Step 1116: train/loss = 0.5158816576004028, train/raw-loss = 0.460931658744812, train/logprobs = tensor([[-0.5568, -2.1736],
        [-0.8007, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10990000516176224
Epoch 0, Step 1117: train/loss = 0.5777435898780823, train/raw-loss = 0.5094027519226074, train/logprobs = tensor([[-0.5972, -2.1707],
        [-1.3948, -1.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13668155670166016
Epoch 0, Step 1118: train/loss = 0.6007794141769409, train/raw-loss = 0.552824854850769, train/logprobs = tensor([[-0.3272, -1.9616],
        [-0.4968, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590908885002136
Epoch 0, Step 1119: train/loss = 0.42766648530960083, train/raw-loss = 0.3659455478191376, train/logprobs = tensor([[-0.4784, -4.0612],
        [-1.0281, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1234419196844101
Epoch 0, Step 1120: train/loss = 0.2896999716758728, train/raw-loss = 0.21801495552062988, train/logprobs = tensor([[-0.8276, -3.6080],
        [-1.6915, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14337003231048584
Epoch 0, Step 1121: train/loss = 0.38667455315589905, train/raw-loss = 0.31663239002227783, train/logprobs = tensor([[-0.6552, -3.0778],
        [-1.7227, -0.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14008428156375885
Epoch 0, Step 1122: train/loss = 0.5847910642623901, train/raw-loss = 0.5249872803688049, train/logprobs = tensor([[-0.4925, -3.3529],
        [-0.9571, -0.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11960761249065399
Epoch 0, Step 1123: train/loss = 0.29439929127693176, train/raw-loss = 0.231613889336586, train/logprobs = tensor([[-0.5710, -6.5270],
        [-1.4074, -1.4382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12557080388069153
Epoch 0, Step 1124: train/loss = 0.4069579839706421, train/raw-loss = 0.34956055879592896, train/logprobs = tensor([[-0.8359, -6.1127],
        [-1.3151, -1.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11479485034942627
Epoch 0, Step 1125: train/loss = 0.41225385665893555, train/raw-loss = 0.35368260741233826, train/logprobs = tensor([[-0.5553, -2.4818],
        [-1.0079, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11714255809783936
Epoch 0, Step 1126: train/loss = 0.5217940807342529, train/raw-loss = 0.4594232141971588, train/logprobs = tensor([[-0.8598, -4.6686],
        [-1.0839, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12474174052476883
Epoch 0, Step 1127: train/loss = 0.4327196776866913, train/raw-loss = 0.37555602192878723, train/logprobs = tensor([[-0.3876, -3.0231],
        [-0.6149, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11432735621929169
Epoch 0, Step 1128: train/loss = 0.6196271181106567, train/raw-loss = 0.5569060444831848, train/logprobs = tensor([[-1.3643, -2.0280],
        [-1.0694, -0.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12544216215610504
Epoch 0, Step 1129: train/loss = 0.3297607898712158, train/raw-loss = 0.26113858819007874, train/logprobs = tensor([[-0.6416, -3.1549],
        [-1.4163, -0.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13724440336227417
Epoch 0, Step 1130: train/loss = 0.5298283696174622, train/raw-loss = 0.4854929447174072, train/logprobs = tensor([[-0.3354, -1.6035],
        [-0.7726, -0.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08867084234952927
Epoch 0, Step 1131: train/loss = 0.42058712244033813, train/raw-loss = 0.37170976400375366, train/logprobs = tensor([[-0.4441, -3.0510],
        [-0.7518, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09775467962026596
Epoch 0, Step 1132: train/loss = 0.5837641954421997, train/raw-loss = 0.5194671750068665, train/logprobs = tensor([[-0.7891, -2.8606],
        [-0.7344, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12859398126602173
Epoch 0, Step 1133: train/loss = 0.6521685123443604, train/raw-loss = 0.59674072265625, train/logprobs = tensor([[-0.6457, -0.8633],
        [-0.8023, -0.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085560917854309
Epoch 0, Step 1134: train/loss = 0.4286381006240845, train/raw-loss = 0.3662748336791992, train/logprobs = tensor([[-1.1212, -5.8676],
        [-1.3353, -1.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1247265636920929
Epoch 0, Step 1135: train/loss = 0.38477885723114014, train/raw-loss = 0.3241667151451111, train/logprobs = tensor([[-0.5174, -3.6267],
        [-0.9721, -0.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12122433632612228
Epoch 0, Step 1136: train/loss = 0.4151138365268707, train/raw-loss = 0.35351669788360596, train/logprobs = tensor([[-0.7279, -4.5710],
        [-1.3161, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12319426238536835
Epoch 0, Step 1137: train/loss = 0.3910842835903168, train/raw-loss = 0.33202841877937317, train/logprobs = tensor([[-0.7565, -6.1624],
        [-1.1577, -1.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181117594242096
Epoch 0, Step 1138: train/loss = 0.547394871711731, train/raw-loss = 0.4945908784866333, train/logprobs = tensor([[-0.5589, -1.7065],
        [-0.7807, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10560788214206696
Epoch 0, Step 1139: train/loss = 0.40880391001701355, train/raw-loss = 0.32763245701789856, train/logprobs = tensor([[-0.5529, -2.6284],
        [-1.4812, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623428612947464
Epoch 0, Step 1140: train/loss = 0.419232577085495, train/raw-loss = 0.3612603545188904, train/logprobs = tensor([[-0.5511, -5.3279],
        [-1.0790, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11594447493553162
Epoch 0, Step 1141: train/loss = 0.4320485293865204, train/raw-loss = 0.3772891163825989, train/logprobs = tensor([[-0.5581, -3.6243],
        [-0.9392, -1.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951884090900421
Epoch 0, Step 1142: train/loss = 0.578316867351532, train/raw-loss = 0.5246405005455017, train/logprobs = tensor([[-0.6804, -1.8545],
        [-1.3992, -1.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10735265165567398
Epoch 0, Step 1143: train/loss = 0.5474217534065247, train/raw-loss = 0.4821496903896332, train/logprobs = tensor([[-0.5837, -1.7461],
        [-0.9767, -0.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13054408133029938
Epoch 0, Step 1144: train/loss = 0.4709809422492981, train/raw-loss = 0.4184892177581787, train/logprobs = tensor([[-0.4767, -3.2015],
        [-0.5737, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10498343408107758
Epoch 0, Step 1145: train/loss = 0.32366231083869934, train/raw-loss = 0.27060046792030334, train/logprobs = tensor([[-0.4426, -5.6967],
        [-0.6853, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10612372308969498
Epoch 0, Step 1146: train/loss = 0.2646368443965912, train/raw-loss = 0.18608281016349792, train/logprobs = tensor([[-0.6372, -9.2476],
        [-1.2592, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1571081131696701
Epoch 0, Step 1147: train/loss = 0.3497464060783386, train/raw-loss = 0.2754829525947571, train/logprobs = tensor([[-0.8587, -3.8614],
        [-1.4859, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14852695167064667
Epoch 0, Step 1148: train/loss = 0.54625403881073, train/raw-loss = 0.4866637587547302, train/logprobs = tensor([[-0.6585, -1.4807],
        [-1.1628, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11918048560619354
Epoch 0, Step 1149: train/loss = 0.3796956539154053, train/raw-loss = 0.31636080145835876, train/logprobs = tensor([[-0.7055, -4.4023],
        [-1.4212, -0.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266697645187378
Epoch 0, Step 1150: train/loss = 0.5424892902374268, train/raw-loss = 0.48543113470077515, train/logprobs = tensor([[-0.8601, -3.6757],
        [-0.6271, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1141163632273674
Epoch 0, Step 1151: train/loss = 0.35929906368255615, train/raw-loss = 0.29140618443489075, train/logprobs = tensor([[-0.8504, -6.8351],
        [-1.5319, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357857584953308
Epoch 0, Step 1152: train/loss = 0.22806799411773682, train/raw-loss = 0.15282130241394043, train/logprobs = tensor([[-0.6469, -6.5322],
        [-1.6542, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15049336850643158
Epoch 0, Step 1153: train/loss = 0.4797729253768921, train/raw-loss = 0.4217357635498047, train/logprobs = tensor([[-0.4151, -1.9156],
        [-0.8085, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160743236541748
Epoch 0, Step 1154: train/loss = 0.4213721752166748, train/raw-loss = 0.3599882423877716, train/logprobs = tensor([[-0.6857, -3.0069],
        [-1.2458, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12276782840490341
Epoch 0, Step 1155: train/loss = 0.407312273979187, train/raw-loss = 0.3572463393211365, train/logprobs = tensor([[-0.5300, -2.8752],
        [-1.0956, -1.2686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10013182461261749
Epoch 0, Step 1156: train/loss = 0.5205056667327881, train/raw-loss = 0.46115416288375854, train/logprobs = tensor([[-0.5746, -1.6910],
        [-1.1331, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11870301514863968
Epoch 0, Step 1157: train/loss = 0.43148401379585266, train/raw-loss = 0.36827853322029114, train/logprobs = tensor([[-0.8045, -5.7221],
        [-1.0023, -1.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12641102075576782
Epoch 0, Step 1158: train/loss = 0.2910044491291046, train/raw-loss = 0.22414234280586243, train/logprobs = tensor([[-0.6843, -5.1833],
        [-1.2755, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13372421264648438
Epoch 0, Step 1159: train/loss = 0.38950616121292114, train/raw-loss = 0.32988443970680237, train/logprobs = tensor([[-0.5087, -3.3442],
        [-0.7518, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11924338340759277
Epoch 0, Step 1160: train/loss = 0.5649205446243286, train/raw-loss = 0.5145609974861145, train/logprobs = tensor([[-0.6224, -2.7707],
        [-0.8917, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10071908682584763
Epoch 0, Step 1161: train/loss = 0.5092360973358154, train/raw-loss = 0.4386340081691742, train/logprobs = tensor([[-0.6383, -1.9412],
        [-0.9857, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120420813560486
Epoch 0, Step 1162: train/loss = 0.40225616097450256, train/raw-loss = 0.3380963206291199, train/logprobs = tensor([[-0.7502, -4.9651],
        [-1.3849, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12831969559192657
Epoch 0, Step 1163: train/loss = 0.3312050700187683, train/raw-loss = 0.2641223073005676, train/logprobs = tensor([[-0.6054, -5.6181],
        [-1.0526, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13416552543640137
Epoch 0, Step 1164: train/loss = 0.41595250368118286, train/raw-loss = 0.3504906892776489, train/logprobs = tensor([[-0.5567, -6.3286],
        [-1.0403, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13092367351055145
Epoch 0, Step 1165: train/loss = 0.41592130064964294, train/raw-loss = 0.36071115732192993, train/logprobs = tensor([[-0.6806, -3.9812],
        [-1.0548, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11042021960020065
Epoch 0, Step 1166: train/loss = 0.36574074625968933, train/raw-loss = 0.2945926785469055, train/logprobs = tensor([[-0.6125, -2.9536],
        [-1.5780, -0.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422961950302124
Epoch 0, Step 1167: train/loss = 0.4907075762748718, train/raw-loss = 0.4293789565563202, train/logprobs = tensor([[-0.5118, -4.0814],
        [-1.0037, -1.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12265720963478088
Epoch 0, Step 1168: train/loss = 0.5289211869239807, train/raw-loss = 0.4720190763473511, train/logprobs = tensor([[-0.7816, -2.7496],
        [-1.1266, -1.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11380426585674286
Epoch 0, Step 1169: train/loss = 0.6794378757476807, train/raw-loss = 0.6129202842712402, train/logprobs = tensor([[-1.8978, -4.7886],
        [-1.1833, -1.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1330353170633316
Epoch 0, Step 1170: train/loss = 0.3372122645378113, train/raw-loss = 0.2818938195705414, train/logprobs = tensor([[-0.5748, -5.0544],
        [-1.0422, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11063686013221741
Epoch 0, Step 1171: train/loss = 0.5860255360603333, train/raw-loss = 0.5286729335784912, train/logprobs = tensor([[-0.7585, -2.5149],
        [-1.1231, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11470529437065125
Epoch 0, Step 1172: train/loss = 0.3186173439025879, train/raw-loss = 0.2603529095649719, train/logprobs = tensor([[-0.5873, -6.6164],
        [-1.0660, -1.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11652885377407074
Epoch 0, Step 1173: train/loss = 0.3014119565486908, train/raw-loss = 0.23915919661521912, train/logprobs = tensor([[-0.7471, -5.2814],
        [-1.2006, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450551986694336
Epoch 0, Step 1174: train/loss = 0.5456098914146423, train/raw-loss = 0.4994830787181854, train/logprobs = tensor([[-0.5706, -1.8753],
        [-1.0320, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09225363284349442
Epoch 0, Step 1175: train/loss = 0.39330020546913147, train/raw-loss = 0.32857275009155273, train/logprobs = tensor([[-0.8199, -4.5425],
        [-1.1812, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294548511505127
Epoch 0, Step 1176: train/loss = 0.620667040348053, train/raw-loss = 0.5752667188644409, train/logprobs = tensor([[-0.6409, -1.7904],
        [-1.0422, -1.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09080072492361069
Epoch 0, Step 1177: train/loss = 0.5163706541061401, train/raw-loss = 0.455075204372406, train/logprobs = tensor([[-0.5988, -3.0425],
        [-1.0037, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12259083241224289
Epoch 0, Step 1178: train/loss = 0.6492115259170532, train/raw-loss = 0.5943256616592407, train/logprobs = tensor([[-1.6039, -3.0913],
        [-0.9143, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977159440517426
Epoch 0, Step 1179: train/loss = 0.5658059120178223, train/raw-loss = 0.5018285512924194, train/logprobs = tensor([[-1.0377, -1.7351],
        [-1.1464, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12795472145080566
Epoch 0, Step 1180: train/loss = 0.6133615374565125, train/raw-loss = 0.5584204792976379, train/logprobs = tensor([[-0.6274, -0.9275],
        [-1.1926, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10988219082355499
Epoch 0, Step 1181: train/loss = 0.35772883892059326, train/raw-loss = 0.3066968619823456, train/logprobs = tensor([[-0.8975, -4.2134],
        [-1.0998, -1.1282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10206397622823715
Epoch 0, Step 1182: train/loss = 0.5825557112693787, train/raw-loss = 0.5182279348373413, train/logprobs = tensor([[-0.8497, -4.2684],
        [-1.2783, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286555379629135
Epoch 0, Step 1183: train/loss = 0.5997580885887146, train/raw-loss = 0.5528627038002014, train/logprobs = tensor([[-0.5635, -1.8389],
        [-0.6491, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09379080682992935
Epoch 0, Step 1184: train/loss = 0.5739257335662842, train/raw-loss = 0.5097641944885254, train/logprobs = tensor([[-0.7554, -2.3798],
        [-1.0717, -0.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12832313776016235
Epoch 0, Step 1185: train/loss = 0.43458259105682373, train/raw-loss = 0.37717729806900024, train/logprobs = tensor([[-0.5837, -3.3453],
        [-1.3737, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11481055617332458
Epoch 0, Step 1186: train/loss = 0.5469590425491333, train/raw-loss = 0.4941870868206024, train/logprobs = tensor([[-0.5589, -3.4919],
        [-0.8042, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554389655590057
Epoch 0, Step 1187: train/loss = 0.37032634019851685, train/raw-loss = 0.30577993392944336, train/logprobs = tensor([[-0.9789, -5.8863],
        [-1.0684, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290927529335022
Epoch 0, Step 1188: train/loss = 0.37925058603286743, train/raw-loss = 0.3174858093261719, train/logprobs = tensor([[-0.6254, -3.6346],
        [-1.3322, -1.1053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12352954596281052
Epoch 0, Step 1189: train/loss = 0.3778979182243347, train/raw-loss = 0.3120712637901306, train/logprobs = tensor([[-0.5665, -2.6617],
        [-1.2391, -0.6227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131653293967247
Epoch 0, Step 1190: train/loss = 0.46775317192077637, train/raw-loss = 0.40587055683135986, train/logprobs = tensor([[-0.6035, -2.5131],
        [-1.0849, -0.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12376528978347778
Epoch 0, Step 1191: train/loss = 0.3887600898742676, train/raw-loss = 0.3340687155723572, train/logprobs = tensor([[-0.6839, -5.6303],
        [-1.0196, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1093827411532402
Epoch 0, Step 1192: train/loss = 0.28955352306365967, train/raw-loss = 0.22585079073905945, train/logprobs = tensor([[-0.5608, -7.5566],
        [-1.0828, -1.4093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12740547955036163
Epoch 0, Step 1193: train/loss = 0.5310378074645996, train/raw-loss = 0.4653320908546448, train/logprobs = tensor([[-0.6225, -1.6113],
        [-1.4039, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13141143321990967
Epoch 0, Step 1194: train/loss = 0.5741250514984131, train/raw-loss = 0.5164508819580078, train/logprobs = tensor([[-1.0789, -3.3492],
        [-0.8775, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11534839123487473
Epoch 0, Step 1195: train/loss = 0.5374451875686646, train/raw-loss = 0.48052698373794556, train/logprobs = tensor([[-0.8454, -4.0539],
        [-0.7316, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.113836370408535
Epoch 0, Step 1196: train/loss = 0.6042377948760986, train/raw-loss = 0.5441380143165588, train/logprobs = tensor([[-1.6014, -3.5376],
        [-1.1335, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12019951641559601
Epoch 0, Step 1197: train/loss = 0.23406952619552612, train/raw-loss = 0.16702547669410706, train/logprobs = tensor([[-0.5499, -5.9721],
        [-1.5156, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13408814370632172
Epoch 0, Step 1198: train/loss = 0.43685346841812134, train/raw-loss = 0.3705901503562927, train/logprobs = tensor([[-0.8240, -4.2196],
        [-1.2888, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13252657651901245
Epoch 0, Step 1199: train/loss = 0.6484960317611694, train/raw-loss = 0.6019521951675415, train/logprobs = tensor([[-0.4250, -0.6328],
        [-0.5853, -0.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09308771789073944
Epoch 0, Step 1200: train/loss = 0.481620192527771, train/raw-loss = 0.42507433891296387, train/logprobs = tensor([[-0.7288, -3.1179],
        [-0.9251, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11309170722961426
Epoch 0, Step 1201: train/loss = 0.564093828201294, train/raw-loss = 0.5164501667022705, train/logprobs = tensor([[-0.5742, -1.8941],
        [-0.8340, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952872484922409
Epoch 0, Step 1202: train/loss = 0.2815149426460266, train/raw-loss = 0.21000315248966217, train/logprobs = tensor([[-0.7107, -8.1535],
        [-1.2680, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430235654115677
Epoch 0, Step 1203: train/loss = 0.35643160343170166, train/raw-loss = 0.2945351004600525, train/logprobs = tensor([[-0.4459, -5.3812],
        [-1.1135, -1.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12379299104213715
Epoch 0, Step 1204: train/loss = 0.46607068181037903, train/raw-loss = 0.41298043727874756, train/logprobs = tensor([[-0.8623, -1.8276],
        [-1.3311, -0.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10618048161268234
Epoch 0, Step 1205: train/loss = 0.5416901111602783, train/raw-loss = 0.4739217162132263, train/logprobs = tensor([[-0.7699, -2.7758],
        [-0.8482, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355368196964264
Epoch 0, Step 1206: train/loss = 0.4515606164932251, train/raw-loss = 0.3882087469100952, train/logprobs = tensor([[-0.7327, -4.1859],
        [-1.1235, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12670373916625977
Epoch 0, Step 1207: train/loss = 0.34061694145202637, train/raw-loss = 0.2782301902770996, train/logprobs = tensor([[-0.6650, -4.5380],
        [-1.1287, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12477346509695053
Epoch 0, Step 1208: train/loss = 0.2943096160888672, train/raw-loss = 0.2276022732257843, train/logprobs = tensor([[-0.7399, -4.3924],
        [-1.6704, -0.4486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13341465592384338
Epoch 0, Step 1209: train/loss = 0.26733720302581787, train/raw-loss = 0.19583575427532196, train/logprobs = tensor([[-0.8740, -3.2201],
        [-2.0641, -0.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430029273033142
Epoch 0, Step 1210: train/loss = 0.40460875630378723, train/raw-loss = 0.33612221479415894, train/logprobs = tensor([[-0.4867, -2.9091],
        [-1.1044, -0.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1369730681180954
Epoch 0, Step 1211: train/loss = 0.2682340145111084, train/raw-loss = 0.20376741886138916, train/logprobs = tensor([[-0.6010, -4.7953],
        [-1.3713, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289331465959549
Epoch 0, Step 1212: train/loss = 0.5276253819465637, train/raw-loss = 0.47957924008369446, train/logprobs = tensor([[-0.7151, -4.1526],
        [-0.8617, -0.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609225392341614
Epoch 0, Step 1213: train/loss = 0.42199409008026123, train/raw-loss = 0.36160486936569214, train/logprobs = tensor([[-0.7834, -4.3560],
        [-0.9637, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1207784116268158
Epoch 0, Step 1214: train/loss = 0.4498780071735382, train/raw-loss = 0.38388681411743164, train/logprobs = tensor([[-0.6929, -4.0422],
        [-0.8816, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13198228180408478
Epoch 0, Step 1215: train/loss = 0.4346780478954315, train/raw-loss = 0.37150952219963074, train/logprobs = tensor([[-0.6781, -5.8978],
        [-1.1706, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12633705139160156
Epoch 0, Step 1216: train/loss = 0.48346108198165894, train/raw-loss = 0.42821788787841797, train/logprobs = tensor([[-0.5449, -3.7635],
        [-1.0329, -1.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11048641055822372
Epoch 0, Step 1217: train/loss = 0.46380746364593506, train/raw-loss = 0.4100518524646759, train/logprobs = tensor([[-1.1411, -5.5606],
        [-1.5557, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10751119256019592
Epoch 0, Step 1218: train/loss = 0.4503493010997772, train/raw-loss = 0.3853510022163391, train/logprobs = tensor([[-0.6614, -3.6450],
        [-1.0766, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12999653816223145
Epoch 0, Step 1219: train/loss = 0.3686825931072235, train/raw-loss = 0.2944428622722626, train/logprobs = tensor([[-0.7766, -6.1606],
        [-1.3887, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484794020652771
Epoch 0, Step 1220: train/loss = 0.714800238609314, train/raw-loss = 0.6633317470550537, train/logprobs = tensor([[-0.6857, -0.7002],
        [-0.6734, -0.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293716192245483
Epoch 0, Step 1221: train/loss = 0.4155837893486023, train/raw-loss = 0.37173232436180115, train/logprobs = tensor([[-0.4655, -3.3947],
        [-0.7717, -0.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08770298957824707
Epoch 0, Step 1222: train/loss = 0.5050132274627686, train/raw-loss = 0.44726699590682983, train/logprobs = tensor([[-0.7665, -4.4095],
        [-1.5782, -1.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11549241095781326
Epoch 0, Step 1223: train/loss = 0.3916434347629547, train/raw-loss = 0.3395986557006836, train/logprobs = tensor([[-0.5590, -3.6038],
        [-1.0207, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10408952832221985
Epoch 0, Step 1224: train/loss = 0.4960227608680725, train/raw-loss = 0.45027223229408264, train/logprobs = tensor([[-0.3169, -2.4043],
        [-0.5760, -0.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150105714797974
Epoch 0, Step 1225: train/loss = 0.4204341769218445, train/raw-loss = 0.3753896951675415, train/logprobs = tensor([[-0.4742, -2.7434],
        [-0.6959, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09008903056383133
Epoch 0, Step 1226: train/loss = 0.4754308760166168, train/raw-loss = 0.42307811975479126, train/logprobs = tensor([[-0.7529, -3.0819],
        [-0.7394, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470549762248993
Epoch 0, Step 1227: train/loss = 0.5223263502120972, train/raw-loss = 0.4631689190864563, train/logprobs = tensor([[-1.1158, -2.2542],
        [-1.1185, -0.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11831492185592651
Epoch 0, Step 1228: train/loss = 0.5796574354171753, train/raw-loss = 0.5177479982376099, train/logprobs = tensor([[-0.6079, -1.6430],
        [-0.7769, -0.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238187849521637
Epoch 0, Step 1229: train/loss = 0.3994690477848053, train/raw-loss = 0.3477252125740051, train/logprobs = tensor([[-0.4801, -6.0636],
        [-0.7202, -0.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10348761081695557
Epoch 0, Step 1230: train/loss = 0.6904621720314026, train/raw-loss = 0.6309887170791626, train/logprobs = tensor([[-1.4958, -1.9895],
        [-1.5555, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11894689500331879
Epoch 0, Step 1231: train/loss = 0.49171629548072815, train/raw-loss = 0.42618680000305176, train/logprobs = tensor([[-0.8075, -2.0212],
        [-1.2489, -0.9015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131058931350708
Epoch 0, Step 1232: train/loss = 0.859319806098938, train/raw-loss = 0.8157601356506348, train/logprobs = tensor([[-3.0684, -5.8676],
        [-1.8625, -2.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08711939305067062
Epoch 0, Step 1233: train/loss = 0.5797484517097473, train/raw-loss = 0.5188037753105164, train/logprobs = tensor([[-0.5087, -1.4438],
        [-0.7075, -0.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12188935279846191
Epoch 0, Step 1234: train/loss = 0.41358762979507446, train/raw-loss = 0.35500627756118774, train/logprobs = tensor([[-0.6874, -2.8177],
        [-1.2605, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716270446777344
Epoch 0, Step 1235: train/loss = 0.6945483088493347, train/raw-loss = 0.6417032480239868, train/logprobs = tensor([[-1.3744, -5.0877],
        [-0.8003, -1.3598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569008439779282
Epoch 0, Step 1236: train/loss = 0.3818986415863037, train/raw-loss = 0.32524704933166504, train/logprobs = tensor([[-0.3758, -5.0005],
        [-0.7425, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11330314725637436
Epoch 0, Step 1237: train/loss = 0.3462880551815033, train/raw-loss = 0.2835437059402466, train/logprobs = tensor([[-0.6841, -6.3110],
        [-1.3481, -1.2650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12548871338367462
Epoch 0, Step 1238: train/loss = 0.4830774664878845, train/raw-loss = 0.42272821068763733, train/logprobs = tensor([[-0.6476, -3.7332],
        [-1.0996, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12069854140281677
Epoch 0, Step 1239: train/loss = 0.5697307586669922, train/raw-loss = 0.5208061337471008, train/logprobs = tensor([[-0.7551, -2.5710],
        [-0.6838, -0.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09784920513629913
Epoch 0, Step 1240: train/loss = 0.5088738799095154, train/raw-loss = 0.45031875371932983, train/logprobs = tensor([[-0.9871, -5.1115],
        [-1.5563, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11711031198501587
Epoch 0, Step 1241: train/loss = 0.39942455291748047, train/raw-loss = 0.3324584662914276, train/logprobs = tensor([[-0.6186, -2.6811],
        [-1.3680, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13393211364746094
Epoch 0, Step 1242: train/loss = 0.48056599497795105, train/raw-loss = 0.4236713647842407, train/logprobs = tensor([[-0.6700, -2.7265],
        [-1.2090, -1.1367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11378929764032364
Epoch 0, Step 1243: train/loss = 0.5372198820114136, train/raw-loss = 0.4773343503475189, train/logprobs = tensor([[-0.5954, -1.6880],
        [-1.0751, -0.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1197710633277893
Epoch 0, Step 1244: train/loss = 0.4461956024169922, train/raw-loss = 0.3850261867046356, train/logprobs = tensor([[-0.6197, -1.9581],
        [-1.0660, -0.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12233883142471313
Epoch 0, Step 1245: train/loss = 0.30497339367866516, train/raw-loss = 0.2283422201871872, train/logprobs = tensor([[-0.5212, -4.1528],
        [-1.6434, -1.2106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15326233208179474
Epoch 0, Step 1246: train/loss = 0.30699923634529114, train/raw-loss = 0.24414832890033722, train/logprobs = tensor([[-0.6212, -3.1054],
        [-1.4220, -0.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12570182979106903
Epoch 0, Step 1247: train/loss = 0.46618860960006714, train/raw-loss = 0.398340106010437, train/logprobs = tensor([[-1.0133, -4.3801],
        [-0.9573, -1.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13569706678390503
Epoch 0, Step 1248: train/loss = 0.5180616974830627, train/raw-loss = 0.45602330565452576, train/logprobs = tensor([[-0.5928, -2.0134],
        [-1.0646, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407675385475159
Epoch 0, Step 1249: train/loss = 0.560469388961792, train/raw-loss = 0.49824443459510803, train/logprobs = tensor([[-0.7206, -1.5139],
        [-1.1101, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12444981932640076
Epoch 0, Step 1250: train/loss = 0.5474545955657959, train/raw-loss = 0.474721223115921, train/logprobs = tensor([[-0.7262, -2.1520],
        [-0.9692, -0.9191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14546674489974976
Epoch 0, Step 1251: train/loss = 0.42552682757377625, train/raw-loss = 0.3582805395126343, train/logprobs = tensor([[-0.4398, -4.0394],
        [-1.0678, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344926357269287
Epoch 0, Step 1252: train/loss = 0.30564749240875244, train/raw-loss = 0.2284640669822693, train/logprobs = tensor([[-0.7135, -5.7949],
        [-1.6967, -1.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543668806552887
Epoch 0, Step 1253: train/loss = 0.45738983154296875, train/raw-loss = 0.39720168709754944, train/logprobs = tensor([[-0.6335, -2.2487],
        [-1.1161, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12037638574838638
Epoch 0, Step 1254: train/loss = 0.47695428133010864, train/raw-loss = 0.4200061559677124, train/logprobs = tensor([[-0.3975, -2.5247],
        [-0.7927, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11389628797769547
Epoch 0, Step 1255: train/loss = 0.6916367411613464, train/raw-loss = 0.640174150466919, train/logprobs = tensor([[-0.5482, -0.7389],
        [-0.7779, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10292509943246841
Epoch 0, Step 1256: train/loss = 0.4012676775455475, train/raw-loss = 0.33861303329467773, train/logprobs = tensor([[-0.9988, -2.2075],
        [-2.1639, -1.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1253092885017395
Epoch 0, Step 1257: train/loss = 0.5290439128875732, train/raw-loss = 0.4707942306995392, train/logprobs = tensor([[-0.4609, -2.1950],
        [-0.6854, -0.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1164993941783905
Epoch 0, Step 1258: train/loss = 0.39539456367492676, train/raw-loss = 0.33785098791122437, train/logprobs = tensor([[-0.7012, -3.1290],
        [-1.4160, -0.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11508716642856598
Epoch 0, Step 1259: train/loss = 0.6497616767883301, train/raw-loss = 0.589565098285675, train/logprobs = tensor([[-0.4247, -1.1017],
        [-0.7319, -0.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12039317190647125
Epoch 0, Step 1260: train/loss = 0.4697471559047699, train/raw-loss = 0.4021126925945282, train/logprobs = tensor([[-0.6656, -6.6626],
        [-1.4376, -1.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1352689117193222
Epoch 0, Step 1261: train/loss = 0.5296447277069092, train/raw-loss = 0.44390562176704407, train/logprobs = tensor([[-0.6430, -2.6315],
        [-1.3377, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17147807776927948
Epoch 0, Step 1262: train/loss = 0.4361969232559204, train/raw-loss = 0.3786027729511261, train/logprobs = tensor([[-0.6416, -3.7737],
        [-1.0847, -1.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11518833786249161
Epoch 0, Step 1263: train/loss = 0.4688078761100769, train/raw-loss = 0.4121992290019989, train/logprobs = tensor([[-0.7797, -2.9550],
        [-1.0453, -0.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1132173091173172
Epoch 0, Step 1264: train/loss = 0.34309208393096924, train/raw-loss = 0.27740398049354553, train/logprobs = tensor([[-0.7965, -3.6359],
        [-1.3253, -0.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131376251578331
Epoch 0, Step 1265: train/loss = 0.48906370997428894, train/raw-loss = 0.42127931118011475, train/logprobs = tensor([[-0.7488, -2.5907],
        [-1.4091, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13556887209415436
Epoch 0, Step 1266: train/loss = 0.4400312602519989, train/raw-loss = 0.37810784578323364, train/logprobs = tensor([[-0.9976, -5.9986],
        [-1.2008, -1.1782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12384681403636932
Epoch 0, Step 1267: train/loss = 0.2588990032672882, train/raw-loss = 0.19163715839385986, train/logprobs = tensor([[-0.7306, -4.1962],
        [-1.6863, -1.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1345236748456955
Epoch 0, Step 1268: train/loss = 0.3261522054672241, train/raw-loss = 0.2614158093929291, train/logprobs = tensor([[-0.7191, -6.6831],
        [-1.7768, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12947280704975128
Epoch 0, Step 1269: train/loss = 0.41036346554756165, train/raw-loss = 0.3534994125366211, train/logprobs = tensor([[-0.7738, -3.4909],
        [-1.5720, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11372816562652588
Epoch 0, Step 1270: train/loss = 0.5358623266220093, train/raw-loss = 0.47727617621421814, train/logprobs = tensor([[-0.7771, -3.4873],
        [-1.0416, -1.1927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11717227101325989
Epoch 0, Step 1271: train/loss = 0.5479217171669006, train/raw-loss = 0.49905067682266235, train/logprobs = tensor([[-0.6314, -3.0305],
        [-0.7220, -1.1792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09774211049079895
Epoch 0, Step 1272: train/loss = 0.35432755947113037, train/raw-loss = 0.29371678829193115, train/logprobs = tensor([[-0.7581, -3.4961],
        [-1.4201, -0.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12122155725955963
Epoch 0, Step 1273: train/loss = 0.5617808103561401, train/raw-loss = 0.49958333373069763, train/logprobs = tensor([[-0.9437, -2.5355],
        [-0.8833, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12439487874507904
Epoch 0, Step 1274: train/loss = 0.5159609913825989, train/raw-loss = 0.45031964778900146, train/logprobs = tensor([[-0.3758, -2.8182],
        [-0.7667, -1.0072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13128283619880676
Epoch 0, Step 1275: train/loss = 0.44041329622268677, train/raw-loss = 0.3751544654369354, train/logprobs = tensor([[-0.4671, -2.0842],
        [-1.1050, -0.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13051757216453552
Epoch 0, Step 1276: train/loss = 0.36211061477661133, train/raw-loss = 0.31090062856674194, train/logprobs = tensor([[-0.5593, -6.9836],
        [-1.0710, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10241995006799698
Epoch 0, Step 1277: train/loss = 0.5337667465209961, train/raw-loss = 0.4803847074508667, train/logprobs = tensor([[-0.6062, -1.5962],
        [-0.7930, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1067640632390976
Epoch 0, Step 1278: train/loss = 0.30065006017684937, train/raw-loss = 0.2336566150188446, train/logprobs = tensor([[-0.3944, -4.3323],
        [-1.3599, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339869499206543
Epoch 0, Step 1279: train/loss = 0.30202051997184753, train/raw-loss = 0.22512677311897278, train/logprobs = tensor([[-0.6346, -5.3816],
        [-1.4794, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15378746390342712
Epoch 0, Step 1280: train/loss = 0.37501081824302673, train/raw-loss = 0.30816686153411865, train/logprobs = tensor([[-0.5437, -4.5276],
        [-1.1946, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13368791341781616
Epoch 0, Step 1281: train/loss = 0.4053556025028229, train/raw-loss = 0.34265273809432983, train/logprobs = tensor([[-0.6084, -3.8566],
        [-0.9921, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254056990146637
Epoch 0, Step 1282: train/loss = 0.5163649916648865, train/raw-loss = 0.4692203402519226, train/logprobs = tensor([[-0.3841, -2.2061],
        [-0.5930, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09428931027650833
