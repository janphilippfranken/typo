{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 23:25:45,281][root][INFO] - beta: 0.2
[2024-03-12 23:25:45,281][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.2-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6530619859695435, train/raw-loss = 0.64960777759552, train/logprobs = tensor([[-0.5568, -0.9073],
        [-0.4912, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01727093942463398
Epoch 0, Step 65: train/loss = 0.5891295671463013, train/raw-loss = 0.586371660232544, train/logprobs = tensor([[-0.4078, -2.3858],
        [-0.4047, -1.6180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013789295218884945
Epoch 0, Step 66: train/loss = 0.6313971281051636, train/raw-loss = 0.6279458403587341, train/logprobs = tensor([[-0.6690, -1.2269],
        [-0.6745, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01725633256137371
Epoch 0, Step 67: train/loss = 0.6111084222793579, train/raw-loss = 0.6082071661949158, train/logprobs = tensor([[-0.4566, -1.6523],
        [-0.4386, -1.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014506087638437748
Epoch 0, Step 68: train/loss = 0.6236241459846497, train/raw-loss = 0.6205734610557556, train/logprobs = tensor([[-0.5315, -0.8139],
        [-0.6265, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01525328028947115
Epoch 0, Step 69: train/loss = 0.6388169527053833, train/raw-loss = 0.6356706619262695, train/logprobs = tensor([[-0.6249, -0.8802],
        [-0.6399, -0.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015731267631053925
Epoch 0, Step 70: train/loss = 0.6065374612808228, train/raw-loss = 0.6037026643753052, train/logprobs = tensor([[-0.5826, -1.5747],
        [-0.5836, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014174006879329681
Epoch 0, Step 71: train/loss = 0.6168296337127686, train/raw-loss = 0.6138507723808289, train/logprobs = tensor([[-0.5089, -1.2026],
        [-0.5335, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014894288033246994
Epoch 0, Step 72: train/loss = 0.6406302452087402, train/raw-loss = 0.6375073194503784, train/logprobs = tensor([[-0.5488, -1.3673],
        [-0.5549, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015614472329616547
Epoch 0, Step 73: train/loss = 0.6779775619506836, train/raw-loss = 0.6745644211769104, train/logprobs = tensor([[-0.5529, -1.0903],
        [-0.5393, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017065558582544327
Epoch 0, Step 74: train/loss = 0.6502944231033325, train/raw-loss = 0.6466955542564392, train/logprobs = tensor([[-0.6142, -0.9836],
        [-0.5841, -0.7530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01799452304840088
Epoch 0, Step 75: train/loss = 0.6073862314224243, train/raw-loss = 0.604900598526001, train/logprobs = tensor([[-0.4141, -1.3310],
        [-0.4378, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01242789626121521
Epoch 0, Step 76: train/loss = 0.5471041202545166, train/raw-loss = 0.5443965792655945, train/logprobs = tensor([[-0.4650, -2.4535],
        [-0.4997, -1.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01353762298822403
Epoch 0, Step 77: train/loss = 0.6076997518539429, train/raw-loss = 0.6044761538505554, train/logprobs = tensor([[-0.6573, -1.0143],
        [-0.6921, -0.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016118133440613747
Epoch 0, Step 78: train/loss = 0.6543285846710205, train/raw-loss = 0.6509723663330078, train/logprobs = tensor([[-0.6901, -0.9512],
        [-0.6817, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01678081415593624
Epoch 0, Step 79: train/loss = 0.5781630277633667, train/raw-loss = 0.5751475095748901, train/logprobs = tensor([[-0.5677, -2.4048],
        [-0.5716, -1.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015077606774866581
Epoch 0, Step 80: train/loss = 0.6289864182472229, train/raw-loss = 0.6254040002822876, train/logprobs = tensor([[-0.7446, -1.0113],
        [-0.7357, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017912372946739197
Epoch 0, Step 81: train/loss = 0.5725996494293213, train/raw-loss = 0.5704092383384705, train/logprobs = tensor([[-0.5265, -2.5100],
        [-0.5216, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010952161625027657
Epoch 0, Step 82: train/loss = 0.6507226228713989, train/raw-loss = 0.64697265625, train/logprobs = tensor([[-0.6925, -1.1125],
        [-0.6236, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01874951273202896
Epoch 0, Step 83: train/loss = 0.6847845911979675, train/raw-loss = 0.6807593703269958, train/logprobs = tensor([[-1.5389, -1.6592],
        [-1.4968, -1.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020126409828662872
Epoch 0, Step 84: train/loss = 0.6434540748596191, train/raw-loss = 0.639690101146698, train/logprobs = tensor([[-0.6084, -0.9781],
        [-0.5897, -0.7249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018820008262991905
Epoch 0, Step 85: train/loss = 0.5640808939933777, train/raw-loss = 0.5608395338058472, train/logprobs = tensor([[-0.5885, -2.0111],
        [-0.5795, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016206791624426842
Epoch 0, Step 86: train/loss = 0.6302661895751953, train/raw-loss = 0.6268409490585327, train/logprobs = tensor([[-0.5679, -0.9149],
        [-0.5949, -0.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017126217484474182
Epoch 0, Step 87: train/loss = 0.6076416969299316, train/raw-loss = 0.6044015884399414, train/logprobs = tensor([[-0.6378, -1.0351],
        [-0.7064, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016200844198465347
Epoch 0, Step 88: train/loss = 0.6136963963508606, train/raw-loss = 0.6099727749824524, train/logprobs = tensor([[-1.0035, -2.1801],
        [-0.9335, -1.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01861823908984661
Epoch 0, Step 89: train/loss = 0.6399110555648804, train/raw-loss = 0.6363471746444702, train/logprobs = tensor([[-0.5693, -0.9939],
        [-0.5555, -0.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017818933352828026
Epoch 0, Step 90: train/loss = 0.629536509513855, train/raw-loss = 0.6262022256851196, train/logprobs = tensor([[-0.4664, -1.0618],
        [-0.4749, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016671620309352875
Epoch 0, Step 91: train/loss = 0.44783058762550354, train/raw-loss = 0.4452609419822693, train/logprobs = tensor([[-0.4699, -2.7840],
        [-0.5096, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012848122976720333
Epoch 0, Step 92: train/loss = 0.6545227766036987, train/raw-loss = 0.6504544615745544, train/logprobs = tensor([[-0.6956, -1.0865],
        [-0.6942, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02034165896475315
Epoch 0, Step 93: train/loss = 0.5931295156478882, train/raw-loss = 0.5899194478988647, train/logprobs = tensor([[-0.5680, -1.4605],
        [-0.5591, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016050493344664574
Epoch 0, Step 94: train/loss = 0.5915232300758362, train/raw-loss = 0.5881267189979553, train/logprobs = tensor([[-0.6781, -1.8449],
        [-0.7731, -1.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01698254980146885
Epoch 0, Step 95: train/loss = 0.6280936598777771, train/raw-loss = 0.6253393888473511, train/logprobs = tensor([[-0.5259, -1.0193],
        [-0.5225, -0.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013771369121968746
Epoch 0, Step 96: train/loss = 0.6934140920639038, train/raw-loss = 0.6836471557617188, train/logprobs = tensor([[-0.6041, -0.9029],
        [-0.5856, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04883454740047455
Epoch 0, Step 97: train/loss = 0.5723937749862671, train/raw-loss = 0.5642391443252563, train/logprobs = tensor([[-0.6387, -1.9586],
        [-0.6187, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04077303782105446
Epoch 0, Step 98: train/loss = 0.617580235004425, train/raw-loss = 0.6115580797195435, train/logprobs = tensor([[-0.3859, -0.9898],
        [-0.3304, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030110687017440796
Epoch 0, Step 99: train/loss = 0.6322180032730103, train/raw-loss = 0.625771164894104, train/logprobs = tensor([[-0.5308, -1.0532],
        [-0.5058, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03223421797156334
Epoch 0, Step 100: train/loss = 0.548591136932373, train/raw-loss = 0.5418201684951782, train/logprobs = tensor([[-0.6815, -2.8150],
        [-0.6545, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03385505825281143
Epoch 0, Step 101: train/loss = 0.5999811291694641, train/raw-loss = 0.5883741974830627, train/logprobs = tensor([[-0.9664, -1.8552],
        [-0.9259, -1.2913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05803458020091057
Epoch 0, Step 102: train/loss = 0.5861512422561646, train/raw-loss = 0.5783288478851318, train/logprobs = tensor([[-0.4992, -1.3628],
        [-0.4894, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03911204636096954
Epoch 0, Step 103: train/loss = 0.5616308450698853, train/raw-loss = 0.5550022125244141, train/logprobs = tensor([[-0.6358, -1.7318],
        [-0.5477, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033143091946840286
Epoch 0, Step 104: train/loss = 0.4532800316810608, train/raw-loss = 0.4444386959075928, train/logprobs = tensor([[-0.7993, -4.5308],
        [-0.6591, -2.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04420654848217964
Epoch 0, Step 105: train/loss = 0.6070126295089722, train/raw-loss = 0.5988405346870422, train/logprobs = tensor([[-0.6787, -1.2076],
        [-0.6194, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04086024686694145
Epoch 0, Step 106: train/loss = 0.46008896827697754, train/raw-loss = 0.453372597694397, train/logprobs = tensor([[-0.6841, -4.4451],
        [-0.6179, -2.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033581823110580444
Epoch 0, Step 107: train/loss = 0.6093062162399292, train/raw-loss = 0.5991185307502747, train/logprobs = tensor([[-0.7234, -1.5443],
        [-0.6781, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050938576459884644
Epoch 0, Step 108: train/loss = 0.6667216420173645, train/raw-loss = 0.6614882349967957, train/logprobs = tensor([[-0.5306, -0.6634],
        [-0.4649, -0.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02616707980632782
Epoch 0, Step 109: train/loss = 0.6099321246147156, train/raw-loss = 0.6028144955635071, train/logprobs = tensor([[-0.6425, -1.2835],
        [-0.5552, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035588331520557404
Epoch 0, Step 110: train/loss = 0.5461931824684143, train/raw-loss = 0.5389144420623779, train/logprobs = tensor([[-0.6637, -2.9739],
        [-0.5465, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036393795162439346
Epoch 0, Step 111: train/loss = 0.5783313512802124, train/raw-loss = 0.5728140473365784, train/logprobs = tensor([[-0.4369, -1.5223],
        [-0.4206, -0.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027586253359913826
Epoch 0, Step 112: train/loss = 0.6047007441520691, train/raw-loss = 0.5978150963783264, train/logprobs = tensor([[-0.6323, -1.1121],
        [-0.5923, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03442848101258278
Epoch 0, Step 113: train/loss = 0.6364079117774963, train/raw-loss = 0.626107394695282, train/logprobs = tensor([[-0.6500, -1.2905],
        [-0.5752, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051502469927072525
Epoch 0, Step 114: train/loss = 0.6075264811515808, train/raw-loss = 0.5992928743362427, train/logprobs = tensor([[-0.5666, -1.0741],
        [-0.5359, -0.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04116811230778694
Epoch 0, Step 115: train/loss = 0.620226263999939, train/raw-loss = 0.6137372255325317, train/logprobs = tensor([[-0.5715, -1.1755],
        [-0.5361, -0.7194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03244539722800255
Epoch 0, Step 116: train/loss = 0.5673738121986389, train/raw-loss = 0.5584301352500916, train/logprobs = tensor([[-0.6698, -2.0779],
        [-0.6110, -1.2812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0447184294462204
Epoch 0, Step 117: train/loss = 0.6250724792480469, train/raw-loss = 0.6177080869674683, train/logprobs = tensor([[-0.4868, -1.7788],
        [-0.4597, -1.4011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03682174161076546
Epoch 0, Step 118: train/loss = 0.4995538890361786, train/raw-loss = 0.4934851825237274, train/logprobs = tensor([[-0.6588, -3.2135],
        [-0.5721, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030343446880578995
Epoch 0, Step 119: train/loss = 0.5737075209617615, train/raw-loss = 0.5644999742507935, train/logprobs = tensor([[-0.6172, -1.6992],
        [-0.5652, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04603773355484009
Epoch 0, Step 120: train/loss = 0.5267617702484131, train/raw-loss = 0.5182327032089233, train/logprobs = tensor([[-0.7878, -2.6568],
        [-0.7642, -1.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04264536127448082
Epoch 0, Step 121: train/loss = 0.611299455165863, train/raw-loss = 0.6045092344284058, train/logprobs = tensor([[-0.5031, -1.2465],
        [-0.4473, -0.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03395150974392891
Epoch 0, Step 122: train/loss = 0.5472116470336914, train/raw-loss = 0.5389882326126099, train/logprobs = tensor([[-0.8526, -1.9638],
        [-0.7400, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04111705720424652
Epoch 0, Step 123: train/loss = 0.6724885702133179, train/raw-loss = 0.6644401550292969, train/logprobs = tensor([[-0.5345, -0.8006],
        [-0.5081, -0.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04024223983287811
Epoch 0, Step 124: train/loss = 0.5896323919296265, train/raw-loss = 0.5806623101234436, train/logprobs = tensor([[-0.7960, -1.6178],
        [-0.7078, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04485045745968819
Epoch 0, Step 125: train/loss = 0.5473451614379883, train/raw-loss = 0.5388429760932922, train/logprobs = tensor([[-0.7098, -3.2309],
        [-0.6302, -2.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04251079261302948
Epoch 0, Step 126: train/loss = 0.6368578672409058, train/raw-loss = 0.6274778842926025, train/logprobs = tensor([[-0.6808, -1.2164],
        [-0.5690, -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04689987003803253
Epoch 0, Step 127: train/loss = 0.617104172706604, train/raw-loss = 0.6092732548713684, train/logprobs = tensor([[-0.5126, -1.5070],
        [-0.4476, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03915467485785484
Epoch 0, Step 128: train/loss = 0.675518274307251, train/raw-loss = 0.6553143262863159, train/logprobs = tensor([[-0.8426, -1.0528],
        [-0.7951, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10101953893899918
Epoch 0, Step 129: train/loss = 0.5383021831512451, train/raw-loss = 0.5154364705085754, train/logprobs = tensor([[-0.7499, -2.9419],
        [-0.6385, -1.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11432862281799316
Epoch 0, Step 130: train/loss = 0.6421211361885071, train/raw-loss = 0.6244251132011414, train/logprobs = tensor([[-0.5411, -1.1751],
        [-0.4729, -0.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08848005533218384
Epoch 0, Step 131: train/loss = 0.5240654349327087, train/raw-loss = 0.5026029348373413, train/logprobs = tensor([[-0.7799, -4.1682],
        [-0.6935, -2.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10731233656406403
Epoch 0, Step 132: train/loss = 0.5567465424537659, train/raw-loss = 0.5359437465667725, train/logprobs = tensor([[-0.8046, -2.4034],
        [-0.6408, -1.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10401396453380585
Epoch 0, Step 133: train/loss = 0.567536473274231, train/raw-loss = 0.5466777086257935, train/logprobs = tensor([[-0.6526, -2.4587],
        [-0.5615, -1.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10429374128580093
Epoch 0, Step 134: train/loss = 0.5792510509490967, train/raw-loss = 0.5611140727996826, train/logprobs = tensor([[-0.7648, -1.7093],
        [-0.6262, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09068474918603897
Epoch 0, Step 135: train/loss = 0.6145223379135132, train/raw-loss = 0.5960026383399963, train/logprobs = tensor([[-0.5249, -1.5127],
        [-0.3965, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09259837865829468
Epoch 0, Step 136: train/loss = 0.5396388173103333, train/raw-loss = 0.524867594242096, train/logprobs = tensor([[-0.4435, -2.1728],
        [-0.3955, -1.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07385618984699249
Epoch 0, Step 137: train/loss = 0.6109554767608643, train/raw-loss = 0.5947673916816711, train/logprobs = tensor([[-0.4437, -1.3757],
        [-0.4067, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809403508901596
Epoch 0, Step 138: train/loss = 0.5614999532699585, train/raw-loss = 0.542832612991333, train/logprobs = tensor([[-0.4422, -1.7618],
        [-0.3648, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333647787570953
Epoch 0, Step 139: train/loss = 0.5470758676528931, train/raw-loss = 0.527018666267395, train/logprobs = tensor([[-0.6261, -2.4324],
        [-0.5003, -1.4098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028563439846039
Epoch 0, Step 140: train/loss = 0.6013984084129333, train/raw-loss = 0.580970048904419, train/logprobs = tensor([[-0.7865, -1.8070],
        [-0.6675, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214163362979889
Epoch 0, Step 141: train/loss = 0.6074175834655762, train/raw-loss = 0.5848608016967773, train/logprobs = tensor([[-0.9282, -1.9684],
        [-0.6849, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11278362572193146
Epoch 0, Step 142: train/loss = 0.6330442428588867, train/raw-loss = 0.6141058802604675, train/logprobs = tensor([[-0.5672, -1.2503],
        [-0.4790, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09469187259674072
Epoch 0, Step 143: train/loss = 0.6531243920326233, train/raw-loss = 0.6354446411132812, train/logprobs = tensor([[-0.7583, -1.5942],
        [-0.5968, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08839893341064453
Epoch 0, Step 144: train/loss = 0.4902011454105377, train/raw-loss = 0.4730295240879059, train/logprobs = tensor([[-0.5799, -4.0147],
        [-0.4954, -2.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08585814386606216
Epoch 0, Step 145: train/loss = 0.6305893659591675, train/raw-loss = 0.6148171424865723, train/logprobs = tensor([[-0.6558, -1.5502],
        [-0.5694, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0788610428571701
Epoch 0, Step 146: train/loss = 0.56961590051651, train/raw-loss = 0.5494790077209473, train/logprobs = tensor([[-0.6544, -2.8413],
        [-0.5203, -1.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068453848361969
Epoch 0, Step 147: train/loss = 0.623444676399231, train/raw-loss = 0.6062352657318115, train/logprobs = tensor([[-0.6291, -1.2288],
        [-0.5238, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08604729175567627
Epoch 0, Step 148: train/loss = 0.7107170820236206, train/raw-loss = 0.6849534511566162, train/logprobs = tensor([[-1.5630, -1.8924],
        [-1.1706, -1.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12881864607334137
Epoch 0, Step 149: train/loss = 0.6494288444519043, train/raw-loss = 0.6291109919548035, train/logprobs = tensor([[-0.6408, -1.3065],
        [-0.5318, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015893816947937
Epoch 0, Step 150: train/loss = 0.5586643815040588, train/raw-loss = 0.5351533889770508, train/logprobs = tensor([[-0.8322, -3.5795],
        [-0.7307, -2.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11755476146936417
Epoch 0, Step 151: train/loss = 0.6029857397079468, train/raw-loss = 0.58150315284729, train/logprobs = tensor([[-0.6834, -1.8998],
        [-0.5388, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10741272568702698
Epoch 0, Step 152: train/loss = 0.6247879862785339, train/raw-loss = 0.6012598872184753, train/logprobs = tensor([[-0.8515, -1.4321],
        [-0.7665, -0.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11764076352119446
Epoch 0, Step 153: train/loss = 0.5913318991661072, train/raw-loss = 0.5691499710083008, train/logprobs = tensor([[-0.6244, -2.1133],
        [-0.5109, -1.3211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11090972274541855
Epoch 0, Step 154: train/loss = 0.6604328751564026, train/raw-loss = 0.6400327682495117, train/logprobs = tensor([[-0.7557, -1.6414],
        [-0.6522, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10200026631355286
Epoch 0, Step 155: train/loss = 0.5722386837005615, train/raw-loss = 0.554468035697937, train/logprobs = tensor([[-0.6001, -2.9713],
        [-0.5069, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08885312080383301
Epoch 0, Step 156: train/loss = 0.6705533266067505, train/raw-loss = 0.652815580368042, train/logprobs = tensor([[-0.6429, -0.7765],
        [-0.5700, -0.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08868909627199173
Epoch 0, Step 157: train/loss = 0.706710934638977, train/raw-loss = 0.6863788366317749, train/logprobs = tensor([[-0.7506, -0.8121],
        [-0.6606, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10166053473949432
Epoch 0, Step 158: train/loss = 0.6678135395050049, train/raw-loss = 0.646620512008667, train/logprobs = tensor([[-0.7076, -1.2425],
        [-0.5028, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10596509277820587
Epoch 0, Step 159: train/loss = 0.6896851062774658, train/raw-loss = 0.6684973239898682, train/logprobs = tensor([[-0.8726, -1.0662],
        [-0.7200, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593891888856888
Epoch 0, Step 160: train/loss = 0.5598652362823486, train/raw-loss = 0.5364618301391602, train/logprobs = tensor([[-1.1440, -2.3743],
        [-0.8765, -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11701703071594238
Epoch 0, Step 161: train/loss = 0.6385815143585205, train/raw-loss = 0.6219386458396912, train/logprobs = tensor([[-0.6864, -1.3498],
        [-0.5702, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08321435749530792
Epoch 0, Step 162: train/loss = 0.5821279883384705, train/raw-loss = 0.5657898187637329, train/logprobs = tensor([[-0.5967, -3.1458],
        [-0.5159, -2.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0816907063126564
Epoch 0, Step 163: train/loss = 0.5636078119277954, train/raw-loss = 0.5452903509140015, train/logprobs = tensor([[-0.5974, -2.2372],
        [-0.4408, -1.2798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09158730506896973
Epoch 0, Step 164: train/loss = 0.5884684324264526, train/raw-loss = 0.5719302892684937, train/logprobs = tensor([[-0.6894, -1.9053],
        [-0.5383, -1.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0826910063624382
Epoch 0, Step 165: train/loss = 0.5650684237480164, train/raw-loss = 0.5463442206382751, train/logprobs = tensor([[-0.6804, -2.2713],
        [-0.5064, -1.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09362093359231949
Epoch 0, Step 166: train/loss = 0.43459993600845337, train/raw-loss = 0.41821521520614624, train/logprobs = tensor([[-0.6638, -6.9736],
        [-0.4571, -4.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192368596792221
Epoch 0, Step 167: train/loss = 0.6295360326766968, train/raw-loss = 0.611035943031311, train/logprobs = tensor([[-0.7489, -1.5081],
        [-0.5866, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09250036627054214
Epoch 0, Step 168: train/loss = 0.6075542569160461, train/raw-loss = 0.5902836322784424, train/logprobs = tensor([[-0.7306, -1.6097],
        [-0.5430, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08635295927524567
Epoch 0, Step 169: train/loss = 0.6656268835067749, train/raw-loss = 0.6480723023414612, train/logprobs = tensor([[-0.8196, -1.3696],
        [-0.7367, -1.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777274936437607
Epoch 0, Step 170: train/loss = 0.5944726467132568, train/raw-loss = 0.5771947503089905, train/logprobs = tensor([[-0.6174, -1.7678],
        [-0.5683, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08638958632946014
Epoch 0, Step 171: train/loss = 0.6506418585777283, train/raw-loss = 0.6324186325073242, train/logprobs = tensor([[-0.6747, -1.4171],
        [-0.5320, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111645817756653
Epoch 0, Step 172: train/loss = 0.5079293251037598, train/raw-loss = 0.490842342376709, train/logprobs = tensor([[-0.6543, -2.7172],
        [-0.5846, -1.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08543487638235092
Epoch 0, Step 173: train/loss = 0.5486664772033691, train/raw-loss = 0.5331512689590454, train/logprobs = tensor([[-0.6418, -2.5672],
        [-0.5474, -1.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07757601886987686
Epoch 0, Step 174: train/loss = 0.5498278141021729, train/raw-loss = 0.5318005084991455, train/logprobs = tensor([[-0.7075, -2.1365],
        [-0.5472, -1.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09013660252094269
Epoch 0, Step 175: train/loss = 0.44876688718795776, train/raw-loss = 0.4336269795894623, train/logprobs = tensor([[-0.5277, -3.7795],
        [-0.4026, -2.0294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07569962739944458
Epoch 0, Step 176: train/loss = 0.6074323654174805, train/raw-loss = 0.5868110656738281, train/logprobs = tensor([[-0.7608, -1.7333],
        [-0.5012, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10310650616884232
Epoch 0, Step 177: train/loss = 0.5918281078338623, train/raw-loss = 0.5699709057807922, train/logprobs = tensor([[-1.1200, -2.6354],
        [-0.6606, -1.3398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10928589105606079
Epoch 0, Step 178: train/loss = 0.6222631931304932, train/raw-loss = 0.6016535758972168, train/logprobs = tensor([[-0.8859, -2.5463],
        [-0.7681, -1.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1030479222536087
Epoch 0, Step 179: train/loss = 0.6051353216171265, train/raw-loss = 0.5876115560531616, train/logprobs = tensor([[-0.6753, -2.5536],
        [-0.5215, -1.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08761890232563019
Epoch 0, Step 180: train/loss = 0.6999481916427612, train/raw-loss = 0.6792983412742615, train/logprobs = tensor([[-0.8688, -0.9436],
        [-0.6824, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10324904322624207
Epoch 0, Step 181: train/loss = 0.7252240777015686, train/raw-loss = 0.7069010734558105, train/logprobs = tensor([[-2.8888, -4.2757],
        [-1.9217, -2.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09161530435085297
Epoch 0, Step 182: train/loss = 0.6302557587623596, train/raw-loss = 0.6119437217712402, train/logprobs = tensor([[-0.5500, -1.3066],
        [-0.4669, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09156008064746857
Epoch 0, Step 183: train/loss = 0.5947693586349487, train/raw-loss = 0.5765610933303833, train/logprobs = tensor([[-0.7336, -1.8153],
        [-0.6040, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910411924123764
Epoch 0, Step 184: train/loss = 0.513745903968811, train/raw-loss = 0.49464571475982666, train/logprobs = tensor([[-1.2209, -4.3903],
        [-1.2022, -2.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550109505653381
Epoch 0, Step 185: train/loss = 0.6043113470077515, train/raw-loss = 0.5847316980361938, train/logprobs = tensor([[-0.8783, -2.1589],
        [-0.6995, -1.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09789817035198212
Epoch 0, Step 186: train/loss = 0.597427248954773, train/raw-loss = 0.573363721370697, train/logprobs = tensor([[-0.8487, -1.7451],
        [-0.7397, -1.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12031744420528412
Epoch 0, Step 187: train/loss = 0.5941462516784668, train/raw-loss = 0.5787913799285889, train/logprobs = tensor([[-0.6233, -2.3899],
        [-0.5031, -1.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07677458971738815
Epoch 0, Step 188: train/loss = 0.5271924138069153, train/raw-loss = 0.5084593296051025, train/logprobs = tensor([[-0.8904, -4.2623],
        [-0.6441, -2.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366539865732193
Epoch 0, Step 189: train/loss = 0.6720262765884399, train/raw-loss = 0.6555707454681396, train/logprobs = tensor([[-0.6227, -0.9273],
        [-0.5114, -0.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08227767795324326
Epoch 0, Step 190: train/loss = 0.5560029149055481, train/raw-loss = 0.5379257798194885, train/logprobs = tensor([[-0.8500, -3.8257],
        [-0.6255, -2.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038537740707397
Epoch 0, Step 191: train/loss = 0.6393863558769226, train/raw-loss = 0.621720016002655, train/logprobs = tensor([[-0.7106, -1.1904],
        [-0.6129, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0883316844701767
Epoch 0, Step 192: train/loss = 0.5770582556724548, train/raw-loss = 0.5482906103134155, train/logprobs = tensor([[-0.8014, -1.7383],
        [-0.5659, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14383840560913086
Epoch 0, Step 193: train/loss = 0.4891206920146942, train/raw-loss = 0.45963597297668457, train/logprobs = tensor([[-0.8275, -3.5237],
        [-0.6399, -1.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14742355048656464
Epoch 0, Step 194: train/loss = 0.5040177702903748, train/raw-loss = 0.4733516275882721, train/logprobs = tensor([[-0.9614, -4.1804],
        [-0.7437, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15333065390586853
Epoch 0, Step 195: train/loss = 0.5210728049278259, train/raw-loss = 0.4911932349205017, train/logprobs = tensor([[-0.8912, -3.7970],
        [-0.6312, -1.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14939793944358826
Epoch 0, Step 196: train/loss = 0.595848560333252, train/raw-loss = 0.56853848695755, train/logprobs = tensor([[-0.7611, -1.7407],
        [-0.5884, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13655030727386475
Epoch 0, Step 197: train/loss = 0.5453867316246033, train/raw-loss = 0.5179685354232788, train/logprobs = tensor([[-0.7534, -2.6715],
        [-0.5101, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13709086179733276
Epoch 0, Step 198: train/loss = 0.5827736258506775, train/raw-loss = 0.5548150539398193, train/logprobs = tensor([[-0.7210, -1.9863],
        [-0.5343, -0.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397928148508072
Epoch 0, Step 199: train/loss = 0.4568365812301636, train/raw-loss = 0.43165019154548645, train/logprobs = tensor([[-0.5617, -2.6599],
        [-0.3698, -0.7026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12593214213848114
Epoch 0, Step 200: train/loss = 0.5081328749656677, train/raw-loss = 0.48330938816070557, train/logprobs = tensor([[-0.9325, -2.4952],
        [-0.6363, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12411735951900482
Epoch 0, Step 201: train/loss = 0.5071006417274475, train/raw-loss = 0.47471314668655396, train/logprobs = tensor([[-1.0018, -3.6995],
        [-0.6684, -1.4699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16193757951259613
Epoch 0, Step 202: train/loss = 0.6144292950630188, train/raw-loss = 0.5877703428268433, train/logprobs = tensor([[-0.7447, -1.2872],
        [-0.6609, -0.6820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329485058784485
Epoch 0, Step 203: train/loss = 0.6075983047485352, train/raw-loss = 0.5776569843292236, train/logprobs = tensor([[-0.8506, -3.1504],
        [-0.5221, -1.3156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14970672130584717
Epoch 0, Step 204: train/loss = 0.5227341055870056, train/raw-loss = 0.49970361590385437, train/logprobs = tensor([[-0.9811, -2.3337],
        [-0.7267, -0.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11515254527330399
Epoch 0, Step 205: train/loss = 0.45046621561050415, train/raw-loss = 0.4261183440685272, train/logprobs = tensor([[-0.5944, -2.7193],
        [-0.5009, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12173952162265778
Epoch 0, Step 206: train/loss = 0.37031880021095276, train/raw-loss = 0.34673160314559937, train/logprobs = tensor([[-0.6540, -6.0415],
        [-0.5108, -1.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793582886457443
Epoch 0, Step 207: train/loss = 0.487133264541626, train/raw-loss = 0.4596961736679077, train/logprobs = tensor([[-1.0210, -2.6250],
        [-0.8074, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13718535006046295
Epoch 0, Step 208: train/loss = 0.49723827838897705, train/raw-loss = 0.472415030002594, train/logprobs = tensor([[-0.8473, -3.7856],
        [-0.5417, -1.2628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12411616742610931
Epoch 0, Step 209: train/loss = 0.5565047860145569, train/raw-loss = 0.5257014036178589, train/logprobs = tensor([[-0.8406, -2.4041],
        [-0.6502, -1.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15401694178581238
Epoch 0, Step 210: train/loss = 0.5511858463287354, train/raw-loss = 0.5268540978431702, train/logprobs = tensor([[-0.7409, -1.8459],
        [-0.5757, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12165871262550354
Epoch 0, Step 211: train/loss = 0.5961949825286865, train/raw-loss = 0.568989098072052, train/logprobs = tensor([[-1.1987, -4.4730],
        [-1.1248, -1.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360289454460144
Epoch 0, Step 212: train/loss = 0.6187907457351685, train/raw-loss = 0.5944012403488159, train/logprobs = tensor([[-0.5981, -1.4966],
        [-0.4658, -0.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194763123989105
Epoch 0, Step 213: train/loss = 0.6317838430404663, train/raw-loss = 0.6017038226127625, train/logprobs = tensor([[-0.7625, -1.4939],
        [-0.5227, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504000425338745
Epoch 0, Step 214: train/loss = 0.5316630601882935, train/raw-loss = 0.5046162605285645, train/logprobs = tensor([[-0.6830, -3.2373],
        [-0.5900, -1.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13523396849632263
Epoch 0, Step 215: train/loss = 0.5116855502128601, train/raw-loss = 0.48137366771698, train/logprobs = tensor([[-1.0205, -3.2485],
        [-0.8950, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15155938267707825
Epoch 0, Step 216: train/loss = 0.6212324500083923, train/raw-loss = 0.5943089723587036, train/logprobs = tensor([[-0.8923, -1.4712],
        [-0.5104, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1346176564693451
Epoch 0, Step 217: train/loss = 0.4890981614589691, train/raw-loss = 0.4619929790496826, train/logprobs = tensor([[-0.6666, -2.8513],
        [-0.5048, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13552595674991608
Epoch 0, Step 218: train/loss = 0.6871286034584045, train/raw-loss = 0.6649314165115356, train/logprobs = tensor([[-0.6790, -0.8608],
        [-0.5415, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098574101924896
Epoch 0, Step 219: train/loss = 0.5773479342460632, train/raw-loss = 0.5537835359573364, train/logprobs = tensor([[-0.7463, -2.0138],
        [-0.5672, -0.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11782205104827881
Epoch 0, Step 220: train/loss = 0.45372968912124634, train/raw-loss = 0.4255464971065521, train/logprobs = tensor([[-1.2294, -4.1666],
        [-0.8336, -1.3511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14091578125953674
Epoch 0, Step 221: train/loss = 0.5214986801147461, train/raw-loss = 0.5011570453643799, train/logprobs = tensor([[-0.5134, -4.4060],
        [-0.4220, -1.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10170818120241165
Epoch 0, Step 222: train/loss = 0.5755801796913147, train/raw-loss = 0.5524864792823792, train/logprobs = tensor([[-0.7405, -2.2894],
        [-0.5234, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11546842008829117
Epoch 0, Step 223: train/loss = 0.5845038890838623, train/raw-loss = 0.5596097111701965, train/logprobs = tensor([[-0.9251, -2.3649],
        [-0.6482, -0.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12447100132703781
Epoch 0, Step 224: train/loss = 0.5715837478637695, train/raw-loss = 0.5442335605621338, train/logprobs = tensor([[-0.8014, -1.7720],
        [-0.6576, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13675105571746826
Epoch 0, Step 225: train/loss = 0.5883682370185852, train/raw-loss = 0.5682339668273926, train/logprobs = tensor([[-0.6989, -1.7432],
        [-0.4248, -0.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10067129135131836
Epoch 0, Step 226: train/loss = 0.9537432789802551, train/raw-loss = 0.9305484890937805, train/logprobs = tensor([[-2.5022, -3.7538],
        [-0.6805, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11597408354282379
Epoch 0, Step 227: train/loss = 0.4994390606880188, train/raw-loss = 0.469587504863739, train/logprobs = tensor([[-1.2095, -3.8916],
        [-0.5575, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492578238248825
Epoch 0, Step 228: train/loss = 0.5504398941993713, train/raw-loss = 0.5301323533058167, train/logprobs = tensor([[-0.6291, -2.3156],
        [-0.4165, -1.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10153751075267792
Epoch 0, Step 229: train/loss = 0.43155479431152344, train/raw-loss = 0.40478137135505676, train/logprobs = tensor([[-1.0371, -5.7913],
        [-0.8617, -2.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386720418930054
Epoch 0, Step 230: train/loss = 0.45196589827537537, train/raw-loss = 0.4243239164352417, train/logprobs = tensor([[-1.2699, -3.7825],
        [-1.1197, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13821011781692505
Epoch 0, Step 231: train/loss = 0.43117910623550415, train/raw-loss = 0.4083347022533417, train/logprobs = tensor([[-0.7238, -4.7193],
        [-0.6703, -0.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11422208696603775
Epoch 0, Step 232: train/loss = 0.5365109443664551, train/raw-loss = 0.5148804187774658, train/logprobs = tensor([[-0.6670, -2.7282],
        [-0.5890, -1.3999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10815265774726868
Epoch 0, Step 233: train/loss = 0.641786515712738, train/raw-loss = 0.6179618239402771, train/logprobs = tensor([[-1.4191, -5.6715],
        [-0.8104, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11912340670824051
Epoch 0, Step 234: train/loss = 0.6214583516120911, train/raw-loss = 0.6009661555290222, train/logprobs = tensor([[-0.6648, -1.2459],
        [-0.4969, -0.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10246110707521439
Epoch 0, Step 235: train/loss = 0.4871312081813812, train/raw-loss = 0.4621927738189697, train/logprobs = tensor([[-1.0869, -5.0168],
        [-0.5568, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12469233572483063
Epoch 0, Step 236: train/loss = 0.5862141847610474, train/raw-loss = 0.5571283102035522, train/logprobs = tensor([[-0.7964, -2.3089],
        [-0.6191, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14542937278747559
Epoch 0, Step 237: train/loss = 0.5263282656669617, train/raw-loss = 0.4990032911300659, train/logprobs = tensor([[-0.8104, -2.3894],
        [-0.6407, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13662469387054443
Epoch 0, Step 238: train/loss = 0.47334587574005127, train/raw-loss = 0.4512341022491455, train/logprobs = tensor([[-0.6350, -2.8865],
        [-0.4856, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11055859178304672
Epoch 0, Step 239: train/loss = 0.6542370319366455, train/raw-loss = 0.6316099762916565, train/logprobs = tensor([[-0.8922, -1.2391],
        [-0.5491, -0.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11313536763191223
Epoch 0, Step 240: train/loss = 0.6234356164932251, train/raw-loss = 0.5921779870986938, train/logprobs = tensor([[-1.2386, -2.9123],
        [-1.1162, -1.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15628796815872192
Epoch 0, Step 241: train/loss = 0.49370071291923523, train/raw-loss = 0.46953344345092773, train/logprobs = tensor([[-0.5891, -2.1622],
        [-0.5280, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12083633244037628
Epoch 0, Step 242: train/loss = 0.6214132905006409, train/raw-loss = 0.6003584861755371, train/logprobs = tensor([[-0.6253, -1.1687],
        [-0.4040, -0.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10527405142784119
Epoch 0, Step 243: train/loss = 0.6448187828063965, train/raw-loss = 0.6221932172775269, train/logprobs = tensor([[-0.8902, -1.3189],
        [-0.4912, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11312791705131531
Epoch 0, Step 244: train/loss = 0.5079277753829956, train/raw-loss = 0.47923189401626587, train/logprobs = tensor([[-1.1545, -4.3368],
        [-0.6507, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14347916841506958
Epoch 0, Step 245: train/loss = 0.5456050634384155, train/raw-loss = 0.5196858644485474, train/logprobs = tensor([[-1.2284, -2.7851],
        [-0.6124, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12959599494934082
Epoch 0, Step 246: train/loss = 0.449451208114624, train/raw-loss = 0.4244810938835144, train/logprobs = tensor([[-0.7237, -4.4740],
        [-0.6763, -1.6242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12485057860612869
Epoch 0, Step 247: train/loss = 0.5599263906478882, train/raw-loss = 0.5315709114074707, train/logprobs = tensor([[-1.0325, -2.8089],
        [-0.7356, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14177733659744263
Epoch 0, Step 248: train/loss = 0.6018699407577515, train/raw-loss = 0.5783187747001648, train/logprobs = tensor([[-0.7173, -2.0658],
        [-0.6883, -1.3689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1177556961774826
Epoch 0, Step 249: train/loss = 0.5224974155426025, train/raw-loss = 0.5011723041534424, train/logprobs = tensor([[-0.5042, -2.5748],
        [-0.5082, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10662546753883362
Epoch 0, Step 250: train/loss = 0.5186857581138611, train/raw-loss = 0.4938862919807434, train/logprobs = tensor([[-1.3526, -5.0006],
        [-0.5644, -1.2440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12399731576442719
Epoch 0, Step 251: train/loss = 0.39786309003829956, train/raw-loss = 0.3744712471961975, train/logprobs = tensor([[-0.7072, -3.3899],
        [-0.6096, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11695928871631622
Epoch 0, Step 252: train/loss = 0.5558991432189941, train/raw-loss = 0.5331222414970398, train/logprobs = tensor([[-0.5435, -1.8457],
        [-0.4290, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11388442665338516
Epoch 0, Step 253: train/loss = 0.7154535055160522, train/raw-loss = 0.6932056546211243, train/logprobs = tensor([[-0.8330, -0.7138],
        [-0.6346, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11123930662870407
Epoch 0, Step 254: train/loss = 0.4648135304450989, train/raw-loss = 0.4409165382385254, train/logprobs = tensor([[-0.8486, -3.8053],
        [-0.5640, -1.0195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11948496848344803
Epoch 0, Step 255: train/loss = 0.5741624236106873, train/raw-loss = 0.5469694137573242, train/logprobs = tensor([[-1.1758, -2.8913],
        [-0.8980, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13596504926681519
Epoch 0, Step 256: train/loss = 0.6680340766906738, train/raw-loss = 0.6476202011108398, train/logprobs = tensor([[-0.6147, -0.9443],
        [-0.4291, -0.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10206903517246246
Epoch 0, Step 257: train/loss = 0.6480592489242554, train/raw-loss = 0.6245197057723999, train/logprobs = tensor([[-0.8408, -1.4235],
        [-0.6023, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11769785732030869
Epoch 0, Step 258: train/loss = 0.3829687237739563, train/raw-loss = 0.3535952568054199, train/logprobs = tensor([[-1.0687, -3.8922],
        [-0.9409, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14686715602874756
Epoch 0, Step 259: train/loss = 0.5329294204711914, train/raw-loss = 0.511115550994873, train/logprobs = tensor([[-0.6341, -3.9814],
        [-0.4956, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906920582056046
Epoch 0, Step 260: train/loss = 0.44944268465042114, train/raw-loss = 0.4268074035644531, train/logprobs = tensor([[-0.5877, -4.8994],
        [-0.4623, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11317618191242218
Epoch 0, Step 261: train/loss = 0.4715304374694824, train/raw-loss = 0.44502532482147217, train/logprobs = tensor([[-0.8837, -2.5030],
        [-0.8238, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13252553343772888
Epoch 0, Step 262: train/loss = 0.5559948682785034, train/raw-loss = 0.5267513990402222, train/logprobs = tensor([[-0.7757, -2.7505],
        [-0.6373, -1.3569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14621731638908386
Epoch 0, Step 263: train/loss = 0.622810959815979, train/raw-loss = 0.593063473701477, train/logprobs = tensor([[-1.4728, -2.4025],
        [-1.1158, -1.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1487373262643814
Epoch 0, Step 264: train/loss = 0.6061967015266418, train/raw-loss = 0.5808395147323608, train/logprobs = tensor([[-0.7941, -1.5662],
        [-0.6910, -0.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1267857551574707
Epoch 0, Step 265: train/loss = 0.6572115421295166, train/raw-loss = 0.633676290512085, train/logprobs = tensor([[-0.9597, -1.4649],
        [-0.6233, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767639219760895
Epoch 0, Step 266: train/loss = 0.43250972032546997, train/raw-loss = 0.40496987104415894, train/logprobs = tensor([[-1.1303, -4.0504],
        [-0.9826, -1.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13769929111003876
Epoch 0, Step 267: train/loss = 0.4636329412460327, train/raw-loss = 0.4404003620147705, train/logprobs = tensor([[-0.7485, -2.8454],
        [-0.5362, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11616310477256775
Epoch 0, Step 268: train/loss = 0.5142120122909546, train/raw-loss = 0.4896238446235657, train/logprobs = tensor([[-0.7010, -5.4277],
        [-0.6676, -1.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294125556945801
Epoch 0, Step 269: train/loss = 0.5142555832862854, train/raw-loss = 0.4907814562320709, train/logprobs = tensor([[-0.8405, -4.1444],
        [-0.7141, -1.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11737057566642761
Epoch 0, Step 270: train/loss = 0.49273091554641724, train/raw-loss = 0.4713093638420105, train/logprobs = tensor([[-0.4482, -2.4674],
        [-0.3453, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1071079671382904
Epoch 0, Step 271: train/loss = 0.5142842531204224, train/raw-loss = 0.4902992248535156, train/logprobs = tensor([[-0.8596, -2.3785],
        [-0.6673, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11992529034614563
Epoch 0, Step 272: train/loss = 0.6704822182655334, train/raw-loss = 0.6483997106552124, train/logprobs = tensor([[-0.6506, -0.9259],
        [-0.5522, -0.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11041224002838135
Epoch 0, Step 273: train/loss = 0.5687135457992554, train/raw-loss = 0.5467259883880615, train/logprobs = tensor([[-0.5060, -1.4542],
        [-0.5078, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10993780195713043
Epoch 0, Step 274: train/loss = 0.5885992050170898, train/raw-loss = 0.5633097290992737, train/logprobs = tensor([[-0.6298, -1.8717],
        [-0.5016, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12644734978675842
Epoch 0, Step 275: train/loss = 0.48300784826278687, train/raw-loss = 0.4625356197357178, train/logprobs = tensor([[-0.5179, -2.1308],
        [-0.4338, -0.5225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236092656850815
Epoch 0, Step 276: train/loss = 0.5720882415771484, train/raw-loss = 0.5407670140266418, train/logprobs = tensor([[-1.3716, -2.8462],
        [-1.0947, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15660598874092102
Epoch 0, Step 277: train/loss = 0.6122351884841919, train/raw-loss = 0.5814639925956726, train/logprobs = tensor([[-0.8519, -1.3571],
        [-0.7985, -0.7551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15385591983795166
Epoch 0, Step 278: train/loss = 0.5418164730072021, train/raw-loss = 0.5136663913726807, train/logprobs = tensor([[-0.8858, -1.7429],
        [-0.6834, -0.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14075034856796265
Epoch 0, Step 279: train/loss = 0.4330763816833496, train/raw-loss = 0.40481558442115784, train/logprobs = tensor([[-1.0825, -4.5431],
        [-0.7221, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14130406081676483
Epoch 0, Step 280: train/loss = 0.5128059387207031, train/raw-loss = 0.48835688829421997, train/logprobs = tensor([[-0.8917, -4.6217],
        [-0.6088, -1.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1222454160451889
Epoch 0, Step 281: train/loss = 0.5588761568069458, train/raw-loss = 0.5378201603889465, train/logprobs = tensor([[-0.5974, -1.3593],
        [-0.4718, -0.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10528028011322021
Epoch 0, Step 282: train/loss = 0.5812144875526428, train/raw-loss = 0.5426226258277893, train/logprobs = tensor([[-1.4342, -3.7432],
        [-0.8596, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19295930862426758
Epoch 0, Step 283: train/loss = 0.5075264573097229, train/raw-loss = 0.48374247550964355, train/logprobs = tensor([[-0.8581, -2.5738],
        [-0.6120, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11891994625329971
Epoch 0, Step 284: train/loss = 0.5482454895973206, train/raw-loss = 0.5283664464950562, train/logprobs = tensor([[-0.5159, -1.5707],
        [-0.4735, -0.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939513355493546
Epoch 0, Step 285: train/loss = 0.5882896184921265, train/raw-loss = 0.5625739097595215, train/logprobs = tensor([[-0.6163, -1.3090],
        [-0.5663, -0.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12857818603515625
Epoch 0, Step 286: train/loss = 0.5155157446861267, train/raw-loss = 0.49382877349853516, train/logprobs = tensor([[-0.4414, -1.9742],
        [-0.3343, -0.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1084347516298294
Epoch 0, Step 287: train/loss = 0.5067381262779236, train/raw-loss = 0.47722581028938293, train/logprobs = tensor([[-0.8458, -4.2307],
        [-0.7595, -1.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14756137132644653
Epoch 0, Step 288: train/loss = 0.5352277755737305, train/raw-loss = 0.5108110308647156, train/logprobs = tensor([[-0.6111, -1.8726],
        [-0.6038, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12208385765552521
Epoch 0, Step 289: train/loss = 0.513098955154419, train/raw-loss = 0.4869849383831024, train/logprobs = tensor([[-0.8956, -3.4578],
        [-0.7477, -1.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1305702030658722
Epoch 0, Step 290: train/loss = 0.5124801397323608, train/raw-loss = 0.48670774698257446, train/logprobs = tensor([[-0.5974, -3.1315],
        [-0.5508, -1.5421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12886178493499756
Epoch 0, Step 291: train/loss = 0.4395691156387329, train/raw-loss = 0.41372910141944885, train/logprobs = tensor([[-0.7529, -2.5784],
        [-0.7491, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292000114917755
Epoch 0, Step 292: train/loss = 0.5397647023200989, train/raw-loss = 0.5141836404800415, train/logprobs = tensor([[-0.6440, -1.5881],
        [-0.6722, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279052197933197
Epoch 0, Step 293: train/loss = 0.5284781455993652, train/raw-loss = 0.500634491443634, train/logprobs = tensor([[-0.8255, -2.4810],
        [-0.7309, -1.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13921821117401123
Epoch 0, Step 294: train/loss = 0.5494225025177002, train/raw-loss = 0.5242388248443604, train/logprobs = tensor([[-1.0125, -2.0028],
        [-0.7633, -0.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12591849267482758
Epoch 0, Step 295: train/loss = 0.5243996977806091, train/raw-loss = 0.4949784576892853, train/logprobs = tensor([[-1.6283, -3.3176],
        [-1.4331, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14710618555545807
Epoch 0, Step 296: train/loss = 0.56259685754776, train/raw-loss = 0.5399901866912842, train/logprobs = tensor([[-0.7488, -2.0876],
        [-0.6591, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11303345859050751
Epoch 0, Step 297: train/loss = 0.44629260897636414, train/raw-loss = 0.4206188917160034, train/logprobs = tensor([[-0.6547, -3.7806],
        [-0.6657, -1.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836861610412598
Epoch 0, Step 298: train/loss = 0.5216971039772034, train/raw-loss = 0.5017057657241821, train/logprobs = tensor([[-0.6062, -1.7556],
        [-0.6724, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995683282613754
Epoch 0, Step 299: train/loss = 0.46149274706840515, train/raw-loss = 0.43686777353286743, train/logprobs = tensor([[-1.0765, -3.2659],
        [-0.9730, -0.6756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12312489748001099
Epoch 0, Step 300: train/loss = 0.504127562046051, train/raw-loss = 0.4796094298362732, train/logprobs = tensor([[-0.7852, -2.8162],
        [-0.8111, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12259082496166229
Epoch 0, Step 301: train/loss = 0.5521144866943359, train/raw-loss = 0.5291853547096252, train/logprobs = tensor([[-0.6866, -1.4138],
        [-0.6031, -0.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11464560031890869
Epoch 0, Step 302: train/loss = 0.4749632477760315, train/raw-loss = 0.4499334990978241, train/logprobs = tensor([[-0.6895, -2.5170],
        [-0.6161, -0.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12514878809452057
Epoch 0, Step 303: train/loss = 0.43358153104782104, train/raw-loss = 0.4076133072376251, train/logprobs = tensor([[-0.5774, -3.1011],
        [-0.5785, -0.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12984107434749603
Epoch 0, Step 304: train/loss = 0.5317813754081726, train/raw-loss = 0.507607638835907, train/logprobs = tensor([[-0.6633, -1.8877],
        [-0.6354, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12086859345436096
Epoch 0, Step 305: train/loss = 0.5339354872703552, train/raw-loss = 0.5094523429870605, train/logprobs = tensor([[-0.9746, -3.1393],
        [-0.5489, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241579592227936
Epoch 0, Step 306: train/loss = 0.5690203309059143, train/raw-loss = 0.5425156354904175, train/logprobs = tensor([[-0.8448, -3.6791],
        [-0.6949, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325235366821289
Epoch 0, Step 307: train/loss = 0.5424171686172485, train/raw-loss = 0.514249324798584, train/logprobs = tensor([[-0.9004, -4.1404],
        [-0.8671, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408393681049347
Epoch 0, Step 308: train/loss = 0.574981153011322, train/raw-loss = 0.5516140460968018, train/logprobs = tensor([[-0.7480, -1.5387],
        [-0.6395, -0.6930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11683554947376251
Epoch 0, Step 309: train/loss = 0.5746495723724365, train/raw-loss = 0.552483856678009, train/logprobs = tensor([[-0.5533, -1.6028],
        [-0.4714, -0.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11082857847213745
Epoch 0, Step 310: train/loss = 0.39469248056411743, train/raw-loss = 0.3671652674674988, train/logprobs = tensor([[-0.7388, -4.7122],
        [-0.5414, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376359462738037
Epoch 0, Step 311: train/loss = 0.5389434695243835, train/raw-loss = 0.5161356925964355, train/logprobs = tensor([[-0.5969, -2.7848],
        [-0.6051, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11403888463973999
Epoch 0, Step 312: train/loss = 0.5795184373855591, train/raw-loss = 0.5559372305870056, train/logprobs = tensor([[-0.6913, -3.4207],
        [-0.5058, -1.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11790608614683151
Epoch 0, Step 313: train/loss = 0.4751354455947876, train/raw-loss = 0.4482288360595703, train/logprobs = tensor([[-0.6773, -2.5923],
        [-0.6457, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13453300297260284
Epoch 0, Step 314: train/loss = 0.6125112771987915, train/raw-loss = 0.5902215242385864, train/logprobs = tensor([[-0.6573, -0.9807],
        [-0.6106, -0.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11144888401031494
Epoch 0, Step 315: train/loss = 0.5852861404418945, train/raw-loss = 0.5580218434333801, train/logprobs = tensor([[-2.1101, -4.0404],
        [-1.5549, -1.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13632148504257202
Epoch 0, Step 316: train/loss = 0.6939852237701416, train/raw-loss = 0.6699861288070679, train/logprobs = tensor([[-0.7847, -0.7464],
        [-0.7855, -0.6435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11999562382698059
Epoch 0, Step 317: train/loss = 0.4211134910583496, train/raw-loss = 0.3976202607154846, train/logprobs = tensor([[-0.4962, -4.8723],
        [-0.4914, -1.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11746615171432495
Epoch 0, Step 318: train/loss = 0.44864901900291443, train/raw-loss = 0.4246889054775238, train/logprobs = tensor([[-0.8000, -3.0325],
        [-0.7427, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1198006272315979
Epoch 0, Step 319: train/loss = 0.4647490084171295, train/raw-loss = 0.4417474865913391, train/logprobs = tensor([[-0.5839, -2.9775],
        [-0.5854, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11500748991966248
Epoch 0, Step 320: train/loss = 0.5181125998497009, train/raw-loss = 0.49538201093673706, train/logprobs = tensor([[-0.9005, -2.8506],
        [-0.6709, -0.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11365299671888351
Epoch 0, Step 321: train/loss = 0.5383272767066956, train/raw-loss = 0.5187892913818359, train/logprobs = tensor([[-0.6698, -1.8043],
        [-0.6357, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09769010543823242
Epoch 0, Step 322: train/loss = 0.448912113904953, train/raw-loss = 0.42727071046829224, train/logprobs = tensor([[-1.0534, -4.0833],
        [-0.9069, -1.4606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10820698738098145
Epoch 0, Step 323: train/loss = 0.49580779671669006, train/raw-loss = 0.47484731674194336, train/logprobs = tensor([[-0.4561, -2.4353],
        [-0.4535, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10480239987373352
Epoch 0, Step 324: train/loss = 0.3626001179218292, train/raw-loss = 0.3390312194824219, train/logprobs = tensor([[-0.8415, -5.5742],
        [-0.6775, -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784455180168152
Epoch 0, Step 325: train/loss = 0.6082732677459717, train/raw-loss = 0.5873669385910034, train/logprobs = tensor([[-0.6537, -1.2453],
        [-0.5968, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045314371585846
Epoch 0, Step 326: train/loss = 0.39507198333740234, train/raw-loss = 0.3714159429073334, train/logprobs = tensor([[-0.9208, -5.0332],
        [-1.0383, -1.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182803213596344
Epoch 0, Step 327: train/loss = 0.7090709209442139, train/raw-loss = 0.6787546277046204, train/logprobs = tensor([[-0.9111, -1.1445],
        [-0.6855, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515815258026123
Epoch 0, Step 328: train/loss = 0.6113417148590088, train/raw-loss = 0.589101254940033, train/logprobs = tensor([[-0.9035, -1.7948],
        [-0.8607, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11120237410068512
Epoch 0, Step 329: train/loss = 0.5921549797058105, train/raw-loss = 0.5687713623046875, train/logprobs = tensor([[-1.1362, -1.6844],
        [-0.8953, -0.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11691799759864807
Epoch 0, Step 330: train/loss = 0.34549808502197266, train/raw-loss = 0.322971910238266, train/logprobs = tensor([[-0.7235, -4.6129],
        [-0.6704, -1.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11263081431388855
Epoch 0, Step 331: train/loss = 0.4631772041320801, train/raw-loss = 0.4447309374809265, train/logprobs = tensor([[-0.6618, -4.1520],
        [-0.6262, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09223122894763947
Epoch 0, Step 332: train/loss = 0.409294068813324, train/raw-loss = 0.3847227692604065, train/logprobs = tensor([[-0.8262, -4.0383],
        [-0.9093, -1.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1228565126657486
Epoch 0, Step 333: train/loss = 0.5101112723350525, train/raw-loss = 0.48776984214782715, train/logprobs = tensor([[-0.8295, -2.8774],
        [-0.6342, -1.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170703172683716
Epoch 0, Step 334: train/loss = 0.6358162760734558, train/raw-loss = 0.6150809526443481, train/logprobs = tensor([[-0.7727, -0.9846],
        [-0.6623, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10367682576179504
Epoch 0, Step 335: train/loss = 0.43824028968811035, train/raw-loss = 0.41597720980644226, train/logprobs = tensor([[-0.6861, -2.5428],
        [-0.5765, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11131531000137329
Epoch 0, Step 336: train/loss = 0.5164361596107483, train/raw-loss = 0.4928673505783081, train/logprobs = tensor([[-0.5816, -1.8171],
        [-0.6213, -0.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784402281045914
Epoch 0, Step 337: train/loss = 0.49793121218681335, train/raw-loss = 0.4724343419075012, train/logprobs = tensor([[-0.9366, -2.3847],
        [-0.8791, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12748438119888306
Epoch 0, Step 338: train/loss = 0.5015978217124939, train/raw-loss = 0.47965529561042786, train/logprobs = tensor([[-0.5925, -1.8135],
        [-0.5689, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10971257090568542
Epoch 0, Step 339: train/loss = 0.44776642322540283, train/raw-loss = 0.42910903692245483, train/logprobs = tensor([[-0.3912, -4.3553],
        [-0.4081, -1.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09328673779964447
Epoch 0, Step 340: train/loss = 0.6094158887863159, train/raw-loss = 0.5890868902206421, train/logprobs = tensor([[-0.8787, -1.5149],
        [-0.7386, -0.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10164474695920944
Epoch 0, Step 341: train/loss = 0.38196834921836853, train/raw-loss = 0.36019253730773926, train/logprobs = tensor([[-0.6534, -3.3754],
        [-0.6997, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10887910425662994
Epoch 0, Step 342: train/loss = 0.4960384666919708, train/raw-loss = 0.476158082485199, train/logprobs = tensor([[-0.5984, -2.8735],
        [-0.6345, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09940197318792343
Epoch 0, Step 343: train/loss = 0.5718501806259155, train/raw-loss = 0.5502015352249146, train/logprobs = tensor([[-0.7114, -2.1556],
        [-0.6946, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1082429587841034
Epoch 0, Step 344: train/loss = 0.4322989583015442, train/raw-loss = 0.4087294042110443, train/logprobs = tensor([[-1.0255, -5.8519],
        [-0.8484, -1.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784759908914566
Epoch 0, Step 345: train/loss = 0.48892030119895935, train/raw-loss = 0.46507900953292847, train/logprobs = tensor([[-1.2512, -4.2049],
        [-1.1667, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920656263828278
Epoch 0, Step 346: train/loss = 0.5066975951194763, train/raw-loss = 0.4813699722290039, train/logprobs = tensor([[-0.8307, -3.9696],
        [-0.7630, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266380101442337
Epoch 0, Step 347: train/loss = 0.49815335869789124, train/raw-loss = 0.4781857430934906, train/logprobs = tensor([[-0.6425, -4.3765],
        [-0.6613, -1.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09983804821968079
Epoch 0, Step 348: train/loss = 0.51474928855896, train/raw-loss = 0.494642436504364, train/logprobs = tensor([[-0.7735, -3.3483],
        [-0.8020, -1.0438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10053414851427078
Epoch 0, Step 349: train/loss = 0.39590930938720703, train/raw-loss = 0.37094175815582275, train/logprobs = tensor([[-0.7536, -3.1564],
        [-0.7591, -0.9007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12483781576156616
Epoch 0, Step 350: train/loss = 0.5941276550292969, train/raw-loss = 0.566394567489624, train/logprobs = tensor([[-1.3503, -2.7042],
        [-1.0678, -1.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13866542279720306
Epoch 0, Step 351: train/loss = 0.5163349509239197, train/raw-loss = 0.4929480254650116, train/logprobs = tensor([[-0.7889, -2.6801],
        [-0.7615, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11693458259105682
Epoch 0, Step 352: train/loss = 0.4366586208343506, train/raw-loss = 0.41772669553756714, train/logprobs = tensor([[-0.5226, -3.8501],
        [-0.6155, -1.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09465942531824112
Epoch 0, Step 353: train/loss = 0.3917931020259857, train/raw-loss = 0.3676005005836487, train/logprobs = tensor([[-0.7450, -4.5899],
        [-0.8880, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12096293270587921
Epoch 0, Step 354: train/loss = 0.6183261871337891, train/raw-loss = 0.5981972813606262, train/logprobs = tensor([[-0.5028, -1.0129],
        [-0.5466, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10064460337162018
Epoch 0, Step 355: train/loss = 0.5072659850120544, train/raw-loss = 0.48300701379776, train/logprobs = tensor([[-0.7596, -2.5206],
        [-0.8313, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12129499763250351
Epoch 0, Step 356: train/loss = 0.6136345267295837, train/raw-loss = 0.5907933115959167, train/logprobs = tensor([[-0.5382, -1.1214],
        [-0.5144, -0.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11420609802007675
Epoch 0, Step 357: train/loss = 0.6501682996749878, train/raw-loss = 0.6220365762710571, train/logprobs = tensor([[-1.9962, -2.6206],
        [-1.6352, -1.8161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14065882563591003
Epoch 0, Step 358: train/loss = 0.5204081535339355, train/raw-loss = 0.5020453929901123, train/logprobs = tensor([[-0.5527, -4.0838],
        [-0.5167, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181360900402069
Epoch 0, Step 359: train/loss = 0.5737943649291992, train/raw-loss = 0.5496114492416382, train/logprobs = tensor([[-0.9737, -2.0859],
        [-0.8905, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12091460824012756
Epoch 0, Step 360: train/loss = 0.5316125154495239, train/raw-loss = 0.5060983896255493, train/logprobs = tensor([[-0.9467, -2.6643],
        [-0.8707, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12757039070129395
Epoch 0, Step 361: train/loss = 0.5521339178085327, train/raw-loss = 0.5275519490242004, train/logprobs = tensor([[-0.6667, -1.3129],
        [-0.7284, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1229097843170166
Epoch 0, Step 362: train/loss = 0.5876752734184265, train/raw-loss = 0.5655373334884644, train/logprobs = tensor([[-0.7154, -1.8548],
        [-0.7196, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11068938672542572
Epoch 0, Step 363: train/loss = 0.7314110994338989, train/raw-loss = 0.7112101912498474, train/logprobs = tensor([[-1.3215, -1.2097],
        [-0.9340, -0.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10100424289703369
Epoch 0, Step 364: train/loss = 0.3895874619483948, train/raw-loss = 0.3684048354625702, train/logprobs = tensor([[-0.4383, -5.2915],
        [-0.5678, -1.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10591304302215576
Epoch 0, Step 365: train/loss = 0.4240875840187073, train/raw-loss = 0.4027281403541565, train/logprobs = tensor([[-0.5802, -2.6886],
        [-0.6321, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10679718106985092
Epoch 0, Step 366: train/loss = 0.5233345627784729, train/raw-loss = 0.501078724861145, train/logprobs = tensor([[-0.6206, -2.7437],
        [-0.6169, -0.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127916723489761
Epoch 0, Step 367: train/loss = 0.4304414391517639, train/raw-loss = 0.4086567163467407, train/logprobs = tensor([[-0.6248, -3.4749],
        [-0.7173, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10892361402511597
Epoch 0, Step 368: train/loss = 0.4708032011985779, train/raw-loss = 0.44915974140167236, train/logprobs = tensor([[-0.4411, -2.5795],
        [-0.4556, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10821712762117386
Epoch 0, Step 369: train/loss = 0.4890846014022827, train/raw-loss = 0.4682302176952362, train/logprobs = tensor([[-0.4599, -1.9714],
        [-0.5579, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10427182167768478
Epoch 0, Step 370: train/loss = 0.6391705274581909, train/raw-loss = 0.6204559206962585, train/logprobs = tensor([[-0.4320, -0.8437],
        [-0.4445, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09357310831546783
Epoch 0, Step 371: train/loss = 0.4873400330543518, train/raw-loss = 0.46831607818603516, train/logprobs = tensor([[-0.4484, -3.3568],
        [-0.4816, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09511979669332504
Epoch 0, Step 372: train/loss = 0.4294079542160034, train/raw-loss = 0.4114062190055847, train/logprobs = tensor([[-0.5682, -3.3021],
        [-0.5785, -0.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09000864624977112
Epoch 0, Step 373: train/loss = 0.5287148952484131, train/raw-loss = 0.5028893351554871, train/logprobs = tensor([[-0.8659, -4.4319],
        [-0.7530, -1.4854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12912775576114655
Epoch 0, Step 374: train/loss = 0.5172567367553711, train/raw-loss = 0.498471200466156, train/logprobs = tensor([[-0.3310, -2.3224],
        [-0.3652, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09392766654491425
Epoch 0, Step 375: train/loss = 0.4993496537208557, train/raw-loss = 0.4749225080013275, train/logprobs = tensor([[-0.7878, -1.6529],
        [-0.9833, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12213555723428726
Epoch 0, Step 376: train/loss = 0.41180914640426636, train/raw-loss = 0.387157142162323, train/logprobs = tensor([[-0.6666, -4.7417],
        [-0.8829, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12325994670391083
Epoch 0, Step 377: train/loss = 0.5655280351638794, train/raw-loss = 0.5409709215164185, train/logprobs = tensor([[-0.6811, -2.8997],
        [-0.6098, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12278559058904648
Epoch 0, Step 378: train/loss = 0.5296245813369751, train/raw-loss = 0.5091758966445923, train/logprobs = tensor([[-0.7515, -3.6888],
        [-0.7272, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10224319994449615
Epoch 0, Step 379: train/loss = 0.5987932085990906, train/raw-loss = 0.5751799941062927, train/logprobs = tensor([[-0.9829, -2.1643],
        [-0.8989, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806593835353851
Epoch 0, Step 380: train/loss = 0.5058451294898987, train/raw-loss = 0.4820070266723633, train/logprobs = tensor([[-0.6353, -1.9783],
        [-0.6704, -0.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11919065564870834
Epoch 0, Step 381: train/loss = 0.4358713924884796, train/raw-loss = 0.4094119668006897, train/logprobs = tensor([[-0.7170, -3.8055],
        [-0.9424, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13229724764823914
Epoch 0, Step 382: train/loss = 0.3834558427333832, train/raw-loss = 0.36324143409729004, train/logprobs = tensor([[-0.6158, -3.8013],
        [-0.6259, -0.8116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1010720282793045
Epoch 0, Step 383: train/loss = 0.4214354157447815, train/raw-loss = 0.39805367588996887, train/logprobs = tensor([[-0.4928, -2.6565],
        [-0.6357, -0.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169087290763855
Epoch 0, Step 384: train/loss = 0.4738028347492218, train/raw-loss = 0.4466381072998047, train/logprobs = tensor([[-0.8266, -5.8323],
        [-1.0018, -1.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358235776424408
Epoch 0, Step 385: train/loss = 0.5735738277435303, train/raw-loss = 0.5405727028846741, train/logprobs = tensor([[-1.2898, -2.2547],
        [-1.0996, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16500551998615265
Epoch 0, Step 386: train/loss = 0.6914978623390198, train/raw-loss = 0.6670738458633423, train/logprobs = tensor([[-0.8955, -0.9215],
        [-0.7767, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12212017923593521
Epoch 0, Step 387: train/loss = 0.4783764183521271, train/raw-loss = 0.451711505651474, train/logprobs = tensor([[-0.6994, -5.0629],
        [-0.9030, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13332462310791016
Epoch 0, Step 388: train/loss = 0.5237458944320679, train/raw-loss = 0.49320369958877563, train/logprobs = tensor([[-0.7595, -2.4112],
        [-0.8586, -1.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15271103382110596
Epoch 0, Step 389: train/loss = 0.43727439641952515, train/raw-loss = 0.4084882438182831, train/logprobs = tensor([[-0.6492, -2.7328],
        [-0.7194, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14393073320388794
Epoch 0, Step 390: train/loss = 0.45475393533706665, train/raw-loss = 0.42388099431991577, train/logprobs = tensor([[-1.1084, -2.6790],
        [-1.4134, -1.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15436473488807678
Epoch 0, Step 391: train/loss = 0.5156035423278809, train/raw-loss = 0.489596426486969, train/logprobs = tensor([[-0.5009, -2.0410],
        [-0.5585, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13003547489643097
Epoch 0, Step 392: train/loss = 0.431110680103302, train/raw-loss = 0.40865403413772583, train/logprobs = tensor([[-0.5046, -3.4449],
        [-0.6561, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11228322982788086
Epoch 0, Step 393: train/loss = 0.5436533093452454, train/raw-loss = 0.514859676361084, train/logprobs = tensor([[-0.8737, -2.2026],
        [-0.6880, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14396819472312927
Epoch 0, Step 394: train/loss = 0.42597508430480957, train/raw-loss = 0.40066802501678467, train/logprobs = tensor([[-0.9864, -6.7343],
        [-0.8819, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12653511762619019
Epoch 0, Step 395: train/loss = 0.48597806692123413, train/raw-loss = 0.4657701253890991, train/logprobs = tensor([[-0.7277, -5.9647],
        [-0.5082, -0.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10103978961706161
Epoch 0, Step 396: train/loss = 0.5367110967636108, train/raw-loss = 0.5094558000564575, train/logprobs = tensor([[-0.8083, -2.0390],
        [-0.8005, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13627655804157257
Epoch 0, Step 397: train/loss = 0.5353909134864807, train/raw-loss = 0.5114251971244812, train/logprobs = tensor([[-0.5051, -2.4067],
        [-0.4800, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11982869356870651
Epoch 0, Step 398: train/loss = 0.37878358364105225, train/raw-loss = 0.352710485458374, train/logprobs = tensor([[-0.6035, -3.7376],
        [-0.7695, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13036535680294037
Epoch 0, Step 399: train/loss = 0.5737876296043396, train/raw-loss = 0.5451055765151978, train/logprobs = tensor([[-0.9206, -1.4898],
        [-1.0399, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14341028034687042
Epoch 0, Step 400: train/loss = 0.5575089454650879, train/raw-loss = 0.5347360372543335, train/logprobs = tensor([[-0.5466, -1.3747],
        [-0.6196, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11386466026306152
Epoch 0, Step 401: train/loss = 0.425619512796402, train/raw-loss = 0.40008288621902466, train/logprobs = tensor([[-0.8802, -3.7056],
        [-0.9116, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1276831030845642
Epoch 0, Step 402: train/loss = 0.42866051197052, train/raw-loss = 0.40393510460853577, train/logprobs = tensor([[-0.7105, -3.5515],
        [-0.7312, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12362686544656754
Epoch 0, Step 403: train/loss = 0.5247098803520203, train/raw-loss = 0.5079368352890015, train/logprobs = tensor([[-0.3414, -1.8858],
        [-0.3817, -0.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08386515080928802
Epoch 0, Step 404: train/loss = 0.6358016729354858, train/raw-loss = 0.6125263571739197, train/logprobs = tensor([[-0.5975, -1.2662],
        [-0.5688, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11637650430202484
Epoch 0, Step 405: train/loss = 0.5480896830558777, train/raw-loss = 0.527437686920166, train/logprobs = tensor([[-0.4992, -3.4650],
        [-0.5714, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10325991362333298
Epoch 0, Step 406: train/loss = 0.5253812670707703, train/raw-loss = 0.501327395439148, train/logprobs = tensor([[-0.5905, -2.2730],
        [-0.6064, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026946246623993
Epoch 0, Step 407: train/loss = 0.5833688378334045, train/raw-loss = 0.5650321841239929, train/logprobs = tensor([[-0.5343, -1.1449],
        [-0.5535, -0.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916832834482193
Epoch 0, Step 408: train/loss = 0.5740902423858643, train/raw-loss = 0.5476819276809692, train/logprobs = tensor([[-0.6327, -1.2190],
        [-0.8929, -0.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13204143941402435
Epoch 0, Step 409: train/loss = 0.30550312995910645, train/raw-loss = 0.27900630235671997, train/logprobs = tensor([[-0.8886, -5.0777],
        [-1.2270, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13248419761657715
Epoch 0, Step 410: train/loss = 0.5645584464073181, train/raw-loss = 0.5392553806304932, train/logprobs = tensor([[-0.5962, -2.1469],
        [-0.5956, -1.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12651538848876953
Epoch 0, Step 411: train/loss = 0.5158613920211792, train/raw-loss = 0.4862733781337738, train/logprobs = tensor([[-0.5211, -1.7977],
        [-0.6003, -0.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.147939994931221
Epoch 0, Step 412: train/loss = 0.5679960250854492, train/raw-loss = 0.5437020063400269, train/logprobs = tensor([[-0.4917, -1.5708],
        [-0.6227, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147016823291779
Epoch 0, Step 413: train/loss = 0.5425450801849365, train/raw-loss = 0.5202122330665588, train/logprobs = tensor([[-0.7941, -4.1822],
        [-0.7073, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11166414618492126
Epoch 0, Step 414: train/loss = 0.4789133071899414, train/raw-loss = 0.45927608013153076, train/logprobs = tensor([[-0.4455, -1.8948],
        [-0.5913, -0.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09818603843450546
Epoch 0, Step 415: train/loss = 0.45329177379608154, train/raw-loss = 0.42820343375205994, train/logprobs = tensor([[-0.8063, -4.2786],
        [-0.9008, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12544158101081848
Epoch 0, Step 416: train/loss = 0.5979520678520203, train/raw-loss = 0.5695397257804871, train/logprobs = tensor([[-0.7936, -1.6355],
        [-0.7327, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14206165075302124
Epoch 0, Step 417: train/loss = 0.4192696511745453, train/raw-loss = 0.3889947533607483, train/logprobs = tensor([[-0.6829, -4.6219],
        [-0.9679, -0.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513744741678238
Epoch 0, Step 418: train/loss = 0.4045090675354004, train/raw-loss = 0.3785167336463928, train/logprobs = tensor([[-0.6514, -2.8043],
        [-0.9736, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129961758852005
Epoch 0, Step 419: train/loss = 0.4764476716518402, train/raw-loss = 0.44892486929893494, train/logprobs = tensor([[-1.0053, -3.1939],
        [-0.9633, -1.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13761402666568756
Epoch 0, Step 420: train/loss = 0.4793217182159424, train/raw-loss = 0.4512864947319031, train/logprobs = tensor([[-0.7687, -3.3119],
        [-0.8854, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14017602801322937
Epoch 0, Step 421: train/loss = 0.38329434394836426, train/raw-loss = 0.35113370418548584, train/logprobs = tensor([[-0.7160, -2.7082],
        [-1.0810, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16080325841903687
Epoch 0, Step 422: train/loss = 0.38710692524909973, train/raw-loss = 0.35386937856674194, train/logprobs = tensor([[-1.0696, -4.6837],
        [-1.1000, -1.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16618755459785461
Epoch 0, Step 423: train/loss = 0.5030767321586609, train/raw-loss = 0.4778250753879547, train/logprobs = tensor([[-0.6355, -3.3399],
        [-0.6107, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12625813484191895
Epoch 0, Step 424: train/loss = 0.3831859827041626, train/raw-loss = 0.3570571839809418, train/logprobs = tensor([[-0.6644, -4.4038],
        [-0.8128, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13064396381378174
Epoch 0, Step 425: train/loss = 0.8536837100982666, train/raw-loss = 0.8307978510856628, train/logprobs = tensor([[-2.0711, -3.3848],
        [-0.7717, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11442919820547104
Epoch 0, Step 426: train/loss = 0.44160890579223633, train/raw-loss = 0.4065323770046234, train/logprobs = tensor([[-0.9535, -3.0409],
        [-1.0737, -0.7119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1753827929496765
Epoch 0, Step 427: train/loss = 0.4035739004611969, train/raw-loss = 0.3746248781681061, train/logprobs = tensor([[-0.6202, -3.0705],
        [-0.7339, -0.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1447450816631317
Epoch 0, Step 428: train/loss = 0.7623163461685181, train/raw-loss = 0.7320353984832764, train/logprobs = tensor([[-1.2202, -1.3380],
        [-0.7009, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15140467882156372
Epoch 0, Step 429: train/loss = 0.3890227675437927, train/raw-loss = 0.36310532689094543, train/logprobs = tensor([[-0.6140, -3.0858],
        [-0.8187, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12958720326423645
Epoch 0, Step 430: train/loss = 0.5045917630195618, train/raw-loss = 0.4799268841743469, train/logprobs = tensor([[-0.6718, -3.4226],
        [-0.7043, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12332426011562347
Epoch 0, Step 431: train/loss = 0.48060286045074463, train/raw-loss = 0.45205485820770264, train/logprobs = tensor([[-0.7091, -1.6608],
        [-0.8532, -0.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14273998141288757
Epoch 0, Step 432: train/loss = 0.5620826482772827, train/raw-loss = 0.5328558683395386, train/logprobs = tensor([[-0.7712, -1.3466],
        [-0.9626, -0.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.146133691072464
Epoch 0, Step 433: train/loss = 0.5396718978881836, train/raw-loss = 0.5156298279762268, train/logprobs = tensor([[-0.7041, -1.7969],
        [-0.7476, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12021028995513916
Epoch 0, Step 434: train/loss = 0.35314738750457764, train/raw-loss = 0.31898367404937744, train/logprobs = tensor([[-0.8825, -5.0266],
        [-0.8897, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1708185076713562
Epoch 0, Step 435: train/loss = 0.5438674688339233, train/raw-loss = 0.5085940361022949, train/logprobs = tensor([[-1.5506, -3.3386],
        [-0.9991, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17636705935001373
Epoch 0, Step 436: train/loss = 0.43685320019721985, train/raw-loss = 0.4081522822380066, train/logprobs = tensor([[-0.8858, -4.4152],
        [-1.0847, -1.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14350441098213196
Epoch 0, Step 437: train/loss = 0.4408271312713623, train/raw-loss = 0.41204965114593506, train/logprobs = tensor([[-0.6990, -3.6111],
        [-0.8325, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1438872069120407
Epoch 0, Step 438: train/loss = 0.48711615800857544, train/raw-loss = 0.46139752864837646, train/logprobs = tensor([[-0.5460, -2.7334],
        [-0.6499, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12859322130680084
Epoch 0, Step 439: train/loss = 0.5657051801681519, train/raw-loss = 0.5402613282203674, train/logprobs = tensor([[-0.5363, -1.2764],
        [-0.6149, -0.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12721911072731018
Epoch 0, Step 440: train/loss = 0.6063604354858398, train/raw-loss = 0.5778152942657471, train/logprobs = tensor([[-0.9690, -1.8976],
        [-0.6887, -0.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427258402109146
Epoch 0, Step 441: train/loss = 0.6597479581832886, train/raw-loss = 0.6341863870620728, train/logprobs = tensor([[-1.0936, -1.6947],
        [-0.7028, -0.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278078705072403
Epoch 0, Step 442: train/loss = 0.5943492650985718, train/raw-loss = 0.5634893178939819, train/logprobs = tensor([[-0.5420, -1.2097],
        [-0.6016, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1542995721101761
Epoch 0, Step 443: train/loss = 0.7499674558639526, train/raw-loss = 0.7192347049713135, train/logprobs = tensor([[-1.8978, -1.5709],
        [-1.2789, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15366341173648834
Epoch 0, Step 444: train/loss = 0.47615331411361694, train/raw-loss = 0.44405877590179443, train/logprobs = tensor([[-1.0633, -2.8288],
        [-0.7828, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16047275066375732
Epoch 0, Step 445: train/loss = 0.42382094264030457, train/raw-loss = 0.39372649788856506, train/logprobs = tensor([[-0.7070, -3.4543],
        [-0.8024, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504722386598587
Epoch 0, Step 446: train/loss = 0.5133745670318604, train/raw-loss = 0.4871518611907959, train/logprobs = tensor([[-0.9383, -2.4005],
        [-0.8432, -0.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13111355900764465
Epoch 0, Step 447: train/loss = 0.39710599184036255, train/raw-loss = 0.36656397581100464, train/logprobs = tensor([[-1.1377, -6.0271],
        [-0.8617, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527099311351776
Epoch 0, Step 448: train/loss = 0.37007057666778564, train/raw-loss = 0.3418981432914734, train/logprobs = tensor([[-0.6463, -5.6900],
        [-0.8151, -1.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14086207747459412
Epoch 0, Step 449: train/loss = 0.6158568859100342, train/raw-loss = 0.5899307727813721, train/logprobs = tensor([[-0.8619, -2.0547],
        [-0.7966, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12963058054447174
Epoch 0, Step 450: train/loss = 0.5893499851226807, train/raw-loss = 0.558771550655365, train/logprobs = tensor([[-1.0501, -2.0492],
        [-1.1256, -0.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15289196372032166
Epoch 0, Step 451: train/loss = 0.5151803493499756, train/raw-loss = 0.4860179126262665, train/logprobs = tensor([[-0.7991, -1.7472],
        [-0.8846, -0.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14581210911273956
Epoch 0, Step 452: train/loss = 0.34558621048927307, train/raw-loss = 0.31651294231414795, train/logprobs = tensor([[-0.7695, -6.7677],
        [-1.1052, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14536632597446442
Epoch 0, Step 453: train/loss = 0.3543374538421631, train/raw-loss = 0.32698801159858704, train/logprobs = tensor([[-0.6397, -4.7516],
        [-0.9486, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1367473006248474
Epoch 0, Step 454: train/loss = 0.5395418405532837, train/raw-loss = 0.5179784893989563, train/logprobs = tensor([[-0.4015, -2.8813],
        [-0.4741, -0.6174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10781661421060562
Epoch 0, Step 455: train/loss = 0.37764498591423035, train/raw-loss = 0.35081085562705994, train/logprobs = tensor([[-0.7440, -3.8651],
        [-0.9847, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13417071104049683
Epoch 0, Step 456: train/loss = 0.6304358243942261, train/raw-loss = 0.59279465675354, train/logprobs = tensor([[-0.8895, -1.4904],
        [-0.9345, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18820615112781525
Epoch 0, Step 457: train/loss = 0.41032153367996216, train/raw-loss = 0.37679991126060486, train/logprobs = tensor([[-0.5782, -2.9877],
        [-0.8987, -0.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16760823130607605
Epoch 0, Step 458: train/loss = 0.3820713758468628, train/raw-loss = 0.3530960977077484, train/logprobs = tensor([[-0.5924, -5.3330],
        [-0.8180, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14487646520137787
Epoch 0, Step 459: train/loss = 0.4165170192718506, train/raw-loss = 0.3853435814380646, train/logprobs = tensor([[-0.7607, -3.1688],
        [-0.8640, -0.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1558670997619629
Epoch 0, Step 460: train/loss = 0.46601539850234985, train/raw-loss = 0.4354482889175415, train/logprobs = tensor([[-0.7744, -3.5306],
        [-0.8647, -0.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15283556282520294
Epoch 0, Step 461: train/loss = 0.4575018882751465, train/raw-loss = 0.4278818964958191, train/logprobs = tensor([[-1.1331, -3.5782],
        [-1.0074, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1481000781059265
Epoch 0, Step 462: train/loss = 0.48370638489723206, train/raw-loss = 0.4520770013332367, train/logprobs = tensor([[-0.8610, -2.0972],
        [-1.0346, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15814679861068726
Epoch 0, Step 463: train/loss = 0.4741672873497009, train/raw-loss = 0.4441429376602173, train/logprobs = tensor([[-0.8776, -2.2923],
        [-1.1871, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501215249300003
Epoch 0, Step 464: train/loss = 0.3542620539665222, train/raw-loss = 0.3226531147956848, train/logprobs = tensor([[-0.5563, -4.6586],
        [-0.9036, -1.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15804459154605865
Epoch 0, Step 465: train/loss = 0.5105847716331482, train/raw-loss = 0.4812108874320984, train/logprobs = tensor([[-0.6138, -1.7484],
        [-0.9415, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14686937630176544
Epoch 0, Step 466: train/loss = 0.6011862754821777, train/raw-loss = 0.5712327361106873, train/logprobs = tensor([[-1.1298, -2.4152],
        [-1.0434, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14976772665977478
Epoch 0, Step 467: train/loss = 0.5464279651641846, train/raw-loss = 0.519046425819397, train/logprobs = tensor([[-0.9774, -2.5753],
        [-0.7730, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1369074434041977
Epoch 0, Step 468: train/loss = 0.2665213942527771, train/raw-loss = 0.22994956374168396, train/logprobs = tensor([[-0.6808, -4.1683],
        [-1.3149, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18285927176475525
Epoch 0, Step 469: train/loss = 0.556541919708252, train/raw-loss = 0.532187819480896, train/logprobs = tensor([[-0.5617, -1.8211],
        [-0.9009, -0.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177061289548874
Epoch 0, Step 470: train/loss = 0.5593892335891724, train/raw-loss = 0.5279591679573059, train/logprobs = tensor([[-0.8694, -2.4475],
        [-0.6580, -1.0600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15715032815933228
Epoch 0, Step 471: train/loss = 0.3221566677093506, train/raw-loss = 0.29734426736831665, train/logprobs = tensor([[-0.4740, -4.6848],
        [-0.6973, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12406183779239655
Epoch 0, Step 472: train/loss = 0.4889838695526123, train/raw-loss = 0.46216925978660583, train/logprobs = tensor([[-0.5228, -3.5512],
        [-0.6976, -0.8168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13407303392887115
Epoch 0, Step 473: train/loss = 0.45004451274871826, train/raw-loss = 0.4187083840370178, train/logprobs = tensor([[-1.1698, -5.4044],
        [-0.9259, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566806435585022
Epoch 0, Step 474: train/loss = 0.46072688698768616, train/raw-loss = 0.43383753299713135, train/logprobs = tensor([[-0.6234, -2.9643],
        [-0.8162, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13444681465625763
Epoch 0, Step 475: train/loss = 0.3467769920825958, train/raw-loss = 0.31424498558044434, train/logprobs = tensor([[-0.7612, -4.9316],
        [-0.8718, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16266009211540222
Epoch 0, Step 476: train/loss = 0.4831508696079254, train/raw-loss = 0.45578739047050476, train/logprobs = tensor([[-0.4981, -2.1636],
        [-0.4908, -0.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368173360824585
Epoch 0, Step 477: train/loss = 0.43995556235313416, train/raw-loss = 0.407058984041214, train/logprobs = tensor([[-0.6414, -4.1948],
        [-0.6769, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16448292136192322
Epoch 0, Step 478: train/loss = 0.3261348009109497, train/raw-loss = 0.294550359249115, train/logprobs = tensor([[-0.8621, -6.8837],
        [-0.9330, -1.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15792228281497955
Epoch 0, Step 479: train/loss = 0.5014578104019165, train/raw-loss = 0.4797976613044739, train/logprobs = tensor([[-0.3956, -3.7589],
        [-0.5675, -1.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10830049216747284
Epoch 0, Step 480: train/loss = 0.6220285296440125, train/raw-loss = 0.5975464582443237, train/logprobs = tensor([[-0.4730, -1.2030],
        [-0.6058, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241058051586151
Epoch 0, Step 481: train/loss = 0.29250240325927734, train/raw-loss = 0.25701695680618286, train/logprobs = tensor([[-0.9483, -5.5528],
        [-1.2304, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774270236492157
Epoch 0, Step 482: train/loss = 0.5242745876312256, train/raw-loss = 0.49398964643478394, train/logprobs = tensor([[-0.7769, -1.4298],
        [-1.0795, -0.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15142472088336945
Epoch 0, Step 483: train/loss = 0.46775221824645996, train/raw-loss = 0.44070330262184143, train/logprobs = tensor([[-0.5241, -3.6017],
        [-0.8154, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13524436950683594
Epoch 0, Step 484: train/loss = 0.4545402228832245, train/raw-loss = 0.42350825667381287, train/logprobs = tensor([[-0.6076, -2.8151],
        [-0.8025, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15515972673892975
Epoch 0, Step 485: train/loss = 0.2805836498737335, train/raw-loss = 0.24554228782653809, train/logprobs = tensor([[-1.0579, -6.7844],
        [-1.5690, -1.6478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17520685493946075
Epoch 0, Step 486: train/loss = 0.6027328968048096, train/raw-loss = 0.5787232518196106, train/logprobs = tensor([[-0.5109, -1.1531],
        [-0.6910, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004806101322174
Epoch 0, Step 487: train/loss = 0.49098503589630127, train/raw-loss = 0.4664497375488281, train/logprobs = tensor([[-1.0104, -3.3080],
        [-1.0698, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267658114433289
Epoch 0, Step 488: train/loss = 0.4600105583667755, train/raw-loss = 0.4336621165275574, train/logprobs = tensor([[-0.6255, -4.9640],
        [-0.7303, -1.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1317422240972519
Epoch 0, Step 489: train/loss = 0.3761599063873291, train/raw-loss = 0.34361347556114197, train/logprobs = tensor([[-0.5990, -6.0513],
        [-1.1229, -1.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16273222863674164
Epoch 0, Step 490: train/loss = 0.49800992012023926, train/raw-loss = 0.4626169502735138, train/logprobs = tensor([[-0.6012, -1.8839],
        [-0.8234, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1769648641347885
Epoch 0, Step 491: train/loss = 0.39652472734451294, train/raw-loss = 0.3626878261566162, train/logprobs = tensor([[-0.9287, -4.6607],
        [-1.4535, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16918432712554932
Epoch 0, Step 492: train/loss = 0.39585328102111816, train/raw-loss = 0.36638981103897095, train/logprobs = tensor([[-0.8748, -4.5423],
        [-1.2872, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14731724560260773
Epoch 0, Step 493: train/loss = 0.5822928547859192, train/raw-loss = 0.5572741031646729, train/logprobs = tensor([[-0.4797, -1.7828],
        [-0.4785, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12509381771087646
Epoch 0, Step 494: train/loss = 0.4584304094314575, train/raw-loss = 0.4211660623550415, train/logprobs = tensor([[-0.9031, -2.2034],
        [-1.3686, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18632175028324127
Epoch 0, Step 495: train/loss = 0.43692249059677124, train/raw-loss = 0.41068053245544434, train/logprobs = tensor([[-0.4980, -4.5999],
        [-0.7979, -0.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13120999932289124
Epoch 0, Step 496: train/loss = 0.4426202178001404, train/raw-loss = 0.411588579416275, train/logprobs = tensor([[-0.6531, -3.7016],
        [-0.7100, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15515801310539246
Epoch 0, Step 497: train/loss = 0.5076919794082642, train/raw-loss = 0.4816765785217285, train/logprobs = tensor([[-0.5077, -1.5488],
        [-0.6938, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13007721304893494
Epoch 0, Step 498: train/loss = 0.3223908543586731, train/raw-loss = 0.28619763255119324, train/logprobs = tensor([[-0.6930, -3.4128],
        [-1.0382, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1809661090373993
Epoch 0, Step 499: train/loss = 0.42902684211730957, train/raw-loss = 0.40130695700645447, train/logprobs = tensor([[-0.6881, -4.0157],
        [-0.9321, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13859935104846954
Epoch 0, Step 500: train/loss = 0.5402005910873413, train/raw-loss = 0.5106247067451477, train/logprobs = tensor([[-0.6673, -2.7408],
        [-0.9233, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14787930250167847
Epoch 0, Step 501: train/loss = 0.4437240958213806, train/raw-loss = 0.41388216614723206, train/logprobs = tensor([[-0.8335, -5.0173],
        [-0.8036, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14920970797538757
Epoch 0, Step 502: train/loss = 0.3186571002006531, train/raw-loss = 0.2844134569168091, train/logprobs = tensor([[-0.5897, -2.8712],
        [-1.1660, -0.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17121818661689758
Epoch 0, Step 503: train/loss = 0.6635799407958984, train/raw-loss = 0.6417263746261597, train/logprobs = tensor([[-0.6285, -1.0644],
        [-0.5508, -0.7198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10926799476146698
Epoch 0, Step 504: train/loss = 0.41693904995918274, train/raw-loss = 0.39215245842933655, train/logprobs = tensor([[-0.5284, -3.8964],
        [-0.6409, -1.0603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12393291294574738
Epoch 0, Step 505: train/loss = 0.367256224155426, train/raw-loss = 0.33616214990615845, train/logprobs = tensor([[-0.6768, -6.1625],
        [-1.1142, -1.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1554703265428543
Epoch 0, Step 506: train/loss = 0.5380575656890869, train/raw-loss = 0.5115864276885986, train/logprobs = tensor([[-0.6212, -1.9100],
        [-0.7198, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323554962873459
Epoch 0, Step 507: train/loss = 0.5035995244979858, train/raw-loss = 0.4727632999420166, train/logprobs = tensor([[-0.9596, -6.5231],
        [-1.0050, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15418115258216858
Epoch 0, Step 508: train/loss = 0.48145946860313416, train/raw-loss = 0.4508839547634125, train/logprobs = tensor([[-0.6836, -2.5456],
        [-0.8993, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528775691986084
Epoch 0, Step 509: train/loss = 0.5482513308525085, train/raw-loss = 0.516404390335083, train/logprobs = tensor([[-0.6872, -1.9786],
        [-0.7483, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1592344343662262
Epoch 0, Step 510: train/loss = 0.4575229287147522, train/raw-loss = 0.4283885359764099, train/logprobs = tensor([[-0.7728, -4.0717],
        [-1.1728, -1.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14567188918590546
Epoch 0, Step 511: train/loss = 0.5025914311408997, train/raw-loss = 0.4732629656791687, train/logprobs = tensor([[-0.8420, -3.8318],
        [-0.8715, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14664238691329956
Epoch 0, Step 512: train/loss = 0.46053892374038696, train/raw-loss = 0.4340810775756836, train/logprobs = tensor([[-0.7251, -2.4071],
        [-1.2501, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13228943943977356
Epoch 0, Step 513: train/loss = 0.4858796298503876, train/raw-loss = 0.45968008041381836, train/logprobs = tensor([[-0.4170, -3.5376],
        [-0.6056, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099759817123413
Epoch 0, Step 514: train/loss = 0.3429020047187805, train/raw-loss = 0.3079603910446167, train/logprobs = tensor([[-0.6064, -4.8836],
        [-1.1280, -1.5011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17470809817314148
Epoch 0, Step 515: train/loss = 0.702570378780365, train/raw-loss = 0.6749874353408813, train/logprobs = tensor([[-0.5062, -0.5821],
        [-0.6263, -0.6247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13791483640670776
Epoch 0, Step 516: train/loss = 0.3936617374420166, train/raw-loss = 0.3595365285873413, train/logprobs = tensor([[-0.8153, -3.1755],
        [-1.3084, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17062613368034363
Epoch 0, Step 517: train/loss = 0.4279450476169586, train/raw-loss = 0.3998383581638336, train/logprobs = tensor([[-0.6150, -2.7182],
        [-0.8298, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140533447265625
Epoch 0, Step 518: train/loss = 0.3499870002269745, train/raw-loss = 0.317170113325119, train/logprobs = tensor([[-0.7947, -5.7058],
        [-1.6578, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16408434510231018
Epoch 0, Step 519: train/loss = 0.340599924325943, train/raw-loss = 0.30660155415534973, train/logprobs = tensor([[-0.9821, -4.4714],
        [-1.0919, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16999201476573944
Epoch 0, Step 520: train/loss = 0.74546879529953, train/raw-loss = 0.7199037075042725, train/logprobs = tensor([[-1.0947, -1.0733],
        [-0.8271, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12782543897628784
Epoch 0, Step 521: train/loss = 0.44988125562667847, train/raw-loss = 0.4263581931591034, train/logprobs = tensor([[-0.3568, -2.8078],
        [-0.5761, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761526763439178
Epoch 0, Step 522: train/loss = 0.5949636697769165, train/raw-loss = 0.5666369795799255, train/logprobs = tensor([[-1.4159, -3.6434],
        [-0.9474, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14163342118263245
Epoch 0, Step 523: train/loss = 0.5008512735366821, train/raw-loss = 0.4733140468597412, train/logprobs = tensor([[-0.5443, -2.4125],
        [-0.6580, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376861333847046
Epoch 0, Step 524: train/loss = 0.288176029920578, train/raw-loss = 0.25788193941116333, train/logprobs = tensor([[-0.4651, -6.5805],
        [-0.8792, -1.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514703929424286
Epoch 0, Step 525: train/loss = 0.5174148082733154, train/raw-loss = 0.4859619140625, train/logprobs = tensor([[-0.7190, -2.1753],
        [-0.8975, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15726438164710999
Epoch 0, Step 526: train/loss = 0.46690452098846436, train/raw-loss = 0.4459696412086487, train/logprobs = tensor([[-0.3913, -2.0298],
        [-0.6719, -0.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10467438399791718
Epoch 0, Step 527: train/loss = 0.25879237055778503, train/raw-loss = 0.2275291383266449, train/logprobs = tensor([[-0.5468, -4.5440],
        [-1.1629, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15631625056266785
Epoch 0, Step 528: train/loss = 0.357486367225647, train/raw-loss = 0.3350363075733185, train/logprobs = tensor([[-0.3525, -6.3637],
        [-0.5169, -1.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11225029826164246
Epoch 0, Step 529: train/loss = 0.3964409828186035, train/raw-loss = 0.3653615117073059, train/logprobs = tensor([[-0.6787, -4.8260],
        [-1.0131, -1.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15539731085300446
Epoch 0, Step 530: train/loss = 0.5744253993034363, train/raw-loss = 0.541671872138977, train/logprobs = tensor([[-0.5859, -1.8307],
        [-1.1038, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16376784443855286
Epoch 0, Step 531: train/loss = 0.5321991443634033, train/raw-loss = 0.5048445463180542, train/logprobs = tensor([[-0.4281, -1.6766],
        [-0.6241, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13677294552326202
Epoch 0, Step 532: train/loss = 0.4830179810523987, train/raw-loss = 0.45311683416366577, train/logprobs = tensor([[-0.6122, -3.2098],
        [-1.0386, -0.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14950592815876007
Epoch 0, Step 533: train/loss = 0.4340575933456421, train/raw-loss = 0.3969375491142273, train/logprobs = tensor([[-0.9697, -4.4930],
        [-0.9778, -1.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1856001615524292
Epoch 0, Step 534: train/loss = 0.502194881439209, train/raw-loss = 0.4720882475376129, train/logprobs = tensor([[-0.4832, -2.6895],
        [-0.7532, -1.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15053310990333557
Epoch 0, Step 535: train/loss = 0.336861252784729, train/raw-loss = 0.2982335090637207, train/logprobs = tensor([[-0.8633, -4.5478],
        [-1.4331, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19313882291316986
Epoch 0, Step 536: train/loss = 0.3906501531600952, train/raw-loss = 0.3605111241340637, train/logprobs = tensor([[-0.7675, -3.0879],
        [-0.9298, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15069516003131866
Epoch 0, Step 537: train/loss = 0.3789646625518799, train/raw-loss = 0.34799474477767944, train/logprobs = tensor([[-0.6728, -2.5094],
        [-1.2079, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15484942495822906
Epoch 0, Step 538: train/loss = 0.3680874705314636, train/raw-loss = 0.33641237020492554, train/logprobs = tensor([[-0.8449, -5.0860],
        [-0.8088, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583755910396576
Epoch 0, Step 539: train/loss = 0.4445670545101166, train/raw-loss = 0.4199335277080536, train/logprobs = tensor([[-0.4657, -3.6902],
        [-0.6832, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12316757440567017
Epoch 0, Step 540: train/loss = 0.485255628824234, train/raw-loss = 0.45385488867759705, train/logprobs = tensor([[-0.7449, -3.0149],
        [-1.1811, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15700359642505646
Epoch 0, Step 541: train/loss = 0.31370478868484497, train/raw-loss = 0.28101930022239685, train/logprobs = tensor([[-0.8462, -6.0316],
        [-1.4957, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16342738270759583
Epoch 0, Step 542: train/loss = 0.39282554388046265, train/raw-loss = 0.3673657178878784, train/logprobs = tensor([[-0.7015, -3.0254],
        [-1.0160, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12729927897453308
Epoch 0, Step 543: train/loss = 0.410981684923172, train/raw-loss = 0.38449960947036743, train/logprobs = tensor([[-0.5912, -5.3538],
        [-0.8074, -1.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13241030275821686
Epoch 0, Step 544: train/loss = 0.48289552330970764, train/raw-loss = 0.4501205384731293, train/logprobs = tensor([[-0.6772, -2.4150],
        [-0.8887, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638750284910202
Epoch 0, Step 545: train/loss = 0.36054497957229614, train/raw-loss = 0.3290020227432251, train/logprobs = tensor([[-0.6671, -3.6687],
        [-1.3159, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1577148288488388
Epoch 0, Step 546: train/loss = 0.4027465283870697, train/raw-loss = 0.3738722801208496, train/logprobs = tensor([[-0.4537, -3.3135],
        [-0.7929, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1443711817264557
Epoch 0, Step 547: train/loss = 0.3917989134788513, train/raw-loss = 0.36152875423431396, train/logprobs = tensor([[-0.7253, -4.7762],
        [-0.9197, -1.5880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15135063230991364
Epoch 0, Step 548: train/loss = 0.5336158871650696, train/raw-loss = 0.5053155422210693, train/logprobs = tensor([[-0.5017, -1.3752],
        [-0.7990, -0.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14150165021419525
Epoch 0, Step 549: train/loss = 0.4638185501098633, train/raw-loss = 0.4309259057044983, train/logprobs = tensor([[-0.9394, -2.3545],
        [-1.4000, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644631326198578
Epoch 0, Step 550: train/loss = 0.35478371381759644, train/raw-loss = 0.3181755244731903, train/logprobs = tensor([[-1.0823, -4.9155],
        [-1.6160, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18304088711738586
Epoch 0, Step 551: train/loss = 0.5365837812423706, train/raw-loss = 0.5053848028182983, train/logprobs = tensor([[-0.6580, -2.0257],
        [-0.9423, -1.1898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15599490702152252
Epoch 0, Step 552: train/loss = 0.3532736003398895, train/raw-loss = 0.32130756974220276, train/logprobs = tensor([[-0.7046, -3.2557],
        [-1.3138, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1598299741744995
Epoch 0, Step 553: train/loss = 0.4012918770313263, train/raw-loss = 0.36889398097991943, train/logprobs = tensor([[-0.4911, -3.2602],
        [-0.8797, -1.4306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16198931634426117
Epoch 0, Step 554: train/loss = 0.3766407370567322, train/raw-loss = 0.34641724824905396, train/logprobs = tensor([[-0.5072, -4.9091],
        [-0.7787, -1.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1511172354221344
Epoch 0, Step 555: train/loss = 0.44250819087028503, train/raw-loss = 0.410441517829895, train/logprobs = tensor([[-1.0499, -3.3387],
        [-1.0010, -0.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16033339500427246
Epoch 0, Step 556: train/loss = 0.40438300371170044, train/raw-loss = 0.3757387697696686, train/logprobs = tensor([[-0.4657, -4.1989],
        [-0.7680, -1.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14322136342525482
Epoch 0, Step 557: train/loss = 0.40373367071151733, train/raw-loss = 0.36832576990127563, train/logprobs = tensor([[-0.8262, -3.9523],
        [-1.3875, -1.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770394891500473
Epoch 0, Step 558: train/loss = 0.6392202377319336, train/raw-loss = 0.6030582189559937, train/logprobs = tensor([[-0.7677, -1.2494],
        [-0.9507, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18080969154834747
Epoch 0, Step 559: train/loss = 0.4274725914001465, train/raw-loss = 0.3959452211856842, train/logprobs = tensor([[-0.7260, -3.6319],
        [-0.7863, -0.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15763668715953827
Epoch 0, Step 560: train/loss = 0.5343982577323914, train/raw-loss = 0.508965253829956, train/logprobs = tensor([[-0.3774, -2.1606],
        [-0.4897, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271650344133377
Epoch 0, Step 561: train/loss = 0.4653366804122925, train/raw-loss = 0.43256083130836487, train/logprobs = tensor([[-0.5829, -2.2324],
        [-1.0444, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638791263103485
Epoch 0, Step 562: train/loss = 0.4155831038951874, train/raw-loss = 0.38265302777290344, train/logprobs = tensor([[-0.7237, -3.9581],
        [-1.1043, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16465044021606445
Epoch 0, Step 563: train/loss = 0.4834156334400177, train/raw-loss = 0.456504225730896, train/logprobs = tensor([[-0.4896, -3.5074],
        [-0.6789, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13455688953399658
Epoch 0, Step 564: train/loss = 0.480420857667923, train/raw-loss = 0.4451723098754883, train/logprobs = tensor([[-0.6305, -1.9112],
        [-1.0426, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17624284327030182
Epoch 0, Step 565: train/loss = 0.37353482842445374, train/raw-loss = 0.33527088165283203, train/logprobs = tensor([[-0.9265, -3.3865],
        [-1.6869, -1.8035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1913195550441742
Epoch 0, Step 566: train/loss = 0.4650115370750427, train/raw-loss = 0.4365352988243103, train/logprobs = tensor([[-0.5185, -6.9346],
        [-0.7216, -1.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423811912536621
Epoch 0, Step 567: train/loss = 0.34286633133888245, train/raw-loss = 0.3066011667251587, train/logprobs = tensor([[-0.5185, -3.6976],
        [-1.2153, -1.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18132570385932922
Epoch 0, Step 568: train/loss = 0.5316308736801147, train/raw-loss = 0.4972396194934845, train/logprobs = tensor([[-0.5711, -3.1479],
        [-1.0745, -1.2769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17195641994476318
Epoch 0, Step 569: train/loss = 0.33083605766296387, train/raw-loss = 0.2893068790435791, train/logprobs = tensor([[-0.8868, -2.7900],
        [-1.6574, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2076459527015686
Epoch 0, Step 570: train/loss = 0.722607433795929, train/raw-loss = 0.688157320022583, train/logprobs = tensor([[-1.7156, -2.7568],
        [-1.0799, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17225046455860138
Epoch 0, Step 571: train/loss = 0.40567296743392944, train/raw-loss = 0.3775246739387512, train/logprobs = tensor([[-0.6967, -4.0580],
        [-0.7302, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14074161648750305
Epoch 0, Step 572: train/loss = 0.3988458514213562, train/raw-loss = 0.3703804016113281, train/logprobs = tensor([[-0.4860, -3.6635],
        [-0.5587, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423271745443344
Epoch 0, Step 573: train/loss = 0.3480139374732971, train/raw-loss = 0.3158179521560669, train/logprobs = tensor([[-0.5458, -4.0321],
        [-0.8083, -1.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16097977757453918
Epoch 0, Step 574: train/loss = 0.5455663800239563, train/raw-loss = 0.5185250043869019, train/logprobs = tensor([[-0.5023, -1.4937],
        [-0.7787, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13520695269107819
Epoch 0, Step 575: train/loss = 0.34577834606170654, train/raw-loss = 0.30901551246643066, train/logprobs = tensor([[-0.6340, -4.3177],
        [-1.2988, -1.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183814138174057
Epoch 0, Step 576: train/loss = 0.5137541890144348, train/raw-loss = 0.4738660454750061, train/logprobs = tensor([[-1.0344, -1.9749],
        [-1.2692, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19944068789482117
Epoch 0, Step 577: train/loss = 0.6031026244163513, train/raw-loss = 0.5650287866592407, train/logprobs = tensor([[-0.8431, -1.8019],
        [-1.1427, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19036933779716492
Epoch 0, Step 578: train/loss = 0.3236556053161621, train/raw-loss = 0.28246015310287476, train/logprobs = tensor([[-0.8045, -4.6095],
        [-1.4890, -0.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20597730576992035
Epoch 0, Step 579: train/loss = 0.4218425154685974, train/raw-loss = 0.38967713713645935, train/logprobs = tensor([[-0.8367, -4.5488],
        [-1.2371, -1.8793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16082674264907837
Epoch 0, Step 580: train/loss = 0.37774375081062317, train/raw-loss = 0.3485966920852661, train/logprobs = tensor([[-0.8660, -5.9792],
        [-1.0425, -1.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14573517441749573
Epoch 0, Step 581: train/loss = 0.35060861706733704, train/raw-loss = 0.31639763712882996, train/logprobs = tensor([[-0.6782, -6.2712],
        [-1.2787, -2.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17105497419834137
Epoch 0, Step 582: train/loss = 0.5078308582305908, train/raw-loss = 0.47749412059783936, train/logprobs = tensor([[-0.6766, -1.9062],
        [-1.1501, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516837626695633
Epoch 0, Step 583: train/loss = 0.5265733003616333, train/raw-loss = 0.4971160590648651, train/logprobs = tensor([[-0.8076, -2.3379],
        [-0.9076, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14728640019893646
Epoch 0, Step 584: train/loss = 0.5053879618644714, train/raw-loss = 0.4760609269142151, train/logprobs = tensor([[-0.5056, -2.1169],
        [-0.8980, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14663515985012054
Epoch 0, Step 585: train/loss = 0.5419321656227112, train/raw-loss = 0.5133584141731262, train/logprobs = tensor([[-0.3360, -2.4644],
        [-0.5412, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14286866784095764
Epoch 0, Step 586: train/loss = 0.41418373584747314, train/raw-loss = 0.3742903470993042, train/logprobs = tensor([[-0.8377, -2.1583],
        [-1.4400, -0.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19946682453155518
Epoch 0, Step 587: train/loss = 0.5179306268692017, train/raw-loss = 0.48579728603363037, train/logprobs = tensor([[-0.7250, -1.6051],
        [-1.1258, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16066661477088928
Epoch 0, Step 588: train/loss = 0.3778710961341858, train/raw-loss = 0.34632518887519836, train/logprobs = tensor([[-0.8015, -4.8238],
        [-1.4895, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15772958099842072
Epoch 0, Step 589: train/loss = 0.39404216408729553, train/raw-loss = 0.35607439279556274, train/logprobs = tensor([[-0.7082, -3.5908],
        [-1.1912, -0.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18983888626098633
Epoch 0, Step 590: train/loss = 0.325996994972229, train/raw-loss = 0.29650095105171204, train/logprobs = tensor([[-0.5754, -4.9409],
        [-0.8857, -1.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14748017489910126
Epoch 0, Step 591: train/loss = 0.6426430940628052, train/raw-loss = 0.6089725494384766, train/logprobs = tensor([[-0.6430, -0.8962],
        [-0.8237, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1683523803949356
Epoch 0, Step 592: train/loss = 0.49734124541282654, train/raw-loss = 0.46500396728515625, train/logprobs = tensor([[-0.5711, -2.1008],
        [-0.9148, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16168634593486786
Epoch 0, Step 593: train/loss = 0.43638747930526733, train/raw-loss = 0.40303707122802734, train/logprobs = tensor([[-0.5735, -2.9510],
        [-0.9168, -1.0581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16675201058387756
Epoch 0, Step 594: train/loss = 0.3081175982952118, train/raw-loss = 0.2715858519077301, train/logprobs = tensor([[-0.7180, -3.7681],
        [-1.1502, -0.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18265876173973083
Epoch 0, Step 595: train/loss = 0.5097866654396057, train/raw-loss = 0.4765300154685974, train/logprobs = tensor([[-0.6043, -2.1621],
        [-0.8701, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16628329455852509
Epoch 0, Step 596: train/loss = 0.4478720426559448, train/raw-loss = 0.4161229133605957, train/logprobs = tensor([[-0.7252, -4.3860],
        [-1.0547, -1.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15874575078487396
Epoch 0, Step 597: train/loss = 0.6279011368751526, train/raw-loss = 0.5939951539039612, train/logprobs = tensor([[-0.6305, -0.9944],
        [-1.0754, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16952985525131226
Epoch 0, Step 598: train/loss = 0.4276517629623413, train/raw-loss = 0.3936103284358978, train/logprobs = tensor([[-1.1334, -3.5487],
        [-1.0570, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17020708322525024
Epoch 0, Step 599: train/loss = 0.42655837535858154, train/raw-loss = 0.3950124680995941, train/logprobs = tensor([[-0.4986, -4.0447],
        [-0.8947, -1.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15772943198680878
Epoch 0, Step 600: train/loss = 0.46252205967903137, train/raw-loss = 0.4300042390823364, train/logprobs = tensor([[-0.4987, -2.9221],
        [-0.7398, -0.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16258922219276428
Epoch 0, Step 601: train/loss = 0.46215516328811646, train/raw-loss = 0.42749324440956116, train/logprobs = tensor([[-0.9425, -2.3473],
        [-1.3823, -1.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1733095645904541
Epoch 0, Step 602: train/loss = 0.4801524877548218, train/raw-loss = 0.4412207305431366, train/logprobs = tensor([[-1.0280, -3.0077],
        [-1.2213, -1.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19465863704681396
Epoch 0, Step 603: train/loss = 0.2935951352119446, train/raw-loss = 0.25990116596221924, train/logprobs = tensor([[-0.5491, -5.5653],
        [-1.0554, -1.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1684698462486267
Epoch 0, Step 604: train/loss = 0.5146047472953796, train/raw-loss = 0.48510995507240295, train/logprobs = tensor([[-0.4176, -1.7012],
        [-0.6627, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14747397601604462
Epoch 0, Step 605: train/loss = 0.498596727848053, train/raw-loss = 0.4679100215435028, train/logprobs = tensor([[-0.7305, -1.1756],
        [-1.3937, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534334421157837
Epoch 0, Step 606: train/loss = 0.44146397709846497, train/raw-loss = 0.409749299287796, train/logprobs = tensor([[-0.6713, -2.3894],
        [-0.8388, -0.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15857340395450592
Epoch 0, Step 607: train/loss = 0.4141905605792999, train/raw-loss = 0.37717628479003906, train/logprobs = tensor([[-0.7193, -3.1309],
        [-0.9505, -0.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18507105112075806
Epoch 0, Step 608: train/loss = 0.4461340308189392, train/raw-loss = 0.40852949023246765, train/logprobs = tensor([[-0.6096, -2.9599],
        [-1.1604, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18802279233932495
Epoch 0, Step 609: train/loss = 0.34642407298088074, train/raw-loss = 0.30882465839385986, train/logprobs = tensor([[-0.8993, -5.8607],
        [-1.5143, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18799704313278198
Epoch 0, Step 610: train/loss = 0.2778838574886322, train/raw-loss = 0.2329058051109314, train/logprobs = tensor([[-1.2326, -6.9245],
        [-1.8202, -1.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22489029169082642
Epoch 0, Step 611: train/loss = 0.29110202193260193, train/raw-loss = 0.2608841061592102, train/logprobs = tensor([[-0.5152, -4.2824],
        [-0.8525, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151089608669281
Epoch 0, Step 612: train/loss = 0.5397759675979614, train/raw-loss = 0.5036308169364929, train/logprobs = tensor([[-0.7757, -3.4827],
        [-1.0258, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1807258427143097
Epoch 0, Step 613: train/loss = 0.5815398693084717, train/raw-loss = 0.5443018674850464, train/logprobs = tensor([[-0.7935, -1.9809],
        [-1.0346, -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18619021773338318
Epoch 0, Step 614: train/loss = 0.4487546682357788, train/raw-loss = 0.40944942831993103, train/logprobs = tensor([[-0.7432, -2.4014],
        [-1.0136, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19652611017227173
Epoch 0, Step 615: train/loss = 0.44756072759628296, train/raw-loss = 0.4075464904308319, train/logprobs = tensor([[-0.7019, -2.3141],
        [-1.2661, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20007120072841644
Epoch 0, Step 616: train/loss = 0.6424950361251831, train/raw-loss = 0.6093627214431763, train/logprobs = tensor([[-0.5102, -0.9877],
        [-0.8220, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16566136479377747
Epoch 0, Step 617: train/loss = 0.4535728991031647, train/raw-loss = 0.4255342185497284, train/logprobs = tensor([[-0.7030, -3.5911],
        [-0.9550, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14019350707530975
Epoch 0, Step 618: train/loss = 0.4100852310657501, train/raw-loss = 0.3764479458332062, train/logprobs = tensor([[-0.5160, -2.8427],
        [-1.0491, -1.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1681862622499466
Epoch 0, Step 619: train/loss = 0.3647628426551819, train/raw-loss = 0.3347804844379425, train/logprobs = tensor([[-0.4934, -4.6586],
        [-0.8779, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14991167187690735
Epoch 0, Step 620: train/loss = 0.35039931535720825, train/raw-loss = 0.3107756972312927, train/logprobs = tensor([[-0.8364, -3.7801],
        [-1.4026, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19811801612377167
Epoch 0, Step 621: train/loss = 0.5820087194442749, train/raw-loss = 0.5517381429672241, train/logprobs = tensor([[-0.6756, -0.9367],
        [-1.0713, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15135279297828674
Epoch 0, Step 622: train/loss = 0.4593532979488373, train/raw-loss = 0.42453157901763916, train/logprobs = tensor([[-0.4517, -4.6569],
        [-0.9953, -1.1328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17410878837108612
Epoch 0, Step 623: train/loss = 0.4119724929332733, train/raw-loss = 0.38211092352867126, train/logprobs = tensor([[-0.5973, -5.0160],
        [-1.0025, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.149307981133461
Epoch 0, Step 624: train/loss = 0.45914095640182495, train/raw-loss = 0.4234786629676819, train/logprobs = tensor([[-0.5868, -2.9595],
        [-1.1358, -1.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17831160128116608
Epoch 0, Step 625: train/loss = 0.4935745894908905, train/raw-loss = 0.45834824442863464, train/logprobs = tensor([[-0.7118, -4.4406],
        [-0.8646, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1761317104101181
Epoch 0, Step 626: train/loss = 0.46968671679496765, train/raw-loss = 0.436712384223938, train/logprobs = tensor([[-0.5728, -2.2530],
        [-0.9322, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648716926574707
Epoch 0, Step 627: train/loss = 0.43528541922569275, train/raw-loss = 0.4005962610244751, train/logprobs = tensor([[-0.4653, -2.4319],
        [-1.0248, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17344576120376587
Epoch 0, Step 628: train/loss = 0.40462157130241394, train/raw-loss = 0.3681894540786743, train/logprobs = tensor([[-0.4687, -2.6046],
        [-1.0243, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1821606159210205
Epoch 0, Step 629: train/loss = 0.4674448072910309, train/raw-loss = 0.4375913739204407, train/logprobs = tensor([[-0.4170, -2.0186],
        [-0.7695, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492672860622406
Epoch 0, Step 630: train/loss = 0.3942570686340332, train/raw-loss = 0.364894837141037, train/logprobs = tensor([[-0.4455, -3.5766],
        [-0.6678, -0.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14681099355220795
Epoch 0, Step 631: train/loss = 0.2741518020629883, train/raw-loss = 0.23611882328987122, train/logprobs = tensor([[-1.0614, -4.7350],
        [-1.7115, -1.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19016499817371368
Epoch 0, Step 632: train/loss = 0.46471714973449707, train/raw-loss = 0.4262460172176361, train/logprobs = tensor([[-0.8844, -4.1846],
        [-1.1368, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19235576689243317
Epoch 0, Step 633: train/loss = 0.36669546365737915, train/raw-loss = 0.3335917890071869, train/logprobs = tensor([[-0.8726, -4.7095],
        [-1.1347, -1.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16551828384399414
Epoch 0, Step 634: train/loss = 0.37797072529792786, train/raw-loss = 0.33915242552757263, train/logprobs = tensor([[-0.4546, -4.0952],
        [-1.1698, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19409151375293732
Epoch 0, Step 635: train/loss = 0.3557060956954956, train/raw-loss = 0.32037895917892456, train/logprobs = tensor([[-0.5634, -4.2466],
        [-1.1341, -1.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1766357272863388
Epoch 0, Step 636: train/loss = 0.471966028213501, train/raw-loss = 0.44182759523391724, train/logprobs = tensor([[-0.5554, -3.0994],
        [-0.8554, -1.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1506921350955963
Epoch 0, Step 637: train/loss = 0.4130652844905853, train/raw-loss = 0.38395223021507263, train/logprobs = tensor([[-0.6477, -4.0538],
        [-0.9222, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14556509256362915
Epoch 0, Step 638: train/loss = 0.6006136536598206, train/raw-loss = 0.5674110054969788, train/logprobs = tensor([[-0.5056, -1.1814],
        [-0.7411, -0.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16601338982582092
Epoch 0, Step 639: train/loss = 0.4165820777416229, train/raw-loss = 0.37641817331314087, train/logprobs = tensor([[-0.9152, -3.6910],
        [-1.3203, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20081959664821625
Epoch 0, Step 640: train/loss = 0.3829294741153717, train/raw-loss = 0.352845698595047, train/logprobs = tensor([[-0.6066, -5.2139],
        [-0.8320, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15041883289813995
Epoch 0, Step 641: train/loss = 0.6478027701377869, train/raw-loss = 0.6128290295600891, train/logprobs = tensor([[-1.3869, -3.3472],
        [-1.1779, -1.1554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17486906051635742
Epoch 0, Step 642: train/loss = 0.4046075940132141, train/raw-loss = 0.3681643605232239, train/logprobs = tensor([[-1.0866, -4.2272],
        [-1.2719, -1.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182216078042984
Epoch 0, Step 643: train/loss = 0.3085325360298157, train/raw-loss = 0.2733125686645508, train/logprobs = tensor([[-0.5811, -5.8315],
        [-0.9803, -0.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.176099956035614
Epoch 0, Step 644: train/loss = 0.5309731364250183, train/raw-loss = 0.4914722740650177, train/logprobs = tensor([[-1.0433, -1.3175],
        [-1.5051, -0.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1975046843290329
Epoch 0, Step 645: train/loss = 0.4270535409450531, train/raw-loss = 0.3951796889305115, train/logprobs = tensor([[-1.0537, -5.3658],
        [-1.7130, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1593693047761917
Epoch 0, Step 646: train/loss = 0.573146402835846, train/raw-loss = 0.5367767810821533, train/logprobs = tensor([[-0.6829, -1.2685],
        [-1.0179, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18184813857078552
Epoch 0, Step 647: train/loss = 0.45242124795913696, train/raw-loss = 0.4197155237197876, train/logprobs = tensor([[-0.6048, -3.1964],
        [-1.1360, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16352862119674683
Epoch 0, Step 648: train/loss = 0.37961792945861816, train/raw-loss = 0.3448140025138855, train/logprobs = tensor([[-0.6458, -4.9431],
        [-1.2528, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17401963472366333
Epoch 0, Step 649: train/loss = 0.2316654920578003, train/raw-loss = 0.1951102763414383, train/logprobs = tensor([[-0.6356, -6.7783],
        [-1.5338, -1.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18277603387832642
Epoch 0, Step 650: train/loss = 0.3015679121017456, train/raw-loss = 0.26575765013694763, train/logprobs = tensor([[-0.6759, -6.3964],
        [-1.2251, -1.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17905132472515106
Epoch 0, Step 651: train/loss = 0.27884459495544434, train/raw-loss = 0.24082741141319275, train/logprobs = tensor([[-0.9775, -5.5820],
        [-1.4995, -1.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1900859922170639
Epoch 0, Step 652: train/loss = 0.33880627155303955, train/raw-loss = 0.3132018446922302, train/logprobs = tensor([[-0.9149, -6.7630],
        [-1.3336, -1.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12802214920520782
Epoch 0, Step 653: train/loss = 0.48409608006477356, train/raw-loss = 0.4542030692100525, train/logprobs = tensor([[-0.8309, -2.9355],
        [-1.1553, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14946502447128296
Epoch 0, Step 654: train/loss = 0.5975663661956787, train/raw-loss = 0.5660099387168884, train/logprobs = tensor([[-0.6410, -2.3008],
        [-0.7404, -0.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15778207778930664
Epoch 0, Step 655: train/loss = 0.3613544702529907, train/raw-loss = 0.31616657972335815, train/logprobs = tensor([[-1.0536, -3.8835],
        [-1.5981, -1.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22593951225280762
Epoch 0, Step 656: train/loss = 0.25803953409194946, train/raw-loss = 0.22118254005908966, train/logprobs = tensor([[-1.0566, -8.0292],
        [-1.4943, -1.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18428507447242737
Epoch 0, Step 657: train/loss = 0.35151100158691406, train/raw-loss = 0.3219207525253296, train/logprobs = tensor([[-0.6795, -5.2122],
        [-1.0725, -1.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14795131981372833
Epoch 0, Step 658: train/loss = 0.48588496446609497, train/raw-loss = 0.4469834566116333, train/logprobs = tensor([[-1.1454, -3.6975],
        [-1.2562, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19450770318508148
Epoch 0, Step 659: train/loss = 0.24973124265670776, train/raw-loss = 0.21107253432273865, train/logprobs = tensor([[-0.5870, -5.3234],
        [-1.2503, -0.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1932935118675232
Epoch 0, Step 660: train/loss = 0.5724043846130371, train/raw-loss = 0.535675585269928, train/logprobs = tensor([[-0.8335, -2.4391],
        [-0.7926, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18364392220973969
Epoch 0, Step 661: train/loss = 0.40884795784950256, train/raw-loss = 0.37254056334495544, train/logprobs = tensor([[-0.5938, -4.6249],
        [-1.1272, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18153689801692963
Epoch 0, Step 662: train/loss = 0.5472323894500732, train/raw-loss = 0.5173286199569702, train/logprobs = tensor([[-0.6680, -1.7463],
        [-0.8290, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14951851963996887
Epoch 0, Step 663: train/loss = 0.41433513164520264, train/raw-loss = 0.37940913438796997, train/logprobs = tensor([[-1.0675, -6.2430],
        [-0.9635, -1.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1746300309896469
Epoch 0, Step 664: train/loss = 0.42617151141166687, train/raw-loss = 0.3917107880115509, train/logprobs = tensor([[-0.7445, -2.6409],
        [-1.2030, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230363190174103
Epoch 0, Step 665: train/loss = 0.4708716869354248, train/raw-loss = 0.43234479427337646, train/logprobs = tensor([[-1.1530, -2.4216],
        [-1.1890, -0.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926342248916626
Epoch 0, Step 666: train/loss = 0.4097629189491272, train/raw-loss = 0.37408551573753357, train/logprobs = tensor([[-0.8509, -4.2815],
        [-1.5334, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1783871352672577
Epoch 0, Step 667: train/loss = 0.4356595277786255, train/raw-loss = 0.39838579297065735, train/logprobs = tensor([[-0.7120, -3.9766],
        [-1.3434, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863686591386795
Epoch 0, Step 668: train/loss = 0.5347591042518616, train/raw-loss = 0.4946572184562683, train/logprobs = tensor([[-0.7121, -1.5725],
        [-1.1211, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20050956308841705
Epoch 0, Step 669: train/loss = 0.3222256898880005, train/raw-loss = 0.2918161153793335, train/logprobs = tensor([[-0.6066, -5.4785],
        [-1.0875, -0.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15204782783985138
Epoch 0, Step 670: train/loss = 0.37016960978507996, train/raw-loss = 0.3388928174972534, train/logprobs = tensor([[-0.8776, -5.7044],
        [-1.0824, -1.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15638397634029388
Epoch 0, Step 671: train/loss = 0.4267498552799225, train/raw-loss = 0.39410749077796936, train/logprobs = tensor([[-0.9294, -3.8021],
        [-0.9461, -0.7779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16321176290512085
Epoch 0, Step 672: train/loss = 0.5022424459457397, train/raw-loss = 0.47058603167533875, train/logprobs = tensor([[-0.7171, -3.5557],
        [-1.2385, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582821011543274
Epoch 0, Step 673: train/loss = 0.39054346084594727, train/raw-loss = 0.3520217537879944, train/logprobs = tensor([[-0.5574, -3.6599],
        [-1.1017, -0.7823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926085650920868
Epoch 0, Step 674: train/loss = 0.39120203256607056, train/raw-loss = 0.3606869876384735, train/logprobs = tensor([[-0.4155, -2.4821],
        [-0.9429, -0.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15257510542869568
Epoch 0, Step 675: train/loss = 0.35510125756263733, train/raw-loss = 0.31209373474121094, train/logprobs = tensor([[-0.6331, -3.2697],
        [-1.4013, -1.2687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2150374948978424
Epoch 0, Step 676: train/loss = 0.3326183259487152, train/raw-loss = 0.3013937473297119, train/logprobs = tensor([[-0.5304, -6.2469],
        [-1.1393, -1.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15612289309501648
Epoch 0, Step 677: train/loss = 0.43195641040802, train/raw-loss = 0.3933256268501282, train/logprobs = tensor([[-0.4371, -3.2333],
        [-0.8851, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19315411150455475
Epoch 0, Step 678: train/loss = 0.33002573251724243, train/raw-loss = 0.2843373417854309, train/logprobs = tensor([[-0.5977, -4.7731],
        [-1.4151, -1.3476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22844186425209045
Epoch 0, Step 679: train/loss = 0.3084908425807953, train/raw-loss = 0.2726793885231018, train/logprobs = tensor([[-0.9548, -4.3088],
        [-1.2808, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790573000907898
Epoch 0, Step 680: train/loss = 0.37642985582351685, train/raw-loss = 0.3441925644874573, train/logprobs = tensor([[-0.7173, -5.0962],
        [-1.0324, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16118654608726501
Epoch 0, Step 681: train/loss = 0.34128016233444214, train/raw-loss = 0.3042233884334564, train/logprobs = tensor([[-0.5226, -3.5988],
        [-1.1486, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18528376519680023
Epoch 0, Step 682: train/loss = 0.5346691012382507, train/raw-loss = 0.4935992956161499, train/logprobs = tensor([[-1.1611, -3.0350],
        [-1.0312, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20534919202327728
Epoch 0, Step 683: train/loss = 0.5401068925857544, train/raw-loss = 0.500074028968811, train/logprobs = tensor([[-0.9036, -2.1280],
        [-1.5040, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200164332985878
Epoch 0, Step 684: train/loss = 0.3514633774757385, train/raw-loss = 0.3194204568862915, train/logprobs = tensor([[-0.6160, -4.1475],
        [-1.0983, -1.3832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16021455824375153
Epoch 0, Step 685: train/loss = 0.43037834763526917, train/raw-loss = 0.3970799446105957, train/logprobs = tensor([[-0.5807, -3.6898],
        [-1.0012, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16649198532104492
Epoch 0, Step 686: train/loss = 0.49068424105644226, train/raw-loss = 0.4434833824634552, train/logprobs = tensor([[-1.4027, -2.9223],
        [-1.5679, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2360042929649353
Epoch 0, Step 687: train/loss = 0.42057400941848755, train/raw-loss = 0.3914669156074524, train/logprobs = tensor([[-0.9142, -3.5319],
        [-1.1179, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14553552865982056
Epoch 0, Step 688: train/loss = 0.22244849801063538, train/raw-loss = 0.18256737291812897, train/logprobs = tensor([[-0.5556, -6.0243],
        [-1.3324, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994055211544037
Epoch 0, Step 689: train/loss = 0.35352426767349243, train/raw-loss = 0.320040762424469, train/logprobs = tensor([[-0.6924, -4.8465],
        [-1.2601, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1674174964427948
Epoch 0, Step 690: train/loss = 0.4771859645843506, train/raw-loss = 0.45175448060035706, train/logprobs = tensor([[-0.3560, -3.5708],
        [-0.5985, -1.0408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271573007106781
Epoch 0, Step 691: train/loss = 0.29472726583480835, train/raw-loss = 0.25128886103630066, train/logprobs = tensor([[-0.7789, -5.2347],
        [-1.9776, -1.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21719202399253845
Epoch 0, Step 692: train/loss = 0.3817934989929199, train/raw-loss = 0.34806591272354126, train/logprobs = tensor([[-0.5076, -2.9661],
        [-0.9773, -0.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16863799095153809
Epoch 0, Step 693: train/loss = 0.4231240153312683, train/raw-loss = 0.39197492599487305, train/logprobs = tensor([[-0.6941, -2.9953],
        [-1.0072, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557454615831375
Epoch 0, Step 694: train/loss = 0.3419038653373718, train/raw-loss = 0.3101142644882202, train/logprobs = tensor([[-0.7676, -5.2129],
        [-1.0912, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589481383562088
Epoch 0, Step 695: train/loss = 0.5364524722099304, train/raw-loss = 0.5010287761688232, train/logprobs = tensor([[-0.6694, -1.8002],
        [-1.2331, -1.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17711834609508514
Epoch 0, Step 696: train/loss = 0.4092768728733063, train/raw-loss = 0.37194040417671204, train/logprobs = tensor([[-0.6514, -3.6355],
        [-1.5260, -1.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18668246269226074
Epoch 0, Step 697: train/loss = 0.40844759345054626, train/raw-loss = 0.3732181787490845, train/logprobs = tensor([[-0.4342, -2.4133],
        [-0.9021, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1761472523212433
Epoch 0, Step 698: train/loss = 0.4443318545818329, train/raw-loss = 0.40926456451416016, train/logprobs = tensor([[-0.7314, -3.2286],
        [-1.4005, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17533640563488007
Epoch 0, Step 699: train/loss = 0.2559650242328644, train/raw-loss = 0.2176271378993988, train/logprobs = tensor([[-0.8707, -5.8607],
        [-1.8352, -1.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19168946146965027
Epoch 0, Step 700: train/loss = 0.39926111698150635, train/raw-loss = 0.3612021803855896, train/logprobs = tensor([[-0.9348, -6.1383],
        [-1.1907, -1.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19029463827610016
Epoch 0, Step 701: train/loss = 0.34970587491989136, train/raw-loss = 0.3125106990337372, train/logprobs = tensor([[-0.7965, -4.8389],
        [-1.1031, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18597589433193207
Epoch 0, Step 702: train/loss = 0.45054829120635986, train/raw-loss = 0.41838935017585754, train/logprobs = tensor([[-0.5502, -2.2058],
        [-1.0179, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16079458594322205
Epoch 0, Step 703: train/loss = 0.5365056991577148, train/raw-loss = 0.5005777478218079, train/logprobs = tensor([[-0.7189, -2.1731],
        [-1.1836, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17963974177837372
Epoch 0, Step 704: train/loss = 0.28136730194091797, train/raw-loss = 0.24266913533210754, train/logprobs = tensor([[-1.2060, -7.8571],
        [-1.9868, -2.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19349075853824615
Epoch 0, Step 705: train/loss = 0.22837720811367035, train/raw-loss = 0.18757444620132446, train/logprobs = tensor([[-0.9727, -5.4279],
        [-1.7821, -1.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20401374995708466
Epoch 0, Step 706: train/loss = 0.4460429549217224, train/raw-loss = 0.4199574291706085, train/logprobs = tensor([[-0.5136, -3.7650],
        [-0.7565, -0.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13042771816253662
Epoch 0, Step 707: train/loss = 0.39833974838256836, train/raw-loss = 0.35979223251342773, train/logprobs = tensor([[-0.7715, -3.9096],
        [-1.2886, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19273778796195984
Epoch 0, Step 708: train/loss = 0.4315495491027832, train/raw-loss = 0.3986567556858063, train/logprobs = tensor([[-0.5941, -4.0403],
        [-0.9869, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644640564918518
Epoch 0, Step 709: train/loss = 0.162139430642128, train/raw-loss = 0.12033003568649292, train/logprobs = tensor([[-0.8399, -7.1076],
        [-2.2231, -1.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20904698967933655
Epoch 0, Step 710: train/loss = 0.3194849491119385, train/raw-loss = 0.2780294418334961, train/logprobs = tensor([[-0.9436, -4.7198],
        [-1.5298, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20727767050266266
Epoch 0, Step 711: train/loss = 0.4692775011062622, train/raw-loss = 0.43568509817123413, train/logprobs = tensor([[-0.5221, -2.5094],
        [-1.0457, -0.4076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16796205937862396
Epoch 0, Step 712: train/loss = 0.40271639823913574, train/raw-loss = 0.36859431862831116, train/logprobs = tensor([[-0.8518, -4.0946],
        [-1.4457, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17061057686805725
Epoch 0, Step 713: train/loss = 0.3468327224254608, train/raw-loss = 0.30897656083106995, train/logprobs = tensor([[-0.9110, -5.6575],
        [-1.4082, -1.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18928073346614838
Epoch 0, Step 714: train/loss = 0.47799551486968994, train/raw-loss = 0.4442022442817688, train/logprobs = tensor([[-0.7925, -4.8840],
        [-1.1834, -1.3700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16896609961986542
Epoch 0, Step 715: train/loss = 0.3025531470775604, train/raw-loss = 0.26805007457733154, train/logprobs = tensor([[-0.7823, -7.0047],
        [-1.0952, -1.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1725153625011444
Epoch 0, Step 716: train/loss = 0.5277202725410461, train/raw-loss = 0.4907635748386383, train/logprobs = tensor([[-0.7262, -1.7575],
        [-1.1645, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18478363752365112
Epoch 0, Step 717: train/loss = 0.43798598647117615, train/raw-loss = 0.4024384021759033, train/logprobs = tensor([[-0.7011, -3.5260],
        [-1.5688, -1.4459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1777377724647522
Epoch 0, Step 718: train/loss = 0.5525655746459961, train/raw-loss = 0.5164938569068909, train/logprobs = tensor([[-1.3270, -3.2758],
        [-1.4674, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18035857379436493
Epoch 0, Step 719: train/loss = 0.45824021100997925, train/raw-loss = 0.42660242319107056, train/logprobs = tensor([[-0.4957, -2.4345],
        [-0.8182, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15818904340267181
Epoch 0, Step 720: train/loss = 0.3456093966960907, train/raw-loss = 0.30361974239349365, train/logprobs = tensor([[-0.8205, -3.9421],
        [-1.4781, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20994830131530762
Epoch 0, Step 721: train/loss = 0.41800278425216675, train/raw-loss = 0.3740423023700714, train/logprobs = tensor([[-0.8939, -3.5376],
        [-1.1944, -1.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21980227530002594
Epoch 0, Step 722: train/loss = 0.7078500390052795, train/raw-loss = 0.6729744076728821, train/logprobs = tensor([[-0.6144, -0.7005],
        [-0.8753, -0.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1743781864643097
Epoch 0, Step 723: train/loss = 0.33203089237213135, train/raw-loss = 0.2812826931476593, train/logprobs = tensor([[-1.0667, -3.9732],
        [-1.6297, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25374096632003784
Epoch 0, Step 724: train/loss = 0.3137871026992798, train/raw-loss = 0.2818044424057007, train/logprobs = tensor([[-0.6029, -5.7517],
        [-1.2357, -1.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15991321206092834
Epoch 0, Step 725: train/loss = 0.5957310199737549, train/raw-loss = 0.559624433517456, train/logprobs = tensor([[-1.2868, -3.0219],
        [-1.0139, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18053314089775085
Epoch 0, Step 726: train/loss = 0.272583931684494, train/raw-loss = 0.2396375834941864, train/logprobs = tensor([[-0.4915, -6.7691],
        [-0.9454, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16473175585269928
Epoch 0, Step 727: train/loss = 0.5403609871864319, train/raw-loss = 0.5058258771896362, train/logprobs = tensor([[-1.2602, -4.6429],
        [-1.0260, -1.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17267584800720215
Epoch 0, Step 728: train/loss = 0.2176702618598938, train/raw-loss = 0.1798713505268097, train/logprobs = tensor([[-0.8707, -8.9090],
        [-1.7752, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18899452686309814
Epoch 0, Step 729: train/loss = 0.569412350654602, train/raw-loss = 0.531377911567688, train/logprobs = tensor([[-1.4021, -2.8236],
        [-1.4271, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190172016620636
Epoch 0, Step 730: train/loss = 0.47712242603302, train/raw-loss = 0.44915443658828735, train/logprobs = tensor([[-0.4025, -2.3244],
        [-0.6516, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13984009623527527
Epoch 0, Step 731: train/loss = 0.4744005799293518, train/raw-loss = 0.4390140473842621, train/logprobs = tensor([[-0.7118, -2.7957],
        [-0.9669, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17693254351615906
Epoch 0, Step 732: train/loss = 0.439314603805542, train/raw-loss = 0.4007211923599243, train/logprobs = tensor([[-0.6190, -3.1168],
        [-1.1509, -1.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19296692311763763
Epoch 0, Step 733: train/loss = 0.44106486439704895, train/raw-loss = 0.41104480624198914, train/logprobs = tensor([[-0.5623, -3.9997],
        [-0.9660, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15010026097297668
Epoch 0, Step 734: train/loss = 0.44646114110946655, train/raw-loss = 0.4088693857192993, train/logprobs = tensor([[-0.9182, -2.9373],
        [-1.3578, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18795885145664215
Epoch 0, Step 735: train/loss = 0.6913886666297913, train/raw-loss = 0.6565320491790771, train/logprobs = tensor([[-0.9868, -1.4241],
        [-0.8463, -1.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17428316175937653
Epoch 0, Step 736: train/loss = 0.6404663920402527, train/raw-loss = 0.6138461232185364, train/logprobs = tensor([[-0.3958, -1.1012],
        [-0.6844, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13310138881206512
Epoch 0, Step 737: train/loss = 0.27133846282958984, train/raw-loss = 0.22694489359855652, train/logprobs = tensor([[-0.8616, -3.8254],
        [-1.9275, -1.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2219679206609726
Epoch 0, Step 738: train/loss = 0.5945115685462952, train/raw-loss = 0.5586870312690735, train/logprobs = tensor([[-0.6612, -2.0224],
        [-1.5440, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17912250757217407
Epoch 0, Step 739: train/loss = 0.3645608425140381, train/raw-loss = 0.32884785532951355, train/logprobs = tensor([[-1.1890, -3.7126],
        [-2.3227, -1.5654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17856495082378387
Epoch 0, Step 740: train/loss = 0.22575372457504272, train/raw-loss = 0.1874638795852661, train/logprobs = tensor([[-0.8569, -5.2758],
        [-1.6111, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19144919514656067
Epoch 0, Step 741: train/loss = 0.22181308269500732, train/raw-loss = 0.17490363121032715, train/logprobs = tensor([[-0.9326, -7.5141],
        [-1.9140, -1.2515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23454737663269043
Epoch 0, Step 742: train/loss = 0.45187026262283325, train/raw-loss = 0.41691431403160095, train/logprobs = tensor([[-0.5377, -2.9716],
        [-1.0084, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1747797131538391
Epoch 0, Step 743: train/loss = 0.29930025339126587, train/raw-loss = 0.26469096541404724, train/logprobs = tensor([[-1.0695, -6.9622],
        [-1.7729, -1.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1730463057756424
Epoch 0, Step 744: train/loss = 0.581564724445343, train/raw-loss = 0.5504848957061768, train/logprobs = tensor([[-0.6623, -1.1711],
        [-0.8731, -0.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15539894998073578
Epoch 0, Step 745: train/loss = 0.3915489912033081, train/raw-loss = 0.35803553462028503, train/logprobs = tensor([[-0.4914, -3.2375],
        [-0.8126, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16756737232208252
Epoch 0, Step 746: train/loss = 0.6449253559112549, train/raw-loss = 0.6094133853912354, train/logprobs = tensor([[-0.7290, -0.8194],
        [-0.9611, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17755964398384094
Epoch 0, Step 747: train/loss = 0.45234790444374084, train/raw-loss = 0.4227604269981384, train/logprobs = tensor([[-0.5854, -2.3846],
        [-0.8152, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479371190071106
Epoch 0, Step 748: train/loss = 0.5318228602409363, train/raw-loss = 0.4983671009540558, train/logprobs = tensor([[-0.4870, -1.4908],
        [-1.0895, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1672787368297577
Epoch 0, Step 749: train/loss = 0.47428521513938904, train/raw-loss = 0.43586286902427673, train/logprobs = tensor([[-1.0070, -4.2476],
        [-1.4439, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19211174547672272
Epoch 0, Step 750: train/loss = 0.4103490710258484, train/raw-loss = 0.37202194333076477, train/logprobs = tensor([[-0.9334, -5.0738],
        [-2.1674, -2.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19163566827774048
Epoch 0, Step 751: train/loss = 0.5485842227935791, train/raw-loss = 0.5145332217216492, train/logprobs = tensor([[-0.6642, -3.5789],
        [-0.9249, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17025478184223175
Epoch 0, Step 752: train/loss = 0.513785183429718, train/raw-loss = 0.4801383316516876, train/logprobs = tensor([[-0.5451, -3.4325],
        [-0.9866, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16823436319828033
Epoch 0, Step 753: train/loss = 0.34337568283081055, train/raw-loss = 0.3059549629688263, train/logprobs = tensor([[-0.6654, -3.4654],
        [-1.0075, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18710343539714813
Epoch 0, Step 754: train/loss = 0.3757423162460327, train/raw-loss = 0.3395591378211975, train/logprobs = tensor([[-0.7324, -2.9993],
        [-1.2952, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18091584742069244
Epoch 0, Step 755: train/loss = 0.3199698030948639, train/raw-loss = 0.2785901725292206, train/logprobs = tensor([[-0.9619, -6.3779],
        [-1.7712, -1.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20689824223518372
Epoch 0, Step 756: train/loss = 0.3996739983558655, train/raw-loss = 0.36501285433769226, train/logprobs = tensor([[-1.0437, -4.8562],
        [-1.5340, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17330576479434967
Epoch 0, Step 757: train/loss = 0.5092958807945251, train/raw-loss = 0.46872952580451965, train/logprobs = tensor([[-0.6723, -4.0449],
        [-1.0854, -0.8862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20283162593841553
Epoch 0, Step 758: train/loss = 0.34014299511909485, train/raw-loss = 0.3070584237575531, train/logprobs = tensor([[-0.5845, -5.2888],
        [-1.1855, -1.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16542281210422516
Epoch 0, Step 759: train/loss = 0.4178514778614044, train/raw-loss = 0.3816149830818176, train/logprobs = tensor([[-0.7661, -4.2077],
        [-1.0976, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18118256330490112
Epoch 0, Step 760: train/loss = 0.49674177169799805, train/raw-loss = 0.4601486921310425, train/logprobs = tensor([[-1.2735, -3.5848],
        [-1.5049, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18296577036380768
Epoch 0, Step 761: train/loss = 0.6441583037376404, train/raw-loss = 0.608609139919281, train/logprobs = tensor([[-1.3723, -1.4899],
        [-1.6896, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17774580419063568
Epoch 0, Step 762: train/loss = 0.45422470569610596, train/raw-loss = 0.4126279950141907, train/logprobs = tensor([[-0.6353, -3.3249],
        [-1.2339, -0.9858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20798349380493164
Epoch 0, Step 763: train/loss = 0.38940611481666565, train/raw-loss = 0.3439027667045593, train/logprobs = tensor([[-0.8949, -2.9345],
        [-1.5459, -1.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22751665115356445
Epoch 0, Step 764: train/loss = 0.495329886674881, train/raw-loss = 0.4611346125602722, train/logprobs = tensor([[-0.6771, -1.7419],
        [-1.2192, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17097651958465576
Epoch 0, Step 765: train/loss = 0.3982449173927307, train/raw-loss = 0.36478838324546814, train/logprobs = tensor([[-0.7049, -5.2696],
        [-1.4031, -1.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16728271543979645
Epoch 0, Step 766: train/loss = 0.27913206815719604, train/raw-loss = 0.23629452288150787, train/logprobs = tensor([[-0.8710, -4.0658],
        [-1.5103, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21418774127960205
Epoch 0, Step 767: train/loss = 0.5528886914253235, train/raw-loss = 0.514008641242981, train/logprobs = tensor([[-0.6522, -2.1592],
        [-0.9559, -1.1894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19440032541751862
Epoch 0, Step 768: train/loss = 0.6466063261032104, train/raw-loss = 0.6160299777984619, train/logprobs = tensor([[-0.6023, -1.0412],
        [-0.7873, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528814733028412
Epoch 0, Step 769: train/loss = 0.3800531327724457, train/raw-loss = 0.3405003547668457, train/logprobs = tensor([[-0.9108, -3.2715],
        [-1.3410, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19776390492916107
Epoch 0, Step 770: train/loss = 0.47399356961250305, train/raw-loss = 0.44250616431236267, train/logprobs = tensor([[-0.5019, -2.1301],
        [-0.7673, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574370115995407
Epoch 0, Step 771: train/loss = 0.3049841821193695, train/raw-loss = 0.2741566598415375, train/logprobs = tensor([[-0.6651, -4.7203],
        [-0.9273, -1.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15413758158683777
Epoch 0, Step 772: train/loss = 0.2987057566642761, train/raw-loss = 0.2595091462135315, train/logprobs = tensor([[-1.0673, -4.1033],
        [-1.4837, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1959831416606903
Epoch 0, Step 773: train/loss = 0.4371275007724762, train/raw-loss = 0.40108349919319153, train/logprobs = tensor([[-1.0955, -3.9998],
        [-1.1256, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802200973033905
Epoch 0, Step 774: train/loss = 0.4692698121070862, train/raw-loss = 0.43348953127861023, train/logprobs = tensor([[-1.3026, -2.9972],
        [-1.3731, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17890138924121857
Epoch 0, Step 775: train/loss = 0.7696484923362732, train/raw-loss = 0.7331718802452087, train/logprobs = tensor([[-2.9896, -8.4650],
        [-1.5024, -1.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18238279223442078
Epoch 0, Step 776: train/loss = 0.31095999479293823, train/raw-loss = 0.280047744512558, train/logprobs = tensor([[-0.7768, -5.2120],
        [-1.2736, -1.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15456116199493408
Epoch 0, Step 777: train/loss = 0.46944665908813477, train/raw-loss = 0.43963566422462463, train/logprobs = tensor([[-0.5292, -2.3822],
        [-0.9774, -0.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14905481040477753
Epoch 0, Step 778: train/loss = 0.3756864666938782, train/raw-loss = 0.3386250436306, train/logprobs = tensor([[-0.7277, -3.8926],
        [-1.1327, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1853070706129074
Epoch 0, Step 779: train/loss = 0.4735640287399292, train/raw-loss = 0.440131813287735, train/logprobs = tensor([[-0.8152, -4.1965],
        [-0.8689, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16716107726097107
Epoch 0, Step 780: train/loss = 0.5746801495552063, train/raw-loss = 0.5458427667617798, train/logprobs = tensor([[-0.6191, -1.9054],
        [-0.6930, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14418677985668182
Epoch 0, Step 781: train/loss = 0.45967432856559753, train/raw-loss = 0.42263126373291016, train/logprobs = tensor([[-0.9105, -2.8170],
        [-1.4810, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18521520495414734
Epoch 0, Step 782: train/loss = 0.4033300578594208, train/raw-loss = 0.3567425608634949, train/logprobs = tensor([[-1.7173, -7.3737],
        [-1.5591, -1.3156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329372763633728
Epoch 0, Step 783: train/loss = 0.2899421155452728, train/raw-loss = 0.25500738620758057, train/logprobs = tensor([[-0.7043, -4.5013],
        [-1.1089, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1746736615896225
Epoch 0, Step 784: train/loss = 0.2340763360261917, train/raw-loss = 0.1997605711221695, train/logprobs = tensor([[ -0.8108, -10.5215],
        [ -1.4729,  -1.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1715787649154663
Epoch 0, Step 785: train/loss = 0.48211073875427246, train/raw-loss = 0.4573281705379486, train/logprobs = tensor([[-0.3889, -3.0692],
        [-0.5251, -0.9364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1239127516746521
Epoch 0, Step 786: train/loss = 0.2953767776489258, train/raw-loss = 0.26201358437538147, train/logprobs = tensor([[-0.6649, -6.5413],
        [-0.9123, -1.2061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16681590676307678
Epoch 0, Step 787: train/loss = 0.4860711097717285, train/raw-loss = 0.44828325510025024, train/logprobs = tensor([[-0.7044, -2.6050],
        [-1.0198, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18893936276435852
Epoch 0, Step 788: train/loss = 0.3589991629123688, train/raw-loss = 0.32092392444610596, train/logprobs = tensor([[-0.7064, -7.2658],
        [-1.1697, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19037625193595886
Epoch 0, Step 789: train/loss = 0.6066049337387085, train/raw-loss = 0.5765579342842102, train/logprobs = tensor([[-0.8980, -1.7248],
        [-0.7930, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502349078655243
Epoch 0, Step 790: train/loss = 0.48477697372436523, train/raw-loss = 0.4486907720565796, train/logprobs = tensor([[-0.6932, -2.8905],
        [-0.8776, -0.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18043111264705658
Epoch 0, Step 791: train/loss = 0.5768744349479675, train/raw-loss = 0.5434893369674683, train/logprobs = tensor([[-1.0425, -1.5922],
        [-1.2747, -0.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16692563891410828
Epoch 0, Step 792: train/loss = 0.3806055188179016, train/raw-loss = 0.3450138568878174, train/logprobs = tensor([[-0.7890, -3.5120],
        [-1.3179, -0.9585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17795835435390472
Epoch 0, Step 793: train/loss = 0.45613962411880493, train/raw-loss = 0.41860058903694153, train/logprobs = tensor([[-0.8050, -6.0651],
        [-1.2234, -1.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18769514560699463
Epoch 0, Step 794: train/loss = 0.29712462425231934, train/raw-loss = 0.25497138500213623, train/logprobs = tensor([[-0.7383, -5.4473],
        [-1.3656, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2107662707567215
Epoch 0, Step 795: train/loss = 0.38374924659729004, train/raw-loss = 0.35184359550476074, train/logprobs = tensor([[-1.0324, -4.4295],
        [-1.1655, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15952812135219574
Epoch 0, Step 796: train/loss = 0.30711793899536133, train/raw-loss = 0.26860344409942627, train/logprobs = tensor([[-0.8874, -6.7714],
        [-1.3544, -1.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19257250428199768
Epoch 0, Step 797: train/loss = 0.48450222611427307, train/raw-loss = 0.45353496074676514, train/logprobs = tensor([[-0.5529, -1.8285],
        [-0.7919, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15483634173870087
Epoch 0, Step 798: train/loss = 0.4697742164134979, train/raw-loss = 0.43940305709838867, train/logprobs = tensor([[-0.8315, -5.3504],
        [-0.8965, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518559753894806
Epoch 0, Step 799: train/loss = 0.474968820810318, train/raw-loss = 0.4357927739620209, train/logprobs = tensor([[-1.2726, -5.9734],
        [-1.5477, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19588036835193634
Epoch 0, Step 800: train/loss = 0.6428372859954834, train/raw-loss = 0.6095749139785767, train/logprobs = tensor([[-1.3506, -2.1483],
        [-1.0776, -0.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16631145775318146
Epoch 0, Step 801: train/loss = 0.23097364604473114, train/raw-loss = 0.18810787796974182, train/logprobs = tensor([[-1.0804, -7.8571],
        [-1.7798, -1.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21432875096797943
Epoch 0, Step 802: train/loss = 0.432888925075531, train/raw-loss = 0.40470629930496216, train/logprobs = tensor([[-0.7976, -2.5937],
        [-1.0959, -1.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14091311395168304
Epoch 0, Step 803: train/loss = 0.3639695644378662, train/raw-loss = 0.3344167470932007, train/logprobs = tensor([[-0.7902, -4.6065],
        [-1.1225, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14776399731636047
Epoch 0, Step 804: train/loss = 0.515411913394928, train/raw-loss = 0.4784792959690094, train/logprobs = tensor([[-0.8554, -3.6765],
        [-1.1947, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18466323614120483
Epoch 0, Step 805: train/loss = 0.4782874882221222, train/raw-loss = 0.4478767514228821, train/logprobs = tensor([[-0.5695, -2.5886],
        [-0.8282, -0.7052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15205371379852295
Epoch 0, Step 806: train/loss = 0.38502222299575806, train/raw-loss = 0.3465970456600189, train/logprobs = tensor([[-0.9865, -5.2178],
        [-1.3450, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1921258568763733
Epoch 0, Step 807: train/loss = 0.3306106626987457, train/raw-loss = 0.2941248416900635, train/logprobs = tensor([[-0.8722, -7.0809],
        [-1.1587, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824290156364441
Epoch 0, Step 808: train/loss = 0.3377372622489929, train/raw-loss = 0.3062232732772827, train/logprobs = tensor([[-0.6683, -4.0377],
        [-1.1105, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1575699746608734
Epoch 0, Step 809: train/loss = 0.34468406438827515, train/raw-loss = 0.30547305941581726, train/logprobs = tensor([[-0.7774, -6.0250],
        [-1.2166, -0.8276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19605490565299988
Epoch 0, Step 810: train/loss = 0.29639533162117004, train/raw-loss = 0.25914034247398376, train/logprobs = tensor([[-0.7003, -5.0101],
        [-1.2098, -0.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627497553825378
Epoch 0, Step 811: train/loss = 0.4935281276702881, train/raw-loss = 0.45690980553627014, train/logprobs = tensor([[-0.7717, -3.7929],
        [-0.9897, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18309172987937927
Epoch 0, Step 812: train/loss = 0.5546650886535645, train/raw-loss = 0.5226380825042725, train/logprobs = tensor([[-0.8632, -2.3158],
        [-1.1420, -1.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1601351797580719
Epoch 0, Step 813: train/loss = 0.5204085111618042, train/raw-loss = 0.4861065149307251, train/logprobs = tensor([[-0.9656, -1.9288],
        [-0.9584, -0.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17150989174842834
Epoch 0, Step 814: train/loss = 0.25638633966445923, train/raw-loss = 0.22176051139831543, train/logprobs = tensor([[-0.8592, -5.6046],
        [-2.1640, -1.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.173129141330719
Epoch 0, Step 815: train/loss = 0.44211578369140625, train/raw-loss = 0.40616920590400696, train/logprobs = tensor([[-0.8593, -2.9352],
        [-0.9565, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1797327995300293
Epoch 0, Step 816: train/loss = 0.2949121594429016, train/raw-loss = 0.26986053586006165, train/logprobs = tensor([[-0.4877, -8.0336],
        [-0.6194, -1.6307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252581775188446
Epoch 0, Step 817: train/loss = 0.3783678114414215, train/raw-loss = 0.3392144441604614, train/logprobs = tensor([[-1.0683, -5.2312],
        [-1.4767, -1.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19576682150363922
Epoch 0, Step 818: train/loss = 0.3035001754760742, train/raw-loss = 0.268054723739624, train/logprobs = tensor([[-0.7368, -8.1199],
        [-1.2661, -2.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1772272288799286
Epoch 0, Step 819: train/loss = 0.3600196838378906, train/raw-loss = 0.3312240540981293, train/logprobs = tensor([[-0.4278, -5.0189],
        [-0.7963, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14397823810577393
Epoch 0, Step 820: train/loss = 0.374606728553772, train/raw-loss = 0.3342980444431305, train/logprobs = tensor([[-1.0282, -4.1493],
        [-1.3788, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20154350996017456
Epoch 0, Step 821: train/loss = 0.4056708812713623, train/raw-loss = 0.36764270067214966, train/logprobs = tensor([[-0.8036, -3.0668],
        [-1.3829, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19014079868793488
Epoch 0, Step 822: train/loss = 0.46927833557128906, train/raw-loss = 0.43948662281036377, train/logprobs = tensor([[-0.8082, -3.1528],
        [-0.9493, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14895862340927124
Epoch 0, Step 823: train/loss = 0.5088813304901123, train/raw-loss = 0.47635194659233093, train/logprobs = tensor([[-1.3269, -5.4499],
        [-1.0662, -2.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626470386981964
Epoch 0, Step 824: train/loss = 0.33972403407096863, train/raw-loss = 0.3056352138519287, train/logprobs = tensor([[-0.6053, -5.6185],
        [-1.1050, -1.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17044398188591003
Epoch 0, Step 825: train/loss = 0.6618692874908447, train/raw-loss = 0.6283012628555298, train/logprobs = tensor([[-1.0458, -0.7280],
        [-1.4860, -0.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16784007847309113
Epoch 0, Step 826: train/loss = 0.3672076463699341, train/raw-loss = 0.3299647271633148, train/logprobs = tensor([[-1.0248, -3.8681],
        [-1.5161, -1.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18621458113193512
Epoch 0, Step 827: train/loss = 0.42122215032577515, train/raw-loss = 0.3918798565864563, train/logprobs = tensor([[-0.5738, -2.9952],
        [-0.7284, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14671143889427185
Epoch 0, Step 828: train/loss = 0.2889400124549866, train/raw-loss = 0.2488335371017456, train/logprobs = tensor([[-0.8927, -3.7500],
        [-1.7807, -0.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20053242146968842
Epoch 0, Step 829: train/loss = 0.5209718942642212, train/raw-loss = 0.4849056005477905, train/logprobs = tensor([[-1.2489, -3.9016],
        [-1.2556, -1.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18033169209957123
Epoch 0, Step 830: train/loss = 0.39801913499832153, train/raw-loss = 0.36977285146713257, train/logprobs = tensor([[-0.4746, -5.9622],
        [-0.6871, -1.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1412314772605896
Epoch 0, Step 831: train/loss = 0.3318990468978882, train/raw-loss = 0.3030412793159485, train/logprobs = tensor([[-0.5337, -2.5730],
        [-1.1446, -0.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14428888261318207
Epoch 0, Step 832: train/loss = 0.3741416931152344, train/raw-loss = 0.3382267951965332, train/logprobs = tensor([[-0.8183, -3.1157],
        [-1.4999, -0.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17957431077957153
Epoch 0, Step 833: train/loss = 0.6126006245613098, train/raw-loss = 0.5775489807128906, train/logprobs = tensor([[-0.8807, -1.3176],
        [-0.9223, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17525839805603027
Epoch 0, Step 834: train/loss = 0.32262173295021057, train/raw-loss = 0.2831369638442993, train/logprobs = tensor([[-1.2123, -5.7950],
        [-1.6659, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1974238008260727
Epoch 0, Step 835: train/loss = 0.5755355358123779, train/raw-loss = 0.5479812622070312, train/logprobs = tensor([[-0.9866, -3.7958],
        [-1.2624, -1.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13777127861976624
Epoch 0, Step 836: train/loss = 0.40685057640075684, train/raw-loss = 0.3714473843574524, train/logprobs = tensor([[-0.7276, -4.7722],
        [-1.2120, -1.3950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17701590061187744
Epoch 0, Step 837: train/loss = 0.36980265378952026, train/raw-loss = 0.3368849456310272, train/logprobs = tensor([[-0.5665, -3.4024],
        [-0.8353, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16458868980407715
Epoch 0, Step 838: train/loss = 0.4025481939315796, train/raw-loss = 0.3679220676422119, train/logprobs = tensor([[-0.9055, -4.3451],
        [-1.0751, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17313051223754883
Epoch 0, Step 839: train/loss = 0.31660789251327515, train/raw-loss = 0.2861337661743164, train/logprobs = tensor([[-0.7228, -5.0398],
        [-1.1956, -1.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1523706167936325
Epoch 0, Step 840: train/loss = 0.3426038920879364, train/raw-loss = 0.3000219464302063, train/logprobs = tensor([[-0.8310, -6.9692],
        [-1.4816, -1.0598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21290969848632812
Epoch 0, Step 841: train/loss = 0.5150396823883057, train/raw-loss = 0.4775569438934326, train/logprobs = tensor([[-0.7335, -2.4989],
        [-1.1360, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1874135434627533
Epoch 0, Step 842: train/loss = 0.36219972372055054, train/raw-loss = 0.32843688130378723, train/logprobs = tensor([[-0.6149, -5.2570],
        [-1.4349, -1.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16881415247917175
Epoch 0, Step 843: train/loss = 0.39025378227233887, train/raw-loss = 0.3529730439186096, train/logprobs = tensor([[-1.2408, -4.9162],
        [-1.1941, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18640375137329102
Epoch 0, Step 844: train/loss = 0.4555909037590027, train/raw-loss = 0.41846954822540283, train/logprobs = tensor([[-1.5546, -5.6506],
        [-1.3496, -1.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1856066882610321
Epoch 0, Step 845: train/loss = 0.3305765390396118, train/raw-loss = 0.29207003116607666, train/logprobs = tensor([[-0.9001, -6.2892],
        [-1.5631, -1.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19253267347812653
Epoch 0, Step 846: train/loss = 0.3232269287109375, train/raw-loss = 0.2968119978904724, train/logprobs = tensor([[-0.5809, -9.0007],
        [-0.9489, -1.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13207471370697021
Epoch 0, Step 847: train/loss = 0.41710999608039856, train/raw-loss = 0.3843246102333069, train/logprobs = tensor([[-0.9373, -4.2608],
        [-1.2038, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16392700374126434
Epoch 0, Step 848: train/loss = 0.2510972321033478, train/raw-loss = 0.20918357372283936, train/logprobs = tensor([[-0.9856, -5.1421],
        [-1.8517, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20956823229789734
Epoch 0, Step 849: train/loss = 0.2709340453147888, train/raw-loss = 0.23456275463104248, train/logprobs = tensor([[-1.5030, -8.8667],
        [-1.8682, -1.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18185655772686005
Epoch 0, Step 850: train/loss = 0.42963120341300964, train/raw-loss = 0.396129310131073, train/logprobs = tensor([[-0.6900, -4.3601],
        [-0.9537, -1.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16750945150852203
Epoch 0, Step 851: train/loss = 0.3443133234977722, train/raw-loss = 0.3083549737930298, train/logprobs = tensor([[-1.0941, -6.4148],
        [-1.6378, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17979170382022858
Epoch 0, Step 852: train/loss = 0.37013423442840576, train/raw-loss = 0.3381378948688507, train/logprobs = tensor([[-0.6012, -4.6351],
        [-1.1506, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1599816083908081
Epoch 0, Step 853: train/loss = 0.5650082230567932, train/raw-loss = 0.533048689365387, train/logprobs = tensor([[-1.3494, -3.8226],
        [-1.5313, -1.1464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1597977876663208
Epoch 0, Step 854: train/loss = 0.3618053197860718, train/raw-loss = 0.32354098558425903, train/logprobs = tensor([[-0.9295, -5.8003],
        [-1.4166, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19132179021835327
Epoch 0, Step 855: train/loss = 0.40049177408218384, train/raw-loss = 0.3676767945289612, train/logprobs = tensor([[-0.8664, -4.7419],
        [-1.3186, -1.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640748530626297
Epoch 0, Step 856: train/loss = 0.2787516117095947, train/raw-loss = 0.23942574858665466, train/logprobs = tensor([[-0.8877, -4.6222],
        [-1.6590, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19662931561470032
Epoch 0, Step 857: train/loss = 0.35674041509628296, train/raw-loss = 0.3149716258049011, train/logprobs = tensor([[-0.8133, -6.5942],
        [-1.4441, -1.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20884400606155396
Epoch 0, Step 858: train/loss = 0.5939894914627075, train/raw-loss = 0.5536432266235352, train/logprobs = tensor([[-2.1508, -3.4175],
        [-1.5708, -0.7963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2017313838005066
Epoch 0, Step 859: train/loss = 0.39374643564224243, train/raw-loss = 0.3623214066028595, train/logprobs = tensor([[-0.8509, -3.4153],
        [-1.4689, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15712513029575348
Epoch 0, Step 860: train/loss = 0.43357542157173157, train/raw-loss = 0.39779627323150635, train/logprobs = tensor([[-0.9976, -4.1817],
        [-1.1607, -1.3808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788957118988037
Epoch 0, Step 861: train/loss = 0.5568535327911377, train/raw-loss = 0.5187418460845947, train/logprobs = tensor([[-1.1334, -4.0542],
        [-1.0641, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19055858254432678
Epoch 0, Step 862: train/loss = 0.3404780626296997, train/raw-loss = 0.30000364780426025, train/logprobs = tensor([[-0.9538, -6.7315],
        [-1.2544, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.202372208237648
Epoch 0, Step 863: train/loss = 0.5499223470687866, train/raw-loss = 0.5118017792701721, train/logprobs = tensor([[-1.2724, -4.3546],
        [-1.1665, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1906026303768158
Epoch 0, Step 864: train/loss = 0.6507017016410828, train/raw-loss = 0.6155598163604736, train/logprobs = tensor([[-1.4578, -2.5528],
        [-1.2117, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17570918798446655
Epoch 0, Step 865: train/loss = 0.33985820412635803, train/raw-loss = 0.3015521168708801, train/logprobs = tensor([[-0.9010, -3.3397],
        [-1.5399, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19153040647506714
Epoch 0, Step 866: train/loss = 0.32685616612434387, train/raw-loss = 0.292165070772171, train/logprobs = tensor([[-0.7791, -6.0814],
        [-0.9589, -1.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17345549166202545
Epoch 0, Step 867: train/loss = 0.5640630722045898, train/raw-loss = 0.5291081666946411, train/logprobs = tensor([[-0.8057, -2.7537],
        [-1.2526, -1.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1747743934392929
Epoch 0, Step 868: train/loss = 0.45808669924736023, train/raw-loss = 0.41197413206100464, train/logprobs = tensor([[-0.9916, -2.0097],
        [-1.5745, -0.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2305627316236496
Epoch 0, Step 869: train/loss = 0.3768324851989746, train/raw-loss = 0.33789533376693726, train/logprobs = tensor([[-0.9613, -2.0244],
        [-1.8397, -0.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19468575716018677
Epoch 0, Step 870: train/loss = 0.4034533202648163, train/raw-loss = 0.37035897374153137, train/logprobs = tensor([[-0.9775, -6.6777],
        [-1.4209, -1.5873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16547170281410217
Epoch 0, Step 871: train/loss = 0.32799381017684937, train/raw-loss = 0.29383718967437744, train/logprobs = tensor([[-0.6097, -5.3690],
        [-1.0767, -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17078296840190887
Epoch 0, Step 872: train/loss = 0.4845283627510071, train/raw-loss = 0.45617175102233887, train/logprobs = tensor([[-0.4446, -3.4141],
        [-0.5969, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14178308844566345
Epoch 0, Step 873: train/loss = 0.4144246578216553, train/raw-loss = 0.38249966502189636, train/logprobs = tensor([[-0.9662, -3.8028],
        [-1.2993, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15962478518486023
Epoch 0, Step 874: train/loss = 0.30016833543777466, train/raw-loss = 0.25435715913772583, train/logprobs = tensor([[-1.1642, -6.5233],
        [-1.9768, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22905588150024414
Epoch 0, Step 875: train/loss = 0.6039703488349915, train/raw-loss = 0.5721712708473206, train/logprobs = tensor([[-0.9740, -1.2855],
        [-1.3277, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589953452348709
Epoch 0, Step 876: train/loss = 0.37615424394607544, train/raw-loss = 0.34996894001960754, train/logprobs = tensor([[-0.4522, -6.6263],
        [-0.8809, -1.2699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13092651963233948
Epoch 0, Step 877: train/loss = 0.4014138877391815, train/raw-loss = 0.3611446022987366, train/logprobs = tensor([[-1.3836, -5.4620],
        [-2.0842, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20134630799293518
Epoch 0, Step 878: train/loss = 0.9912527799606323, train/raw-loss = 0.9531760811805725, train/logprobs = tensor([[-3.0414, -5.5142],
        [-1.4772, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19038335978984833
Epoch 0, Step 879: train/loss = 0.30417096614837646, train/raw-loss = 0.2708805501461029, train/logprobs = tensor([[-0.5296, -8.3687],
        [-1.1537, -1.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16645193099975586
Epoch 0, Step 880: train/loss = 0.33633938431739807, train/raw-loss = 0.3032774031162262, train/logprobs = tensor([[-0.7305, -5.0015],
        [-1.1199, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165309876203537
Epoch 0, Step 881: train/loss = 0.48132577538490295, train/raw-loss = 0.4474370777606964, train/logprobs = tensor([[-0.6754, -4.2751],
        [-0.9286, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16944341361522675
Epoch 0, Step 882: train/loss = 0.5764374136924744, train/raw-loss = 0.5422062873840332, train/logprobs = tensor([[-0.9224, -2.2072],
        [-0.8509, -1.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17115575075149536
Epoch 0, Step 883: train/loss = 0.34442633390426636, train/raw-loss = 0.3038000166416168, train/logprobs = tensor([[-1.2276, -3.8488],
        [-2.0415, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20313173532485962
Epoch 0, Step 884: train/loss = 0.37431174516677856, train/raw-loss = 0.33662813901901245, train/logprobs = tensor([[-0.7594, -4.5415],
        [-1.1159, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18841807544231415
Epoch 0, Step 885: train/loss = 0.32776081562042236, train/raw-loss = 0.28882551193237305, train/logprobs = tensor([[-1.2320, -5.9125],
        [-1.3878, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19467639923095703
Epoch 0, Step 886: train/loss = 0.500113844871521, train/raw-loss = 0.4649178981781006, train/logprobs = tensor([[-0.7476, -2.9481],
        [-1.2710, -0.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1759798526763916
Epoch 0, Step 887: train/loss = 0.43863826990127563, train/raw-loss = 0.4043596684932709, train/logprobs = tensor([[-0.7962, -4.5813],
        [-1.1509, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1713930368423462
Epoch 0, Step 888: train/loss = 0.21643874049186707, train/raw-loss = 0.1784439980983734, train/logprobs = tensor([[-0.7646, -6.4235],
        [-1.5425, -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18997377157211304
Epoch 0, Step 889: train/loss = 0.39941611886024475, train/raw-loss = 0.3614051342010498, train/logprobs = tensor([[-0.9723, -3.8412],
        [-1.3509, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19005495309829712
Epoch 0, Step 890: train/loss = 0.3761655390262604, train/raw-loss = 0.3356952965259552, train/logprobs = tensor([[-0.8795, -3.5547],
        [-1.3037, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20235119760036469
Epoch 0, Step 891: train/loss = 0.27573415637016296, train/raw-loss = 0.2443876713514328, train/logprobs = tensor([[-0.8339, -5.8201],
        [-1.4050, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15673258900642395
Epoch 0, Step 892: train/loss = 0.3624255955219269, train/raw-loss = 0.324139267206192, train/logprobs = tensor([[-0.7251, -4.6897],
        [-1.2080, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19143164157867432
Epoch 0, Step 893: train/loss = 0.4319540560245514, train/raw-loss = 0.39996349811553955, train/logprobs = tensor([[-0.8462, -4.0762],
        [-1.1526, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15995271503925323
Epoch 0, Step 894: train/loss = 0.3440367579460144, train/raw-loss = 0.3047082722187042, train/logprobs = tensor([[-0.8211, -7.2130],
        [-1.2834, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19664254784584045
Epoch 0, Step 895: train/loss = 0.43316179513931274, train/raw-loss = 0.3972605764865875, train/logprobs = tensor([[-0.7065, -5.6057],
        [-1.4420, -2.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1795060932636261
Epoch 0, Step 896: train/loss = 0.5302298069000244, train/raw-loss = 0.49465256929397583, train/logprobs = tensor([[-1.0200, -2.5704],
        [-1.1681, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17788635194301605
Epoch 0, Step 897: train/loss = 0.45472899079322815, train/raw-loss = 0.4082161784172058, train/logprobs = tensor([[-1.0770, -3.5429],
        [-1.6128, -1.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23256415128707886
Epoch 0, Step 898: train/loss = 0.5053486227989197, train/raw-loss = 0.472406268119812, train/logprobs = tensor([[-0.8123, -1.4349],
        [-1.1873, -0.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16471178829669952
Epoch 0, Step 899: train/loss = 0.4189106822013855, train/raw-loss = 0.3794430196285248, train/logprobs = tensor([[-0.7205, -4.3728],
        [-1.1411, -1.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19733843207359314
Epoch 0, Step 900: train/loss = 0.2847357392311096, train/raw-loss = 0.24802838265895844, train/logprobs = tensor([[ -1.3091, -10.2623],
        [ -1.6613,  -1.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18353679776191711
Epoch 0, Step 901: train/loss = 0.34187689423561096, train/raw-loss = 0.30797624588012695, train/logprobs = tensor([[-0.4475, -4.4291],
        [-1.0108, -1.0903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1695033609867096
Epoch 0, Step 902: train/loss = 0.23328329622745514, train/raw-loss = 0.19606229662895203, train/logprobs = tensor([[-0.8069, -7.7618],
        [-1.5453, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18610501289367676
Epoch 0, Step 903: train/loss = 0.3715529441833496, train/raw-loss = 0.32979822158813477, train/logprobs = tensor([[-1.0837, -3.8161],
        [-1.7223, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087734043598175
Epoch 0, Step 904: train/loss = 0.4147122800350189, train/raw-loss = 0.3833051919937134, train/logprobs = tensor([[-1.4428, -4.5687],
        [-1.6417, -1.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15703552961349487
Epoch 0, Step 905: train/loss = 0.29469653964042664, train/raw-loss = 0.2646833658218384, train/logprobs = tensor([[-0.5191, -6.8305],
        [-1.0254, -1.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15006588399410248
Epoch 0, Step 906: train/loss = 0.6032626628875732, train/raw-loss = 0.5759433507919312, train/logprobs = tensor([[-0.7334, -1.4321],
        [-0.6973, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13659648597240448
Epoch 0, Step 907: train/loss = 0.5907586216926575, train/raw-loss = 0.5579947233200073, train/logprobs = tensor([[-0.9403, -1.7220],
        [-0.9068, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638195514678955
Epoch 0, Step 908: train/loss = 0.34486716985702515, train/raw-loss = 0.3076273500919342, train/logprobs = tensor([[-0.8234, -5.4410],
        [-1.3191, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18619918823242188
Epoch 0, Step 909: train/loss = 0.30715370178222656, train/raw-loss = 0.26265814900398254, train/logprobs = tensor([[-1.3586, -4.5581],
        [-2.1422, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22247782349586487
Epoch 0, Step 910: train/loss = 0.5210033655166626, train/raw-loss = 0.48523348569869995, train/logprobs = tensor([[-1.0599, -4.0074],
        [-1.2253, -1.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788492202758789
Epoch 0, Step 911: train/loss = 0.265489399433136, train/raw-loss = 0.2278919368982315, train/logprobs = tensor([[-0.9007, -7.0071],
        [-1.3699, -1.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1879872977733612
Epoch 0, Step 912: train/loss = 0.4408736526966095, train/raw-loss = 0.40334707498550415, train/logprobs = tensor([[-1.3221, -5.7642],
        [-1.1230, -1.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1876329481601715
Epoch 0, Step 913: train/loss = 0.32813626527786255, train/raw-loss = 0.29139962792396545, train/logprobs = tensor([[-0.8604, -5.9324],
        [-1.5688, -1.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18368327617645264
Epoch 0, Step 914: train/loss = 0.5045782327651978, train/raw-loss = 0.4744396209716797, train/logprobs = tensor([[-0.4455, -2.2275],
        [-0.9302, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1506931483745575
Epoch 0, Step 915: train/loss = 0.3908909857273102, train/raw-loss = 0.35127878189086914, train/logprobs = tensor([[-0.8833, -3.6315],
        [-1.3218, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19806092977523804
Epoch 0, Step 916: train/loss = 0.4115612506866455, train/raw-loss = 0.38021838665008545, train/logprobs = tensor([[-1.3670, -3.2974],
        [-1.3977, -1.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567142754793167
Epoch 0, Step 917: train/loss = 0.3866136372089386, train/raw-loss = 0.346503347158432, train/logprobs = tensor([[-1.1539, -3.4305],
        [-1.5207, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20055145025253296
Epoch 0, Step 918: train/loss = 0.522294282913208, train/raw-loss = 0.487800657749176, train/logprobs = tensor([[-0.6439, -1.6533],
        [-0.9343, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17246809601783752
Epoch 0, Step 919: train/loss = 0.5802692174911499, train/raw-loss = 0.5490673780441284, train/logprobs = tensor([[-0.9802, -2.8824],
        [-1.1064, -1.3532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1560092568397522
Epoch 0, Step 920: train/loss = 0.6050347089767456, train/raw-loss = 0.5771730542182922, train/logprobs = tensor([[-0.9549, -0.9254],
        [-1.2960, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13930824398994446
Epoch 0, Step 921: train/loss = 0.5355297327041626, train/raw-loss = 0.5064614415168762, train/logprobs = tensor([[-0.5097, -2.0242],
        [-1.0627, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14534151554107666
Epoch 0, Step 922: train/loss = 0.4634096622467041, train/raw-loss = 0.43005192279815674, train/logprobs = tensor([[-0.8089, -4.2938],
        [-0.8227, -1.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1667887568473816
Epoch 0, Step 923: train/loss = 0.443762868642807, train/raw-loss = 0.40345191955566406, train/logprobs = tensor([[-1.1555, -4.3302],
        [-1.2248, -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2015548050403595
Epoch 0, Step 924: train/loss = 0.3388047516345978, train/raw-loss = 0.3043971657752991, train/logprobs = tensor([[-0.8556, -4.9469],
        [-1.5841, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17203786969184875
Epoch 0, Step 925: train/loss = 0.516781747341156, train/raw-loss = 0.4888436496257782, train/logprobs = tensor([[-0.5745, -1.9899],
        [-0.6419, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13969047367572784
Epoch 0, Step 926: train/loss = 0.5204581618309021, train/raw-loss = 0.4925410747528076, train/logprobs = tensor([[-0.4982, -2.2854],
        [-0.7380, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13958537578582764
Epoch 0, Step 927: train/loss = 0.5369751453399658, train/raw-loss = 0.49607425928115845, train/logprobs = tensor([[-1.3323, -3.6359],
        [-1.2252, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20450443029403687
Epoch 0, Step 928: train/loss = 0.3433505892753601, train/raw-loss = 0.3037097454071045, train/logprobs = tensor([[-0.9414, -5.1682],
        [-1.1353, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1982041895389557
Epoch 0, Step 929: train/loss = 0.3267344534397125, train/raw-loss = 0.2899380624294281, train/logprobs = tensor([[-0.6511, -3.9915],
        [-1.5304, -1.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18398192524909973
Epoch 0, Step 930: train/loss = 0.42668312788009644, train/raw-loss = 0.38519078493118286, train/logprobs = tensor([[-0.7839, -2.2258],
        [-1.4137, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2074619084596634
Epoch 0, Step 931: train/loss = 0.33588165044784546, train/raw-loss = 0.3041943311691284, train/logprobs = tensor([[-0.7402, -3.5482],
        [-1.2583, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15843665599822998
Epoch 0, Step 932: train/loss = 0.37017717957496643, train/raw-loss = 0.32776838541030884, train/logprobs = tensor([[-0.6257, -4.1397],
        [-1.3794, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21204394102096558
Epoch 0, Step 933: train/loss = 0.445578932762146, train/raw-loss = 0.41337382793426514, train/logprobs = tensor([[-0.6966, -2.3558],
        [-1.0952, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16102531552314758
Epoch 0, Step 934: train/loss = 0.4761075973510742, train/raw-loss = 0.4417684078216553, train/logprobs = tensor([[-0.5517, -2.9550],
        [-1.0888, -0.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17169618606567383
Epoch 0, Step 935: train/loss = 0.38924479484558105, train/raw-loss = 0.34614095091819763, train/logprobs = tensor([[-0.9882, -3.8717],
        [-1.6827, -1.2000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2155192643404007
Epoch 0, Step 936: train/loss = 0.4794114828109741, train/raw-loss = 0.4373502731323242, train/logprobs = tensor([[-1.0793, -3.1077],
        [-1.4980, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21030615270137787
Epoch 0, Step 937: train/loss = 0.4890155792236328, train/raw-loss = 0.4506395161151886, train/logprobs = tensor([[-0.9196, -4.1771],
        [-1.1950, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19188034534454346
Epoch 0, Step 938: train/loss = 0.32184749841690063, train/raw-loss = 0.27143141627311707, train/logprobs = tensor([[-0.8338, -3.6937],
        [-1.8812, -1.4637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25208044052124023
Epoch 0, Step 939: train/loss = 0.37432169914245605, train/raw-loss = 0.3369433879852295, train/logprobs = tensor([[-1.0138, -4.3112],
        [-1.0884, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18689146637916565
Epoch 0, Step 940: train/loss = 0.2844168245792389, train/raw-loss = 0.23785877227783203, train/logprobs = tensor([[-0.8741, -3.7298],
        [-1.9021, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327902913093567
Epoch 0, Step 941: train/loss = 0.40810757875442505, train/raw-loss = 0.37602630257606506, train/logprobs = tensor([[-0.8987, -3.9763],
        [-1.3114, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16040633618831635
Epoch 0, Step 942: train/loss = 0.44695061445236206, train/raw-loss = 0.40013790130615234, train/logprobs = tensor([[-1.1389, -4.2451],
        [-1.8097, -1.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340635508298874
Epoch 0, Step 943: train/loss = 0.3368346095085144, train/raw-loss = 0.28982600569725037, train/logprobs = tensor([[-0.9224, -3.4211],
        [-2.0561, -1.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2350429743528366
Epoch 0, Step 944: train/loss = 0.2061358094215393, train/raw-loss = 0.16624146699905396, train/logprobs = tensor([[-0.8099, -8.0089],
        [-1.8304, -1.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19947175681591034
Epoch 0, Step 945: train/loss = 0.4357526898384094, train/raw-loss = 0.4014629125595093, train/logprobs = tensor([[-1.1314, -3.3532],
        [-1.2767, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1714487373828888
Epoch 0, Step 946: train/loss = 0.399262011051178, train/raw-loss = 0.35873618721961975, train/logprobs = tensor([[-0.9271, -6.5310],
        [-1.6046, -1.2537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20262913405895233
Epoch 0, Step 947: train/loss = 0.7220423221588135, train/raw-loss = 0.690892219543457, train/logprobs = tensor([[-0.9154, -0.9242],
        [-0.9906, -0.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557508111000061
Epoch 0, Step 948: train/loss = 0.4067069888114929, train/raw-loss = 0.366141140460968, train/logprobs = tensor([[-0.7596, -3.0193],
        [-1.2359, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2028292566537857
Epoch 0, Step 949: train/loss = 0.4661005139350891, train/raw-loss = 0.42535319924354553, train/logprobs = tensor([[-1.0224, -3.4824],
        [-1.3804, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20373645424842834
Epoch 0, Step 950: train/loss = 0.2835313379764557, train/raw-loss = 0.25191694498062134, train/logprobs = tensor([[-0.4570, -4.1858],
        [-1.4541, -0.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15807196497917175
Epoch 0, Step 951: train/loss = 0.5646355152130127, train/raw-loss = 0.522817850112915, train/logprobs = tensor([[-1.6595, -4.0601],
        [-1.3964, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20908860862255096
Epoch 0, Step 952: train/loss = 0.3873175084590912, train/raw-loss = 0.3573683500289917, train/logprobs = tensor([[-0.4417, -3.9828],
        [-0.8396, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497458815574646
Epoch 0, Step 953: train/loss = 0.5271884799003601, train/raw-loss = 0.49531614780426025, train/logprobs = tensor([[-0.8345, -2.2450],
        [-1.1690, -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15936152637004852
Epoch 0, Step 954: train/loss = 0.4916054606437683, train/raw-loss = 0.460588663816452, train/logprobs = tensor([[-0.7228, -1.5740],
        [-1.0986, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15508395433425903
Epoch 0, Step 955: train/loss = 0.32532355189323425, train/raw-loss = 0.2874544858932495, train/logprobs = tensor([[-0.8982, -6.5859],
        [-1.3701, -1.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18934530019760132
Epoch 0, Step 956: train/loss = 0.34682804346084595, train/raw-loss = 0.31363728642463684, train/logprobs = tensor([[-0.5741, -4.2547],
        [-1.1594, -1.2419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16595381498336792
Epoch 0, Step 957: train/loss = 0.42569369077682495, train/raw-loss = 0.3912716209888458, train/logprobs = tensor([[-1.0680, -4.8969],
        [-1.4555, -1.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.172110453248024
Epoch 0, Step 958: train/loss = 0.4433645009994507, train/raw-loss = 0.40892428159713745, train/logprobs = tensor([[-0.8802, -5.1120],
        [-0.9520, -0.9646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1722012162208557
Epoch 0, Step 959: train/loss = 0.41291213035583496, train/raw-loss = 0.37910330295562744, train/logprobs = tensor([[-0.6785, -3.7977],
        [-1.2147, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16904421150684357
Epoch 0, Step 960: train/loss = 0.5493595600128174, train/raw-loss = 0.5181764364242554, train/logprobs = tensor([[-0.6639, -1.2863],
        [-1.2426, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15591581165790558
Epoch 0, Step 961: train/loss = 0.29130131006240845, train/raw-loss = 0.2536107301712036, train/logprobs = tensor([[-1.0440, -4.6353],
        [-1.8895, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18845298886299133
Epoch 0, Step 962: train/loss = 0.47651341557502747, train/raw-loss = 0.4398415982723236, train/logprobs = tensor([[-1.4959, -5.1174],
        [-2.0286, -1.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18335895240306854
Epoch 0, Step 963: train/loss = 0.4941049814224243, train/raw-loss = 0.4569646120071411, train/logprobs = tensor([[-0.7968, -2.0371],
        [-1.0082, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18570177257061005
Epoch 0, Step 964: train/loss = 0.4396567940711975, train/raw-loss = 0.4030712842941284, train/logprobs = tensor([[-0.8358, -2.9066],
        [-1.4216, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18292739987373352
Epoch 0, Step 965: train/loss = 0.36252909898757935, train/raw-loss = 0.3330903649330139, train/logprobs = tensor([[-0.9358, -4.3049],
        [-1.3656, -1.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471937596797943
Epoch 0, Step 966: train/loss = 0.39980247616767883, train/raw-loss = 0.36614668369293213, train/logprobs = tensor([[-0.4714, -2.5003],
        [-1.2622, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16827885806560516
Epoch 0, Step 967: train/loss = 0.42714792490005493, train/raw-loss = 0.3943902254104614, train/logprobs = tensor([[-0.6113, -2.7586],
        [-1.2109, -0.5277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16378842294216156
Epoch 0, Step 968: train/loss = 0.45717746019363403, train/raw-loss = 0.4229744076728821, train/logprobs = tensor([[-0.9786, -3.0264],
        [-1.9067, -1.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710153967142105
Epoch 0, Step 969: train/loss = 0.3421407639980316, train/raw-loss = 0.29510629177093506, train/logprobs = tensor([[-0.6368, -4.2438],
        [-1.7261, -1.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235172301530838
Epoch 0, Step 970: train/loss = 0.4428025484085083, train/raw-loss = 0.405103862285614, train/logprobs = tensor([[-0.7185, -2.5247],
        [-1.2000, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1884935051202774
Epoch 0, Step 971: train/loss = 0.401571661233902, train/raw-loss = 0.3658043444156647, train/logprobs = tensor([[-0.3744, -4.3702],
        [-0.8963, -1.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178836852312088
Epoch 0, Step 972: train/loss = 0.4519309401512146, train/raw-loss = 0.4181867241859436, train/logprobs = tensor([[-0.7456, -4.9004],
        [-0.9687, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16872115433216095
Epoch 0, Step 973: train/loss = 0.5167874693870544, train/raw-loss = 0.4827238917350769, train/logprobs = tensor([[-0.6510, -1.9654],
        [-1.2798, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703180968761444
Epoch 0, Step 974: train/loss = 0.4248650074005127, train/raw-loss = 0.3847608268260956, train/logprobs = tensor([[-0.8827, -4.2411],
        [-1.3902, -1.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005208134651184
Epoch 0, Step 975: train/loss = 0.3214045763015747, train/raw-loss = 0.2814626693725586, train/logprobs = tensor([[-0.5193, -3.7095],
        [-1.0701, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19970950484275818
Epoch 0, Step 976: train/loss = 0.5069811940193176, train/raw-loss = 0.4689050614833832, train/logprobs = tensor([[-0.4341, -2.8024],
        [-1.2672, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19038066267967224
Epoch 0, Step 977: train/loss = 0.46094250679016113, train/raw-loss = 0.4235280752182007, train/logprobs = tensor([[-0.7975, -3.5186],
        [-1.1392, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870720386505127
Epoch 0, Step 978: train/loss = 0.4355970323085785, train/raw-loss = 0.3903835713863373, train/logprobs = tensor([[-1.4765, -3.7928],
        [-1.5626, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22606734931468964
Epoch 0, Step 979: train/loss = 0.4152284860610962, train/raw-loss = 0.38022032380104065, train/logprobs = tensor([[-0.6704, -3.0527],
        [-1.1607, -1.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17504088580608368
Epoch 0, Step 980: train/loss = 0.2919275164604187, train/raw-loss = 0.2566949129104614, train/logprobs = tensor([[-0.6293, -3.7444],
        [-1.2626, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.176162987947464
Epoch 0, Step 981: train/loss = 0.4375263452529907, train/raw-loss = 0.39889806509017944, train/logprobs = tensor([[-1.1649, -5.1866],
        [-1.9460, -1.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19314157962799072
Epoch 0, Step 982: train/loss = 0.3665519058704376, train/raw-loss = 0.32686328887939453, train/logprobs = tensor([[-0.8272, -3.1088],
        [-1.3888, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19844314455986023
Epoch 0, Step 983: train/loss = 0.44268444180488586, train/raw-loss = 0.4067797362804413, train/logprobs = tensor([[-0.9151, -3.2051],
        [-1.1139, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17952361702919006
Epoch 0, Step 984: train/loss = 0.47609013319015503, train/raw-loss = 0.43139445781707764, train/logprobs = tensor([[-0.5908, -2.0870],
        [-1.4527, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234785556793213
Epoch 0, Step 985: train/loss = 0.5366905927658081, train/raw-loss = 0.5059695839881897, train/logprobs = tensor([[-0.6393, -1.5199],
        [-1.0016, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15360501408576965
Epoch 0, Step 986: train/loss = 0.20693723857402802, train/raw-loss = 0.164496049284935, train/logprobs = tensor([[-0.7137, -7.4213],
        [-1.8874, -1.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21220597624778748
Epoch 0, Step 987: train/loss = 0.5346671938896179, train/raw-loss = 0.5037169456481934, train/logprobs = tensor([[-1.1987, -2.0859],
        [-1.2156, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15475140511989594
Epoch 0, Step 988: train/loss = 0.5914742350578308, train/raw-loss = 0.5502053499221802, train/logprobs = tensor([[-0.7419, -2.3127],
        [-2.2518, -1.4418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20634472370147705
Epoch 0, Step 989: train/loss = 0.3433085083961487, train/raw-loss = 0.30323946475982666, train/logprobs = tensor([[-0.8741, -2.8835],
        [-1.5436, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20034514367580414
Epoch 0, Step 990: train/loss = 0.47092822194099426, train/raw-loss = 0.4368070960044861, train/logprobs = tensor([[-0.5731, -2.8968],
        [-0.9149, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17060571908950806
Epoch 0, Step 991: train/loss = 0.5415019392967224, train/raw-loss = 0.509569525718689, train/logprobs = tensor([[-0.6174, -1.2279],
        [-0.9004, -0.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15966221690177917
Epoch 0, Step 992: train/loss = 0.3572213351726532, train/raw-loss = 0.3205830454826355, train/logprobs = tensor([[-0.5175, -3.8088],
        [-1.1894, -0.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18319159746170044
Epoch 0, Step 993: train/loss = 0.35034888982772827, train/raw-loss = 0.3117743134498596, train/logprobs = tensor([[-0.5930, -2.8490],
        [-1.4294, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1928728222846985
Epoch 0, Step 994: train/loss = 0.20135673880577087, train/raw-loss = 0.153758704662323, train/logprobs = tensor([[-0.7709, -5.2186],
        [-2.0272, -1.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23799017071723938
Epoch 0, Step 995: train/loss = 0.23652595281600952, train/raw-loss = 0.20255142450332642, train/logprobs = tensor([[-0.5417, -5.6785],
        [-1.1448, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16987255215644836
Epoch 0, Step 996: train/loss = 0.5037329196929932, train/raw-loss = 0.4697413742542267, train/logprobs = tensor([[-0.5809, -2.7735],
        [-1.0583, -1.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16995765268802643
Epoch 0, Step 997: train/loss = 0.2951680123806, train/raw-loss = 0.2624622583389282, train/logprobs = tensor([[-0.7572, -4.9683],
        [-1.0635, -1.2905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16352880001068115
Epoch 0, Step 998: train/loss = 0.31275874376296997, train/raw-loss = 0.2578189969062805, train/logprobs = tensor([[-0.7941, -3.7519],
        [-2.1673, -0.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27469873428344727
Epoch 0, Step 999: train/loss = 0.47693002223968506, train/raw-loss = 0.4413742125034332, train/logprobs = tensor([[-0.7106, -2.2758],
        [-1.3420, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17777904868125916
Epoch 0, Step 1000: train/loss = 0.47333836555480957, train/raw-loss = 0.4254431426525116, train/logprobs = tensor([[-1.0766, -2.4587],
        [-2.0535, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23947621881961823
Epoch 0, Step 1001: train/loss = 0.39535728096961975, train/raw-loss = 0.35204586386680603, train/logprobs = tensor([[-0.8029, -4.1412],
        [-1.4472, -1.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21655702590942383
Epoch 0, Step 1002: train/loss = 0.4132789373397827, train/raw-loss = 0.36509454250335693, train/logprobs = tensor([[-0.5910, -4.4646],
        [-1.7286, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24092188477516174
Epoch 0, Step 1003: train/loss = 0.38121962547302246, train/raw-loss = 0.33625203371047974, train/logprobs = tensor([[-1.2354, -4.0865],
        [-1.6458, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22483810782432556
Epoch 0, Step 1004: train/loss = 0.6260902285575867, train/raw-loss = 0.5884697437286377, train/logprobs = tensor([[-0.6835, -1.0940],
        [-0.9220, -0.7862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18810231983661652
Epoch 0, Step 1005: train/loss = 0.17654472589492798, train/raw-loss = 0.13422131538391113, train/logprobs = tensor([[-0.8060, -7.0628],
        [-2.0522, -1.5053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21161697804927826
Epoch 0, Step 1006: train/loss = 0.5828582048416138, train/raw-loss = 0.5462608337402344, train/logprobs = tensor([[-0.8882, -1.5061],
        [-1.2861, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18298661708831787
Epoch 0, Step 1007: train/loss = 0.5437304377555847, train/raw-loss = 0.509758710861206, train/logprobs = tensor([[-1.4972, -1.8834],
        [-1.9307, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16985878348350525
Epoch 0, Step 1008: train/loss = 0.4473736882209778, train/raw-loss = 0.4112362265586853, train/logprobs = tensor([[-0.6252, -3.7009],
        [-1.2185, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18068727850914001
Epoch 0, Step 1009: train/loss = 0.45027777552604675, train/raw-loss = 0.412019282579422, train/logprobs = tensor([[-0.7351, -5.8597],
        [-1.5720, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19129234552383423
Epoch 0, Step 1010: train/loss = 0.4876832365989685, train/raw-loss = 0.4475820064544678, train/logprobs = tensor([[-1.0521, -3.8462],
        [-1.0971, -1.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20050621032714844
Epoch 0, Step 1011: train/loss = 0.6196774244308472, train/raw-loss = 0.5774906873703003, train/logprobs = tensor([[-0.5807, -1.6064],
        [-1.3704, -1.6695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21093344688415527
Epoch 0, Step 1012: train/loss = 0.25592005252838135, train/raw-loss = 0.2197633534669876, train/logprobs = tensor([[-0.6533, -4.6268],
        [-1.9176, -1.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18078354001045227
Epoch 0, Step 1013: train/loss = 0.15951909124851227, train/raw-loss = 0.11043813079595566, train/logprobs = tensor([[-1.0997, -6.9089],
        [-3.1212, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24540472030639648
Epoch 0, Step 1014: train/loss = 0.40475785732269287, train/raw-loss = 0.3650639057159424, train/logprobs = tensor([[-0.8713, -3.8611],
        [-1.6147, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19846978783607483
Epoch 0, Step 1015: train/loss = 0.2530699372291565, train/raw-loss = 0.2133646160364151, train/logprobs = tensor([[-0.5792, -4.6974],
        [-1.9381, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19852666556835175
Epoch 0, Step 1016: train/loss = 0.3964253067970276, train/raw-loss = 0.35619574785232544, train/logprobs = tensor([[-0.9882, -5.1835],
        [-1.5865, -1.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20114779472351074
Epoch 0, Step 1017: train/loss = 0.3512972593307495, train/raw-loss = 0.3128703236579895, train/logprobs = tensor([[-0.6707, -6.1858],
        [-1.2246, -1.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19213464856147766
Epoch 0, Step 1018: train/loss = 0.4937427043914795, train/raw-loss = 0.4562888443470001, train/logprobs = tensor([[-0.9898, -3.7300],
        [-1.2560, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187269389629364
Epoch 0, Step 1019: train/loss = 0.4083368182182312, train/raw-loss = 0.3623020648956299, train/logprobs = tensor([[-1.2015, -4.3276],
        [-1.8127, -1.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23017367720603943
Epoch 0, Step 1020: train/loss = 0.43568360805511475, train/raw-loss = 0.4007056951522827, train/logprobs = tensor([[-0.9119, -5.9673],
        [-1.0569, -1.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17488957941532135
Epoch 0, Step 1021: train/loss = 0.32019925117492676, train/raw-loss = 0.2827824652194977, train/logprobs = tensor([[-0.6858, -5.1741],
        [-1.4423, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870838701725006
Epoch 0, Step 1022: train/loss = 0.5117290019989014, train/raw-loss = 0.48265135288238525, train/logprobs = tensor([[-0.6548, -1.6315],
        [-1.0089, -0.8599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14538829028606415
Epoch 0, Step 1023: train/loss = 0.612295389175415, train/raw-loss = 0.574561595916748, train/logprobs = tensor([[-0.5714, -1.9385],
        [-1.3050, -1.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886688470840454
Epoch 0, Step 1024: train/loss = 0.4123735725879669, train/raw-loss = 0.3706446886062622, train/logprobs = tensor([[-1.1482, -4.4883],
        [-1.3993, -1.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20864447951316833
Epoch 0, Step 1025: train/loss = 0.3518963158130646, train/raw-loss = 0.31539595127105713, train/logprobs = tensor([[-0.8947, -4.1291],
        [-1.4861, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18250183761119843
Epoch 0, Step 1026: train/loss = 0.3512706458568573, train/raw-loss = 0.30533745884895325, train/logprobs = tensor([[-0.8912, -4.1409],
        [-1.5112, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22966593503952026
Epoch 0, Step 1027: train/loss = 0.6584298610687256, train/raw-loss = 0.6265576481819153, train/logprobs = tensor([[-0.6420, -1.0928],
        [-0.9283, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15936096012592316
Epoch 0, Step 1028: train/loss = 0.3878118395805359, train/raw-loss = 0.3573880195617676, train/logprobs = tensor([[-0.8125, -5.5017],
        [-1.9975, -1.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1521192193031311
Epoch 0, Step 1029: train/loss = 0.5382275581359863, train/raw-loss = 0.5055509209632874, train/logprobs = tensor([[-0.4873, -2.3165],
        [-0.8961, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1633833795785904
Epoch 0, Step 1030: train/loss = 0.30900445580482483, train/raw-loss = 0.26541411876678467, train/logprobs = tensor([[-0.7929, -5.9513],
        [-2.1569, -1.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21795159578323364
Epoch 0, Step 1031: train/loss = 0.41985270380973816, train/raw-loss = 0.3749728500843048, train/logprobs = tensor([[-0.9809, -2.7779],
        [-1.4142, -1.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224399134516716
Epoch 0, Step 1032: train/loss = 0.45804905891418457, train/raw-loss = 0.4223470687866211, train/logprobs = tensor([[-0.8745, -2.4981],
        [-1.7362, -1.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17851006984710693
Epoch 0, Step 1033: train/loss = 0.3047228455543518, train/raw-loss = 0.25452151894569397, train/logprobs = tensor([[-1.1536, -5.1130],
        [-2.5492, -1.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510067820549011
Epoch 0, Step 1034: train/loss = 0.40664708614349365, train/raw-loss = 0.3721492290496826, train/logprobs = tensor([[-0.8745, -2.5697],
        [-1.4416, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.172489196062088
Epoch 0, Step 1035: train/loss = 0.5001437664031982, train/raw-loss = 0.4574677348136902, train/logprobs = tensor([[-0.9017, -2.7543],
        [-1.6687, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21338032186031342
Epoch 0, Step 1036: train/loss = 0.49648770689964294, train/raw-loss = 0.45533287525177, train/logprobs = tensor([[-0.6913, -2.4983],
        [-1.2592, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20577414333820343
Epoch 0, Step 1037: train/loss = 0.48290401697158813, train/raw-loss = 0.44458314776420593, train/logprobs = tensor([[-0.6885, -2.5484],
        [-1.5621, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19160442054271698
Epoch 0, Step 1038: train/loss = 0.38428083062171936, train/raw-loss = 0.3372107744216919, train/logprobs = tensor([[-1.0472, -5.5017],
        [-1.6264, -1.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23535028100013733
Epoch 0, Step 1039: train/loss = 0.32435688376426697, train/raw-loss = 0.2802847623825073, train/logprobs = tensor([[-0.8291, -7.0097],
        [-1.8086, -2.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22036075592041016
Epoch 0, Step 1040: train/loss = 0.4839220643043518, train/raw-loss = 0.4436553716659546, train/logprobs = tensor([[-1.5283, -4.0575],
        [-1.7434, -1.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20133352279663086
Epoch 0, Step 1041: train/loss = 0.2963973879814148, train/raw-loss = 0.2545461058616638, train/logprobs = tensor([[-0.8931, -6.2893],
        [-1.7025, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20925626158714294
Epoch 0, Step 1042: train/loss = 0.4832810163497925, train/raw-loss = 0.4562711715698242, train/logprobs = tensor([[-0.7489, -2.7878],
        [-0.8723, -0.9970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13504905998706818
Epoch 0, Step 1043: train/loss = 0.714310884475708, train/raw-loss = 0.6801825761795044, train/logprobs = tensor([[-1.3508, -1.6418],
        [-1.2074, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1706417053937912
Epoch 0, Step 1044: train/loss = 0.5011709332466125, train/raw-loss = 0.46346819400787354, train/logprobs = tensor([[-0.8413, -1.6978],
        [-1.9642, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18851357698440552
Epoch 0, Step 1045: train/loss = 0.41013264656066895, train/raw-loss = 0.37525469064712524, train/logprobs = tensor([[-0.6501, -3.8080],
        [-1.2463, -0.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17438983917236328
Epoch 0, Step 1046: train/loss = 0.3855707347393036, train/raw-loss = 0.3476793169975281, train/logprobs = tensor([[-0.6240, -3.6160],
        [-1.2510, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894570291042328
Epoch 0, Step 1047: train/loss = 0.4902592599391937, train/raw-loss = 0.4511373043060303, train/logprobs = tensor([[-0.7687, -1.7314],
        [-1.1459, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19560985267162323
Epoch 0, Step 1048: train/loss = 0.19332125782966614, train/raw-loss = 0.15302607417106628, train/logprobs = tensor([[-0.7342, -7.9748],
        [-1.7753, -1.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014758139848709
Epoch 0, Step 1049: train/loss = 0.3179890513420105, train/raw-loss = 0.2708815336227417, train/logprobs = tensor([[-0.9527, -3.6549],
        [-1.9697, -1.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23553767800331116
Epoch 0, Step 1050: train/loss = 0.4941580295562744, train/raw-loss = 0.4620139002799988, train/logprobs = tensor([[-0.5999, -1.3024],
        [-1.3749, -0.8197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1607208549976349
Epoch 0, Step 1051: train/loss = 0.6368060111999512, train/raw-loss = 0.6067427396774292, train/logprobs = tensor([[-0.7353, -1.4361],
        [-0.6644, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15031640231609344
Epoch 0, Step 1052: train/loss = 0.35341519117355347, train/raw-loss = 0.3191392719745636, train/logprobs = tensor([[-0.6738, -3.8298],
        [-1.2203, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1713794469833374
Epoch 0, Step 1053: train/loss = 0.2643398642539978, train/raw-loss = 0.2292836457490921, train/logprobs = tensor([[-0.7313, -4.6618],
        [-1.7726, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752811223268509
Epoch 0, Step 1054: train/loss = 0.4342736303806305, train/raw-loss = 0.4009878635406494, train/logprobs = tensor([[-0.9399, -2.3152],
        [-1.3228, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16642898321151733
Epoch 0, Step 1055: train/loss = 0.5004369020462036, train/raw-loss = 0.4602392017841339, train/logprobs = tensor([[-0.9297, -3.5026],
        [-1.8721, -2.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20098872482776642
Epoch 0, Step 1056: train/loss = 0.42472705245018005, train/raw-loss = 0.3901408612728119, train/logprobs = tensor([[-0.7928, -3.2398],
        [-1.1985, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17293083667755127
Epoch 0, Step 1057: train/loss = 0.3538227379322052, train/raw-loss = 0.31854450702667236, train/logprobs = tensor([[-0.6274, -5.6568],
        [-1.5227, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1763911247253418
Epoch 0, Step 1058: train/loss = 0.3022095859050751, train/raw-loss = 0.26075485348701477, train/logprobs = tensor([[-0.6720, -4.0143],
        [-1.7017, -0.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20727361738681793
Epoch 0, Step 1059: train/loss = 0.5658656358718872, train/raw-loss = 0.5230240821838379, train/logprobs = tensor([[-0.8182, -1.9747],
        [-1.0174, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2142076939344406
Epoch 0, Step 1060: train/loss = 0.5977360010147095, train/raw-loss = 0.5594322085380554, train/logprobs = tensor([[-0.7185, -2.1307],
        [-1.3726, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915188431739807
Epoch 0, Step 1061: train/loss = 0.46234920620918274, train/raw-loss = 0.4186027944087982, train/logprobs = tensor([[-0.8586, -4.0039],
        [-1.4959, -1.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21873199939727783
Epoch 0, Step 1062: train/loss = 0.3850124776363373, train/raw-loss = 0.3424101769924164, train/logprobs = tensor([[-0.9799, -3.1883],
        [-1.7837, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2130114883184433
Epoch 0, Step 1063: train/loss = 0.6263992786407471, train/raw-loss = 0.5899423360824585, train/logprobs = tensor([[-1.4690, -2.8294],
        [-1.0137, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18228480219841003
Epoch 0, Step 1064: train/loss = 0.360228955745697, train/raw-loss = 0.3194200396537781, train/logprobs = tensor([[-0.7688, -5.5775],
        [-1.4971, -1.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2040444016456604
Epoch 0, Step 1065: train/loss = 0.48378580808639526, train/raw-loss = 0.4454009532928467, train/logprobs = tensor([[-0.7152, -2.6238],
        [-1.2807, -0.9269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19192418456077576
Epoch 0, Step 1066: train/loss = 0.4262966513633728, train/raw-loss = 0.39138415455818176, train/logprobs = tensor([[-1.4887, -4.0587],
        [-1.6060, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745625138282776
Epoch 0, Step 1067: train/loss = 0.17293612658977509, train/raw-loss = 0.13329899311065674, train/logprobs = tensor([[-0.9773, -8.4003],
        [-2.3888, -1.3947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19818571209907532
Epoch 0, Step 1068: train/loss = 0.38317131996154785, train/raw-loss = 0.3434096872806549, train/logprobs = tensor([[-0.7178, -3.3490],
        [-1.4437, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19880813360214233
Epoch 0, Step 1069: train/loss = 0.5627529621124268, train/raw-loss = 0.5260350704193115, train/logprobs = tensor([[-1.2446, -5.4273],
        [-1.3623, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18358948826789856
Epoch 0, Step 1070: train/loss = 0.3196094334125519, train/raw-loss = 0.2754194140434265, train/logprobs = tensor([[-0.7567, -4.1199],
        [-1.7054, -1.4757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209501415491104
Epoch 0, Step 1071: train/loss = 0.20394837856292725, train/raw-loss = 0.15865841507911682, train/logprobs = tensor([[-0.8950, -7.0983],
        [-2.1486, -1.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22644977271556854
Epoch 0, Step 1072: train/loss = 0.21006155014038086, train/raw-loss = 0.16980795562267303, train/logprobs = tensor([[-0.8417, -7.1593],
        [-1.7406, -1.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20126794278621674
Epoch 0, Step 1073: train/loss = 0.35860684514045715, train/raw-loss = 0.31531083583831787, train/logprobs = tensor([[-0.8589, -3.3113],
        [-1.7168, -1.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2164800763130188
Epoch 0, Step 1074: train/loss = 0.39903563261032104, train/raw-loss = 0.36124616861343384, train/logprobs = tensor([[-0.5973, -5.7639],
        [-1.2982, -1.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18894734978675842
Epoch 0, Step 1075: train/loss = 0.4070513844490051, train/raw-loss = 0.37428978085517883, train/logprobs = tensor([[-0.5199, -3.3506],
        [-0.8147, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16380807757377625
Epoch 0, Step 1076: train/loss = 0.3938714861869812, train/raw-loss = 0.34481003880500793, train/logprobs = tensor([[-0.6626, -4.1787],
        [-1.5349, -1.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24530737102031708
Epoch 0, Step 1077: train/loss = 0.42385560274124146, train/raw-loss = 0.3892873227596283, train/logprobs = tensor([[-0.5523, -3.8247],
        [-1.3423, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17284142971038818
Epoch 0, Step 1078: train/loss = 0.49234920740127563, train/raw-loss = 0.45694008469581604, train/logprobs = tensor([[-1.1048, -3.2807],
        [-1.4071, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17704568803310394
Epoch 0, Step 1079: train/loss = 0.2676001787185669, train/raw-loss = 0.22421914339065552, train/logprobs = tensor([[-0.6522, -7.5859],
        [-1.5195, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21690522134304047
Epoch 0, Step 1080: train/loss = 0.4671875238418579, train/raw-loss = 0.4311347007751465, train/logprobs = tensor([[-0.8056, -2.6375],
        [-1.4861, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18026402592658997
Epoch 0, Step 1081: train/loss = 0.2708069980144501, train/raw-loss = 0.23000600934028625, train/logprobs = tensor([[-1.4461, -5.7356],
        [-1.8088, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20400497317314148
Epoch 0, Step 1082: train/loss = 0.6085379123687744, train/raw-loss = 0.5763969421386719, train/logprobs = tensor([[-0.7057, -1.2246],
        [-1.2850, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16070491075515747
Epoch 0, Step 1083: train/loss = 0.47945088148117065, train/raw-loss = 0.4302801191806793, train/logprobs = tensor([[-1.0239, -3.1943],
        [-1.8859, -1.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24585387110710144
Epoch 0, Step 1084: train/loss = 0.44075196981430054, train/raw-loss = 0.40528011322021484, train/logprobs = tensor([[-0.5698, -3.2718],
        [-1.1419, -0.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17735892534255981
Epoch 0, Step 1085: train/loss = 0.49558544158935547, train/raw-loss = 0.46480199694633484, train/logprobs = tensor([[-0.5588, -1.9346],
        [-1.1975, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15391728281974792
Epoch 0, Step 1086: train/loss = 0.3701087236404419, train/raw-loss = 0.3274511694908142, train/logprobs = tensor([[-0.7851, -5.3430],
        [-1.6275, -1.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21328774094581604
Epoch 0, Step 1087: train/loss = 0.3656092584133148, train/raw-loss = 0.3361169695854187, train/logprobs = tensor([[-0.7481, -6.2731],
        [-0.9132, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14746135473251343
Epoch 0, Step 1088: train/loss = 0.45732420682907104, train/raw-loss = 0.4169900119304657, train/logprobs = tensor([[-1.2973, -3.0710],
        [-1.5859, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20167088508605957
Epoch 0, Step 1089: train/loss = 0.4732101261615753, train/raw-loss = 0.443088173866272, train/logprobs = tensor([[-0.7431, -2.4213],
        [-1.0263, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15060970187187195
Epoch 0, Step 1090: train/loss = 0.32850778102874756, train/raw-loss = 0.2894783020019531, train/logprobs = tensor([[-0.6770, -4.1172],
        [-1.7197, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1951473206281662
Epoch 0, Step 1091: train/loss = 0.3037704527378082, train/raw-loss = 0.26894959807395935, train/logprobs = tensor([[-0.5611, -3.6104],
        [-1.5123, -1.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1741042137145996
Epoch 0, Step 1092: train/loss = 0.32284092903137207, train/raw-loss = 0.2776954770088196, train/logprobs = tensor([[-0.9267, -3.8278],
        [-1.7667, -1.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22572734951972961
Epoch 0, Step 1093: train/loss = 0.4528001844882965, train/raw-loss = 0.4102123975753784, train/logprobs = tensor([[-0.8052, -4.3644],
        [-1.6112, -1.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2129388451576233
Epoch 0, Step 1094: train/loss = 0.3434750437736511, train/raw-loss = 0.3065248429775238, train/logprobs = tensor([[-0.6148, -2.5873],
        [-1.3916, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1847509890794754
Epoch 0, Step 1095: train/loss = 0.5483323335647583, train/raw-loss = 0.5060371160507202, train/logprobs = tensor([[-1.1267, -3.0849],
        [-1.3552, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21147650480270386
Epoch 0, Step 1096: train/loss = 0.313636839389801, train/raw-loss = 0.2792515754699707, train/logprobs = tensor([[-0.8377, -4.7689],
        [-1.3187, -1.1501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17192620038986206
Epoch 0, Step 1097: train/loss = 0.2855072319507599, train/raw-loss = 0.23825709521770477, train/logprobs = tensor([[-1.0053, -5.4939],
        [-1.7703, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23625068366527557
Epoch 0, Step 1098: train/loss = 0.3449932634830475, train/raw-loss = 0.30343183875083923, train/logprobs = tensor([[-0.4759, -6.9420],
        [-1.5184, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20780718326568604
Epoch 0, Step 1099: train/loss = 0.4756712317466736, train/raw-loss = 0.4328496754169464, train/logprobs = tensor([[-0.6953, -1.8828],
        [-1.5929, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21410775184631348
Epoch 0, Step 1100: train/loss = 0.391518771648407, train/raw-loss = 0.35263872146606445, train/logprobs = tensor([[-0.7524, -3.3208],
        [-1.3865, -1.1023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19440022110939026
Epoch 0, Step 1101: train/loss = 0.2883336544036865, train/raw-loss = 0.24831220507621765, train/logprobs = tensor([[-0.8002, -7.7066],
        [-1.9470, -1.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20010726153850555
Epoch 0, Step 1102: train/loss = 0.3371657133102417, train/raw-loss = 0.3039296269416809, train/logprobs = tensor([[-0.9430, -4.9390],
        [-1.2739, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16618052124977112
Epoch 0, Step 1103: train/loss = 0.2954147458076477, train/raw-loss = 0.2522298991680145, train/logprobs = tensor([[-1.0689, -6.1770],
        [-1.7892, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2159242182970047
Epoch 0, Step 1104: train/loss = 0.5743820071220398, train/raw-loss = 0.535049557685852, train/logprobs = tensor([[-0.9639, -4.3331],
        [-1.1143, -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19666211307048798
Epoch 0, Step 1105: train/loss = 0.37569665908813477, train/raw-loss = 0.3438349664211273, train/logprobs = tensor([[-0.7683, -4.3125],
        [-0.9946, -0.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15930858254432678
Epoch 0, Step 1106: train/loss = 0.35459429025650024, train/raw-loss = 0.3099707365036011, train/logprobs = tensor([[-1.3377, -6.6345],
        [-1.7538, -1.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22311776876449585
Epoch 0, Step 1107: train/loss = 0.3725951313972473, train/raw-loss = 0.3391232192516327, train/logprobs = tensor([[-0.7127, -4.1080],
        [-1.2291, -0.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16735951602458954
Epoch 0, Step 1108: train/loss = 0.4115191102027893, train/raw-loss = 0.3815634846687317, train/logprobs = tensor([[-0.5848, -2.8904],
        [-1.1459, -1.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14977826178073883
Epoch 0, Step 1109: train/loss = 0.39257216453552246, train/raw-loss = 0.3572657108306885, train/logprobs = tensor([[-0.8134, -2.9379],
        [-1.3840, -1.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17653214931488037
Epoch 0, Step 1110: train/loss = 0.4980950951576233, train/raw-loss = 0.46369102597236633, train/logprobs = tensor([[-0.7232, -3.6914],
        [-1.0539, -1.5354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17202024161815643
Epoch 0, Step 1111: train/loss = 0.3824879825115204, train/raw-loss = 0.3458450436592102, train/logprobs = tensor([[-0.8269, -4.2310],
        [-1.0695, -1.3199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18321479856967926
Epoch 0, Step 1112: train/loss = 0.595596432685852, train/raw-loss = 0.5496125817298889, train/logprobs = tensor([[-1.8041, -5.8542],
        [-1.5255, -1.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22991928458213806
Epoch 0, Step 1113: train/loss = 0.5395811796188354, train/raw-loss = 0.5029826164245605, train/logprobs = tensor([[-0.8743, -2.2217],
        [-1.1915, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18299254775047302
Epoch 0, Step 1114: train/loss = 0.3897494375705719, train/raw-loss = 0.355623722076416, train/logprobs = tensor([[-0.8386, -2.8098],
        [-1.4700, -0.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17062854766845703
Epoch 0, Step 1115: train/loss = 0.49211621284484863, train/raw-loss = 0.45374006032943726, train/logprobs = tensor([[-0.4370, -1.8961],
        [-0.9370, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19188103079795837
Epoch 0, Step 1116: train/loss = 0.4711911678314209, train/raw-loss = 0.4382041096687317, train/logprobs = tensor([[-0.5874, -2.5417],
        [-0.9911, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1649353951215744
Epoch 0, Step 1117: train/loss = 0.5357600450515747, train/raw-loss = 0.4915016293525696, train/logprobs = tensor([[-0.7267, -2.6075],
        [-1.9373, -1.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22129201889038086
Epoch 0, Step 1118: train/loss = 0.6094934344291687, train/raw-loss = 0.5818835496902466, train/logprobs = tensor([[-0.3990, -2.4433],
        [-0.5801, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13804937899112701
Epoch 0, Step 1119: train/loss = 0.3577854335308075, train/raw-loss = 0.3154010474681854, train/logprobs = tensor([[-0.5781, -5.0577],
        [-1.4361, -1.3304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21192194521427155
Epoch 0, Step 1120: train/loss = 0.20550227165222168, train/raw-loss = 0.15857794880867004, train/logprobs = tensor([[-1.1152, -4.3666],
        [-2.3021, -0.9127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23462150990962982
Epoch 0, Step 1121: train/loss = 0.34914982318878174, train/raw-loss = 0.3045175075531006, train/logprobs = tensor([[-0.8707, -3.9501],
        [-2.1224, -0.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22316157817840576
Epoch 0, Step 1122: train/loss = 0.565599262714386, train/raw-loss = 0.5252258777618408, train/logprobs = tensor([[-0.6605, -4.1050],
        [-1.3804, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20186728239059448
Epoch 0, Step 1123: train/loss = 0.2394087314605713, train/raw-loss = 0.19828370213508606, train/logprobs = tensor([[-0.8007, -7.7833],
        [-1.8725, -1.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20562508702278137
Epoch 0, Step 1124: train/loss = 0.3632294833660126, train/raw-loss = 0.3248215913772583, train/logprobs = tensor([[-1.0158, -7.6257],
        [-1.6274, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19203943014144897
Epoch 0, Step 1125: train/loss = 0.3986527919769287, train/raw-loss = 0.36120641231536865, train/logprobs = tensor([[-0.6550, -2.6204],
        [-1.3507, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18723197281360626
Epoch 0, Step 1126: train/loss = 0.5000437498092651, train/raw-loss = 0.456865131855011, train/logprobs = tensor([[-1.1321, -4.1411],
        [-1.4268, -2.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21589307487010956
Epoch 0, Step 1127: train/loss = 0.38935381174087524, train/raw-loss = 0.35333073139190674, train/logprobs = tensor([[-0.5246, -3.5694],
        [-0.7705, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18011540174484253
Epoch 0, Step 1128: train/loss = 0.6111619472503662, train/raw-loss = 0.5714429020881653, train/logprobs = tensor([[-1.6113, -2.5342],
        [-1.2009, -1.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19859538972377777
Epoch 0, Step 1129: train/loss = 0.28332918882369995, train/raw-loss = 0.2368704080581665, train/logprobs = tensor([[-0.8182, -3.7636],
        [-1.9439, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23229390382766724
Epoch 0, Step 1130: train/loss = 0.4824947714805603, train/raw-loss = 0.45505017042160034, train/logprobs = tensor([[-0.3912, -2.0610],
        [-1.0058, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1372230052947998
Epoch 0, Step 1131: train/loss = 0.36464226245880127, train/raw-loss = 0.33378076553344727, train/logprobs = tensor([[-0.4923, -3.6248],
        [-1.0955, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15430735051631927
Epoch 0, Step 1132: train/loss = 0.5543753504753113, train/raw-loss = 0.5125659704208374, train/logprobs = tensor([[-1.0584, -3.5287],
        [-1.1171, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2090468555688858
Epoch 0, Step 1133: train/loss = 0.6269756555557251, train/raw-loss = 0.5925970077514648, train/logprobs = tensor([[-0.8078, -1.0001],
        [-0.9996, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17189306020736694
Epoch 0, Step 1134: train/loss = 0.39263054728507996, train/raw-loss = 0.3498851954936981, train/logprobs = tensor([[-1.4984, -7.1909],
        [-1.8237, -1.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2137266844511032
Epoch 0, Step 1135: train/loss = 0.33728939294815063, train/raw-loss = 0.2984989285469055, train/logprobs = tensor([[-0.6496, -4.1784],
        [-1.2508, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19395217299461365
Epoch 0, Step 1136: train/loss = 0.3587881028652191, train/raw-loss = 0.3167003393173218, train/logprobs = tensor([[-0.8336, -5.1432],
        [-1.7635, -1.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2104388177394867
Epoch 0, Step 1137: train/loss = 0.3822195827960968, train/raw-loss = 0.33859625458717346, train/logprobs = tensor([[-1.1801, -7.7336],
        [-1.5360, -1.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181166559457779
Epoch 0, Step 1138: train/loss = 0.5199506878852844, train/raw-loss = 0.4869883358478546, train/logprobs = tensor([[-0.5688, -1.8985],
        [-1.0367, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16481177508831024
Epoch 0, Step 1139: train/loss = 0.34003138542175293, train/raw-loss = 0.2860952913761139, train/logprobs = tensor([[-0.6504, -3.1938],
        [-2.0449, -1.3051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26968058943748474
Epoch 0, Step 1140: train/loss = 0.3675340712070465, train/raw-loss = 0.3312484622001648, train/logprobs = tensor([[-0.6694, -5.8584],
        [-1.3406, -1.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1814279854297638
Epoch 0, Step 1141: train/loss = 0.412725567817688, train/raw-loss = 0.3783150315284729, train/logprobs = tensor([[-0.5966, -3.9446],
        [-1.2940, -1.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1720525175333023
Epoch 0, Step 1142: train/loss = 0.5123178958892822, train/raw-loss = 0.4769059121608734, train/logprobs = tensor([[-0.6897, -2.1053],
        [-1.8017, -1.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17706012725830078
Epoch 0, Step 1143: train/loss = 0.5141022205352783, train/raw-loss = 0.4714546799659729, train/logprobs = tensor([[-0.8073, -2.2210],
        [-1.3093, -1.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21323785185813904
Epoch 0, Step 1144: train/loss = 0.4521157145500183, train/raw-loss = 0.4196057915687561, train/logprobs = tensor([[-0.6580, -3.9140],
        [-0.7097, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16254952549934387
Epoch 0, Step 1145: train/loss = 0.28642505407333374, train/raw-loss = 0.25327268242836, train/logprobs = tensor([[-0.5291, -6.3463],
        [-0.9540, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16576190292835236
Epoch 0, Step 1146: train/loss = 0.1958012878894806, train/raw-loss = 0.14762014150619507, train/logprobs = tensor([[ -0.7740, -11.1541],
        [ -1.7398,  -1.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24090567231178284
Epoch 0, Step 1147: train/loss = 0.3293839693069458, train/raw-loss = 0.27826353907585144, train/logprobs = tensor([[-1.2174, -4.3752],
        [-1.9577, -1.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556021809577942
Epoch 0, Step 1148: train/loss = 0.5156199336051941, train/raw-loss = 0.47189241647720337, train/logprobs = tensor([[-0.9052, -2.0121],
        [-1.5913, -1.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21863749623298645
Epoch 0, Step 1149: train/loss = 0.33204323053359985, train/raw-loss = 0.2915226221084595, train/logprobs = tensor([[-0.9717, -5.0765],
        [-1.8392, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20260310173034668
Epoch 0, Step 1150: train/loss = 0.5846355557441711, train/raw-loss = 0.5423198938369751, train/logprobs = tensor([[-1.3527, -4.5141],
        [-0.7338, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21157850325107574
Epoch 0, Step 1151: train/loss = 0.2822532057762146, train/raw-loss = 0.23988185822963715, train/logprobs = tensor([[-1.0816, -7.1560],
        [-2.2575, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21185661852359772
Epoch 0, Step 1152: train/loss = 0.16349917650222778, train/raw-loss = 0.11605888605117798, train/logprobs = tensor([[-0.8265, -7.3881],
        [-2.2466, -1.2889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23720146715641022
Epoch 0, Step 1153: train/loss = 0.4113365709781647, train/raw-loss = 0.3705821633338928, train/logprobs = tensor([[-0.5458, -2.5912],
        [-1.0855, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2037719488143921
Epoch 0, Step 1154: train/loss = 0.36362022161483765, train/raw-loss = 0.32456275820732117, train/logprobs = tensor([[-0.7928, -3.7118],
        [-1.6520, -1.2093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19528716802597046
Epoch 0, Step 1155: train/loss = 0.37179863452911377, train/raw-loss = 0.3400137424468994, train/logprobs = tensor([[-0.6636, -3.2272],
        [-1.5131, -1.6630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15892446041107178
Epoch 0, Step 1156: train/loss = 0.4988064169883728, train/raw-loss = 0.45703935623168945, train/logprobs = tensor([[-0.8273, -2.1264],
        [-1.5437, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20883549749851227
Epoch 0, Step 1157: train/loss = 0.3889412581920624, train/raw-loss = 0.34687891602516174, train/logprobs = tensor([[-1.0063, -6.6953],
        [-1.4048, -2.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21031174063682556
Epoch 0, Step 1158: train/loss = 0.21449542045593262, train/raw-loss = 0.1696258783340454, train/logprobs = tensor([[-0.7783, -5.9942],
        [-1.7318, -1.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2243477702140808
Epoch 0, Step 1159: train/loss = 0.36705493927001953, train/raw-loss = 0.3308015465736389, train/logprobs = tensor([[-0.6261, -3.9787],
        [-0.8946, -1.4029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18126705288887024
Epoch 0, Step 1160: train/loss = 0.5249476432800293, train/raw-loss = 0.4874471426010132, train/logprobs = tensor([[-0.8863, -4.2806],
        [-1.2009, -1.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18750256299972534
Epoch 0, Step 1161: train/loss = 0.4739993214607239, train/raw-loss = 0.43171796202659607, train/logprobs = tensor([[-0.7749, -2.4249],
        [-1.3276, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21140673756599426
Epoch 0, Step 1162: train/loss = 0.3171311318874359, train/raw-loss = 0.27300846576690674, train/logprobs = tensor([[-0.9506, -5.4919],
        [-1.9851, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22061337530612946
Epoch 0, Step 1163: train/loss = 0.26281100511550903, train/raw-loss = 0.22083938121795654, train/logprobs = tensor([[-0.6854, -6.1814],
        [-1.4024, -1.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20985808968544006
Epoch 0, Step 1164: train/loss = 0.34383395314216614, train/raw-loss = 0.30142679810523987, train/logprobs = tensor([[-0.7055, -6.9430],
        [-1.5737, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21203570067882538
Epoch 0, Step 1165: train/loss = 0.38835641741752625, train/raw-loss = 0.3531758189201355, train/logprobs = tensor([[-0.9611, -4.5283],
        [-1.3349, -1.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1759030818939209
Epoch 0, Step 1166: train/loss = 0.3031761050224304, train/raw-loss = 0.2544444799423218, train/logprobs = tensor([[-0.7761, -3.7185],
        [-2.1220, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2436581701040268
Epoch 0, Step 1167: train/loss = 0.4508671164512634, train/raw-loss = 0.409781813621521, train/logprobs = tensor([[-0.6658, -5.3395],
        [-1.3189, -1.6231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20542657375335693
Epoch 0, Step 1168: train/loss = 0.49645739793777466, train/raw-loss = 0.45934414863586426, train/logprobs = tensor([[-0.9184, -2.9648],
        [-1.4852, -1.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18556617200374603
Epoch 0, Step 1169: train/loss = 0.7323735356330872, train/raw-loss = 0.6866658329963684, train/logprobs = tensor([[-2.3570, -5.2086],
        [-1.5229, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22853845357894897
Epoch 0, Step 1170: train/loss = 0.27611076831817627, train/raw-loss = 0.24069508910179138, train/logprobs = tensor([[-0.6965, -5.3062],
        [-1.4702, -1.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17707839608192444
Epoch 0, Step 1171: train/loss = 0.5601120591163635, train/raw-loss = 0.5198749303817749, train/logprobs = tensor([[-0.9932, -3.2708],
        [-1.5897, -1.0246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011857032775879
Epoch 0, Step 1172: train/loss = 0.28522419929504395, train/raw-loss = 0.25082528591156006, train/logprobs = tensor([[-0.6858, -7.3038],
        [-1.4848, -2.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17199450731277466
Epoch 0, Step 1173: train/loss = 0.22681796550750732, train/raw-loss = 0.18698523938655853, train/logprobs = tensor([[-0.9575, -6.0934],
        [-1.6930, -1.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19916357100009918
Epoch 0, Step 1174: train/loss = 0.49705368280410767, train/raw-loss = 0.4678499698638916, train/logprobs = tensor([[-0.6701, -2.1494],
        [-1.2970, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14601849019527435
Epoch 0, Step 1175: train/loss = 0.30323368310928345, train/raw-loss = 0.25473788380622864, train/logprobs = tensor([[-0.9978, -5.8573],
        [-1.8433, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24247902631759644
Epoch 0, Step 1176: train/loss = 0.6956815123558044, train/raw-loss = 0.6646448373794556, train/logprobs = tensor([[-0.7017, -1.7736],
        [-1.0797, -1.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15518318116664886
Epoch 0, Step 1177: train/loss = 0.4721449017524719, train/raw-loss = 0.4317651093006134, train/logprobs = tensor([[-0.7594, -3.1210],
        [-1.4241, -1.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20189882814884186
Epoch 0, Step 1178: train/loss = 0.6264790892601013, train/raw-loss = 0.5876398086547852, train/logprobs = tensor([[-1.8958, -4.0605],
        [-1.1772, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.194196417927742
Epoch 0, Step 1179: train/loss = 0.4368302822113037, train/raw-loss = 0.3940281867980957, train/logprobs = tensor([[-1.1719, -2.3385],
        [-1.6467, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2140105962753296
Epoch 0, Step 1180: train/loss = 0.5757942795753479, train/raw-loss = 0.5346578359603882, train/logprobs = tensor([[-1.0048, -1.3607],
        [-1.4864, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056821584701538
Epoch 0, Step 1181: train/loss = 0.38519811630249023, train/raw-loss = 0.35201117396354675, train/logprobs = tensor([[-1.1000, -4.8381],
        [-1.3318, -1.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1659346967935562
Epoch 0, Step 1182: train/loss = 0.519426703453064, train/raw-loss = 0.47614046931266785, train/logprobs = tensor([[-1.0644, -5.6006],
        [-1.8670, -1.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2164313942193985
Epoch 0, Step 1183: train/loss = 0.5722299814224243, train/raw-loss = 0.5392294526100159, train/logprobs = tensor([[-0.7119, -2.0407],
        [-0.8302, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16500282287597656
Epoch 0, Step 1184: train/loss = 0.5523439049720764, train/raw-loss = 0.5076770782470703, train/logprobs = tensor([[-1.0122, -2.6691],
        [-1.5882, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.223334401845932
Epoch 0, Step 1185: train/loss = 0.3969210982322693, train/raw-loss = 0.3586093783378601, train/logprobs = tensor([[-0.7065, -3.6588],
        [-1.9110, -1.2848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19155868887901306
Epoch 0, Step 1186: train/loss = 0.5285758376121521, train/raw-loss = 0.49274569749832153, train/logprobs = tensor([[-0.6842, -4.6197],
        [-1.1951, -1.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17915058135986328
Epoch 0, Step 1187: train/loss = 0.3541620373725891, train/raw-loss = 0.3110668659210205, train/logprobs = tensor([[-1.3249, -7.0845],
        [-1.3858, -1.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21547585725784302
Epoch 0, Step 1188: train/loss = 0.307895302772522, train/raw-loss = 0.2656286954879761, train/logprobs = tensor([[-0.8753, -5.0016],
        [-1.9228, -2.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2113329917192459
Epoch 0, Step 1189: train/loss = 0.34655410051345825, train/raw-loss = 0.3041984438896179, train/logprobs = tensor([[-0.7157, -3.2076],
        [-1.6976, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2117781639099121
Epoch 0, Step 1190: train/loss = 0.40472549200057983, train/raw-loss = 0.3598345220088959, train/logprobs = tensor([[-0.8145, -3.0015],
        [-1.6230, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2244548797607422
Epoch 0, Step 1191: train/loss = 0.31789320707321167, train/raw-loss = 0.28332245349884033, train/logprobs = tensor([[-0.8411, -6.1182],
        [-1.5796, -1.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17285391688346863
Epoch 0, Step 1192: train/loss = 0.22281605005264282, train/raw-loss = 0.18178197741508484, train/logprobs = tensor([[-0.7115, -8.4404],
        [-1.5605, -2.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20517031848430634
Epoch 0, Step 1193: train/loss = 0.48636937141418457, train/raw-loss = 0.43914785981178284, train/logprobs = tensor([[-0.8742, -1.9965],
        [-2.0789, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23610754311084747
Epoch 0, Step 1194: train/loss = 0.6475790739059448, train/raw-loss = 0.6082364320755005, train/logprobs = tensor([[-1.5599, -4.3601],
        [-1.1639, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19671350717544556
Epoch 0, Step 1195: train/loss = 0.5469101667404175, train/raw-loss = 0.5060511231422424, train/logprobs = tensor([[-1.1303, -4.5919],
        [-1.1098, -2.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20429503917694092
Epoch 0, Step 1196: train/loss = 0.4977751076221466, train/raw-loss = 0.45701655745506287, train/logprobs = tensor([[-1.6520, -4.3571],
        [-1.5285, -0.9354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2037927210330963
Epoch 0, Step 1197: train/loss = 0.16410548985004425, train/raw-loss = 0.11597731709480286, train/logprobs = tensor([[-0.8363, -6.9397],
        [-2.4619, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24064086377620697
Epoch 0, Step 1198: train/loss = 0.3863900303840637, train/raw-loss = 0.3444742262363434, train/logprobs = tensor([[-1.0772, -4.4539],
        [-1.8765, -1.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20957902073860168
Epoch 0, Step 1199: train/loss = 0.607352614402771, train/raw-loss = 0.5751482248306274, train/logprobs = tensor([[-0.5515, -0.7924],
        [-0.8061, -0.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16102196276187897
Epoch 0, Step 1200: train/loss = 0.44125327467918396, train/raw-loss = 0.401370644569397, train/logprobs = tensor([[-0.8972, -3.8948],
        [-1.2848, -1.3903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994132101535797
Epoch 0, Step 1201: train/loss = 0.5285224914550781, train/raw-loss = 0.4915199875831604, train/logprobs = tensor([[-0.8139, -2.4178],
        [-1.1956, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18501271307468414
Epoch 0, Step 1202: train/loss = 0.215495303273201, train/raw-loss = 0.16902309656143188, train/logprobs = tensor([[-0.9253, -9.4327],
        [-1.8223, -1.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23236103355884552
Epoch 0, Step 1203: train/loss = 0.29518255591392517, train/raw-loss = 0.2550886869430542, train/logprobs = tensor([[-0.4840, -4.8719],
        [-1.6428, -2.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20046934485435486
Epoch 0, Step 1204: train/loss = 0.4079616963863373, train/raw-loss = 0.3700340688228607, train/logprobs = tensor([[-1.0822, -2.5128],
        [-1.7071, -0.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18963810801506042
Epoch 0, Step 1205: train/loss = 0.5211509466171265, train/raw-loss = 0.4780139923095703, train/logprobs = tensor([[-1.0169, -2.9932],
        [-1.2163, -1.6564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156846821308136
Epoch 0, Step 1206: train/loss = 0.4072408974170685, train/raw-loss = 0.36341679096221924, train/logprobs = tensor([[-1.0618, -3.7252],
        [-1.6525, -1.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21912060678005219
Epoch 0, Step 1207: train/loss = 0.26837974786758423, train/raw-loss = 0.22632691264152527, train/logprobs = tensor([[-0.7790, -5.1249],
        [-1.6267, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102642059326172
Epoch 0, Step 1208: train/loss = 0.2379060536623001, train/raw-loss = 0.19313965737819672, train/logprobs = tensor([[-0.9471, -5.3883],
        [-2.2525, -0.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22383199632167816
Epoch 0, Step 1209: train/loss = 0.18969984352588654, train/raw-loss = 0.14128661155700684, train/logprobs = tensor([[-0.9660, -3.9791],
        [-2.6974, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2420661449432373
Epoch 0, Step 1210: train/loss = 0.3371659219264984, train/raw-loss = 0.2901323735713959, train/logprobs = tensor([[-0.7120, -3.5419],
        [-1.6043, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23516765236854553
Epoch 0, Step 1211: train/loss = 0.2821662127971649, train/raw-loss = 0.24027343094348907, train/logprobs = tensor([[-0.8113, -5.7478],
        [-1.4441, -2.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20946376025676727
Epoch 0, Step 1212: train/loss = 0.5043956637382507, train/raw-loss = 0.4694460928440094, train/logprobs = tensor([[-0.9552, -4.8472],
        [-1.3016, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17474786937236786
Epoch 0, Step 1213: train/loss = 0.353742778301239, train/raw-loss = 0.31470608711242676, train/logprobs = tensor([[-0.8924, -5.1202],
        [-1.4798, -1.3506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19518356025218964
Epoch 0, Step 1214: train/loss = 0.454243004322052, train/raw-loss = 0.4127301573753357, train/logprobs = tensor([[-0.9535, -4.5411],
        [-1.1124, -1.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20756402611732483
Epoch 0, Step 1215: train/loss = 0.3748762905597687, train/raw-loss = 0.3279804289340973, train/logprobs = tensor([[-0.8126, -5.9892],
        [-1.8197, -1.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23447935283184052
Epoch 0, Step 1216: train/loss = 0.4606429934501648, train/raw-loss = 0.4187876284122467, train/logprobs = tensor([[-0.6863, -3.8721],
        [-1.5066, -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20927682518959045
Epoch 0, Step 1217: train/loss = 0.42577120661735535, train/raw-loss = 0.38645222783088684, train/logprobs = tensor([[-1.4063, -7.6042],
        [-2.0213, -2.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19659492373466492
Epoch 0, Step 1218: train/loss = 0.39731645584106445, train/raw-loss = 0.35636645555496216, train/logprobs = tensor([[-0.8125, -4.4386],
        [-1.6269, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20475006103515625
Epoch 0, Step 1219: train/loss = 0.29157528281211853, train/raw-loss = 0.23577092587947845, train/logprobs = tensor([[-1.1516, -8.4332],
        [-2.1429, -1.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.279021680355072
Epoch 0, Step 1220: train/loss = 0.6749011278152466, train/raw-loss = 0.6399118900299072, train/logprobs = tensor([[-0.8272, -0.8345],
        [-1.0188, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174946129322052
Epoch 0, Step 1221: train/loss = 0.35720938444137573, train/raw-loss = 0.32672247290611267, train/logprobs = tensor([[-0.5923, -4.2684],
        [-1.0668, -0.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15243469178676605
Epoch 0, Step 1222: train/loss = 0.4472827613353729, train/raw-loss = 0.4033941328525543, train/logprobs = tensor([[-0.9952, -6.0237],
        [-2.4369, -1.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21944314241409302
Epoch 0, Step 1223: train/loss = 0.28666096925735474, train/raw-loss = 0.25391316413879395, train/logprobs = tensor([[-0.7324, -4.1082],
        [-1.4948, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16373898088932037
Epoch 0, Step 1224: train/loss = 0.45578092336654663, train/raw-loss = 0.42578163743019104, train/logprobs = tensor([[-0.3810, -3.1343],
        [-0.8202, -1.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14999639987945557
Epoch 0, Step 1225: train/loss = 0.3905903697013855, train/raw-loss = 0.35695070028305054, train/logprobs = tensor([[-0.7030, -3.3419],
        [-1.0386, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16819827258586884
Epoch 0, Step 1226: train/loss = 0.4805789589881897, train/raw-loss = 0.4386010766029358, train/logprobs = tensor([[-1.0177, -4.0502],
        [-1.1383, -2.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2098892629146576
Epoch 0, Step 1227: train/loss = 0.559678316116333, train/raw-loss = 0.5199571251869202, train/logprobs = tensor([[-1.3907, -2.8722],
        [-1.4286, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1986059546470642
Epoch 0, Step 1228: train/loss = 0.5067659616470337, train/raw-loss = 0.4660760760307312, train/logprobs = tensor([[-0.8024, -2.0197],
        [-1.1732, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20344939827919006
Epoch 0, Step 1229: train/loss = 0.3543543219566345, train/raw-loss = 0.32088905572891235, train/logprobs = tensor([[-0.6040, -6.6842],
        [-1.0916, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16732636094093323
Epoch 0, Step 1230: train/loss = 0.6117547750473022, train/raw-loss = 0.5692957639694214, train/logprobs = tensor([[-1.8362, -2.5076],
        [-2.1865, -1.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21229515969753265
Epoch 0, Step 1231: train/loss = 0.43486639857292175, train/raw-loss = 0.3904862105846405, train/logprobs = tensor([[-1.1336, -2.5041],
        [-1.7866, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22190096974372864
Epoch 0, Step 1232: train/loss = 1.0296683311462402, train/raw-loss = 0.9993646740913391, train/logprobs = tensor([[-4.2822, -7.4252],
        [-2.3440, -3.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515180766582489
Epoch 0, Step 1233: train/loss = 0.5433828830718994, train/raw-loss = 0.5036311149597168, train/logprobs = tensor([[-0.6199, -1.8201],
        [-0.9226, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19875898957252502
Epoch 0, Step 1234: train/loss = 0.3875100314617157, train/raw-loss = 0.34574106335639954, train/logprobs = tensor([[-0.9772, -3.4994],
        [-1.7477, -1.3339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.208844855427742
Epoch 0, Step 1235: train/loss = 0.7868970632553101, train/raw-loss = 0.7494117617607117, train/logprobs = tensor([[-1.9263, -6.3367],
        [-1.0501, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18742646276950836
Epoch 0, Step 1236: train/loss = 0.29945752024650574, train/raw-loss = 0.2599344253540039, train/logprobs = tensor([[-0.5076, -6.8147],
        [-1.1088, -1.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19761550426483154
Epoch 0, Step 1237: train/loss = 0.2708519995212555, train/raw-loss = 0.2283330261707306, train/logprobs = tensor([[-0.8378, -8.4130],
        [-2.0261, -1.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2125948667526245
Epoch 0, Step 1238: train/loss = 0.4536915123462677, train/raw-loss = 0.41367173194885254, train/logprobs = tensor([[-0.6969, -3.5132],
        [-1.4829, -1.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20009905099868774
Epoch 0, Step 1239: train/loss = 0.5346589088439941, train/raw-loss = 0.5043554306030273, train/logprobs = tensor([[-0.9951, -4.0808],
        [-0.8514, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515175700187683
Epoch 0, Step 1240: train/loss = 0.5146611928939819, train/raw-loss = 0.47101834416389465, train/logprobs = tensor([[-1.4205, -7.2903],
        [-2.1837, -1.3323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21821430325508118
Epoch 0, Step 1241: train/loss = 0.3287334144115448, train/raw-loss = 0.27975231409072876, train/logprobs = tensor([[-0.7801, -3.3976],
        [-2.1785, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24490544199943542
Epoch 0, Step 1242: train/loss = 0.403970330953598, train/raw-loss = 0.36908158659935, train/logprobs = tensor([[-0.9132, -3.0569],
        [-1.8024, -1.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17444376647472382
Epoch 0, Step 1243: train/loss = 0.4724765419960022, train/raw-loss = 0.4321022033691406, train/logprobs = tensor([[-0.7337, -2.2473],
        [-1.5432, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20187155902385712
Epoch 0, Step 1244: train/loss = 0.35009488463401794, train/raw-loss = 0.3080754280090332, train/logprobs = tensor([[-0.7898, -2.8747],
        [-1.6867, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21009725332260132
Epoch 0, Step 1245: train/loss = 0.25332051515579224, train/raw-loss = 0.2039709985256195, train/logprobs = tensor([[-0.7202, -4.8138],
        [-2.2568, -1.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24674758315086365
Epoch 0, Step 1246: train/loss = 0.22412905097007751, train/raw-loss = 0.18411891162395477, train/logprobs = tensor([[-0.8423, -4.0358],
        [-2.0221, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20005062222480774
Epoch 0, Step 1247: train/loss = 0.40940430760383606, train/raw-loss = 0.36465024948120117, train/logprobs = tensor([[-1.2839, -4.7233],
        [-1.3792, -1.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2237703502178192
Epoch 0, Step 1248: train/loss = 0.4800211787223816, train/raw-loss = 0.4360710680484772, train/logprobs = tensor([[-0.7208, -2.4840],
        [-1.4652, -1.3311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21975047886371613
Epoch 0, Step 1249: train/loss = 0.5461088418960571, train/raw-loss = 0.4989457130432129, train/logprobs = tensor([[-1.1312, -2.2718],
        [-1.6049, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2358156442642212
Epoch 0, Step 1250: train/loss = 0.48342156410217285, train/raw-loss = 0.4381604790687561, train/logprobs = tensor([[-0.8951, -2.7070],
        [-1.2778, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22630532085895538
Epoch 0, Step 1251: train/loss = 0.3993276357650757, train/raw-loss = 0.352571576833725, train/logprobs = tensor([[-0.5478, -4.6393],
        [-1.6241, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23378050327301025
Epoch 0, Step 1252: train/loss = 0.2041599154472351, train/raw-loss = 0.1469230204820633, train/logprobs = tensor([[-0.9392, -7.7307],
        [-2.6504, -2.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28618448972702026
Epoch 0, Step 1253: train/loss = 0.3951587677001953, train/raw-loss = 0.353515625, train/logprobs = tensor([[-0.7973, -2.7434],
        [-1.6895, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20821581780910492
Epoch 0, Step 1254: train/loss = 0.4360188841819763, train/raw-loss = 0.3994319438934326, train/logprobs = tensor([[-0.4713, -2.7542],
        [-1.1333, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18293483555316925
Epoch 0, Step 1255: train/loss = 0.6761641502380371, train/raw-loss = 0.6391276121139526, train/logprobs = tensor([[-0.6609, -0.9450],
        [-1.2381, -1.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1851826012134552
Epoch 0, Step 1256: train/loss = 0.3381168246269226, train/raw-loss = 0.2912052571773529, train/logprobs = tensor([[-1.2488, -3.0042],
        [-3.2444, -2.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23455779254436493
Epoch 0, Step 1257: train/loss = 0.4709629416465759, train/raw-loss = 0.4292728304862976, train/logprobs = tensor([[-0.6188, -2.9938],
        [-1.0207, -0.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20845070481300354
Epoch 0, Step 1258: train/loss = 0.31511637568473816, train/raw-loss = 0.26825085282325745, train/logprobs = tensor([[-0.9149, -4.0502],
        [-2.1586, -1.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23432748019695282
Epoch 0, Step 1259: train/loss = 0.634397029876709, train/raw-loss = 0.5901377201080322, train/logprobs = tensor([[-0.6555, -1.3308],
        [-1.1858, -1.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22129669785499573
Epoch 0, Step 1260: train/loss = 0.469529926776886, train/raw-loss = 0.41452527046203613, train/logprobs = tensor([[ -0.9130, -10.7592],
        [ -2.0702,  -2.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750232219696045
Epoch 0, Step 1261: train/loss = 0.5199005603790283, train/raw-loss = 0.4574756622314453, train/logprobs = tensor([[-0.8549, -3.1883],
        [-2.3055, -1.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31212472915649414
Epoch 0, Step 1262: train/loss = 0.4156930446624756, train/raw-loss = 0.3723334074020386, train/logprobs = tensor([[-0.8595, -3.9767],
        [-1.6176, -1.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21679812669754028
Epoch 0, Step 1263: train/loss = 0.504295825958252, train/raw-loss = 0.4593806266784668, train/logprobs = tensor([[-1.4604, -4.9260],
        [-1.4655, -1.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22457580268383026
Epoch 0, Step 1264: train/loss = 0.30658143758773804, train/raw-loss = 0.2609789967536926, train/logprobs = tensor([[-1.1502, -5.0905],
        [-1.8667, -1.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22801226377487183
Epoch 0, Step 1265: train/loss = 0.4650518596172333, train/raw-loss = 0.4186955690383911, train/logprobs = tensor([[-0.9383, -2.9974],
        [-2.1384, -1.3901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23178140819072723
Epoch 0, Step 1266: train/loss = 0.43363237380981445, train/raw-loss = 0.3925812542438507, train/logprobs = tensor([[-1.3879, -8.3486],
        [-1.7717, -1.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20525559782981873
Epoch 0, Step 1267: train/loss = 0.184104323387146, train/raw-loss = 0.13926143944263458, train/logprobs = tensor([[-0.8883, -5.0411],
        [-2.3804, -1.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22421441972255707
Epoch 0, Step 1268: train/loss = 0.2748323082923889, train/raw-loss = 0.23330555856227875, train/logprobs = tensor([[-0.9208, -7.4779],
        [-2.5964, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2076336294412613
Epoch 0, Step 1269: train/loss = 0.37114936113357544, train/raw-loss = 0.32799163460731506, train/logprobs = tensor([[-1.1687, -4.9846],
        [-2.0834, -2.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21578863263130188
Epoch 0, Step 1270: train/loss = 0.4887530207633972, train/raw-loss = 0.448921799659729, train/logprobs = tensor([[-0.9906, -3.5688],
        [-1.5711, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19915613532066345
Epoch 0, Step 1271: train/loss = 0.5842790603637695, train/raw-loss = 0.5504517555236816, train/logprobs = tensor([[-0.8092, -4.5525],
        [-1.0597, -1.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691366583108902
Epoch 0, Step 1272: train/loss = 0.2972356677055359, train/raw-loss = 0.2486063688993454, train/logprobs = tensor([[-1.1081, -5.2992],
        [-2.2029, -2.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431465983390808
Epoch 0, Step 1273: train/loss = 0.5045181512832642, train/raw-loss = 0.4629649221897125, train/logprobs = tensor([[-1.1404, -3.0184],
        [-1.3701, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20776614546775818
Epoch 0, Step 1274: train/loss = 0.4676434099674225, train/raw-loss = 0.4234756529331207, train/logprobs = tensor([[-0.4701, -3.3329],
        [-1.1225, -1.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22083866596221924
Epoch 0, Step 1275: train/loss = 0.3379649519920349, train/raw-loss = 0.2901514768600464, train/logprobs = tensor([[-0.5739, -3.0163],
        [-1.7534, -0.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23906737565994263
Epoch 0, Step 1276: train/loss = 0.32301071286201477, train/raw-loss = 0.28372302651405334, train/logprobs = tensor([[-0.7528, -9.9543],
        [-1.5748, -1.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19643840193748474
Epoch 0, Step 1277: train/loss = 0.47091346979141235, train/raw-loss = 0.43204909563064575, train/logprobs = tensor([[-0.7867, -2.1839],
        [-1.1702, -1.2007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19432207942008972
Epoch 0, Step 1278: train/loss = 0.2694735527038574, train/raw-loss = 0.22314850986003876, train/logprobs = tensor([[-0.5239, -4.5760],
        [-1.9179, -1.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2316252589225769
Epoch 0, Step 1279: train/loss = 0.23010972142219543, train/raw-loss = 0.17962634563446045, train/logprobs = tensor([[-0.8471, -6.0704],
        [-2.3419, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25241681933403015
Epoch 0, Step 1280: train/loss = 0.3122928738594055, train/raw-loss = 0.2659096121788025, train/logprobs = tensor([[-0.6873, -4.9917],
        [-1.9201, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23191629350185394
Epoch 0, Step 1281: train/loss = 0.37452346086502075, train/raw-loss = 0.32836151123046875, train/logprobs = tensor([[-0.8924, -5.0214],
        [-1.3821, -1.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23080991208553314
Epoch 0, Step 1282: train/loss = 0.4804109036922455, train/raw-loss = 0.4477185606956482, train/logprobs = tensor([[-0.4863, -2.8482],
        [-0.8465, -1.4224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1634616106748581
Epoch 0, Step 1283: train/loss = 0.48668140172958374, train/raw-loss = 0.4483022689819336, train/logprobs = tensor([[-0.5643, -2.4820],
        [-1.1316, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19189563393592834
Epoch 0, Step 1284: train/loss = 0.4778938889503479, train/raw-loss = 0.443276047706604, train/logprobs = tensor([[-0.4957, -4.1715],
        [-0.9280, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17308898270130157
Epoch 0, Step 1285: train/loss = 0.2162654548883438, train/raw-loss = 0.17383265495300293, train/logprobs = tensor([[-0.9279, -7.9102],
        [-2.4190, -1.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21216396987438202
Epoch 0, Step 1286: train/loss = 0.2507660686969757, train/raw-loss = 0.20993077754974365, train/logprobs = tensor([[-0.7159, -5.9064],
        [-2.0858, -1.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2041763961315155
Epoch 0, Step 1287: train/loss = 0.4237179756164551, train/raw-loss = 0.3795919418334961, train/logprobs = tensor([[-0.6281, -5.2263],
        [-1.6596, -1.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2206302434206009
Epoch 0, Step 1288: train/loss = 0.7015405297279358, train/raw-loss = 0.6603951454162598, train/logprobs = tensor([[-1.5613, -3.5872],
        [-1.2447, -1.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20572683215141296
Epoch 0, Step 1289: train/loss = 0.3620339035987854, train/raw-loss = 0.324468195438385, train/logprobs = tensor([[-0.9108, -4.6193],
        [-2.0770, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18782860040664673
Epoch 0, Step 1290: train/loss = 0.35918736457824707, train/raw-loss = 0.3194417953491211, train/logprobs = tensor([[-0.8459, -4.4659],
        [-1.6693, -1.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1987277865409851
Epoch 0, Step 1291: train/loss = 0.4099424481391907, train/raw-loss = 0.3688164949417114, train/logprobs = tensor([[ -2.0355, -11.9038],
        [ -2.6569,  -2.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20562982559204102
Epoch 0, Step 1292: train/loss = 0.35701093077659607, train/raw-loss = 0.30586305260658264, train/logprobs = tensor([[-0.7646, -6.0072],
        [-2.3844, -2.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557394802570343
Epoch 0, Step 1293: train/loss = 0.2620323598384857, train/raw-loss = 0.21455302834510803, train/logprobs = tensor([[-0.8825, -5.1945],
        [-2.6794, -1.0219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2373967468738556
Epoch 0, Step 1294: train/loss = 0.37729784846305847, train/raw-loss = 0.3301403522491455, train/logprobs = tensor([[-1.0760, -3.2547],
        [-2.4135, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23578743636608124
Epoch 0, Step 1295: train/loss = 0.3479994237422943, train/raw-loss = 0.3100089132785797, train/logprobs = tensor([[-0.9419, -5.6540],
        [-2.4155, -3.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1899527907371521
Epoch 0, Step 1296: train/loss = 0.22553645074367523, train/raw-loss = 0.18254335224628448, train/logprobs = tensor([[-0.8427, -3.9491],
        [-2.2315, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21496546268463135
Epoch 0, Step 1297: train/loss = 0.3703209161758423, train/raw-loss = 0.3262019157409668, train/logprobs = tensor([[-0.7780, -7.6300],
        [-1.5296, -2.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2205950915813446
Epoch 0, Step 1298: train/loss = 0.4548490643501282, train/raw-loss = 0.40487146377563477, train/logprobs = tensor([[-1.3426, -2.1059],
        [-2.3177, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498878836631775
Epoch 0, Step 1299: train/loss = 0.32991018891334534, train/raw-loss = 0.2884806990623474, train/logprobs = tensor([[-0.6533, -5.1910],
        [-2.0546, -1.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2071472853422165
Epoch 0, Step 1300: train/loss = 0.45543041825294495, train/raw-loss = 0.40559276938438416, train/logprobs = tensor([[-0.9358, -5.9758],
        [-1.7398, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24918827414512634
Epoch 0, Step 1301: train/loss = 0.5896928310394287, train/raw-loss = 0.5346956849098206, train/logprobs = tensor([[-1.1188, -2.5803],
        [-1.5316, -1.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749858498573303
Epoch 0, Step 1302: train/loss = 0.45979809761047363, train/raw-loss = 0.4203950762748718, train/logprobs = tensor([[-0.6007, -1.5508],
        [-1.4201, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1970149129629135
Epoch 0, Step 1303: train/loss = 0.46178025007247925, train/raw-loss = 0.42198315262794495, train/logprobs = tensor([[-0.4601, -3.0043],
        [-1.3407, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19898566603660583
Epoch 0, Step 1304: train/loss = 0.48604971170425415, train/raw-loss = 0.4417649805545807, train/logprobs = tensor([[-0.6563, -2.3422],
        [-2.0378, -1.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2214238941669464
Epoch 0, Step 1305: train/loss = 0.4630316197872162, train/raw-loss = 0.4196992516517639, train/logprobs = tensor([[-2.0618, -6.1530],
        [-2.2546, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21666188538074493
Epoch 0, Step 1306: train/loss = 0.35994476079940796, train/raw-loss = 0.31225988268852234, train/logprobs = tensor([[-2.0284, -6.2688],
        [-2.4679, -1.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23842447996139526
Epoch 0, Step 1307: train/loss = 0.41210803389549255, train/raw-loss = 0.3778843581676483, train/logprobs = tensor([[-1.0662, -2.3915],
        [-2.0173, -0.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111843824386597
Epoch 0, Step 1308: train/loss = 0.42714768648147583, train/raw-loss = 0.38924717903137207, train/logprobs = tensor([[-0.6156, -4.3585],
        [-1.7417, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1895027607679367
Epoch 0, Step 1309: train/loss = 0.41057300567626953, train/raw-loss = 0.36885684728622437, train/logprobs = tensor([[-0.8940, -2.6188],
        [-1.7491, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.208580881357193
Epoch 0, Step 1310: train/loss = 0.40736448764801025, train/raw-loss = 0.3652002811431885, train/logprobs = tensor([[-0.6679, -3.6686],
        [-1.7702, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21082092821598053
Epoch 0, Step 1311: train/loss = 0.3136184811592102, train/raw-loss = 0.2738116383552551, train/logprobs = tensor([[-0.6545, -3.8549],
        [-2.0083, -1.4411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903406500816345
Epoch 0, Step 1312: train/loss = 0.5149470567703247, train/raw-loss = 0.4676673710346222, train/logprobs = tensor([[-0.7989, -2.8411],
        [-2.0389, -1.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.236398383975029
Epoch 0, Step 1313: train/loss = 0.7454022169113159, train/raw-loss = 0.6954749822616577, train/logprobs = tensor([[-2.0372, -2.2733],
        [-1.9538, -1.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24963605403900146
Epoch 0, Step 1314: train/loss = 0.9199429750442505, train/raw-loss = 0.8739311695098877, train/logprobs = tensor([[-1.8500, -1.7414],
        [-1.2713, -1.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2300586700439453
Epoch 0, Step 1315: train/loss = 0.2306612879037857, train/raw-loss = 0.18296284973621368, train/logprobs = tensor([[ -0.7998, -12.8112],
        [ -2.3264,  -2.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384921759366989
Epoch 0, Step 1316: train/loss = 0.4234742224216461, train/raw-loss = 0.38206860423088074, train/logprobs = tensor([[-0.7337, -2.5721],
        [-1.7567, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20702803134918213
Epoch 0, Step 1317: train/loss = 0.48011305928230286, train/raw-loss = 0.4343508183956146, train/logprobs = tensor([[-0.6003, -2.3913],
        [-1.7949, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22881127893924713
Epoch 0, Step 1318: train/loss = 0.3284670412540436, train/raw-loss = 0.282032310962677, train/logprobs = tensor([[-0.8184, -5.6832],
        [-1.6383, -2.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23217365145683289
Epoch 0, Step 1319: train/loss = 0.30910372734069824, train/raw-loss = 0.2635559141635895, train/logprobs = tensor([[-0.7255, -3.5462],
        [-2.2199, -0.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22773902118206024
Epoch 0, Step 1320: train/loss = 0.40410900115966797, train/raw-loss = 0.359281986951828, train/logprobs = tensor([[-1.0780, -5.0126],
        [-2.5332, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22413501143455505
Epoch 0, Step 1321: train/loss = 0.5490913391113281, train/raw-loss = 0.5055099725723267, train/logprobs = tensor([[-0.6117, -2.0000],
        [-1.2259, -1.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.217906653881073
Epoch 0, Step 1322: train/loss = 0.3991570770740509, train/raw-loss = 0.35246720910072327, train/logprobs = tensor([[-0.6602, -2.2433],
        [-1.5970, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2334493100643158
Epoch 0, Step 1323: train/loss = 0.5295702815055847, train/raw-loss = 0.4966183304786682, train/logprobs = tensor([[-0.6416, -3.3850],
        [-0.7645, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16475966572761536
Epoch 0, Step 1324: train/loss = 0.3876335322856903, train/raw-loss = 0.34185993671417236, train/logprobs = tensor([[-0.5828, -5.3473],
        [-1.2789, -1.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22886791825294495
Epoch 0, Step 1325: train/loss = 0.6304848194122314, train/raw-loss = 0.6004961729049683, train/logprobs = tensor([[-0.3530, -2.8869],
        [-0.7752, -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1499430537223816
Epoch 0, Step 1326: train/loss = 0.3944399356842041, train/raw-loss = 0.3391761779785156, train/logprobs = tensor([[-1.7865, -7.2206],
        [-2.0808, -1.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2763187885284424
Epoch 0, Step 1327: train/loss = 0.5060398578643799, train/raw-loss = 0.45415616035461426, train/logprobs = tensor([[-1.8322, -3.6074],
        [-2.3899, -1.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25941866636276245
Epoch 0, Step 1328: train/loss = 0.3203454911708832, train/raw-loss = 0.274922639131546, train/logprobs = tensor([[-0.9622, -5.0998],
        [-1.6297, -2.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22711434960365295
Epoch 0, Step 1329: train/loss = 0.2598992586135864, train/raw-loss = 0.20395563542842865, train/logprobs = tensor([[-1.5817, -6.4232],
        [-3.4976, -2.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27971819043159485
Epoch 0, Step 1330: train/loss = 0.5004584789276123, train/raw-loss = 0.4507347643375397, train/logprobs = tensor([[-1.4161, -6.1009],
        [-1.7157, -3.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2486184537410736
Epoch 0, Step 1331: train/loss = 0.3226056396961212, train/raw-loss = 0.26781022548675537, train/logprobs = tensor([[-1.1825, -3.4987],
        [-2.4390, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739771008491516
Epoch 0, Step 1332: train/loss = 0.26993465423583984, train/raw-loss = 0.21869084239006042, train/logprobs = tensor([[-0.9872, -4.8798],
        [-2.1652, -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25621891021728516
Epoch 0, Step 1333: train/loss = 0.4690190553665161, train/raw-loss = 0.426387757062912, train/logprobs = tensor([[-0.9236, -3.6649],
        [-1.5172, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21315641701221466
Epoch 0, Step 1334: train/loss = 0.7340185046195984, train/raw-loss = 0.6821369528770447, train/logprobs = tensor([[-2.1372, -3.6156],
        [-2.6264, -1.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25940781831741333
Epoch 0, Step 1335: train/loss = 0.36796534061431885, train/raw-loss = 0.3256518542766571, train/logprobs = tensor([[-2.0894, -6.4073],
        [-3.2577, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21156759560108185
Epoch 0, Step 1336: train/loss = 0.3327905535697937, train/raw-loss = 0.2854231894016266, train/logprobs = tensor([[-0.9012, -8.2310],
        [-1.8650, -2.3573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.236836776137352
Epoch 0, Step 1337: train/loss = 0.4698479175567627, train/raw-loss = 0.4406081736087799, train/logprobs = tensor([[-0.4916, -5.7410],
        [-0.9002, -1.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14619863033294678
Epoch 0, Step 1338: train/loss = 0.32900846004486084, train/raw-loss = 0.2742811441421509, train/logprobs = tensor([[-0.7859, -3.8969],
        [-2.2193, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2736365497112274
Epoch 0, Step 1339: train/loss = 0.3146248161792755, train/raw-loss = 0.2585129141807556, train/logprobs = tensor([[-1.2800, -3.8742],
        [-2.8699, -1.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805594503879547
Epoch 0, Step 1340: train/loss = 0.21943293511867523, train/raw-loss = 0.17232517898082733, train/logprobs = tensor([[-0.7770, -4.7629],
        [-2.6887, -1.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2355387806892395
Epoch 0, Step 1341: train/loss = 0.344474196434021, train/raw-loss = 0.31007999181747437, train/logprobs = tensor([[-1.0588, -3.7949],
        [-2.0064, -1.3097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17197102308273315
Epoch 0, Step 1342: train/loss = 0.5877236127853394, train/raw-loss = 0.5543164014816284, train/logprobs = tensor([[-0.9127, -2.8512],
        [-0.9441, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16703638434410095
Epoch 0, Step 1343: train/loss = 0.21602818369865417, train/raw-loss = 0.17028410732746124, train/logprobs = tensor([[-0.8920, -4.3810],
        [-2.6399, -0.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22872033715248108
Epoch 0, Step 1344: train/loss = 0.6994563341140747, train/raw-loss = 0.6619306802749634, train/logprobs = tensor([[-1.7547, -4.4262],
        [-0.9642, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18762829899787903
Epoch 0, Step 1345: train/loss = 0.5110524892807007, train/raw-loss = 0.4602448344230652, train/logprobs = tensor([[-1.1619, -2.8862],
        [-2.1635, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540383040904999
Epoch 0, Step 1346: train/loss = 0.4852806031703949, train/raw-loss = 0.4347462058067322, train/logprobs = tensor([[-1.2772, -3.0292],
        [-2.2249, -1.4416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25267213582992554
Epoch 0, Step 1347: train/loss = 0.41330021619796753, train/raw-loss = 0.36907199025154114, train/logprobs = tensor([[-1.0262, -3.7607],
        [-2.0885, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22114112973213196
Epoch 0, Step 1348: train/loss = 0.5029665231704712, train/raw-loss = 0.46733665466308594, train/logprobs = tensor([[-0.9547, -2.1456],
        [-2.4229, -2.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1781492531299591
Epoch 0, Step 1349: train/loss = 0.39795270562171936, train/raw-loss = 0.35242167115211487, train/logprobs = tensor([[-1.2663, -3.1315],
        [-2.2688, -1.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22765518724918365
Epoch 0, Step 1350: train/loss = 0.35086750984191895, train/raw-loss = 0.3110891878604889, train/logprobs = tensor([[-0.7765, -8.2954],
        [-1.8799, -2.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19889162480831146
Epoch 0, Step 1351: train/loss = 0.5307536125183105, train/raw-loss = 0.48548346757888794, train/logprobs = tensor([[-0.8943, -2.5097],
        [-2.2831, -2.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22635042667388916
Epoch 0, Step 1352: train/loss = 0.5167297124862671, train/raw-loss = 0.48507440090179443, train/logprobs = tensor([[-0.7652, -2.5548],
        [-1.0711, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15827679634094238
Epoch 0, Step 1353: train/loss = 0.5984205603599548, train/raw-loss = 0.5640521049499512, train/logprobs = tensor([[-0.6818, -3.8306],
        [-1.1421, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17184218764305115
Epoch 0, Step 1354: train/loss = 0.3859855532646179, train/raw-loss = 0.33735355734825134, train/logprobs = tensor([[-0.7350, -2.5672],
        [-2.0000, -1.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24315978586673737
Epoch 0, Step 1355: train/loss = 0.1701643466949463, train/raw-loss = 0.13114818930625916, train/logprobs = tensor([[-1.0221, -7.7513],
        [-2.2653, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19508084654808044
Epoch 0, Step 1356: train/loss = 0.42803889513015747, train/raw-loss = 0.3875966966152191, train/logprobs = tensor([[-1.2807, -3.2129],
        [-2.0424, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20221096277236938
Epoch 0, Step 1357: train/loss = 0.5711341500282288, train/raw-loss = 0.5268312692642212, train/logprobs = tensor([[-0.6108, -1.4622],
        [-1.1452, -1.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22151465713977814
Epoch 0, Step 1358: train/loss = 0.25154584646224976, train/raw-loss = 0.20450633764266968, train/logprobs = tensor([[-0.7964, -4.4792],
        [-2.5798, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23519763350486755
Epoch 0, Step 1359: train/loss = 0.5100357532501221, train/raw-loss = 0.46152567863464355, train/logprobs = tensor([[-0.5928, -2.9767],
        [-1.6376, -1.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24255019426345825
Epoch 0, Step 1360: train/loss = 0.26166149973869324, train/raw-loss = 0.22076502442359924, train/logprobs = tensor([[-0.9312, -4.3217],
        [-1.9428, -1.6708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20448237657546997
Epoch 0, Step 1361: train/loss = 0.3154308497905731, train/raw-loss = 0.2691485285758972, train/logprobs = tensor([[-0.9173, -5.0275],
        [-1.9457, -1.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2314116358757019
Epoch 0, Step 1362: train/loss = 0.38083335757255554, train/raw-loss = 0.3323650062084198, train/logprobs = tensor([[-0.8096, -4.2788],
        [-2.5951, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24234183132648468
Epoch 0, Step 1363: train/loss = 0.501804769039154, train/raw-loss = 0.4651840925216675, train/logprobs = tensor([[-0.7344, -3.1578],
        [-1.1672, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18310342729091644
Epoch 0, Step 1364: train/loss = 0.3870735764503479, train/raw-loss = 0.342424213886261, train/logprobs = tensor([[-0.5337, -4.1655],
        [-1.5299, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2232469916343689
Epoch 0, Step 1365: train/loss = 0.3643597662448883, train/raw-loss = 0.3269016146659851, train/logprobs = tensor([[-0.4018, -4.8114],
        [-1.2508, -1.0476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18729078769683838
Epoch 0, Step 1366: train/loss = 0.5260566473007202, train/raw-loss = 0.4921592175960541, train/logprobs = tensor([[-0.4306, -3.1699],
        [-0.9468, -1.5206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16948704421520233
Epoch 0, Step 1367: train/loss = 0.36969292163848877, train/raw-loss = 0.3220835328102112, train/logprobs = tensor([[-0.7577, -5.7435],
        [-2.4613, -1.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23804712295532227
Epoch 0, Step 1368: train/loss = 0.5283040404319763, train/raw-loss = 0.4899672269821167, train/logprobs = tensor([[-0.8173, -2.2117],
        [-1.3292, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19168412685394287
Epoch 0, Step 1369: train/loss = 0.42153671383857727, train/raw-loss = 0.3676365911960602, train/logprobs = tensor([[-0.5644, -2.0256],
        [-2.8107, -1.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.269500732421875
Epoch 0, Step 1370: train/loss = 0.4730367660522461, train/raw-loss = 0.42939943075180054, train/logprobs = tensor([[-0.8663, -2.3379],
        [-1.7683, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181866466999054
Epoch 0, Step 1371: train/loss = 0.4223923683166504, train/raw-loss = 0.37972623109817505, train/logprobs = tensor([[-0.7308, -3.7846],
        [-1.6809, -1.1882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21333074569702148
Epoch 0, Step 1372: train/loss = 0.23094861209392548, train/raw-loss = 0.18178805708885193, train/logprobs = tensor([[-0.8717, -7.3711],
        [-2.6494, -1.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24580273032188416
Epoch 0, Step 1373: train/loss = 0.6711863875389099, train/raw-loss = 0.6301117539405823, train/logprobs = tensor([[-1.7605, -3.0436],
        [-2.6682, -1.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20537309348583221
Epoch 0, Step 1374: train/loss = 0.41216227412223816, train/raw-loss = 0.37435653805732727, train/logprobs = tensor([[-0.4505, -3.6317],
        [-1.6172, -1.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18902865052223206
Epoch 0, Step 1375: train/loss = 0.280214786529541, train/raw-loss = 0.23668478429317474, train/logprobs = tensor([[-1.0922, -6.0518],
        [-2.1259, -1.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21765005588531494
Epoch 0, Step 1376: train/loss = 0.2342911809682846, train/raw-loss = 0.1816958785057068, train/logprobs = tensor([[-1.1036, -5.4474],
        [-3.1557, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26297643780708313
Epoch 0, Step 1377: train/loss = 0.4164024591445923, train/raw-loss = 0.3745882213115692, train/logprobs = tensor([[-0.6749, -6.1071],
        [-1.6339, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20907117426395416
Epoch 0, Step 1378: train/loss = 0.4948192238807678, train/raw-loss = 0.446442186832428, train/logprobs = tensor([[-1.2364, -3.6910],
        [-1.6156, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24188533425331116
Epoch 0, Step 1379: train/loss = 0.6001400947570801, train/raw-loss = 0.5459024906158447, train/logprobs = tensor([[-1.1651, -3.0263],
        [-2.2778, -2.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.271187961101532
Epoch 0, Step 1380: train/loss = 0.165713369846344, train/raw-loss = 0.11417052894830704, train/logprobs = tensor([[-0.5637, -5.9339],
        [-2.2261, -1.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2577142119407654
Epoch 0, Step 1381: train/loss = 0.29102569818496704, train/raw-loss = 0.23704873025417328, train/logprobs = tensor([[-0.7575, -8.2046],
        [-1.9122, -1.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26988485455513
Epoch 0, Step 1382: train/loss = 0.29641908407211304, train/raw-loss = 0.24257004261016846, train/logprobs = tensor([[-1.2710, -6.9342],
        [-2.1261, -1.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2692451477050781
Epoch 0, Step 1383: train/loss = 0.3341948390007019, train/raw-loss = 0.29225271940231323, train/logprobs = tensor([[-0.9946, -5.6423],
        [-2.6078, -2.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20971064269542694
Epoch 0, Step 1384: train/loss = 0.4519299864768982, train/raw-loss = 0.4094812870025635, train/logprobs = tensor([[-0.7053, -3.9277],
        [-1.7411, -1.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21224352717399597
Epoch 0, Step 1385: train/loss = 0.37282294034957886, train/raw-loss = 0.3173626661300659, train/logprobs = tensor([[-1.0078, -2.8765],
        [-2.9489, -1.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2773014307022095
Epoch 0, Step 1386: train/loss = 0.2587764859199524, train/raw-loss = 0.19992949068546295, train/logprobs = tensor([[-1.0815, -3.9656],
        [-2.6181, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942350208759308
Epoch 0, Step 1387: train/loss = 0.4917702376842499, train/raw-loss = 0.4395883083343506, train/logprobs = tensor([[-0.6922, -1.7821],
        [-2.2971, -1.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26090964674949646
Epoch 0, Step 1388: train/loss = 0.32700589299201965, train/raw-loss = 0.28468573093414307, train/logprobs = tensor([[-1.1427, -5.1954],
        [-2.2336, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2116008847951889
Epoch 0, Step 1389: train/loss = 0.5098519921302795, train/raw-loss = 0.4570871591567993, train/logprobs = tensor([[-1.4316, -4.3987],
        [-1.9987, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638242244720459
Epoch 0, Step 1390: train/loss = 0.43187984824180603, train/raw-loss = 0.38692277669906616, train/logprobs = tensor([[-0.8301, -2.8595],
        [-1.5120, -1.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22478541731834412
Epoch 0, Step 1391: train/loss = 0.4071849584579468, train/raw-loss = 0.36226963996887207, train/logprobs = tensor([[-0.7279, -3.0026],
        [-1.8931, -1.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22457647323608398
Epoch 0, Step 1392: train/loss = 0.30723097920417786, train/raw-loss = 0.26450908184051514, train/logprobs = tensor([[-0.9301, -8.0838],
        [-1.7961, -2.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21360954642295837
Epoch 0, Step 1393: train/loss = 0.2744489312171936, train/raw-loss = 0.2213897556066513, train/logprobs = tensor([[-0.7007, -7.4684],
        [-2.8199, -2.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652958631515503
Epoch 0, Step 1394: train/loss = 0.3708854913711548, train/raw-loss = 0.3154580891132355, train/logprobs = tensor([[-0.6466, -2.3587],
        [-2.4079, -1.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27713683247566223
Epoch 0, Step 1395: train/loss = 0.3534209728240967, train/raw-loss = 0.29613104462623596, train/logprobs = tensor([[-0.8161, -4.4169],
        [-2.1500, -2.3402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2864496409893036
Epoch 0, Step 1396: train/loss = 0.28644487261772156, train/raw-loss = 0.22824370861053467, train/logprobs = tensor([[-0.9596, -5.5917],
        [-2.5088, -1.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2910057008266449
Epoch 0, Step 1397: train/loss = 0.2919323742389679, train/raw-loss = 0.2515796422958374, train/logprobs = tensor([[-0.7830, -9.3687],
        [-1.5382, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20176362991333008
Epoch 0, Step 1398: train/loss = 0.15753322839736938, train/raw-loss = 0.09531712532043457, train/logprobs = tensor([[-1.1488, -6.3407],
        [-3.0944, -1.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3110805153846741
Epoch 0, Step 1399: train/loss = 0.3022454082965851, train/raw-loss = 0.24626319110393524, train/logprobs = tensor([[-0.5226, -4.1276],
        [-2.9521, -1.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27991119027137756
Epoch 0, Step 1400: train/loss = 0.6184608936309814, train/raw-loss = 0.5646775960922241, train/logprobs = tensor([[-0.7699, -7.5723],
        [-2.2347, -3.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689162492752075
Epoch 0, Step 1401: train/loss = 0.29005640745162964, train/raw-loss = 0.2292148470878601, train/logprobs = tensor([[-1.5373, -7.0715],
        [-3.3242, -2.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30420780181884766
Epoch 0, Step 1402: train/loss = 0.24887408316135406, train/raw-loss = 0.20030808448791504, train/logprobs = tensor([[-0.8303, -4.5529],
        [-2.5496, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2428300380706787
Epoch 0, Step 1403: train/loss = 0.3851586878299713, train/raw-loss = 0.3381213843822479, train/logprobs = tensor([[-1.5484, -4.9152],
        [-2.2339, -2.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23518648743629456
Epoch 0, Step 1404: train/loss = 0.27972114086151123, train/raw-loss = 0.23318448662757874, train/logprobs = tensor([[-0.8896, -7.1952],
        [-2.8031, -1.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23268336057662964
Epoch 0, Step 1405: train/loss = 0.43233880400657654, train/raw-loss = 0.37636464834213257, train/logprobs = tensor([[-0.9599, -6.7051],
        [-2.4868, -2.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798708379268646
Epoch 0, Step 1406: train/loss = 0.5073791742324829, train/raw-loss = 0.46563827991485596, train/logprobs = tensor([[-0.5134, -2.1402],
        [-1.4160, -1.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087046355009079
Epoch 0, Step 1407: train/loss = 0.306083619594574, train/raw-loss = 0.26246559619903564, train/logprobs = tensor([[-1.0272, -7.1090],
        [-1.9288, -1.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180900275707245
Epoch 0, Step 1408: train/loss = 0.13184528052806854, train/raw-loss = 0.08781585097312927, train/logprobs = tensor([[ -0.7443, -10.6000],
        [ -2.5911,  -2.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22014713287353516
Epoch 0, Step 1409: train/loss = 0.5468080043792725, train/raw-loss = 0.5038001537322998, train/logprobs = tensor([[-0.6949, -1.4953],
        [-1.5081, -1.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2150391936302185
Epoch 0, Step 1410: train/loss = 0.3571443557739258, train/raw-loss = 0.3030596673488617, train/logprobs = tensor([[-0.7656, -5.3512],
        [-3.0368, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27042338252067566
Epoch 0, Step 1411: train/loss = 0.42484456300735474, train/raw-loss = 0.36844637989997864, train/logprobs = tensor([[-0.4850, -3.7845],
        [-1.6695, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819908559322357
Epoch 0, Step 1412: train/loss = 0.33450621366500854, train/raw-loss = 0.28471916913986206, train/logprobs = tensor([[-0.5956, -2.5683],
        [-2.8479, -1.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489352524280548
Epoch 0, Step 1413: train/loss = 0.3107971251010895, train/raw-loss = 0.2665458917617798, train/logprobs = tensor([[-0.9703, -4.2254],
        [-2.0600, -1.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212563455104828
Epoch 0, Step 1414: train/loss = 0.534103274345398, train/raw-loss = 0.4958982765674591, train/logprobs = tensor([[-0.6770, -4.1435],
        [-1.4279, -2.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191025048494339
Epoch 0, Step 1415: train/loss = 0.47487199306488037, train/raw-loss = 0.4429299235343933, train/logprobs = tensor([[-0.6961, -1.8050],
        [-1.4981, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15971045196056366
Epoch 0, Step 1416: train/loss = 0.2930822968482971, train/raw-loss = 0.2465757131576538, train/logprobs = tensor([[-1.0826, -8.9396],
        [-2.4350, -2.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23253291845321655
Epoch 0, Step 1417: train/loss = 0.22087362408638, train/raw-loss = 0.17168593406677246, train/logprobs = tensor([[-0.5949, -8.1725],
        [-1.9385, -2.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24593843519687653
Epoch 0, Step 1418: train/loss = 0.38294094800949097, train/raw-loss = 0.33778244256973267, train/logprobs = tensor([[-0.9167, -3.1393],
        [-1.9631, -1.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2257925271987915
Epoch 0, Step 1419: train/loss = 0.6021004319190979, train/raw-loss = 0.5680713653564453, train/logprobs = tensor([[-0.4756, -1.5934],
        [-1.3221, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1701451689004898
Epoch 0, Step 1420: train/loss = 0.22664698958396912, train/raw-loss = 0.18196426331996918, train/logprobs = tensor([[-0.5329, -4.3535],
        [-2.1003, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341357171535492
Epoch 0, Step 1421: train/loss = 0.5259521007537842, train/raw-loss = 0.4856308698654175, train/logprobs = tensor([[-0.6604, -2.7329],
        [-1.7369, -2.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20160585641860962
Epoch 0, Step 1422: train/loss = 0.5452728271484375, train/raw-loss = 0.5135940313339233, train/logprobs = tensor([[-0.3530, -1.3909],
        [-0.9494, -0.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839383006095886
Epoch 0, Step 1423: train/loss = 0.47038477659225464, train/raw-loss = 0.429482638835907, train/logprobs = tensor([[-0.5164, -3.3980],
        [-1.4438, -2.6442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20451071858406067
Epoch 0, Step 1424: train/loss = 0.11019215732812881, train/raw-loss = 0.04949641972780228, train/logprobs = tensor([[-0.8490, -8.7555],
        [-3.7758, -1.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034786880016327
Epoch 0, Step 1425: train/loss = 0.2957559823989868, train/raw-loss = 0.2509553134441376, train/logprobs = tensor([[-1.1292, -5.6575],
        [-2.2940, -2.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22400352358818054
Epoch 0, Step 1426: train/loss = 0.27185073494911194, train/raw-loss = 0.22225594520568848, train/logprobs = tensor([[-0.8990, -8.3467],
        [-2.8864, -3.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24797391891479492
Epoch 0, Step 1427: train/loss = 0.497111052274704, train/raw-loss = 0.44797465205192566, train/logprobs = tensor([[-0.8188, -2.4654],
        [-2.4229, -1.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24568210542201996
Epoch 0, Step 1428: train/loss = 0.27949318289756775, train/raw-loss = 0.22873583436012268, train/logprobs = tensor([[-0.8064, -6.2037],
        [-2.5203, -1.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2537866234779358
Epoch 0, Step 1429: train/loss = 0.23909325897693634, train/raw-loss = 0.1903553158044815, train/logprobs = tensor([[-0.8060, -6.6892],
        [-2.5714, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24368971586227417
Epoch 0, Step 1430: train/loss = 0.31106802821159363, train/raw-loss = 0.2668133080005646, train/logprobs = tensor([[-1.2729, -7.0496],
        [-2.8234, -3.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22127360105514526
Epoch 0, Step 1431: train/loss = 0.1675908863544464, train/raw-loss = 0.11105552315711975, train/logprobs = tensor([[ -0.9144, -12.7319],
        [ -2.9644,  -3.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2826767563819885
Epoch 0, Step 1432: train/loss = 0.7481180429458618, train/raw-loss = 0.6871215105056763, train/logprobs = tensor([[-0.5505, -5.9927],
        [-3.1956, -3.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30498257279396057
Epoch 0, Step 1433: train/loss = 0.3718237280845642, train/raw-loss = 0.32950860261917114, train/logprobs = tensor([[-0.5396, -3.6781],
        [-2.3611, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21157559752464294
Epoch 0, Step 1434: train/loss = 0.2390812337398529, train/raw-loss = 0.1814078390598297, train/logprobs = tensor([[-0.7334, -4.7298],
        [-3.1691, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883669137954712
Epoch 0, Step 1435: train/loss = 0.4009360373020172, train/raw-loss = 0.3310839533805847, train/logprobs = tensor([[-0.8934, -7.7566],
        [-3.6170, -2.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34926050901412964
Epoch 0, Step 1436: train/loss = 0.4991952180862427, train/raw-loss = 0.45355987548828125, train/logprobs = tensor([[ -2.1663, -12.2453],
        [ -2.1337,  -2.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22817674279212952
Epoch 0, Step 1437: train/loss = 0.3565906584262848, train/raw-loss = 0.31705331802368164, train/logprobs = tensor([[-0.5239, -8.7944],
        [-2.0482, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1976865828037262
Epoch 0, Step 1438: train/loss = 0.13754914700984955, train/raw-loss = 0.09429138898849487, train/logprobs = tensor([[ -1.1390, -10.4869],
        [ -3.6593,  -1.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21628881990909576
Epoch 0, Step 1439: train/loss = 0.3433711528778076, train/raw-loss = 0.3080291748046875, train/logprobs = tensor([[-0.7999, -3.7879],
        [-2.6761, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17670977115631104
Epoch 0, Step 1440: train/loss = 0.4146226644515991, train/raw-loss = 0.3653639554977417, train/logprobs = tensor([[-0.6887, -4.8077],
        [-2.4648, -1.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24629366397857666
Epoch 0, Step 1441: train/loss = 0.5797007083892822, train/raw-loss = 0.5385802388191223, train/logprobs = tensor([[-0.9951, -1.6731],
        [-1.8067, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20560222864151
Epoch 0, Step 1442: train/loss = 0.10150396823883057, train/raw-loss = 0.04622671380639076, train/logprobs = tensor([[-1.0829, -7.4860],
        [-3.9423, -1.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27638623118400574
Epoch 0, Step 1443: train/loss = 0.6614634394645691, train/raw-loss = 0.6135464310646057, train/logprobs = tensor([[-1.2314, -4.8151],
        [-1.7045, -2.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23958523571491241
Epoch 0, Step 1444: train/loss = 0.27263766527175903, train/raw-loss = 0.21152141690254211, train/logprobs = tensor([[-1.0140, -4.4252],
        [-3.8541, -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305581271648407
Epoch 0, Step 1445: train/loss = 0.5547690987586975, train/raw-loss = 0.509211540222168, train/logprobs = tensor([[-0.3814, -3.2635],
        [-1.6151, -2.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22778776288032532
Epoch 0, Step 1446: train/loss = 0.5122256278991699, train/raw-loss = 0.46048712730407715, train/logprobs = tensor([[-1.6608, -8.7419],
        [-2.4747, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2586924731731415
Epoch 0, Step 1447: train/loss = 0.31616121530532837, train/raw-loss = 0.2721460163593292, train/logprobs = tensor([[-1.2650, -4.9543],
        [-2.0407, -1.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22007593512535095
Epoch 0, Step 1448: train/loss = 0.4025876820087433, train/raw-loss = 0.3514271676540375, train/logprobs = tensor([[-1.3150, -4.6403],
        [-1.8380, -2.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558026909828186
Epoch 0, Step 1449: train/loss = 0.46753501892089844, train/raw-loss = 0.4143998324871063, train/logprobs = tensor([[-0.6517, -5.9041],
        [-2.2583, -2.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26567602157592773
Epoch 0, Step 1450: train/loss = 0.3046250641345978, train/raw-loss = 0.2506687641143799, train/logprobs = tensor([[-0.5589, -3.9945],
        [-2.0054, -1.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26978152990341187
Epoch 0, Step 1451: train/loss = 0.3104347884654999, train/raw-loss = 0.25511544942855835, train/logprobs = tensor([[-0.9150, -6.3312],
        [-3.0167, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765967547893524
Epoch 0, Step 1452: train/loss = 0.4947080612182617, train/raw-loss = 0.4383760094642639, train/logprobs = tensor([[-0.6581, -7.2204],
        [-2.8930, -2.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2816602289676666
Epoch 0, Step 1453: train/loss = 0.22518226504325867, train/raw-loss = 0.1733408272266388, train/logprobs = tensor([[-0.9319, -4.7152],
        [-2.7933, -1.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592070996761322
Epoch 0, Step 1454: train/loss = 0.32938796281814575, train/raw-loss = 0.2808527946472168, train/logprobs = tensor([[-0.9041, -4.6826],
        [-3.2667, -2.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24267597496509552
Epoch 0, Step 1455: train/loss = 0.300311803817749, train/raw-loss = 0.25130146741867065, train/logprobs = tensor([[-0.5429, -4.4283],
        [-3.8965, -3.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24505163729190826
Epoch 0, Step 1456: train/loss = 0.25696438550949097, train/raw-loss = 0.21471191942691803, train/logprobs = tensor([[-0.8919, -7.2716],
        [-2.4938, -2.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21126233041286469
Epoch 0, Step 1457: train/loss = 0.37105289101600647, train/raw-loss = 0.327150821685791, train/logprobs = tensor([[-0.8954, -4.1554],
        [-2.7338, -2.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21951019763946533
Epoch 0, Step 1458: train/loss = 0.6278493404388428, train/raw-loss = 0.5755279660224915, train/logprobs = tensor([[-0.9487, -1.4754],
        [-2.3463, -1.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616070806980133
Epoch 0, Step 1459: train/loss = 0.19129672646522522, train/raw-loss = 0.1296171396970749, train/logprobs = tensor([[-0.6802, -8.5910],
        [-3.9280, -2.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30839797854423523
Epoch 0, Step 1460: train/loss = 0.2667396664619446, train/raw-loss = 0.21722747385501862, train/logprobs = tensor([[-1.4794, -7.2150],
        [-2.9811, -1.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2475610077381134
Epoch 0, Step 1461: train/loss = 0.6100674867630005, train/raw-loss = 0.5477954149246216, train/logprobs = tensor([[-0.7775, -2.6504],
        [-3.3391, -2.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31136053800582886
Epoch 0, Step 1462: train/loss = 0.3711007833480835, train/raw-loss = 0.31378602981567383, train/logprobs = tensor([[-0.8213, -3.5009],
        [-2.8606, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865736484527588
Epoch 0, Step 1463: train/loss = 0.24280303716659546, train/raw-loss = 0.19317395985126495, train/logprobs = tensor([[-1.0609, -4.8620],
        [-3.8130, -2.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24814531207084656
Epoch 0, Step 1464: train/loss = 0.4857473373413086, train/raw-loss = 0.4322901666164398, train/logprobs = tensor([[-0.7248, -4.1962],
        [-2.4638, -1.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26728594303131104
Epoch 0, Step 1465: train/loss = 0.24915167689323425, train/raw-loss = 0.2054496705532074, train/logprobs = tensor([[-0.8973, -5.8305],
        [-3.3854, -2.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21851007640361786
Epoch 0, Step 1466: train/loss = 0.4061603248119354, train/raw-loss = 0.35578227043151855, train/logprobs = tensor([[-0.7645, -4.2015],
        [-1.9101, -2.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518903613090515
Epoch 0, Step 1467: train/loss = 0.25723159313201904, train/raw-loss = 0.21056866645812988, train/logprobs = tensor([[-0.8641, -9.1299],
        [-3.3149, -2.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23331449925899506
Epoch 0, Step 1468: train/loss = 0.4293546974658966, train/raw-loss = 0.38265013694763184, train/logprobs = tensor([[-1.4906, -7.4923],
        [-3.0657, -2.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23352277278900146
Epoch 0, Step 1469: train/loss = 0.4179401993751526, train/raw-loss = 0.37102389335632324, train/logprobs = tensor([[-0.5952, -3.9790],
        [-1.4216, -2.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2345815896987915
Epoch 0, Step 1470: train/loss = 0.19638478755950928, train/raw-loss = 0.13446363806724548, train/logprobs = tensor([[-0.8808, -4.6005],
        [-2.9799, -1.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3096056580543518
Epoch 0, Step 1471: train/loss = 0.46938595175743103, train/raw-loss = 0.414484441280365, train/logprobs = tensor([[-0.5971, -2.6464],
        [-2.3755, -2.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27450764179229736
Epoch 0, Step 1472: train/loss = 0.3372874855995178, train/raw-loss = 0.30329492688179016, train/logprobs = tensor([[-0.6587, -7.9076],
        [-1.4192, -1.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16996274888515472
Epoch 0, Step 1473: train/loss = 0.2656495273113251, train/raw-loss = 0.21077977120876312, train/logprobs = tensor([[-0.8974, -4.6155],
        [-2.7503, -1.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743487060070038
Epoch 0, Step 1474: train/loss = 0.3587305545806885, train/raw-loss = 0.309426486492157, train/logprobs = tensor([[-1.0089, -4.1952],
        [-2.3075, -2.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24652042984962463
Epoch 0, Step 1475: train/loss = 0.3820008337497711, train/raw-loss = 0.33937013149261475, train/logprobs = tensor([[-0.8134, -2.5549],
        [-2.4065, -1.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21315360069274902
Epoch 0, Step 1476: train/loss = 0.47861358523368835, train/raw-loss = 0.42604711651802063, train/logprobs = tensor([[-1.3674, -4.0637],
        [-2.7642, -3.4803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262832373380661
Epoch 0, Step 1477: train/loss = 0.17737609148025513, train/raw-loss = 0.12641701102256775, train/logprobs = tensor([[-1.3857, -6.4213],
        [-3.3161, -1.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547954320907593
Epoch 0, Step 1478: train/loss = 0.6349188685417175, train/raw-loss = 0.5788953304290771, train/logprobs = tensor([[-0.5749, -1.1921],
        [-2.4332, -1.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801177501678467
Epoch 0, Step 1479: train/loss = 0.5207539200782776, train/raw-loss = 0.45586585998535156, train/logprobs = tensor([[-0.6908, -3.0315],
        [-2.6580, -2.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32444021105766296
Epoch 0, Step 1480: train/loss = 0.47289955615997314, train/raw-loss = 0.4181271493434906, train/logprobs = tensor([[-0.8718, -4.6444],
        [-4.0069, -2.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27386194467544556
Epoch 0, Step 1481: train/loss = 0.3649613857269287, train/raw-loss = 0.3180191218852997, train/logprobs = tensor([[-0.9143, -5.0070],
        [-2.4714, -1.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347111999988556
Epoch 0, Step 1482: train/loss = 0.3405263423919678, train/raw-loss = 0.29014670848846436, train/logprobs = tensor([[-0.8074, -6.7113],
        [-2.5230, -2.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518981099128723
Epoch 0, Step 1483: train/loss = 0.31716734170913696, train/raw-loss = 0.26987719535827637, train/logprobs = tensor([[-0.8525, -4.0465],
        [-3.3635, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23645079135894775
Epoch 0, Step 1484: train/loss = 0.1964297741651535, train/raw-loss = 0.144419863820076, train/logprobs = tensor([[-0.5550, -5.6140],
        [-2.7212, -1.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600494921207428
Epoch 0, Step 1485: train/loss = 0.47619619965553284, train/raw-loss = 0.43424537777900696, train/logprobs = tensor([[-0.9421, -3.0055],
        [-1.5036, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20975399017333984
Epoch 0, Step 1486: train/loss = 0.5830314755439758, train/raw-loss = 0.529715359210968, train/logprobs = tensor([[-1.1658, -2.5338],
        [-1.9190, -2.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665807008743286
Epoch 0, Step 1487: train/loss = 0.2427166998386383, train/raw-loss = 0.19914306700229645, train/logprobs = tensor([[-1.6099, -5.6700],
        [-3.0386, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21786823868751526
Epoch 0, Step 1488: train/loss = 0.5353016257286072, train/raw-loss = 0.48320066928863525, train/logprobs = tensor([[-0.4502, -1.8884],
        [-1.9818, -1.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605048418045044
Epoch 0, Step 1489: train/loss = 0.4367944598197937, train/raw-loss = 0.3976702094078064, train/logprobs = tensor([[-0.9711, -3.6386],
        [-1.9259, -1.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19562122225761414
Epoch 0, Step 1490: train/loss = 0.42104071378707886, train/raw-loss = 0.37960517406463623, train/logprobs = tensor([[-0.5561, -3.2692],
        [-1.9988, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20717769861221313
Epoch 0, Step 1491: train/loss = 0.243232861161232, train/raw-loss = 0.187322199344635, train/logprobs = tensor([[-1.2868, -6.6513],
        [-3.3058, -2.0476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27955329418182373
Epoch 0, Step 1492: train/loss = 0.4043238162994385, train/raw-loss = 0.35493239760398865, train/logprobs = tensor([[-0.7987, -3.7064],
        [-2.5495, -2.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2469572126865387
Epoch 0, Step 1493: train/loss = 0.32495948672294617, train/raw-loss = 0.2735777497291565, train/logprobs = tensor([[-0.7663, -3.5390],
        [-3.2416, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2569085955619812
Epoch 0, Step 1494: train/loss = 0.17148247361183167, train/raw-loss = 0.10181183367967606, train/logprobs = tensor([[-0.6629, -5.5610],
        [-3.4497, -1.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3483531177043915
Epoch 0, Step 1495: train/loss = 0.24203899502754211, train/raw-loss = 0.17974402010440826, train/logprobs = tensor([[-0.5994, -7.4555],
        [-2.9682, -2.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3114749491214752
Epoch 0, Step 1496: train/loss = 0.25631749629974365, train/raw-loss = 0.21147343516349792, train/logprobs = tensor([[-0.8811, -6.0932],
        [-2.1414, -1.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22422033548355103
Epoch 0, Step 1497: train/loss = 0.3617215156555176, train/raw-loss = 0.32295048236846924, train/logprobs = tensor([[-0.6779, -3.4389],
        [-2.1030, -1.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19385533034801483
Epoch 0, Step 1498: train/loss = 0.2837345004081726, train/raw-loss = 0.2318148910999298, train/logprobs = tensor([[-0.7502, -3.5298],
        [-3.5008, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25959810614585876
Epoch 0, Step 1499: train/loss = 0.3830348253250122, train/raw-loss = 0.33802011609077454, train/logprobs = tensor([[-1.4679, -3.4234],
        [-2.7762, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22507359087467194
Epoch 0, Step 1500: train/loss = 0.4986797571182251, train/raw-loss = 0.4734812378883362, train/logprobs = tensor([[-0.3432, -3.6658],
        [-0.6624, -1.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12599265575408936
Epoch 0, Step 1501: train/loss = 0.24970564246177673, train/raw-loss = 0.18322187662124634, train/logprobs = tensor([[-0.5566, -5.4868],
        [-4.1486, -2.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.332418829202652
Epoch 0, Step 1502: train/loss = 0.11483134329319, train/raw-loss = 0.05112111568450928, train/logprobs = tensor([[-1.0814, -7.3317],
        [-3.5708, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31855112314224243
Epoch 0, Step 1503: train/loss = 0.4407098591327667, train/raw-loss = 0.3866487741470337, train/logprobs = tensor([[-1.0744, -3.3934],
        [-3.3683, -1.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27030542492866516
Epoch 0, Step 1504: train/loss = 0.3159905672073364, train/raw-loss = 0.26978787779808044, train/logprobs = tensor([[-0.6792, -5.0048],
        [-2.1357, -1.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2310134470462799
Epoch 0, Step 1505: train/loss = 0.24676871299743652, train/raw-loss = 0.19997772574424744, train/logprobs = tensor([[-0.8554, -5.6992],
        [-2.8283, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339549958705902
Epoch 0, Step 1506: train/loss = 0.17464576661586761, train/raw-loss = 0.12547723948955536, train/logprobs = tensor([[-0.7345, -4.4096],
        [-3.2982, -1.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24584263563156128
Epoch 0, Step 1507: train/loss = 0.380043089389801, train/raw-loss = 0.32275986671447754, train/logprobs = tensor([[-0.5773, -3.2389],
        [-2.0467, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2864162027835846
Epoch 0, Step 1508: train/loss = 0.4348488748073578, train/raw-loss = 0.38299089670181274, train/logprobs = tensor([[-1.1410, -4.0708],
        [-2.3264, -1.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25928980112075806
Epoch 0, Step 1509: train/loss = 0.4885205030441284, train/raw-loss = 0.4442770779132843, train/logprobs = tensor([[-0.8842, -2.5125],
        [-2.3358, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22121727466583252
Epoch 0, Step 1510: train/loss = 0.44609788060188293, train/raw-loss = 0.3899814188480377, train/logprobs = tensor([[-0.6164, -5.8892],
        [-1.9882, -2.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805822193622589
Epoch 0, Step 1511: train/loss = 0.15977030992507935, train/raw-loss = 0.11493409425020218, train/logprobs = tensor([[-1.2180, -6.5987],
        [-2.8596, -1.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22418101131916046
Epoch 0, Step 1512: train/loss = 0.39750444889068604, train/raw-loss = 0.34748414158821106, train/logprobs = tensor([[-0.7349, -3.2373],
        [-2.1762, -1.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25010156631469727
Epoch 0, Step 1513: train/loss = 0.277553915977478, train/raw-loss = 0.2264590710401535, train/logprobs = tensor([[-0.5952, -4.9888],
        [-2.5559, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2554740905761719
Epoch 0, Step 1514: train/loss = 0.40999293327331543, train/raw-loss = 0.3633277416229248, train/logprobs = tensor([[-1.5543, -7.1175],
        [-2.5979, -2.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333258092403412
Epoch 0, Step 1515: train/loss = 0.3028392493724823, train/raw-loss = 0.2518041133880615, train/logprobs = tensor([[-0.7598, -4.6941],
        [-3.4135, -1.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25517573952674866
Epoch 0, Step 1516: train/loss = 0.6441705822944641, train/raw-loss = 0.6115342378616333, train/logprobs = tensor([[-0.7278, -0.8457],
        [-1.7790, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16318175196647644
Epoch 0, Step 1517: train/loss = 0.16104517877101898, train/raw-loss = 0.1157115250825882, train/logprobs = tensor([[ -1.0025, -11.1953],
        [ -3.6350,  -3.5205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22666823863983154
Epoch 0, Step 1518: train/loss = 0.4910416305065155, train/raw-loss = 0.4530518651008606, train/logprobs = tensor([[-1.9695, -4.4591],
        [-2.0627, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18994878232479095
Epoch 0, Step 1519: train/loss = 0.5432949662208557, train/raw-loss = 0.49714013934135437, train/logprobs = tensor([[-0.7822, -2.6173],
        [-1.9641, -1.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23077411949634552
Epoch 0, Step 1520: train/loss = 0.17355337738990784, train/raw-loss = 0.11515204608440399, train/logprobs = tensor([[-0.7411, -7.7430],
        [-3.7347, -2.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920066714286804
Epoch 0, Step 1521: train/loss = 0.43061959743499756, train/raw-loss = 0.3912178874015808, train/logprobs = tensor([[-1.9941, -2.4043],
        [-3.0895, -1.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19700855016708374
Epoch 0, Step 1522: train/loss = 0.436232328414917, train/raw-loss = 0.4000524878501892, train/logprobs = tensor([[ -2.1131, -10.3463],
        [ -2.8955,  -2.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18089942634105682
Epoch 0, Step 1523: train/loss = 0.1258659064769745, train/raw-loss = 0.08123750984668732, train/logprobs = tensor([[-0.9683, -5.9620],
        [-4.1254, -2.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22314190864562988
Epoch 0, Step 1524: train/loss = 0.3276868760585785, train/raw-loss = 0.27439314126968384, train/logprobs = tensor([[-0.9314, -3.4980],
        [-2.9289, -1.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26646870374679565
Epoch 0, Step 1525: train/loss = 0.7492688894271851, train/raw-loss = 0.6969789266586304, train/logprobs = tensor([[-0.7223, -0.8418],
        [-2.0103, -1.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614498734474182
Epoch 0, Step 1526: train/loss = 0.4427086114883423, train/raw-loss = 0.4042339324951172, train/logprobs = tensor([[-0.6358, -3.0355],
        [-1.8496, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1923733800649643
Epoch 0, Step 1527: train/loss = 0.41437533497810364, train/raw-loss = 0.35609370470046997, train/logprobs = tensor([[-1.5113, -2.8515],
        [-2.5319, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914082109928131
Epoch 0, Step 1528: train/loss = 0.18645787239074707, train/raw-loss = 0.13621200621128082, train/logprobs = tensor([[-0.5161, -5.3912],
        [-3.0691, -2.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512294054031372
Epoch 0, Step 1529: train/loss = 0.42459654808044434, train/raw-loss = 0.3737789988517761, train/logprobs = tensor([[-0.8453, -3.7427],
        [-2.9604, -1.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540878653526306
Epoch 0, Step 1530: train/loss = 0.25279757380485535, train/raw-loss = 0.1953488290309906, train/logprobs = tensor([[-0.8648, -5.2973],
        [-3.6765, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28724366426467896
Epoch 0, Step 1531: train/loss = 0.4211083650588989, train/raw-loss = 0.3711634874343872, train/logprobs = tensor([[-0.7071, -4.8921],
        [-2.5511, -1.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24972441792488098
Epoch 0, Step 1532: train/loss = 0.5012247562408447, train/raw-loss = 0.45207884907722473, train/logprobs = tensor([[-0.9005, -3.9187],
        [-1.6041, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24572929739952087
Epoch 0, Step 1533: train/loss = 0.30046790838241577, train/raw-loss = 0.264378160238266, train/logprobs = tensor([[-0.4065, -3.6992],
        [-1.8833, -1.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18044860661029816
Epoch 0, Step 1534: train/loss = 0.33829277753829956, train/raw-loss = 0.28816545009613037, train/logprobs = tensor([[-1.8095, -6.7049],
        [-2.7846, -2.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506365478038788
Epoch 0, Step 1535: train/loss = 0.4430432617664337, train/raw-loss = 0.386481910943985, train/logprobs = tensor([[-0.7695, -2.8377],
        [-2.6671, -2.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28280651569366455
Epoch 0, Step 1536: train/loss = 0.3438464105129242, train/raw-loss = 0.30340826511383057, train/logprobs = tensor([[-0.6097, -5.6590],
        [-1.8333, -1.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20219087600708008
Epoch 0, Step 1537: train/loss = 0.36180099844932556, train/raw-loss = 0.31235459446907043, train/logprobs = tensor([[-1.5925, -3.7199],
        [-2.1826, -1.2804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24723199009895325
Epoch 0, Step 1538: train/loss = 0.3266340494155884, train/raw-loss = 0.2817791700363159, train/logprobs = tensor([[-0.6389, -5.1572],
        [-2.5116, -2.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22427433729171753
Epoch 0, Step 1539: train/loss = 0.4814387261867523, train/raw-loss = 0.4277206063270569, train/logprobs = tensor([[-0.7708, -2.7455],
        [-1.9143, -2.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2685905694961548
Epoch 0, Step 1540: train/loss = 0.2986246347427368, train/raw-loss = 0.2493589073419571, train/logprobs = tensor([[-1.3150, -5.2169],
        [-3.0639, -1.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24632856249809265
Epoch 0, Step 1541: train/loss = 0.1568281650543213, train/raw-loss = 0.10596523433923721, train/logprobs = tensor([[-0.8256, -9.8742],
        [-3.1065, -2.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254314661026001
Epoch 0, Step 1542: train/loss = 0.6487983465194702, train/raw-loss = 0.6128039360046387, train/logprobs = tensor([[-0.9349, -0.9485],
        [-1.2375, -0.8616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17997173964977264
Epoch 0, Step 1543: train/loss = 0.4599512815475464, train/raw-loss = 0.40899425745010376, train/logprobs = tensor([[-0.6710, -2.6185],
        [-3.1550, -1.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25478506088256836
Epoch 0, Step 1544: train/loss = 0.3545924425125122, train/raw-loss = 0.29805538058280945, train/logprobs = tensor([[-0.8897, -5.8850],
        [-4.3343, -2.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28268522024154663
Epoch 0, Step 1545: train/loss = 0.34026068449020386, train/raw-loss = 0.2878495454788208, train/logprobs = tensor([[-1.1085, -3.7766],
        [-2.8161, -1.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26205575466156006
Epoch 0, Step 1546: train/loss = 0.4736648499965668, train/raw-loss = 0.42254167795181274, train/logprobs = tensor([[-0.7597, -2.9740],
        [-2.4886, -1.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556156516075134
Epoch 0, Step 1547: train/loss = 0.4450158476829529, train/raw-loss = 0.4016277492046356, train/logprobs = tensor([[-0.7308, -2.8700],
        [-2.1853, -1.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21694061160087585
Epoch 0, Step 1548: train/loss = 0.41645368933677673, train/raw-loss = 0.37398311495780945, train/logprobs = tensor([[-0.5485, -4.8313],
        [-1.6008, -2.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21235261857509613
Epoch 0, Step 1549: train/loss = 0.4908474385738373, train/raw-loss = 0.44595032930374146, train/logprobs = tensor([[-0.5598, -3.0650],
        [-2.1306, -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22448542714118958
Epoch 0, Step 1550: train/loss = 0.5476321578025818, train/raw-loss = 0.502491295337677, train/logprobs = tensor([[-0.8870, -2.0782],
        [-2.1583, -1.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22570443153381348
Epoch 0, Step 1551: train/loss = 0.21473205089569092, train/raw-loss = 0.15917061269283295, train/logprobs = tensor([[-0.7340, -5.6612],
        [-2.6171, -2.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27780723571777344
Epoch 0, Step 1552: train/loss = 0.3227214217185974, train/raw-loss = 0.272298127412796, train/logprobs = tensor([[ -0.9515, -10.7193],
        [ -2.7222,  -3.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25211647152900696
Epoch 0, Step 1553: train/loss = 0.3017675280570984, train/raw-loss = 0.24953481554985046, train/logprobs = tensor([[-1.0588, -4.9675],
        [-2.3976, -1.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611634433269501
Epoch 0, Step 1554: train/loss = 0.4834202527999878, train/raw-loss = 0.4363742768764496, train/logprobs = tensor([[-1.0000, -2.9212],
        [-2.1061, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23522977530956268
Epoch 0, Step 1555: train/loss = 0.2810443639755249, train/raw-loss = 0.2328999936580658, train/logprobs = tensor([[-1.3486, -4.5022],
        [-3.0906, -1.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24072179198265076
Epoch 0, Step 1556: train/loss = 0.36632096767425537, train/raw-loss = 0.32185325026512146, train/logprobs = tensor([[-0.5635, -8.0768],
        [-1.8079, -2.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2223384976387024
Epoch 0, Step 1557: train/loss = 0.3318069279193878, train/raw-loss = 0.2902206480503082, train/logprobs = tensor([[-0.7819, -6.7566],
        [-1.7560, -2.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20793136954307556
Epoch 0, Step 1558: train/loss = 0.2456689476966858, train/raw-loss = 0.19480136036872864, train/logprobs = tensor([[-0.7305, -8.8430],
        [-2.9656, -2.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254337877035141
Epoch 0, Step 1559: train/loss = 0.3944528102874756, train/raw-loss = 0.3464457094669342, train/logprobs = tensor([[-1.6130, -3.8702],
        [-3.6067, -1.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2400355339050293
Epoch 0, Step 1560: train/loss = 0.17972292006015778, train/raw-loss = 0.13491301238536835, train/logprobs = tensor([[-0.8971, -6.4649],
        [-2.4499, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22404959797859192
Epoch 0, Step 1561: train/loss = 0.23040148615837097, train/raw-loss = 0.1644166111946106, train/logprobs = tensor([[-1.2445, -5.3190],
        [-4.6961, -2.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3299243450164795
Epoch 0, Step 1562: train/loss = 0.4761310815811157, train/raw-loss = 0.422355592250824, train/logprobs = tensor([[-3.0883, -8.8739],
        [-3.1744, -1.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26887738704681396
Epoch 0, Step 1563: train/loss = 0.6133107542991638, train/raw-loss = 0.557692289352417, train/logprobs = tensor([[-0.9799, -1.7849],
        [-2.2835, -2.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780926525592804
Epoch 0, Step 1564: train/loss = 0.31034329533576965, train/raw-loss = 0.2649436593055725, train/logprobs = tensor([[-0.8648, -4.8021],
        [-3.4819, -2.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22699812054634094
Epoch 0, Step 1565: train/loss = 0.5221878290176392, train/raw-loss = 0.47673237323760986, train/logprobs = tensor([[-1.2144, -2.0453],
        [-2.4129, -1.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22727739810943604
Epoch 0, Step 1566: train/loss = 0.25157424807548523, train/raw-loss = 0.19168555736541748, train/logprobs = tensor([[-0.7172, -6.4160],
        [-3.3428, -2.7132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29944342374801636
Epoch 0, Step 1567: train/loss = 0.5659340023994446, train/raw-loss = 0.52345871925354, train/logprobs = tensor([[-0.5548, -3.2998],
        [-1.6954, -1.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2123764455318451
Epoch 0, Step 1568: train/loss = 0.4235606789588928, train/raw-loss = 0.3711971640586853, train/logprobs = tensor([[-2.0720, -8.8242],
        [-2.8595, -1.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618175148963928
Epoch 0, Step 1569: train/loss = 0.4403281807899475, train/raw-loss = 0.3861212134361267, train/logprobs = tensor([[-1.6821, -4.0379],
        [-2.2763, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27103492617607117
Epoch 0, Step 1570: train/loss = 0.3911345899105072, train/raw-loss = 0.3457951843738556, train/logprobs = tensor([[-1.0608, -3.8958],
        [-2.0603, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22669708728790283
Epoch 0, Step 1571: train/loss = 0.3762945532798767, train/raw-loss = 0.327382355928421, train/logprobs = tensor([[-0.8298, -2.7221],
        [-2.2612, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24456101655960083
Epoch 0, Step 1572: train/loss = 0.24610881507396698, train/raw-loss = 0.1905219852924347, train/logprobs = tensor([[-0.8515, -5.2813],
        [-2.8353, -0.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27793410420417786
Epoch 0, Step 1573: train/loss = 0.20578402280807495, train/raw-loss = 0.16544434428215027, train/logprobs = tensor([[-1.0215, -6.0766],
        [-3.5477, -1.2645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20169848203659058
Epoch 0, Step 1574: train/loss = 0.3108534812927246, train/raw-loss = 0.25722429156303406, train/logprobs = tensor([[-0.6901, -5.5549],
        [-3.2767, -2.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268145889043808
Epoch 0, Step 1575: train/loss = 0.33048054575920105, train/raw-loss = 0.28305500745773315, train/logprobs = tensor([[-1.0891, -4.3979],
        [-2.9735, -1.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23712781071662903
Epoch 0, Step 1576: train/loss = 0.7434130907058716, train/raw-loss = 0.7058882713317871, train/logprobs = tensor([[-0.5716, -0.7931],
        [-0.9232, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18762388825416565
Epoch 0, Step 1577: train/loss = 0.5037427544593811, train/raw-loss = 0.44709351658821106, train/logprobs = tensor([[-0.7873, -1.9241],
        [-2.4218, -1.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.283246248960495
Epoch 0, Step 1578: train/loss = 0.2693415880203247, train/raw-loss = 0.2334129512310028, train/logprobs = tensor([[-1.5863, -9.5790],
        [-2.3399, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17964313924312592
Epoch 0, Step 1579: train/loss = 0.40255123376846313, train/raw-loss = 0.3510356545448303, train/logprobs = tensor([[-0.6046, -5.3063],
        [-2.6303, -2.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575778365135193
Epoch 0, Step 1580: train/loss = 0.30300143361091614, train/raw-loss = 0.25341811776161194, train/logprobs = tensor([[-0.5341, -3.2869],
        [-2.2585, -1.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24791651964187622
Epoch 0, Step 1581: train/loss = 0.14547276496887207, train/raw-loss = 0.08908198028802872, train/logprobs = tensor([[-1.1432, -4.2555],
        [-4.1475, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281953901052475
Epoch 0, Step 1582: train/loss = 0.15828469395637512, train/raw-loss = 0.11482646316289902, train/logprobs = tensor([[-1.2237, -8.0599],
        [-3.4558, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21729111671447754
Epoch 0, Step 1583: train/loss = 0.43076619505882263, train/raw-loss = 0.376661479473114, train/logprobs = tensor([[-0.9152, -6.7260],
        [-4.4039, -2.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705236077308655
Epoch 0, Step 1584: train/loss = 0.1954323649406433, train/raw-loss = 0.14695939421653748, train/logprobs = tensor([[-1.2420, -7.1284],
        [-2.7771, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24236488342285156
Epoch 0, Step 1585: train/loss = 0.19961997866630554, train/raw-loss = 0.1312304139137268, train/logprobs = tensor([[-1.1517, -4.7271],
        [-3.1683, -1.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34194791316986084
Epoch 0, Step 1586: train/loss = 0.32947754859924316, train/raw-loss = 0.27522313594818115, train/logprobs = tensor([[-0.9257, -6.7092],
        [-2.7822, -1.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27127212285995483
Epoch 0, Step 1587: train/loss = 0.12382568418979645, train/raw-loss = 0.06633547693490982, train/logprobs = tensor([[-0.9420, -5.4268],
        [-3.4070, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28745099902153015
Epoch 0, Step 1588: train/loss = 0.28281262516975403, train/raw-loss = 0.24663236737251282, train/logprobs = tensor([[-0.6068, -4.7499],
        [-1.9274, -1.1928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18090122938156128
Epoch 0, Step 1589: train/loss = 0.3566863536834717, train/raw-loss = 0.31193801760673523, train/logprobs = tensor([[-0.8708, -6.0655],
        [-2.3649, -1.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.223741814494133
Epoch 0, Step 1590: train/loss = 0.3641514480113983, train/raw-loss = 0.32688575983047485, train/logprobs = tensor([[-0.7593, -6.3261],
        [-1.2299, -1.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863284409046173
Epoch 0, Step 1591: train/loss = 0.33321937918663025, train/raw-loss = 0.28061312437057495, train/logprobs = tensor([[-0.7837, -6.3693],
        [-3.0497, -4.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2630311846733093
Epoch 0, Step 1592: train/loss = 0.3192595839500427, train/raw-loss = 0.26104825735092163, train/logprobs = tensor([[-0.9554, -4.0983],
        [-2.2571, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2910567820072174
Epoch 0, Step 1593: train/loss = 0.2815645635128021, train/raw-loss = 0.23101723194122314, train/logprobs = tensor([[-1.0230, -6.8172],
        [-2.5884, -1.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527367174625397
Epoch 0, Step 1594: train/loss = 0.24015745520591736, train/raw-loss = 0.18148083984851837, train/logprobs = tensor([[-0.8396, -4.8294],
        [-3.0944, -1.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29338309168815613
Epoch 0, Step 1595: train/loss = 0.2617836892604828, train/raw-loss = 0.2112201750278473, train/logprobs = tensor([[-0.7890, -4.1044],
        [-2.3045, -2.1560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2528176009654999
Epoch 0, Step 1596: train/loss = 0.28625115752220154, train/raw-loss = 0.22505156695842743, train/logprobs = tensor([[-0.7924, -7.6522],
        [-3.5800, -2.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059978783130646
Epoch 0, Step 1597: train/loss = 0.21812893450260162, train/raw-loss = 0.1723238229751587, train/logprobs = tensor([[-1.1641, -6.4811],
        [-3.5389, -2.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22902557253837585
Epoch 0, Step 1598: train/loss = 0.3138769567012787, train/raw-loss = 0.2732381820678711, train/logprobs = tensor([[-1.1965, -6.9657],
        [-2.2950, -1.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20319390296936035
Epoch 0, Step 1599: train/loss = 0.13520434498786926, train/raw-loss = 0.07265621423721313, train/logprobs = tensor([[-0.7573, -8.9521],
        [-3.4270, -2.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31274062395095825
Epoch 0, Step 1600: train/loss = 0.29858067631721497, train/raw-loss = 0.24953407049179077, train/logprobs = tensor([[-1.5566, -7.1117],
        [-2.8443, -2.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24523308873176575
Epoch 0, Step 1601: train/loss = 0.1180039793252945, train/raw-loss = 0.0691116452217102, train/logprobs = tensor([[ -0.6886, -11.0618],
        [ -2.8756,  -3.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24446167051792145
Epoch 0, Step 1602: train/loss = 0.2209874838590622, train/raw-loss = 0.16606435179710388, train/logprobs = tensor([[-0.6096, -5.3591],
        [-2.3708, -2.1964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746155858039856
Epoch 0, Step 1603: train/loss = 0.5007338523864746, train/raw-loss = 0.4577735662460327, train/logprobs = tensor([[-0.5783, -3.2852],
        [-1.9882, -2.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21480144560337067
Epoch 0, Step 1604: train/loss = 0.22918502986431122, train/raw-loss = 0.18702152371406555, train/logprobs = tensor([[-0.6230, -6.7935],
        [-1.9918, -3.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21081747114658356
Epoch 0, Step 1605: train/loss = 0.4231194257736206, train/raw-loss = 0.37852829694747925, train/logprobs = tensor([[-1.0501, -4.4417],
        [-2.0489, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22295573353767395
Epoch 0, Step 1606: train/loss = 0.17457860708236694, train/raw-loss = 0.13157466053962708, train/logprobs = tensor([[-0.7437, -7.6642],
        [-2.6505, -2.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21501967310905457
Epoch 0, Step 1607: train/loss = 0.28811728954315186, train/raw-loss = 0.2367253452539444, train/logprobs = tensor([[-1.0310, -3.9073],
        [-2.1608, -1.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25695961713790894
Epoch 0, Step 1608: train/loss = 0.37467724084854126, train/raw-loss = 0.32127636671066284, train/logprobs = tensor([[-1.0970, -8.5496],
        [-2.6106, -3.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26700419187545776
Epoch 0, Step 1609: train/loss = 0.40734338760375977, train/raw-loss = 0.360213965177536, train/logprobs = tensor([[-1.2612, -6.8781],
        [-2.0845, -2.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235647052526474
Epoch 0, Step 1610: train/loss = 0.555493175983429, train/raw-loss = 0.505693793296814, train/logprobs = tensor([[-1.5388, -4.3738],
        [-1.7824, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24899700284004211
Epoch 0, Step 1611: train/loss = 0.3515521287918091, train/raw-loss = 0.3041155934333801, train/logprobs = tensor([[-1.0678, -2.6309],
        [-3.1097, -1.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23718294501304626
Epoch 0, Step 1612: train/loss = 0.23942415416240692, train/raw-loss = 0.18448913097381592, train/logprobs = tensor([[-1.0163, -7.5407],
        [-3.3092, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746751606464386
Epoch 0, Step 1613: train/loss = 0.6111246347427368, train/raw-loss = 0.5608271956443787, train/logprobs = tensor([[-0.7138, -1.6433],
        [-1.7148, -1.3187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514874041080475
Epoch 0, Step 1614: train/loss = 0.24049440026283264, train/raw-loss = 0.19086313247680664, train/logprobs = tensor([[-1.9455, -7.5701],
        [-3.5538, -2.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24815639853477478
Epoch 0, Step 1615: train/loss = 0.361747682094574, train/raw-loss = 0.3204146921634674, train/logprobs = tensor([[-0.6889, -7.2901],
        [-1.8098, -2.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20666487514972687
Epoch 0, Step 1616: train/loss = 0.406296968460083, train/raw-loss = 0.35800519585609436, train/logprobs = tensor([[-0.7477, -5.1527],
        [-3.2392, -2.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24145886301994324
Epoch 0, Step 1617: train/loss = 0.400784969329834, train/raw-loss = 0.36337220668792725, train/logprobs = tensor([[-0.7244, -3.9772],
        [-1.9401, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18706366419792175
Epoch 0, Step 1618: train/loss = 0.47012028098106384, train/raw-loss = 0.4259617328643799, train/logprobs = tensor([[-0.6978, -2.5086],
        [-2.0153, -1.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22079268097877502
Epoch 0, Step 1619: train/loss = 0.22646328806877136, train/raw-loss = 0.1847444772720337, train/logprobs = tensor([[-0.8259, -6.5701],
        [-2.0540, -1.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2085939645767212
Epoch 0, Step 1620: train/loss = 0.3133922219276428, train/raw-loss = 0.26168784499168396, train/logprobs = tensor([[-0.8332, -4.4121],
        [-2.4913, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585219740867615
Epoch 0, Step 1621: train/loss = 0.31878745555877686, train/raw-loss = 0.26861217617988586, train/logprobs = tensor([[-1.0713, -4.3462],
        [-2.7163, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25087636709213257
Epoch 0, Step 1622: train/loss = 0.2054184377193451, train/raw-loss = 0.157653346657753, train/logprobs = tensor([[-1.3372, -6.8661],
        [-3.0063, -1.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23882541060447693
Epoch 0, Step 1623: train/loss = 0.4586353003978729, train/raw-loss = 0.414679616689682, train/logprobs = tensor([[-0.5744, -3.2444],
        [-1.9480, -1.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21977834403514862
Epoch 0, Step 1624: train/loss = 0.18629924952983856, train/raw-loss = 0.14364056289196014, train/logprobs = tensor([[-0.8159, -3.7483],
        [-2.7307, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21329353749752045
Epoch 0, Step 1625: train/loss = 0.22171273827552795, train/raw-loss = 0.16532358527183533, train/logprobs = tensor([[-0.9348, -6.2392],
        [-2.9968, -1.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819457948207855
Epoch 0, Step 1626: train/loss = 0.41122370958328247, train/raw-loss = 0.3735363185405731, train/logprobs = tensor([[-1.4334, -2.3873],
        [-2.6155, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18843698501586914
Epoch 0, Step 1627: train/loss = 0.3732106685638428, train/raw-loss = 0.32674866914749146, train/logprobs = tensor([[-1.5981, -4.2739],
        [-2.7679, -1.5609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23231004178524017
Epoch 0, Step 1628: train/loss = 0.2594349980354309, train/raw-loss = 0.22161665558815002, train/logprobs = tensor([[-0.8379, -7.2947],
        [-1.6296, -1.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1890917420387268
Epoch 0, Step 1629: train/loss = 0.42242997884750366, train/raw-loss = 0.37997663021087646, train/logprobs = tensor([[-1.0080, -4.3146],
        [-1.9217, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21226680278778076
Epoch 0, Step 1630: train/loss = 0.4524330794811249, train/raw-loss = 0.401878297328949, train/logprobs = tensor([[-0.8172, -2.2786],
        [-2.7885, -1.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527739703655243
Epoch 0, Step 1631: train/loss = 0.14340463280677795, train/raw-loss = 0.09867837280035019, train/logprobs = tensor([[-0.5965, -8.8016],
        [-2.2010, -1.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22363126277923584
Epoch 0, Step 1632: train/loss = 0.3059366047382355, train/raw-loss = 0.25304844975471497, train/logprobs = tensor([[-0.9004, -6.8861],
        [-2.4771, -1.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644408643245697
Epoch 0, Step 1633: train/loss = 0.3023757040500641, train/raw-loss = 0.2634434998035431, train/logprobs = tensor([[-1.0831, -5.9464],
        [-3.2933, -1.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19466093182563782
Epoch 0, Step 1634: train/loss = 0.46244001388549805, train/raw-loss = 0.3999949097633362, train/logprobs = tensor([[-1.3080, -3.6500],
        [-3.0079, -2.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3122255802154541
Epoch 0, Step 1635: train/loss = 0.32347211241722107, train/raw-loss = 0.2623128592967987, train/logprobs = tensor([[-0.6786, -7.4214],
        [-3.8116, -2.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30579617619514465
Epoch 0, Step 1636: train/loss = 0.2519574463367462, train/raw-loss = 0.19159716367721558, train/logprobs = tensor([[-0.6117, -6.0656],
        [-2.5283, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3018013536930084
Epoch 0, Step 1637: train/loss = 0.3232998251914978, train/raw-loss = 0.2756361663341522, train/logprobs = tensor([[-0.9252, -6.7107],
        [-3.3883, -2.7475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2383183091878891
Epoch 0, Step 1638: train/loss = 0.27154746651649475, train/raw-loss = 0.22275301814079285, train/logprobs = tensor([[-0.8836, -6.3195],
        [-3.0823, -2.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24397225677967072
Epoch 0, Step 1639: train/loss = 0.42699170112609863, train/raw-loss = 0.3886728882789612, train/logprobs = tensor([[-1.1158, -7.0738],
        [-1.4292, -1.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19159412384033203
Epoch 0, Step 1640: train/loss = 0.29272520542144775, train/raw-loss = 0.24357390403747559, train/logprobs = tensor([[-0.7337, -7.2478],
        [-2.1771, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24575664103031158
Epoch 0, Step 1641: train/loss = 0.28724566102027893, train/raw-loss = 0.25082308053970337, train/logprobs = tensor([[-0.3771, -6.0347],
        [-2.3805, -2.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18211282789707184
Epoch 0, Step 1642: train/loss = 0.2630452513694763, train/raw-loss = 0.2132377326488495, train/logprobs = tensor([[-0.8080, -6.1781],
        [-3.3874, -3.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24903762340545654
Epoch 0, Step 1643: train/loss = 0.3381088078022003, train/raw-loss = 0.297029972076416, train/logprobs = tensor([[-1.3966, -7.3206],
        [-3.0256, -1.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20539429783821106
Epoch 0, Step 1644: train/loss = 0.35453271865844727, train/raw-loss = 0.3010829985141754, train/logprobs = tensor([[-1.3361, -5.6180],
        [-2.8140, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2672484517097473
Epoch 0, Step 1645: train/loss = 0.15804846584796906, train/raw-loss = 0.11060268431901932, train/logprobs = tensor([[ -0.8730, -10.8562],
        [ -3.0966,  -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23722891509532928
Epoch 0, Step 1646: train/loss = 0.5423483848571777, train/raw-loss = 0.49349522590637207, train/logprobs = tensor([[-1.2261, -2.8166],
        [-1.9657, -1.2684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24426598846912384
Epoch 0, Step 1647: train/loss = 0.2977170944213867, train/raw-loss = 0.25318002700805664, train/logprobs = tensor([[-0.7045, -3.1299],
        [-2.0851, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22268518805503845
Epoch 0, Step 1648: train/loss = 0.34847694635391235, train/raw-loss = 0.30424565076828003, train/logprobs = tensor([[-0.7284, -2.9609],
        [-2.1907, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22115659713745117
Epoch 0, Step 1649: train/loss = 0.321768581867218, train/raw-loss = 0.27463921904563904, train/logprobs = tensor([[-0.6302, -5.4132],
        [-2.5321, -2.0815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23564685881137848
Epoch 0, Step 1650: train/loss = 0.37879711389541626, train/raw-loss = 0.33536583185195923, train/logprobs = tensor([[-0.8121, -4.9184],
        [-1.9973, -1.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21715648472309113
Epoch 0, Step 1651: train/loss = 0.22626818716526031, train/raw-loss = 0.17737658321857452, train/logprobs = tensor([[-0.7143, -4.8117],
        [-2.6195, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24445801973342896
Epoch 0, Step 1652: train/loss = 0.548134446144104, train/raw-loss = 0.5014706254005432, train/logprobs = tensor([[-0.5488, -3.3155],
        [-1.8136, -1.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333189845085144
Epoch 0, Step 1653: train/loss = 0.2954493761062622, train/raw-loss = 0.24180631339550018, train/logprobs = tensor([[-0.6633, -4.4965],
        [-2.4696, -1.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682153880596161
Epoch 0, Step 1654: train/loss = 0.3679838180541992, train/raw-loss = 0.32196301221847534, train/logprobs = tensor([[-1.1830, -5.8817],
        [-2.1545, -1.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23010408878326416
Epoch 0, Step 1655: train/loss = 0.25405335426330566, train/raw-loss = 0.20355470478534698, train/logprobs = tensor([[-0.6493, -8.4347],
        [-2.3861, -2.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524932324886322
Epoch 0, Step 1656: train/loss = 0.21431972086429596, train/raw-loss = 0.15738484263420105, train/logprobs = tensor([[-0.6690, -4.1329],
        [-3.4227, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28467440605163574
Epoch 0, Step 1657: train/loss = 0.4174882769584656, train/raw-loss = 0.35723984241485596, train/logprobs = tensor([[-0.9581, -2.9546],
        [-3.6503, -2.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30124232172966003
Epoch 0, Step 1658: train/loss = 0.5437847375869751, train/raw-loss = 0.500798225402832, train/logprobs = tensor([[-0.8989, -3.3937],
        [-2.4860, -3.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21493250131607056
Epoch 0, Step 1659: train/loss = 0.2666405737400055, train/raw-loss = 0.2085907757282257, train/logprobs = tensor([[-0.9734, -3.7999],
        [-3.7520, -1.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902489900588989
Epoch 0, Step 1660: train/loss = 0.2273559868335724, train/raw-loss = 0.1851014792919159, train/logprobs = tensor([[-1.1653, -6.9899],
        [-2.7103, -1.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21127259731292725
Epoch 0, Step 1661: train/loss = 0.617411732673645, train/raw-loss = 0.5745973587036133, train/logprobs = tensor([[-1.1005, -2.1316],
        [-1.7704, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21407213807106018
Epoch 0, Step 1662: train/loss = 0.2085719108581543, train/raw-loss = 0.15813693404197693, train/logprobs = tensor([[-1.0093, -6.6377],
        [-3.1671, -2.0930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25217491388320923
Epoch 0, Step 1663: train/loss = 0.2518116235733032, train/raw-loss = 0.20927342772483826, train/logprobs = tensor([[-1.0768, -3.1061],
        [-3.1150, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21269097924232483
Epoch 0, Step 1664: train/loss = 0.3836050033569336, train/raw-loss = 0.3238191306591034, train/logprobs = tensor([[-0.8567, -2.3699],
        [-2.7338, -1.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.298929363489151
Epoch 0, Step 1665: train/loss = 0.29440224170684814, train/raw-loss = 0.24086828529834747, train/logprobs = tensor([[-1.7684, -5.3239],
        [-3.0189, -1.7771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26766982674598694
Epoch 0, Step 1666: train/loss = 0.3874918222427368, train/raw-loss = 0.3466232717037201, train/logprobs = tensor([[-0.9951, -3.5723],
        [-2.2356, -0.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20434263348579407
Epoch 0, Step 1667: train/loss = 0.20394766330718994, train/raw-loss = 0.166128009557724, train/logprobs = tensor([[-0.5459, -6.4773],
        [-2.1641, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18909822404384613
Epoch 0, Step 1668: train/loss = 0.557469367980957, train/raw-loss = 0.5295618176460266, train/logprobs = tensor([[-0.7946, -3.1626],
        [-0.6859, -1.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13953745365142822
Epoch 0, Step 1669: train/loss = 0.13006144762039185, train/raw-loss = 0.07586278766393661, train/logprobs = tensor([[-0.7834, -7.6322],
        [-3.0461, -2.1191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27099335193634033
Epoch 0, Step 1670: train/loss = 0.09867299348115921, train/raw-loss = 0.05020869895815849, train/logprobs = tensor([[-0.8784, -8.3075],
        [-4.0194, -1.3304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24232149124145508
Epoch 0, Step 1671: train/loss = 0.3115575909614563, train/raw-loss = 0.27090197801589966, train/logprobs = tensor([[-1.9953, -5.2853],
        [-2.9727, -1.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2032780945301056
Epoch 0, Step 1672: train/loss = 0.38657477498054504, train/raw-loss = 0.33970823884010315, train/logprobs = tensor([[-1.1819, -4.0665],
        [-2.6204, -1.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23433277010917664
Epoch 0, Step 1673: train/loss = 0.2914629578590393, train/raw-loss = 0.24546214938163757, train/logprobs = tensor([[-0.6926, -3.8384],
        [-2.1206, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23000402748584747
Epoch 0, Step 1674: train/loss = 0.3443041443824768, train/raw-loss = 0.3104241192340851, train/logprobs = tensor([[-0.7722, -4.4754],
        [-1.6635, -1.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1694001704454422
Epoch 0, Step 1675: train/loss = 0.3925793468952179, train/raw-loss = 0.34724271297454834, train/logprobs = tensor([[-1.8631, -7.1092],
        [-2.4215, -2.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2266831398010254
Epoch 0, Step 1676: train/loss = 0.31998908519744873, train/raw-loss = 0.25540316104888916, train/logprobs = tensor([[-1.2412, -5.3682],
        [-3.7928, -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32292965054512024
Epoch 0, Step 1677: train/loss = 0.3551125228404999, train/raw-loss = 0.32361289858818054, train/logprobs = tensor([[-0.8057, -5.2211],
        [-2.8865, -2.3393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574980914592743
Epoch 0, Step 1678: train/loss = 0.3687315881252289, train/raw-loss = 0.3185546100139618, train/logprobs = tensor([[-0.9427, -3.9309],
        [-2.9709, -1.5015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25088489055633545
Epoch 0, Step 1679: train/loss = 0.3714796006679535, train/raw-loss = 0.32360777258872986, train/logprobs = tensor([[-0.8664, -3.3860],
        [-2.6394, -1.2689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.239359050989151
Epoch 0, Step 1680: train/loss = 0.4437275230884552, train/raw-loss = 0.39815443754196167, train/logprobs = tensor([[-0.7283, -2.9911],
        [-1.7752, -1.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22786542773246765
Epoch 0, Step 1681: train/loss = 0.26849353313446045, train/raw-loss = 0.22998759150505066, train/logprobs = tensor([[-0.9292, -9.8516],
        [-2.5015, -1.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925298273563385
Epoch 0, Step 1682: train/loss = 0.442127525806427, train/raw-loss = 0.3881498873233795, train/logprobs = tensor([[-0.8069, -4.7736],
        [-2.3881, -1.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698880136013031
Epoch 0, Step 1683: train/loss = 0.4029812812805176, train/raw-loss = 0.35157331824302673, train/logprobs = tensor([[-1.8617, -4.7465],
        [-3.1663, -1.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570398449897766
Epoch 0, Step 1684: train/loss = 0.4779477119445801, train/raw-loss = 0.43961066007614136, train/logprobs = tensor([[-0.6506, -1.4601],
        [-1.8809, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191685289144516
Epoch 0, Step 1685: train/loss = 0.39514538645744324, train/raw-loss = 0.35063716769218445, train/logprobs = tensor([[-0.6978, -3.5785],
        [-2.2671, -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2225409597158432
Epoch 0, Step 1686: train/loss = 0.17812290787696838, train/raw-loss = 0.1344502717256546, train/logprobs = tensor([[-0.8971, -7.5798],
        [-2.7099, -2.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21836313605308533
Epoch 0, Step 1687: train/loss = 0.31890493631362915, train/raw-loss = 0.268413245677948, train/logprobs = tensor([[-0.8065, -4.9238],
        [-2.4547, -1.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252458393573761
Epoch 0, Step 1688: train/loss = 0.40173229575157166, train/raw-loss = 0.3550707697868347, train/logprobs = tensor([[-1.2266, -6.9051],
        [-1.8170, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23330777883529663
Epoch 0, Step 1689: train/loss = 0.39271870255470276, train/raw-loss = 0.34376060962677, train/logprobs = tensor([[-0.8263, -5.0725],
        [-2.4758, -1.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24479037523269653
Epoch 0, Step 1690: train/loss = 0.40420645475387573, train/raw-loss = 0.35912033915519714, train/logprobs = tensor([[-0.8593, -3.1331],
        [-1.6445, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2254306823015213
Epoch 0, Step 1691: train/loss = 0.47884196043014526, train/raw-loss = 0.4411884546279907, train/logprobs = tensor([[-1.4109, -4.3242],
        [-1.8938, -1.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18826723098754883
Epoch 0, Step 1692: train/loss = 0.29235947132110596, train/raw-loss = 0.22813163697719574, train/logprobs = tensor([[-1.0955, -4.6296],
        [-3.5663, -1.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3211390972137451
Epoch 0, Step 1693: train/loss = 0.4231373369693756, train/raw-loss = 0.3671469986438751, train/logprobs = tensor([[-1.0928, -3.9396],
        [-2.3806, -1.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27995172142982483
Epoch 0, Step 1694: train/loss = 0.2148858904838562, train/raw-loss = 0.17175143957138062, train/logprobs = tensor([[-0.9500, -4.3679],
        [-3.0244, -1.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21567222476005554
Epoch 0, Step 1695: train/loss = 0.6564253568649292, train/raw-loss = 0.6056963801383972, train/logprobs = tensor([[-1.0609, -3.9317],
        [-1.8185, -1.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25364503264427185
Epoch 0, Step 1696: train/loss = 0.4692014455795288, train/raw-loss = 0.4210697412490845, train/logprobs = tensor([[-1.6490, -4.1460],
        [-2.1300, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24065861105918884
Epoch 0, Step 1697: train/loss = 0.5425232648849487, train/raw-loss = 0.5090011358261108, train/logprobs = tensor([[-0.5486, -2.3891],
        [-1.1732, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16761060059070587
Epoch 0, Step 1698: train/loss = 0.4205258786678314, train/raw-loss = 0.37450337409973145, train/logprobs = tensor([[-1.2274, -3.9448],
        [-1.6345, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2301127165555954
Epoch 0, Step 1699: train/loss = 0.39332810044288635, train/raw-loss = 0.3482401669025421, train/logprobs = tensor([[-1.0387, -4.7545],
        [-2.2825, -1.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22543960809707642
Epoch 0, Step 1700: train/loss = 0.4338605999946594, train/raw-loss = 0.37800133228302, train/logprobs = tensor([[-1.1736, -4.3602],
        [-2.1225, -2.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792963981628418
Epoch 0, Step 1701: train/loss = 0.4845978021621704, train/raw-loss = 0.4415346086025238, train/logprobs = tensor([[-1.7195, -2.7898],
        [-2.6002, -2.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21531569957733154
Epoch 0, Step 1702: train/loss = 0.3845558762550354, train/raw-loss = 0.3300853967666626, train/logprobs = tensor([[-0.6761, -3.7477],
        [-2.4808, -2.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723523676395416
Epoch 0, Step 1703: train/loss = 0.2762335538864136, train/raw-loss = 0.22987604141235352, train/logprobs = tensor([[-0.8173, -5.4576],
        [-2.7083, -2.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23178760707378387
Epoch 0, Step 1704: train/loss = 0.20896224677562714, train/raw-loss = 0.15629184246063232, train/logprobs = tensor([[-1.2254, -7.2732],
        [-3.1630, -1.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26335206627845764
Epoch 0, Step 1705: train/loss = 0.3622143864631653, train/raw-loss = 0.3159438371658325, train/logprobs = tensor([[-0.7775, -5.8132],
        [-2.2538, -1.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23135265707969666
Epoch 0, Step 1706: train/loss = 0.23609499633312225, train/raw-loss = 0.1896822303533554, train/logprobs = tensor([[-0.7985, -4.6596],
        [-3.4818, -1.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23206378519535065
Epoch 0, Step 1707: train/loss = 0.3597964644432068, train/raw-loss = 0.3095334768295288, train/logprobs = tensor([[-0.9599, -3.1150],
        [-2.5932, -2.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513149380683899
Epoch 0, Step 1708: train/loss = 0.3739789128303528, train/raw-loss = 0.3311332166194916, train/logprobs = tensor([[-1.0890, -3.9519],
        [-2.5289, -1.5564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.214228555560112
Epoch 0, Step 1709: train/loss = 0.4658146798610687, train/raw-loss = 0.41780200600624084, train/logprobs = tensor([[-1.0787, -4.9405],
        [-1.8703, -1.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2400633990764618
Epoch 0, Step 1710: train/loss = 0.34776559472084045, train/raw-loss = 0.29470962285995483, train/logprobs = tensor([[-0.9111, -4.5054],
        [-2.5684, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26527994871139526
Epoch 0, Step 1711: train/loss = 0.20240426063537598, train/raw-loss = 0.14199775457382202, train/logprobs = tensor([[-0.8931, -7.0464],
        [-3.7082, -1.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020325303077698
Epoch 0, Step 1712: train/loss = 0.17105859518051147, train/raw-loss = 0.12960617244243622, train/logprobs = tensor([[-0.5335, -9.8088],
        [-1.8942, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20726212859153748
Epoch 0, Step 1713: train/loss = 0.23293301463127136, train/raw-loss = 0.1838844120502472, train/logprobs = tensor([[-1.0625, -5.3416],
        [-3.1884, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2452429085969925
Epoch 0, Step 1714: train/loss = 0.5260084867477417, train/raw-loss = 0.4784437417984009, train/logprobs = tensor([[-1.0613, -2.6120],
        [-1.3659, -1.3192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23782390356063843
Epoch 0, Step 1715: train/loss = 0.36517447233200073, train/raw-loss = 0.31554943323135376, train/logprobs = tensor([[-0.9104, -3.2669],
        [-1.8661, -1.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24812501668930054
Epoch 0, Step 1716: train/loss = 0.5201307535171509, train/raw-loss = 0.4679514765739441, train/logprobs = tensor([[-1.2355, -3.9841],
        [-1.9198, -2.2769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26089632511138916
Epoch 0, Step 1717: train/loss = 0.40988701581954956, train/raw-loss = 0.36282071471214294, train/logprobs = tensor([[-0.9276, -7.9880],
        [-2.4695, -1.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2353316843509674
Epoch 0, Step 1718: train/loss = 0.4113856554031372, train/raw-loss = 0.3676875829696655, train/logprobs = tensor([[-1.4033, -3.9690],
        [-2.3800, -1.2154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2184901386499405
Epoch 0, Step 1719: train/loss = 0.3468579947948456, train/raw-loss = 0.2898445129394531, train/logprobs = tensor([[-0.9594, -7.2557],
        [-3.2798, -1.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28506752848625183
Epoch 0, Step 1720: train/loss = 0.778468132019043, train/raw-loss = 0.7294137477874756, train/logprobs = tensor([[-2.5539, -3.8522],
        [-1.9202, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24527187645435333
Epoch 0, Step 1721: train/loss = 0.23669876158237457, train/raw-loss = 0.17956918478012085, train/logprobs = tensor([[-1.7593, -8.2270],
        [-3.9812, -3.2989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28564783930778503
Epoch 0, Step 1722: train/loss = 0.19252297282218933, train/raw-loss = 0.13925960659980774, train/logprobs = tensor([[-0.4819, -5.3296],
        [-3.3655, -2.2039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26631683111190796
Epoch 0, Step 1723: train/loss = 0.3566243648529053, train/raw-loss = 0.2946348786354065, train/logprobs = tensor([[-1.2325, -4.9172],
        [-3.4126, -2.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3099473714828491
Epoch 0, Step 1724: train/loss = 0.3020363748073578, train/raw-loss = 0.26221150159835815, train/logprobs = tensor([[-1.3604, -7.8768],
        [-2.2482, -1.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1991243064403534
Epoch 0, Step 1725: train/loss = 0.48037290573120117, train/raw-loss = 0.43092331290245056, train/logprobs = tensor([[-1.1630, -4.2541],
        [-2.4219, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24724777042865753
Epoch 0, Step 1726: train/loss = 0.16909629106521606, train/raw-loss = 0.12181170284748077, train/logprobs = tensor([[-0.9926, -7.1364],
        [-2.7239, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23642295598983765
Epoch 0, Step 1727: train/loss = 0.2288207709789276, train/raw-loss = 0.18326742947101593, train/logprobs = tensor([[-0.8406, -4.9147],
        [-2.6709, -2.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22776666283607483
Epoch 0, Step 1728: train/loss = 0.5328340530395508, train/raw-loss = 0.49631258845329285, train/logprobs = tensor([[-1.1196, -3.8450],
        [-1.2193, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18260729312896729
Epoch 0, Step 1729: train/loss = 0.16451168060302734, train/raw-loss = 0.11625101417303085, train/logprobs = tensor([[-1.2874, -9.1105],
        [-2.6288, -1.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24130335450172424
Epoch 0, Step 1730: train/loss = 0.689318835735321, train/raw-loss = 0.6312432289123535, train/logprobs = tensor([[-1.1945, -2.1007],
        [-2.3113, -2.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29037827253341675
Epoch 0, Step 1731: train/loss = 0.5521299839019775, train/raw-loss = 0.5117251873016357, train/logprobs = tensor([[-0.6208, -3.3470],
        [-1.9205, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20202422142028809
Epoch 0, Step 1732: train/loss = 0.3241932690143585, train/raw-loss = 0.2794118821620941, train/logprobs = tensor([[-1.1923, -6.3494],
        [-2.3137, -1.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2239069938659668
Epoch 0, Step 1733: train/loss = 0.4116937518119812, train/raw-loss = 0.3700524866580963, train/logprobs = tensor([[-0.6091, -4.0329],
        [-1.6787, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2082064151763916
Epoch 0, Step 1734: train/loss = 0.4165676236152649, train/raw-loss = 0.37517184019088745, train/logprobs = tensor([[-1.4325, -5.5338],
        [-1.6251, -1.9585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2069789171218872
Epoch 0, Step 1735: train/loss = 0.21801944077014923, train/raw-loss = 0.17615212500095367, train/logprobs = tensor([[-1.4074, -6.8663],
        [-2.4504, -1.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20933663845062256
Epoch 0, Step 1736: train/loss = 0.19509993493556976, train/raw-loss = 0.13446402549743652, train/logprobs = tensor([[-1.2941, -6.5861],
        [-3.4411, -2.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031795024871826
Epoch 0, Step 1737: train/loss = 0.16564570367336273, train/raw-loss = 0.10990285128355026, train/logprobs = tensor([[-0.9383, -7.7776],
        [-3.8327, -2.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27871426939964294
Epoch 0, Step 1738: train/loss = 0.34638357162475586, train/raw-loss = 0.30237793922424316, train/logprobs = tensor([[-2.0925, -6.0857],
        [-2.7913, -1.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22002843022346497
Epoch 0, Step 1739: train/loss = 0.45074546337127686, train/raw-loss = 0.40361613035202026, train/logprobs = tensor([[-1.3172, -4.9313],
        [-1.7777, -1.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2356467992067337
Epoch 0, Step 1740: train/loss = 0.41832464933395386, train/raw-loss = 0.37809011340141296, train/logprobs = tensor([[-0.9294, -3.9316],
        [-2.2576, -2.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011728137731552
Epoch 0, Step 1741: train/loss = 0.3750021457672119, train/raw-loss = 0.3334342837333679, train/logprobs = tensor([[-0.9047, -5.1673],
        [-2.5208, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20783935487270355
Epoch 0, Step 1742: train/loss = 0.33650606870651245, train/raw-loss = 0.28028619289398193, train/logprobs = tensor([[-2.1239, -8.8584],
        [-2.6674, -2.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281099408864975
Epoch 0, Step 1743: train/loss = 0.5494126081466675, train/raw-loss = 0.5024624466896057, train/logprobs = tensor([[-0.9240, -2.6163],
        [-2.2003, -1.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23475074768066406
Epoch 0, Step 1744: train/loss = 0.19534003734588623, train/raw-loss = 0.15085066854953766, train/logprobs = tensor([[-1.8135, -6.7815],
        [-2.9468, -1.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2224467545747757
Epoch 0, Step 1745: train/loss = 0.4211144745349884, train/raw-loss = 0.3709568679332733, train/logprobs = tensor([[-0.8694, -5.9313],
        [-2.0468, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25078803300857544
Epoch 0, Step 1746: train/loss = 0.4054821729660034, train/raw-loss = 0.363308846950531, train/logprobs = tensor([[-0.7521, -2.9854],
        [-1.8619, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2108665406703949
Epoch 0, Step 1747: train/loss = 0.4053197205066681, train/raw-loss = 0.36540359258651733, train/logprobs = tensor([[-0.8019, -2.6539],
        [-2.4227, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1995808482170105
Epoch 0, Step 1748: train/loss = 0.4262644946575165, train/raw-loss = 0.3780260682106018, train/logprobs = tensor([[-0.9813, -1.9438],
        [-2.9697, -1.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2411920726299286
Epoch 0, Step 1749: train/loss = 0.37435463070869446, train/raw-loss = 0.32230591773986816, train/logprobs = tensor([[-1.1359, -4.2317],
        [-2.5586, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26024359464645386
Epoch 0, Step 1750: train/loss = 0.30040183663368225, train/raw-loss = 0.24963775277137756, train/logprobs = tensor([[ -1.6187, -11.7914],
        [ -2.6678,  -2.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538204789161682
Epoch 0, Step 1751: train/loss = 0.5010327696800232, train/raw-loss = 0.4564133882522583, train/logprobs = tensor([[-1.6195, -5.3714],
        [-1.8606, -2.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22309698164463043
Epoch 0, Step 1752: train/loss = 0.28690341114997864, train/raw-loss = 0.24913989007472992, train/logprobs = tensor([[-0.9342, -8.3368],
        [-2.2337, -2.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18881756067276
Epoch 0, Step 1753: train/loss = 0.20719259977340698, train/raw-loss = 0.1603315770626068, train/logprobs = tensor([[-1.6872, -7.5131],
        [-3.0012, -1.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23430508375167847
Epoch 0, Step 1754: train/loss = 0.11218754947185516, train/raw-loss = 0.05624350532889366, train/logprobs = tensor([[ -1.2870, -10.9776],
        [ -3.9383,  -1.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2797202467918396
Epoch 0, Step 1755: train/loss = 0.30801108479499817, train/raw-loss = 0.25729700922966003, train/logprobs = tensor([[-1.7519, -3.8826],
        [-2.8609, -1.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25357046723365784
Epoch 0, Step 1756: train/loss = 0.42855995893478394, train/raw-loss = 0.3871701955795288, train/logprobs = tensor([[-1.8309, -4.0114],
        [-2.0273, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2069488763809204
Epoch 0, Step 1757: train/loss = 0.608492910861969, train/raw-loss = 0.5541963577270508, train/logprobs = tensor([[-1.3255, -1.5340],
        [-1.9020, -1.2050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27148279547691345
Epoch 0, Step 1758: train/loss = 0.28003424406051636, train/raw-loss = 0.23680655658245087, train/logprobs = tensor([[-0.9729, -8.1100],
        [-1.8981, -2.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21613840758800507
Epoch 0, Step 1759: train/loss = 0.4257766604423523, train/raw-loss = 0.3892099857330322, train/logprobs = tensor([[-0.6893, -2.9224],
        [-2.5216, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1828332394361496
Epoch 0, Step 1760: train/loss = 0.503091037273407, train/raw-loss = 0.45491260290145874, train/logprobs = tensor([[-0.9380, -5.4476],
        [-2.9909, -2.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24089239537715912
Epoch 0, Step 1761: train/loss = 0.19022026658058167, train/raw-loss = 0.13531695306301117, train/logprobs = tensor([[-0.9462, -5.8713],
        [-2.4897, -1.4597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27451664209365845
Epoch 0, Step 1762: train/loss = 0.38427650928497314, train/raw-loss = 0.33653342723846436, train/logprobs = tensor([[-1.3438, -5.9161],
        [-2.4941, -1.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2387152463197708
Epoch 0, Step 1763: train/loss = 0.48529961705207825, train/raw-loss = 0.4376412034034729, train/logprobs = tensor([[-1.8413, -7.1541],
        [-1.5585, -1.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23829199373722076
Epoch 0, Step 1764: train/loss = 0.17386312782764435, train/raw-loss = 0.128974050283432, train/logprobs = tensor([[-0.6316, -5.8498],
        [-2.1064, -1.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2244453728199005
Epoch 0, Step 1765: train/loss = 0.4525502920150757, train/raw-loss = 0.39989954233169556, train/logprobs = tensor([[-0.7274, -3.6549],
        [-1.8430, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26325368881225586
Epoch 0, Step 1766: train/loss = 0.26093751192092896, train/raw-loss = 0.22241023182868958, train/logprobs = tensor([[-1.3119, -7.4904],
        [-2.3721, -1.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926363706588745
Epoch 0, Step 1767: train/loss = 0.25262558460235596, train/raw-loss = 0.20784465968608856, train/logprobs = tensor([[ -0.6586, -10.9809],
        [ -2.0060,  -2.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22390450537204742
Epoch 0, Step 1768: train/loss = 0.2511230707168579, train/raw-loss = 0.19240489602088928, train/logprobs = tensor([[-1.1640, -5.1784],
        [-3.2928, -2.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29359084367752075
Epoch 0, Step 1769: train/loss = 0.22075818479061127, train/raw-loss = 0.1786903291940689, train/logprobs = tensor([[-1.0968, -4.4644],
        [-2.8685, -1.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21033921837806702
Epoch 0, Step 1770: train/loss = 0.2894231975078583, train/raw-loss = 0.24994733929634094, train/logprobs = tensor([[ -1.3947, -12.4844],
        [ -2.3594,  -2.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1973792463541031
Epoch 0, Step 1771: train/loss = 0.41051915287971497, train/raw-loss = 0.36066949367523193, train/logprobs = tensor([[-1.0725, -4.0349],
        [-2.5071, -1.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24924838542938232
Epoch 0, Step 1772: train/loss = 0.325103223323822, train/raw-loss = 0.2825529873371124, train/logprobs = tensor([[-1.3640, -5.8372],
        [-1.9780, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.212751105427742
Epoch 0, Step 1773: train/loss = 0.21970638632774353, train/raw-loss = 0.16107329726219177, train/logprobs = tensor([[-1.0424, -8.0477],
        [-2.6249, -1.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29316550493240356
Epoch 0, Step 1774: train/loss = 0.5884037613868713, train/raw-loss = 0.5306704044342041, train/logprobs = tensor([[-2.2390, -3.9829],
        [-2.9544, -2.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28866636753082275
Epoch 0, Step 1775: train/loss = 0.42761608958244324, train/raw-loss = 0.37667906284332275, train/logprobs = tensor([[-1.1177, -2.8447],
        [-2.0926, -1.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25468531250953674
Epoch 0, Step 1776: train/loss = 0.7706053256988525, train/raw-loss = 0.7201260924339294, train/logprobs = tensor([[-3.2779, -9.6743],
        [-2.9536, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523961365222931
Epoch 0, Step 1777: train/loss = 0.3964025378227234, train/raw-loss = 0.34389954805374146, train/logprobs = tensor([[-0.7024, -4.6907],
        [-2.5312, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26251497864723206
Epoch 0, Step 1778: train/loss = 0.36567243933677673, train/raw-loss = 0.3110571503639221, train/logprobs = tensor([[-1.5613, -5.8130],
        [-2.6410, -1.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27307650446891785
Epoch 0, Step 1779: train/loss = 0.43263038992881775, train/raw-loss = 0.38956281542778015, train/logprobs = tensor([[-0.7594, -7.0046],
        [-1.6146, -1.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2153378129005432
Epoch 0, Step 1780: train/loss = 0.3610885739326477, train/raw-loss = 0.3098015785217285, train/logprobs = tensor([[-0.5677, -4.7471],
        [-1.7120, -1.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564347982406616
Epoch 0, Step 1781: train/loss = 0.3543264865875244, train/raw-loss = 0.30340826511383057, train/logprobs = tensor([[-0.8593, -4.4203],
        [-2.3471, -1.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545909285545349
Epoch 0, Step 1782: train/loss = 0.18326851725578308, train/raw-loss = 0.14318178594112396, train/logprobs = tensor([[-0.6195, -7.7701],
        [-1.6509, -1.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20043368637561798
Epoch 0, Step 1783: train/loss = 0.35894760489463806, train/raw-loss = 0.30279767513275146, train/logprobs = tensor([[-1.2919, -5.2345],
        [-3.3241, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28074952960014343
Epoch 0, Step 1784: train/loss = 0.49577972292900085, train/raw-loss = 0.4541994333267212, train/logprobs = tensor([[-1.6035, -3.8122],
        [-1.6973, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079015076160431
Epoch 0, Step 1785: train/loss = 0.49204951524734497, train/raw-loss = 0.4418615400791168, train/logprobs = tensor([[-1.2314, -3.8381],
        [-1.7517, -1.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2509399354457855
Epoch 0, Step 1786: train/loss = 0.5243374109268188, train/raw-loss = 0.4828610420227051, train/logprobs = tensor([[-0.8784, -3.2112],
        [-1.3966, -1.4109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2073819637298584
Epoch 0, Step 1787: train/loss = 0.47248199582099915, train/raw-loss = 0.41756415367126465, train/logprobs = tensor([[-1.8165, -4.5414],
        [-2.4149, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2745891511440277
Epoch 0, Step 1788: train/loss = 0.42593076825141907, train/raw-loss = 0.3877263367176056, train/logprobs = tensor([[-0.6470, -3.9935],
        [-0.9389, -1.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19102197885513306
Epoch 0, Step 1789: train/loss = 0.3015679717063904, train/raw-loss = 0.2562903165817261, train/logprobs = tensor([[-1.3171, -5.6593],
        [-2.7362, -1.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263883352279663
Epoch 0, Step 1790: train/loss = 0.23796513676643372, train/raw-loss = 0.18608489632606506, train/logprobs = tensor([[-1.0929, -8.1153],
        [-2.7652, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25940126180648804
Epoch 0, Step 1791: train/loss = 0.39144113659858704, train/raw-loss = 0.34412533044815063, train/logprobs = tensor([[-1.4484, -3.4335],
        [-2.6881, -1.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23657891154289246
Epoch 0, Step 1792: train/loss = 0.2983960807323456, train/raw-loss = 0.2428300380706787, train/logprobs = tensor([[-0.8793, -4.9479],
        [-2.6346, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27783018350601196
Epoch 0, Step 1793: train/loss = 0.25559282302856445, train/raw-loss = 0.206511989235878, train/logprobs = tensor([[-1.1487, -7.3234],
        [-2.4266, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24540409445762634
Epoch 0, Step 1794: train/loss = 0.2548784613609314, train/raw-loss = 0.2087806910276413, train/logprobs = tensor([[-1.3421, -3.9105],
        [-3.3358, -1.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23048877716064453
Epoch 0, Step 1795: train/loss = 0.22137342393398285, train/raw-loss = 0.18361179530620575, train/logprobs = tensor([[-0.6719, -8.9070],
        [-2.8417, -2.5825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18880820274353027
Epoch 0, Step 1796: train/loss = 0.454212486743927, train/raw-loss = 0.41346150636672974, train/logprobs = tensor([[-0.8997, -2.4765],
        [-1.3490, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20375484228134155
Epoch 0, Step 1797: train/loss = 0.44345906376838684, train/raw-loss = 0.3969334363937378, train/logprobs = tensor([[ -2.5944, -10.7292],
        [ -2.9103,  -1.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23262828588485718
Epoch 0, Step 1798: train/loss = 0.30337250232696533, train/raw-loss = 0.25588497519493103, train/logprobs = tensor([[-1.1321, -7.2057],
        [-4.8071, -3.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2374376505613327
Epoch 0, Step 1799: train/loss = 0.38622328639030457, train/raw-loss = 0.3442058563232422, train/logprobs = tensor([[-1.1934, -5.9908],
        [-2.1735, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2100871354341507
Epoch 0, Step 1800: train/loss = 0.13482673466205597, train/raw-loss = 0.08094073086977005, train/logprobs = tensor([[ -0.9278, -12.0716],
        [ -2.9994,  -1.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2694300413131714
Epoch 0, Step 1801: train/loss = 0.2697020471096039, train/raw-loss = 0.22545656561851501, train/logprobs = tensor([[-1.1088, -6.7522],
        [-2.8481, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212274670600891
Epoch 0, Step 1802: train/loss = 0.33353209495544434, train/raw-loss = 0.287295937538147, train/logprobs = tensor([[-1.3287, -5.8441],
        [-2.2293, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23118089139461517
Epoch 0, Step 1803: train/loss = 0.3082387447357178, train/raw-loss = 0.26374953985214233, train/logprobs = tensor([[-1.4792, -6.7440],
        [-2.1678, -2.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22244592010974884
Epoch 0, Step 1804: train/loss = 0.43136724829673767, train/raw-loss = 0.3850156366825104, train/logprobs = tensor([[-1.1532, -4.1919],
        [-2.2212, -0.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23175819218158722
Epoch 0, Step 1805: train/loss = 0.3332135081291199, train/raw-loss = 0.293576717376709, train/logprobs = tensor([[-0.9306, -3.7160],
        [-2.6911, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19818398356437683
Epoch 0, Step 1806: train/loss = 0.24903516471385956, train/raw-loss = 0.2111712396144867, train/logprobs = tensor([[-0.8481, -5.2693],
        [-2.4306, -0.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1893196403980255
Epoch 0, Step 1807: train/loss = 0.5989417433738708, train/raw-loss = 0.5570791363716125, train/logprobs = tensor([[-0.6269, -3.5693],
        [-1.3801, -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20931291580200195
Epoch 0, Step 1808: train/loss = 0.28796082735061646, train/raw-loss = 0.24401161074638367, train/logprobs = tensor([[-0.7467, -7.3374],
        [-1.6409, -1.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21974614262580872
Epoch 0, Step 1809: train/loss = 0.3059360980987549, train/raw-loss = 0.2604622542858124, train/logprobs = tensor([[-0.9152, -9.5547],
        [-2.0081, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273692786693573
Epoch 0, Step 1810: train/loss = 0.39813897013664246, train/raw-loss = 0.36060571670532227, train/logprobs = tensor([[-1.0045, -2.6080],
        [-1.9784, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18766632676124573
Epoch 0, Step 1811: train/loss = 0.36959901452064514, train/raw-loss = 0.324619323015213, train/logprobs = tensor([[-1.3568, -6.6986],
        [-2.4071, -2.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248985469341278
Epoch 0, Step 1812: train/loss = 0.15014778077602386, train/raw-loss = 0.10008867084980011, train/logprobs = tensor([[-2.1187, -9.6906],
        [-4.0967, -1.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502955496311188
Epoch 0, Step 1813: train/loss = 0.23527491092681885, train/raw-loss = 0.1907799392938614, train/logprobs = tensor([[ -1.2082, -10.9645],
        [ -2.5969,  -3.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2224748134613037
Epoch 0, Step 1814: train/loss = 0.2997378706932068, train/raw-loss = 0.24052292108535767, train/logprobs = tensor([[-0.9629, -4.0003],
        [-2.6442, -2.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29607468843460083
Epoch 0, Step 1815: train/loss = 0.1899280548095703, train/raw-loss = 0.14789414405822754, train/logprobs = tensor([[-1.1719, -8.3424],
        [-2.2960, -2.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21016953885555267
Epoch 0, Step 1816: train/loss = 0.3005123436450958, train/raw-loss = 0.25557976961135864, train/logprobs = tensor([[-0.9020, -5.2251],
        [-1.4338, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22466281056404114
Epoch 0, Step 1817: train/loss = 0.6259045004844666, train/raw-loss = 0.5844577550888062, train/logprobs = tensor([[-1.1159, -1.4382],
        [-1.2722, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20723353326320648
Epoch 0, Step 1818: train/loss = 0.18754743039608002, train/raw-loss = 0.13627658784389496, train/logprobs = tensor([[-0.9763, -8.8258],
        [-3.0094, -1.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2563542425632477
Epoch 0, Step 1819: train/loss = 0.34096860885620117, train/raw-loss = 0.2941487431526184, train/logprobs = tensor([[-1.3036, -5.9139],
        [-2.3010, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23409941792488098
Epoch 0, Step 1820: train/loss = 0.3340587615966797, train/raw-loss = 0.2848741412162781, train/logprobs = tensor([[-0.9060, -5.0865],
        [-2.0550, -1.0978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24592295289039612
Epoch 0, Step 1821: train/loss = 0.2601432204246521, train/raw-loss = 0.21086697280406952, train/logprobs = tensor([[-0.9087, -6.7739],
        [-1.9647, -1.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24638131260871887
Epoch 0, Step 1822: train/loss = 0.3643535375595093, train/raw-loss = 0.31011873483657837, train/logprobs = tensor([[-1.2505, -4.0957],
        [-1.9709, -1.2008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27117401361465454
Epoch 0, Step 1823: train/loss = 0.4409327805042267, train/raw-loss = 0.3803322911262512, train/logprobs = tensor([[-0.6582, -4.1666],
        [-2.9017, -1.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3030024766921997
Epoch 0, Step 1824: train/loss = 0.3686613142490387, train/raw-loss = 0.3283570408821106, train/logprobs = tensor([[-0.7597, -4.0185],
        [-1.8829, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2015213519334793
Epoch 0, Step 1825: train/loss = 0.3040020763874054, train/raw-loss = 0.25111961364746094, train/logprobs = tensor([[-1.1101, -5.6136],
        [-2.4681, -1.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26441243290901184
Epoch 0, Step 1826: train/loss = 0.28271806240081787, train/raw-loss = 0.24021920561790466, train/logprobs = tensor([[-1.4615, -7.9257],
        [-2.2883, -1.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21249429881572723
Epoch 0, Step 1827: train/loss = 0.24206392467021942, train/raw-loss = 0.17831847071647644, train/logprobs = tensor([[-1.0192, -3.6077],
        [-2.8117, -1.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31872716546058655
Epoch 0, Step 1828: train/loss = 0.21559622883796692, train/raw-loss = 0.16459673643112183, train/logprobs = tensor([[-1.6224, -8.8420],
        [-3.2019, -1.3980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549973726272583
Epoch 0, Step 1829: train/loss = 0.4206289052963257, train/raw-loss = 0.3806456923484802, train/logprobs = tensor([[-0.8499, -4.3412],
        [-1.1430, -0.6720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1999160796403885
Epoch 0, Step 1830: train/loss = 0.4093034267425537, train/raw-loss = 0.36734694242477417, train/logprobs = tensor([[-0.5932, -4.4872],
        [-1.5154, -2.3991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2097824662923813
Epoch 0, Step 1831: train/loss = 0.6969912052154541, train/raw-loss = 0.6546924710273743, train/logprobs = tensor([[-0.7722, -0.9871],
        [-1.0302, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21149380505084991
Epoch 0, Step 1832: train/loss = 0.29592084884643555, train/raw-loss = 0.25024721026420593, train/logprobs = tensor([[-0.6475, -4.9916],
        [-1.5232, -1.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22836823761463165
Epoch 0, Step 1833: train/loss = 0.5841617584228516, train/raw-loss = 0.5319026112556458, train/logprobs = tensor([[-0.5662, -2.6284],
        [-1.3741, -2.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612958252429962
Epoch 0, Step 1834: train/loss = 0.486255407333374, train/raw-loss = 0.42539453506469727, train/logprobs = tensor([[-1.9430, -5.9437],
        [-1.7187, -1.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30430424213409424
Epoch 0, Step 1835: train/loss = 0.20492149889469147, train/raw-loss = 0.15927454829216003, train/logprobs = tensor([[ -0.7056, -10.8299],
        [ -1.8123,  -2.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22823476791381836
Epoch 0, Step 1836: train/loss = 0.14433977007865906, train/raw-loss = 0.08709053695201874, train/logprobs = tensor([[-1.4469, -7.8903],
        [-3.3824, -1.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862461805343628
Epoch 0, Step 1837: train/loss = 0.3381791114807129, train/raw-loss = 0.29675108194351196, train/logprobs = tensor([[-1.3080, -7.8862],
        [-2.2855, -1.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20714019238948822
Epoch 0, Step 1838: train/loss = 0.2852266728878021, train/raw-loss = 0.23280134797096252, train/logprobs = tensor([[-1.3108, -5.3648],
        [-2.1872, -1.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26212671399116516
Epoch 0, Step 1839: train/loss = 0.2741008698940277, train/raw-loss = 0.22503986954689026, train/logprobs = tensor([[-1.0195, -5.8348],
        [-2.0687, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2453048825263977
Epoch 0, Step 1840: train/loss = 0.24328726530075073, train/raw-loss = 0.1937616765499115, train/logprobs = tensor([[ -1.5594, -11.9275],
        [ -2.4418,  -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24762794375419617
Epoch 0, Step 1841: train/loss = 0.3886412978172302, train/raw-loss = 0.34035587310791016, train/logprobs = tensor([[-0.7125, -4.5772],
        [-2.0762, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24142718315124512
Epoch 0, Step 1842: train/loss = 0.34632065892219543, train/raw-loss = 0.29705214500427246, train/logprobs = tensor([[-1.6257, -8.0453],
        [-2.1539, -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2463425248861313
Epoch 0, Step 1843: train/loss = 0.19896537065505981, train/raw-loss = 0.15468572080135345, train/logprobs = tensor([[-1.3848, -9.5284],
        [-2.9958, -1.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22139817476272583
Epoch 0, Step 1844: train/loss = 0.2546030879020691, train/raw-loss = 0.19141820073127747, train/logprobs = tensor([[-1.2501, -5.3635],
        [-3.5912, -1.3775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31592437624931335
Epoch 0, Step 1845: train/loss = 0.14386725425720215, train/raw-loss = 0.09402197599411011, train/logprobs = tensor([[-1.2143, -9.8996],
        [-3.0088, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492264211177826
Epoch 0, Step 1846: train/loss = 0.43945446610450745, train/raw-loss = 0.3913068175315857, train/logprobs = tensor([[-0.9489, -4.0791],
        [-2.1808, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24073822796344757
Epoch 0, Step 1847: train/loss = 0.14484016597270966, train/raw-loss = 0.09285332262516022, train/logprobs = tensor([[-1.0371, -6.6512],
        [-3.1137, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599341869354248
Epoch 0, Step 1848: train/loss = 0.3805813789367676, train/raw-loss = 0.3408203125, train/logprobs = tensor([[-0.7883, -3.1890],
        [-2.3787, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1988053321838379
Epoch 0, Step 1849: train/loss = 0.4312964677810669, train/raw-loss = 0.3974282443523407, train/logprobs = tensor([[-0.7208, -3.8830],
        [-1.3467, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16934099793434143
Epoch 0, Step 1850: train/loss = 0.2428244948387146, train/raw-loss = 0.20044495165348053, train/logprobs = tensor([[-1.3133, -7.7506],
        [-2.0748, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21189773082733154
Epoch 0, Step 1851: train/loss = 0.11777261644601822, train/raw-loss = 0.06541042029857635, train/logprobs = tensor([[-0.9374, -7.3231],
        [-3.4221, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26181095838546753
Epoch 0, Step 1852: train/loss = 0.13552440702915192, train/raw-loss = 0.09342721104621887, train/logprobs = tensor([[ -1.2263, -12.2350],
        [ -3.0123,  -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21048599481582642
Epoch 0, Step 1853: train/loss = 0.3906499743461609, train/raw-loss = 0.3520968556404114, train/logprobs = tensor([[-0.8423, -8.1393],
        [-1.5099, -1.6857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1927657574415207
Epoch 0, Step 1854: train/loss = 1.426615834236145, train/raw-loss = 1.3862371444702148, train/logprobs = tensor([[-4.4054, -5.7944],
        [-2.2706, -3.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2018939107656479
Epoch 0, Step 1855: train/loss = 0.21939320862293243, train/raw-loss = 0.16591325402259827, train/logprobs = tensor([[ -1.1284, -11.2008],
        [ -3.4195,  -2.2537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26739978790283203
Epoch 0, Step 1856: train/loss = 0.2761812210083008, train/raw-loss = 0.23294150829315186, train/logprobs = tensor([[-0.6674, -8.6615],
        [-2.2415, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21619857847690582
Epoch 0, Step 1857: train/loss = 0.21912871301174164, train/raw-loss = 0.1718742698431015, train/logprobs = tensor([[-1.1219, -6.2836],
        [-2.6125, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2362721711397171
Epoch 0, Step 1858: train/loss = 0.3873504400253296, train/raw-loss = 0.3330005407333374, train/logprobs = tensor([[-1.6972, -5.0449],
        [-2.0562, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27174949645996094
Epoch 0, Step 1859: train/loss = 0.30536022782325745, train/raw-loss = 0.253564715385437, train/logprobs = tensor([[-0.9225, -4.6934],
        [-1.9973, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25897765159606934
Epoch 0, Step 1860: train/loss = 0.3423350155353546, train/raw-loss = 0.29522308707237244, train/logprobs = tensor([[-1.0456, -6.2751],
        [-2.5499, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23555955290794373
Epoch 0, Step 1861: train/loss = 0.1561780869960785, train/raw-loss = 0.109895259141922, train/logprobs = tensor([[ -0.7946, -10.6735],
        [ -2.4856,  -1.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23141413927078247
Epoch 0, Step 1862: train/loss = 0.2988034784793854, train/raw-loss = 0.2533361315727234, train/logprobs = tensor([[-0.6999, -7.2647],
        [-1.6343, -1.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273368537425995
Epoch 0, Step 1863: train/loss = 0.5137861967086792, train/raw-loss = 0.46312806010246277, train/logprobs = tensor([[-1.4012, -4.6944],
        [-2.2968, -1.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25329047441482544
Epoch 0, Step 1864: train/loss = 0.3142688274383545, train/raw-loss = 0.2690771222114563, train/logprobs = tensor([[-1.5820, -7.6573],
        [-2.1651, -1.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22595864534378052
Epoch 0, Step 1865: train/loss = 0.4166463017463684, train/raw-loss = 0.37134385108947754, train/logprobs = tensor([[-0.6617, -4.7289],
        [-1.3213, -1.2933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22651249170303345
Epoch 0, Step 1866: train/loss = 0.4571117162704468, train/raw-loss = 0.41526010632514954, train/logprobs = tensor([[-1.3297, -4.1011],
        [-1.7603, -1.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20925812423229218
Epoch 0, Step 1867: train/loss = 0.4742746949195862, train/raw-loss = 0.4242824614048004, train/logprobs = tensor([[-1.1676, -4.4907],
        [-2.8329, -2.1433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24996118247509003
Epoch 0, Step 1868: train/loss = 0.49288392066955566, train/raw-loss = 0.44671761989593506, train/logprobs = tensor([[-0.9958, -3.3404],
        [-1.8305, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23083138465881348
Epoch 0, Step 1869: train/loss = 0.4055425524711609, train/raw-loss = 0.36162859201431274, train/logprobs = tensor([[-1.7630, -6.1376],
        [-3.6616, -3.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21956980228424072
Epoch 0, Step 1870: train/loss = 0.25326007604599, train/raw-loss = 0.20671552419662476, train/logprobs = tensor([[ -2.0186, -10.3559],
        [ -2.9256,  -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327226996421814
Epoch 0, Step 1871: train/loss = 0.31423717737197876, train/raw-loss = 0.2733843922615051, train/logprobs = tensor([[-0.5811, -8.2969],
        [-1.3515, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.204263836145401
Epoch 0, Step 1872: train/loss = 0.6671596765518188, train/raw-loss = 0.632666826248169, train/logprobs = tensor([[-0.8683, -1.1282],
        [-0.8942, -0.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1724642813205719
Epoch 0, Step 1873: train/loss = 0.4542979896068573, train/raw-loss = 0.4094282388687134, train/logprobs = tensor([[-1.0061, -4.2714],
        [-1.9750, -1.3371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22434890270233154
Epoch 0, Step 1874: train/loss = 0.18921718001365662, train/raw-loss = 0.1473006308078766, train/logprobs = tensor([[-0.7622, -7.5661],
        [-1.9215, -2.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20958268642425537
Epoch 0, Step 1875: train/loss = 0.4696744978427887, train/raw-loss = 0.42541542649269104, train/logprobs = tensor([[-1.3226, -4.1922],
        [-1.7837, -1.2910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212952971458435
Epoch 0, Step 1876: train/loss = 0.3863414227962494, train/raw-loss = 0.3433583378791809, train/logprobs = tensor([[-1.3671, -6.4025],
        [-1.7394, -1.6448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2149154543876648
Epoch 0, Step 1877: train/loss = 0.2578202188014984, train/raw-loss = 0.2021840512752533, train/logprobs = tensor([[-1.0994, -9.7126],
        [-3.9168, -2.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781808078289032
Epoch 0, Step 1878: train/loss = 0.19804081320762634, train/raw-loss = 0.14260579645633698, train/logprobs = tensor([[-1.1458, -8.2839],
        [-2.8300, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27717506885528564
Epoch 0, Step 1879: train/loss = 0.2487068474292755, train/raw-loss = 0.1985936164855957, train/logprobs = tensor([[-1.2144, -7.9152],
        [-2.8142, -2.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25056618452072144
Epoch 0, Step 1880: train/loss = 0.41923391819000244, train/raw-loss = 0.38565462827682495, train/logprobs = tensor([[-1.1383, -4.1107],
        [-1.8020, -1.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1678965836763382
Epoch 0, Step 1881: train/loss = 0.32461073994636536, train/raw-loss = 0.27873170375823975, train/logprobs = tensor([[-1.4063, -4.0753],
        [-2.6306, -1.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22939512133598328
Epoch 0, Step 1882: train/loss = 0.19396895170211792, train/raw-loss = 0.13518236577510834, train/logprobs = tensor([[-1.4635, -8.8085],
        [-4.5007, -1.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29393285512924194
Epoch 0, Step 1883: train/loss = 0.37498989701271057, train/raw-loss = 0.32865363359451294, train/logprobs = tensor([[-1.4690, -3.6001],
        [-2.2825, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.231681227684021
Epoch 0, Step 1884: train/loss = 0.31581875681877136, train/raw-loss = 0.26607459783554077, train/logprobs = tensor([[-1.8094, -9.6617],
        [-2.7454, -1.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2487209290266037
Epoch 0, Step 1885: train/loss = 0.35861632227897644, train/raw-loss = 0.3147887587547302, train/logprobs = tensor([[-1.2517, -6.6502],
        [-1.9047, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21913757920265198
Epoch 0, Step 1886: train/loss = 0.3673786520957947, train/raw-loss = 0.3200939893722534, train/logprobs = tensor([[-0.9054, -5.5098],
        [-3.0452, -2.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2364233434200287
Epoch 0, Step 1887: train/loss = 0.24986547231674194, train/raw-loss = 0.18946492671966553, train/logprobs = tensor([[-0.8341, -3.2549],
        [-3.1127, -1.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020027279853821
Epoch 0, Step 1888: train/loss = 0.6413763165473938, train/raw-loss = 0.5987433791160583, train/logprobs = tensor([[-1.1169, -1.6424],
        [-1.2077, -1.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21316461265087128
Epoch 0, Step 1889: train/loss = 0.22378602623939514, train/raw-loss = 0.1717759668827057, train/logprobs = tensor([[-1.3762, -9.3938],
        [-2.3640, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26005035638809204
Epoch 0, Step 1890: train/loss = 0.42466533184051514, train/raw-loss = 0.3814711272716522, train/logprobs = tensor([[-1.6911, -4.1216],
        [-2.3887, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21597109735012054
Epoch 0, Step 1891: train/loss = 0.5273842811584473, train/raw-loss = 0.4648372530937195, train/logprobs = tensor([[-2.6633, -6.1845],
        [-3.0579, -2.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3127351999282837
Epoch 0, Step 1892: train/loss = 0.5228166580200195, train/raw-loss = 0.46519315242767334, train/logprobs = tensor([[-1.7652, -3.8666],
        [-2.2032, -1.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881174683570862
Epoch 0, Step 1893: train/loss = 0.4299488961696625, train/raw-loss = 0.38365697860717773, train/logprobs = tensor([[-1.2767, -4.2494],
        [-1.9290, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23145964741706848
Epoch 0, Step 1894: train/loss = 0.3570745289325714, train/raw-loss = 0.30749326944351196, train/logprobs = tensor([[-0.7291, -2.9664],
        [-2.4472, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24790623784065247
Epoch 0, Step 1895: train/loss = 0.43044471740722656, train/raw-loss = 0.39142435789108276, train/logprobs = tensor([[-0.6846, -5.0240],
        [-1.0792, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1951017677783966
Epoch 0, Step 1896: train/loss = 0.21120993793010712, train/raw-loss = 0.17285947501659393, train/logprobs = tensor([[-1.2194, -8.5058],
        [-3.0502, -2.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19175226986408234
Epoch 0, Step 1897: train/loss = 0.13397103548049927, train/raw-loss = 0.08172115683555603, train/logprobs = tensor([[-0.7730, -9.5085],
        [-2.4803, -2.2537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612494230270386
Epoch 0, Step 1898: train/loss = 0.3994143605232239, train/raw-loss = 0.3535178601741791, train/logprobs = tensor([[-1.2368, -6.6231],
        [-1.9735, -0.8474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22948238253593445
Epoch 0, Step 1899: train/loss = 0.30356234312057495, train/raw-loss = 0.2550373375415802, train/logprobs = tensor([[-1.8210, -6.2782],
        [-3.5846, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24262507259845734
Epoch 0, Step 1900: train/loss = 0.32732683420181274, train/raw-loss = 0.28029611706733704, train/logprobs = tensor([[-1.7141, -7.2186],
        [-1.9352, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2351536750793457
Epoch 0, Step 1901: train/loss = 0.5136964321136475, train/raw-loss = 0.4583483338356018, train/logprobs = tensor([[-2.2332, -6.6850],
        [-2.6923, -2.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27674049139022827
Epoch 0, Step 1902: train/loss = 0.3871086835861206, train/raw-loss = 0.349376916885376, train/logprobs = tensor([[-1.1631, -7.4861],
        [-1.5016, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18865883350372314
Epoch 0, Step 1903: train/loss = 0.514828085899353, train/raw-loss = 0.4716659188270569, train/logprobs = tensor([[-0.9839, -3.2546],
        [-1.6105, -2.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158105969429016
Epoch 0, Step 1904: train/loss = 0.36699801683425903, train/raw-loss = 0.32527226209640503, train/logprobs = tensor([[-1.2426, -9.1295],
        [-1.9082, -1.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20862889289855957
Epoch 0, Step 1905: train/loss = 0.40578049421310425, train/raw-loss = 0.3540688753128052, train/logprobs = tensor([[ -1.9092, -11.5712],
        [ -2.1057,  -1.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25855791568756104
Epoch 0, Step 1906: train/loss = 0.46117109060287476, train/raw-loss = 0.41249972581863403, train/logprobs = tensor([[-1.4256, -3.3214],
        [-1.7624, -1.3176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24335676431655884
Epoch 0, Step 1907: train/loss = 0.39438652992248535, train/raw-loss = 0.35303544998168945, train/logprobs = tensor([[-1.1692, -6.9850],
        [-1.6395, -1.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20675547420978546
Epoch 0, Step 1908: train/loss = 0.5612087845802307, train/raw-loss = 0.5131163001060486, train/logprobs = tensor([[-1.7492, -4.8988],
        [-1.6395, -2.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24046257138252258
Epoch 0, Step 1909: train/loss = 0.3359929621219635, train/raw-loss = 0.275835245847702, train/logprobs = tensor([[-1.2284, -8.8415],
        [-3.8436, -2.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007885813713074
Epoch 0, Step 1910: train/loss = 0.3616092801094055, train/raw-loss = 0.31969478726387024, train/logprobs = tensor([[-1.1380, -5.4585],
        [-1.9146, -1.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095724195241928
Epoch 0, Step 1911: train/loss = 0.2519226372241974, train/raw-loss = 0.19864743947982788, train/logprobs = tensor([[-1.3359, -9.3973],
        [-3.2153, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663760483264923
Epoch 0, Step 1912: train/loss = 0.34859779477119446, train/raw-loss = 0.2947458028793335, train/logprobs = tensor([[-1.4541, -4.2401],
        [-2.7983, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26925989985466003
Epoch 0, Step 1913: train/loss = 0.2998993396759033, train/raw-loss = 0.2548142671585083, train/logprobs = tensor([[-0.9976, -4.3217],
        [-2.7120, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22542524337768555
Epoch 0, Step 1914: train/loss = 0.14669883251190186, train/raw-loss = 0.1006956547498703, train/logprobs = tensor([[ -1.1199, -11.6274],
        [ -3.0224,  -2.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23001588881015778
Epoch 0, Step 1915: train/loss = 0.16919580101966858, train/raw-loss = 0.12413490563631058, train/logprobs = tensor([[ -1.2226, -11.3991],
        [ -2.7800,  -1.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22530454397201538
Epoch 0, Step 1916: train/loss = 0.4128114581108093, train/raw-loss = 0.35253840684890747, train/logprobs = tensor([[-0.8685, -4.0190],
        [-2.4030, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30136528611183167
Epoch 0, Step 1917: train/loss = 0.5814801454544067, train/raw-loss = 0.541985034942627, train/logprobs = tensor([[-1.6830, -3.6304],
        [-1.6500, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19747546315193176
Epoch 0, Step 1918: train/loss = 0.20452742278575897, train/raw-loss = 0.14483730494976044, train/logprobs = tensor([[-1.2930, -6.2431],
        [-3.7240, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29845061898231506
Epoch 0, Step 1919: train/loss = 0.17671003937721252, train/raw-loss = 0.12497923523187637, train/logprobs = tensor([[-1.2669, -9.5182],
        [-2.7629, -1.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2586539387702942
Epoch 0, Step 1920: train/loss = 0.2150323987007141, train/raw-loss = 0.168570876121521, train/logprobs = tensor([[-0.9763, -6.4838],
        [-2.6010, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23230764269828796
Epoch 0, Step 1921: train/loss = 0.27967706322669983, train/raw-loss = 0.230991393327713, train/logprobs = tensor([[ -0.7321, -10.8435],
        [ -2.9807,  -2.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24342840909957886
Epoch 0, Step 1922: train/loss = 0.12450134754180908, train/raw-loss = 0.07331101596355438, train/logprobs = tensor([[-1.0838, -9.4142],
        [-3.4715, -1.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559516429901123
Epoch 0, Step 1923: train/loss = 0.26896071434020996, train/raw-loss = 0.2233360856771469, train/logprobs = tensor([[ -0.7959, -10.0042],
        [ -2.2588,  -1.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22812306880950928
Epoch 0, Step 1924: train/loss = 0.1570519208908081, train/raw-loss = 0.10083907842636108, train/logprobs = tensor([[-1.0640, -7.9127],
        [-2.6305, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28106415271759033
Epoch 0, Step 1925: train/loss = 0.29818445444107056, train/raw-loss = 0.24995364248752594, train/logprobs = tensor([[-1.1407, -9.4333],
        [-2.5067, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2411540001630783
Epoch 0, Step 1926: train/loss = 0.36995524168014526, train/raw-loss = 0.3299049139022827, train/logprobs = tensor([[-1.1240, -4.6417],
        [-2.0322, -1.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20025157928466797
Epoch 0, Step 1927: train/loss = 0.2312709093093872, train/raw-loss = 0.17609918117523193, train/logprobs = tensor([[-1.5853, -7.9310],
        [-2.5813, -1.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.275858610868454
Epoch 0, Step 1928: train/loss = 0.37920260429382324, train/raw-loss = 0.3377191424369812, train/logprobs = tensor([[-0.9421, -4.8626],
        [-1.9564, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20741727948188782
Epoch 0, Step 1929: train/loss = 0.31017881631851196, train/raw-loss = 0.26166269183158875, train/logprobs = tensor([[-0.9511, -6.2820],
        [-1.8486, -0.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2425806224346161
Epoch 0, Step 1930: train/loss = 0.49204400181770325, train/raw-loss = 0.4463783800601959, train/logprobs = tensor([[-1.1471, -5.3762],
        [-0.8737, -1.5157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22832807898521423
Epoch 0, Step 1931: train/loss = 0.5900325179100037, train/raw-loss = 0.5487329363822937, train/logprobs = tensor([[-1.4975, -4.6858],
        [-1.5378, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20649784803390503
Epoch 0, Step 1932: train/loss = 0.4406962990760803, train/raw-loss = 0.3921118974685669, train/logprobs = tensor([[-1.2078, -4.8561],
        [-2.5142, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2429220825433731
Epoch 0, Step 1933: train/loss = 0.5386667251586914, train/raw-loss = 0.4897167682647705, train/logprobs = tensor([[-1.7501, -4.3597],
        [-1.8897, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24474984407424927
Epoch 0, Step 1934: train/loss = 0.4644119441509247, train/raw-loss = 0.4155673384666443, train/logprobs = tensor([[-1.3107, -3.6570],
        [-1.7678, -1.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2442229837179184
Epoch 0, Step 1935: train/loss = 0.23546400666236877, train/raw-loss = 0.19201749563217163, train/logprobs = tensor([[-1.1731, -6.1075],
        [-3.0097, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2172326147556305
Epoch 0, Step 1936: train/loss = 0.23088045418262482, train/raw-loss = 0.17308981716632843, train/logprobs = tensor([[ -1.0058, -13.3837],
        [ -2.2871,  -1.3042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28895309567451477
Epoch 0, Step 1937: train/loss = 0.6169089674949646, train/raw-loss = 0.5738130807876587, train/logprobs = tensor([[-1.4039, -1.6569],
        [-2.2405, -1.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21547935903072357
Epoch 0, Step 1938: train/loss = 0.8125890493392944, train/raw-loss = 0.7622014880180359, train/logprobs = tensor([[-3.3279, -6.6097],
        [-2.0414, -2.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25193774700164795
Epoch 0, Step 1939: train/loss = 0.4400893449783325, train/raw-loss = 0.3987202048301697, train/logprobs = tensor([[-0.9222, -3.2156],
        [-1.2083, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20684565603733063
Epoch 0, Step 1940: train/loss = 0.4682355523109436, train/raw-loss = 0.4237816631793976, train/logprobs = tensor([[-1.6453, -6.5097],
        [-1.9480, -1.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2222694456577301
Epoch 0, Step 1941: train/loss = 0.7549178004264832, train/raw-loss = 0.6958627700805664, train/logprobs = tensor([[-2.4728, -4.2034],
        [-2.6716, -2.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952749729156494
Epoch 0, Step 1942: train/loss = 0.30812016129493713, train/raw-loss = 0.2522469162940979, train/logprobs = tensor([[-1.6254, -7.3066],
        [-3.1711, -1.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27936631441116333
Epoch 0, Step 1943: train/loss = 0.2602963447570801, train/raw-loss = 0.20717264711856842, train/logprobs = tensor([[-0.8495, -7.9626],
        [-2.8956, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26561853289604187
Epoch 0, Step 1944: train/loss = 0.5045261383056641, train/raw-loss = 0.46153122186660767, train/logprobs = tensor([[-1.1352, -2.4549],
        [-1.9461, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21497491002082825
Epoch 0, Step 1945: train/loss = 0.4070679545402527, train/raw-loss = 0.3588525354862213, train/logprobs = tensor([[-0.7550, -3.3795],
        [-2.0268, -1.0436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24107713997364044
Epoch 0, Step 1946: train/loss = 0.6622893810272217, train/raw-loss = 0.604681670665741, train/logprobs = tensor([[-2.6574, -6.8147],
        [-2.1499, -3.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2880384922027588
Epoch 0, Step 1947: train/loss = 0.5157402157783508, train/raw-loss = 0.47065669298171997, train/logprobs = tensor([[-1.0987, -1.8403],
        [-1.6803, -1.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22541770339012146
Epoch 0, Step 1948: train/loss = 0.31816622614860535, train/raw-loss = 0.27868178486824036, train/logprobs = tensor([[-0.7034, -7.0768],
        [-1.3833, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19742223620414734
Epoch 0, Step 1949: train/loss = 0.35404518246650696, train/raw-loss = 0.31063345074653625, train/logprobs = tensor([[-1.1083, -5.0765],
        [-1.8209, -1.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21705873310565948
Epoch 0, Step 1950: train/loss = 0.31558987498283386, train/raw-loss = 0.27169209718704224, train/logprobs = tensor([[-1.3913, -8.7134],
        [-1.8050, -1.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2194889336824417
Epoch 0, Step 1951: train/loss = 0.25264519453048706, train/raw-loss = 0.2080741673707962, train/logprobs = tensor([[-1.0533, -5.3660],
        [-3.0060, -1.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22285515069961548
Epoch 0, Step 1952: train/loss = 0.3620377480983734, train/raw-loss = 0.31230226159095764, train/logprobs = tensor([[-1.0896, -4.3192],
        [-3.2548, -2.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24867740273475647
Epoch 0, Step 1953: train/loss = 0.4485679268836975, train/raw-loss = 0.4068148732185364, train/logprobs = tensor([[-1.2155, -8.5279],
        [-1.8426, -2.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087654024362564
Epoch 0, Step 1954: train/loss = 0.24445980787277222, train/raw-loss = 0.1999826282262802, train/logprobs = tensor([[-1.2330, -9.0253],
        [-2.3587, -1.2204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2223859280347824
Epoch 0, Step 1955: train/loss = 0.2622876763343811, train/raw-loss = 0.2120787501335144, train/logprobs = tensor([[-2.0010, -6.6886],
        [-2.9356, -1.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25104445219039917
Epoch 0, Step 1956: train/loss = 0.4270815849304199, train/raw-loss = 0.3710653781890869, train/logprobs = tensor([[-0.9910, -5.0242],
        [-2.3565, -3.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800811529159546
Epoch 0, Step 1957: train/loss = 0.3667336106300354, train/raw-loss = 0.3149920105934143, train/logprobs = tensor([[-1.0146, -6.9242],
        [-2.8373, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25870800018310547
Epoch 0, Step 1958: train/loss = 0.20891273021697998, train/raw-loss = 0.1580267995595932, train/logprobs = tensor([[ -1.7047, -12.6210],
        [ -3.1927,  -2.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544296383857727
Epoch 0, Step 1959: train/loss = 0.2473442405462265, train/raw-loss = 0.19324737787246704, train/logprobs = tensor([[ -1.2271, -10.0935],
        [ -3.0159,  -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2704842984676361
Epoch 0, Step 1960: train/loss = 0.2656852602958679, train/raw-loss = 0.21378734707832336, train/logprobs = tensor([[-1.0662, -9.6237],
        [-2.8327, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25948959589004517
Epoch 0, Step 1961: train/loss = 0.14537176489830017, train/raw-loss = 0.08993835747241974, train/logprobs = tensor([[-0.9636, -9.2100],
        [-2.5594, -1.2768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2771669924259186
Epoch 0, Step 1962: train/loss = 0.5474650859832764, train/raw-loss = 0.4887123107910156, train/logprobs = tensor([[-0.8568, -2.0132],
        [-1.6756, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937638461589813
Epoch 0, Step 1963: train/loss = 0.34907495975494385, train/raw-loss = 0.2979782223701477, train/logprobs = tensor([[-0.9882, -7.4141],
        [-1.9088, -1.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25548383593559265
Epoch 0, Step 1964: train/loss = 0.2761901319026947, train/raw-loss = 0.2313104271888733, train/logprobs = tensor([[-0.7472, -6.1387],
        [-1.9293, -1.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22439859807491302
Epoch 0, Step 1965: train/loss = 0.5072567462921143, train/raw-loss = 0.4588163495063782, train/logprobs = tensor([[-1.0134, -2.8443],
        [-1.4919, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24220187962055206
Epoch 0, Step 1966: train/loss = 0.16220517456531525, train/raw-loss = 0.11355559527873993, train/logprobs = tensor([[ -1.2577, -16.5354],
        [ -2.5796,  -2.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.243247851729393
Epoch 0, Step 1967: train/loss = 0.44796356558799744, train/raw-loss = 0.39571890234947205, train/logprobs = tensor([[-2.1094, -6.7230],
        [-1.9217, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26122334599494934
Epoch 0, Step 1968: train/loss = 0.44217100739479065, train/raw-loss = 0.39732110500335693, train/logprobs = tensor([[-1.2058, -5.1040],
        [-2.5448, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22424955666065216
Epoch 0, Step 1969: train/loss = 0.21311436593532562, train/raw-loss = 0.16204853355884552, train/logprobs = tensor([[ -1.0107, -11.2912],
        [ -3.1571,  -1.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553291916847229
Epoch 0, Step 1970: train/loss = 0.29339030385017395, train/raw-loss = 0.24119089543819427, train/logprobs = tensor([[-1.5023, -8.7432],
        [-2.0515, -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609969973564148
Epoch 0, Step 1971: train/loss = 0.26332610845565796, train/raw-loss = 0.21884122490882874, train/logprobs = tensor([[-0.8279, -6.0481],
        [-2.3528, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2224244475364685
Epoch 0, Step 1972: train/loss = 0.2259078323841095, train/raw-loss = 0.16366241872310638, train/logprobs = tensor([[-1.2102, -7.1612],
        [-3.4353, -1.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31122705340385437
Epoch 0, Step 1973: train/loss = 0.2880838215351105, train/raw-loss = 0.2322697937488556, train/logprobs = tensor([[-1.3853, -7.7466],
        [-3.5423, -1.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790701687335968
Epoch 0, Step 1974: train/loss = 0.263239324092865, train/raw-loss = 0.21002164483070374, train/logprobs = tensor([[-1.1569, -6.9582],
        [-2.3299, -1.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2660883367061615
Epoch 0, Step 1975: train/loss = 0.5183910131454468, train/raw-loss = 0.47641289234161377, train/logprobs = tensor([[-0.9628, -3.6934],
        [-1.8789, -1.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20989084243774414
Epoch 0, Step 1976: train/loss = 0.29586565494537354, train/raw-loss = 0.24332314729690552, train/logprobs = tensor([[-1.1202, -8.4893],
        [-2.2351, -2.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26271262764930725
Epoch 0, Step 1977: train/loss = 0.14894388616085052, train/raw-loss = 0.09828832745552063, train/logprobs = tensor([[ -1.4286, -14.5915],
        [ -3.0652,  -2.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532777786254883
Epoch 0, Step 1978: train/loss = 0.23256343603134155, train/raw-loss = 0.17853529751300812, train/logprobs = tensor([[-0.9965, -6.0035],
        [-2.3187, -1.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27014070749282837
Epoch 0, Step 1979: train/loss = 0.40984001755714417, train/raw-loss = 0.35436320304870605, train/logprobs = tensor([[-1.2751, -5.8284],
        [-2.4101, -1.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2773840129375458
Epoch 0, Step 1980: train/loss = 0.30440595746040344, train/raw-loss = 0.25031131505966187, train/logprobs = tensor([[-1.6983, -6.6900],
        [-3.0224, -1.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2704732418060303
Epoch 0, Step 1981: train/loss = 0.1679135113954544, train/raw-loss = 0.11587837338447571, train/logprobs = tensor([[ -1.0183, -10.5012],
        [ -2.9875,  -2.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601756751537323
Epoch 0, Step 1982: train/loss = 0.47606146335601807, train/raw-loss = 0.4291967451572418, train/logprobs = tensor([[-1.8072, -2.9456],
        [-2.1432, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343233972787857
Epoch 0, Step 1983: train/loss = 0.4600326120853424, train/raw-loss = 0.42007654905319214, train/logprobs = tensor([[-0.7612, -2.4842],
        [-1.4377, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1997803896665573
Epoch 0, Step 1984: train/loss = 0.24446994066238403, train/raw-loss = 0.1941160261631012, train/logprobs = tensor([[-1.7232, -9.7056],
        [-2.6140, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517695724964142
Epoch 0, Step 1985: train/loss = 0.40396618843078613, train/raw-loss = 0.35829636454582214, train/logprobs = tensor([[-1.3992, -3.7236],
        [-2.0551, -1.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22834910452365875
Epoch 0, Step 1986: train/loss = 0.5983067154884338, train/raw-loss = 0.5592854022979736, train/logprobs = tensor([[-1.2990, -4.2896],
        [-1.4069, -1.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1951066106557846
Epoch 0, Step 1987: train/loss = 0.47453272342681885, train/raw-loss = 0.4280953109264374, train/logprobs = tensor([[-1.9612, -6.8983],
        [-2.2946, -3.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23218703269958496
Epoch 0, Step 1988: train/loss = 0.4683719873428345, train/raw-loss = 0.4351394772529602, train/logprobs = tensor([[-0.5064, -3.8530],
        [-1.3214, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16616255044937134
Epoch 0, Step 1989: train/loss = 0.45500463247299194, train/raw-loss = 0.4048044979572296, train/logprobs = tensor([[-1.3279, -5.5478],
        [-1.1910, -1.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25100067257881165
Epoch 0, Step 1990: train/loss = 0.1760951578617096, train/raw-loss = 0.12484824657440186, train/logprobs = tensor([[ -1.0105, -13.4087],
        [ -2.8171,  -2.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562345564365387
Epoch 0, Step 1991: train/loss = 0.268410861492157, train/raw-loss = 0.2218519151210785, train/logprobs = tensor([[-1.2466, -8.5899],
        [-2.4756, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23279476165771484
Epoch 0, Step 1992: train/loss = 0.45433616638183594, train/raw-loss = 0.39358505606651306, train/logprobs = tensor([[-1.7127, -6.4432],
        [-2.2459, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30375584959983826
Epoch 0, Step 1993: train/loss = 0.5166398882865906, train/raw-loss = 0.46606484055519104, train/logprobs = tensor([[-1.7909, -5.9212],
        [-1.5795, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25287511944770813
Epoch 0, Step 1994: train/loss = 0.2906537652015686, train/raw-loss = 0.24184751510620117, train/logprobs = tensor([[-0.8121, -6.1826],
        [-2.3109, -1.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440314143896103
Epoch 0, Step 1995: train/loss = 0.20025116205215454, train/raw-loss = 0.15093158185482025, train/logprobs = tensor([[-1.1870, -6.9903],
        [-2.8893, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24659788608551025
Epoch 0, Step 1996: train/loss = 0.41227829456329346, train/raw-loss = 0.37379711866378784, train/logprobs = tensor([[-1.1396, -3.4176],
        [-2.1373, -1.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19240586459636688
Epoch 0, Step 1997: train/loss = 0.3460945188999176, train/raw-loss = 0.28904443979263306, train/logprobs = tensor([[-0.9996, -7.1816],
        [-2.5258, -1.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2852504551410675
Epoch 0, Step 1998: train/loss = 0.559964656829834, train/raw-loss = 0.5145103931427002, train/logprobs = tensor([[-1.2114, -3.4716],
        [-1.6731, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22727122902870178
Epoch 0, Step 1999: train/loss = 0.6572167873382568, train/raw-loss = 0.6153384447097778, train/logprobs = tensor([[-2.8514, -4.0583],
        [-2.2458, -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20939166843891144
Epoch 0, Step 2000: train/loss = 0.5024874806404114, train/raw-loss = 0.4631492793560028, train/logprobs = tensor([[-1.0122, -3.0427],
        [-1.2955, -1.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1966911107301712
Epoch 0, Step 2001: train/loss = 0.4777074158191681, train/raw-loss = 0.42330145835876465, train/logprobs = tensor([[-1.3886, -2.8477],
        [-2.4464, -1.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720296084880829
Epoch 0, Step 2002: train/loss = 0.2729901671409607, train/raw-loss = 0.2348046898841858, train/logprobs = tensor([[-1.0699, -7.6586],
        [-1.9765, -1.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19092759490013123
Epoch 0, Step 2003: train/loss = 0.36090415716171265, train/raw-loss = 0.30296409130096436, train/logprobs = tensor([[-2.0802, -6.6130],
        [-2.4792, -1.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897002398967743
Epoch 0, Step 2004: train/loss = 0.18062445521354675, train/raw-loss = 0.13368171453475952, train/logprobs = tensor([[ -0.7590, -10.2179],
        [ -2.0663,  -1.4407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23471377789974213
Epoch 0, Step 2005: train/loss = 0.12072274833917618, train/raw-loss = 0.06660476326942444, train/logprobs = tensor([[ -1.2529, -11.8478],
        [ -3.7385,  -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705899178981781
Epoch 0, Step 2006: train/loss = 0.30998629331588745, train/raw-loss = 0.2735685110092163, train/logprobs = tensor([[ -0.9602, -12.6538],
        [ -1.7376,  -1.4298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18208904564380646
Epoch 0, Step 2007: train/loss = 0.3704996705055237, train/raw-loss = 0.32201889157295227, train/logprobs = tensor([[-0.8022, -3.8253],
        [-1.7793, -1.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24240410327911377
Epoch 0, Step 2008: train/loss = 0.4112106263637543, train/raw-loss = 0.3670247197151184, train/logprobs = tensor([[-1.2495, -5.5525],
        [-2.3460, -1.3255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22092944383621216
Epoch 0, Step 2009: train/loss = 0.6043449640274048, train/raw-loss = 0.5485500693321228, train/logprobs = tensor([[-2.3610, -6.1125],
        [-1.7575, -2.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789745628833771
Epoch 0, Step 2010: train/loss = 0.30921289324760437, train/raw-loss = 0.26563724875450134, train/logprobs = tensor([[-1.3688, -8.1188],
        [-2.3147, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21787823736667633
Epoch 0, Step 2011: train/loss = 0.20788408815860748, train/raw-loss = 0.16736599802970886, train/logprobs = tensor([[-0.7008, -4.7616],
        [-2.3928, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20259051024913788
Epoch 0, Step 2012: train/loss = 0.4247855544090271, train/raw-loss = 0.3753361701965332, train/logprobs = tensor([[-1.0562, -4.6224],
        [-1.8841, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24724692106246948
Epoch 0, Step 2013: train/loss = 0.5020288825035095, train/raw-loss = 0.4597172737121582, train/logprobs = tensor([[-0.9153, -1.7160],
        [-1.6131, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21155813336372375
Epoch 0, Step 2014: train/loss = 0.5017024874687195, train/raw-loss = 0.44779083132743835, train/logprobs = tensor([[-2.3829, -8.5909],
        [-3.1536, -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26955825090408325
Epoch 0, Step 2015: train/loss = 0.4790438413619995, train/raw-loss = 0.43284177780151367, train/logprobs = tensor([[-0.9352, -3.0800],
        [-1.3454, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23101019859313965
Epoch 0, Step 2016: train/loss = 0.3171634078025818, train/raw-loss = 0.26713085174560547, train/logprobs = tensor([[-1.4506, -4.8790],
        [-2.5542, -1.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25016269087791443
Epoch 0, Step 2017: train/loss = 0.19634754955768585, train/raw-loss = 0.14888259768486023, train/logprobs = tensor([[-1.2089, -9.1315],
        [-2.2027, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23732472956180573
Epoch 0, Step 2018: train/loss = 0.23415668308734894, train/raw-loss = 0.18047930300235748, train/logprobs = tensor([[-1.2991, -9.4406],
        [-2.9507, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2683869004249573
Epoch 0, Step 2019: train/loss = 0.31840357184410095, train/raw-loss = 0.27715814113616943, train/logprobs = tensor([[-0.9076, -5.6005],
        [-1.4181, -1.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20622709393501282
Epoch 0, Step 2020: train/loss = 0.723378598690033, train/raw-loss = 0.6755451560020447, train/logprobs = tensor([[-1.7354, -2.3843],
        [-1.4993, -0.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23916688561439514
Epoch 0, Step 2021: train/loss = 0.41681814193725586, train/raw-loss = 0.3804813325405121, train/logprobs = tensor([[-0.4729, -5.0800],
        [-0.9581, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18168392777442932
Epoch 0, Step 2022: train/loss = 0.47470521926879883, train/raw-loss = 0.4222390949726105, train/logprobs = tensor([[-1.0010, -3.3951],
        [-2.5356, -1.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623306214809418
Epoch 0, Step 2023: train/loss = 0.2474949061870575, train/raw-loss = 0.19233238697052002, train/logprobs = tensor([[-1.2783, -7.7816],
        [-3.6637, -1.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758125066757202
Epoch 0, Step 2024: train/loss = 0.13072176277637482, train/raw-loss = 0.07644516974687576, train/logprobs = tensor([[ -1.1645, -11.2814],
        [ -3.1298,  -2.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713829576969147
Epoch 0, Step 2025: train/loss = 0.5188617706298828, train/raw-loss = 0.4695476293563843, train/logprobs = tensor([[-2.2079, -7.6137],
        [-2.4086, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24657076597213745
Epoch 0, Step 2026: train/loss = 0.16011233627796173, train/raw-loss = 0.10856388509273529, train/logprobs = tensor([[-0.7969, -8.3759],
        [-2.2271, -1.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2577422857284546
Epoch 0, Step 2027: train/loss = 0.2530601918697357, train/raw-loss = 0.2035669982433319, train/logprobs = tensor([[-0.6899, -4.7975],
        [-1.6208, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24746586382389069
Epoch 0, Step 2028: train/loss = 0.3123699724674225, train/raw-loss = 0.269278347492218, train/logprobs = tensor([[-1.3040, -5.8453],
        [-2.2088, -1.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21545828878879547
Epoch 0, Step 2029: train/loss = 0.5205968618392944, train/raw-loss = 0.47325295209884644, train/logprobs = tensor([[-0.8941, -1.6092],
        [-1.4389, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23671932518482208
Epoch 0, Step 2030: train/loss = 0.2510594427585602, train/raw-loss = 0.19754458963871002, train/logprobs = tensor([[-0.9901, -7.1830],
        [-2.3846, -0.6891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2675743103027344
Epoch 0, Step 2031: train/loss = 0.5930760502815247, train/raw-loss = 0.5516865253448486, train/logprobs = tensor([[-0.7947, -1.1650],
        [-1.1211, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20694732666015625
Epoch 0, Step 2032: train/loss = 0.37791064381599426, train/raw-loss = 0.3374462127685547, train/logprobs = tensor([[-1.9274, -6.4780],
        [-2.3465, -0.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2023220956325531
Epoch 0, Step 2033: train/loss = 0.791383683681488, train/raw-loss = 0.7528741359710693, train/logprobs = tensor([[-1.8625, -1.8952],
        [-0.9710, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19254738092422485
Epoch 0, Step 2034: train/loss = 0.41171571612358093, train/raw-loss = 0.36676502227783203, train/logprobs = tensor([[-0.9297, -4.1659],
        [-1.6641, -1.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22475355863571167
Epoch 0, Step 2035: train/loss = 0.46392419934272766, train/raw-loss = 0.420696496963501, train/logprobs = tensor([[-1.8181, -6.1461],
        [-1.8053, -0.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21613852679729462
Epoch 0, Step 2036: train/loss = 0.20171670615673065, train/raw-loss = 0.14806216955184937, train/logprobs = tensor([[ -1.2721, -11.9863],
        [ -2.4834,  -1.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26827263832092285
Epoch 0, Step 2037: train/loss = 0.2596089839935303, train/raw-loss = 0.21352139115333557, train/logprobs = tensor([[-1.1411, -9.1217],
        [-1.9109, -1.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23043790459632874
Epoch 0, Step 2038: train/loss = 0.3279939293861389, train/raw-loss = 0.26736754179000854, train/logprobs = tensor([[-1.1975, -6.5865],
        [-2.4354, -1.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30313193798065186
Epoch 0, Step 2039: train/loss = 0.353656142950058, train/raw-loss = 0.31075233221054077, train/logprobs = tensor([[-1.2641, -4.7309],
        [-2.0039, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21451902389526367
Epoch 0, Step 2040: train/loss = 0.38924720883369446, train/raw-loss = 0.34638336300849915, train/logprobs = tensor([[-1.2066, -5.3265],
        [-1.5287, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21431930363178253
Epoch 0, Step 2041: train/loss = 0.206858292222023, train/raw-loss = 0.16495314240455627, train/logprobs = tensor([[-0.8705, -8.2030],
        [-2.8714, -2.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20952585339546204
Epoch 0, Step 2042: train/loss = 0.21297413110733032, train/raw-loss = 0.16306369006633759, train/logprobs = tensor([[-1.0008, -9.0439],
        [-2.3036, -1.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495521754026413
Epoch 0, Step 2043: train/loss = 0.42941442131996155, train/raw-loss = 0.38169652223587036, train/logprobs = tensor([[ -1.1519, -10.1072],
        [ -2.3388,  -1.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2385895848274231
Epoch 0, Step 2044: train/loss = 0.7291679382324219, train/raw-loss = 0.6619759798049927, train/logprobs = tensor([[-3.5457, -5.1061],
        [-4.0978, -1.4229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33596014976501465
Epoch 0, Step 2045: train/loss = 0.4256467819213867, train/raw-loss = 0.38497844338417053, train/logprobs = tensor([[-0.9445, -2.4477],
        [-1.6094, -1.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033417969942093
Epoch 0, Step 2046: train/loss = 0.2127220630645752, train/raw-loss = 0.17959138751029968, train/logprobs = tensor([[ -0.4448, -10.5140],
        [ -1.1238,  -1.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1656533032655716
Epoch 0, Step 2047: train/loss = 0.39446625113487244, train/raw-loss = 0.3452339470386505, train/logprobs = tensor([[-2.5008, -8.3628],
        [-3.4370, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24616126716136932
Epoch 0, Step 2048: train/loss = 0.3369150757789612, train/raw-loss = 0.28920841217041016, train/logprobs = tensor([[-1.3837, -7.3744],
        [-1.6159, -1.2198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23853343725204468
Epoch 0, Step 2049: train/loss = 0.31424111127853394, train/raw-loss = 0.26410385966300964, train/logprobs = tensor([[-1.3487, -5.5546],
        [-3.2303, -1.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506862282752991
Epoch 0, Step 2050: train/loss = 0.17173460125923157, train/raw-loss = 0.11235339194536209, train/logprobs = tensor([[-1.1891, -5.9798],
        [-2.6109, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2969059944152832
Epoch 0, Step 2051: train/loss = 0.29887789487838745, train/raw-loss = 0.2552189826965332, train/logprobs = tensor([[-0.7632, -9.1648],
        [-1.8892, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21829448640346527
Epoch 0, Step 2052: train/loss = 0.42336082458496094, train/raw-loss = 0.36098241806030273, train/logprobs = tensor([[-1.4227, -4.1998],
        [-3.6261, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31189218163490295
Epoch 0, Step 2053: train/loss = 0.553284227848053, train/raw-loss = 0.48386192321777344, train/logprobs = tensor([[-2.7056, -6.1394],
        [-1.9923, -3.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3471115827560425
Epoch 0, Step 2054: train/loss = 0.42724865674972534, train/raw-loss = 0.3786263167858124, train/logprobs = tensor([[-1.3047, -2.2378],
        [-2.3246, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24311169981956482
Epoch 0, Step 2055: train/loss = 0.3505993187427521, train/raw-loss = 0.31316518783569336, train/logprobs = tensor([[-1.3605, -6.1229],
        [-1.4661, -0.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18717089295387268
Epoch 0, Step 2056: train/loss = 0.29473909735679626, train/raw-loss = 0.2517147660255432, train/logprobs = tensor([[-1.2384, -2.8660],
        [-3.4036, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21512161195278168
Epoch 0, Step 2057: train/loss = 0.5299375057220459, train/raw-loss = 0.4795686900615692, train/logprobs = tensor([[-1.0142, -2.6356],
        [-2.2486, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25184398889541626
Epoch 0, Step 2058: train/loss = 0.16766676306724548, train/raw-loss = 0.10393668711185455, train/logprobs = tensor([[-1.1681, -9.0042],
        [-3.6670, -1.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31865033507347107
Epoch 0, Step 2059: train/loss = 0.2550663948059082, train/raw-loss = 0.19566906988620758, train/logprobs = tensor([[-1.1099, -9.9257],
        [-2.8622, -2.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2969866394996643
Epoch 0, Step 2060: train/loss = 0.36138153076171875, train/raw-loss = 0.31194376945495605, train/logprobs = tensor([[-1.7781, -4.7041],
        [-2.1442, -1.3068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2471889853477478
Epoch 0, Step 2061: train/loss = 0.25454699993133545, train/raw-loss = 0.20601962506771088, train/logprobs = tensor([[-1.2759, -8.7560],
        [-3.0157, -1.2089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24263690412044525
Epoch 0, Step 2062: train/loss = 0.25774845480918884, train/raw-loss = 0.19132106006145477, train/logprobs = tensor([[-1.7969, -5.6838],
        [-3.0568, -0.7892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33213695883750916
Epoch 0, Step 2063: train/loss = 0.399141788482666, train/raw-loss = 0.3464687764644623, train/logprobs = tensor([[-1.0580, -4.0290],
        [-2.6333, -1.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633649408817291
Epoch 0, Step 2064: train/loss = 0.6152105331420898, train/raw-loss = 0.5622726082801819, train/logprobs = tensor([[-2.3617, -5.4384],
        [-2.2848, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26468950510025024
Epoch 0, Step 2065: train/loss = 0.21055671572685242, train/raw-loss = 0.16627272963523865, train/logprobs = tensor([[ -1.2128, -11.0547],
        [ -2.2509,  -1.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22141997516155243
Epoch 0, Step 2066: train/loss = 0.3349608778953552, train/raw-loss = 0.2802055776119232, train/logprobs = tensor([[-1.1267, -6.3723],
        [-2.4089, -1.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2737763226032257
Epoch 0, Step 2067: train/loss = 0.45036429166793823, train/raw-loss = 0.4013558030128479, train/logprobs = tensor([[-1.7534, -6.0618],
        [-2.0757, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2450423240661621
Epoch 0, Step 2068: train/loss = 0.5864226818084717, train/raw-loss = 0.5368627309799194, train/logprobs = tensor([[-1.3262, -4.5065],
        [-2.2285, -1.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24780017137527466
Epoch 0, Step 2069: train/loss = 0.3885563313961029, train/raw-loss = 0.34114229679107666, train/logprobs = tensor([[-0.8616, -4.2228],
        [-2.0392, -1.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2370702177286148
Epoch 0, Step 2070: train/loss = 0.13873103260993958, train/raw-loss = 0.09032968431711197, train/logprobs = tensor([[ -1.7297, -12.2653],
        [ -3.6291,  -0.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24200673401355743
Epoch 0, Step 2071: train/loss = 0.4384101927280426, train/raw-loss = 0.3808828592300415, train/logprobs = tensor([[-1.4392, -4.9129],
        [-2.0151, -1.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876366972923279
Epoch 0, Step 2072: train/loss = 0.22594474256038666, train/raw-loss = 0.16929690539836884, train/logprobs = tensor([[-1.3409, -7.9109],
        [-2.7162, -0.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832391560077667
Epoch 0, Step 2073: train/loss = 0.300324410200119, train/raw-loss = 0.24176016449928284, train/logprobs = tensor([[-1.4440, -5.5474],
        [-2.3834, -2.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2928210496902466
Epoch 0, Step 2074: train/loss = 0.4125019609928131, train/raw-loss = 0.36216244101524353, train/logprobs = tensor([[-1.0707, -3.5699],
        [-2.3906, -1.6825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.251697301864624
Epoch 0, Step 2075: train/loss = 0.4942629635334015, train/raw-loss = 0.4425480365753174, train/logprobs = tensor([[-1.2451, -3.1824],
        [-2.2216, -1.7305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585747539997101
Epoch 0, Step 2076: train/loss = 0.38569074869155884, train/raw-loss = 0.33780279755592346, train/logprobs = tensor([[-1.9651, -9.8980],
        [-2.4684, -2.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23943954706192017
Epoch 0, Step 2077: train/loss = 0.2688137888908386, train/raw-loss = 0.21944108605384827, train/logprobs = tensor([[-1.0227, -7.7984],
        [-2.1731, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24686360359191895
Epoch 0, Step 2078: train/loss = 0.2289240062236786, train/raw-loss = 0.17651262879371643, train/logprobs = tensor([[-1.6100, -5.8447],
        [-2.8057, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26205676794052124
Epoch 0, Step 2079: train/loss = 0.3338110148906708, train/raw-loss = 0.2852381467819214, train/logprobs = tensor([[-0.8168, -6.2656],
        [-1.8490, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24286437034606934
Epoch 0, Step 2080: train/loss = 0.19999279081821442, train/raw-loss = 0.15398050844669342, train/logprobs = tensor([[-1.2434, -7.8009],
        [-2.7075, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23006145656108856
Epoch 0, Step 2081: train/loss = 0.3316202759742737, train/raw-loss = 0.2727613151073456, train/logprobs = tensor([[-1.6095, -4.5313],
        [-3.2121, -1.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29429468512535095
Epoch 0, Step 2082: train/loss = 0.213329017162323, train/raw-loss = 0.16365835070610046, train/logprobs = tensor([[ -1.0791, -13.3970],
        [ -2.6442,  -1.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24835331737995148
Epoch 0, Step 2083: train/loss = 0.45361122488975525, train/raw-loss = 0.4021661877632141, train/logprobs = tensor([[-1.4892, -3.1011],
        [-2.3816, -1.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25722527503967285
Epoch 0, Step 2084: train/loss = 0.20673292875289917, train/raw-loss = 0.15976297855377197, train/logprobs = tensor([[-1.1606, -8.3287],
        [-3.5110, -0.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23484978079795837
Epoch 0, Step 2085: train/loss = 0.48787587881088257, train/raw-loss = 0.4555501639842987, train/logprobs = tensor([[-1.3781, -4.0514],
        [-1.5598, -2.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16162841022014618
Epoch 0, Step 2086: train/loss = 0.3346877098083496, train/raw-loss = 0.2916989326477051, train/logprobs = tensor([[-0.7229, -5.6781],
        [-1.4909, -1.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21494385600090027
Epoch 0, Step 2087: train/loss = 0.1250733733177185, train/raw-loss = 0.07227084040641785, train/logprobs = tensor([[ -1.6217, -16.3481],
        [ -3.5829,  -1.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26401272416114807
Epoch 0, Step 2088: train/loss = 0.40429437160491943, train/raw-loss = 0.35497164726257324, train/logprobs = tensor([[-0.8065, -9.7290],
        [-2.3588, -1.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2466137409210205
Epoch 0, Step 2089: train/loss = 0.5892568826675415, train/raw-loss = 0.5436334609985352, train/logprobs = tensor([[-2.0180, -4.4386],
        [-1.7579, -1.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22811730206012726
Epoch 0, Step 2090: train/loss = 0.5094820857048035, train/raw-loss = 0.46736806631088257, train/logprobs = tensor([[-1.8828, -3.8636],
        [-2.1189, -1.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21057042479515076
Epoch 0, Step 2091: train/loss = 0.3439576029777527, train/raw-loss = 0.30264925956726074, train/logprobs = tensor([[-1.1322, -4.3461],
        [-1.6272, -1.3384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20654156804084778
Epoch 0, Step 2092: train/loss = 0.13477228581905365, train/raw-loss = 0.08015831559896469, train/logprobs = tensor([[-1.0340, -8.3264],
        [-2.8498, -1.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730697989463806
Epoch 0, Step 2093: train/loss = 0.6675090789794922, train/raw-loss = 0.6219509840011597, train/logprobs = tensor([[-2.9194, -6.6075],
        [-2.3219, -1.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2277906835079193
Epoch 0, Step 2094: train/loss = 0.22388863563537598, train/raw-loss = 0.17372018098831177, train/logprobs = tensor([[ -0.9097, -10.0701],
        [ -2.6599,  -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508423924446106
Epoch 0, Step 2095: train/loss = 0.4368453621864319, train/raw-loss = 0.37994277477264404, train/logprobs = tensor([[-1.2585, -5.8986],
        [-2.6082, -1.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845129370689392
Epoch 0, Step 2096: train/loss = 0.43263787031173706, train/raw-loss = 0.3872905373573303, train/logprobs = tensor([[-1.6702, -8.3684],
        [-2.3048, -1.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2267366200685501
Epoch 0, Step 2097: train/loss = 0.41231244802474976, train/raw-loss = 0.3570936918258667, train/logprobs = tensor([[-1.2551, -5.1471],
        [-2.1898, -1.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27609363198280334
Epoch 0, Step 2098: train/loss = 0.11334487795829773, train/raw-loss = 0.061824921518564224, train/logprobs = tensor([[-0.9633, -7.5409],
        [-3.2838, -1.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25759974122047424
Epoch 0, Step 2099: train/loss = 0.29205718636512756, train/raw-loss = 0.2333540916442871, train/logprobs = tensor([[-1.2514, -8.2449],
        [-1.8781, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2935154438018799
Epoch 0, Step 2100: train/loss = 0.45884764194488525, train/raw-loss = 0.40191853046417236, train/logprobs = tensor([[-1.1806, -2.5775],
        [-2.0086, -1.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284645676612854
Epoch 0, Step 2101: train/loss = 0.41377198696136475, train/raw-loss = 0.3645666837692261, train/logprobs = tensor([[-1.0653, -4.1487],
        [-2.3169, -1.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24602659046649933
Epoch 0, Step 2102: train/loss = 0.3934120535850525, train/raw-loss = 0.35485631227493286, train/logprobs = tensor([[-1.4965, -7.0451],
        [-1.7425, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19277876615524292
Epoch 0, Step 2103: train/loss = 0.3074658513069153, train/raw-loss = 0.2596622109413147, train/logprobs = tensor([[-1.0502, -7.2738],
        [-2.1537, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23901833593845367
Epoch 0, Step 2104: train/loss = 0.3419927656650543, train/raw-loss = 0.2959105372428894, train/logprobs = tensor([[-1.0160, -3.0082],
        [-2.4401, -1.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23041121661663055
Epoch 0, Step 2105: train/loss = 0.3933926224708557, train/raw-loss = 0.33180904388427734, train/logprobs = tensor([[-1.2978, -4.2264],
        [-2.8277, -2.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30791783332824707
Epoch 0, Step 2106: train/loss = 0.48767539858818054, train/raw-loss = 0.4332074224948883, train/logprobs = tensor([[-0.8645, -2.9561],
        [-1.7577, -1.5706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723398208618164
Epoch 0, Step 2107: train/loss = 0.4093879461288452, train/raw-loss = 0.36493971943855286, train/logprobs = tensor([[-1.9422, -4.3044],
        [-2.2074, -1.3560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2222411036491394
Epoch 0, Step 2108: train/loss = 0.3030913770198822, train/raw-loss = 0.26601240038871765, train/logprobs = tensor([[-1.1214, -7.6943],
        [-1.9988, -1.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18539489805698395
Epoch 0, Step 2109: train/loss = 0.34991583228111267, train/raw-loss = 0.30346187949180603, train/logprobs = tensor([[ -0.9618, -12.8555],
        [ -1.8787,  -2.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23226988315582275
Epoch 0, Step 2110: train/loss = 0.49602144956588745, train/raw-loss = 0.4526006281375885, train/logprobs = tensor([[-2.0808, -4.1796],
        [-2.2649, -1.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21710410714149475
Epoch 0, Step 2111: train/loss = 0.2833971381187439, train/raw-loss = 0.22761817276477814, train/logprobs = tensor([[-1.2274, -4.8770],
        [-2.9068, -1.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27889484167099
Epoch 0, Step 2112: train/loss = 0.26849618554115295, train/raw-loss = 0.21840259432792664, train/logprobs = tensor([[-0.9618, -8.4894],
        [-2.6377, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504679262638092
Epoch 0, Step 2113: train/loss = 0.3518649935722351, train/raw-loss = 0.29695138335227966, train/logprobs = tensor([[ -1.0394, -10.5279],
        [ -3.1123,  -1.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2745680809020996
Epoch 0, Step 2114: train/loss = 0.2212158441543579, train/raw-loss = 0.16728582978248596, train/logprobs = tensor([[-1.2809, -9.6669],
        [-2.2823, -2.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26965004205703735
Epoch 0, Step 2115: train/loss = 0.13708584010601044, train/raw-loss = 0.08885622769594193, train/logprobs = tensor([[ -1.2082, -12.7855],
        [ -3.1618,  -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24114805459976196
Epoch 0, Step 2116: train/loss = 0.25694113969802856, train/raw-loss = 0.200831800699234, train/logprobs = tensor([[-1.7070, -9.8490],
        [-3.4442, -2.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28054675459861755
Epoch 0, Step 2117: train/loss = 0.4870762526988983, train/raw-loss = 0.44609180092811584, train/logprobs = tensor([[-0.6547, -5.3205],
        [-1.6730, -1.2268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20492222905158997
Epoch 0, Step 2118: train/loss = 0.3177250325679779, train/raw-loss = 0.26479947566986084, train/logprobs = tensor([[-1.1694, -8.8306],
        [-1.9697, -2.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26462775468826294
Epoch 0, Step 2119: train/loss = 0.1901891529560089, train/raw-loss = 0.13687744736671448, train/logprobs = tensor([[-1.1601, -5.6509],
        [-2.8896, -0.6201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665584683418274
Epoch 0, Step 2120: train/loss = 0.8740357160568237, train/raw-loss = 0.8298375606536865, train/logprobs = tensor([[-3.2051, -3.7095],
        [-1.8660, -1.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209906429052353
Epoch 0, Step 2121: train/loss = 0.6358404159545898, train/raw-loss = 0.5802332162857056, train/logprobs = tensor([[-2.6171, -7.7182],
        [-2.2058, -1.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.278035968542099
Epoch 0, Step 2122: train/loss = 0.2598479688167572, train/raw-loss = 0.20924238860607147, train/logprobs = tensor([[-1.2781, -7.1444],
        [-2.2345, -1.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25302791595458984
Epoch 0, Step 2123: train/loss = 0.5128991603851318, train/raw-loss = 0.46447330713272095, train/logprobs = tensor([[-2.1281, -7.4482],
        [-2.5032, -2.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2421291321516037
Epoch 0, Step 2124: train/loss = 0.20445199310779572, train/raw-loss = 0.1524714231491089, train/logprobs = tensor([[-1.3523, -6.6020],
        [-2.9417, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25990283489227295
Epoch 0, Step 2125: train/loss = 0.25133299827575684, train/raw-loss = 0.20527790486812592, train/logprobs = tensor([[-1.2149, -5.3004],
        [-1.9670, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23027537763118744
Epoch 0, Step 2126: train/loss = 0.3820229172706604, train/raw-loss = 0.3383283019065857, train/logprobs = tensor([[-1.0280, -3.5041],
        [-2.4502, -0.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21847304701805115
Epoch 0, Step 2127: train/loss = 0.2253301739692688, train/raw-loss = 0.17563025653362274, train/logprobs = tensor([[ -2.4225, -10.1602],
        [ -3.6627,  -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2484995722770691
Epoch 0, Step 2128: train/loss = 0.2381674349308014, train/raw-loss = 0.19565974175930023, train/logprobs = tensor([[-1.3311, -6.3176],
        [-2.6583, -1.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21253840625286102
Epoch 0, Step 2129: train/loss = 0.28915512561798096, train/raw-loss = 0.24299933016300201, train/logprobs = tensor([[-0.6402, -7.1734],
        [-2.0172, -1.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23077885806560516
Epoch 0, Step 2130: train/loss = 0.36524784564971924, train/raw-loss = 0.31343406438827515, train/logprobs = tensor([[-1.9698, -4.8900],
        [-2.2859, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25906890630722046
Epoch 0, Step 2131: train/loss = 0.2583085000514984, train/raw-loss = 0.20357230305671692, train/logprobs = tensor([[-1.1938, -4.7672],
        [-2.3577, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27368101477622986
Epoch 0, Step 2132: train/loss = 0.32689929008483887, train/raw-loss = 0.2809218168258667, train/logprobs = tensor([[-1.7185, -8.0809],
        [-2.4556, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22988732159137726
Epoch 0, Step 2133: train/loss = 0.32750535011291504, train/raw-loss = 0.28641489148139954, train/logprobs = tensor([[-1.1659, -5.9284],
        [-1.7053, -1.2316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20545220375061035
Epoch 0, Step 2134: train/loss = 0.6313081979751587, train/raw-loss = 0.5723904371261597, train/logprobs = tensor([[-2.5850, -8.0508],
        [-2.7171, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29458868503570557
Epoch 0, Step 2135: train/loss = 0.30953845381736755, train/raw-loss = 0.2640891969203949, train/logprobs = tensor([[-0.6132, -8.4905],
        [-2.5285, -1.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22724634408950806
Epoch 0, Step 2136: train/loss = 0.241540789604187, train/raw-loss = 0.18552054464817047, train/logprobs = tensor([[-1.0184, -6.8906],
        [-2.7529, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801011800765991
Epoch 0, Step 2137: train/loss = 0.3418911099433899, train/raw-loss = 0.2843075096607208, train/logprobs = tensor([[-1.3542, -5.8799],
        [-2.4923, -0.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879181206226349
Epoch 0, Step 2138: train/loss = 0.12163235247135162, train/raw-loss = 0.08075245469808578, train/logprobs = tensor([[-1.2474, -7.7556],
        [-3.9501, -1.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2043994814157486
Epoch 0, Step 2139: train/loss = 0.26266682147979736, train/raw-loss = 0.2104218304157257, train/logprobs = tensor([[-1.1533, -7.2351],
        [-3.0459, -2.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26122498512268066
Epoch 0, Step 2140: train/loss = 0.4294087886810303, train/raw-loss = 0.39189890027046204, train/logprobs = tensor([[-1.2836, -4.6613],
        [-1.7569, -2.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18754950165748596
Epoch 0, Step 2141: train/loss = 2.3786709308624268, train/raw-loss = 2.3251256942749023, train/logprobs = tensor([[-8.4623, -8.5183],
        [-2.8754, -2.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26772835850715637
Epoch 0, Step 2142: train/loss = 0.14364123344421387, train/raw-loss = 0.08727239072322845, train/logprobs = tensor([[-1.3658, -8.6052],
        [-3.6189, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28184419870376587
Epoch 0, Step 2143: train/loss = 0.3931938409805298, train/raw-loss = 0.34065893292427063, train/logprobs = tensor([[-1.2296, -6.5925],
        [-1.7043, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26267457008361816
Epoch 0, Step 2144: train/loss = 0.49371033906936646, train/raw-loss = 0.4449554681777954, train/logprobs = tensor([[-1.6895, -3.5588],
        [-1.8995, -1.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24377447366714478
Epoch 0, Step 2145: train/loss = 0.3468181788921356, train/raw-loss = 0.30377864837646484, train/logprobs = tensor([[-0.7471, -4.3171],
        [-1.3339, -0.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21519766747951508
Epoch 0, Step 2146: train/loss = 0.34849756956100464, train/raw-loss = 0.2978394627571106, train/logprobs = tensor([[-1.6983, -4.6710],
        [-2.2208, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25329065322875977
Epoch 0, Step 2147: train/loss = 0.24932169914245605, train/raw-loss = 0.201676145195961, train/logprobs = tensor([[-2.1848, -6.5505],
        [-2.8893, -1.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2382277399301529
Epoch 0, Step 2148: train/loss = 0.09214417636394501, train/raw-loss = 0.047732871025800705, train/logprobs = tensor([[-1.1745, -8.1853],
        [-3.7232, -1.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22205650806427002
Epoch 0, Step 2149: train/loss = 0.4468764662742615, train/raw-loss = 0.40153342485427856, train/logprobs = tensor([[-1.1960, -6.9634],
        [-2.1095, -2.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22671514749526978
Epoch 0, Step 2150: train/loss = 0.3896743655204773, train/raw-loss = 0.34290197491645813, train/logprobs = tensor([[-2.9330, -5.2437],
        [-3.9803, -2.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23386186361312866
Epoch 0, Step 2151: train/loss = 0.3953208923339844, train/raw-loss = 0.36234402656555176, train/logprobs = tensor([[-1.4034, -8.3596],
        [-2.1521, -1.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648842990398407
Epoch 0, Step 2152: train/loss = 0.4601828455924988, train/raw-loss = 0.4160654544830322, train/logprobs = tensor([[-0.9229, -4.7473],
        [-1.2669, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22058698534965515
Epoch 0, Step 2153: train/loss = 0.29420340061187744, train/raw-loss = 0.22056543827056885, train/logprobs = tensor([[-1.3993, -5.2720],
        [-3.7212, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3681897521018982
Epoch 0, Step 2154: train/loss = 0.2727172076702118, train/raw-loss = 0.22409532964229584, train/logprobs = tensor([[-1.7864, -8.0836],
        [-3.0679, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24310937523841858
Epoch 0, Step 2155: train/loss = 0.172221839427948, train/raw-loss = 0.12574876844882965, train/logprobs = tensor([[ -0.8435, -13.0625],
        [ -2.6874,  -1.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23236539959907532
Epoch 0, Step 2156: train/loss = 0.48456621170043945, train/raw-loss = 0.4420107901096344, train/logprobs = tensor([[-0.9920, -4.9630],
        [-1.9398, -2.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21277712285518646
Epoch 0, Step 2157: train/loss = 0.12373979389667511, train/raw-loss = 0.07154053449630737, train/logprobs = tensor([[-1.6126, -8.2451],
        [-3.8383, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609962522983551
Epoch 0, Step 2158: train/loss = 0.5686135292053223, train/raw-loss = 0.5124972462654114, train/logprobs = tensor([[-1.4778, -7.9912],
        [-3.0837, -2.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28058117628097534
Epoch 0, Step 2159: train/loss = 0.9398447871208191, train/raw-loss = 0.8794590830802917, train/logprobs = tensor([[ -3.8481, -12.0725],
        [ -4.4738,  -2.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019285202026367
Epoch 0, Step 2160: train/loss = 0.28579214215278625, train/raw-loss = 0.2271123230457306, train/logprobs = tensor([[-0.6103, -7.3733],
        [-2.7066, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933991849422455
Epoch 0, Step 2161: train/loss = 0.285089373588562, train/raw-loss = 0.23506806790828705, train/logprobs = tensor([[-2.3498, -8.2969],
        [-3.1075, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2501066327095032
Epoch 0, Step 2162: train/loss = 0.3925917446613312, train/raw-loss = 0.34056249260902405, train/logprobs = tensor([[-1.2290, -5.1847],
        [-2.9228, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26014620065689087
Epoch 0, Step 2163: train/loss = 0.30680423974990845, train/raw-loss = 0.24729762971401215, train/logprobs = tensor([[-1.0891, -4.2625],
        [-2.5796, -1.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29753318428993225
Epoch 0, Step 2164: train/loss = 0.2049085646867752, train/raw-loss = 0.16188809275627136, train/logprobs = tensor([[ -1.0339, -12.2847],
        [ -2.7029,  -1.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21510227024555206
Epoch 0, Step 2165: train/loss = 0.4520716667175293, train/raw-loss = 0.4062260389328003, train/logprobs = tensor([[-0.6554, -2.6419],
        [-1.8767, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22922810912132263
Epoch 0, Step 2166: train/loss = 0.46572521328926086, train/raw-loss = 0.4188178777694702, train/logprobs = tensor([[-1.2787, -8.8451],
        [-1.8586, -1.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23453688621520996
Epoch 0, Step 2167: train/loss = 0.5409042239189148, train/raw-loss = 0.4937117099761963, train/logprobs = tensor([[-0.6337, -1.3439],
        [-2.1285, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23596256971359253
Epoch 0, Step 2168: train/loss = 0.3517119288444519, train/raw-loss = 0.30781304836273193, train/logprobs = tensor([[-1.4082, -7.0931],
        [-1.5242, -2.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21949446201324463
Epoch 0, Step 2169: train/loss = 0.5268052220344543, train/raw-loss = 0.4849441349506378, train/logprobs = tensor([[-0.9344, -2.6699],
        [-2.4938, -1.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20930537581443787
Epoch 0, Step 2170: train/loss = 0.26365989446640015, train/raw-loss = 0.20444932579994202, train/logprobs = tensor([[-2.0870, -9.0282],
        [-3.4815, -1.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960529029369354
Epoch 0, Step 2171: train/loss = 0.6296507120132446, train/raw-loss = 0.5693905353546143, train/logprobs = tensor([[-2.2481, -6.2191],
        [-1.6785, -1.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30130115151405334
Epoch 0, Step 2172: train/loss = 0.5407907962799072, train/raw-loss = 0.4983963370323181, train/logprobs = tensor([[-1.0423, -2.9671],
        [-1.7507, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2119724452495575
Epoch 0, Step 2173: train/loss = 0.44467657804489136, train/raw-loss = 0.39804476499557495, train/logprobs = tensor([[-1.2648, -7.1903],
        [-1.6523, -3.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2331589162349701
Epoch 0, Step 2174: train/loss = 0.28159528970718384, train/raw-loss = 0.2317126989364624, train/logprobs = tensor([[-0.7190, -4.2937],
        [-1.9272, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2494129240512848
Epoch 0, Step 2175: train/loss = 0.26340916752815247, train/raw-loss = 0.2171555608510971, train/logprobs = tensor([[-0.9308, -8.8804],
        [-2.5570, -1.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312680184841156
Epoch 0, Step 2176: train/loss = 0.36260586977005005, train/raw-loss = 0.32195359468460083, train/logprobs = tensor([[-2.8009, -7.9379],
        [-3.4069, -2.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2032613456249237
Epoch 0, Step 2177: train/loss = 0.31785422563552856, train/raw-loss = 0.264792799949646, train/logprobs = tensor([[-1.7291, -8.1534],
        [-2.6550, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26530706882476807
Epoch 0, Step 2178: train/loss = 0.32267677783966064, train/raw-loss = 0.2751114070415497, train/logprobs = tensor([[-1.3638, -8.3586],
        [-1.9110, -2.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23782680928707123
Epoch 0, Step 2179: train/loss = 0.38035547733306885, train/raw-loss = 0.33111387491226196, train/logprobs = tensor([[-1.3193, -3.9796],
        [-2.0114, -1.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24620799720287323
Epoch 0, Step 2180: train/loss = 0.40717536211013794, train/raw-loss = 0.35943591594696045, train/logprobs = tensor([[-0.6584, -5.3317],
        [-1.5877, -1.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2386973798274994
Epoch 0, Step 2181: train/loss = 0.16432836651802063, train/raw-loss = 0.10005492717027664, train/logprobs = tensor([[-1.0084, -7.2273],
        [-3.2383, -2.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.321367084980011
Epoch 0, Step 2182: train/loss = 0.5633927583694458, train/raw-loss = 0.5077453255653381, train/logprobs = tensor([[-1.5221, -4.7983],
        [-1.7049, -1.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27823716402053833
Epoch 0, Step 2183: train/loss = 0.1471197009086609, train/raw-loss = 0.08969216793775558, train/logprobs = tensor([[-1.2236, -7.6538],
        [-3.3399, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871376574039459
Epoch 0, Step 2184: train/loss = 0.7447903752326965, train/raw-loss = 0.6948548555374146, train/logprobs = tensor([[-0.7869, -1.1672],
        [-2.9803, -1.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2496773600578308
Epoch 0, Step 2185: train/loss = 0.5046684741973877, train/raw-loss = 0.4443962872028351, train/logprobs = tensor([[-1.7830, -4.5090],
        [-2.5505, -2.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013608157634735
Epoch 0, Step 2186: train/loss = 0.3171839416027069, train/raw-loss = 0.272384375333786, train/logprobs = tensor([[-1.3445, -7.0469],
        [-2.0515, -1.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22399777173995972
Epoch 0, Step 2187: train/loss = 0.46355244517326355, train/raw-loss = 0.40258634090423584, train/logprobs = tensor([[-1.3333, -3.4808],
        [-3.8362, -2.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048306107521057
Epoch 0, Step 2188: train/loss = 0.1950533241033554, train/raw-loss = 0.12839800119400024, train/logprobs = tensor([[-1.3212, -6.8844],
        [-3.9211, -1.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33327656984329224
Epoch 0, Step 2189: train/loss = 0.47085997462272644, train/raw-loss = 0.42990362644195557, train/logprobs = tensor([[-0.9951, -3.3887],
        [-1.6513, -0.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20478153228759766
Epoch 0, Step 2190: train/loss = 0.16956889629364014, train/raw-loss = 0.12098616361618042, train/logprobs = tensor([[ -1.7204, -14.9651],
        [ -3.4430,  -2.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24291369318962097
Epoch 0, Step 2191: train/loss = 0.4137464165687561, train/raw-loss = 0.36474373936653137, train/logprobs = tensor([[-0.9750, -2.3178],
        [-2.1285, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24501341581344604
Epoch 0, Step 2192: train/loss = 0.16356050968170166, train/raw-loss = 0.10252687335014343, train/logprobs = tensor([[-1.4796, -7.0682],
        [-3.9190, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3051682114601135
Epoch 0, Step 2193: train/loss = 0.3563193380832672, train/raw-loss = 0.3038373589515686, train/logprobs = tensor([[-0.8376, -4.8408],
        [-2.3897, -2.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26240989565849304
Epoch 0, Step 2194: train/loss = 0.4124048352241516, train/raw-loss = 0.37272247672080994, train/logprobs = tensor([[-1.3439, -8.3949],
        [-1.9322, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19841168820858002
Epoch 0, Step 2195: train/loss = 0.24579297006130219, train/raw-loss = 0.19723862409591675, train/logprobs = tensor([[ -1.2609, -10.8053],
        [ -2.6871,  -1.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24277178943157196
Epoch 0, Step 2196: train/loss = 0.6905010938644409, train/raw-loss = 0.6442729830741882, train/logprobs = tensor([[-1.7409, -1.7532],
        [-1.5872, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23114052414894104
Epoch 0, Step 2197: train/loss = 0.22567881643772125, train/raw-loss = 0.17062555253505707, train/logprobs = tensor([[ -1.5065, -10.6725],
        [ -2.5088,  -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752663791179657
Epoch 0, Step 2198: train/loss = 0.3643539845943451, train/raw-loss = 0.3164966106414795, train/logprobs = tensor([[ -2.6020, -10.4484],
        [ -3.1862,  -3.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23928672075271606
Epoch 0, Step 2199: train/loss = 0.5393581986427307, train/raw-loss = 0.490896612405777, train/logprobs = tensor([[-0.7986, -1.3728],
        [-1.7024, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2423078715801239
Epoch 0, Step 2200: train/loss = 0.343535840511322, train/raw-loss = 0.29130682349205017, train/logprobs = tensor([[-0.8400, -4.1927],
        [-2.7844, -1.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26114514470100403
Epoch 0, Step 2201: train/loss = 0.4615441858768463, train/raw-loss = 0.4196011424064636, train/logprobs = tensor([[-0.9892, -2.2691],
        [-1.2298, -0.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20971518754959106
Epoch 0, Step 2202: train/loss = 0.5201253294944763, train/raw-loss = 0.46781736612319946, train/logprobs = tensor([[-1.5289, -2.4901],
        [-2.3314, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26153966784477234
Epoch 0, Step 2203: train/loss = 0.31211191415786743, train/raw-loss = 0.2513168454170227, train/logprobs = tensor([[-1.4773, -7.6771],
        [-3.6224, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30397552251815796
Epoch 0, Step 2204: train/loss = 0.3414868712425232, train/raw-loss = 0.29796552658081055, train/logprobs = tensor([[-1.3362, -5.9888],
        [-2.1379, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21760666370391846
Epoch 0, Step 2205: train/loss = 0.24336467683315277, train/raw-loss = 0.19676846265792847, train/logprobs = tensor([[-0.9634, -6.8101],
        [-2.8569, -1.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329811304807663
Epoch 0, Step 2206: train/loss = 0.5225974321365356, train/raw-loss = 0.48116472363471985, train/logprobs = tensor([[-1.3480, -3.1962],
        [-1.6300, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20716366171836853
Epoch 0, Step 2207: train/loss = 0.16715306043624878, train/raw-loss = 0.1162453442811966, train/logprobs = tensor([[-1.1497, -7.5761],
        [-2.7117, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545385956764221
Epoch 0, Step 2208: train/loss = 0.46122199296951294, train/raw-loss = 0.4121880531311035, train/logprobs = tensor([[-1.1900, -4.9630],
        [-2.3523, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24516955018043518
Epoch 0, Step 2209: train/loss = 0.22082878649234772, train/raw-loss = 0.16955265402793884, train/logprobs = tensor([[-1.1023, -8.2524],
        [-3.2837, -2.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25638073682785034
Epoch 0, Step 2210: train/loss = 0.32571446895599365, train/raw-loss = 0.2829225957393646, train/logprobs = tensor([[-1.4790, -5.1929],
        [-3.5066, -2.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21395935118198395
Epoch 0, Step 2211: train/loss = 0.4238990247249603, train/raw-loss = 0.3580322563648224, train/logprobs = tensor([[-0.8187, -6.4245],
        [-3.6660, -2.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293338418006897
Epoch 0, Step 2212: train/loss = 0.3133189082145691, train/raw-loss = 0.2553887963294983, train/logprobs = tensor([[-1.5966, -6.9721],
        [-3.1795, -1.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28965047001838684
Epoch 0, Step 2213: train/loss = 0.22140541672706604, train/raw-loss = 0.17308248579502106, train/logprobs = tensor([[-1.3939, -7.6194],
        [-2.4811, -1.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24161459505558014
Epoch 0, Step 2214: train/loss = 0.15274617075920105, train/raw-loss = 0.09833073616027832, train/logprobs = tensor([[-1.3776, -8.7030],
        [-3.8442, -2.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27207714319229126
Epoch 0, Step 2215: train/loss = 0.33119332790374756, train/raw-loss = 0.2735214829444885, train/logprobs = tensor([[-1.8517, -6.6421],
        [-2.3413, -1.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288359135389328
Epoch 0, Step 2216: train/loss = 0.2630677819252014, train/raw-loss = 0.21204596757888794, train/logprobs = tensor([[-1.8702, -6.6171],
        [-4.2256, -1.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551090121269226
Epoch 0, Step 2217: train/loss = 0.47429007291793823, train/raw-loss = 0.42102891206741333, train/logprobs = tensor([[-3.5514, -6.2842],
        [-4.8198, -1.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663058638572693
Epoch 0, Step 2218: train/loss = 0.39331504702568054, train/raw-loss = 0.35201215744018555, train/logprobs = tensor([[-1.1320, -5.4655],
        [-2.1898, -2.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2065143883228302
Epoch 0, Step 2219: train/loss = 0.3684377670288086, train/raw-loss = 0.3275625705718994, train/logprobs = tensor([[ -1.5718, -10.8055],
        [ -2.0207,  -1.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20437605679035187
Epoch 0, Step 2220: train/loss = 0.4841926693916321, train/raw-loss = 0.4253113865852356, train/logprobs = tensor([[-1.3875, -5.2901],
        [-3.2942, -2.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29440635442733765
Epoch 0, Step 2221: train/loss = 0.6875483989715576, train/raw-loss = 0.6377267837524414, train/logprobs = tensor([[ -2.9981, -12.3901],
        [ -2.3346,  -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24910801649093628
Epoch 0, Step 2222: train/loss = 0.29317110776901245, train/raw-loss = 0.24771076440811157, train/logprobs = tensor([[-0.5905, -7.6018],
        [-1.8566, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22730162739753723
Epoch 0, Step 2223: train/loss = 0.24262724816799164, train/raw-loss = 0.2017846405506134, train/logprobs = tensor([[-1.2288, -6.7538],
        [-3.2018, -2.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20421314239501953
Epoch 0, Step 2224: train/loss = 0.17866477370262146, train/raw-loss = 0.12735293805599213, train/logprobs = tensor([[ -1.0959, -10.2742],
        [ -4.1476,  -2.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25655919313430786
Epoch 0, Step 2225: train/loss = 0.5232651829719543, train/raw-loss = 0.47859227657318115, train/logprobs = tensor([[-1.5651, -4.0566],
        [-2.3155, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22336457669734955
Epoch 0, Step 2226: train/loss = 0.11162140220403671, train/raw-loss = 0.05918576940894127, train/logprobs = tensor([[-0.8397, -9.2382],
        [-3.1292, -2.2106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621782124042511
Epoch 0, Step 2227: train/loss = 0.3010929226875305, train/raw-loss = 0.24730277061462402, train/logprobs = tensor([[-0.6394, -5.2492],
        [-2.5480, -1.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26895079016685486
Epoch 0, Step 2228: train/loss = 0.26619666814804077, train/raw-loss = 0.21177048981189728, train/logprobs = tensor([[-0.8742, -6.6667],
        [-3.0892, -1.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27213093638420105
Epoch 0, Step 2229: train/loss = 0.3329106867313385, train/raw-loss = 0.2900274395942688, train/logprobs = tensor([[-0.8675, -6.4318],
        [-1.7163, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21441635489463806
Epoch 0, Step 2230: train/loss = 0.3247219920158386, train/raw-loss = 0.2785671651363373, train/logprobs = tensor([[-1.6621, -5.7007],
        [-2.6873, -1.5711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23077407479286194
Epoch 0, Step 2231: train/loss = 0.40016937255859375, train/raw-loss = 0.3572762608528137, train/logprobs = tensor([[-0.6499, -5.6521],
        [-1.4413, -1.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2144656777381897
Epoch 0, Step 2232: train/loss = 0.3522416353225708, train/raw-loss = 0.28995606303215027, train/logprobs = tensor([[-1.1235, -4.9065],
        [-4.2844, -1.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31142786145210266
Epoch 0, Step 2233: train/loss = 0.24926377832889557, train/raw-loss = 0.20727857947349548, train/logprobs = tensor([[-1.5089, -9.2515],
        [-2.2153, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20992600917816162
Epoch 0, Step 2234: train/loss = 0.2866838574409485, train/raw-loss = 0.2333402782678604, train/logprobs = tensor([[-1.4066, -7.7033],
        [-2.6990, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.266717791557312
Epoch 0, Step 2235: train/loss = 0.6572814583778381, train/raw-loss = 0.6039061546325684, train/logprobs = tensor([[-2.4267, -6.0608],
        [-2.9287, -1.1712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668766975402832
Epoch 0, Step 2236: train/loss = 0.32357773184776306, train/raw-loss = 0.2763470411300659, train/logprobs = tensor([[-0.8486, -5.5808],
        [-2.0091, -1.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23615328967571259
Epoch 0, Step 2237: train/loss = 0.6041550040245056, train/raw-loss = 0.5569677352905273, train/logprobs = tensor([[-1.9099, -4.3530],
        [-2.3830, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23593637347221375
Epoch 0, Step 2238: train/loss = 0.3394893407821655, train/raw-loss = 0.27874207496643066, train/logprobs = tensor([[-2.0304, -8.0700],
        [-3.9325, -1.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30373644828796387
Epoch 0, Step 2239: train/loss = 0.2950007915496826, train/raw-loss = 0.24086472392082214, train/logprobs = tensor([[-1.3361, -7.1240],
        [-2.5118, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27068030834198
Epoch 0, Step 2240: train/loss = 0.29769665002822876, train/raw-loss = 0.24858085811138153, train/logprobs = tensor([[-1.5513, -8.0433],
        [-2.4865, -1.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2455788403749466
Epoch 0, Step 2241: train/loss = 0.3163999915122986, train/raw-loss = 0.2677738666534424, train/logprobs = tensor([[-1.2686, -3.6974],
        [-2.3632, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431306093931198
Epoch 0, Step 2242: train/loss = 0.4648420512676239, train/raw-loss = 0.4228382408618927, train/logprobs = tensor([[-1.1991, -4.5678],
        [-3.1007, -2.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2100193351507187
Epoch 0, Step 2243: train/loss = 0.37826991081237793, train/raw-loss = 0.33167192339897156, train/logprobs = tensor([[-0.9549, -5.6397],
        [-1.9944, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23298998177051544
Epoch 0, Step 2244: train/loss = 0.23527590930461884, train/raw-loss = 0.18190190196037292, train/logprobs = tensor([[-1.1791, -9.5978],
        [-2.7924, -2.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26687008142471313
Epoch 0, Step 2245: train/loss = 0.40608981251716614, train/raw-loss = 0.3683607280254364, train/logprobs = tensor([[-0.9070, -6.4522],
        [-1.7274, -1.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18864543735980988
Epoch 0, Step 2246: train/loss = 0.2162836194038391, train/raw-loss = 0.15677402913570404, train/logprobs = tensor([[-1.2399, -7.3923],
        [-3.1009, -1.3842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29754793643951416
Epoch 0, Step 2247: train/loss = 0.18707455694675446, train/raw-loss = 0.13241085410118103, train/logprobs = tensor([[-0.9367, -5.6812],
        [-3.4974, -1.4406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27331849932670593
Epoch 0, Step 2248: train/loss = 0.5034275650978088, train/raw-loss = 0.4583159387111664, train/logprobs = tensor([[-0.7555, -1.5559],
        [-1.5703, -1.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22555798292160034
Epoch 0, Step 2249: train/loss = 0.21665282547473907, train/raw-loss = 0.17505350708961487, train/logprobs = tensor([[-0.8334, -4.6598],
        [-2.0985, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20799663662910461
Epoch 0, Step 2250: train/loss = 0.2598435580730438, train/raw-loss = 0.21128834784030914, train/logprobs = tensor([[-0.8210, -5.9683],
        [-2.3193, -1.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24277614057064056
Epoch 0, Step 2251: train/loss = 0.2230595052242279, train/raw-loss = 0.1702699512243271, train/logprobs = tensor([[-0.8970, -5.7486],
        [-2.4597, -1.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639477550983429
Epoch 0, Step 2252: train/loss = 0.45977267622947693, train/raw-loss = 0.4171038269996643, train/logprobs = tensor([[-1.2676, -2.9912],
        [-1.7513, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2133442908525467
Epoch 0, Step 2253: train/loss = 0.43226584792137146, train/raw-loss = 0.3846849799156189, train/logprobs = tensor([[-0.9936, -5.9588],
        [-2.1310, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23790417611598969
Epoch 0, Step 2254: train/loss = 0.5016639232635498, train/raw-loss = 0.4547559916973114, train/logprobs = tensor([[-1.1485, -2.0620],
        [-1.7725, -1.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2345396876335144
Epoch 0, Step 2255: train/loss = 0.17413924634456635, train/raw-loss = 0.13431942462921143, train/logprobs = tensor([[ -1.3425, -15.7032],
        [ -2.5528,  -3.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19909901916980743
Epoch 0, Step 2256: train/loss = 0.3723568618297577, train/raw-loss = 0.3112267255783081, train/logprobs = tensor([[-1.1977, -6.7892],
        [-2.2466, -2.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056508004665375
Epoch 0, Step 2257: train/loss = 0.4132964611053467, train/raw-loss = 0.36621883511543274, train/logprobs = tensor([[-1.5158, -4.1248],
        [-2.2581, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23538804054260254
Epoch 0, Step 2258: train/loss = 0.3635184168815613, train/raw-loss = 0.3134474754333496, train/logprobs = tensor([[-1.3719, -7.6787],
        [-2.3399, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25035470724105835
Epoch 0, Step 2259: train/loss = 0.1404888927936554, train/raw-loss = 0.08472337573766708, train/logprobs = tensor([[ -0.7084, -12.2944],
        [ -2.7192,  -1.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27882763743400574
Epoch 0, Step 2260: train/loss = 0.3354533016681671, train/raw-loss = 0.29203057289123535, train/logprobs = tensor([[-1.0841, -7.0516],
        [-2.3709, -2.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21711373329162598
Epoch 0, Step 2261: train/loss = 0.196669340133667, train/raw-loss = 0.1396132856607437, train/logprobs = tensor([[-1.2546, -8.0339],
        [-3.3708, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2852802574634552
Epoch 0, Step 2262: train/loss = 0.44296208024024963, train/raw-loss = 0.39279240369796753, train/logprobs = tensor([[-1.0146, -2.5055],
        [-2.2930, -1.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508482336997986
Epoch 0, Step 2263: train/loss = 0.4021522104740143, train/raw-loss = 0.3513127267360687, train/logprobs = tensor([[-0.8682, -3.5295],
        [-2.5494, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2541973888874054
Epoch 0, Step 2264: train/loss = 0.4032231271266937, train/raw-loss = 0.35946160554885864, train/logprobs = tensor([[-1.0353, -6.5460],
        [-1.6752, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21880750358104706
Epoch 0, Step 2265: train/loss = 0.29840970039367676, train/raw-loss = 0.25469255447387695, train/logprobs = tensor([[-1.4703, -7.1722],
        [-2.8549, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2185857743024826
Epoch 0, Step 2266: train/loss = 0.18009893596172333, train/raw-loss = 0.13712957501411438, train/logprobs = tensor([[ -1.0568, -11.6387],
        [ -3.0817,  -2.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.214846670627594
Epoch 0, Step 2267: train/loss = 0.5185494422912598, train/raw-loss = 0.4775114357471466, train/logprobs = tensor([[-0.8989, -1.4297],
        [-1.3907, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20519007742404938
Epoch 0, Step 2268: train/loss = 0.1943824291229248, train/raw-loss = 0.1343924105167389, train/logprobs = tensor([[-0.9839, -5.7136],
        [-4.0161, -1.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29995012283325195
Epoch 0, Step 2269: train/loss = 0.4285293519496918, train/raw-loss = 0.37893134355545044, train/logprobs = tensor([[-1.3684, -3.6191],
        [-2.8209, -1.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24799008667469025
Epoch 0, Step 2270: train/loss = 0.2637013792991638, train/raw-loss = 0.22388997673988342, train/logprobs = tensor([[-0.6599, -6.4502],
        [-1.3402, -1.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19905707240104675
Epoch 0, Step 2271: train/loss = 0.30767905712127686, train/raw-loss = 0.25903722643852234, train/logprobs = tensor([[-1.4466, -6.2322],
        [-2.8758, -1.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24320918321609497
Epoch 0, Step 2272: train/loss = 0.30611926317214966, train/raw-loss = 0.26665830612182617, train/logprobs = tensor([[-1.1703, -7.6158],
        [-3.4188, -1.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.197304829955101
Epoch 0, Step 2273: train/loss = 0.3454068899154663, train/raw-loss = 0.30943262577056885, train/logprobs = tensor([[-1.3464, -5.5292],
        [-1.5461, -1.2867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17987145483493805
Epoch 0, Step 2274: train/loss = 0.13200236856937408, train/raw-loss = 0.08200474083423615, train/logprobs = tensor([[-0.6046, -7.2816],
        [-2.3814, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2499881088733673
Epoch 0, Step 2275: train/loss = 0.136015385389328, train/raw-loss = 0.08607117086648941, train/logprobs = tensor([[-1.2272, -7.0564],
        [-3.3762, -1.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24972109496593475
Epoch 0, Step 2276: train/loss = 0.23004524409770966, train/raw-loss = 0.18383567035198212, train/logprobs = tensor([[-1.0125, -7.2782],
        [-2.8926, -1.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23104795813560486
Epoch 0, Step 2277: train/loss = 0.43429136276245117, train/raw-loss = 0.3959987759590149, train/logprobs = tensor([[-0.7750, -2.4966],
        [-1.3512, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19146285951137543
Epoch 0, Step 2278: train/loss = 0.3129296600818634, train/raw-loss = 0.260057657957077, train/logprobs = tensor([[-1.6109, -4.5714],
        [-2.7354, -1.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643600404262543
Epoch 0, Step 2279: train/loss = 0.8460913300514221, train/raw-loss = 0.8034257888793945, train/logprobs = tensor([[-3.1318, -8.1063],
        [-2.0718, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21332769095897675
Epoch 0, Step 2280: train/loss = 0.42560338973999023, train/raw-loss = 0.3859748840332031, train/logprobs = tensor([[-0.8420, -3.8269],
        [-1.8141, -1.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19814234972000122
Epoch 0, Step 2281: train/loss = 0.12672430276870728, train/raw-loss = 0.07756368815898895, train/logprobs = tensor([[-0.9226, -7.8495],
        [-4.1410, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24580302834510803
Epoch 0, Step 2282: train/loss = 0.3880830705165863, train/raw-loss = 0.33925512433052063, train/logprobs = tensor([[-0.8904, -6.2338],
        [-2.2116, -2.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2441396415233612
Epoch 0, Step 2283: train/loss = 0.1932535171508789, train/raw-loss = 0.14866231381893158, train/logprobs = tensor([[-0.7873, -6.6000],
        [-2.0240, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22295603156089783
Epoch 0, Step 2284: train/loss = 0.7363016605377197, train/raw-loss = 0.6895288228988647, train/logprobs = tensor([[-2.2334, -5.7657],
        [-2.4647, -1.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2338639497756958
Epoch 0, Step 2285: train/loss = 0.2852552533149719, train/raw-loss = 0.23045381903648376, train/logprobs = tensor([[ -1.6342, -11.5694],
        [ -2.7544,  -2.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740071415901184
Epoch 0, Step 2286: train/loss = 0.26361191272735596, train/raw-loss = 0.21349751949310303, train/logprobs = tensor([[-1.7402, -7.5851],
        [-2.6157, -1.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25057193636894226
Epoch 0, Step 2287: train/loss = 0.6437128782272339, train/raw-loss = 0.5977527499198914, train/logprobs = tensor([[-2.3678, -6.8991],
        [-2.5886, -2.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2298005223274231
Epoch 0, Step 2288: train/loss = 0.25966060161590576, train/raw-loss = 0.2141675055027008, train/logprobs = tensor([[-1.6590, -8.8186],
        [-2.3991, -2.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22746542096138
Epoch 0, Step 2289: train/loss = 0.3621969521045685, train/raw-loss = 0.3206496834754944, train/logprobs = tensor([[-1.0659, -7.9843],
        [-2.9078, -1.8763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2077362984418869
Epoch 0, Step 2290: train/loss = 0.7660986185073853, train/raw-loss = 0.7179394364356995, train/logprobs = tensor([[-1.1476, -2.2733],
        [-2.9380, -2.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24079583585262299
Epoch 0, Step 2291: train/loss = 0.11055724322795868, train/raw-loss = 0.047658324241638184, train/logprobs = tensor([[ -1.1265, -10.0837],
        [ -4.4552,  -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31449460983276367
Epoch 0, Step 2292: train/loss = 0.5836504697799683, train/raw-loss = 0.5416560173034668, train/logprobs = tensor([[-2.0555, -5.2073],
        [-2.2063, -1.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20997218787670135
Epoch 0, Step 2293: train/loss = 0.31672629714012146, train/raw-loss = 0.25696849822998047, train/logprobs = tensor([[-1.5624, -5.5263],
        [-3.4030, -1.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29878902435302734
Epoch 0, Step 2294: train/loss = 0.2748183012008667, train/raw-loss = 0.21547290682792664, train/logprobs = tensor([[-0.8862, -9.3298],
        [-3.0283, -1.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967270016670227
Epoch 0, Step 2295: train/loss = 0.3174889087677002, train/raw-loss = 0.267304390668869, train/logprobs = tensor([[-1.5889, -5.0859],
        [-2.5776, -1.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25092262029647827
Epoch 0, Step 2296: train/loss = 0.44908881187438965, train/raw-loss = 0.4065459370613098, train/logprobs = tensor([[-1.0735, -2.2429],
        [-2.8473, -1.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2127145230770111
Epoch 0, Step 2297: train/loss = 0.3149539828300476, train/raw-loss = 0.2671710252761841, train/logprobs = tensor([[-1.0569, -5.0322],
        [-2.3179, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23891480267047882
Epoch 0, Step 2298: train/loss = 0.08929778635501862, train/raw-loss = 0.03930861875414848, train/logprobs = tensor([[ -0.9634, -18.8167],
        [ -4.0393,  -3.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24994584918022156
Epoch 0, Step 2299: train/loss = 0.5468464493751526, train/raw-loss = 0.4958995282649994, train/logprobs = tensor([[-1.0201, -3.4434],
        [-1.9373, -1.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25473424792289734
Epoch 0, Step 2300: train/loss = 0.14661303162574768, train/raw-loss = 0.10810510814189911, train/logprobs = tensor([[-1.4908, -6.0412],
        [-3.2960, -1.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19253966212272644
Epoch 0, Step 2301: train/loss = 0.19073337316513062, train/raw-loss = 0.13504831492900848, train/logprobs = tensor([[-0.8934, -9.9459],
        [-3.9412, -1.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27842527627944946
Epoch 0, Step 2302: train/loss = 0.38616758584976196, train/raw-loss = 0.3485010266304016, train/logprobs = tensor([[-0.5961, -8.9227],
        [-2.6042, -1.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18833276629447937
Epoch 0, Step 2303: train/loss = 0.25728681683540344, train/raw-loss = 0.20427288115024567, train/logprobs = tensor([[-1.7541, -7.6900],
        [-3.5563, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2650696635246277
Epoch 0, Step 2304: train/loss = 0.2815360724925995, train/raw-loss = 0.230858713388443, train/logprobs = tensor([[-1.0313, -8.8741],
        [-2.3214, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533867359161377
Epoch 0, Step 2305: train/loss = 0.519208550453186, train/raw-loss = 0.46560657024383545, train/logprobs = tensor([[-2.3358, -8.9825],
        [-2.7311, -1.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26800960302352905
Epoch 0, Step 2306: train/loss = 0.3856254816055298, train/raw-loss = 0.345874547958374, train/logprobs = tensor([[-1.3339, -4.5464],
        [-2.1465, -2.3530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19875457882881165
Epoch 0, Step 2307: train/loss = 0.5224345922470093, train/raw-loss = 0.4755304455757141, train/logprobs = tensor([[-1.1372, -5.8877],
        [-3.6979, -2.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23452050983905792
Epoch 0, Step 2308: train/loss = 0.41332998871803284, train/raw-loss = 0.36660897731781006, train/logprobs = tensor([[-0.7176, -4.7473],
        [-1.4883, -1.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2336050271987915
Epoch 0, Step 2309: train/loss = 0.380673348903656, train/raw-loss = 0.33819425106048584, train/logprobs = tensor([[ -2.3127, -10.4979],
        [ -2.3123,  -1.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2123955488204956
Epoch 0, Step 2310: train/loss = 0.6018148064613342, train/raw-loss = 0.546150803565979, train/logprobs = tensor([[-1.3666, -4.3638],
        [-3.2316, -2.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2783203125
Epoch 0, Step 2311: train/loss = 0.5624142289161682, train/raw-loss = 0.5201588869094849, train/logprobs = tensor([[-0.7791, -2.8345],
        [-1.2453, -1.0515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21127678453922272
Epoch 0, Step 2312: train/loss = 0.2178269624710083, train/raw-loss = 0.16610145568847656, train/logprobs = tensor([[-0.8928, -4.8503],
        [-2.8052, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2586274743080139
Epoch 0, Step 2313: train/loss = 0.21882864832878113, train/raw-loss = 0.16432081162929535, train/logprobs = tensor([[-1.1361, -6.5699],
        [-2.9253, -2.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725391685962677
Epoch 0, Step 2314: train/loss = 0.206964373588562, train/raw-loss = 0.15873508155345917, train/logprobs = tensor([[ -1.2805, -11.5710],
        [ -2.5017,  -1.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24114647507667542
Epoch 0, Step 2315: train/loss = 0.1918809860944748, train/raw-loss = 0.13894234597682953, train/logprobs = tensor([[-1.2152, -6.7093],
        [-3.0798, -1.3819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26469317078590393
Epoch 0, Step 2316: train/loss = 0.2952495515346527, train/raw-loss = 0.25318676233291626, train/logprobs = tensor([[-0.9145, -5.1756],
        [-2.1323, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21031390130519867
Epoch 0, Step 2317: train/loss = 0.23958252370357513, train/raw-loss = 0.19776204228401184, train/logprobs = tensor([[-1.4919, -6.6822],
        [-2.3029, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20910228788852692
Epoch 0, Step 2318: train/loss = 0.4626924693584442, train/raw-loss = 0.42237532138824463, train/logprobs = tensor([[-0.8891, -4.7558],
        [-1.6209, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20158573985099792
Epoch 0, Step 2319: train/loss = 0.19050440192222595, train/raw-loss = 0.13818830251693726, train/logprobs = tensor([[-1.5346, -8.7119],
        [-3.1906, -1.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615804672241211
Epoch 0, Step 2320: train/loss = 0.36129873991012573, train/raw-loss = 0.3015940189361572, train/logprobs = tensor([[-1.2818, -5.1944],
        [-2.2906, -1.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985233664512634
Epoch 0, Step 2321: train/loss = 0.4802563488483429, train/raw-loss = 0.4253310263156891, train/logprobs = tensor([[-0.8610, -3.6816],
        [-2.0579, -1.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27462679147720337
Epoch 0, Step 2322: train/loss = 0.4275549054145813, train/raw-loss = 0.37629085779190063, train/logprobs = tensor([[-2.8170, -8.4845],
        [-3.5430, -1.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25632017850875854
Epoch 0, Step 2323: train/loss = 0.5563145279884338, train/raw-loss = 0.5117689371109009, train/logprobs = tensor([[-1.2504, -1.9840],
        [-1.5816, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.222727969288826
Epoch 0, Step 2324: train/loss = 0.29826000332832336, train/raw-loss = 0.2521876096725464, train/logprobs = tensor([[-0.8803, -7.8489],
        [-2.0912, -1.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2303619682788849
Epoch 0, Step 2325: train/loss = 0.4734501838684082, train/raw-loss = 0.43305253982543945, train/logprobs = tensor([[-0.5810, -2.9366],
        [-1.0926, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20198814570903778
Epoch 0, Step 2326: train/loss = 0.20674282312393188, train/raw-loss = 0.14577309787273407, train/logprobs = tensor([[ -1.6407, -10.2593],
        [ -4.3189,  -1.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048486113548279
Epoch 0, Step 2327: train/loss = 0.4797911047935486, train/raw-loss = 0.4391663074493408, train/logprobs = tensor([[-1.3476, -6.1413],
        [-2.0848, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20312389731407166
Epoch 0, Step 2328: train/loss = 0.39430785179138184, train/raw-loss = 0.3229711651802063, train/logprobs = tensor([[-1.0614, -7.0308],
        [-3.1778, -1.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3566833436489105
Epoch 0, Step 2329: train/loss = 0.4336715340614319, train/raw-loss = 0.3950849175453186, train/logprobs = tensor([[-0.8455, -5.4370],
        [-1.2904, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19293314218521118
Epoch 0, Step 2330: train/loss = 0.27367377281188965, train/raw-loss = 0.22106237709522247, train/logprobs = tensor([[-0.7696, -5.4781],
        [-2.3768, -1.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26305705308914185
Epoch 0, Step 2331: train/loss = 0.5885185599327087, train/raw-loss = 0.5462014675140381, train/logprobs = tensor([[-1.4495, -3.6154],
        [-1.0409, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2115854024887085
Epoch 0, Step 2332: train/loss = 0.3166656196117401, train/raw-loss = 0.270548552274704, train/logprobs = tensor([[-1.4366, -6.6534],
        [-2.7519, -1.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23058536648750305
Epoch 0, Step 2333: train/loss = 0.38405776023864746, train/raw-loss = 0.3220469653606415, train/logprobs = tensor([[-1.0207, -4.8591],
        [-3.3632, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100540339946747
Epoch 0, Step 2334: train/loss = 0.3001028597354889, train/raw-loss = 0.24986642599105835, train/logprobs = tensor([[-1.5147, -7.7152],
        [-2.2183, -2.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511821389198303
Epoch 0, Step 2335: train/loss = 0.07773668318986893, train/raw-loss = 0.03100721910595894, train/logprobs = tensor([[ -1.4306, -11.5272],
        [ -4.7933,  -2.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23364731669425964
Epoch 0, Step 2336: train/loss = 0.2950160503387451, train/raw-loss = 0.2474072426557541, train/logprobs = tensor([[-0.8581, -9.3823],
        [-2.9719, -1.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23804408311843872
Epoch 0, Step 2337: train/loss = 0.24382628500461578, train/raw-loss = 0.19088490307331085, train/logprobs = tensor([[ -2.5076, -11.3413],
        [ -3.8088,  -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26470687985420227
Epoch 0, Step 2338: train/loss = 0.3473000228404999, train/raw-loss = 0.28629881143569946, train/logprobs = tensor([[-1.6353, -4.4279],
        [-3.3651, -1.3693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30500608682632446
Epoch 0, Step 2339: train/loss = 0.44965413212776184, train/raw-loss = 0.4033648371696472, train/logprobs = tensor([[-1.8236, -4.5143],
        [-2.3824, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23144644498825073
Epoch 0, Step 2340: train/loss = 0.35198938846588135, train/raw-loss = 0.302423357963562, train/logprobs = tensor([[-1.3644, -3.5656],
        [-2.7361, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24782997369766235
Epoch 0, Step 2341: train/loss = 0.7260481119155884, train/raw-loss = 0.6830176115036011, train/logprobs = tensor([[-2.3368, -4.8937],
        [-2.1051, -1.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151523232460022
Epoch 0, Step 2342: train/loss = 0.4129233956336975, train/raw-loss = 0.3653659224510193, train/logprobs = tensor([[-1.0156, -2.6255],
        [-2.2158, -1.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23778748512268066
Epoch 0, Step 2343: train/loss = 0.16782361268997192, train/raw-loss = 0.10595018416643143, train/logprobs = tensor([[-0.8553, -7.0773],
        [-3.2469, -1.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3093671202659607
Epoch 0, Step 2344: train/loss = 0.21328184008598328, train/raw-loss = 0.17304439842700958, train/logprobs = tensor([[-0.9061, -7.1415],
        [-2.3064, -1.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011871039867401
Epoch 0, Step 2345: train/loss = 0.25885215401649475, train/raw-loss = 0.2143060714006424, train/logprobs = tensor([[-0.7907, -8.3787],
        [-3.0642, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22273042798042297
Epoch 0, Step 2346: train/loss = 0.2695286273956299, train/raw-loss = 0.22612722218036652, train/logprobs = tensor([[-0.8602, -6.4140],
        [-1.8006, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2170070856809616
Epoch 0, Step 2347: train/loss = 0.33114680647850037, train/raw-loss = 0.276382714509964, train/logprobs = tensor([[-1.1209, -5.6924],
        [-3.7007, -1.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738204300403595
Epoch 0, Step 2348: train/loss = 0.14865294098854065, train/raw-loss = 0.10193868726491928, train/logprobs = tensor([[-1.6785, -7.4553],
        [-3.6148, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2335713505744934
Epoch 0, Step 2349: train/loss = 0.9452896118164062, train/raw-loss = 0.8989530801773071, train/logprobs = tensor([[-2.9314, -4.7477],
        [-1.6649, -2.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23168277740478516
Epoch 0, Step 2350: train/loss = 0.3595249354839325, train/raw-loss = 0.31646668910980225, train/logprobs = tensor([[-0.9295, -4.3844],
        [-1.8779, -1.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21529114246368408
Epoch 0, Step 2351: train/loss = 0.42409786581993103, train/raw-loss = 0.3816736340522766, train/logprobs = tensor([[-0.7187, -2.8016],
        [-1.7675, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2121211588382721
Epoch 0, Step 2352: train/loss = 0.19988882541656494, train/raw-loss = 0.15987050533294678, train/logprobs = tensor([[-0.8414, -7.3605],
        [-2.5886, -1.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20009158551692963
Epoch 0, Step 2353: train/loss = 0.4061066508293152, train/raw-loss = 0.3637557923793793, train/logprobs = tensor([[-0.9447, -5.0575],
        [-1.7478, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21175435185432434
Epoch 0, Step 2354: train/loss = 0.33917221426963806, train/raw-loss = 0.29115045070648193, train/logprobs = tensor([[-2.4328, -6.1288],
        [-2.7802, -1.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2401086539030075
Epoch 0, Step 2355: train/loss = 0.24893294274806976, train/raw-loss = 0.19790609180927277, train/logprobs = tensor([[ -1.0220, -10.8189],
        [ -3.2173,  -1.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551342248916626
Epoch 0, Step 2356: train/loss = 0.3022230565547943, train/raw-loss = 0.2522432208061218, train/logprobs = tensor([[-1.4220, -8.5830],
        [-2.0701, -1.2492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498992383480072
Epoch 0, Step 2357: train/loss = 0.27766698598861694, train/raw-loss = 0.2124159187078476, train/logprobs = tensor([[-1.5432, -5.3893],
        [-2.9177, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32625529170036316
Epoch 0, Step 2358: train/loss = 0.30451565980911255, train/raw-loss = 0.26267582178115845, train/logprobs = tensor([[-1.3008, -4.7518],
        [-3.0962, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20919904112815857
Epoch 0, Step 2359: train/loss = 0.17231881618499756, train/raw-loss = 0.11921266466379166, train/logprobs = tensor([[-1.4350, -9.5818],
        [-3.7295, -1.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655308246612549
Epoch 0, Step 2360: train/loss = 0.30199867486953735, train/raw-loss = 0.25833675265312195, train/logprobs = tensor([[-1.0296, -4.6971],
        [-2.1751, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21830961108207703
Epoch 0, Step 2361: train/loss = 0.2978527545928955, train/raw-loss = 0.2435767650604248, train/logprobs = tensor([[-1.3892, -6.4337],
        [-2.7184, -1.2782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27137988805770874
Epoch 0, Step 2362: train/loss = 0.2154582142829895, train/raw-loss = 0.15432478487491608, train/logprobs = tensor([[-0.8651, -4.9488],
        [-2.2736, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056671619415283
Epoch 0, Step 2363: train/loss = 0.28183263540267944, train/raw-loss = 0.23445427417755127, train/logprobs = tensor([[-0.8986, -4.8543],
        [-2.5813, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368917465209961
Epoch 0, Step 2364: train/loss = 0.5568137168884277, train/raw-loss = 0.5073103904724121, train/logprobs = tensor([[-2.3752, -5.1524],
        [-3.1740, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24751700460910797
Epoch 0, Step 2365: train/loss = 0.28242459893226624, train/raw-loss = 0.23980370163917542, train/logprobs = tensor([[-0.9823, -8.2989],
        [-1.8939, -1.2226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21310462057590485
Epoch 0, Step 2366: train/loss = 0.43560791015625, train/raw-loss = 0.3913057744503021, train/logprobs = tensor([[-1.1773, -4.2269],
        [-1.1061, -1.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.221510648727417
Epoch 0, Step 2367: train/loss = 0.4754630923271179, train/raw-loss = 0.4333454668521881, train/logprobs = tensor([[-0.8821, -3.2791],
        [-1.8865, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21058815717697144
Epoch 0, Step 2368: train/loss = 0.57890784740448, train/raw-loss = 0.5274559855461121, train/logprobs = tensor([[-2.4214, -6.1354],
        [-2.7000, -1.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572595477104187
Epoch 0, Step 2369: train/loss = 0.4156434237957001, train/raw-loss = 0.36833256483078003, train/logprobs = tensor([[-0.9978, -3.6601],
        [-2.5771, -1.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365543097257614
Epoch 0, Step 2370: train/loss = 0.12519827485084534, train/raw-loss = 0.07673428952693939, train/logprobs = tensor([[-1.4312, -8.2489],
        [-3.4365, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24231989681720734
Epoch 0, Step 2371: train/loss = 0.21936914324760437, train/raw-loss = 0.16239655017852783, train/logprobs = tensor([[-1.0209, -5.0840],
        [-2.9505, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848629057407379
Epoch 0, Step 2372: train/loss = 0.2513502538204193, train/raw-loss = 0.1952185332775116, train/logprobs = tensor([[-0.7024, -7.5491],
        [-2.8354, -2.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2806586027145386
Epoch 0, Step 2373: train/loss = 0.20181719958782196, train/raw-loss = 0.1431816965341568, train/logprobs = tensor([[-0.7938, -5.6568],
        [-3.2521, -1.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931775450706482
Epoch 0, Step 2374: train/loss = 0.2688636779785156, train/raw-loss = 0.2169274538755417, train/logprobs = tensor([[-0.7272, -6.0362],
        [-1.7811, -1.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25968116521835327
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-13 00:37:45,352][root][INFO] - beta: 0.3
[2024-03-13 00:37:45,352][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.3-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6548246741294861, train/raw-loss = 0.6495987772941589, train/logprobs = tensor([[-0.5573, -0.9072],
        [-0.4922, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01741955801844597
Epoch 0, Step 65: train/loss = 0.5899941325187683, train/raw-loss = 0.5857954025268555, train/logprobs = tensor([[-0.4070, -2.3937],
        [-0.4050, -1.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01399573776870966
Epoch 0, Step 66: train/loss = 0.6319034099578857, train/raw-loss = 0.6266941428184509, train/logprobs = tensor([[-0.6670, -1.2264],
        [-0.6761, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017364149913191795
Epoch 0, Step 67: train/loss = 0.6115397214889526, train/raw-loss = 0.6071405410766602, train/logprobs = tensor([[-0.4570, -1.6574],
        [-0.4394, -1.2546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01466421503573656
Epoch 0, Step 68: train/loss = 0.6243724822998047, train/raw-loss = 0.6197435855865479, train/logprobs = tensor([[-0.5313, -0.8133],
        [-0.6277, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015429443679749966
Epoch 0, Step 69: train/loss = 0.6412106156349182, train/raw-loss = 0.6364691853523254, train/logprobs = tensor([[-0.6259, -0.8774],
        [-0.6394, -0.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015804797410964966
Epoch 0, Step 70: train/loss = 0.606876015663147, train/raw-loss = 0.6025667190551758, train/logprobs = tensor([[-0.5816, -1.5791],
        [-0.5848, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014364168047904968
Epoch 0, Step 71: train/loss = 0.6175409555435181, train/raw-loss = 0.6131045818328857, train/logprobs = tensor([[-0.5089, -1.2086],
        [-0.5335, -0.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014788052067160606
Epoch 0, Step 72: train/loss = 0.6433379054069519, train/raw-loss = 0.6386556625366211, train/logprobs = tensor([[-0.5467, -1.3656],
        [-0.5517, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015607494860887527
Epoch 0, Step 73: train/loss = 0.6793097853660583, train/raw-loss = 0.6742078065872192, train/logprobs = tensor([[-0.5542, -1.0911],
        [-0.5418, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01700666733086109
Epoch 0, Step 74: train/loss = 0.6520530581474304, train/raw-loss = 0.646562933921814, train/logprobs = tensor([[-0.6140, -0.9861],
        [-0.5815, -0.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01830052025616169
Epoch 0, Step 75: train/loss = 0.6082082986831665, train/raw-loss = 0.6044463515281677, train/logprobs = tensor([[-0.4130, -1.3300],
        [-0.4388, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012539805844426155
Epoch 0, Step 76: train/loss = 0.5482411980628967, train/raw-loss = 0.5441524982452393, train/logprobs = tensor([[-0.4645, -2.4598],
        [-0.4983, -1.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013628868386149406
Epoch 0, Step 77: train/loss = 0.6093743443489075, train/raw-loss = 0.6045247912406921, train/logprobs = tensor([[-0.6555, -1.0110],
        [-0.6915, -0.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016165263950824738
Epoch 0, Step 78: train/loss = 0.6559019088745117, train/raw-loss = 0.6508196592330933, train/logprobs = tensor([[-0.6902, -0.9502],
        [-0.6835, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016940640285611153
Epoch 0, Step 79: train/loss = 0.5793964862823486, train/raw-loss = 0.5748891830444336, train/logprobs = tensor([[-0.5693, -2.4091],
        [-0.5731, -1.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01502439845353365
Epoch 0, Step 80: train/loss = 0.6302112936973572, train/raw-loss = 0.6248288154602051, train/logprobs = tensor([[-0.7425, -1.0095],
        [-0.7360, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017941707745194435
Epoch 0, Step 81: train/loss = 0.5736069083213806, train/raw-loss = 0.5702394247055054, train/logprobs = tensor([[-0.5280, -2.5049],
        [-0.5219, -1.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011224905028939247
Epoch 0, Step 82: train/loss = 0.6528760194778442, train/raw-loss = 0.6472131609916687, train/logprobs = tensor([[-0.6936, -1.1156],
        [-0.6209, -0.8246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01887611486017704
Epoch 0, Step 83: train/loss = 0.6874900460243225, train/raw-loss = 0.6813997626304626, train/logprobs = tensor([[-1.5396, -1.6598],
        [-1.4916, -1.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020301073789596558
Epoch 0, Step 84: train/loss = 0.6451941132545471, train/raw-loss = 0.6394739151000977, train/logprobs = tensor([[-0.6092, -0.9785],
        [-0.5892, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019067317247390747
Epoch 0, Step 85: train/loss = 0.5640863180160522, train/raw-loss = 0.5592270493507385, train/logprobs = tensor([[-0.5910, -2.0205],
        [-0.5795, -1.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016197485849261284
Epoch 0, Step 86: train/loss = 0.6321606040000916, train/raw-loss = 0.6269472241401672, train/logprobs = tensor([[-0.5689, -0.9168],
        [-0.5939, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01737806387245655
Epoch 0, Step 87: train/loss = 0.6091702580451965, train/raw-loss = 0.604310154914856, train/logprobs = tensor([[-0.6368, -1.0342],
        [-0.7064, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016200387850403786
Epoch 0, Step 88: train/loss = 0.616270899772644, train/raw-loss = 0.610595166683197, train/logprobs = tensor([[-1.0024, -2.1787],
        [-0.9361, -1.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01891915313899517
Epoch 0, Step 89: train/loss = 0.6414952278137207, train/raw-loss = 0.6361006498336792, train/logprobs = tensor([[-0.5701, -0.9983],
        [-0.5551, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017981959506869316
Epoch 0, Step 90: train/loss = 0.6326382160186768, train/raw-loss = 0.6276158690452576, train/logprobs = tensor([[-0.4664, -1.0580],
        [-0.4738, -0.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01674095168709755
Epoch 0, Step 91: train/loss = 0.44960740208625793, train/raw-loss = 0.4456914961338043, train/logprobs = tensor([[-0.4698, -2.7812],
        [-0.5089, -1.4961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013053014874458313
Epoch 0, Step 92: train/loss = 0.6571577787399292, train/raw-loss = 0.6510480642318726, train/logprobs = tensor([[-0.6945, -1.0867],
        [-0.6936, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020365852862596512
Epoch 0, Step 93: train/loss = 0.5955159068107605, train/raw-loss = 0.5906965136528015, train/logprobs = tensor([[-0.5692, -1.4579],
        [-0.5587, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01606466807425022
Epoch 0, Step 94: train/loss = 0.5942810773849487, train/raw-loss = 0.5891062617301941, train/logprobs = tensor([[-0.6772, -1.8421],
        [-0.7721, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01724936068058014
Epoch 0, Step 95: train/loss = 0.6304203271865845, train/raw-loss = 0.6262738704681396, train/logprobs = tensor([[-0.5259, -1.0171],
        [-0.5221, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013821704313158989
Epoch 0, Step 96: train/loss = 0.6970555782318115, train/raw-loss = 0.6833032369613647, train/logprobs = tensor([[-0.6020, -0.8986],
        [-0.5860, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04584108293056488
Epoch 0, Step 97: train/loss = 0.5752190351486206, train/raw-loss = 0.5637960433959961, train/logprobs = tensor([[-0.6364, -1.9527],
        [-0.6142, -1.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03807659074664116
Epoch 0, Step 98: train/loss = 0.6213204860687256, train/raw-loss = 0.6128070950508118, train/logprobs = tensor([[-0.3850, -0.9838],
        [-0.3300, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028378119692206383
Epoch 0, Step 99: train/loss = 0.6344539523124695, train/raw-loss = 0.6252905130386353, train/logprobs = tensor([[-0.5303, -1.0500],
        [-0.5064, -0.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0305445808917284
Epoch 0, Step 100: train/loss = 0.5513104200363159, train/raw-loss = 0.541799008846283, train/logprobs = tensor([[-0.6817, -2.8038],
        [-0.6566, -1.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03170492500066757
Epoch 0, Step 101: train/loss = 0.6029523611068726, train/raw-loss = 0.586628794670105, train/logprobs = tensor([[-0.9604, -1.8484],
        [-0.9289, -1.2860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054411932826042175
Epoch 0, Step 102: train/loss = 0.5893948078155518, train/raw-loss = 0.5784433484077454, train/logprobs = tensor([[-0.4986, -1.3607],
        [-0.4892, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03650496155023575
Epoch 0, Step 103: train/loss = 0.5632078647613525, train/raw-loss = 0.5539709329605103, train/logprobs = tensor([[-0.6352, -1.7249],
        [-0.5484, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03078976646065712
Epoch 0, Step 104: train/loss = 0.4564778804779053, train/raw-loss = 0.4441017210483551, train/logprobs = tensor([[-0.7973, -4.5350],
        [-0.6596, -2.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041253842413425446
Epoch 0, Step 105: train/loss = 0.6096490025520325, train/raw-loss = 0.5981938242912292, train/logprobs = tensor([[-0.6763, -1.2044],
        [-0.6199, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03818393871188164
Epoch 0, Step 106: train/loss = 0.46174606680870056, train/raw-loss = 0.4523512125015259, train/logprobs = tensor([[-0.6824, -4.4278],
        [-0.6205, -2.5846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03131614252924919
Epoch 0, Step 107: train/loss = 0.6121954321861267, train/raw-loss = 0.5979761481285095, train/logprobs = tensor([[-0.7207, -1.5410],
        [-0.6798, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0473976768553257
Epoch 0, Step 108: train/loss = 0.6688565015792847, train/raw-loss = 0.6614841818809509, train/logprobs = tensor([[-0.5297, -0.6616],
        [-0.4658, -0.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02457420900464058
Epoch 0, Step 109: train/loss = 0.6135143637657166, train/raw-loss = 0.6034798622131348, train/logprobs = tensor([[-0.6394, -1.2781],
        [-0.5531, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03344840928912163
Epoch 0, Step 110: train/loss = 0.5490514636039734, train/raw-loss = 0.5390014052391052, train/logprobs = tensor([[-0.6618, -2.9619],
        [-0.5458, -1.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03350019082427025
Epoch 0, Step 111: train/loss = 0.5819835662841797, train/raw-loss = 0.574275553226471, train/logprobs = tensor([[-0.4371, -1.5141],
        [-0.4178, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025693275034427643
Epoch 0, Step 112: train/loss = 0.6066932082176208, train/raw-loss = 0.5969617366790771, train/logprobs = tensor([[-0.6322, -1.1113],
        [-0.5927, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032438233494758606
Epoch 0, Step 113: train/loss = 0.6388214826583862, train/raw-loss = 0.624348521232605, train/logprobs = tensor([[-0.6489, -1.2885],
        [-0.5773, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04824308678507805
Epoch 0, Step 114: train/loss = 0.6098629832267761, train/raw-loss = 0.5983188152313232, train/logprobs = tensor([[-0.5656, -1.0717],
        [-0.5363, -0.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03848067671060562
Epoch 0, Step 115: train/loss = 0.6222952604293823, train/raw-loss = 0.6131188869476318, train/logprobs = tensor([[-0.5694, -1.1733],
        [-0.5342, -0.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030588045716285706
Epoch 0, Step 116: train/loss = 0.5707893371582031, train/raw-loss = 0.5581998825073242, train/logprobs = tensor([[-0.6691, -2.0753],
        [-0.6105, -1.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041964974254369736
Epoch 0, Step 117: train/loss = 0.6272813677787781, train/raw-loss = 0.6169302463531494, train/logprobs = tensor([[-0.4855, -1.7736],
        [-0.4611, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034503739327192307
Epoch 0, Step 118: train/loss = 0.5013876557350159, train/raw-loss = 0.4928598999977112, train/logprobs = tensor([[-0.6592, -3.2090],
        [-0.5729, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028425903990864754
Epoch 0, Step 119: train/loss = 0.577862024307251, train/raw-loss = 0.5647894144058228, train/logprobs = tensor([[-0.6167, -1.6925],
        [-0.5662, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04357529431581497
Epoch 0, Step 120: train/loss = 0.5294768810272217, train/raw-loss = 0.5174788236618042, train/logprobs = tensor([[-0.7859, -2.6422],
        [-0.7665, -1.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039993446320295334
Epoch 0, Step 121: train/loss = 0.6131603717803955, train/raw-loss = 0.6035420298576355, train/logprobs = tensor([[-0.5018, -1.2434],
        [-0.4479, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032061025500297546
Epoch 0, Step 122: train/loss = 0.5488337874412537, train/raw-loss = 0.5373252034187317, train/logprobs = tensor([[-0.8491, -1.9574],
        [-0.7402, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836192935705185
Epoch 0, Step 123: train/loss = 0.6750266551971436, train/raw-loss = 0.6638392210006714, train/logprobs = tensor([[-0.5342, -0.8004],
        [-0.5072, -0.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037291672080755234
Epoch 0, Step 124: train/loss = 0.5920687913894653, train/raw-loss = 0.579533040523529, train/logprobs = tensor([[-0.7947, -1.6168],
        [-0.7082, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04178581386804581
Epoch 0, Step 125: train/loss = 0.5488507151603699, train/raw-loss = 0.5369518399238586, train/logprobs = tensor([[-0.7080, -3.2057],
        [-0.6296, -2.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03966285288333893
Epoch 0, Step 126: train/loss = 0.6396556496620178, train/raw-loss = 0.6264054775238037, train/logprobs = tensor([[-0.6776, -1.2124],
        [-0.5694, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04416726902127266
Epoch 0, Step 127: train/loss = 0.6208404302597046, train/raw-loss = 0.6096267104148865, train/logprobs = tensor([[-0.5117, -1.5042],
        [-0.4467, -1.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037379126995801926
Epoch 0, Step 128: train/loss = 0.6843553781509399, train/raw-loss = 0.6536241173744202, train/logprobs = tensor([[-0.8350, -1.0460],
        [-0.7882, -0.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10243741422891617
Epoch 0, Step 129: train/loss = 0.5489052534103394, train/raw-loss = 0.5121653079986572, train/logprobs = tensor([[-0.7456, -2.9144],
        [-0.6347, -1.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246629595756531
Epoch 0, Step 130: train/loss = 0.6523920297622681, train/raw-loss = 0.6216964721679688, train/logprobs = tensor([[-0.5380, -1.1739],
        [-0.4701, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10231854021549225
Epoch 0, Step 131: train/loss = 0.534865140914917, train/raw-loss = 0.4991210699081421, train/logprobs = tensor([[-0.7781, -4.1487],
        [-0.6840, -2.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191469207406044
Epoch 0, Step 132: train/loss = 0.564902126789093, train/raw-loss = 0.5312302112579346, train/logprobs = tensor([[-0.7993, -2.3805],
        [-0.6376, -1.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11223961412906647
Epoch 0, Step 133: train/loss = 0.575392484664917, train/raw-loss = 0.5412096977233887, train/logprobs = tensor([[-0.6524, -2.4415],
        [-0.5579, -1.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11394267529249191
Epoch 0, Step 134: train/loss = 0.5883017778396606, train/raw-loss = 0.5579867362976074, train/logprobs = tensor([[-0.7570, -1.6938],
        [-0.6200, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104987025260925
Epoch 0, Step 135: train/loss = 0.624883234500885, train/raw-loss = 0.5926386117935181, train/logprobs = tensor([[-0.5213, -1.5039],
        [-0.3942, -0.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074821725487709
Epoch 0, Step 136: train/loss = 0.5492428541183472, train/raw-loss = 0.5212560296058655, train/logprobs = tensor([[-0.4422, -2.1580],
        [-0.3933, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09328947961330414
Epoch 0, Step 137: train/loss = 0.6222291588783264, train/raw-loss = 0.5936446785926819, train/logprobs = tensor([[-0.4412, -1.3591],
        [-0.4045, -0.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09528146684169769
Epoch 0, Step 138: train/loss = 0.5722914934158325, train/raw-loss = 0.5393373966217041, train/logprobs = tensor([[-0.4398, -1.7435],
        [-0.3631, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10984710603952408
Epoch 0, Step 139: train/loss = 0.5542349219322205, train/raw-loss = 0.5209459066390991, train/logprobs = tensor([[-0.6202, -2.4156],
        [-0.4982, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11096327751874924
Epoch 0, Step 140: train/loss = 0.6120307445526123, train/raw-loss = 0.5793999433517456, train/logprobs = tensor([[-0.7858, -1.7909],
        [-0.6601, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10876929759979248
Epoch 0, Step 141: train/loss = 0.6157257556915283, train/raw-loss = 0.580152153968811, train/logprobs = tensor([[-0.9219, -1.9563],
        [-0.6768, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11857862770557404
Epoch 0, Step 142: train/loss = 0.641136646270752, train/raw-loss = 0.6105176210403442, train/logprobs = tensor([[-0.5631, -1.2405],
        [-0.4763, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10206346213817596
Epoch 0, Step 143: train/loss = 0.663092851638794, train/raw-loss = 0.6334446668624878, train/logprobs = tensor([[-0.7522, -1.5848],
        [-0.5902, -1.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09882726520299911
Epoch 0, Step 144: train/loss = 0.4965168237686157, train/raw-loss = 0.46759921312332153, train/logprobs = tensor([[-0.5769, -3.9947],
        [-0.4946, -2.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09639202058315277
Epoch 0, Step 145: train/loss = 0.6395284533500671, train/raw-loss = 0.6126071214675903, train/logprobs = tensor([[-0.6523, -1.5420],
        [-0.5650, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08973784744739532
Epoch 0, Step 146: train/loss = 0.5769017338752747, train/raw-loss = 0.5448586940765381, train/logprobs = tensor([[-0.6506, -2.8268],
        [-0.5151, -1.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10681010782718658
Epoch 0, Step 147: train/loss = 0.6359739899635315, train/raw-loss = 0.6068152189254761, train/logprobs = tensor([[-0.6243, -1.2095],
        [-0.5157, -0.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09719593822956085
Epoch 0, Step 148: train/loss = 0.722385585308075, train/raw-loss = 0.6837249994277954, train/logprobs = tensor([[-1.5483, -1.8797],
        [-1.1476, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12886855006217957
Epoch 0, Step 149: train/loss = 0.6576647162437439, train/raw-loss = 0.6269864439964294, train/logprobs = tensor([[-0.6387, -1.2961],
        [-0.5257, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10226105898618698
Epoch 0, Step 150: train/loss = 0.5683533549308777, train/raw-loss = 0.5336496829986572, train/logprobs = tensor([[-0.8270, -3.5596],
        [-0.7223, -2.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567904055118561
Epoch 0, Step 151: train/loss = 0.6137049198150635, train/raw-loss = 0.5798836350440979, train/logprobs = tensor([[-0.6810, -1.8852],
        [-0.5313, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127375140786171
Epoch 0, Step 152: train/loss = 0.6362873315811157, train/raw-loss = 0.5993327498435974, train/logprobs = tensor([[-0.8411, -1.4213],
        [-0.7602, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12318173795938492
Epoch 0, Step 153: train/loss = 0.6033620238304138, train/raw-loss = 0.5667787790298462, train/logprobs = tensor([[-0.6199, -2.0900],
        [-0.5059, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194404006004333
Epoch 0, Step 154: train/loss = 0.6694333553314209, train/raw-loss = 0.6379784941673279, train/logprobs = tensor([[-0.7509, -1.6317],
        [-0.6502, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484949499368668
Epoch 0, Step 155: train/loss = 0.580822229385376, train/raw-loss = 0.5525659322738647, train/logprobs = tensor([[-0.5993, -2.9481],
        [-0.5035, -1.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09418745338916779
Epoch 0, Step 156: train/loss = 0.6780208349227905, train/raw-loss = 0.6507599949836731, train/logprobs = tensor([[-0.6381, -0.7697],
        [-0.5707, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09086942672729492
Epoch 0, Step 157: train/loss = 0.7148512005805969, train/raw-loss = 0.6863070726394653, train/logprobs = tensor([[-0.7455, -0.8061],
        [-0.6541, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09514699876308441
Epoch 0, Step 158: train/loss = 0.6756598949432373, train/raw-loss = 0.6432501077651978, train/logprobs = tensor([[-0.7026, -1.2340],
        [-0.4946, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10803274810314178
Epoch 0, Step 159: train/loss = 0.6984410285949707, train/raw-loss = 0.6666809916496277, train/logprobs = tensor([[-0.8652, -1.0580],
        [-0.7173, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10586671531200409
Epoch 0, Step 160: train/loss = 0.55949467420578, train/raw-loss = 0.5274027585983276, train/logprobs = tensor([[-1.1288, -2.3484],
        [-0.8597, -1.1221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10697315633296967
Epoch 0, Step 161: train/loss = 0.6409437656402588, train/raw-loss = 0.6184602975845337, train/logprobs = tensor([[-0.6792, -1.3300],
        [-0.5601, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07494484633207321
Epoch 0, Step 162: train/loss = 0.581743597984314, train/raw-loss = 0.5590688586235046, train/logprobs = tensor([[-0.5876, -3.1045],
        [-0.5083, -1.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07558264583349228
Epoch 0, Step 163: train/loss = 0.5623438358306885, train/raw-loss = 0.5360009074211121, train/logprobs = tensor([[-0.5890, -2.2003],
        [-0.4367, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08780982345342636
Epoch 0, Step 164: train/loss = 0.5850407481193542, train/raw-loss = 0.5620419979095459, train/logprobs = tensor([[-0.6827, -1.8831],
        [-0.5235, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07666263729333878
Epoch 0, Step 165: train/loss = 0.563740611076355, train/raw-loss = 0.5368872880935669, train/logprobs = tensor([[-0.6693, -2.2394],
        [-0.4946, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895109474658966
Epoch 0, Step 166: train/loss = 0.4361380934715271, train/raw-loss = 0.41177165508270264, train/logprobs = tensor([[-0.6539, -6.9021],
        [-0.4494, -3.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08122134208679199
Epoch 0, Step 167: train/loss = 0.6342239379882812, train/raw-loss = 0.6074814796447754, train/logprobs = tensor([[-0.7433, -1.4846],
        [-0.5777, -0.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08914142102003098
Epoch 0, Step 168: train/loss = 0.6055735349655151, train/raw-loss = 0.5813207626342773, train/logprobs = tensor([[-0.7258, -1.5923],
        [-0.5439, -0.8348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08084233850240707
Epoch 0, Step 169: train/loss = 0.6703234314918518, train/raw-loss = 0.6462105512619019, train/logprobs = tensor([[-0.8077, -1.3586],
        [-0.7292, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08037620037794113
Epoch 0, Step 170: train/loss = 0.5960202217102051, train/raw-loss = 0.5706602334976196, train/logprobs = tensor([[-0.6072, -1.7460],
        [-0.5610, -1.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0845334529876709
Epoch 0, Step 171: train/loss = 0.6560127139091492, train/raw-loss = 0.6300729513168335, train/logprobs = tensor([[-0.6622, -1.3918],
        [-0.5192, -0.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0864657387137413
Epoch 0, Step 172: train/loss = 0.5115445852279663, train/raw-loss = 0.4866945743560791, train/logprobs = tensor([[-0.6476, -2.6751],
        [-0.5794, -1.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283349871635437
Epoch 0, Step 173: train/loss = 0.5437393188476562, train/raw-loss = 0.5209074020385742, train/logprobs = tensor([[-0.6329, -2.5306],
        [-0.5455, -1.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07610619813203812
Epoch 0, Step 174: train/loss = 0.5481956005096436, train/raw-loss = 0.5226148366928101, train/logprobs = tensor([[-0.6974, -2.1181],
        [-0.5484, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08526936173439026
Epoch 0, Step 175: train/loss = 0.44812315702438354, train/raw-loss = 0.42503121495246887, train/logprobs = tensor([[-0.5194, -3.7267],
        [-0.4014, -1.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07697314023971558
Epoch 0, Step 176: train/loss = 0.608170211315155, train/raw-loss = 0.5787744522094727, train/logprobs = tensor([[-0.7499, -1.7157],
        [-0.4959, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09798574447631836
Epoch 0, Step 177: train/loss = 0.5965115427970886, train/raw-loss = 0.5659646987915039, train/logprobs = tensor([[-1.1005, -2.5957],
        [-0.6362, -1.2558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10182281583547592
Epoch 0, Step 178: train/loss = 0.6257715821266174, train/raw-loss = 0.5973562002182007, train/logprobs = tensor([[-0.8775, -2.5074],
        [-0.7569, -1.7860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09471800923347473
Epoch 0, Step 179: train/loss = 0.606897234916687, train/raw-loss = 0.5820785760879517, train/logprobs = tensor([[-0.6696, -2.5289],
        [-0.5103, -1.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.082728810608387
Epoch 0, Step 180: train/loss = 0.7084043622016907, train/raw-loss = 0.6801874041557312, train/logprobs = tensor([[-0.8584, -0.9335],
        [-0.6575, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09405668824911118
Epoch 0, Step 181: train/loss = 0.7271351218223572, train/raw-loss = 0.7008993625640869, train/logprobs = tensor([[-2.8551, -4.2226],
        [-1.9062, -2.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08745259046554565
Epoch 0, Step 182: train/loss = 0.635285496711731, train/raw-loss = 0.6096382141113281, train/logprobs = tensor([[-0.5464, -1.2893],
        [-0.4645, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08549093455076218
Epoch 0, Step 183: train/loss = 0.5931797623634338, train/raw-loss = 0.5671374201774597, train/logprobs = tensor([[-0.7270, -1.7946],
        [-0.5988, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08680789172649384
Epoch 0, Step 184: train/loss = 0.5135563611984253, train/raw-loss = 0.4867880046367645, train/logprobs = tensor([[-1.2174, -4.3292],
        [-1.1918, -2.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08922795206308365
Epoch 0, Step 185: train/loss = 0.6031855344772339, train/raw-loss = 0.5762218236923218, train/logprobs = tensor([[-0.8705, -2.1359],
        [-0.6840, -1.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987913280725479
Epoch 0, Step 186: train/loss = 0.6031674146652222, train/raw-loss = 0.5695044994354248, train/logprobs = tensor([[-0.8338, -1.7185],
        [-0.7288, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11220969259738922
Epoch 0, Step 187: train/loss = 0.5940059423446655, train/raw-loss = 0.5718023180961609, train/logprobs = tensor([[-0.6162, -2.3647],
        [-0.4947, -1.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07401195913553238
Epoch 0, Step 188: train/loss = 0.5260555744171143, train/raw-loss = 0.4996054172515869, train/logprobs = tensor([[-0.8809, -4.2197],
        [-0.6238, -2.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08816718310117722
Epoch 0, Step 189: train/loss = 0.6758473515510559, train/raw-loss = 0.6534829139709473, train/logprobs = tensor([[-0.6141, -0.9153],
        [-0.5070, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07454825192689896
Epoch 0, Step 190: train/loss = 0.5547351837158203, train/raw-loss = 0.5300929546356201, train/logprobs = tensor([[-0.8410, -3.7926],
        [-0.6208, -1.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08214062452316284
Epoch 0, Step 191: train/loss = 0.6412962079048157, train/raw-loss = 0.6157875657081604, train/logprobs = tensor([[-0.7020, -1.1809],
        [-0.6028, -0.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502879738807678
Epoch 0, Step 192: train/loss = 0.5867449641227722, train/raw-loss = 0.5473626255989075, train/logprobs = tensor([[-0.7851, -1.6801],
        [-0.5579, -0.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312745213508606
Epoch 0, Step 193: train/loss = 0.5021790266036987, train/raw-loss = 0.4604768753051758, train/logprobs = tensor([[-0.8120, -3.4112],
        [-0.6432, -1.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13900721073150635
Epoch 0, Step 194: train/loss = 0.5109831690788269, train/raw-loss = 0.4682210385799408, train/logprobs = tensor([[-0.9341, -4.0598],
        [-0.7392, -1.1535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14254042506217957
Epoch 0, Step 195: train/loss = 0.534631073474884, train/raw-loss = 0.4948684573173523, train/logprobs = tensor([[-0.8693, -3.6801],
        [-0.6147, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13254204392433167
Epoch 0, Step 196: train/loss = 0.6070241332054138, train/raw-loss = 0.5698156952857971, train/logprobs = tensor([[-0.7422, -1.6719],
        [-0.5842, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124028280377388
Epoch 0, Step 197: train/loss = 0.5542747974395752, train/raw-loss = 0.5162937045097351, train/logprobs = tensor([[-0.7361, -2.5897],
        [-0.5057, -0.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12660343945026398
Epoch 0, Step 198: train/loss = 0.5894427299499512, train/raw-loss = 0.5511690378189087, train/logprobs = tensor([[-0.7060, -1.9245],
        [-0.5442, -0.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12757912278175354
Epoch 0, Step 199: train/loss = 0.47024255990982056, train/raw-loss = 0.434224396944046, train/logprobs = tensor([[-0.5447, -2.5477],
        [-0.3718, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.120060496032238
Epoch 0, Step 200: train/loss = 0.5110300779342651, train/raw-loss = 0.477544903755188, train/logprobs = tensor([[-0.9084, -2.4302],
        [-0.6588, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161702871322632
Epoch 0, Step 201: train/loss = 0.5094032287597656, train/raw-loss = 0.46548187732696533, train/logprobs = tensor([[-0.9677, -3.5858],
        [-0.6787, -1.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464044749736786
Epoch 0, Step 202: train/loss = 0.6259635090827942, train/raw-loss = 0.5889674425125122, train/logprobs = tensor([[-0.7252, -1.2389],
        [-0.6687, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1233203262090683
Epoch 0, Step 203: train/loss = 0.6204007267951965, train/raw-loss = 0.5791929960250854, train/logprobs = tensor([[-0.8296, -3.0156],
        [-0.4843, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1373591274023056
Epoch 0, Step 204: train/loss = 0.533536970615387, train/raw-loss = 0.5013375878334045, train/logprobs = tensor([[-0.9599, -2.2565],
        [-0.7285, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10733122378587723
Epoch 0, Step 205: train/loss = 0.45893996953964233, train/raw-loss = 0.42421096563339233, train/logprobs = tensor([[-0.5827, -2.6305],
        [-0.5029, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11576322466135025
Epoch 0, Step 206: train/loss = 0.37999972701072693, train/raw-loss = 0.34678322076797485, train/logprobs = tensor([[-0.6403, -5.8847],
        [-0.5159, -1.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11072167009115219
Epoch 0, Step 207: train/loss = 0.49509960412979126, train/raw-loss = 0.4576224684715271, train/logprobs = tensor([[-0.9993, -2.5448],
        [-0.7872, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12492374330759048
Epoch 0, Step 208: train/loss = 0.5061626434326172, train/raw-loss = 0.47164615988731384, train/logprobs = tensor([[-0.8268, -3.6821],
        [-0.5445, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11505479365587234
Epoch 0, Step 209: train/loss = 0.5666895508766174, train/raw-loss = 0.5237403512001038, train/logprobs = tensor([[-0.8153, -2.3142],
        [-0.6391, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14316391944885254
Epoch 0, Step 210: train/loss = 0.5615031719207764, train/raw-loss = 0.5267234444618225, train/logprobs = tensor([[-0.7271, -1.7991],
        [-0.5676, -0.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1159326508641243
Epoch 0, Step 211: train/loss = 0.6067187190055847, train/raw-loss = 0.5694523453712463, train/logprobs = tensor([[-1.1561, -4.3565],
        [-1.0967, -1.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12422133982181549
Epoch 0, Step 212: train/loss = 0.6283456087112427, train/raw-loss = 0.5953049659729004, train/logprobs = tensor([[-0.5876, -1.4402],
        [-0.4598, -0.5637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11013554036617279
Epoch 0, Step 213: train/loss = 0.6386292576789856, train/raw-loss = 0.5973895788192749, train/logprobs = tensor([[-0.7421, -1.4454],
        [-0.5176, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13746553659439087
Epoch 0, Step 214: train/loss = 0.5442615151405334, train/raw-loss = 0.5065624713897705, train/logprobs = tensor([[-0.6629, -3.1333],
        [-0.5832, -1.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12566351890563965
Epoch 0, Step 215: train/loss = 0.520372211933136, train/raw-loss = 0.4802195131778717, train/logprobs = tensor([[-0.9985, -3.1231],
        [-0.8846, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13384218513965607
Epoch 0, Step 216: train/loss = 0.6319769024848938, train/raw-loss = 0.596272349357605, train/logprobs = tensor([[-0.8639, -1.4018],
        [-0.5211, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11901505291461945
Epoch 0, Step 217: train/loss = 0.49734798073768616, train/raw-loss = 0.46032822132110596, train/logprobs = tensor([[-0.6440, -2.7470],
        [-0.5098, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12339925765991211
Epoch 0, Step 218: train/loss = 0.6965524554252625, train/raw-loss = 0.6661548614501953, train/logprobs = tensor([[-0.6601, -0.8364],
        [-0.5376, -0.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10132518410682678
Epoch 0, Step 219: train/loss = 0.5857834815979004, train/raw-loss = 0.5523258447647095, train/logprobs = tensor([[-0.7239, -1.9403],
        [-0.5659, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11152547597885132
Epoch 0, Step 220: train/loss = 0.4531906247138977, train/raw-loss = 0.41573625802993774, train/logprobs = tensor([[-1.1966, -4.0436],
        [-0.8629, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12484794855117798
Epoch 0, Step 221: train/loss = 0.5311481952667236, train/raw-loss = 0.5019388198852539, train/logprobs = tensor([[-0.5032, -4.2730],
        [-0.4235, -1.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09736461937427521
Epoch 0, Step 222: train/loss = 0.5810547471046448, train/raw-loss = 0.549320638179779, train/logprobs = tensor([[-0.7222, -2.2299],
        [-0.5289, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10578037798404694
Epoch 0, Step 223: train/loss = 0.591839611530304, train/raw-loss = 0.5575469732284546, train/logprobs = tensor([[-0.8971, -2.2942],
        [-0.6465, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11430875211954117
Epoch 0, Step 224: train/loss = 0.5785281658172607, train/raw-loss = 0.541844367980957, train/logprobs = tensor([[-0.7767, -1.6851],
        [-0.6635, -0.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227919697761536
Epoch 0, Step 225: train/loss = 0.5926105976104736, train/raw-loss = 0.5636914968490601, train/logprobs = tensor([[-0.6663, -1.6479],
        [-0.4406, -0.4224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09639693796634674
Epoch 0, Step 226: train/loss = 0.9330146312713623, train/raw-loss = 0.9009034037590027, train/logprobs = tensor([[-2.4056, -3.6274],
        [-0.6718, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10703747719526291
Epoch 0, Step 227: train/loss = 0.5028761625289917, train/raw-loss = 0.4610895812511444, train/logprobs = tensor([[-1.1502, -3.7260],
        [-0.5602, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13928866386413574
Epoch 0, Step 228: train/loss = 0.5511825084686279, train/raw-loss = 0.5238925218582153, train/logprobs = tensor([[-0.6089, -2.2358],
        [-0.4341, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09096668660640717
Epoch 0, Step 229: train/loss = 0.44252848625183105, train/raw-loss = 0.40767115354537964, train/logprobs = tensor([[-1.0031, -5.6362],
        [-0.8434, -2.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1161910891532898
Epoch 0, Step 230: train/loss = 0.460857093334198, train/raw-loss = 0.42416006326675415, train/logprobs = tensor([[-1.2423, -3.6399],
        [-1.0934, -1.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12232334911823273
Epoch 0, Step 231: train/loss = 0.4367460310459137, train/raw-loss = 0.40532350540161133, train/logprobs = tensor([[-0.7075, -4.5961],
        [-0.6809, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10474175214767456
Epoch 0, Step 232: train/loss = 0.5474865436553955, train/raw-loss = 0.5166856646537781, train/logprobs = tensor([[-0.6473, -2.6420],
        [-0.5844, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10266966372728348
Epoch 0, Step 233: train/loss = 0.6342151165008545, train/raw-loss = 0.6017872095108032, train/logprobs = tensor([[-1.3646, -5.4988],
        [-0.8285, -1.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10809306800365448
Epoch 0, Step 234: train/loss = 0.6304974555969238, train/raw-loss = 0.6008689999580383, train/logprobs = tensor([[-0.6416, -1.2007],
        [-0.4961, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09876143932342529
Epoch 0, Step 235: train/loss = 0.4927239716053009, train/raw-loss = 0.45821326971054077, train/logprobs = tensor([[-1.0473, -4.8310],
        [-0.5687, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11503562331199646
Epoch 0, Step 236: train/loss = 0.5981892943382263, train/raw-loss = 0.5588482618331909, train/logprobs = tensor([[-0.7785, -2.1859],
        [-0.6176, -1.1464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13113686442375183
Epoch 0, Step 237: train/loss = 0.534457802772522, train/raw-loss = 0.4985279440879822, train/logprobs = tensor([[-0.7953, -2.2832],
        [-0.6457, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11976619064807892
Epoch 0, Step 238: train/loss = 0.4826433062553406, train/raw-loss = 0.45226043462753296, train/logprobs = tensor([[-0.6169, -2.7740],
        [-0.4929, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10127623379230499
Epoch 0, Step 239: train/loss = 0.6567830443382263, train/raw-loss = 0.6254504323005676, train/logprobs = tensor([[-0.8669, -1.1985],
        [-0.5566, -0.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10444196313619614
Epoch 0, Step 240: train/loss = 0.6264443397521973, train/raw-loss = 0.5853648781776428, train/logprobs = tensor([[-1.1906, -2.7949],
        [-1.0985, -1.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13693159818649292
Epoch 0, Step 241: train/loss = 0.5015287399291992, train/raw-loss = 0.46817681193351746, train/logprobs = tensor([[-0.5763, -2.0840],
        [-0.5276, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11117313802242279
Epoch 0, Step 242: train/loss = 0.6306153535842896, train/raw-loss = 0.6001272797584534, train/logprobs = tensor([[-0.6080, -1.1187],
        [-0.4085, -0.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10162688046693802
Epoch 0, Step 243: train/loss = 0.6516773700714111, train/raw-loss = 0.6222673654556274, train/logprobs = tensor([[-0.8671, -1.2731],
        [-0.4898, -0.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803316742181778
Epoch 0, Step 244: train/loss = 0.5049775838851929, train/raw-loss = 0.46702736616134644, train/logprobs = tensor([[-1.1219, -4.1582],
        [-0.6754, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12650072574615479
Epoch 0, Step 245: train/loss = 0.5498828291893005, train/raw-loss = 0.5144720077514648, train/logprobs = tensor([[-1.1791, -2.6345],
        [-0.6302, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11803624033927917
Epoch 0, Step 246: train/loss = 0.4568313956260681, train/raw-loss = 0.42260244488716125, train/logprobs = tensor([[-0.7021, -4.2678],
        [-0.6760, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11409637331962585
Epoch 0, Step 247: train/loss = 0.5689995884895325, train/raw-loss = 0.5314887762069702, train/logprobs = tensor([[-1.0045, -2.7108],
        [-0.7417, -1.0230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12503594160079956
Epoch 0, Step 248: train/loss = 0.6064584851264954, train/raw-loss = 0.5756250023841858, train/logprobs = tensor([[-0.6998, -2.0158],
        [-0.6808, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.102778360247612
Epoch 0, Step 249: train/loss = 0.5310072302818298, train/raw-loss = 0.5012916326522827, train/logprobs = tensor([[-0.4965, -2.4739],
        [-0.5095, -1.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0990520492196083
Epoch 0, Step 250: train/loss = 0.5218391418457031, train/raw-loss = 0.4877251386642456, train/logprobs = tensor([[-1.3050, -4.7775],
        [-0.5792, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11371338367462158
Epoch 0, Step 251: train/loss = 0.40588751435279846, train/raw-loss = 0.37255746126174927, train/logprobs = tensor([[-0.6880, -3.2640],
        [-0.6333, -0.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11110018193721771
Epoch 0, Step 252: train/loss = 0.5657297372817993, train/raw-loss = 0.5342069268226624, train/logprobs = tensor([[-0.5227, -1.7763],
        [-0.4210, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1050758957862854
Epoch 0, Step 253: train/loss = 0.720292329788208, train/raw-loss = 0.6897637844085693, train/logprobs = tensor([[-0.8059, -0.6807],
        [-0.6325, -0.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176189243793488
Epoch 0, Step 254: train/loss = 0.4759090840816498, train/raw-loss = 0.4427330791950226, train/logprobs = tensor([[-0.8252, -3.6458],
        [-0.5760, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11058659851551056
Epoch 0, Step 255: train/loss = 0.579609751701355, train/raw-loss = 0.5435174703598022, train/logprobs = tensor([[-1.1472, -2.7930],
        [-0.9004, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12030768394470215
Epoch 0, Step 256: train/loss = 0.6713835000991821, train/raw-loss = 0.6455891132354736, train/logprobs = tensor([[-0.5987, -0.9236],
        [-0.4349, -0.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08598120510578156
Epoch 0, Step 257: train/loss = 0.6531464457511902, train/raw-loss = 0.6230880618095398, train/logprobs = tensor([[-0.8194, -1.3530],
        [-0.6089, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10019465535879135
Epoch 0, Step 258: train/loss = 0.38299113512039185, train/raw-loss = 0.3459879457950592, train/logprobs = tensor([[-1.0122, -3.7012],
        [-0.9571, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12334394454956055
Epoch 0, Step 259: train/loss = 0.5393863916397095, train/raw-loss = 0.511813223361969, train/logprobs = tensor([[-0.6199, -3.9094],
        [-0.5109, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09191058576107025
Epoch 0, Step 260: train/loss = 0.4534476399421692, train/raw-loss = 0.42431116104125977, train/logprobs = tensor([[-0.5620, -4.8255],
        [-0.4690, -1.4653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09712158888578415
Epoch 0, Step 261: train/loss = 0.48029017448425293, train/raw-loss = 0.4459569454193115, train/logprobs = tensor([[-0.8586, -2.3915],
        [-0.8462, -0.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11444419622421265
Epoch 0, Step 262: train/loss = 0.5624297261238098, train/raw-loss = 0.5266585350036621, train/logprobs = tensor([[-0.7487, -2.6565],
        [-0.6282, -1.3294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11923740804195404
Epoch 0, Step 263: train/loss = 0.6252658367156982, train/raw-loss = 0.5872162580490112, train/logprobs = tensor([[-1.4046, -2.2847],
        [-1.0914, -1.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12683174014091492
Epoch 0, Step 264: train/loss = 0.6110373735427856, train/raw-loss = 0.5799582600593567, train/logprobs = tensor([[-0.7766, -1.5103],
        [-0.6863, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10359711199998856
Epoch 0, Step 265: train/loss = 0.6652951836585999, train/raw-loss = 0.6350614428520203, train/logprobs = tensor([[-0.9357, -1.4052],
        [-0.6487, -0.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10077925026416779
Epoch 0, Step 266: train/loss = 0.43739786744117737, train/raw-loss = 0.4026978611946106, train/logprobs = tensor([[-1.0925, -3.8422],
        [-1.0136, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11566662788391113
Epoch 0, Step 267: train/loss = 0.47062140703201294, train/raw-loss = 0.4398425221443176, train/logprobs = tensor([[-0.7253, -2.6853],
        [-0.5543, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259626805782318
Epoch 0, Step 268: train/loss = 0.5166500806808472, train/raw-loss = 0.48683029413223267, train/logprobs = tensor([[-0.6866, -5.2856],
        [-0.6675, -1.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939931333065033
Epoch 0, Step 269: train/loss = 0.5204565525054932, train/raw-loss = 0.49035322666168213, train/logprobs = tensor([[-0.8234, -4.0875],
        [-0.7200, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10034438222646713
Epoch 0, Step 270: train/loss = 0.5041795372962952, train/raw-loss = 0.4753042161464691, train/logprobs = tensor([[-0.4370, -2.3322],
        [-0.3518, -0.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09625104069709778
Epoch 0, Step 271: train/loss = 0.5197616815567017, train/raw-loss = 0.48840537667274475, train/logprobs = tensor([[-0.8310, -2.2826],
        [-0.6746, -0.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10452096164226532
Epoch 0, Step 272: train/loss = 0.6840997338294983, train/raw-loss = 0.6561417579650879, train/logprobs = tensor([[-0.6355, -0.8908],
        [-0.5566, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09319335967302322
Epoch 0, Step 273: train/loss = 0.5769639611244202, train/raw-loss = 0.5484762787818909, train/logprobs = tensor([[-0.4901, -1.3792],
        [-0.5038, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09495897591114044
Epoch 0, Step 274: train/loss = 0.5950829982757568, train/raw-loss = 0.5632915496826172, train/logprobs = tensor([[-0.6061, -1.7855],
        [-0.4981, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597144067287445
Epoch 0, Step 275: train/loss = 0.4939305782318115, train/raw-loss = 0.46803367137908936, train/logprobs = tensor([[-0.5066, -2.0291],
        [-0.4402, -0.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0863228514790535
Epoch 0, Step 276: train/loss = 0.5749444365501404, train/raw-loss = 0.537383496761322, train/logprobs = tensor([[-1.3272, -2.7519],
        [-1.0837, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12520305812358856
Epoch 0, Step 277: train/loss = 0.6218172907829285, train/raw-loss = 0.583255410194397, train/logprobs = tensor([[-0.8217, -1.3049],
        [-0.7859, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12853959202766418
Epoch 0, Step 278: train/loss = 0.5529344081878662, train/raw-loss = 0.5173512697219849, train/logprobs = tensor([[-0.8535, -1.6293],
        [-0.7116, -0.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11861050128936768
Epoch 0, Step 279: train/loss = 0.43911880254745483, train/raw-loss = 0.4034877419471741, train/logprobs = tensor([[-1.0589, -4.4169],
        [-0.7422, -1.1069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11877025663852692
Epoch 0, Step 280: train/loss = 0.5163577795028687, train/raw-loss = 0.48454907536506653, train/logprobs = tensor([[-0.8563, -4.5444],
        [-0.6261, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060289815068245
Epoch 0, Step 281: train/loss = 0.5723638534545898, train/raw-loss = 0.5453919172286987, train/logprobs = tensor([[-0.5833, -1.2926],
        [-0.4806, -0.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08990631252527237
Epoch 0, Step 282: train/loss = 0.5855355858802795, train/raw-loss = 0.5373984575271606, train/logprobs = tensor([[-1.3575, -3.5547],
        [-0.8442, -1.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16045701503753662
Epoch 0, Step 283: train/loss = 0.51785808801651, train/raw-loss = 0.48729127645492554, train/logprobs = tensor([[-0.8273, -2.4572],
        [-0.6202, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10188929736614227
Epoch 0, Step 284: train/loss = 0.5621976852416992, train/raw-loss = 0.53562331199646, train/logprobs = tensor([[-0.5036, -1.4901],
        [-0.4833, -0.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885811373591423
Epoch 0, Step 285: train/loss = 0.5977640151977539, train/raw-loss = 0.5660141706466675, train/logprobs = tensor([[-0.5999, -1.2518],
        [-0.5747, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058327779173851
Epoch 0, Step 286: train/loss = 0.5227921009063721, train/raw-loss = 0.494945228099823, train/logprobs = tensor([[-0.4287, -1.9051],
        [-0.3420, -0.5018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09282267093658447
Epoch 0, Step 287: train/loss = 0.5129499435424805, train/raw-loss = 0.4757416248321533, train/logprobs = tensor([[-0.8181, -4.0699],
        [-0.7681, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12402776628732681
Epoch 0, Step 288: train/loss = 0.5456435680389404, train/raw-loss = 0.5130101442337036, train/logprobs = tensor([[-0.5991, -1.7892],
        [-0.6116, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10877810418605804
Epoch 0, Step 289: train/loss = 0.516853928565979, train/raw-loss = 0.4806911051273346, train/logprobs = tensor([[-0.8707, -3.3469],
        [-0.7660, -1.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12054266035556793
Epoch 0, Step 290: train/loss = 0.5155229568481445, train/raw-loss = 0.4826657772064209, train/logprobs = tensor([[-0.5868, -3.0316],
        [-0.5407, -1.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10952380299568176
Epoch 0, Step 291: train/loss = 0.45464783906936646, train/raw-loss = 0.41980236768722534, train/logprobs = tensor([[-0.7325, -2.4108],
        [-0.7665, -0.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11615152657032013
Epoch 0, Step 292: train/loss = 0.5519641041755676, train/raw-loss = 0.5188500881195068, train/logprobs = tensor([[-0.6273, -1.4891],
        [-0.6911, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11038009822368622
Epoch 0, Step 293: train/loss = 0.5426321625709534, train/raw-loss = 0.5053139925003052, train/logprobs = tensor([[-0.8055, -2.3675],
        [-0.7198, -1.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1243937611579895
Epoch 0, Step 294: train/loss = 0.5539109706878662, train/raw-loss = 0.5207301378250122, train/logprobs = tensor([[-0.9762, -1.8721],
        [-0.7841, -0.5358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11060275882482529
Epoch 0, Step 295: train/loss = 0.5313565731048584, train/raw-loss = 0.49290353059768677, train/logprobs = tensor([[-1.5260, -3.1467],
        [-1.3296, -1.3808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12817659974098206
Epoch 0, Step 296: train/loss = 0.569216251373291, train/raw-loss = 0.538141131401062, train/logprobs = tensor([[-0.7190, -2.0119],
        [-0.6587, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358349233865738
Epoch 0, Step 297: train/loss = 0.4564986228942871, train/raw-loss = 0.42295998334884644, train/logprobs = tensor([[-0.6427, -3.6166],
        [-0.6680, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11179548501968384
Epoch 0, Step 298: train/loss = 0.5341506004333496, train/raw-loss = 0.5061394572257996, train/logprobs = tensor([[-0.5813, -1.6569],
        [-0.6862, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09337051212787628
Epoch 0, Step 299: train/loss = 0.4617222547531128, train/raw-loss = 0.4290199875831604, train/logprobs = tensor([[-1.0451, -3.1571],
        [-1.0083, -0.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10900752246379852
Epoch 0, Step 300: train/loss = 0.5122040510177612, train/raw-loss = 0.4805328845977783, train/logprobs = tensor([[-0.7637, -2.6523],
        [-0.8039, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10557042807340622
Epoch 0, Step 301: train/loss = 0.5597227215766907, train/raw-loss = 0.5295732021331787, train/logprobs = tensor([[-0.6651, -1.3572],
        [-0.6122, -0.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10049831867218018
Epoch 0, Step 302: train/loss = 0.4866659939289093, train/raw-loss = 0.45355314016342163, train/logprobs = tensor([[-0.6761, -2.3865],
        [-0.6167, -0.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11037616431713104
Epoch 0, Step 303: train/loss = 0.44549548625946045, train/raw-loss = 0.4112018048763275, train/logprobs = tensor([[-0.5601, -2.9016],
        [-0.5754, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11431237310171127
Epoch 0, Step 304: train/loss = 0.5457297563552856, train/raw-loss = 0.513132631778717, train/logprobs = tensor([[-0.6489, -1.8000],
        [-0.6374, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10865719616413116
Epoch 0, Step 305: train/loss = 0.5403128862380981, train/raw-loss = 0.5077827572822571, train/logprobs = tensor([[-0.9269, -2.9865],
        [-0.5562, -0.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843370109796524
Epoch 0, Step 306: train/loss = 0.5796943306922913, train/raw-loss = 0.5451892614364624, train/logprobs = tensor([[-0.8344, -3.5866],
        [-0.6936, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11501692980527878
Epoch 0, Step 307: train/loss = 0.5544874668121338, train/raw-loss = 0.518430233001709, train/logprobs = tensor([[-0.8725, -4.0771],
        [-0.8577, -1.5232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1201908066868782
Epoch 0, Step 308: train/loss = 0.5861866474151611, train/raw-loss = 0.5557148456573486, train/logprobs = tensor([[-0.7272, -1.4617],
        [-0.6477, -0.6875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10157260298728943
Epoch 0, Step 309: train/loss = 0.5872975587844849, train/raw-loss = 0.5576210618019104, train/logprobs = tensor([[-0.5370, -1.4801],
        [-0.4728, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09892164170742035
Epoch 0, Step 310: train/loss = 0.40331003069877625, train/raw-loss = 0.3659628629684448, train/logprobs = tensor([[-0.7097, -4.4665],
        [-0.5537, -0.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12449061870574951
Epoch 0, Step 311: train/loss = 0.5494296550750732, train/raw-loss = 0.5190169811248779, train/logprobs = tensor([[-0.5848, -2.6904],
        [-0.6128, -1.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10137554258108139
Epoch 0, Step 312: train/loss = 0.5874282121658325, train/raw-loss = 0.5567967891693115, train/logprobs = tensor([[-0.6791, -3.3758],
        [-0.5347, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10210476070642471
Epoch 0, Step 313: train/loss = 0.4820142984390259, train/raw-loss = 0.446333646774292, train/logprobs = tensor([[-0.6560, -2.4682],
        [-0.6359, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11893542110919952
Epoch 0, Step 314: train/loss = 0.6233750581741333, train/raw-loss = 0.5938440561294556, train/logprobs = tensor([[-0.6342, -0.9247],
        [-0.6273, -0.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843656420707703
Epoch 0, Step 315: train/loss = 0.5969001054763794, train/raw-loss = 0.5611857175827026, train/logprobs = tensor([[-2.0131, -3.8647],
        [-1.4731, -1.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11904797703027725
Epoch 0, Step 316: train/loss = 0.6997110843658447, train/raw-loss = 0.6706581115722656, train/logprobs = tensor([[-0.7636, -0.7197],
        [-0.7574, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09684325009584427
Epoch 0, Step 317: train/loss = 0.4314907193183899, train/raw-loss = 0.3991329073905945, train/logprobs = tensor([[-0.4905, -4.6797],
        [-0.4954, -1.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1078592985868454
Epoch 0, Step 318: train/loss = 0.4555701017379761, train/raw-loss = 0.42366689443588257, train/logprobs = tensor([[-0.7757, -2.8852],
        [-0.7563, -0.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10634393990039825
Epoch 0, Step 319: train/loss = 0.47707605361938477, train/raw-loss = 0.44591954350471497, train/logprobs = tensor([[-0.5671, -2.8666],
        [-0.5803, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385505110025406
Epoch 0, Step 320: train/loss = 0.5267132520675659, train/raw-loss = 0.49646541476249695, train/logprobs = tensor([[-0.8678, -2.7192],
        [-0.6755, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10082598030567169
Epoch 0, Step 321: train/loss = 0.548213541507721, train/raw-loss = 0.5215148329734802, train/logprobs = tensor([[-0.6573, -1.7511],
        [-0.6377, -0.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899558335542679
Epoch 0, Step 322: train/loss = 0.4527982175350189, train/raw-loss = 0.4238000512123108, train/logprobs = tensor([[-1.0313, -3.9291],
        [-0.9235, -1.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09666058421134949
Epoch 0, Step 323: train/loss = 0.5017021894454956, train/raw-loss = 0.47325122356414795, train/logprobs = tensor([[-0.4388, -2.3537],
        [-0.4524, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483658522367477
Epoch 0, Step 324: train/loss = 0.370138943195343, train/raw-loss = 0.337403267621994, train/logprobs = tensor([[-0.8188, -5.3996],
        [-0.6850, -1.3405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091189980506897
Epoch 0, Step 325: train/loss = 0.6179550886154175, train/raw-loss = 0.5910195112228394, train/logprobs = tensor([[-0.6327, -1.1917],
        [-0.5888, -0.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978529274463654
Epoch 0, Step 326: train/loss = 0.40630221366882324, train/raw-loss = 0.37472301721572876, train/logprobs = tensor([[-0.9051, -4.9189],
        [-1.0476, -1.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10526415705680847
Epoch 0, Step 327: train/loss = 0.7156476974487305, train/raw-loss = 0.678301215171814, train/logprobs = tensor([[-0.8737, -1.1002],
        [-0.6644, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12448859214782715
Epoch 0, Step 328: train/loss = 0.617828369140625, train/raw-loss = 0.5893036127090454, train/logprobs = tensor([[-0.8740, -1.7371],
        [-0.8366, -0.9748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508220851421356
Epoch 0, Step 329: train/loss = 0.5988805294036865, train/raw-loss = 0.5678576231002808, train/logprobs = tensor([[-1.1073, -1.6170],
        [-0.8932, -0.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10340975224971771
Epoch 0, Step 330: train/loss = 0.3541218042373657, train/raw-loss = 0.32339340448379517, train/logprobs = tensor([[-0.7013, -4.4293],
        [-0.6687, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1024278849363327
Epoch 0, Step 331: train/loss = 0.47048425674438477, train/raw-loss = 0.44603654742240906, train/logprobs = tensor([[-0.6465, -4.0605],
        [-0.6239, -0.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08149246871471405
Epoch 0, Step 332: train/loss = 0.4181180000305176, train/raw-loss = 0.3854152262210846, train/logprobs = tensor([[-0.8038, -3.8208],
        [-0.9129, -1.4263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10900913178920746
Epoch 0, Step 333: train/loss = 0.5158392190933228, train/raw-loss = 0.48535725474357605, train/logprobs = tensor([[-0.8028, -2.8212],
        [-0.6447, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10160648822784424
Epoch 0, Step 334: train/loss = 0.6437524557113647, train/raw-loss = 0.6160300970077515, train/logprobs = tensor([[-0.7575, -0.9553],
        [-0.6629, -0.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0924077033996582
Epoch 0, Step 335: train/loss = 0.45068222284317017, train/raw-loss = 0.42125654220581055, train/logprobs = tensor([[-0.6703, -2.4282],
        [-0.5786, -0.6050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09808559715747833
Epoch 0, Step 336: train/loss = 0.5281189680099487, train/raw-loss = 0.497206449508667, train/logprobs = tensor([[-0.5660, -1.7447],
        [-0.6188, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10304169356822968
Epoch 0, Step 337: train/loss = 0.5055822134017944, train/raw-loss = 0.47167500853538513, train/logprobs = tensor([[-0.9087, -2.2850],
        [-0.8991, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11302395910024643
Epoch 0, Step 338: train/loss = 0.519616425037384, train/raw-loss = 0.4897018074989319, train/logprobs = tensor([[-0.5789, -1.7271],
        [-0.5767, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09971538186073303
Epoch 0, Step 339: train/loss = 0.4571842551231384, train/raw-loss = 0.4324052929878235, train/logprobs = tensor([[-0.3824, -4.2720],
        [-0.4088, -1.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08259648084640503
Epoch 0, Step 340: train/loss = 0.6110444068908691, train/raw-loss = 0.5844579935073853, train/logprobs = tensor([[-0.8444, -1.4422],
        [-0.7476, -0.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08862148225307465
Epoch 0, Step 341: train/loss = 0.3918725252151489, train/raw-loss = 0.36230045557022095, train/logprobs = tensor([[-0.6326, -3.2472],
        [-0.7018, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09857356548309326
Epoch 0, Step 342: train/loss = 0.5026553869247437, train/raw-loss = 0.4765048027038574, train/logprobs = tensor([[-0.5830, -2.7777],
        [-0.6282, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08716851472854614
Epoch 0, Step 343: train/loss = 0.5801029205322266, train/raw-loss = 0.5511153936386108, train/logprobs = tensor([[-0.6855, -2.0894],
        [-0.6932, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09662504494190216
Epoch 0, Step 344: train/loss = 0.43672800064086914, train/raw-loss = 0.40508216619491577, train/logprobs = tensor([[-1.0023, -5.6437],
        [-0.8406, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10548600554466248
Epoch 0, Step 345: train/loss = 0.4898875653743744, train/raw-loss = 0.4583986699581146, train/logprobs = tensor([[-1.2087, -4.0254],
        [-1.1889, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10496298968791962
Epoch 0, Step 346: train/loss = 0.5091790556907654, train/raw-loss = 0.4768868088722229, train/logprobs = tensor([[-0.8059, -3.8621],
        [-0.7584, -1.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764078050851822
Epoch 0, Step 347: train/loss = 0.5047401189804077, train/raw-loss = 0.4777856469154358, train/logprobs = tensor([[-0.6261, -4.3016],
        [-0.6501, -1.4470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08984813839197159
Epoch 0, Step 348: train/loss = 0.5257471799850464, train/raw-loss = 0.4992028474807739, train/logprobs = tensor([[-0.7622, -3.2079],
        [-0.8121, -1.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08848103880882263
Epoch 0, Step 349: train/loss = 0.40932172536849976, train/raw-loss = 0.37566542625427246, train/logprobs = tensor([[-0.7331, -2.9663],
        [-0.7688, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11218787729740143
Epoch 0, Step 350: train/loss = 0.6046103239059448, train/raw-loss = 0.5688039064407349, train/logprobs = tensor([[-1.2900, -2.5858],
        [-1.0313, -1.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11935503780841827
Epoch 0, Step 351: train/loss = 0.5247706770896912, train/raw-loss = 0.49420711398124695, train/logprobs = tensor([[-0.7596, -2.5511],
        [-0.7525, -1.1327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10187855362892151
Epoch 0, Step 352: train/loss = 0.4493335485458374, train/raw-loss = 0.42350292205810547, train/logprobs = tensor([[-0.5248, -3.7278],
        [-0.6155, -1.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610205352306366
Epoch 0, Step 353: train/loss = 0.40151381492614746, train/raw-loss = 0.36959075927734375, train/logprobs = tensor([[-0.7347, -4.4930],
        [-0.8756, -1.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10641013085842133
Epoch 0, Step 354: train/loss = 0.6262581944465637, train/raw-loss = 0.6001734733581543, train/logprobs = tensor([[-0.4908, -0.9852],
        [-0.5310, -0.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08694888651371002
Epoch 0, Step 355: train/loss = 0.5155925750732422, train/raw-loss = 0.484430730342865, train/logprobs = tensor([[-0.7581, -2.4963],
        [-0.8230, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10387291014194489
Epoch 0, Step 356: train/loss = 0.6210955381393433, train/raw-loss = 0.5905652642250061, train/logprobs = tensor([[-0.5248, -1.0980],
        [-0.5086, -0.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176753997802734
Epoch 0, Step 357: train/loss = 0.6589010953903198, train/raw-loss = 0.6235231757164001, train/logprobs = tensor([[-1.9397, -2.5511],
        [-1.5515, -1.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.117926225066185
Epoch 0, Step 358: train/loss = 0.5262125730514526, train/raw-loss = 0.5022808313369751, train/logprobs = tensor([[-0.5388, -3.9970],
        [-0.5149, -1.3958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07977224886417389
Epoch 0, Step 359: train/loss = 0.5774508118629456, train/raw-loss = 0.5460893511772156, train/logprobs = tensor([[-0.9516, -1.9971],
        [-0.8824, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453835129737854
Epoch 0, Step 360: train/loss = 0.5381363034248352, train/raw-loss = 0.5056108236312866, train/logprobs = tensor([[-0.9301, -2.6113],
        [-0.8520, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10841819643974304
Epoch 0, Step 361: train/loss = 0.5616612434387207, train/raw-loss = 0.529643177986145, train/logprobs = tensor([[-0.6471, -1.2656],
        [-0.7142, -0.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10672683268785477
Epoch 0, Step 362: train/loss = 0.594836950302124, train/raw-loss = 0.5658615827560425, train/logprobs = tensor([[-0.6952, -1.7870],
        [-0.7030, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09658453613519669
Epoch 0, Step 363: train/loss = 0.7364225387573242, train/raw-loss = 0.7109335660934448, train/logprobs = tensor([[-1.2880, -1.1773],
        [-0.9243, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08496313542127609
Epoch 0, Step 364: train/loss = 0.39931029081344604, train/raw-loss = 0.37085145711898804, train/logprobs = tensor([[-0.4251, -5.1794],
        [-0.5616, -1.2793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09486285597085953
Epoch 0, Step 365: train/loss = 0.43435564637184143, train/raw-loss = 0.4053734540939331, train/logprobs = tensor([[-0.5675, -2.6259],
        [-0.6227, -0.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09660740196704865
Epoch 0, Step 366: train/loss = 0.5301889181137085, train/raw-loss = 0.5017014145851135, train/logprobs = tensor([[-0.6027, -2.6265],
        [-0.6083, -0.5420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09495821595191956
Epoch 0, Step 367: train/loss = 0.43737104535102844, train/raw-loss = 0.40822285413742065, train/logprobs = tensor([[-0.6143, -3.3663],
        [-0.7123, -0.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09716060757637024
Epoch 0, Step 368: train/loss = 0.47537389397621155, train/raw-loss = 0.447863906621933, train/logprobs = tensor([[-0.4336, -2.4717],
        [-0.4433, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916999951004982
Epoch 0, Step 369: train/loss = 0.49784520268440247, train/raw-loss = 0.4708820581436157, train/logprobs = tensor([[-0.4603, -1.9361],
        [-0.5485, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987712860107422
Epoch 0, Step 370: train/loss = 0.6436865925788879, train/raw-loss = 0.6193166971206665, train/logprobs = tensor([[-0.4188, -0.8413],
        [-0.4314, -0.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08123284578323364
Epoch 0, Step 371: train/loss = 0.49448633193969727, train/raw-loss = 0.46925443410873413, train/logprobs = tensor([[-0.4440, -3.2330],
        [-0.4799, -1.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08410632610321045
Epoch 0, Step 372: train/loss = 0.4376400411128998, train/raw-loss = 0.4138410985469818, train/logprobs = tensor([[-0.5622, -3.1885],
        [-0.5654, -0.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07932962477207184
Epoch 0, Step 373: train/loss = 0.5328248143196106, train/raw-loss = 0.5006970167160034, train/logprobs = tensor([[-0.8255, -4.2922],
        [-0.7361, -1.4230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10709275305271149
Epoch 0, Step 374: train/loss = 0.5279340147972107, train/raw-loss = 0.5016597509384155, train/logprobs = tensor([[-0.3244, -2.2549],
        [-0.3641, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08758096396923065
Epoch 0, Step 375: train/loss = 0.5083070993423462, train/raw-loss = 0.47636115550994873, train/logprobs = tensor([[-0.7679, -1.6284],
        [-0.9699, -0.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10648643225431442
Epoch 0, Step 376: train/loss = 0.42135247588157654, train/raw-loss = 0.389504075050354, train/logprobs = tensor([[-0.6485, -4.5650],
        [-0.8617, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10616128146648407
Epoch 0, Step 377: train/loss = 0.5720895528793335, train/raw-loss = 0.5411754846572876, train/logprobs = tensor([[-0.6709, -2.7760],
        [-0.6014, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1030469536781311
Epoch 0, Step 378: train/loss = 0.5371249914169312, train/raw-loss = 0.5102636814117432, train/logprobs = tensor([[-0.7369, -3.6010],
        [-0.7132, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953776955604553
Epoch 0, Step 379: train/loss = 0.6026248931884766, train/raw-loss = 0.5733639001846313, train/logprobs = tensor([[-0.9709, -2.1071],
        [-0.8685, -0.8862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09753645956516266
Epoch 0, Step 380: train/loss = 0.5144135355949402, train/raw-loss = 0.48450547456741333, train/logprobs = tensor([[-0.6234, -1.9006],
        [-0.6664, -0.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09969354420900345
Epoch 0, Step 381: train/loss = 0.4447701871395111, train/raw-loss = 0.41018611192703247, train/logprobs = tensor([[-0.7055, -3.8102],
        [-0.9274, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11528024077415466
Epoch 0, Step 382: train/loss = 0.3926197588443756, train/raw-loss = 0.36497125029563904, train/logprobs = tensor([[-0.5883, -3.6625],
        [-0.6188, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09216174483299255
Epoch 0, Step 383: train/loss = 0.4316873848438263, train/raw-loss = 0.4006790518760681, train/logprobs = tensor([[-0.4830, -2.5722],
        [-0.6279, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336114466190338
Epoch 0, Step 384: train/loss = 0.4905230402946472, train/raw-loss = 0.45407626032829285, train/logprobs = tensor([[-0.8297, -5.8021],
        [-0.9655, -1.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1214892789721489
Epoch 0, Step 385: train/loss = 0.587809681892395, train/raw-loss = 0.5450067520141602, train/logprobs = tensor([[-1.2709, -2.1890],
        [-1.0639, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14267638325691223
Epoch 0, Step 386: train/loss = 0.7063260078430176, train/raw-loss = 0.6765971779823303, train/logprobs = tensor([[-0.8920, -0.8975],
        [-0.7296, -0.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909626841545105
Epoch 0, Step 387: train/loss = 0.4857288599014282, train/raw-loss = 0.45154473185539246, train/logprobs = tensor([[-0.6814, -4.8910],
        [-0.8845, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11394695937633514
Epoch 0, Step 388: train/loss = 0.5382809042930603, train/raw-loss = 0.49826574325561523, train/logprobs = tensor([[-0.7556, -2.3519],
        [-0.8255, -1.1053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13338378071784973
Epoch 0, Step 389: train/loss = 0.450415700674057, train/raw-loss = 0.41135308146476746, train/logprobs = tensor([[-0.6365, -2.6279],
        [-0.7004, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13020871579647064
Epoch 0, Step 390: train/loss = 0.4598422646522522, train/raw-loss = 0.4196251630783081, train/logprobs = tensor([[-1.0699, -2.6133],
        [-1.3881, -1.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13405703008174896
Epoch 0, Step 391: train/loss = 0.5263720750808716, train/raw-loss = 0.4926626980304718, train/logprobs = tensor([[-0.4978, -1.9766],
        [-0.5462, -0.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1123645007610321
Epoch 0, Step 392: train/loss = 0.44157013297080994, train/raw-loss = 0.41191157698631287, train/logprobs = tensor([[-0.4940, -3.3952],
        [-0.6503, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09886178374290466
Epoch 0, Step 393: train/loss = 0.5576392412185669, train/raw-loss = 0.5198602676391602, train/logprobs = tensor([[-0.8336, -2.0798],
        [-0.6668, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12592987716197968
Epoch 0, Step 394: train/loss = 0.4284859597682953, train/raw-loss = 0.3958030939102173, train/logprobs = tensor([[-0.9568, -6.5047],
        [-0.8774, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10894295573234558
Epoch 0, Step 395: train/loss = 0.492144376039505, train/raw-loss = 0.4658586084842682, train/logprobs = tensor([[-0.7090, -5.8480],
        [-0.4928, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08761923015117645
Epoch 0, Step 396: train/loss = 0.5405915379524231, train/raw-loss = 0.505029559135437, train/logprobs = tensor([[-0.7863, -2.0013],
        [-0.7921, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11853994429111481
Epoch 0, Step 397: train/loss = 0.5474773049354553, train/raw-loss = 0.5156685709953308, train/logprobs = tensor([[-0.4955, -2.3220],
        [-0.4747, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10602904111146927
Epoch 0, Step 398: train/loss = 0.39222875237464905, train/raw-loss = 0.3570985198020935, train/logprobs = tensor([[-0.5972, -3.6037],
        [-0.7513, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11710070818662643
Epoch 0, Step 399: train/loss = 0.5778189897537231, train/raw-loss = 0.5417382717132568, train/logprobs = tensor([[-0.8967, -1.4816],
        [-1.0082, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026914209127426
Epoch 0, Step 400: train/loss = 0.5659315586090088, train/raw-loss = 0.5361900329589844, train/logprobs = tensor([[-0.5365, -1.3432],
        [-0.6031, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09913836419582367
Epoch 0, Step 401: train/loss = 0.4290613830089569, train/raw-loss = 0.3962809145450592, train/logprobs = tensor([[-0.8398, -3.5603],
        [-0.8904, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10926811397075653
Epoch 0, Step 402: train/loss = 0.43802469968795776, train/raw-loss = 0.4058603048324585, train/logprobs = tensor([[-0.7016, -3.4559],
        [-0.7173, -0.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10721465945243835
Epoch 0, Step 403: train/loss = 0.5312121510505676, train/raw-loss = 0.5082942247390747, train/logprobs = tensor([[-0.3368, -1.8497],
        [-0.3770, -0.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07639309763908386
Epoch 0, Step 404: train/loss = 0.6401558518409729, train/raw-loss = 0.6094088554382324, train/logprobs = tensor([[-0.5901, -1.2678],
        [-0.5496, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249010473489761
Epoch 0, Step 405: train/loss = 0.558013916015625, train/raw-loss = 0.5306105017662048, train/logprobs = tensor([[-0.4838, -3.3858],
        [-0.5533, -0.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09134472161531448
Epoch 0, Step 406: train/loss = 0.5319253206253052, train/raw-loss = 0.4987771213054657, train/logprobs = tensor([[-0.5807, -2.2321],
        [-0.6013, -0.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11049406975507736
Epoch 0, Step 407: train/loss = 0.592008113861084, train/raw-loss = 0.5675675272941589, train/logprobs = tensor([[-0.5286, -1.1193],
        [-0.5432, -0.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08146868646144867
Epoch 0, Step 408: train/loss = 0.5837207436561584, train/raw-loss = 0.548405647277832, train/logprobs = tensor([[-0.6245, -1.2116],
        [-0.8715, -0.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11771715432405472
Epoch 0, Step 409: train/loss = 0.3167168200016022, train/raw-loss = 0.2812861204147339, train/logprobs = tensor([[-0.8825, -5.0414],
        [-1.2014, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11810244619846344
Epoch 0, Step 410: train/loss = 0.5740628242492676, train/raw-loss = 0.5415472984313965, train/logprobs = tensor([[-0.5926, -2.1234],
        [-0.5795, -1.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838499665260315
Epoch 0, Step 411: train/loss = 0.5268917679786682, train/raw-loss = 0.4877094030380249, train/logprobs = tensor([[-0.5108, -1.7111],
        [-0.5911, -0.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13060784339904785
Epoch 0, Step 412: train/loss = 0.5783080458641052, train/raw-loss = 0.5454372763633728, train/logprobs = tensor([[-0.4803, -1.5263],
        [-0.6084, -0.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10956929624080658
Epoch 0, Step 413: train/loss = 0.5519559979438782, train/raw-loss = 0.5230673551559448, train/logprobs = tensor([[-0.7811, -4.1263],
        [-0.6818, -1.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09629517793655396
Epoch 0, Step 414: train/loss = 0.48875945806503296, train/raw-loss = 0.4619947671890259, train/logprobs = tensor([[-0.4454, -1.8618],
        [-0.5766, -0.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08921553939580917
Epoch 0, Step 415: train/loss = 0.46659862995147705, train/raw-loss = 0.4332200586795807, train/logprobs = tensor([[-0.7815, -4.1947],
        [-0.8615, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11126188933849335
Epoch 0, Step 416: train/loss = 0.6052961349487305, train/raw-loss = 0.5700235366821289, train/logprobs = tensor([[-0.7770, -1.5671],
        [-0.7279, -0.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11757543683052063
Epoch 0, Step 417: train/loss = 0.43168580532073975, train/raw-loss = 0.39136821031570435, train/logprobs = tensor([[-0.6597, -4.3823],
        [-0.9459, -0.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343919038772583
Epoch 0, Step 418: train/loss = 0.4146234095096588, train/raw-loss = 0.3798842430114746, train/logprobs = tensor([[-0.6393, -2.7448],
        [-0.9477, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579713225364685
Epoch 0, Step 419: train/loss = 0.4735581874847412, train/raw-loss = 0.4369388520717621, train/logprobs = tensor([[-0.9564, -3.2287],
        [-0.9427, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206453830003738
Epoch 0, Step 420: train/loss = 0.4884885549545288, train/raw-loss = 0.4517633318901062, train/logprobs = tensor([[-0.7499, -3.2556],
        [-0.8680, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241753935813904
Epoch 0, Step 421: train/loss = 0.40062519907951355, train/raw-loss = 0.3592624366283417, train/logprobs = tensor([[-0.7186, -2.6426],
        [-1.0545, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13787594437599182
Epoch 0, Step 422: train/loss = 0.3957868218421936, train/raw-loss = 0.35388338565826416, train/logprobs = tensor([[-1.0357, -4.4745],
        [-1.0708, -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13967806100845337
Epoch 0, Step 423: train/loss = 0.5145959258079529, train/raw-loss = 0.48099273443222046, train/logprobs = tensor([[-0.6209, -3.2897],
        [-0.5974, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11201062798500061
Epoch 0, Step 424: train/loss = 0.39295339584350586, train/raw-loss = 0.3583964407444, train/logprobs = tensor([[-0.6396, -4.3752],
        [-0.7891, -1.1784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11518979072570801
Epoch 0, Step 425: train/loss = 0.8701568245887756, train/raw-loss = 0.8400397300720215, train/logprobs = tensor([[-2.0697, -3.3014],
        [-0.7298, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039015859365463
Epoch 0, Step 426: train/loss = 0.4600940942764282, train/raw-loss = 0.41434746980667114, train/logprobs = tensor([[-0.9321, -2.8473],
        [-1.0449, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15248873829841614
Epoch 0, Step 427: train/loss = 0.4134041368961334, train/raw-loss = 0.37648966908454895, train/logprobs = tensor([[-0.6133, -2.9930],
        [-0.7122, -0.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12304822355508804
Epoch 0, Step 428: train/loss = 0.7589272260665894, train/raw-loss = 0.7199058532714844, train/logprobs = tensor([[-1.1463, -1.2910],
        [-0.6770, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13007095456123352
Epoch 0, Step 429: train/loss = 0.4015258848667145, train/raw-loss = 0.3670695424079895, train/logprobs = tensor([[-0.6040, -3.0698],
        [-0.7827, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485442519187927
Epoch 0, Step 430: train/loss = 0.5160956978797913, train/raw-loss = 0.4831801950931549, train/logprobs = tensor([[-0.6585, -3.3570],
        [-0.6854, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10971841216087341
Epoch 0, Step 431: train/loss = 0.4961869716644287, train/raw-loss = 0.4592258930206299, train/logprobs = tensor([[-0.7030, -1.6125],
        [-0.8362, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12320367246866226
Epoch 0, Step 432: train/loss = 0.5789836645126343, train/raw-loss = 0.5410826802253723, train/logprobs = tensor([[-0.7637, -1.3029],
        [-0.9152, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12633675336837769
Epoch 0, Step 433: train/loss = 0.5573663711547852, train/raw-loss = 0.5256263613700867, train/logprobs = tensor([[-0.6797, -1.7075],
        [-0.7245, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10579998046159744
Epoch 0, Step 434: train/loss = 0.36609625816345215, train/raw-loss = 0.3214414715766907, train/logprobs = tensor([[-0.8420, -4.7832],
        [-0.8591, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14884932339191437
Epoch 0, Step 435: train/loss = 0.5553922057151794, train/raw-loss = 0.5104295015335083, train/logprobs = tensor([[-1.5059, -3.1664],
        [-0.9545, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14987562596797943
Epoch 0, Step 436: train/loss = 0.44579121470451355, train/raw-loss = 0.4070872664451599, train/logprobs = tensor([[-0.8546, -4.3417],
        [-1.0649, -1.4276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901310622692108
Epoch 0, Step 437: train/loss = 0.4496888518333435, train/raw-loss = 0.41318318247795105, train/logprobs = tensor([[-0.6851, -3.5643],
        [-0.8127, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168557941913605
Epoch 0, Step 438: train/loss = 0.4952949285507202, train/raw-loss = 0.46025294065475464, train/logprobs = tensor([[-0.5352, -2.6614],
        [-0.6368, -0.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1168065071105957
Epoch 0, Step 439: train/loss = 0.5753989815711975, train/raw-loss = 0.5427583456039429, train/logprobs = tensor([[-0.5164, -1.2464],
        [-0.5953, -0.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10880208015441895
Epoch 0, Step 440: train/loss = 0.6062049865722656, train/raw-loss = 0.5681406855583191, train/logprobs = tensor([[-0.9114, -1.8502],
        [-0.6729, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12688088417053223
Epoch 0, Step 441: train/loss = 0.6734240055084229, train/raw-loss = 0.639833390712738, train/logprobs = tensor([[-1.0830, -1.6493],
        [-0.6752, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11196857690811157
Epoch 0, Step 442: train/loss = 0.6095408201217651, train/raw-loss = 0.5713271498680115, train/logprobs = tensor([[-0.5296, -1.1431],
        [-0.5778, -0.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12737874686717987
Epoch 0, Step 443: train/loss = 0.7619138360023499, train/raw-loss = 0.7222919464111328, train/logprobs = tensor([[-1.8506, -1.5287],
        [-1.1918, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13207300007343292
Epoch 0, Step 444: train/loss = 0.48653268814086914, train/raw-loss = 0.4441823363304138, train/logprobs = tensor([[-1.0039, -2.7214],
        [-0.7550, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14116781949996948
Epoch 0, Step 445: train/loss = 0.4362548589706421, train/raw-loss = 0.3951347768306732, train/logprobs = tensor([[-0.6641, -3.2362],
        [-0.7832, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13706697523593903
Epoch 0, Step 446: train/loss = 0.5243786573410034, train/raw-loss = 0.48976922035217285, train/logprobs = tensor([[-0.9303, -2.3493],
        [-0.8262, -0.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11536486446857452
Epoch 0, Step 447: train/loss = 0.4075956344604492, train/raw-loss = 0.3671550154685974, train/logprobs = tensor([[-1.1046, -5.8864],
        [-0.8436, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13480210304260254
Epoch 0, Step 448: train/loss = 0.3786153197288513, train/raw-loss = 0.34084224700927734, train/logprobs = tensor([[-0.6312, -5.5271],
        [-0.7944, -1.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12591029703617096
Epoch 0, Step 449: train/loss = 0.6210681796073914, train/raw-loss = 0.586188793182373, train/logprobs = tensor([[-0.8342, -1.9974],
        [-0.7860, -0.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11626454442739487
Epoch 0, Step 450: train/loss = 0.6015085577964783, train/raw-loss = 0.5613995790481567, train/logprobs = tensor([[-1.0473, -2.0075],
        [-1.1050, -0.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336965709924698
Epoch 0, Step 451: train/loss = 0.5291826725006104, train/raw-loss = 0.49129801988601685, train/logprobs = tensor([[-0.7875, -1.7102],
        [-0.8577, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12628227472305298
Epoch 0, Step 452: train/loss = 0.35473498702049255, train/raw-loss = 0.31568923592567444, train/logprobs = tensor([[-0.7496, -6.6918],
        [-1.0829, -1.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.130152627825737
Epoch 0, Step 453: train/loss = 0.3666837513446808, train/raw-loss = 0.3308364450931549, train/logprobs = tensor([[-0.6221, -4.6476],
        [-0.9013, -1.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11949092149734497
Epoch 0, Step 454: train/loss = 0.549201250076294, train/raw-loss = 0.5197139978408813, train/logprobs = tensor([[-0.3952, -2.8067],
        [-0.4673, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09829097986221313
Epoch 0, Step 455: train/loss = 0.3896934688091278, train/raw-loss = 0.35404548048973083, train/logprobs = tensor([[-0.7159, -3.7939],
        [-0.9334, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11882658302783966
Epoch 0, Step 456: train/loss = 0.6446883678436279, train/raw-loss = 0.5968994498252869, train/logprobs = tensor([[-0.8687, -1.4274],
        [-0.8995, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15929652750492096
Epoch 0, Step 457: train/loss = 0.4254612624645233, train/raw-loss = 0.3818221390247345, train/logprobs = tensor([[-0.5652, -2.8580],
        [-0.8771, -0.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1454637497663498
Epoch 0, Step 458: train/loss = 0.3936081826686859, train/raw-loss = 0.3551074266433716, train/logprobs = tensor([[-0.5791, -5.0742],
        [-0.8021, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12833595275878906
Epoch 0, Step 459: train/loss = 0.43090564012527466, train/raw-loss = 0.38906529545783997, train/logprobs = tensor([[-0.7437, -3.0676],
        [-0.8360, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1394677758216858
Epoch 0, Step 460: train/loss = 0.478253573179245, train/raw-loss = 0.4381710886955261, train/logprobs = tensor([[-0.7624, -3.4050],
        [-0.8463, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13360829651355743
Epoch 0, Step 461: train/loss = 0.4739021062850952, train/raw-loss = 0.4338974952697754, train/logprobs = tensor([[-1.0971, -3.4274],
        [-0.9745, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333487331867218
Epoch 0, Step 462: train/loss = 0.5037835240364075, train/raw-loss = 0.4619961380958557, train/logprobs = tensor([[-0.8504, -2.0054],
        [-0.9921, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13929134607315063
Epoch 0, Step 463: train/loss = 0.4854917824268341, train/raw-loss = 0.4467836022377014, train/logprobs = tensor([[-0.8661, -2.1827],
        [-1.1194, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12902729213237762
Epoch 0, Step 464: train/loss = 0.3676856756210327, train/raw-loss = 0.3257879316806793, train/logprobs = tensor([[-0.5473, -4.5900],
        [-0.8807, -1.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13965924084186554
Epoch 0, Step 465: train/loss = 0.525994598865509, train/raw-loss = 0.48673322796821594, train/logprobs = tensor([[-0.6109, -1.6478],
        [-0.9199, -0.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13087129592895508
Epoch 0, Step 466: train/loss = 0.6083652377128601, train/raw-loss = 0.568618893623352, train/logprobs = tensor([[-1.0745, -2.3673],
        [-1.0118, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324876844882965
Epoch 0, Step 467: train/loss = 0.5487161874771118, train/raw-loss = 0.5119608044624329, train/logprobs = tensor([[-0.9505, -2.5076],
        [-0.7555, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12251807749271393
Epoch 0, Step 468: train/loss = 0.2902349829673767, train/raw-loss = 0.24085073173046112, train/logprobs = tensor([[-0.6903, -4.0513],
        [-1.2638, -0.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16461418569087982
Epoch 0, Step 469: train/loss = 0.5683581829071045, train/raw-loss = 0.5353823900222778, train/logprobs = tensor([[-0.5831, -1.7272],
        [-0.8789, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10991932451725006
Epoch 0, Step 470: train/loss = 0.5749930143356323, train/raw-loss = 0.5339813232421875, train/logprobs = tensor([[-0.8829, -2.4166],
        [-0.6459, -0.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13670557737350464
Epoch 0, Step 471: train/loss = 0.3326157033443451, train/raw-loss = 0.2983775734901428, train/logprobs = tensor([[-0.4630, -4.5706],
        [-0.6806, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11412721127271652
Epoch 0, Step 472: train/loss = 0.5031089782714844, train/raw-loss = 0.466739296913147, train/logprobs = tensor([[-0.5149, -3.4954],
        [-0.6720, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123248726129532
Epoch 0, Step 473: train/loss = 0.45579203963279724, train/raw-loss = 0.4144095182418823, train/logprobs = tensor([[-1.1204, -5.2311],
        [-0.8946, -0.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13794174790382385
Epoch 0, Step 474: train/loss = 0.4703482389450073, train/raw-loss = 0.4354188144207001, train/logprobs = tensor([[-0.6097, -2.8943],
        [-0.7883, -0.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11643137037754059
Epoch 0, Step 475: train/loss = 0.36052531003952026, train/raw-loss = 0.31693387031555176, train/logprobs = tensor([[-0.7347, -4.7707],
        [-0.8367, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14530478417873383
Epoch 0, Step 476: train/loss = 0.5061547756195068, train/raw-loss = 0.4673449397087097, train/logprobs = tensor([[-0.4892, -2.0168],
        [-0.4803, -0.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293661743402481
Epoch 0, Step 477: train/loss = 0.43618789315223694, train/raw-loss = 0.39228153228759766, train/logprobs = tensor([[-0.6245, -4.1224],
        [-0.6622, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.146354541182518
Epoch 0, Step 478: train/loss = 0.3408205509185791, train/raw-loss = 0.2986214756965637, train/logprobs = tensor([[-0.8343, -6.5222],
        [-0.8894, -1.3353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14066354930400848
Epoch 0, Step 479: train/loss = 0.5082637667655945, train/raw-loss = 0.47813040018081665, train/logprobs = tensor([[-0.3871, -3.7615],
        [-0.5563, -1.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10044444352388382
Epoch 0, Step 480: train/loss = 0.6405924558639526, train/raw-loss = 0.6085289120674133, train/logprobs = tensor([[-0.4686, -1.1242],
        [-0.5820, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10687857866287231
Epoch 0, Step 481: train/loss = 0.30540651082992554, train/raw-loss = 0.25790390372276306, train/logprobs = tensor([[-0.9430, -5.5274],
        [-1.2002, -1.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583421528339386
Epoch 0, Step 482: train/loss = 0.5368010997772217, train/raw-loss = 0.4974355101585388, train/logprobs = tensor([[-0.7945, -1.4481],
        [-1.0355, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13121859729290009
Epoch 0, Step 483: train/loss = 0.47812560200691223, train/raw-loss = 0.44167980551719666, train/logprobs = tensor([[-0.5287, -3.5543],
        [-0.7901, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12148602306842804
Epoch 0, Step 484: train/loss = 0.4729610085487366, train/raw-loss = 0.4306517541408539, train/logprobs = tensor([[-0.5909, -2.7269],
        [-0.7746, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14103084802627563
Epoch 0, Step 485: train/loss = 0.30289140343666077, train/raw-loss = 0.2559559941291809, train/logprobs = tensor([[-1.0400, -6.6314],
        [-1.4937, -1.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15645140409469604
Epoch 0, Step 486: train/loss = 0.6116556525230408, train/raw-loss = 0.5781401991844177, train/logprobs = tensor([[-0.5195, -1.1446],
        [-0.6816, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171811819076538
Epoch 0, Step 487: train/loss = 0.4954128861427307, train/raw-loss = 0.4616171717643738, train/logprobs = tensor([[-0.9766, -3.2479],
        [-1.0366, -0.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11265243589878082
Epoch 0, Step 488: train/loss = 0.4686071276664734, train/raw-loss = 0.4328182339668274, train/logprobs = tensor([[-0.6180, -4.8500],
        [-0.7136, -1.6272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11929634213447571
Epoch 0, Step 489: train/loss = 0.39521557092666626, train/raw-loss = 0.3502557873725891, train/logprobs = tensor([[-0.5823, -5.9928],
        [-1.0835, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14986595511436462
Epoch 0, Step 490: train/loss = 0.515114426612854, train/raw-loss = 0.4681667685508728, train/logprobs = tensor([[-0.5733, -1.7973],
        [-0.7830, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1564919501543045
Epoch 0, Step 491: train/loss = 0.42043232917785645, train/raw-loss = 0.3748823404312134, train/logprobs = tensor([[-0.9098, -4.5281],
        [-1.3953, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518334001302719
Epoch 0, Step 492: train/loss = 0.416394978761673, train/raw-loss = 0.3759162127971649, train/logprobs = tensor([[-0.8697, -4.5252],
        [-1.2416, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13492926955223083
Epoch 0, Step 493: train/loss = 0.593005895614624, train/raw-loss = 0.5592618584632874, train/logprobs = tensor([[-0.4525, -1.6697],
        [-0.4636, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11248019337654114
Epoch 0, Step 494: train/loss = 0.4783639907836914, train/raw-loss = 0.42950230836868286, train/logprobs = tensor([[-0.8674, -2.0751],
        [-1.3084, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16287235915660858
Epoch 0, Step 495: train/loss = 0.4513276219367981, train/raw-loss = 0.4144366979598999, train/logprobs = tensor([[-0.4917, -4.4114],
        [-0.7722, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12296976894140244
Epoch 0, Step 496: train/loss = 0.45813554525375366, train/raw-loss = 0.4159502387046814, train/logprobs = tensor([[-0.6289, -3.5040],
        [-0.6739, -1.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406177580356598
Epoch 0, Step 497: train/loss = 0.5163518786430359, train/raw-loss = 0.48159554600715637, train/logprobs = tensor([[-0.5037, -1.5164],
        [-0.6733, -0.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11585444211959839
Epoch 0, Step 498: train/loss = 0.3443039655685425, train/raw-loss = 0.2952079176902771, train/logprobs = tensor([[-0.6653, -3.2205],
        [-0.9984, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16365359723567963
Epoch 0, Step 499: train/loss = 0.44366222620010376, train/raw-loss = 0.40584084391593933, train/logprobs = tensor([[-0.6750, -3.9259],
        [-0.9083, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12607133388519287
Epoch 0, Step 500: train/loss = 0.5497332811355591, train/raw-loss = 0.5106323957443237, train/logprobs = tensor([[-0.6573, -2.6734],
        [-0.8917, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13033634424209595
Epoch 0, Step 501: train/loss = 0.4552338421344757, train/raw-loss = 0.41350167989730835, train/logprobs = tensor([[-0.8052, -4.8599],
        [-0.7787, -1.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13910718262195587
Epoch 0, Step 502: train/loss = 0.3417465090751648, train/raw-loss = 0.2967071533203125, train/logprobs = tensor([[-0.5755, -2.7339],
        [-1.1205, -0.7822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15013116598129272
Epoch 0, Step 503: train/loss = 0.67105633020401, train/raw-loss = 0.6406620740890503, train/logprobs = tensor([[-0.6343, -1.0773],
        [-0.5425, -0.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013142317533493
Epoch 0, Step 504: train/loss = 0.42706742882728577, train/raw-loss = 0.392345666885376, train/logprobs = tensor([[-0.5061, -3.7817],
        [-0.6283, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11573921144008636
Epoch 0, Step 505: train/loss = 0.38220542669296265, train/raw-loss = 0.3394291400909424, train/logprobs = tensor([[-0.6458, -6.2455],
        [-1.0761, -1.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425877809524536
Epoch 0, Step 506: train/loss = 0.5540921688079834, train/raw-loss = 0.5184535384178162, train/logprobs = tensor([[-0.6120, -1.7938],
        [-0.7009, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879553645849228
Epoch 0, Step 507: train/loss = 0.5164851546287537, train/raw-loss = 0.47538429498672485, train/logprobs = tensor([[-0.9423, -6.1985],
        [-0.9515, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13700291514396667
Epoch 0, Step 508: train/loss = 0.49943414330482483, train/raw-loss = 0.4586416482925415, train/logprobs = tensor([[-0.6636, -2.3604],
        [-0.8614, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13597506284713745
Epoch 0, Step 509: train/loss = 0.558731198310852, train/raw-loss = 0.5169988870620728, train/logprobs = tensor([[-0.6733, -1.9023],
        [-0.6894, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391076296567917
Epoch 0, Step 510: train/loss = 0.469769150018692, train/raw-loss = 0.43086689710617065, train/logprobs = tensor([[-0.7626, -3.7869],
        [-1.0608, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12967421114444733
Epoch 0, Step 511: train/loss = 0.5135427117347717, train/raw-loss = 0.47382083535194397, train/logprobs = tensor([[-0.8269, -3.6330],
        [-0.8369, -0.7552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324063241481781
Epoch 0, Step 512: train/loss = 0.4660428464412689, train/raw-loss = 0.43104854226112366, train/logprobs = tensor([[-0.7255, -2.3330],
        [-1.2126, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664760112762451
Epoch 0, Step 513: train/loss = 0.4944171905517578, train/raw-loss = 0.45967957377433777, train/logprobs = tensor([[-0.4099, -3.3919],
        [-0.5903, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579222977161407
Epoch 0, Step 514: train/loss = 0.3545132577419281, train/raw-loss = 0.3091576397418976, train/logprobs = tensor([[-0.6150, -4.8099],
        [-1.0888, -1.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15118534862995148
Epoch 0, Step 515: train/loss = 0.7087336778640747, train/raw-loss = 0.6732660531997681, train/logprobs = tensor([[-0.4967, -0.5760],
        [-0.6034, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11822547763586044
Epoch 0, Step 516: train/loss = 0.41338545083999634, train/raw-loss = 0.36961305141448975, train/logprobs = tensor([[-0.7814, -3.0059],
        [-1.2430, -1.3689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14590802788734436
Epoch 0, Step 517: train/loss = 0.43976059556007385, train/raw-loss = 0.4021769165992737, train/logprobs = tensor([[-0.5993, -2.6149],
        [-0.8060, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252788007259369
Epoch 0, Step 518: train/loss = 0.3657497763633728, train/raw-loss = 0.3231319487094879, train/logprobs = tensor([[-0.7845, -5.5642],
        [-1.5919, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14205946028232574
Epoch 0, Step 519: train/loss = 0.3575151264667511, train/raw-loss = 0.3115808367729187, train/logprobs = tensor([[-0.9635, -4.2985],
        [-1.0565, -1.1008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15311424434185028
Epoch 0, Step 520: train/loss = 0.7412855625152588, train/raw-loss = 0.7074294090270996, train/logprobs = tensor([[-1.0398, -1.0416],
        [-0.8097, -0.7465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128537729382515
Epoch 0, Step 521: train/loss = 0.46364402770996094, train/raw-loss = 0.4323350489139557, train/logprobs = tensor([[-0.3505, -2.6949],
        [-0.5563, -0.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436318814754486
Epoch 0, Step 522: train/loss = 0.5945844054222107, train/raw-loss = 0.556980550289154, train/logprobs = tensor([[-1.3379, -3.4623],
        [-0.9181, -0.7833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12534624338150024
Epoch 0, Step 523: train/loss = 0.5134662389755249, train/raw-loss = 0.47756677865982056, train/logprobs = tensor([[-0.5358, -2.3320],
        [-0.6340, -0.7119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966492235660553
Epoch 0, Step 524: train/loss = 0.3091994822025299, train/raw-loss = 0.2694661319255829, train/logprobs = tensor([[-0.4576, -6.4322],
        [-0.8442, -1.3518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13244453072547913
Epoch 0, Step 525: train/loss = 0.5303744673728943, train/raw-loss = 0.4880986511707306, train/logprobs = tensor([[-0.7021, -2.0987],
        [-0.8664, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14091934263706207
Epoch 0, Step 526: train/loss = 0.4727683961391449, train/raw-loss = 0.4445551335811615, train/logprobs = tensor([[-0.3788, -1.9811],
        [-0.6478, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09404413402080536
Epoch 0, Step 527: train/loss = 0.27371546626091003, train/raw-loss = 0.23288872838020325, train/logprobs = tensor([[-0.5400, -4.4928],
        [-1.0937, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13608911633491516
Epoch 0, Step 528: train/loss = 0.3689334988594055, train/raw-loss = 0.33877795934677124, train/logprobs = tensor([[-0.3506, -6.1989],
        [-0.4913, -1.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10051839798688889
Epoch 0, Step 529: train/loss = 0.41228511929512024, train/raw-loss = 0.37178006768226624, train/logprobs = tensor([[-0.6640, -4.7221],
        [-0.9613, -1.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13501684367656708
Epoch 0, Step 530: train/loss = 0.5846481323242188, train/raw-loss = 0.5406105518341064, train/logprobs = tensor([[-0.5886, -1.7908],
        [-1.0695, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14679178595542908
Epoch 0, Step 531: train/loss = 0.5462305545806885, train/raw-loss = 0.5107274055480957, train/logprobs = tensor([[-0.4130, -1.5573],
        [-0.6067, -0.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11834369599819183
Epoch 0, Step 532: train/loss = 0.49572184681892395, train/raw-loss = 0.4563760757446289, train/logprobs = tensor([[-0.6050, -3.1580],
        [-1.0023, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13115251064300537
Epoch 0, Step 533: train/loss = 0.44345545768737793, train/raw-loss = 0.3967409133911133, train/logprobs = tensor([[-0.8870, -4.1576],
        [-0.9319, -1.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15571509301662445
Epoch 0, Step 534: train/loss = 0.5173866748809814, train/raw-loss = 0.47669124603271484, train/logprobs = tensor([[-0.4799, -2.6323],
        [-0.7366, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565145432949066
Epoch 0, Step 535: train/loss = 0.35388556122779846, train/raw-loss = 0.30261489748954773, train/logprobs = tensor([[-0.8417, -4.3566],
        [-1.3727, -1.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17090213298797607
Epoch 0, Step 536: train/loss = 0.407021701335907, train/raw-loss = 0.3675997257232666, train/logprobs = tensor([[-0.7155, -2.8352],
        [-0.8967, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13140663504600525
Epoch 0, Step 537: train/loss = 0.38748884201049805, train/raw-loss = 0.34753456711769104, train/logprobs = tensor([[-0.6575, -2.5068],
        [-1.1589, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331809163093567
Epoch 0, Step 538: train/loss = 0.3874894380569458, train/raw-loss = 0.34604865312576294, train/logprobs = tensor([[-0.8262, -4.7591],
        [-0.7766, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1381361335515976
Epoch 0, Step 539: train/loss = 0.45612502098083496, train/raw-loss = 0.42366355657577515, train/logprobs = tensor([[-0.4398, -3.5926],
        [-0.6596, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10820478200912476
Epoch 0, Step 540: train/loss = 0.4965609014034271, train/raw-loss = 0.45490193367004395, train/logprobs = tensor([[-0.7190, -2.9267],
        [-1.1410, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13886331021785736
Epoch 0, Step 541: train/loss = 0.3310735523700714, train/raw-loss = 0.2883269190788269, train/logprobs = tensor([[-0.8417, -5.9415],
        [-1.4344, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424887776374817
Epoch 0, Step 542: train/loss = 0.4046100080013275, train/raw-loss = 0.3711523115634918, train/logprobs = tensor([[-0.6865, -3.0247],
        [-0.9711, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11152562499046326
Epoch 0, Step 543: train/loss = 0.4232776165008545, train/raw-loss = 0.38744494318962097, train/logprobs = tensor([[-0.5988, -5.1719],
        [-0.7784, -1.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1194421797990799
Epoch 0, Step 544: train/loss = 0.4979936182498932, train/raw-loss = 0.45574188232421875, train/logprobs = tensor([[-0.6544, -2.2651],
        [-0.8462, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14083918929100037
Epoch 0, Step 545: train/loss = 0.3782663941383362, train/raw-loss = 0.33771002292633057, train/logprobs = tensor([[-0.6422, -3.4592],
        [-1.2626, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13518783450126648
Epoch 0, Step 546: train/loss = 0.41852372884750366, train/raw-loss = 0.3810262680053711, train/logprobs = tensor([[-0.4532, -3.1181],
        [-0.7639, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12499159574508667
Epoch 0, Step 547: train/loss = 0.402476966381073, train/raw-loss = 0.36347177624702454, train/logprobs = tensor([[-0.6957, -4.6309],
        [-0.8734, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13001735508441925
Epoch 0, Step 548: train/loss = 0.5414571166038513, train/raw-loss = 0.50567227602005, train/logprobs = tensor([[-0.4853, -1.3080],
        [-0.7735, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192827969789505
Epoch 0, Step 549: train/loss = 0.48435497283935547, train/raw-loss = 0.44185614585876465, train/logprobs = tensor([[-0.9302, -2.2375],
        [-1.3400, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1416626274585724
Epoch 0, Step 550: train/loss = 0.37127700448036194, train/raw-loss = 0.32386770844459534, train/logprobs = tensor([[-1.0388, -4.6732],
        [-1.5292, -1.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803098678588867
Epoch 0, Step 551: train/loss = 0.5449380874633789, train/raw-loss = 0.5055924654006958, train/logprobs = tensor([[-0.6368, -1.8761],
        [-0.8899, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13115203380584717
Epoch 0, Step 552: train/loss = 0.37260913848876953, train/raw-loss = 0.3324583172798157, train/logprobs = tensor([[-0.6851, -3.1062],
        [-1.2402, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13383600115776062
Epoch 0, Step 553: train/loss = 0.4183301329612732, train/raw-loss = 0.377512663602829, train/logprobs = tensor([[-0.4773, -3.0507],
        [-0.8425, -1.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13605822622776031
Epoch 0, Step 554: train/loss = 0.38905656337738037, train/raw-loss = 0.35113146901130676, train/logprobs = tensor([[-0.4997, -4.6190],
        [-0.7422, -1.4331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12641693651676178
Epoch 0, Step 555: train/loss = 0.45461905002593994, train/raw-loss = 0.41390448808670044, train/logprobs = tensor([[-1.0250, -3.2675],
        [-0.9664, -0.6377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13571526110172272
Epoch 0, Step 556: train/loss = 0.4135485291481018, train/raw-loss = 0.3760230541229248, train/logprobs = tensor([[-0.4543, -4.1398],
        [-0.7469, -1.2154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1250849813222885
Epoch 0, Step 557: train/loss = 0.423401415348053, train/raw-loss = 0.3782345950603485, train/logprobs = tensor([[-0.8162, -3.7947],
        [-1.3099, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15055599808692932
Epoch 0, Step 558: train/loss = 0.6438286900520325, train/raw-loss = 0.5987344980239868, train/logprobs = tensor([[-0.7226, -1.1680],
        [-0.9081, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15031394362449646
Epoch 0, Step 559: train/loss = 0.44672122597694397, train/raw-loss = 0.4060535430908203, train/logprobs = tensor([[-0.6940, -3.2913],
        [-0.7400, -0.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13555891811847687
Epoch 0, Step 560: train/loss = 0.5408847332000732, train/raw-loss = 0.5093303918838501, train/logprobs = tensor([[-0.3656, -2.0463],
        [-0.4602, -0.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10518121719360352
Epoch 0, Step 561: train/loss = 0.48146718740463257, train/raw-loss = 0.43988850712776184, train/logprobs = tensor([[-0.5581, -2.1301],
        [-1.0022, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13859565556049347
Epoch 0, Step 562: train/loss = 0.4309229254722595, train/raw-loss = 0.38826271891593933, train/logprobs = tensor([[-0.6914, -3.8058],
        [-1.0574, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14220061898231506
Epoch 0, Step 563: train/loss = 0.49243974685668945, train/raw-loss = 0.45784372091293335, train/logprobs = tensor([[-0.4655, -3.3961],
        [-0.6469, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11532009392976761
Epoch 0, Step 564: train/loss = 0.4953465759754181, train/raw-loss = 0.4507545232772827, train/logprobs = tensor([[-0.6147, -1.8070],
        [-0.9923, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14864009618759155
Epoch 0, Step 565: train/loss = 0.3783707916736603, train/raw-loss = 0.33031004667282104, train/logprobs = tensor([[-0.9074, -3.3389],
        [-1.5961, -1.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16020233929157257
Epoch 0, Step 566: train/loss = 0.4721345007419586, train/raw-loss = 0.43579399585723877, train/logprobs = tensor([[-0.5013, -6.8532],
        [-0.7005, -1.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12113506346940994
Epoch 0, Step 567: train/loss = 0.36175090074539185, train/raw-loss = 0.3155614733695984, train/logprobs = tensor([[-0.5242, -3.5098],
        [-1.1480, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15396472811698914
Epoch 0, Step 568: train/loss = 0.5423681139945984, train/raw-loss = 0.49810051918029785, train/logprobs = tensor([[-0.5592, -3.0208],
        [-1.0259, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14755868911743164
Epoch 0, Step 569: train/loss = 0.35162341594696045, train/raw-loss = 0.29906564950942993, train/logprobs = tensor([[-0.8512, -2.6097],
        [-1.5847, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1751924455165863
Epoch 0, Step 570: train/loss = 0.7140122652053833, train/raw-loss = 0.6697429418563843, train/logprobs = tensor([[-1.6109, -2.5750],
        [-1.0172, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14756432175636292
Epoch 0, Step 571: train/loss = 0.4160528779029846, train/raw-loss = 0.38074859976768494, train/logprobs = tensor([[-0.6653, -3.8539],
        [-0.6940, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11768091470003128
Epoch 0, Step 572: train/loss = 0.4070601761341095, train/raw-loss = 0.37109291553497314, train/logprobs = tensor([[-0.4403, -3.3547],
        [-0.5407, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11989085376262665
Epoch 0, Step 573: train/loss = 0.3679516613483429, train/raw-loss = 0.3271167278289795, train/logprobs = tensor([[-0.5472, -3.8341],
        [-0.7693, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13611654937267303
Epoch 0, Step 574: train/loss = 0.5577359795570374, train/raw-loss = 0.523796796798706, train/logprobs = tensor([[-0.4859, -1.3852],
        [-0.7410, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1131305918097496
Epoch 0, Step 575: train/loss = 0.3649662733078003, train/raw-loss = 0.31796544790267944, train/logprobs = tensor([[-0.6173, -4.0805],
        [-1.2236, -1.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566694974899292
Epoch 0, Step 576: train/loss = 0.5276039838790894, train/raw-loss = 0.4744637608528137, train/logprobs = tensor([[-0.9856, -1.8844],
        [-1.2268, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17713402211666107
Epoch 0, Step 577: train/loss = 0.6078978776931763, train/raw-loss = 0.5585813522338867, train/logprobs = tensor([[-0.7929, -1.7031],
        [-1.0946, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643884927034378
Epoch 0, Step 578: train/loss = 0.34447401762008667, train/raw-loss = 0.2918820083141327, train/logprobs = tensor([[-0.7734, -4.3796],
        [-1.4107, -0.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17530658841133118
Epoch 0, Step 579: train/loss = 0.41432327032089233, train/raw-loss = 0.3736129105091095, train/logprobs = tensor([[-0.8053, -4.5163],
        [-1.1740, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357012242078781
Epoch 0, Step 580: train/loss = 0.39341652393341064, train/raw-loss = 0.3564356565475464, train/logprobs = tensor([[-0.8905, -5.7685],
        [-1.0095, -1.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12326956540346146
Epoch 0, Step 581: train/loss = 0.3686540722846985, train/raw-loss = 0.3252984881401062, train/logprobs = tensor([[-0.6654, -6.1843],
        [-1.1878, -1.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445186734199524
Epoch 0, Step 582: train/loss = 0.5190736055374146, train/raw-loss = 0.4802178144454956, train/logprobs = tensor([[-0.6507, -1.8214],
        [-1.1042, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295192390680313
Epoch 0, Step 583: train/loss = 0.5348796844482422, train/raw-loss = 0.49691325426101685, train/logprobs = tensor([[-0.7854, -2.2390],
        [-0.8442, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265547275543213
Epoch 0, Step 584: train/loss = 0.5056234002113342, train/raw-loss = 0.46901771426200867, train/logprobs = tensor([[-0.5066, -2.0518],
        [-0.8441, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12201887369155884
Epoch 0, Step 585: train/loss = 0.5534412860870361, train/raw-loss = 0.5167217254638672, train/logprobs = tensor([[-0.3332, -2.3000],
        [-0.5045, -0.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12239845097064972
Epoch 0, Step 586: train/loss = 0.4311935305595398, train/raw-loss = 0.379925012588501, train/logprobs = tensor([[-0.7907, -2.0426],
        [-1.3637, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1708950698375702
Epoch 0, Step 587: train/loss = 0.5300098657608032, train/raw-loss = 0.490811824798584, train/logprobs = tensor([[-0.6785, -1.4982],
        [-1.0307, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13066014647483826
Epoch 0, Step 588: train/loss = 0.3899666368961334, train/raw-loss = 0.34961551427841187, train/logprobs = tensor([[-0.7797, -4.6433],
        [-1.4210, -1.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13450367748737335
Epoch 0, Step 589: train/loss = 0.40734949707984924, train/raw-loss = 0.3598552346229553, train/logprobs = tensor([[-0.6682, -3.4173],
        [-1.1220, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583143174648285
Epoch 0, Step 590: train/loss = 0.3372194766998291, train/raw-loss = 0.2997818887233734, train/logprobs = tensor([[-0.5569, -4.6245],
        [-0.8423, -1.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12479196488857269
Epoch 0, Step 591: train/loss = 0.6605703830718994, train/raw-loss = 0.6172158718109131, train/logprobs = tensor([[-0.6561, -0.8516],
        [-0.7763, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445152312517166
Epoch 0, Step 592: train/loss = 0.5077791810035706, train/raw-loss = 0.46690601110458374, train/logprobs = tensor([[-0.5665, -1.9224],
        [-0.8755, -0.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13624384999275208
Epoch 0, Step 593: train/loss = 0.44979095458984375, train/raw-loss = 0.40687060356140137, train/logprobs = tensor([[-0.5478, -2.8041],
        [-0.8851, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.143067866563797
Epoch 0, Step 594: train/loss = 0.3268236815929413, train/raw-loss = 0.27976036071777344, train/logprobs = tensor([[-0.6946, -3.5405],
        [-1.0984, -0.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15687774121761322
Epoch 0, Step 595: train/loss = 0.5292683243751526, train/raw-loss = 0.4874624013900757, train/logprobs = tensor([[-0.5734, -1.9247],
        [-0.8301, -1.0015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13935303688049316
Epoch 0, Step 596: train/loss = 0.4623679518699646, train/raw-loss = 0.4215608239173889, train/logprobs = tensor([[-0.7139, -4.2606],
        [-1.0123, -1.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360236555337906
Epoch 0, Step 597: train/loss = 0.6459176540374756, train/raw-loss = 0.6034038066864014, train/logprobs = tensor([[-0.6176, -0.9174],
        [-1.0098, -0.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14171293377876282
Epoch 0, Step 598: train/loss = 0.43803849816322327, train/raw-loss = 0.393068790435791, train/logprobs = tensor([[-1.0824, -3.4378],
        [-1.0158, -0.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14989900588989258
Epoch 0, Step 599: train/loss = 0.4365311563014984, train/raw-loss = 0.39528197050094604, train/logprobs = tensor([[-0.4884, -4.0055],
        [-0.8423, -1.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374972015619278
Epoch 0, Step 600: train/loss = 0.47092336416244507, train/raw-loss = 0.4296415448188782, train/logprobs = tensor([[-0.4733, -2.8088],
        [-0.7225, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376059651374817
Epoch 0, Step 601: train/loss = 0.474895715713501, train/raw-loss = 0.4303995966911316, train/logprobs = tensor([[-0.9070, -2.2342],
        [-1.3247, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14832034707069397
Epoch 0, Step 602: train/loss = 0.5006833672523499, train/raw-loss = 0.45106565952301025, train/logprobs = tensor([[-0.9848, -2.7500],
        [-1.1364, -1.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165392205119133
Epoch 0, Step 603: train/loss = 0.3079434037208557, train/raw-loss = 0.2646111249923706, train/logprobs = tensor([[-0.5291, -5.4385],
        [-0.9959, -1.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444409042596817
Epoch 0, Step 604: train/loss = 0.526980459690094, train/raw-loss = 0.489068865776062, train/logprobs = tensor([[-0.3983, -1.5924],
        [-0.6392, -0.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12637214362621307
Epoch 0, Step 605: train/loss = 0.5156296491622925, train/raw-loss = 0.47623202204704285, train/logprobs = tensor([[-0.7154, -1.1017],
        [-1.3279, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13132552802562714
Epoch 0, Step 606: train/loss = 0.45414119958877563, train/raw-loss = 0.41478753089904785, train/logprobs = tensor([[-0.6228, -2.1896],
        [-0.7935, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311788707971573
Epoch 0, Step 607: train/loss = 0.4329066872596741, train/raw-loss = 0.38535982370376587, train/logprobs = tensor([[-0.6901, -2.9744],
        [-0.9111, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15848955512046814
Epoch 0, Step 608: train/loss = 0.4528522491455078, train/raw-loss = 0.4057736396789551, train/logprobs = tensor([[-0.5778, -2.8034],
        [-1.1039, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569286584854126
Epoch 0, Step 609: train/loss = 0.35919612646102905, train/raw-loss = 0.31183910369873047, train/logprobs = tensor([[-0.8599, -5.5070],
        [-1.4579, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1578567624092102
Epoch 0, Step 610: train/loss = 0.29156607389450073, train/raw-loss = 0.23340752720832825, train/logprobs = tensor([[-1.1493, -6.7498],
        [-1.7020, -1.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19386178255081177
Epoch 0, Step 611: train/loss = 0.3063720166683197, train/raw-loss = 0.26784008741378784, train/logprobs = tensor([[-0.5002, -4.0113],
        [-0.8242, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284397840499878
Epoch 0, Step 612: train/loss = 0.5584306716918945, train/raw-loss = 0.5117270350456238, train/logprobs = tensor([[-0.7215, -3.4224],
        [-0.9549, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1556786596775055
Epoch 0, Step 613: train/loss = 0.5943851470947266, train/raw-loss = 0.5474357604980469, train/logprobs = tensor([[-0.7579, -1.8666],
        [-0.9754, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15649785101413727
Epoch 0, Step 614: train/loss = 0.46436044573783875, train/raw-loss = 0.4145854115486145, train/logprobs = tensor([[-0.6984, -2.2737],
        [-0.9508, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16591677069664001
Epoch 0, Step 615: train/loss = 0.4658206105232239, train/raw-loss = 0.41450363397598267, train/logprobs = tensor([[-0.6558, -2.1864],
        [-1.1766, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17105647921562195
Epoch 0, Step 616: train/loss = 0.6473177075386047, train/raw-loss = 0.6059992909431458, train/logprobs = tensor([[-0.4880, -0.9425],
        [-0.7630, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13772793114185333
Epoch 0, Step 617: train/loss = 0.47266578674316406, train/raw-loss = 0.43599408864974976, train/logprobs = tensor([[-0.6771, -3.4621],
        [-0.9008, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1222391352057457
Epoch 0, Step 618: train/loss = 0.4289056658744812, train/raw-loss = 0.38549941778182983, train/logprobs = tensor([[-0.5014, -2.6842],
        [-0.9865, -1.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14468741416931152
Epoch 0, Step 619: train/loss = 0.37130773067474365, train/raw-loss = 0.33239465951919556, train/logprobs = tensor([[-0.4732, -4.3661],
        [-0.8392, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12971021234989166
Epoch 0, Step 620: train/loss = 0.3720299005508423, train/raw-loss = 0.32095155119895935, train/logprobs = tensor([[-0.8081, -3.5154],
        [-1.3330, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1702612042427063
Epoch 0, Step 621: train/loss = 0.6026365756988525, train/raw-loss = 0.5635777711868286, train/logprobs = tensor([[-0.6692, -0.8799],
        [-0.9980, -0.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13019591569900513
Epoch 0, Step 622: train/loss = 0.46992063522338867, train/raw-loss = 0.4256038963794708, train/logprobs = tensor([[-0.4312, -4.5630],
        [-0.9215, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14772246778011322
Epoch 0, Step 623: train/loss = 0.41834506392478943, train/raw-loss = 0.3795170187950134, train/logprobs = tensor([[-0.5823, -4.8331],
        [-0.9646, -1.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294267177581787
Epoch 0, Step 624: train/loss = 0.46947747468948364, train/raw-loss = 0.42354345321655273, train/logprobs = tensor([[-0.5443, -2.8813],
        [-1.0785, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15311333537101746
Epoch 0, Step 625: train/loss = 0.5036391019821167, train/raw-loss = 0.4574526846408844, train/logprobs = tensor([[-0.6660, -4.2046],
        [-0.8004, -1.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1539546549320221
Epoch 0, Step 626: train/loss = 0.4853178858757019, train/raw-loss = 0.4427381157875061, train/logprobs = tensor([[-0.5478, -2.1469],
        [-0.8889, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419326663017273
Epoch 0, Step 627: train/loss = 0.45428466796875, train/raw-loss = 0.40938615798950195, train/logprobs = tensor([[-0.4408, -2.2095],
        [-0.9847, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14966177940368652
Epoch 0, Step 628: train/loss = 0.425656259059906, train/raw-loss = 0.3801308870315552, train/logprobs = tensor([[-0.4558, -2.4247],
        [-0.9661, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15175127983093262
Epoch 0, Step 629: train/loss = 0.4866424798965454, train/raw-loss = 0.44710567593574524, train/logprobs = tensor([[-0.3943, -1.8359],
        [-0.7263, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13178929686546326
Epoch 0, Step 630: train/loss = 0.41078808903694153, train/raw-loss = 0.37246173620224, train/logprobs = tensor([[-0.4287, -3.4267],
        [-0.6405, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12775452435016632
Epoch 0, Step 631: train/loss = 0.29992246627807617, train/raw-loss = 0.25103288888931274, train/logprobs = tensor([[-1.0782, -4.7020],
        [-1.6180, -1.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16296526789665222
Epoch 0, Step 632: train/loss = 0.4825042486190796, train/raw-loss = 0.4304661154747009, train/logprobs = tensor([[-0.8716, -3.8538],
        [-1.0896, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734604388475418
Epoch 0, Step 633: train/loss = 0.37691032886505127, train/raw-loss = 0.3334878087043762, train/logprobs = tensor([[-0.8240, -4.5692],
        [-1.0776, -1.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1447417140007019
Epoch 0, Step 634: train/loss = 0.3924146890640259, train/raw-loss = 0.3425058126449585, train/logprobs = tensor([[-0.4472, -3.8635],
        [-1.1066, -0.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16636298596858978
Epoch 0, Step 635: train/loss = 0.3712241053581238, train/raw-loss = 0.32616591453552246, train/logprobs = tensor([[-0.5344, -4.1718],
        [-1.0752, -1.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15019404888153076
Epoch 0, Step 636: train/loss = 0.49110326170921326, train/raw-loss = 0.45188936591148376, train/logprobs = tensor([[-0.5441, -3.0247],
        [-0.7931, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13071319460868835
Epoch 0, Step 637: train/loss = 0.42447006702423096, train/raw-loss = 0.3872440755367279, train/logprobs = tensor([[-0.6278, -3.8866],
        [-0.8627, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12408658117055893
Epoch 0, Step 638: train/loss = 0.6168392896652222, train/raw-loss = 0.5740744471549988, train/logprobs = tensor([[-0.4948, -1.1292],
        [-0.6904, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425495445728302
Epoch 0, Step 639: train/loss = 0.4373141825199127, train/raw-loss = 0.3856843113899231, train/logprobs = tensor([[-0.8726, -3.4214],
        [-1.2333, -1.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17209947109222412
Epoch 0, Step 640: train/loss = 0.39259588718414307, train/raw-loss = 0.3539157509803772, train/logprobs = tensor([[-0.5610, -4.8912],
        [-0.7930, -1.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12893380224704742
Epoch 0, Step 641: train/loss = 0.6358925104141235, train/raw-loss = 0.5902442932128906, train/logprobs = tensor([[-1.3048, -3.1789],
        [-1.0544, -0.9364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15216058492660522
Epoch 0, Step 642: train/loss = 0.4150567650794983, train/raw-loss = 0.3683074712753296, train/logprobs = tensor([[-0.9917, -3.9875],
        [-1.1581, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15583094954490662
Epoch 0, Step 643: train/loss = 0.32529768347740173, train/raw-loss = 0.2790549695491791, train/logprobs = tensor([[-0.5503, -5.4374],
        [-0.9336, -0.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541423499584198
Epoch 0, Step 644: train/loss = 0.5479341745376587, train/raw-loss = 0.49737420678138733, train/logprobs = tensor([[-0.9948, -1.2382],
        [-1.4141, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16853304207324982
Epoch 0, Step 645: train/loss = 0.438334584236145, train/raw-loss = 0.398501455783844, train/logprobs = tensor([[-1.0430, -5.0099],
        [-1.6970, -1.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13277707993984222
Epoch 0, Step 646: train/loss = 0.590837299823761, train/raw-loss = 0.5447900295257568, train/logprobs = tensor([[-0.6080, -1.1725],
        [-0.9265, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15349093079566956
Epoch 0, Step 647: train/loss = 0.472013920545578, train/raw-loss = 0.4297345280647278, train/logprobs = tensor([[-0.5877, -3.0178],
        [-1.0385, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1409313976764679
Epoch 0, Step 648: train/loss = 0.40618452429771423, train/raw-loss = 0.36098048090934753, train/logprobs = tensor([[-0.6148, -4.7681],
        [-1.1418, -1.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15068010985851288
Epoch 0, Step 649: train/loss = 0.2562764883041382, train/raw-loss = 0.2091572880744934, train/logprobs = tensor([[-0.5926, -6.4287],
        [-1.4369, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1570640206336975
Epoch 0, Step 650: train/loss = 0.3187696039676666, train/raw-loss = 0.27198484539985657, train/logprobs = tensor([[-0.6184, -6.0180],
        [-1.1571, -1.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1559491604566574
Epoch 0, Step 651: train/loss = 0.29087451100349426, train/raw-loss = 0.24164173007011414, train/logprobs = tensor([[-0.9047, -5.3271],
        [-1.4017, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641092747449875
Epoch 0, Step 652: train/loss = 0.370066374540329, train/raw-loss = 0.3367408215999603, train/logprobs = tensor([[-0.9426, -6.6399],
        [-1.2376, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11108512431383133
Epoch 0, Step 653: train/loss = 0.4915691018104553, train/raw-loss = 0.4531899094581604, train/logprobs = tensor([[-0.7566, -2.7050],
        [-1.0681, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279306560754776
Epoch 0, Step 654: train/loss = 0.6054222583770752, train/raw-loss = 0.5650942325592041, train/logprobs = tensor([[-0.6163, -2.2268],
        [-0.6775, -0.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13442660868167877
Epoch 0, Step 655: train/loss = 0.38562819361686707, train/raw-loss = 0.3291248679161072, train/logprobs = tensor([[-0.9490, -3.5153],
        [-1.4852, -1.2722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18834443390369415
Epoch 0, Step 656: train/loss = 0.27668237686157227, train/raw-loss = 0.229371577501297, train/logprobs = tensor([[-1.0062, -7.6400],
        [-1.3965, -1.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1577027142047882
Epoch 0, Step 657: train/loss = 0.3547671437263489, train/raw-loss = 0.3158853054046631, train/logprobs = tensor([[-0.6229, -5.0002],
        [-1.0166, -1.3593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12960614264011383
Epoch 0, Step 658: train/loss = 0.48993629217147827, train/raw-loss = 0.4400182366371155, train/logprobs = tensor([[-1.0299, -3.4706],
        [-1.1934, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16639350354671478
Epoch 0, Step 659: train/loss = 0.2673226296901703, train/raw-loss = 0.21733230352401733, train/logprobs = tensor([[-0.5315, -4.8320],
        [-1.1606, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16663450002670288
Epoch 0, Step 660: train/loss = 0.5893586874008179, train/raw-loss = 0.5417019724845886, train/logprobs = tensor([[-0.7867, -2.2476],
        [-0.7448, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15885578095912933
Epoch 0, Step 661: train/loss = 0.42415615916252136, train/raw-loss = 0.3773609697818756, train/logprobs = tensor([[-0.5676, -4.3972],
        [-1.0439, -0.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15598395466804504
Epoch 0, Step 662: train/loss = 0.5593744516372681, train/raw-loss = 0.5224552154541016, train/logprobs = tensor([[-0.6369, -1.6227],
        [-0.7731, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306401133537292
Epoch 0, Step 663: train/loss = 0.43346014618873596, train/raw-loss = 0.3899318277835846, train/logprobs = tensor([[-0.9608, -5.6354],
        [-0.8818, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1450943797826767
Epoch 0, Step 664: train/loss = 0.44995516538619995, train/raw-loss = 0.4061632752418518, train/logprobs = tensor([[-0.7109, -2.4176],
        [-1.0962, -0.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14597296714782715
Epoch 0, Step 665: train/loss = 0.49504148960113525, train/raw-loss = 0.44443652033805847, train/logprobs = tensor([[-1.0472, -2.1652],
        [-1.0988, -0.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16868311166763306
Epoch 0, Step 666: train/loss = 0.42484939098358154, train/raw-loss = 0.3786769211292267, train/logprobs = tensor([[-0.7979, -4.0074],
        [-1.4307, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1539081335067749
Epoch 0, Step 667: train/loss = 0.4520781934261322, train/raw-loss = 0.40498974919319153, train/logprobs = tensor([[-0.6506, -3.7274],
        [-1.2304, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15696142613887787
Epoch 0, Step 668: train/loss = 0.5588970184326172, train/raw-loss = 0.509127140045166, train/logprobs = tensor([[-0.6727, -1.4296],
        [-1.0478, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16589975357055664
Epoch 0, Step 669: train/loss = 0.3406568765640259, train/raw-loss = 0.3004707098007202, train/logprobs = tensor([[-0.5800, -5.1517],
        [-1.0190, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13395395874977112
Epoch 0, Step 670: train/loss = 0.3804109990596771, train/raw-loss = 0.3406657874584198, train/logprobs = tensor([[-0.8104, -5.2558],
        [-1.0191, -1.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13248394429683685
Epoch 0, Step 671: train/loss = 0.43240460753440857, train/raw-loss = 0.3903059959411621, train/logprobs = tensor([[-0.8358, -3.5837],
        [-0.8768, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14032870531082153
Epoch 0, Step 672: train/loss = 0.5002027750015259, train/raw-loss = 0.4605831801891327, train/logprobs = tensor([[-0.6693, -3.4283],
        [-1.1362, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320653259754181
Epoch 0, Step 673: train/loss = 0.4174211919307709, train/raw-loss = 0.36820194125175476, train/logprobs = tensor([[-0.5554, -3.5129],
        [-1.0303, -0.6880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16406413912773132
Epoch 0, Step 674: train/loss = 0.4115595519542694, train/raw-loss = 0.37149176001548767, train/logprobs = tensor([[-0.4035, -2.4066],
        [-0.8797, -0.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13355933129787445
Epoch 0, Step 675: train/loss = 0.3719552457332611, train/raw-loss = 0.3170280158519745, train/logprobs = tensor([[-0.5847, -3.0290],
        [-1.3242, -1.0474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18309077620506287
Epoch 0, Step 676: train/loss = 0.3435558080673218, train/raw-loss = 0.30293452739715576, train/logprobs = tensor([[-0.4699, -5.8666],
        [-1.0671, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13540434837341309
Epoch 0, Step 677: train/loss = 0.46651703119277954, train/raw-loss = 0.41775059700012207, train/logprobs = tensor([[-0.4096, -2.9599],
        [-0.8141, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16255474090576172
Epoch 0, Step 678: train/loss = 0.3517272174358368, train/raw-loss = 0.2944854497909546, train/logprobs = tensor([[-0.5579, -4.5627],
        [-1.3130, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1908058524131775
Epoch 0, Step 679: train/loss = 0.32016700506210327, train/raw-loss = 0.2744133472442627, train/logprobs = tensor([[-0.9055, -4.1470],
        [-1.1786, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15251222252845764
Epoch 0, Step 680: train/loss = 0.38341107964515686, train/raw-loss = 0.3429446220397949, train/logprobs = tensor([[-0.6523, -4.8560],
        [-0.9769, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1348881721496582
Epoch 0, Step 681: train/loss = 0.36084598302841187, train/raw-loss = 0.31362244486808777, train/logprobs = tensor([[-0.4918, -3.3971],
        [-1.0586, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15741172432899475
Epoch 0, Step 682: train/loss = 0.556059718132019, train/raw-loss = 0.5025990009307861, train/logprobs = tensor([[-1.0902, -2.7899],
        [-0.9545, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17820242047309875
Epoch 0, Step 683: train/loss = 0.5505253076553345, train/raw-loss = 0.4994219243526459, train/logprobs = tensor([[-0.8387, -2.0049],
        [-1.4058, -0.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703445315361023
Epoch 0, Step 684: train/loss = 0.3646858334541321, train/raw-loss = 0.3241845369338989, train/logprobs = tensor([[-0.5738, -4.0502],
        [-1.0145, -1.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13500429689884186
Epoch 0, Step 685: train/loss = 0.4356875717639923, train/raw-loss = 0.3921026885509491, train/logprobs = tensor([[-0.5380, -3.4844],
        [-0.9332, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14528293907642365
Epoch 0, Step 686: train/loss = 0.507538914680481, train/raw-loss = 0.44842931628227234, train/logprobs = tensor([[-1.3168, -2.8299],
        [-1.4179, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19703204929828644
Epoch 0, Step 687: train/loss = 0.4405749440193176, train/raw-loss = 0.403796911239624, train/logprobs = tensor([[-0.8664, -3.2920],
        [-1.0408, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1225934773683548
Epoch 0, Step 688: train/loss = 0.2402394413948059, train/raw-loss = 0.18954619765281677, train/logprobs = tensor([[-0.5125, -5.5955],
        [-1.2455, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897745430469513
Epoch 0, Step 689: train/loss = 0.3613305985927582, train/raw-loss = 0.3177226483821869, train/logprobs = tensor([[-0.6085, -4.6886],
        [-1.2059, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14535987377166748
Epoch 0, Step 690: train/loss = 0.48170462250709534, train/raw-loss = 0.4492012858390808, train/logprobs = tensor([[-0.3411, -3.3407],
        [-0.5661, -0.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10834451764822006
Epoch 0, Step 691: train/loss = 0.32081112265586853, train/raw-loss = 0.26745834946632385, train/logprobs = tensor([[-0.7527, -4.9943],
        [-1.8491, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17784255743026733
Epoch 0, Step 692: train/loss = 0.3947526514530182, train/raw-loss = 0.3512499928474426, train/logprobs = tensor([[-0.4797, -2.7751],
        [-0.9302, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1450089067220688
Epoch 0, Step 693: train/loss = 0.42968127131462097, train/raw-loss = 0.3889312148094177, train/logprobs = tensor([[-0.6343, -2.8553],
        [-0.9398, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358335316181183
Epoch 0, Step 694: train/loss = 0.351459264755249, train/raw-loss = 0.3095892369747162, train/logprobs = tensor([[-0.7168, -5.1572],
        [-1.0394, -1.3752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1395667940378189
Epoch 0, Step 695: train/loss = 0.5532184839248657, train/raw-loss = 0.5076678991317749, train/logprobs = tensor([[-0.6208, -1.6745],
        [-1.1515, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518353819847107
Epoch 0, Step 696: train/loss = 0.4247552156448364, train/raw-loss = 0.37604379653930664, train/logprobs = tensor([[-0.5961, -3.4989],
        [-1.4524, -1.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16237148642539978
Epoch 0, Step 697: train/loss = 0.42392560839653015, train/raw-loss = 0.37770429253578186, train/logprobs = tensor([[-0.4068, -2.2533],
        [-0.8376, -0.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15407095849514008
Epoch 0, Step 698: train/loss = 0.45592761039733887, train/raw-loss = 0.41148388385772705, train/logprobs = tensor([[-0.6654, -3.0446],
        [-1.2836, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14814579486846924
Epoch 0, Step 699: train/loss = 0.27118027210235596, train/raw-loss = 0.2225913256406784, train/logprobs = tensor([[-0.8175, -5.6681],
        [-1.7266, -1.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196317970752716
Epoch 0, Step 700: train/loss = 0.415844202041626, train/raw-loss = 0.3681231737136841, train/logprobs = tensor([[-0.8844, -5.9453],
        [-1.1072, -1.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15907005965709686
Epoch 0, Step 701: train/loss = 0.3676580488681793, train/raw-loss = 0.31950753927230835, train/logprobs = tensor([[-0.7445, -4.6616],
        [-1.0363, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16050168871879578
Epoch 0, Step 702: train/loss = 0.46245700120925903, train/raw-loss = 0.4228478670120239, train/logprobs = tensor([[-0.5277, -2.0645],
        [-0.9515, -0.8127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13203033804893494
Epoch 0, Step 703: train/loss = 0.5535721182823181, train/raw-loss = 0.5072956085205078, train/logprobs = tensor([[-0.6877, -2.1062],
        [-1.1132, -1.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15425503253936768
Epoch 0, Step 704: train/loss = 0.28990525007247925, train/raw-loss = 0.24108481407165527, train/logprobs = tensor([[-1.0769, -7.6881],
        [-1.8558, -1.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16273467242717743
Epoch 0, Step 705: train/loss = 0.2526623606681824, train/raw-loss = 0.1994970440864563, train/logprobs = tensor([[-0.9635, -5.3142],
        [-1.6522, -1.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17721769213676453
Epoch 0, Step 706: train/loss = 0.46518129110336304, train/raw-loss = 0.4325491487979889, train/logprobs = tensor([[-0.4724, -3.5399],
        [-0.6976, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10877396166324615
Epoch 0, Step 707: train/loss = 0.4072718322277069, train/raw-loss = 0.3592751920223236, train/logprobs = tensor([[-0.7118, -3.7178],
        [-1.1670, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15998882055282593
Epoch 0, Step 708: train/loss = 0.44727540016174316, train/raw-loss = 0.40551820397377014, train/logprobs = tensor([[-0.5521, -3.7663],
        [-0.9028, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.139190673828125
Epoch 0, Step 709: train/loss = 0.17844581604003906, train/raw-loss = 0.12578585743904114, train/logprobs = tensor([[-0.7695, -6.9693],
        [-2.0774, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17553316056728363
Epoch 0, Step 710: train/loss = 0.3273092210292816, train/raw-loss = 0.27595439553260803, train/logprobs = tensor([[-0.8265, -4.3921],
        [-1.4191, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17118270695209503
Epoch 0, Step 711: train/loss = 0.4835675060749054, train/raw-loss = 0.44054463505744934, train/logprobs = tensor([[-0.4847, -2.4462],
        [-0.9825, -0.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14340966939926147
Epoch 0, Step 712: train/loss = 0.4259786605834961, train/raw-loss = 0.3823187053203583, train/logprobs = tensor([[-0.7739, -3.8210],
        [-1.3235, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14553332328796387
Epoch 0, Step 713: train/loss = 0.36585426330566406, train/raw-loss = 0.3196253776550293, train/logprobs = tensor([[-0.8714, -5.4701],
        [-1.2878, -1.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15409629046916962
Epoch 0, Step 714: train/loss = 0.4917576014995575, train/raw-loss = 0.4497448801994324, train/logprobs = tensor([[-0.7697, -4.6573],
        [-1.0270, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1400424689054489
Epoch 0, Step 715: train/loss = 0.3136511445045471, train/raw-loss = 0.27067673206329346, train/logprobs = tensor([[-0.6799, -6.4558],
        [-0.9779, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14324809610843658
Epoch 0, Step 716: train/loss = 0.5427757501602173, train/raw-loss = 0.49555400013923645, train/logprobs = tensor([[-0.6806, -1.6953],
        [-1.0719, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15740591287612915
Epoch 0, Step 717: train/loss = 0.45333415269851685, train/raw-loss = 0.4097963571548462, train/logprobs = tensor([[-0.6662, -3.4695],
        [-1.4344, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14512589573860168
Epoch 0, Step 718: train/loss = 0.5267056822776794, train/raw-loss = 0.48113030195236206, train/logprobs = tensor([[-1.2112, -3.2074],
        [-1.3565, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1519179344177246
Epoch 0, Step 719: train/loss = 0.475442498922348, train/raw-loss = 0.43405529856681824, train/logprobs = tensor([[-0.4681, -2.2546],
        [-0.7753, -0.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13795733451843262
Epoch 0, Step 720: train/loss = 0.3665222227573395, train/raw-loss = 0.31247568130493164, train/logprobs = tensor([[-0.7477, -3.6750],
        [-1.3644, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801549196243286
Epoch 0, Step 721: train/loss = 0.43629950284957886, train/raw-loss = 0.37883853912353516, train/logprobs = tensor([[-0.8535, -3.2230],
        [-1.1115, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19153648614883423
Epoch 0, Step 722: train/loss = 0.7119510769844055, train/raw-loss = 0.6684736013412476, train/logprobs = tensor([[-0.5836, -0.6727],
        [-0.7839, -0.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1449250429868698
Epoch 0, Step 723: train/loss = 0.3579002022743225, train/raw-loss = 0.2930050790309906, train/logprobs = tensor([[-0.9752, -3.7559],
        [-1.4637, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2163170874118805
Epoch 0, Step 724: train/loss = 0.3307397663593292, train/raw-loss = 0.29006361961364746, train/logprobs = tensor([[-0.5735, -5.6820],
        [-1.1438, -1.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13558711111545563
Epoch 0, Step 725: train/loss = 0.595893919467926, train/raw-loss = 0.5508702993392944, train/logprobs = tensor([[-1.1499, -2.9678],
        [-0.9168, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15007872879505157
Epoch 0, Step 726: train/loss = 0.2926703095436096, train/raw-loss = 0.25025123357772827, train/logprobs = tensor([[-0.4550, -6.3657],
        [-0.8690, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14139683544635773
Epoch 0, Step 727: train/loss = 0.5485441088676453, train/raw-loss = 0.5041137337684631, train/logprobs = tensor([[-1.1787, -4.2500],
        [-0.9304, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1481013000011444
Epoch 0, Step 728: train/loss = 0.23411375284194946, train/raw-loss = 0.18677467107772827, train/logprobs = tensor([[-0.7920, -8.5444],
        [-1.6721, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1577969193458557
Epoch 0, Step 729: train/loss = 0.59867924451828, train/raw-loss = 0.5496768355369568, train/logprobs = tensor([[-1.3981, -2.6724],
        [-1.3145, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16334137320518494
Epoch 0, Step 730: train/loss = 0.4896540641784668, train/raw-loss = 0.45400577783584595, train/logprobs = tensor([[-0.3673, -2.1046],
        [-0.6082, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11882758885622025
Epoch 0, Step 731: train/loss = 0.4916543960571289, train/raw-loss = 0.4468398988246918, train/logprobs = tensor([[-0.6443, -2.5964],
        [-0.8945, -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.149381622672081
Epoch 0, Step 732: train/loss = 0.4544457197189331, train/raw-loss = 0.40407511591911316, train/logprobs = tensor([[-0.5878, -2.9184],
        [-1.0681, -1.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16790200769901276
Epoch 0, Step 733: train/loss = 0.4565756618976593, train/raw-loss = 0.41882702708244324, train/logprobs = tensor([[-0.5516, -3.8618],
        [-0.8963, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125828817486763
Epoch 0, Step 734: train/loss = 0.4676755964756012, train/raw-loss = 0.4195253252983093, train/logprobs = tensor([[-0.8546, -2.6916],
        [-1.2472, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16050100326538086
Epoch 0, Step 735: train/loss = 0.6891725063323975, train/raw-loss = 0.6476101875305176, train/logprobs = tensor([[-0.8815, -1.2880],
        [-0.7807, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13854096829891205
Epoch 0, Step 736: train/loss = 0.6458408236503601, train/raw-loss = 0.6130089163780212, train/logprobs = tensor([[-0.3676, -1.0407],
        [-0.6276, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094396561384201
Epoch 0, Step 737: train/loss = 0.29237452149391174, train/raw-loss = 0.23552726209163666, train/logprobs = tensor([[-0.7737, -3.5720],
        [-1.7875, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18949085474014282
Epoch 0, Step 738: train/loss = 0.5863179564476013, train/raw-loss = 0.5415500402450562, train/logprobs = tensor([[-0.6742, -1.9648],
        [-1.4060, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492263674736023
Epoch 0, Step 739: train/loss = 0.3598146438598633, train/raw-loss = 0.31426703929901123, train/logprobs = tensor([[-1.1909, -3.6396],
        [-2.1427, -1.4166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15182547271251678
Epoch 0, Step 740: train/loss = 0.239818274974823, train/raw-loss = 0.19084735214710236, train/logprobs = tensor([[-0.7617, -4.8826],
        [-1.5040, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16323637962341309
Epoch 0, Step 741: train/loss = 0.24573251605033875, train/raw-loss = 0.18507815897464752, train/logprobs = tensor([[-0.8305, -7.1878],
        [-1.7331, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021811604499817
Epoch 0, Step 742: train/loss = 0.461197167634964, train/raw-loss = 0.41714081168174744, train/logprobs = tensor([[-0.5001, -2.8047],
        [-0.9433, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14685440063476562
Epoch 0, Step 743: train/loss = 0.31220293045043945, train/raw-loss = 0.26827189326286316, train/logprobs = tensor([[-0.9687, -6.9199],
        [-1.6363, -1.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14643682539463043
Epoch 0, Step 744: train/loss = 0.5982919931411743, train/raw-loss = 0.5592548847198486, train/logprobs = tensor([[-0.5992, -1.0428],
        [-0.8105, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301237940788269
Epoch 0, Step 745: train/loss = 0.40360403060913086, train/raw-loss = 0.3614756464958191, train/logprobs = tensor([[-0.4432, -3.0361],
        [-0.7507, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14042799174785614
Epoch 0, Step 746: train/loss = 0.6595479846000671, train/raw-loss = 0.6156280636787415, train/logprobs = tensor([[-0.6596, -0.7457],
        [-0.8808, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463996320962906
Epoch 0, Step 747: train/loss = 0.46509772539138794, train/raw-loss = 0.42740654945373535, train/logprobs = tensor([[-0.5524, -2.2554],
        [-0.7640, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256372481584549
Epoch 0, Step 748: train/loss = 0.5553498268127441, train/raw-loss = 0.5135811567306519, train/logprobs = tensor([[-0.4443, -1.3305],
        [-1.0053, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392289102077484
Epoch 0, Step 749: train/loss = 0.47655540704727173, train/raw-loss = 0.4290533661842346, train/logprobs = tensor([[-0.9024, -4.0331],
        [-1.3527, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15834015607833862
Epoch 0, Step 750: train/loss = 0.4311576187610626, train/raw-loss = 0.3840113878250122, train/logprobs = tensor([[-0.9203, -4.8406],
        [-1.9445, -2.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15715420246124268
Epoch 0, Step 751: train/loss = 0.5588682889938354, train/raw-loss = 0.5152191519737244, train/logprobs = tensor([[-0.6326, -3.3728],
        [-0.8246, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14549720287322998
Epoch 0, Step 752: train/loss = 0.5200608968734741, train/raw-loss = 0.47582000494003296, train/logprobs = tensor([[-0.4979, -3.2633],
        [-0.9297, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474696397781372
Epoch 0, Step 753: train/loss = 0.36432868242263794, train/raw-loss = 0.3160003125667572, train/logprobs = tensor([[-0.5898, -3.1037],
        [-0.9221, -0.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1610945761203766
Epoch 0, Step 754: train/loss = 0.3871361017227173, train/raw-loss = 0.34164854884147644, train/logprobs = tensor([[-0.6959, -2.8771],
        [-1.2232, -0.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15162524580955505
Epoch 0, Step 755: train/loss = 0.3377020061016083, train/raw-loss = 0.2838728725910187, train/logprobs = tensor([[-0.8813, -6.1708],
        [-1.6603, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17943039536476135
Epoch 0, Step 756: train/loss = 0.41570571064949036, train/raw-loss = 0.3699600100517273, train/logprobs = tensor([[-0.9480, -4.6013],
        [-1.4281, -0.7123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15248556435108185
Epoch 0, Step 757: train/loss = 0.5187423825263977, train/raw-loss = 0.4678746163845062, train/logprobs = tensor([[-0.6010, -3.9216],
        [-1.0029, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16955918073654175
Epoch 0, Step 758: train/loss = 0.3436456024646759, train/raw-loss = 0.30091938376426697, train/logprobs = tensor([[-0.5458, -5.1581],
        [-1.1184, -1.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14242075383663177
Epoch 0, Step 759: train/loss = 0.4349631369113922, train/raw-loss = 0.3889012932777405, train/logprobs = tensor([[-0.7077, -3.9839],
        [-1.0073, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15353955328464508
Epoch 0, Step 760: train/loss = 0.5163319110870361, train/raw-loss = 0.472181499004364, train/logprobs = tensor([[-1.1802, -3.4462],
        [-1.3310, -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14716807007789612
Epoch 0, Step 761: train/loss = 0.6562277674674988, train/raw-loss = 0.6118446588516235, train/logprobs = tensor([[-1.2936, -1.3651],
        [-1.5535, -1.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479436755180359
Epoch 0, Step 762: train/loss = 0.4638788402080536, train/raw-loss = 0.4119587540626526, train/logprobs = tensor([[-0.5622, -3.0941],
        [-1.1391, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1730668842792511
Epoch 0, Step 763: train/loss = 0.38830968737602234, train/raw-loss = 0.330832302570343, train/logprobs = tensor([[-0.8341, -2.8354],
        [-1.4342, -1.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19159135222434998
Epoch 0, Step 764: train/loss = 0.515373945236206, train/raw-loss = 0.47353070974349976, train/logprobs = tensor([[-0.6411, -1.6056],
        [-1.0976, -0.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13947738707065582
Epoch 0, Step 765: train/loss = 0.41106289625167847, train/raw-loss = 0.3697091042995453, train/logprobs = tensor([[-0.6930, -5.1093],
        [-1.3021, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13784600794315338
Epoch 0, Step 766: train/loss = 0.3036949932575226, train/raw-loss = 0.24922433495521545, train/logprobs = tensor([[-0.8036, -3.7477],
        [-1.3813, -1.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181568905711174
Epoch 0, Step 767: train/loss = 0.5562307834625244, train/raw-loss = 0.505628228187561, train/logprobs = tensor([[-0.6117, -1.9767],
        [-0.8937, -0.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16867497563362122
Epoch 0, Step 768: train/loss = 0.654822826385498, train/raw-loss = 0.6174893379211426, train/logprobs = tensor([[-0.5237, -0.9103],
        [-0.7163, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124444879591465
Epoch 0, Step 769: train/loss = 0.39833006262779236, train/raw-loss = 0.3493121564388275, train/logprobs = tensor([[-0.8475, -3.0247],
        [-1.2263, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16339299082756042
Epoch 0, Step 770: train/loss = 0.4822535216808319, train/raw-loss = 0.4433336555957794, train/logprobs = tensor([[-0.4689, -1.9654],
        [-0.6958, -0.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1297328621149063
Epoch 0, Step 771: train/loss = 0.31540387868881226, train/raw-loss = 0.27574554085731506, train/logprobs = tensor([[-0.6144, -4.6429],
        [-0.8807, -1.4351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13219444453716278
Epoch 0, Step 772: train/loss = 0.3179287910461426, train/raw-loss = 0.2692136764526367, train/logprobs = tensor([[-0.9873, -3.8643],
        [-1.3470, -0.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623838245868683
Epoch 0, Step 773: train/loss = 0.43616434931755066, train/raw-loss = 0.39183342456817627, train/logprobs = tensor([[-0.9755, -3.8327],
        [-1.0401, -1.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14776970446109772
Epoch 0, Step 774: train/loss = 0.47709858417510986, train/raw-loss = 0.4325384199619293, train/logprobs = tensor([[-1.1569, -2.7285],
        [-1.2684, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14853401482105255
Epoch 0, Step 775: train/loss = 0.7452100515365601, train/raw-loss = 0.6992220282554626, train/logprobs = tensor([[-2.7316, -8.0799],
        [-1.3789, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15329331159591675
Epoch 0, Step 776: train/loss = 0.3268466293811798, train/raw-loss = 0.2872319519519806, train/logprobs = tensor([[-0.7232, -5.2777],
        [-1.1846, -1.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13204891979694366
Epoch 0, Step 777: train/loss = 0.484973669052124, train/raw-loss = 0.44743233919143677, train/logprobs = tensor([[-0.4993, -2.3383],
        [-0.9223, -0.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12513774633407593
Epoch 0, Step 778: train/loss = 0.38504064083099365, train/raw-loss = 0.3375936448574066, train/logprobs = tensor([[-0.6660, -3.7524],
        [-1.0496, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581565886735916
Epoch 0, Step 779: train/loss = 0.4888184666633606, train/raw-loss = 0.44728565216064453, train/logprobs = tensor([[-0.7614, -3.9709],
        [-0.8037, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13844263553619385
Epoch 0, Step 780: train/loss = 0.5765050649642944, train/raw-loss = 0.5396240949630737, train/logprobs = tensor([[-0.5879, -1.9277],
        [-0.6262, -1.0815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12293674796819687
Epoch 0, Step 781: train/loss = 0.47837626934051514, train/raw-loss = 0.4338793158531189, train/logprobs = tensor([[-0.8396, -2.6025],
        [-1.3279, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1483231782913208
Epoch 0, Step 782: train/loss = 0.38643795251846313, train/raw-loss = 0.32767578959465027, train/logprobs = tensor([[-1.5031, -7.0979],
        [-1.4861, -1.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19587385654449463
Epoch 0, Step 783: train/loss = 0.3063051700592041, train/raw-loss = 0.2599436342716217, train/logprobs = tensor([[-0.6479, -4.2911],
        [-1.0391, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545386016368866
Epoch 0, Step 784: train/loss = 0.2534676790237427, train/raw-loss = 0.2092379927635193, train/logprobs = tensor([[ -0.7614, -10.2587],
        [ -1.3463,  -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474321484565735
Epoch 0, Step 785: train/loss = 0.5002167224884033, train/raw-loss = 0.4689481854438782, train/logprobs = tensor([[-0.3496, -2.7901],
        [-0.4888, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422833263874054
Epoch 0, Step 786: train/loss = 0.30414700508117676, train/raw-loss = 0.2616294026374817, train/logprobs = tensor([[-0.5917, -6.3452],
        [-0.8484, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417253464460373
Epoch 0, Step 787: train/loss = 0.5073361992835999, train/raw-loss = 0.46025437116622925, train/logprobs = tensor([[-0.6662, -2.4164],
        [-0.9286, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15693935751914978
Epoch 0, Step 788: train/loss = 0.37619027495384216, train/raw-loss = 0.3271999955177307, train/logprobs = tensor([[-0.6519, -6.9344],
        [-1.0619, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16330094635486603
Epoch 0, Step 789: train/loss = 0.6089165806770325, train/raw-loss = 0.5710461735725403, train/logprobs = tensor([[-0.8045, -1.6442],
        [-0.7353, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1262344866991043
Epoch 0, Step 790: train/loss = 0.5005694627761841, train/raw-loss = 0.4552372097969055, train/logprobs = tensor([[-0.6502, -2.6762],
        [-0.7947, -0.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15110743045806885
Epoch 0, Step 791: train/loss = 0.5751720666885376, train/raw-loss = 0.5337965488433838, train/logprobs = tensor([[-0.9680, -1.6517],
        [-1.1516, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379183977842331
Epoch 0, Step 792: train/loss = 0.3998352587223053, train/raw-loss = 0.35529211163520813, train/logprobs = tensor([[-0.7081, -3.3525],
        [-1.2122, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14847710728645325
Epoch 0, Step 793: train/loss = 0.47366803884506226, train/raw-loss = 0.4265765845775604, train/logprobs = tensor([[-0.7798, -6.1838],
        [-1.1029, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15697143971920013
Epoch 0, Step 794: train/loss = 0.31616970896720886, train/raw-loss = 0.26207053661346436, train/logprobs = tensor([[-0.7009, -5.1378],
        [-1.2521, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18033058941364288
Epoch 0, Step 795: train/loss = 0.40239080786705017, train/raw-loss = 0.36115536093711853, train/logprobs = tensor([[-0.9824, -4.3081],
        [-1.0786, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374514251947403
Epoch 0, Step 796: train/loss = 0.32530099153518677, train/raw-loss = 0.276470422744751, train/logprobs = tensor([[-0.8102, -6.5882],
        [-1.2504, -1.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16276848316192627
Epoch 0, Step 797: train/loss = 0.4983977675437927, train/raw-loss = 0.45955991744995117, train/logprobs = tensor([[-0.5393, -1.7746],
        [-0.7524, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12945958971977234
Epoch 0, Step 798: train/loss = 0.4795219302177429, train/raw-loss = 0.44180071353912354, train/logprobs = tensor([[-0.7682, -5.1283],
        [-0.8119, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12573735415935516
Epoch 0, Step 799: train/loss = 0.4831981360912323, train/raw-loss = 0.4333415627479553, train/logprobs = tensor([[-1.1911, -5.8003],
        [-1.4401, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1661885678768158
Epoch 0, Step 800: train/loss = 0.6495107412338257, train/raw-loss = 0.6079555749893188, train/logprobs = tensor([[-1.2395, -1.9831],
        [-1.0168, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385173201560974
Epoch 0, Step 801: train/loss = 0.2479761689901352, train/raw-loss = 0.19403629004955292, train/logprobs = tensor([[-1.0030, -7.3171],
        [-1.6539, -1.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17979955673217773
Epoch 0, Step 802: train/loss = 0.4536525309085846, train/raw-loss = 0.4182519316673279, train/logprobs = tensor([[-0.7685, -2.4407],
        [-1.0329, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800189316272736
Epoch 0, Step 803: train/loss = 0.37927594780921936, train/raw-loss = 0.3416549563407898, train/logprobs = tensor([[-0.7199, -4.3160],
        [-1.0327, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12540337443351746
Epoch 0, Step 804: train/loss = 0.5179741978645325, train/raw-loss = 0.47136250138282776, train/logprobs = tensor([[-0.7740, -3.4840],
        [-1.0967, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15537230670452118
Epoch 0, Step 805: train/loss = 0.4923725128173828, train/raw-loss = 0.45441922545433044, train/logprobs = tensor([[-0.5252, -2.4238],
        [-0.7680, -0.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12651091814041138
Epoch 0, Step 806: train/loss = 0.4022846817970276, train/raw-loss = 0.35393422842025757, train/logprobs = tensor([[-0.9170, -5.2046],
        [-1.2266, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16116830706596375
Epoch 0, Step 807: train/loss = 0.3428901433944702, train/raw-loss = 0.2962346076965332, train/logprobs = tensor([[-0.8262, -6.8374],
        [-1.0928, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1555183082818985
Epoch 0, Step 808: train/loss = 0.34864649176597595, train/raw-loss = 0.30859512090682983, train/logprobs = tensor([[-0.6023, -3.9276],
        [-1.0240, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13350462913513184
Epoch 0, Step 809: train/loss = 0.36260658502578735, train/raw-loss = 0.31332746148109436, train/logprobs = tensor([[-0.6890, -5.8538],
        [-1.1138, -0.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16426371037960052
Epoch 0, Step 810: train/loss = 0.31442731618881226, train/raw-loss = 0.26610636711120605, train/logprobs = tensor([[-0.6463, -4.8790],
        [-1.1159, -0.7162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16106975078582764
Epoch 0, Step 811: train/loss = 0.4951714277267456, train/raw-loss = 0.45042741298675537, train/logprobs = tensor([[-0.6998, -3.6276],
        [-0.8756, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14914679527282715
Epoch 0, Step 812: train/loss = 0.562248170375824, train/raw-loss = 0.5221768617630005, train/logprobs = tensor([[-0.7956, -2.3669],
        [-1.0414, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335708498954773
Epoch 0, Step 813: train/loss = 0.5242427587509155, train/raw-loss = 0.4809582829475403, train/logprobs = tensor([[-0.8654, -1.8598],
        [-0.8894, -0.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14428162574768066
Epoch 0, Step 814: train/loss = 0.271120548248291, train/raw-loss = 0.22838017344474792, train/logprobs = tensor([[-0.7987, -5.3212],
        [-1.9835, -1.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424679309129715
Epoch 0, Step 815: train/loss = 0.45953014492988586, train/raw-loss = 0.41419297456741333, train/logprobs = tensor([[-0.7980, -2.7500],
        [-0.8783, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15112394094467163
Epoch 0, Step 816: train/loss = 0.3030959665775299, train/raw-loss = 0.269754558801651, train/logprobs = tensor([[-0.4349, -7.5660],
        [-0.5851, -1.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111380010843277
Epoch 0, Step 817: train/loss = 0.4027003049850464, train/raw-loss = 0.35427969694137573, train/logprobs = tensor([[-1.0040, -5.0446],
        [-1.3549, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16140195727348328
Epoch 0, Step 818: train/loss = 0.3192509412765503, train/raw-loss = 0.27487194538116455, train/logprobs = tensor([[-0.6738, -8.1443],
        [-1.1621, -2.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14793002605438232
Epoch 0, Step 819: train/loss = 0.3739176392555237, train/raw-loss = 0.33650946617126465, train/logprobs = tensor([[-0.3887, -4.6539],
        [-0.7318, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12469382584095001
Epoch 0, Step 820: train/loss = 0.3944750428199768, train/raw-loss = 0.3439830541610718, train/logprobs = tensor([[-0.9216, -3.8709],
        [-1.2277, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16830681264400482
Epoch 0, Step 821: train/loss = 0.42488524317741394, train/raw-loss = 0.37819963693618774, train/logprobs = tensor([[-0.7222, -2.8223],
        [-1.2576, -0.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15561875700950623
Epoch 0, Step 822: train/loss = 0.4821908473968506, train/raw-loss = 0.4440012276172638, train/logprobs = tensor([[-0.7530, -2.9797],
        [-0.8810, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272987276315689
Epoch 0, Step 823: train/loss = 0.5050971508026123, train/raw-loss = 0.4651225805282593, train/logprobs = tensor([[-1.1924, -5.6301],
        [-0.9729, -2.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332486867904663
Epoch 0, Step 824: train/loss = 0.36110764741897583, train/raw-loss = 0.3175640106201172, train/logprobs = tensor([[-0.5759, -5.4709],
        [-1.0184, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14514538645744324
Epoch 0, Step 825: train/loss = 0.6810570955276489, train/raw-loss = 0.6403861045837402, train/logprobs = tensor([[-0.9870, -0.6266],
        [-1.3838, -0.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13556985557079315
Epoch 0, Step 826: train/loss = 0.4220248758792877, train/raw-loss = 0.3748518228530884, train/logprobs = tensor([[-1.2294, -4.0093],
        [-1.3947, -1.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572435200214386
Epoch 0, Step 827: train/loss = 0.43657076358795166, train/raw-loss = 0.3992026448249817, train/logprobs = tensor([[-0.5425, -2.7881],
        [-0.6811, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12456036359071732
Epoch 0, Step 828: train/loss = 0.3132716417312622, train/raw-loss = 0.2622501850128174, train/logprobs = tensor([[-0.8335, -3.6439],
        [-1.6121, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17007148265838623
Epoch 0, Step 829: train/loss = 0.5265112519264221, train/raw-loss = 0.481370747089386, train/logprobs = tensor([[-1.1274, -3.6333],
        [-1.1442, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504683792591095
Epoch 0, Step 830: train/loss = 0.3949476480484009, train/raw-loss = 0.3591817021369934, train/logprobs = tensor([[-0.4332, -5.5509],
        [-0.6423, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11921989917755127
Epoch 0, Step 831: train/loss = 0.35308921337127686, train/raw-loss = 0.3173505663871765, train/logprobs = tensor([[-0.5317, -2.5215],
        [-1.0217, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11912886798381805
Epoch 0, Step 832: train/loss = 0.3959639072418213, train/raw-loss = 0.3512735366821289, train/logprobs = tensor([[-0.7454, -2.9627],
        [-1.3927, -0.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1489679366350174
Epoch 0, Step 833: train/loss = 0.6235032677650452, train/raw-loss = 0.5810933709144592, train/logprobs = tensor([[-0.8022, -1.2463],
        [-0.8201, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14136621356010437
Epoch 0, Step 834: train/loss = 0.34859371185302734, train/raw-loss = 0.29974257946014404, train/logprobs = tensor([[-1.1102, -5.8202],
        [-1.5094, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16283704340457916
Epoch 0, Step 835: train/loss = 0.6087459325790405, train/raw-loss = 0.5751696825027466, train/logprobs = tensor([[-0.9263, -3.7862],
        [-1.0268, -1.2880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11192099750041962
Epoch 0, Step 836: train/loss = 0.42917782068252563, train/raw-loss = 0.3830259144306183, train/logprobs = tensor([[-0.7203, -4.8897],
        [-1.0927, -1.2830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15383978188037872
Epoch 0, Step 837: train/loss = 0.39193427562713623, train/raw-loss = 0.3508022725582123, train/logprobs = tensor([[-0.4990, -3.0870],
        [-0.7650, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1371067464351654
Epoch 0, Step 838: train/loss = 0.41709065437316895, train/raw-loss = 0.372169554233551, train/logprobs = tensor([[-0.8225, -3.8991],
        [-1.0245, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14973703026771545
Epoch 0, Step 839: train/loss = 0.3308704197406769, train/raw-loss = 0.2918738126754761, train/logprobs = tensor([[-0.6591, -4.9926],
        [-1.1039, -1.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12998870015144348
Epoch 0, Step 840: train/loss = 0.3568897843360901, train/raw-loss = 0.3036840558052063, train/logprobs = tensor([[-0.7235, -6.6742],
        [-1.3457, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17735251784324646
Epoch 0, Step 841: train/loss = 0.5329405069351196, train/raw-loss = 0.48569801449775696, train/logprobs = tensor([[-0.6756, -2.3769],
        [-1.0348, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15747511386871338
Epoch 0, Step 842: train/loss = 0.3717505931854248, train/raw-loss = 0.32804596424102783, train/logprobs = tensor([[-0.5586, -5.3305],
        [-1.3255, -1.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14568206667900085
Epoch 0, Step 843: train/loss = 0.4013769328594208, train/raw-loss = 0.3535457253456116, train/logprobs = tensor([[-1.1219, -4.5777],
        [-1.0954, -1.0310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15943744778633118
Epoch 0, Step 844: train/loss = 0.45525848865509033, train/raw-loss = 0.4075343608856201, train/logprobs = tensor([[-1.4117, -5.5037],
        [-1.2400, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15908053517341614
Epoch 0, Step 845: train/loss = 0.3497728407382965, train/raw-loss = 0.3009836673736572, train/logprobs = tensor([[-0.8127, -6.4710],
        [-1.3987, -1.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16263063251972198
Epoch 0, Step 846: train/loss = 0.3350682258605957, train/raw-loss = 0.3003343343734741, train/logprobs = tensor([[-0.5531, -8.5488],
        [-0.8989, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1157795786857605
Epoch 0, Step 847: train/loss = 0.43544310331344604, train/raw-loss = 0.3933681547641754, train/logprobs = tensor([[-0.9149, -4.2138],
        [-1.1373, -1.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402498483657837
Epoch 0, Step 848: train/loss = 0.2750144600868225, train/raw-loss = 0.22192808985710144, train/logprobs = tensor([[-0.9073, -5.0631],
        [-1.6918, -1.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17695459723472595
Epoch 0, Step 849: train/loss = 0.2917393147945404, train/raw-loss = 0.24607133865356445, train/logprobs = tensor([[-1.4089, -8.4705],
        [-1.6974, -1.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15222662687301636
Epoch 0, Step 850: train/loss = 0.43870389461517334, train/raw-loss = 0.39549708366394043, train/logprobs = tensor([[-0.6362, -4.1513],
        [-0.8858, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1440226435661316
Epoch 0, Step 851: train/loss = 0.358478307723999, train/raw-loss = 0.31186115741729736, train/logprobs = tensor([[-1.0282, -6.2159],
        [-1.5516, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15539047122001648
Epoch 0, Step 852: train/loss = 0.3914673924446106, train/raw-loss = 0.3514748215675354, train/logprobs = tensor([[-0.5404, -4.2886],
        [-1.0568, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333085298538208
Epoch 0, Step 853: train/loss = 0.5680803060531616, train/raw-loss = 0.5285210013389587, train/logprobs = tensor([[-1.1875, -3.6864],
        [-1.4128, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318642795085907
Epoch 0, Step 854: train/loss = 0.37877556681632996, train/raw-loss = 0.3306007981300354, train/logprobs = tensor([[-0.8431, -5.5117],
        [-1.2850, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16058246791362762
Epoch 0, Step 855: train/loss = 0.4121864438056946, train/raw-loss = 0.37083494663238525, train/logprobs = tensor([[-0.8137, -4.6655],
        [-1.2316, -1.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137838214635849
Epoch 0, Step 856: train/loss = 0.2984965443611145, train/raw-loss = 0.25040575861930847, train/logprobs = tensor([[-0.8183, -4.2521],
        [-1.5258, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16030260920524597
Epoch 0, Step 857: train/loss = 0.3718009889125824, train/raw-loss = 0.3198361396789551, train/logprobs = tensor([[-0.7015, -6.3461],
        [-1.3018, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17321614921092987
Epoch 0, Step 858: train/loss = 0.6017419099807739, train/raw-loss = 0.5502766370773315, train/logprobs = tensor([[-1.9788, -3.1943],
        [-1.4319, -0.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17155098915100098
Epoch 0, Step 859: train/loss = 0.3832766115665436, train/raw-loss = 0.3433179259300232, train/logprobs = tensor([[-0.8419, -3.4726],
        [-1.3733, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13319562375545502
Epoch 0, Step 860: train/loss = 0.4477977752685547, train/raw-loss = 0.4033259451389313, train/logprobs = tensor([[-0.8881, -4.0326],
        [-1.0440, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1482393443584442
Epoch 0, Step 861: train/loss = 0.5778886079788208, train/raw-loss = 0.5310826897621155, train/logprobs = tensor([[-1.0097, -3.9072],
        [-0.9099, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1560198962688446
Epoch 0, Step 862: train/loss = 0.35547834634780884, train/raw-loss = 0.30334702134132385, train/logprobs = tensor([[-0.8366, -6.3929],
        [-1.1470, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17377108335494995
Epoch 0, Step 863: train/loss = 0.5534440279006958, train/raw-loss = 0.5049681067466736, train/logprobs = tensor([[-1.1292, -4.1404],
        [-1.0663, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1615864634513855
Epoch 0, Step 864: train/loss = 0.6611626744270325, train/raw-loss = 0.6167535185813904, train/logprobs = tensor([[-1.3244, -2.3354],
        [-1.0817, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14803053438663483
Epoch 0, Step 865: train/loss = 0.3683215081691742, train/raw-loss = 0.3214553892612457, train/logprobs = tensor([[-0.8184, -3.0990],
        [-1.3309, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562204360961914
Epoch 0, Step 866: train/loss = 0.34434133768081665, train/raw-loss = 0.30270320177078247, train/logprobs = tensor([[-0.7112, -5.7977],
        [-0.8551, -1.3263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13879388570785522
Epoch 0, Step 867: train/loss = 0.5724284052848816, train/raw-loss = 0.5299064517021179, train/logprobs = tensor([[-0.7273, -2.5611],
        [-1.1521, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14173978567123413
Epoch 0, Step 868: train/loss = 0.4875340461730957, train/raw-loss = 0.4298867881298065, train/logprobs = tensor([[-0.9259, -1.8573],
        [-1.4187, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1921575665473938
Epoch 0, Step 869: train/loss = 0.3967569172382355, train/raw-loss = 0.3499324321746826, train/logprobs = tensor([[-0.8728, -1.9253],
        [-1.6808, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15608158707618713
Epoch 0, Step 870: train/loss = 0.4128725528717041, train/raw-loss = 0.372037410736084, train/logprobs = tensor([[-0.8940, -6.1887],
        [-1.3164, -1.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361171156167984
Epoch 0, Step 871: train/loss = 0.346537709236145, train/raw-loss = 0.302464097738266, train/logprobs = tensor([[-0.5458, -5.2615],
        [-0.9805, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14691206812858582
Epoch 0, Step 872: train/loss = 0.4944072365760803, train/raw-loss = 0.45909738540649414, train/logprobs = tensor([[-0.4047, -3.2044],
        [-0.5482, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11769956350326538
Epoch 0, Step 873: train/loss = 0.4324662685394287, train/raw-loss = 0.3923320174217224, train/logprobs = tensor([[-0.9088, -3.7764],
        [-1.1802, -0.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13378086686134338
Epoch 0, Step 874: train/loss = 0.3308362364768982, train/raw-loss = 0.271846741437912, train/logprobs = tensor([[-1.1398, -6.3332],
        [-1.7954, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19663162529468536
Epoch 0, Step 875: train/loss = 0.6175351738929749, train/raw-loss = 0.5790479183197021, train/logprobs = tensor([[-0.8715, -1.1619],
        [-1.1107, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282908171415329
Epoch 0, Step 876: train/loss = 0.3940574526786804, train/raw-loss = 0.3606272339820862, train/logprobs = tensor([[-0.4185, -6.5540],
        [-0.7948, -1.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11143415421247482
Epoch 0, Step 877: train/loss = 0.4423028230667114, train/raw-loss = 0.3902990221977234, train/logprobs = tensor([[-1.3224, -5.1819],
        [-1.8720, -0.8733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17334604263305664
Epoch 0, Step 878: train/loss = 1.1157945394515991, train/raw-loss = 1.0676263570785522, train/logprobs = tensor([[-3.1171, -5.1734],
        [-1.3494, -0.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16056032478809357
Epoch 0, Step 879: train/loss = 0.32080310583114624, train/raw-loss = 0.27786383032798767, train/logprobs = tensor([[-0.4903, -8.0765],
        [-1.0515, -1.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14313098788261414
Epoch 0, Step 880: train/loss = 0.3515099883079529, train/raw-loss = 0.3110244870185852, train/logprobs = tensor([[-0.6336, -4.6567],
        [-0.9920, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13495172560214996
Epoch 0, Step 881: train/loss = 0.4950021505355835, train/raw-loss = 0.4535471200942993, train/logprobs = tensor([[-0.6011, -3.9833],
        [-0.8343, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13818350434303284
Epoch 0, Step 882: train/loss = 0.5805881023406982, train/raw-loss = 0.5386018753051758, train/logprobs = tensor([[-0.8509, -2.0484],
        [-0.7648, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13995403051376343
Epoch 0, Step 883: train/loss = 0.36471039056777954, train/raw-loss = 0.3136047124862671, train/logprobs = tensor([[-1.1359, -3.5970],
        [-1.9158, -0.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703522652387619
Epoch 0, Step 884: train/loss = 0.38067036867141724, train/raw-loss = 0.33361613750457764, train/logprobs = tensor([[-0.6916, -4.3964],
        [-1.0176, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15684747695922852
Epoch 0, Step 885: train/loss = 0.34493201971054077, train/raw-loss = 0.29575181007385254, train/logprobs = tensor([[-1.1475, -5.5661],
        [-1.2642, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1639341115951538
Epoch 0, Step 886: train/loss = 0.5199014544487, train/raw-loss = 0.47665831446647644, train/logprobs = tensor([[-0.6803, -2.8673],
        [-1.1384, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441437005996704
Epoch 0, Step 887: train/loss = 0.4596819281578064, train/raw-loss = 0.4169577360153198, train/logprobs = tensor([[-0.7250, -4.2338],
        [-1.0375, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424138993024826
Epoch 0, Step 888: train/loss = 0.23479920625686646, train/raw-loss = 0.18668913841247559, train/logprobs = tensor([[-0.6675, -6.1450],
        [-1.3869, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603669375181198
Epoch 0, Step 889: train/loss = 0.4153866767883301, train/raw-loss = 0.3675386905670166, train/logprobs = tensor([[-0.8659, -3.6246],
        [-1.2229, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15949326753616333
Epoch 0, Step 890: train/loss = 0.3890130817890167, train/raw-loss = 0.3387467563152313, train/logprobs = tensor([[-0.8155, -3.3808],
        [-1.2164, -1.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675543636083603
Epoch 0, Step 891: train/loss = 0.2930348217487335, train/raw-loss = 0.2528282403945923, train/logprobs = tensor([[-0.7800, -5.5862],
        [-1.3243, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13402196764945984
Epoch 0, Step 892: train/loss = 0.375629186630249, train/raw-loss = 0.3260335922241211, train/logprobs = tensor([[-0.6293, -4.4012],
        [-1.1313, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16531863808631897
Epoch 0, Step 893: train/loss = 0.4530412256717682, train/raw-loss = 0.412322461605072, train/logprobs = tensor([[-0.7934, -4.0125],
        [-1.0512, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13572925329208374
Epoch 0, Step 894: train/loss = 0.3598092794418335, train/raw-loss = 0.3106016516685486, train/logprobs = tensor([[-0.7346, -7.0147],
        [-1.1365, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640254110097885
Epoch 0, Step 895: train/loss = 0.44731852412223816, train/raw-loss = 0.4021000862121582, train/logprobs = tensor([[-0.6871, -6.1345],
        [-1.3080, -2.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15072812139987946
Epoch 0, Step 896: train/loss = 0.5453712940216064, train/raw-loss = 0.5010958909988403, train/logprobs = tensor([[-0.9303, -2.4318],
        [-1.0609, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14758461713790894
Epoch 0, Step 897: train/loss = 0.4682523012161255, train/raw-loss = 0.4098826050758362, train/logprobs = tensor([[-0.9743, -3.2945],
        [-1.4690, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19456571340560913
Epoch 0, Step 898: train/loss = 0.5214202404022217, train/raw-loss = 0.4818853735923767, train/logprobs = tensor([[-0.7406, -1.3546],
        [-1.0811, -0.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13178278505802155
Epoch 0, Step 899: train/loss = 0.43727731704711914, train/raw-loss = 0.3870365023612976, train/logprobs = tensor([[-0.6398, -4.2614],
        [-1.0465, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16746951639652252
Epoch 0, Step 900: train/loss = 0.2896310091018677, train/raw-loss = 0.24394464492797852, train/logprobs = tensor([[-1.1558, -9.9602],
        [-1.5362, -1.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15228787064552307
Epoch 0, Step 901: train/loss = 0.3598349988460541, train/raw-loss = 0.3167569041252136, train/logprobs = tensor([[-0.4125, -4.2035],
        [-0.9262, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14359360933303833
Epoch 0, Step 902: train/loss = 0.2509017288684845, train/raw-loss = 0.203474760055542, train/logprobs = tensor([[-0.7439, -7.2413],
        [-1.4354, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15808993577957153
Epoch 0, Step 903: train/loss = 0.37907785177230835, train/raw-loss = 0.3276025056838989, train/logprobs = tensor([[-0.9778, -3.7224],
        [-1.5694, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17158453166484833
Epoch 0, Step 904: train/loss = 0.43489283323287964, train/raw-loss = 0.39600032567977905, train/logprobs = tensor([[-1.3462, -4.4098],
        [-1.5009, -1.5690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129641592502594
Epoch 0, Step 905: train/loss = 0.3179432153701782, train/raw-loss = 0.28018447756767273, train/logprobs = tensor([[-0.5038, -6.6318],
        [-0.9196, -1.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258624792098999
Epoch 0, Step 906: train/loss = 0.61937016248703, train/raw-loss = 0.5863944292068481, train/logprobs = tensor([[-0.6611, -1.2747],
        [-0.6318, -0.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10991910099983215
Epoch 0, Step 907: train/loss = 0.6026253700256348, train/raw-loss = 0.5622716546058655, train/logprobs = tensor([[-0.8572, -1.5614],
        [-0.8368, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13451237976551056
Epoch 0, Step 908: train/loss = 0.3623378276824951, train/raw-loss = 0.31495124101638794, train/logprobs = tensor([[-0.7304, -5.1444],
        [-1.2058, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15795528888702393
Epoch 0, Step 909: train/loss = 0.3313692808151245, train/raw-loss = 0.27555301785469055, train/logprobs = tensor([[-1.1788, -4.0334],
        [-1.9950, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18605419993400574
Epoch 0, Step 910: train/loss = 0.5373715162277222, train/raw-loss = 0.49450868368148804, train/logprobs = tensor([[-0.9573, -3.8136],
        [-1.1195, -1.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14287608861923218
Epoch 0, Step 911: train/loss = 0.2775840759277344, train/raw-loss = 0.2302177995443344, train/logprobs = tensor([[-0.7922, -6.8363],
        [-1.2503, -1.2887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15788759291172028
Epoch 0, Step 912: train/loss = 0.4652138650417328, train/raw-loss = 0.41689178347587585, train/logprobs = tensor([[-1.2044, -5.3698],
        [-0.9285, -1.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16107359528541565
Epoch 0, Step 913: train/loss = 0.3483871519565582, train/raw-loss = 0.30104297399520874, train/logprobs = tensor([[-0.8499, -5.9983],
        [-1.4397, -1.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15781396627426147
Epoch 0, Step 914: train/loss = 0.5139651298522949, train/raw-loss = 0.4762542247772217, train/logprobs = tensor([[-0.4109, -2.0582],
        [-0.8542, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12570299208164215
Epoch 0, Step 915: train/loss = 0.41304346919059753, train/raw-loss = 0.3637884259223938, train/logprobs = tensor([[-0.8424, -3.2927],
        [-1.2333, -0.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16418346762657166
Epoch 0, Step 916: train/loss = 0.4182513952255249, train/raw-loss = 0.37869560718536377, train/logprobs = tensor([[-1.2332, -3.1032],
        [-1.2943, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318526566028595
Epoch 0, Step 917: train/loss = 0.40508291125297546, train/raw-loss = 0.35468748211860657, train/logprobs = tensor([[-1.0782, -3.2792],
        [-1.3844, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.167984738945961
Epoch 0, Step 918: train/loss = 0.5409163236618042, train/raw-loss = 0.49952271580696106, train/logprobs = tensor([[-0.5959, -1.5304],
        [-0.8407, -0.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13797879219055176
Epoch 0, Step 919: train/loss = 0.5807167291641235, train/raw-loss = 0.5419604778289795, train/logprobs = tensor([[-0.9038, -2.7259],
        [-0.9929, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12918761372566223
Epoch 0, Step 920: train/loss = 0.616993248462677, train/raw-loss = 0.5814669132232666, train/logprobs = tensor([[-0.8426, -0.8430],
        [-1.1653, -0.6245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11842088401317596
Epoch 0, Step 921: train/loss = 0.5524653792381287, train/raw-loss = 0.5153993368148804, train/logprobs = tensor([[-0.4865, -1.9499],
        [-0.9638, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12355346232652664
Epoch 0, Step 922: train/loss = 0.469896137714386, train/raw-loss = 0.4271836578845978, train/logprobs = tensor([[-0.7284, -4.0282],
        [-0.7513, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14237476885318756
Epoch 0, Step 923: train/loss = 0.4501190781593323, train/raw-loss = 0.4002341032028198, train/logprobs = tensor([[-1.0646, -4.1379],
        [-1.0872, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662832498550415
Epoch 0, Step 924: train/loss = 0.34135299921035767, train/raw-loss = 0.2986363172531128, train/logprobs = tensor([[-0.7746, -5.0368],
        [-1.4554, -1.5236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14238889515399933
Epoch 0, Step 925: train/loss = 0.5317189693450928, train/raw-loss = 0.4974752366542816, train/logprobs = tensor([[-0.5040, -1.7683],
        [-0.5879, -0.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11414570361375809
Epoch 0, Step 926: train/loss = 0.5370189547538757, train/raw-loss = 0.5024440288543701, train/logprobs = tensor([[-0.4702, -2.1185],
        [-0.6782, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11524982750415802
Epoch 0, Step 927: train/loss = 0.559694230556488, train/raw-loss = 0.5084706544876099, train/logprobs = tensor([[-1.2579, -3.4797],
        [-1.1011, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17074546217918396
Epoch 0, Step 928: train/loss = 0.36529773473739624, train/raw-loss = 0.31628113985061646, train/logprobs = tensor([[-0.8408, -5.0212],
        [-0.9928, -1.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16338852047920227
Epoch 0, Step 929: train/loss = 0.35071709752082825, train/raw-loss = 0.30503660440444946, train/logprobs = tensor([[-0.6108, -3.7204],
        [-1.4149, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15226829051971436
Epoch 0, Step 930: train/loss = 0.45464205741882324, train/raw-loss = 0.4050390124320984, train/logprobs = tensor([[-0.7651, -2.1339],
        [-1.2595, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1653435081243515
Epoch 0, Step 931: train/loss = 0.3628285229206085, train/raw-loss = 0.323387086391449, train/logprobs = tensor([[-0.6675, -3.1854],
        [-1.1245, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314714401960373
Epoch 0, Step 932: train/loss = 0.3997883200645447, train/raw-loss = 0.34700122475624084, train/logprobs = tensor([[-0.5709, -3.8254],
        [-1.2415, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17595694959163666
Epoch 0, Step 933: train/loss = 0.4643974304199219, train/raw-loss = 0.4256914258003235, train/logprobs = tensor([[-0.6031, -2.1112],
        [-0.9867, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901997566223145
Epoch 0, Step 934: train/loss = 0.4939879775047302, train/raw-loss = 0.45153188705444336, train/logprobs = tensor([[-0.5088, -2.8032],
        [-0.9948, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1415203958749771
Epoch 0, Step 935: train/loss = 0.3999858796596527, train/raw-loss = 0.3465786874294281, train/logprobs = tensor([[-0.8915, -3.6213],
        [-1.5059, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17802393436431885
Epoch 0, Step 936: train/loss = 0.49658215045928955, train/raw-loss = 0.4449715316295624, train/logprobs = tensor([[-0.9640, -2.7801],
        [-1.3216, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17203539609909058
Epoch 0, Step 937: train/loss = 0.5013900995254517, train/raw-loss = 0.4540495276451111, train/logprobs = tensor([[-0.8431, -3.7830],
        [-1.0866, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15780189633369446
Epoch 0, Step 938: train/loss = 0.33614277839660645, train/raw-loss = 0.27327296137809753, train/logprobs = tensor([[-0.7479, -3.4707],
        [-1.6789, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20956605672836304
Epoch 0, Step 939: train/loss = 0.39199572801589966, train/raw-loss = 0.34491628408432007, train/logprobs = tensor([[-0.9243, -4.1246],
        [-0.9847, -0.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569315642118454
Epoch 0, Step 940: train/loss = 0.2953641712665558, train/raw-loss = 0.2375992238521576, train/logprobs = tensor([[-0.7935, -3.5645],
        [-1.7433, -1.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19254980981349945
Epoch 0, Step 941: train/loss = 0.41390562057495117, train/raw-loss = 0.3749046325683594, train/logprobs = tensor([[-0.7755, -3.7851],
        [-1.2023, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13000324368476868
Epoch 0, Step 942: train/loss = 0.4645228981971741, train/raw-loss = 0.40684837102890015, train/logprobs = tensor([[-1.0405, -3.9155],
        [-1.6301, -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1922483742237091
Epoch 0, Step 943: train/loss = 0.355868935585022, train/raw-loss = 0.2978121340274811, train/logprobs = tensor([[-0.8280, -3.2006],
        [-1.8420, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19352266192436218
Epoch 0, Step 944: train/loss = 0.22204099595546722, train/raw-loss = 0.17131663858890533, train/logprobs = tensor([[-0.7230, -7.5328],
        [-1.6851, -1.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16908113658428192
Epoch 0, Step 945: train/loss = 0.4702554941177368, train/raw-loss = 0.42823803424835205, train/logprobs = tensor([[-1.1147, -3.2819],
        [-1.0933, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1400582194328308
Epoch 0, Step 946: train/loss = 0.42030060291290283, train/raw-loss = 0.36963433027267456, train/logprobs = tensor([[-0.8128, -6.1384],
        [-1.4588, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16888758540153503
Epoch 0, Step 947: train/loss = 0.735298752784729, train/raw-loss = 0.697383463382721, train/logprobs = tensor([[-0.8169, -0.8180],
        [-0.8551, -0.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12638452649116516
Epoch 0, Step 948: train/loss = 0.42634081840515137, train/raw-loss = 0.37494954466819763, train/logprobs = tensor([[-0.6846, -2.7935],
        [-1.1220, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17130416631698608
Epoch 0, Step 949: train/loss = 0.4861834645271301, train/raw-loss = 0.4361172318458557, train/logprobs = tensor([[-0.9178, -3.2440],
        [-1.2352, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16688741743564606
Epoch 0, Step 950: train/loss = 0.3035440444946289, train/raw-loss = 0.2631635069847107, train/logprobs = tensor([[-0.4353, -3.7970],
        [-1.3459, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13460178673267365
Epoch 0, Step 951: train/loss = 0.5692234039306641, train/raw-loss = 0.5187544822692871, train/logprobs = tensor([[-1.5183, -3.8626],
        [-1.2268, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1682298183441162
Epoch 0, Step 952: train/loss = 0.407047301530838, train/raw-loss = 0.3690319359302521, train/logprobs = tensor([[-0.3940, -3.8340],
        [-0.7706, -0.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1267179548740387
Epoch 0, Step 953: train/loss = 0.5251492261886597, train/raw-loss = 0.48536044359207153, train/logprobs = tensor([[-0.6991, -2.0594],
        [-1.0371, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13262906670570374
Epoch 0, Step 954: train/loss = 0.5152931213378906, train/raw-loss = 0.4766700267791748, train/logprobs = tensor([[-0.6639, -1.4369],
        [-0.9794, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12874366343021393
Epoch 0, Step 955: train/loss = 0.33693504333496094, train/raw-loss = 0.2904403507709503, train/logprobs = tensor([[-0.8193, -6.3927],
        [-1.2549, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549823135137558
Epoch 0, Step 956: train/loss = 0.3615105152130127, train/raw-loss = 0.3203604221343994, train/logprobs = tensor([[-0.5286, -3.8452],
        [-1.0584, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13716697692871094
Epoch 0, Step 957: train/loss = 0.45132046937942505, train/raw-loss = 0.40881186723709106, train/logprobs = tensor([[-1.0600, -5.1801],
        [-1.3373, -1.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14169526100158691
Epoch 0, Step 958: train/loss = 0.457691490650177, train/raw-loss = 0.4156540632247925, train/logprobs = tensor([[-0.8102, -4.7726],
        [-0.8555, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14012466371059418
Epoch 0, Step 959: train/loss = 0.4207912087440491, train/raw-loss = 0.37939274311065674, train/logprobs = tensor([[-0.6083, -3.7713],
        [-1.1035, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379949301481247
Epoch 0, Step 960: train/loss = 0.552612841129303, train/raw-loss = 0.5132826566696167, train/logprobs = tensor([[-0.6166, -1.2824],
        [-1.1245, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131100594997406
Epoch 0, Step 961: train/loss = 0.31280094385147095, train/raw-loss = 0.2648937404155731, train/logprobs = tensor([[-0.9471, -4.1763],
        [-1.7322, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15969069302082062
Epoch 0, Step 962: train/loss = 0.494859904050827, train/raw-loss = 0.44917941093444824, train/logprobs = tensor([[-1.4184, -4.9955],
        [-1.8120, -1.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15226827561855316
Epoch 0, Step 963: train/loss = 0.5063137412071228, train/raw-loss = 0.4614286422729492, train/logprobs = tensor([[-0.7017, -1.8865],
        [-0.9173, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1496170461177826
Epoch 0, Step 964: train/loss = 0.45929425954818726, train/raw-loss = 0.4134039878845215, train/logprobs = tensor([[-0.7440, -2.6875],
        [-1.2665, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15296751260757446
Epoch 0, Step 965: train/loss = 0.3746532201766968, train/raw-loss = 0.33643025159835815, train/logprobs = tensor([[-0.9014, -4.1280],
        [-1.3092, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1274099349975586
Epoch 0, Step 966: train/loss = 0.42022714018821716, train/raw-loss = 0.3784119486808777, train/logprobs = tensor([[-0.4404, -2.4739],
        [-1.1548, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13938379287719727
Epoch 0, Step 967: train/loss = 0.4463123679161072, train/raw-loss = 0.40526628494262695, train/logprobs = tensor([[-0.5645, -2.5186],
        [-1.1198, -0.4799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368202567100525
Epoch 0, Step 968: train/loss = 0.46766728162765503, train/raw-loss = 0.4267667531967163, train/logprobs = tensor([[-0.8984, -2.8965],
        [-1.7643, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13633501529693604
Epoch 0, Step 969: train/loss = 0.36323636770248413, train/raw-loss = 0.30605632066726685, train/logprobs = tensor([[-0.5622, -4.3123],
        [-1.5500, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19060014188289642
Epoch 0, Step 970: train/loss = 0.4601437747478485, train/raw-loss = 0.41260969638824463, train/logprobs = tensor([[-0.6299, -2.3595],
        [-1.0768, -0.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1584469974040985
Epoch 0, Step 971: train/loss = 0.4175281822681427, train/raw-loss = 0.3731110692024231, train/logprobs = tensor([[-0.3303, -4.1366],
        [-0.8155, -1.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480570286512375
Epoch 0, Step 972: train/loss = 0.4708517789840698, train/raw-loss = 0.43020230531692505, train/logprobs = tensor([[-0.6576, -4.6408],
        [-0.8751, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13549822568893433
Epoch 0, Step 973: train/loss = 0.5271176099777222, train/raw-loss = 0.4855234622955322, train/logprobs = tensor([[-0.5982, -1.8908],
        [-1.1695, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13864733278751373
Epoch 0, Step 974: train/loss = 0.4381254315376282, train/raw-loss = 0.388468474149704, train/logprobs = tensor([[-0.7951, -3.8508],
        [-1.2811, -1.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16552332043647766
Epoch 0, Step 975: train/loss = 0.3476231098175049, train/raw-loss = 0.2979132831096649, train/logprobs = tensor([[-0.4773, -3.4492],
        [-0.9455, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16569943726062775
Epoch 0, Step 976: train/loss = 0.5235961079597473, train/raw-loss = 0.47523391246795654, train/logprobs = tensor([[-0.4077, -2.7249],
        [-1.1682, -1.2171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612071692943573
Epoch 0, Step 977: train/loss = 0.4703677296638489, train/raw-loss = 0.42373916506767273, train/logprobs = tensor([[-0.7447, -3.2540],
        [-1.0544, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15542858839035034
Epoch 0, Step 978: train/loss = 0.44553083181381226, train/raw-loss = 0.3907807469367981, train/logprobs = tensor([[-1.3119, -3.5278],
        [-1.4003, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18250024318695068
Epoch 0, Step 979: train/loss = 0.43482714891433716, train/raw-loss = 0.3930485248565674, train/logprobs = tensor([[-0.5695, -2.7483],
        [-1.0457, -0.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13926208019256592
Epoch 0, Step 980: train/loss = 0.30900853872299194, train/raw-loss = 0.26606881618499756, train/logprobs = tensor([[-0.5677, -3.5008],
        [-1.1689, -0.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14313241839408875
Epoch 0, Step 981: train/loss = 0.4259883761405945, train/raw-loss = 0.37773123383522034, train/logprobs = tensor([[-1.0447, -4.8968],
        [-1.7763, -1.6930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16085705161094666
Epoch 0, Step 982: train/loss = 0.368807852268219, train/raw-loss = 0.32181990146636963, train/logprobs = tensor([[-0.7032, -2.9987],
        [-1.2316, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15662655234336853
Epoch 0, Step 983: train/loss = 0.45317548513412476, train/raw-loss = 0.4085889756679535, train/logprobs = tensor([[-0.8492, -3.1071],
        [-1.0394, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1486218273639679
Epoch 0, Step 984: train/loss = 0.47218525409698486, train/raw-loss = 0.41672295331954956, train/logprobs = tensor([[-0.5291, -2.0239],
        [-1.3320, -1.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18487435579299927
Epoch 0, Step 985: train/loss = 0.5523431897163391, train/raw-loss = 0.5149423480033875, train/logprobs = tensor([[-0.5989, -1.3975],
        [-0.9067, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12466941773891449
Epoch 0, Step 986: train/loss = 0.23527996242046356, train/raw-loss = 0.1824783980846405, train/logprobs = tensor([[-0.6689, -7.1253],
        [-1.6958, -1.5268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17600521445274353
Epoch 0, Step 987: train/loss = 0.6090136766433716, train/raw-loss = 0.5689653754234314, train/logprobs = tensor([[-1.4074, -2.2232],
        [-1.1256, -0.5880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13349442183971405
Epoch 0, Step 988: train/loss = 0.5853089094161987, train/raw-loss = 0.5346165895462036, train/logprobs = tensor([[-0.6676, -2.1518],
        [-2.0905, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1689743846654892
Epoch 0, Step 989: train/loss = 0.36863330006599426, train/raw-loss = 0.32047390937805176, train/logprobs = tensor([[-0.7954, -2.7504],
        [-1.3589, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16053125262260437
Epoch 0, Step 990: train/loss = 0.48561906814575195, train/raw-loss = 0.4439678192138672, train/logprobs = tensor([[-0.5145, -2.6923],
        [-0.8163, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13883757591247559
Epoch 0, Step 991: train/loss = 0.5556499361991882, train/raw-loss = 0.5177868008613586, train/logprobs = tensor([[-0.5355, -1.0984],
        [-0.8577, -0.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12621045112609863
Epoch 0, Step 992: train/loss = 0.3821254074573517, train/raw-loss = 0.3353719115257263, train/logprobs = tensor([[-0.4902, -3.6174],
        [-1.0679, -0.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15584497153759003
Epoch 0, Step 993: train/loss = 0.3710229694843292, train/raw-loss = 0.32252609729766846, train/logprobs = tensor([[-0.5526, -2.6889],
        [-1.2941, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616562008857727
Epoch 0, Step 994: train/loss = 0.22891005873680115, train/raw-loss = 0.1704627275466919, train/logprobs = tensor([[-0.7327, -4.8420],
        [-1.8297, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1948244869709015
Epoch 0, Step 995: train/loss = 0.25429704785346985, train/raw-loss = 0.2136944830417633, train/logprobs = tensor([[-0.4949, -5.1730],
        [-1.0318, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1353418529033661
Epoch 0, Step 996: train/loss = 0.515480637550354, train/raw-loss = 0.4745374321937561, train/logprobs = tensor([[-0.5168, -2.9347],
        [-0.9647, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13647745549678802
Epoch 0, Step 997: train/loss = 0.31080323457717896, train/raw-loss = 0.2693733870983124, train/logprobs = tensor([[-0.6793, -4.6207],
        [-0.9702, -1.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13809938728809357
Epoch 0, Step 998: train/loss = 0.3391444981098175, train/raw-loss = 0.27139198780059814, train/logprobs = tensor([[-0.6942, -3.4797],
        [-1.9264, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22584179043769836
Epoch 0, Step 999: train/loss = 0.4907146096229553, train/raw-loss = 0.44737961888313293, train/logprobs = tensor([[-0.6444, -2.1528],
        [-1.2217, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444994926452637
Epoch 0, Step 1000: train/loss = 0.4934490919113159, train/raw-loss = 0.43386101722717285, train/logprobs = tensor([[-0.9777, -2.3172],
        [-1.8391, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1986268013715744
Epoch 0, Step 1001: train/loss = 0.41357970237731934, train/raw-loss = 0.3586779236793518, train/logprobs = tensor([[-0.7613, -3.6879],
        [-1.3276, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18300604820251465
Epoch 0, Step 1002: train/loss = 0.4330917000770569, train/raw-loss = 0.3736341893672943, train/logprobs = tensor([[-0.5387, -4.2806],
        [-1.5468, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19819176197052002
Epoch 0, Step 1003: train/loss = 0.4010387063026428, train/raw-loss = 0.34566375613212585, train/logprobs = tensor([[-1.1289, -3.8882],
        [-1.4867, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1845831722021103
Epoch 0, Step 1004: train/loss = 0.6310675144195557, train/raw-loss = 0.5855176448822021, train/logprobs = tensor([[-0.6093, -0.9730],
        [-0.8341, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15183275938034058
Epoch 0, Step 1005: train/loss = 0.20611418783664703, train/raw-loss = 0.15319159626960754, train/logprobs = tensor([[-0.7711, -6.8235],
        [-1.8305, -1.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17640866339206696
Epoch 0, Step 1006: train/loss = 0.5985469818115234, train/raw-loss = 0.5547150373458862, train/logprobs = tensor([[-0.7926, -1.3074],
        [-1.1620, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14610645174980164
Epoch 0, Step 1007: train/loss = 0.5667890310287476, train/raw-loss = 0.5240145921707153, train/logprobs = tensor([[-1.4776, -1.8860],
        [-1.7630, -0.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142581507563591
Epoch 0, Step 1008: train/loss = 0.4623391032218933, train/raw-loss = 0.4169681966304779, train/logprobs = tensor([[-0.5710, -3.5262],
        [-1.1142, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15123634040355682
Epoch 0, Step 1009: train/loss = 0.4657321572303772, train/raw-loss = 0.4185274839401245, train/logprobs = tensor([[-0.6493, -5.3005],
        [-1.4504, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15734896063804626
Epoch 0, Step 1010: train/loss = 0.4915851354598999, train/raw-loss = 0.4429832696914673, train/logprobs = tensor([[-0.9459, -3.5630],
        [-0.9732, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16200631856918335
Epoch 0, Step 1011: train/loss = 0.6193557977676392, train/raw-loss = 0.5691942572593689, train/logprobs = tensor([[-0.5161, -1.4843],
        [-1.2494, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16720536351203918
Epoch 0, Step 1012: train/loss = 0.27980753779411316, train/raw-loss = 0.2342211902141571, train/logprobs = tensor([[-0.6349, -4.3413],
        [-1.7304, -0.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1519545167684555
Epoch 0, Step 1013: train/loss = 0.1939142942428589, train/raw-loss = 0.1319456845521927, train/logprobs = tensor([[-1.0529, -6.5814],
        [-2.8322, -1.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20656198263168335
Epoch 0, Step 1014: train/loss = 0.4259950518608093, train/raw-loss = 0.37568241357803345, train/logprobs = tensor([[-0.8231, -3.6535],
        [-1.4357, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16770869493484497
Epoch 0, Step 1015: train/loss = 0.28137317299842834, train/raw-loss = 0.23113787174224854, train/logprobs = tensor([[-0.5333, -4.4479],
        [-1.7231, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1674509346485138
Epoch 0, Step 1016: train/loss = 0.41784968972206116, train/raw-loss = 0.36787569522857666, train/logprobs = tensor([[-0.9013, -4.9897],
        [-1.4331, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.166579931974411
Epoch 0, Step 1017: train/loss = 0.3668551743030548, train/raw-loss = 0.31954360008239746, train/logprobs = tensor([[-0.5925, -5.9863],
        [-1.0609, -1.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15770529210567474
Epoch 0, Step 1018: train/loss = 0.5001779794692993, train/raw-loss = 0.4534881114959717, train/logprobs = tensor([[-0.8778, -3.4118],
        [-1.1438, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15563291311264038
Epoch 0, Step 1019: train/loss = 0.421006441116333, train/raw-loss = 0.3661578893661499, train/logprobs = tensor([[-1.1031, -4.2900],
        [-1.6075, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18282853066921234
Epoch 0, Step 1020: train/loss = 0.45056647062301636, train/raw-loss = 0.4067000150680542, train/logprobs = tensor([[-0.8176, -5.7842],
        [-0.9356, -1.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14622142910957336
Epoch 0, Step 1021: train/loss = 0.34083259105682373, train/raw-loss = 0.2939605712890625, train/logprobs = tensor([[-0.6439, -4.7808],
        [-1.2946, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562400460243225
Epoch 0, Step 1022: train/loss = 0.5106099247932434, train/raw-loss = 0.4763084053993225, train/logprobs = tensor([[-0.5543, -1.4631],
        [-0.9410, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11433830112218857
Epoch 0, Step 1023: train/loss = 0.6076733469963074, train/raw-loss = 0.5616702437400818, train/logprobs = tensor([[-0.5430, -1.8534],
        [-1.2000, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1533435434103012
Epoch 0, Step 1024: train/loss = 0.4233190715312958, train/raw-loss = 0.3729870915412903, train/logprobs = tensor([[-1.0200, -4.2536],
        [-1.2515, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16777333617210388
Epoch 0, Step 1025: train/loss = 0.3793095648288727, train/raw-loss = 0.3352212607860565, train/logprobs = tensor([[-0.8240, -3.8904],
        [-1.3007, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1469610333442688
Epoch 0, Step 1026: train/loss = 0.3684166669845581, train/raw-loss = 0.3100881278514862, train/logprobs = tensor([[-0.7850, -3.9378],
        [-1.3642, -0.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.194428488612175
Epoch 0, Step 1027: train/loss = 0.6656649112701416, train/raw-loss = 0.6276063919067383, train/logprobs = tensor([[-0.5501, -0.9540],
        [-0.8171, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1268613487482071
Epoch 0, Step 1028: train/loss = 0.39929401874542236, train/raw-loss = 0.3610821068286896, train/logprobs = tensor([[-0.8134, -4.9919],
        [-1.8131, -1.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12737300992012024
Epoch 0, Step 1029: train/loss = 0.5566819906234741, train/raw-loss = 0.5148588418960571, train/logprobs = tensor([[-0.4432, -2.1576],
        [-0.8122, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13941045105457306
Epoch 0, Step 1030: train/loss = 0.3332766890525818, train/raw-loss = 0.2797955572605133, train/logprobs = tensor([[-0.7032, -5.5210],
        [-1.9450, -1.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1782703548669815
Epoch 0, Step 1031: train/loss = 0.45526033639907837, train/raw-loss = 0.4002707600593567, train/logprobs = tensor([[-0.8734, -2.4345],
        [-1.2402, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18329854309558868
Epoch 0, Step 1032: train/loss = 0.46971818804740906, train/raw-loss = 0.4271426200866699, train/logprobs = tensor([[-0.7579, -2.2336],
        [-1.5746, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14191865921020508
Epoch 0, Step 1033: train/loss = 0.32779186964035034, train/raw-loss = 0.2641104757785797, train/logprobs = tensor([[-1.0721, -4.7366],
        [-2.3232, -1.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21227127313613892
Epoch 0, Step 1034: train/loss = 0.41718244552612305, train/raw-loss = 0.3748946487903595, train/logprobs = tensor([[-0.8071, -2.4308],
        [-1.3163, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14095930755138397
Epoch 0, Step 1035: train/loss = 0.5022729635238647, train/raw-loss = 0.44946038722991943, train/logprobs = tensor([[-0.8585, -2.7081],
        [-1.5428, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17604191601276398
Epoch 0, Step 1036: train/loss = 0.5245800018310547, train/raw-loss = 0.47764384746551514, train/logprobs = tensor([[-0.5559, -2.1576],
        [-1.1344, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15645389258861542
Epoch 0, Step 1037: train/loss = 0.5012735724449158, train/raw-loss = 0.4534645676612854, train/logprobs = tensor([[-0.6260, -2.6057],
        [-1.4005, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15936343371868134
Epoch 0, Step 1038: train/loss = 0.41256511211395264, train/raw-loss = 0.35367724299430847, train/logprobs = tensor([[-0.9563, -4.9265],
        [-1.4708, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19629278779029846
Epoch 0, Step 1039: train/loss = 0.33347171545028687, train/raw-loss = 0.28000396490097046, train/logprobs = tensor([[-0.7547, -7.1691],
        [-1.6307, -2.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1782257854938507
Epoch 0, Step 1040: train/loss = 0.49792128801345825, train/raw-loss = 0.45092999935150146, train/logprobs = tensor([[-1.4090, -3.6683],
        [-1.6273, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566375344991684
Epoch 0, Step 1041: train/loss = 0.3163233995437622, train/raw-loss = 0.264839231967926, train/logprobs = tensor([[-0.7899, -6.0376],
        [-1.5179, -1.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17161397635936737
Epoch 0, Step 1042: train/loss = 0.5012556314468384, train/raw-loss = 0.46732574701309204, train/logprobs = tensor([[-0.7171, -2.6020],
        [-0.7943, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11309950798749924
Epoch 0, Step 1043: train/loss = 0.700302243232727, train/raw-loss = 0.6562732458114624, train/logprobs = tensor([[-1.2306, -1.5220],
        [-1.1050, -0.7411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14676323533058167
Epoch 0, Step 1044: train/loss = 0.5220907926559448, train/raw-loss = 0.47464805841445923, train/logprobs = tensor([[-0.8329, -1.5910],
        [-1.8025, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15814240276813507
Epoch 0, Step 1045: train/loss = 0.42933389544487, train/raw-loss = 0.38745391368865967, train/logprobs = tensor([[-0.6180, -3.4900],
        [-1.1337, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13959990441799164
Epoch 0, Step 1046: train/loss = 0.4077666401863098, train/raw-loss = 0.3605845272541046, train/logprobs = tensor([[-0.5602, -3.4707],
        [-1.1286, -0.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15727365016937256
Epoch 0, Step 1047: train/loss = 0.5086468458175659, train/raw-loss = 0.46217963099479675, train/logprobs = tensor([[-0.6733, -1.5542],
        [-1.0665, -0.7299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15489067137241364
Epoch 0, Step 1048: train/loss = 0.21893472969532013, train/raw-loss = 0.170604407787323, train/logprobs = tensor([[-0.6906, -7.6150],
        [-1.5832, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16110101342201233
Epoch 0, Step 1049: train/loss = 0.33939266204833984, train/raw-loss = 0.28180503845214844, train/logprobs = tensor([[-0.8696, -3.4870],
        [-1.7863, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19195863604545593
Epoch 0, Step 1050: train/loss = 0.5101706981658936, train/raw-loss = 0.46974506974220276, train/logprobs = tensor([[-0.5520, -1.2548],
        [-1.2345, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134752094745636
Epoch 0, Step 1051: train/loss = 0.6381763815879822, train/raw-loss = 0.6031578779220581, train/logprobs = tensor([[-0.6590, -1.3028],
        [-0.6412, -0.7873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672843247652054
Epoch 0, Step 1052: train/loss = 0.3704430162906647, train/raw-loss = 0.3276982307434082, train/logprobs = tensor([[-0.6147, -3.6520],
        [-1.1047, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14248260855674744
Epoch 0, Step 1053: train/loss = 0.2916559875011444, train/raw-loss = 0.24706768989562988, train/logprobs = tensor([[-0.6879, -4.4270],
        [-1.6134, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1486276090145111
Epoch 0, Step 1054: train/loss = 0.4711543917655945, train/raw-loss = 0.4320926368236542, train/logprobs = tensor([[-0.8653, -2.0381],
        [-1.2214, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13020586967468262
Epoch 0, Step 1055: train/loss = 0.5108311772346497, train/raw-loss = 0.461162269115448, train/logprobs = tensor([[-0.8954, -3.4064],
        [-1.7170, -2.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16556303203105927
Epoch 0, Step 1056: train/loss = 0.4407155513763428, train/raw-loss = 0.39816009998321533, train/logprobs = tensor([[-0.7378, -3.1878],
        [-1.0207, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141851544380188
Epoch 0, Step 1057: train/loss = 0.36610645055770874, train/raw-loss = 0.322966605424881, train/logprobs = tensor([[-0.5853, -5.4254],
        [-1.3813, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14379934966564178
Epoch 0, Step 1058: train/loss = 0.32560843229293823, train/raw-loss = 0.2728530764579773, train/logprobs = tensor([[-0.6070, -3.6217],
        [-1.5667, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17585119605064392
Epoch 0, Step 1059: train/loss = 0.5943741798400879, train/raw-loss = 0.5453782081604004, train/logprobs = tensor([[-0.6920, -1.6268],
        [-0.9377, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16331981122493744
Epoch 0, Step 1060: train/loss = 0.5938418507575989, train/raw-loss = 0.5467416048049927, train/logprobs = tensor([[-0.6616, -2.0058],
        [-1.2210, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15700066089630127
Epoch 0, Step 1061: train/loss = 0.49080073833465576, train/raw-loss = 0.4378218650817871, train/logprobs = tensor([[-0.8015, -3.9160],
        [-1.3495, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17659616470336914
Epoch 0, Step 1062: train/loss = 0.4262271523475647, train/raw-loss = 0.3721410632133484, train/logprobs = tensor([[-0.9188, -2.9571],
        [-1.6501, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18028703331947327
Epoch 0, Step 1063: train/loss = 0.6005370616912842, train/raw-loss = 0.5579925775527954, train/logprobs = tensor([[-1.2425, -2.4640],
        [-0.9371, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14181481301784515
Epoch 0, Step 1064: train/loss = 0.3789422810077667, train/raw-loss = 0.32974866032600403, train/logprobs = tensor([[-0.7243, -5.1196],
        [-1.3545, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1639786809682846
Epoch 0, Step 1065: train/loss = 0.5049240589141846, train/raw-loss = 0.4584141969680786, train/logprobs = tensor([[-0.6473, -2.2622],
        [-1.1436, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15503282845020294
Epoch 0, Step 1066: train/loss = 0.4428821802139282, train/raw-loss = 0.40030938386917114, train/logprobs = tensor([[-1.4281, -3.8455],
        [-1.4671, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190936088562012
Epoch 0, Step 1067: train/loss = 0.1969936490058899, train/raw-loss = 0.14718025922775269, train/logprobs = tensor([[-0.8912, -7.9510],
        [-2.1792, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16604463756084442
Epoch 0, Step 1068: train/loss = 0.404056578874588, train/raw-loss = 0.35561278462409973, train/logprobs = tensor([[-0.6307, -3.0062],
        [-1.3060, -0.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16147927939891815
Epoch 0, Step 1069: train/loss = 0.5628093481063843, train/raw-loss = 0.5173659324645996, train/logprobs = tensor([[-1.0978, -5.1038],
        [-1.1927, -1.0230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151478111743927
Epoch 0, Step 1070: train/loss = 0.34412047266960144, train/raw-loss = 0.28811460733413696, train/logprobs = tensor([[-0.7275, -4.0398],
        [-1.5298, -1.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866862177848816
Epoch 0, Step 1071: train/loss = 0.2242063283920288, train/raw-loss = 0.1700608730316162, train/logprobs = tensor([[-0.7734, -6.3782],
        [-1.9596, -1.4327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1804848313331604
Epoch 0, Step 1072: train/loss = 0.2285434603691101, train/raw-loss = 0.17807942628860474, train/logprobs = tensor([[-0.7383, -6.6957],
        [-1.5742, -1.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16821350157260895
Epoch 0, Step 1073: train/loss = 0.3909866213798523, train/raw-loss = 0.3377149999141693, train/logprobs = tensor([[-0.8125, -3.4383],
        [-1.5209, -1.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1775720715522766
Epoch 0, Step 1074: train/loss = 0.4176703095436096, train/raw-loss = 0.3722001314163208, train/logprobs = tensor([[-0.5758, -5.1955],
        [-1.1657, -1.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15156732499599457
Epoch 0, Step 1075: train/loss = 0.42521724104881287, train/raw-loss = 0.3854074478149414, train/logprobs = tensor([[-0.4971, -3.1179],
        [-0.7649, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13269929587841034
Epoch 0, Step 1076: train/loss = 0.40910059213638306, train/raw-loss = 0.34823474287986755, train/logprobs = tensor([[-0.5918, -3.9304],
        [-1.3874, -1.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20288607478141785
Epoch 0, Step 1077: train/loss = 0.42429664731025696, train/raw-loss = 0.379237562417984, train/logprobs = tensor([[-0.5185, -3.4555],
        [-1.2826, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15019699931144714
Epoch 0, Step 1078: train/loss = 0.5032030344009399, train/raw-loss = 0.45670610666275024, train/logprobs = tensor([[-1.0320, -3.0091],
        [-1.3201, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15498974919319153
Epoch 0, Step 1079: train/loss = 0.28942108154296875, train/raw-loss = 0.23539412021636963, train/logprobs = tensor([[-0.5908, -6.9600],
        [-1.3584, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18008989095687866
Epoch 0, Step 1080: train/loss = 0.49570879340171814, train/raw-loss = 0.4524819254875183, train/logprobs = tensor([[-0.7306, -2.5314],
        [-1.3355, -1.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14408966898918152
Epoch 0, Step 1081: train/loss = 0.2794906497001648, train/raw-loss = 0.23203077912330627, train/logprobs = tensor([[-1.2757, -5.1019],
        [-1.6716, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581995189189911
Epoch 0, Step 1082: train/loss = 0.6196249723434448, train/raw-loss = 0.5802766680717468, train/logprobs = tensor([[-0.7063, -1.1494],
        [-1.1958, -1.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13116109371185303
Epoch 0, Step 1083: train/loss = 0.503707766532898, train/raw-loss = 0.44362011551856995, train/logprobs = tensor([[-0.9567, -2.9901],
        [-1.6455, -1.4929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20029224455356598
Epoch 0, Step 1084: train/loss = 0.4585738182067871, train/raw-loss = 0.4145640730857849, train/logprobs = tensor([[-0.5397, -2.9712],
        [-1.0294, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14669916033744812
Epoch 0, Step 1085: train/loss = 0.5167891383171082, train/raw-loss = 0.47799405455589294, train/logprobs = tensor([[-0.6130, -2.0063],
        [-1.0947, -0.7194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12931685149669647
Epoch 0, Step 1086: train/loss = 0.39353567361831665, train/raw-loss = 0.3429286479949951, train/logprobs = tensor([[-0.6917, -5.0006],
        [-1.4471, -1.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16869011521339417
Epoch 0, Step 1087: train/loss = 0.37434902787208557, train/raw-loss = 0.3361639082431793, train/logprobs = tensor([[-0.6843, -5.6008],
        [-0.8454, -0.7164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272837072610855
Epoch 0, Step 1088: train/loss = 0.48967280983924866, train/raw-loss = 0.43913665413856506, train/logprobs = tensor([[-1.2436, -2.8105],
        [-1.4475, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16845373809337616
Epoch 0, Step 1089: train/loss = 0.4914574921131134, train/raw-loss = 0.45443224906921387, train/logprobs = tensor([[-0.7154, -2.3222],
        [-0.9225, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12341739237308502
Epoch 0, Step 1090: train/loss = 0.3465919494628906, train/raw-loss = 0.2982262969017029, train/logprobs = tensor([[-0.6218, -3.7139],
        [-1.5617, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612188220024109
Epoch 0, Step 1091: train/loss = 0.33714351058006287, train/raw-loss = 0.29465746879577637, train/logprobs = tensor([[-0.5624, -3.4102],
        [-1.3477, -1.4133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14162014424800873
Epoch 0, Step 1092: train/loss = 0.3568035960197449, train/raw-loss = 0.30366218090057373, train/logprobs = tensor([[-0.9001, -3.4144],
        [-1.5238, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771380454301834
Epoch 0, Step 1093: train/loss = 0.47564539313316345, train/raw-loss = 0.42326557636260986, train/logprobs = tensor([[-0.7898, -3.8799],
        [-1.4973, -1.1661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17459942400455475
Epoch 0, Step 1094: train/loss = 0.3697029650211334, train/raw-loss = 0.3239125609397888, train/logprobs = tensor([[-0.5845, -2.3699],
        [-1.2530, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526346206665039
Epoch 0, Step 1095: train/loss = 0.5558773279190063, train/raw-loss = 0.5026673078536987, train/logprobs = tensor([[-1.0160, -2.9059],
        [-1.2191, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17736665904521942
Epoch 0, Step 1096: train/loss = 0.33962565660476685, train/raw-loss = 0.2970499098300934, train/logprobs = tensor([[-0.7758, -4.6295],
        [-1.2019, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14191921055316925
Epoch 0, Step 1097: train/loss = 0.306400328874588, train/raw-loss = 0.24809123575687408, train/logprobs = tensor([[-0.9106, -4.8636],
        [-1.5852, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19436374306678772
Epoch 0, Step 1098: train/loss = 0.35857388377189636, train/raw-loss = 0.3091227114200592, train/logprobs = tensor([[-0.4381, -6.6173],
        [-1.3619, -0.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648373007774353
Epoch 0, Step 1099: train/loss = 0.48330676555633545, train/raw-loss = 0.4298303723335266, train/logprobs = tensor([[-0.6481, -1.6690],
        [-1.5245, -0.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17825466394424438
Epoch 0, Step 1100: train/loss = 0.40282586216926575, train/raw-loss = 0.35487228631973267, train/logprobs = tensor([[-0.6837, -3.1585],
        [-1.2911, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1598452776670456
Epoch 0, Step 1101: train/loss = 0.308596134185791, train/raw-loss = 0.26128360629081726, train/logprobs = tensor([[-0.7024, -6.9082],
        [-1.7848, -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15770845115184784
Epoch 0, Step 1102: train/loss = 0.36653459072113037, train/raw-loss = 0.3238304555416107, train/logprobs = tensor([[-0.9686, -4.8463],
        [-1.1682, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423470675945282
Epoch 0, Step 1103: train/loss = 0.3096919655799866, train/raw-loss = 0.25858932733535767, train/logprobs = tensor([[-0.9560, -5.6881],
        [-1.6015, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703420877456665
Epoch 0, Step 1104: train/loss = 0.5905264019966125, train/raw-loss = 0.5474717617034912, train/logprobs = tensor([[-0.8575, -4.1054],
        [-0.9880, -0.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14351552724838257
Epoch 0, Step 1105: train/loss = 0.4029254913330078, train/raw-loss = 0.3626655340194702, train/logprobs = tensor([[-0.7914, -4.0124],
        [-0.8986, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13419987261295319
Epoch 0, Step 1106: train/loss = 0.3828764855861664, train/raw-loss = 0.32685357332229614, train/logprobs = tensor([[-1.2411, -6.0221],
        [-1.5390, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18674305081367493
Epoch 0, Step 1107: train/loss = 0.3924817740917206, train/raw-loss = 0.3497256338596344, train/logprobs = tensor([[-0.6846, -3.9331],
        [-1.1156, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14252054691314697
Epoch 0, Step 1108: train/loss = 0.41467174887657166, train/raw-loss = 0.37776029109954834, train/logprobs = tensor([[-0.5876, -2.8419],
        [-1.0655, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12303807586431503
Epoch 0, Step 1109: train/loss = 0.4194338619709015, train/raw-loss = 0.37421345710754395, train/logprobs = tensor([[-0.7468, -2.8208],
        [-1.2286, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15073463320732117
Epoch 0, Step 1110: train/loss = 0.5201117992401123, train/raw-loss = 0.4774460792541504, train/logprobs = tensor([[-0.6529, -3.6090],
        [-0.9100, -1.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422191858291626
Epoch 0, Step 1111: train/loss = 0.3893824815750122, train/raw-loss = 0.34655043482780457, train/logprobs = tensor([[-0.7375, -4.2198],
        [-0.9801, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427735537290573
Epoch 0, Step 1112: train/loss = 0.5792328119277954, train/raw-loss = 0.5218885540962219, train/logprobs = tensor([[-1.5390, -5.1148],
        [-1.4117, -1.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1911475509405136
Epoch 0, Step 1113: train/loss = 0.546564519405365, train/raw-loss = 0.5011618137359619, train/logprobs = tensor([[-0.7649, -1.9482],
        [-1.1155, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15134236216545105
Epoch 0, Step 1114: train/loss = 0.4093523621559143, train/raw-loss = 0.3660506308078766, train/logprobs = tensor([[-0.8157, -2.6086],
        [-1.3290, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14433902502059937
Epoch 0, Step 1115: train/loss = 0.5114244818687439, train/raw-loss = 0.4664822220802307, train/logprobs = tensor([[-0.3949, -1.6793],
        [-0.8351, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.149807408452034
Epoch 0, Step 1116: train/loss = 0.4824425280094147, train/raw-loss = 0.4409782290458679, train/logprobs = tensor([[-0.5544, -2.3221],
        [-0.9121, -0.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13821443915367126
Epoch 0, Step 1117: train/loss = 0.5494962930679321, train/raw-loss = 0.49586212635040283, train/logprobs = tensor([[-0.6841, -2.6799],
        [-1.7282, -1.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17878039181232452
Epoch 0, Step 1118: train/loss = 0.6153215169906616, train/raw-loss = 0.5806832909584045, train/logprobs = tensor([[-0.3647, -2.2364],
        [-0.5339, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11546078324317932
Epoch 0, Step 1119: train/loss = 0.38874921202659607, train/raw-loss = 0.33779212832450867, train/logprobs = tensor([[-0.5183, -4.5808],
        [-1.2615, -1.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16985687613487244
Epoch 0, Step 1120: train/loss = 0.24136582016944885, train/raw-loss = 0.18279606103897095, train/logprobs = tensor([[-1.0422, -4.1142],
        [-2.0707, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19523248076438904
Epoch 0, Step 1121: train/loss = 0.35816511511802673, train/raw-loss = 0.3019176125526428, train/logprobs = tensor([[-0.8272, -3.6865],
        [-1.9812, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749168515205383
Epoch 0, Step 1122: train/loss = 0.5724692344665527, train/raw-loss = 0.5229130387306213, train/logprobs = tensor([[-0.6196, -3.7868],
        [-1.2479, -0.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1651873141527176
Epoch 0, Step 1123: train/loss = 0.2573031187057495, train/raw-loss = 0.20690889656543732, train/logprobs = tensor([[-0.7442, -7.5671],
        [-1.6975, -1.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16798077523708344
Epoch 0, Step 1124: train/loss = 0.3776779770851135, train/raw-loss = 0.32994723320007324, train/logprobs = tensor([[-0.9076, -7.2373],
        [-1.5140, -1.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591024547815323
Epoch 0, Step 1125: train/loss = 0.4052475094795227, train/raw-loss = 0.3597202003002167, train/logprobs = tensor([[-0.6263, -2.5715],
        [-1.2089, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15175771713256836
Epoch 0, Step 1126: train/loss = 0.5119728446006775, train/raw-loss = 0.46237683296203613, train/logprobs = tensor([[-0.9705, -4.3037],
        [-1.2557, -1.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16532008349895477
Epoch 0, Step 1127: train/loss = 0.4065137505531311, train/raw-loss = 0.3616097867488861, train/logprobs = tensor([[-0.4543, -3.2962],
        [-0.6845, -0.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14967982470989227
Epoch 0, Step 1128: train/loss = 0.5984089374542236, train/raw-loss = 0.5483890771865845, train/logprobs = tensor([[-1.5051, -2.4137],
        [-1.1334, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16673287749290466
Epoch 0, Step 1129: train/loss = 0.30539265275001526, train/raw-loss = 0.24674105644226074, train/logprobs = tensor([[-0.8099, -3.5866],
        [-1.7628, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.195505291223526
Epoch 0, Step 1130: train/loss = 0.4984372854232788, train/raw-loss = 0.4653095602989197, train/logprobs = tensor([[-0.3700, -1.8867],
        [-0.8991, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1104256808757782
Epoch 0, Step 1131: train/loss = 0.384416401386261, train/raw-loss = 0.3470101058483124, train/logprobs = tensor([[-0.4687, -3.4032],
        [-0.9374, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468767166137695
Epoch 0, Step 1132: train/loss = 0.5691437721252441, train/raw-loss = 0.5159137845039368, train/logprobs = tensor([[-0.9581, -3.2398],
        [-0.9579, -0.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17743323743343353
Epoch 0, Step 1133: train/loss = 0.6338393688201904, train/raw-loss = 0.5900124311447144, train/logprobs = tensor([[-0.7318, -0.9284],
        [-0.9484, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14608976244926453
Epoch 0, Step 1134: train/loss = 0.40296486020088196, train/raw-loss = 0.34979361295700073, train/logprobs = tensor([[-1.3269, -6.7577],
        [-1.6234, -1.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17723749577999115
Epoch 0, Step 1135: train/loss = 0.3605669438838959, train/raw-loss = 0.31195786595344543, train/logprobs = tensor([[-0.6282, -4.0387],
        [-1.1368, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16203024983406067
Epoch 0, Step 1136: train/loss = 0.38915061950683594, train/raw-loss = 0.3375840187072754, train/logprobs = tensor([[-0.8113, -4.6540],
        [-1.5921, -1.2515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17188864946365356
Epoch 0, Step 1137: train/loss = 0.38909679651260376, train/raw-loss = 0.33870580792427063, train/logprobs = tensor([[-0.9919, -7.4435],
        [-1.3364, -1.7817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16796988248825073
Epoch 0, Step 1138: train/loss = 0.5331248641014099, train/raw-loss = 0.4920824468135834, train/logprobs = tensor([[-0.5812, -1.7993],
        [-0.8857, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13680803775787354
Epoch 0, Step 1139: train/loss = 0.36433571577072144, train/raw-loss = 0.2966904044151306, train/logprobs = tensor([[-0.5984, -3.0458],
        [-1.8280, -1.1739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22548438608646393
Epoch 0, Step 1140: train/loss = 0.39203333854675293, train/raw-loss = 0.3472845256328583, train/logprobs = tensor([[-0.6335, -5.5660],
        [-1.2180, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14916279911994934
Epoch 0, Step 1141: train/loss = 0.41533297300338745, train/raw-loss = 0.3732162117958069, train/logprobs = tensor([[-0.6085, -3.8553],
        [-1.1046, -1.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14038912951946259
Epoch 0, Step 1142: train/loss = 0.5426575541496277, train/raw-loss = 0.5008822083473206, train/logprobs = tensor([[-0.7112, -1.9945],
        [-1.6054, -1.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13925109803676605
Epoch 0, Step 1143: train/loss = 0.5348587036132812, train/raw-loss = 0.48259931802749634, train/logprobs = tensor([[-0.6994, -2.0445],
        [-1.1619, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17419791221618652
Epoch 0, Step 1144: train/loss = 0.45134925842285156, train/raw-loss = 0.4107130169868469, train/logprobs = tensor([[-0.5929, -3.6820],
        [-0.6445, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354542225599289
Epoch 0, Step 1145: train/loss = 0.29257676005363464, train/raw-loss = 0.2515636682510376, train/logprobs = tensor([[-0.5073, -5.8905],
        [-0.8466, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13671033084392548
Epoch 0, Step 1146: train/loss = 0.21709886193275452, train/raw-loss = 0.15909332036972046, train/logprobs = tensor([[ -0.6741, -10.3421],
        [ -1.5277,  -1.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1933518499135971
Epoch 0, Step 1147: train/loss = 0.3347204327583313, train/raw-loss = 0.2712588906288147, train/logprobs = tensor([[-1.0957, -4.1642],
        [-1.8035, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21153844892978668
Epoch 0, Step 1148: train/loss = 0.5336934328079224, train/raw-loss = 0.4812462329864502, train/logprobs = tensor([[-0.8004, -1.7841],
        [-1.3991, -1.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17482402920722961
Epoch 0, Step 1149: train/loss = 0.3538685441017151, train/raw-loss = 0.30134809017181396, train/logprobs = tensor([[-0.8739, -4.7833],
        [-1.6916, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1750682294368744
Epoch 0, Step 1150: train/loss = 0.5798308849334717, train/raw-loss = 0.5304948687553406, train/logprobs = tensor([[-1.1681, -4.1139],
        [-0.6291, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.164453387260437
Epoch 0, Step 1151: train/loss = 0.3201923370361328, train/raw-loss = 0.26671481132507324, train/logprobs = tensor([[-1.0129, -6.9407],
        [-1.9534, -1.2722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17825831472873688
Epoch 0, Step 1152: train/loss = 0.1903723180294037, train/raw-loss = 0.1313643753528595, train/logprobs = tensor([[-0.7715, -7.0642],
        [-2.0199, -1.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19669313728809357
Epoch 0, Step 1153: train/loss = 0.4391031265258789, train/raw-loss = 0.3924221396446228, train/logprobs = tensor([[-0.4723, -2.1727],
        [-0.9586, -0.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15560322999954224
Epoch 0, Step 1154: train/loss = 0.3879767060279846, train/raw-loss = 0.3394911289215088, train/logprobs = tensor([[-0.8041, -3.5638],
        [-1.4907, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16161873936653137
Epoch 0, Step 1155: train/loss = 0.37400415539741516, train/raw-loss = 0.3337213099002838, train/logprobs = tensor([[-0.6471, -3.1426],
        [-1.3656, -1.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13427624106407166
Epoch 0, Step 1156: train/loss = 0.5103668570518494, train/raw-loss = 0.4585382342338562, train/logprobs = tensor([[-0.7639, -2.0254],
        [-1.3678, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727619618177414
Epoch 0, Step 1157: train/loss = 0.4034837484359741, train/raw-loss = 0.35164588689804077, train/logprobs = tensor([[-0.9307, -6.3631],
        [-1.2538, -2.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17279288172721863
Epoch 0, Step 1158: train/loss = 0.2522818148136139, train/raw-loss = 0.19546231627464294, train/logprobs = tensor([[-0.7496, -5.4989],
        [-1.5295, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18939834833145142
Epoch 0, Step 1159: train/loss = 0.3806752562522888, train/raw-loss = 0.33435294032096863, train/logprobs = tensor([[-0.6053, -3.6404],
        [-0.8156, -1.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15440784394741058
Epoch 0, Step 1160: train/loss = 0.5354475975036621, train/raw-loss = 0.4912946820259094, train/logprobs = tensor([[-0.7549, -3.7914],
        [-1.0690, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471761018037796
Epoch 0, Step 1161: train/loss = 0.4813914895057678, train/raw-loss = 0.4283234477043152, train/logprobs = tensor([[-0.6938, -2.1488],
        [-1.1958, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17689351737499237
Epoch 0, Step 1162: train/loss = 0.3435332775115967, train/raw-loss = 0.28825968503952026, train/logprobs = tensor([[-0.8901, -5.3573],
        [-1.7000, -1.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1842452734708786
Epoch 0, Step 1163: train/loss = 0.2860513925552368, train/raw-loss = 0.2331053614616394, train/logprobs = tensor([[-0.6621, -6.0329],
        [-1.2621, -1.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17648673057556152
Epoch 0, Step 1164: train/loss = 0.36744773387908936, train/raw-loss = 0.3154570162296295, train/logprobs = tensor([[-0.6623, -6.7109],
        [-1.3786, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17330242693424225
Epoch 0, Step 1165: train/loss = 0.38094478845596313, train/raw-loss = 0.337230384349823, train/logprobs = tensor([[-0.8286, -4.2475],
        [-1.2219, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14571459591388702
Epoch 0, Step 1166: train/loss = 0.32838788628578186, train/raw-loss = 0.26791346073150635, train/logprobs = tensor([[-0.7281, -3.4163],
        [-1.9089, -0.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2015814632177353
Epoch 0, Step 1167: train/loss = 0.4683196544647217, train/raw-loss = 0.4170653820037842, train/logprobs = tensor([[-0.6225, -4.9076],
        [-1.1593, -1.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17084747552871704
Epoch 0, Step 1168: train/loss = 0.5090774297714233, train/raw-loss = 0.4625331163406372, train/logprobs = tensor([[-0.9058, -3.0032],
        [-1.3263, -1.4460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15514767169952393
Epoch 0, Step 1169: train/loss = 0.7048184275627136, train/raw-loss = 0.6486213803291321, train/logprobs = tensor([[-2.1697, -5.0868],
        [-1.3670, -1.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1873236894607544
Epoch 0, Step 1170: train/loss = 0.29975783824920654, train/raw-loss = 0.2555886507034302, train/logprobs = tensor([[-0.6681, -5.1616],
        [-1.3043, -1.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472305804491043
Epoch 0, Step 1171: train/loss = 0.5685960650444031, train/raw-loss = 0.5220379829406738, train/logprobs = tensor([[-0.8763, -2.9923],
        [-1.3785, -0.8793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15519367158412933
Epoch 0, Step 1172: train/loss = 0.2942647933959961, train/raw-loss = 0.25072795152664185, train/logprobs = tensor([[-0.6853, -7.2493],
        [-1.3355, -2.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14512291550636292
Epoch 0, Step 1173: train/loss = 0.2501026690006256, train/raw-loss = 0.20192065834999084, train/logprobs = tensor([[-0.8658, -5.8830],
        [-1.4900, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16060663759708405
Epoch 0, Step 1174: train/loss = 0.5177002549171448, train/raw-loss = 0.48174336552619934, train/logprobs = tensor([[-0.6673, -2.0879],
        [-1.1751, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11985613405704498
Epoch 0, Step 1175: train/loss = 0.33073222637176514, train/raw-loss = 0.27563148736953735, train/logprobs = tensor([[-0.9094, -5.3726],
        [-1.5742, -1.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18366912007331848
Epoch 0, Step 1176: train/loss = 0.6250651478767395, train/raw-loss = 0.5878282785415649, train/logprobs = tensor([[-0.7352, -1.9841],
        [-1.0463, -1.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12412286549806595
Epoch 0, Step 1177: train/loss = 0.4845760464668274, train/raw-loss = 0.43388205766677856, train/logprobs = tensor([[-0.6982, -3.1774],
        [-1.2848, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897983849048615
Epoch 0, Step 1178: train/loss = 0.6806954145431519, train/raw-loss = 0.6340290307998657, train/logprobs = tensor([[-1.8631, -3.6584],
        [-1.0320, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15555456280708313
Epoch 0, Step 1179: train/loss = 0.4684963822364807, train/raw-loss = 0.4164063334465027, train/logprobs = tensor([[-1.0909, -2.1494],
        [-1.4479, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363341152668
Epoch 0, Step 1180: train/loss = 0.5845881104469299, train/raw-loss = 0.5348770022392273, train/logprobs = tensor([[-0.8766, -1.2266],
        [-1.3740, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16570360958576202
Epoch 0, Step 1181: train/loss = 0.36000314354896545, train/raw-loss = 0.3197552561759949, train/logprobs = tensor([[-1.0195, -4.4712],
        [-1.2295, -1.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13415971398353577
Epoch 0, Step 1182: train/loss = 0.5390625, train/raw-loss = 0.4870946705341339, train/logprobs = tensor([[-0.9790, -5.0469],
        [-1.6210, -1.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17322604358196259
Epoch 0, Step 1183: train/loss = 0.5819928646087646, train/raw-loss = 0.5409094095230103, train/logprobs = tensor([[-0.6699, -2.0679],
        [-0.7815, -0.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13694480061531067
Epoch 0, Step 1184: train/loss = 0.5649539232254028, train/raw-loss = 0.5086559653282166, train/logprobs = tensor([[-0.9104, -2.5058],
        [-1.4021, -0.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1876598596572876
Epoch 0, Step 1185: train/loss = 0.40620723366737366, train/raw-loss = 0.3582620322704315, train/logprobs = tensor([[-0.6860, -3.5875],
        [-1.7558, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15981724858283997
Epoch 0, Step 1186: train/loss = 0.5254798531532288, train/raw-loss = 0.4824504852294922, train/logprobs = tensor([[-0.6362, -4.2523],
        [-1.0226, -1.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14343130588531494
Epoch 0, Step 1187: train/loss = 0.377900630235672, train/raw-loss = 0.32459455728530884, train/logprobs = tensor([[-1.2163, -6.8849],
        [-1.1854, -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1776868849992752
Epoch 0, Step 1188: train/loss = 0.34067147970199585, train/raw-loss = 0.2896963357925415, train/logprobs = tensor([[-0.8011, -4.6661],
        [-1.6651, -1.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16991716623306274
Epoch 0, Step 1189: train/loss = 0.35543298721313477, train/raw-loss = 0.30151331424713135, train/logprobs = tensor([[-0.6774, -2.9932],
        [-1.5350, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17973223328590393
Epoch 0, Step 1190: train/loss = 0.4310542941093445, train/raw-loss = 0.3773711323738098, train/logprobs = tensor([[-0.7066, -2.8238],
        [-1.3872, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1789439618587494
Epoch 0, Step 1191: train/loss = 0.3624267578125, train/raw-loss = 0.3199208378791809, train/logprobs = tensor([[-0.8153, -5.7929],
        [-1.3336, -1.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14168642461299896
Epoch 0, Step 1192: train/loss = 0.24753926694393158, train/raw-loss = 0.1963673084974289, train/logprobs = tensor([[-0.6628, -8.3852],
        [-1.3739, -1.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1705731451511383
Epoch 0, Step 1193: train/loss = 0.4962489902973175, train/raw-loss = 0.43740010261535645, train/logprobs = tensor([[-0.7804, -1.8963],
        [-1.8537, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19616302847862244
Epoch 0, Step 1194: train/loss = 0.5986539125442505, train/raw-loss = 0.5516347289085388, train/logprobs = tensor([[-1.2962, -3.6641],
        [-1.0397, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15673035383224487
Epoch 0, Step 1195: train/loss = 0.5434446334838867, train/raw-loss = 0.49519428610801697, train/logprobs = tensor([[-1.0435, -4.5071],
        [-0.8733, -1.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16083449125289917
Epoch 0, Step 1196: train/loss = 0.5326718091964722, train/raw-loss = 0.48351866006851196, train/logprobs = tensor([[-1.6532, -4.0195],
        [-1.3904, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638438105583191
Epoch 0, Step 1197: train/loss = 0.19005045294761658, train/raw-loss = 0.1300073266029358, train/logprobs = tensor([[-0.7471, -6.6772],
        [-2.1353, -1.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2001436948776245
Epoch 0, Step 1198: train/loss = 0.4026005268096924, train/raw-loss = 0.35064440965652466, train/logprobs = tensor([[-0.9832, -4.2606],
        [-1.6464, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731870472431183
Epoch 0, Step 1199: train/loss = 0.6256895661354065, train/raw-loss = 0.5867513418197632, train/logprobs = tensor([[-0.4991, -0.7425],
        [-0.7019, -0.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12979412078857422
Epoch 0, Step 1200: train/loss = 0.45309317111968994, train/raw-loss = 0.40710264444351196, train/logprobs = tensor([[-0.8101, -3.3861],
        [-1.1404, -1.2842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1533016413450241
Epoch 0, Step 1201: train/loss = 0.548829197883606, train/raw-loss = 0.5039761066436768, train/logprobs = tensor([[-0.7561, -2.2797],
        [-1.0192, -0.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14951010048389435
Epoch 0, Step 1202: train/loss = 0.25602737069129944, train/raw-loss = 0.19713528454303741, train/logprobs = tensor([[-0.9049, -9.0491],
        [-1.5545, -1.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19630688428878784
Epoch 0, Step 1203: train/loss = 0.3128474950790405, train/raw-loss = 0.2635178565979004, train/logprobs = tensor([[-0.4585, -5.1219],
        [-1.4377, -2.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16443213820457458
Epoch 0, Step 1204: train/loss = 0.4305684268474579, train/raw-loss = 0.38777193427085876, train/logprobs = tensor([[-1.0301, -2.3082],
        [-1.5286, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1426548957824707
Epoch 0, Step 1205: train/loss = 0.5221315026283264, train/raw-loss = 0.470294326543808, train/logprobs = tensor([[-0.9401, -2.8505],
        [-1.0381, -1.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17279046773910522
Epoch 0, Step 1206: train/loss = 0.4242858588695526, train/raw-loss = 0.3704269826412201, train/logprobs = tensor([[-0.9505, -3.9086],
        [-1.4229, -1.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1795295625925064
Epoch 0, Step 1207: train/loss = 0.29600971937179565, train/raw-loss = 0.24430078268051147, train/logprobs = tensor([[-0.7802, -5.0047],
        [-1.4062, -1.0456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17236314713954926
Epoch 0, Step 1208: train/loss = 0.2583850920200348, train/raw-loss = 0.20186741650104523, train/logprobs = tensor([[-0.9167, -5.1283],
        [-2.0748, -0.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18839220702648163
Epoch 0, Step 1209: train/loss = 0.21129043400287628, train/raw-loss = 0.15327095985412598, train/logprobs = tensor([[-0.9128, -3.6731],
        [-2.4524, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19339823722839355
Epoch 0, Step 1210: train/loss = 0.35802724957466125, train/raw-loss = 0.2986888885498047, train/logprobs = tensor([[-0.6371, -3.3542],
        [-1.4452, -0.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19779454171657562
Epoch 0, Step 1211: train/loss = 0.2651969790458679, train/raw-loss = 0.21621447801589966, train/logprobs = tensor([[-0.7085, -5.1250],
        [-1.3948, -1.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16327492892742157
Epoch 0, Step 1212: train/loss = 0.5097153186798096, train/raw-loss = 0.4696000814437866, train/logprobs = tensor([[-0.8485, -4.6105],
        [-1.1723, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13371729850769043
Epoch 0, Step 1213: train/loss = 0.3802565634250641, train/raw-loss = 0.3319603204727173, train/logprobs = tensor([[-0.8956, -4.9358],
        [-1.2292, -1.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1609874963760376
Epoch 0, Step 1214: train/loss = 0.45667901635169983, train/raw-loss = 0.4046153724193573, train/logprobs = tensor([[-0.8884, -4.4042],
        [-0.9905, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17354540526866913
Epoch 0, Step 1215: train/loss = 0.39766573905944824, train/raw-loss = 0.3412964344024658, train/logprobs = tensor([[-0.7875, -5.8823],
        [-1.5830, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18789765238761902
Epoch 0, Step 1216: train/loss = 0.4718739986419678, train/raw-loss = 0.42365968227386475, train/logprobs = tensor([[-0.6680, -3.6592],
        [-1.3085, -1.4003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1607143133878708
Epoch 0, Step 1217: train/loss = 0.43660542368888855, train/raw-loss = 0.3919760584831238, train/logprobs = tensor([[-1.2717, -6.9942],
        [-1.8147, -1.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14876437187194824
Epoch 0, Step 1218: train/loss = 0.4146946966648102, train/raw-loss = 0.3621481955051422, train/logprobs = tensor([[-0.7689, -4.1770],
        [-1.4057, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17515508830547333
Epoch 0, Step 1219: train/loss = 0.3234633207321167, train/raw-loss = 0.2549613118171692, train/logprobs = tensor([[-1.0368, -7.4421],
        [-1.8383, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22833998501300812
Epoch 0, Step 1220: train/loss = 0.6946368217468262, train/raw-loss = 0.6521196961402893, train/logprobs = tensor([[-0.7867, -0.7900],
        [-0.8757, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417238563299179
Epoch 0, Step 1221: train/loss = 0.3819069266319275, train/raw-loss = 0.3452109694480896, train/logprobs = tensor([[-0.5508, -3.7819],
        [-0.9422, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12231980264186859
Epoch 0, Step 1222: train/loss = 0.4595229923725128, train/raw-loss = 0.4070936441421509, train/logprobs = tensor([[-0.9641, -5.5693],
        [-2.2378, -1.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17476461827754974
Epoch 0, Step 1223: train/loss = 0.32060128450393677, train/raw-loss = 0.2792952060699463, train/logprobs = tensor([[-0.6813, -3.9262],
        [-1.3250, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1376868188381195
Epoch 0, Step 1224: train/loss = 0.46087414026260376, train/raw-loss = 0.4235263466835022, train/logprobs = tensor([[-0.3828, -2.9164],
        [-0.7165, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12449273467063904
Epoch 0, Step 1225: train/loss = 0.4054601788520813, train/raw-loss = 0.3646322190761566, train/logprobs = tensor([[-0.6480, -3.1755],
        [-0.9186, -0.7198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360931545495987
Epoch 0, Step 1226: train/loss = 0.4769217371940613, train/raw-loss = 0.4303880035877228, train/logprobs = tensor([[-0.8398, -3.6513],
        [-0.9250, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15511247515678406
Epoch 0, Step 1227: train/loss = 0.5238047242164612, train/raw-loss = 0.47629666328430176, train/logprobs = tensor([[-1.2317, -2.6436],
        [-1.2476, -0.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583603024482727
Epoch 0, Step 1228: train/loss = 0.5324510335922241, train/raw-loss = 0.48195159435272217, train/logprobs = tensor([[-0.7260, -1.8859],
        [-1.0077, -0.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16833144426345825
Epoch 0, Step 1229: train/loss = 0.3734154999256134, train/raw-loss = 0.33136406540870667, train/logprobs = tensor([[-0.5787, -6.2890],
        [-0.9566, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14017146825790405
Epoch 0, Step 1230: train/loss = 0.61290043592453, train/raw-loss = 0.5598704218864441, train/logprobs = tensor([[-1.6236, -2.2631],
        [-1.9522, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17676661908626556
Epoch 0, Step 1231: train/loss = 0.4587831497192383, train/raw-loss = 0.40514492988586426, train/logprobs = tensor([[-1.0776, -2.3289],
        [-1.5356, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17879407107830048
Epoch 0, Step 1232: train/loss = 0.9733630418777466, train/raw-loss = 0.9344027042388916, train/logprobs = tensor([[-3.8665, -6.9005],
        [-2.1216, -2.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12986749410629272
Epoch 0, Step 1233: train/loss = 0.5589901804924011, train/raw-loss = 0.5092220306396484, train/logprobs = tensor([[-0.5949, -1.6917],
        [-0.8388, -0.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16589388251304626
Epoch 0, Step 1234: train/loss = 0.3993570804595947, train/raw-loss = 0.35064658522605896, train/logprobs = tensor([[-0.9118, -3.5632],
        [-1.5012, -1.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16236838698387146
Epoch 0, Step 1235: train/loss = 0.7609531283378601, train/raw-loss = 0.7165502309799194, train/logprobs = tensor([[-1.7087, -5.8793],
        [-0.9238, -1.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14800970256328583
Epoch 0, Step 1236: train/loss = 0.32654768228530884, train/raw-loss = 0.27803194522857666, train/logprobs = tensor([[-0.4821, -6.2265],
        [-0.9683, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16171908378601074
Epoch 0, Step 1237: train/loss = 0.2957988977432251, train/raw-loss = 0.24338382482528687, train/logprobs = tensor([[-0.7711, -7.4330],
        [-1.7912, -1.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1747167706489563
Epoch 0, Step 1238: train/loss = 0.46045011281967163, train/raw-loss = 0.41085895895957947, train/logprobs = tensor([[-0.6667, -3.5371],
        [-1.3280, -1.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16530394554138184
Epoch 0, Step 1239: train/loss = 0.5519742369651794, train/raw-loss = 0.5146095156669617, train/logprobs = tensor([[-0.8728, -3.3519],
        [-0.7681, -1.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454921007156372
Epoch 0, Step 1240: train/loss = 0.5246828198432922, train/raw-loss = 0.47126150131225586, train/logprobs = tensor([[-1.3295, -6.7533],
        [-1.9794, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17807111144065857
Epoch 0, Step 1241: train/loss = 0.3545738756656647, train/raw-loss = 0.2932920455932617, train/logprobs = tensor([[-0.7605, -3.1851],
        [-1.8797, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042727917432785
Epoch 0, Step 1242: train/loss = 0.4345836639404297, train/raw-loss = 0.38979071378707886, train/logprobs = tensor([[-0.8714, -3.0964],
        [-1.5811, -1.4190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14930970966815948
Epoch 0, Step 1243: train/loss = 0.49850064516067505, train/raw-loss = 0.4476719796657562, train/logprobs = tensor([[-0.6952, -2.1299],
        [-1.3570, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16942882537841797
Epoch 0, Step 1244: train/loss = 0.3807523846626282, train/raw-loss = 0.32723474502563477, train/logprobs = tensor([[-0.7397, -2.6875],
        [-1.4400, -0.5513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178392231464386
Epoch 0, Step 1245: train/loss = 0.2737864851951599, train/raw-loss = 0.21118934452533722, train/logprobs = tensor([[-0.6984, -4.6842],
        [-2.0333, -1.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20865710079669952
Epoch 0, Step 1246: train/loss = 0.2543381452560425, train/raw-loss = 0.20512771606445312, train/logprobs = tensor([[-0.7933, -3.6898],
        [-1.8149, -0.6046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16403478384017944
Epoch 0, Step 1247: train/loss = 0.44250184297561646, train/raw-loss = 0.3867519497871399, train/logprobs = tensor([[-1.1905, -4.5292],
        [-1.1686, -1.3518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18583300709724426
Epoch 0, Step 1248: train/loss = 0.4971618354320526, train/raw-loss = 0.4430233836174011, train/logprobs = tensor([[-0.6513, -2.3057],
        [-1.3045, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18046137690544128
Epoch 0, Step 1249: train/loss = 0.5449092388153076, train/raw-loss = 0.4894914925098419, train/logprobs = tensor([[-0.9453, -2.0106],
        [-1.4222, -1.2561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1847257912158966
Epoch 0, Step 1250: train/loss = 0.5010114312171936, train/raw-loss = 0.4442056119441986, train/logprobs = tensor([[-0.7958, -2.4775],
        [-1.1478, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18935267627239227
Epoch 0, Step 1251: train/loss = 0.4152452349662781, train/raw-loss = 0.3573457896709442, train/logprobs = tensor([[-0.5134, -4.3002],
        [-1.4095, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19299806654453278
Epoch 0, Step 1252: train/loss = 0.2386666089296341, train/raw-loss = 0.1678721308708191, train/logprobs = tensor([[-0.8737, -7.3129],
        [-2.3252, -1.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359815388917923
Epoch 0, Step 1253: train/loss = 0.41748547554016113, train/raw-loss = 0.3681756556034088, train/logprobs = tensor([[-0.7470, -2.4301],
        [-1.4462, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16436609625816345
Epoch 0, Step 1254: train/loss = 0.4430937170982361, train/raw-loss = 0.39766210317611694, train/logprobs = tensor([[-0.4449, -2.7463],
        [-0.9775, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15143869817256927
Epoch 0, Step 1255: train/loss = 0.6802228689193726, train/raw-loss = 0.6351978778839111, train/logprobs = tensor([[-0.6257, -0.8682],
        [-1.0635, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15008330345153809
Epoch 0, Step 1256: train/loss = 0.34027111530303955, train/raw-loss = 0.28632453083992004, train/logprobs = tensor([[-1.1914, -2.7152],
        [-2.8699, -1.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17982202768325806
Epoch 0, Step 1257: train/loss = 0.49634289741516113, train/raw-loss = 0.44632256031036377, train/logprobs = tensor([[-0.5816, -2.7102],
        [-0.8537, -0.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16673441231250763
Epoch 0, Step 1258: train/loss = 0.3382399082183838, train/raw-loss = 0.28251081705093384, train/logprobs = tensor([[-0.8095, -3.6939],
        [-1.8819, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18576353788375854
Epoch 0, Step 1259: train/loss = 0.6519040465354919, train/raw-loss = 0.5997017621994019, train/logprobs = tensor([[-0.5969, -1.2249],
        [-0.9829, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17400763928890228
Epoch 0, Step 1260: train/loss = 0.48395857214927673, train/raw-loss = 0.4198440909385681, train/logprobs = tensor([[-0.8446, -9.3627],
        [-1.8352, -2.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21371492743492126
Epoch 0, Step 1261: train/loss = 0.5215902328491211, train/raw-loss = 0.44609972834587097, train/logprobs = tensor([[-0.7919, -3.0057],
        [-1.9665, -1.6656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516351044178009
Epoch 0, Step 1262: train/loss = 0.42741507291793823, train/raw-loss = 0.37863630056381226, train/logprobs = tensor([[-0.7799, -3.8194],
        [-1.4076, -1.4748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16259586811065674
Epoch 0, Step 1263: train/loss = 0.4984526038169861, train/raw-loss = 0.4446294903755188, train/logprobs = tensor([[-1.2473, -4.3085],
        [-1.3131, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17941036820411682
Epoch 0, Step 1264: train/loss = 0.3197716176509857, train/raw-loss = 0.2654109001159668, train/logprobs = tensor([[-1.0099, -4.4612],
        [-1.6194, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18120229244232178
Epoch 0, Step 1265: train/loss = 0.47623568773269653, train/raw-loss = 0.418778657913208, train/logprobs = tensor([[-0.8580, -2.8111],
        [-1.8606, -1.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19152356684207916
Epoch 0, Step 1266: train/loss = 0.434395968914032, train/raw-loss = 0.3845847249031067, train/logprobs = tensor([[-1.2793, -7.3411],
        [-1.5985, -1.3783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16603738069534302
Epoch 0, Step 1267: train/loss = 0.21318164467811584, train/raw-loss = 0.15725159645080566, train/logprobs = tensor([[-0.8231, -4.7076],
        [-2.1042, -1.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18643346428871155
Epoch 0, Step 1268: train/loss = 0.29863882064819336, train/raw-loss = 0.2464597523212433, train/logprobs = tensor([[-0.8998, -7.0959],
        [-2.3272, -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17393025755882263
Epoch 0, Step 1269: train/loss = 0.3848055899143219, train/raw-loss = 0.33523836731910706, train/logprobs = tensor([[-0.9527, -4.1751],
        [-1.9189, -1.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1652241349220276
Epoch 0, Step 1270: train/loss = 0.5106704831123352, train/raw-loss = 0.460521936416626, train/logprobs = tensor([[-0.9609, -3.5914],
        [-1.3852, -1.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671619564294815
Epoch 0, Step 1271: train/loss = 0.5709999799728394, train/raw-loss = 0.5294404029846191, train/logprobs = tensor([[-0.7710, -3.9985],
        [-0.8943, -1.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13853180408477783
Epoch 0, Step 1272: train/loss = 0.3200582265853882, train/raw-loss = 0.26323166489601135, train/logprobs = tensor([[-1.0233, -4.8603],
        [-1.8475, -1.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894218921661377
Epoch 0, Step 1273: train/loss = 0.5306471586227417, train/raw-loss = 0.4787101149559021, train/logprobs = tensor([[-1.0723, -2.8156],
        [-1.1538, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731235682964325
Epoch 0, Step 1274: train/loss = 0.4800723195075989, train/raw-loss = 0.4268202781677246, train/logprobs = tensor([[-0.4237, -3.3929],
        [-0.9702, -1.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17750681936740875
Epoch 0, Step 1275: train/loss = 0.37822645902633667, train/raw-loss = 0.3237047791481018, train/logprobs = tensor([[-0.5118, -2.6260],
        [-1.4687, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18173907697200775
Epoch 0, Step 1276: train/loss = 0.3412114083766937, train/raw-loss = 0.29448801279067993, train/logprobs = tensor([[-0.6917, -9.0809],
        [-1.3586, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15574462711811066
Epoch 0, Step 1277: train/loss = 0.5147726535797119, train/raw-loss = 0.4708905518054962, train/logprobs = tensor([[-0.7153, -1.7863],
        [-1.0261, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14627361297607422
Epoch 0, Step 1278: train/loss = 0.2766084372997284, train/raw-loss = 0.21992582082748413, train/logprobs = tensor([[-0.4785, -4.4468],
        [-1.7529, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18894203007221222
Epoch 0, Step 1279: train/loss = 0.24470780789852142, train/raw-loss = 0.18337422609329224, train/logprobs = tensor([[-0.7894, -5.9267],
        [-2.0098, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2044452726840973
Epoch 0, Step 1280: train/loss = 0.3340842127799988, train/raw-loss = 0.2780844271183014, train/logprobs = tensor([[-0.6284, -4.7720],
        [-1.6400, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866658329963684
Epoch 0, Step 1281: train/loss = 0.3995189070701599, train/raw-loss = 0.3432697653770447, train/logprobs = tensor([[-0.8131, -4.6412],
        [-1.1812, -1.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749727308750153
Epoch 0, Step 1282: train/loss = 0.49804896116256714, train/raw-loss = 0.4575357735157013, train/logprobs = tensor([[-0.4654, -2.7663],
        [-0.7289, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350439339876175
Epoch 0, Step 1283: train/loss = 0.5217873454093933, train/raw-loss = 0.47511762380599976, train/logprobs = tensor([[-0.4769, -2.1994],
        [-0.9474, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1555657684803009
Epoch 0, Step 1284: train/loss = 0.5084582567214966, train/raw-loss = 0.4650525450706482, train/logprobs = tensor([[-0.5042, -4.2047],
        [-0.8417, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1446857899427414
Epoch 0, Step 1285: train/loss = 0.2252093255519867, train/raw-loss = 0.17288410663604736, train/logprobs = tensor([[-0.8805, -7.4647],
        [-2.1684, -1.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1744174063205719
Epoch 0, Step 1286: train/loss = 0.27343836426734924, train/raw-loss = 0.2231098711490631, train/logprobs = tensor([[-0.7398, -5.4855],
        [-1.8834, -1.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677616834640503
Epoch 0, Step 1287: train/loss = 0.4468400478363037, train/raw-loss = 0.3952189087867737, train/logprobs = tensor([[-0.5495, -5.0216],
        [-1.4017, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17207053303718567
Epoch 0, Step 1288: train/loss = 0.7035022974014282, train/raw-loss = 0.6539030075073242, train/logprobs = tensor([[-1.4179, -3.3151],
        [-0.9238, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1653309315443039
Epoch 0, Step 1289: train/loss = 0.3759968876838684, train/raw-loss = 0.3293926417827606, train/logprobs = tensor([[-0.8411, -4.5185],
        [-1.8315, -1.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15534742176532745
Epoch 0, Step 1290: train/loss = 0.37582260370254517, train/raw-loss = 0.3280501365661621, train/logprobs = tensor([[-0.7189, -3.9955],
        [-1.4946, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15924157202243805
Epoch 0, Step 1291: train/loss = 0.4057771861553192, train/raw-loss = 0.35287246108055115, train/logprobs = tensor([[ -1.8816, -11.3519],
        [ -2.4231,  -2.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17634911835193634
Epoch 0, Step 1292: train/loss = 0.3437597155570984, train/raw-loss = 0.2810594141483307, train/logprobs = tensor([[-0.7310, -5.3847],
        [-2.1185, -2.3495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20900093019008636
Epoch 0, Step 1293: train/loss = 0.28373053669929504, train/raw-loss = 0.22376184165477753, train/logprobs = tensor([[-0.8509, -5.0711],
        [-2.4432, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1998956948518753
Epoch 0, Step 1294: train/loss = 0.393987774848938, train/raw-loss = 0.33832037448883057, train/logprobs = tensor([[-0.9653, -3.0342],
        [-2.1126, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18555791676044464
Epoch 0, Step 1295: train/loss = 0.37155622243881226, train/raw-loss = 0.3257518708705902, train/logprobs = tensor([[-0.9246, -5.4757],
        [-2.0788, -3.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15268126130104065
Epoch 0, Step 1296: train/loss = 0.26038801670074463, train/raw-loss = 0.20752762258052826, train/logprobs = tensor([[-0.7857, -3.6829],
        [-1.9608, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1762012392282486
Epoch 0, Step 1297: train/loss = 0.40429818630218506, train/raw-loss = 0.3507506251335144, train/logprobs = tensor([[-0.7194, -7.0780],
        [-1.2669, -2.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17849190533161163
Epoch 0, Step 1298: train/loss = 0.44576048851013184, train/raw-loss = 0.3835821747779846, train/logprobs = tensor([[-1.1340, -1.9940],
        [-2.0881, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20726101100444794
Epoch 0, Step 1299: train/loss = 0.3401249051094055, train/raw-loss = 0.2900555431842804, train/logprobs = tensor([[-0.6209, -4.9785],
        [-1.8337, -1.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1668977439403534
Epoch 0, Step 1300: train/loss = 0.46583184599876404, train/raw-loss = 0.40477192401885986, train/logprobs = tensor([[-0.8675, -5.5054],
        [-1.5624, -1.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20353305339813232
Epoch 0, Step 1301: train/loss = 0.5792198777198792, train/raw-loss = 0.5159072875976562, train/logprobs = tensor([[-1.0050, -2.2879],
        [-1.2694, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21104198694229126
Epoch 0, Step 1302: train/loss = 0.47464919090270996, train/raw-loss = 0.4275367259979248, train/logprobs = tensor([[-0.5938, -1.5244],
        [-1.2415, -0.7297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15704159438610077
Epoch 0, Step 1303: train/loss = 0.481601744890213, train/raw-loss = 0.4347810745239258, train/logprobs = tensor([[-0.4016, -2.7352],
        [-1.1670, -0.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15606878697872162
Epoch 0, Step 1304: train/loss = 0.4886326789855957, train/raw-loss = 0.43416160345077515, train/logprobs = tensor([[-0.6126, -2.4903],
        [-1.7883, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18157018721103668
Epoch 0, Step 1305: train/loss = 0.5578855276107788, train/raw-loss = 0.5062974691390991, train/logprobs = tensor([[-2.2486, -5.7812],
        [-2.0162, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17196013033390045
Epoch 0, Step 1306: train/loss = 0.36943182349205017, train/raw-loss = 0.3119155168533325, train/logprobs = tensor([[-1.8701, -5.7714],
        [-2.2754, -1.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19172099232673645
Epoch 0, Step 1307: train/loss = 0.4389844536781311, train/raw-loss = 0.3974718749523163, train/logprobs = tensor([[-0.9636, -2.0416],
        [-1.7496, -0.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383751928806305
Epoch 0, Step 1308: train/loss = 0.44699740409851074, train/raw-loss = 0.4022761285305023, train/logprobs = tensor([[-0.5409, -4.1697],
        [-1.5696, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14907079935073853
Epoch 0, Step 1309: train/loss = 0.40706443786621094, train/raw-loss = 0.35533350706100464, train/logprobs = tensor([[-0.8694, -2.3512],
        [-1.5333, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17243638634681702
Epoch 0, Step 1310: train/loss = 0.4305569529533386, train/raw-loss = 0.37929344177246094, train/logprobs = tensor([[-0.6496, -3.6163],
        [-1.5089, -0.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1708783656358719
Epoch 0, Step 1311: train/loss = 0.34058910608291626, train/raw-loss = 0.29215776920318604, train/logprobs = tensor([[-0.6348, -3.7944],
        [-1.7729, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16143770515918732
Epoch 0, Step 1312: train/loss = 0.507228434085846, train/raw-loss = 0.45191121101379395, train/logprobs = tensor([[-0.7564, -2.5914],
        [-1.7599, -1.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18439072370529175
Epoch 0, Step 1313: train/loss = 0.8362939953804016, train/raw-loss = 0.779680073261261, train/logprobs = tensor([[-1.8636, -2.1018],
        [-1.2462, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18871313333511353
Epoch 0, Step 1314: train/loss = 0.8318536877632141, train/raw-loss = 0.7789840698242188, train/logprobs = tensor([[-1.5328, -1.4561],
        [-1.1360, -0.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17623181641101837
Epoch 0, Step 1315: train/loss = 0.25546401739120483, train/raw-loss = 0.1993202269077301, train/logprobs = tensor([[ -0.7081, -11.7955],
        [ -1.9973,  -2.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1871458888053894
Epoch 0, Step 1316: train/loss = 0.44674623012542725, train/raw-loss = 0.39704203605651855, train/logprobs = tensor([[-0.6903, -2.4530],
        [-1.5007, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16568058729171753
Epoch 0, Step 1317: train/loss = 0.5589355826377869, train/raw-loss = 0.5042923092842102, train/logprobs = tensor([[-0.5376, -2.0432],
        [-1.5251, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1821441948413849
Epoch 0, Step 1318: train/loss = 0.34979039430618286, train/raw-loss = 0.2928077280521393, train/logprobs = tensor([[-0.7399, -5.8124],
        [-1.4013, -1.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18994221091270447
Epoch 0, Step 1319: train/loss = 0.33076441287994385, train/raw-loss = 0.27501213550567627, train/logprobs = tensor([[-0.6813, -3.3978],
        [-1.9544, -0.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18584084510803223
Epoch 0, Step 1320: train/loss = 0.4245508909225464, train/raw-loss = 0.37143778800964355, train/logprobs = tensor([[-1.0575, -4.6252],
        [-2.2393, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17704364657402039
Epoch 0, Step 1321: train/loss = 0.5513941049575806, train/raw-loss = 0.4976103901863098, train/logprobs = tensor([[-0.5471, -1.8568],
        [-1.0830, -1.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1792788952589035
Epoch 0, Step 1322: train/loss = 0.43540892004966736, train/raw-loss = 0.3784397542476654, train/logprobs = tensor([[-0.6055, -1.9342],
        [-1.3821, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18989743292331696
Epoch 0, Step 1323: train/loss = 0.5454361438751221, train/raw-loss = 0.5088035464286804, train/logprobs = tensor([[-0.6465, -3.0723],
        [-0.6756, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12210869044065475
Epoch 0, Step 1324: train/loss = 0.42492401599884033, train/raw-loss = 0.36793646216392517, train/logprobs = tensor([[-0.5278, -5.0907],
        [-1.0855, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18995851278305054
Epoch 0, Step 1325: train/loss = 0.6713200211524963, train/raw-loss = 0.6336814165115356, train/logprobs = tensor([[-0.3384, -2.5292],
        [-0.6789, -1.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12546201050281525
Epoch 0, Step 1326: train/loss = 0.41923004388809204, train/raw-loss = 0.3564426302909851, train/logprobs = tensor([[-1.6203, -6.1340],
        [-1.7637, -1.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20929138362407684
Epoch 0, Step 1327: train/loss = 0.5033621788024902, train/raw-loss = 0.44169461727142334, train/logprobs = tensor([[-1.6895, -3.1417],
        [-2.1725, -1.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20555852353572845
Epoch 0, Step 1328: train/loss = 0.3501673638820648, train/raw-loss = 0.2980130910873413, train/logprobs = tensor([[-0.8691, -4.5292],
        [-1.3589, -1.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17384758591651917
Epoch 0, Step 1329: train/loss = 0.26462796330451965, train/raw-loss = 0.20039981603622437, train/logprobs = tensor([[-1.4039, -6.0489],
        [-2.9205, -1.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21409380435943604
Epoch 0, Step 1330: train/loss = 0.5307857990264893, train/raw-loss = 0.47201287746429443, train/logprobs = tensor([[-1.2519, -5.4693],
        [-1.4105, -2.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.195909783244133
Epoch 0, Step 1331: train/loss = 0.34844085574150085, train/raw-loss = 0.2823561728000641, train/logprobs = tensor([[-1.0830, -3.3147],
        [-2.0567, -0.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22028231620788574
Epoch 0, Step 1332: train/loss = 0.30011358857154846, train/raw-loss = 0.23694518208503723, train/logprobs = tensor([[-0.9258, -4.6152],
        [-1.8279, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2105613350868225
Epoch 0, Step 1333: train/loss = 0.4717223048210144, train/raw-loss = 0.4215974807739258, train/logprobs = tensor([[-0.8165, -3.1246],
        [-1.3150, -1.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16708266735076904
Epoch 0, Step 1334: train/loss = 0.6793527603149414, train/raw-loss = 0.6203723549842834, train/logprobs = tensor([[-1.9023, -3.3506],
        [-2.3322, -1.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19660136103630066
Epoch 0, Step 1335: train/loss = 0.34286001324653625, train/raw-loss = 0.28818973898887634, train/logprobs = tensor([[-1.8746, -5.7987],
        [-2.9935, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18223430216312408
Epoch 0, Step 1336: train/loss = 0.35657113790512085, train/raw-loss = 0.3006366193294525, train/logprobs = tensor([[-0.8158, -8.0614],
        [-1.5812, -2.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18644830584526062
Epoch 0, Step 1337: train/loss = 0.4921676218509674, train/raw-loss = 0.455875039100647, train/logprobs = tensor([[-0.4542, -5.7597],
        [-0.7812, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12097518146038055
Epoch 0, Step 1338: train/loss = 0.35245347023010254, train/raw-loss = 0.2848641276359558, train/logprobs = tensor([[-0.7036, -3.7295],
        [-1.8339, -1.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22529779374599457
Epoch 0, Step 1339: train/loss = 0.33851391077041626, train/raw-loss = 0.2712433338165283, train/logprobs = tensor([[-1.0643, -3.5666],
        [-2.5083, -1.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22423529624938965
Epoch 0, Step 1340: train/loss = 0.23762448132038116, train/raw-loss = 0.17985080182552338, train/logprobs = tensor([[-0.7390, -4.5187],
        [-2.3259, -1.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925789713859558
Epoch 0, Step 1341: train/loss = 0.3580135405063629, train/raw-loss = 0.31530940532684326, train/logprobs = tensor([[-1.0394, -3.6139],
        [-1.8141, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423470377922058
Epoch 0, Step 1342: train/loss = 0.6167031526565552, train/raw-loss = 0.5749539732933044, train/logprobs = tensor([[-0.8400, -2.5306],
        [-0.7092, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13916385173797607
Epoch 0, Step 1343: train/loss = 0.24184760451316833, train/raw-loss = 0.18474119901657104, train/logprobs = tensor([[-0.8366, -3.8322],
        [-2.3821, -0.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19035470485687256
Epoch 0, Step 1344: train/loss = 0.7372388243675232, train/raw-loss = 0.6915441751480103, train/logprobs = tensor([[-1.8658, -4.2000],
        [-0.9218, -1.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15231570601463318
Epoch 0, Step 1345: train/loss = 0.5156685709953308, train/raw-loss = 0.4563544690608978, train/logprobs = tensor([[-0.9890, -2.5202],
        [-1.9432, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977137327194214
Epoch 0, Step 1346: train/loss = 0.5137037634849548, train/raw-loss = 0.45256757736206055, train/logprobs = tensor([[-1.1008, -2.4591],
        [-1.8153, -1.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20378725230693817
Epoch 0, Step 1347: train/loss = 0.43835705518722534, train/raw-loss = 0.382947713136673, train/logprobs = tensor([[-0.9565, -3.3643],
        [-1.8472, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18469783663749695
Epoch 0, Step 1348: train/loss = 0.49976643919944763, train/raw-loss = 0.45892035961151123, train/logprobs = tensor([[-0.8682, -1.8670],
        [-1.8952, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1361537128686905
Epoch 0, Step 1349: train/loss = 0.4162823259830475, train/raw-loss = 0.36174750328063965, train/logprobs = tensor([[-1.0964, -2.7793],
        [-1.9140, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18178269267082214
Epoch 0, Step 1350: train/loss = 0.35581153631210327, train/raw-loss = 0.3086090683937073, train/logprobs = tensor([[-0.6917, -7.8364],
        [-1.6455, -2.3435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15734146535396576
Epoch 0, Step 1351: train/loss = 0.48732447624206543, train/raw-loss = 0.4339439272880554, train/logprobs = tensor([[-1.0991, -2.7012],
        [-2.1186, -2.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17793524265289307
Epoch 0, Step 1352: train/loss = 0.5275595188140869, train/raw-loss = 0.49063363671302795, train/logprobs = tensor([[-0.6271, -2.1084],
        [-0.9354, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1230863481760025
Epoch 0, Step 1353: train/loss = 0.59409499168396, train/raw-loss = 0.5539695024490356, train/logprobs = tensor([[-0.6716, -3.6665],
        [-0.9853, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13375172019004822
Epoch 0, Step 1354: train/loss = 0.40229934453964233, train/raw-loss = 0.34349071979522705, train/logprobs = tensor([[-0.6843, -2.3640],
        [-1.8634, -1.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19602859020233154
Epoch 0, Step 1355: train/loss = 0.19584603607654572, train/raw-loss = 0.14763686060905457, train/logprobs = tensor([[-0.9548, -7.3671],
        [-2.0503, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16069720685482025
Epoch 0, Step 1356: train/loss = 0.45402991771698, train/raw-loss = 0.40566286444664, train/logprobs = tensor([[-1.1228, -2.9881],
        [-1.7303, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16122359037399292
Epoch 0, Step 1357: train/loss = 0.5903207659721375, train/raw-loss = 0.5434442162513733, train/logprobs = tensor([[-0.5100, -1.1971],
        [-0.9539, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15625518560409546
Epoch 0, Step 1358: train/loss = 0.2786322236061096, train/raw-loss = 0.2207176387310028, train/logprobs = tensor([[-0.7449, -4.1430],
        [-2.1913, -1.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19304853677749634
Epoch 0, Step 1359: train/loss = 0.5319898724555969, train/raw-loss = 0.4720001220703125, train/logprobs = tensor([[-0.5770, -2.7535],
        [-1.3595, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1999659240245819
Epoch 0, Step 1360: train/loss = 0.3107416033744812, train/raw-loss = 0.2608715891838074, train/logprobs = tensor([[-0.7872, -3.6720],
        [-1.6817, -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16623333096504211
Epoch 0, Step 1361: train/loss = 0.3350014388561249, train/raw-loss = 0.2787908911705017, train/logprobs = tensor([[-0.8584, -4.5243],
        [-1.6630, -1.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1873685121536255
Epoch 0, Step 1362: train/loss = 0.39017871022224426, train/raw-loss = 0.32958588004112244, train/logprobs = tensor([[-0.7550, -3.7182],
        [-2.3633, -0.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20197612047195435
Epoch 0, Step 1363: train/loss = 0.5137715339660645, train/raw-loss = 0.46843308210372925, train/logprobs = tensor([[-0.6073, -2.7710],
        [-0.9989, -0.6904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15112802386283875
Epoch 0, Step 1364: train/loss = 0.41363397240638733, train/raw-loss = 0.3612389862537384, train/logprobs = tensor([[-0.5107, -3.8628],
        [-1.2529, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17464984953403473
Epoch 0, Step 1365: train/loss = 0.3816158175468445, train/raw-loss = 0.33492493629455566, train/logprobs = tensor([[-0.3921, -4.6762],
        [-1.0929, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155636265873909
Epoch 0, Step 1366: train/loss = 0.5322120189666748, train/raw-loss = 0.489493191242218, train/logprobs = tensor([[-0.4091, -3.2331],
        [-0.8169, -1.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14239594340324402
Epoch 0, Step 1367: train/loss = 0.3558747470378876, train/raw-loss = 0.30227696895599365, train/logprobs = tensor([[-0.6865, -5.1538],
        [-2.1884, -1.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17865926027297974
Epoch 0, Step 1368: train/loss = 0.5511798858642578, train/raw-loss = 0.5046835541725159, train/logprobs = tensor([[-0.7011, -1.9966],
        [-1.1498, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15498776733875275
Epoch 0, Step 1369: train/loss = 0.42787256836891174, train/raw-loss = 0.36445358395576477, train/logprobs = tensor([[-0.5437, -1.8798],
        [-2.4035, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21139657497406006
Epoch 0, Step 1370: train/loss = 0.49798986315727234, train/raw-loss = 0.4436761140823364, train/logprobs = tensor([[-0.8408, -2.1123],
        [-1.5143, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18104569613933563
Epoch 0, Step 1371: train/loss = 0.44411975145339966, train/raw-loss = 0.3950769305229187, train/logprobs = tensor([[-0.6284, -3.4652],
        [-1.4233, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16347616910934448
Epoch 0, Step 1372: train/loss = 0.2685036063194275, train/raw-loss = 0.20871931314468384, train/logprobs = tensor([[-0.8029, -6.4156],
        [-2.2150, -1.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19928096234798431
Epoch 0, Step 1373: train/loss = 0.5939576029777527, train/raw-loss = 0.5500309467315674, train/logprobs = tensor([[-1.4485, -2.7101],
        [-2.4656, -1.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464218646287918
Epoch 0, Step 1374: train/loss = 0.4288480281829834, train/raw-loss = 0.38384246826171875, train/logprobs = tensor([[-0.4709, -3.4337],
        [-1.3866, -1.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1500186175107956
Epoch 0, Step 1375: train/loss = 0.3083582818508148, train/raw-loss = 0.2593320310115814, train/logprobs = tensor([[-0.9011, -5.9716],
        [-1.8512, -1.6825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16342082619667053
Epoch 0, Step 1376: train/loss = 0.25780484080314636, train/raw-loss = 0.19772501289844513, train/logprobs = tensor([[-1.0330, -4.8212],
        [-2.8817, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20026615262031555
Epoch 0, Step 1377: train/loss = 0.4449768662452698, train/raw-loss = 0.39821699261665344, train/logprobs = tensor([[-0.5612, -5.2029],
        [-1.3649, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15586625039577484
Epoch 0, Step 1378: train/loss = 0.5020419955253601, train/raw-loss = 0.4471670985221863, train/logprobs = tensor([[-1.0765, -3.3516],
        [-1.2618, -0.6653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829162985086441
Epoch 0, Step 1379: train/loss = 0.5578291416168213, train/raw-loss = 0.49517881870269775, train/logprobs = tensor([[-1.0704, -2.8267],
        [-1.9054, -2.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20883440971374512
Epoch 0, Step 1380: train/loss = 0.20273542404174805, train/raw-loss = 0.140584796667099, train/logprobs = tensor([[-0.5399, -5.6416],
        [-1.8981, -1.3917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20716877281665802
Epoch 0, Step 1381: train/loss = 0.3270006775856018, train/raw-loss = 0.2630496323108673, train/logprobs = tensor([[-0.6440, -7.4057],
        [-1.5477, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2131701409816742
Epoch 0, Step 1382: train/loss = 0.3526913821697235, train/raw-loss = 0.2911532521247864, train/logprobs = tensor([[-1.1159, -5.9725],
        [-1.7146, -1.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20512714982032776
Epoch 0, Step 1383: train/loss = 0.30879104137420654, train/raw-loss = 0.2590126395225525, train/logprobs = tensor([[-0.9723, -5.4412],
        [-2.2502, -2.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16592803597450256
Epoch 0, Step 1384: train/loss = 0.4701537787914276, train/raw-loss = 0.4178159534931183, train/logprobs = tensor([[-0.6514, -3.6229],
        [-1.5001, -1.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17445945739746094
Epoch 0, Step 1385: train/loss = 0.37194234132766724, train/raw-loss = 0.3055671453475952, train/logprobs = tensor([[-0.9079, -2.6114],
        [-2.6738, -1.3852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22125056385993958
Epoch 0, Step 1386: train/loss = 0.30479350686073303, train/raw-loss = 0.23276138305664062, train/logprobs = tensor([[-1.0058, -3.4521],
        [-2.2479, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24010705947875977
Epoch 0, Step 1387: train/loss = 0.5004433393478394, train/raw-loss = 0.437603235244751, train/logprobs = tensor([[-0.6310, -1.6318],
        [-1.9255, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20946696400642395
Epoch 0, Step 1388: train/loss = 0.3241787552833557, train/raw-loss = 0.2744561433792114, train/logprobs = tensor([[-1.0598, -4.6667],
        [-1.9689, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165741965174675
Epoch 0, Step 1389: train/loss = 0.5128693580627441, train/raw-loss = 0.4500257968902588, train/logprobs = tensor([[-1.2368, -3.6537],
        [-1.7619, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.209478497505188
Epoch 0, Step 1390: train/loss = 0.4562285840511322, train/raw-loss = 0.4001990556716919, train/logprobs = tensor([[-0.7499, -2.5015],
        [-1.2899, -1.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1867651343345642
Epoch 0, Step 1391: train/loss = 0.4251236617565155, train/raw-loss = 0.3707748353481293, train/logprobs = tensor([[-0.6973, -2.7951],
        [-1.5974, -1.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18116268515586853
Epoch 0, Step 1392: train/loss = 0.33327606320381165, train/raw-loss = 0.2826395034790039, train/logprobs = tensor([[-0.7951, -7.5457],
        [-1.5171, -1.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16878846287727356
Epoch 0, Step 1393: train/loss = 0.2959994375705719, train/raw-loss = 0.23120325803756714, train/logprobs = tensor([[-0.6619, -7.0136],
        [-2.4076, -2.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21598735451698303
Epoch 0, Step 1394: train/loss = 0.38058388233184814, train/raw-loss = 0.3121090531349182, train/logprobs = tensor([[-0.6152, -2.1755],
        [-2.1097, -1.1126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22824952006340027
Epoch 0, Step 1395: train/loss = 0.40345895290374756, train/raw-loss = 0.33467817306518555, train/logprobs = tensor([[-0.7680, -4.0484],
        [-1.8325, -2.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22926923632621765
Epoch 0, Step 1396: train/loss = 0.31286031007766724, train/raw-loss = 0.241799995303154, train/logprobs = tensor([[-0.9206, -5.3356],
        [-2.1197, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23686765134334564
Epoch 0, Step 1397: train/loss = 0.31117457151412964, train/raw-loss = 0.2630856931209564, train/logprobs = tensor([[-0.6729, -8.4641],
        [-1.3017, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16029632091522217
Epoch 0, Step 1398: train/loss = 0.18377406895160675, train/raw-loss = 0.10602181404829025, train/logprobs = tensor([[-1.0189, -5.5352],
        [-2.6849, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591741681098938
Epoch 0, Step 1399: train/loss = 0.326809823513031, train/raw-loss = 0.2572455108165741, train/logprobs = tensor([[-0.5299, -3.7743],
        [-2.6268, -1.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318810522556305
Epoch 0, Step 1400: train/loss = 0.6089578866958618, train/raw-loss = 0.5452213883399963, train/logprobs = tensor([[-0.7160, -7.3631],
        [-1.8427, -2.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21245479583740234
Epoch 0, Step 1401: train/loss = 0.31630441546440125, train/raw-loss = 0.239741250872612, train/logprobs = tensor([[-1.4017, -6.5260],
        [-2.9081, -2.3584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2552105784416199
Epoch 0, Step 1402: train/loss = 0.27995941042900085, train/raw-loss = 0.21932676434516907, train/logprobs = tensor([[-0.7380, -4.2821],
        [-2.1301, -1.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20210888981819153
Epoch 0, Step 1403: train/loss = 0.40880388021469116, train/raw-loss = 0.35678330063819885, train/logprobs = tensor([[-1.3458, -4.2426],
        [-1.8105, -1.5507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734018623828888
Epoch 0, Step 1404: train/loss = 0.2998788356781006, train/raw-loss = 0.24611639976501465, train/logprobs = tensor([[-0.8042, -7.5714],
        [-2.4117, -1.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17920812964439392
Epoch 0, Step 1405: train/loss = 0.44585472345352173, train/raw-loss = 0.3787015676498413, train/logprobs = tensor([[-0.8435, -6.4065],
        [-2.1958, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22384387254714966
Epoch 0, Step 1406: train/loss = 0.5137393474578857, train/raw-loss = 0.4637302756309509, train/logprobs = tensor([[-0.4827, -1.9719],
        [-1.2376, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666969656944275
Epoch 0, Step 1407: train/loss = 0.33757418394088745, train/raw-loss = 0.2864378094673157, train/logprobs = tensor([[-0.9488, -7.3498],
        [-1.6170, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17045460641384125
Epoch 0, Step 1408: train/loss = 0.16344304382801056, train/raw-loss = 0.1081155315041542, train/logprobs = tensor([[ -0.6989, -10.1688],
        [ -2.2854,  -2.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18442502617835999
Epoch 0, Step 1409: train/loss = 0.5837012529373169, train/raw-loss = 0.5329158306121826, train/logprobs = tensor([[-0.6162, -1.2618],
        [-1.2518, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1692846119403839
Epoch 0, Step 1410: train/loss = 0.39032918214797974, train/raw-loss = 0.3230053782463074, train/logprobs = tensor([[-0.7323, -4.7365],
        [-2.6967, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22441262006759644
Epoch 0, Step 1411: train/loss = 0.4518602192401886, train/raw-loss = 0.38442757725715637, train/logprobs = tensor([[-0.4755, -3.4192],
        [-1.3605, -1.2797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224775493144989
Epoch 0, Step 1412: train/loss = 0.3574332892894745, train/raw-loss = 0.29521965980529785, train/logprobs = tensor([[-0.5858, -2.3401],
        [-2.4442, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20737875998020172
Epoch 0, Step 1413: train/loss = 0.3406725525856018, train/raw-loss = 0.29142606258392334, train/logprobs = tensor([[-0.8815, -3.7259],
        [-1.7207, -1.3738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16415508091449738
Epoch 0, Step 1414: train/loss = 0.48126187920570374, train/raw-loss = 0.4363618791103363, train/logprobs = tensor([[-0.6958, -4.4342],
        [-1.3101, -2.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1496666669845581
Epoch 0, Step 1415: train/loss = 0.506462037563324, train/raw-loss = 0.46749138832092285, train/logprobs = tensor([[-0.5629, -1.4914],
        [-1.3310, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12990228831768036
Epoch 0, Step 1416: train/loss = 0.3146764039993286, train/raw-loss = 0.25921186804771423, train/logprobs = tensor([[-0.9544, -8.4184],
        [-2.0984, -2.6756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18488170206546783
Epoch 0, Step 1417: train/loss = 0.2557147443294525, train/raw-loss = 0.19974008202552795, train/logprobs = tensor([[-0.5503, -7.5682],
        [-1.6575, -2.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18658220767974854
Epoch 0, Step 1418: train/loss = 0.4080660939216614, train/raw-loss = 0.35530275106430054, train/logprobs = tensor([[-0.8566, -2.9720],
        [-1.6474, -1.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17587780952453613
Epoch 0, Step 1419: train/loss = 0.6029798984527588, train/raw-loss = 0.5613570213317871, train/logprobs = tensor([[-0.4322, -1.4699],
        [-1.1798, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13874280452728271
Epoch 0, Step 1420: train/loss = 0.275768518447876, train/raw-loss = 0.22239276766777039, train/logprobs = tensor([[-0.4653, -3.9745],
        [-1.7913, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17791922390460968
Epoch 0, Step 1421: train/loss = 0.5314576625823975, train/raw-loss = 0.48336973786354065, train/logprobs = tensor([[-0.6161, -2.7205],
        [-1.5431, -2.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16029295325279236
Epoch 0, Step 1422: train/loss = 0.5588354468345642, train/raw-loss = 0.5202038288116455, train/logprobs = tensor([[-0.3284, -1.3546],
        [-0.8253, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287718415260315
Epoch 0, Step 1423: train/loss = 0.4407280683517456, train/raw-loss = 0.3926730155944824, train/logprobs = tensor([[-0.4621, -3.0253],
        [-1.2518, -1.9082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16018356382846832
Epoch 0, Step 1424: train/loss = 0.13845524191856384, train/raw-loss = 0.06662525236606598, train/logprobs = tensor([[-0.7582, -8.6198],
        [-3.2680, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23943328857421875
Epoch 0, Step 1425: train/loss = 0.3382902145385742, train/raw-loss = 0.2899348735809326, train/logprobs = tensor([[-0.8534, -4.3324],
        [-2.1038, -2.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16118445992469788
Epoch 0, Step 1426: train/loss = 0.2960522770881653, train/raw-loss = 0.23885348439216614, train/logprobs = tensor([[-0.8396, -8.0428],
        [-2.4492, -2.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19066262245178223
Epoch 0, Step 1427: train/loss = 0.46777838468551636, train/raw-loss = 0.408863365650177, train/logprobs = tensor([[-0.7817, -2.3431],
        [-2.0970, -1.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19638341665267944
Epoch 0, Step 1428: train/loss = 0.3021596074104309, train/raw-loss = 0.24163073301315308, train/logprobs = tensor([[-0.6762, -5.6717],
        [-2.1986, -1.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20176301896572113
Epoch 0, Step 1429: train/loss = 0.26893916726112366, train/raw-loss = 0.21032552421092987, train/logprobs = tensor([[-0.7372, -6.2275],
        [-2.2187, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19537878036499023
Epoch 0, Step 1430: train/loss = 0.3066553473472595, train/raw-loss = 0.25445058941841125, train/logprobs = tensor([[-1.2195, -6.9248],
        [-2.5718, -3.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17401587963104248
Epoch 0, Step 1431: train/loss = 0.1838093400001526, train/raw-loss = 0.1131613552570343, train/logprobs = tensor([[ -0.8314, -12.6995],
        [ -2.6208,  -3.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2354932576417923
Epoch 0, Step 1432: train/loss = 0.7210425734519958, train/raw-loss = 0.6485188007354736, train/logprobs = tensor([[-0.5434, -5.8401],
        [-2.8002, -2.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24174591898918152
Epoch 0, Step 1433: train/loss = 0.41060101985931396, train/raw-loss = 0.36108773946762085, train/logprobs = tensor([[-0.5004, -3.3022],
        [-1.9455, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16504418849945068
Epoch 0, Step 1434: train/loss = 0.25160983204841614, train/raw-loss = 0.1844625473022461, train/logprobs = tensor([[-0.7237, -4.3596],
        [-2.7581, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22382423281669617
Epoch 0, Step 1435: train/loss = 0.4063519835472107, train/raw-loss = 0.32168346643447876, train/logprobs = tensor([[-0.8272, -6.7835],
        [-3.1595, -2.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822285592556
Epoch 0, Step 1436: train/loss = 0.517080545425415, train/raw-loss = 0.4618557393550873, train/logprobs = tensor([[ -1.9148, -11.0668],
        [ -1.9919,  -2.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18408262729644775
Epoch 0, Step 1437: train/loss = 0.3791388273239136, train/raw-loss = 0.3354280889034271, train/logprobs = tensor([[-0.4980, -8.2143],
        [-1.7708, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14570243656635284
Epoch 0, Step 1438: train/loss = 0.16979002952575684, train/raw-loss = 0.11919130384922028, train/logprobs = tensor([[ -1.0080, -10.1927],
        [ -3.3203,  -1.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16866245865821838
Epoch 0, Step 1439: train/loss = 0.3484598994255066, train/raw-loss = 0.30691149830818176, train/logprobs = tensor([[-0.7495, -3.5761],
        [-2.3293, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138494610786438
Epoch 0, Step 1440: train/loss = 0.4156675636768341, train/raw-loss = 0.3573318123817444, train/logprobs = tensor([[-0.6209, -4.0060],
        [-2.0947, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19445253908634186
Epoch 0, Step 1441: train/loss = 0.6049064993858337, train/raw-loss = 0.5541937351226807, train/logprobs = tensor([[-0.9018, -1.4707],
        [-1.5303, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1690426468849182
Epoch 0, Step 1442: train/loss = 0.13066941499710083, train/raw-loss = 0.06291840225458145, train/logprobs = tensor([[-0.9500, -6.3798],
        [-3.5495, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22583666443824768
Epoch 0, Step 1443: train/loss = 0.6281032562255859, train/raw-loss = 0.5741350650787354, train/logprobs = tensor([[-1.0907, -4.2253],
        [-1.1673, -1.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17989391088485718
Epoch 0, Step 1444: train/loss = 0.30132222175598145, train/raw-loss = 0.228133425116539, train/logprobs = tensor([[-0.8608, -3.7410],
        [-3.4246, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24396257102489471
Epoch 0, Step 1445: train/loss = 0.5367652177810669, train/raw-loss = 0.48250120878219604, train/logprobs = tensor([[-0.3762, -2.9923],
        [-1.3390, -2.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18087995052337646
Epoch 0, Step 1446: train/loss = 0.490924209356308, train/raw-loss = 0.43011412024497986, train/logprobs = tensor([[-1.3837, -7.9331],
        [-2.1732, -1.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20270024240016937
Epoch 0, Step 1447: train/loss = 0.3459942042827606, train/raw-loss = 0.29432761669158936, train/logprobs = tensor([[-1.1487, -4.2848],
        [-1.7859, -1.3650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17222186923027039
Epoch 0, Step 1448: train/loss = 0.49400439858436584, train/raw-loss = 0.4336305260658264, train/logprobs = tensor([[-1.1804, -4.0003],
        [-1.4499, -1.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20124629139900208
Epoch 0, Step 1449: train/loss = 0.4904012680053711, train/raw-loss = 0.42846035957336426, train/logprobs = tensor([[-0.5805, -5.6982],
        [-1.8988, -1.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20646969974040985
Epoch 0, Step 1450: train/loss = 0.34238046407699585, train/raw-loss = 0.2769882380962372, train/logprobs = tensor([[-0.4964, -3.5434],
        [-1.6998, -1.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21797406673431396
Epoch 0, Step 1451: train/loss = 0.32967686653137207, train/raw-loss = 0.26508551836013794, train/logprobs = tensor([[-0.8600, -5.4694],
        [-2.7234, -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21530452370643616
Epoch 0, Step 1452: train/loss = 0.48808225989341736, train/raw-loss = 0.4187154769897461, train/logprobs = tensor([[-0.5997, -6.9869],
        [-2.4932, -2.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312227040529251
Epoch 0, Step 1453: train/loss = 0.2675555348396301, train/raw-loss = 0.2084256112575531, train/logprobs = tensor([[-0.7951, -3.7810],
        [-2.3826, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19709983468055725
Epoch 0, Step 1454: train/loss = 0.3547503352165222, train/raw-loss = 0.2955966591835022, train/logprobs = tensor([[-0.8064, -4.1342],
        [-2.8570, -2.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19717881083488464
Epoch 0, Step 1455: train/loss = 0.2767048478126526, train/raw-loss = 0.21734744310379028, train/logprobs = tensor([[-0.5274, -4.4503],
        [-3.5398, -3.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19785799086093903
Epoch 0, Step 1456: train/loss = 0.26623666286468506, train/raw-loss = 0.21507027745246887, train/logprobs = tensor([[-0.8275, -6.9964],
        [-2.1132, -2.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.170554518699646
Epoch 0, Step 1457: train/loss = 0.34889480471611023, train/raw-loss = 0.29769593477249146, train/logprobs = tensor([[-0.8457, -4.2153],
        [-2.3437, -2.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17066290974617004
Epoch 0, Step 1458: train/loss = 0.6435283422470093, train/raw-loss = 0.5822410583496094, train/logprobs = tensor([[-0.7641, -1.1705],
        [-1.9897, -1.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042907476425171
Epoch 0, Step 1459: train/loss = 0.20922426879405975, train/raw-loss = 0.1323588788509369, train/logprobs = tensor([[-0.6467, -8.2331],
        [-3.4553, -2.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25621798634529114
Epoch 0, Step 1460: train/loss = 0.27498942613601685, train/raw-loss = 0.21599192917346954, train/logprobs = tensor([[-1.3031, -6.9085],
        [-2.6324, -1.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19665835797786713
Epoch 0, Step 1461: train/loss = 0.5930734872817993, train/raw-loss = 0.5162703394889832, train/logprobs = tensor([[-0.7068, -2.4229],
        [-2.9655, -1.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256010502576828
Epoch 0, Step 1462: train/loss = 0.3839445114135742, train/raw-loss = 0.3173070251941681, train/logprobs = tensor([[-0.7195, -2.9155],
        [-2.4323, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22212505340576172
Epoch 0, Step 1463: train/loss = 0.2614338994026184, train/raw-loss = 0.19990521669387817, train/logprobs = tensor([[-0.8813, -4.4197],
        [-3.4215, -1.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20509560406208038
Epoch 0, Step 1464: train/loss = 0.5014756321907043, train/raw-loss = 0.43681925535202026, train/logprobs = tensor([[-0.6634, -3.7238],
        [-2.0372, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21552124619483948
Epoch 0, Step 1465: train/loss = 0.291944682598114, train/raw-loss = 0.24066545069217682, train/logprobs = tensor([[-0.7870, -5.2473],
        [-2.9299, -2.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17093080282211304
Epoch 0, Step 1466: train/loss = 0.4681905508041382, train/raw-loss = 0.4072585105895996, train/logprobs = tensor([[-0.6618, -3.5924],
        [-1.6567, -1.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2031068652868271
Epoch 0, Step 1467: train/loss = 0.2790416479110718, train/raw-loss = 0.22186279296875, train/logprobs = tensor([[-0.8556, -8.7224],
        [-2.9425, -2.1069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19059614837169647
Epoch 0, Step 1468: train/loss = 0.4354204535484314, train/raw-loss = 0.3788066506385803, train/logprobs = tensor([[-1.3768, -6.9762],
        [-2.5877, -1.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18871274590492249
Epoch 0, Step 1469: train/loss = 0.42616701126098633, train/raw-loss = 0.3704894781112671, train/logprobs = tensor([[-0.5042, -3.5077],
        [-1.2112, -1.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18559178709983826
Epoch 0, Step 1470: train/loss = 0.24063634872436523, train/raw-loss = 0.16450135409832, train/logprobs = tensor([[-0.7783, -4.0949],
        [-2.5369, -1.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25378334522247314
Epoch 0, Step 1471: train/loss = 0.4801957607269287, train/raw-loss = 0.4149932861328125, train/logprobs = tensor([[-0.5672, -2.4872],
        [-2.0174, -2.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21734149754047394
Epoch 0, Step 1472: train/loss = 0.34614789485931396, train/raw-loss = 0.30502551794052124, train/logprobs = tensor([[-0.6114, -7.1549],
        [-1.2936, -1.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13707467913627625
Epoch 0, Step 1473: train/loss = 0.32882964611053467, train/raw-loss = 0.2613108158111572, train/logprobs = tensor([[-1.0061, -4.1568],
        [-2.4382, -1.5543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22506272792816162
Epoch 0, Step 1474: train/loss = 0.45187294483184814, train/raw-loss = 0.3928181231021881, train/logprobs = tensor([[-0.8434, -3.3349],
        [-2.0552, -2.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19684937596321106
Epoch 0, Step 1475: train/loss = 0.4004412889480591, train/raw-loss = 0.3500373959541321, train/logprobs = tensor([[-0.7139, -2.1912],
        [-2.1586, -1.1898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16801302134990692
Epoch 0, Step 1476: train/loss = 0.5366689562797546, train/raw-loss = 0.4733070731163025, train/logprobs = tensor([[-1.1977, -3.4604],
        [-2.4166, -3.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21120642125606537
Epoch 0, Step 1477: train/loss = 0.22360703349113464, train/raw-loss = 0.1622539460659027, train/logprobs = tensor([[-1.1530, -5.6446],
        [-2.8140, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20451036095619202
Epoch 0, Step 1478: train/loss = 0.6329665780067444, train/raw-loss = 0.5612969994544983, train/logprobs = tensor([[-0.5063, -1.0850],
        [-2.2197, -1.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2388986051082611
Epoch 0, Step 1479: train/loss = 0.5515689849853516, train/raw-loss = 0.4703243374824524, train/logprobs = tensor([[-0.5829, -2.6869],
        [-2.3102, -2.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708152234554291
Epoch 0, Step 1480: train/loss = 0.447770893573761, train/raw-loss = 0.37963443994522095, train/logprobs = tensor([[-0.8853, -4.3203],
        [-3.5315, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22712154686450958
Epoch 0, Step 1481: train/loss = 0.3758876323699951, train/raw-loss = 0.3175622224807739, train/logprobs = tensor([[-0.8220, -4.6692],
        [-2.3242, -1.7752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1944180428981781
Epoch 0, Step 1482: train/loss = 0.34519752860069275, train/raw-loss = 0.2828799784183502, train/logprobs = tensor([[-0.6941, -6.4290],
        [-2.2748, -2.7641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20772522687911987
Epoch 0, Step 1483: train/loss = 0.3379848003387451, train/raw-loss = 0.2788715064525604, train/logprobs = tensor([[-0.7698, -3.6003],
        [-2.9929, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19704440236091614
Epoch 0, Step 1484: train/loss = 0.23034778237342834, train/raw-loss = 0.16617324948310852, train/logprobs = tensor([[-0.4829, -5.1297],
        [-2.4191, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21391507983207703
Epoch 0, Step 1485: train/loss = 0.4831010401248932, train/raw-loss = 0.4322640001773834, train/logprobs = tensor([[-0.7679, -2.5492],
        [-1.3883, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16945677995681763
Epoch 0, Step 1486: train/loss = 0.5888749957084656, train/raw-loss = 0.523899257183075, train/logprobs = tensor([[-1.0140, -2.2757],
        [-1.4922, -1.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21658584475517273
Epoch 0, Step 1487: train/loss = 0.25391972064971924, train/raw-loss = 0.2023073136806488, train/logprobs = tensor([[-1.2716, -4.7745],
        [-2.7723, -1.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17204132676124573
Epoch 0, Step 1488: train/loss = 0.5682932734489441, train/raw-loss = 0.5056387782096863, train/logprobs = tensor([[-0.4409, -1.6921],
        [-1.7013, -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20884832739830017
Epoch 0, Step 1489: train/loss = 0.46791037917137146, train/raw-loss = 0.4206787347793579, train/logprobs = tensor([[-0.8680, -3.1823],
        [-1.7239, -1.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15743884444236755
Epoch 0, Step 1490: train/loss = 0.41407227516174316, train/raw-loss = 0.3627687692642212, train/logprobs = tensor([[-0.5156, -2.9243],
        [-1.7873, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17101162672042847
Epoch 0, Step 1491: train/loss = 0.2638172507286072, train/raw-loss = 0.19662173092365265, train/logprobs = tensor([[-1.1285, -5.7780],
        [-2.9593, -1.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2239849865436554
Epoch 0, Step 1492: train/loss = 0.42649656534194946, train/raw-loss = 0.3662187457084656, train/logprobs = tensor([[-0.6933, -3.6350],
        [-2.2129, -1.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20092597603797913
Epoch 0, Step 1493: train/loss = 0.34354764223098755, train/raw-loss = 0.28174111247062683, train/logprobs = tensor([[-0.6918, -3.0665],
        [-2.8509, -1.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2060217708349228
Epoch 0, Step 1494: train/loss = 0.21641820669174194, train/raw-loss = 0.13214078545570374, train/logprobs = tensor([[-0.6347, -4.9584],
        [-3.0587, -1.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2809247672557831
Epoch 0, Step 1495: train/loss = 0.25660017132759094, train/raw-loss = 0.18076887726783752, train/logprobs = tensor([[-0.5461, -6.7313],
        [-2.6065, -2.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25277096033096313
Epoch 0, Step 1496: train/loss = 0.26333844661712646, train/raw-loss = 0.20712757110595703, train/logprobs = tensor([[-0.7936, -5.2038],
        [-1.9691, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18736958503723145
Epoch 0, Step 1497: train/loss = 0.3772599995136261, train/raw-loss = 0.3292636275291443, train/logprobs = tensor([[-0.5733, -2.9356],
        [-1.8644, -1.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15998786687850952
Epoch 0, Step 1498: train/loss = 0.3180757164955139, train/raw-loss = 0.253121018409729, train/logprobs = tensor([[-0.7548, -3.0453],
        [-3.0812, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2165156602859497
Epoch 0, Step 1499: train/loss = 0.40699589252471924, train/raw-loss = 0.35081592202186584, train/logprobs = tensor([[-1.3869, -3.1574],
        [-2.6371, -1.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18726663291454315
Epoch 0, Step 1500: train/loss = 0.5089155435562134, train/raw-loss = 0.47786325216293335, train/logprobs = tensor([[-0.3366, -3.3479],
        [-0.6078, -1.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350773483514786
Epoch 0, Step 1501: train/loss = 0.270671010017395, train/raw-loss = 0.18884773552417755, train/logprobs = tensor([[-0.5431, -5.0094],
        [-3.6774, -1.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727442681789398
Epoch 0, Step 1502: train/loss = 0.15188035368919373, train/raw-loss = 0.07766124606132507, train/logprobs = tensor([[-0.9106, -6.5453],
        [-3.0502, -1.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24739700555801392
Epoch 0, Step 1503: train/loss = 0.44535738229751587, train/raw-loss = 0.3806602358818054, train/logprobs = tensor([[-0.9371, -3.0742],
        [-2.9651, -1.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156570553779602
Epoch 0, Step 1504: train/loss = 0.3612194359302521, train/raw-loss = 0.30356234312057495, train/logprobs = tensor([[-0.5889, -4.4827],
        [-1.8848, -1.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19219036400318146
Epoch 0, Step 1505: train/loss = 0.27727165818214417, train/raw-loss = 0.2205963432788849, train/logprobs = tensor([[-0.7247, -4.9464],
        [-2.4785, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18891771137714386
Epoch 0, Step 1506: train/loss = 0.22618304193019867, train/raw-loss = 0.16587987542152405, train/logprobs = tensor([[-0.6612, -3.9071],
        [-3.0059, -1.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2010105848312378
Epoch 0, Step 1507: train/loss = 0.40424078702926636, train/raw-loss = 0.33437666296958923, train/logprobs = tensor([[-0.5373, -2.8165],
        [-1.7973, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23288042843341827
Epoch 0, Step 1508: train/loss = 0.4888441562652588, train/raw-loss = 0.4244069755077362, train/logprobs = tensor([[-1.0555, -3.4920],
        [-2.2032, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21479058265686035
Epoch 0, Step 1509: train/loss = 0.49125009775161743, train/raw-loss = 0.4365600049495697, train/logprobs = tensor([[-0.9157, -2.3075],
        [-2.1510, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18230040371418
Epoch 0, Step 1510: train/loss = 0.46230873465538025, train/raw-loss = 0.39433372020721436, train/logprobs = tensor([[-0.5689, -5.3519],
        [-1.6813, -2.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22658339142799377
Epoch 0, Step 1511: train/loss = 0.1978451907634735, train/raw-loss = 0.14129774272441864, train/logprobs = tensor([[-1.0764, -5.9591],
        [-2.6115, -1.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18849149346351624
Epoch 0, Step 1512: train/loss = 0.42847907543182373, train/raw-loss = 0.36754491925239563, train/logprobs = tensor([[-0.6915, -2.7488],
        [-1.9691, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20311371982097626
Epoch 0, Step 1513: train/loss = 0.29643917083740234, train/raw-loss = 0.23297645151615143, train/logprobs = tensor([[-0.5688, -4.5227],
        [-2.3110, -1.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21154235303401947
Epoch 0, Step 1514: train/loss = 0.45105409622192383, train/raw-loss = 0.39542484283447266, train/logprobs = tensor([[-1.3486, -6.9445],
        [-2.0484, -1.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1854308396577835
Epoch 0, Step 1515: train/loss = 0.25796017050743103, train/raw-loss = 0.19579121470451355, train/logprobs = tensor([[-0.7350, -4.2825],
        [-2.9699, -1.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2072298675775528
Epoch 0, Step 1516: train/loss = 0.6437321901321411, train/raw-loss = 0.6026235222816467, train/logprobs = tensor([[-0.6521, -0.7803],
        [-1.6260, -1.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13702872395515442
Epoch 0, Step 1517: train/loss = 0.17880278825759888, train/raw-loss = 0.1232076957821846, train/logprobs = tensor([[ -0.8907, -10.8736],
        [ -3.2606,  -3.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18531693518161774
Epoch 0, Step 1518: train/loss = 0.46341800689697266, train/raw-loss = 0.4171329736709595, train/logprobs = tensor([[-1.5435, -3.7552],
        [-1.8552, -0.7465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15428346395492554
Epoch 0, Step 1519: train/loss = 0.5650836825370789, train/raw-loss = 0.5101303458213806, train/logprobs = tensor([[-0.7047, -2.1566],
        [-1.6881, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183177649974823
Epoch 0, Step 1520: train/loss = 0.20570522546768188, train/raw-loss = 0.13165761530399323, train/logprobs = tensor([[-0.7241, -7.3652],
        [-3.3382, -2.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24682536721229553
Epoch 0, Step 1521: train/loss = 0.4267568290233612, train/raw-loss = 0.3760402500629425, train/logprobs = tensor([[-1.6403, -2.1730],
        [-2.9622, -1.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16905534267425537
Epoch 0, Step 1522: train/loss = 0.42255622148513794, train/raw-loss = 0.3789353370666504, train/logprobs = tensor([[ -2.0207, -10.1442],
        [ -2.7037,  -2.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14540283381938934
Epoch 0, Step 1523: train/loss = 0.17259082198143005, train/raw-loss = 0.11730419099330902, train/logprobs = tensor([[-0.9324, -5.4383],
        [-3.7743, -2.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18428874015808105
Epoch 0, Step 1524: train/loss = 0.3536251485347748, train/raw-loss = 0.2866913676261902, train/logprobs = tensor([[-0.8623, -3.1900],
        [-2.5795, -1.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22311262786388397
Epoch 0, Step 1525: train/loss = 0.7690909504890442, train/raw-loss = 0.705544650554657, train/logprobs = tensor([[-0.6316, -0.7023],
        [-1.7209, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21182096004486084
Epoch 0, Step 1526: train/loss = 0.4533103406429291, train/raw-loss = 0.4059789776802063, train/logprobs = tensor([[-0.5876, -2.7716],
        [-1.6550, -1.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1577712893486023
Epoch 0, Step 1527: train/loss = 0.43873661756515503, train/raw-loss = 0.365072637796402, train/logprobs = tensor([[-1.3907, -2.5293],
        [-2.2370, -1.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24554651975631714
Epoch 0, Step 1528: train/loss = 0.21906813979148865, train/raw-loss = 0.15661048889160156, train/logprobs = tensor([[-0.4800, -4.9910],
        [-2.7565, -2.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20819216966629028
Epoch 0, Step 1529: train/loss = 0.44104093313217163, train/raw-loss = 0.37419676780700684, train/logprobs = tensor([[-0.7640, -3.5312],
        [-2.7406, -1.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2228139340877533
Epoch 0, Step 1530: train/loss = 0.26443415880203247, train/raw-loss = 0.1942034214735031, train/logprobs = tensor([[-0.7608, -4.8866],
        [-3.2663, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23410239815711975
Epoch 0, Step 1531: train/loss = 0.42586004734039307, train/raw-loss = 0.366011381149292, train/logprobs = tensor([[-0.6322, -4.3630],
        [-2.2075, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994955837726593
Epoch 0, Step 1532: train/loss = 0.5071830153465271, train/raw-loss = 0.4517817497253418, train/logprobs = tensor([[-0.7371, -3.3710],
        [-1.4799, -1.1646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1846708506345749
Epoch 0, Step 1533: train/loss = 0.3381844162940979, train/raw-loss = 0.29500889778137207, train/logprobs = tensor([[-0.4002, -3.1961],
        [-1.6335, -1.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14391839504241943
Epoch 0, Step 1534: train/loss = 0.346103310585022, train/raw-loss = 0.2841184437274933, train/logprobs = tensor([[-1.5734, -5.8822],
        [-2.5066, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20661619305610657
Epoch 0, Step 1535: train/loss = 0.48179519176483154, train/raw-loss = 0.41047704219818115, train/logprobs = tensor([[-0.6894, -2.4281],
        [-2.3522, -2.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2377271205186844
Epoch 0, Step 1536: train/loss = 0.3537784218788147, train/raw-loss = 0.303555428981781, train/logprobs = tensor([[-0.5558, -5.2911],
        [-1.6441, -1.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1674100160598755
Epoch 0, Step 1537: train/loss = 0.40166419744491577, train/raw-loss = 0.3406426012516022, train/logprobs = tensor([[-1.4994, -3.3340],
        [-1.9304, -1.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20340533554553986
Epoch 0, Step 1538: train/loss = 0.35915398597717285, train/raw-loss = 0.30415141582489014, train/logprobs = tensor([[-0.5707, -5.6837],
        [-2.2148, -2.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18334193527698517
Epoch 0, Step 1539: train/loss = 0.5162554979324341, train/raw-loss = 0.45011305809020996, train/logprobs = tensor([[-0.6596, -2.2735],
        [-1.7597, -1.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2204747051000595
Epoch 0, Step 1540: train/loss = 0.3305201232433319, train/raw-loss = 0.26885151863098145, train/logprobs = tensor([[-1.0805, -4.7183],
        [-2.7749, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20556201040744781
Epoch 0, Step 1541: train/loss = 0.17846918106079102, train/raw-loss = 0.11647363752126694, train/logprobs = tensor([[-0.7162, -8.9317],
        [-2.8549, -1.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20665177702903748
Epoch 0, Step 1542: train/loss = 0.6592901349067688, train/raw-loss = 0.6149097681045532, train/logprobs = tensor([[-0.7929, -0.8265],
        [-1.0742, -0.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14793455600738525
Epoch 0, Step 1543: train/loss = 0.47790220379829407, train/raw-loss = 0.4149402976036072, train/logprobs = tensor([[-0.6028, -2.4838],
        [-2.8637, -1.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20987312495708466
Epoch 0, Step 1544: train/loss = 0.38266217708587646, train/raw-loss = 0.31113800406455994, train/logprobs = tensor([[-0.8070, -5.3653],
        [-3.8909, -1.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23841382563114166
Epoch 0, Step 1545: train/loss = 0.38953834772109985, train/raw-loss = 0.32627397775650024, train/logprobs = tensor([[-1.0438, -3.4079],
        [-2.3626, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21088135242462158
Epoch 0, Step 1546: train/loss = 0.49075448513031006, train/raw-loss = 0.4264248013496399, train/logprobs = tensor([[-0.6724, -2.6420],
        [-2.2468, -1.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21443232893943787
Epoch 0, Step 1547: train/loss = 0.4793250858783722, train/raw-loss = 0.4273853302001953, train/logprobs = tensor([[-0.6693, -2.5985],
        [-1.8844, -1.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17313233017921448
Epoch 0, Step 1548: train/loss = 0.43767857551574707, train/raw-loss = 0.38302990794181824, train/logprobs = tensor([[-0.5000, -4.6682],
        [-1.4234, -2.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18216226994991302
Epoch 0, Step 1549: train/loss = 0.5164597034454346, train/raw-loss = 0.4622771441936493, train/logprobs = tensor([[-0.4984, -2.6849],
        [-1.8952, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18060854077339172
Epoch 0, Step 1550: train/loss = 0.5360268950462341, train/raw-loss = 0.48138725757598877, train/logprobs = tensor([[-0.8106, -1.8574],
        [-1.9552, -1.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18213212490081787
Epoch 0, Step 1551: train/loss = 0.2335851639509201, train/raw-loss = 0.1696232557296753, train/logprobs = tensor([[-0.6551, -5.0042],
        [-2.2160, -2.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21320630609989166
Epoch 0, Step 1552: train/loss = 0.34728601574897766, train/raw-loss = 0.2860282063484192, train/logprobs = tensor([[-0.8498, -9.7695],
        [-2.5189, -3.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20419271290302277
Epoch 0, Step 1553: train/loss = 0.3133357763290405, train/raw-loss = 0.248775914311409, train/logprobs = tensor([[-0.8799, -4.3213],
        [-2.2151, -1.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151995599269867
Epoch 0, Step 1554: train/loss = 0.49046963453292847, train/raw-loss = 0.4323706030845642, train/logprobs = tensor([[-0.8585, -2.6429],
        [-1.8687, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19366341829299927
Epoch 0, Step 1555: train/loss = 0.2753709554672241, train/raw-loss = 0.2123529314994812, train/logprobs = tensor([[-1.2047, -3.9379],
        [-2.8662, -1.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21006010472774506
Epoch 0, Step 1556: train/loss = 0.39389121532440186, train/raw-loss = 0.33935457468032837, train/logprobs = tensor([[-0.5204, -7.6045],
        [-1.5372, -2.2461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1817888766527176
Epoch 0, Step 1557: train/loss = 0.3241347074508667, train/raw-loss = 0.27335211634635925, train/logprobs = tensor([[-0.6567, -6.2699],
        [-1.5976, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16927528381347656
Epoch 0, Step 1558: train/loss = 0.2667309641838074, train/raw-loss = 0.20526212453842163, train/logprobs = tensor([[-0.6383, -8.1932],
        [-2.6065, -2.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20489616692066193
Epoch 0, Step 1559: train/loss = 0.40252768993377686, train/raw-loss = 0.3421037197113037, train/logprobs = tensor([[-1.4003, -3.5363],
        [-3.3894, -1.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20141324400901794
Epoch 0, Step 1560: train/loss = 0.21619544923305511, train/raw-loss = 0.1613178551197052, train/logprobs = tensor([[-0.8389, -5.9020],
        [-2.1794, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829252541065216
Epoch 0, Step 1561: train/loss = 0.2562158703804016, train/raw-loss = 0.17359969019889832, train/logprobs = tensor([[-1.0862, -4.5859],
        [-4.3292, -1.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27538731694221497
Epoch 0, Step 1562: train/loss = 0.47490471601486206, train/raw-loss = 0.40802231431007385, train/logprobs = tensor([[-2.7842, -8.3992],
        [-2.9619, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2229412943124771
Epoch 0, Step 1563: train/loss = 0.596347987651825, train/raw-loss = 0.5274451971054077, train/logprobs = tensor([[-0.8752, -1.6213],
        [-2.1171, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22967597842216492
Epoch 0, Step 1564: train/loss = 0.3220931887626648, train/raw-loss = 0.265285849571228, train/logprobs = tensor([[-0.7602, -4.4590],
        [-3.1626, -1.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18935763835906982
Epoch 0, Step 1565: train/loss = 0.5400549173355103, train/raw-loss = 0.4840601682662964, train/logprobs = tensor([[-1.0291, -1.6951],
        [-2.2034, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866491734981537
Epoch 0, Step 1566: train/loss = 0.2685772478580475, train/raw-loss = 0.19385705888271332, train/logprobs = tensor([[-0.6592, -5.5423],
        [-2.9551, -2.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24906721711158752
Epoch 0, Step 1567: train/loss = 0.5642319917678833, train/raw-loss = 0.5167717933654785, train/logprobs = tensor([[-0.4793, -3.0654],
        [-1.4653, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15820074081420898
Epoch 0, Step 1568: train/loss = 0.4000662565231323, train/raw-loss = 0.33863168954849243, train/logprobs = tensor([[-1.8508, -8.1016],
        [-2.6058, -1.5254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20478174090385437
Epoch 0, Step 1569: train/loss = 0.45825937390327454, train/raw-loss = 0.39123275876045227, train/logprobs = tensor([[-1.4450, -3.5685],
        [-2.0130, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22342199087142944
Epoch 0, Step 1570: train/loss = 0.40847381949424744, train/raw-loss = 0.3504768908023834, train/logprobs = tensor([[-0.8767, -3.4425],
        [-1.8973, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.193323016166687
Epoch 0, Step 1571: train/loss = 0.3980548083782196, train/raw-loss = 0.338603675365448, train/logprobs = tensor([[-0.7240, -2.3093],
        [-2.0034, -0.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19817045331001282
Epoch 0, Step 1572: train/loss = 0.27109792828559875, train/raw-loss = 0.20350879430770874, train/logprobs = tensor([[-0.7849, -4.9133],
        [-2.5724, -0.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22529707849025726
Epoch 0, Step 1573: train/loss = 0.22660338878631592, train/raw-loss = 0.17591111361980438, train/logprobs = tensor([[-0.8904, -5.7400],
        [-3.3164, -1.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897425055503845
Epoch 0, Step 1574: train/loss = 0.34532079100608826, train/raw-loss = 0.27898964285850525, train/logprobs = tensor([[-0.6319, -4.6824],
        [-2.9084, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22110380232334137
Epoch 0, Step 1575: train/loss = 0.36649253964424133, train/raw-loss = 0.3050929307937622, train/logprobs = tensor([[-0.9059, -3.7921],
        [-2.7530, -1.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2046654224395752
Epoch 0, Step 1576: train/loss = 0.7478290796279907, train/raw-loss = 0.7029235363006592, train/logprobs = tensor([[-0.5023, -0.6612],
        [-0.8023, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968489110469818
Epoch 0, Step 1577: train/loss = 0.531872570514679, train/raw-loss = 0.46188127994537354, train/logprobs = tensor([[-0.7373, -1.6122],
        [-2.1307, -1.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23330429196357727
Epoch 0, Step 1578: train/loss = 0.2825002670288086, train/raw-loss = 0.2377893179655075, train/logprobs = tensor([[-1.4083, -9.3865],
        [-2.1535, -1.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14903660118579865
Epoch 0, Step 1579: train/loss = 0.4297163784503937, train/raw-loss = 0.36656075716018677, train/logprobs = tensor([[-0.5764, -4.8456],
        [-2.4940, -1.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21051865816116333
Epoch 0, Step 1580: train/loss = 0.348944753408432, train/raw-loss = 0.28946515917778015, train/logprobs = tensor([[-0.4664, -2.8630],
        [-1.9784, -1.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19826534390449524
Epoch 0, Step 1581: train/loss = 0.1838366538286209, train/raw-loss = 0.11461694538593292, train/logprobs = tensor([[-0.9637, -3.5746],
        [-3.8164, -1.2722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23073235154151917
Epoch 0, Step 1582: train/loss = 0.17834237217903137, train/raw-loss = 0.12636888027191162, train/logprobs = tensor([[-1.0718, -8.0229],
        [-3.2130, -1.3971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17324495315551758
Epoch 0, Step 1583: train/loss = 0.42864376306533813, train/raw-loss = 0.36123204231262207, train/logprobs = tensor([[-0.8524, -6.3788],
        [-4.0460, -2.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22470566630363464
Epoch 0, Step 1584: train/loss = 0.20729807019233704, train/raw-loss = 0.15073691308498383, train/logprobs = tensor([[-1.1658, -6.4656],
        [-2.5189, -1.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18853716552257538
Epoch 0, Step 1585: train/loss = 0.2367003858089447, train/raw-loss = 0.15111057460308075, train/logprobs = tensor([[-0.9751, -4.1054],
        [-2.8559, -1.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2852994203567505
Epoch 0, Step 1586: train/loss = 0.34280073642730713, train/raw-loss = 0.27637729048728943, train/logprobs = tensor([[-0.7623, -6.1685],
        [-2.5374, -1.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22141140699386597
Epoch 0, Step 1587: train/loss = 0.15420770645141602, train/raw-loss = 0.082321897149086, train/logprobs = tensor([[-0.8742, -4.8429],
        [-3.0726, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23961934447288513
Epoch 0, Step 1588: train/loss = 0.3098183870315552, train/raw-loss = 0.26452895998954773, train/logprobs = tensor([[-0.5470, -4.4359],
        [-1.7820, -1.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15096476674079895
Epoch 0, Step 1589: train/loss = 0.3754636347293854, train/raw-loss = 0.32270193099975586, train/logprobs = tensor([[-0.7874, -4.9979],
        [-1.9222, -1.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17587226629257202
Epoch 0, Step 1590: train/loss = 0.3902486562728882, train/raw-loss = 0.34566745162010193, train/logprobs = tensor([[-0.6584, -5.9122],
        [-1.0237, -1.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1486039161682129
Epoch 0, Step 1591: train/loss = 0.38551485538482666, train/raw-loss = 0.3166925609111786, train/logprobs = tensor([[-0.7014, -5.9303],
        [-2.7486, -4.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2294076532125473
Epoch 0, Step 1592: train/loss = 0.3415737748146057, train/raw-loss = 0.2715680003166199, train/logprobs = tensor([[-0.7944, -3.6825],
        [-1.9179, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23335251212120056
Epoch 0, Step 1593: train/loss = 0.2991911470890045, train/raw-loss = 0.2381148636341095, train/logprobs = tensor([[-0.8403, -6.1760],
        [-2.3199, -1.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2035875916481018
Epoch 0, Step 1594: train/loss = 0.30419814586639404, train/raw-loss = 0.22935053706169128, train/logprobs = tensor([[-0.7268, -4.0758],
        [-2.7241, -1.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24949198961257935
Epoch 0, Step 1595: train/loss = 0.3064316213130951, train/raw-loss = 0.2425861954689026, train/logprobs = tensor([[-0.6353, -3.7217],
        [-2.0598, -2.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21281802654266357
Epoch 0, Step 1596: train/loss = 0.32157623767852783, train/raw-loss = 0.24471387267112732, train/logprobs = tensor([[-0.7059, -7.6628],
        [-3.2669, -2.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562078833580017
Epoch 0, Step 1597: train/loss = 0.2494407445192337, train/raw-loss = 0.19235888123512268, train/logprobs = tensor([[-0.9607, -5.8348],
        [-3.3064, -2.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19027288258075714
Epoch 0, Step 1598: train/loss = 0.3431100845336914, train/raw-loss = 0.2955002784729004, train/logprobs = tensor([[-1.1083, -6.9179],
        [-2.0598, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15869933366775513
Epoch 0, Step 1599: train/loss = 0.1756320595741272, train/raw-loss = 0.09655725955963135, train/logprobs = tensor([[-0.6465, -8.6454],
        [-3.0297, -2.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26358267664909363
Epoch 0, Step 1600: train/loss = 0.3793014585971832, train/raw-loss = 0.32106947898864746, train/logprobs = tensor([[-1.3380, -6.0027],
        [-1.8803, -1.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19410663843154907
Epoch 0, Step 1601: train/loss = 0.14354681968688965, train/raw-loss = 0.08306458592414856, train/logprobs = tensor([[ -0.6264, -10.4746],
        [ -2.5689,  -4.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20160749554634094
Epoch 0, Step 1602: train/loss = 0.2809390425682068, train/raw-loss = 0.2112654149532318, train/logprobs = tensor([[-0.5833, -5.2244],
        [-2.0825, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23224537074565887
Epoch 0, Step 1603: train/loss = 0.5547066926956177, train/raw-loss = 0.5010904669761658, train/logprobs = tensor([[-0.5360, -2.8003],
        [-1.8077, -1.9002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17872081696987152
Epoch 0, Step 1604: train/loss = 0.2766273617744446, train/raw-loss = 0.22345206141471863, train/logprobs = tensor([[-0.5805, -6.0820],
        [-1.7589, -3.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17725101113319397
Epoch 0, Step 1605: train/loss = 0.44487446546554565, train/raw-loss = 0.3879348337650299, train/logprobs = tensor([[-0.9197, -4.0328],
        [-1.8489, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897987723350525
Epoch 0, Step 1606: train/loss = 0.2048530876636505, train/raw-loss = 0.15068143606185913, train/logprobs = tensor([[-0.7320, -7.7586],
        [-2.4201, -2.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18057218194007874
Epoch 0, Step 1607: train/loss = 0.32866525650024414, train/raw-loss = 0.26532694697380066, train/logprobs = tensor([[-0.8804, -3.6510],
        [-1.8548, -1.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21112759411334991
Epoch 0, Step 1608: train/loss = 0.39937976002693176, train/raw-loss = 0.33461958169937134, train/logprobs = tensor([[-0.9666, -8.0226],
        [-2.1551, -3.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21586720645427704
Epoch 0, Step 1609: train/loss = 0.4107920527458191, train/raw-loss = 0.35103583335876465, train/logprobs = tensor([[-1.1430, -7.8822],
        [-1.8597, -2.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1991872936487198
Epoch 0, Step 1610: train/loss = 0.5303961038589478, train/raw-loss = 0.47088658809661865, train/logprobs = tensor([[-1.2276, -3.9824],
        [-1.5795, -1.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1983649879693985
Epoch 0, Step 1611: train/loss = 0.3794291317462921, train/raw-loss = 0.32049477100372314, train/logprobs = tensor([[-0.8878, -2.2771],
        [-2.8649, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19644789397716522
Epoch 0, Step 1612: train/loss = 0.2591691315174103, train/raw-loss = 0.1899004578590393, train/logprobs = tensor([[-0.9192, -6.8405],
        [-3.0655, -1.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23089554905891418
Epoch 0, Step 1613: train/loss = 0.6154212951660156, train/raw-loss = 0.5538384318351746, train/logprobs = tensor([[-0.6203, -1.3788],
        [-1.4987, -1.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052764594554901
Epoch 0, Step 1614: train/loss = 0.2857568860054016, train/raw-loss = 0.2228303998708725, train/logprobs = tensor([[-1.7112, -7.0252],
        [-3.1872, -2.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20975489914417267
Epoch 0, Step 1615: train/loss = 0.36144763231277466, train/raw-loss = 0.3087238669395447, train/logprobs = tensor([[-0.6044, -7.1459],
        [-1.6134, -2.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1757458746433258
Epoch 0, Step 1616: train/loss = 0.41901862621307373, train/raw-loss = 0.358890175819397, train/logprobs = tensor([[-0.8070, -5.0687],
        [-2.9341, -2.6147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20042815804481506
Epoch 0, Step 1617: train/loss = 0.41357421875, train/raw-loss = 0.3675537705421448, train/logprobs = tensor([[-0.6913, -4.0749],
        [-1.7267, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534014195203781
Epoch 0, Step 1618: train/loss = 0.5269259214401245, train/raw-loss = 0.4718073308467865, train/logprobs = tensor([[-0.5946, -2.1271],
        [-1.8631, -1.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18372860550880432
Epoch 0, Step 1619: train/loss = 0.24751071631908417, train/raw-loss = 0.19542145729064941, train/logprobs = tensor([[-0.7302, -5.7894],
        [-1.8197, -1.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363089323043823
Epoch 0, Step 1620: train/loss = 0.35153427720069885, train/raw-loss = 0.2854214012622833, train/logprobs = tensor([[-0.8067, -3.9529],
        [-2.2312, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22037623822689056
Epoch 0, Step 1621: train/loss = 0.3475068211555481, train/raw-loss = 0.28574633598327637, train/logprobs = tensor([[-0.8922, -3.8457],
        [-2.4218, -1.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20586828887462616
Epoch 0, Step 1622: train/loss = 0.22223401069641113, train/raw-loss = 0.16102972626686096, train/logprobs = tensor([[-1.2228, -7.0435],
        [-2.8703, -1.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20401424169540405
Epoch 0, Step 1623: train/loss = 0.48785045742988586, train/raw-loss = 0.43186235427856445, train/logprobs = tensor([[-0.5118, -2.8226],
        [-1.7455, -1.4776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18662700057029724
Epoch 0, Step 1624: train/loss = 0.2170601785182953, train/raw-loss = 0.16755230724811554, train/logprobs = tensor([[-0.7147, -3.4364],
        [-2.4007, -0.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16502618789672852
Epoch 0, Step 1625: train/loss = 0.2568112015724182, train/raw-loss = 0.18743911385536194, train/logprobs = tensor([[-0.7912, -5.2977],
        [-2.6601, -1.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23124022781848907
Epoch 0, Step 1626: train/loss = 0.43989598751068115, train/raw-loss = 0.3929555118083954, train/logprobs = tensor([[-1.3894, -2.1903],
        [-2.3932, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15646834671497345
Epoch 0, Step 1627: train/loss = 0.3937382102012634, train/raw-loss = 0.3372430205345154, train/logprobs = tensor([[-1.5101, -4.2280],
        [-2.4327, -1.4430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18831729888916016
Epoch 0, Step 1628: train/loss = 0.29013359546661377, train/raw-loss = 0.2427968680858612, train/logprobs = tensor([[-0.7566, -6.7795],
        [-1.4837, -1.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15778911113739014
Epoch 0, Step 1629: train/loss = 0.44450658559799194, train/raw-loss = 0.39311909675598145, train/logprobs = tensor([[-0.8636, -3.7122],
        [-1.6636, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129164934158325
Epoch 0, Step 1630: train/loss = 0.4525986611843109, train/raw-loss = 0.39082518219947815, train/logprobs = tensor([[-0.7414, -2.0244],
        [-2.5148, -1.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2059115320444107
Epoch 0, Step 1631: train/loss = 0.17063438892364502, train/raw-loss = 0.11421820521354675, train/logprobs = tensor([[-0.5231, -8.1088],
        [-1.9310, -1.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1880539357662201
Epoch 0, Step 1632: train/loss = 0.34654122591018677, train/raw-loss = 0.280972421169281, train/logprobs = tensor([[-0.8880, -7.5365],
        [-2.2056, -1.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21856263279914856
Epoch 0, Step 1633: train/loss = 0.3165251612663269, train/raw-loss = 0.26655662059783936, train/logprobs = tensor([[-1.0347, -5.7816],
        [-3.0120, -1.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665617972612381
Epoch 0, Step 1634: train/loss = 0.4751235842704773, train/raw-loss = 0.4000459611415863, train/logprobs = tensor([[-1.1694, -3.3135],
        [-2.6864, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502587139606476
Epoch 0, Step 1635: train/loss = 0.3301320970058441, train/raw-loss = 0.25349611043930054, train/logprobs = tensor([[-0.6451, -6.9068],
        [-3.4496, -1.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25545328855514526
Epoch 0, Step 1636: train/loss = 0.29174527525901794, train/raw-loss = 0.21604245901107788, train/logprobs = tensor([[-0.5590, -5.9499],
        [-2.2080, -1.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523426413536072
Epoch 0, Step 1637: train/loss = 0.3539242148399353, train/raw-loss = 0.29408755898475647, train/logprobs = tensor([[-0.8586, -7.0328],
        [-3.0698, -2.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19945554435253143
Epoch 0, Step 1638: train/loss = 0.29095351696014404, train/raw-loss = 0.22954103350639343, train/logprobs = tensor([[-0.7828, -6.4361],
        [-2.7877, -2.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20470832288265228
Epoch 0, Step 1639: train/loss = 0.4337001442909241, train/raw-loss = 0.3854037821292877, train/logprobs = tensor([[-0.9299, -6.6628],
        [-1.3562, -1.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1609879732131958
Epoch 0, Step 1640: train/loss = 0.32184550166130066, train/raw-loss = 0.25723230838775635, train/logprobs = tensor([[-0.6292, -6.3838],
        [-1.9964, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21537728607654572
Epoch 0, Step 1641: train/loss = 0.30360791087150574, train/raw-loss = 0.2573155164718628, train/logprobs = tensor([[-0.3934, -5.8581],
        [-2.1955, -2.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15430808067321777
Epoch 0, Step 1642: train/loss = 0.28890368342399597, train/raw-loss = 0.22655808925628662, train/logprobs = tensor([[-0.7716, -5.7412],
        [-3.0703, -3.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2078186273574829
Epoch 0, Step 1643: train/loss = 0.36389800906181335, train/raw-loss = 0.3127707540988922, train/logprobs = tensor([[-1.3701, -7.8119],
        [-2.7180, -1.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17042413353919983
Epoch 0, Step 1644: train/loss = 0.35680654644966125, train/raw-loss = 0.28809091448783875, train/logprobs = tensor([[-1.1696, -5.5433],
        [-2.5746, -1.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22905200719833374
Epoch 0, Step 1645: train/loss = 0.17437392473220825, train/raw-loss = 0.1143091470003128, train/logprobs = tensor([[ -0.7532, -11.0189],
        [ -2.8909,  -1.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20021593570709229
Epoch 0, Step 1646: train/loss = 0.525126576423645, train/raw-loss = 0.46617773175239563, train/logprobs = tensor([[-1.0196, -2.4908],
        [-1.7559, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19649627804756165
Epoch 0, Step 1647: train/loss = 0.31454163789749146, train/raw-loss = 0.2565203309059143, train/logprobs = tensor([[-0.5642, -2.8091],
        [-1.9263, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19340431690216064
Epoch 0, Step 1648: train/loss = 0.3698141574859619, train/raw-loss = 0.3145109713077545, train/logprobs = tensor([[-0.6072, -2.5669],
        [-1.9346, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1843441277742386
Epoch 0, Step 1649: train/loss = 0.36208993196487427, train/raw-loss = 0.30295848846435547, train/logprobs = tensor([[-0.5622, -6.0714],
        [-2.2652, -1.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.197104811668396
Epoch 0, Step 1650: train/loss = 0.40887704491615295, train/raw-loss = 0.35365185141563416, train/logprobs = tensor([[-0.7215, -4.6435],
        [-1.7543, -1.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.184083953499794
Epoch 0, Step 1651: train/loss = 0.25986066460609436, train/raw-loss = 0.19907712936401367, train/logprobs = tensor([[-0.6927, -4.3461],
        [-2.3440, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20261172950267792
Epoch 0, Step 1652: train/loss = 0.5627349615097046, train/raw-loss = 0.5053571462631226, train/logprobs = tensor([[-0.4975, -3.2353],
        [-1.5549, -1.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19125938415527344
Epoch 0, Step 1653: train/loss = 0.3167807459831238, train/raw-loss = 0.248843714594841, train/logprobs = tensor([[-0.5737, -4.2457],
        [-2.1547, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22645685076713562
Epoch 0, Step 1654: train/loss = 0.3537827432155609, train/raw-loss = 0.3010929524898529, train/logprobs = tensor([[-1.0726, -6.5618],
        [-1.8967, -1.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17563265562057495
Epoch 0, Step 1655: train/loss = 0.28217774629592896, train/raw-loss = 0.21932771801948547, train/logprobs = tensor([[-0.5815, -8.1062],
        [-2.0632, -2.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20950007438659668
Epoch 0, Step 1656: train/loss = 0.2537865936756134, train/raw-loss = 0.1822267472743988, train/logprobs = tensor([[-0.6322, -3.7564],
        [-3.0769, -0.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23853275179862976
Epoch 0, Step 1657: train/loss = 0.4533424973487854, train/raw-loss = 0.3793838918209076, train/logprobs = tensor([[-1.0063, -2.5784],
        [-3.4153, -2.0185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24652869999408722
Epoch 0, Step 1658: train/loss = 0.5313405394554138, train/raw-loss = 0.47904640436172485, train/logprobs = tensor([[-0.8873, -3.2266],
        [-2.3322, -2.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1743137687444687
Epoch 0, Step 1659: train/loss = 0.3052203357219696, train/raw-loss = 0.23208490014076233, train/logprobs = tensor([[-0.9394, -3.3944],
        [-3.3783, -1.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2437848150730133
Epoch 0, Step 1660: train/loss = 0.23563122749328613, train/raw-loss = 0.1820971816778183, train/logprobs = tensor([[-0.9896, -6.5604],
        [-2.3959, -1.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17844676971435547
Epoch 0, Step 1661: train/loss = 0.655722975730896, train/raw-loss = 0.6029964685440063, train/logprobs = tensor([[-1.0772, -2.0358],
        [-1.5252, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17575496435165405
Epoch 0, Step 1662: train/loss = 0.2463689148426056, train/raw-loss = 0.18113350868225098, train/logprobs = tensor([[-0.9714, -7.7153],
        [-2.8804, -1.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21745142340660095
Epoch 0, Step 1663: train/loss = 0.2746964693069458, train/raw-loss = 0.21964110434055328, train/logprobs = tensor([[-0.9379, -2.9581],
        [-2.9137, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1835179328918457
Epoch 0, Step 1664: train/loss = 0.41731396317481995, train/raw-loss = 0.3409324884414673, train/logprobs = tensor([[-0.7588, -2.0325],
        [-2.4547, -1.1564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25460493564605713
Epoch 0, Step 1665: train/loss = 0.3303040862083435, train/raw-loss = 0.26325753331184387, train/logprobs = tensor([[-1.7363, -4.8854],
        [-2.7521, -1.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234884649515152
Epoch 0, Step 1666: train/loss = 0.4086601734161377, train/raw-loss = 0.35972487926483154, train/logprobs = tensor([[-0.8620, -2.9731],
        [-2.0105, -0.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1631176769733429
Epoch 0, Step 1667: train/loss = 0.2268790304660797, train/raw-loss = 0.17999520897865295, train/logprobs = tensor([[-0.4750, -6.0334],
        [-1.9751, -0.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15627934038639069
Epoch 0, Step 1668: train/loss = 0.5380911231040955, train/raw-loss = 0.5047472715377808, train/logprobs = tensor([[-0.5824, -2.6073],
        [-0.5728, -1.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11114613711833954
Epoch 0, Step 1669: train/loss = 0.1625470221042633, train/raw-loss = 0.09291329234838486, train/logprobs = tensor([[-0.7483, -7.4698],
        [-2.7098, -1.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2321123629808426
Epoch 0, Step 1670: train/loss = 0.118891641497612, train/raw-loss = 0.05825948715209961, train/logprobs = tensor([[-0.7905, -7.8579],
        [-3.6444, -1.2417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20210717618465424
Epoch 0, Step 1671: train/loss = 0.3019944131374359, train/raw-loss = 0.2506219148635864, train/logprobs = tensor([[-1.6993, -4.9912],
        [-2.8331, -1.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17124168574810028
Epoch 0, Step 1672: train/loss = 0.44075435400009155, train/raw-loss = 0.38006576895713806, train/logprobs = tensor([[-1.1377, -3.7460],
        [-2.4340, -1.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20229533314704895
Epoch 0, Step 1673: train/loss = 0.3202093839645386, train/raw-loss = 0.26264289021492004, train/logprobs = tensor([[-0.6324, -3.5985],
        [-1.8998, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1918882429599762
Epoch 0, Step 1674: train/loss = 0.3799932301044464, train/raw-loss = 0.3375898599624634, train/logprobs = tensor([[-0.7705, -4.2009],
        [-1.4099, -1.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14134448766708374
Epoch 0, Step 1675: train/loss = 0.4058128893375397, train/raw-loss = 0.3513244092464447, train/logprobs = tensor([[-1.7094, -6.5959],
        [-2.1927, -2.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18162813782691956
Epoch 0, Step 1676: train/loss = 0.33473604917526245, train/raw-loss = 0.25207456946372986, train/logprobs = tensor([[-1.1250, -5.0455],
        [-3.5352, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27553820610046387
Epoch 0, Step 1677: train/loss = 0.34162506461143494, train/raw-loss = 0.3010413646697998, train/logprobs = tensor([[-0.8646, -5.0659],
        [-2.6779, -2.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13527899980545044
Epoch 0, Step 1678: train/loss = 0.3493083715438843, train/raw-loss = 0.2863028347492218, train/logprobs = tensor([[-0.8443, -3.6749],
        [-2.6534, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21001845598220825
Epoch 0, Step 1679: train/loss = 0.39229658246040344, train/raw-loss = 0.33333155512809753, train/logprobs = tensor([[-0.7768, -3.1314],
        [-2.3548, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19655008614063263
Epoch 0, Step 1680: train/loss = 0.4479646682739258, train/raw-loss = 0.39306342601776123, train/logprobs = tensor([[-0.6369, -2.6379],
        [-1.6831, -1.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1830042153596878
Epoch 0, Step 1681: train/loss = 0.27508577704429626, train/raw-loss = 0.22844809293746948, train/logprobs = tensor([[ -0.8221, -10.5875],
        [ -2.3030,  -1.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1554589420557022
Epoch 0, Step 1682: train/loss = 0.4447603225708008, train/raw-loss = 0.37867259979248047, train/logprobs = tensor([[-0.7223, -4.4404],
        [-2.0866, -1.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22029238939285278
Epoch 0, Step 1683: train/loss = 0.41693246364593506, train/raw-loss = 0.351204514503479, train/logprobs = tensor([[-1.6801, -4.3728],
        [-2.7884, -1.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21909312903881073
Epoch 0, Step 1684: train/loss = 0.4961060881614685, train/raw-loss = 0.44985514879226685, train/logprobs = tensor([[-0.5993, -1.4014],
        [-1.5675, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15416958928108215
Epoch 0, Step 1685: train/loss = 0.4139487147331238, train/raw-loss = 0.35971692204475403, train/logprobs = tensor([[-0.6019, -3.3119],
        [-2.0611, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18077270686626434
Epoch 0, Step 1686: train/loss = 0.19816075265407562, train/raw-loss = 0.1442684531211853, train/logprobs = tensor([[-0.8278, -8.7153],
        [-2.4695, -2.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1796410083770752
Epoch 0, Step 1687: train/loss = 0.34223702549934387, train/raw-loss = 0.2765286862850189, train/logprobs = tensor([[-0.7140, -4.6946],
        [-2.2036, -1.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2190277874469757
Epoch 0, Step 1688: train/loss = 0.4174715578556061, train/raw-loss = 0.35837626457214355, train/logprobs = tensor([[-1.0217, -6.5749],
        [-1.6527, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1969841569662094
Epoch 0, Step 1689: train/loss = 0.40185976028442383, train/raw-loss = 0.3416898846626282, train/logprobs = tensor([[-0.7542, -4.5681],
        [-2.1739, -1.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20056623220443726
Epoch 0, Step 1690: train/loss = 0.4407612085342407, train/raw-loss = 0.38476473093032837, train/logprobs = tensor([[-0.7304, -2.6074],
        [-1.4351, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18665486574172974
Epoch 0, Step 1691: train/loss = 0.49640750885009766, train/raw-loss = 0.4479413628578186, train/logprobs = tensor([[-1.3635, -4.2523],
        [-1.7091, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16155380010604858
Epoch 0, Step 1692: train/loss = 0.3040015697479248, train/raw-loss = 0.22663170099258423, train/logprobs = tensor([[-0.9595, -4.3514],
        [-3.1050, -1.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578994631767273
Epoch 0, Step 1693: train/loss = 0.42789775133132935, train/raw-loss = 0.36201146245002747, train/logprobs = tensor([[-1.0244, -3.7811],
        [-1.9882, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21962100267410278
Epoch 0, Step 1694: train/loss = 0.24386247992515564, train/raw-loss = 0.18959352374076843, train/logprobs = tensor([[-0.9043, -4.0559],
        [-2.8015, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18089652061462402
Epoch 0, Step 1695: train/loss = 0.6688861846923828, train/raw-loss = 0.6036896705627441, train/logprobs = tensor([[-1.0122, -3.8225],
        [-1.6437, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21732161939144135
Epoch 0, Step 1696: train/loss = 0.4615015387535095, train/raw-loss = 0.4024021625518799, train/logprobs = tensor([[-1.4034, -3.6298],
        [-1.8832, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19699791073799133
Epoch 0, Step 1697: train/loss = 0.5549317002296448, train/raw-loss = 0.511389970779419, train/logprobs = tensor([[-0.5101, -2.2602],
        [-1.0577, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1451389640569687
Epoch 0, Step 1698: train/loss = 0.4470985531806946, train/raw-loss = 0.39121612906455994, train/logprobs = tensor([[-1.0816, -3.6546],
        [-1.3529, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627478182315826
Epoch 0, Step 1699: train/loss = 0.41205477714538574, train/raw-loss = 0.35541993379592896, train/logprobs = tensor([[-0.8670, -4.2677],
        [-2.1122, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1887827217578888
Epoch 0, Step 1700: train/loss = 0.44236868619918823, train/raw-loss = 0.37189793586730957, train/logprobs = tensor([[-1.0396, -4.0759],
        [-1.8017, -1.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23490256071090698
Epoch 0, Step 1701: train/loss = 0.5051894187927246, train/raw-loss = 0.4486009180545807, train/logprobs = tensor([[-1.4941, -2.4393],
        [-2.5151, -2.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18862852454185486
Epoch 0, Step 1702: train/loss = 0.4158332347869873, train/raw-loss = 0.3469253182411194, train/logprobs = tensor([[-0.6122, -3.3029],
        [-2.2595, -2.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22969302535057068
Epoch 0, Step 1703: train/loss = 0.29891255497932434, train/raw-loss = 0.24177399277687073, train/logprobs = tensor([[-0.6908, -5.8585],
        [-2.4960, -2.4306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19046185910701752
Epoch 0, Step 1704: train/loss = 0.23638921976089478, train/raw-loss = 0.1688220500946045, train/logprobs = tensor([[-1.0802, -6.8729],
        [-2.8710, -1.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22522389888763428
Epoch 0, Step 1705: train/loss = 0.37747499346733093, train/raw-loss = 0.32050830125808716, train/logprobs = tensor([[-0.6994, -7.0123],
        [-2.0213, -1.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.189889058470726
Epoch 0, Step 1706: train/loss = 0.25314632058143616, train/raw-loss = 0.19277751445770264, train/logprobs = tensor([[-0.7446, -4.5022],
        [-3.2569, -1.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2012292444705963
Epoch 0, Step 1707: train/loss = 0.3974780738353729, train/raw-loss = 0.333196222782135, train/logprobs = tensor([[-0.8365, -2.8978],
        [-2.3103, -2.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21427282691001892
Epoch 0, Step 1708: train/loss = 0.4016292989253998, train/raw-loss = 0.34852275252342224, train/logprobs = tensor([[-0.9103, -3.5887],
        [-2.2005, -1.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770218312740326
Epoch 0, Step 1709: train/loss = 0.4747506082057953, train/raw-loss = 0.41499584913253784, train/logprobs = tensor([[-0.9965, -4.6472],
        [-1.6409, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19918248057365417
Epoch 0, Step 1710: train/loss = 0.38762715458869934, train/raw-loss = 0.32025665044784546, train/logprobs = tensor([[-0.8275, -4.2805],
        [-2.2619, -1.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22456836700439453
Epoch 0, Step 1711: train/loss = 0.20827600359916687, train/raw-loss = 0.13153862953186035, train/logprobs = tensor([[-0.8124, -6.6621],
        [-3.3445, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557912766933441
Epoch 0, Step 1712: train/loss = 0.1977803111076355, train/raw-loss = 0.14685827493667603, train/logprobs = tensor([[-0.4729, -9.2656],
        [-1.6313, -1.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16974009573459625
Epoch 0, Step 1713: train/loss = 0.2557399868965149, train/raw-loss = 0.19534295797348022, train/logprobs = tensor([[-0.8932, -4.9279],
        [-2.8823, -1.4405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20132336020469666
Epoch 0, Step 1714: train/loss = 0.5489019751548767, train/raw-loss = 0.4912380874156952, train/logprobs = tensor([[-1.0649, -2.6373],
        [-1.1367, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19221293926239014
Epoch 0, Step 1715: train/loss = 0.405194491147995, train/raw-loss = 0.3447621464729309, train/logprobs = tensor([[-0.8794, -2.8868],
        [-1.6376, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20144109427928925
Epoch 0, Step 1716: train/loss = 0.5546422600746155, train/raw-loss = 0.48768097162246704, train/logprobs = tensor([[-1.1905, -3.6239],
        [-1.7415, -2.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2232043445110321
Epoch 0, Step 1717: train/loss = 0.4189589023590088, train/raw-loss = 0.3621368408203125, train/logprobs = tensor([[-0.7684, -7.6862],
        [-2.1429, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894068568944931
Epoch 0, Step 1718: train/loss = 0.43835434317588806, train/raw-loss = 0.3826653063297272, train/logprobs = tensor([[-1.2512, -3.5266],
        [-2.1518, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18563032150268555
Epoch 0, Step 1719: train/loss = 0.3484872877597809, train/raw-loss = 0.2745375335216522, train/logprobs = tensor([[-0.8594, -7.0415],
        [-2.9651, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246499165892601
Epoch 0, Step 1720: train/loss = 0.7648664116859436, train/raw-loss = 0.7032023668289185, train/logprobs = tensor([[-2.2774, -3.5202],
        [-1.6807, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20554687082767487
Epoch 0, Step 1721: train/loss = 0.26605507731437683, train/raw-loss = 0.19332775473594666, train/logprobs = tensor([[-1.5284, -7.9268],
        [-3.6025, -3.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24242445826530457
Epoch 0, Step 1722: train/loss = 0.22609540820121765, train/raw-loss = 0.15906473994255066, train/logprobs = tensor([[-0.4633, -4.8292],
        [-3.0643, -1.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22343549132347107
Epoch 0, Step 1723: train/loss = 0.3834470510482788, train/raw-loss = 0.3064831495285034, train/logprobs = tensor([[-1.2235, -5.1094],
        [-3.0773, -2.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565462589263916
Epoch 0, Step 1724: train/loss = 0.3176335394382477, train/raw-loss = 0.26881492137908936, train/logprobs = tensor([[-1.3274, -7.6471],
        [-2.0583, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16272875666618347
Epoch 0, Step 1725: train/loss = 0.47494176030158997, train/raw-loss = 0.4128786027431488, train/logprobs = tensor([[-0.9522, -6.0287],
        [-2.1756, -1.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20687709748744965
Epoch 0, Step 1726: train/loss = 0.18933874368667603, train/raw-loss = 0.13069745898246765, train/logprobs = tensor([[-0.8832, -6.6038],
        [-2.4678, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19547095894813538
Epoch 0, Step 1727: train/loss = 0.2652530372142792, train/raw-loss = 0.2063099890947342, train/logprobs = tensor([[-0.7998, -4.5306],
        [-2.4153, -1.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19647686183452606
Epoch 0, Step 1728: train/loss = 0.5612276792526245, train/raw-loss = 0.5185836553573608, train/logprobs = tensor([[-0.9955, -3.5026],
        [-0.9703, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14214691519737244
Epoch 0, Step 1729: train/loss = 0.18719741702079773, train/raw-loss = 0.12631745636463165, train/logprobs = tensor([[-1.1168, -8.2470],
        [-2.3682, -1.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20293326675891876
Epoch 0, Step 1730: train/loss = 0.6904526352882385, train/raw-loss = 0.6212629675865173, train/logprobs = tensor([[-1.1132, -1.9783],
        [-1.9066, -1.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23063218593597412
Epoch 0, Step 1731: train/loss = 0.5638435482978821, train/raw-loss = 0.5133625268936157, train/logprobs = tensor([[-0.5806, -3.1588],
        [-1.7511, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16827015578746796
Epoch 0, Step 1732: train/loss = 0.3916899263858795, train/raw-loss = 0.3363212049007416, train/logprobs = tensor([[-1.0805, -7.9500],
        [-1.9521, -1.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18456241488456726
Epoch 0, Step 1733: train/loss = 0.40993139147758484, train/raw-loss = 0.3583446443080902, train/logprobs = tensor([[-0.5561, -3.8338],
        [-1.4441, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17195577919483185
Epoch 0, Step 1734: train/loss = 0.4201485514640808, train/raw-loss = 0.36973294615745544, train/logprobs = tensor([[-1.3819, -5.6074],
        [-1.3949, -1.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16805194318294525
Epoch 0, Step 1735: train/loss = 0.22664187848567963, train/raw-loss = 0.1782797873020172, train/logprobs = tensor([[-1.0883, -6.2783],
        [-2.1852, -1.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612069308757782
Epoch 0, Step 1736: train/loss = 0.2345927655696869, train/raw-loss = 0.1553495228290558, train/logprobs = tensor([[-1.2294, -6.6137],
        [-3.1004, -1.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641441226005554
Epoch 0, Step 1737: train/loss = 0.19774381816387177, train/raw-loss = 0.1274263560771942, train/logprobs = tensor([[-0.8060, -8.3486],
        [-3.4772, -2.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23439152538776398
Epoch 0, Step 1738: train/loss = 0.38316401839256287, train/raw-loss = 0.3266684412956238, train/logprobs = tensor([[-1.9933, -5.7054],
        [-2.5013, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18831858038902283
Epoch 0, Step 1739: train/loss = 0.46493440866470337, train/raw-loss = 0.40619635581970215, train/logprobs = tensor([[-1.0867, -4.4688],
        [-1.6342, -1.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19579347968101501
Epoch 0, Step 1740: train/loss = 0.42207837104797363, train/raw-loss = 0.37268537282943726, train/logprobs = tensor([[-0.8893, -4.0811],
        [-2.1019, -2.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16464342176914215
Epoch 0, Step 1741: train/loss = 0.3936939835548401, train/raw-loss = 0.34315136075019836, train/logprobs = tensor([[-0.7445, -5.1348],
        [-2.2878, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16847531497478485
Epoch 0, Step 1742: train/loss = 0.3584206700325012, train/raw-loss = 0.290799617767334, train/logprobs = tensor([[-1.9030, -8.5986],
        [-2.2993, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22540345788002014
Epoch 0, Step 1743: train/loss = 0.5498735904693604, train/raw-loss = 0.4932328760623932, train/logprobs = tensor([[-0.8206, -2.5864],
        [-1.9689, -1.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18880239129066467
Epoch 0, Step 1744: train/loss = 0.24022668600082397, train/raw-loss = 0.18558448553085327, train/logprobs = tensor([[-1.7408, -6.6651],
        [-2.6441, -1.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18214070796966553
Epoch 0, Step 1745: train/loss = 0.43685638904571533, train/raw-loss = 0.3749462962150574, train/logprobs = tensor([[-0.7954, -5.9360],
        [-1.8195, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20636697113513947
Epoch 0, Step 1746: train/loss = 0.4333539307117462, train/raw-loss = 0.37875795364379883, train/logprobs = tensor([[-0.6710, -2.7743],
        [-1.6395, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1819865107536316
Epoch 0, Step 1747: train/loss = 0.40693509578704834, train/raw-loss = 0.35614755749702454, train/logprobs = tensor([[-0.7590, -2.5141],
        [-2.2429, -1.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16929179430007935
Epoch 0, Step 1748: train/loss = 0.4123625159263611, train/raw-loss = 0.35209187865257263, train/logprobs = tensor([[-0.9585, -1.8539],
        [-2.6656, -1.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20090214908123016
Epoch 0, Step 1749: train/loss = 0.40092116594314575, train/raw-loss = 0.3334820866584778, train/logprobs = tensor([[-1.0492, -3.9769],
        [-2.3438, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22479690611362457
Epoch 0, Step 1750: train/loss = 0.2841140031814575, train/raw-loss = 0.22372232377529144, train/logprobs = tensor([[ -1.3162, -11.6974],
        [ -2.4070,  -1.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20130562782287598
Epoch 0, Step 1751: train/loss = 0.47539353370666504, train/raw-loss = 0.4200631380081177, train/logprobs = tensor([[-1.4429, -5.1885],
        [-1.7355, -2.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1844346970319748
Epoch 0, Step 1752: train/loss = 0.3055439591407776, train/raw-loss = 0.2597137987613678, train/logprobs = tensor([[-0.8550, -8.3208],
        [-1.9656, -2.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15276721119880676
Epoch 0, Step 1753: train/loss = 0.23365044593811035, train/raw-loss = 0.17490875720977783, train/logprobs = tensor([[-1.5074, -9.1037],
        [-2.5674, -1.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19580556452274323
Epoch 0, Step 1754: train/loss = 0.13463807106018066, train/raw-loss = 0.06372510641813278, train/logprobs = tensor([[ -1.1026, -10.5371],
        [ -3.6049,  -1.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23637655377388
Epoch 0, Step 1755: train/loss = 0.32756438851356506, train/raw-loss = 0.26887935400009155, train/logprobs = tensor([[-1.5743, -3.5918],
        [-2.5143, -1.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19561676681041718
Epoch 0, Step 1756: train/loss = 0.4916987121105194, train/raw-loss = 0.4395703077316284, train/logprobs = tensor([[-1.8883, -3.7899],
        [-1.8590, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737613081932068
Epoch 0, Step 1757: train/loss = 0.6369758248329163, train/raw-loss = 0.5731775164604187, train/logprobs = tensor([[-1.1537, -1.2792],
        [-1.6496, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126610428094864
Epoch 0, Step 1758: train/loss = 0.29826003313064575, train/raw-loss = 0.24666668474674225, train/logprobs = tensor([[-0.8464, -7.2499],
        [-1.6301, -1.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17197786271572113
Epoch 0, Step 1759: train/loss = 0.4253251850605011, train/raw-loss = 0.3801935613155365, train/logprobs = tensor([[-0.7174, -2.8259],
        [-2.3040, -1.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15043877065181732
Epoch 0, Step 1760: train/loss = 0.522947371006012, train/raw-loss = 0.4634101688861847, train/logprobs = tensor([[-0.9269, -6.5470],
        [-2.7744, -1.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19845741987228394
Epoch 0, Step 1761: train/loss = 0.2270064353942871, train/raw-loss = 0.15749983489513397, train/logprobs = tensor([[-0.8397, -5.0772],
        [-2.2239, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23168864846229553
Epoch 0, Step 1762: train/loss = 0.4256238043308258, train/raw-loss = 0.36772620677948, train/logprobs = tensor([[-1.2307, -5.7432],
        [-2.1195, -1.1755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19299200177192688
Epoch 0, Step 1763: train/loss = 0.4990139603614807, train/raw-loss = 0.4357367157936096, train/logprobs = tensor([[-1.6927, -6.6814],
        [-1.3777, -1.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21092411875724792
Epoch 0, Step 1764: train/loss = 0.20235800743103027, train/raw-loss = 0.14482280611991882, train/logprobs = tensor([[-0.5681, -5.6964],
        [-1.8343, -1.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19178402423858643
Epoch 0, Step 1765: train/loss = 0.47395092248916626, train/raw-loss = 0.40792572498321533, train/logprobs = tensor([[-0.6282, -3.4140],
        [-1.5707, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22008398175239563
Epoch 0, Step 1766: train/loss = 0.2901737093925476, train/raw-loss = 0.24116086959838867, train/logprobs = tensor([[-1.2662, -6.9075],
        [-2.1730, -1.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16337615251541138
Epoch 0, Step 1767: train/loss = 0.26782622933387756, train/raw-loss = 0.21200653910636902, train/logprobs = tensor([[ -0.6018, -11.3434],
        [ -1.7247,  -1.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.186065673828125
Epoch 0, Step 1768: train/loss = 0.3002796471118927, train/raw-loss = 0.22613625228405, train/logprobs = tensor([[-1.0596, -4.9066],
        [-2.9694, -2.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24714453518390656
Epoch 0, Step 1769: train/loss = 0.2562218904495239, train/raw-loss = 0.20419970154762268, train/logprobs = tensor([[-0.9502, -3.9384],
        [-2.6567, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17340725660324097
Epoch 0, Step 1770: train/loss = 0.28861144185066223, train/raw-loss = 0.23852893710136414, train/logprobs = tensor([[ -1.1728, -12.2503],
        [ -2.1006,  -2.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16694164276123047
Epoch 0, Step 1771: train/loss = 0.44524863362312317, train/raw-loss = 0.38265132904052734, train/logprobs = tensor([[-1.0164, -3.7004],
        [-2.2062, -1.2867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20865780115127563
Epoch 0, Step 1772: train/loss = 0.319585382938385, train/raw-loss = 0.26504069566726685, train/logprobs = tensor([[-1.1571, -5.1282],
        [-1.7911, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18181569874286652
Epoch 0, Step 1773: train/loss = 0.23457294702529907, train/raw-loss = 0.16190868616104126, train/logprobs = tensor([[-0.8783, -7.4150],
        [-2.2816, -1.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24221426248550415
Epoch 0, Step 1774: train/loss = 0.5817728638648987, train/raw-loss = 0.5099883079528809, train/logprobs = tensor([[-2.0057, -3.9472],
        [-2.5099, -1.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23928198218345642
Epoch 0, Step 1775: train/loss = 0.4431876540184021, train/raw-loss = 0.3807635009288788, train/logprobs = tensor([[-0.9612, -2.5722],
        [-1.9186, -1.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20808060467243195
Epoch 0, Step 1776: train/loss = 0.7592974901199341, train/raw-loss = 0.6962623596191406, train/logprobs = tensor([[-3.0904, -9.7532],
        [-2.7075, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21011711657047272
Epoch 0, Step 1777: train/loss = 0.39951446652412415, train/raw-loss = 0.3308706283569336, train/logprobs = tensor([[-0.6138, -4.6932],
        [-2.2480, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22881269454956055
Epoch 0, Step 1778: train/loss = 0.3702162206172943, train/raw-loss = 0.30127665400505066, train/logprobs = tensor([[-1.3825, -5.6154],
        [-2.3820, -1.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22979852557182312
Epoch 0, Step 1779: train/loss = 0.45011410117149353, train/raw-loss = 0.39542025327682495, train/logprobs = tensor([[-0.6657, -6.8517],
        [-1.4138, -1.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18231278657913208
Epoch 0, Step 1780: train/loss = 0.39598435163497925, train/raw-loss = 0.3339869976043701, train/logprobs = tensor([[-0.5014, -4.9455],
        [-1.4282, -1.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20665796101093292
Epoch 0, Step 1781: train/loss = 0.37264755368232727, train/raw-loss = 0.3086692690849304, train/logprobs = tensor([[-0.7656, -4.1328],
        [-2.0421, -1.3274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21326085925102234
Epoch 0, Step 1782: train/loss = 0.21228376030921936, train/raw-loss = 0.16133616864681244, train/logprobs = tensor([[-0.6011, -7.0948],
        [-1.4910, -1.3007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1698252558708191
Epoch 0, Step 1783: train/loss = 0.3846743404865265, train/raw-loss = 0.31503915786743164, train/logprobs = tensor([[-1.1475, -4.8213],
        [-3.0212, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23211725056171417
Epoch 0, Step 1784: train/loss = 0.5098200440406799, train/raw-loss = 0.46022796630859375, train/logprobs = tensor([[-1.4876, -3.4978],
        [-1.5121, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16530683636665344
Epoch 0, Step 1785: train/loss = 0.5169156193733215, train/raw-loss = 0.45350316166877747, train/logprobs = tensor([[-1.0719, -3.6003],
        [-1.5529, -1.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21137483417987823
Epoch 0, Step 1786: train/loss = 0.5180314183235168, train/raw-loss = 0.46875518560409546, train/logprobs = tensor([[-0.6589, -2.7647],
        [-1.2305, -1.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16425420343875885
Epoch 0, Step 1787: train/loss = 0.469801127910614, train/raw-loss = 0.40067464113235474, train/logprobs = tensor([[-1.3917, -3.8674],
        [-2.1769, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2304215133190155
Epoch 0, Step 1788: train/loss = 0.4369509816169739, train/raw-loss = 0.3904504179954529, train/logprobs = tensor([[-0.5639, -3.5219],
        [-0.8010, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1550019383430481
Epoch 0, Step 1789: train/loss = 0.3131733536720276, train/raw-loss = 0.2570570707321167, train/logprobs = tensor([[-1.1298, -5.2223],
        [-2.4828, -1.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18705430626869202
Epoch 0, Step 1790: train/loss = 0.2595117688179016, train/raw-loss = 0.19568346440792084, train/logprobs = tensor([[-0.9652, -8.0113],
        [-2.4072, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21276098489761353
Epoch 0, Step 1791: train/loss = 0.4052198529243469, train/raw-loss = 0.3456801772117615, train/logprobs = tensor([[-1.3135, -3.0768],
        [-2.3761, -1.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19846557080745697
Epoch 0, Step 1792: train/loss = 0.321553111076355, train/raw-loss = 0.25077933073043823, train/logprobs = tensor([[-0.7511, -4.7118],
        [-2.4287, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23591256141662598
Epoch 0, Step 1793: train/loss = 0.2763201594352722, train/raw-loss = 0.21359874308109283, train/logprobs = tensor([[-0.9869, -6.9733],
        [-2.1614, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20907138288021088
Epoch 0, Step 1794: train/loss = 0.2867150902748108, train/raw-loss = 0.2291973978281021, train/logprobs = tensor([[-1.2785, -3.4543],
        [-3.0044, -1.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19172564148902893
Epoch 0, Step 1795: train/loss = 0.23874780535697937, train/raw-loss = 0.1901683211326599, train/logprobs = tensor([[-0.5995, -8.6496],
        [-2.5776, -2.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16193164885044098
Epoch 0, Step 1796: train/loss = 0.5083445310592651, train/raw-loss = 0.4576282203197479, train/logprobs = tensor([[-0.8148, -2.0387],
        [-1.1946, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16905435919761658
Epoch 0, Step 1797: train/loss = 0.4306589365005493, train/raw-loss = 0.3726663589477539, train/logprobs = tensor([[ -2.2259, -10.1476],
        [ -2.6113,  -1.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1933085322380066
Epoch 0, Step 1798: train/loss = 0.306852251291275, train/raw-loss = 0.24575275182724, train/logprobs = tensor([[-1.1381, -7.2828],
        [-4.4172, -2.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20366498827934265
Epoch 0, Step 1799: train/loss = 0.4075162708759308, train/raw-loss = 0.3538714349269867, train/logprobs = tensor([[-1.1300, -6.0244],
        [-1.9856, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178816020488739
Epoch 0, Step 1800: train/loss = 0.16181568801403046, train/raw-loss = 0.09474191069602966, train/logprobs = tensor([[ -0.8431, -11.1788],
        [ -2.7422,  -1.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22357924282550812
Epoch 0, Step 1801: train/loss = 0.28862816095352173, train/raw-loss = 0.23135890066623688, train/logprobs = tensor([[-0.9896, -6.5100],
        [-2.6455, -0.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19089755415916443
Epoch 0, Step 1802: train/loss = 0.40248870849609375, train/raw-loss = 0.34449344873428345, train/logprobs = tensor([[-1.2801, -6.2582],
        [-1.8228, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19331754744052887
Epoch 0, Step 1803: train/loss = 0.32836461067199707, train/raw-loss = 0.2705686688423157, train/logprobs = tensor([[-1.2666, -6.2630],
        [-1.9798, -1.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19265323877334595
Epoch 0, Step 1804: train/loss = 0.45589327812194824, train/raw-loss = 0.3993690609931946, train/logprobs = tensor([[-1.0936, -3.7085],
        [-1.9877, -0.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188414067029953
Epoch 0, Step 1805: train/loss = 0.3486122190952301, train/raw-loss = 0.29810255765914917, train/logprobs = tensor([[-0.7813, -3.4725],
        [-2.4396, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16836555302143097
Epoch 0, Step 1806: train/loss = 0.27306050062179565, train/raw-loss = 0.22612333297729492, train/logprobs = tensor([[-0.6976, -5.2099],
        [-2.2086, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15645724534988403
Epoch 0, Step 1807: train/loss = 0.6182512044906616, train/raw-loss = 0.5662316083908081, train/logprobs = tensor([[-0.5675, -3.4494],
        [-1.1645, -1.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17339852452278137
Epoch 0, Step 1808: train/loss = 0.3036735951900482, train/raw-loss = 0.25051751732826233, train/logprobs = tensor([[-0.6598, -6.2412],
        [-1.4487, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17718693614006042
Epoch 0, Step 1809: train/loss = 0.3257998526096344, train/raw-loss = 0.26817524433135986, train/logprobs = tensor([[-0.7696, -9.3543],
        [-1.8004, -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19208204746246338
Epoch 0, Step 1810: train/loss = 0.4176303744316101, train/raw-loss = 0.37287986278533936, train/logprobs = tensor([[-0.8311, -2.5538],
        [-1.8374, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.149168461561203
Epoch 0, Step 1811: train/loss = 0.40596669912338257, train/raw-loss = 0.3541083335876465, train/logprobs = tensor([[-1.0452, -6.0372],
        [-2.0044, -1.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17286115884780884
Epoch 0, Step 1812: train/loss = 0.15382641553878784, train/raw-loss = 0.0901372879743576, train/logprobs = tensor([[-1.8870, -9.0271],
        [-3.8128, -1.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21229706704616547
Epoch 0, Step 1813: train/loss = 0.23592907190322876, train/raw-loss = 0.1806020587682724, train/logprobs = tensor([[ -1.0887, -11.7623],
        [ -2.2686,  -2.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18442334234714508
Epoch 0, Step 1814: train/loss = 0.32889214158058167, train/raw-loss = 0.25475239753723145, train/logprobs = tensor([[-0.8029, -3.5726],
        [-2.3079, -1.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24713236093521118
Epoch 0, Step 1815: train/loss = 0.21570786833763123, train/raw-loss = 0.1629868596792221, train/logprobs = tensor([[-0.9637, -9.6178],
        [-2.0180, -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17573672533035278
Epoch 0, Step 1816: train/loss = 0.3207836449146271, train/raw-loss = 0.2656369209289551, train/logprobs = tensor([[-0.7511, -4.7122],
        [-1.2093, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18382248282432556
Epoch 0, Step 1817: train/loss = 0.6431360244750977, train/raw-loss = 0.5931557416915894, train/logprobs = tensor([[-0.9483, -1.1905],
        [-1.1707, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666010618209839
Epoch 0, Step 1818: train/loss = 0.206539124250412, train/raw-loss = 0.1403626799583435, train/logprobs = tensor([[ -0.8841, -10.1773],
        [ -2.7369,  -1.3656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22058811783790588
Epoch 0, Step 1819: train/loss = 0.3581952154636383, train/raw-loss = 0.3013788163661957, train/logprobs = tensor([[-1.1191, -5.5465],
        [-1.9907, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18938808143138885
Epoch 0, Step 1820: train/loss = 0.37298133969306946, train/raw-loss = 0.3125287890434265, train/logprobs = tensor([[-0.7654, -4.6337],
        [-1.8006, -0.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20150841772556305
Epoch 0, Step 1821: train/loss = 0.28431206941604614, train/raw-loss = 0.22384673357009888, train/logprobs = tensor([[-0.7897, -6.3737],
        [-1.7612, -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2015511393547058
Epoch 0, Step 1822: train/loss = 0.3862764537334442, train/raw-loss = 0.3193608522415161, train/logprobs = tensor([[-1.0896, -3.5852],
        [-1.7348, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22305205464363098
Epoch 0, Step 1823: train/loss = 0.4734547734260559, train/raw-loss = 0.39784589409828186, train/logprobs = tensor([[-0.6142, -3.9078],
        [-2.5375, -1.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25202956795692444
Epoch 0, Step 1824: train/loss = 0.39319121837615967, train/raw-loss = 0.34114646911621094, train/logprobs = tensor([[-0.6796, -3.6869],
        [-1.7424, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734824776649475
Epoch 0, Step 1825: train/loss = 0.31997716426849365, train/raw-loss = 0.255429208278656, train/logprobs = tensor([[-0.9401, -5.1748],
        [-2.1872, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151598334312439
Epoch 0, Step 1826: train/loss = 0.3160907030105591, train/raw-loss = 0.2621535658836365, train/logprobs = tensor([[-1.3411, -7.4302],
        [-1.9870, -1.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17979051172733307
Epoch 0, Step 1827: train/loss = 0.28228455781936646, train/raw-loss = 0.20176243782043457, train/logprobs = tensor([[-0.9240, -3.2364],
        [-2.5130, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26840707659721375
Epoch 0, Step 1828: train/loss = 0.2348276525735855, train/raw-loss = 0.16966284811496735, train/logprobs = tensor([[-1.3673, -8.3700],
        [-2.8743, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21721601486206055
Epoch 0, Step 1829: train/loss = 0.44202202558517456, train/raw-loss = 0.39265066385269165, train/logprobs = tensor([[-0.7814, -4.0174],
        [-0.9798, -0.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16457121074199677
Epoch 0, Step 1830: train/loss = 0.4292863607406616, train/raw-loss = 0.37862035632133484, train/logprobs = tensor([[-0.5091, -4.1183],
        [-1.2801, -1.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16888666152954102
Epoch 0, Step 1831: train/loss = 0.7095712423324585, train/raw-loss = 0.6586413383483887, train/logprobs = tensor([[-0.6671, -0.8352],
        [-0.8639, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1697663515806198
Epoch 0, Step 1832: train/loss = 0.32997119426727295, train/raw-loss = 0.2726072669029236, train/logprobs = tensor([[-0.5808, -4.4065],
        [-1.3025, -1.3309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19121302664279938
Epoch 0, Step 1833: train/loss = 0.5965451002120972, train/raw-loss = 0.532799482345581, train/logprobs = tensor([[-0.5044, -2.2973],
        [-1.1486, -2.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21248546242713928
Epoch 0, Step 1834: train/loss = 0.5138053894042969, train/raw-loss = 0.44024714827537537, train/logprobs = tensor([[-1.7005, -5.5901],
        [-1.4105, -1.0914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24519401788711548
Epoch 0, Step 1835: train/loss = 0.21613767743110657, train/raw-loss = 0.15970337390899658, train/logprobs = tensor([[ -0.5860, -11.0975],
        [ -1.5688,  -2.3478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18811440467834473
Epoch 0, Step 1836: train/loss = 0.1735060214996338, train/raw-loss = 0.1019527018070221, train/logprobs = tensor([[-1.2993, -7.5576],
        [-3.1010, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2385110855102539
Epoch 0, Step 1837: train/loss = 0.3412570655345917, train/raw-loss = 0.2888616621494293, train/logprobs = tensor([[-1.0611, -7.0117],
        [-2.0352, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1746513843536377
Epoch 0, Step 1838: train/loss = 0.31002771854400635, train/raw-loss = 0.24873456358909607, train/logprobs = tensor([[-1.0774, -4.7438],
        [-1.7464, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2043105661869049
Epoch 0, Step 1839: train/loss = 0.27951952815055847, train/raw-loss = 0.21828655898571014, train/logprobs = tensor([[-0.8758, -5.4075],
        [-1.7831, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20410984754562378
Epoch 0, Step 1840: train/loss = 0.2549089193344116, train/raw-loss = 0.1939249336719513, train/logprobs = tensor([[ -1.3619, -11.4398],
        [ -2.1967,  -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20328006148338318
Epoch 0, Step 1841: train/loss = 0.40649306774139404, train/raw-loss = 0.34620359539985657, train/logprobs = tensor([[-0.6218, -4.2175],
        [-1.8697, -0.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20096486806869507
Epoch 0, Step 1842: train/loss = 0.36480146646499634, train/raw-loss = 0.3041805326938629, train/logprobs = tensor([[-1.4711, -9.3543],
        [-1.8784, -1.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20206966996192932
Epoch 0, Step 1843: train/loss = 0.20502355694770813, train/raw-loss = 0.1502310335636139, train/logprobs = tensor([[-1.2341, -8.9773],
        [-2.7579, -1.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18264174461364746
Epoch 0, Step 1844: train/loss = 0.2931665778160095, train/raw-loss = 0.2161640226840973, train/logprobs = tensor([[-1.1234, -4.8139],
        [-3.1856, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25667518377304077
Epoch 0, Step 1845: train/loss = 0.17883603274822235, train/raw-loss = 0.11525551974773407, train/logprobs = tensor([[-1.0836, -9.3379],
        [-2.6490, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21193501353263855
Epoch 0, Step 1846: train/loss = 0.4631902873516083, train/raw-loss = 0.4051535129547119, train/logprobs = tensor([[-0.7424, -3.7912],
        [-1.8489, -1.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19345587491989136
Epoch 0, Step 1847: train/loss = 0.1793806552886963, train/raw-loss = 0.11435571312904358, train/logprobs = tensor([[-0.9395, -5.7886],
        [-2.7799, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21674980223178864
Epoch 0, Step 1848: train/loss = 0.39596855640411377, train/raw-loss = 0.34733647108078003, train/logprobs = tensor([[-0.7146, -3.1240],
        [-2.1244, -1.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1621069312095642
Epoch 0, Step 1849: train/loss = 0.43565481901168823, train/raw-loss = 0.3940688967704773, train/logprobs = tensor([[-0.6204, -3.6653],
        [-1.1883, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13861975073814392
Epoch 0, Step 1850: train/loss = 0.2531774640083313, train/raw-loss = 0.20194818079471588, train/logprobs = tensor([[-1.0825, -7.3335],
        [-1.7917, -0.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17076422274112701
Epoch 0, Step 1851: train/loss = 0.14173604547977448, train/raw-loss = 0.07658900320529938, train/logprobs = tensor([[-0.8002, -6.5942],
        [-3.0860, -0.6201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2171567976474762
Epoch 0, Step 1852: train/loss = 0.16377612948417664, train/raw-loss = 0.11032306402921677, train/logprobs = tensor([[ -1.0772, -12.0614],
        [ -2.6903,  -1.5106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1781768500804901
Epoch 0, Step 1853: train/loss = 0.38948532938957214, train/raw-loss = 0.3432219326496124, train/logprobs = tensor([[-0.7265, -7.8808],
        [-1.3520, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1542113870382309
Epoch 0, Step 1854: train/loss = 1.2263025045394897, train/raw-loss = 1.176690936088562, train/logprobs = tensor([[-3.8697, -5.4953],
        [-1.8983, -2.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1653718203306198
Epoch 0, Step 1855: train/loss = 0.24310946464538574, train/raw-loss = 0.1758337914943695, train/logprobs = tensor([[ -0.9483, -10.9129],
        [ -3.0151,  -2.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22425225377082825
Epoch 0, Step 1856: train/loss = 0.2560657858848572, train/raw-loss = 0.20207437872886658, train/logprobs = tensor([[-0.5875, -8.2470],
        [-1.9380, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179971382021904
Epoch 0, Step 1857: train/loss = 0.24244150519371033, train/raw-loss = 0.18360461294651031, train/logprobs = tensor([[-1.0347, -5.9974],
        [-2.2965, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19612300395965576
Epoch 0, Step 1858: train/loss = 0.4035398066043854, train/raw-loss = 0.33565837144851685, train/logprobs = tensor([[-1.4480, -4.4486],
        [-1.8005, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22627140581607819
Epoch 0, Step 1859: train/loss = 0.34484273195266724, train/raw-loss = 0.2784004807472229, train/logprobs = tensor([[-0.7281, -4.2280],
        [-1.6970, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22147423028945923
Epoch 0, Step 1860: train/loss = 0.37695255875587463, train/raw-loss = 0.3198184669017792, train/logprobs = tensor([[-0.9129, -5.9987],
        [-2.2351, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19044694304466248
Epoch 0, Step 1861: train/loss = 0.17878121137619019, train/raw-loss = 0.12006359547376633, train/logprobs = tensor([[ -0.6774, -10.5108],
        [ -2.2384,  -1.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572539627552032
Epoch 0, Step 1862: train/loss = 0.33622679114341736, train/raw-loss = 0.27758634090423584, train/logprobs = tensor([[-0.6202, -6.5882],
        [-1.4431, -1.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1954682171344757
Epoch 0, Step 1863: train/loss = 0.5168153047561646, train/raw-loss = 0.4544249176979065, train/logprobs = tensor([[-1.2667, -4.3065],
        [-2.0457, -1.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20796777307987213
Epoch 0, Step 1864: train/loss = 0.3391892910003662, train/raw-loss = 0.28230181336402893, train/logprobs = tensor([[-1.3547, -6.9220],
        [-1.9624, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18962493538856506
Epoch 0, Step 1865: train/loss = 0.46269047260284424, train/raw-loss = 0.40842360258102417, train/logprobs = tensor([[-0.5986, -4.3853],
        [-1.0823, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18088951706886292
Epoch 0, Step 1866: train/loss = 0.47952699661254883, train/raw-loss = 0.4278757870197296, train/logprobs = tensor([[-1.0881, -3.4251],
        [-1.5439, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17217066884040833
Epoch 0, Step 1867: train/loss = 0.4777250587940216, train/raw-loss = 0.41407325863838196, train/logprobs = tensor([[-0.9734, -4.2050],
        [-2.4650, -1.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2121727019548416
Epoch 0, Step 1868: train/loss = 0.5104640126228333, train/raw-loss = 0.4546104669570923, train/logprobs = tensor([[-0.7821, -2.9045],
        [-1.4705, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18617846071720123
Epoch 0, Step 1869: train/loss = 0.46370890736579895, train/raw-loss = 0.4084257483482361, train/logprobs = tensor([[-1.6917, -6.1688],
        [-3.3635, -2.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18427735567092896
Epoch 0, Step 1870: train/loss = 0.26476359367370605, train/raw-loss = 0.20649588108062744, train/logprobs = tensor([[ -1.8135, -10.4215],
        [ -2.5729,  -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19422566890716553
Epoch 0, Step 1871: train/loss = 0.3470131754875183, train/raw-loss = 0.2975659966468811, train/logprobs = tensor([[-0.4935, -7.7747],
        [-1.1707, -1.2315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16482387483119965
Epoch 0, Step 1872: train/loss = 0.6687564849853516, train/raw-loss = 0.6274116635322571, train/logprobs = tensor([[-0.7564, -0.9944],
        [-0.7153, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13781613111495972
Epoch 0, Step 1873: train/loss = 0.4800727963447571, train/raw-loss = 0.4246687889099121, train/logprobs = tensor([[-0.9251, -4.1104],
        [-1.7335, -1.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18467995524406433
Epoch 0, Step 1874: train/loss = 0.21474918723106384, train/raw-loss = 0.16365164518356323, train/logprobs = tensor([[-0.6475, -7.0613],
        [-1.6822, -1.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703251302242279
Epoch 0, Step 1875: train/loss = 0.4751024842262268, train/raw-loss = 0.42200377583503723, train/logprobs = tensor([[-1.0786, -3.8914],
        [-1.5505, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17699582874774933
Epoch 0, Step 1876: train/loss = 0.37976545095443726, train/raw-loss = 0.32678839564323425, train/logprobs = tensor([[-1.1854, -6.7654],
        [-1.5321, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.176590234041214
Epoch 0, Step 1877: train/loss = 0.28176403045654297, train/raw-loss = 0.21319910883903503, train/logprobs = tensor([[-0.9831, -9.9993],
        [-3.3501, -1.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22854967415332794
Epoch 0, Step 1878: train/loss = 0.22960609197616577, train/raw-loss = 0.15960580110549927, train/logprobs = tensor([[-0.9719, -7.6597],
        [-2.5367, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333342283964157
Epoch 0, Step 1879: train/loss = 0.26708412170410156, train/raw-loss = 0.20516900718212128, train/logprobs = tensor([[-1.0795, -7.4855],
        [-2.5308, -1.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20638373494148254
Epoch 0, Step 1880: train/loss = 0.4428395628929138, train/raw-loss = 0.40065133571624756, train/logprobs = tensor([[-0.9906, -3.6749],
        [-1.6157, -1.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14062729477882385
Epoch 0, Step 1881: train/loss = 0.36209240555763245, train/raw-loss = 0.30410370230674744, train/logprobs = tensor([[-1.1159, -3.6294],
        [-2.1781, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19329573214054108
Epoch 0, Step 1882: train/loss = 0.20887842774391174, train/raw-loss = 0.13540543615818024, train/logprobs = tensor([[-1.3499, -8.3227],
        [-4.1171, -1.4087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24490991234779358
Epoch 0, Step 1883: train/loss = 0.3955926299095154, train/raw-loss = 0.33815690875053406, train/logprobs = tensor([[-1.2805, -3.2339],
        [-2.0532, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19145241379737854
Epoch 0, Step 1884: train/loss = 0.32966211438179016, train/raw-loss = 0.2651365399360657, train/logprobs = tensor([[-1.5842, -9.3416],
        [-2.4286, -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21508526802062988
Epoch 0, Step 1885: train/loss = 0.37500762939453125, train/raw-loss = 0.3239254951477051, train/logprobs = tensor([[-1.0566, -6.0510],
        [-1.5160, -1.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1702737808227539
Epoch 0, Step 1886: train/loss = 0.38440945744514465, train/raw-loss = 0.327096164226532, train/logprobs = tensor([[-0.8227, -5.6667],
        [-2.7268, -1.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19104425609111786
Epoch 0, Step 1887: train/loss = 0.30516162514686584, train/raw-loss = 0.22871965169906616, train/logprobs = tensor([[-0.6799, -2.8375],
        [-2.7057, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2548065483570099
Epoch 0, Step 1888: train/loss = 0.6487147808074951, train/raw-loss = 0.5938621759414673, train/logprobs = tensor([[-0.8993, -1.3754],
        [-1.0060, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284207582473755
Epoch 0, Step 1889: train/loss = 0.24703450500965118, train/raw-loss = 0.18108786642551422, train/logprobs = tensor([[-1.1209, -8.7832],
        [-2.0849, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21982207894325256
Epoch 0, Step 1890: train/loss = 0.46755707263946533, train/raw-loss = 0.4146060347557068, train/logprobs = tensor([[-1.5104, -3.8023],
        [-1.9869, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17650340497493744
Epoch 0, Step 1891: train/loss = 0.5816442966461182, train/raw-loss = 0.506875216960907, train/logprobs = tensor([[-2.2538, -5.3305],
        [-2.3243, -1.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24923017621040344
Epoch 0, Step 1892: train/loss = 0.5214455127716064, train/raw-loss = 0.4520608186721802, train/logprobs = tensor([[-1.4617, -3.3624],
        [-1.9182, -1.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23128220438957214
Epoch 0, Step 1893: train/loss = 0.4575490355491638, train/raw-loss = 0.4006028175354004, train/logprobs = tensor([[-1.0953, -3.5170],
        [-1.6926, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18982058763504028
Epoch 0, Step 1894: train/loss = 0.3754154145717621, train/raw-loss = 0.3125489354133606, train/logprobs = tensor([[-0.6705, -2.6434],
        [-2.1485, -1.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20955483615398407
Epoch 0, Step 1895: train/loss = 0.452817440032959, train/raw-loss = 0.40478211641311646, train/logprobs = tensor([[-0.5464, -4.9756],
        [-0.9267, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16011761128902435
Epoch 0, Step 1896: train/loss = 0.24067510664463043, train/raw-loss = 0.19243477284908295, train/logprobs = tensor([[-1.0618, -8.2649],
        [-2.6858, -2.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16080111265182495
Epoch 0, Step 1897: train/loss = 0.1646169126033783, train/raw-loss = 0.10031521320343018, train/logprobs = tensor([[-0.6525, -9.1058],
        [-2.1174, -1.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21433903276920319
Epoch 0, Step 1898: train/loss = 0.4243896007537842, train/raw-loss = 0.36850717663764954, train/logprobs = tensor([[-1.0414, -5.8865],
        [-1.6405, -0.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627481162548065
Epoch 0, Step 1899: train/loss = 0.31480637192726135, train/raw-loss = 0.25380951166152954, train/logprobs = tensor([[-1.6661, -5.5914],
        [-3.2820, -0.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033228874206543
Epoch 0, Step 1900: train/loss = 0.35034528374671936, train/raw-loss = 0.2923993766307831, train/logprobs = tensor([[-1.4723, -6.6049],
        [-1.6633, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1931529939174652
Epoch 0, Step 1901: train/loss = 0.5126432180404663, train/raw-loss = 0.44389939308166504, train/logprobs = tensor([[-1.8826, -5.9117],
        [-2.2702, -1.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22914615273475647
Epoch 0, Step 1902: train/loss = 0.40711861848831177, train/raw-loss = 0.35951101779937744, train/logprobs = tensor([[-1.0353, -6.4515],
        [-1.3260, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15869200229644775
Epoch 0, Step 1903: train/loss = 0.5061715841293335, train/raw-loss = 0.4554142355918884, train/logprobs = tensor([[-0.8940, -3.0846],
        [-1.2917, -1.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16919125616550446
Epoch 0, Step 1904: train/loss = 0.36773359775543213, train/raw-loss = 0.316215842962265, train/logprobs = tensor([[-1.0770, -8.8005],
        [-1.6528, -1.4859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17172585427761078
Epoch 0, Step 1905: train/loss = 0.4406316578388214, train/raw-loss = 0.37607529759407043, train/logprobs = tensor([[ -1.7221, -11.7710],
        [ -1.7704,  -1.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21518799662590027
Epoch 0, Step 1906: train/loss = 0.48672881722450256, train/raw-loss = 0.42794328927993774, train/logprobs = tensor([[-1.3143, -2.9356],
        [-1.5222, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19595178961753845
Epoch 0, Step 1907: train/loss = 0.4007270634174347, train/raw-loss = 0.34966132044792175, train/logprobs = tensor([[-0.9986, -6.4843],
        [-1.3728, -0.9215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17021915316581726
Epoch 0, Step 1908: train/loss = 0.5827867984771729, train/raw-loss = 0.5226901769638062, train/logprobs = tensor([[-1.5172, -5.0273],
        [-1.3411, -2.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20032215118408203
Epoch 0, Step 1909: train/loss = 0.3535076379776001, train/raw-loss = 0.2779586613178253, train/logprobs = tensor([[-1.0980, -8.2071],
        [-3.4202, -1.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25182992219924927
Epoch 0, Step 1910: train/loss = 0.3677304983139038, train/raw-loss = 0.3135705292224884, train/logprobs = tensor([[-0.9196, -5.3532],
        [-1.6804, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18053309619426727
Epoch 0, Step 1911: train/loss = 0.274029403924942, train/raw-loss = 0.20661751925945282, train/logprobs = tensor([[-1.2378, -8.7497],
        [-2.8752, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22470623254776
Epoch 0, Step 1912: train/loss = 0.37893861532211304, train/raw-loss = 0.30995213985443115, train/logprobs = tensor([[-1.2417, -3.7765],
        [-2.4661, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22995488345623016
Epoch 0, Step 1913: train/loss = 0.31013023853302, train/raw-loss = 0.2538467347621918, train/logprobs = tensor([[-0.9047, -4.0227],
        [-2.4184, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1876116842031479
Epoch 0, Step 1914: train/loss = 0.16618213057518005, train/raw-loss = 0.10960950702428818, train/logprobs = tensor([[ -0.8493, -11.4470],
        [ -2.7092,  -2.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885753870010376
Epoch 0, Step 1915: train/loss = 0.21018436551094055, train/raw-loss = 0.1521892547607422, train/logprobs = tensor([[ -1.1828, -11.1553],
        [ -2.4815,  -1.5325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1933169960975647
Epoch 0, Step 1916: train/loss = 0.44447457790374756, train/raw-loss = 0.36874496936798096, train/logprobs = tensor([[-0.7615, -3.5678],
        [-2.1256, -1.3864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25243207812309265
Epoch 0, Step 1917: train/loss = 0.5754833221435547, train/raw-loss = 0.527773380279541, train/logprobs = tensor([[-1.3881, -3.0050],
        [-1.4138, -1.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1590331494808197
Epoch 0, Step 1918: train/loss = 0.24850721657276154, train/raw-loss = 0.17220616340637207, train/logprobs = tensor([[-1.0762, -5.6382],
        [-3.3171, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543368637561798
Epoch 0, Step 1919: train/loss = 0.21678704023361206, train/raw-loss = 0.15284067392349243, train/logprobs = tensor([[-1.1212, -8.8122],
        [-2.2858, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21315455436706543
Epoch 0, Step 1920: train/loss = 0.2408938705921173, train/raw-loss = 0.1833721399307251, train/logprobs = tensor([[-0.8349, -5.6602],
        [-2.2902, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1917390674352646
Epoch 0, Step 1921: train/loss = 0.30084192752838135, train/raw-loss = 0.23925815522670746, train/logprobs = tensor([[-0.6691, -9.9850],
        [-2.6978, -2.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20527932047843933
Epoch 0, Step 1922: train/loss = 0.15387943387031555, train/raw-loss = 0.08901489526033401, train/logprobs = tensor([[-0.9438, -8.8178],
        [-3.0750, -1.3301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21621505916118622
Epoch 0, Step 1923: train/loss = 0.2980250418186188, train/raw-loss = 0.24156048893928528, train/logprobs = tensor([[-0.8070, -9.9055],
        [-2.0453, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1882152259349823
Epoch 0, Step 1924: train/loss = 0.19378989934921265, train/raw-loss = 0.1235983595252037, train/logprobs = tensor([[-0.9115, -7.5210],
        [-2.2142, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23397183418273926
Epoch 0, Step 1925: train/loss = 0.3216317296028137, train/raw-loss = 0.2603591978549957, train/logprobs = tensor([[-0.9933, -9.0855],
        [-2.2270, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042417973279953
Epoch 0, Step 1926: train/loss = 0.38154831528663635, train/raw-loss = 0.3309328556060791, train/logprobs = tensor([[-0.9179, -4.2756],
        [-1.8167, -1.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1687181144952774
Epoch 0, Step 1927: train/loss = 0.2570667862892151, train/raw-loss = 0.18794657289981842, train/logprobs = tensor([[-1.3931, -7.1867],
        [-2.2017, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2304007112979889
Epoch 0, Step 1928: train/loss = 0.4013795256614685, train/raw-loss = 0.3492860198020935, train/logprobs = tensor([[-0.7590, -4.3770],
        [-1.6537, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17364493012428284
Epoch 0, Step 1929: train/loss = 0.3258814513683319, train/raw-loss = 0.2677450478076935, train/logprobs = tensor([[-0.7857, -5.8225],
        [-1.6034, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1937880516052246
Epoch 0, Step 1930: train/loss = 0.5132092833518982, train/raw-loss = 0.4608609974384308, train/logprobs = tensor([[-0.9663, -4.9425],
        [-0.6560, -1.2685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1744941771030426
Epoch 0, Step 1931: train/loss = 0.6013518571853638, train/raw-loss = 0.5500809550285339, train/logprobs = tensor([[-1.3573, -4.3478],
        [-1.3095, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17090289294719696
Epoch 0, Step 1932: train/loss = 0.49149519205093384, train/raw-loss = 0.43294548988342285, train/logprobs = tensor([[-0.9643, -4.5601],
        [-2.0737, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1951656937599182
Epoch 0, Step 1933: train/loss = 0.5212180614471436, train/raw-loss = 0.45513418316841125, train/logprobs = tensor([[-1.5364, -4.1524],
        [-1.6967, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22027960419654846
Epoch 0, Step 1934: train/loss = 0.489296019077301, train/raw-loss = 0.43031883239746094, train/logprobs = tensor([[-1.0588, -3.1991],
        [-1.4233, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1965906023979187
Epoch 0, Step 1935: train/loss = 0.25514522194862366, train/raw-loss = 0.19889795780181885, train/logprobs = tensor([[-1.1519, -6.0111],
        [-2.7223, -1.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749091029167175
Epoch 0, Step 1936: train/loss = 0.2540242075920105, train/raw-loss = 0.18333064019680023, train/logprobs = tensor([[ -0.8615, -12.2329],
        [ -1.9581,  -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23564529418945312
Epoch 0, Step 1937: train/loss = 0.6251640319824219, train/raw-loss = 0.5712302923202515, train/logprobs = tensor([[-1.7335, -1.9869],
        [-2.1167, -1.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17977924644947052
Epoch 0, Step 1938: train/loss = 0.8050051927566528, train/raw-loss = 0.741581380367279, train/logprobs = tensor([[-2.9275, -5.9684],
        [-1.7601, -2.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2114127278327942
Epoch 0, Step 1939: train/loss = 0.46642887592315674, train/raw-loss = 0.4166817367076874, train/logprobs = tensor([[-0.8136, -2.9017],
        [-1.0192, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1658237874507904
Epoch 0, Step 1940: train/loss = 0.5006000995635986, train/raw-loss = 0.44591212272644043, train/logprobs = tensor([[-1.3848, -6.9621],
        [-1.6624, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18229326605796814
Epoch 0, Step 1941: train/loss = 0.7664911150932312, train/raw-loss = 0.6918540000915527, train/logprobs = tensor([[-2.3049, -3.9336],
        [-2.3024, -1.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24879038333892822
Epoch 0, Step 1942: train/loss = 0.33961021900177, train/raw-loss = 0.2692573666572571, train/logprobs = tensor([[-1.3938, -6.9822],
        [-2.7945, -1.2860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23450957238674164
Epoch 0, Step 1943: train/loss = 0.27594664692878723, train/raw-loss = 0.20810219645500183, train/logprobs = tensor([[-0.7394, -7.2651],
        [-2.5367, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22614817321300507
Epoch 0, Step 1944: train/loss = 0.5053145289421082, train/raw-loss = 0.4555344581604004, train/logprobs = tensor([[-0.9943, -2.2298],
        [-1.6876, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16593343019485474
Epoch 0, Step 1945: train/loss = 0.42920076847076416, train/raw-loss = 0.36906206607818604, train/logprobs = tensor([[-0.6824, -2.9833],
        [-1.7741, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20046228170394897
Epoch 0, Step 1946: train/loss = 0.645358681678772, train/raw-loss = 0.5760883092880249, train/logprobs = tensor([[-2.2300, -6.2836],
        [-1.6608, -2.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23090127110481262
Epoch 0, Step 1947: train/loss = 0.542711079120636, train/raw-loss = 0.4890691637992859, train/logprobs = tensor([[-0.9700, -1.6334],
        [-1.3633, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178806334733963
Epoch 0, Step 1948: train/loss = 0.3444790244102478, train/raw-loss = 0.29562750458717346, train/logprobs = tensor([[-0.6196, -6.6162],
        [-1.1498, -0.5536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16283848881721497
Epoch 0, Step 1949: train/loss = 0.3906427025794983, train/raw-loss = 0.3399840295314789, train/logprobs = tensor([[-0.9597, -4.7154],
        [-1.4921, -1.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1688622385263443
Epoch 0, Step 1950: train/loss = 0.348941832780838, train/raw-loss = 0.2929433584213257, train/logprobs = tensor([[-1.2206, -8.6327],
        [-1.5710, -1.2592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18666145205497742
Epoch 0, Step 1951: train/loss = 0.2750648260116577, train/raw-loss = 0.21949175000190735, train/logprobs = tensor([[-0.9239, -4.8518],
        [-2.7299, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852436363697052
Epoch 0, Step 1952: train/loss = 0.37312987446784973, train/raw-loss = 0.31158098578453064, train/logprobs = tensor([[-0.8851, -3.9150],
        [-2.8088, -1.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2051628977060318
Epoch 0, Step 1953: train/loss = 0.4282973110675812, train/raw-loss = 0.37804538011550903, train/logprobs = tensor([[-0.9872, -8.2224],
        [-1.5485, -1.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675063967704773
Epoch 0, Step 1954: train/loss = 0.2578461766242981, train/raw-loss = 0.20421655476093292, train/logprobs = tensor([[-1.0258, -8.9840],
        [-2.0592, -0.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17876535654067993
Epoch 0, Step 1955: train/loss = 0.2967076897621155, train/raw-loss = 0.23550057411193848, train/logprobs = tensor([[-1.7138, -6.6382],
        [-2.5488, -1.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20402371883392334
Epoch 0, Step 1956: train/loss = 0.4576423466205597, train/raw-loss = 0.3863973021507263, train/logprobs = tensor([[-0.8601, -4.8723],
        [-1.9745, -2.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2374834418296814
Epoch 0, Step 1957: train/loss = 0.38698863983154297, train/raw-loss = 0.32243847846984863, train/logprobs = tensor([[-0.8453, -6.4666],
        [-2.5129, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21516723930835724
Epoch 0, Step 1958: train/loss = 0.23596876859664917, train/raw-loss = 0.1721302568912506, train/logprobs = tensor([[ -1.5150, -12.7337],
        [ -2.8060,  -1.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21279503405094147
Epoch 0, Step 1959: train/loss = 0.26739513874053955, train/raw-loss = 0.1986541599035263, train/logprobs = tensor([[-1.0320, -9.6188],
        [-2.6686, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291366159915924
Epoch 0, Step 1960: train/loss = 0.2866368889808655, train/raw-loss = 0.22272484004497528, train/logprobs = tensor([[-0.9403, -8.6860],
        [-2.4466, -1.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21304020285606384
Epoch 0, Step 1961: train/loss = 0.178782656788826, train/raw-loss = 0.11019885540008545, train/logprobs = tensor([[-0.8404, -8.3703],
        [-2.2029, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22861267626285553
Epoch 0, Step 1962: train/loss = 0.56791090965271, train/raw-loss = 0.4961172044277191, train/logprobs = tensor([[-0.7185, -1.7158],
        [-1.4041, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23931239545345306
Epoch 0, Step 1963: train/loss = 0.3977784812450409, train/raw-loss = 0.3335701823234558, train/logprobs = tensor([[-0.9126, -6.9173],
        [-1.6394, -1.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21402758359909058
Epoch 0, Step 1964: train/loss = 0.2987930178642273, train/raw-loss = 0.24443435668945312, train/logprobs = tensor([[-0.6330, -5.5967],
        [-1.6374, -1.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18119549751281738
Epoch 0, Step 1965: train/loss = 0.512196958065033, train/raw-loss = 0.45599716901779175, train/logprobs = tensor([[-0.8385, -2.3877],
        [-1.2022, -0.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18733268976211548
Epoch 0, Step 1966: train/loss = 0.19477827847003937, train/raw-loss = 0.134059339761734, train/logprobs = tensor([[ -1.1431, -15.4796],
        [ -2.2214,  -1.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2023964822292328
Epoch 0, Step 1967: train/loss = 0.47445064783096313, train/raw-loss = 0.4097176790237427, train/logprobs = tensor([[-1.8349, -6.2356],
        [-1.5526, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21577656269073486
Epoch 0, Step 1968: train/loss = 0.4653260111808777, train/raw-loss = 0.40485498309135437, train/logprobs = tensor([[-1.0826, -4.8127],
        [-2.2960, -0.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20157012343406677
Epoch 0, Step 1969: train/loss = 0.2364627867937088, train/raw-loss = 0.1734386533498764, train/logprobs = tensor([[ -0.8605, -10.6743],
        [ -2.8365,  -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21008044481277466
Epoch 0, Step 1970: train/loss = 0.3102535307407379, train/raw-loss = 0.24617230892181396, train/logprobs = tensor([[-1.2350, -8.2585],
        [-1.7308, -1.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21360398828983307
Epoch 0, Step 1971: train/loss = 0.2876974642276764, train/raw-loss = 0.23339053988456726, train/logprobs = tensor([[-0.7539, -5.5002],
        [-2.0497, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18102309107780457
Epoch 0, Step 1972: train/loss = 0.25234276056289673, train/raw-loss = 0.172659769654274, train/logprobs = tensor([[-1.0847, -6.4740],
        [-3.0065, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2656099498271942
Epoch 0, Step 1973: train/loss = 0.29405975341796875, train/raw-loss = 0.22261761128902435, train/logprobs = tensor([[-1.0661, -7.0666],
        [-3.2728, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23814044892787933
Epoch 0, Step 1974: train/loss = 0.2867441475391388, train/raw-loss = 0.21811163425445557, train/logprobs = tensor([[-1.0155, -6.3780],
        [-2.0865, -1.2685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22877509891986847
Epoch 0, Step 1975: train/loss = 0.4972652792930603, train/raw-loss = 0.4476805627346039, train/logprobs = tensor([[-0.8449, -3.5616],
        [-1.6036, -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16528239846229553
Epoch 0, Step 1976: train/loss = 0.3197270333766937, train/raw-loss = 0.25499457120895386, train/logprobs = tensor([[-0.9715, -7.9963],
        [-1.9332, -1.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21577492356300354
Epoch 0, Step 1977: train/loss = 0.15962687134742737, train/raw-loss = 0.09779105335474014, train/logprobs = tensor([[ -1.0932, -14.1260],
        [ -2.6802,  -1.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20611940324306488
Epoch 0, Step 1978: train/loss = 0.2698550820350647, train/raw-loss = 0.20441490411758423, train/logprobs = tensor([[-0.8278, -5.5461],
        [-1.9415, -1.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21813397109508514
Epoch 0, Step 1979: train/loss = 0.41388627886772156, train/raw-loss = 0.34328100085258484, train/logprobs = tensor([[-1.0917, -5.5136],
        [-2.1242, -1.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23535087704658508
Epoch 0, Step 1980: train/loss = 0.31268852949142456, train/raw-loss = 0.24712753295898438, train/logprobs = tensor([[-1.5094, -6.0789],
        [-2.4241, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2185365855693817
Epoch 0, Step 1981: train/loss = 0.18871507048606873, train/raw-loss = 0.12374882400035858, train/logprobs = tensor([[-0.8470, -9.6635],
        [-2.6943, -2.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2165541648864746
Epoch 0, Step 1982: train/loss = 0.483898401260376, train/raw-loss = 0.4265347719192505, train/logprobs = tensor([[-1.5581, -2.6536],
        [-1.8520, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19121214747428894
Epoch 0, Step 1983: train/loss = 0.4764598608016968, train/raw-loss = 0.4284660816192627, train/logprobs = tensor([[-0.6433, -2.2269],
        [-1.2344, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15997931361198425
Epoch 0, Step 1984: train/loss = 0.2725445330142975, train/raw-loss = 0.2110532820224762, train/logprobs = tensor([[-1.5372, -9.1588],
        [-2.2457, -0.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2049708515405655
Epoch 0, Step 1985: train/loss = 0.44291216135025024, train/raw-loss = 0.38571929931640625, train/logprobs = tensor([[-1.1576, -3.5837],
        [-1.7750, -1.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19064290821552277
Epoch 0, Step 1986: train/loss = 0.6061359643936157, train/raw-loss = 0.5591797828674316, train/logprobs = tensor([[-1.1726, -3.9269],
        [-1.1935, -1.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15652057528495789
Epoch 0, Step 1987: train/loss = 0.5059061050415039, train/raw-loss = 0.4489715099334717, train/logprobs = tensor([[-1.7685, -6.4922],
        [-1.8768, -3.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897820085287094
Epoch 0, Step 1988: train/loss = 0.47958463430404663, train/raw-loss = 0.4383836090564728, train/logprobs = tensor([[-0.4475, -3.6320],
        [-1.1811, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13733671605587006
Epoch 0, Step 1989: train/loss = 0.48027515411376953, train/raw-loss = 0.41766121983528137, train/logprobs = tensor([[-1.1151, -4.8708],
        [-0.9254, -1.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20871305465698242
Epoch 0, Step 1990: train/loss = 0.18996304273605347, train/raw-loss = 0.12832114100456238, train/logprobs = tensor([[ -0.7882, -13.6768],
        [ -2.4152,  -1.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20547297596931458
Epoch 0, Step 1991: train/loss = 0.2916490137577057, train/raw-loss = 0.23103271424770355, train/logprobs = tensor([[-0.9492, -7.7664],
        [-2.2415, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20205430686473846
Epoch 0, Step 1992: train/loss = 0.4936229884624481, train/raw-loss = 0.41696038842201233, train/logprobs = tensor([[-1.5700, -5.8248],
        [-1.9656, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555418908596039
Epoch 0, Step 1993: train/loss = 0.5404635667800903, train/raw-loss = 0.4784417748451233, train/logprobs = tensor([[-1.5157, -5.2632],
        [-1.3421, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2067393809556961
Epoch 0, Step 1994: train/loss = 0.3171504735946655, train/raw-loss = 0.25510117411613464, train/logprobs = tensor([[-0.7427, -5.2618],
        [-2.0841, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2068309485912323
Epoch 0, Step 1995: train/loss = 0.22595621645450592, train/raw-loss = 0.16818179190158844, train/logprobs = tensor([[-0.9380, -6.1417],
        [-2.5050, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925813853740692
Epoch 0, Step 1996: train/loss = 0.4168202579021454, train/raw-loss = 0.3670048415660858, train/logprobs = tensor([[-0.9520, -3.0494],
        [-1.8706, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16605140268802643
Epoch 0, Step 1997: train/loss = 0.3679678738117218, train/raw-loss = 0.2971695065498352, train/logprobs = tensor([[-0.8467, -6.7696],
        [-2.1605, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23599451780319214
Epoch 0, Step 1998: train/loss = 0.569102942943573, train/raw-loss = 0.5160300731658936, train/logprobs = tensor([[-0.9495, -2.9357],
        [-1.4035, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17690958082675934
Epoch 0, Step 1999: train/loss = 0.7377431988716125, train/raw-loss = 0.6889171004295349, train/logprobs = tensor([[-2.3799, -3.5168],
        [-1.4580, -1.2942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1627536565065384
Epoch 0, Step 2000: train/loss = 0.49901363253593445, train/raw-loss = 0.4509062170982361, train/logprobs = tensor([[-0.9170, -2.8910],
        [-1.0070, -1.1897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16035805642604828
Epoch 0, Step 2001: train/loss = 0.5006977915763855, train/raw-loss = 0.43545806407928467, train/logprobs = tensor([[-1.1530, -2.4348],
        [-2.0001, -1.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2174658179283142
Epoch 0, Step 2002: train/loss = 0.31822699308395386, train/raw-loss = 0.27046525478363037, train/logprobs = tensor([[-0.9244, -6.8015],
        [-1.6833, -1.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15920591354370117
Epoch 0, Step 2003: train/loss = 0.3763265907764435, train/raw-loss = 0.30615782737731934, train/logprobs = tensor([[-1.8182, -5.5567],
        [-2.1750, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23389585316181183
Epoch 0, Step 2004: train/loss = 0.20561671257019043, train/raw-loss = 0.14696572721004486, train/logprobs = tensor([[-0.6152, -9.6846],
        [-1.7470, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19550326466560364
Epoch 0, Step 2005: train/loss = 0.14499223232269287, train/raw-loss = 0.07942645996809006, train/logprobs = tensor([[ -1.0310, -10.7846],
        [ -3.2965,  -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21855252981185913
Epoch 0, Step 2006: train/loss = 0.3344182074069977, train/raw-loss = 0.28668904304504395, train/logprobs = tensor([[ -0.8379, -11.7020],
        [ -1.4902,  -1.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15909726917743683
Epoch 0, Step 2007: train/loss = 0.4039612114429474, train/raw-loss = 0.3443218469619751, train/logprobs = tensor([[-0.6696, -3.2881],
        [-1.4377, -1.0679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1987977921962738
Epoch 0, Step 2008: train/loss = 0.43038052320480347, train/raw-loss = 0.3794926702976227, train/logprobs = tensor([[-1.1041, -5.4600],
        [-1.8525, -1.1894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1696261614561081
Epoch 0, Step 2009: train/loss = 0.6334026455879211, train/raw-loss = 0.5651114583015442, train/logprobs = tensor([[-2.0968, -5.4904],
        [-1.2927, -2.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22763723134994507
Epoch 0, Step 2010: train/loss = 0.3302977681159973, train/raw-loss = 0.274789422750473, train/logprobs = tensor([[-1.2070, -7.2893],
        [-2.0013, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18502771854400635
Epoch 0, Step 2011: train/loss = 0.26869526505470276, train/raw-loss = 0.21827375888824463, train/logprobs = tensor([[-0.6914, -4.2152],
        [-2.0684, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1680717021226883
Epoch 0, Step 2012: train/loss = 0.435423344373703, train/raw-loss = 0.3752734661102295, train/logprobs = tensor([[-0.8466, -4.2352],
        [-1.6049, -0.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2004995346069336
Epoch 0, Step 2013: train/loss = 0.531572163105011, train/raw-loss = 0.4812448024749756, train/logprobs = tensor([[-0.8238, -1.5148],
        [-1.3810, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677578240633011
Epoch 0, Step 2014: train/loss = 0.5032910108566284, train/raw-loss = 0.43518325686454773, train/logprobs = tensor([[-2.1392, -8.5993],
        [-2.8914, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2270258367061615
Epoch 0, Step 2015: train/loss = 0.5062543749809265, train/raw-loss = 0.45034259557724, train/logprobs = tensor([[-0.8254, -2.7164],
        [-1.1396, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863725483417511
Epoch 0, Step 2016: train/loss = 0.34940630197525024, train/raw-loss = 0.2872769832611084, train/logprobs = tensor([[-1.3180, -4.5209],
        [-2.1200, -1.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20709770917892456
Epoch 0, Step 2017: train/loss = 0.21799510717391968, train/raw-loss = 0.15667085349559784, train/logprobs = tensor([[-1.0654, -7.8520],
        [-1.9831, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20441415905952454
Epoch 0, Step 2018: train/loss = 0.25218743085861206, train/raw-loss = 0.18475905060768127, train/logprobs = tensor([[-1.1138, -8.6744],
        [-2.5855, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22476132214069366
Epoch 0, Step 2019: train/loss = 0.3502906262874603, train/raw-loss = 0.3010715842247009, train/logprobs = tensor([[-0.7656, -4.8228],
        [-1.1611, -1.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16406358778476715
Epoch 0, Step 2020: train/loss = 0.7545478940010071, train/raw-loss = 0.6976870894432068, train/logprobs = tensor([[-1.6881, -2.2679],
        [-1.2681, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18953633308410645
Epoch 0, Step 2021: train/loss = 0.44383496046066284, train/raw-loss = 0.3973897099494934, train/logprobs = tensor([[-0.4169, -4.6665],
        [-0.8288, -0.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15481755137443542
Epoch 0, Step 2022: train/loss = 0.5041117072105408, train/raw-loss = 0.44017547369003296, train/logprobs = tensor([[-0.8824, -3.0184],
        [-2.2022, -1.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2131207138299942
Epoch 0, Step 2023: train/loss = 0.2744747996330261, train/raw-loss = 0.20611155033111572, train/logprobs = tensor([[-1.1388, -6.8076],
        [-3.2521, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22787752747535706
Epoch 0, Step 2024: train/loss = 0.14900797605514526, train/raw-loss = 0.08249524235725403, train/logprobs = tensor([[ -0.9682, -10.6250],
        [ -2.7050,  -2.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22170910239219666
Epoch 0, Step 2025: train/loss = 0.5265029668807983, train/raw-loss = 0.4650559723377228, train/logprobs = tensor([[-1.9026, -7.7499],
        [-2.0809, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20482318103313446
Epoch 0, Step 2026: train/loss = 0.190408855676651, train/raw-loss = 0.12708456814289093, train/logprobs = tensor([[-0.6719, -7.5290],
        [-1.8992, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21108099818229675
Epoch 0, Step 2027: train/loss = 0.2963098883628845, train/raw-loss = 0.23606491088867188, train/logprobs = tensor([[-0.6073, -4.3461],
        [-1.3457, -0.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20081660151481628
Epoch 0, Step 2028: train/loss = 0.33101779222488403, train/raw-loss = 0.27934813499450684, train/logprobs = tensor([[-1.0677, -5.2054],
        [-1.9866, -1.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17223230004310608
Epoch 0, Step 2029: train/loss = 0.5639161467552185, train/raw-loss = 0.5053263902664185, train/logprobs = tensor([[-0.8409, -1.5413],
        [-1.1531, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19529925286769867
Epoch 0, Step 2030: train/loss = 0.2863827645778656, train/raw-loss = 0.21959549188613892, train/logprobs = tensor([[-0.8224, -6.5402],
        [-2.0543, -0.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.222624272108078
Epoch 0, Step 2031: train/loss = 0.6147502660751343, train/raw-loss = 0.5624020099639893, train/logprobs = tensor([[-0.6804, -1.0046],
        [-0.9020, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17449405789375305
Epoch 0, Step 2032: train/loss = 0.39328238368034363, train/raw-loss = 0.3424045443534851, train/logprobs = tensor([[-1.6755, -5.6391],
        [-2.0170, -0.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16959285736083984
Epoch 0, Step 2033: train/loss = 0.7882228493690491, train/raw-loss = 0.7417388558387756, train/logprobs = tensor([[-1.6252, -1.6408],
        [-0.7975, -0.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15494666993618011
Epoch 0, Step 2034: train/loss = 0.4331322908401489, train/raw-loss = 0.3771645426750183, train/logprobs = tensor([[-0.8171, -3.6435],
        [-1.3244, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18655917048454285
Epoch 0, Step 2035: train/loss = 0.4296274781227112, train/raw-loss = 0.37563395500183105, train/logprobs = tensor([[-1.3993, -5.2603],
        [-1.6098, -0.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799784004688263
Epoch 0, Step 2036: train/loss = 0.23685793578624725, train/raw-loss = 0.16941925883293152, train/logprobs = tensor([[ -1.0995, -11.0633],
        [ -2.1442,  -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22479550540447235
Epoch 0, Step 2037: train/loss = 0.28967005014419556, train/raw-loss = 0.2315966933965683, train/logprobs = tensor([[-0.9903, -8.3231],
        [-1.6106, -1.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19357779622077942
Epoch 0, Step 2038: train/loss = 0.34880679845809937, train/raw-loss = 0.2728464603424072, train/logprobs = tensor([[-1.0245, -5.8203],
        [-2.0801, -1.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25320112705230713
Epoch 0, Step 2039: train/loss = 0.3746647238731384, train/raw-loss = 0.3222663700580597, train/logprobs = tensor([[-1.0852, -4.1526],
        [-1.6893, -0.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17466112971305847
Epoch 0, Step 2040: train/loss = 0.4439174234867096, train/raw-loss = 0.39421331882476807, train/logprobs = tensor([[-1.1473, -4.8938],
        [-1.2477, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16568030416965485
Epoch 0, Step 2041: train/loss = 0.2356307953596115, train/raw-loss = 0.18373152613639832, train/logprobs = tensor([[-0.6990, -7.7880],
        [-2.5577, -1.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1729975938796997
Epoch 0, Step 2042: train/loss = 0.2533647119998932, train/raw-loss = 0.19073234498500824, train/logprobs = tensor([[-0.8311, -8.3717],
        [-1.9587, -1.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087746411561966
Epoch 0, Step 2043: train/loss = 0.44773775339126587, train/raw-loss = 0.388353168964386, train/logprobs = tensor([[ -1.0120, -10.1874],
        [ -1.9866,  -1.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19794858992099762
Epoch 0, Step 2044: train/loss = 0.6615516543388367, train/raw-loss = 0.578272819519043, train/logprobs = tensor([[-3.0093, -4.5257],
        [-3.7032, -1.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.277596116065979
Epoch 0, Step 2045: train/loss = 0.4651619493961334, train/raw-loss = 0.4144240915775299, train/logprobs = tensor([[-0.7538, -2.0114],
        [-1.3926, -1.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16912613809108734
Epoch 0, Step 2046: train/loss = 0.2311311662197113, train/raw-loss = 0.19007062911987305, train/logprobs = tensor([[-0.3871, -9.4303],
        [-0.9758, -1.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13686852157115936
Epoch 0, Step 2047: train/loss = 0.4058303236961365, train/raw-loss = 0.34438684582710266, train/logprobs = tensor([[-2.1057, -7.2139],
        [-2.9603, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20481154322624207
Epoch 0, Step 2048: train/loss = 0.3669722378253937, train/raw-loss = 0.3092247545719147, train/logprobs = tensor([[-1.1025, -6.8122],
        [-1.2258, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1924915760755539
Epoch 0, Step 2049: train/loss = 0.32629698514938354, train/raw-loss = 0.2630974054336548, train/logprobs = tensor([[-1.2772, -5.0757],
        [-2.6578, -1.3365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2106652706861496
Epoch 0, Step 2050: train/loss = 0.19640891253948212, train/raw-loss = 0.12269587069749832, train/logprobs = tensor([[-0.9991, -5.6370],
        [-2.2901, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24571016430854797
Epoch 0, Step 2051: train/loss = 0.3222663998603821, train/raw-loss = 0.2683948278427124, train/logprobs = tensor([[-0.6880, -8.2283],
        [-1.5929, -1.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17957179248332977
Epoch 0, Step 2052: train/loss = 0.42742276191711426, train/raw-loss = 0.34997305274009705, train/logprobs = tensor([[-1.1976, -3.8258],
        [-3.2563, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581656575202942
Epoch 0, Step 2053: train/loss = 0.5720245838165283, train/raw-loss = 0.4892934560775757, train/logprobs = tensor([[-2.2421, -5.8880],
        [-1.4525, -2.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757705748081207
Epoch 0, Step 2054: train/loss = 0.44076406955718994, train/raw-loss = 0.38136422634124756, train/logprobs = tensor([[-1.0411, -1.9024],
        [-2.0382, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19799938797950745
Epoch 0, Step 2055: train/loss = 0.39569491147994995, train/raw-loss = 0.3471300005912781, train/logprobs = tensor([[-1.1990, -5.1563],
        [-1.2024, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16188304126262665
Epoch 0, Step 2056: train/loss = 0.32383251190185547, train/raw-loss = 0.2729618549346924, train/logprobs = tensor([[-1.1024, -2.4673],
        [-3.0490, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16956894099712372
Epoch 0, Step 2057: train/loss = 0.5282111167907715, train/raw-loss = 0.4652276635169983, train/logprobs = tensor([[-0.8459, -2.3728],
        [-1.9843, -0.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20994476974010468
Epoch 0, Step 2058: train/loss = 0.19600263237953186, train/raw-loss = 0.11584644764661789, train/logprobs = tensor([[-1.0273, -8.6530],
        [-3.1911, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26718729734420776
Epoch 0, Step 2059: train/loss = 0.2882445156574249, train/raw-loss = 0.21529541909694672, train/logprobs = tensor([[-0.9622, -9.4245],
        [-2.4526, -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24316368997097015
Epoch 0, Step 2060: train/loss = 0.38091909885406494, train/raw-loss = 0.3195434510707855, train/logprobs = tensor([[-1.4917, -4.2509],
        [-1.8415, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20458553731441498
Epoch 0, Step 2061: train/loss = 0.2956821024417877, train/raw-loss = 0.23476898670196533, train/logprobs = tensor([[-1.0934, -8.0204],
        [-2.5041, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20304372906684875
Epoch 0, Step 2062: train/loss = 0.3054870367050171, train/raw-loss = 0.22178035974502563, train/logprobs = tensor([[-1.5108, -5.1277],
        [-2.5249, -0.7136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27902233600616455
Epoch 0, Step 2063: train/loss = 0.4286658465862274, train/raw-loss = 0.3626580536365509, train/logprobs = tensor([[-0.9060, -3.5803],
        [-2.3653, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200259119272232
Epoch 0, Step 2064: train/loss = 0.5925060510635376, train/raw-loss = 0.526138424873352, train/logprobs = tensor([[-2.0205, -4.5728],
        [-1.9981, -1.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212255895137787
Epoch 0, Step 2065: train/loss = 0.23784767091274261, train/raw-loss = 0.18144679069519043, train/logprobs = tensor([[ -0.9925, -11.1940],
        [ -1.9289,  -1.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18800291419029236
Epoch 0, Step 2066: train/loss = 0.367530882358551, train/raw-loss = 0.30013594031333923, train/logprobs = tensor([[-0.9718, -5.7334],
        [-1.9402, -1.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2246498465538025
Epoch 0, Step 2067: train/loss = 0.4688096046447754, train/raw-loss = 0.4085797965526581, train/logprobs = tensor([[-1.4769, -5.5736],
        [-1.7596, -1.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20076589286327362
Epoch 0, Step 2068: train/loss = 0.5613454580307007, train/raw-loss = 0.5018734335899353, train/logprobs = tensor([[-1.1140, -4.1474],
        [-1.8463, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19823996722698212
Epoch 0, Step 2069: train/loss = 0.4188936948776245, train/raw-loss = 0.35805708169937134, train/logprobs = tensor([[-0.7659, -3.6579],
        [-1.7595, -1.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20278868079185486
Epoch 0, Step 2070: train/loss = 0.1619926244020462, train/raw-loss = 0.09990440309047699, train/logprobs = tensor([[ -1.3356, -10.7569],
        [ -3.2314,  -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20696072280406952
Epoch 0, Step 2071: train/loss = 0.461836576461792, train/raw-loss = 0.3897557556629181, train/logprobs = tensor([[-1.2304, -4.3788],
        [-1.6966, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24026936292648315
Epoch 0, Step 2072: train/loss = 0.2532949447631836, train/raw-loss = 0.18380525708198547, train/logprobs = tensor([[-1.0742, -7.3620],
        [-2.2879, -0.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2316323220729828
Epoch 0, Step 2073: train/loss = 0.3382898271083832, train/raw-loss = 0.26466768980026245, train/logprobs = tensor([[-1.2607, -5.0145],
        [-2.0265, -1.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2454070746898651
Epoch 0, Step 2074: train/loss = 0.44389039278030396, train/raw-loss = 0.383020281791687, train/logprobs = tensor([[-0.8557, -3.1127],
        [-1.9523, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2029002159833908
Epoch 0, Step 2075: train/loss = 0.49861884117126465, train/raw-loss = 0.4321601390838623, train/logprobs = tensor([[-1.0416, -2.8582],
        [-1.8635, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.221529021859169
Epoch 0, Step 2076: train/loss = 0.3824933171272278, train/raw-loss = 0.3205489218235016, train/logprobs = tensor([[-1.8191, -9.4753],
        [-2.1458, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2064812332391739
Epoch 0, Step 2077: train/loss = 0.30180197954177856, train/raw-loss = 0.24250370264053345, train/logprobs = tensor([[-0.8792, -6.8453],
        [-1.8207, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19766093790531158
Epoch 0, Step 2078: train/loss = 0.2453083097934723, train/raw-loss = 0.18079203367233276, train/logprobs = tensor([[-1.3031, -4.9979],
        [-2.4265, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2150542140007019
Epoch 0, Step 2079: train/loss = 0.3637857735157013, train/raw-loss = 0.3047454357147217, train/logprobs = tensor([[-0.7184, -5.8209],
        [-1.5042, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19680102169513702
Epoch 0, Step 2080: train/loss = 0.23417262732982635, train/raw-loss = 0.17463690042495728, train/logprobs = tensor([[-1.1214, -7.1570],
        [-2.3453, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19845238327980042
Epoch 0, Step 2081: train/loss = 0.3645963966846466, train/raw-loss = 0.2919735014438629, train/logprobs = tensor([[-1.4163, -3.9398],
        [-2.8512, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2420763075351715
Epoch 0, Step 2082: train/loss = 0.2411034107208252, train/raw-loss = 0.18009334802627563, train/logprobs = tensor([[ -0.8985, -12.7886],
        [ -2.2660,  -1.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20336684584617615
Epoch 0, Step 2083: train/loss = 0.4501224160194397, train/raw-loss = 0.3877815008163452, train/logprobs = tensor([[-1.2580, -2.8771],
        [-2.0565, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2078031301498413
Epoch 0, Step 2084: train/loss = 0.23058858513832092, train/raw-loss = 0.17268435657024384, train/logprobs = tensor([[-0.9649, -8.0121],
        [-3.1256, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19301412999629974
Epoch 0, Step 2085: train/loss = 0.498451292514801, train/raw-loss = 0.45961490273475647, train/logprobs = tensor([[-1.1718, -3.7979],
        [-1.2716, -2.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294546276330948
Epoch 0, Step 2086: train/loss = 0.3653621971607208, train/raw-loss = 0.3129907548427582, train/logprobs = tensor([[-0.6258, -4.7904],
        [-1.1542, -0.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17457155883312225
Epoch 0, Step 2087: train/loss = 0.15387892723083496, train/raw-loss = 0.08683893084526062, train/logprobs = tensor([[ -1.4128, -15.5581],
        [ -3.1042,  -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234666347503662
Epoch 0, Step 2088: train/loss = 0.41688182950019836, train/raw-loss = 0.355855256319046, train/logprobs = tensor([[-0.6960, -8.9729],
        [-2.0672, -1.4720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20342183113098145
Epoch 0, Step 2089: train/loss = 0.6166791915893555, train/raw-loss = 0.5610257983207703, train/logprobs = tensor([[-1.7862, -3.8987],
        [-1.3765, -1.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18551120162010193
Epoch 0, Step 2090: train/loss = 0.5397012829780579, train/raw-loss = 0.48730555176734924, train/logprobs = tensor([[-1.7324, -3.4792],
        [-1.6785, -1.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174652561545372
Epoch 0, Step 2091: train/loss = 0.36281800270080566, train/raw-loss = 0.314777672290802, train/logprobs = tensor([[-0.9240, -4.0511],
        [-1.3013, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16013436019420624
Epoch 0, Step 2092: train/loss = 0.1661587655544281, train/raw-loss = 0.09843496978282928, train/logprobs = tensor([[-0.8640, -7.5179],
        [-2.4657, -1.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22574591636657715
Epoch 0, Step 2093: train/loss = 0.6528701782226562, train/raw-loss = 0.5927832722663879, train/logprobs = tensor([[-2.5832, -5.9787],
        [-2.0132, -1.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20028965175151825
Epoch 0, Step 2094: train/loss = 0.250296413898468, train/raw-loss = 0.18890583515167236, train/logprobs = tensor([[-0.6814, -9.4811],
        [-2.2255, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20463521778583527
Epoch 0, Step 2095: train/loss = 0.4828072786331177, train/raw-loss = 0.41319066286087036, train/logprobs = tensor([[-1.0924, -5.3319],
        [-2.2084, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23205527663230896
Epoch 0, Step 2096: train/loss = 0.43497493863105774, train/raw-loss = 0.37865594029426575, train/logprobs = tensor([[-1.3987, -8.3958],
        [-1.9615, -1.2699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18772995471954346
Epoch 0, Step 2097: train/loss = 0.44273099303245544, train/raw-loss = 0.3745451271533966, train/logprobs = tensor([[-1.0313, -4.7752],
        [-1.8698, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22728605568408966
Epoch 0, Step 2098: train/loss = 0.13918593525886536, train/raw-loss = 0.073982834815979, train/logprobs = tensor([[-0.8528, -7.0678],
        [-2.8479, -1.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21734365820884705
Epoch 0, Step 2099: train/loss = 0.33200210332870483, train/raw-loss = 0.2604367434978485, train/logprobs = tensor([[-1.1163, -7.7400],
        [-1.5043, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23855116963386536
Epoch 0, Step 2100: train/loss = 0.4806520938873291, train/raw-loss = 0.40865209698677063, train/logprobs = tensor([[-0.9807, -2.2587],
        [-1.6729, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2399999350309372
Epoch 0, Step 2101: train/loss = 0.4483833611011505, train/raw-loss = 0.3890600800514221, train/logprobs = tensor([[-0.9682, -3.6935],
        [-1.9433, -1.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.197744220495224
Epoch 0, Step 2102: train/loss = 0.37960386276245117, train/raw-loss = 0.33164212107658386, train/logprobs = tensor([[-1.2708, -6.7441],
        [-1.4295, -0.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15987257659435272
Epoch 0, Step 2103: train/loss = 0.3359966278076172, train/raw-loss = 0.274574875831604, train/logprobs = tensor([[-0.8745, -6.8386],
        [-1.7940, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2047392725944519
Epoch 0, Step 2104: train/loss = 0.3722926676273346, train/raw-loss = 0.3145494759082794, train/logprobs = tensor([[-0.8554, -2.6073],
        [-2.0801, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19247734546661377
Epoch 0, Step 2105: train/loss = 0.4195246994495392, train/raw-loss = 0.34418341517448425, train/logprobs = tensor([[-1.0959, -3.9145],
        [-2.3688, -2.5808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511376142501831
Epoch 0, Step 2106: train/loss = 0.502181887626648, train/raw-loss = 0.43638208508491516, train/logprobs = tensor([[-0.7784, -2.6766],
        [-1.4095, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2193327248096466
Epoch 0, Step 2107: train/loss = 0.40935972332954407, train/raw-loss = 0.3545939028263092, train/logprobs = tensor([[-1.5998, -3.7352],
        [-1.9289, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18255282938480377
Epoch 0, Step 2108: train/loss = 0.3088636100292206, train/raw-loss = 0.263007253408432, train/logprobs = tensor([[-0.9134, -7.1101],
        [-1.7818, -1.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15285444259643555
Epoch 0, Step 2109: train/loss = 0.3791987895965576, train/raw-loss = 0.32403212785720825, train/logprobs = tensor([[ -0.8194, -13.1663],
        [ -1.5656,  -1.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18388880789279938
Epoch 0, Step 2110: train/loss = 0.5381935238838196, train/raw-loss = 0.48250025510787964, train/logprobs = tensor([[-2.0142, -4.2547],
        [-1.9688, -1.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18564429879188538
Epoch 0, Step 2111: train/loss = 0.31184032559394836, train/raw-loss = 0.24061483144760132, train/logprobs = tensor([[-1.0971, -4.4855],
        [-2.4808, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23741817474365234
Epoch 0, Step 2112: train/loss = 0.28505706787109375, train/raw-loss = 0.22308874130249023, train/logprobs = tensor([[-0.8148, -7.6622],
        [-2.2997, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20656105875968933
Epoch 0, Step 2113: train/loss = 0.3653615713119507, train/raw-loss = 0.29851454496383667, train/logprobs = tensor([[ -0.9007, -10.0264],
        [ -2.7345,  -1.2224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22282351553440094
Epoch 0, Step 2114: train/loss = 0.24927055835723877, train/raw-loss = 0.18179410696029663, train/logprobs = tensor([[-1.0191, -9.1126],
        [-1.8240, -2.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2249215543270111
Epoch 0, Step 2115: train/loss = 0.16362795233726501, train/raw-loss = 0.102628692984581, train/logprobs = tensor([[ -1.0454, -11.1178],
        [ -2.7840,  -1.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033308446407318
Epoch 0, Step 2116: train/loss = 0.2840351462364197, train/raw-loss = 0.2105063796043396, train/logprobs = tensor([[-1.5978, -8.8222],
        [-3.2263, -2.2004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2450958639383316
Epoch 0, Step 2117: train/loss = 0.5076261758804321, train/raw-loss = 0.45686835050582886, train/logprobs = tensor([[-0.5500, -4.9392],
        [-1.4300, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691928207874298
Epoch 0, Step 2118: train/loss = 0.35132837295532227, train/raw-loss = 0.28513750433921814, train/logprobs = tensor([[-0.9848, -8.1196],
        [-1.6346, -1.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22063615918159485
Epoch 0, Step 2119: train/loss = 0.2373584806919098, train/raw-loss = 0.17069320380687714, train/logprobs = tensor([[-1.0687, -5.1605],
        [-2.4418, -0.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22221757471561432
Epoch 0, Step 2120: train/loss = 0.8679873943328857, train/raw-loss = 0.8127814531326294, train/logprobs = tensor([[-2.8545, -3.2484],
        [-1.5201, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1840200126171112
Epoch 0, Step 2121: train/loss = 0.6728949546813965, train/raw-loss = 0.6035456657409668, train/logprobs = tensor([[-2.3289, -7.0500],
        [-1.7867, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23116451501846313
Epoch 0, Step 2122: train/loss = 0.3475186824798584, train/raw-loss = 0.2834032475948334, train/logprobs = tensor([[-1.6151, -6.5269],
        [-2.0060, -1.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21371811628341675
Epoch 0, Step 2123: train/loss = 0.5078619718551636, train/raw-loss = 0.44246309995651245, train/logprobs = tensor([[-1.9251, -6.9117],
        [-2.2059, -1.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21799613535404205
Epoch 0, Step 2124: train/loss = 0.2513830363750458, train/raw-loss = 0.1836022436618805, train/logprobs = tensor([[-1.2482, -6.2773],
        [-2.5767, -1.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259359359741211
Epoch 0, Step 2125: train/loss = 0.27849307656288147, train/raw-loss = 0.21961596608161926, train/logprobs = tensor([[-0.9349, -4.5414],
        [-1.6307, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19625701010227203
Epoch 0, Step 2126: train/loss = 0.4024190902709961, train/raw-loss = 0.3472127616405487, train/logprobs = tensor([[-0.8440, -3.2006],
        [-2.2009, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18402113020420074
Epoch 0, Step 2127: train/loss = 0.2558304965496063, train/raw-loss = 0.18825341761112213, train/logprobs = tensor([[-2.2310, -9.8959],
        [-3.2840, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22525691986083984
Epoch 0, Step 2128: train/loss = 0.28673967719078064, train/raw-loss = 0.23386219143867493, train/logprobs = tensor([[-1.1994, -6.0699],
        [-2.2415, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17625819146633148
Epoch 0, Step 2129: train/loss = 0.31268858909606934, train/raw-loss = 0.256719172000885, train/logprobs = tensor([[-0.5354, -6.2825],
        [-1.6811, -1.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1865645945072174
Epoch 0, Step 2130: train/loss = 0.3806878924369812, train/raw-loss = 0.31675925850868225, train/logprobs = tensor([[-1.5593, -4.5929],
        [-1.8290, -1.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21309542655944824
Epoch 0, Step 2131: train/loss = 0.29745492339134216, train/raw-loss = 0.22954592108726501, train/logprobs = tensor([[-1.0372, -4.0808],
        [-1.9881, -0.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22636333107948303
Epoch 0, Step 2132: train/loss = 0.3313813805580139, train/raw-loss = 0.2736985683441162, train/logprobs = tensor([[-1.5545, -7.6348],
        [-2.1080, -0.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19227614998817444
Epoch 0, Step 2133: train/loss = 0.3495134115219116, train/raw-loss = 0.2957417368888855, train/logprobs = tensor([[-1.0035, -5.3221],
        [-1.4507, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17923897504806519
Epoch 0, Step 2134: train/loss = 0.5675714015960693, train/raw-loss = 0.4912562668323517, train/logprobs = tensor([[-2.1016, -6.9880],
        [-2.3915, -0.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25438380241394043
Epoch 0, Step 2135: train/loss = 0.34325867891311646, train/raw-loss = 0.2862468957901001, train/logprobs = tensor([[-0.5008, -7.3142],
        [-2.2292, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1900392472743988
Epoch 0, Step 2136: train/loss = 0.2808649241924286, train/raw-loss = 0.21157841384410858, train/logprobs = tensor([[-0.8508, -6.1398],
        [-2.2485, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23095500469207764
Epoch 0, Step 2137: train/loss = 0.3579053282737732, train/raw-loss = 0.28832003474235535, train/logprobs = tensor([[-1.1124, -5.1280],
        [-2.0241, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23195090889930725
Epoch 0, Step 2138: train/loss = 0.1494186520576477, train/raw-loss = 0.09873926639556885, train/logprobs = tensor([[-1.1592, -7.3239],
        [-3.5677, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16893130540847778
Epoch 0, Step 2139: train/loss = 0.2817397117614746, train/raw-loss = 0.21753084659576416, train/logprobs = tensor([[-0.9768, -6.4670],
        [-2.5748, -1.7789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21402959525585175
Epoch 0, Step 2140: train/loss = 0.423484742641449, train/raw-loss = 0.3784042000770569, train/logprobs = tensor([[-1.0753, -4.1970],
        [-1.4630, -1.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502683460712433
Epoch 0, Step 2141: train/loss = 2.19016170501709, train/raw-loss = 2.122060775756836, train/logprobs = tensor([[-7.6105, -7.8483],
        [-2.4747, -1.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22700399160385132
Epoch 0, Step 2142: train/loss = 0.17061175405979156, train/raw-loss = 0.10149501264095306, train/logprobs = tensor([[-1.1187, -7.6029],
        [-3.1100, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23038917779922485
Epoch 0, Step 2143: train/loss = 0.4038621485233307, train/raw-loss = 0.3398915231227875, train/logprobs = tensor([[-0.9735, -5.7248],
        [-1.4254, -0.7575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21323524415493011
Epoch 0, Step 2144: train/loss = 0.4951983392238617, train/raw-loss = 0.42970529198646545, train/logprobs = tensor([[-1.4832, -3.1731],
        [-1.6524, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2183101773262024
Epoch 0, Step 2145: train/loss = 0.38818636536598206, train/raw-loss = 0.3352023661136627, train/logprobs = tensor([[-0.6168, -3.5306],
        [-1.1234, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17661328613758087
Epoch 0, Step 2146: train/loss = 0.3501132130622864, train/raw-loss = 0.2889465391635895, train/logprobs = tensor([[-1.3714, -3.9283],
        [-1.9134, -0.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.203888937830925
Epoch 0, Step 2147: train/loss = 0.28277578949928284, train/raw-loss = 0.22187098860740662, train/logprobs = tensor([[-1.8078, -6.0125],
        [-2.6237, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20301595330238342
Epoch 0, Step 2148: train/loss = 0.10530571639537811, train/raw-loss = 0.05171411857008934, train/logprobs = tensor([[-0.9201, -7.5716],
        [-3.3291, -1.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17863865196704865
Epoch 0, Step 2149: train/loss = 0.4655190706253052, train/raw-loss = 0.4113268554210663, train/logprobs = tensor([[-0.9989, -6.3922],
        [-1.7452, -2.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18064069747924805
Epoch 0, Step 2150: train/loss = 0.4378768801689148, train/raw-loss = 0.38149625062942505, train/logprobs = tensor([[-2.5320, -4.5898],
        [-3.2643, -1.5886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18793541193008423
Epoch 0, Step 2151: train/loss = 0.4724797010421753, train/raw-loss = 0.43216264247894287, train/logprobs = tensor([[-1.3973, -8.6960],
        [-1.6339, -1.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343902200460434
Epoch 0, Step 2152: train/loss = 0.4584248960018158, train/raw-loss = 0.4053463339805603, train/logprobs = tensor([[-0.7274, -4.2485],
        [-1.0966, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17692846059799194
Epoch 0, Step 2153: train/loss = 0.3308365046977997, train/raw-loss = 0.23539762198925018, train/logprobs = tensor([[-1.2608, -4.9127],
        [-3.3069, -1.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181295394897461
Epoch 0, Step 2154: train/loss = 0.28686922788619995, train/raw-loss = 0.2249525785446167, train/logprobs = tensor([[-1.4655, -7.1245],
        [-2.5677, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20638884603977203
Epoch 0, Step 2155: train/loss = 0.22305117547512054, train/raw-loss = 0.16596916317939758, train/logprobs = tensor([[ -0.7169, -12.7029],
        [ -2.2929,  -1.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19027334451675415
Epoch 0, Step 2156: train/loss = 0.48509514331817627, train/raw-loss = 0.43251490592956543, train/logprobs = tensor([[-0.8295, -5.1830],
        [-1.6299, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17526750266551971
Epoch 0, Step 2157: train/loss = 0.15382494032382965, train/raw-loss = 0.08603095263242722, train/logprobs = tensor([[-1.4312, -7.5620],
        [-3.4350, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22597992420196533
Epoch 0, Step 2158: train/loss = 0.571537435054779, train/raw-loss = 0.5022616386413574, train/logprobs = tensor([[-1.2119, -7.6475],
        [-2.6748, -2.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23091912269592285
Epoch 0, Step 2159: train/loss = 0.9332952499389648, train/raw-loss = 0.8549398183822632, train/logprobs = tensor([[ -3.4329, -10.2608],
        [ -3.9646,  -2.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26118478178977966
Epoch 0, Step 2160: train/loss = 0.3068668246269226, train/raw-loss = 0.2344626635313034, train/logprobs = tensor([[-0.5486, -6.8514],
        [-2.3231, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24134719371795654
Epoch 0, Step 2161: train/loss = 0.32605308294296265, train/raw-loss = 0.2633611261844635, train/logprobs = tensor([[-2.0626, -7.5472],
        [-2.6311, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20897316932678223
Epoch 0, Step 2162: train/loss = 0.40303558111190796, train/raw-loss = 0.33817651867866516, train/logprobs = tensor([[-1.0226, -4.5565],
        [-2.6241, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21619684994220734
Epoch 0, Step 2163: train/loss = 0.3435654640197754, train/raw-loss = 0.27050453424453735, train/logprobs = tensor([[-0.9137, -3.8998],
        [-2.1737, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24353647232055664
Epoch 0, Step 2164: train/loss = 0.230983167886734, train/raw-loss = 0.17774824798107147, train/logprobs = tensor([[ -0.9295, -11.5650],
        [ -2.4355,  -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774497628211975
Epoch 0, Step 2165: train/loss = 0.4636879563331604, train/raw-loss = 0.407985121011734, train/logprobs = tensor([[-0.5280, -2.3477],
        [-1.5746, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1856761872768402
Epoch 0, Step 2166: train/loss = 0.4516860246658325, train/raw-loss = 0.39510607719421387, train/logprobs = tensor([[-1.0073, -9.2434],
        [-1.5040, -1.4064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18859978020191193
Epoch 0, Step 2167: train/loss = 0.5523898601531982, train/raw-loss = 0.4907710552215576, train/logprobs = tensor([[-0.5634, -1.1922],
        [-1.9256, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20539605617523193
Epoch 0, Step 2168: train/loss = 0.3628120422363281, train/raw-loss = 0.3109883666038513, train/logprobs = tensor([[-1.1454, -6.5248],
        [-1.2753, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727454960346222
Epoch 0, Step 2169: train/loss = 0.5325258374214172, train/raw-loss = 0.4799377918243408, train/logprobs = tensor([[-0.8099, -2.3244],
        [-2.2085, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17529353499412537
Epoch 0, Step 2170: train/loss = 0.26714929938316345, train/raw-loss = 0.19459186494350433, train/logprobs = tensor([[-1.7507, -8.0946],
        [-3.1337, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24185815453529358
Epoch 0, Step 2171: train/loss = 0.6357637643814087, train/raw-loss = 0.561038613319397, train/logprobs = tensor([[-1.9485, -5.4664],
        [-1.3053, -1.3503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2490839958190918
Epoch 0, Step 2172: train/loss = 0.5683275461196899, train/raw-loss = 0.5178190469741821, train/logprobs = tensor([[-0.9256, -2.7739],
        [-1.3242, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1683616042137146
Epoch 0, Step 2173: train/loss = 0.4718165397644043, train/raw-loss = 0.41534143686294556, train/logprobs = tensor([[-1.0543, -6.7238],
        [-1.3528, -2.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18825025856494904
Epoch 0, Step 2174: train/loss = 0.33654698729515076, train/raw-loss = 0.2757933735847473, train/logprobs = tensor([[-0.6695, -3.7264],
        [-1.5829, -0.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20251211524009705
Epoch 0, Step 2175: train/loss = 0.2789105772972107, train/raw-loss = 0.21949982643127441, train/logprobs = tensor([[-0.7695, -7.8790],
        [-2.2814, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19803586602210999
Epoch 0, Step 2176: train/loss = 0.4002496302127838, train/raw-loss = 0.3507421314716339, train/logprobs = tensor([[-2.3831, -7.6442],
        [-2.7615, -1.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16502490639686584
Epoch 0, Step 2177: train/loss = 0.4351026117801666, train/raw-loss = 0.36952659487724304, train/logprobs = tensor([[-1.7674, -7.3556],
        [-2.1492, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2185867428779602
Epoch 0, Step 2178: train/loss = 0.35176706314086914, train/raw-loss = 0.2928488552570343, train/logprobs = tensor([[-1.2064, -7.8937],
        [-1.6176, -1.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19639399647712708
Epoch 0, Step 2179: train/loss = 0.41072091460227966, train/raw-loss = 0.35094571113586426, train/logprobs = tensor([[-1.1038, -3.4445],
        [-1.6322, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19925081729888916
Epoch 0, Step 2180: train/loss = 0.44170820713043213, train/raw-loss = 0.38110846281051636, train/logprobs = tensor([[-0.5459, -4.8200],
        [-1.2838, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20199915766716003
Epoch 0, Step 2181: train/loss = 0.19833777844905853, train/raw-loss = 0.11851976811885834, train/logprobs = tensor([[-0.8684, -6.9781],
        [-2.7095, -1.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2660600244998932
Epoch 0, Step 2182: train/loss = 0.6066591143608093, train/raw-loss = 0.5404966473579407, train/logprobs = tensor([[-1.3708, -4.4198],
        [-1.2500, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22054153680801392
Epoch 0, Step 2183: train/loss = 0.1848631501197815, train/raw-loss = 0.11217013001441956, train/logprobs = tensor([[-1.0849, -6.5801],
        [-2.8582, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2423100769519806
Epoch 0, Step 2184: train/loss = 0.750232458114624, train/raw-loss = 0.6902079582214355, train/logprobs = tensor([[-0.7459, -1.0345],
        [-2.7167, -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20008143782615662
Epoch 0, Step 2185: train/loss = 0.4963548183441162, train/raw-loss = 0.42193421721458435, train/logprobs = tensor([[-1.4574, -3.7089],
        [-2.1554, -1.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24806861579418182
Epoch 0, Step 2186: train/loss = 0.32993146777153015, train/raw-loss = 0.27562612295150757, train/logprobs = tensor([[-1.0937, -5.9536],
        [-1.7162, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18101781606674194
Epoch 0, Step 2187: train/loss = 0.45401060581207275, train/raw-loss = 0.3795372247695923, train/logprobs = tensor([[-1.2767, -3.2992],
        [-3.2593, -1.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24824470281600952
Epoch 0, Step 2188: train/loss = 0.2321552187204361, train/raw-loss = 0.15084730088710785, train/logprobs = tensor([[-1.0900, -6.3113],
        [-3.2888, -1.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2710264027118683
Epoch 0, Step 2189: train/loss = 0.515685498714447, train/raw-loss = 0.46399986743927, train/logprobs = tensor([[-0.8993, -3.1598],
        [-1.3509, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17228543758392334
Epoch 0, Step 2190: train/loss = 0.2068169265985489, train/raw-loss = 0.14570888876914978, train/logprobs = tensor([[ -1.5630, -15.0577],
        [ -2.9148,  -1.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20369340479373932
Epoch 0, Step 2191: train/loss = 0.4636308252811432, train/raw-loss = 0.4035128355026245, train/logprobs = tensor([[-0.9250, -2.2874],
        [-1.6864, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20039315521717072
Epoch 0, Step 2192: train/loss = 0.1994195580482483, train/raw-loss = 0.12178469449281693, train/logprobs = tensor([[-1.3942, -6.3521],
        [-3.4871, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25878286361694336
Epoch 0, Step 2193: train/loss = 0.39450860023498535, train/raw-loss = 0.3299265503883362, train/logprobs = tensor([[-0.7062, -4.5125],
        [-1.8999, -1.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21527348458766937
Epoch 0, Step 2194: train/loss = 0.43746477365493774, train/raw-loss = 0.38725489377975464, train/logprobs = tensor([[-1.1952, -8.0779],
        [-1.6071, -0.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16736634075641632
Epoch 0, Step 2195: train/loss = 0.25866249203681946, train/raw-loss = 0.1993849277496338, train/logprobs = tensor([[ -0.9978, -10.0096],
        [ -2.2313,  -1.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1975918710231781
Epoch 0, Step 2196: train/loss = 0.7221788167953491, train/raw-loss = 0.6657079458236694, train/logprobs = tensor([[-1.5213, -1.5057],
        [-1.2734, -0.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18823634088039398
Epoch 0, Step 2197: train/loss = 0.24700409173965454, train/raw-loss = 0.17820347845554352, train/logprobs = tensor([[-1.3038, -9.7968],
        [-2.1778, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22933530807495117
Epoch 0, Step 2198: train/loss = 0.4230484962463379, train/raw-loss = 0.3659285306930542, train/logprobs = tensor([[-2.2513, -9.6048],
        [-2.3920, -2.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19039985537528992
Epoch 0, Step 2199: train/loss = 0.5686413049697876, train/raw-loss = 0.5116195678710938, train/logprobs = tensor([[-0.7329, -1.3081],
        [-1.3282, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190072700381279
Epoch 0, Step 2200: train/loss = 0.3722175359725952, train/raw-loss = 0.30918312072753906, train/logprobs = tensor([[-0.7598, -3.9796],
        [-2.2851, -1.2925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21011468768119812
Epoch 0, Step 2201: train/loss = 0.4907745122909546, train/raw-loss = 0.4415525197982788, train/logprobs = tensor([[-0.7903, -1.7886],
        [-0.9946, -0.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16407319903373718
Epoch 0, Step 2202: train/loss = 0.5243345499038696, train/raw-loss = 0.45928242802619934, train/logprobs = tensor([[-1.3015, -2.0356],
        [-2.0036, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21684041619300842
Epoch 0, Step 2203: train/loss = 0.3089548945426941, train/raw-loss = 0.23051217198371887, train/logprobs = tensor([[-1.2133, -6.9955],
        [-3.2005, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614755928516388
Epoch 0, Step 2204: train/loss = 0.35457634925842285, train/raw-loss = 0.30174362659454346, train/logprobs = tensor([[-1.1267, -5.6619],
        [-1.8460, -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17610904574394226
Epoch 0, Step 2205: train/loss = 0.2647712230682373, train/raw-loss = 0.20932920277118683, train/logprobs = tensor([[-0.7257, -6.9041],
        [-2.4795, -1.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18480665981769562
Epoch 0, Step 2206: train/loss = 0.5482233762741089, train/raw-loss = 0.4947556257247925, train/logprobs = tensor([[-1.2317, -2.9300],
        [-1.3607, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17822563648223877
Epoch 0, Step 2207: train/loss = 0.19319544732570648, train/raw-loss = 0.1298161745071411, train/logprobs = tensor([[-0.9557, -6.9036],
        [-2.3184, -0.8297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21126419305801392
Epoch 0, Step 2208: train/loss = 0.471511572599411, train/raw-loss = 0.4126891493797302, train/logprobs = tensor([[-0.9813, -4.4883],
        [-1.9997, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1960747241973877
Epoch 0, Step 2209: train/loss = 0.2424093335866928, train/raw-loss = 0.17574697732925415, train/logprobs = tensor([[-1.0643, -7.6497],
        [-2.9235, -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22220781445503235
Epoch 0, Step 2210: train/loss = 0.3891204297542572, train/raw-loss = 0.33573606610298157, train/logprobs = tensor([[-1.3398, -4.6627],
        [-3.0691, -2.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17794790863990784
Epoch 0, Step 2211: train/loss = 0.43595826625823975, train/raw-loss = 0.35567960143089294, train/logprobs = tensor([[-0.7167, -6.0118],
        [-3.1040, -1.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26759546995162964
Epoch 0, Step 2212: train/loss = 0.3126261830329895, train/raw-loss = 0.23901094496250153, train/logprobs = tensor([[-1.3017, -6.3370],
        [-2.8053, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24538415670394897
Epoch 0, Step 2213: train/loss = 0.23940351605415344, train/raw-loss = 0.1804257333278656, train/logprobs = tensor([[-1.0768, -7.0597],
        [-1.9836, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19659259915351868
Epoch 0, Step 2214: train/loss = 0.17793095111846924, train/raw-loss = 0.10949763655662537, train/logprobs = tensor([[-1.1540, -8.0302],
        [-3.3731, -1.5354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22811104357242584
Epoch 0, Step 2215: train/loss = 0.3570069372653961, train/raw-loss = 0.2858569622039795, train/logprobs = tensor([[-1.6203, -6.0690],
        [-1.9207, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23716655373573303
Epoch 0, Step 2216: train/loss = 0.26705023646354675, train/raw-loss = 0.2017894685268402, train/logprobs = tensor([[-1.5134, -6.0905],
        [-3.6061, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2175358533859253
Epoch 0, Step 2217: train/loss = 0.36213937401771545, train/raw-loss = 0.295257568359375, train/logprobs = tensor([[-2.8512, -5.3536],
        [-4.5672, -1.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22293934226036072
Epoch 0, Step 2218: train/loss = 0.3948654234409332, train/raw-loss = 0.3436231315135956, train/logprobs = tensor([[-0.8955, -5.0872],
        [-1.8448, -2.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17080755531787872
Epoch 0, Step 2219: train/loss = 0.38198593258857727, train/raw-loss = 0.33290231227874756, train/logprobs = tensor([[-1.2987, -9.9343],
        [-1.7210, -1.4060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1636120080947876
Epoch 0, Step 2220: train/loss = 0.46488672494888306, train/raw-loss = 0.38973885774612427, train/logprobs = tensor([[-1.4894, -5.1785],
        [-2.8296, -2.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25049278140068054
Epoch 0, Step 2221: train/loss = 0.6813796758651733, train/raw-loss = 0.6198997497558594, train/logprobs = tensor([[ -2.6294, -11.2287],
        [ -1.9245,  -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20493316650390625
Epoch 0, Step 2222: train/loss = 0.3388250470161438, train/raw-loss = 0.28179481625556946, train/logprobs = tensor([[-0.4922, -6.7253],
        [-1.5755, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190100759267807
Epoch 0, Step 2223: train/loss = 0.2549501061439514, train/raw-loss = 0.20383842289447784, train/logprobs = tensor([[-1.0375, -6.4715],
        [-2.8324, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17037224769592285
Epoch 0, Step 2224: train/loss = 0.18924430012702942, train/raw-loss = 0.12373214215040207, train/logprobs = tensor([[ -1.0136, -10.0056],
        [ -3.7290,  -2.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2183738648891449
Epoch 0, Step 2225: train/loss = 0.5260747075080872, train/raw-loss = 0.4730030596256256, train/logprobs = tensor([[-1.4115, -3.6076],
        [-1.6905, -1.1182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17690542340278625
Epoch 0, Step 2226: train/loss = 0.14351266622543335, train/raw-loss = 0.0775357037782669, train/logprobs = tensor([[-0.6944, -9.1151],
        [-2.7008, -1.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21992316842079163
Epoch 0, Step 2227: train/loss = 0.3286045789718628, train/raw-loss = 0.26189231872558594, train/logprobs = tensor([[-0.5632, -4.7465],
        [-2.1623, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22237414121627808
Epoch 0, Step 2228: train/loss = 0.2885049879550934, train/raw-loss = 0.22197549045085907, train/logprobs = tensor([[-0.7654, -6.0196],
        [-2.6640, -1.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2217649668455124
Epoch 0, Step 2229: train/loss = 0.3733453154563904, train/raw-loss = 0.31927552819252014, train/logprobs = tensor([[-0.7563, -5.2170],
        [-1.4103, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802327185869217
Epoch 0, Step 2230: train/loss = 0.34206730127334595, train/raw-loss = 0.284895658493042, train/logprobs = tensor([[-1.3716, -5.1054],
        [-2.3834, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19057214260101318
Epoch 0, Step 2231: train/loss = 0.4219718277454376, train/raw-loss = 0.36633723974227905, train/logprobs = tensor([[-0.6183, -5.2865],
        [-1.1923, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18544858694076538
Epoch 0, Step 2232: train/loss = 0.3678586184978485, train/raw-loss = 0.29048293828964233, train/logprobs = tensor([[-0.9448, -4.3337],
        [-3.7642, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579190135002136
Epoch 0, Step 2233: train/loss = 0.2594519257545471, train/raw-loss = 0.20829442143440247, train/logprobs = tensor([[-1.2912, -8.2912],
        [-1.8848, -0.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1705249845981598
Epoch 0, Step 2234: train/loss = 0.30690911412239075, train/raw-loss = 0.24040596187114716, train/logprobs = tensor([[-1.2544, -7.0397],
        [-2.2684, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22167712450027466
Epoch 0, Step 2235: train/loss = 0.7743461728096008, train/raw-loss = 0.7090485692024231, train/logprobs = tensor([[-2.2119, -5.4972],
        [-2.3318, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21765869855880737
Epoch 0, Step 2236: train/loss = 0.3487936854362488, train/raw-loss = 0.2902451157569885, train/logprobs = tensor([[-0.7121, -4.7924],
        [-1.6806, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19516193866729736
Epoch 0, Step 2237: train/loss = 0.6207405924797058, train/raw-loss = 0.564155101776123, train/logprobs = tensor([[-1.8205, -3.5981],
        [-2.0853, -0.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18861806392669678
Epoch 0, Step 2238: train/loss = 0.35561203956604004, train/raw-loss = 0.2793024778366089, train/logprobs = tensor([[-1.6396, -6.9541],
        [-3.3645, -1.3097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25436532497406006
Epoch 0, Step 2239: train/loss = 0.3432106375694275, train/raw-loss = 0.2763676941394806, train/logprobs = tensor([[-1.0784, -6.8066],
        [-2.0780, -1.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22280986607074738
Epoch 0, Step 2240: train/loss = 0.3332063555717468, train/raw-loss = 0.27018511295318604, train/logprobs = tensor([[-1.3442, -7.2833],
        [-2.0603, -1.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21007072925567627
Epoch 0, Step 2241: train/loss = 0.339510977268219, train/raw-loss = 0.2799019515514374, train/logprobs = tensor([[-1.1335, -3.3118],
        [-2.0354, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1986967772245407
Epoch 0, Step 2242: train/loss = 0.4749357998371124, train/raw-loss = 0.4221401512622833, train/logprobs = tensor([[-1.1034, -4.4446],
        [-2.7471, -1.5718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17598551511764526
Epoch 0, Step 2243: train/loss = 0.4012378454208374, train/raw-loss = 0.3453735113143921, train/logprobs = tensor([[-0.7437, -4.9916],
        [-1.6271, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18621429800987244
Epoch 0, Step 2244: train/loss = 0.2646770179271698, train/raw-loss = 0.19707047939300537, train/logprobs = tensor([[-1.0847, -9.2458],
        [-2.3706, -2.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253550887107849
Epoch 0, Step 2245: train/loss = 0.43484270572662354, train/raw-loss = 0.38754820823669434, train/logprobs = tensor([[-0.8699, -5.7636],
        [-1.3945, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15764831006526947
Epoch 0, Step 2246: train/loss = 0.2527557909488678, train/raw-loss = 0.17923396825790405, train/logprobs = tensor([[-1.0072, -6.7353],
        [-2.5454, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24507270753383636
Epoch 0, Step 2247: train/loss = 0.22380532324314117, train/raw-loss = 0.1549738645553589, train/logprobs = tensor([[-0.8686, -5.0893],
        [-3.1143, -1.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2294381856918335
Epoch 0, Step 2248: train/loss = 0.5299400687217712, train/raw-loss = 0.4755144417285919, train/logprobs = tensor([[-0.5917, -1.2641],
        [-1.2860, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18141873180866241
Epoch 0, Step 2249: train/loss = 0.26947006583213806, train/raw-loss = 0.21882346272468567, train/logprobs = tensor([[-0.8189, -4.3368],
        [-1.7540, -0.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16882194578647614
Epoch 0, Step 2250: train/loss = 0.2984495759010315, train/raw-loss = 0.2347959280014038, train/logprobs = tensor([[-0.7012, -5.5866],
        [-1.9159, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21217885613441467
Epoch 0, Step 2251: train/loss = 0.26526254415512085, train/raw-loss = 0.19896139204502106, train/logprobs = tensor([[-0.7671, -4.9071],
        [-2.0576, -1.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22100377082824707
Epoch 0, Step 2252: train/loss = 0.4904944896697998, train/raw-loss = 0.43652141094207764, train/logprobs = tensor([[-1.0789, -2.6039],
        [-1.4204, -0.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799103021621704
Epoch 0, Step 2253: train/loss = 0.4463942348957062, train/raw-loss = 0.3839283883571625, train/logprobs = tensor([[-0.8170, -5.4584],
        [-1.8122, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20821954309940338
Epoch 0, Step 2254: train/loss = 0.526723325252533, train/raw-loss = 0.4706476926803589, train/logprobs = tensor([[-0.9311, -1.7271],
        [-1.4370, -1.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18691875040531158
Epoch 0, Step 2255: train/loss = 0.2203068733215332, train/raw-loss = 0.1709611415863037, train/logprobs = tensor([[ -1.2505, -14.7816],
        [ -2.1128,  -2.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16448575258255005
Epoch 0, Step 2256: train/loss = 0.4002676010131836, train/raw-loss = 0.3295421004295349, train/logprobs = tensor([[-0.9506, -6.2313],
        [-1.7552, -1.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2357517033815384
Epoch 0, Step 2257: train/loss = 0.45949339866638184, train/raw-loss = 0.4015040397644043, train/logprobs = tensor([[-1.2881, -3.4828],
        [-1.8347, -1.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1932978332042694
Epoch 0, Step 2258: train/loss = 0.373992919921875, train/raw-loss = 0.31106123328208923, train/logprobs = tensor([[-1.1291, -7.4209],
        [-1.9993, -1.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20977221429347992
Epoch 0, Step 2259: train/loss = 0.17652443051338196, train/raw-loss = 0.10986340790987015, train/logprobs = tensor([[ -0.5829, -12.4251],
        [ -2.1897,  -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22220338881015778
Epoch 0, Step 2260: train/loss = 0.34252795577049255, train/raw-loss = 0.2897464632987976, train/logprobs = tensor([[-0.8156, -5.7304],
        [-2.0050, -1.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17593836784362793
Epoch 0, Step 2261: train/loss = 0.2250291407108307, train/raw-loss = 0.15352985262870789, train/logprobs = tensor([[-1.0057, -7.3477],
        [-3.0257, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23833096027374268
Epoch 0, Step 2262: train/loss = 0.44037821888923645, train/raw-loss = 0.37870079278945923, train/logprobs = tensor([[-0.8318, -2.2614],
        [-1.8801, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2055913656949997
Epoch 0, Step 2263: train/loss = 0.4069109261035919, train/raw-loss = 0.3442855775356293, train/logprobs = tensor([[-0.7483, -3.1135],
        [-2.1840, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087511569261551
Epoch 0, Step 2264: train/loss = 0.4303121566772461, train/raw-loss = 0.37697142362594604, train/logprobs = tensor([[-0.8639, -6.1350],
        [-1.3885, -0.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17780236899852753
Epoch 0, Step 2265: train/loss = 0.3133985698223114, train/raw-loss = 0.2585228681564331, train/logprobs = tensor([[-1.2733, -6.3039],
        [-2.6299, -0.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182918980717659
Epoch 0, Step 2266: train/loss = 0.19637878239154816, train/raw-loss = 0.14364777505397797, train/logprobs = tensor([[ -0.9641, -10.8770],
        [ -2.5298,  -1.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17577007412910461
Epoch 0, Step 2267: train/loss = 0.5550216436386108, train/raw-loss = 0.5055041909217834, train/logprobs = tensor([[-0.7950, -1.3027],
        [-1.0813, -0.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16505810618400574
Epoch 0, Step 2268: train/loss = 0.2097223550081253, train/raw-loss = 0.1347150355577469, train/logprobs = tensor([[-0.9512, -5.2425],
        [-3.4745, -1.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500244081020355
Epoch 0, Step 2269: train/loss = 0.4372605085372925, train/raw-loss = 0.37719106674194336, train/logprobs = tensor([[-1.2663, -3.1856],
        [-2.3929, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20023155212402344
Epoch 0, Step 2270: train/loss = 0.30716344714164734, train/raw-loss = 0.2600105404853821, train/logprobs = tensor([[-0.5708, -5.5876],
        [-1.0686, -1.4036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1571764051914215
Epoch 0, Step 2271: train/loss = 0.32662534713745117, train/raw-loss = 0.2666248381137848, train/logprobs = tensor([[-1.2395, -7.0129],
        [-2.4894, -1.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000017762184143
Epoch 0, Step 2272: train/loss = 0.3256469666957855, train/raw-loss = 0.2761419713497162, train/logprobs = tensor([[-1.0245, -7.7127],
        [-3.0355, -1.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16501662135124207
Epoch 0, Step 2273: train/loss = 0.3831712603569031, train/raw-loss = 0.3381557762622833, train/logprobs = tensor([[-1.1706, -5.1034],
        [-1.3078, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15005159378051758
Epoch 0, Step 2274: train/loss = 0.17023330926895142, train/raw-loss = 0.10947790741920471, train/logprobs = tensor([[-0.4447, -6.4244],
        [-1.9228, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2025180160999298
Epoch 0, Step 2275: train/loss = 0.1507827192544937, train/raw-loss = 0.08907916396856308, train/logprobs = tensor([[-0.9762, -6.5195],
        [-3.0132, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20567849278450012
Epoch 0, Step 2276: train/loss = 0.24937932193279266, train/raw-loss = 0.19239738583564758, train/logprobs = tensor([[-0.8835, -7.1866],
        [-2.4876, -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18993976712226868
Epoch 0, Step 2277: train/loss = 0.46698543429374695, train/raw-loss = 0.423359215259552, train/logprobs = tensor([[-0.5978, -2.1227],
        [-1.0383, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14542070031166077
Epoch 0, Step 2278: train/loss = 0.3536120653152466, train/raw-loss = 0.2902238368988037, train/logprobs = tensor([[-1.3835, -4.2388],
        [-2.2009, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21129393577575684
Epoch 0, Step 2279: train/loss = 0.8875330686569214, train/raw-loss = 0.8347837328910828, train/logprobs = tensor([[-3.0150, -8.7154],
        [-1.7395, -1.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17583125829696655
Epoch 0, Step 2280: train/loss = 0.44227534532546997, train/raw-loss = 0.39157018065452576, train/logprobs = tensor([[-0.6952, -3.3589],
        [-1.5501, -1.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16901719570159912
Epoch 0, Step 2281: train/loss = 0.15033650398254395, train/raw-loss = 0.0889129489660263, train/logprobs = tensor([[-0.8233, -7.1591],
        [-3.7070, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20474518835544586
Epoch 0, Step 2282: train/loss = 0.4348911643028259, train/raw-loss = 0.3744940459728241, train/logprobs = tensor([[-0.7894, -5.6290],
        [-1.8171, -1.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20132365822792053
Epoch 0, Step 2283: train/loss = 0.23404355347156525, train/raw-loss = 0.1794309914112091, train/logprobs = tensor([[-0.7031, -6.1684],
        [-1.6590, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18204188346862793
Epoch 0, Step 2284: train/loss = 0.6933343410491943, train/raw-loss = 0.6349069476127625, train/logprobs = tensor([[-1.9390, -5.3313],
        [-2.0300, -1.3945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19475793838500977
Epoch 0, Step 2285: train/loss = 0.31816378235816956, train/raw-loss = 0.2516458034515381, train/logprobs = tensor([[ -1.4298, -10.8197],
        [ -2.2686,  -2.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22172658145427704
Epoch 0, Step 2286: train/loss = 0.2784225344657898, train/raw-loss = 0.217868834733963, train/logprobs = tensor([[-1.4365, -6.7949],
        [-2.1735, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20184573531150818
Epoch 0, Step 2287: train/loss = 0.6799423694610596, train/raw-loss = 0.6201839447021484, train/logprobs = tensor([[-2.1529, -6.7481],
        [-2.1504, -1.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19919487833976746
Epoch 0, Step 2288: train/loss = 0.27918991446495056, train/raw-loss = 0.2246123105287552, train/logprobs = tensor([[-1.4401, -8.0698],
        [-2.0571, -2.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18192531168460846
Epoch 0, Step 2289: train/loss = 0.3773866891860962, train/raw-loss = 0.32560962438583374, train/logprobs = tensor([[-0.8261, -8.2202],
        [-2.5502, -1.4490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17259015142917633
Epoch 0, Step 2290: train/loss = 0.7867509722709656, train/raw-loss = 0.727308988571167, train/logprobs = tensor([[-1.1141, -2.0665],
        [-2.7103, -2.3101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19814011454582214
Epoch 0, Step 2291: train/loss = 0.14114293456077576, train/raw-loss = 0.061114683747291565, train/logprobs = tensor([[-0.9906, -9.5230],
        [-3.9560, -0.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26676082611083984
Epoch 0, Step 2292: train/loss = 0.5606173872947693, train/raw-loss = 0.5114887356758118, train/logprobs = tensor([[-1.7751, -4.8533],
        [-1.7921, -1.4372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1637621521949768
Epoch 0, Step 2293: train/loss = 0.32614028453826904, train/raw-loss = 0.25390756130218506, train/logprobs = tensor([[-1.2181, -4.9815],
        [-2.9185, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24077577888965607
Epoch 0, Step 2294: train/loss = 0.31635361909866333, train/raw-loss = 0.2441815882921219, train/logprobs = tensor([[-0.7512, -8.7828],
        [-2.5503, -1.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2405734807252884
Epoch 0, Step 2295: train/loss = 0.33681029081344604, train/raw-loss = 0.2760528326034546, train/logprobs = tensor([[-1.3530, -4.4218],
        [-2.2400, -1.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2025248110294342
Epoch 0, Step 2296: train/loss = 0.46189627051353455, train/raw-loss = 0.41218075156211853, train/logprobs = tensor([[-0.9174, -1.9445],
        [-2.3024, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16571840643882751
Epoch 0, Step 2297: train/loss = 0.33615317940711975, train/raw-loss = 0.27879583835601807, train/logprobs = tensor([[-0.8803, -4.3900],
        [-2.0015, -0.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1911911964416504
Epoch 0, Step 2298: train/loss = 0.11568482220172882, train/raw-loss = 0.05122712627053261, train/logprobs = tensor([[ -0.8967, -17.7075],
        [ -3.6641,  -2.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21485896408557892
Epoch 0, Step 2299: train/loss = 0.546097993850708, train/raw-loss = 0.48280277848243713, train/logprobs = tensor([[-0.8684, -3.1167],
        [-1.5321, -1.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21098390221595764
Epoch 0, Step 2300: train/loss = 0.1737251728773117, train/raw-loss = 0.12178722023963928, train/logprobs = tensor([[-1.3072, -5.2693],
        [-2.9361, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731264889240265
Epoch 0, Step 2301: train/loss = 0.20982900261878967, train/raw-loss = 0.1390477865934372, train/logprobs = tensor([[-0.7937, -9.4162],
        [-3.3971, -1.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23593735694885254
Epoch 0, Step 2302: train/loss = 0.397915244102478, train/raw-loss = 0.35002708435058594, train/logprobs = tensor([[-0.5096, -8.6397],
        [-2.3060, -1.3494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15962712466716766
Epoch 0, Step 2303: train/loss = 0.258032888174057, train/raw-loss = 0.19168944656848907, train/logprobs = tensor([[-1.3721, -6.8972],
        [-3.1109, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22114478051662445
Epoch 0, Step 2304: train/loss = 0.328830361366272, train/raw-loss = 0.26456066966056824, train/logprobs = tensor([[-0.9213, -8.0369],
        [-1.9131, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2142322063446045
Epoch 0, Step 2305: train/loss = 0.5279719829559326, train/raw-loss = 0.45983022451400757, train/logprobs = tensor([[-1.9884, -8.9456],
        [-2.3418, -1.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22713914513587952
Epoch 0, Step 2306: train/loss = 0.40936729311943054, train/raw-loss = 0.36216801404953003, train/logprobs = tensor([[-1.2254, -4.1646],
        [-1.6841, -1.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1573309749364853
Epoch 0, Step 2307: train/loss = 0.5183915495872498, train/raw-loss = 0.4609573483467102, train/logprobs = tensor([[-0.8303, -5.2523],
        [-3.4064, -2.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1914471834897995
Epoch 0, Step 2308: train/loss = 0.4431024193763733, train/raw-loss = 0.3847867548465729, train/logprobs = tensor([[-0.6349, -4.4060],
        [-1.1727, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19438548386096954
Epoch 0, Step 2309: train/loss = 0.41423526406288147, train/raw-loss = 0.365153044462204, train/logprobs = tensor([[ -2.0203, -10.2161],
        [ -1.8344,  -1.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1636073887348175
Epoch 0, Step 2310: train/loss = 0.5670639276504517, train/raw-loss = 0.49497562646865845, train/logprobs = tensor([[-1.2026, -3.9721],
        [-2.8005, -2.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24029412865638733
Epoch 0, Step 2311: train/loss = 0.5719324350357056, train/raw-loss = 0.5213425159454346, train/logprobs = tensor([[-0.6641, -2.6072],
        [-0.9676, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16863295435905457
Epoch 0, Step 2312: train/loss = 0.2628037929534912, train/raw-loss = 0.19955699145793915, train/logprobs = tensor([[-0.7989, -4.3824],
        [-2.3400, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21082265675067902
Epoch 0, Step 2313: train/loss = 0.2397247850894928, train/raw-loss = 0.17223793268203735, train/logprobs = tensor([[-0.9442, -6.0070],
        [-2.5295, -1.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224956214427948
Epoch 0, Step 2314: train/loss = 0.22820819914340973, train/raw-loss = 0.16877862811088562, train/logprobs = tensor([[ -1.0678, -10.6736],
        [ -2.0482,  -1.6311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19809864461421967
Epoch 0, Step 2315: train/loss = 0.22624465823173523, train/raw-loss = 0.15709279477596283, train/logprobs = tensor([[-1.0430, -6.2149],
        [-2.6128, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23050624132156372
Epoch 0, Step 2316: train/loss = 0.3314249813556671, train/raw-loss = 0.27961036562919617, train/logprobs = tensor([[-0.7850, -4.8116],
        [-1.8451, -0.7441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17271541059017181
Epoch 0, Step 2317: train/loss = 0.26858046650886536, train/raw-loss = 0.21507227420806885, train/logprobs = tensor([[-1.3005, -6.1765],
        [-1.9542, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17836061120033264
Epoch 0, Step 2318: train/loss = 0.4813079237937927, train/raw-loss = 0.4335266053676605, train/logprobs = tensor([[-0.7656, -4.2017],
        [-1.2789, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1592709869146347
Epoch 0, Step 2319: train/loss = 0.22851359844207764, train/raw-loss = 0.16073738038539886, train/logprobs = tensor([[-1.3748, -8.0778],
        [-2.7299, -1.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22592070698738098
Epoch 0, Step 2320: train/loss = 0.3851574659347534, train/raw-loss = 0.31354543566703796, train/logprobs = tensor([[-1.0241, -4.6577],
        [-1.8979, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2387067973613739
Epoch 0, Step 2321: train/loss = 0.5056971907615662, train/raw-loss = 0.4387752115726471, train/logprobs = tensor([[-0.7175, -3.3656],
        [-1.6213, -1.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2230733036994934
Epoch 0, Step 2322: train/loss = 0.4521001875400543, train/raw-loss = 0.3859636187553406, train/logprobs = tensor([[-2.8539, -7.8061],
        [-3.2520, -1.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22045524418354034
Epoch 0, Step 2323: train/loss = 0.5700390338897705, train/raw-loss = 0.5186271071434021, train/logprobs = tensor([[-1.0564, -1.7100],
        [-1.2907, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17137295007705688
Epoch 0, Step 2324: train/loss = 0.33064764738082886, train/raw-loss = 0.2752225995063782, train/logprobs = tensor([[-0.7590, -7.6177],
        [-1.7015, -1.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18475015461444855
Epoch 0, Step 2325: train/loss = 0.4981227219104767, train/raw-loss = 0.44694846868515015, train/logprobs = tensor([[-0.4905, -2.4793],
        [-0.9135, -0.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17058080434799194
Epoch 0, Step 2326: train/loss = 0.22599507868289948, train/raw-loss = 0.1514347493648529, train/logprobs = tensor([[ -1.4722, -10.0001],
        [ -3.8472,  -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24853438138961792
Epoch 0, Step 2327: train/loss = 0.4916742444038391, train/raw-loss = 0.4418780207633972, train/logprobs = tensor([[-1.1977, -5.7900],
        [-1.7972, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16598743200302124
Epoch 0, Step 2328: train/loss = 0.4229152798652649, train/raw-loss = 0.3355126976966858, train/logprobs = tensor([[-0.8847, -6.6154],
        [-2.5423, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29134196043014526
Epoch 0, Step 2329: train/loss = 0.45799165964126587, train/raw-loss = 0.41075754165649414, train/logprobs = tensor([[-0.6745, -4.8740],
        [-1.0330, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15744704008102417
Epoch 0, Step 2330: train/loss = 0.30163294076919556, train/raw-loss = 0.23617488145828247, train/logprobs = tensor([[-0.6544, -4.8868],
        [-1.9669, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21819350123405457
Epoch 0, Step 2331: train/loss = 0.6165670156478882, train/raw-loss = 0.5613335967063904, train/logprobs = tensor([[-1.3431, -3.3837],
        [-0.9136, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1841113567352295
Epoch 0, Step 2332: train/loss = 0.33223122358322144, train/raw-loss = 0.2756872773170471, train/logprobs = tensor([[-0.9314, -5.9075],
        [-1.9822, -1.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18847990036010742
Epoch 0, Step 2333: train/loss = 0.39782455563545227, train/raw-loss = 0.32465967535972595, train/logprobs = tensor([[-0.8547, -4.3601],
        [-2.8370, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24388298392295837
Epoch 0, Step 2334: train/loss = 0.35796409845352173, train/raw-loss = 0.2960752844810486, train/logprobs = tensor([[-1.3567, -7.1452],
        [-1.7371, -2.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20629599690437317
Epoch 0, Step 2335: train/loss = 0.09704847633838654, train/raw-loss = 0.03963194787502289, train/logprobs = tensor([[ -1.1173, -11.1869],
        [ -4.1218,  -2.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19138841331005096
Epoch 0, Step 2336: train/loss = 0.3123757541179657, train/raw-loss = 0.2536703944206238, train/logprobs = tensor([[-0.7826, -8.3519],
        [-2.5231, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19568446278572083
Epoch 0, Step 2337: train/loss = 0.24790571630001068, train/raw-loss = 0.18055196106433868, train/logprobs = tensor([[ -2.1099, -10.8031],
        [ -3.2937,  -1.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22451256215572357
Epoch 0, Step 2338: train/loss = 0.3512822985649109, train/raw-loss = 0.27555200457572937, train/logprobs = tensor([[-1.3842, -4.0137],
        [-2.9356, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25243428349494934
Epoch 0, Step 2339: train/loss = 0.470858097076416, train/raw-loss = 0.4171912670135498, train/logprobs = tensor([[-1.6340, -4.0988],
        [-2.0055, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788894087076187
Epoch 0, Step 2340: train/loss = 0.3824215531349182, train/raw-loss = 0.3202841579914093, train/logprobs = tensor([[-1.1410, -3.1607],
        [-2.3445, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2071247100830078
Epoch 0, Step 2341: train/loss = 0.7364070415496826, train/raw-loss = 0.6828782558441162, train/logprobs = tensor([[-2.1832, -4.5807],
        [-1.7006, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17842933535575867
Epoch 0, Step 2342: train/loss = 0.43155810236930847, train/raw-loss = 0.37452730536460876, train/logprobs = tensor([[-0.8067, -2.1727],
        [-1.8021, -1.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1901026964187622
Epoch 0, Step 2343: train/loss = 0.20771834254264832, train/raw-loss = 0.13486993312835693, train/logprobs = tensor([[-0.7209, -6.5730],
        [-2.6709, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24282801151275635
Epoch 0, Step 2344: train/loss = 0.23431068658828735, train/raw-loss = 0.18426287174224854, train/logprobs = tensor([[-0.7950, -6.6417],
        [-1.9345, -1.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1668260544538498
Epoch 0, Step 2345: train/loss = 0.2546381950378418, train/raw-loss = 0.19797906279563904, train/logprobs = tensor([[-0.6810, -7.9140],
        [-2.6636, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1888638138771057
Epoch 0, Step 2346: train/loss = 0.3004821836948395, train/raw-loss = 0.24856159090995789, train/logprobs = tensor([[-0.7505, -5.6146],
        [-1.4769, -0.6791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17306865751743317
Epoch 0, Step 2347: train/loss = 0.34584081172943115, train/raw-loss = 0.2802499830722809, train/logprobs = tensor([[-0.9512, -5.3797],
        [-3.1796, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21863599121570587
Epoch 0, Step 2348: train/loss = 0.17221537232398987, train/raw-loss = 0.11239391565322876, train/logprobs = tensor([[-1.4157, -6.8333],
        [-3.2113, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19940486550331116
Epoch 0, Step 2349: train/loss = 0.9314342737197876, train/raw-loss = 0.8745079040527344, train/logprobs = tensor([[-2.6670, -4.2751],
        [-1.3400, -1.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897544264793396
Epoch 0, Step 2350: train/loss = 0.4010702073574066, train/raw-loss = 0.35104018449783325, train/logprobs = tensor([[-0.7222, -3.7829],
        [-1.3704, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16676679253578186
Epoch 0, Step 2351: train/loss = 0.4438628554344177, train/raw-loss = 0.3940430283546448, train/logprobs = tensor([[-0.6002, -2.5678],
        [-1.4514, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16606606543064117
Epoch 0, Step 2352: train/loss = 0.22208856046199799, train/raw-loss = 0.17242465913295746, train/logprobs = tensor([[-0.7348, -6.8080],
        [-2.2202, -1.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16554631292819977
Epoch 0, Step 2353: train/loss = 0.43269777297973633, train/raw-loss = 0.37784039974212646, train/logprobs = tensor([[-0.7768, -4.5823],
        [-1.4028, -0.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18285799026489258
Epoch 0, Step 2354: train/loss = 0.36630797386169434, train/raw-loss = 0.301323264837265, train/logprobs = tensor([[-2.1398, -5.0828],
        [-2.5787, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2166157066822052
Epoch 0, Step 2355: train/loss = 0.26815345883369446, train/raw-loss = 0.2081609070301056, train/logprobs = tensor([[-0.8847, -9.8521],
        [-2.7548, -1.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19997522234916687
Epoch 0, Step 2356: train/loss = 0.32175540924072266, train/raw-loss = 0.25829339027404785, train/logprobs = tensor([[-1.1973, -7.4235],
        [-1.7027, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2115401327610016
Epoch 0, Step 2357: train/loss = 0.30921608209609985, train/raw-loss = 0.2245883047580719, train/logprobs = tensor([[-1.3268, -4.8439],
        [-2.4723, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2820926010608673
Epoch 0, Step 2358: train/loss = 0.32375043630599976, train/raw-loss = 0.2723301649093628, train/logprobs = tensor([[-1.1262, -4.3090],
        [-2.7836, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17140085995197296
Epoch 0, Step 2359: train/loss = 0.20093339681625366, train/raw-loss = 0.13475200533866882, train/logprobs = tensor([[-1.1997, -8.8253],
        [-3.2748, -1.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22060462832450867
Epoch 0, Step 2360: train/loss = 0.3309396803379059, train/raw-loss = 0.27741897106170654, train/logprobs = tensor([[-0.8538, -4.3685],
        [-1.7626, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17840245366096497
Epoch 0, Step 2361: train/loss = 0.3106926679611206, train/raw-loss = 0.24345745146274567, train/logprobs = tensor([[-1.1554, -5.6774],
        [-2.1931, -1.1618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2241174429655075
Epoch 0, Step 2362: train/loss = 0.2562773525714874, train/raw-loss = 0.18133984506130219, train/logprobs = tensor([[-0.7445, -4.2160],
        [-1.9068, -0.7124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24979177117347717
Epoch 0, Step 2363: train/loss = 0.3130532503128052, train/raw-loss = 0.25390470027923584, train/logprobs = tensor([[-0.8561, -4.3354],
        [-2.1498, -0.7910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1971617490053177
Epoch 0, Step 2364: train/loss = 0.49830079078674316, train/raw-loss = 0.4373742341995239, train/logprobs = tensor([[-1.8605, -4.1516],
        [-2.6397, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20308858156204224
Epoch 0, Step 2365: train/loss = 0.3024086356163025, train/raw-loss = 0.2510219216346741, train/logprobs = tensor([[-0.7705, -7.1485],
        [-1.4996, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17128916084766388
Epoch 0, Step 2366: train/loss = 0.45597028732299805, train/raw-loss = 0.39959394931793213, train/logprobs = tensor([[-1.0371, -3.6942],
        [-0.9079, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1879211813211441
Epoch 0, Step 2367: train/loss = 0.4828665256500244, train/raw-loss = 0.4326000213623047, train/logprobs = tensor([[-0.7219, -2.9907],
        [-1.5249, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675550788640976
Epoch 0, Step 2368: train/loss = 0.5666049122810364, train/raw-loss = 0.5070486664772034, train/logprobs = tensor([[-2.0396, -5.4059],
        [-2.1229, -1.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19852077960968018
Epoch 0, Step 2369: train/loss = 0.44297146797180176, train/raw-loss = 0.38559097051620483, train/logprobs = tensor([[-0.9202, -3.5658],
        [-2.0945, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19126833975315094
Epoch 0, Step 2370: train/loss = 0.15855872631072998, train/raw-loss = 0.09908314049243927, train/logprobs = tensor([[-1.2127, -7.6401],
        [-2.8776, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19825193285942078
Epoch 0, Step 2371: train/loss = 0.25109127163887024, train/raw-loss = 0.18048113584518433, train/logprobs = tensor([[-0.9720, -4.3409],
        [-2.5509, -1.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23536717891693115
Epoch 0, Step 2372: train/loss = 0.2837664484977722, train/raw-loss = 0.21010370552539825, train/logprobs = tensor([[-0.6211, -7.1883],
        [-2.4391, -1.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2455425262451172
Epoch 0, Step 2373: train/loss = 0.22801315784454346, train/raw-loss = 0.1580977439880371, train/logprobs = tensor([[-0.6807, -5.1361],
        [-2.6843, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2330513894557953
Epoch 0, Step 2374: train/loss = 0.30750179290771484, train/raw-loss = 0.24226117134094238, train/logprobs = tensor([[-0.6456, -5.4497],
        [-1.4290, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21746881306171417
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-13 01:50:00,762][root][INFO] - beta: 0.4
[2024-03-13 01:50:00,762][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.4-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6566261053085327, train/raw-loss = 0.6497894525527954, train/logprobs = tensor([[-0.5577, -0.9073],
        [-0.4924, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01709161326289177
Epoch 0, Step 65: train/loss = 0.5920658111572266, train/raw-loss = 0.5865657925605774, train/logprobs = tensor([[-0.4079, -2.3925],
        [-0.4040, -1.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013750179670751095
Epoch 0, Step 66: train/loss = 0.6338993310928345, train/raw-loss = 0.6269830465316772, train/logprobs = tensor([[-0.6674, -1.2270],
        [-0.6749, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01729084737598896
Epoch 0, Step 67: train/loss = 0.6149088144302368, train/raw-loss = 0.6090624332427979, train/logprobs = tensor([[-0.4550, -1.6505],
        [-0.4388, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014615766704082489
Epoch 0, Step 68: train/loss = 0.6264838576316833, train/raw-loss = 0.6203752756118774, train/logprobs = tensor([[-0.5328, -0.8147],
        [-0.6252, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01527143083512783
Epoch 0, Step 69: train/loss = 0.643507719039917, train/raw-loss = 0.6373023986816406, train/logprobs = tensor([[-0.6258, -0.8797],
        [-0.6359, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015513364225625992
Epoch 0, Step 70: train/loss = 0.6085793972015381, train/raw-loss = 0.6029224395751953, train/logprobs = tensor([[-0.5833, -1.5771],
        [-0.5850, -1.1800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014142408967018127
Epoch 0, Step 71: train/loss = 0.6181466579437256, train/raw-loss = 0.6123076677322388, train/logprobs = tensor([[-0.5105, -1.2087],
        [-0.5342, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01459735818207264
Epoch 0, Step 72: train/loss = 0.6427726745605469, train/raw-loss = 0.63658207654953, train/logprobs = tensor([[-0.5497, -1.3694],
        [-0.5536, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015476444736123085
Epoch 0, Step 73: train/loss = 0.6806927919387817, train/raw-loss = 0.6739844083786011, train/logprobs = tensor([[-0.5521, -1.0912],
        [-0.5404, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016770802438259125
Epoch 0, Step 74: train/loss = 0.6532460451126099, train/raw-loss = 0.646000862121582, train/logprobs = tensor([[-0.6144, -0.9856],
        [-0.5830, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018112890422344208
Epoch 0, Step 75: train/loss = 0.6107017993927002, train/raw-loss = 0.6057240962982178, train/logprobs = tensor([[-0.4146, -1.3261],
        [-0.4372, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012444347143173218
Epoch 0, Step 76: train/loss = 0.5492939949035645, train/raw-loss = 0.5439069271087646, train/logprobs = tensor([[-0.4639, -2.4539],
        [-0.4996, -1.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013467572629451752
Epoch 0, Step 77: train/loss = 0.6111436486244202, train/raw-loss = 0.6047768592834473, train/logprobs = tensor([[-0.6563, -1.0097],
        [-0.6916, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01591690629720688
Epoch 0, Step 78: train/loss = 0.6566998362541199, train/raw-loss = 0.6500385999679565, train/logprobs = tensor([[-0.6863, -0.9494],
        [-0.6827, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01665307953953743
Epoch 0, Step 79: train/loss = 0.5808169841766357, train/raw-loss = 0.5749181509017944, train/logprobs = tensor([[-0.5694, -2.4096],
        [-0.5741, -1.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014747042208909988
Epoch 0, Step 80: train/loss = 0.6322970986366272, train/raw-loss = 0.6252997517585754, train/logprobs = tensor([[-0.7401, -1.0077],
        [-0.7339, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01749344728887081
Epoch 0, Step 81: train/loss = 0.575447678565979, train/raw-loss = 0.5710379481315613, train/logprobs = tensor([[-0.5280, -2.4977],
        [-0.5217, -1.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011024432256817818
Epoch 0, Step 82: train/loss = 0.65370774269104, train/raw-loss = 0.6463433504104614, train/logprobs = tensor([[-0.6923, -1.1149],
        [-0.6227, -0.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018410859629511833
Epoch 0, Step 83: train/loss = 0.6888282299041748, train/raw-loss = 0.6808361411094666, train/logprobs = tensor([[-1.5373, -1.6580],
        [-1.4981, -1.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019980138167738914
Epoch 0, Step 84: train/loss = 0.6472470760345459, train/raw-loss = 0.6397107839584351, train/logprobs = tensor([[-0.6090, -0.9770],
        [-0.5901, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018840808421373367
Epoch 0, Step 85: train/loss = 0.5671044588088989, train/raw-loss = 0.5607754588127136, train/logprobs = tensor([[-0.5894, -2.0137],
        [-0.5813, -1.3679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015822453424334526
Epoch 0, Step 86: train/loss = 0.6333609819412231, train/raw-loss = 0.6265246272087097, train/logprobs = tensor([[-0.5675, -0.9142],
        [-0.5943, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01709097996354103
Epoch 0, Step 87: train/loss = 0.6108285188674927, train/raw-loss = 0.6044998168945312, train/logprobs = tensor([[-0.6350, -1.0348],
        [-0.7050, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0158216692507267
Epoch 0, Step 88: train/loss = 0.6177374720573425, train/raw-loss = 0.6102138161659241, train/logprobs = tensor([[-1.0053, -2.1751],
        [-0.9349, -1.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018809165805578232
Epoch 0, Step 89: train/loss = 0.6431445479393005, train/raw-loss = 0.6360172629356384, train/logprobs = tensor([[-0.5685, -0.9947],
        [-0.5556, -0.7305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017818383872509003
Epoch 0, Step 90: train/loss = 0.6338193416595459, train/raw-loss = 0.6272153854370117, train/logprobs = tensor([[-0.4661, -1.0592],
        [-0.4742, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016509773209691048
Epoch 0, Step 91: train/loss = 0.4499983787536621, train/raw-loss = 0.4448845088481903, train/logprobs = tensor([[-0.4691, -2.7865],
        [-0.5088, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012784612365067005
Epoch 0, Step 92: train/loss = 0.6578316688537598, train/raw-loss = 0.649827778339386, train/logprobs = tensor([[-0.6957, -1.0901],
        [-0.6934, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020009811967611313
Epoch 0, Step 93: train/loss = 0.5968955159187317, train/raw-loss = 0.5905071496963501, train/logprobs = tensor([[-0.5692, -1.4601],
        [-0.5583, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015970805659890175
Epoch 0, Step 94: train/loss = 0.596005380153656, train/raw-loss = 0.5892868041992188, train/logprobs = tensor([[-0.6789, -1.8418],
        [-0.7702, -1.3469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016796492040157318
Epoch 0, Step 95: train/loss = 0.6317818760871887, train/raw-loss = 0.6263784170150757, train/logprobs = tensor([[-0.5264, -1.0153],
        [-0.5224, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013508674688637257
Epoch 0, Step 96: train/loss = 0.7011638879776001, train/raw-loss = 0.6835193037986755, train/logprobs = tensor([[-0.5987, -0.8955],
        [-0.5844, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04411141946911812
Epoch 0, Step 97: train/loss = 0.577964186668396, train/raw-loss = 0.5631046295166016, train/logprobs = tensor([[-0.6351, -1.9437],
        [-0.6157, -1.2065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03714900091290474
Epoch 0, Step 98: train/loss = 0.624605655670166, train/raw-loss = 0.6134305596351624, train/logprobs = tensor([[-0.3840, -0.9799],
        [-0.3295, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027937807142734528
Epoch 0, Step 99: train/loss = 0.637640118598938, train/raw-loss = 0.6255564093589783, train/logprobs = tensor([[-0.5290, -1.0444],
        [-0.5055, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030209431424736977
Epoch 0, Step 100: train/loss = 0.5536967515945435, train/raw-loss = 0.541363537311554, train/logprobs = tensor([[-0.6795, -2.7801],
        [-0.6598, -1.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03083300031721592
Epoch 0, Step 101: train/loss = 0.6088045239448547, train/raw-loss = 0.5877493619918823, train/logprobs = tensor([[-0.9595, -1.8423],
        [-0.9285, -1.2887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052638016641139984
Epoch 0, Step 102: train/loss = 0.5915987491607666, train/raw-loss = 0.5774692893028259, train/logprobs = tensor([[-0.4960, -1.3585],
        [-0.4895, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03532358631491661
Epoch 0, Step 103: train/loss = 0.5661267042160034, train/raw-loss = 0.5540899634361267, train/logprobs = tensor([[-0.6354, -1.7196],
        [-0.5483, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030091876164078712
Epoch 0, Step 104: train/loss = 0.46026813983917236, train/raw-loss = 0.4443162977695465, train/logprobs = tensor([[-0.7944, -4.5108],
        [-0.6604, -2.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039879560470581055
Epoch 0, Step 105: train/loss = 0.6120485067367554, train/raw-loss = 0.597355842590332, train/logprobs = tensor([[-0.6755, -1.1983],
        [-0.6216, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03673175349831581
Epoch 0, Step 106: train/loss = 0.46521472930908203, train/raw-loss = 0.4529310166835785, train/logprobs = tensor([[-0.6798, -4.4003],
        [-0.6219, -2.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030709311366081238
Epoch 0, Step 107: train/loss = 0.616046667098999, train/raw-loss = 0.5977826118469238, train/logprobs = tensor([[-0.7187, -1.5334],
        [-0.6783, -1.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0456601157784462
Epoch 0, Step 108: train/loss = 0.6709923148155212, train/raw-loss = 0.6613966226577759, train/logprobs = tensor([[-0.5286, -0.6599],
        [-0.4650, -0.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023989364504814148
Epoch 0, Step 109: train/loss = 0.6156921982765198, train/raw-loss = 0.6025880575180054, train/logprobs = tensor([[-0.6376, -1.2755],
        [-0.5533, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032760217785835266
Epoch 0, Step 110: train/loss = 0.5513472557067871, train/raw-loss = 0.5383578538894653, train/logprobs = tensor([[-0.6620, -2.9571],
        [-0.5462, -1.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032473575323820114
Epoch 0, Step 111: train/loss = 0.5844399929046631, train/raw-loss = 0.57417893409729, train/logprobs = tensor([[-0.4361, -1.5098],
        [-0.4179, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02565254271030426
Epoch 0, Step 112: train/loss = 0.6099275350570679, train/raw-loss = 0.5972123146057129, train/logprobs = tensor([[-0.6299, -1.1028],
        [-0.5920, -0.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03178803622722626
Epoch 0, Step 113: train/loss = 0.6450934410095215, train/raw-loss = 0.6263361573219299, train/logprobs = tensor([[-0.6481, -1.2780],
        [-0.5740, -0.8999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04689318314194679
Epoch 0, Step 114: train/loss = 0.613384485244751, train/raw-loss = 0.5984967947006226, train/logprobs = tensor([[-0.5656, -1.0681],
        [-0.5356, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03721925616264343
Epoch 0, Step 115: train/loss = 0.6257506608963013, train/raw-loss = 0.6137208938598633, train/logprobs = tensor([[-0.5651, -1.1638],
        [-0.5314, -0.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030074289068579674
Epoch 0, Step 116: train/loss = 0.5747119188308716, train/raw-loss = 0.5585212111473083, train/logprobs = tensor([[-0.6684, -2.0659],
        [-0.6101, -1.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040476854890584946
Epoch 0, Step 117: train/loss = 0.630794882774353, train/raw-loss = 0.6172407865524292, train/logprobs = tensor([[-0.4845, -1.7665],
        [-0.4606, -1.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033885326236486435
Epoch 0, Step 118: train/loss = 0.5041872262954712, train/raw-loss = 0.492929071187973, train/logprobs = tensor([[-0.6569, -3.1997],
        [-0.5727, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02814546786248684
Epoch 0, Step 119: train/loss = 0.5817180871963501, train/raw-loss = 0.564781904220581, train/logprobs = tensor([[-0.6162, -1.6879],
        [-0.5656, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042340539395809174
Epoch 0, Step 120: train/loss = 0.5336822271347046, train/raw-loss = 0.5180044174194336, train/logprobs = tensor([[-0.7851, -2.6275],
        [-0.7661, -1.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03919440507888794
Epoch 0, Step 121: train/loss = 0.6150506734848022, train/raw-loss = 0.6023492813110352, train/logprobs = tensor([[-0.5008, -1.2416],
        [-0.4476, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03175339102745056
Epoch 0, Step 122: train/loss = 0.5517345666885376, train/raw-loss = 0.5368353128433228, train/logprobs = tensor([[-0.8464, -1.9518],
        [-0.7427, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0372481569647789
Epoch 0, Step 123: train/loss = 0.6780955195426941, train/raw-loss = 0.663787305355072, train/logprobs = tensor([[-0.5321, -0.7973],
        [-0.5077, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03577045351266861
Epoch 0, Step 124: train/loss = 0.5950310826301575, train/raw-loss = 0.5788748264312744, train/logprobs = tensor([[-0.7930, -1.6133],
        [-0.7069, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0403907410800457
Epoch 0, Step 125: train/loss = 0.5510811805725098, train/raw-loss = 0.5357125401496887, train/logprobs = tensor([[-0.7043, -3.1946],
        [-0.6292, -2.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038421642035245895
Epoch 0, Step 126: train/loss = 0.6428793668746948, train/raw-loss = 0.6257709264755249, train/logprobs = tensor([[-0.6763, -1.2064],
        [-0.5704, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0427711196243763
Epoch 0, Step 127: train/loss = 0.6242728233337402, train/raw-loss = 0.6094068288803101, train/logprobs = tensor([[-0.5108, -1.4984],
        [-0.4445, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03716496750712395
Epoch 0, Step 128: train/loss = 0.694448709487915, train/raw-loss = 0.6513451933860779, train/logprobs = tensor([[-0.8247, -1.0398],
        [-0.7815, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10775870084762573
Epoch 0, Step 129: train/loss = 0.5666861534118652, train/raw-loss = 0.5121602416038513, train/logprobs = tensor([[-0.7420, -2.8746],
        [-0.6301, -1.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13631464540958405
Epoch 0, Step 130: train/loss = 0.6718790531158447, train/raw-loss = 0.6232619881629944, train/logprobs = tensor([[-0.5360, -1.1615],
        [-0.4672, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12154268473386765
Epoch 0, Step 131: train/loss = 0.5528523921966553, train/raw-loss = 0.4979555308818817, train/logprobs = tensor([[-0.7756, -4.1052],
        [-0.6811, -2.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1372421383857727
Epoch 0, Step 132: train/loss = 0.5783709287643433, train/raw-loss = 0.5280218720436096, train/logprobs = tensor([[-0.7892, -2.3608],
        [-0.6362, -1.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12587252259254456
Epoch 0, Step 133: train/loss = 0.5898603200912476, train/raw-loss = 0.5380958914756775, train/logprobs = tensor([[-0.6450, -2.4243],
        [-0.5571, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12941117584705353
Epoch 0, Step 134: train/loss = 0.604045033454895, train/raw-loss = 0.5569558143615723, train/logprobs = tensor([[-0.7503, -1.6746],
        [-0.6180, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11772315204143524
Epoch 0, Step 135: train/loss = 0.6423692107200623, train/raw-loss = 0.5910593271255493, train/logprobs = tensor([[-0.5186, -1.4956],
        [-0.3926, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12827466428279877
Epoch 0, Step 136: train/loss = 0.5678473711013794, train/raw-loss = 0.5205968618392944, train/logprobs = tensor([[-0.4411, -2.1379],
        [-0.3931, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11812639236450195
Epoch 0, Step 137: train/loss = 0.6396839618682861, train/raw-loss = 0.5933988094329834, train/logprobs = tensor([[-0.4382, -1.3473],
        [-0.4020, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11571288108825684
Epoch 0, Step 138: train/loss = 0.590857207775116, train/raw-loss = 0.537567138671875, train/logprobs = tensor([[-0.4379, -1.7299],
        [-0.3624, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13322508335113525
Epoch 0, Step 139: train/loss = 0.5716656446456909, train/raw-loss = 0.5206276178359985, train/logprobs = tensor([[-0.6157, -2.3885],
        [-0.4940, -1.3205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12759503722190857
Epoch 0, Step 140: train/loss = 0.6249768137931824, train/raw-loss = 0.576686441898346, train/logprobs = tensor([[-0.7793, -1.7754],
        [-0.6581, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12072581052780151
Epoch 0, Step 141: train/loss = 0.6309790015220642, train/raw-loss = 0.578886866569519, train/logprobs = tensor([[-0.9168, -1.9346],
        [-0.6736, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13023044168949127
Epoch 0, Step 142: train/loss = 0.6560431718826294, train/raw-loss = 0.609876811504364, train/logprobs = tensor([[-0.5607, -1.2274],
        [-0.4756, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11541600525379181
Epoch 0, Step 143: train/loss = 0.6767709255218506, train/raw-loss = 0.6312033534049988, train/logprobs = tensor([[-0.7480, -1.5806],
        [-0.5867, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1139189749956131
Epoch 0, Step 144: train/loss = 0.5084661245346069, train/raw-loss = 0.4636934697628021, train/logprobs = tensor([[-0.5749, -3.9747],
        [-0.4950, -2.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11193151772022247
Epoch 0, Step 145: train/loss = 0.6532063484191895, train/raw-loss = 0.611285924911499, train/logprobs = tensor([[-0.6447, -1.5361],
        [-0.5590, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10480113327503204
Epoch 0, Step 146: train/loss = 0.5919253826141357, train/raw-loss = 0.5443998575210571, train/logprobs = tensor([[-0.6452, -2.7969],
        [-0.5121, -1.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11881372332572937
Epoch 0, Step 147: train/loss = 0.6508598327636719, train/raw-loss = 0.6051136255264282, train/logprobs = tensor([[-0.6220, -1.2016],
        [-0.5144, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11436550319194794
Epoch 0, Step 148: train/loss = 0.7344130277633667, train/raw-loss = 0.6808441281318665, train/logprobs = tensor([[-1.5311, -1.8692],
        [-1.1298, -1.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13392220437526703
Epoch 0, Step 149: train/loss = 0.6696946620941162, train/raw-loss = 0.627289891242981, train/logprobs = tensor([[-0.6337, -1.2797],
        [-0.5208, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10601192712783813
Epoch 0, Step 150: train/loss = 0.5801233649253845, train/raw-loss = 0.5326175093650818, train/logprobs = tensor([[-0.8218, -3.5343],
        [-0.7203, -2.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876467615365982
Epoch 0, Step 151: train/loss = 0.6273134350776672, train/raw-loss = 0.5781067609786987, train/logprobs = tensor([[-0.6733, -1.8668],
        [-0.5273, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12301678955554962
Epoch 0, Step 152: train/loss = 0.6527549028396606, train/raw-loss = 0.5993273854255676, train/logprobs = tensor([[-0.8352, -1.4051],
        [-0.7584, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13356870412826538
Epoch 0, Step 153: train/loss = 0.6212610006332397, train/raw-loss = 0.5657318830490112, train/logprobs = tensor([[-0.6174, -2.0641],
        [-0.5019, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1388227641582489
Epoch 0, Step 154: train/loss = 0.6805298328399658, train/raw-loss = 0.6358543634414673, train/logprobs = tensor([[-0.7449, -1.6227],
        [-0.6454, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11168863624334335
Epoch 0, Step 155: train/loss = 0.5933778285980225, train/raw-loss = 0.5519558191299438, train/logprobs = tensor([[-0.5962, -2.9378],
        [-0.5005, -1.7862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355502367019653
Epoch 0, Step 156: train/loss = 0.6881316304206848, train/raw-loss = 0.6495146155357361, train/logprobs = tensor([[-0.6368, -0.7660],
        [-0.5703, -0.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654255211353302
Epoch 0, Step 157: train/loss = 0.7231866121292114, train/raw-loss = 0.6862549781799316, train/logprobs = tensor([[-0.7402, -0.8012],
        [-0.6490, -0.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09232921898365021
Epoch 0, Step 158: train/loss = 0.6904623508453369, train/raw-loss = 0.6445484161376953, train/logprobs = tensor([[-0.6983, -1.2201],
        [-0.4865, -0.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478494107723236
Epoch 0, Step 159: train/loss = 0.7105602025985718, train/raw-loss = 0.6666598916053772, train/logprobs = tensor([[-0.8603, -1.0532],
        [-0.7135, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10975086688995361
Epoch 0, Step 160: train/loss = 0.5628737211227417, train/raw-loss = 0.5198999643325806, train/logprobs = tensor([[-1.1057, -2.3171],
        [-0.8487, -1.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10743448138237
Epoch 0, Step 161: train/loss = 0.6471492648124695, train/raw-loss = 0.6174071431159973, train/logprobs = tensor([[-0.6694, -1.3059],
        [-0.5574, -0.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07435537874698639
Epoch 0, Step 162: train/loss = 0.5888729095458984, train/raw-loss = 0.5565325021743774, train/logprobs = tensor([[-0.5802, -3.0464],
        [-0.5043, -1.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08085106313228607
Epoch 0, Step 163: train/loss = 0.5721173882484436, train/raw-loss = 0.53298020362854, train/logprobs = tensor([[-0.5809, -2.1511],
        [-0.4354, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09784303605556488
Epoch 0, Step 164: train/loss = 0.5881847739219666, train/raw-loss = 0.5558239221572876, train/logprobs = tensor([[-0.6732, -1.8640],
        [-0.5182, -0.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08090227842330933
Epoch 0, Step 165: train/loss = 0.569984495639801, train/raw-loss = 0.5303399562835693, train/logprobs = tensor([[-0.6575, -2.2036],
        [-0.4918, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09911137819290161
Epoch 0, Step 166: train/loss = 0.4483310580253601, train/raw-loss = 0.40913042426109314, train/logprobs = tensor([[-0.6435, -6.8279],
        [-0.4467, -3.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09800158441066742
Epoch 0, Step 167: train/loss = 0.6437240839004517, train/raw-loss = 0.6045072078704834, train/logprobs = tensor([[-0.7324, -1.4599],
        [-0.5694, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980420634150505
Epoch 0, Step 168: train/loss = 0.6131959557533264, train/raw-loss = 0.5771815776824951, train/logprobs = tensor([[-0.7149, -1.5585],
        [-0.5474, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09003574401140213
Epoch 0, Step 169: train/loss = 0.6790626645088196, train/raw-loss = 0.6465110778808594, train/logprobs = tensor([[-0.7962, -1.3409],
        [-0.7260, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0813789814710617
Epoch 0, Step 170: train/loss = 0.6051273345947266, train/raw-loss = 0.5669284462928772, train/logprobs = tensor([[-0.5950, -1.7193],
        [-0.5562, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09549722075462341
Epoch 0, Step 171: train/loss = 0.6645646095275879, train/raw-loss = 0.627496600151062, train/logprobs = tensor([[-0.6552, -1.3720],
        [-0.5131, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267005324363708
Epoch 0, Step 172: train/loss = 0.5239843130111694, train/raw-loss = 0.4857510030269623, train/logprobs = tensor([[-0.6443, -2.6381],
        [-0.5757, -1.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09558334201574326
Epoch 0, Step 173: train/loss = 0.5512151718139648, train/raw-loss = 0.5154278874397278, train/logprobs = tensor([[-0.6258, -2.4944],
        [-0.5419, -1.4310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08946819603443146
Epoch 0, Step 174: train/loss = 0.5562388300895691, train/raw-loss = 0.5191502571105957, train/logprobs = tensor([[-0.6881, -2.0893],
        [-0.5509, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09272152930498123
Epoch 0, Step 175: train/loss = 0.4619406461715698, train/raw-loss = 0.4241068363189697, train/logprobs = tensor([[-0.5109, -3.6502],
        [-0.4041, -1.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09458450227975845
Epoch 0, Step 176: train/loss = 0.620301365852356, train/raw-loss = 0.5767967700958252, train/logprobs = tensor([[-0.7392, -1.6855],
        [-0.4954, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10876151919364929
Epoch 0, Step 177: train/loss = 0.6038976907730103, train/raw-loss = 0.5609403848648071, train/logprobs = tensor([[-1.0758, -2.5448],
        [-0.6338, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739331692457199
Epoch 0, Step 178: train/loss = 0.6336666345596313, train/raw-loss = 0.5951212048530579, train/logprobs = tensor([[-0.8645, -2.4584],
        [-0.7496, -1.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09636354446411133
Epoch 0, Step 179: train/loss = 0.6183440089225769, train/raw-loss = 0.5818080306053162, train/logprobs = tensor([[-0.6632, -2.4990],
        [-0.5002, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133990108966827
Epoch 0, Step 180: train/loss = 0.7184267044067383, train/raw-loss = 0.6807937026023865, train/logprobs = tensor([[-0.8474, -0.9149],
        [-0.6467, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408240765333176
Epoch 0, Step 181: train/loss = 0.7378253936767578, train/raw-loss = 0.698830783367157, train/logprobs = tensor([[-2.8287, -4.1683],
        [-1.8862, -2.3617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09748643636703491
Epoch 0, Step 182: train/loss = 0.6446880102157593, train/raw-loss = 0.6089350581169128, train/logprobs = tensor([[-0.5394, -1.2652],
        [-0.4594, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08938242495059967
Epoch 0, Step 183: train/loss = 0.6022342443466187, train/raw-loss = 0.5636645555496216, train/logprobs = tensor([[-0.7167, -1.7673],
        [-0.5945, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09642411023378372
Epoch 0, Step 184: train/loss = 0.5217951536178589, train/raw-loss = 0.4839950203895569, train/logprobs = tensor([[-1.2007, -4.2534],
        [-1.1756, -2.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09450043737888336
Epoch 0, Step 185: train/loss = 0.6069025993347168, train/raw-loss = 0.5700702667236328, train/logprobs = tensor([[-0.8625, -2.1162],
        [-0.6765, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09208085387945175
Epoch 0, Step 186: train/loss = 0.6148175597190857, train/raw-loss = 0.5678945779800415, train/logprobs = tensor([[-0.8195, -1.6879],
        [-0.7153, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11730752140283585
Epoch 0, Step 187: train/loss = 0.6001654863357544, train/raw-loss = 0.5667122602462769, train/logprobs = tensor([[-0.6103, -2.3384],
        [-0.4898, -1.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363319933414459
Epoch 0, Step 188: train/loss = 0.5311485528945923, train/raw-loss = 0.49272674322128296, train/logprobs = tensor([[-0.8643, -4.1666],
        [-0.6135, -2.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605449438095093
Epoch 0, Step 189: train/loss = 0.6819223761558533, train/raw-loss = 0.6522997617721558, train/logprobs = tensor([[-0.6061, -0.9025],
        [-0.5061, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07405652850866318
Epoch 0, Step 190: train/loss = 0.5614829063415527, train/raw-loss = 0.5281329154968262, train/logprobs = tensor([[-0.8362, -3.7310],
        [-0.6158, -1.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833749771118164
Epoch 0, Step 191: train/loss = 0.6508783102035522, train/raw-loss = 0.6129141449928284, train/logprobs = tensor([[-0.6931, -1.1678],
        [-0.5973, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949103906750679
Epoch 0, Step 192: train/loss = 0.5994312763214111, train/raw-loss = 0.5495991706848145, train/logprobs = tensor([[-0.7664, -1.6116],
        [-0.5569, -0.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12458010017871857
Epoch 0, Step 193: train/loss = 0.5190654993057251, train/raw-loss = 0.4635384678840637, train/logprobs = tensor([[-0.7911, -3.2814],
        [-0.6428, -1.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13881763815879822
Epoch 0, Step 194: train/loss = 0.5180577635765076, train/raw-loss = 0.4659672975540161, train/logprobs = tensor([[-0.9053, -3.9352],
        [-0.7338, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302262842655182
Epoch 0, Step 195: train/loss = 0.5455611348152161, train/raw-loss = 0.49636420607566833, train/logprobs = tensor([[-0.8441, -3.5498],
        [-0.6087, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12299227714538574
Epoch 0, Step 196: train/loss = 0.6183070540428162, train/raw-loss = 0.570479691028595, train/logprobs = tensor([[-0.7225, -1.6135],
        [-0.5830, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11956825852394104
Epoch 0, Step 197: train/loss = 0.5641969442367554, train/raw-loss = 0.5163402557373047, train/logprobs = tensor([[-0.7182, -2.4954],
        [-0.5077, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11964167654514313
Epoch 0, Step 198: train/loss = 0.5965769290924072, train/raw-loss = 0.5481775403022766, train/logprobs = tensor([[-0.6882, -1.8698],
        [-0.5504, -0.6695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12099845707416534
Epoch 0, Step 199: train/loss = 0.489079087972641, train/raw-loss = 0.43887796998023987, train/logprobs = tensor([[-0.5257, -2.4346],
        [-0.3734, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12550273537635803
Epoch 0, Step 200: train/loss = 0.5210355520248413, train/raw-loss = 0.4788590669631958, train/logprobs = tensor([[-0.8953, -2.3631],
        [-0.6701, -0.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10544129461050034
Epoch 0, Step 201: train/loss = 0.5172990560531616, train/raw-loss = 0.46150386333465576, train/logprobs = tensor([[-0.9334, -3.4668],
        [-0.6786, -1.3440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13948792219161987
Epoch 0, Step 202: train/loss = 0.6357440948486328, train/raw-loss = 0.5902128219604492, train/logprobs = tensor([[-0.7091, -1.2034],
        [-0.6739, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11382823437452316
Epoch 0, Step 203: train/loss = 0.629126787185669, train/raw-loss = 0.5776163935661316, train/logprobs = tensor([[-0.7998, -2.8802],
        [-0.4680, -1.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12877598404884338
Epoch 0, Step 204: train/loss = 0.5467743873596191, train/raw-loss = 0.503785252571106, train/logprobs = tensor([[-0.9377, -2.1759],
        [-0.7290, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10747283697128296
Epoch 0, Step 205: train/loss = 0.4746038317680359, train/raw-loss = 0.42694413661956787, train/logprobs = tensor([[-0.5698, -2.5485],
        [-0.5078, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11914926767349243
Epoch 0, Step 206: train/loss = 0.39419710636138916, train/raw-loss = 0.34834861755371094, train/logprobs = tensor([[-0.6267, -5.7122],
        [-0.5215, -1.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11462116241455078
Epoch 0, Step 207: train/loss = 0.5071548223495483, train/raw-loss = 0.4593198001384735, train/logprobs = tensor([[-0.9702, -2.4437],
        [-0.7814, -0.8197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11958754807710648
Epoch 0, Step 208: train/loss = 0.5207347869873047, train/raw-loss = 0.4751913249492645, train/logprobs = tensor([[-0.7970, -3.5590],
        [-0.5410, -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.113858662545681
Epoch 0, Step 209: train/loss = 0.5808396935462952, train/raw-loss = 0.5267348289489746, train/logprobs = tensor([[-0.7868, -2.2069],
        [-0.6291, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1352621465921402
Epoch 0, Step 210: train/loss = 0.5712023377418518, train/raw-loss = 0.5281786918640137, train/logprobs = tensor([[-0.7087, -1.7553],
        [-0.5637, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10755904018878937
Epoch 0, Step 211: train/loss = 0.6159953474998474, train/raw-loss = 0.5696111917495728, train/logprobs = tensor([[-1.1085, -4.2405],
        [-1.0629, -1.8931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11596044898033142
Epoch 0, Step 212: train/loss = 0.6395443677902222, train/raw-loss = 0.5974728465080261, train/logprobs = tensor([[-0.5761, -1.3807],
        [-0.4556, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517875105142593
Epoch 0, Step 213: train/loss = 0.646674394607544, train/raw-loss = 0.5958441495895386, train/logprobs = tensor([[-0.7189, -1.4003],
        [-0.5129, -0.6930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12707552313804626
Epoch 0, Step 214: train/loss = 0.5603628754615784, train/raw-loss = 0.509834885597229, train/logprobs = tensor([[-0.6436, -3.0247],
        [-0.5734, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12632004916667938
Epoch 0, Step 215: train/loss = 0.5308720469474792, train/raw-loss = 0.4808775782585144, train/logprobs = tensor([[-0.9747, -2.9941],
        [-0.8712, -1.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12498611956834793
Epoch 0, Step 216: train/loss = 0.6454415321350098, train/raw-loss = 0.6019120216369629, train/logprobs = tensor([[-0.8398, -1.3274],
        [-0.5292, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882358253002167
Epoch 0, Step 217: train/loss = 0.5088870525360107, train/raw-loss = 0.4616163671016693, train/logprobs = tensor([[-0.6186, -2.6370],
        [-0.5120, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817674338817596
Epoch 0, Step 218: train/loss = 0.7042781114578247, train/raw-loss = 0.6669225692749023, train/logprobs = tensor([[-0.6390, -0.8126],
        [-0.5286, -0.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09338895976543427
Epoch 0, Step 219: train/loss = 0.5993876457214355, train/raw-loss = 0.5539824366569519, train/logprobs = tensor([[-0.6990, -1.8513],
        [-0.5602, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11351292580366135
Epoch 0, Step 220: train/loss = 0.45905131101608276, train/raw-loss = 0.41290801763534546, train/logprobs = tensor([[-1.1638, -3.9071],
        [-0.8766, -1.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11535830050706863
Epoch 0, Step 221: train/loss = 0.5458082556724548, train/raw-loss = 0.5050337314605713, train/logprobs = tensor([[-0.4930, -4.1400],
        [-0.4248, -1.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10193642973899841
Epoch 0, Step 222: train/loss = 0.5926792621612549, train/raw-loss = 0.5504661202430725, train/logprobs = tensor([[-0.7032, -2.1681],
        [-0.5239, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10553296655416489
Epoch 0, Step 223: train/loss = 0.6029374599456787, train/raw-loss = 0.5580006241798401, train/logprobs = tensor([[-0.8683, -2.2195],
        [-0.6405, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.112341970205307
Epoch 0, Step 224: train/loss = 0.5935825109481812, train/raw-loss = 0.5450665950775146, train/logprobs = tensor([[-0.7504, -1.6063],
        [-0.6575, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128999084234238
Epoch 0, Step 225: train/loss = 0.6029840111732483, train/raw-loss = 0.5618998408317566, train/logprobs = tensor([[-0.6356, -1.5727],
        [-0.4444, -0.4124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271057486534119
Epoch 0, Step 226: train/loss = 0.9131274223327637, train/raw-loss = 0.8679132461547852, train/logprobs = tensor([[-2.3023, -3.5113],
        [-0.6756, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11303550004959106
Epoch 0, Step 227: train/loss = 0.5126853585243225, train/raw-loss = 0.4554523229598999, train/logprobs = tensor([[-1.0956, -3.5713],
        [-0.5632, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14308258891105652
Epoch 0, Step 228: train/loss = 0.5634853839874268, train/raw-loss = 0.5244099497795105, train/logprobs = tensor([[-0.5906, -2.1536],
        [-0.4398, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09768850356340408
Epoch 0, Step 229: train/loss = 0.4595687985420227, train/raw-loss = 0.4122546911239624, train/logprobs = tensor([[-0.9678, -5.4552],
        [-0.8295, -2.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11828529834747314
Epoch 0, Step 230: train/loss = 0.47350016236305237, train/raw-loss = 0.42461422085762024, train/logprobs = tensor([[-1.1956, -3.4718],
        [-1.0743, -1.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12221485376358032
Epoch 0, Step 231: train/loss = 0.44848668575286865, train/raw-loss = 0.4049264192581177, train/logprobs = tensor([[-0.6900, -4.4532],
        [-0.6799, -0.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10890072584152222
Epoch 0, Step 232: train/loss = 0.5668088793754578, train/raw-loss = 0.520988941192627, train/logprobs = tensor([[-0.6346, -2.5538],
        [-0.5797, -1.3326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11454984545707703
Epoch 0, Step 233: train/loss = 0.635991632938385, train/raw-loss = 0.5913463234901428, train/logprobs = tensor([[-1.3189, -5.3534],
        [-0.8283, -1.4064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161334067583084
Epoch 0, Step 234: train/loss = 0.6440012454986572, train/raw-loss = 0.6004667282104492, train/logprobs = tensor([[-0.6209, -1.1615],
        [-0.4934, -0.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088363379240036
Epoch 0, Step 235: train/loss = 0.5038058161735535, train/raw-loss = 0.45618337392807007, train/logprobs = tensor([[-1.0124, -4.6537],
        [-0.5757, -1.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11905630677938461
Epoch 0, Step 236: train/loss = 0.61236971616745, train/raw-loss = 0.5601688623428345, train/logprobs = tensor([[-0.7583, -2.0791],
        [-0.6171, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13050198554992676
Epoch 0, Step 237: train/loss = 0.5443947315216064, train/raw-loss = 0.49911025166511536, train/logprobs = tensor([[-0.7736, -2.1767],
        [-0.6506, -0.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11321116983890533
Epoch 0, Step 238: train/loss = 0.4968404769897461, train/raw-loss = 0.4541248083114624, train/logprobs = tensor([[-0.6000, -2.6763],
        [-0.4957, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10678904503583908
Epoch 0, Step 239: train/loss = 0.6652669906616211, train/raw-loss = 0.6233330368995667, train/logprobs = tensor([[-0.8428, -1.1575],
        [-0.5647, -0.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10483477264642715
Epoch 0, Step 240: train/loss = 0.6350579261779785, train/raw-loss = 0.5833365321159363, train/logprobs = tensor([[-1.1518, -2.6676],
        [-1.0800, -1.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12930375337600708
Epoch 0, Step 241: train/loss = 0.5208323001861572, train/raw-loss = 0.4728702902793884, train/logprobs = tensor([[-0.5664, -2.0100],
        [-0.5255, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199050173163414
Epoch 0, Step 242: train/loss = 0.6480407118797302, train/raw-loss = 0.6043044328689575, train/logprobs = tensor([[-0.5925, -1.0722],
        [-0.4073, -0.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10934069752693176
Epoch 0, Step 243: train/loss = 0.6614270210266113, train/raw-loss = 0.6224439144134521, train/logprobs = tensor([[-0.8366, -1.2278],
        [-0.4985, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745767712593079
Epoch 0, Step 244: train/loss = 0.510116696357727, train/raw-loss = 0.4601055383682251, train/logprobs = tensor([[-1.0848, -3.9775],
        [-0.6892, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12502779066562653
Epoch 0, Step 245: train/loss = 0.5579147934913635, train/raw-loss = 0.5100390315055847, train/logprobs = tensor([[-1.1305, -2.5039],
        [-0.6453, -0.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11968940496444702
Epoch 0, Step 246: train/loss = 0.47413843870162964, train/raw-loss = 0.4255959093570709, train/logprobs = tensor([[-0.6840, -4.0807],
        [-0.6762, -1.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12135635316371918
Epoch 0, Step 247: train/loss = 0.5804280042648315, train/raw-loss = 0.532107412815094, train/logprobs = tensor([[-0.9821, -2.6207],
        [-0.7427, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12080161273479462
Epoch 0, Step 248: train/loss = 0.6159547567367554, train/raw-loss = 0.5757461786270142, train/logprobs = tensor([[-0.6787, -1.9593],
        [-0.6797, -1.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10052137821912766
Epoch 0, Step 249: train/loss = 0.5477346777915955, train/raw-loss = 0.5056027770042419, train/logprobs = tensor([[-0.4883, -2.3732],
        [-0.5068, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10532981157302856
Epoch 0, Step 250: train/loss = 0.5312792658805847, train/raw-loss = 0.4833459258079529, train/logprobs = tensor([[-1.2587, -4.5817],
        [-0.5835, -1.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11983340978622437
Epoch 0, Step 251: train/loss = 0.4264732599258423, train/raw-loss = 0.37784406542778015, train/logprobs = tensor([[-0.6690, -3.1153],
        [-0.6368, -0.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12157286703586578
Epoch 0, Step 252: train/loss = 0.5795560479164124, train/raw-loss = 0.5368777513504028, train/logprobs = tensor([[-0.5058, -1.7060],
        [-0.4154, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10669579356908798
Epoch 0, Step 253: train/loss = 0.7289422750473022, train/raw-loss = 0.6879028081893921, train/logprobs = tensor([[-0.7830, -0.6514],
        [-0.6305, -0.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259877145290375
Epoch 0, Step 254: train/loss = 0.49239853024482727, train/raw-loss = 0.44601044058799744, train/logprobs = tensor([[-0.7981, -3.4776],
        [-0.5839, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11597020924091339
Epoch 0, Step 255: train/loss = 0.5894153714179993, train/raw-loss = 0.541827917098999, train/logprobs = tensor([[-1.1237, -2.6915],
        [-0.8969, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11896878480911255
Epoch 0, Step 256: train/loss = 0.680229127407074, train/raw-loss = 0.6460635662078857, train/logprobs = tensor([[-0.5853, -0.8973],
        [-0.4377, -0.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08541388064622879
Epoch 0, Step 257: train/loss = 0.662555456161499, train/raw-loss = 0.6231725215911865, train/logprobs = tensor([[-0.7970, -1.3017],
        [-0.6078, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09845718741416931
Epoch 0, Step 258: train/loss = 0.3903438448905945, train/raw-loss = 0.344742089509964, train/logprobs = tensor([[-0.9620, -3.5307],
        [-0.9572, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11400441825389862
Epoch 0, Step 259: train/loss = 0.5492340922355652, train/raw-loss = 0.5135345458984375, train/logprobs = tensor([[-0.6032, -3.8255],
        [-0.5152, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924883604049683
Epoch 0, Step 260: train/loss = 0.46336930990219116, train/raw-loss = 0.42376571893692017, train/logprobs = tensor([[-0.5450, -4.7046],
        [-0.4709, -1.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0990089401602745
Epoch 0, Step 261: train/loss = 0.49752289056777954, train/raw-loss = 0.4494546949863434, train/logprobs = tensor([[-0.8337, -2.2911],
        [-0.8467, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1201704740524292
Epoch 0, Step 262: train/loss = 0.573293924331665, train/raw-loss = 0.5292577743530273, train/logprobs = tensor([[-0.7230, -2.5566],
        [-0.6203, -1.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11009036749601364
Epoch 0, Step 263: train/loss = 0.6318811178207397, train/raw-loss = 0.5849701762199402, train/logprobs = tensor([[-1.3526, -2.1914],
        [-1.0758, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1172773689031601
Epoch 0, Step 264: train/loss = 0.6205253005027771, train/raw-loss = 0.5813869833946228, train/logprobs = tensor([[-0.7580, -1.4501],
        [-0.6794, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09784581512212753
Epoch 0, Step 265: train/loss = 0.673812210559845, train/raw-loss = 0.6347446441650391, train/logprobs = tensor([[-0.9102, -1.3623],
        [-0.6492, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09766899794340134
Epoch 0, Step 266: train/loss = 0.4470544755458832, train/raw-loss = 0.4021183252334595, train/logprobs = tensor([[-1.0574, -3.6628],
        [-1.0252, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11234041303396225
Epoch 0, Step 267: train/loss = 0.4856222867965698, train/raw-loss = 0.44364285469055176, train/logprobs = tensor([[-0.7066, -2.5569],
        [-0.5598, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10494862496852875
Epoch 0, Step 268: train/loss = 0.5240455269813538, train/raw-loss = 0.4858168065547943, train/logprobs = tensor([[-0.6726, -5.1612],
        [-0.6621, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0955718383193016
Epoch 0, Step 269: train/loss = 0.5327720642089844, train/raw-loss = 0.4919995367527008, train/logprobs = tensor([[-0.8056, -4.0020],
        [-0.7097, -1.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1019313782453537
Epoch 0, Step 270: train/loss = 0.521059513092041, train/raw-loss = 0.4798375070095062, train/logprobs = tensor([[-0.4249, -2.2104],
        [-0.3536, -0.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10305503755807877
Epoch 0, Step 271: train/loss = 0.5325709581375122, train/raw-loss = 0.490517258644104, train/logprobs = tensor([[-0.8107, -2.2077],
        [-0.6693, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10513434559106827
Epoch 0, Step 272: train/loss = 0.6976715326309204, train/raw-loss = 0.6594711542129517, train/logprobs = tensor([[-0.6220, -0.8649],
        [-0.5529, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550094604492188
Epoch 0, Step 273: train/loss = 0.5936132073402405, train/raw-loss = 0.554061233997345, train/logprobs = tensor([[-0.4785, -1.3153],
        [-0.4995, -0.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09887988865375519
Epoch 0, Step 274: train/loss = 0.6113407611846924, train/raw-loss = 0.5687917470932007, train/logprobs = tensor([[-0.5895, -1.7026],
        [-0.4927, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10637257993221283
Epoch 0, Step 275: train/loss = 0.5076525211334229, train/raw-loss = 0.4733225703239441, train/logprobs = tensor([[-0.4958, -1.9390],
        [-0.4405, -0.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08582476526498795
Epoch 0, Step 276: train/loss = 0.5797117948532104, train/raw-loss = 0.5342108011245728, train/logprobs = tensor([[-1.2817, -2.6622],
        [-1.0677, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11375253647565842
Epoch 0, Step 277: train/loss = 0.6352206468582153, train/raw-loss = 0.5860584378242493, train/logprobs = tensor([[-0.7975, -1.2535],
        [-0.7701, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12290547043085098
Epoch 0, Step 278: train/loss = 0.5708460807800293, train/raw-loss = 0.5241748094558716, train/logprobs = tensor([[-0.8260, -1.5274],
        [-0.7193, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11667826771736145
Epoch 0, Step 279: train/loss = 0.4483151435852051, train/raw-loss = 0.403371661901474, train/logprobs = tensor([[-1.0302, -4.2850],
        [-0.7469, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235864460468292
Epoch 0, Step 280: train/loss = 0.5249120593070984, train/raw-loss = 0.4824233055114746, train/logprobs = tensor([[-0.8288, -4.4592],
        [-0.6320, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622186958789825
Epoch 0, Step 281: train/loss = 0.5891237854957581, train/raw-loss = 0.5510925054550171, train/logprobs = tensor([[-0.5681, -1.2346],
        [-0.4838, -0.4743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09507817775011063
Epoch 0, Step 282: train/loss = 0.5958622097969055, train/raw-loss = 0.5374022126197815, train/logprobs = tensor([[-1.2921, -3.3806],
        [-0.8282, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14615002274513245
Epoch 0, Step 283: train/loss = 0.5321804881095886, train/raw-loss = 0.4912137985229492, train/logprobs = tensor([[-0.7979, -2.3533],
        [-0.6221, -0.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1024167612195015
Epoch 0, Step 284: train/loss = 0.5824689865112305, train/raw-loss = 0.5416367053985596, train/logprobs = tensor([[-0.4945, -1.4194],
        [-0.4845, -0.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10208048671483994
Epoch 0, Step 285: train/loss = 0.6119058132171631, train/raw-loss = 0.5711193084716797, train/logprobs = tensor([[-0.5881, -1.1996],
        [-0.5748, -0.5733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10196619480848312
Epoch 0, Step 286: train/loss = 0.5380890369415283, train/raw-loss = 0.5004838705062866, train/logprobs = tensor([[-0.4188, -1.8281],
        [-0.3434, -0.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401308745145798
Epoch 0, Step 287: train/loss = 0.5231916904449463, train/raw-loss = 0.4769975244998932, train/logprobs = tensor([[-0.7908, -3.9147],
        [-0.7617, -1.3901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11548541486263275
Epoch 0, Step 288: train/loss = 0.5619136691093445, train/raw-loss = 0.5185883045196533, train/logprobs = tensor([[-0.5860, -1.7154],
        [-0.6090, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10831336677074432
Epoch 0, Step 289: train/loss = 0.5318676233291626, train/raw-loss = 0.4837406277656555, train/logprobs = tensor([[-0.8472, -3.2320],
        [-0.7507, -1.3696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12031752616167068
Epoch 0, Step 290: train/loss = 0.5266247987747192, train/raw-loss = 0.4844180941581726, train/logprobs = tensor([[-0.5733, -2.9418],
        [-0.5357, -1.4560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551676154136658
Epoch 0, Step 291: train/loss = 0.4714518189430237, train/raw-loss = 0.42689627408981323, train/logprobs = tensor([[-0.7183, -2.2896],
        [-0.7665, -0.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138886213302612
Epoch 0, Step 292: train/loss = 0.5646187663078308, train/raw-loss = 0.5231207609176636, train/logprobs = tensor([[-0.6160, -1.4243],
        [-0.6880, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10374489426612854
Epoch 0, Step 293: train/loss = 0.5579391121864319, train/raw-loss = 0.5096701383590698, train/logprobs = tensor([[-0.7900, -2.2809],
        [-0.7106, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1206725686788559
Epoch 0, Step 294: train/loss = 0.5646141171455383, train/raw-loss = 0.5203903913497925, train/logprobs = tensor([[-0.9391, -1.7755],
        [-0.7801, -0.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11055922508239746
Epoch 0, Step 295: train/loss = 0.5416477918624878, train/raw-loss = 0.49295711517333984, train/logprobs = tensor([[-1.4532, -3.0107],
        [-1.2876, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172655761241913
Epoch 0, Step 296: train/loss = 0.5795273780822754, train/raw-loss = 0.5372670292854309, train/logprobs = tensor([[-0.6917, -1.9401],
        [-0.6506, -0.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10565099865198135
Epoch 0, Step 297: train/loss = 0.4710560441017151, train/raw-loss = 0.4279271364212036, train/logprobs = tensor([[-0.6323, -3.4923],
        [-0.6656, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10782220959663391
Epoch 0, Step 298: train/loss = 0.550051748752594, train/raw-loss = 0.5102335810661316, train/logprobs = tensor([[-0.5607, -1.5785],
        [-0.6845, -0.6708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954540431499481
Epoch 0, Step 299: train/loss = 0.471000611782074, train/raw-loss = 0.42937713861465454, train/logprobs = tensor([[-1.0145, -3.0479],
        [-1.0024, -0.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1040586605668068
Epoch 0, Step 300: train/loss = 0.5220726728439331, train/raw-loss = 0.48226070404052734, train/logprobs = tensor([[-0.7486, -2.5260],
        [-0.7936, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09952996671199799
Epoch 0, Step 301: train/loss = 0.5743552446365356, train/raw-loss = 0.5315742492675781, train/logprobs = tensor([[-0.6492, -1.3161],
        [-0.6064, -0.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10695262998342514
Epoch 0, Step 302: train/loss = 0.5011723637580872, train/raw-loss = 0.45760577917099, train/logprobs = tensor([[-0.6594, -2.2892],
        [-0.6066, -0.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10891638696193695
Epoch 0, Step 303: train/loss = 0.4602563977241516, train/raw-loss = 0.4159615635871887, train/logprobs = tensor([[-0.5491, -2.7576],
        [-0.5679, -0.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11073717474937439
Epoch 0, Step 304: train/loss = 0.5601534247398376, train/raw-loss = 0.5167590379714966, train/logprobs = tensor([[-0.6417, -1.7444],
        [-0.6356, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10848598182201385
Epoch 0, Step 305: train/loss = 0.5544604063034058, train/raw-loss = 0.5090746879577637, train/logprobs = tensor([[-0.8950, -2.8584],
        [-0.5498, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11346432566642761
Epoch 0, Step 306: train/loss = 0.5888474583625793, train/raw-loss = 0.5459161400794983, train/logprobs = tensor([[-0.8152, -3.5204],
        [-0.6875, -1.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073281466960907
Epoch 0, Step 307: train/loss = 0.5668333768844604, train/raw-loss = 0.5207852125167847, train/logprobs = tensor([[-0.8498, -4.0185],
        [-0.8463, -1.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11512038856744766
Epoch 0, Step 308: train/loss = 0.5981238484382629, train/raw-loss = 0.5570665001869202, train/logprobs = tensor([[-0.7096, -1.4161],
        [-0.6477, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10264329612255096
Epoch 0, Step 309: train/loss = 0.6038230657577515, train/raw-loss = 0.5633952617645264, train/logprobs = tensor([[-0.5256, -1.3963],
        [-0.4677, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1010696068406105
Epoch 0, Step 310: train/loss = 0.41589951515197754, train/raw-loss = 0.3673509657382965, train/logprobs = tensor([[-0.6844, -4.2711],
        [-0.5498, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137143313884735
Epoch 0, Step 311: train/loss = 0.5623562932014465, train/raw-loss = 0.5216769576072693, train/logprobs = tensor([[-0.5727, -2.6097],
        [-0.6104, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10169827938079834
Epoch 0, Step 312: train/loss = 0.5963876247406006, train/raw-loss = 0.5578984022140503, train/logprobs = tensor([[-0.6644, -3.3246],
        [-0.5340, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622310101985931
Epoch 0, Step 313: train/loss = 0.49661117792129517, train/raw-loss = 0.4491557776927948, train/logprobs = tensor([[-0.6377, -2.3755],
        [-0.6292, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11863841116428375
Epoch 0, Step 314: train/loss = 0.6360621452331543, train/raw-loss = 0.5968655347824097, train/logprobs = tensor([[-0.6202, -0.8893],
        [-0.6266, -0.4597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09799148142337799
Epoch 0, Step 315: train/loss = 0.6034164428710938, train/raw-loss = 0.5564149618148804, train/logprobs = tensor([[-1.9238, -3.7170],
        [-1.4306, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1175035685300827
Epoch 0, Step 316: train/loss = 0.7057721614837646, train/raw-loss = 0.671338677406311, train/logprobs = tensor([[-0.7473, -0.6981],
        [-0.7418, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0860838070511818
Epoch 0, Step 317: train/loss = 0.4437221884727478, train/raw-loss = 0.40021055936813354, train/logprobs = tensor([[-0.4836, -4.5142],
        [-0.4949, -1.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10877898335456848
Epoch 0, Step 318: train/loss = 0.4664667248725891, train/raw-loss = 0.4235897958278656, train/logprobs = tensor([[-0.7534, -2.7768],
        [-0.7556, -0.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10719230026006699
Epoch 0, Step 319: train/loss = 0.49322080612182617, train/raw-loss = 0.4497055113315582, train/logprobs = tensor([[-0.5538, -2.7560],
        [-0.5741, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10878831893205643
Epoch 0, Step 320: train/loss = 0.5349636673927307, train/raw-loss = 0.49518483877182007, train/logprobs = tensor([[-0.8373, -2.6342],
        [-0.6716, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09944707155227661
Epoch 0, Step 321: train/loss = 0.5595706701278687, train/raw-loss = 0.5231384038925171, train/logprobs = tensor([[-0.6428, -1.7094],
        [-0.6244, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09108076989650726
Epoch 0, Step 322: train/loss = 0.4670085906982422, train/raw-loss = 0.42684993147850037, train/logprobs = tensor([[-1.0292, -3.9326],
        [-0.9110, -1.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039666295051575
Epoch 0, Step 323: train/loss = 0.5132586359977722, train/raw-loss = 0.47409364581108093, train/logprobs = tensor([[-0.4250, -2.2924],
        [-0.4442, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09791240841150284
Epoch 0, Step 324: train/loss = 0.38499268889427185, train/raw-loss = 0.33840638399124146, train/logprobs = tensor([[-0.8021, -5.2776],
        [-0.6809, -1.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1164657473564148
Epoch 0, Step 325: train/loss = 0.6306286454200745, train/raw-loss = 0.5945781469345093, train/logprobs = tensor([[-0.6153, -1.1510],
        [-0.5748, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09012635797262192
Epoch 0, Step 326: train/loss = 0.4216162860393524, train/raw-loss = 0.3784216046333313, train/logprobs = tensor([[-0.8983, -4.8518],
        [-1.0380, -1.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10798671841621399
Epoch 0, Step 327: train/loss = 0.7234485149383545, train/raw-loss = 0.6786949634552002, train/logprobs = tensor([[-0.8510, -1.0664],
        [-0.6477, -0.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188377439975739
Epoch 0, Step 328: train/loss = 0.6263852119445801, train/raw-loss = 0.5894763469696045, train/logprobs = tensor([[-0.8451, -1.6860],
        [-0.8196, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227216243743896
Epoch 0, Step 329: train/loss = 0.6121789216995239, train/raw-loss = 0.5700914859771729, train/logprobs = tensor([[-1.0827, -1.5677],
        [-0.8773, -0.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521867871284485
Epoch 0, Step 330: train/loss = 0.3658217489719391, train/raw-loss = 0.32299119234085083, train/logprobs = tensor([[-0.6826, -4.3076],
        [-0.6616, -0.9563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707636922597885
Epoch 0, Step 331: train/loss = 0.4831085801124573, train/raw-loss = 0.44834017753601074, train/logprobs = tensor([[-0.6324, -3.9704],
        [-0.6172, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08692101389169693
Epoch 0, Step 332: train/loss = 0.4328039884567261, train/raw-loss = 0.3880845904350281, train/logprobs = tensor([[-0.7899, -3.6826],
        [-0.9061, -1.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11179844290018082
Epoch 0, Step 333: train/loss = 0.5267595648765564, train/raw-loss = 0.48507270216941833, train/logprobs = tensor([[-0.7775, -2.7847],
        [-0.6283, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421718657016754
Epoch 0, Step 334: train/loss = 0.6528857946395874, train/raw-loss = 0.6166097521781921, train/logprobs = tensor([[-0.7428, -0.9335],
        [-0.6526, -0.4776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09069009125232697
Epoch 0, Step 335: train/loss = 0.4644778072834015, train/raw-loss = 0.42411893606185913, train/logprobs = tensor([[-0.6577, -2.3527],
        [-0.5759, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10089718550443649
Epoch 0, Step 336: train/loss = 0.5400006771087646, train/raw-loss = 0.4987165927886963, train/logprobs = tensor([[-0.5525, -1.7057],
        [-0.6133, -0.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1032102108001709
Epoch 0, Step 337: train/loss = 0.5192400813102722, train/raw-loss = 0.4754231870174408, train/logprobs = tensor([[-0.8844, -2.2068],
        [-0.8822, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954225063323975
Epoch 0, Step 338: train/loss = 0.5367199778556824, train/raw-loss = 0.49517619609832764, train/logprobs = tensor([[-0.5668, -1.6663],
        [-0.5698, -0.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385945439338684
Epoch 0, Step 339: train/loss = 0.4738551080226898, train/raw-loss = 0.43604812026023865, train/logprobs = tensor([[-0.3762, -4.1753],
        [-0.4024, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451757371425629
Epoch 0, Step 340: train/loss = 0.616511881351471, train/raw-loss = 0.5815176963806152, train/logprobs = tensor([[-0.8137, -1.3848],
        [-0.7393, -0.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08748555928468704
Epoch 0, Step 341: train/loss = 0.40735507011413574, train/raw-loss = 0.36541712284088135, train/logprobs = tensor([[-0.6154, -3.1614],
        [-0.6893, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484474897384644
Epoch 0, Step 342: train/loss = 0.5133918523788452, train/raw-loss = 0.4772273302078247, train/logprobs = tensor([[-0.5694, -2.7100],
        [-0.6215, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904112160205841
Epoch 0, Step 343: train/loss = 0.5944079160690308, train/raw-loss = 0.5562987327575684, train/logprobs = tensor([[-0.6665, -2.0341],
        [-0.6830, -1.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.095272958278656
Epoch 0, Step 344: train/loss = 0.44330769777297974, train/raw-loss = 0.4008552134037018, train/logprobs = tensor([[-0.9651, -5.4960],
        [-0.8220, -1.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10613119602203369
Epoch 0, Step 345: train/loss = 0.49787184596061707, train/raw-loss = 0.45771893858909607, train/logprobs = tensor([[-1.1696, -3.8782],
        [-1.1614, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10038231313228607
Epoch 0, Step 346: train/loss = 0.5172393321990967, train/raw-loss = 0.47394564747810364, train/logprobs = tensor([[-0.7866, -3.7477],
        [-0.7466, -1.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10823424160480499
Epoch 0, Step 347: train/loss = 0.5188809633255005, train/raw-loss = 0.4795318841934204, train/logprobs = tensor([[-0.6137, -4.2412],
        [-0.6412, -1.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09837279468774796
Epoch 0, Step 348: train/loss = 0.5383182168006897, train/raw-loss = 0.5027104616165161, train/logprobs = tensor([[-0.7421, -3.0873],
        [-0.7972, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08901932835578918
Epoch 0, Step 349: train/loss = 0.42565229535102844, train/raw-loss = 0.37973687052726746, train/logprobs = tensor([[-0.7109, -2.8440],
        [-0.7556, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478850990533829
Epoch 0, Step 350: train/loss = 0.6145642399787903, train/raw-loss = 0.569667637348175, train/logprobs = tensor([[-1.2447, -2.4984],
        [-1.0087, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11224152147769928
Epoch 0, Step 351: train/loss = 0.5366157293319702, train/raw-loss = 0.4951266646385193, train/logprobs = tensor([[-0.7405, -2.4645],
        [-0.7369, -1.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10372254997491837
Epoch 0, Step 352: train/loss = 0.4647281765937805, train/raw-loss = 0.4270392656326294, train/logprobs = tensor([[-0.5214, -3.6355],
        [-0.6052, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09422235190868378
Epoch 0, Step 353: train/loss = 0.4114590585231781, train/raw-loss = 0.3702317774295807, train/logprobs = tensor([[-0.7225, -4.4098],
        [-0.8587, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10306821763515472
Epoch 0, Step 354: train/loss = 0.6348604559898376, train/raw-loss = 0.6002289652824402, train/logprobs = tensor([[-0.4873, -0.9717],
        [-0.5226, -0.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08657865971326828
Epoch 0, Step 355: train/loss = 0.5220054388046265, train/raw-loss = 0.4835777282714844, train/logprobs = tensor([[-0.7453, -2.4912],
        [-0.8043, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0960693508386612
Epoch 0, Step 356: train/loss = 0.6285779476165771, train/raw-loss = 0.5901899933815002, train/logprobs = tensor([[-0.5167, -1.0843],
        [-0.5009, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0959697887301445
Epoch 0, Step 357: train/loss = 0.6660820245742798, train/raw-loss = 0.6235741972923279, train/logprobs = tensor([[-1.8729, -2.4881],
        [-1.4766, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10626955330371857
Epoch 0, Step 358: train/loss = 0.5358996987342834, train/raw-loss = 0.5025528073310852, train/logprobs = tensor([[-0.5300, -3.9262],
        [-0.5057, -1.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08336714655160904
Epoch 0, Step 359: train/loss = 0.5860382914543152, train/raw-loss = 0.5453280210494995, train/logprobs = tensor([[-0.9273, -1.9243],
        [-0.8667, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10177548974752426
Epoch 0, Step 360: train/loss = 0.547292947769165, train/raw-loss = 0.5062075257301331, train/logprobs = tensor([[-0.9160, -2.5630],
        [-0.8364, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271354019641876
Epoch 0, Step 361: train/loss = 0.573298454284668, train/raw-loss = 0.5314360857009888, train/logprobs = tensor([[-0.6301, -1.2274],
        [-0.7025, -0.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10465576499700546
Epoch 0, Step 362: train/loss = 0.6036366820335388, train/raw-loss = 0.5673090219497681, train/logprobs = tensor([[-0.6797, -1.7341],
        [-0.6827, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09081916511058807
Epoch 0, Step 363: train/loss = 0.745594322681427, train/raw-loss = 0.712761640548706, train/logprobs = tensor([[-1.2712, -1.1606],
        [-0.8955, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08208164572715759
Epoch 0, Step 364: train/loss = 0.41158485412597656, train/raw-loss = 0.37448403239250183, train/logprobs = tensor([[-0.4161, -5.1107],
        [-0.5477, -1.2155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09275206923484802
Epoch 0, Step 365: train/loss = 0.44731903076171875, train/raw-loss = 0.4072483777999878, train/logprobs = tensor([[-0.5576, -2.5845],
        [-0.6115, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017666220664978
Epoch 0, Step 366: train/loss = 0.5393741130828857, train/raw-loss = 0.5020401477813721, train/logprobs = tensor([[-0.5907, -2.5459],
        [-0.6048, -0.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333492815494537
Epoch 0, Step 367: train/loss = 0.44730091094970703, train/raw-loss = 0.40918734669685364, train/logprobs = tensor([[-0.6023, -3.2878],
        [-0.6981, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09528395533561707
Epoch 0, Step 368: train/loss = 0.4902993440628052, train/raw-loss = 0.452392041683197, train/logprobs = tensor([[-0.4286, -2.3990],
        [-0.4379, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09476831555366516
Epoch 0, Step 369: train/loss = 0.5071386694908142, train/raw-loss = 0.47183558344841003, train/logprobs = tensor([[-0.4586, -1.9135],
        [-0.5383, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08825774490833282
Epoch 0, Step 370: train/loss = 0.6489068269729614, train/raw-loss = 0.6169607043266296, train/logprobs = tensor([[-0.4101, -0.8407],
        [-0.4238, -0.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07986535876989365
Epoch 0, Step 371: train/loss = 0.5055792331695557, train/raw-loss = 0.47185149788856506, train/logprobs = tensor([[-0.4407, -3.1231],
        [-0.4714, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0843193531036377
Epoch 0, Step 372: train/loss = 0.4523733854293823, train/raw-loss = 0.4163334369659424, train/logprobs = tensor([[-0.5636, -3.1283],
        [-0.5547, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009989351034164
Epoch 0, Step 373: train/loss = 0.5390781164169312, train/raw-loss = 0.49949485063552856, train/logprobs = tensor([[-0.7894, -4.2177],
        [-0.7135, -1.3643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09895830601453781
Epoch 0, Step 374: train/loss = 0.5379587411880493, train/raw-loss = 0.502197265625, train/logprobs = tensor([[-0.3199, -2.2242],
        [-0.3583, -0.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08940373361110687
Epoch 0, Step 375: train/loss = 0.5183402895927429, train/raw-loss = 0.4764662981033325, train/logprobs = tensor([[-0.7505, -1.6087],
        [-0.9483, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468491911888123
Epoch 0, Step 376: train/loss = 0.43394601345062256, train/raw-loss = 0.3918599784374237, train/logprobs = tensor([[-0.6384, -4.4744],
        [-0.8397, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521513223648071
Epoch 0, Step 377: train/loss = 0.5807291865348816, train/raw-loss = 0.542100727558136, train/logprobs = tensor([[-0.6629, -2.6704],
        [-0.5910, -0.8173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657116234302521
Epoch 0, Step 378: train/loss = 0.5471484065055847, train/raw-loss = 0.5116695165634155, train/logprobs = tensor([[-0.7250, -3.5148],
        [-0.7032, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08869721740484238
Epoch 0, Step 379: train/loss = 0.6104297041893005, train/raw-loss = 0.5742993354797363, train/logprobs = tensor([[-0.9602, -2.0655],
        [-0.8428, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09032595157623291
Epoch 0, Step 380: train/loss = 0.5271542072296143, train/raw-loss = 0.4895133972167969, train/logprobs = tensor([[-0.6151, -1.8438],
        [-0.6519, -0.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09410202503204346
Epoch 0, Step 381: train/loss = 0.4551846981048584, train/raw-loss = 0.41252008080482483, train/logprobs = tensor([[-0.6905, -3.8038],
        [-0.8993, -1.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10666154325008392
Epoch 0, Step 382: train/loss = 0.4063575267791748, train/raw-loss = 0.3670644760131836, train/logprobs = tensor([[-0.5742, -3.5746],
        [-0.6062, -0.7337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09823266416788101
Epoch 0, Step 383: train/loss = 0.44791853427886963, train/raw-loss = 0.40505465865135193, train/logprobs = tensor([[-0.4746, -2.4879],
        [-0.6177, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10715973377227783
Epoch 0, Step 384: train/loss = 0.5063133835792542, train/raw-loss = 0.46036022901535034, train/logprobs = tensor([[-0.8274, -5.7151],
        [-0.9288, -1.2880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11488282680511475
Epoch 0, Step 385: train/loss = 0.5977063179016113, train/raw-loss = 0.5451366901397705, train/logprobs = tensor([[-1.2285, -2.1126],
        [-1.0257, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13142409920692444
Epoch 0, Step 386: train/loss = 0.7212647199630737, train/raw-loss = 0.6858545541763306, train/logprobs = tensor([[-0.8984, -0.8722],
        [-0.7005, -0.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852546662092209
Epoch 0, Step 387: train/loss = 0.4946278929710388, train/raw-loss = 0.4521319270133972, train/logprobs = tensor([[-0.6683, -4.7604],
        [-0.8636, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10623994469642639
Epoch 0, Step 388: train/loss = 0.5503779649734497, train/raw-loss = 0.5006042122840881, train/logprobs = tensor([[-0.7356, -2.2780],
        [-0.7947, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244344413280487
Epoch 0, Step 389: train/loss = 0.4645096957683563, train/raw-loss = 0.4143630564212799, train/logprobs = tensor([[-0.6162, -2.5098],
        [-0.6802, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12536656856536865
Epoch 0, Step 390: train/loss = 0.46794363856315613, train/raw-loss = 0.4184688329696655, train/logprobs = tensor([[-1.0466, -2.5853],
        [-1.3503, -1.2840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1236870288848877
Epoch 0, Step 391: train/loss = 0.5350287556648254, train/raw-loss = 0.4936123788356781, train/logprobs = tensor([[-0.4962, -1.9242],
        [-0.5357, -0.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10354088246822357
Epoch 0, Step 392: train/loss = 0.453520804643631, train/raw-loss = 0.414648175239563, train/logprobs = tensor([[-0.4888, -3.3418],
        [-0.6428, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718160331249237
Epoch 0, Step 393: train/loss = 0.5678812265396118, train/raw-loss = 0.5191438794136047, train/logprobs = tensor([[-0.7979, -2.0033],
        [-0.6493, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1218433603644371
Epoch 0, Step 394: train/loss = 0.43519484996795654, train/raw-loss = 0.3923606872558594, train/logprobs = tensor([[-0.9139, -6.3223],
        [-0.8551, -0.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10708537697792053
Epoch 0, Step 395: train/loss = 0.50123131275177, train/raw-loss = 0.46623966097831726, train/logprobs = tensor([[-0.6966, -5.7248],
        [-0.4761, -0.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08747907727956772
Epoch 0, Step 396: train/loss = 0.5471847653388977, train/raw-loss = 0.5040514469146729, train/logprobs = tensor([[-0.7704, -1.9648],
        [-0.7670, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10783325135707855
Epoch 0, Step 397: train/loss = 0.5607684254646301, train/raw-loss = 0.5196924209594727, train/logprobs = tensor([[-0.4887, -2.2484],
        [-0.4667, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10269002616405487
Epoch 0, Step 398: train/loss = 0.4085865020751953, train/raw-loss = 0.36266767978668213, train/logprobs = tensor([[-0.5870, -3.4700],
        [-0.7286, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11479704827070236
Epoch 0, Step 399: train/loss = 0.5814308524131775, train/raw-loss = 0.537589967250824, train/logprobs = tensor([[-0.8659, -1.4660],
        [-0.9837, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1096021756529808
Epoch 0, Step 400: train/loss = 0.5755841135978699, train/raw-loss = 0.5388586521148682, train/logprobs = tensor([[-0.5296, -1.3222],
        [-0.5877, -0.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09181363880634308
Epoch 0, Step 401: train/loss = 0.43725574016571045, train/raw-loss = 0.39557039737701416, train/logprobs = tensor([[-0.8077, -3.4680],
        [-0.8626, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421328246593475
Epoch 0, Step 402: train/loss = 0.4498984217643738, train/raw-loss = 0.40711069107055664, train/logprobs = tensor([[-0.6939, -3.3728],
        [-0.7008, -0.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10696933418512344
Epoch 0, Step 403: train/loss = 0.5407676100730896, train/raw-loss = 0.5092244744300842, train/logprobs = tensor([[-0.3344, -1.7978],
        [-0.3715, -0.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07885783165693283
Epoch 0, Step 404: train/loss = 0.6439387202262878, train/raw-loss = 0.6064477562904358, train/logprobs = tensor([[-0.5839, -1.2622],
        [-0.5278, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0937274843454361
Epoch 0, Step 405: train/loss = 0.5677651762962341, train/raw-loss = 0.5317384004592896, train/logprobs = tensor([[-0.4725, -3.2951],
        [-0.5408, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006685763597488
Epoch 0, Step 406: train/loss = 0.5377352237701416, train/raw-loss = 0.49665966629981995, train/logprobs = tensor([[-0.5751, -2.2016],
        [-0.5964, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1026889979839325
Epoch 0, Step 407: train/loss = 0.6020674705505371, train/raw-loss = 0.5695950984954834, train/logprobs = tensor([[-0.5218, -1.0983],
        [-0.5269, -0.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08118090033531189
Epoch 0, Step 408: train/loss = 0.5929571986198425, train/raw-loss = 0.5493054389953613, train/logprobs = tensor([[-0.6164, -1.2047],
        [-0.8467, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10912929475307465
Epoch 0, Step 409: train/loss = 0.32948756217956543, train/raw-loss = 0.28346896171569824, train/logprobs = tensor([[-0.8800, -4.9607],
        [-1.1857, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504659056663513
Epoch 0, Step 410: train/loss = 0.5840749740600586, train/raw-loss = 0.5435206294059753, train/logprobs = tensor([[-0.5880, -2.1059],
        [-0.5606, -1.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138595849275589
Epoch 0, Step 411: train/loss = 0.5417174100875854, train/raw-loss = 0.49297040700912476, train/logprobs = tensor([[-0.5067, -1.6374],
        [-0.5788, -0.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12186740338802338
Epoch 0, Step 412: train/loss = 0.590814471244812, train/raw-loss = 0.5493415594100952, train/logprobs = tensor([[-0.4734, -1.4818],
        [-0.5884, -0.6113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10368221253156662
Epoch 0, Step 413: train/loss = 0.5617137551307678, train/raw-loss = 0.5255286693572998, train/logprobs = tensor([[-0.7753, -4.0566],
        [-0.6595, -1.2974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09046270698308945
Epoch 0, Step 414: train/loss = 0.5007576942443848, train/raw-loss = 0.46504756808280945, train/logprobs = tensor([[-0.4372, -1.8071],
        [-0.5627, -0.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08927534520626068
Epoch 0, Step 415: train/loss = 0.4784986972808838, train/raw-loss = 0.4358036518096924, train/logprobs = tensor([[-0.7737, -4.1128],
        [-0.8350, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673758387565613
Epoch 0, Step 416: train/loss = 0.615572988986969, train/raw-loss = 0.5728520750999451, train/logprobs = tensor([[-0.7522, -1.4886],
        [-0.7058, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10680222511291504
Epoch 0, Step 417: train/loss = 0.44385239481925964, train/raw-loss = 0.3930398225784302, train/logprobs = tensor([[-0.6362, -4.1813],
        [-0.9210, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12703147530555725
Epoch 0, Step 418: train/loss = 0.425201416015625, train/raw-loss = 0.38138657808303833, train/logprobs = tensor([[-0.6278, -2.6637],
        [-0.9219, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10953718423843384
Epoch 0, Step 419: train/loss = 0.4748583734035492, train/raw-loss = 0.4287012219429016, train/logprobs = tensor([[-0.9160, -3.2772],
        [-0.9122, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11539296805858612
Epoch 0, Step 420: train/loss = 0.5010626912117004, train/raw-loss = 0.4540204107761383, train/logprobs = tensor([[-0.7420, -3.1555],
        [-0.8450, -0.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11760573834180832
Epoch 0, Step 421: train/loss = 0.4206787049770355, train/raw-loss = 0.3700736165046692, train/logprobs = tensor([[-0.7052, -2.5163],
        [-1.0181, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12651270627975464
Epoch 0, Step 422: train/loss = 0.4147951006889343, train/raw-loss = 0.36267632246017456, train/logprobs = tensor([[-1.0140, -4.3065],
        [-1.0461, -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13029694557189941
Epoch 0, Step 423: train/loss = 0.5280623435974121, train/raw-loss = 0.48511582612991333, train/logprobs = tensor([[-0.6065, -3.2172],
        [-0.5859, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10736636817455292
Epoch 0, Step 424: train/loss = 0.40352633595466614, train/raw-loss = 0.35897302627563477, train/logprobs = tensor([[-0.6236, -4.3537],
        [-0.7680, -1.1181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138320714235306
Epoch 0, Step 425: train/loss = 0.8796711564064026, train/raw-loss = 0.8413310050964355, train/logprobs = tensor([[-2.0378, -3.2035],
        [-0.6904, -1.0185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09585035592317581
Epoch 0, Step 426: train/loss = 0.47143039107322693, train/raw-loss = 0.4155287742614746, train/logprobs = tensor([[-0.9039, -2.6991],
        [-1.0200, -0.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397540271282196
Epoch 0, Step 427: train/loss = 0.42345067858695984, train/raw-loss = 0.37859249114990234, train/logprobs = tensor([[-0.6016, -2.9237],
        [-0.6873, -0.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11214549839496613
Epoch 0, Step 428: train/loss = 0.7534656524658203, train/raw-loss = 0.7055519223213196, train/logprobs = tensor([[-1.0815, -1.2390],
        [-0.6596, -0.6095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1197841614484787
Epoch 0, Step 429: train/loss = 0.40859729051589966, train/raw-loss = 0.3661719858646393, train/logprobs = tensor([[-0.5993, -3.0800],
        [-0.7552, -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10606325417757034
Epoch 0, Step 430: train/loss = 0.52564537525177, train/raw-loss = 0.4852792024612427, train/logprobs = tensor([[-0.6492, -3.2685],
        [-0.6668, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10091553628444672
Epoch 0, Step 431: train/loss = 0.5096336603164673, train/raw-loss = 0.4645584225654602, train/logprobs = tensor([[-0.7024, -1.5796],
        [-0.8174, -0.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268796026706696
Epoch 0, Step 432: train/loss = 0.5932357311248779, train/raw-loss = 0.5457109808921814, train/logprobs = tensor([[-0.7490, -1.2522],
        [-0.8882, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11881178617477417
Epoch 0, Step 433: train/loss = 0.569495677947998, train/raw-loss = 0.5290238261222839, train/logprobs = tensor([[-0.6502, -1.6380],
        [-0.7053, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10117959976196289
Epoch 0, Step 434: train/loss = 0.3816820979118347, train/raw-loss = 0.32580557465553284, train/logprobs = tensor([[-0.8091, -4.5622],
        [-0.8315, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396913081407547
Epoch 0, Step 435: train/loss = 0.5673817992210388, train/raw-loss = 0.5113974213600159, train/logprobs = tensor([[-1.4507, -3.0001],
        [-0.9322, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13996098935604095
Epoch 0, Step 436: train/loss = 0.45439401268959045, train/raw-loss = 0.4054702818393707, train/logprobs = tensor([[-0.8318, -4.2457],
        [-1.0467, -1.3696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1223093643784523
Epoch 0, Step 437: train/loss = 0.4621843099594116, train/raw-loss = 0.41540318727493286, train/logprobs = tensor([[-0.6813, -3.5168],
        [-0.7909, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11695278435945511
Epoch 0, Step 438: train/loss = 0.5046100616455078, train/raw-loss = 0.4599185287952423, train/logprobs = tensor([[-0.5231, -2.5747],
        [-0.6201, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11172883957624435
Epoch 0, Step 439: train/loss = 0.5850710272789001, train/raw-loss = 0.5455136895179749, train/logprobs = tensor([[-0.4986, -1.2155],
        [-0.5796, -0.4684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09889333695173264
Epoch 0, Step 440: train/loss = 0.6058076620101929, train/raw-loss = 0.5590941309928894, train/logprobs = tensor([[-0.8611, -1.7946],
        [-0.6544, -0.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11678382009267807
Epoch 0, Step 441: train/loss = 0.6798449754714966, train/raw-loss = 0.6382153034210205, train/logprobs = tensor([[-1.0497, -1.6033],
        [-0.6585, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10407428443431854
Epoch 0, Step 442: train/loss = 0.6254869699478149, train/raw-loss = 0.5789841413497925, train/logprobs = tensor([[-0.5223, -1.0948],
        [-0.5584, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11625717580318451
Epoch 0, Step 443: train/loss = 0.7724449038505554, train/raw-loss = 0.7259612083435059, train/logprobs = tensor([[-1.7597, -1.4562],
        [-1.0892, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11620926111936569
Epoch 0, Step 444: train/loss = 0.4963493347167969, train/raw-loss = 0.4437929391860962, train/logprobs = tensor([[-0.9565, -2.6228],
        [-0.7302, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313910186290741
Epoch 0, Step 445: train/loss = 0.4490845203399658, train/raw-loss = 0.3970927596092224, train/logprobs = tensor([[-0.6352, -3.0654],
        [-0.7633, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12997940182685852
Epoch 0, Step 446: train/loss = 0.5369887351989746, train/raw-loss = 0.49359753727912903, train/logprobs = tensor([[-0.9159, -2.2807],
        [-0.8040, -0.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10847806185483932
Epoch 0, Step 447: train/loss = 0.4158163070678711, train/raw-loss = 0.3634653687477112, train/logprobs = tensor([[-1.0498, -5.7982],
        [-0.8236, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13087734580039978
Epoch 0, Step 448: train/loss = 0.3948708474636078, train/raw-loss = 0.34759658575057983, train/logprobs = tensor([[-0.6141, -5.3765],
        [-0.7728, -1.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181856095790863
Epoch 0, Step 449: train/loss = 0.6252856850624084, train/raw-loss = 0.5819107294082642, train/logprobs = tensor([[-0.8105, -1.9142],
        [-0.7707, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843734443187714
Epoch 0, Step 450: train/loss = 0.6115829348564148, train/raw-loss = 0.5620008707046509, train/logprobs = tensor([[-1.0205, -1.9423],
        [-1.0791, -0.5417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1239551454782486
Epoch 0, Step 451: train/loss = 0.5452542901039124, train/raw-loss = 0.4996120035648346, train/logprobs = tensor([[-0.7810, -1.6515],
        [-0.8441, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11410565674304962
Epoch 0, Step 452: train/loss = 0.36642342805862427, train/raw-loss = 0.31855660676956177, train/logprobs = tensor([[-0.7250, -6.5179],
        [-1.0452, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966709047555923
Epoch 0, Step 453: train/loss = 0.3774557113647461, train/raw-loss = 0.33529728651046753, train/logprobs = tensor([[-0.6152, -4.5417],
        [-0.8668, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10539601743221283
Epoch 0, Step 454: train/loss = 0.5600271224975586, train/raw-loss = 0.5226930975914001, train/logprobs = tensor([[-0.3920, -2.7198],
        [-0.4602, -0.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933350920677185
Epoch 0, Step 455: train/loss = 0.39999470114707947, train/raw-loss = 0.35674813389778137, train/logprobs = tensor([[-0.6848, -3.6986],
        [-0.8799, -0.8161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10811647772789001
Epoch 0, Step 456: train/loss = 0.6496819257736206, train/raw-loss = 0.5942800641059875, train/logprobs = tensor([[-0.8408, -1.3796],
        [-0.8735, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13850462436676025
Epoch 0, Step 457: train/loss = 0.43777889013290405, train/raw-loss = 0.38553306460380554, train/logprobs = tensor([[-0.5530, -2.7737],
        [-0.8529, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13061457872390747
Epoch 0, Step 458: train/loss = 0.4039504826068878, train/raw-loss = 0.3564169704914093, train/logprobs = tensor([[-0.5656, -4.8029],
        [-0.7878, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11883380264043808
Epoch 0, Step 459: train/loss = 0.4424052834510803, train/raw-loss = 0.3914188742637634, train/logprobs = tensor([[-0.7228, -2.9402],
        [-0.8195, -0.5465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127466082572937
Epoch 0, Step 460: train/loss = 0.4875824451446533, train/raw-loss = 0.4387238621711731, train/logprobs = tensor([[-0.7484, -3.2870],
        [-0.8297, -0.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12214648723602295
Epoch 0, Step 461: train/loss = 0.4823799133300781, train/raw-loss = 0.4330179691314697, train/logprobs = tensor([[-1.0411, -3.2751],
        [-0.9455, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12340489029884338
Epoch 0, Step 462: train/loss = 0.5210558772087097, train/raw-loss = 0.4702281653881073, train/logprobs = tensor([[-0.8351, -1.9065],
        [-0.9628, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127069354057312
Epoch 0, Step 463: train/loss = 0.49936872720718384, train/raw-loss = 0.45210063457489014, train/logprobs = tensor([[-0.8515, -2.0870],
        [-1.0796, -0.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817024648189545
Epoch 0, Step 464: train/loss = 0.3816567361354828, train/raw-loss = 0.330344557762146, train/logprobs = tensor([[-0.5352, -4.4379],
        [-0.8610, -1.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12828052043914795
Epoch 0, Step 465: train/loss = 0.5365382432937622, train/raw-loss = 0.48803162574768066, train/logprobs = tensor([[-0.5987, -1.6065],
        [-0.9073, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12126651406288147
Epoch 0, Step 466: train/loss = 0.6081479787826538, train/raw-loss = 0.5599644184112549, train/logprobs = tensor([[-1.0223, -2.4034],
        [-0.9880, -0.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12045887112617493
Epoch 0, Step 467: train/loss = 0.5465774536132812, train/raw-loss = 0.5016021132469177, train/logprobs = tensor([[-0.9165, -2.4562],
        [-0.7439, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11243817210197449
Epoch 0, Step 468: train/loss = 0.3108431398868561, train/raw-loss = 0.25061726570129395, train/logprobs = tensor([[-0.6806, -3.8796],
        [-1.2231, -0.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15056467056274414
Epoch 0, Step 469: train/loss = 0.5789167881011963, train/raw-loss = 0.5385198593139648, train/logprobs = tensor([[-0.5535, -1.6150],
        [-0.8523, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10099227726459503
Epoch 0, Step 470: train/loss = 0.5932055711746216, train/raw-loss = 0.5417303442955017, train/logprobs = tensor([[-0.8838, -2.3535],
        [-0.6333, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12868809700012207
Epoch 0, Step 471: train/loss = 0.34799474477767944, train/raw-loss = 0.302228182554245, train/logprobs = tensor([[-0.4560, -4.4254],
        [-0.6641, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11441637575626373
Epoch 0, Step 472: train/loss = 0.5125042200088501, train/raw-loss = 0.46662092208862305, train/logprobs = tensor([[-0.5033, -3.4349],
        [-0.6518, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11470822989940643
Epoch 0, Step 473: train/loss = 0.460089772939682, train/raw-loss = 0.4105033874511719, train/logprobs = tensor([[-1.0637, -4.9881],
        [-0.8617, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12396591901779175
Epoch 0, Step 474: train/loss = 0.47991177439689636, train/raw-loss = 0.437187135219574, train/logprobs = tensor([[-0.5957, -2.8251],
        [-0.7654, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10681168735027313
Epoch 0, Step 475: train/loss = 0.3744520843029022, train/raw-loss = 0.3204002380371094, train/logprobs = tensor([[-0.7159, -4.6225],
        [-0.8118, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351296603679657
Epoch 0, Step 476: train/loss = 0.524674117565155, train/raw-loss = 0.4747612774372101, train/logprobs = tensor([[-0.4771, -1.8857],
        [-0.4760, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12478218227624893
Epoch 0, Step 477: train/loss = 0.44388583302497864, train/raw-loss = 0.3884371221065521, train/logprobs = tensor([[-0.6073, -3.9967],
        [-0.6574, -0.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13862180709838867
Epoch 0, Step 478: train/loss = 0.3568658232688904, train/raw-loss = 0.30657944083213806, train/logprobs = tensor([[-0.8048, -6.1623],
        [-0.8500, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12571600079536438
Epoch 0, Step 479: train/loss = 0.5149844288825989, train/raw-loss = 0.4767034649848938, train/logprobs = tensor([[-0.3726, -3.7976],
        [-0.5362, -1.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0957023948431015
Epoch 0, Step 480: train/loss = 0.6545751094818115, train/raw-loss = 0.614773690700531, train/logprobs = tensor([[-0.4615, -1.0696],
        [-0.5587, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09950347244739532
Epoch 0, Step 481: train/loss = 0.32190558314323425, train/raw-loss = 0.2623279094696045, train/logprobs = tensor([[-0.9202, -5.4479],
        [-1.1605, -1.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14894422888755798
Epoch 0, Step 482: train/loss = 0.5434544086456299, train/raw-loss = 0.49735894799232483, train/logprobs = tensor([[-0.7920, -1.4834],
        [-0.9966, -0.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11523868143558502
Epoch 0, Step 483: train/loss = 0.4868859350681305, train/raw-loss = 0.44220221042633057, train/logprobs = tensor([[-0.5318, -3.5010],
        [-0.7685, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170938611030579
Epoch 0, Step 484: train/loss = 0.4914284944534302, train/raw-loss = 0.43730035424232483, train/logprobs = tensor([[-0.5718, -2.6023],
        [-0.7426, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13532035052776337
Epoch 0, Step 485: train/loss = 0.323200523853302, train/raw-loss = 0.2664017081260681, train/logprobs = tensor([[-1.0168, -6.4665],
        [-1.4253, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419970542192459
Epoch 0, Step 486: train/loss = 0.624463677406311, train/raw-loss = 0.5814039707183838, train/logprobs = tensor([[-0.5168, -1.1125],
        [-0.6725, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076493039727211
Epoch 0, Step 487: train/loss = 0.5029308795928955, train/raw-loss = 0.4579135775566101, train/logprobs = tensor([[-0.9411, -3.1629],
        [-1.0031, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1125432699918747
Epoch 0, Step 488: train/loss = 0.4809708595275879, train/raw-loss = 0.43437403440475464, train/logprobs = tensor([[-0.6119, -4.6907],
        [-0.7032, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11649200320243835
Epoch 0, Step 489: train/loss = 0.4134867489337921, train/raw-loss = 0.3572513461112976, train/logprobs = tensor([[-0.5636, -5.9423],
        [-1.0450, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14058853685855865
Epoch 0, Step 490: train/loss = 0.5351662635803223, train/raw-loss = 0.4760529398918152, train/logprobs = tensor([[-0.5533, -1.7096],
        [-0.7532, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14778324961662292
Epoch 0, Step 491: train/loss = 0.4402925968170166, train/raw-loss = 0.38413944840431213, train/logprobs = tensor([[-0.8937, -4.4506],
        [-1.3396, -1.2753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14038291573524475
Epoch 0, Step 492: train/loss = 0.43293240666389465, train/raw-loss = 0.3805578649044037, train/logprobs = tensor([[-0.8503, -4.4717],
        [-1.1989, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1309363842010498
Epoch 0, Step 493: train/loss = 0.6073776483535767, train/raw-loss = 0.5634956359863281, train/logprobs = tensor([[-0.4328, -1.5566],
        [-0.4525, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10970503836870193
Epoch 0, Step 494: train/loss = 0.49100977182388306, train/raw-loss = 0.4331502914428711, train/logprobs = tensor([[-0.8321, -1.9802],
        [-1.2426, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14464858174324036
Epoch 0, Step 495: train/loss = 0.46533873677253723, train/raw-loss = 0.41704434156417847, train/logprobs = tensor([[-0.4828, -4.2184],
        [-0.7516, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1207360029220581
Epoch 0, Step 496: train/loss = 0.47407662868499756, train/raw-loss = 0.42173826694488525, train/logprobs = tensor([[-0.6113, -3.2991],
        [-0.6591, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.130845844745636
Epoch 0, Step 497: train/loss = 0.526111364364624, train/raw-loss = 0.4837134778499603, train/logprobs = tensor([[-0.4971, -1.4677],
        [-0.6647, -0.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599479079246521
Epoch 0, Step 498: train/loss = 0.36457493901252747, train/raw-loss = 0.30453255772590637, train/logprobs = tensor([[-0.6517, -3.0314],
        [-0.9530, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15010595321655273
Epoch 0, Step 499: train/loss = 0.4536783695220947, train/raw-loss = 0.4043956995010376, train/logprobs = tensor([[-0.6455, -3.8339],
        [-0.9001, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12320657074451447
Epoch 0, Step 500: train/loss = 0.5534940958023071, train/raw-loss = 0.5064899325370789, train/logprobs = tensor([[-0.6471, -2.6211],
        [-0.8703, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11751043051481247
Epoch 0, Step 501: train/loss = 0.46570420265197754, train/raw-loss = 0.41305476427078247, train/logprobs = tensor([[-0.7756, -4.6677],
        [-0.7527, -1.1970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13162362575531006
Epoch 0, Step 502: train/loss = 0.359615683555603, train/raw-loss = 0.30500802397727966, train/logprobs = tensor([[-0.5528, -2.6350],
        [-1.0887, -0.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365191787481308
Epoch 0, Step 503: train/loss = 0.6751784086227417, train/raw-loss = 0.6363040208816528, train/logprobs = tensor([[-0.6277, -1.0812],
        [-0.5327, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718595445156097
Epoch 0, Step 504: train/loss = 0.4421887993812561, train/raw-loss = 0.39663606882095337, train/logprobs = tensor([[-0.4903, -3.6345],
        [-0.6208, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11388169229030609
Epoch 0, Step 505: train/loss = 0.3987968862056732, train/raw-loss = 0.3445255756378174, train/logprobs = tensor([[-0.6198, -6.3104],
        [-1.0342, -1.5763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356782615184784
Epoch 0, Step 506: train/loss = 0.5706059336662292, train/raw-loss = 0.5256567001342773, train/logprobs = tensor([[-0.6066, -1.6782],
        [-0.6839, -0.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11237308382987976
Epoch 0, Step 507: train/loss = 0.5295453071594238, train/raw-loss = 0.4760100841522217, train/logprobs = tensor([[-0.9198, -5.9033],
        [-0.9137, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338379830121994
Epoch 0, Step 508: train/loss = 0.5138435363769531, train/raw-loss = 0.4645537734031677, train/logprobs = tensor([[-0.6472, -2.1718],
        [-0.8288, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12322434037923813
Epoch 0, Step 509: train/loss = 0.5710686445236206, train/raw-loss = 0.5207568407058716, train/logprobs = tensor([[-0.6654, -1.8328],
        [-0.6597, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12577953934669495
Epoch 0, Step 510: train/loss = 0.4852830469608307, train/raw-loss = 0.4346848428249359, train/logprobs = tensor([[-0.7493, -3.5734],
        [-0.9950, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12649554014205933
Epoch 0, Step 511: train/loss = 0.523690938949585, train/raw-loss = 0.4744674563407898, train/logprobs = tensor([[-0.8034, -3.3889],
        [-0.8083, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12305884063243866
Epoch 0, Step 512: train/loss = 0.47469615936279297, train/raw-loss = 0.43038061261177063, train/logprobs = tensor([[-0.7026, -2.2396],
        [-1.1695, -0.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11078887432813644
Epoch 0, Step 513: train/loss = 0.5075020790100098, train/raw-loss = 0.4603564739227295, train/logprobs = tensor([[-0.4122, -3.2346],
        [-0.5799, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11786395311355591
Epoch 0, Step 514: train/loss = 0.37307024002075195, train/raw-loss = 0.315397709608078, train/logprobs = tensor([[-0.6185, -4.6477],
        [-1.0558, -1.3268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14418134093284607
Epoch 0, Step 515: train/loss = 0.7173506021499634, train/raw-loss = 0.672623872756958, train/logprobs = tensor([[-0.4980, -0.5741],
        [-0.5905, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11181682348251343
Epoch 0, Step 516: train/loss = 0.4271079897880554, train/raw-loss = 0.37282490730285645, train/logprobs = tensor([[-0.7481, -2.9041],
        [-1.1775, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13570775091648102
Epoch 0, Step 517: train/loss = 0.45435699820518494, train/raw-loss = 0.40503939986228943, train/logprobs = tensor([[-0.5858, -2.4908],
        [-0.7929, -0.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12329396605491638
Epoch 0, Step 518: train/loss = 0.38108131289482117, train/raw-loss = 0.3283301889896393, train/logprobs = tensor([[-0.7659, -5.4860],
        [-1.5413, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318778097629547
Epoch 0, Step 519: train/loss = 0.3740365207195282, train/raw-loss = 0.31546685099601746, train/logprobs = tensor([[-0.9305, -4.0717],
        [-1.0249, -1.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14642417430877686
Epoch 0, Step 520: train/loss = 0.7392071485519409, train/raw-loss = 0.6956232190132141, train/logprobs = tensor([[-0.9844, -1.0049],
        [-0.8008, -0.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10895982384681702
Epoch 0, Step 521: train/loss = 0.4799209237098694, train/raw-loss = 0.43859273195266724, train/logprobs = tensor([[-0.3478, -2.6037],
        [-0.5377, -0.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10332038253545761
Epoch 0, Step 522: train/loss = 0.5998055338859558, train/raw-loss = 0.5520653128623962, train/logprobs = tensor([[-1.2722, -3.3479],
        [-0.8881, -0.7461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193506270647049
Epoch 0, Step 523: train/loss = 0.530279278755188, train/raw-loss = 0.4835647642612457, train/logprobs = tensor([[-0.5182, -2.2101],
        [-0.6166, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11678630113601685
Epoch 0, Step 524: train/loss = 0.3275933861732483, train/raw-loss = 0.2737117111682892, train/logprobs = tensor([[-0.4440, -6.3426],
        [-0.8204, -1.2582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13470415771007538
Epoch 0, Step 525: train/loss = 0.5440260171890259, train/raw-loss = 0.490331768989563, train/logprobs = tensor([[-0.6740, -1.9974],
        [-0.8384, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13423554599285126
Epoch 0, Step 526: train/loss = 0.4887337386608124, train/raw-loss = 0.44836342334747314, train/logprobs = tensor([[-0.3739, -1.8869],
        [-0.6340, -0.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10092584043741226
Epoch 0, Step 527: train/loss = 0.28928858041763306, train/raw-loss = 0.2386462539434433, train/logprobs = tensor([[-0.5424, -4.4023],
        [-1.0418, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266057789325714
Epoch 0, Step 528: train/loss = 0.3853161633014679, train/raw-loss = 0.3422919511795044, train/logprobs = tensor([[-0.3459, -5.9428],
        [-0.4739, -1.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10756052285432816
Epoch 0, Step 529: train/loss = 0.4315526783466339, train/raw-loss = 0.3791978061199188, train/logprobs = tensor([[-0.6523, -4.5885],
        [-0.9231, -1.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13088718056678772
Epoch 0, Step 530: train/loss = 0.5952575206756592, train/raw-loss = 0.5400914549827576, train/logprobs = tensor([[-0.5882, -1.7434],
        [-1.0368, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13791526854038239
Epoch 0, Step 531: train/loss = 0.5614139437675476, train/raw-loss = 0.5154389142990112, train/logprobs = tensor([[-0.4042, -1.4764],
        [-0.5952, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11493748426437378
Epoch 0, Step 532: train/loss = 0.5114423036575317, train/raw-loss = 0.460074782371521, train/logprobs = tensor([[-0.5976, -3.0278],
        [-0.9883, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12841898202896118
Epoch 0, Step 533: train/loss = 0.4545033574104309, train/raw-loss = 0.39703696966171265, train/logprobs = tensor([[-0.8423, -3.8459],
        [-0.9140, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14366595447063446
Epoch 0, Step 534: train/loss = 0.5329567193984985, train/raw-loss = 0.4805831015110016, train/logprobs = tensor([[-0.4722, -2.5328],
        [-0.7122, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13093407452106476
Epoch 0, Step 535: train/loss = 0.3751780390739441, train/raw-loss = 0.3108597993850708, train/logprobs = tensor([[-0.8340, -4.2147],
        [-1.3163, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16079555451869965
Epoch 0, Step 536: train/loss = 0.42359691858291626, train/raw-loss = 0.37398266792297363, train/logprobs = tensor([[-0.6580, -2.6272],
        [-0.8731, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12403559684753418
Epoch 0, Step 537: train/loss = 0.4032784700393677, train/raw-loss = 0.35327064990997314, train/logprobs = tensor([[-0.6370, -2.4707],
        [-1.1136, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12501958012580872
Epoch 0, Step 538: train/loss = 0.4050373136997223, train/raw-loss = 0.3499782979488373, train/logprobs = tensor([[-0.7890, -4.5606],
        [-0.7521, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13764753937721252
Epoch 0, Step 539: train/loss = 0.47098082304000854, train/raw-loss = 0.42830580472946167, train/logprobs = tensor([[-0.4201, -3.4351],
        [-0.6437, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10668744146823883
Epoch 0, Step 540: train/loss = 0.5073834657669067, train/raw-loss = 0.45364701747894287, train/logprobs = tensor([[-0.6812, -2.8739],
        [-1.0997, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13434116542339325
Epoch 0, Step 541: train/loss = 0.3480203151702881, train/raw-loss = 0.29350438714027405, train/logprobs = tensor([[-0.8118, -5.7957],
        [-1.3884, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362898051738739
Epoch 0, Step 542: train/loss = 0.41783371567726135, train/raw-loss = 0.3736308813095093, train/logprobs = tensor([[-0.6613, -2.9212],
        [-0.9446, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050708591938019
Epoch 0, Step 543: train/loss = 0.43552303314208984, train/raw-loss = 0.3873923122882843, train/logprobs = tensor([[-0.5935, -4.9512],
        [-0.7592, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12032672017812729
Epoch 0, Step 544: train/loss = 0.5151009559631348, train/raw-loss = 0.46057891845703125, train/logprobs = tensor([[-0.6256, -2.1069],
        [-0.8209, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13630515336990356
Epoch 0, Step 545: train/loss = 0.39881768822669983, train/raw-loss = 0.34728264808654785, train/logprobs = tensor([[-0.6200, -3.2493],
        [-1.2096, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1288377046585083
Epoch 0, Step 546: train/loss = 0.4347343444824219, train/raw-loss = 0.3869688808917999, train/logprobs = tensor([[-0.4485, -2.9489],
        [-0.7395, -0.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11941366642713547
Epoch 0, Step 547: train/loss = 0.41672635078430176, train/raw-loss = 0.36631590127944946, train/logprobs = tensor([[-0.6633, -4.4580],
        [-0.8552, -1.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12602610886096954
Epoch 0, Step 548: train/loss = 0.5513071417808533, train/raw-loss = 0.5037056803703308, train/logprobs = tensor([[-0.4690, -1.2886],
        [-0.7513, -0.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11900371313095093
Epoch 0, Step 549: train/loss = 0.49907803535461426, train/raw-loss = 0.44652068614959717, train/logprobs = tensor([[-0.8844, -2.1400],
        [-1.2870, -0.8276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13139334321022034
Epoch 0, Step 550: train/loss = 0.3906681537628174, train/raw-loss = 0.3311857581138611, train/logprobs = tensor([[-1.0068, -4.5412],
        [-1.4529, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14870594441890717
Epoch 0, Step 551: train/loss = 0.5521510243415833, train/raw-loss = 0.5035495162010193, train/logprobs = tensor([[-0.6196, -1.7798],
        [-0.8488, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12150366604328156
Epoch 0, Step 552: train/loss = 0.39104118943214417, train/raw-loss = 0.3399718403816223, train/logprobs = tensor([[-0.6677, -2.9746],
        [-1.1979, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12767337262630463
Epoch 0, Step 553: train/loss = 0.4357725977897644, train/raw-loss = 0.38445109128952026, train/logprobs = tensor([[-0.4667, -2.9074],
        [-0.8222, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12830373644828796
Epoch 0, Step 554: train/loss = 0.4001120328903198, train/raw-loss = 0.35230788588523865, train/logprobs = tensor([[-0.4895, -4.4909],
        [-0.7256, -1.3062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11951033025979996
Epoch 0, Step 555: train/loss = 0.46358758211135864, train/raw-loss = 0.4147524833679199, train/logprobs = tensor([[-0.9871, -3.1564],
        [-0.9446, -0.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122087761759758
Epoch 0, Step 556: train/loss = 0.4284593462944031, train/raw-loss = 0.3776533007621765, train/logprobs = tensor([[-0.4434, -3.9941],
        [-0.7277, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270151287317276
Epoch 0, Step 557: train/loss = 0.44354522228240967, train/raw-loss = 0.38711419701576233, train/logprobs = tensor([[-0.8039, -3.7087],
        [-1.2487, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14107753336429596
Epoch 0, Step 558: train/loss = 0.6474423408508301, train/raw-loss = 0.5934416055679321, train/logprobs = tensor([[-0.6827, -1.1290],
        [-0.8745, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13500180840492249
Epoch 0, Step 559: train/loss = 0.4638015627861023, train/raw-loss = 0.41151270270347595, train/logprobs = tensor([[-0.6691, -3.0612],
        [-0.7068, -0.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13072212040424347
Epoch 0, Step 560: train/loss = 0.5551549196243286, train/raw-loss = 0.5146841406822205, train/logprobs = tensor([[-0.3583, -1.9527],
        [-0.4411, -0.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101176917552948
Epoch 0, Step 561: train/loss = 0.49587154388427734, train/raw-loss = 0.4442625641822815, train/logprobs = tensor([[-0.5389, -2.0516],
        [-0.9696, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12902235984802246
Epoch 0, Step 562: train/loss = 0.4462478458881378, train/raw-loss = 0.39352598786354065, train/logprobs = tensor([[-0.6671, -3.6647],
        [-1.0275, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13180464506149292
Epoch 0, Step 563: train/loss = 0.5013418197631836, train/raw-loss = 0.4583410322666168, train/logprobs = tensor([[-0.4500, -3.2726],
        [-0.6311, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10750199854373932
Epoch 0, Step 564: train/loss = 0.5161969065666199, train/raw-loss = 0.4611676335334778, train/logprobs = tensor([[-0.6126, -1.6957],
        [-0.9613, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13757312297821045
Epoch 0, Step 565: train/loss = 0.390794962644577, train/raw-loss = 0.33283817768096924, train/logprobs = tensor([[-0.8939, -3.2323],
        [-1.5200, -1.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14489193260669708
Epoch 0, Step 566: train/loss = 0.485787034034729, train/raw-loss = 0.43715089559555054, train/logprobs = tensor([[-0.4867, -6.7065],
        [-0.6845, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12159028649330139
Epoch 0, Step 567: train/loss = 0.3771211504936218, train/raw-loss = 0.3224896192550659, train/logprobs = tensor([[-0.5295, -3.3433],
        [-1.0938, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13657882809638977
Epoch 0, Step 568: train/loss = 0.5545470714569092, train/raw-loss = 0.49759647250175476, train/logprobs = tensor([[-0.5519, -2.9033],
        [-0.9961, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14237649738788605
Epoch 0, Step 569: train/loss = 0.37160739302635193, train/raw-loss = 0.308682918548584, train/logprobs = tensor([[-0.8142, -2.4556],
        [-1.5241, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15731114149093628
Epoch 0, Step 570: train/loss = 0.7005658745765686, train/raw-loss = 0.6460933685302734, train/logprobs = tensor([[-1.4879, -2.3857],
        [-0.9583, -0.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13618122041225433
Epoch 0, Step 571: train/loss = 0.4305878281593323, train/raw-loss = 0.3819681406021118, train/logprobs = tensor([[-0.6408, -3.7270],
        [-0.6724, -0.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12154923379421234
Epoch 0, Step 572: train/loss = 0.42663446068763733, train/raw-loss = 0.379306435585022, train/logprobs = tensor([[-0.4055, -2.9337],
        [-0.5279, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11832010000944138
Epoch 0, Step 573: train/loss = 0.386836439371109, train/raw-loss = 0.33329063653945923, train/logprobs = tensor([[-0.5452, -3.6589],
        [-0.7411, -1.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386458158493042
Epoch 0, Step 574: train/loss = 0.5731810927391052, train/raw-loss = 0.5271627902984619, train/logprobs = tensor([[-0.4840, -1.3258],
        [-0.7117, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150456964969635
Epoch 0, Step 575: train/loss = 0.3863893151283264, train/raw-loss = 0.3282588720321655, train/logprobs = tensor([[-0.5929, -3.8572],
        [-1.1749, -1.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14532622694969177
Epoch 0, Step 576: train/loss = 0.5376732349395752, train/raw-loss = 0.4727751910686493, train/logprobs = tensor([[-0.9125, -1.7744],
        [-1.1961, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.162244975566864
Epoch 0, Step 577: train/loss = 0.6187572479248047, train/raw-loss = 0.5592434406280518, train/logprobs = tensor([[-0.7379, -1.5766],
        [-1.0399, -0.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14878444373607635
Epoch 0, Step 578: train/loss = 0.3640593886375427, train/raw-loss = 0.3033575713634491, train/logprobs = tensor([[-0.7489, -4.1261],
        [-1.3644, -0.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15175451338291168
Epoch 0, Step 579: train/loss = 0.42226964235305786, train/raw-loss = 0.37308967113494873, train/logprobs = tensor([[-0.7744, -4.3830],
        [-1.1150, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294988334178925
Epoch 0, Step 580: train/loss = 0.42047688364982605, train/raw-loss = 0.37582963705062866, train/logprobs = tensor([[-0.9230, -5.5235],
        [-0.9593, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161814630031586
Epoch 0, Step 581: train/loss = 0.38469958305358887, train/raw-loss = 0.3331684470176697, train/logprobs = tensor([[-0.6577, -6.2462],
        [-1.1322, -1.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12882785499095917
Epoch 0, Step 582: train/loss = 0.5298843383789062, train/raw-loss = 0.4826178252696991, train/logprobs = tensor([[-0.6257, -1.7222],
        [-1.0610, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181662380695343
Epoch 0, Step 583: train/loss = 0.544426679611206, train/raw-loss = 0.49645155668258667, train/logprobs = tensor([[-0.7792, -2.2109],
        [-0.8135, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11993800103664398
Epoch 0, Step 584: train/loss = 0.5129783749580383, train/raw-loss = 0.46800699830055237, train/logprobs = tensor([[-0.4908, -1.9666],
        [-0.8133, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124284639954567
Epoch 0, Step 585: train/loss = 0.5640960931777954, train/raw-loss = 0.5182621479034424, train/logprobs = tensor([[-0.3264, -2.1437],
        [-0.4940, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458484083414078
Epoch 0, Step 586: train/loss = 0.44517016410827637, train/raw-loss = 0.38599729537963867, train/logprobs = tensor([[-0.7429, -1.9393],
        [-1.3043, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14793215692043304
Epoch 0, Step 587: train/loss = 0.5422806739807129, train/raw-loss = 0.49495729804039, train/logprobs = tensor([[-0.6656, -1.4591],
        [-0.9654, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1183084025979042
Epoch 0, Step 588: train/loss = 0.4071709215641022, train/raw-loss = 0.3592039942741394, train/logprobs = tensor([[-0.7662, -4.6205],
        [-1.3602, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11991726607084274
Epoch 0, Step 589: train/loss = 0.4213344156742096, train/raw-loss = 0.3657815456390381, train/logprobs = tensor([[-0.6254, -3.2352],
        [-1.0736, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13888223469257355
Epoch 0, Step 590: train/loss = 0.3511931300163269, train/raw-loss = 0.3041185140609741, train/logprobs = tensor([[-0.5312, -4.4142],
        [-0.7939, -1.1906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11768659204244614
Epoch 0, Step 591: train/loss = 0.6736503839492798, train/raw-loss = 0.6231221556663513, train/logprobs = tensor([[-0.6357, -0.7852],
        [-0.7428, -0.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12632068991661072
Epoch 0, Step 592: train/loss = 0.5210930109024048, train/raw-loss = 0.47176772356033325, train/logprobs = tensor([[-0.5577, -1.8264],
        [-0.8443, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1233132928609848
Epoch 0, Step 593: train/loss = 0.4632757902145386, train/raw-loss = 0.41216564178466797, train/logprobs = tensor([[-0.5231, -2.6207],
        [-0.8618, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12777546048164368
Epoch 0, Step 594: train/loss = 0.3512044847011566, train/raw-loss = 0.2925289571285248, train/logprobs = tensor([[-0.6763, -3.2169],
        [-1.0709, -0.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14668872952461243
Epoch 0, Step 595: train/loss = 0.5457268357276917, train/raw-loss = 0.4950614273548126, train/logprobs = tensor([[-0.5523, -1.7793],
        [-0.7891, -0.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12666361033916473
Epoch 0, Step 596: train/loss = 0.47602352499961853, train/raw-loss = 0.42630934715270996, train/logprobs = tensor([[-0.6975, -4.0283],
        [-0.9998, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12428541481494904
Epoch 0, Step 597: train/loss = 0.653679370880127, train/raw-loss = 0.6043444275856018, train/logprobs = tensor([[-0.6018, -0.8801],
        [-0.9619, -0.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12333739548921585
Epoch 0, Step 598: train/loss = 0.4472470283508301, train/raw-loss = 0.38955622911453247, train/logprobs = tensor([[-1.0112, -3.2885],
        [-0.9852, -0.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14422710239887238
Epoch 0, Step 599: train/loss = 0.4506596326828003, train/raw-loss = 0.39843395352363586, train/logprobs = tensor([[-0.4870, -3.9332],
        [-0.8024, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13056418299674988
Epoch 0, Step 600: train/loss = 0.48587650060653687, train/raw-loss = 0.43501925468444824, train/logprobs = tensor([[-0.4612, -2.7288],
        [-0.7009, -0.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12714320421218872
Epoch 0, Step 601: train/loss = 0.4825677275657654, train/raw-loss = 0.4287419319152832, train/logprobs = tensor([[-0.8876, -2.1799],
        [-1.2902, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13456445932388306
Epoch 0, Step 602: train/loss = 0.5191555023193359, train/raw-loss = 0.4591757655143738, train/logprobs = tensor([[-0.9313, -2.5131],
        [-1.0623, -1.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14994925260543823
Epoch 0, Step 603: train/loss = 0.3225409984588623, train/raw-loss = 0.269397497177124, train/logprobs = tensor([[-0.5190, -5.3472],
        [-0.9603, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13285872340202332
Epoch 0, Step 604: train/loss = 0.5444834232330322, train/raw-loss = 0.49669691920280457, train/logprobs = tensor([[-0.3823, -1.4709],
        [-0.6275, -0.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11946634948253632
Epoch 0, Step 605: train/loss = 0.5339903831481934, train/raw-loss = 0.48570775985717773, train/logprobs = tensor([[-0.6728, -1.0336],
        [-1.2807, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12070655822753906
Epoch 0, Step 606: train/loss = 0.4756103456020355, train/raw-loss = 0.4272366464138031, train/logprobs = tensor([[-0.6170, -2.0378],
        [-0.7721, -0.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12093429267406464
Epoch 0, Step 607: train/loss = 0.4472348690032959, train/raw-loss = 0.3895173668861389, train/logprobs = tensor([[-0.6691, -2.8428],
        [-0.8893, -0.9034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14429378509521484
Epoch 0, Step 608: train/loss = 0.4608973264694214, train/raw-loss = 0.40541213750839233, train/logprobs = tensor([[-0.5466, -2.5893],
        [-1.0781, -0.8579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13871294260025024
Epoch 0, Step 609: train/loss = 0.36990490555763245, train/raw-loss = 0.31443625688552856, train/logprobs = tensor([[-0.8215, -5.3774],
        [-1.4067, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386716365814209
Epoch 0, Step 610: train/loss = 0.30157074332237244, train/raw-loss = 0.23195919394493103, train/logprobs = tensor([[-1.0798, -6.5750],
        [-1.6399, -1.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17402887344360352
Epoch 0, Step 611: train/loss = 0.31785303354263306, train/raw-loss = 0.27093833684921265, train/logprobs = tensor([[-0.4830, -3.8386],
        [-0.8063, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728675663471222
Epoch 0, Step 612: train/loss = 0.5732904672622681, train/raw-loss = 0.5172590017318726, train/logprobs = tensor([[-0.6699, -3.3226],
        [-0.9217, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14007875323295593
Epoch 0, Step 613: train/loss = 0.6040170192718506, train/raw-loss = 0.5484748482704163, train/logprobs = tensor([[-0.7083, -1.7527],
        [-0.9415, -0.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885551691055298
Epoch 0, Step 614: train/loss = 0.47593116760253906, train/raw-loss = 0.41834086179733276, train/logprobs = tensor([[-0.6637, -2.1703],
        [-0.9085, -0.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14397571980953217
Epoch 0, Step 615: train/loss = 0.4758368730545044, train/raw-loss = 0.4167187213897705, train/logprobs = tensor([[-0.6103, -2.1938],
        [-1.0952, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14779537916183472
Epoch 0, Step 616: train/loss = 0.6544460654258728, train/raw-loss = 0.6058756113052368, train/logprobs = tensor([[-0.4710, -0.9067],
        [-0.7319, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12142609059810638
Epoch 0, Step 617: train/loss = 0.48557379841804504, train/raw-loss = 0.44129157066345215, train/logprobs = tensor([[-0.6532, -3.5191],
        [-0.8690, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11070559918880463
Epoch 0, Step 618: train/loss = 0.4450324475765228, train/raw-loss = 0.39272528886795044, train/logprobs = tensor([[-0.4934, -2.5273],
        [-0.9534, -0.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13076786696910858
Epoch 0, Step 619: train/loss = 0.3804686665534973, train/raw-loss = 0.33190226554870605, train/logprobs = tensor([[-0.4552, -4.3451],
        [-0.8233, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141594290733337
Epoch 0, Step 620: train/loss = 0.3908655643463135, train/raw-loss = 0.3306885063648224, train/logprobs = tensor([[-0.7804, -3.2092],
        [-1.2883, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15044263005256653
Epoch 0, Step 621: train/loss = 0.6166977882385254, train/raw-loss = 0.569876492023468, train/logprobs = tensor([[-0.6541, -0.8332],
        [-0.9491, -0.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11705321073532104
Epoch 0, Step 622: train/loss = 0.47741129994392395, train/raw-loss = 0.42511552572250366, train/logprobs = tensor([[-0.4132, -4.4901],
        [-0.8713, -0.9586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1307394653558731
Epoch 0, Step 623: train/loss = 0.4225631356239319, train/raw-loss = 0.37379390001296997, train/logprobs = tensor([[-0.5629, -4.6390],
        [-0.9385, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12192307412624359
Epoch 0, Step 624: train/loss = 0.48050034046173096, train/raw-loss = 0.42576301097869873, train/logprobs = tensor([[-0.5218, -2.7925],
        [-1.0342, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13684330880641937
Epoch 0, Step 625: train/loss = 0.5123174786567688, train/raw-loss = 0.4559779167175293, train/logprobs = tensor([[-0.6080, -3.9476],
        [-0.7645, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14084887504577637
Epoch 0, Step 626: train/loss = 0.495319664478302, train/raw-loss = 0.4449347257614136, train/logprobs = tensor([[-0.5204, -2.0486],
        [-0.8536, -0.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259623020887375
Epoch 0, Step 627: train/loss = 0.47027528285980225, train/raw-loss = 0.4152432084083557, train/logprobs = tensor([[-0.4291, -2.0500],
        [-0.9532, -0.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13758023083209991
Epoch 0, Step 628: train/loss = 0.4423293173313141, train/raw-loss = 0.3887357711791992, train/logprobs = tensor([[-0.4383, -2.2973],
        [-0.9362, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13398386538028717
Epoch 0, Step 629: train/loss = 0.5020447969436646, train/raw-loss = 0.45287078619003296, train/logprobs = tensor([[-0.3745, -1.7431],
        [-0.7097, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12293505668640137
Epoch 0, Step 630: train/loss = 0.4275195002555847, train/raw-loss = 0.37998560070991516, train/logprobs = tensor([[-0.4054, -3.3039],
        [-0.6289, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11883467435836792
Epoch 0, Step 631: train/loss = 0.3217344284057617, train/raw-loss = 0.2640538811683655, train/logprobs = tensor([[-1.0830, -4.6485],
        [-1.5446, -1.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.144201397895813
Epoch 0, Step 632: train/loss = 0.4949139356613159, train/raw-loss = 0.4289044141769409, train/logprobs = tensor([[-0.8257, -3.6961],
        [-1.0442, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1650238037109375
Epoch 0, Step 633: train/loss = 0.37932291626930237, train/raw-loss = 0.3264112174510956, train/logprobs = tensor([[-0.7440, -4.3688],
        [-1.0483, -1.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322791576385498
Epoch 0, Step 634: train/loss = 0.4037932753562927, train/raw-loss = 0.3445587754249573, train/logprobs = tensor([[-0.4467, -3.6299],
        [-1.0791, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14808624982833862
Epoch 0, Step 635: train/loss = 0.3833828866481781, train/raw-loss = 0.32945889234542847, train/logprobs = tensor([[-0.5071, -4.0906],
        [-1.0346, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1348099559545517
Epoch 0, Step 636: train/loss = 0.5040138363838196, train/raw-loss = 0.4549929201602936, train/logprobs = tensor([[-0.5249, -2.9339],
        [-0.7577, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12255239486694336
Epoch 0, Step 637: train/loss = 0.4329111576080322, train/raw-loss = 0.3874317705631256, train/logprobs = tensor([[-0.6022, -3.7491],
        [-0.8340, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11369840800762177
Epoch 0, Step 638: train/loss = 0.6349942684173584, train/raw-loss = 0.5842522978782654, train/logprobs = tensor([[-0.4889, -1.0383],
        [-0.6704, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12685497105121613
Epoch 0, Step 639: train/loss = 0.4554806351661682, train/raw-loss = 0.39596468210220337, train/logprobs = tensor([[-0.8197, -3.2195],
        [-1.1405, -0.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14878974854946136
Epoch 0, Step 640: train/loss = 0.40305018424987793, train/raw-loss = 0.35593944787979126, train/logprobs = tensor([[-0.5231, -4.6714],
        [-0.7594, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11777689307928085
Epoch 0, Step 641: train/loss = 0.637873113155365, train/raw-loss = 0.5853967070579529, train/logprobs = tensor([[-1.2590, -3.0722],
        [-0.9876, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311909556388855
Epoch 0, Step 642: train/loss = 0.4264945685863495, train/raw-loss = 0.37127459049224854, train/logprobs = tensor([[-0.9167, -3.6868],
        [-1.0735, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380499005317688
Epoch 0, Step 643: train/loss = 0.33642280101776123, train/raw-loss = 0.2808893918991089, train/logprobs = tensor([[-0.5141, -5.2177],
        [-0.9177, -0.8021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1388334482908249
Epoch 0, Step 644: train/loss = 0.5619749426841736, train/raw-loss = 0.5031474232673645, train/logprobs = tensor([[-0.9370, -1.1673],
        [-1.3575, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14706876873970032
Epoch 0, Step 645: train/loss = 0.4458748996257782, train/raw-loss = 0.3982759714126587, train/logprobs = tensor([[-1.0406, -5.1232],
        [-1.6464, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11899729073047638
Epoch 0, Step 646: train/loss = 0.6052632331848145, train/raw-loss = 0.552284300327301, train/logprobs = tensor([[-0.5432, -1.0716],
        [-0.8732, -0.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13244736194610596
Epoch 0, Step 647: train/loss = 0.4886906147003174, train/raw-loss = 0.43832653760910034, train/logprobs = tensor([[-0.5589, -2.7767],
        [-0.9506, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12591023743152618
Epoch 0, Step 648: train/loss = 0.4265550374984741, train/raw-loss = 0.37209346890449524, train/logprobs = tensor([[-0.5914, -4.4157],
        [-1.0818, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13615386188030243
Epoch 0, Step 649: train/loss = 0.27908340096473694, train/raw-loss = 0.22296997904777527, train/logprobs = tensor([[-0.5707, -6.0634],
        [-1.3677, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14028355479240417
Epoch 0, Step 650: train/loss = 0.3369506895542145, train/raw-loss = 0.2822209894657135, train/logprobs = tensor([[-0.5806, -5.6742],
        [-1.1058, -1.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13682428002357483
Epoch 0, Step 651: train/loss = 0.30778294801712036, train/raw-loss = 0.24973000586032867, train/logprobs = tensor([[-0.8635, -4.9423],
        [-1.3340, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14513233304023743
Epoch 0, Step 652: train/loss = 0.3911891579627991, train/raw-loss = 0.3506985306739807, train/logprobs = tensor([[-0.9506, -6.7686],
        [-1.1782, -1.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012265682220459
Epoch 0, Step 653: train/loss = 0.4919371008872986, train/raw-loss = 0.44634270668029785, train/logprobs = tensor([[-0.7007, -2.5793],
        [-1.0260, -0.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11398592591285706
Epoch 0, Step 654: train/loss = 0.6122795343399048, train/raw-loss = 0.5653569102287292, train/logprobs = tensor([[-0.5770, -2.1136],
        [-0.6476, -0.6245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11730655282735825
Epoch 0, Step 655: train/loss = 0.3977985978126526, train/raw-loss = 0.3327464163303375, train/logprobs = tensor([[-0.8720, -3.4221],
        [-1.4425, -1.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16263045370578766
Epoch 0, Step 656: train/loss = 0.29438284039497375, train/raw-loss = 0.23741565644741058, train/logprobs = tensor([[-1.0168, -7.6072],
        [-1.3651, -1.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424180120229721
Epoch 0, Step 657: train/loss = 0.36501631140708923, train/raw-loss = 0.3176589608192444, train/logprobs = tensor([[-0.5930, -4.7505],
        [-0.9875, -1.2419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11839333176612854
Epoch 0, Step 658: train/loss = 0.4999542534351349, train/raw-loss = 0.4402619004249573, train/logprobs = tensor([[-0.9525, -3.3313],
        [-1.1483, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492309868335724
Epoch 0, Step 659: train/loss = 0.28447824716567993, train/raw-loss = 0.22445771098136902, train/logprobs = tensor([[-0.5026, -4.7505],
        [-1.0952, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1500512659549713
Epoch 0, Step 660: train/loss = 0.5962755680084229, train/raw-loss = 0.5414507389068604, train/logprobs = tensor([[-0.7663, -2.0783],
        [-0.7215, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370619237422943
Epoch 0, Step 661: train/loss = 0.438496470451355, train/raw-loss = 0.3831927478313446, train/logprobs = tensor([[-0.5416, -4.1665],
        [-0.9979, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13825929164886475
Epoch 0, Step 662: train/loss = 0.5651135444641113, train/raw-loss = 0.5221076011657715, train/logprobs = tensor([[-0.6021, -1.5377],
        [-0.7452, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1075148954987526
Epoch 0, Step 663: train/loss = 0.45610833168029785, train/raw-loss = 0.40588852763175964, train/logprobs = tensor([[-0.9277, -5.4310],
        [-0.8387, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255495250225067
Epoch 0, Step 664: train/loss = 0.4655313491821289, train/raw-loss = 0.41502344608306885, train/logprobs = tensor([[-0.6653, -2.3025],
        [-1.0347, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12626972794532776
Epoch 0, Step 665: train/loss = 0.5177063345909119, train/raw-loss = 0.4577491581439972, train/logprobs = tensor([[-0.9602, -1.9230],
        [-1.0327, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14989301562309265
Epoch 0, Step 666: train/loss = 0.43575072288513184, train/raw-loss = 0.38114407658576965, train/logprobs = tensor([[-0.7445, -3.7723],
        [-1.3582, -0.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13651655614376068
Epoch 0, Step 667: train/loss = 0.46470993757247925, train/raw-loss = 0.41091156005859375, train/logprobs = tensor([[-0.6167, -3.6088],
        [-1.1666, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13449589908123016
Epoch 0, Step 668: train/loss = 0.5686209797859192, train/raw-loss = 0.5119179487228394, train/logprobs = tensor([[-0.6241, -1.3661],
        [-0.9939, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14175765216350555
Epoch 0, Step 669: train/loss = 0.3530932664871216, train/raw-loss = 0.30431467294692993, train/logprobs = tensor([[-0.5683, -4.8968],
        [-0.9903, -0.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194637209177017
Epoch 0, Step 670: train/loss = 0.39676153659820557, train/raw-loss = 0.3492429852485657, train/logprobs = tensor([[-0.7853, -5.0573],
        [-0.9952, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11879631876945496
Epoch 0, Step 671: train/loss = 0.43913790583610535, train/raw-loss = 0.3894200325012207, train/logprobs = tensor([[-0.7617, -3.3134],
        [-0.8368, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1242946982383728
Epoch 0, Step 672: train/loss = 0.5059337019920349, train/raw-loss = 0.45796531438827515, train/logprobs = tensor([[-0.6573, -3.3275],
        [-1.0517, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11992090940475464
Epoch 0, Step 673: train/loss = 0.44164007902145386, train/raw-loss = 0.38350462913513184, train/logprobs = tensor([[-0.5456, -3.3690],
        [-0.9889, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1453385204076767
Epoch 0, Step 674: train/loss = 0.42745310068130493, train/raw-loss = 0.3784864544868469, train/logprobs = tensor([[-0.3958, -2.3563],
        [-0.8537, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241670489311218
Epoch 0, Step 675: train/loss = 0.39187660813331604, train/raw-loss = 0.32588809728622437, train/logprobs = tensor([[-0.5753, -2.8128],
        [-1.2727, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.164971262216568
Epoch 0, Step 676: train/loss = 0.3550258278846741, train/raw-loss = 0.30505216121673584, train/logprobs = tensor([[-0.4435, -6.0387],
        [-1.0236, -1.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12493415921926498
Epoch 0, Step 677: train/loss = 0.4920819401741028, train/raw-loss = 0.4340668022632599, train/logprobs = tensor([[-0.3951, -2.7983],
        [-0.7770, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14503797888755798
Epoch 0, Step 678: train/loss = 0.3683529794216156, train/raw-loss = 0.3021027445793152, train/logprobs = tensor([[-0.5450, -4.4923],
        [-1.2879, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16562552750110626
Epoch 0, Step 679: train/loss = 0.32949408888816833, train/raw-loss = 0.27411702275276184, train/logprobs = tensor([[-0.8655, -4.0749],
        [-1.1357, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1384427696466446
Epoch 0, Step 680: train/loss = 0.3912532925605774, train/raw-loss = 0.34400805830955505, train/logprobs = tensor([[-0.6077, -4.8619],
        [-0.9430, -0.6187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11811309307813644
Epoch 0, Step 681: train/loss = 0.3852214813232422, train/raw-loss = 0.3277071416378021, train/logprobs = tensor([[-0.4768, -3.1170],
        [-1.0115, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14378580451011658
Epoch 0, Step 682: train/loss = 0.5628360509872437, train/raw-loss = 0.5000021457672119, train/logprobs = tensor([[-1.0085, -2.5129],
        [-0.9302, -0.6680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15708495676517487
Epoch 0, Step 683: train/loss = 0.5653361082077026, train/raw-loss = 0.5024989247322083, train/logprobs = tensor([[-0.8029, -1.9490],
        [-1.3501, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15709304809570312
Epoch 0, Step 684: train/loss = 0.38595592975616455, train/raw-loss = 0.3368319272994995, train/logprobs = tensor([[-0.5546, -4.0021],
        [-0.9723, -1.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12281002104282379
Epoch 0, Step 685: train/loss = 0.44098782539367676, train/raw-loss = 0.3877871632575989, train/logprobs = tensor([[-0.4991, -3.3049],
        [-0.9037, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13300171494483948
Epoch 0, Step 686: train/loss = 0.5178905725479126, train/raw-loss = 0.4485555589199066, train/logprobs = tensor([[-1.2187, -2.6998],
        [-1.3264, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17333751916885376
Epoch 0, Step 687: train/loss = 0.45591938495635986, train/raw-loss = 0.41148972511291504, train/logprobs = tensor([[-0.8251, -3.0302],
        [-1.0126, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1110740527510643
Epoch 0, Step 688: train/loss = 0.25611022114753723, train/raw-loss = 0.19553403556346893, train/logprobs = tensor([[-0.5099, -5.5659],
        [-1.1803, -0.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15144047141075134
Epoch 0, Step 689: train/loss = 0.36796635389328003, train/raw-loss = 0.31713977456092834, train/logprobs = tensor([[-0.5565, -4.7187],
        [-1.1739, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270664930343628
Epoch 0, Step 690: train/loss = 0.486990362405777, train/raw-loss = 0.4466778039932251, train/logprobs = tensor([[-0.3315, -3.2448],
        [-0.5585, -0.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078142583370209
Epoch 0, Step 691: train/loss = 0.3447427451610565, train/raw-loss = 0.2838190793991089, train/logprobs = tensor([[-0.7430, -4.8097],
        [-1.7863, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15230923891067505
Epoch 0, Step 692: train/loss = 0.40656736493110657, train/raw-loss = 0.35407042503356934, train/logprobs = tensor([[-0.4764, -2.7110],
        [-0.8899, -0.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13124242424964905
Epoch 0, Step 693: train/loss = 0.43654510378837585, train/raw-loss = 0.38733047246932983, train/logprobs = tensor([[-0.5900, -2.7044],
        [-0.9138, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12303652614355087
Epoch 0, Step 694: train/loss = 0.35899072885513306, train/raw-loss = 0.308640718460083, train/logprobs = tensor([[-0.6779, -5.0022],
        [-1.0177, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12587498128414154
Epoch 0, Step 695: train/loss = 0.5714337825775146, train/raw-loss = 0.5157878994941711, train/logprobs = tensor([[-0.6086, -1.6322],
        [-1.1166, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13911478221416473
Epoch 0, Step 696: train/loss = 0.44258129596710205, train/raw-loss = 0.3841886818408966, train/logprobs = tensor([[-0.5695, -3.4677],
        [-1.4019, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.145981565117836
Epoch 0, Step 697: train/loss = 0.4440308213233948, train/raw-loss = 0.39037978649139404, train/logprobs = tensor([[-0.3900, -2.0880],
        [-0.7932, -0.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13412749767303467
Epoch 0, Step 698: train/loss = 0.4674113690853119, train/raw-loss = 0.4135618805885315, train/logprobs = tensor([[-0.6191, -2.8739],
        [-1.2405, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13462378084659576
Epoch 0, Step 699: train/loss = 0.2907666563987732, train/raw-loss = 0.23354370892047882, train/logprobs = tensor([[-0.7783, -5.4456],
        [-1.6676, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14305740594863892
Epoch 0, Step 700: train/loss = 0.4313727617263794, train/raw-loss = 0.37577784061431885, train/logprobs = tensor([[-0.8793, -5.7321],
        [-1.0657, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13898736238479614
Epoch 0, Step 701: train/loss = 0.3784206509590149, train/raw-loss = 0.3201461434364319, train/logprobs = tensor([[-0.6957, -4.4817],
        [-1.0194, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456862837076187
Epoch 0, Step 702: train/loss = 0.47572511434555054, train/raw-loss = 0.42905768752098083, train/logprobs = tensor([[-0.5162, -1.9471],
        [-0.9218, -0.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11666858196258545
Epoch 0, Step 703: train/loss = 0.562965989112854, train/raw-loss = 0.5083776116371155, train/logprobs = tensor([[-0.6505, -2.1364],
        [-1.0513, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13647091388702393
Epoch 0, Step 704: train/loss = 0.3045503497123718, train/raw-loss = 0.2468375861644745, train/logprobs = tensor([[-1.0383, -7.6926],
        [-1.7976, -1.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14428186416625977
Epoch 0, Step 705: train/loss = 0.2703929543495178, train/raw-loss = 0.20625145733356476, train/logprobs = tensor([[-0.9312, -5.0964],
        [-1.5828, -1.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16035369038581848
Epoch 0, Step 706: train/loss = 0.4808480441570282, train/raw-loss = 0.44139254093170166, train/logprobs = tensor([[-0.4543, -3.3965],
        [-0.6621, -0.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09863875806331635
Epoch 0, Step 707: train/loss = 0.41456466913223267, train/raw-loss = 0.3579256534576416, train/logprobs = tensor([[-0.6518, -3.5513],
        [-1.0912, -0.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14159750938415527
Epoch 0, Step 708: train/loss = 0.4563200771808624, train/raw-loss = 0.40817421674728394, train/logprobs = tensor([[-0.5233, -3.4908],
        [-0.8636, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1203647255897522
Epoch 0, Step 709: train/loss = 0.19571346044540405, train/raw-loss = 0.13448746502399445, train/logprobs = tensor([[-0.7296, -6.8740],
        [-1.9293, -1.5706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15306496620178223
Epoch 0, Step 710: train/loss = 0.33528730273246765, train/raw-loss = 0.2779102921485901, train/logprobs = tensor([[-0.7316, -4.0900],
        [-1.3702, -0.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14344239234924316
Epoch 0, Step 711: train/loss = 0.4961817264556885, train/raw-loss = 0.44590508937835693, train/logprobs = tensor([[-0.4706, -2.4080],
        [-0.9615, -0.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12569160759449005
Epoch 0, Step 712: train/loss = 0.4374830722808838, train/raw-loss = 0.38656264543533325, train/logprobs = tensor([[-0.7084, -3.5762],
        [-1.2689, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12730102241039276
Epoch 0, Step 713: train/loss = 0.3805371820926666, train/raw-loss = 0.32538729906082153, train/logprobs = tensor([[-0.8247, -5.2755],
        [-1.2160, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378747522830963
Epoch 0, Step 714: train/loss = 0.5059895515441895, train/raw-loss = 0.4576529562473297, train/logprobs = tensor([[-0.7872, -4.4796],
        [-0.9843, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12084145098924637
Epoch 0, Step 715: train/loss = 0.3269578814506531, train/raw-loss = 0.2758725583553314, train/logprobs = tensor([[-0.6304, -6.0858],
        [-0.9299, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12771330773830414
Epoch 0, Step 716: train/loss = 0.5581502914428711, train/raw-loss = 0.5025746822357178, train/logprobs = tensor([[-0.6436, -1.6209],
        [-1.0436, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13893909752368927
Epoch 0, Step 717: train/loss = 0.46258777379989624, train/raw-loss = 0.4123501777648926, train/logprobs = tensor([[-0.6465, -3.4785],
        [-1.3833, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12559400498867035
Epoch 0, Step 718: train/loss = 0.5314633846282959, train/raw-loss = 0.47806450724601746, train/logprobs = tensor([[-1.1516, -3.0926],
        [-1.2724, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13349707424640656
Epoch 0, Step 719: train/loss = 0.487835168838501, train/raw-loss = 0.43867090344429016, train/logprobs = tensor([[-0.4523, -2.0537],
        [-0.7647, -0.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12291070818901062
Epoch 0, Step 720: train/loss = 0.38223880529403687, train/raw-loss = 0.32009899616241455, train/logprobs = tensor([[-0.6892, -3.4957],
        [-1.2832, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15534959733486176
Epoch 0, Step 721: train/loss = 0.45122262835502625, train/raw-loss = 0.38277560472488403, train/logprobs = tensor([[-0.8331, -3.1021],
        [-1.0678, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111743986606598
Epoch 0, Step 722: train/loss = 0.7201798558235168, train/raw-loss = 0.672809362411499, train/logprobs = tensor([[-0.5706, -0.6641],
        [-0.6969, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11842644214630127
Epoch 0, Step 723: train/loss = 0.37710636854171753, train/raw-loss = 0.3005616366863251, train/logprobs = tensor([[-0.9139, -3.5961],
        [-1.3838, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19136178493499756
Epoch 0, Step 724: train/loss = 0.34390348196029663, train/raw-loss = 0.2956359386444092, train/logprobs = tensor([[-0.5516, -5.5810],
        [-1.1148, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12066894769668579
Epoch 0, Step 725: train/loss = 0.589001476764679, train/raw-loss = 0.5390822291374207, train/logprobs = tensor([[-1.0596, -2.9422],
        [-0.8472, -0.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12479817867279053
Epoch 0, Step 726: train/loss = 0.31041577458381653, train/raw-loss = 0.2604557275772095, train/logprobs = tensor([[-0.4324, -6.0967],
        [-0.8359, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1249002069234848
Epoch 0, Step 727: train/loss = 0.5532324314117432, train/raw-loss = 0.5021488666534424, train/logprobs = tensor([[-1.1074, -4.0070],
        [-0.8655, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12770909070968628
Epoch 0, Step 728: train/loss = 0.24822570383548737, train/raw-loss = 0.1900542974472046, train/logprobs = tensor([[-0.7353, -8.5595],
        [-1.6280, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14542847871780396
Epoch 0, Step 729: train/loss = 0.6018321514129639, train/raw-loss = 0.5440632104873657, train/logprobs = tensor([[-1.3265, -2.5088],
        [-1.2872, -1.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14442239701747894
Epoch 0, Step 730: train/loss = 0.5084286332130432, train/raw-loss = 0.4655827283859253, train/logprobs = tensor([[-0.3495, -1.9625],
        [-0.5916, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10711485147476196
Epoch 0, Step 731: train/loss = 0.5104645490646362, train/raw-loss = 0.45912688970565796, train/logprobs = tensor([[-0.6000, -2.4439],
        [-0.8354, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12834402918815613
Epoch 0, Step 732: train/loss = 0.4799882769584656, train/raw-loss = 0.4193325936794281, train/logprobs = tensor([[-0.5713, -2.7285],
        [-0.9998, -1.3757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15163925290107727
Epoch 0, Step 733: train/loss = 0.47121065855026245, train/raw-loss = 0.4259205758571625, train/logprobs = tensor([[-0.5626, -3.7641],
        [-0.8627, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322524398565292
Epoch 0, Step 734: train/loss = 0.48751404881477356, train/raw-loss = 0.4302828013896942, train/logprobs = tensor([[-0.8183, -2.4884],
        [-1.1847, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14307813346385956
Epoch 0, Step 735: train/loss = 0.6917405128479004, train/raw-loss = 0.6426703929901123, train/logprobs = tensor([[-0.8330, -1.2178],
        [-0.7640, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267518043518066
Epoch 0, Step 736: train/loss = 0.65140700340271, train/raw-loss = 0.6132439374923706, train/logprobs = tensor([[-0.3591, -1.0045],
        [-0.5957, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09540766477584839
Epoch 0, Step 737: train/loss = 0.30579888820648193, train/raw-loss = 0.23998871445655823, train/logprobs = tensor([[-0.7110, -3.4460],
        [-1.6846, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16452541947364807
Epoch 0, Step 738: train/loss = 0.5838326215744019, train/raw-loss = 0.529672384262085, train/logprobs = tensor([[-0.6651, -1.9164],
        [-1.3416, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13540062308311462
Epoch 0, Step 739: train/loss = 0.3513258695602417, train/raw-loss = 0.2980433404445648, train/logprobs = tensor([[-1.1291, -3.5508],
        [-2.0514, -1.3323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13320642709732056
Epoch 0, Step 740: train/loss = 0.24525044858455658, train/raw-loss = 0.18916723132133484, train/logprobs = tensor([[-0.7050, -4.8491],
        [-1.4560, -0.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14020806550979614
Epoch 0, Step 741: train/loss = 0.2641376852989197, train/raw-loss = 0.19131219387054443, train/logprobs = tensor([[-0.7821, -7.1115],
        [-1.6202, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18206371366977692
Epoch 0, Step 742: train/loss = 0.4678107798099518, train/raw-loss = 0.41705554723739624, train/logprobs = tensor([[-0.4787, -2.7466],
        [-0.8911, -0.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12688808143138885
Epoch 0, Step 743: train/loss = 0.3295561373233795, train/raw-loss = 0.27682799100875854, train/logprobs = tensor([[-0.9412, -7.0020],
        [-1.5503, -1.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13182038068771362
Epoch 0, Step 744: train/loss = 0.6133589744567871, train/raw-loss = 0.5668470859527588, train/logprobs = tensor([[-0.5595, -0.9537],
        [-0.7816, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11627976596355438
Epoch 0, Step 745: train/loss = 0.41265517473220825, train/raw-loss = 0.3625859022140503, train/logprobs = tensor([[-0.4115, -2.9192],
        [-0.7307, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517321109771729
Epoch 0, Step 746: train/loss = 0.6753268241882324, train/raw-loss = 0.6223126649856567, train/logprobs = tensor([[-0.6241, -0.7027],
        [-0.8669, -0.6395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325354278087616
Epoch 0, Step 747: train/loss = 0.4741268455982208, train/raw-loss = 0.4295074939727783, train/logprobs = tensor([[-0.5388, -2.2401],
        [-0.7542, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11154840141534805
Epoch 0, Step 748: train/loss = 0.577464759349823, train/raw-loss = 0.5283962488174438, train/logprobs = tensor([[-0.4395, -1.2042],
        [-0.9591, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267127633094788
Epoch 0, Step 749: train/loss = 0.47953763604164124, train/raw-loss = 0.4256443977355957, train/logprobs = tensor([[-0.8340, -3.8404],
        [-1.2578, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13473312556743622
Epoch 0, Step 750: train/loss = 0.44419512152671814, train/raw-loss = 0.39178842306137085, train/logprobs = tensor([[-0.9059, -4.7851],
        [-1.8377, -1.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13101685047149658
Epoch 0, Step 751: train/loss = 0.5701202750205994, train/raw-loss = 0.519071638584137, train/logprobs = tensor([[-0.6399, -3.1749],
        [-0.7821, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12762171030044556
Epoch 0, Step 752: train/loss = 0.5277643799781799, train/raw-loss = 0.47699636220932007, train/logprobs = tensor([[-0.4677, -3.1282],
        [-0.8763, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12691999971866608
Epoch 0, Step 753: train/loss = 0.3774278461933136, train/raw-loss = 0.3222411870956421, train/logprobs = tensor([[-0.5364, -2.9434],
        [-0.8734, -0.6147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379666030406952
Epoch 0, Step 754: train/loss = 0.4072539210319519, train/raw-loss = 0.35175952315330505, train/logprobs = tensor([[-0.6985, -2.8233],
        [-1.1717, -0.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13873602449893951
Epoch 0, Step 755: train/loss = 0.35243260860443115, train/raw-loss = 0.28889238834381104, train/logprobs = tensor([[-0.8008, -6.0722],
        [-1.5831, -1.4430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588505357503891
Epoch 0, Step 756: train/loss = 0.43597498536109924, train/raw-loss = 0.38162824511528015, train/logprobs = tensor([[-0.9004, -4.4193],
        [-1.3577, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13586682081222534
Epoch 0, Step 757: train/loss = 0.5332244634628296, train/raw-loss = 0.4731425642967224, train/logprobs = tensor([[-0.5560, -3.9186],
        [-0.9513, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15020468831062317
Epoch 0, Step 758: train/loss = 0.34926837682724, train/raw-loss = 0.2961009442806244, train/logprobs = tensor([[-0.5163, -5.1237],
        [-1.1052, -1.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13291862607002258
Epoch 0, Step 759: train/loss = 0.44182288646698, train/raw-loss = 0.388418972492218, train/logprobs = tensor([[-0.6514, -3.9409],
        [-0.9517, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335098147392273
Epoch 0, Step 760: train/loss = 0.5231329202651978, train/raw-loss = 0.4724847674369812, train/logprobs = tensor([[-1.0965, -3.3890],
        [-1.2432, -0.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12662041187286377
Epoch 0, Step 761: train/loss = 0.6673620343208313, train/raw-loss = 0.6154522895812988, train/logprobs = tensor([[-1.2776, -1.3286],
        [-1.4599, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12977443635463715
Epoch 0, Step 762: train/loss = 0.47474080324172974, train/raw-loss = 0.415357381105423, train/logprobs = tensor([[-0.5194, -2.8313],
        [-1.0969, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484585404396057
Epoch 0, Step 763: train/loss = 0.4043063819408417, train/raw-loss = 0.3382083773612976, train/logprobs = tensor([[-0.7901, -2.7054],
        [-1.3412, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1652449667453766
Epoch 0, Step 764: train/loss = 0.5347968339920044, train/raw-loss = 0.48618558049201965, train/logprobs = tensor([[-0.6303, -1.5246],
        [-1.0264, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12152808904647827
Epoch 0, Step 765: train/loss = 0.41966915130615234, train/raw-loss = 0.37126821279525757, train/logprobs = tensor([[-0.6915, -5.1028],
        [-1.2804, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12100236117839813
Epoch 0, Step 766: train/loss = 0.3229987323284149, train/raw-loss = 0.25741052627563477, train/logprobs = tensor([[-0.7565, -3.5554],
        [-1.3211, -1.1969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16397051513195038
Epoch 0, Step 767: train/loss = 0.5632386207580566, train/raw-loss = 0.5032532215118408, train/logprobs = tensor([[-0.5909, -1.8034],
        [-0.8774, -0.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1499634087085724
Epoch 0, Step 768: train/loss = 0.655433714389801, train/raw-loss = 0.6133580207824707, train/logprobs = tensor([[-0.4807, -0.8408],
        [-0.6604, -0.6721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1051892340183258
Epoch 0, Step 769: train/loss = 0.4177223742008209, train/raw-loss = 0.3637753129005432, train/logprobs = tensor([[-0.8139, -2.9919],
        [-1.0723, -0.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13486766815185547
Epoch 0, Step 770: train/loss = 0.47815001010894775, train/raw-loss = 0.4331662058830261, train/logprobs = tensor([[-0.4434, -1.9901],
        [-0.6806, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124594658613205
Epoch 0, Step 771: train/loss = 0.321077436208725, train/raw-loss = 0.271336168050766, train/logprobs = tensor([[-0.5955, -4.7530],
        [-0.8839, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12435314804315567
Epoch 0, Step 772: train/loss = 0.33382707834243774, train/raw-loss = 0.2762657701969147, train/logprobs = tensor([[-0.9505, -3.7259],
        [-1.2779, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14390330016613007
Epoch 0, Step 773: train/loss = 0.4398542642593384, train/raw-loss = 0.388203501701355, train/logprobs = tensor([[-0.9100, -3.7325],
        [-1.0462, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12912696599960327
Epoch 0, Step 774: train/loss = 0.4915781617164612, train/raw-loss = 0.44142618775367737, train/logprobs = tensor([[-1.0805, -2.5273],
        [-1.1767, -0.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12537994980812073
Epoch 0, Step 775: train/loss = 0.763818621635437, train/raw-loss = 0.7086774706840515, train/logprobs = tensor([[-2.7077, -7.9580],
        [-1.3347, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13785287737846375
Epoch 0, Step 776: train/loss = 0.3339950442314148, train/raw-loss = 0.288230299949646, train/logprobs = tensor([[-0.6802, -5.2347],
        [-1.1760, -1.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11441183090209961
Epoch 0, Step 777: train/loss = 0.4960228204727173, train/raw-loss = 0.4515923857688904, train/logprobs = tensor([[-0.4868, -2.3095],
        [-0.8903, -0.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11107612401247025
Epoch 0, Step 778: train/loss = 0.39582347869873047, train/raw-loss = 0.33944863080978394, train/logprobs = tensor([[-0.6429, -3.6781],
        [-1.0016, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14093713462352753
Epoch 0, Step 779: train/loss = 0.49873918294906616, train/raw-loss = 0.44795775413513184, train/logprobs = tensor([[-0.7308, -3.8436],
        [-0.7733, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12695354223251343
Epoch 0, Step 780: train/loss = 0.5873712301254272, train/raw-loss = 0.5436573028564453, train/logprobs = tensor([[-0.5552, -1.8400],
        [-0.5842, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10928484052419662
Epoch 0, Step 781: train/loss = 0.4979035556316376, train/raw-loss = 0.44585826992988586, train/logprobs = tensor([[-0.8052, -2.4144],
        [-1.2165, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13011322915554047
Epoch 0, Step 782: train/loss = 0.39079636335372925, train/raw-loss = 0.32227838039398193, train/logprobs = tensor([[-1.4218, -6.8871],
        [-1.4102, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129498720169067
Epoch 0, Step 783: train/loss = 0.32476747035980225, train/raw-loss = 0.26719990372657776, train/logprobs = tensor([[-0.6135, -4.0889],
        [-0.9956, -0.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1439189314842224
Epoch 0, Step 784: train/loss = 0.2728661298751831, train/raw-loss = 0.2189369797706604, train/logprobs = tensor([[-0.7319, -9.9053],
        [-1.2413, -1.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13482284545898438
Epoch 0, Step 785: train/loss = 0.516120195388794, train/raw-loss = 0.47889283299446106, train/logprobs = tensor([[-0.3379, -2.6316],
        [-0.4743, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09306839853525162
Epoch 0, Step 786: train/loss = 0.3132516145706177, train/raw-loss = 0.26133713126182556, train/logprobs = tensor([[-0.5593, -6.2693],
        [-0.8157, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12978608906269073
Epoch 0, Step 787: train/loss = 0.5085967779159546, train/raw-loss = 0.4545937776565552, train/logprobs = tensor([[-0.6268, -2.3723],
        [-0.8852, -0.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13500748574733734
Epoch 0, Step 788: train/loss = 0.3918936550617218, train/raw-loss = 0.33133751153945923, train/logprobs = tensor([[-0.6108, -6.7203],
        [-0.9932, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15139031410217285
Epoch 0, Step 789: train/loss = 0.6144499778747559, train/raw-loss = 0.5696332454681396, train/logprobs = tensor([[-0.7507, -1.5888],
        [-0.7070, -0.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11204177886247635
Epoch 0, Step 790: train/loss = 0.5160719752311707, train/raw-loss = 0.45976048707962036, train/logprobs = tensor([[-0.6188, -2.5028],
        [-0.7614, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14077872037887573
Epoch 0, Step 791: train/loss = 0.5758457183837891, train/raw-loss = 0.5269939303398132, train/logprobs = tensor([[-0.9109, -1.6709],
        [-1.0945, -0.6390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12212950736284256
Epoch 0, Step 792: train/loss = 0.4143226444721222, train/raw-loss = 0.3611501455307007, train/logprobs = tensor([[-0.6672, -3.2872],
        [-1.1716, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13293123245239258
Epoch 0, Step 793: train/loss = 0.4871824383735657, train/raw-loss = 0.4297606647014618, train/logprobs = tensor([[-0.7508, -6.2844],
        [-1.0499, -1.3627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14355437457561493
Epoch 0, Step 794: train/loss = 0.3398941159248352, train/raw-loss = 0.27627021074295044, train/logprobs = tensor([[-0.6810, -4.9684],
        [-1.1663, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15905976295471191
Epoch 0, Step 795: train/loss = 0.4076566994190216, train/raw-loss = 0.35817140340805054, train/logprobs = tensor([[-0.9215, -4.1934],
        [-1.0417, -1.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12371326237916946
Epoch 0, Step 796: train/loss = 0.3411293923854828, train/raw-loss = 0.28254973888397217, train/logprobs = tensor([[-0.7654, -6.4551],
        [-1.1632, -1.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14644913375377655
Epoch 0, Step 797: train/loss = 0.5057652592658997, train/raw-loss = 0.4613746404647827, train/logprobs = tensor([[-0.5237, -1.6854],
        [-0.7313, -0.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11097657680511475
Epoch 0, Step 798: train/loss = 0.47666555643081665, train/raw-loss = 0.43027204275131226, train/logprobs = tensor([[-0.7171, -5.0437],
        [-0.7881, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.115983746945858
Epoch 0, Step 799: train/loss = 0.4974813163280487, train/raw-loss = 0.4385416507720947, train/logprobs = tensor([[-1.1561, -5.7590],
        [-1.3547, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14734920859336853
Epoch 0, Step 800: train/loss = 0.6645205020904541, train/raw-loss = 0.6164056658744812, train/logprobs = tensor([[-1.1757, -1.8477],
        [-1.0037, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1202869862318039
Epoch 0, Step 801: train/loss = 0.2591460645198822, train/raw-loss = 0.19616657495498657, train/logprobs = tensor([[-0.9703, -7.1156],
        [-1.6025, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1574486643075943
Epoch 0, Step 802: train/loss = 0.4766996502876282, train/raw-loss = 0.43524497747421265, train/logprobs = tensor([[-0.7477, -2.3740],
        [-0.8940, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10363677144050598
Epoch 0, Step 803: train/loss = 0.38693967461586, train/raw-loss = 0.3407391607761383, train/logprobs = tensor([[-0.6822, -4.2855],
        [-0.9911, -1.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11550137400627136
Epoch 0, Step 804: train/loss = 0.5161421298980713, train/raw-loss = 0.4600924849510193, train/logprobs = tensor([[-0.7356, -3.3826],
        [-1.0537, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1401241421699524
Epoch 0, Step 805: train/loss = 0.501797080039978, train/raw-loss = 0.45561856031417847, train/logprobs = tensor([[-0.5075, -2.3726],
        [-0.7541, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11544638872146606
Epoch 0, Step 806: train/loss = 0.4141979217529297, train/raw-loss = 0.35653212666511536, train/logprobs = tensor([[-0.8730, -5.3361],
        [-1.1595, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14416442811489105
Epoch 0, Step 807: train/loss = 0.35405224561691284, train/raw-loss = 0.2983275055885315, train/logprobs = tensor([[-0.7659, -6.7508],
        [-1.0379, -1.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393118053674698
Epoch 0, Step 808: train/loss = 0.35689833760261536, train/raw-loss = 0.30837759375572205, train/logprobs = tensor([[-0.5789, -3.8972],
        [-0.9816, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12130183726549149
Epoch 0, Step 809: train/loss = 0.3739846348762512, train/raw-loss = 0.3196983337402344, train/logprobs = tensor([[-0.6395, -5.9297],
        [-1.0207, -0.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357157677412033
Epoch 0, Step 810: train/loss = 0.3330141603946686, train/raw-loss = 0.2742369771003723, train/logprobs = tensor([[-0.6170, -4.8090],
        [-1.0308, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14694297313690186
Epoch 0, Step 811: train/loss = 0.49040475487709045, train/raw-loss = 0.4381723999977112, train/logprobs = tensor([[-0.6565, -3.5453],
        [-0.8041, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13058091700077057
Epoch 0, Step 812: train/loss = 0.5684064030647278, train/raw-loss = 0.5212957859039307, train/logprobs = tensor([[-0.7445, -2.3118],
        [-0.9906, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11777645349502563
Epoch 0, Step 813: train/loss = 0.5391411781311035, train/raw-loss = 0.4896172881126404, train/logprobs = tensor([[-0.8059, -1.8380],
        [-0.7800, -0.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12380964308977127
Epoch 0, Step 814: train/loss = 0.27127328515052795, train/raw-loss = 0.2231893390417099, train/logprobs = tensor([[-0.7614, -5.3558],
        [-1.8352, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12020985037088394
Epoch 0, Step 815: train/loss = 0.4737805128097534, train/raw-loss = 0.4202326536178589, train/logprobs = tensor([[-0.7595, -2.6786],
        [-0.8070, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386957347393036
Epoch 0, Step 816: train/loss = 0.3114354610443115, train/raw-loss = 0.26838722825050354, train/logprobs = tensor([[-0.4025, -7.2381],
        [-0.5741, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762062668800354
Epoch 0, Step 817: train/loss = 0.4222792983055115, train/raw-loss = 0.3661844730377197, train/logprobs = tensor([[-0.9497, -5.0063],
        [-1.2753, -1.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402370035648346
Epoch 0, Step 818: train/loss = 0.3258619010448456, train/raw-loss = 0.2735421061515808, train/logprobs = tensor([[-0.6374, -8.6244],
        [-1.0863, -2.1342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13079948723316193
Epoch 0, Step 819: train/loss = 0.3801610469818115, train/raw-loss = 0.33554473519325256, train/logprobs = tensor([[-0.3591, -4.4957],
        [-0.6957, -0.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1115407794713974
Epoch 0, Step 820: train/loss = 0.41961321234703064, train/raw-loss = 0.36262816190719604, train/logprobs = tensor([[-0.8846, -3.7118],
        [-1.0648, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14246264100074768
Epoch 0, Step 821: train/loss = 0.4405035376548767, train/raw-loss = 0.38616296648979187, train/logprobs = tensor([[-0.6744, -2.7071],
        [-1.1676, -0.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358514130115509
Epoch 0, Step 822: train/loss = 0.4927375912666321, train/raw-loss = 0.4468344449996948, train/logprobs = tensor([[-0.7168, -2.9572],
        [-0.8679, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11475780606269836
Epoch 0, Step 823: train/loss = 0.5181765556335449, train/raw-loss = 0.47240447998046875, train/logprobs = tensor([[-1.1410, -5.7330],
        [-0.8921, -2.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1144302487373352
Epoch 0, Step 824: train/loss = 0.3818207383155823, train/raw-loss = 0.32934728264808655, train/logprobs = tensor([[-0.5404, -5.3121],
        [-0.9538, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311836838722229
Epoch 0, Step 825: train/loss = 0.7067883014678955, train/raw-loss = 0.659669041633606, train/logprobs = tensor([[-0.9980, -0.5867],
        [-1.3012, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11779804527759552
Epoch 0, Step 826: train/loss = 0.431781142950058, train/raw-loss = 0.37554648518562317, train/logprobs = tensor([[-1.1406, -3.9880],
        [-1.2894, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14058668911457062
Epoch 0, Step 827: train/loss = 0.4487745761871338, train/raw-loss = 0.4035590887069702, train/logprobs = tensor([[-0.5029, -2.6944],
        [-0.6299, -0.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11303864419460297
Epoch 0, Step 828: train/loss = 0.3295063078403473, train/raw-loss = 0.26846301555633545, train/logprobs = tensor([[-0.7937, -3.5121],
        [-1.4938, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152608260512352
Epoch 0, Step 829: train/loss = 0.5528802275657654, train/raw-loss = 0.49801772832870483, train/logprobs = tensor([[-1.0917, -3.6720],
        [-1.0557, -1.2326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13715626299381256
Epoch 0, Step 830: train/loss = 0.395554780960083, train/raw-loss = 0.35161980986595154, train/logprobs = tensor([[-0.4104, -5.6213],
        [-0.6240, -1.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983747988939285
Epoch 0, Step 831: train/loss = 0.37200474739074707, train/raw-loss = 0.3299148678779602, train/logprobs = tensor([[-0.5269, -2.4454],
        [-0.9528, -0.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522472858428955
Epoch 0, Step 832: train/loss = 0.4132060110569, train/raw-loss = 0.3606301546096802, train/logprobs = tensor([[-0.7051, -2.8673],
        [-1.3028, -0.4269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314397156238556
Epoch 0, Step 833: train/loss = 0.6338980197906494, train/raw-loss = 0.5837692022323608, train/logprobs = tensor([[-0.7486, -1.1967],
        [-0.7602, -0.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12532195448875427
Epoch 0, Step 834: train/loss = 0.36857789754867554, train/raw-loss = 0.31268441677093506, train/logprobs = tensor([[-1.0300, -6.1983],
        [-1.3798, -1.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13973362743854523
Epoch 0, Step 835: train/loss = 0.6201175451278687, train/raw-loss = 0.579910159111023, train/logprobs = tensor([[-0.9071, -3.9452],
        [-0.9398, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10051846504211426
Epoch 0, Step 836: train/loss = 0.45429563522338867, train/raw-loss = 0.39875951409339905, train/logprobs = tensor([[-0.7176, -5.1264],
        [-1.0021, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13884036242961884
Epoch 0, Step 837: train/loss = 0.409039705991745, train/raw-loss = 0.35891634225845337, train/logprobs = tensor([[-0.4787, -2.9006],
        [-0.7317, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12530845403671265
Epoch 0, Step 838: train/loss = 0.4244508147239685, train/raw-loss = 0.37160009145736694, train/logprobs = tensor([[-0.7718, -3.6894],
        [-0.9620, -0.6442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321268379688263
Epoch 0, Step 839: train/loss = 0.3470892906188965, train/raw-loss = 0.29978859424591064, train/logprobs = tensor([[-0.6185, -4.9442],
        [-1.0304, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11825177073478699
Epoch 0, Step 840: train/loss = 0.3692511320114136, train/raw-loss = 0.3070632815361023, train/logprobs = tensor([[-0.6673, -6.4336],
        [-1.2530, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155469611287117
Epoch 0, Step 841: train/loss = 0.5479037165641785, train/raw-loss = 0.494201123714447, train/logprobs = tensor([[-0.6321, -2.3001],
        [-0.9092, -0.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13425646722316742
Epoch 0, Step 842: train/loss = 0.3948870003223419, train/raw-loss = 0.3404941260814667, train/logprobs = tensor([[-0.5138, -5.6454],
        [-1.2237, -1.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13598226010799408
Epoch 0, Step 843: train/loss = 0.4223062992095947, train/raw-loss = 0.3656282424926758, train/logprobs = tensor([[-1.0487, -4.4507],
        [-0.9661, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14169520139694214
Epoch 0, Step 844: train/loss = 0.47038739919662476, train/raw-loss = 0.4134162366390228, train/logprobs = tensor([[-1.3344, -5.6170],
        [-1.1254, -1.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14242787659168243
Epoch 0, Step 845: train/loss = 0.36768031120300293, train/raw-loss = 0.3097394108772278, train/logprobs = tensor([[-0.7582, -6.8812],
        [-1.2688, -1.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14485220611095428
Epoch 0, Step 846: train/loss = 0.3460402488708496, train/raw-loss = 0.30125072598457336, train/logprobs = tensor([[-0.5278, -8.4772],
        [-0.8659, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119738221168518
Epoch 0, Step 847: train/loss = 0.44539010524749756, train/raw-loss = 0.3944849371910095, train/logprobs = tensor([[-0.8785, -4.0807],
        [-1.1021, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272629052400589
Epoch 0, Step 848: train/loss = 0.29935503005981445, train/raw-loss = 0.2347744107246399, train/logprobs = tensor([[-0.8605, -5.1214],
        [-1.5690, -0.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16145150363445282
Epoch 0, Step 849: train/loss = 0.3110845983028412, train/raw-loss = 0.2556343972682953, train/logprobs = tensor([[-1.3229, -8.1429],
        [-1.5683, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13862547278404236
Epoch 0, Step 850: train/loss = 0.44137829542160034, train/raw-loss = 0.3899111747741699, train/logprobs = tensor([[-0.5927, -3.9475],
        [-0.8239, -1.0956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12866777181625366
Epoch 0, Step 851: train/loss = 0.36934053897857666, train/raw-loss = 0.31235453486442566, train/logprobs = tensor([[-0.9378, -6.2358],
        [-1.4767, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424650251865387
Epoch 0, Step 852: train/loss = 0.4009017050266266, train/raw-loss = 0.35319000482559204, train/logprobs = tensor([[-0.5021, -4.1614],
        [-0.9894, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11927928030490875
Epoch 0, Step 853: train/loss = 0.5727241039276123, train/raw-loss = 0.5257136821746826, train/logprobs = tensor([[-1.1305, -3.7540],
        [-1.3538, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11752593517303467
Epoch 0, Step 854: train/loss = 0.394521027803421, train/raw-loss = 0.3387558162212372, train/logprobs = tensor([[-0.7878, -5.3859],
        [-1.1599, -0.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1394130289554596
Epoch 0, Step 855: train/loss = 0.41722238063812256, train/raw-loss = 0.3660566806793213, train/logprobs = tensor([[-0.8045, -4.8642],
        [-1.2069, -1.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12791424989700317
Epoch 0, Step 856: train/loss = 0.3092404305934906, train/raw-loss = 0.2525344491004944, train/logprobs = tensor([[-0.7598, -4.2147],
        [-1.4252, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14176489412784576
Epoch 0, Step 857: train/loss = 0.380726158618927, train/raw-loss = 0.31980186700820923, train/logprobs = tensor([[-0.6589, -6.3090],
        [-1.2263, -0.8595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15231066942214966
Epoch 0, Step 858: train/loss = 0.5997987985610962, train/raw-loss = 0.5382944941520691, train/logprobs = tensor([[-1.8198, -3.0735],
        [-1.3327, -0.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15376071631908417
Epoch 0, Step 859: train/loss = 0.38348716497421265, train/raw-loss = 0.33771711587905884, train/logprobs = tensor([[-0.7661, -3.4904],
        [-1.2588, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11442513763904572
Epoch 0, Step 860: train/loss = 0.4577042758464813, train/raw-loss = 0.4057666063308716, train/logprobs = tensor([[-0.8154, -3.8948],
        [-0.9865, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1298442929983139
Epoch 0, Step 861: train/loss = 0.5898609757423401, train/raw-loss = 0.5344639420509338, train/logprobs = tensor([[-0.9342, -3.7421],
        [-0.8409, -0.9919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1384926587343216
Epoch 0, Step 862: train/loss = 0.3763557970523834, train/raw-loss = 0.3153437376022339, train/logprobs = tensor([[-0.7652, -6.1498],
        [-1.0103, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15253011882305145
Epoch 0, Step 863: train/loss = 0.582741379737854, train/raw-loss = 0.5253850221633911, train/logprobs = tensor([[-1.0954, -3.9688],
        [-0.9901, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14339089393615723
Epoch 0, Step 864: train/loss = 0.6792794466018677, train/raw-loss = 0.6270220279693604, train/logprobs = tensor([[-1.2716, -2.2285],
        [-0.9791, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13064351677894592
Epoch 0, Step 865: train/loss = 0.3823201656341553, train/raw-loss = 0.3267265558242798, train/logprobs = tensor([[-0.7745, -3.0966],
        [-1.1973, -0.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13898411393165588
Epoch 0, Step 866: train/loss = 0.35110074281692505, train/raw-loss = 0.3002036213874817, train/logprobs = tensor([[-0.6753, -5.8060],
        [-0.8209, -1.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12724275887012482
Epoch 0, Step 867: train/loss = 0.5725979208946228, train/raw-loss = 0.5225777626037598, train/logprobs = tensor([[-0.7042, -2.5731],
        [-1.0646, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12505032122135162
Epoch 0, Step 868: train/loss = 0.5145179033279419, train/raw-loss = 0.4486682713031769, train/logprobs = tensor([[-0.9082, -1.7967],
        [-1.2795, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16462400555610657
Epoch 0, Step 869: train/loss = 0.4074469804763794, train/raw-loss = 0.3508719205856323, train/logprobs = tensor([[-0.8280, -1.9287],
        [-1.6029, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14143764972686768
Epoch 0, Step 870: train/loss = 0.42135244607925415, train/raw-loss = 0.372856080532074, train/logprobs = tensor([[-0.8742, -6.0516],
        [-1.2874, -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12124092876911163
Epoch 0, Step 871: train/loss = 0.3679405450820923, train/raw-loss = 0.3141682744026184, train/logprobs = tensor([[-0.5279, -5.2918],
        [-0.8966, -1.1787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13443061709403992
Epoch 0, Step 872: train/loss = 0.49696478247642517, train/raw-loss = 0.4557907283306122, train/logprobs = tensor([[-0.3855, -3.2302],
        [-0.5072, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293520987033844
Epoch 0, Step 873: train/loss = 0.44504114985466003, train/raw-loss = 0.39768338203430176, train/logprobs = tensor([[-0.8747, -3.8650],
        [-1.0664, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1183943971991539
Epoch 0, Step 874: train/loss = 0.34363025426864624, train/raw-loss = 0.2727077603340149, train/logprobs = tensor([[-1.0991, -6.3156],
        [-1.6764, -0.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1773061454296112
Epoch 0, Step 875: train/loss = 0.6283131241798401, train/raw-loss = 0.5812287926673889, train/logprobs = tensor([[-0.8339, -1.1240],
        [-1.0557, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11771093308925629
Epoch 0, Step 876: train/loss = 0.4132653474807739, train/raw-loss = 0.3737739026546478, train/logprobs = tensor([[-0.3866, -6.6047],
        [-0.6715, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09872862696647644
Epoch 0, Step 877: train/loss = 0.4710187017917633, train/raw-loss = 0.4068894684314728, train/logprobs = tensor([[-1.3294, -5.2114],
        [-1.7511, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603231132030487
Epoch 0, Step 878: train/loss = 1.0403708219528198, train/raw-loss = 0.9834314584732056, train/logprobs = tensor([[-2.8814, -4.8928],
        [-1.2643, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14234834909439087
Epoch 0, Step 879: train/loss = 0.3306421935558319, train/raw-loss = 0.27815762162208557, train/logprobs = tensor([[-0.4831, -7.9777],
        [-0.9779, -1.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13121145963668823
Epoch 0, Step 880: train/loss = 0.3708014190196991, train/raw-loss = 0.32116973400115967, train/logprobs = tensor([[-0.6220, -4.7245],
        [-0.9158, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407927215099335
Epoch 0, Step 881: train/loss = 0.5069394111633301, train/raw-loss = 0.4579711854457855, train/logprobs = tensor([[-0.5603, -4.0389],
        [-0.7571, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122420534491539
Epoch 0, Step 882: train/loss = 0.587550163269043, train/raw-loss = 0.5358358025550842, train/logprobs = tensor([[-0.8283, -1.9975],
        [-0.7399, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12928591668605804
Epoch 0, Step 883: train/loss = 0.37817156314849854, train/raw-loss = 0.31669825315475464, train/logprobs = tensor([[-1.0926, -3.5211],
        [-1.7825, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15368331968784332
Epoch 0, Step 884: train/loss = 0.3827154040336609, train/raw-loss = 0.326770544052124, train/logprobs = tensor([[-0.6526, -4.4278],
        [-0.9531, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13986219465732574
Epoch 0, Step 885: train/loss = 0.36373370885849, train/raw-loss = 0.3033891022205353, train/logprobs = tensor([[-1.1106, -5.2827],
        [-1.1808, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15086154639720917
Epoch 0, Step 886: train/loss = 0.5293318033218384, train/raw-loss = 0.4790485203266144, train/logprobs = tensor([[-0.6645, -2.9506],
        [-0.9501, -0.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12570828199386597
Epoch 0, Step 887: train/loss = 0.47793900966644287, train/raw-loss = 0.42688676714897156, train/logprobs = tensor([[-0.6898, -4.3127],
        [-0.9469, -1.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12763050198554993
Epoch 0, Step 888: train/loss = 0.251715749502182, train/raw-loss = 0.1925271451473236, train/logprobs = tensor([[-0.6203, -6.0052],
        [-1.3123, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479714810848236
Epoch 0, Step 889: train/loss = 0.4331022799015045, train/raw-loss = 0.3766248822212219, train/logprobs = tensor([[-0.8326, -3.5441],
        [-1.1201, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411934792995453
Epoch 0, Step 890: train/loss = 0.3965320289134979, train/raw-loss = 0.3363931179046631, train/logprobs = tensor([[-0.7856, -3.3148],
        [-1.1460, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15034723281860352
Epoch 0, Step 891: train/loss = 0.3074856102466583, train/raw-loss = 0.25796666741371155, train/logprobs = tensor([[-0.7501, -5.6879],
        [-1.2557, -1.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12379737943410873
Epoch 0, Step 892: train/loss = 0.3873085379600525, train/raw-loss = 0.32858771085739136, train/logprobs = tensor([[-0.5934, -4.3643],
        [-1.0700, -0.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14680218696594238
Epoch 0, Step 893: train/loss = 0.47143757343292236, train/raw-loss = 0.421976238489151, train/logprobs = tensor([[-0.7504, -3.8905],
        [-0.9980, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12365342676639557
Epoch 0, Step 894: train/loss = 0.36677461862564087, train/raw-loss = 0.3071073293685913, train/logprobs = tensor([[-0.7054, -7.1442],
        [-1.0891, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491682082414627
Epoch 0, Step 895: train/loss = 0.4688403308391571, train/raw-loss = 0.41465243697166443, train/logprobs = tensor([[-0.6968, -6.5873],
        [-1.2057, -2.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354697346687317
Epoch 0, Step 896: train/loss = 0.5585143566131592, train/raw-loss = 0.5043885111808777, train/logprobs = tensor([[-0.9228, -2.3060],
        [-0.9989, -0.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13531458377838135
Epoch 0, Step 897: train/loss = 0.4843979477882385, train/raw-loss = 0.4200748801231384, train/logprobs = tensor([[-0.9097, -3.1994],
        [-1.2859, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16080769896507263
Epoch 0, Step 898: train/loss = 0.5340292453765869, train/raw-loss = 0.4863891303539276, train/logprobs = tensor([[-0.7286, -1.3683],
        [-1.0185, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11910030245780945
Epoch 0, Step 899: train/loss = 0.45425036549568176, train/raw-loss = 0.39301878213882446, train/logprobs = tensor([[-0.6056, -4.2633],
        [-0.9805, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15307894349098206
Epoch 0, Step 900: train/loss = 0.2969355881214142, train/raw-loss = 0.24251259863376617, train/logprobs = tensor([[-1.0712, -9.5924],
        [-1.4508, -1.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13605743646621704
Epoch 0, Step 901: train/loss = 0.3721544146537781, train/raw-loss = 0.32074129581451416, train/logprobs = tensor([[-0.3964, -4.2326],
        [-0.8634, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12853288650512695
Epoch 0, Step 902: train/loss = 0.2759682238101959, train/raw-loss = 0.22124913334846497, train/logprobs = tensor([[-0.6939, -7.2418],
        [-1.2785, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1367977410554886
Epoch 0, Step 903: train/loss = 0.3854901194572449, train/raw-loss = 0.3246140480041504, train/logprobs = tensor([[-0.9153, -3.7841],
        [-1.4303, -0.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15219010412693024
Epoch 0, Step 904: train/loss = 0.4696158170700073, train/raw-loss = 0.4199722707271576, train/logprobs = tensor([[-1.3296, -4.3225],
        [-1.3935, -1.4841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1241089254617691
Epoch 0, Step 905: train/loss = 0.32964301109313965, train/raw-loss = 0.2818109393119812, train/logprobs = tensor([[-0.5178, -6.8338],
        [-0.8666, -1.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1195802092552185
Epoch 0, Step 906: train/loss = 0.6360187530517578, train/raw-loss = 0.5935379862785339, train/logprobs = tensor([[-0.6525, -1.2218],
        [-0.5687, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10620191693305969
Epoch 0, Step 907: train/loss = 0.6126764416694641, train/raw-loss = 0.5645700693130493, train/logprobs = tensor([[-0.8185, -1.4366],
        [-0.7648, -0.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026592344045639
Epoch 0, Step 908: train/loss = 0.3743945360183716, train/raw-loss = 0.3169272541999817, train/logprobs = tensor([[-0.6697, -5.0770],
        [-1.1151, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14366823434829712
Epoch 0, Step 909: train/loss = 0.3487306237220764, train/raw-loss = 0.28155964612960815, train/logprobs = tensor([[-1.1509, -3.9039],
        [-1.8998, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16792747378349304
Epoch 0, Step 910: train/loss = 0.5473921298980713, train/raw-loss = 0.4955456256866455, train/logprobs = tensor([[-0.9987, -3.9196],
        [-1.0699, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12961623072624207
Epoch 0, Step 911: train/loss = 0.2961437702178955, train/raw-loss = 0.24078428745269775, train/logprobs = tensor([[-0.7622, -7.3320],
        [-1.1288, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138398677110672
Epoch 0, Step 912: train/loss = 0.5146558284759521, train/raw-loss = 0.46155351400375366, train/logprobs = tensor([[-1.2407, -5.2355],
        [-0.7108, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13275575637817383
Epoch 0, Step 913: train/loss = 0.37221914529800415, train/raw-loss = 0.3146337866783142, train/logprobs = tensor([[-0.8143, -6.0162],
        [-1.2926, -1.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14396332204341888
Epoch 0, Step 914: train/loss = 0.5236981511116028, train/raw-loss = 0.47571349143981934, train/logprobs = tensor([[-0.3874, -1.9934],
        [-0.8252, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11996161937713623
Epoch 0, Step 915: train/loss = 0.42150068283081055, train/raw-loss = 0.3647940754890442, train/logprobs = tensor([[-0.7987, -3.2315],
        [-1.1345, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14176645874977112
Epoch 0, Step 916: train/loss = 0.42004886269569397, train/raw-loss = 0.37090587615966797, train/logprobs = tensor([[-1.1742, -3.0639],
        [-1.2311, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12285743653774261
Epoch 0, Step 917: train/loss = 0.43465977907180786, train/raw-loss = 0.3761020004749298, train/logprobs = tensor([[-1.0913, -3.3170],
        [-1.2446, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463944911956787
Epoch 0, Step 918: train/loss = 0.5655516982078552, train/raw-loss = 0.515909731388092, train/logprobs = tensor([[-0.5774, -1.4383],
        [-0.7736, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12410496175289154
Epoch 0, Step 919: train/loss = 0.5771451592445374, train/raw-loss = 0.5300476551055908, train/logprobs = tensor([[-0.9369, -2.7868],
        [-0.9168, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11774376034736633
Epoch 0, Step 920: train/loss = 0.6341137290000916, train/raw-loss = 0.5888893604278564, train/logprobs = tensor([[-0.8387, -0.8193],
        [-1.1084, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11306099593639374
Epoch 0, Step 921: train/loss = 0.5811562538146973, train/raw-loss = 0.5349631905555725, train/logprobs = tensor([[-0.4673, -1.9348],
        [-0.8494, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11548267304897308
Epoch 0, Step 922: train/loss = 0.47538450360298157, train/raw-loss = 0.4228197932243347, train/logprobs = tensor([[-0.6842, -3.9575],
        [-0.7053, -0.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13141174614429474
Epoch 0, Step 923: train/loss = 0.45866522192955017, train/raw-loss = 0.399045467376709, train/logprobs = tensor([[-1.0175, -4.0039],
        [-0.9785, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14904946088790894
Epoch 0, Step 924: train/loss = 0.34088805317878723, train/raw-loss = 0.2887832522392273, train/logprobs = tensor([[-0.7210, -5.5894],
        [-1.3691, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026204705238342
Epoch 0, Step 925: train/loss = 0.5352577567100525, train/raw-loss = 0.495527982711792, train/logprobs = tensor([[-0.4784, -1.7321],
        [-0.5591, -0.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932441264390945
Epoch 0, Step 926: train/loss = 0.5492628216743469, train/raw-loss = 0.5060926675796509, train/logprobs = tensor([[-0.4567, -2.0376],
        [-0.6414, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10792537033557892
Epoch 0, Step 927: train/loss = 0.5764658451080322, train/raw-loss = 0.5166665315628052, train/logprobs = tensor([[-1.2517, -3.3787],
        [-1.0215, -0.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949849247932434
Epoch 0, Step 928: train/loss = 0.3861023187637329, train/raw-loss = 0.3255003094673157, train/logprobs = tensor([[-0.8171, -5.0567],
        [-0.9132, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15150509774684906
Epoch 0, Step 929: train/loss = 0.35065436363220215, train/raw-loss = 0.29580044746398926, train/logprobs = tensor([[-0.6061, -3.7582],
        [-1.3615, -1.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137134850025177
Epoch 0, Step 930: train/loss = 0.49244433641433716, train/raw-loss = 0.4350188076496124, train/logprobs = tensor([[-0.7999, -2.1547],
        [-1.0888, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14356377720832825
Epoch 0, Step 931: train/loss = 0.3740432560443878, train/raw-loss = 0.32826468348503113, train/logprobs = tensor([[-0.6135, -3.1039],
        [-1.0229, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11444634944200516
Epoch 0, Step 932: train/loss = 0.42131686210632324, train/raw-loss = 0.35702934861183167, train/logprobs = tensor([[-0.5099, -3.7616],
        [-1.1433, -0.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16071873903274536
Epoch 0, Step 933: train/loss = 0.4717280864715576, train/raw-loss = 0.4243150055408478, train/logprobs = tensor([[-0.5719, -2.1299],
        [-0.9467, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11853276193141937
Epoch 0, Step 934: train/loss = 0.5115772485733032, train/raw-loss = 0.45902758836746216, train/logprobs = tensor([[-0.5089, -2.7789],
        [-0.9100, -0.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13137421011924744
Epoch 0, Step 935: train/loss = 0.40460628271102905, train/raw-loss = 0.3417152166366577, train/logprobs = tensor([[-0.8695, -3.6584],
        [-1.3988, -0.8101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15722769498825073
Epoch 0, Step 936: train/loss = 0.5050837993621826, train/raw-loss = 0.4451749324798584, train/logprobs = tensor([[-0.9200, -2.6646],
        [-1.2052, -0.7860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497720330953598
Epoch 0, Step 937: train/loss = 0.5204559564590454, train/raw-loss = 0.4635668992996216, train/logprobs = tensor([[-0.8314, -3.6049],
        [-0.9570, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14222264289855957
Epoch 0, Step 938: train/loss = 0.3539291024208069, train/raw-loss = 0.2820880115032196, train/logprobs = tensor([[-0.7302, -3.3251],
        [-1.5138, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1796027421951294
Epoch 0, Step 939: train/loss = 0.4082699418067932, train/raw-loss = 0.35257166624069214, train/logprobs = tensor([[-0.8938, -4.1171],
        [-0.9273, -0.6113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13924574851989746
Epoch 0, Step 940: train/loss = 0.29861217737197876, train/raw-loss = 0.23074600100517273, train/logprobs = tensor([[-0.7734, -3.8395],
        [-1.6343, -1.1800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1696654111146927
Epoch 0, Step 941: train/loss = 0.40235164761543274, train/raw-loss = 0.3547716438770294, train/logprobs = tensor([[-0.6950, -3.7823],
        [-1.1705, -0.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11894997954368591
Epoch 0, Step 942: train/loss = 0.4648514986038208, train/raw-loss = 0.40061527490615845, train/logprobs = tensor([[-0.9835, -3.9029],
        [-1.4890, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16059057414531708
Epoch 0, Step 943: train/loss = 0.3687869906425476, train/raw-loss = 0.3052399456501007, train/logprobs = tensor([[-0.7398, -3.0061],
        [-1.6553, -0.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15886753797531128
Epoch 0, Step 944: train/loss = 0.23597803711891174, train/raw-loss = 0.17642533779144287, train/logprobs = tensor([[-0.6581, -7.4451],
        [-1.5645, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488817036151886
Epoch 0, Step 945: train/loss = 0.487739235162735, train/raw-loss = 0.44042980670928955, train/logprobs = tensor([[-1.0226, -3.2523],
        [-0.9713, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182735413312912
Epoch 0, Step 946: train/loss = 0.4385831356048584, train/raw-loss = 0.3802211284637451, train/logprobs = tensor([[-0.7803, -5.8984],
        [-1.2435, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14590498805046082
Epoch 0, Step 947: train/loss = 0.7384457588195801, train/raw-loss = 0.6932633519172668, train/logprobs = tensor([[-0.7432, -0.7565],
        [-0.7710, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11295606195926666
Epoch 0, Step 948: train/loss = 0.43750619888305664, train/raw-loss = 0.37522435188293457, train/logprobs = tensor([[-0.6514, -2.8036],
        [-1.0225, -0.5727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557045578956604
Epoch 0, Step 949: train/loss = 0.5171182751655579, train/raw-loss = 0.46014589071273804, train/logprobs = tensor([[-0.9276, -3.0451],
        [-1.1344, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14243105053901672
Epoch 0, Step 950: train/loss = 0.3239414095878601, train/raw-loss = 0.2723029851913452, train/logprobs = tensor([[-0.4187, -3.6288],
        [-1.2736, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12909606099128723
Epoch 0, Step 951: train/loss = 0.5847957730293274, train/raw-loss = 0.5239506959915161, train/logprobs = tensor([[-1.4083, -3.7031],
        [-1.0822, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1521126925945282
Epoch 0, Step 952: train/loss = 0.4252901077270508, train/raw-loss = 0.37952589988708496, train/logprobs = tensor([[-0.3613, -3.8301],
        [-0.7270, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11441048979759216
Epoch 0, Step 953: train/loss = 0.537111759185791, train/raw-loss = 0.4859558641910553, train/logprobs = tensor([[-0.7005, -2.1057],
        [-0.9612, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12788979709148407
Epoch 0, Step 954: train/loss = 0.5219982862472534, train/raw-loss = 0.4763723611831665, train/logprobs = tensor([[-0.6483, -1.4930],
        [-0.8970, -0.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11406485736370087
Epoch 0, Step 955: train/loss = 0.3601790964603424, train/raw-loss = 0.3027093708515167, train/logprobs = tensor([[-0.7810, -6.2973],
        [-1.1503, -1.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1436743438243866
Epoch 0, Step 956: train/loss = 0.3825988173484802, train/raw-loss = 0.33308494091033936, train/logprobs = tensor([[-0.5095, -3.3466],
        [-0.9819, -1.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12378478050231934
Epoch 0, Step 957: train/loss = 0.4623968005180359, train/raw-loss = 0.41082870960235596, train/logprobs = tensor([[-1.0172, -5.2255],
        [-1.2598, -1.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12892022728919983
Epoch 0, Step 958: train/loss = 0.4720568358898163, train/raw-loss = 0.41975319385528564, train/logprobs = tensor([[-0.7993, -4.7523],
        [-0.8098, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1307590901851654
Epoch 0, Step 959: train/loss = 0.4328809380531311, train/raw-loss = 0.38122206926345825, train/logprobs = tensor([[-0.5986, -3.8871],
        [-1.0482, -0.8044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12914714217185974
Epoch 0, Step 960: train/loss = 0.5659006834030151, train/raw-loss = 0.5199564099311829, train/logprobs = tensor([[-0.6135, -1.2924],
        [-1.0107, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11486068367958069
Epoch 0, Step 961: train/loss = 0.33081376552581787, train/raw-loss = 0.2725313603878021, train/logprobs = tensor([[-0.8810, -3.7232],
        [-1.6458, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14570602774620056
Epoch 0, Step 962: train/loss = 0.5153047442436218, train/raw-loss = 0.46635955572128296, train/logprobs = tensor([[-1.4191, -5.0959],
        [-1.6146, -1.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12236301600933075
Epoch 0, Step 963: train/loss = 0.5039459466934204, train/raw-loss = 0.45156365633010864, train/logprobs = tensor([[-0.6217, -1.7642],
        [-0.8763, -0.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13095557689666748
Epoch 0, Step 964: train/loss = 0.4787270128726959, train/raw-loss = 0.4204583764076233, train/logprobs = tensor([[-0.7103, -2.6495],
        [-1.1682, -0.8527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456715315580368
Epoch 0, Step 965: train/loss = 0.3851292133331299, train/raw-loss = 0.33568137884140015, train/logprobs = tensor([[-0.8760, -4.0300],
        [-1.2763, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12361955642700195
Epoch 0, Step 966: train/loss = 0.44684040546417236, train/raw-loss = 0.39640897512435913, train/logprobs = tensor([[-0.4417, -2.4948],
        [-1.0575, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12607863545417786
Epoch 0, Step 967: train/loss = 0.4573999047279358, train/raw-loss = 0.4095216393470764, train/logprobs = tensor([[-0.5371, -2.5441],
        [-0.9992, -0.3917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11969564855098724
Epoch 0, Step 968: train/loss = 0.47792869806289673, train/raw-loss = 0.42938047647476196, train/logprobs = tensor([[-0.8807, -2.8499],
        [-1.6662, -1.2630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137052416801453
Epoch 0, Step 969: train/loss = 0.37377503514289856, train/raw-loss = 0.3097115755081177, train/logprobs = tensor([[-0.5526, -4.5965],
        [-1.4103, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1601586788892746
Epoch 0, Step 970: train/loss = 0.46764206886291504, train/raw-loss = 0.41550973057746887, train/logprobs = tensor([[-0.5725, -2.4255],
        [-0.9189, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13033077120780945
Epoch 0, Step 971: train/loss = 0.43570828437805176, train/raw-loss = 0.3797048330307007, train/logprobs = tensor([[-0.3086, -4.1620],
        [-0.7693, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14000870287418365
Epoch 0, Step 972: train/loss = 0.4843185544013977, train/raw-loss = 0.4349443018436432, train/logprobs = tensor([[-0.6489, -4.7145],
        [-0.8151, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12343569099903107
Epoch 0, Step 973: train/loss = 0.5442149043083191, train/raw-loss = 0.4955843687057495, train/logprobs = tensor([[-0.5892, -1.9606],
        [-0.9818, -0.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12157628685235977
Epoch 0, Step 974: train/loss = 0.44020918011665344, train/raw-loss = 0.38256245851516724, train/logprobs = tensor([[-0.7706, -3.7022],
        [-1.2406, -1.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14411680400371552
Epoch 0, Step 975: train/loss = 0.367919921875, train/raw-loss = 0.3081219792366028, train/logprobs = tensor([[-0.4745, -3.3849],
        [-0.8678, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949491620063782
Epoch 0, Step 976: train/loss = 0.5256066918373108, train/raw-loss = 0.4644407033920288, train/logprobs = tensor([[-0.4008, -2.7560],
        [-1.1073, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1529151052236557
Epoch 0, Step 977: train/loss = 0.4870419502258301, train/raw-loss = 0.43056100606918335, train/logprobs = tensor([[-0.7297, -3.2371],
        [-0.9681, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1412024199962616
Epoch 0, Step 978: train/loss = 0.46107664704322815, train/raw-loss = 0.3959933817386627, train/logprobs = tensor([[-1.2235, -3.3706],
        [-1.2601, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1627080738544464
Epoch 0, Step 979: train/loss = 0.44551020860671997, train/raw-loss = 0.39871764183044434, train/logprobs = tensor([[-0.4977, -2.6586],
        [-0.9806, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169813871383667
Epoch 0, Step 980: train/loss = 0.32649746537208557, train/raw-loss = 0.2740325629711151, train/logprobs = tensor([[-0.5916, -3.5788],
        [-1.0551, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13116224110126495
Epoch 0, Step 981: train/loss = 0.4108947217464447, train/raw-loss = 0.35484257340431213, train/logprobs = tensor([[-0.9165, -4.8130],
        [-1.6099, -1.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14013047516345978
Epoch 0, Step 982: train/loss = 0.37965521216392517, train/raw-loss = 0.3242540955543518, train/logprobs = tensor([[-0.6668, -2.9394],
        [-1.1254, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13850268721580505
Epoch 0, Step 983: train/loss = 0.4565770626068115, train/raw-loss = 0.40329524874687195, train/logprobs = tensor([[-0.8224, -3.0609],
        [-1.0164, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13320454955101013
Epoch 0, Step 984: train/loss = 0.4766571521759033, train/raw-loss = 0.41555994749069214, train/logprobs = tensor([[-0.5232, -2.0068],
        [-1.2073, -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15274304151535034
Epoch 0, Step 985: train/loss = 0.5701499581336975, train/raw-loss = 0.5250081419944763, train/logprobs = tensor([[-0.6102, -1.3343],
        [-0.8136, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11285452544689178
Epoch 0, Step 986: train/loss = 0.25056079030036926, train/raw-loss = 0.19011317193508148, train/logprobs = tensor([[-0.6504, -7.3795],
        [-1.5522, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15111906826496124
Epoch 0, Step 987: train/loss = 0.608878493309021, train/raw-loss = 0.5589591264724731, train/logprobs = tensor([[-1.3310, -2.2559],
        [-1.0530, -0.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12479840219020844
Epoch 0, Step 988: train/loss = 0.5887406468391418, train/raw-loss = 0.5270984768867493, train/logprobs = tensor([[-0.6042, -2.1143],
        [-1.9448, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15410546958446503
Epoch 0, Step 989: train/loss = 0.3834652900695801, train/raw-loss = 0.32564184069633484, train/logprobs = tensor([[-0.7967, -2.7892],
        [-1.2219, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445586234331131
Epoch 0, Step 990: train/loss = 0.49236395955085754, train/raw-loss = 0.4437851905822754, train/logprobs = tensor([[-0.4944, -2.6144],
        [-0.7705, -0.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12144690752029419
Epoch 0, Step 991: train/loss = 0.5820186138153076, train/raw-loss = 0.5342913866043091, train/logprobs = tensor([[-0.5522, -1.0724],
        [-0.7636, -0.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11931785941123962
Epoch 0, Step 992: train/loss = 0.4103230834007263, train/raw-loss = 0.35561802983283997, train/logprobs = tensor([[-0.4854, -3.5790],
        [-0.9215, -0.4097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13676252961158752
Epoch 0, Step 993: train/loss = 0.3830150365829468, train/raw-loss = 0.32761138677597046, train/logprobs = tensor([[-0.5202, -2.5376],
        [-1.2100, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13850906491279602
Epoch 0, Step 994: train/loss = 0.25150060653686523, train/raw-loss = 0.1854146420955658, train/logprobs = tensor([[-0.7420, -4.8454],
        [-1.6188, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16521480679512024
Epoch 0, Step 995: train/loss = 0.268890380859375, train/raw-loss = 0.21852263808250427, train/logprobs = tensor([[-0.4639, -4.9721],
        [-0.9556, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12591929733753204
Epoch 0, Step 996: train/loss = 0.5125865340232849, train/raw-loss = 0.4661577641963959, train/logprobs = tensor([[-0.5087, -3.6310],
        [-0.8929, -1.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160719096660614
Epoch 0, Step 997: train/loss = 0.3190267086029053, train/raw-loss = 0.2672572433948517, train/logprobs = tensor([[-0.6506, -4.5916],
        [-0.9149, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12942369282245636
Epoch 0, Step 998: train/loss = 0.3614498972892761, train/raw-loss = 0.2832013666629791, train/logprobs = tensor([[-0.6319, -3.3472],
        [-1.6908, -0.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1956212818622589
Epoch 0, Step 999: train/loss = 0.5032380819320679, train/raw-loss = 0.45289862155914307, train/logprobs = tensor([[-0.5685, -1.9413],
        [-1.1335, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125848650932312
Epoch 0, Step 1000: train/loss = 0.5017172694206238, train/raw-loss = 0.43571215867996216, train/logprobs = tensor([[-0.9112, -2.2497],
        [-1.6572, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1650128960609436
Epoch 0, Step 1001: train/loss = 0.41852006316185, train/raw-loss = 0.35726654529571533, train/logprobs = tensor([[-0.6644, -3.2505],
        [-1.2722, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1531338095664978
Epoch 0, Step 1002: train/loss = 0.4529808759689331, train/raw-loss = 0.38480669260025024, train/logprobs = tensor([[-0.5097, -4.3191],
        [-1.4033, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17043548822402954
Epoch 0, Step 1003: train/loss = 0.4322499930858612, train/raw-loss = 0.36800503730773926, train/logprobs = tensor([[-1.1284, -3.9145],
        [-1.3364, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16061237454414368
Epoch 0, Step 1004: train/loss = 0.6433927416801453, train/raw-loss = 0.591253936290741, train/logprobs = tensor([[-0.6073, -0.9389],
        [-0.7654, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13034707307815552
Epoch 0, Step 1005: train/loss = 0.2349470853805542, train/raw-loss = 0.17568755149841309, train/logprobs = tensor([[-0.7481, -6.9860],
        [-1.5780, -1.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1481488049030304
Epoch 0, Step 1006: train/loss = 0.5834433436393738, train/raw-loss = 0.5326147675514221, train/logprobs = tensor([[-0.7283, -1.3253],
        [-1.0700, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12707164883613586
Epoch 0, Step 1007: train/loss = 0.577968955039978, train/raw-loss = 0.528265655040741, train/logprobs = tensor([[-1.4427, -1.8996],
        [-1.5988, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12425824999809265
Epoch 0, Step 1008: train/loss = 0.47123295068740845, train/raw-loss = 0.4163075089454651, train/logprobs = tensor([[-0.5478, -3.5136],
        [-1.0103, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1373135894536972
Epoch 0, Step 1009: train/loss = 0.4742739498615265, train/raw-loss = 0.42079785466194153, train/logprobs = tensor([[-0.6588, -4.9929],
        [-1.4096, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336902379989624
Epoch 0, Step 1010: train/loss = 0.5032752752304077, train/raw-loss = 0.4464300274848938, train/logprobs = tensor([[-0.8731, -3.4800],
        [-0.9108, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14211317896842957
Epoch 0, Step 1011: train/loss = 0.5842246413230896, train/raw-loss = 0.5282658338546753, train/logprobs = tensor([[-0.5294, -1.6101],
        [-1.0843, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13989704847335815
Epoch 0, Step 1012: train/loss = 0.30504417419433594, train/raw-loss = 0.24954268336296082, train/logprobs = tensor([[-0.6153, -4.2874],
        [-1.5137, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13875365257263184
Epoch 0, Step 1013: train/loss = 0.22601604461669922, train/raw-loss = 0.15207959711551666, train/logprobs = tensor([[-0.9024, -6.5482],
        [-2.4822, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18484117090702057
Epoch 0, Step 1014: train/loss = 0.4417286515235901, train/raw-loss = 0.3825928270816803, train/logprobs = tensor([[-0.7951, -3.4595],
        [-1.2950, -0.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14783962070941925
Epoch 0, Step 1015: train/loss = 0.30487093329429626, train/raw-loss = 0.24499861896038055, train/logprobs = tensor([[-0.4966, -4.2726],
        [-1.5736, -0.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968076348304749
Epoch 0, Step 1016: train/loss = 0.4542372226715088, train/raw-loss = 0.3966178297996521, train/logprobs = tensor([[-0.8776, -5.0094],
        [-1.2847, -1.0753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14404837787151337
Epoch 0, Step 1017: train/loss = 0.3832855820655823, train/raw-loss = 0.32552310824394226, train/logprobs = tensor([[-0.5890, -6.0382],
        [-0.9563, -1.2266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444062441587448
Epoch 0, Step 1018: train/loss = 0.5012029409408569, train/raw-loss = 0.4440353512763977, train/logprobs = tensor([[-0.7952, -3.2909],
        [-1.1002, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14291882514953613
Epoch 0, Step 1019: train/loss = 0.4319313168525696, train/raw-loss = 0.3680405616760254, train/logprobs = tensor([[-1.0497, -4.6270],
        [-1.4727, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1597268432378769
Epoch 0, Step 1020: train/loss = 0.45198285579681396, train/raw-loss = 0.39967799186706543, train/logprobs = tensor([[-0.7529, -5.4002],
        [-0.8679, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1307622194290161
Epoch 0, Step 1021: train/loss = 0.3605044186115265, train/raw-loss = 0.30371344089508057, train/logprobs = tensor([[-0.5909, -4.6592],
        [-1.1752, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14197733998298645
Epoch 0, Step 1022: train/loss = 0.5223144292831421, train/raw-loss = 0.4805547893047333, train/logprobs = tensor([[-0.4943, -1.3495],
        [-0.8932, -0.6230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10439902544021606
Epoch 0, Step 1023: train/loss = 0.5887650847434998, train/raw-loss = 0.5360569953918457, train/logprobs = tensor([[-0.5102, -1.8734],
        [-1.0883, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13177016377449036
Epoch 0, Step 1024: train/loss = 0.43463996052742004, train/raw-loss = 0.37746408581733704, train/logprobs = tensor([[-0.8767, -4.1137],
        [-1.1148, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1429397016763687
Epoch 0, Step 1025: train/loss = 0.39504697918891907, train/raw-loss = 0.34347498416900635, train/logprobs = tensor([[-0.7633, -3.5868],
        [-1.1894, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289300173521042
Epoch 0, Step 1026: train/loss = 0.38072460889816284, train/raw-loss = 0.3147701025009155, train/logprobs = tensor([[-0.7081, -3.7549],
        [-1.2461, -0.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648862510919571
Epoch 0, Step 1027: train/loss = 0.6731305718421936, train/raw-loss = 0.6275806427001953, train/logprobs = tensor([[-0.5493, -0.9313],
        [-0.7661, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1138748973608017
Epoch 0, Step 1028: train/loss = 0.39007049798965454, train/raw-loss = 0.3451448082923889, train/logprobs = tensor([[-0.7767, -4.3646],
        [-1.7111, -1.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11231434345245361
Epoch 0, Step 1029: train/loss = 0.5732344388961792, train/raw-loss = 0.5208219289779663, train/logprobs = tensor([[-0.3999, -2.0648],
        [-0.7538, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13103124499320984
Epoch 0, Step 1030: train/loss = 0.36779409646987915, train/raw-loss = 0.3051931858062744, train/logprobs = tensor([[-0.6735, -5.0924],
        [-1.7569, -1.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15650230646133423
Epoch 0, Step 1031: train/loss = 0.4708954691886902, train/raw-loss = 0.41520148515701294, train/logprobs = tensor([[-0.6501, -2.1707],
        [-1.0863, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13923488557338715
Epoch 0, Step 1032: train/loss = 0.4892919659614563, train/raw-loss = 0.4379250705242157, train/logprobs = tensor([[-0.7045, -2.0922],
        [-1.4246, -1.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12841731309890747
Epoch 0, Step 1033: train/loss = 0.33728501200675964, train/raw-loss = 0.26719045639038086, train/logprobs = tensor([[-0.9896, -4.7030],
        [-2.1836, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523634433746338
Epoch 0, Step 1034: train/loss = 0.41962292790412903, train/raw-loss = 0.3682616055011749, train/logprobs = tensor([[-0.7248, -2.3333],
        [-1.2557, -0.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12840329110622406
Epoch 0, Step 1035: train/loss = 0.5089272260665894, train/raw-loss = 0.4443202614784241, train/logprobs = tensor([[-0.7927, -2.5808],
        [-1.4487, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16151729226112366
Epoch 0, Step 1036: train/loss = 0.5459499955177307, train/raw-loss = 0.4926143288612366, train/logprobs = tensor([[-0.5208, -2.0929],
        [-1.0148, -0.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13333910703659058
Epoch 0, Step 1037: train/loss = 0.531160831451416, train/raw-loss = 0.47567427158355713, train/logprobs = tensor([[-0.6191, -2.8412],
        [-1.2741, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13871636986732483
Epoch 0, Step 1038: train/loss = 0.40449416637420654, train/raw-loss = 0.3375462293624878, train/logprobs = tensor([[-0.8905, -4.7557],
        [-1.4019, -1.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16736984252929688
Epoch 0, Step 1039: train/loss = 0.3349666893482208, train/raw-loss = 0.27441686391830444, train/logprobs = tensor([[-0.7089, -7.5151],
        [-1.5055, -2.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15137456357479095
Epoch 0, Step 1040: train/loss = 0.4980340003967285, train/raw-loss = 0.4493432641029358, train/logprobs = tensor([[-1.3419, -3.5304],
        [-1.5650, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1217268779873848
Epoch 0, Step 1041: train/loss = 0.34842604398727417, train/raw-loss = 0.2833826541900635, train/logprobs = tensor([[-0.8050, -6.0800],
        [-1.3793, -1.1121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16260859370231628
Epoch 0, Step 1042: train/loss = 0.5131418704986572, train/raw-loss = 0.47040003538131714, train/logprobs = tensor([[-0.7142, -2.5992],
        [-0.7605, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10685456544160843
Epoch 0, Step 1043: train/loss = 0.6905374526977539, train/raw-loss = 0.6392924785614014, train/logprobs = tensor([[-1.0924, -1.4153],
        [-0.9636, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12811234593391418
Epoch 0, Step 1044: train/loss = 0.5525546669960022, train/raw-loss = 0.49641695618629456, train/logprobs = tensor([[-0.9664, -1.5691],
        [-1.7014, -0.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403442770242691
Epoch 0, Step 1045: train/loss = 0.44316962361335754, train/raw-loss = 0.39465412497520447, train/logprobs = tensor([[-0.5818, -3.4656],
        [-1.0361, -0.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128874659538269
Epoch 0, Step 1046: train/loss = 0.4189198613166809, train/raw-loss = 0.36195382475852966, train/logprobs = tensor([[-0.5455, -3.5241],
        [-1.0528, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14241503179073334
Epoch 0, Step 1047: train/loss = 0.5274940133094788, train/raw-loss = 0.4709339141845703, train/logprobs = tensor([[-0.6533, -1.5297],
        [-1.0398, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1414003223180771
Epoch 0, Step 1048: train/loss = 0.23779623210430145, train/raw-loss = 0.18149010837078094, train/logprobs = tensor([[-0.6190, -7.7009],
        [-1.4214, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14076532423496246
Epoch 0, Step 1049: train/loss = 0.3619828224182129, train/raw-loss = 0.29544442892074585, train/logprobs = tensor([[-0.7878, -3.2957],
        [-1.6709, -0.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16634605824947357
Epoch 0, Step 1050: train/loss = 0.5229668617248535, train/raw-loss = 0.4735076427459717, train/logprobs = tensor([[-0.5047, -1.1553],
        [-1.1216, -0.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364808470010757
Epoch 0, Step 1051: train/loss = 0.6254702806472778, train/raw-loss = 0.5864804983139038, train/logprobs = tensor([[-0.5883, -1.2092],
        [-0.6627, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974743515253067
Epoch 0, Step 1052: train/loss = 0.38355156779289246, train/raw-loss = 0.3330725133419037, train/logprobs = tensor([[-0.5741, -3.3506],
        [-1.0012, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12619762122631073
Epoch 0, Step 1053: train/loss = 0.31726038455963135, train/raw-loss = 0.2647041976451874, train/logprobs = tensor([[-0.6279, -4.3035],
        [-1.4282, -0.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13139048218727112
Epoch 0, Step 1054: train/loss = 0.5018764138221741, train/raw-loss = 0.4553452730178833, train/logprobs = tensor([[-0.8986, -1.9753],
        [-1.2223, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11632782965898514
Epoch 0, Step 1055: train/loss = 0.4980156421661377, train/raw-loss = 0.4404735565185547, train/logprobs = tensor([[-0.8826, -3.4294],
        [-1.5180, -1.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14385510981082916
Epoch 0, Step 1056: train/loss = 0.4506664276123047, train/raw-loss = 0.4012654423713684, train/logprobs = tensor([[-0.6890, -3.3230],
        [-0.9055, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12350255250930786
Epoch 0, Step 1057: train/loss = 0.37617743015289307, train/raw-loss = 0.3260505497455597, train/logprobs = tensor([[-0.5460, -5.4851],
        [-1.3314, -0.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1253172606229782
Epoch 0, Step 1058: train/loss = 0.35854843258857727, train/raw-loss = 0.2956192195415497, train/logprobs = tensor([[-0.5879, -3.3256],
        [-1.4164, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15732307732105255
Epoch 0, Step 1059: train/loss = 0.6081725358963013, train/raw-loss = 0.5506179332733154, train/logprobs = tensor([[-0.5754, -1.4735],
        [-0.8959, -0.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1438865065574646
Epoch 0, Step 1060: train/loss = 0.5856612324714661, train/raw-loss = 0.5314393043518066, train/logprobs = tensor([[-0.6666, -1.9237],
        [-1.1870, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355549395084381
Epoch 0, Step 1061: train/loss = 0.4982289671897888, train/raw-loss = 0.4383319318294525, train/logprobs = tensor([[-0.7049, -3.9851],
        [-1.2690, -1.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14974266290664673
Epoch 0, Step 1062: train/loss = 0.4713286757469177, train/raw-loss = 0.40685707330703735, train/logprobs = tensor([[-0.7929, -2.7237],
        [-1.4797, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16117899119853973
Epoch 0, Step 1063: train/loss = 0.5824524164199829, train/raw-loss = 0.5343509316444397, train/logprobs = tensor([[-1.0537, -2.2239],
        [-0.8709, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12025381624698639
Epoch 0, Step 1064: train/loss = 0.4082299768924713, train/raw-loss = 0.34926992654800415, train/logprobs = tensor([[-0.6874, -4.9421],
        [-1.2292, -1.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14740009605884552
Epoch 0, Step 1065: train/loss = 0.5114774703979492, train/raw-loss = 0.45831117033958435, train/logprobs = tensor([[-0.5995, -2.1152],
        [-1.0753, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13291575014591217
Epoch 0, Step 1066: train/loss = 0.4498453140258789, train/raw-loss = 0.4001739025115967, train/logprobs = tensor([[-1.4006, -3.7496],
        [-1.4224, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12417860329151154
Epoch 0, Step 1067: train/loss = 0.21256843209266663, train/raw-loss = 0.1536000669002533, train/logprobs = tensor([[-0.8305, -7.7881],
        [-2.0561, -1.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474209427833557
Epoch 0, Step 1068: train/loss = 0.4171128571033478, train/raw-loss = 0.36299991607666016, train/logprobs = tensor([[-0.5358, -2.7997],
        [-1.1695, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13528235256671906
Epoch 0, Step 1069: train/loss = 0.5750205516815186, train/raw-loss = 0.5229191780090332, train/logprobs = tensor([[-1.0863, -5.1537],
        [-1.0874, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13025355339050293
Epoch 0, Step 1070: train/loss = 0.36902695894241333, train/raw-loss = 0.3041497468948364, train/logprobs = tensor([[-0.6865, -4.0328],
        [-1.3080, -1.2766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16219305992126465
Epoch 0, Step 1071: train/loss = 0.24150383472442627, train/raw-loss = 0.1798136979341507, train/logprobs = tensor([[-0.6761, -6.0558],
        [-1.7540, -1.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15422536432743073
Epoch 0, Step 1072: train/loss = 0.2459917664527893, train/raw-loss = 0.18755581974983215, train/logprobs = tensor([[-0.6277, -6.4699],
        [-1.4330, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14608989655971527
Epoch 0, Step 1073: train/loss = 0.41759049892425537, train/raw-loss = 0.3558890223503113, train/logprobs = tensor([[-0.7352, -3.7440],
        [-1.3541, -1.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15425369143486023
Epoch 0, Step 1074: train/loss = 0.4279879927635193, train/raw-loss = 0.37284576892852783, train/logprobs = tensor([[-0.5166, -5.0684],
        [-1.0812, -1.3738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13785558938980103
Epoch 0, Step 1075: train/loss = 0.44746044278144836, train/raw-loss = 0.39941999316215515, train/logprobs = tensor([[-0.4897, -3.0671],
        [-0.7614, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12010116130113602
Epoch 0, Step 1076: train/loss = 0.4141024351119995, train/raw-loss = 0.3442762494087219, train/logprobs = tensor([[-0.5269, -3.6642],
        [-1.2835, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17456547915935516
Epoch 0, Step 1077: train/loss = 0.4256604313850403, train/raw-loss = 0.37054502964019775, train/logprobs = tensor([[-0.4715, -3.4891],
        [-1.1783, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377885639667511
Epoch 0, Step 1078: train/loss = 0.5099427103996277, train/raw-loss = 0.45686179399490356, train/logprobs = tensor([[-0.8974, -2.6104],
        [-1.2915, -0.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327023208141327
Epoch 0, Step 1079: train/loss = 0.3090084493160248, train/raw-loss = 0.24440333247184753, train/logprobs = tensor([[-0.5501, -6.6684],
        [-1.2079, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16151277720928192
Epoch 0, Step 1080: train/loss = 0.5092310905456543, train/raw-loss = 0.45542046427726746, train/logprobs = tensor([[-0.6611, -2.5065],
        [-1.2029, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13452646136283875
Epoch 0, Step 1081: train/loss = 0.30188697576522827, train/raw-loss = 0.2466428130865097, train/logprobs = tensor([[-1.2170, -5.0072],
        [-1.5269, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1381104588508606
Epoch 0, Step 1082: train/loss = 0.632935643196106, train/raw-loss = 0.5829209685325623, train/logprobs = tensor([[-0.6924, -1.1266],
        [-1.1472, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12503653764724731
Epoch 0, Step 1083: train/loss = 0.525500476360321, train/raw-loss = 0.45903530716896057, train/logprobs = tensor([[-0.8883, -2.8099],
        [-1.3928, -1.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16616305708885193
Epoch 0, Step 1084: train/loss = 0.48013627529144287, train/raw-loss = 0.4260590672492981, train/logprobs = tensor([[-0.5015, -2.8387],
        [-0.9814, -0.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13519302010536194
Epoch 0, Step 1085: train/loss = 0.5293916463851929, train/raw-loss = 0.4816702604293823, train/logprobs = tensor([[-0.6308, -2.1692],
        [-1.0349, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193036213517189
Epoch 0, Step 1086: train/loss = 0.413176953792572, train/raw-loss = 0.3538724184036255, train/logprobs = tensor([[-0.6806, -4.9898],
        [-1.2854, -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14826138317584991
Epoch 0, Step 1087: train/loss = 0.3760005533695221, train/raw-loss = 0.330794095993042, train/logprobs = tensor([[-0.5923, -5.0189],
        [-0.8006, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11301618814468384
Epoch 0, Step 1088: train/loss = 0.5067481398582458, train/raw-loss = 0.45086103677749634, train/logprobs = tensor([[-1.0602, -2.4803],
        [-1.3110, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13971757888793945
Epoch 0, Step 1089: train/loss = 0.5088976621627808, train/raw-loss = 0.46384698152542114, train/logprobs = tensor([[-0.6880, -2.2290],
        [-0.8685, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11262666434049606
Epoch 0, Step 1090: train/loss = 0.35503581166267395, train/raw-loss = 0.29961296916007996, train/logprobs = tensor([[-0.5433, -3.4735],
        [-1.4829, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13855713605880737
Epoch 0, Step 1091: train/loss = 0.3609815239906311, train/raw-loss = 0.31135985255241394, train/logprobs = tensor([[-0.5155, -3.1939],
        [-1.2570, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12405417114496231
Epoch 0, Step 1092: train/loss = 0.4080299139022827, train/raw-loss = 0.3499980568885803, train/logprobs = tensor([[-0.7683, -2.8276],
        [-1.2505, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14507964253425598
Epoch 0, Step 1093: train/loss = 0.49085673689842224, train/raw-loss = 0.4278770387172699, train/logprobs = tensor([[-0.7196, -3.7104],
        [-1.4514, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15744920074939728
Epoch 0, Step 1094: train/loss = 0.4068031907081604, train/raw-loss = 0.35478198528289795, train/logprobs = tensor([[-0.5493, -2.1099],
        [-1.1016, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13005304336547852
Epoch 0, Step 1095: train/loss = 0.5610344409942627, train/raw-loss = 0.49952587485313416, train/logprobs = tensor([[-0.9637, -2.7038],
        [-1.1375, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15377143025398254
Epoch 0, Step 1096: train/loss = 0.3605740964412689, train/raw-loss = 0.30455106496810913, train/logprobs = tensor([[-0.7228, -4.3858],
        [-1.1942, -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14005757868289948
Epoch 0, Step 1097: train/loss = 0.33611640334129333, train/raw-loss = 0.2733285129070282, train/logprobs = tensor([[-0.8372, -4.2235],
        [-1.3702, -0.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15696963667869568
Epoch 0, Step 1098: train/loss = 0.3711593747138977, train/raw-loss = 0.3154897689819336, train/logprobs = tensor([[-0.4258, -6.1478],
        [-1.2266, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13917401432991028
Epoch 0, Step 1099: train/loss = 0.4980320930480957, train/raw-loss = 0.435560405254364, train/logprobs = tensor([[-0.5759, -1.4297],
        [-1.4367, -0.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15617921948432922
Epoch 0, Step 1100: train/loss = 0.4113321006298065, train/raw-loss = 0.3576315939426422, train/logprobs = tensor([[-0.6047, -3.0827],
        [-1.1689, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13425125181674957
Epoch 0, Step 1101: train/loss = 0.3275391161441803, train/raw-loss = 0.2738490700721741, train/logprobs = tensor([[-0.6226, -5.9081],
        [-1.6400, -1.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13422513008117676
Epoch 0, Step 1102: train/loss = 0.4006965160369873, train/raw-loss = 0.35368070006370544, train/logprobs = tensor([[-0.9638, -4.5427],
        [-1.0531, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11753958463668823
Epoch 0, Step 1103: train/loss = 0.32436326146125793, train/raw-loss = 0.26961731910705566, train/logprobs = tensor([[-0.8541, -5.1458],
        [-1.4208, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13686484098434448
Epoch 0, Step 1104: train/loss = 0.6016122102737427, train/raw-loss = 0.5501450300216675, train/logprobs = tensor([[-0.8148, -4.2233],
        [-0.9632, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12866786122322083
Epoch 0, Step 1105: train/loss = 0.42822059988975525, train/raw-loss = 0.38067129254341125, train/logprobs = tensor([[-0.8030, -3.8858],
        [-0.8097, -0.5671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11887331306934357
Epoch 0, Step 1106: train/loss = 0.39103952050209045, train/raw-loss = 0.3281504511833191, train/logprobs = tensor([[-1.0929, -5.3995],
        [-1.3740, -1.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572226881980896
Epoch 0, Step 1107: train/loss = 0.4017312526702881, train/raw-loss = 0.3503226637840271, train/logprobs = tensor([[-0.6345, -3.7607],
        [-1.0176, -0.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12852148711681366
Epoch 0, Step 1108: train/loss = 0.4274754524230957, train/raw-loss = 0.38105469942092896, train/logprobs = tensor([[-0.5648, -2.7984],
        [-1.0326, -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160518154501915
Epoch 0, Step 1109: train/loss = 0.4486348032951355, train/raw-loss = 0.39528435468673706, train/logprobs = tensor([[-0.6266, -2.6143],
        [-1.1238, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333760917186737
Epoch 0, Step 1110: train/loss = 0.5305314660072327, train/raw-loss = 0.48269277811050415, train/logprobs = tensor([[-0.5949, -3.5265],
        [-0.7803, -1.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11959665268659592
Epoch 0, Step 1111: train/loss = 0.3967190384864807, train/raw-loss = 0.344257652759552, train/logprobs = tensor([[-0.6506, -4.2512],
        [-0.9203, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131153404712677
Epoch 0, Step 1112: train/loss = 0.5804805159568787, train/raw-loss = 0.5202418565750122, train/logprobs = tensor([[-1.4327, -4.2587],
        [-1.3506, -1.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15059655904769897
Epoch 0, Step 1113: train/loss = 0.5651713013648987, train/raw-loss = 0.5115436315536499, train/logprobs = tensor([[-0.6623, -1.6986],
        [-1.0146, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13406912982463837
Epoch 0, Step 1114: train/loss = 0.42236149311065674, train/raw-loss = 0.3726644217967987, train/logprobs = tensor([[-0.7369, -2.3481],
        [-1.2250, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12424267828464508
Epoch 0, Step 1115: train/loss = 0.5250250697135925, train/raw-loss = 0.47000861167907715, train/logprobs = tensor([[-0.3826, -1.6369],
        [-0.7712, -0.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13754113018512726
Epoch 0, Step 1116: train/loss = 0.5001388788223267, train/raw-loss = 0.4504704177379608, train/logprobs = tensor([[-0.5768, -2.2020],
        [-0.8524, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12417112290859222
Epoch 0, Step 1117: train/loss = 0.5657275319099426, train/raw-loss = 0.5030883550643921, train/logprobs = tensor([[-0.6286, -2.3068],
        [-1.5340, -1.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15659800171852112
Epoch 0, Step 1118: train/loss = 0.6145569682121277, train/raw-loss = 0.571357250213623, train/logprobs = tensor([[-0.3324, -2.0679],
        [-0.5260, -0.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10799919068813324
Epoch 0, Step 1119: train/loss = 0.41316574811935425, train/raw-loss = 0.3562546968460083, train/logprobs = tensor([[-0.4894, -4.2124],
        [-1.1114, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422775685787201
Epoch 0, Step 1120: train/loss = 0.265730082988739, train/raw-loss = 0.19996748864650726, train/logprobs = tensor([[-0.8749, -3.8322],
        [-1.8564, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16440652310848236
Epoch 0, Step 1121: train/loss = 0.3705637454986572, train/raw-loss = 0.3060786724090576, train/logprobs = tensor([[-0.6836, -3.3078],
        [-1.8500, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.161212757229805
Epoch 0, Step 1122: train/loss = 0.5823699235916138, train/raw-loss = 0.5263850688934326, train/logprobs = tensor([[-0.5470, -3.6062],
        [-1.0395, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1399623155593872
Epoch 0, Step 1123: train/loss = 0.27680426836013794, train/raw-loss = 0.22039133310317993, train/logprobs = tensor([[-0.6078, -6.8809],
        [-1.5262, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14103227853775024
Epoch 0, Step 1124: train/loss = 0.395341157913208, train/raw-loss = 0.34189262986183167, train/logprobs = tensor([[-0.8682, -5.9935],
        [-1.4211, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336212158203125
Epoch 0, Step 1125: train/loss = 0.4014201760292053, train/raw-loss = 0.34780338406562805, train/logprobs = tensor([[-0.5739, -2.5229],
        [-1.0925, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13404205441474915
Epoch 0, Step 1126: train/loss = 0.5161674618721008, train/raw-loss = 0.4590601623058319, train/logprobs = tensor([[-0.9101, -4.5512],
        [-1.1683, -1.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14276829361915588
Epoch 0, Step 1127: train/loss = 0.4159013330936432, train/raw-loss = 0.3650287687778473, train/logprobs = tensor([[-0.3926, -3.1625],
        [-0.6543, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12718138098716736
Epoch 0, Step 1128: train/loss = 0.6072486639022827, train/raw-loss = 0.5469561219215393, train/logprobs = tensor([[-1.3739, -2.1297],
        [-1.1204, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15073126554489136
Epoch 0, Step 1129: train/loss = 0.3156130015850067, train/raw-loss = 0.2512890696525574, train/logprobs = tensor([[-0.6969, -3.2577],
        [-1.5694, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16080984473228455
Epoch 0, Step 1130: train/loss = 0.5172669887542725, train/raw-loss = 0.47667965292930603, train/logprobs = tensor([[-0.3496, -1.6851],
        [-0.8395, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1014682874083519
Epoch 0, Step 1131: train/loss = 0.4028484523296356, train/raw-loss = 0.35750216245651245, train/logprobs = tensor([[-0.4591, -3.1970],
        [-0.8367, -0.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11336567252874374
Epoch 0, Step 1132: train/loss = 0.5703691244125366, train/raw-loss = 0.5096250176429749, train/logprobs = tensor([[-0.8387, -2.9367],
        [-0.8611, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15186025202274323
Epoch 0, Step 1133: train/loss = 0.6401500701904297, train/raw-loss = 0.5890635848045349, train/logprobs = tensor([[-0.6608, -0.8825],
        [-0.8848, -0.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12771612405776978
Epoch 0, Step 1134: train/loss = 0.4078918695449829, train/raw-loss = 0.3494493365287781, train/logprobs = tensor([[-1.1505, -5.8635],
        [-1.4623, -1.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14610633254051208
Epoch 0, Step 1135: train/loss = 0.3706507384777069, train/raw-loss = 0.3157510757446289, train/logprobs = tensor([[-0.5438, -3.8440],
        [-1.0442, -0.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137249156832695
Epoch 0, Step 1136: train/loss = 0.40217044949531555, train/raw-loss = 0.3452884554862976, train/logprobs = tensor([[-0.7547, -4.6415],
        [-1.4497, -1.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14220502972602844
Epoch 0, Step 1137: train/loss = 0.38463255763053894, train/raw-loss = 0.3299446702003479, train/logprobs = tensor([[-0.8221, -6.2683],
        [-1.2384, -1.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1367197483778
Epoch 0, Step 1138: train/loss = 0.5300549864768982, train/raw-loss = 0.48134949803352356, train/logprobs = tensor([[-0.5527, -1.7732],
        [-0.8334, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12176366150379181
Epoch 0, Step 1139: train/loss = 0.389278382062912, train/raw-loss = 0.3149147629737854, train/logprobs = tensor([[-0.5570, -2.7379],
        [-1.6158, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18590903282165527
Epoch 0, Step 1140: train/loss = 0.4074186682701111, train/raw-loss = 0.3545093536376953, train/logprobs = tensor([[-0.5750, -5.4463],
        [-1.1572, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13227321207523346
Epoch 0, Step 1141: train/loss = 0.42484843730926514, train/raw-loss = 0.37576305866241455, train/logprobs = tensor([[-0.5754, -3.6643],
        [-0.9978, -1.2259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12271340936422348
Epoch 0, Step 1142: train/loss = 0.5648807287216187, train/raw-loss = 0.5152013301849365, train/logprobs = tensor([[-0.7013, -1.9736],
        [-1.5313, -1.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12419835478067398
Epoch 0, Step 1143: train/loss = 0.5320757627487183, train/raw-loss = 0.4730646014213562, train/logprobs = tensor([[-0.6134, -1.9196],
        [-1.0551, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14752797782421112
Epoch 0, Step 1144: train/loss = 0.46503716707229614, train/raw-loss = 0.41640299558639526, train/logprobs = tensor([[-0.4977, -3.2739],
        [-0.6292, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158538401126862
Epoch 0, Step 1145: train/loss = 0.30981481075286865, train/raw-loss = 0.261397123336792, train/logprobs = tensor([[-0.4654, -5.7897],
        [-0.7483, -0.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12104426324367523
Epoch 0, Step 1146: train/loss = 0.24524447321891785, train/raw-loss = 0.1749529391527176, train/logprobs = tensor([[-0.6652, -9.1797],
        [-1.3782, -1.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17572879791259766
Epoch 0, Step 1147: train/loss = 0.3310352563858032, train/raw-loss = 0.26213982701301575, train/logprobs = tensor([[-0.9098, -4.1150],
        [-1.6414, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1722385138273239
Epoch 0, Step 1148: train/loss = 0.5422399640083313, train/raw-loss = 0.4839375913143158, train/logprobs = tensor([[-0.6814, -1.5847],
        [-1.2708, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14575588703155518
Epoch 0, Step 1149: train/loss = 0.3643588721752167, train/raw-loss = 0.3080330789089203, train/logprobs = tensor([[-0.7202, -4.5873],
        [-1.5460, -0.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14081455767154694
Epoch 0, Step 1150: train/loss = 0.5387194752693176, train/raw-loss = 0.4869450330734253, train/logprobs = tensor([[-0.8778, -3.6239],
        [-0.6407, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12943604588508606
Epoch 0, Step 1151: train/loss = 0.34546810388565063, train/raw-loss = 0.2826904058456421, train/logprobs = tensor([[-0.9038, -7.0363],
        [-1.6749, -1.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569441705942154
Epoch 0, Step 1152: train/loss = 0.2071225494146347, train/raw-loss = 0.13934051990509033, train/logprobs = tensor([[-0.6657, -6.7815],
        [-1.8276, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16945505142211914
Epoch 0, Step 1153: train/loss = 0.47103479504585266, train/raw-loss = 0.4174380898475647, train/logprobs = tensor([[-0.4268, -1.9513],
        [-0.8950, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339917778968811
Epoch 0, Step 1154: train/loss = 0.4108262360095978, train/raw-loss = 0.3519235849380493, train/logprobs = tensor([[-0.7195, -3.1889],
        [-1.3790, -1.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14725667238235474
Epoch 0, Step 1155: train/loss = 0.39174747467041016, train/raw-loss = 0.34607362747192383, train/logprobs = tensor([[-0.5694, -2.9220],
        [-1.2217, -1.3700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11418469250202179
Epoch 0, Step 1156: train/loss = 0.5070885419845581, train/raw-loss = 0.45098280906677246, train/logprobs = tensor([[-0.6239, -1.8213],
        [-1.2500, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14026443660259247
Epoch 0, Step 1157: train/loss = 0.4242035150527954, train/raw-loss = 0.36536410450935364, train/logprobs = tensor([[-0.8783, -5.9492],
        [-1.0955, -1.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14709849655628204
Epoch 0, Step 1158: train/loss = 0.2728725075721741, train/raw-loss = 0.21108335256576538, train/logprobs = tensor([[-0.7267, -5.2223],
        [-1.4068, -1.0917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15447291731834412
Epoch 0, Step 1159: train/loss = 0.3830080032348633, train/raw-loss = 0.32976987957954407, train/logprobs = tensor([[-0.5336, -3.4244],
        [-0.7794, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13309529423713684
Epoch 0, Step 1160: train/loss = 0.5578894019126892, train/raw-loss = 0.5113310813903809, train/logprobs = tensor([[-0.6671, -2.9857],
        [-0.9655, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11639582365751266
Epoch 0, Step 1161: train/loss = 0.49329277873039246, train/raw-loss = 0.4299127161502838, train/logprobs = tensor([[-0.6576, -2.0192],
        [-1.0691, -0.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1584502011537552
Epoch 0, Step 1162: train/loss = 0.3809225857257843, train/raw-loss = 0.32063472270965576, train/logprobs = tensor([[-0.8118, -5.2822],
        [-1.5072, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15071964263916016
Epoch 0, Step 1163: train/loss = 0.31059014797210693, train/raw-loss = 0.24904000759124756, train/logprobs = tensor([[-0.6273, -5.8368],
        [-1.1485, -1.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15387532114982605
Epoch 0, Step 1164: train/loss = 0.3952324688434601, train/raw-loss = 0.33531951904296875, train/logprobs = tensor([[-0.5845, -6.6053],
        [-1.1605, -1.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14978232979774475
Epoch 0, Step 1165: train/loss = 0.3973570466041565, train/raw-loss = 0.34781914949417114, train/logprobs = tensor([[-0.6903, -4.1660],
        [-1.1476, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238446980714798
Epoch 0, Step 1166: train/loss = 0.34979236125946045, train/raw-loss = 0.28256136178970337, train/logprobs = tensor([[-0.6318, -3.1170],
        [-1.7577, -0.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1680774837732315
Epoch 0, Step 1167: train/loss = 0.47927865386009216, train/raw-loss = 0.4233410358428955, train/logprobs = tensor([[-0.5328, -4.2672],
        [-1.1077, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13984404504299164
Epoch 0, Step 1168: train/loss = 0.5239332914352417, train/raw-loss = 0.4705793261528015, train/logprobs = tensor([[-0.8213, -2.7495],
        [-1.2315, -1.3805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13338494300842285
Epoch 0, Step 1169: train/loss = 0.6884373426437378, train/raw-loss = 0.6273548007011414, train/logprobs = tensor([[-1.9906, -4.9016],
        [-1.2620, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527063548564911
Epoch 0, Step 1170: train/loss = 0.3265160322189331, train/raw-loss = 0.2757447361946106, train/logprobs = tensor([[-0.6184, -5.0853],
        [-1.1432, -1.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12692825496196747
Epoch 0, Step 1171: train/loss = 0.5798698663711548, train/raw-loss = 0.5265114903450012, train/logprobs = tensor([[-0.7851, -2.7303],
        [-1.2281, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333959549665451
Epoch 0, Step 1172: train/loss = 0.2988547682762146, train/raw-loss = 0.24703383445739746, train/logprobs = tensor([[-0.6096, -6.7196],
        [-1.1711, -1.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12955231964588165
Epoch 0, Step 1173: train/loss = 0.285067617893219, train/raw-loss = 0.22795069217681885, train/logprobs = tensor([[-0.7982, -5.2458],
        [-1.3258, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14279234409332275
Epoch 0, Step 1174: train/loss = 0.5355599522590637, train/raw-loss = 0.4932368993759155, train/logprobs = tensor([[-0.6091, -1.9904],
        [-1.1500, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10580766946077347
Epoch 0, Step 1175: train/loss = 0.36974573135375977, train/raw-loss = 0.309475839138031, train/logprobs = tensor([[-0.8460, -4.8681],
        [-1.3191, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1506747156381607
Epoch 0, Step 1176: train/loss = 0.6232330203056335, train/raw-loss = 0.580072283744812, train/logprobs = tensor([[-0.6800, -1.8337],
        [-1.0571, -1.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10790185630321503
Epoch 0, Step 1177: train/loss = 0.5002474784851074, train/raw-loss = 0.4441700875759125, train/logprobs = tensor([[-0.6233, -3.0969],
        [-1.0977, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14019346237182617
Epoch 0, Step 1178: train/loss = 0.6593073010444641, train/raw-loss = 0.6072328090667725, train/logprobs = tensor([[-1.7015, -3.2601],
        [-0.9772, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301862895488739
Epoch 0, Step 1179: train/loss = 0.5320159196853638, train/raw-loss = 0.47427448630332947, train/logprobs = tensor([[-1.0441, -1.8289],
        [-1.2461, -0.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14435365796089172
Epoch 0, Step 1180: train/loss = 0.6146487593650818, train/raw-loss = 0.5623931884765625, train/logprobs = tensor([[-0.6775, -0.9350],
        [-1.3128, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306389719247818
Epoch 0, Step 1181: train/loss = 0.34402284026145935, train/raw-loss = 0.29829084873199463, train/logprobs = tensor([[-0.9342, -4.3533],
        [-1.1878, -1.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11432992666959763
Epoch 0, Step 1182: train/loss = 0.5732172727584839, train/raw-loss = 0.5112378001213074, train/logprobs = tensor([[-0.8860, -4.6002],
        [-1.4341, -1.3798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15494868159294128
Epoch 0, Step 1183: train/loss = 0.5927335023880005, train/raw-loss = 0.5486355423927307, train/logprobs = tensor([[-0.5865, -1.8644],
        [-0.6910, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11024489253759384
Epoch 0, Step 1184: train/loss = 0.567996621131897, train/raw-loss = 0.5070810317993164, train/logprobs = tensor([[-0.7936, -2.4588],
        [-1.1870, -0.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15228892862796783
Epoch 0, Step 1185: train/loss = 0.42791372537612915, train/raw-loss = 0.3742563724517822, train/logprobs = tensor([[-0.6067, -3.4150],
        [-1.5421, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414335250854492
Epoch 0, Step 1186: train/loss = 0.5396909117698669, train/raw-loss = 0.48955008387565613, train/logprobs = tensor([[-0.5750, -3.6153],
        [-0.9225, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12535205483436584
Epoch 0, Step 1187: train/loss = 0.36106622219085693, train/raw-loss = 0.3027547001838684, train/logprobs = tensor([[-1.0509, -6.1111],
        [-1.1392, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14577871561050415
Epoch 0, Step 1188: train/loss = 0.3631834387779236, train/raw-loss = 0.30627962946891785, train/logprobs = tensor([[-0.6904, -3.9656],
        [-1.4482, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14225956797599792
Epoch 0, Step 1189: train/loss = 0.3572539687156677, train/raw-loss = 0.2965613603591919, train/logprobs = tensor([[-0.5809, -2.8282],
        [-1.3830, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1517314612865448
Epoch 0, Step 1190: train/loss = 0.4561101198196411, train/raw-loss = 0.39821434020996094, train/logprobs = tensor([[-0.6303, -2.6111],
        [-1.2134, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14473947882652283
Epoch 0, Step 1191: train/loss = 0.37422603368759155, train/raw-loss = 0.32381656765937805, train/logprobs = tensor([[-0.7264, -5.7641],
        [-1.1519, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12602367997169495
Epoch 0, Step 1192: train/loss = 0.2696461081504822, train/raw-loss = 0.2117180973291397, train/logprobs = tensor([[-0.5815, -7.5508],
        [-1.2011, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14482006430625916
Epoch 0, Step 1193: train/loss = 0.5164788961410522, train/raw-loss = 0.4553923010826111, train/logprobs = tensor([[-0.6705, -1.7346],
        [-1.5853, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15271644294261932
Epoch 0, Step 1194: train/loss = 0.569604754447937, train/raw-loss = 0.5168137550354004, train/logprobs = tensor([[-1.1153, -3.3601],
        [-0.9547, -0.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13197745382785797
Epoch 0, Step 1195: train/loss = 0.5427760481834412, train/raw-loss = 0.4891236424446106, train/logprobs = tensor([[-0.8781, -4.1273],
        [-0.7849, -1.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13413108885288239
Epoch 0, Step 1196: train/loss = 0.5815210938453674, train/raw-loss = 0.5263841152191162, train/logprobs = tensor([[-1.6463, -3.6387],
        [-1.2530, -0.7296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378423273563385
Epoch 0, Step 1197: train/loss = 0.2136804759502411, train/raw-loss = 0.15132218599319458, train/logprobs = tensor([[-0.6175, -6.2148],
        [-1.7402, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15589572489261627
Epoch 0, Step 1198: train/loss = 0.41486313939094543, train/raw-loss = 0.3551507592201233, train/logprobs = tensor([[-0.8544, -4.2659],
        [-1.4203, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14928089082241058
Epoch 0, Step 1199: train/loss = 0.6380143165588379, train/raw-loss = 0.5954029560089111, train/logprobs = tensor([[-0.4390, -0.6667],
        [-0.6341, -0.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10652834922075272
Epoch 0, Step 1200: train/loss = 0.4660158157348633, train/raw-loss = 0.4135184586048126, train/logprobs = tensor([[-0.7415, -3.2438],
        [-1.0266, -1.2560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13124342262744904
Epoch 0, Step 1201: train/loss = 0.5606728196144104, train/raw-loss = 0.5149997472763062, train/logprobs = tensor([[-0.6057, -1.9927],
        [-0.9470, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11418252438306808
Epoch 0, Step 1202: train/loss = 0.26670992374420166, train/raw-loss = 0.2008172869682312, train/logprobs = tensor([[-0.7630, -8.4523],
        [-1.3866, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16473153233528137
Epoch 0, Step 1203: train/loss = 0.33524566888809204, train/raw-loss = 0.27831459045410156, train/logprobs = tensor([[-0.4493, -5.2860],
        [-1.2649, -2.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14232775568962097
Epoch 0, Step 1204: train/loss = 0.44313931465148926, train/raw-loss = 0.39336851239204407, train/logprobs = tensor([[-0.9031, -1.9813],
        [-1.4596, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12442708760499954
Epoch 0, Step 1205: train/loss = 0.5274746417999268, train/raw-loss = 0.46543827652931213, train/logprobs = tensor([[-0.8391, -2.8958],
        [-0.9567, -1.3506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15509100258350372
Epoch 0, Step 1206: train/loss = 0.43517905473709106, train/raw-loss = 0.3753572106361389, train/logprobs = tensor([[-0.7866, -4.0565],
        [-1.2576, -1.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14955461025238037
Epoch 0, Step 1207: train/loss = 0.3235936760902405, train/raw-loss = 0.26634883880615234, train/logprobs = tensor([[-0.7034, -4.8175],
        [-1.2338, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14311207830905914
Epoch 0, Step 1208: train/loss = 0.2714555859565735, train/raw-loss = 0.208855539560318, train/logprobs = tensor([[-0.7597, -4.7358],
        [-1.8987, -0.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15650010108947754
Epoch 0, Step 1209: train/loss = 0.2386559247970581, train/raw-loss = 0.17379070818424225, train/logprobs = tensor([[-0.8859, -3.3558],
        [-2.2547, -0.6123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16216304898262024
Epoch 0, Step 1210: train/loss = 0.38325443863868713, train/raw-loss = 0.31977564096450806, train/logprobs = tensor([[-0.5076, -3.1054],
        [-1.2380, -0.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1586969792842865
Epoch 0, Step 1211: train/loss = 0.24994999170303345, train/raw-loss = 0.19317308068275452, train/logprobs = tensor([[-0.6130, -5.0036],
        [-1.4672, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14194226264953613
Epoch 0, Step 1212: train/loss = 0.5131292343139648, train/raw-loss = 0.4688378572463989, train/logprobs = tensor([[-0.7629, -4.3434],
        [-0.9939, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11072848737239838
Epoch 0, Step 1213: train/loss = 0.3999277651309967, train/raw-loss = 0.34368789196014404, train/logprobs = tensor([[-0.8041, -4.6715],
        [-1.0797, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14059974253177643
Epoch 0, Step 1214: train/loss = 0.44500523805618286, train/raw-loss = 0.38398855924606323, train/logprobs = tensor([[-0.7454, -4.2441],
        [-0.9507, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15254172682762146
Epoch 0, Step 1215: train/loss = 0.41893911361694336, train/raw-loss = 0.3589375913143158, train/logprobs = tensor([[-0.7106, -6.0986],
        [-1.3356, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1500038206577301
Epoch 0, Step 1216: train/loss = 0.4808805584907532, train/raw-loss = 0.42779532074928284, train/logprobs = tensor([[-0.5834, -3.6138],
        [-1.1477, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13271312415599823
Epoch 0, Step 1217: train/loss = 0.4556663930416107, train/raw-loss = 0.40490514039993286, train/logprobs = tensor([[-1.2429, -5.5687],
        [-1.7036, -1.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12690304219722748
Epoch 0, Step 1218: train/loss = 0.43202200531959534, train/raw-loss = 0.37166154384613037, train/logprobs = tensor([[-0.6813, -3.8838],
        [-1.2135, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1509011834859848
Epoch 0, Step 1219: train/loss = 0.3533557653427124, train/raw-loss = 0.2799210250377655, train/logprobs = tensor([[-0.8671, -6.6854],
        [-1.5977, -1.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18358686566352844
Epoch 0, Step 1220: train/loss = 0.7096529603004456, train/raw-loss = 0.6618656516075134, train/logprobs = tensor([[-0.7262, -0.7376],
        [-0.7593, -0.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11946827173233032
Epoch 0, Step 1221: train/loss = 0.4012697637081146, train/raw-loss = 0.3605414927005768, train/logprobs = tensor([[-0.4886, -3.4486],
        [-0.8605, -0.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10182066261768341
Epoch 0, Step 1222: train/loss = 0.49332407116889954, train/raw-loss = 0.4384506642818451, train/logprobs = tensor([[-0.8449, -4.0759],
        [-1.8148, -1.4441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13718345761299133
Epoch 0, Step 1223: train/loss = 0.35987234115600586, train/raw-loss = 0.3122553825378418, train/logprobs = tensor([[-0.5777, -3.6777],
        [-1.1216, -0.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11904245615005493
Epoch 0, Step 1224: train/loss = 0.48090073466300964, train/raw-loss = 0.4394455552101135, train/logprobs = tensor([[-0.3266, -2.5540],
        [-0.6316, -0.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10363800078630447
Epoch 0, Step 1225: train/loss = 0.4088321328163147, train/raw-loss = 0.36473003029823303, train/logprobs = tensor([[-0.5080, -2.8567],
        [-0.7945, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11025528609752655
Epoch 0, Step 1226: train/loss = 0.467646062374115, train/raw-loss = 0.41819411516189575, train/logprobs = tensor([[-0.7647, -3.2036],
        [-0.8065, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12362995743751526
Epoch 0, Step 1227: train/loss = 0.5071195960044861, train/raw-loss = 0.45239922404289246, train/logprobs = tensor([[-1.1480, -2.3690],
        [-1.2049, -0.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368008553981781
Epoch 0, Step 1228: train/loss = 0.5605299472808838, train/raw-loss = 0.5034064650535583, train/logprobs = tensor([[-0.6348, -1.7808],
        [-0.8618, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14280861616134644
Epoch 0, Step 1229: train/loss = 0.38718217611312866, train/raw-loss = 0.338884562253952, train/logprobs = tensor([[-0.5063, -6.4927],
        [-0.8178, -0.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12074406445026398
Epoch 0, Step 1230: train/loss = 0.6689060926437378, train/raw-loss = 0.6131201982498169, train/logprobs = tensor([[-1.5609, -2.0725],
        [-1.7445, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13946455717086792
Epoch 0, Step 1231: train/loss = 0.46974727511405945, train/raw-loss = 0.40874677896499634, train/logprobs = tensor([[-0.8752, -2.1109],
        [-1.3837, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15250122547149658
Epoch 0, Step 1232: train/loss = 0.856155276298523, train/raw-loss = 0.8146124482154846, train/logprobs = tensor([[-3.1704, -5.7784],
        [-2.0163, -2.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10385710000991821
Epoch 0, Step 1233: train/loss = 0.5623363852500916, train/raw-loss = 0.5057685375213623, train/logprobs = tensor([[-0.5246, -1.5617],
        [-0.7910, -0.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14141957461833954
Epoch 0, Step 1234: train/loss = 0.4001619219779968, train/raw-loss = 0.3463270366191864, train/logprobs = tensor([[-0.7394, -3.0882],
        [-1.3657, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13458721339702606
Epoch 0, Step 1235: train/loss = 0.6908215284347534, train/raw-loss = 0.6413155794143677, train/logprobs = tensor([[-1.3948, -4.9044],
        [-0.8679, -1.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12376481294631958
Epoch 0, Step 1236: train/loss = 0.3661249279975891, train/raw-loss = 0.3137019872665405, train/logprobs = tensor([[-0.3880, -5.3217],
        [-0.8422, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13105729222297668
Epoch 0, Step 1237: train/loss = 0.32608652114868164, train/raw-loss = 0.2674598693847656, train/logprobs = tensor([[-0.7309, -6.1074],
        [-1.5206, -1.3252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14656664431095123
Epoch 0, Step 1238: train/loss = 0.47264009714126587, train/raw-loss = 0.41682010889053345, train/logprobs = tensor([[-0.6438, -3.8689],
        [-1.2132, -1.5420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13954994082450867
Epoch 0, Step 1239: train/loss = 0.5624734163284302, train/raw-loss = 0.5179920196533203, train/logprobs = tensor([[-0.7847, -2.7129],
        [-0.7364, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11120341718196869
Epoch 0, Step 1240: train/loss = 0.5049172043800354, train/raw-loss = 0.4477936327457428, train/logprobs = tensor([[-1.0920, -5.0925],
        [-1.7729, -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1428089141845703
Epoch 0, Step 1241: train/loss = 0.3785535991191864, train/raw-loss = 0.3145396113395691, train/logprobs = tensor([[-0.6373, -2.7460],
        [-1.5787, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16003495454788208
Epoch 0, Step 1242: train/loss = 0.4752207100391388, train/raw-loss = 0.42309752106666565, train/logprobs = tensor([[-0.7055, -2.7108],
        [-1.3503, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13030794262886047
Epoch 0, Step 1243: train/loss = 0.5214558243751526, train/raw-loss = 0.4637320637702942, train/logprobs = tensor([[-0.6139, -1.7777],
        [-1.2272, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14430958032608032
Epoch 0, Step 1244: train/loss = 0.41430652141571045, train/raw-loss = 0.3560338616371155, train/logprobs = tensor([[-0.6599, -2.1397],
        [-1.2290, -0.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14568166434764862
Epoch 0, Step 1245: train/loss = 0.29319754242897034, train/raw-loss = 0.22215212881565094, train/logprobs = tensor([[-0.5573, -4.2793],
        [-1.8088, -1.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1776135414838791
Epoch 0, Step 1246: train/loss = 0.2808961868286133, train/raw-loss = 0.22276334464550018, train/logprobs = tensor([[-0.6696, -3.3060],
        [-1.6052, -0.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14533212780952454
Epoch 0, Step 1247: train/loss = 0.4525817036628723, train/raw-loss = 0.38984012603759766, train/logprobs = tensor([[-1.0768, -4.4910],
        [-1.0380, -1.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15685398876667023
Epoch 0, Step 1248: train/loss = 0.5051054954528809, train/raw-loss = 0.4466495215892792, train/logprobs = tensor([[-0.6143, -2.1248],
        [-1.1781, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14613986015319824
Epoch 0, Step 1249: train/loss = 0.545054018497467, train/raw-loss = 0.4854322075843811, train/logprobs = tensor([[-0.7899, -1.6987],
        [-1.2454, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14905448257923126
Epoch 0, Step 1250: train/loss = 0.5300694108009338, train/raw-loss = 0.4628126621246338, train/logprobs = tensor([[-0.7279, -2.2651],
        [-1.0814, -1.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814188659191132
Epoch 0, Step 1251: train/loss = 0.41653239727020264, train/raw-loss = 0.351875901222229, train/logprobs = tensor([[-0.4646, -4.3091],
        [-1.2180, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16164124011993408
Epoch 0, Step 1252: train/loss = 0.2796792685985565, train/raw-loss = 0.20591142773628235, train/logprobs = tensor([[-0.7469, -5.5649],
        [-1.9752, -1.6293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18441957235336304
Epoch 0, Step 1253: train/loss = 0.43650269508361816, train/raw-loss = 0.38073253631591797, train/logprobs = tensor([[-0.6355, -2.3152],
        [-1.2631, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1394253373146057
Epoch 0, Step 1254: train/loss = 0.4698334336280823, train/raw-loss = 0.4165114760398865, train/logprobs = tensor([[-0.4125, -2.6150],
        [-0.8839, -0.7954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333048790693283
Epoch 0, Step 1255: train/loss = 0.6864429712295532, train/raw-loss = 0.6379841566085815, train/logprobs = tensor([[-0.5597, -0.7751],
        [-0.8744, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1211472898721695
Epoch 0, Step 1256: train/loss = 0.37789133191108704, train/raw-loss = 0.3189350366592407, train/logprobs = tensor([[-1.0843, -2.3458],
        [-2.4623, -1.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14739081263542175
Epoch 0, Step 1257: train/loss = 0.515999972820282, train/raw-loss = 0.4610868990421295, train/logprobs = tensor([[-0.4858, -2.3910],
        [-0.7688, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13728269934654236
Epoch 0, Step 1258: train/loss = 0.37508368492126465, train/raw-loss = 0.31802985072135925, train/logprobs = tensor([[-0.7256, -3.3566],
        [-1.5967, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1426345556974411
Epoch 0, Step 1259: train/loss = 0.6457282304763794, train/raw-loss = 0.5883814692497253, train/logprobs = tensor([[-0.4599, -1.1546],
        [-0.8577, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14336681365966797
Epoch 0, Step 1260: train/loss = 0.4639517664909363, train/raw-loss = 0.39675575494766235, train/logprobs = tensor([[-0.7036, -6.5313],
        [-1.6400, -2.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16799001395702362
Epoch 0, Step 1261: train/loss = 0.514937162399292, train/raw-loss = 0.4329472780227661, train/logprobs = tensor([[-0.6835, -2.7854],
        [-1.5942, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2049746960401535
Epoch 0, Step 1262: train/loss = 0.42956870794296265, train/raw-loss = 0.3743853271007538, train/logprobs = tensor([[-0.6721, -3.8610],
        [-1.2227, -1.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379583775997162
Epoch 0, Step 1263: train/loss = 0.46379944682121277, train/raw-loss = 0.4082905948162079, train/logprobs = tensor([[-0.8672, -3.2479],
        [-1.1507, -1.0072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13877210021018982
Epoch 0, Step 1264: train/loss = 0.33095085620880127, train/raw-loss = 0.27050071954727173, train/logprobs = tensor([[-0.8399, -3.8913],
        [-1.4128, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15112534165382385
Epoch 0, Step 1265: train/loss = 0.4698697030544281, train/raw-loss = 0.4071328043937683, train/logprobs = tensor([[-0.7659, -2.6886],
        [-1.6044, -0.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15684223175048828
Epoch 0, Step 1266: train/loss = 0.426768958568573, train/raw-loss = 0.3686736822128296, train/logprobs = tensor([[-1.0615, -6.5373],
        [-1.3763, -1.2446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14523820579051971
Epoch 0, Step 1267: train/loss = 0.23736712336540222, train/raw-loss = 0.1748599261045456, train/logprobs = tensor([[-0.7583, -4.2798],
        [-1.8876, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15626797080039978
Epoch 0, Step 1268: train/loss = 0.31374746561050415, train/raw-loss = 0.25422680377960205, train/logprobs = tensor([[-0.7654, -7.0357],
        [-2.0662, -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880162477493286
Epoch 0, Step 1269: train/loss = 0.39333081245422363, train/raw-loss = 0.34013426303863525, train/logprobs = tensor([[-0.7969, -3.6188],
        [-1.7536, -1.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13299134373664856
Epoch 0, Step 1270: train/loss = 0.5220639109611511, train/raw-loss = 0.46701860427856445, train/logprobs = tensor([[-0.8481, -3.4390],
        [-1.1879, -1.3326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13761325180530548
Epoch 0, Step 1271: train/loss = 0.5518022775650024, train/raw-loss = 0.5052767992019653, train/logprobs = tensor([[-0.6759, -3.3884],
        [-0.8230, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11631356179714203
Epoch 0, Step 1272: train/loss = 0.3351304233074188, train/raw-loss = 0.2759850025177002, train/logprobs = tensor([[-0.8164, -3.7670],
        [-1.6168, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14786356687545776
Epoch 0, Step 1273: train/loss = 0.5461176037788391, train/raw-loss = 0.48771989345550537, train/logprobs = tensor([[-0.9783, -2.6315],
        [-1.0202, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14599435031414032
Epoch 0, Step 1274: train/loss = 0.5000505447387695, train/raw-loss = 0.4383505880832672, train/logprobs = tensor([[-0.3951, -3.0077],
        [-0.8733, -1.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15424993634223938
Epoch 0, Step 1275: train/loss = 0.4173845052719116, train/raw-loss = 0.356009304523468, train/logprobs = tensor([[-0.4862, -2.2304],
        [-1.2662, -0.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15343791246414185
Epoch 0, Step 1276: train/loss = 0.3485186994075775, train/raw-loss = 0.29814276099205017, train/logprobs = tensor([[-0.5890, -7.0693],
        [-1.1913, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12593987584114075
Epoch 0, Step 1277: train/loss = 0.5165390372276306, train/raw-loss = 0.4662021994590759, train/logprobs = tensor([[-0.6512, -1.6711],
        [-0.9292, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12584207952022552
Epoch 0, Step 1278: train/loss = 0.28404825925827026, train/raw-loss = 0.22136221826076508, train/logprobs = tensor([[-0.3966, -4.3413],
        [-1.5258, -1.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15671508014202118
Epoch 0, Step 1279: train/loss = 0.2825840711593628, train/raw-loss = 0.21221786737442017, train/logprobs = tensor([[-0.6734, -5.6683],
        [-1.6708, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1759154498577118
Epoch 0, Step 1280: train/loss = 0.35833901166915894, train/raw-loss = 0.29558026790618896, train/logprobs = tensor([[-0.5557, -4.7114],
        [-1.3702, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15689674019813538
Epoch 0, Step 1281: train/loss = 0.39139270782470703, train/raw-loss = 0.3312981128692627, train/logprobs = tensor([[-0.6668, -4.0751],
        [-1.1244, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15023648738861084
Epoch 0, Step 1282: train/loss = 0.511564314365387, train/raw-loss = 0.46554529666900635, train/logprobs = tensor([[-0.3971, -2.3684],
        [-0.6642, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504751443862915
Epoch 0, Step 1283: train/loss = 0.5427239537239075, train/raw-loss = 0.487745076417923, train/logprobs = tensor([[-0.4046, -2.0432],
        [-0.9043, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13744716346263885
Epoch 0, Step 1284: train/loss = 0.5036636590957642, train/raw-loss = 0.45480799674987793, train/logprobs = tensor([[-0.4396, -3.8485],
        [-0.7514, -0.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12213924527168274
Epoch 0, Step 1285: train/loss = 0.2410709410905838, train/raw-loss = 0.18065282702445984, train/logprobs = tensor([[-0.7519, -7.4179],
        [-1.9316, -1.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15104524791240692
Epoch 0, Step 1286: train/loss = 0.2634443938732147, train/raw-loss = 0.2110482007265091, train/logprobs = tensor([[-0.5705, -4.7891],
        [-1.6507, -1.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099044561386108
Epoch 0, Step 1287: train/loss = 0.45268434286117554, train/raw-loss = 0.396356999874115, train/logprobs = tensor([[-0.4900, -4.8048],
        [-1.2299, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14081844687461853
Epoch 0, Step 1288: train/loss = 0.6667269468307495, train/raw-loss = 0.6127640008926392, train/logprobs = tensor([[-1.0996, -2.8892],
        [-0.8730, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13490740954875946
Epoch 0, Step 1289: train/loss = 0.38542377948760986, train/raw-loss = 0.33187413215637207, train/logprobs = tensor([[-0.7255, -4.0911],
        [-1.6109, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13387417793273926
Epoch 0, Step 1290: train/loss = 0.39363324642181396, train/raw-loss = 0.3392431139945984, train/logprobs = tensor([[-0.6154, -3.7650],
        [-1.3042, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13597533106803894
Epoch 0, Step 1291: train/loss = 0.40423253178596497, train/raw-loss = 0.34649279713630676, train/logprobs = tensor([[-1.7909, -9.7685],
        [-2.2245, -2.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14434930682182312
Epoch 0, Step 1292: train/loss = 0.3412317931652069, train/raw-loss = 0.27140840888023376, train/logprobs = tensor([[-0.6779, -5.2640],
        [-1.7702, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17455844581127167
Epoch 0, Step 1293: train/loss = 0.2926799952983856, train/raw-loss = 0.2217809557914734, train/logprobs = tensor([[-0.7750, -4.9196],
        [-2.3704, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1772475689649582
Epoch 0, Step 1294: train/loss = 0.41676265001296997, train/raw-loss = 0.3510175943374634, train/logprobs = tensor([[-0.8594, -2.8259],
        [-1.8293, -0.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16436272859573364
Epoch 0, Step 1295: train/loss = 0.38195568323135376, train/raw-loss = 0.3303989768028259, train/logprobs = tensor([[-0.8270, -5.3808],
        [-1.8304, -2.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1288917064666748
Epoch 0, Step 1296: train/loss = 0.29405391216278076, train/raw-loss = 0.23739704489707947, train/logprobs = tensor([[-0.7368, -3.4251],
        [-1.7353, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141642227768898
Epoch 0, Step 1297: train/loss = 0.41315406560897827, train/raw-loss = 0.3551878333091736, train/logprobs = tensor([[-0.6308, -6.5270],
        [-1.0829, -2.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14491555094718933
Epoch 0, Step 1298: train/loss = 0.45164668560028076, train/raw-loss = 0.38643157482147217, train/logprobs = tensor([[-0.9289, -1.6750],
        [-1.9559, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630377471446991
Epoch 0, Step 1299: train/loss = 0.34717807173728943, train/raw-loss = 0.28988125920295715, train/logprobs = tensor([[-0.5459, -4.9349],
        [-1.6368, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14324210584163666
Epoch 0, Step 1300: train/loss = 0.483422189950943, train/raw-loss = 0.4189453721046448, train/logprobs = tensor([[-0.7725, -5.0465],
        [-1.4063, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16119199991226196
Epoch 0, Step 1301: train/loss = 0.5401713848114014, train/raw-loss = 0.47575563192367554, train/logprobs = tensor([[-0.7944, -1.9099],
        [-1.1495, -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1610393226146698
Epoch 0, Step 1302: train/loss = 0.5038771629333496, train/raw-loss = 0.45119914412498474, train/logprobs = tensor([[-0.5201, -1.3438],
        [-1.0956, -0.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13169501721858978
Epoch 0, Step 1303: train/loss = 0.49783027172088623, train/raw-loss = 0.44780251383781433, train/logprobs = tensor([[-0.3711, -2.5912],
        [-1.0351, -0.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12506943941116333
Epoch 0, Step 1304: train/loss = 0.5093010067939758, train/raw-loss = 0.4496791660785675, train/logprobs = tensor([[-0.5671, -2.7528],
        [-1.5116, -1.3854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490546315908432
Epoch 0, Step 1305: train/loss = 0.517254114151001, train/raw-loss = 0.4586775004863739, train/logprobs = tensor([[-1.9428, -5.6816],
        [-1.7740, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14644142985343933
Epoch 0, Step 1306: train/loss = 0.3619230091571808, train/raw-loss = 0.2981921434402466, train/logprobs = tensor([[-1.6055, -5.1187],
        [-2.0627, -1.3964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1593272089958191
Epoch 0, Step 1307: train/loss = 0.48997023701667786, train/raw-loss = 0.4462003707885742, train/logprobs = tensor([[-0.8057, -1.3104],
        [-1.3870, -0.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10942462086677551
Epoch 0, Step 1308: train/loss = 0.4917167127132416, train/raw-loss = 0.4378070533275604, train/logprobs = tensor([[-0.4979, -3.7219],
        [-1.4163, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347740888595581
Epoch 0, Step 1309: train/loss = 0.42998841404914856, train/raw-loss = 0.37271857261657715, train/logprobs = tensor([[-0.7562, -1.8080],
        [-1.3881, -0.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431746929883957
Epoch 0, Step 1310: train/loss = 0.4592585563659668, train/raw-loss = 0.40325209498405457, train/logprobs = tensor([[-0.5794, -3.2865],
        [-1.2439, -0.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14001618325710297
Epoch 0, Step 1311: train/loss = 0.372698575258255, train/raw-loss = 0.3163185715675354, train/logprobs = tensor([[-0.5810, -3.5515],
        [-1.5640, -1.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14094999432563782
Epoch 0, Step 1312: train/loss = 0.48878657817840576, train/raw-loss = 0.4282410740852356, train/logprobs = tensor([[-0.6966, -2.4259],
        [-1.4814, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151363804936409
Epoch 0, Step 1313: train/loss = 0.825447678565979, train/raw-loss = 0.7669345736503601, train/logprobs = tensor([[-1.5218, -1.7409],
        [-0.8600, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14628291130065918
Epoch 0, Step 1314: train/loss = 0.7686559557914734, train/raw-loss = 0.7154799699783325, train/logprobs = tensor([[-1.2905, -1.2538],
        [-1.0306, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13294005393981934
Epoch 0, Step 1315: train/loss = 0.2863503694534302, train/raw-loss = 0.2271774560213089, train/logprobs = tensor([[-0.5834, -8.5462],
        [-1.6323, -1.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479322910308838
Epoch 0, Step 1316: train/loss = 0.4744873642921448, train/raw-loss = 0.42115214467048645, train/logprobs = tensor([[-0.6163, -2.0804],
        [-1.2499, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333380937576294
Epoch 0, Step 1317: train/loss = 0.5691016912460327, train/raw-loss = 0.5087147951126099, train/logprobs = tensor([[-0.4945, -1.8847],
        [-1.3350, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15096722543239594
Epoch 0, Step 1318: train/loss = 0.36918047070503235, train/raw-loss = 0.3074084520339966, train/logprobs = tensor([[-0.6145, -5.3933],
        [-1.1629, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15443001687526703
Epoch 0, Step 1319: train/loss = 0.3408393859863281, train/raw-loss = 0.27726292610168457, train/logprobs = tensor([[-0.6161, -3.2475],
        [-1.6855, -0.4021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15894106030464172
Epoch 0, Step 1320: train/loss = 0.4386087954044342, train/raw-loss = 0.38056325912475586, train/logprobs = tensor([[-0.9604, -4.4223],
        [-1.8916, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14511390030384064
Epoch 0, Step 1321: train/loss = 0.5625795125961304, train/raw-loss = 0.5040781497955322, train/logprobs = tensor([[-0.4820, -1.6871],
        [-0.9237, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1462535560131073
Epoch 0, Step 1322: train/loss = 0.4506663680076599, train/raw-loss = 0.3923165202140808, train/logprobs = tensor([[-0.5109, -1.8105],
        [-1.1837, -0.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14587455987930298
Epoch 0, Step 1323: train/loss = 0.5568828582763672, train/raw-loss = 0.5161349177360535, train/logprobs = tensor([[-0.6352, -2.8695],
        [-0.6056, -0.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10186977684497833
Epoch 0, Step 1324: train/loss = 0.4434143900871277, train/raw-loss = 0.3806082308292389, train/logprobs = tensor([[-0.4762, -4.8436],
        [-0.9295, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15701550245285034
Epoch 0, Step 1325: train/loss = 0.6560025215148926, train/raw-loss = 0.6114456653594971, train/logprobs = tensor([[-0.3268, -2.0991],
        [-0.6512, -1.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139212548732758
Epoch 0, Step 1326: train/loss = 0.4284229874610901, train/raw-loss = 0.3611932694911957, train/logprobs = tensor([[-1.3989, -5.0982],
        [-1.5202, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16807430982589722
Epoch 0, Step 1327: train/loss = 0.4821743965148926, train/raw-loss = 0.41491758823394775, train/logprobs = tensor([[-1.4485, -2.9119],
        [-1.8520, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814205050468445
Epoch 0, Step 1328: train/loss = 0.38199830055236816, train/raw-loss = 0.32381072640419006, train/logprobs = tensor([[-0.7411, -3.9066],
        [-1.1765, -1.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14546895027160645
Epoch 0, Step 1329: train/loss = 0.2903147041797638, train/raw-loss = 0.22039948403835297, train/logprobs = tensor([[-1.1956, -5.6569],
        [-2.3675, -1.3419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17478805780410767
Epoch 0, Step 1330: train/loss = 0.5462156534194946, train/raw-loss = 0.4804322421550751, train/logprobs = tensor([[-1.0526, -4.8280],
        [-1.2084, -1.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16445855796337128
Epoch 0, Step 1331: train/loss = 0.3629459738731384, train/raw-loss = 0.29527851939201355, train/logprobs = tensor([[-0.8470, -2.8812],
        [-1.7319, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16916874051094055
Epoch 0, Step 1332: train/loss = 0.3094569146633148, train/raw-loss = 0.23766463994979858, train/logprobs = tensor([[-0.7909, -4.0165],
        [-1.5423, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1794806718826294
Epoch 0, Step 1333: train/loss = 0.4883507788181305, train/raw-loss = 0.42906397581100464, train/logprobs = tensor([[-0.6958, -2.8155],
        [-1.2450, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14821700751781464
Epoch 0, Step 1334: train/loss = 0.6061476469039917, train/raw-loss = 0.5444703698158264, train/logprobs = tensor([[-1.5993, -3.1005],
        [-2.0692, -1.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541932225227356
Epoch 0, Step 1335: train/loss = 0.37625598907470703, train/raw-loss = 0.31646570563316345, train/logprobs = tensor([[-1.8472, -5.4970],
        [-2.6665, -1.3021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14947570860385895
Epoch 0, Step 1336: train/loss = 0.3862465023994446, train/raw-loss = 0.32792210578918457, train/logprobs = tensor([[-0.6755, -6.6307],
        [-1.3272, -2.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14581090211868286
Epoch 0, Step 1337: train/loss = 0.4968581795692444, train/raw-loss = 0.45735275745391846, train/logprobs = tensor([[-0.3958, -4.8721],
        [-0.6995, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09876345098018646
Epoch 0, Step 1338: train/loss = 0.3774982690811157, train/raw-loss = 0.30242374539375305, train/logprobs = tensor([[-0.6108, -3.4840],
        [-1.5763, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1876862645149231
Epoch 0, Step 1339: train/loss = 0.38515427708625793, train/raw-loss = 0.31524986028671265, train/logprobs = tensor([[-0.9536, -3.1466],
        [-2.0818, -1.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174761101603508
Epoch 0, Step 1340: train/loss = 0.253715842962265, train/raw-loss = 0.18698745965957642, train/logprobs = tensor([[-0.6207, -4.3424],
        [-2.0145, -1.2960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1668209433555603
Epoch 0, Step 1341: train/loss = 0.36565136909484863, train/raw-loss = 0.3191227614879608, train/logprobs = tensor([[-0.7808, -3.1804],
        [-1.6884, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11632155627012253
Epoch 0, Step 1342: train/loss = 0.6477370262145996, train/raw-loss = 0.60291588306427, train/logprobs = tensor([[-0.7838, -2.1722],
        [-0.5259, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11205284297466278
Epoch 0, Step 1343: train/loss = 0.26569661498069763, train/raw-loss = 0.20218247175216675, train/logprobs = tensor([[-0.7401, -3.4769],
        [-2.1418, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1587853580713272
Epoch 0, Step 1344: train/loss = 0.7150769829750061, train/raw-loss = 0.6630827188491821, train/logprobs = tensor([[-1.7388, -3.6819],
        [-0.9280, -0.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12998560070991516
Epoch 0, Step 1345: train/loss = 0.5403935313224792, train/raw-loss = 0.4736085534095764, train/logprobs = tensor([[-0.9070, -2.3658],
        [-1.6675, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16696250438690186
Epoch 0, Step 1346: train/loss = 0.5382148623466492, train/raw-loss = 0.46874281764030457, train/logprobs = tensor([[-1.0054, -2.2874],
        [-1.4714, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17368021607398987
Epoch 0, Step 1347: train/loss = 0.4600895643234253, train/raw-loss = 0.39886024594306946, train/logprobs = tensor([[-0.8721, -2.8604],
        [-1.6602, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1530732363462448
Epoch 0, Step 1348: train/loss = 0.4846445322036743, train/raw-loss = 0.441402405500412, train/logprobs = tensor([[-0.7526, -1.7637],
        [-1.5310, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081053763628006
Epoch 0, Step 1349: train/loss = 0.4203264117240906, train/raw-loss = 0.36187583208084106, train/logprobs = tensor([[-0.9024, -2.3885],
        [-1.6654, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14612652361392975
Epoch 0, Step 1350: train/loss = 0.3801608681678772, train/raw-loss = 0.3276010751724243, train/logprobs = tensor([[-0.6044, -6.7869],
        [-1.4032, -1.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313994824886322
Epoch 0, Step 1351: train/loss = 0.47879576683044434, train/raw-loss = 0.4199310541152954, train/logprobs = tensor([[-1.1035, -2.7332],
        [-1.9251, -1.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471618115901947
Epoch 0, Step 1352: train/loss = 0.5520193576812744, train/raw-loss = 0.5124596357345581, train/logprobs = tensor([[-0.5736, -1.8395],
        [-0.8546, -0.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09889937937259674
Epoch 0, Step 1353: train/loss = 0.5843884348869324, train/raw-loss = 0.5406169891357422, train/logprobs = tensor([[-0.5481, -3.8292],
        [-0.8797, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10942846536636353
Epoch 0, Step 1354: train/loss = 0.43694067001342773, train/raw-loss = 0.36871135234832764, train/logprobs = tensor([[-0.6137, -1.9817],
        [-1.7107, -1.2193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17057335376739502
Epoch 0, Step 1355: train/loss = 0.20999795198440552, train/raw-loss = 0.15398763120174408, train/logprobs = tensor([[-0.7327, -7.0189],
        [-1.7794, -0.9858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.140025794506073
Epoch 0, Step 1356: train/loss = 0.48108726739883423, train/raw-loss = 0.4289610683917999, train/logprobs = tensor([[-0.9126, -2.8125],
        [-1.4383, -0.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13031552731990814
Epoch 0, Step 1357: train/loss = 0.6064938902854919, train/raw-loss = 0.5525180101394653, train/logprobs = tensor([[-0.4670, -1.0950],
        [-0.9072, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13493981957435608
Epoch 0, Step 1358: train/loss = 0.30493906140327454, train/raw-loss = 0.24127629399299622, train/logprobs = tensor([[-0.5964, -3.8561],
        [-1.8478, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591569483280182
Epoch 0, Step 1359: train/loss = 0.5688683986663818, train/raw-loss = 0.500119686126709, train/logprobs = tensor([[-0.4830, -2.6380],
        [-1.1608, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17187167704105377
Epoch 0, Step 1360: train/loss = 0.341667503118515, train/raw-loss = 0.29065537452697754, train/logprobs = tensor([[-0.6170, -3.3069],
        [-1.4005, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1275302767753601
Epoch 0, Step 1361: train/loss = 0.36753901839256287, train/raw-loss = 0.3073660731315613, train/logprobs = tensor([[-0.7962, -4.1141],
        [-1.3345, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15043237805366516
Epoch 0, Step 1362: train/loss = 0.40788814425468445, train/raw-loss = 0.3383139967918396, train/logprobs = tensor([[-0.6578, -3.3728],
        [-2.0492, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.173935204744339
Epoch 0, Step 1363: train/loss = 0.5437153577804565, train/raw-loss = 0.4984993040561676, train/logprobs = tensor([[-0.4601, -2.1212],
        [-0.9397, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11304017156362534
Epoch 0, Step 1364: train/loss = 0.4278242886066437, train/raw-loss = 0.3705121874809265, train/logprobs = tensor([[-0.4507, -3.7847],
        [-1.0339, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14328013360500336
Epoch 0, Step 1365: train/loss = 0.4075564742088318, train/raw-loss = 0.3540763258934021, train/logprobs = tensor([[-0.3611, -4.4868],
        [-0.9773, -0.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13370031118392944
Epoch 0, Step 1366: train/loss = 0.5476428270339966, train/raw-loss = 0.4981301426887512, train/logprobs = tensor([[-0.3956, -2.9818],
        [-0.7454, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12378168106079102
Epoch 0, Step 1367: train/loss = 0.3537423610687256, train/raw-loss = 0.29575249552726746, train/logprobs = tensor([[-0.5915, -4.4936],
        [-1.9172, -1.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14497460424900055
Epoch 0, Step 1368: train/loss = 0.5801197290420532, train/raw-loss = 0.529748797416687, train/logprobs = tensor([[-0.6149, -1.7192],
        [-0.9797, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12592735886573792
Epoch 0, Step 1369: train/loss = 0.4418889284133911, train/raw-loss = 0.3731320798397064, train/logprobs = tensor([[-0.5108, -1.8306],
        [-2.0928, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1718922257423401
Epoch 0, Step 1370: train/loss = 0.5221211910247803, train/raw-loss = 0.4635036289691925, train/logprobs = tensor([[-0.7219, -1.8093],
        [-1.2637, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14654403924942017
Epoch 0, Step 1371: train/loss = 0.4636384844779968, train/raw-loss = 0.4082317352294922, train/logprobs = tensor([[-0.5740, -3.3248],
        [-1.2463, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13851675391197205
Epoch 0, Step 1372: train/loss = 0.30209022760391235, train/raw-loss = 0.23938143253326416, train/logprobs = tensor([[-0.7020, -5.4740],
        [-1.7844, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567719578742981
Epoch 0, Step 1373: train/loss = 0.5480473041534424, train/raw-loss = 0.5006749033927917, train/logprobs = tensor([[-1.3160, -2.2713],
        [-2.2257, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11843088269233704
Epoch 0, Step 1374: train/loss = 0.4318307638168335, train/raw-loss = 0.38062888383865356, train/logprobs = tensor([[-0.4488, -3.3249],
        [-1.1776, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12800469994544983
Epoch 0, Step 1375: train/loss = 0.3329331874847412, train/raw-loss = 0.2795739471912384, train/logprobs = tensor([[-0.7753, -5.6706],
        [-1.5215, -1.6186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13339810073375702
Epoch 0, Step 1376: train/loss = 0.28987178206443787, train/raw-loss = 0.22387361526489258, train/logprobs = tensor([[-0.9560, -4.0451],
        [-2.4842, -0.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16499537229537964
Epoch 0, Step 1377: train/loss = 0.47880497574806213, train/raw-loss = 0.4255024194717407, train/logprobs = tensor([[-0.5043, -4.4912],
        [-1.0946, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13325636088848114
Epoch 0, Step 1378: train/loss = 0.48959460854530334, train/raw-loss = 0.4349912405014038, train/logprobs = tensor([[-0.8939, -2.9902],
        [-1.2208, -0.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13650831580162048
Epoch 0, Step 1379: train/loss = 0.5220274329185486, train/raw-loss = 0.4551757574081421, train/logprobs = tensor([[-0.9448, -2.6536],
        [-1.6501, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16712912917137146
Epoch 0, Step 1380: train/loss = 0.23784253001213074, train/raw-loss = 0.16854643821716309, train/logprobs = tensor([[-0.4982, -5.3159],
        [-1.5623, -1.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17324024438858032
Epoch 0, Step 1381: train/loss = 0.35753411054611206, train/raw-loss = 0.29073643684387207, train/logprobs = tensor([[-0.5271, -5.5454],
        [-1.2558, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1669941246509552
Epoch 0, Step 1382: train/loss = 0.377841591835022, train/raw-loss = 0.3144688904285431, train/logprobs = tensor([[-0.9072, -4.6462],
        [-1.5327, -1.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.158431738615036
Epoch 0, Step 1383: train/loss = 0.30341050028800964, train/raw-loss = 0.24769175052642822, train/logprobs = tensor([[-0.8669, -4.6557],
        [-1.8605, -1.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13929685950279236
Epoch 0, Step 1384: train/loss = 0.48472318053245544, train/raw-loss = 0.42484909296035767, train/logprobs = tensor([[-0.5987, -3.4858],
        [-1.2952, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968523383140564
Epoch 0, Step 1385: train/loss = 0.406247615814209, train/raw-loss = 0.3273991048336029, train/logprobs = tensor([[-0.7581, -2.4517],
        [-2.3627, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19712123274803162
Epoch 0, Step 1386: train/loss = 0.34375065565109253, train/raw-loss = 0.2661713659763336, train/logprobs = tensor([[-0.8388, -2.8329],
        [-1.8697, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19394820928573608
Epoch 0, Step 1387: train/loss = 0.5098953247070312, train/raw-loss = 0.44220662117004395, train/logprobs = tensor([[-0.5574, -1.4816],
        [-1.5625, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16922180354595184
Epoch 0, Step 1388: train/loss = 0.32622024416923523, train/raw-loss = 0.27067843079566956, train/logprobs = tensor([[-0.9683, -4.1147],
        [-1.7648, -0.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885459303855896
Epoch 0, Step 1389: train/loss = 0.5252924561500549, train/raw-loss = 0.4554549753665924, train/logprobs = tensor([[-1.0320, -3.1008],
        [-1.5584, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745937019586563
Epoch 0, Step 1390: train/loss = 0.47306376695632935, train/raw-loss = 0.41411498188972473, train/logprobs = tensor([[-0.5899, -1.9470],
        [-1.1038, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14737197756767273
Epoch 0, Step 1391: train/loss = 0.4364794194698334, train/raw-loss = 0.3746054172515869, train/logprobs = tensor([[-0.6268, -2.7537],
        [-1.3115, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15468496084213257
Epoch 0, Step 1392: train/loss = 0.3439823389053345, train/raw-loss = 0.2898607850074768, train/logprobs = tensor([[-0.6895, -6.1403],
        [-1.3071, -1.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13530385494232178
Epoch 0, Step 1393: train/loss = 0.3172043561935425, train/raw-loss = 0.24431107938289642, train/logprobs = tensor([[-0.5818, -6.7721],
        [-1.9995, -2.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18223324418067932
Epoch 0, Step 1394: train/loss = 0.39586788415908813, train/raw-loss = 0.32010507583618164, train/logprobs = tensor([[-0.5529, -2.0310],
        [-1.7872, -0.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18940696120262146
Epoch 0, Step 1395: train/loss = 0.413108766078949, train/raw-loss = 0.33714744448661804, train/logprobs = tensor([[-0.6959, -3.6786],
        [-1.5519, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18990328907966614
Epoch 0, Step 1396: train/loss = 0.3353661298751831, train/raw-loss = 0.2566181421279907, train/logprobs = tensor([[-0.8056, -4.9894],
        [-1.7014, -1.0784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19686995446681976
Epoch 0, Step 1397: train/loss = 0.32828575372695923, train/raw-loss = 0.2737085223197937, train/logprobs = tensor([[-0.5914, -8.8446],
        [-1.1208, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364431232213974
Epoch 0, Step 1398: train/loss = 0.20974251627922058, train/raw-loss = 0.1244855672121048, train/logprobs = tensor([[-0.8329, -4.7229],
        [-2.2085, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21314236521720886
Epoch 0, Step 1399: train/loss = 0.34292975068092346, train/raw-loss = 0.2655752897262573, train/logprobs = tensor([[-0.4639, -3.4720],
        [-2.2507, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19338616728782654
Epoch 0, Step 1400: train/loss = 0.5739336609840393, train/raw-loss = 0.502325177192688, train/logprobs = tensor([[-0.6607, -7.4624],
        [-1.5072, -2.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17902112007141113
Epoch 0, Step 1401: train/loss = 0.40535104274749756, train/raw-loss = 0.3154851794242859, train/logprobs = tensor([[-1.2918, -6.0525],
        [-2.4565, -2.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22466464340686798
Epoch 0, Step 1402: train/loss = 0.33424049615859985, train/raw-loss = 0.26858410239219666, train/logprobs = tensor([[-0.6163, -3.9105],
        [-1.6983, -1.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641409993171692
Epoch 0, Step 1403: train/loss = 0.3922434449195862, train/raw-loss = 0.33455419540405273, train/logprobs = tensor([[-1.1983, -4.1394],
        [-1.4760, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14422309398651123
Epoch 0, Step 1404: train/loss = 0.3227617144584656, train/raw-loss = 0.2644449770450592, train/logprobs = tensor([[-0.7069, -6.4866],
        [-1.9145, -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14579184353351593
Epoch 0, Step 1405: train/loss = 0.46130961179733276, train/raw-loss = 0.385589063167572, train/logprobs = tensor([[-0.7236, -4.9700],
        [-1.8730, -1.6473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18930138647556305
Epoch 0, Step 1406: train/loss = 0.5122298002243042, train/raw-loss = 0.454593688249588, train/logprobs = tensor([[-0.4546, -1.8944],
        [-1.1264, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1440901905298233
Epoch 0, Step 1407: train/loss = 0.3720417320728302, train/raw-loss = 0.31508344411849976, train/logprobs = tensor([[-0.8557, -6.4247],
        [-1.3461, -1.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14239564538002014
Epoch 0, Step 1408: train/loss = 0.19038298726081848, train/raw-loss = 0.12835291028022766, train/logprobs = tensor([[-0.6164, -8.8606],
        [-1.9264, -2.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15507516264915466
Epoch 0, Step 1409: train/loss = 0.6174287796020508, train/raw-loss = 0.558449923992157, train/logprobs = tensor([[-0.5792, -1.1696],
        [-1.0749, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474471539258957
Epoch 0, Step 1410: train/loss = 0.4035038352012634, train/raw-loss = 0.3255177140235901, train/logprobs = tensor([[-0.7315, -4.3003],
        [-2.1906, -0.9835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19496537744998932
Epoch 0, Step 1411: train/loss = 0.4702436327934265, train/raw-loss = 0.39254677295684814, train/logprobs = tensor([[-0.4299, -3.4317],
        [-1.1259, -1.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19424208998680115
Epoch 0, Step 1412: train/loss = 0.3455677628517151, train/raw-loss = 0.2786029577255249, train/logprobs = tensor([[-0.5526, -2.3013],
        [-1.9550, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1674118936061859
Epoch 0, Step 1413: train/loss = 0.35823607444763184, train/raw-loss = 0.3022764027118683, train/logprobs = tensor([[-0.7908, -3.4670],
        [-1.4763, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1398991346359253
Epoch 0, Step 1414: train/loss = 0.49760839343070984, train/raw-loss = 0.44600361585617065, train/logprobs = tensor([[-0.6682, -4.3556],
        [-1.2869, -2.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901198863983154
Epoch 0, Step 1415: train/loss = 0.5367809534072876, train/raw-loss = 0.49296504259109497, train/logprobs = tensor([[-0.4926, -1.3090],
        [-1.0860, -0.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10953979939222336
Epoch 0, Step 1416: train/loss = 0.32683706283569336, train/raw-loss = 0.2667635381221771, train/logprobs = tensor([[-0.8358, -7.0697],
        [-1.7940, -2.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15018382668495178
Epoch 0, Step 1417: train/loss = 0.27176955342292786, train/raw-loss = 0.2099754363298416, train/logprobs = tensor([[-0.4669, -5.9522],
        [-1.4305, -1.6384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15448527038097382
Epoch 0, Step 1418: train/loss = 0.4287947416305542, train/raw-loss = 0.36845195293426514, train/logprobs = tensor([[-0.7885, -2.8007],
        [-1.5045, -1.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15085691213607788
Epoch 0, Step 1419: train/loss = 0.5990714430809021, train/raw-loss = 0.5505951642990112, train/logprobs = tensor([[-0.3940, -1.4420],
        [-1.0292, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12119076400995255
Epoch 0, Step 1420: train/loss = 0.31691867113113403, train/raw-loss = 0.25741297006607056, train/logprobs = tensor([[-0.4060, -4.0266],
        [-1.4842, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1487642228603363
Epoch 0, Step 1421: train/loss = 0.5386523008346558, train/raw-loss = 0.48254457116127014, train/logprobs = tensor([[-0.5601, -2.6400],
        [-1.3419, -1.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14026927947998047
Epoch 0, Step 1422: train/loss = 0.5833609700202942, train/raw-loss = 0.5376915335655212, train/logprobs = tensor([[-0.2929, -1.1639],
        [-0.7647, -0.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1141735315322876
Epoch 0, Step 1423: train/loss = 0.3993155360221863, train/raw-loss = 0.3448869585990906, train/logprobs = tensor([[-0.4342, -3.0454],
        [-1.2020, -1.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13607141375541687
Epoch 0, Step 1424: train/loss = 0.17169901728630066, train/raw-loss = 0.0937117338180542, train/logprobs = tensor([[-0.6787, -7.3208],
        [-2.6717, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19496820867061615
Epoch 0, Step 1425: train/loss = 0.32300031185150146, train/raw-loss = 0.2666891813278198, train/logprobs = tensor([[-0.7595, -4.0006],
        [-1.9143, -2.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14077788591384888
Epoch 0, Step 1426: train/loss = 0.31509843468666077, train/raw-loss = 0.25031307339668274, train/logprobs = tensor([[-0.6756, -7.6949],
        [-1.9862, -2.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196341812610626
Epoch 0, Step 1427: train/loss = 0.46625757217407227, train/raw-loss = 0.4021297097206116, train/logprobs = tensor([[-0.6985, -2.2245],
        [-1.7450, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16031962633132935
Epoch 0, Step 1428: train/loss = 0.3382279872894287, train/raw-loss = 0.2701466679573059, train/logprobs = tensor([[-0.6001, -4.7237],
        [-1.8042, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17020326852798462
Epoch 0, Step 1429: train/loss = 0.30635935068130493, train/raw-loss = 0.24037106335163116, train/logprobs = tensor([[-0.7396, -6.1368],
        [-1.8099, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16497066617012024
Epoch 0, Step 1430: train/loss = 0.31252139806747437, train/raw-loss = 0.25209569931030273, train/logprobs = tensor([[-1.0822, -6.2988],
        [-2.2328, -2.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15106423199176788
Epoch 0, Step 1431: train/loss = 0.20131656527519226, train/raw-loss = 0.12328557670116425, train/logprobs = tensor([[ -0.7094, -11.9295],
        [ -2.2126,  -3.2226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19507747888565063
Epoch 0, Step 1432: train/loss = 0.6906715631484985, train/raw-loss = 0.6111058592796326, train/logprobs = tensor([[-0.4962, -4.5070],
        [-2.4004, -2.3359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1989143192768097
Epoch 0, Step 1433: train/loss = 0.4462483525276184, train/raw-loss = 0.39150387048721313, train/logprobs = tensor([[-0.4526, -3.2586],
        [-1.6531, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13686123490333557
Epoch 0, Step 1434: train/loss = 0.2728768289089203, train/raw-loss = 0.1966777890920639, train/logprobs = tensor([[-0.6508, -4.2281],
        [-2.3282, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19049756228923798
Epoch 0, Step 1435: train/loss = 0.39596861600875854, train/raw-loss = 0.30841702222824097, train/logprobs = tensor([[-0.7033, -6.0757],
        [-2.5261, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21887898445129395
Epoch 0, Step 1436: train/loss = 0.4718124270439148, train/raw-loss = 0.41750091314315796, train/logprobs = tensor([[-1.5067, -7.9185],
        [-1.7141, -1.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357787549495697
Epoch 0, Step 1437: train/loss = 0.4103086590766907, train/raw-loss = 0.3590160012245178, train/logprobs = tensor([[-0.4622, -7.6824],
        [-1.5343, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12823158502578735
Epoch 0, Step 1438: train/loss = 0.18570595979690552, train/raw-loss = 0.12972109019756317, train/logprobs = tensor([[-0.9000, -9.1636],
        [-2.8371, -1.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13996218144893646
Epoch 0, Step 1439: train/loss = 0.3668857216835022, train/raw-loss = 0.31948429346084595, train/logprobs = tensor([[-0.6638, -3.4006],
        [-1.9885, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11850358545780182
Epoch 0, Step 1440: train/loss = 0.39445456862449646, train/raw-loss = 0.332047700881958, train/logprobs = tensor([[-0.5842, -3.4682],
        [-1.7181, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15601718425750732
Epoch 0, Step 1441: train/loss = 0.624030351638794, train/raw-loss = 0.5596032738685608, train/logprobs = tensor([[-0.8395, -1.4830],
        [-1.4092, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16106778383255005
Epoch 0, Step 1442: train/loss = 0.15282028913497925, train/raw-loss = 0.08097688853740692, train/logprobs = tensor([[-0.8046, -5.8845],
        [-3.0199, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17960849404335022
Epoch 0, Step 1443: train/loss = 0.6279240846633911, train/raw-loss = 0.5693921446800232, train/logprobs = tensor([[-0.9447, -3.4635],
        [-1.0097, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463298797607422
Epoch 0, Step 1444: train/loss = 0.31289902329444885, train/raw-loss = 0.23444129526615143, train/logprobs = tensor([[-0.7587, -3.6549],
        [-2.8180, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19614434242248535
Epoch 0, Step 1445: train/loss = 0.462979257106781, train/raw-loss = 0.406988263130188, train/logprobs = tensor([[-0.3466, -3.0633],
        [-1.0275, -1.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13997754454612732
Epoch 0, Step 1446: train/loss = 0.4769737124443054, train/raw-loss = 0.4107764661312103, train/logprobs = tensor([[-1.1958, -7.1398],
        [-1.8562, -1.1686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654931902885437
Epoch 0, Step 1447: train/loss = 0.37575799226760864, train/raw-loss = 0.31552717089653015, train/logprobs = tensor([[-1.0476, -4.0113],
        [-1.5063, -1.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15057699382305145
Epoch 0, Step 1448: train/loss = 0.4314733147621155, train/raw-loss = 0.3596462309360504, train/logprobs = tensor([[-1.0068, -3.6309],
        [-1.3873, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17956773936748505
Epoch 0, Step 1449: train/loss = 0.5081033110618591, train/raw-loss = 0.442527174949646, train/logprobs = tensor([[-0.5200, -4.2849],
        [-1.5303, -1.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1639403998851776
Epoch 0, Step 1450: train/loss = 0.364930659532547, train/raw-loss = 0.29652875661849976, train/logprobs = tensor([[-0.4425, -3.4096],
        [-1.3871, -1.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17100480198860168
Epoch 0, Step 1451: train/loss = 0.36687880754470825, train/raw-loss = 0.2973565459251404, train/logprobs = tensor([[-0.8012, -4.6033],
        [-2.1229, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17380565404891968
Epoch 0, Step 1452: train/loss = 0.475189208984375, train/raw-loss = 0.3968980312347412, train/logprobs = tensor([[-0.5423, -5.6483],
        [-1.9994, -1.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572797417640686
Epoch 0, Step 1453: train/loss = 0.30240726470947266, train/raw-loss = 0.23756635189056396, train/logprobs = tensor([[-0.6968, -3.5116],
        [-1.9013, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16210228204727173
Epoch 0, Step 1454: train/loss = 0.34668445587158203, train/raw-loss = 0.27751588821411133, train/logprobs = tensor([[-0.7032, -4.1063],
        [-2.4509, -2.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17292152345180511
Epoch 0, Step 1455: train/loss = 0.2687247693538666, train/raw-loss = 0.19918043911457062, train/logprobs = tensor([[-0.4889, -4.4318],
        [-2.9963, -2.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1738608032464981
Epoch 0, Step 1456: train/loss = 0.2854594886302948, train/raw-loss = 0.22929948568344116, train/logprobs = tensor([[-0.7748, -7.0288],
        [-1.7530, -1.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14040005207061768
Epoch 0, Step 1457: train/loss = 0.3504485487937927, train/raw-loss = 0.29199549555778503, train/logprobs = tensor([[-0.7059, -4.1756],
        [-2.0116, -2.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.146132692694664
Epoch 0, Step 1458: train/loss = 0.6344170570373535, train/raw-loss = 0.5649659633636475, train/logprobs = tensor([[-0.6795, -1.0397],
        [-1.6604, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17362761497497559
Epoch 0, Step 1459: train/loss = 0.22929266095161438, train/raw-loss = 0.14207212626934052, train/logprobs = tensor([[-0.6157, -6.7491],
        [-2.8548, -1.9349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21805128455162048
Epoch 0, Step 1460: train/loss = 0.2818412184715271, train/raw-loss = 0.21733108162879944, train/logprobs = tensor([[-1.0504, -6.5095],
        [-2.2913, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16127532720565796
Epoch 0, Step 1461: train/loss = 0.5561022758483887, train/raw-loss = 0.47132545709609985, train/logprobs = tensor([[-0.6575, -2.3251],
        [-2.4754, -1.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21194197237491608
Epoch 0, Step 1462: train/loss = 0.38336580991744995, train/raw-loss = 0.3083847463130951, train/logprobs = tensor([[-0.6375, -3.1443],
        [-1.9761, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18745273351669312
Epoch 0, Step 1463: train/loss = 0.25254568457603455, train/raw-loss = 0.18002058565616608, train/logprobs = tensor([[-0.7548, -4.2927],
        [-2.8690, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18131273984909058
Epoch 0, Step 1464: train/loss = 0.4765155017375946, train/raw-loss = 0.4063446521759033, train/logprobs = tensor([[-0.5785, -3.5428],
        [-1.6065, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1754271239042282
Epoch 0, Step 1465: train/loss = 0.3046637773513794, train/raw-loss = 0.2477612942457199, train/logprobs = tensor([[-0.6697, -4.9457],
        [-2.3838, -2.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422562450170517
Epoch 0, Step 1466: train/loss = 0.4477323591709137, train/raw-loss = 0.378314346075058, train/logprobs = tensor([[-0.5947, -3.5784],
        [-1.4265, -1.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735450178384781
Epoch 0, Step 1467: train/loss = 0.3213375210762024, train/raw-loss = 0.2551712691783905, train/logprobs = tensor([[-0.8606, -7.2552],
        [-2.5348, -1.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16541561484336853
Epoch 0, Step 1468: train/loss = 0.4981614053249359, train/raw-loss = 0.4296116828918457, train/logprobs = tensor([[-1.3296, -6.6901],
        [-2.2039, -1.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17137429118156433
Epoch 0, Step 1469: train/loss = 0.416905015707016, train/raw-loss = 0.3533385992050171, train/logprobs = tensor([[-0.4511, -3.0144],
        [-1.1554, -1.1498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15891599655151367
Epoch 0, Step 1470: train/loss = 0.2681519687175751, train/raw-loss = 0.18358489871025085, train/logprobs = tensor([[-0.6832, -4.0161],
        [-2.0309, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21141767501831055
Epoch 0, Step 1471: train/loss = 0.47291457653045654, train/raw-loss = 0.4011211395263672, train/logprobs = tensor([[-0.4739, -2.2973],
        [-1.6486, -1.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1794835329055786
Epoch 0, Step 1472: train/loss = 0.358476459980011, train/raw-loss = 0.30903416872024536, train/logprobs = tensor([[-0.5702, -7.4117],
        [-1.1791, -1.3585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12360571324825287
Epoch 0, Step 1473: train/loss = 0.32006222009658813, train/raw-loss = 0.24603486061096191, train/logprobs = tensor([[-0.7457, -3.7100],
        [-2.0502, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18506842851638794
Epoch 0, Step 1474: train/loss = 0.4356279671192169, train/raw-loss = 0.37034934759140015, train/logprobs = tensor([[-0.7337, -2.9368],
        [-1.7743, -1.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16319648921489716
Epoch 0, Step 1475: train/loss = 0.423928439617157, train/raw-loss = 0.36488837003707886, train/logprobs = tensor([[-0.6736, -2.0556],
        [-1.8466, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1476002037525177
Epoch 0, Step 1476: train/loss = 0.5513869524002075, train/raw-loss = 0.48122769594192505, train/logprobs = tensor([[-1.0564, -3.1307],
        [-1.8875, -2.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17539797723293304
Epoch 0, Step 1477: train/loss = 0.2508397102355957, train/raw-loss = 0.18420512974262238, train/logprobs = tensor([[-0.9761, -5.3413],
        [-2.3661, -1.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16658645868301392
Epoch 0, Step 1478: train/loss = 0.6102367639541626, train/raw-loss = 0.527674674987793, train/logprobs = tensor([[-0.4818, -1.0001],
        [-1.8988, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2064051330089569
Epoch 0, Step 1479: train/loss = 0.5514718890190125, train/raw-loss = 0.46021610498428345, train/logprobs = tensor([[-0.5363, -2.6417],
        [-1.8958, -1.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22813940048217773
Epoch 0, Step 1480: train/loss = 0.4410717785358429, train/raw-loss = 0.36436542868614197, train/logprobs = tensor([[-0.7483, -4.3846],
        [-2.8749, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1917659193277359
Epoch 0, Step 1481: train/loss = 0.4142931401729584, train/raw-loss = 0.3452915549278259, train/logprobs = tensor([[-0.7448, -4.5543],
        [-2.1406, -1.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17250385880470276
Epoch 0, Step 1482: train/loss = 0.33359482884407043, train/raw-loss = 0.26360082626342773, train/logprobs = tensor([[-0.6151, -6.2005],
        [-1.9494, -2.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17498497664928436
Epoch 0, Step 1483: train/loss = 0.3619382083415985, train/raw-loss = 0.2933530807495117, train/logprobs = tensor([[-0.6760, -3.6144],
        [-2.4670, -0.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17146283388137817
Epoch 0, Step 1484: train/loss = 0.2624518573284149, train/raw-loss = 0.19088952243328094, train/logprobs = tensor([[-0.4279, -4.8680],
        [-2.0035, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17890581488609314
Epoch 0, Step 1485: train/loss = 0.5393415689468384, train/raw-loss = 0.47368013858795166, train/logprobs = tensor([[-0.6589, -2.4042],
        [-1.4295, -1.4218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641535758972168
Epoch 0, Step 1486: train/loss = 0.588438093662262, train/raw-loss = 0.5186981558799744, train/logprobs = tensor([[-0.9060, -2.1206],
        [-1.2707, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1743498295545578
Epoch 0, Step 1487: train/loss = 0.27467578649520874, train/raw-loss = 0.21579700708389282, train/logprobs = tensor([[-1.0670, -4.4515],
        [-2.3556, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14719697833061218
Epoch 0, Step 1488: train/loss = 0.55450838804245, train/raw-loss = 0.48574966192245483, train/logprobs = tensor([[-0.3937, -1.6772],
        [-1.4292, -1.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17189688980579376
Epoch 0, Step 1489: train/loss = 0.5013293027877808, train/raw-loss = 0.4469186067581177, train/logprobs = tensor([[-0.8095, -3.0060],
        [-1.4704, -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360267698764801
Epoch 0, Step 1490: train/loss = 0.4620271921157837, train/raw-loss = 0.4002092480659485, train/logprobs = tensor([[-0.4891, -2.7845],
        [-1.6315, -1.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15454478561878204
Epoch 0, Step 1491: train/loss = 0.30835819244384766, train/raw-loss = 0.23115161061286926, train/logprobs = tensor([[-1.1029, -5.5399],
        [-2.4322, -1.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1930164247751236
Epoch 0, Step 1492: train/loss = 0.4286142587661743, train/raw-loss = 0.36016732454299927, train/logprobs = tensor([[-0.6162, -3.3667],
        [-1.9166, -1.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111733555793762
Epoch 0, Step 1493: train/loss = 0.3541477620601654, train/raw-loss = 0.2829420566558838, train/logprobs = tensor([[-0.6370, -2.8989],
        [-2.4117, -1.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17801424860954285
Epoch 0, Step 1494: train/loss = 0.2533937692642212, train/raw-loss = 0.16228187084197998, train/logprobs = tensor([[-0.5686, -4.4368],
        [-2.4688, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22777974605560303
Epoch 0, Step 1495: train/loss = 0.27130383253097534, train/raw-loss = 0.19026651978492737, train/logprobs = tensor([[-0.5048, -6.1329],
        [-2.1239, -2.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20259329676628113
Epoch 0, Step 1496: train/loss = 0.28627943992614746, train/raw-loss = 0.22050392627716064, train/logprobs = tensor([[-0.6960, -4.9029],
        [-1.7914, -0.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16443872451782227
Epoch 0, Step 1497: train/loss = 0.3720319867134094, train/raw-loss = 0.3155461847782135, train/logprobs = tensor([[-0.5451, -2.9847],
        [-1.5167, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1412145346403122
Epoch 0, Step 1498: train/loss = 0.35249418020248413, train/raw-loss = 0.274192214012146, train/logprobs = tensor([[-0.6548, -2.8489],
        [-2.5875, -0.9188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19575490057468414
Epoch 0, Step 1499: train/loss = 0.432980477809906, train/raw-loss = 0.3660619258880615, train/logprobs = tensor([[-1.1052, -2.8946],
        [-2.5553, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1672963947057724
Epoch 0, Step 1500: train/loss = 0.49172958731651306, train/raw-loss = 0.455898642539978, train/logprobs = tensor([[-0.3158, -3.1940],
        [-0.5955, -1.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957739174365997
Epoch 0, Step 1501: train/loss = 0.27117177844047546, train/raw-loss = 0.17889738082885742, train/logprobs = tensor([[-0.4820, -4.6432],
        [-3.0977, -1.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306860387325287
Epoch 0, Step 1502: train/loss = 0.19545914232730865, train/raw-loss = 0.11331044137477875, train/logprobs = tensor([[-0.8709, -6.2140],
        [-2.5310, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20537173748016357
Epoch 0, Step 1503: train/loss = 0.46181148290634155, train/raw-loss = 0.3877013027667999, train/logprobs = tensor([[-0.9154, -3.0510],
        [-2.4266, -1.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18527540564537048
Epoch 0, Step 1504: train/loss = 0.39122191071510315, train/raw-loss = 0.32150888442993164, train/logprobs = tensor([[-0.5242, -4.3595],
        [-1.6213, -1.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17428246140480042
Epoch 0, Step 1505: train/loss = 0.29992175102233887, train/raw-loss = 0.23579750955104828, train/logprobs = tensor([[-0.6283, -4.6065],
        [-2.0750, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16031062602996826
Epoch 0, Step 1506: train/loss = 0.25895559787750244, train/raw-loss = 0.18549904227256775, train/logprobs = tensor([[-0.5869, -3.9532],
        [-2.6027, -1.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18364137411117554
Epoch 0, Step 1507: train/loss = 0.4177171587944031, train/raw-loss = 0.3375203013420105, train/logprobs = tensor([[-0.4724, -2.7136],
        [-1.5329, -0.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20049214363098145
Epoch 0, Step 1508: train/loss = 0.5246169567108154, train/raw-loss = 0.45097267627716064, train/logprobs = tensor([[-1.0068, -3.4500],
        [-2.1403, -1.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18411070108413696
Epoch 0, Step 1509: train/loss = 0.4847485423088074, train/raw-loss = 0.42877471446990967, train/logprobs = tensor([[-0.8372, -2.1069],
        [-1.8916, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13993456959724426
Epoch 0, Step 1510: train/loss = 0.44289666414260864, train/raw-loss = 0.3661964535713196, train/logprobs = tensor([[-0.5159, -5.2980],
        [-1.3357, -1.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19175054132938385
Epoch 0, Step 1511: train/loss = 0.2461109757423401, train/raw-loss = 0.18134209513664246, train/logprobs = tensor([[-0.9460, -5.6998],
        [-2.2918, -1.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1619221568107605
Epoch 0, Step 1512: train/loss = 0.4342828392982483, train/raw-loss = 0.3628922402858734, train/logprobs = tensor([[-0.5815, -2.6444],
        [-1.7735, -1.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17847652733325958
Epoch 0, Step 1513: train/loss = 0.32173269987106323, train/raw-loss = 0.24558554589748383, train/logprobs = tensor([[-0.5448, -4.3409],
        [-2.0569, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19036784768104553
Epoch 0, Step 1514: train/loss = 0.4759475886821747, train/raw-loss = 0.41110169887542725, train/logprobs = tensor([[-1.2971, -6.0318],
        [-1.9021, -1.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1621146947145462
Epoch 0, Step 1515: train/loss = 0.24768924713134766, train/raw-loss = 0.1758173704147339, train/logprobs = tensor([[-0.6993, -3.9438],
        [-2.6000, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17967969179153442
Epoch 0, Step 1516: train/loss = 0.6673846244812012, train/raw-loss = 0.6163038015365601, train/logprobs = tensor([[-0.5963, -0.7485],
        [-1.5955, -1.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12770184874534607
Epoch 0, Step 1517: train/loss = 0.21748760342597961, train/raw-loss = 0.15360389649868011, train/logprobs = tensor([[-0.8585, -9.9663],
        [-2.7447, -2.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15970924496650696
Epoch 0, Step 1518: train/loss = 0.5079878568649292, train/raw-loss = 0.4535941779613495, train/logprobs = tensor([[-1.4868, -3.5514],
        [-1.7136, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13598421216011047
Epoch 0, Step 1519: train/loss = 0.5575600862503052, train/raw-loss = 0.4946710467338562, train/logprobs = tensor([[-0.6224, -2.3440],
        [-1.4491, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15722258388996124
Epoch 0, Step 1520: train/loss = 0.21897253394126892, train/raw-loss = 0.136405348777771, train/logprobs = tensor([[-0.6394, -7.4818],
        [-2.8098, -1.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20641791820526123
Epoch 0, Step 1521: train/loss = 0.44005969166755676, train/raw-loss = 0.37823453545570374, train/logprobs = tensor([[-1.3830, -2.0156],
        [-2.6055, -1.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15456286072731018
Epoch 0, Step 1522: train/loss = 0.43026235699653625, train/raw-loss = 0.3837171196937561, train/logprobs = tensor([[-1.8690, -9.0299],
        [-2.3779, -2.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1163630485534668
Epoch 0, Step 1523: train/loss = 0.20264193415641785, train/raw-loss = 0.13841292262077332, train/logprobs = tensor([[-0.8406, -5.2107],
        [-3.2170, -1.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16057249903678894
Epoch 0, Step 1524: train/loss = 0.349667489528656, train/raw-loss = 0.27349913120269775, train/logprobs = tensor([[-0.7329, -3.0843],
        [-2.1096, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19042083621025085
Epoch 0, Step 1525: train/loss = 0.7829990983009338, train/raw-loss = 0.7087662220001221, train/logprobs = tensor([[-0.5750, -0.6380],
        [-1.5673, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18558204174041748
Epoch 0, Step 1526: train/loss = 0.47645482420921326, train/raw-loss = 0.41961389780044556, train/logprobs = tensor([[-0.5535, -2.8665],
        [-1.5544, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14210239052772522
Epoch 0, Step 1527: train/loss = 0.4552455544471741, train/raw-loss = 0.37450939416885376, train/logprobs = tensor([[-1.3193, -2.3060],
        [-1.9752, -1.2132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20184031128883362
Epoch 0, Step 1528: train/loss = 0.22987914085388184, train/raw-loss = 0.15786510705947876, train/logprobs = tensor([[-0.4441, -5.0696],
        [-2.3925, -1.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1800350695848465
Epoch 0, Step 1529: train/loss = 0.4805258810520172, train/raw-loss = 0.39277154207229614, train/logprobs = tensor([[-0.6983, -3.3466],
        [-2.6640, -1.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21938583254814148
Epoch 0, Step 1530: train/loss = 0.2747045159339905, train/raw-loss = 0.19807466864585876, train/logprobs = tensor([[-0.6771, -4.8813],
        [-2.6396, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915746033191681
Epoch 0, Step 1531: train/loss = 0.45117515325546265, train/raw-loss = 0.38756975531578064, train/logprobs = tensor([[-0.5745, -4.6521],
        [-1.6594, -1.3021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15901347994804382
Epoch 0, Step 1532: train/loss = 0.5204934477806091, train/raw-loss = 0.4505252242088318, train/logprobs = tensor([[-0.7413, -3.3368],
        [-1.4394, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17492057383060455
Epoch 0, Step 1533: train/loss = 0.3521285355091095, train/raw-loss = 0.30070239305496216, train/logprobs = tensor([[-0.3648, -3.1294],
        [-1.4799, -1.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12856540083885193
Epoch 0, Step 1534: train/loss = 0.3724339008331299, train/raw-loss = 0.3023607134819031, train/logprobs = tensor([[-1.4307, -5.6467],
        [-2.1226, -1.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17518290877342224
Epoch 0, Step 1535: train/loss = 0.504662811756134, train/raw-loss = 0.424325168132782, train/logprobs = tensor([[-0.6688, -2.0769],
        [-2.0125, -1.8076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20084410905838013
Epoch 0, Step 1536: train/loss = 0.35427287220954895, train/raw-loss = 0.2932087779045105, train/logprobs = tensor([[-0.4936, -5.2948],
        [-1.5778, -1.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526602804660797
Epoch 0, Step 1537: train/loss = 0.41792333126068115, train/raw-loss = 0.3471319079399109, train/logprobs = tensor([[-1.2293, -2.9832],
        [-1.6607, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17697854340076447
Epoch 0, Step 1538: train/loss = 0.3613237738609314, train/raw-loss = 0.2986648678779602, train/logprobs = tensor([[-0.4881, -5.2576],
        [-1.9725, -1.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15664726495742798
Epoch 0, Step 1539: train/loss = 0.529758095741272, train/raw-loss = 0.4502277970314026, train/logprobs = tensor([[-0.6251, -2.1663],
        [-1.5226, -1.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19882571697235107
Epoch 0, Step 1540: train/loss = 0.3610365092754364, train/raw-loss = 0.28561127185821533, train/logprobs = tensor([[-0.9518, -4.4037],
        [-2.4976, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18856315314769745
Epoch 0, Step 1541: train/loss = 0.20351223647594452, train/raw-loss = 0.12949439883232117, train/logprobs = tensor([[-0.6319, -8.1083],
        [-2.4413, -1.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18504458665847778
Epoch 0, Step 1542: train/loss = 0.6368095874786377, train/raw-loss = 0.5800608396530151, train/logprobs = tensor([[-0.7636, -0.7859],
        [-1.3872, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14187176525592804
Epoch 0, Step 1543: train/loss = 0.48517483472824097, train/raw-loss = 0.41399362683296204, train/logprobs = tensor([[-0.5641, -2.4274],
        [-2.3712, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17795300483703613
Epoch 0, Step 1544: train/loss = 0.36516180634498596, train/raw-loss = 0.2842088043689728, train/logprobs = tensor([[-0.7410, -5.3734],
        [-3.2437, -1.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20238247513771057
Epoch 0, Step 1545: train/loss = 0.4070742428302765, train/raw-loss = 0.3361201584339142, train/logprobs = tensor([[-1.0080, -3.2303],
        [-1.9729, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17738521099090576
Epoch 0, Step 1546: train/loss = 0.475628525018692, train/raw-loss = 0.3997044563293457, train/logprobs = tensor([[-0.5864, -2.6475],
        [-1.9908, -1.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18981009721755981
Epoch 0, Step 1547: train/loss = 0.5178635120391846, train/raw-loss = 0.4506602883338928, train/logprobs = tensor([[-0.6412, -2.6205],
        [-2.0357, -1.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1680079996585846
Epoch 0, Step 1548: train/loss = 0.44291993975639343, train/raw-loss = 0.38066545128822327, train/logprobs = tensor([[-0.4144, -4.3945],
        [-1.2590, -1.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15563611686229706
Epoch 0, Step 1549: train/loss = 0.5111541152000427, train/raw-loss = 0.4502660930156708, train/logprobs = tensor([[-0.4024, -2.6847],
        [-1.6092, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522199809551239
Epoch 0, Step 1550: train/loss = 0.5055983066558838, train/raw-loss = 0.4474971294403076, train/logprobs = tensor([[-0.7168, -1.8488],
        [-1.7145, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14525297284126282
Epoch 0, Step 1551: train/loss = 0.23919907212257385, train/raw-loss = 0.16715355217456818, train/logprobs = tensor([[-0.6234, -4.9587],
        [-1.8992, -1.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801138073205948
Epoch 0, Step 1552: train/loss = 0.35320770740509033, train/raw-loss = 0.28928667306900024, train/logprobs = tensor([[-0.6955, -7.5795],
        [-2.0976, -2.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15980267524719238
Epoch 0, Step 1553: train/loss = 0.31856608390808105, train/raw-loss = 0.2460055649280548, train/logprobs = tensor([[-0.7860, -4.1746],
        [-1.9657, -1.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1814013421535492
Epoch 0, Step 1554: train/loss = 0.5065961480140686, train/raw-loss = 0.4365088939666748, train/logprobs = tensor([[-0.8146, -2.4758],
        [-1.7008, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752181053161621
Epoch 0, Step 1555: train/loss = 0.3362354040145874, train/raw-loss = 0.26429593563079834, train/logprobs = tensor([[-1.1185, -3.3459],
        [-2.5046, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1798487901687622
Epoch 0, Step 1556: train/loss = 0.4205334782600403, train/raw-loss = 0.3608751893043518, train/logprobs = tensor([[-0.4750, -7.9300],
        [-1.2539, -1.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491456925868988
Epoch 0, Step 1557: train/loss = 0.3142170310020447, train/raw-loss = 0.25763458013534546, train/logprobs = tensor([[-0.5841, -6.2143],
        [-1.5388, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14145611226558685
Epoch 0, Step 1558: train/loss = 0.2929593622684479, train/raw-loss = 0.22161464393138885, train/logprobs = tensor([[-0.6477, -8.3429],
        [-2.1297, -1.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17836178839206696
Epoch 0, Step 1559: train/loss = 0.425871342420578, train/raw-loss = 0.35625070333480835, train/logprobs = tensor([[-1.2137, -3.3360],
        [-2.9782, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17405159771442413
Epoch 0, Step 1560: train/loss = 0.25116801261901855, train/raw-loss = 0.1888892501592636, train/logprobs = tensor([[-0.7401, -5.3011],
        [-1.8589, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15569688379764557
Epoch 0, Step 1561: train/loss = 0.263471782207489, train/raw-loss = 0.16460368037223816, train/logprobs = tensor([[-0.9672, -4.4579],
        [-3.5712, -1.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2471703290939331
Epoch 0, Step 1562: train/loss = 0.5227147340774536, train/raw-loss = 0.4503709375858307, train/logprobs = tensor([[-2.6708, -7.5886],
        [-2.6067, -1.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1808594912290573
Epoch 0, Step 1563: train/loss = 0.5873861312866211, train/raw-loss = 0.5063842535018921, train/logprobs = tensor([[-0.7977, -1.5286],
        [-2.0557, -1.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20250485837459564
Epoch 0, Step 1564: train/loss = 0.32764989137649536, train/raw-loss = 0.2601117193698883, train/logprobs = tensor([[-0.6422, -4.2920],
        [-2.8346, -1.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16884541511535645
Epoch 0, Step 1565: train/loss = 0.5361450910568237, train/raw-loss = 0.47161126136779785, train/logprobs = tensor([[-0.8961, -1.5857],
        [-1.8425, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16133448481559753
Epoch 0, Step 1566: train/loss = 0.294702410697937, train/raw-loss = 0.210885152220726, train/logprobs = tensor([[-0.6081, -5.6304],
        [-2.4982, -1.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20954319834709167
Epoch 0, Step 1567: train/loss = 0.5803480744361877, train/raw-loss = 0.5241755247116089, train/logprobs = tensor([[-0.4608, -3.0198],
        [-1.2985, -0.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14043143391609192
Epoch 0, Step 1568: train/loss = 0.3675311207771301, train/raw-loss = 0.3046041429042816, train/logprobs = tensor([[-1.4177, -6.8744],
        [-2.0732, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15731747448444366
Epoch 0, Step 1569: train/loss = 0.4646645188331604, train/raw-loss = 0.3923039138317108, train/logprobs = tensor([[-1.2750, -3.2328],
        [-1.6753, -0.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18090155720710754
Epoch 0, Step 1570: train/loss = 0.43451008200645447, train/raw-loss = 0.36576905846595764, train/logprobs = tensor([[-0.7465, -3.1937],
        [-1.6913, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17185257375240326
Epoch 0, Step 1571: train/loss = 0.4325975179672241, train/raw-loss = 0.36928361654281616, train/logprobs = tensor([[-0.6267, -2.0163],
        [-1.5737, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15828469395637512
Epoch 0, Step 1572: train/loss = 0.298674613237381, train/raw-loss = 0.22395367920398712, train/logprobs = tensor([[-0.6610, -4.4222],
        [-2.1746, -0.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18680235743522644
Epoch 0, Step 1573: train/loss = 0.2508123517036438, train/raw-loss = 0.194144144654274, train/logprobs = tensor([[-0.8488, -5.5456],
        [-2.6525, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1416705697774887
Epoch 0, Step 1574: train/loss = 0.34986165165901184, train/raw-loss = 0.2773970067501068, train/logprobs = tensor([[-0.5807, -3.5230],
        [-2.3203, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18116161227226257
Epoch 0, Step 1575: train/loss = 0.38381168246269226, train/raw-loss = 0.310293972492218, train/logprobs = tensor([[-0.8112, -3.7628],
        [-2.3639, -1.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1837943196296692
Epoch 0, Step 1576: train/loss = 0.7274801731109619, train/raw-loss = 0.6766840219497681, train/logprobs = tensor([[-0.4608, -0.6110],
        [-0.7258, -0.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12699046730995178
Epoch 0, Step 1577: train/loss = 0.5380101203918457, train/raw-loss = 0.46310654282569885, train/logprobs = tensor([[-0.7219, -1.4476],
        [-1.6764, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18725906312465668
Epoch 0, Step 1578: train/loss = 0.32263416051864624, train/raw-loss = 0.27222204208374023, train/logprobs = tensor([[-1.3649, -8.5537],
        [-1.8715, -1.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12603023648262024
Epoch 0, Step 1579: train/loss = 0.4278624653816223, train/raw-loss = 0.354553759098053, train/logprobs = tensor([[-0.5224, -4.4674],
        [-2.2868, -1.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327178061008453
Epoch 0, Step 1580: train/loss = 0.3713957369327545, train/raw-loss = 0.3028762936592102, train/logprobs = tensor([[-0.4312, -2.7513],
        [-1.6845, -1.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129863798618317
Epoch 0, Step 1581: train/loss = 0.20496505498886108, train/raw-loss = 0.1259264051914215, train/logprobs = tensor([[-0.8070, -3.3442],
        [-3.2884, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19759662449359894
Epoch 0, Step 1582: train/loss = 0.1924431174993515, train/raw-loss = 0.13684403896331787, train/logprobs = tensor([[-0.8742, -7.1701],
        [-2.8594, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13899768888950348
Epoch 0, Step 1583: train/loss = 0.43714699149131775, train/raw-loss = 0.35816705226898193, train/logprobs = tensor([[-0.7629, -6.4939],
        [-3.5275, -2.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19744977355003357
Epoch 0, Step 1584: train/loss = 0.20581892132759094, train/raw-loss = 0.14328879117965698, train/logprobs = tensor([[-0.9420, -5.8118],
        [-2.2290, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1563253402709961
Epoch 0, Step 1585: train/loss = 0.25260981917381287, train/raw-loss = 0.15689845383167267, train/logprobs = tensor([[-0.7985, -3.7741],
        [-2.4110, -1.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2392783910036087
Epoch 0, Step 1586: train/loss = 0.33054161071777344, train/raw-loss = 0.2543138563632965, train/logprobs = tensor([[-0.6653, -6.1291],
        [-2.2758, -1.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19056935608386993
Epoch 0, Step 1587: train/loss = 0.19250240921974182, train/raw-loss = 0.11111065000295639, train/logprobs = tensor([[-0.8288, -4.5258],
        [-2.5831, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20347939431667328
Epoch 0, Step 1588: train/loss = 0.331119567155838, train/raw-loss = 0.27866846323013306, train/logprobs = tensor([[-0.5111, -4.4639],
        [-1.5495, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13112768530845642
Epoch 0, Step 1589: train/loss = 0.3815279006958008, train/raw-loss = 0.32083219289779663, train/logprobs = tensor([[-0.6942, -4.7998],
        [-1.6131, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15173929929733276
Epoch 0, Step 1590: train/loss = 0.3740276098251343, train/raw-loss = 0.3193836808204651, train/logprobs = tensor([[-0.5805, -5.9251],
        [-1.0404, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13660979270935059
Epoch 0, Step 1591: train/loss = 0.43020015954971313, train/raw-loss = 0.34595829248428345, train/logprobs = tensor([[-0.6272, -5.7593],
        [-2.3774, -3.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2106046974658966
Epoch 0, Step 1592: train/loss = 0.3527831435203552, train/raw-loss = 0.2764117121696472, train/logprobs = tensor([[-0.6582, -3.3954],
        [-1.6344, -0.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19092854857444763
Epoch 0, Step 1593: train/loss = 0.31997233629226685, train/raw-loss = 0.25186944007873535, train/logprobs = tensor([[-0.7790, -5.9284],
        [-1.9360, -1.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17025727033615112
Epoch 0, Step 1594: train/loss = 0.29769569635391235, train/raw-loss = 0.21634814143180847, train/logprobs = tensor([[-0.6148, -3.9027],
        [-2.1941, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033688724040985
Epoch 0, Step 1595: train/loss = 0.31392180919647217, train/raw-loss = 0.23794740438461304, train/logprobs = tensor([[-0.6103, -3.7320],
        [-1.9039, -1.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18993595242500305
Epoch 0, Step 1596: train/loss = 0.34610939025878906, train/raw-loss = 0.2537243962287903, train/logprobs = tensor([[-0.6396, -7.5472],
        [-2.8181, -2.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23096244037151337
Epoch 0, Step 1597: train/loss = 0.2754579186439514, train/raw-loss = 0.20909559726715088, train/logprobs = tensor([[-0.8875, -5.3282],
        [-2.8417, -1.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16590578854084015
Epoch 0, Step 1598: train/loss = 0.3549885153770447, train/raw-loss = 0.29842132329940796, train/logprobs = tensor([[-0.8565, -5.9125],
        [-1.8167, -1.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14141800999641418
Epoch 0, Step 1599: train/loss = 0.21196112036705017, train/raw-loss = 0.12470739334821701, train/logprobs = tensor([[-0.5691, -7.5288],
        [-2.5262, -2.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181342989206314
Epoch 0, Step 1600: train/loss = 0.35685786604881287, train/raw-loss = 0.29050183296203613, train/logprobs = tensor([[-1.0114, -5.3720],
        [-1.5853, -1.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16589003801345825
Epoch 0, Step 1601: train/loss = 0.1657627820968628, train/raw-loss = 0.09410454332828522, train/logprobs = tensor([[ -0.5593, -10.9400],
        [ -2.3039,  -3.5115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17914560437202454
Epoch 0, Step 1602: train/loss = 0.2966153621673584, train/raw-loss = 0.2186855524778366, train/logprobs = tensor([[-0.5136, -4.7225],
        [-1.7581, -1.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19482451677322388
Epoch 0, Step 1603: train/loss = 0.5440773963928223, train/raw-loss = 0.4823186993598938, train/logprobs = tensor([[-0.4727, -2.6720],
        [-1.6286, -1.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543966829776764
Epoch 0, Step 1604: train/loss = 0.29800668358802795, train/raw-loss = 0.23722624778747559, train/logprobs = tensor([[-0.5269, -6.1159],
        [-1.4314, -2.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15195108950138092
Epoch 0, Step 1605: train/loss = 0.4855547547340393, train/raw-loss = 0.4142453670501709, train/logprobs = tensor([[-0.8455, -3.9900],
        [-1.7030, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17827346920967102
Epoch 0, Step 1606: train/loss = 0.21371640264987946, train/raw-loss = 0.15439365804195404, train/logprobs = tensor([[-0.6257, -7.2876],
        [-2.1018, -2.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14830687642097473
Epoch 0, Step 1607: train/loss = 0.3500301241874695, train/raw-loss = 0.27685683965682983, train/logprobs = tensor([[-0.7533, -3.3757],
        [-1.8182, -1.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18293312191963196
Epoch 0, Step 1608: train/loss = 0.3718264400959015, train/raw-loss = 0.29941874742507935, train/logprobs = tensor([[-0.8644, -7.7025],
        [-1.8313, -2.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18101921677589417
Epoch 0, Step 1609: train/loss = 0.40445375442504883, train/raw-loss = 0.33677560091018677, train/logprobs = tensor([[-1.0111, -6.9351],
        [-1.6868, -1.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16919536888599396
Epoch 0, Step 1610: train/loss = 0.5344614386558533, train/raw-loss = 0.46727079153060913, train/logprobs = tensor([[-1.0486, -3.8268],
        [-1.3117, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16797666251659393
Epoch 0, Step 1611: train/loss = 0.37673863768577576, train/raw-loss = 0.30805373191833496, train/logprobs = tensor([[-0.7994, -2.1326],
        [-2.5456, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1717122346162796
Epoch 0, Step 1612: train/loss = 0.2783040404319763, train/raw-loss = 0.20261771976947784, train/logprobs = tensor([[-0.7858, -5.9199],
        [-2.5403, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1892157793045044
Epoch 0, Step 1613: train/loss = 0.6333925724029541, train/raw-loss = 0.5630598664283752, train/logprobs = tensor([[-0.5972, -1.1441],
        [-1.3294, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17583175003528595
Epoch 0, Step 1614: train/loss = 0.30438822507858276, train/raw-loss = 0.23073579370975494, train/logprobs = tensor([[-1.4709, -6.7842],
        [-2.6864, -2.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18413111567497253
Epoch 0, Step 1615: train/loss = 0.3679813742637634, train/raw-loss = 0.3072511851787567, train/logprobs = tensor([[-0.4731, -6.7924],
        [-1.4417, -2.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15182539820671082
Epoch 0, Step 1616: train/loss = 0.4223325550556183, train/raw-loss = 0.3558446168899536, train/logprobs = tensor([[-0.6940, -4.8074],
        [-2.4999, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16621986031532288
Epoch 0, Step 1617: train/loss = 0.4177534282207489, train/raw-loss = 0.36557334661483765, train/logprobs = tensor([[-0.5994, -3.8261],
        [-1.5775, -0.6459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13045021891593933
Epoch 0, Step 1618: train/loss = 0.5008578896522522, train/raw-loss = 0.4354666471481323, train/logprobs = tensor([[-0.5693, -2.1395],
        [-1.6179, -1.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16347815096378326
Epoch 0, Step 1619: train/loss = 0.28599077463150024, train/raw-loss = 0.22630196809768677, train/logprobs = tensor([[-0.6462, -5.8765],
        [-1.5490, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14922207593917847
Epoch 0, Step 1620: train/loss = 0.38746392726898193, train/raw-loss = 0.31565967202186584, train/logprobs = tensor([[-0.6150, -3.4573],
        [-1.7256, -1.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1795106679201126
Epoch 0, Step 1621: train/loss = 0.37216418981552124, train/raw-loss = 0.3021974563598633, train/logprobs = tensor([[-0.8234, -3.5413],
        [-2.0145, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1749168336391449
Epoch 0, Step 1622: train/loss = 0.23907124996185303, train/raw-loss = 0.16960355639457703, train/logprobs = tensor([[-1.0200, -5.9063],
        [-2.5574, -1.3860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1736692190170288
Epoch 0, Step 1623: train/loss = 0.4893660843372345, train/raw-loss = 0.4236224293708801, train/logprobs = tensor([[-0.4879, -2.5421],
        [-1.4532, -1.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16435915231704712
Epoch 0, Step 1624: train/loss = 0.23954524099826813, train/raw-loss = 0.18489189445972443, train/logprobs = tensor([[-0.5926, -3.3435],
        [-2.0778, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13663333654403687
Epoch 0, Step 1625: train/loss = 0.2830044627189636, train/raw-loss = 0.20609989762306213, train/logprobs = tensor([[-0.6296, -5.4600],
        [-2.2074, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1922614425420761
Epoch 0, Step 1626: train/loss = 0.46284639835357666, train/raw-loss = 0.40876853466033936, train/logprobs = tensor([[-1.2106, -1.9343],
        [-2.1181, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13519468903541565
Epoch 0, Step 1627: train/loss = 0.4199189841747284, train/raw-loss = 0.35550299286842346, train/logprobs = tensor([[-1.3320, -3.8537],
        [-2.1003, -1.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16103997826576233
Epoch 0, Step 1628: train/loss = 0.2989622950553894, train/raw-loss = 0.24385064840316772, train/logprobs = tensor([[-0.6695, -6.5182],
        [-1.3812, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377790868282318
Epoch 0, Step 1629: train/loss = 0.46416211128234863, train/raw-loss = 0.40227818489074707, train/logprobs = tensor([[-0.7970, -3.1140],
        [-1.5458, -0.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15470978617668152
Epoch 0, Step 1630: train/loss = 0.48018407821655273, train/raw-loss = 0.410092294216156, train/logprobs = tensor([[-0.6768, -1.8877],
        [-2.2477, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752295196056366
Epoch 0, Step 1631: train/loss = 0.20638063549995422, train/raw-loss = 0.13936269283294678, train/logprobs = tensor([[-0.4833, -8.0812],
        [-1.6291, -1.3618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675449013710022
Epoch 0, Step 1632: train/loss = 0.36455875635147095, train/raw-loss = 0.29386112093925476, train/logprobs = tensor([[-0.8098, -7.0440],
        [-1.8583, -1.6327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17674411833286285
Epoch 0, Step 1633: train/loss = 0.34689822793006897, train/raw-loss = 0.2857957184314728, train/logprobs = tensor([[-0.9299, -5.4130],
        [-2.6299, -1.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527562439441681
Epoch 0, Step 1634: train/loss = 0.4459037780761719, train/raw-loss = 0.3615559935569763, train/logprobs = tensor([[-0.9242, -3.0329],
        [-2.3465, -1.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2108694612979889
Epoch 0, Step 1635: train/loss = 0.35752713680267334, train/raw-loss = 0.26991963386535645, train/logprobs = tensor([[-0.5497, -6.8050],
        [-2.9474, -1.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21901869773864746
Epoch 0, Step 1636: train/loss = 0.32539403438568115, train/raw-loss = 0.24459683895111084, train/logprobs = tensor([[-0.4641, -5.6466],
        [-1.7528, -0.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20199298858642578
Epoch 0, Step 1637: train/loss = 0.3681821823120117, train/raw-loss = 0.2983696460723877, train/logprobs = tensor([[-0.7753, -6.8148],
        [-2.7977, -2.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745314598083496
Epoch 0, Step 1638: train/loss = 0.326043963432312, train/raw-loss = 0.25758692622184753, train/logprobs = tensor([[-0.6044, -6.3343],
        [-2.3186, -2.2582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17114266753196716
Epoch 0, Step 1639: train/loss = 0.47340959310531616, train/raw-loss = 0.4114770293235779, train/logprobs = tensor([[-0.8411, -6.8312],
        [-1.3721, -1.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15483149886131287
Epoch 0, Step 1640: train/loss = 0.33145877718925476, train/raw-loss = 0.255243182182312, train/logprobs = tensor([[-0.5172, -5.8883],
        [-1.8316, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19053898751735687
Epoch 0, Step 1641: train/loss = 0.3183574676513672, train/raw-loss = 0.2662389874458313, train/logprobs = tensor([[-0.3383, -5.6012],
        [-1.9289, -2.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302962303161621
Epoch 0, Step 1642: train/loss = 0.28658056259155273, train/raw-loss = 0.2143171727657318, train/logprobs = tensor([[-0.6761, -5.7799],
        [-2.6747, -3.2132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1806584745645523
Epoch 0, Step 1643: train/loss = 0.4020809531211853, train/raw-loss = 0.341815322637558, train/logprobs = tensor([[-1.2591, -7.0229],
        [-2.4272, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066403150558472
Epoch 0, Step 1644: train/loss = 0.3582713007926941, train/raw-loss = 0.280442476272583, train/logprobs = tensor([[-0.9730, -4.9665],
        [-2.2662, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19457212090492249
Epoch 0, Step 1645: train/loss = 0.1866811215877533, train/raw-loss = 0.11911770701408386, train/logprobs = tensor([[ -0.6393, -10.0830],
        [ -2.5694,  -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16890856623649597
Epoch 0, Step 1646: train/loss = 0.5426867008209229, train/raw-loss = 0.47582897543907166, train/logprobs = tensor([[-0.9173, -2.3058],
        [-1.4498, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16714425384998322
Epoch 0, Step 1647: train/loss = 0.34532877802848816, train/raw-loss = 0.2796289324760437, train/logprobs = tensor([[-0.5103, -2.6005],
        [-1.6408, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16424959897994995
Epoch 0, Step 1648: train/loss = 0.3977675437927246, train/raw-loss = 0.3348824083805084, train/logprobs = tensor([[-0.5069, -2.4490],
        [-1.6297, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15721282362937927
Epoch 0, Step 1649: train/loss = 0.38471686840057373, train/raw-loss = 0.3148220181465149, train/logprobs = tensor([[-0.5132, -4.8920],
        [-1.9202, -1.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1747371256351471
Epoch 0, Step 1650: train/loss = 0.4157506227493286, train/raw-loss = 0.3533311188220978, train/logprobs = tensor([[-0.6627, -4.4654],
        [-1.4818, -1.3358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15604881942272186
Epoch 0, Step 1651: train/loss = 0.28316646814346313, train/raw-loss = 0.21546435356140137, train/logprobs = tensor([[-0.5886, -3.8116],
        [-2.0199, -1.2523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1692553013563156
Epoch 0, Step 1652: train/loss = 0.5774664878845215, train/raw-loss = 0.5141072273254395, train/logprobs = tensor([[-0.4585, -3.1596],
        [-1.2156, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839819610118866
Epoch 0, Step 1653: train/loss = 0.3203040361404419, train/raw-loss = 0.24200809001922607, train/logprobs = tensor([[-0.4645, -4.0728],
        [-1.8189, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19573989510536194
Epoch 0, Step 1654: train/loss = 0.3726940453052521, train/raw-loss = 0.31152936816215515, train/logprobs = tensor([[-0.9599, -5.2818],
        [-1.8318, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1529117077589035
Epoch 0, Step 1655: train/loss = 0.31763237714767456, train/raw-loss = 0.24494606256484985, train/logprobs = tensor([[-0.5197, -7.8659],
        [-1.7362, -1.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181715726852417
Epoch 0, Step 1656: train/loss = 0.28749772906303406, train/raw-loss = 0.20905782282352448, train/logprobs = tensor([[-0.5547, -3.1407],
        [-2.6774, -0.4957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19609972834587097
Epoch 0, Step 1657: train/loss = 0.4647509455680847, train/raw-loss = 0.38536596298217773, train/logprobs = tensor([[-0.8373, -2.2672],
        [-2.9702, -1.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19846247136592865
Epoch 0, Step 1658: train/loss = 0.5111346244812012, train/raw-loss = 0.45110854506492615, train/logprobs = tensor([[-0.8069, -3.0961],
        [-2.0734, -2.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15006527304649353
Epoch 0, Step 1659: train/loss = 0.3129061162471771, train/raw-loss = 0.22815066576004028, train/logprobs = tensor([[-0.7908, -3.2967],
        [-2.8207, -1.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2118886113166809
Epoch 0, Step 1660: train/loss = 0.2560923099517822, train/raw-loss = 0.19456148147583008, train/logprobs = tensor([[-0.8606, -6.2760],
        [-2.0726, -0.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15382710099220276
Epoch 0, Step 1661: train/loss = 0.6302344799041748, train/raw-loss = 0.5707953572273254, train/logprobs = tensor([[-0.8487, -1.7050],
        [-1.4257, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14859777688980103
Epoch 0, Step 1662: train/loss = 0.26136305928230286, train/raw-loss = 0.1850677728652954, train/logprobs = tensor([[-0.8762, -7.0230],
        [-2.5615, -1.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1907382309436798
Epoch 0, Step 1663: train/loss = 0.3157186508178711, train/raw-loss = 0.2516545355319977, train/logprobs = tensor([[-0.8650, -2.5688],
        [-2.6378, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16016030311584473
Epoch 0, Step 1664: train/loss = 0.45252424478530884, train/raw-loss = 0.3685418367385864, train/logprobs = tensor([[-0.6474, -1.7406],
        [-2.1506, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20995615422725677
Epoch 0, Step 1665: train/loss = 0.3591877818107605, train/raw-loss = 0.285476416349411, train/logprobs = tensor([[-1.6188, -4.6385],
        [-2.3740, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18427850306034088
Epoch 0, Step 1666: train/loss = 0.41255682706832886, train/raw-loss = 0.3591931164264679, train/logprobs = tensor([[-0.7708, -2.8290],
        [-1.8556, -0.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1334092617034912
Epoch 0, Step 1667: train/loss = 0.24834464490413666, train/raw-loss = 0.19258522987365723, train/logprobs = tensor([[-0.4367, -6.6236],
        [-1.7993, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393985152244568
Epoch 0, Step 1668: train/loss = 0.5450003743171692, train/raw-loss = 0.5020473003387451, train/logprobs = tensor([[-0.5979, -2.4475],
        [-0.5699, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073826476931572
Epoch 0, Step 1669: train/loss = 0.18516892194747925, train/raw-loss = 0.10555575788021088, train/logprobs = tensor([[-0.6563, -7.1922],
        [-2.3940, -1.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903290271759033
Epoch 0, Step 1670: train/loss = 0.13995657861232758, train/raw-loss = 0.07091308385133743, train/logprobs = tensor([[-0.6983, -7.3641],
        [-3.1452, -1.2189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17260871827602386
Epoch 0, Step 1671: train/loss = 0.31337282061576843, train/raw-loss = 0.25540652871131897, train/logprobs = tensor([[-1.6400, -4.9660],
        [-2.5559, -1.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14491572976112366
Epoch 0, Step 1672: train/loss = 0.45229285955429077, train/raw-loss = 0.3801652193069458, train/logprobs = tensor([[-1.0841, -3.6277],
        [-2.1571, -1.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18031904101371765
Epoch 0, Step 1673: train/loss = 0.3398645520210266, train/raw-loss = 0.2746177613735199, train/logprobs = tensor([[-0.5620, -3.2898],
        [-1.6789, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.163116917014122
Epoch 0, Step 1674: train/loss = 0.4046885371208191, train/raw-loss = 0.3530513644218445, train/logprobs = tensor([[-0.7520, -4.1455],
        [-1.2110, -1.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12909285724163055
Epoch 0, Step 1675: train/loss = 0.4477844834327698, train/raw-loss = 0.3883920907974243, train/logprobs = tensor([[-1.5857, -6.1979],
        [-1.7531, -1.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14848102629184723
Epoch 0, Step 1676: train/loss = 0.3415716290473938, train/raw-loss = 0.24958737194538116, train/logprobs = tensor([[-1.0325, -4.7156],
        [-3.1594, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22996065020561218
Epoch 0, Step 1677: train/loss = 0.3511265516281128, train/raw-loss = 0.3048243522644043, train/logprobs = tensor([[-0.7382, -4.5713],
        [-2.1828, -1.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11575556546449661
Epoch 0, Step 1678: train/loss = 0.32662612199783325, train/raw-loss = 0.2585642635822296, train/logprobs = tensor([[-0.7267, -3.2478],
        [-2.3713, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1701546162366867
Epoch 0, Step 1679: train/loss = 0.41554689407348633, train/raw-loss = 0.3471169173717499, train/logprobs = tensor([[-0.6887, -2.9673],
        [-2.1167, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17107492685317993
Epoch 0, Step 1680: train/loss = 0.4718163013458252, train/raw-loss = 0.40738150477409363, train/logprobs = tensor([[-0.5381, -2.2475],
        [-1.5460, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1610870063304901
Epoch 0, Step 1681: train/loss = 0.303406685590744, train/raw-loss = 0.24704325199127197, train/logprobs = tensor([[ -0.7897, -10.0132],
        [ -2.1426,  -1.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14090855419635773
Epoch 0, Step 1682: train/loss = 0.42625829577445984, train/raw-loss = 0.35272079706192017, train/logprobs = tensor([[-0.6505, -4.3346],
        [-1.7776, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838436871767044
Epoch 0, Step 1683: train/loss = 0.3925098478794098, train/raw-loss = 0.3187255561351776, train/logprobs = tensor([[-1.4550, -3.8474],
        [-2.6505, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18446072936058044
Epoch 0, Step 1684: train/loss = 0.5134696960449219, train/raw-loss = 0.4563462436199188, train/logprobs = tensor([[-0.5814, -1.4017],
        [-1.3835, -0.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1428086906671524
Epoch 0, Step 1685: train/loss = 0.41513797640800476, train/raw-loss = 0.35047152638435364, train/logprobs = tensor([[-0.6168, -3.0621],
        [-1.7068, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16166608035564423
Epoch 0, Step 1686: train/loss = 0.23654547333717346, train/raw-loss = 0.1731976866722107, train/logprobs = tensor([[-0.7686, -7.5232],
        [-2.1516, -1.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15836948156356812
Epoch 0, Step 1687: train/loss = 0.3559856712818146, train/raw-loss = 0.28006109595298767, train/logprobs = tensor([[-0.6194, -4.6678],
        [-1.9896, -1.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18981145322322845
Epoch 0, Step 1688: train/loss = 0.44713079929351807, train/raw-loss = 0.3761930465698242, train/logprobs = tensor([[-1.0239, -6.4603],
        [-1.4894, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1773444563150406
Epoch 0, Step 1689: train/loss = 0.40764760971069336, train/raw-loss = 0.33858150243759155, train/logprobs = tensor([[-0.6159, -4.4359],
        [-1.8881, -1.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17266522347927094
Epoch 0, Step 1690: train/loss = 0.47081929445266724, train/raw-loss = 0.40150246024131775, train/logprobs = tensor([[-0.6822, -2.6200],
        [-1.3373, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1732921302318573
Epoch 0, Step 1691: train/loss = 0.471311092376709, train/raw-loss = 0.41911613941192627, train/logprobs = tensor([[-1.0413, -3.8937],
        [-1.4946, -1.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13048745691776276
Epoch 0, Step 1692: train/loss = 0.29844409227371216, train/raw-loss = 0.2132183015346527, train/logprobs = tensor([[-0.8439, -4.1052],
        [-2.5848, -1.2428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.213064506649971
Epoch 0, Step 1693: train/loss = 0.3968081474304199, train/raw-loss = 0.32569560408592224, train/logprobs = tensor([[-0.8704, -3.5687],
        [-1.7510, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1777813732624054
Epoch 0, Step 1694: train/loss = 0.2637624740600586, train/raw-loss = 0.20021596550941467, train/logprobs = tensor([[-0.7537, -3.9784],
        [-2.5209, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588662713766098
Epoch 0, Step 1695: train/loss = 0.6852726340293884, train/raw-loss = 0.6120045185089111, train/logprobs = tensor([[-0.9521, -3.6536],
        [-1.3444, -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183170348405838
Epoch 0, Step 1696: train/loss = 0.45735904574394226, train/raw-loss = 0.39308953285217285, train/logprobs = tensor([[-1.2640, -3.6227],
        [-1.6010, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16067376732826233
Epoch 0, Step 1697: train/loss = 0.5738443732261658, train/raw-loss = 0.5216788649559021, train/logprobs = tensor([[-0.4555, -2.0362],
        [-0.9245, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13041378557682037
Epoch 0, Step 1698: train/loss = 0.48901939392089844, train/raw-loss = 0.42741659283638, train/logprobs = tensor([[-1.0246, -3.5422],
        [-1.0613, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15400704741477966
Epoch 0, Step 1699: train/loss = 0.42658817768096924, train/raw-loss = 0.36105477809906006, train/logprobs = tensor([[-0.7825, -3.8868],
        [-1.8786, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16383349895477295
Epoch 0, Step 1700: train/loss = 0.44209033250808716, train/raw-loss = 0.36391329765319824, train/logprobs = tensor([[-0.9042, -3.7576],
        [-1.3764, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19544249773025513
Epoch 0, Step 1701: train/loss = 0.5292538404464722, train/raw-loss = 0.460407018661499, train/logprobs = tensor([[-1.2780, -2.2151],
        [-2.3355, -1.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1721169501543045
Epoch 0, Step 1702: train/loss = 0.4230654239654541, train/raw-loss = 0.3463059067726135, train/logprobs = tensor([[-0.5390, -3.1444],
        [-1.9224, -1.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19189874827861786
Epoch 0, Step 1703: train/loss = 0.3158760666847229, train/raw-loss = 0.2502691149711609, train/logprobs = tensor([[-0.6373, -5.6302],
        [-2.3072, -2.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16401727497577667
Epoch 0, Step 1704: train/loss = 0.2501201629638672, train/raw-loss = 0.1719546914100647, train/logprobs = tensor([[-0.8962, -6.7260],
        [-2.6812, -1.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19541361927986145
Epoch 0, Step 1705: train/loss = 0.39847204089164734, train/raw-loss = 0.3337111473083496, train/logprobs = tensor([[-0.6310, -6.1677],
        [-1.6767, -1.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190221905708313
Epoch 0, Step 1706: train/loss = 0.2814984917640686, train/raw-loss = 0.20783957839012146, train/logprobs = tensor([[-0.6641, -4.4043],
        [-2.9826, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18414729833602905
Epoch 0, Step 1707: train/loss = 0.4065414071083069, train/raw-loss = 0.3337635099887848, train/logprobs = tensor([[-0.7299, -2.6104],
        [-2.0765, -1.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18194477260112762
Epoch 0, Step 1708: train/loss = 0.4119291305541992, train/raw-loss = 0.3466227054595947, train/logprobs = tensor([[-0.8223, -3.3091],
        [-2.0699, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16326606273651123
Epoch 0, Step 1709: train/loss = 0.472886860370636, train/raw-loss = 0.4083511531352997, train/logprobs = tensor([[-0.9056, -4.1544],
        [-1.4503, -0.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16133931279182434
Epoch 0, Step 1710: train/loss = 0.4182666540145874, train/raw-loss = 0.3386075794696808, train/logprobs = tensor([[-0.7223, -4.1828],
        [-2.0178, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19914765655994415
Epoch 0, Step 1711: train/loss = 0.23050597310066223, train/raw-loss = 0.14358873665332794, train/logprobs = tensor([[-0.6918, -6.6918],
        [-2.8529, -1.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21729308366775513
Epoch 0, Step 1712: train/loss = 0.2357199490070343, train/raw-loss = 0.1753057986497879, train/logprobs = tensor([[-0.4304, -9.4044],
        [-1.3668, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1510353982448578
Epoch 0, Step 1713: train/loss = 0.265819787979126, train/raw-loss = 0.19084399938583374, train/logprobs = tensor([[-0.7952, -4.9047],
        [-2.6086, -1.0369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187439426779747
Epoch 0, Step 1714: train/loss = 0.537908673286438, train/raw-loss = 0.47875046730041504, train/logprobs = tensor([[-0.9054, -2.1638],
        [-1.0063, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14789550006389618
Epoch 0, Step 1715: train/loss = 0.4318509101867676, train/raw-loss = 0.36533865332603455, train/logprobs = tensor([[-0.7893, -2.6535],
        [-1.4037, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16628068685531616
Epoch 0, Step 1716: train/loss = 0.5516799092292786, train/raw-loss = 0.4768776297569275, train/logprobs = tensor([[-1.1136, -3.0460],
        [-1.6054, -1.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18700571358203888
Epoch 0, Step 1717: train/loss = 0.4448122978210449, train/raw-loss = 0.3756609261035919, train/logprobs = tensor([[-0.6893, -7.0135],
        [-1.8461, -1.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17287835478782654
Epoch 0, Step 1718: train/loss = 0.42099225521087646, train/raw-loss = 0.35873910784721375, train/logprobs = tensor([[-0.9232, -2.9057],
        [-1.9690, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15563282370567322
Epoch 0, Step 1719: train/loss = 0.35069599747657776, train/raw-loss = 0.263597697019577, train/logprobs = tensor([[-0.7247, -7.1073],
        [-2.7012, -1.2039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21774575114250183
Epoch 0, Step 1720: train/loss = 0.7110737562179565, train/raw-loss = 0.6450890898704529, train/logprobs = tensor([[-1.8809, -3.1712],
        [-1.3713, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16496160626411438
Epoch 0, Step 1721: train/loss = 0.2865883708000183, train/raw-loss = 0.20393948256969452, train/logprobs = tensor([[-1.2373, -7.4354],
        [-3.1650, -2.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066221833229065
Epoch 0, Step 1722: train/loss = 0.23194068670272827, train/raw-loss = 0.15373869240283966, train/logprobs = tensor([[-0.4103, -4.6994],
        [-2.6634, -1.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1955050230026245
Epoch 0, Step 1723: train/loss = 0.37693774700164795, train/raw-loss = 0.2950543761253357, train/logprobs = tensor([[-1.0373, -4.2656],
        [-2.6411, -1.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20470839738845825
Epoch 0, Step 1724: train/loss = 0.2740727961063385, train/raw-loss = 0.2235814332962036, train/logprobs = tensor([[-0.8882, -6.5782],
        [-1.8940, -1.3427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1262284517288208
Epoch 0, Step 1725: train/loss = 0.4496985375881195, train/raw-loss = 0.37941545248031616, train/logprobs = tensor([[-0.7906, -5.1775],
        [-1.9414, -1.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17570774257183075
Epoch 0, Step 1726: train/loss = 0.2054968625307083, train/raw-loss = 0.1382392942905426, train/logprobs = tensor([[-0.7419, -6.1591],
        [-2.2289, -0.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814391314983368
Epoch 0, Step 1727: train/loss = 0.29504403471946716, train/raw-loss = 0.22577176988124847, train/logprobs = tensor([[-0.7529, -4.3827],
        [-2.1090, -1.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17318065464496613
Epoch 0, Step 1728: train/loss = 0.5494137406349182, train/raw-loss = 0.4996279180049896, train/logprobs = tensor([[-0.8366, -3.3262],
        [-0.8685, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12446445226669312
Epoch 0, Step 1729: train/loss = 0.20850414037704468, train/raw-loss = 0.136091947555542, train/logprobs = tensor([[-1.0426, -8.0146],
        [-2.1853, -1.3402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1810304820537567
Epoch 0, Step 1730: train/loss = 0.6939942240715027, train/raw-loss = 0.6171725988388062, train/logprobs = tensor([[-0.9817, -1.7896],
        [-1.6318, -1.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1920541673898697
Epoch 0, Step 1731: train/loss = 0.5902697443962097, train/raw-loss = 0.5278300046920776, train/logprobs = tensor([[-0.4837, -3.0887],
        [-1.6483, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15609949827194214
Epoch 0, Step 1732: train/loss = 0.42839670181274414, train/raw-loss = 0.36595824360847473, train/logprobs = tensor([[-0.8615, -5.9374],
        [-1.7596, -1.5121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15609616041183472
Epoch 0, Step 1733: train/loss = 0.41392582654953003, train/raw-loss = 0.35274258255958557, train/logprobs = tensor([[-0.4672, -3.6035],
        [-1.3129, -0.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15295813977718353
Epoch 0, Step 1734: train/loss = 0.4102175235748291, train/raw-loss = 0.3545351028442383, train/logprobs = tensor([[-1.2173, -5.4034],
        [-1.2864, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13920605182647705
Epoch 0, Step 1735: train/loss = 0.23640792071819305, train/raw-loss = 0.17730945348739624, train/logprobs = tensor([[-0.9388, -6.0765],
        [-1.9970, -1.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14774616062641144
Epoch 0, Step 1736: train/loss = 0.2311900556087494, train/raw-loss = 0.1418256312608719, train/logprobs = tensor([[-1.0452, -6.2924],
        [-2.8287, -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341105341911316
Epoch 0, Step 1737: train/loss = 0.23178108036518097, train/raw-loss = 0.15223278105258942, train/logprobs = tensor([[-0.6732, -6.9972],
        [-3.0288, -1.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19887080788612366
Epoch 0, Step 1738: train/loss = 0.4195656478404999, train/raw-loss = 0.3571723997592926, train/logprobs = tensor([[-1.7777, -5.3523],
        [-2.1186, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1559831202030182
Epoch 0, Step 1739: train/loss = 0.46058908104896545, train/raw-loss = 0.39576542377471924, train/logprobs = tensor([[-0.9316, -4.0348],
        [-1.5110, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16205909848213196
Epoch 0, Step 1740: train/loss = 0.41639411449432373, train/raw-loss = 0.3581056594848633, train/logprobs = tensor([[-0.7291, -3.8578],
        [-1.9815, -1.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1457211673259735
Epoch 0, Step 1741: train/loss = 0.40780338644981384, train/raw-loss = 0.3498302698135376, train/logprobs = tensor([[-0.6495, -5.1450],
        [-2.0641, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14493274688720703
Epoch 0, Step 1742: train/loss = 0.3387395739555359, train/raw-loss = 0.2714124619960785, train/logprobs = tensor([[-1.4298, -7.6850],
        [-1.9394, -1.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1683177500963211
Epoch 0, Step 1743: train/loss = 0.5510083436965942, train/raw-loss = 0.4836845099925995, train/logprobs = tensor([[-0.7398, -2.3977],
        [-1.7150, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16830964386463165
Epoch 0, Step 1744: train/loss = 0.30191394686698914, train/raw-loss = 0.23987489938735962, train/logprobs = tensor([[-1.7099, -6.4682],
        [-2.3242, -1.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15509767830371857
Epoch 0, Step 1745: train/loss = 0.4493390917778015, train/raw-loss = 0.38211140036582947, train/logprobs = tensor([[-0.6652, -5.6354],
        [-1.5663, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16806921362876892
Epoch 0, Step 1746: train/loss = 0.45856037735939026, train/raw-loss = 0.3956214189529419, train/logprobs = tensor([[-0.6017, -2.5316],
        [-1.4245, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15734735131263733
Epoch 0, Step 1747: train/loss = 0.4076426923274994, train/raw-loss = 0.3512573540210724, train/logprobs = tensor([[-0.6544, -2.3909],
        [-2.0217, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14096340537071228
Epoch 0, Step 1748: train/loss = 0.4336147606372833, train/raw-loss = 0.36306050419807434, train/logprobs = tensor([[-0.8074, -1.6796],
        [-2.2572, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17638568580150604
Epoch 0, Step 1749: train/loss = 0.41606056690216064, train/raw-loss = 0.3400343060493469, train/logprobs = tensor([[-0.8748, -3.4230],
        [-2.1619, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19006569683551788
Epoch 0, Step 1750: train/loss = 0.2791208028793335, train/raw-loss = 0.2058173418045044, train/logprobs = tensor([[ -1.2704, -11.3272],
        [ -2.4271,  -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18325871229171753
Epoch 0, Step 1751: train/loss = 0.4706319272518158, train/raw-loss = 0.41189247369766235, train/logprobs = tensor([[-1.2886, -4.8752],
        [-1.5492, -1.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1468486338853836
Epoch 0, Step 1752: train/loss = 0.3166511356830597, train/raw-loss = 0.26002728939056396, train/logprobs = tensor([[-0.7943, -7.8280],
        [-1.8643, -2.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1415596604347229
Epoch 0, Step 1753: train/loss = 0.256655216217041, train/raw-loss = 0.19191083312034607, train/logprobs = tensor([[-1.1912, -7.2289],
        [-2.1034, -1.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16186094284057617
Epoch 0, Step 1754: train/loss = 0.15266793966293335, train/raw-loss = 0.06834723055362701, train/logprobs = tensor([[-0.8837, -9.6557],
        [-3.3442, -1.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21080178022384644
Epoch 0, Step 1755: train/loss = 0.33765172958374023, train/raw-loss = 0.2703418433666229, train/logprobs = tensor([[-1.3068, -3.1917],
        [-2.3115, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16827479004859924
Epoch 0, Step 1756: train/loss = 0.4709489643573761, train/raw-loss = 0.4117172360420227, train/logprobs = tensor([[-1.5400, -3.4663],
        [-1.6685, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14807943999767303
Epoch 0, Step 1757: train/loss = 0.6123687624931335, train/raw-loss = 0.542150616645813, train/logprobs = tensor([[-0.9608, -1.1966],
        [-1.4086, -0.8198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.175545334815979
Epoch 0, Step 1758: train/loss = 0.3103581964969635, train/raw-loss = 0.251041442155838, train/logprobs = tensor([[-0.7448, -6.6385],
        [-1.4488, -1.4106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1482919156551361
Epoch 0, Step 1759: train/loss = 0.42531150579452515, train/raw-loss = 0.3733694851398468, train/logprobs = tensor([[-0.6829, -2.5968],
        [-1.9008, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12985511124134064
Epoch 0, Step 1760: train/loss = 0.5448722839355469, train/raw-loss = 0.47480708360671997, train/logprobs = tensor([[-0.8751, -5.5459],
        [-2.6318, -1.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1751629263162613
Epoch 0, Step 1761: train/loss = 0.24886126816272736, train/raw-loss = 0.1727108359336853, train/logprobs = tensor([[-0.6980, -4.5057],
        [-1.9541, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19037610292434692
Epoch 0, Step 1762: train/loss = 0.43820804357528687, train/raw-loss = 0.3724020719528198, train/logprobs = tensor([[-0.8659, -5.2039],
        [-1.8374, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16451480984687805
Epoch 0, Step 1763: train/loss = 0.4699728488922119, train/raw-loss = 0.39833396673202515, train/logprobs = tensor([[-1.4229, -5.9555],
        [-1.2727, -1.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790972203016281
Epoch 0, Step 1764: train/loss = 0.21552422642707825, train/raw-loss = 0.14842069149017334, train/logprobs = tensor([[-0.5022, -5.6056],
        [-1.6715, -1.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16775882244110107
Epoch 0, Step 1765: train/loss = 0.4895396828651428, train/raw-loss = 0.41455909609794617, train/logprobs = tensor([[-0.5469, -3.1958],
        [-1.3381, -1.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1874515414237976
Epoch 0, Step 1766: train/loss = 0.31584420800209045, train/raw-loss = 0.25691115856170654, train/logprobs = tensor([[-1.1328, -6.4678],
        [-1.9595, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14733266830444336
Epoch 0, Step 1767: train/loss = 0.28723350167274475, train/raw-loss = 0.2237005978822708, train/logprobs = tensor([[ -0.5390, -10.4826],
        [ -1.5122,  -1.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15883229672908783
Epoch 0, Step 1768: train/loss = 0.3351375460624695, train/raw-loss = 0.25214439630508423, train/logprobs = tensor([[-0.8626, -4.4491],
        [-2.6417, -2.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2074829339981079
Epoch 0, Step 1769: train/loss = 0.26767319440841675, train/raw-loss = 0.202720507979393, train/logprobs = tensor([[-0.8078, -3.5768],
        [-2.5249, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16238170862197876
Epoch 0, Step 1770: train/loss = 0.30651021003723145, train/raw-loss = 0.24967558681964874, train/logprobs = tensor([[ -0.9844, -11.5125],
        [ -1.7308,  -1.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14208652079105377
Epoch 0, Step 1771: train/loss = 0.4561377167701721, train/raw-loss = 0.385333776473999, train/logprobs = tensor([[-0.8516, -3.5318],
        [-2.0359, -1.1008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17700985074043274
Epoch 0, Step 1772: train/loss = 0.31688112020492554, train/raw-loss = 0.2532508671283722, train/logprobs = tensor([[-0.9384, -4.4827],
        [-1.6775, -1.3203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15907566249370575
Epoch 0, Step 1773: train/loss = 0.2515801191329956, train/raw-loss = 0.17078259587287903, train/logprobs = tensor([[-0.7662, -7.1183],
        [-1.9744, -1.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20199377834796906
Epoch 0, Step 1774: train/loss = 0.5747087001800537, train/raw-loss = 0.49785733222961426, train/logprobs = tensor([[-1.8669, -3.6150],
        [-2.3444, -1.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19212859869003296
Epoch 0, Step 1775: train/loss = 0.4556175470352173, train/raw-loss = 0.38453352451324463, train/logprobs = tensor([[-0.8404, -2.3838],
        [-1.6912, -1.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17770996689796448
Epoch 0, Step 1776: train/loss = 0.6070788502693176, train/raw-loss = 0.5360257625579834, train/logprobs = tensor([[-2.3661, -8.2922],
        [-2.5016, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1776326298713684
Epoch 0, Step 1777: train/loss = 0.4264514148235321, train/raw-loss = 0.3473418056964874, train/logprobs = tensor([[-0.5188, -4.2232],
        [-2.0165, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19777394831180573
Epoch 0, Step 1778: train/loss = 0.37807852029800415, train/raw-loss = 0.3005427420139313, train/logprobs = tensor([[-1.1487, -5.1926],
        [-2.0652, -1.0190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19383946061134338
Epoch 0, Step 1779: train/loss = 0.48568660020828247, train/raw-loss = 0.420849084854126, train/logprobs = tensor([[-0.5829, -6.9508],
        [-1.2942, -1.2684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16209381818771362
Epoch 0, Step 1780: train/loss = 0.42632031440734863, train/raw-loss = 0.3561326265335083, train/logprobs = tensor([[-0.4452, -4.7768],
        [-1.2261, -1.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17546923458576202
Epoch 0, Step 1781: train/loss = 0.3525037467479706, train/raw-loss = 0.27737957239151, train/logprobs = tensor([[-0.6688, -3.9239],
        [-1.8266, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187810480594635
Epoch 0, Step 1782: train/loss = 0.22723031044006348, train/raw-loss = 0.16731363534927368, train/logprobs = tensor([[-0.5080, -6.4789],
        [-1.3853, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497916877269745
Epoch 0, Step 1783: train/loss = 0.40470415353775024, train/raw-loss = 0.3261685371398926, train/logprobs = tensor([[-0.9351, -4.5109],
        [-2.5701, -0.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1963389813899994
Epoch 0, Step 1784: train/loss = 0.5146870613098145, train/raw-loss = 0.4575442969799042, train/logprobs = tensor([[-1.3493, -3.1295],
        [-1.3454, -0.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14285698533058167
Epoch 0, Step 1785: train/loss = 0.5103777050971985, train/raw-loss = 0.4359840452671051, train/logprobs = tensor([[-0.9482, -3.4748],
        [-1.4419, -1.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1859840750694275
Epoch 0, Step 1786: train/loss = 0.5500686168670654, train/raw-loss = 0.49061456322669983, train/logprobs = tensor([[-0.5955, -2.3921],
        [-1.1087, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14863508939743042
Epoch 0, Step 1787: train/loss = 0.4861118197441101, train/raw-loss = 0.40513908863067627, train/logprobs = tensor([[-1.2257, -3.4117],
        [-2.0427, -1.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2024318128824234
Epoch 0, Step 1788: train/loss = 0.4468010663986206, train/raw-loss = 0.39036184549331665, train/logprobs = tensor([[-0.5211, -3.2066],
        [-0.7744, -0.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14109815657138824
Epoch 0, Step 1789: train/loss = 0.31806308031082153, train/raw-loss = 0.2508189380168915, train/logprobs = tensor([[-1.0352, -5.2736],
        [-2.1297, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16811037063598633
Epoch 0, Step 1790: train/loss = 0.27495628595352173, train/raw-loss = 0.2024787962436676, train/logprobs = tensor([[-0.8518, -6.7913],
        [-2.1299, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1811937391757965
Epoch 0, Step 1791: train/loss = 0.4174385070800781, train/raw-loss = 0.3462298512458801, train/logprobs = tensor([[-1.1597, -2.8048],
        [-2.1861, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17802168428897858
Epoch 0, Step 1792: train/loss = 0.345032662153244, train/raw-loss = 0.2622310519218445, train/logprobs = tensor([[-0.7083, -4.4050],
        [-2.1655, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20700405538082123
Epoch 0, Step 1793: train/loss = 0.2924863398075104, train/raw-loss = 0.2197927087545395, train/logprobs = tensor([[-0.8997, -6.3960],
        [-2.0295, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1817341148853302
Epoch 0, Step 1794: train/loss = 0.33009791374206543, train/raw-loss = 0.2652443051338196, train/logprobs = tensor([[-1.1379, -3.0484],
        [-2.4005, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1621340811252594
Epoch 0, Step 1795: train/loss = 0.24817952513694763, train/raw-loss = 0.18883420526981354, train/logprobs = tensor([[-0.5041, -8.0924],
        [-2.3882, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14836327731609344
Epoch 0, Step 1796: train/loss = 0.5126626491546631, train/raw-loss = 0.45537811517715454, train/logprobs = tensor([[-0.6663, -1.8359],
        [-1.0630, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1432114839553833
Epoch 0, Step 1797: train/loss = 0.41604650020599365, train/raw-loss = 0.3468019962310791, train/logprobs = tensor([[-1.8698, -9.8711],
        [-2.3641, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17311127483844757
Epoch 0, Step 1798: train/loss = 0.3048696517944336, train/raw-loss = 0.23326608538627625, train/logprobs = tensor([[-1.0142, -6.8043],
        [-3.9042, -2.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790088415145874
Epoch 0, Step 1799: train/loss = 0.39720088243484497, train/raw-loss = 0.3365705907344818, train/logprobs = tensor([[-1.0035, -5.3619],
        [-1.8712, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15157568454742432
Epoch 0, Step 1800: train/loss = 0.17427143454551697, train/raw-loss = 0.09824331104755402, train/logprobs = tensor([[ -0.7520, -10.5497],
        [ -2.4771,  -1.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19007034599781036
Epoch 0, Step 1801: train/loss = 0.3068431615829468, train/raw-loss = 0.24036768078804016, train/logprobs = tensor([[-0.8202, -5.7709],
        [-2.4158, -0.7919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16618871688842773
Epoch 0, Step 1802: train/loss = 0.4415231943130493, train/raw-loss = 0.37416520714759827, train/logprobs = tensor([[-1.1915, -5.7247],
        [-1.6012, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16839496791362762
Epoch 0, Step 1803: train/loss = 0.33917343616485596, train/raw-loss = 0.26957863569259644, train/logprobs = tensor([[-1.0511, -5.8608],
        [-1.8192, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1739870309829712
Epoch 0, Step 1804: train/loss = 0.4599054455757141, train/raw-loss = 0.39361679553985596, train/logprobs = tensor([[-0.9483, -3.3327],
        [-1.8724, -0.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1657216101884842
Epoch 0, Step 1805: train/loss = 0.36729922890663147, train/raw-loss = 0.30690741539001465, train/logprobs = tensor([[-0.7032, -3.4040],
        [-2.1382, -0.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15097948908805847
Epoch 0, Step 1806: train/loss = 0.30104756355285645, train/raw-loss = 0.24667087197303772, train/logprobs = tensor([[-0.6519, -4.7074],
        [-2.0147, -0.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13594169914722443
Epoch 0, Step 1807: train/loss = 0.6114583611488342, train/raw-loss = 0.5509948134422302, train/logprobs = tensor([[-0.5068, -3.2567],
        [-1.0319, -1.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15115877985954285
Epoch 0, Step 1808: train/loss = 0.3189074397087097, train/raw-loss = 0.2566230297088623, train/logprobs = tensor([[-0.5660, -5.5684],
        [-1.3929, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557110995054245
Epoch 0, Step 1809: train/loss = 0.35202521085739136, train/raw-loss = 0.2842525839805603, train/logprobs = tensor([[-0.6764, -9.4277],
        [-1.5345, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1694316565990448
Epoch 0, Step 1810: train/loss = 0.4334124028682709, train/raw-loss = 0.38096439838409424, train/logprobs = tensor([[-0.8140, -2.3903],
        [-1.7653, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13112002611160278
Epoch 0, Step 1811: train/loss = 0.42514750361442566, train/raw-loss = 0.3638644218444824, train/logprobs = tensor([[-0.9836, -5.7764],
        [-1.7928, -1.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15320764482021332
Epoch 0, Step 1812: train/loss = 0.1606750190258026, train/raw-loss = 0.08491051197052002, train/logprobs = tensor([[-1.6437, -8.7749],
        [-3.4744, -1.2607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894112378358841
Epoch 0, Step 1813: train/loss = 0.21932482719421387, train/raw-loss = 0.15990588068962097, train/logprobs = tensor([[-0.8867, -9.7855],
        [-2.1302, -2.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14854741096496582
Epoch 0, Step 1814: train/loss = 0.34697723388671875, train/raw-loss = 0.26484444737434387, train/logprobs = tensor([[-0.7165, -3.2442],
        [-1.9493, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20533189177513123
Epoch 0, Step 1815: train/loss = 0.22646644711494446, train/raw-loss = 0.16317319869995117, train/logprobs = tensor([[-0.8192, -8.5800],
        [-1.9403, -1.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15823307633399963
Epoch 0, Step 1816: train/loss = 0.3348463177680969, train/raw-loss = 0.27075135707855225, train/logprobs = tensor([[-0.6923, -4.5303],
        [-1.0796, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1602374017238617
Epoch 0, Step 1817: train/loss = 0.647309422492981, train/raw-loss = 0.5924174189567566, train/logprobs = tensor([[-0.7595, -1.0071],
        [-1.0552, -0.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13722993433475494
Epoch 0, Step 1818: train/loss = 0.23041307926177979, train/raw-loss = 0.15447482466697693, train/logprobs = tensor([[-0.7366, -8.6679],
        [-2.4394, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18984562158584595
Epoch 0, Step 1819: train/loss = 0.369070827960968, train/raw-loss = 0.300190806388855, train/logprobs = tensor([[-0.9687, -5.4654],
        [-1.7705, -0.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17220008373260498
Epoch 0, Step 1820: train/loss = 0.39771848917007446, train/raw-loss = 0.32975858449935913, train/logprobs = tensor([[-0.6763, -4.2667],
        [-1.4980, -0.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16989976167678833
Epoch 0, Step 1821: train/loss = 0.3015195429325104, train/raw-loss = 0.23198434710502625, train/logprobs = tensor([[-0.7234, -6.1004],
        [-1.6552, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17383798956871033
Epoch 0, Step 1822: train/loss = 0.41283518075942993, train/raw-loss = 0.336455374956131, train/logprobs = tensor([[-0.9738, -3.4144],
        [-1.4751, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19094954431056976
Epoch 0, Step 1823: train/loss = 0.4606364667415619, train/raw-loss = 0.37133002281188965, train/logprobs = tensor([[-0.5645, -3.7908],
        [-2.3464, -1.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22326600551605225
Epoch 0, Step 1824: train/loss = 0.4126078486442566, train/raw-loss = 0.347809761762619, train/logprobs = tensor([[-0.6044, -3.3366],
        [-1.7060, -0.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1619952768087387
Epoch 0, Step 1825: train/loss = 0.364551305770874, train/raw-loss = 0.28694263100624084, train/logprobs = tensor([[-0.8079, -4.8835],
        [-2.1533, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19402174651622772
Epoch 0, Step 1826: train/loss = 0.3217589259147644, train/raw-loss = 0.2601403594017029, train/logprobs = tensor([[-1.1136, -6.2033],
        [-1.8065, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1540464460849762
Epoch 0, Step 1827: train/loss = 0.3148220181465149, train/raw-loss = 0.22401632368564606, train/logprobs = tensor([[-0.7669, -2.9076],
        [-2.3067, -1.3335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22701430320739746
Epoch 0, Step 1828: train/loss = 0.24057289958000183, train/raw-loss = 0.16421547532081604, train/logprobs = tensor([[-1.2122, -8.0073],
        [-2.7652, -1.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19089362025260925
Epoch 0, Step 1829: train/loss = 0.45243433117866516, train/raw-loss = 0.39607667922973633, train/logprobs = tensor([[-0.7049, -3.6253],
        [-0.8896, -0.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14089414477348328
Epoch 0, Step 1830: train/loss = 0.44842249155044556, train/raw-loss = 0.3918938636779785, train/logprobs = tensor([[-0.4514, -4.0163],
        [-1.0949, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14132149517536163
Epoch 0, Step 1831: train/loss = 0.695843517780304, train/raw-loss = 0.6367238759994507, train/logprobs = tensor([[-0.5204, -0.7316],
        [-0.7585, -0.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1477990448474884
Epoch 0, Step 1832: train/loss = 0.3494436740875244, train/raw-loss = 0.283900648355484, train/logprobs = tensor([[-0.5149, -4.2031],
        [-1.0442, -1.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16385747492313385
Epoch 0, Step 1833: train/loss = 0.5720381736755371, train/raw-loss = 0.4996100068092346, train/logprobs = tensor([[-0.4429, -2.0731],
        [-0.9713, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18107056617736816
Epoch 0, Step 1834: train/loss = 0.4953230917453766, train/raw-loss = 0.4205422103404999, train/logprobs = tensor([[-1.3578, -5.1916],
        [-1.2287, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1869521588087082
Epoch 0, Step 1835: train/loss = 0.22578398883342743, train/raw-loss = 0.1593354195356369, train/logprobs = tensor([[ -0.5251, -10.2407],
        [ -1.4856,  -2.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16612140834331512
Epoch 0, Step 1836: train/loss = 0.17896459996700287, train/raw-loss = 0.09464345127344131, train/logprobs = tensor([[-1.1110, -6.7779],
        [-3.0222, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21080288290977478
Epoch 0, Step 1837: train/loss = 0.355648010969162, train/raw-loss = 0.29402464628219604, train/logprobs = tensor([[-0.9490, -6.0015],
        [-1.8591, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15405838191509247
Epoch 0, Step 1838: train/loss = 0.33733290433883667, train/raw-loss = 0.2686554491519928, train/logprobs = tensor([[-0.9312, -4.5393],
        [-1.2978, -0.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17169365286827087
Epoch 0, Step 1839: train/loss = 0.3022693693637848, train/raw-loss = 0.23148801922798157, train/logprobs = tensor([[-0.8974, -5.2036],
        [-1.6922, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17695336043834686
Epoch 0, Step 1840: train/loss = 0.23953130841255188, train/raw-loss = 0.16764022409915924, train/logprobs = tensor([[ -1.1794, -10.7602],
        [ -2.2137,  -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1797277182340622
Epoch 0, Step 1841: train/loss = 0.41149330139160156, train/raw-loss = 0.34322506189346313, train/logprobs = tensor([[-0.5540, -4.0763],
        [-1.7747, -0.6168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17067062854766846
Epoch 0, Step 1842: train/loss = 0.348564088344574, train/raw-loss = 0.28570085763931274, train/logprobs = tensor([[-1.1521, -7.7280],
        [-1.6474, -1.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15715810656547546
Epoch 0, Step 1843: train/loss = 0.2162596881389618, train/raw-loss = 0.14720605313777924, train/logprobs = tensor([[-1.0991, -8.4443],
        [-2.7762, -1.2931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1726340800523758
Epoch 0, Step 1844: train/loss = 0.3283090591430664, train/raw-loss = 0.23617872595787048, train/logprobs = tensor([[-1.0205, -4.4698],
        [-2.8282, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23032580316066742
Epoch 0, Step 1845: train/loss = 0.21518340706825256, train/raw-loss = 0.14202098548412323, train/logprobs = tensor([[-0.9419, -8.9552],
        [-2.3530, -0.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18290603160858154
Epoch 0, Step 1846: train/loss = 0.4881676435470581, train/raw-loss = 0.42152443528175354, train/logprobs = tensor([[-0.6172, -3.7898],
        [-1.6871, -1.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666080355644226
Epoch 0, Step 1847: train/loss = 0.19839422404766083, train/raw-loss = 0.12591108679771423, train/logprobs = tensor([[-0.7692, -4.9169],
        [-2.4949, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1812078356742859
Epoch 0, Step 1848: train/loss = 0.4079199731349945, train/raw-loss = 0.35097914934158325, train/logprobs = tensor([[-0.6606, -2.9188],
        [-1.9046, -1.3864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14235210418701172
Epoch 0, Step 1849: train/loss = 0.43746140599250793, train/raw-loss = 0.3880506157875061, train/logprobs = tensor([[-0.5938, -3.6152],
        [-1.1187, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12352700531482697
Epoch 0, Step 1850: train/loss = 0.2512139678001404, train/raw-loss = 0.19018319249153137, train/logprobs = tensor([[-0.9648, -6.7938],
        [-1.7187, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15257695317268372
Epoch 0, Step 1851: train/loss = 0.16882449388504028, train/raw-loss = 0.0936693325638771, train/logprobs = tensor([[-0.7636, -6.2096],
        [-2.8159, -0.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18788790702819824
Epoch 0, Step 1852: train/loss = 0.18327882885932922, train/raw-loss = 0.11970663070678711, train/logprobs = tensor([[ -0.9587, -10.8492],
        [ -2.6105,  -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15893049538135529
Epoch 0, Step 1853: train/loss = 0.409557044506073, train/raw-loss = 0.35279345512390137, train/logprobs = tensor([[-0.6747, -7.4714],
        [-1.3451, -1.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190888404846191
Epoch 0, Step 1854: train/loss = 1.0100162029266357, train/raw-loss = 0.9545631408691406, train/logprobs = tensor([[-3.3036, -4.8776],
        [-1.8215, -2.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386323869228363
Epoch 0, Step 1855: train/loss = 0.254887193441391, train/raw-loss = 0.1769161820411682, train/logprobs = tensor([[ -0.7776, -10.1284],
        [ -2.8752,  -2.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19492749869823456
Epoch 0, Step 1856: train/loss = 0.2627147436141968, train/raw-loss = 0.20012982189655304, train/logprobs = tensor([[-0.4929, -8.4196],
        [-1.6855, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15646229684352875
Epoch 0, Step 1857: train/loss = 0.24327704310417175, train/raw-loss = 0.17329499125480652, train/logprobs = tensor([[-0.9084, -5.7407],
        [-2.2252, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17495512962341309
Epoch 0, Step 1858: train/loss = 0.3947533071041107, train/raw-loss = 0.3174523711204529, train/logprobs = tensor([[-1.1677, -3.9667],
        [-1.6880, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1932523399591446
Epoch 0, Step 1859: train/loss = 0.35008805990219116, train/raw-loss = 0.280345618724823, train/logprobs = tensor([[-0.6316, -4.1489],
        [-1.5995, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17435608804225922
Epoch 0, Step 1860: train/loss = 0.38869601488113403, train/raw-loss = 0.3202296495437622, train/logprobs = tensor([[-0.7377, -5.4130],
        [-2.2570, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17116594314575195
Epoch 0, Step 1861: train/loss = 0.19037827849388123, train/raw-loss = 0.12140262126922607, train/logprobs = tensor([[-0.5924, -9.8790],
        [-2.0932, -1.5523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17243917286396027
Epoch 0, Step 1862: train/loss = 0.3531407117843628, train/raw-loss = 0.2837109863758087, train/logprobs = tensor([[-0.5277, -6.1044],
        [-1.3817, -1.4894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17357440292835236
Epoch 0, Step 1863: train/loss = 0.5078697800636292, train/raw-loss = 0.4334247410297394, train/logprobs = tensor([[-1.1098, -4.0412],
        [-1.9142, -1.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.186112642288208
Epoch 0, Step 1864: train/loss = 0.3498516082763672, train/raw-loss = 0.28512078523635864, train/logprobs = tensor([[-1.1431, -5.9994],
        [-1.8914, -1.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16182708740234375
Epoch 0, Step 1865: train/loss = 0.48968833684921265, train/raw-loss = 0.4297209680080414, train/logprobs = tensor([[-0.5168, -4.2270],
        [-0.9088, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14991848170757294
Epoch 0, Step 1866: train/loss = 0.4973120093345642, train/raw-loss = 0.43587538599967957, train/logprobs = tensor([[-1.0052, -3.0533],
        [-1.3918, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15359149873256683
Epoch 0, Step 1867: train/loss = 0.4714919924736023, train/raw-loss = 0.39743831753730774, train/logprobs = tensor([[-0.8424, -3.8590],
        [-2.2445, -1.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18513420224189758
Epoch 0, Step 1868: train/loss = 0.5337116718292236, train/raw-loss = 0.4697597920894623, train/logprobs = tensor([[-0.7110, -2.6589],
        [-1.2711, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15987975895404816
Epoch 0, Step 1869: train/loss = 0.48750361800193787, train/raw-loss = 0.4231179654598236, train/logprobs = tensor([[-1.4703, -5.7029],
        [-3.1487, -2.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16096416115760803
Epoch 0, Step 1870: train/loss = 0.22712412476539612, train/raw-loss = 0.16033419966697693, train/logprobs = tensor([[-1.4426, -8.5899],
        [-2.5555, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16697478294372559
Epoch 0, Step 1871: train/loss = 0.3726242780685425, train/raw-loss = 0.3135375678539276, train/logprobs = tensor([[-0.4282, -7.8604],
        [-1.0956, -1.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14771676063537598
Epoch 0, Step 1872: train/loss = 0.688713788986206, train/raw-loss = 0.6403990983963013, train/logprobs = tensor([[-0.6602, -0.8146],
        [-0.6889, -0.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12078677117824554
Epoch 0, Step 1873: train/loss = 0.5044679045677185, train/raw-loss = 0.43952691555023193, train/logprobs = tensor([[-0.8371, -3.7364],
        [-1.5694, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623525321483612
Epoch 0, Step 1874: train/loss = 0.21522395312786102, train/raw-loss = 0.15189900994300842, train/logprobs = tensor([[-0.5794, -6.9479],
        [-1.6794, -1.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15831232070922852
Epoch 0, Step 1875: train/loss = 0.46802854537963867, train/raw-loss = 0.4086613357067108, train/logprobs = tensor([[-0.9102, -3.5827],
        [-1.3841, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14841799437999725
Epoch 0, Step 1876: train/loss = 0.35143882036209106, train/raw-loss = 0.2883024215698242, train/logprobs = tensor([[-0.9797, -6.2803],
        [-1.5493, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15784096717834473
Epoch 0, Step 1877: train/loss = 0.3048022985458374, train/raw-loss = 0.22310708463191986, train/logprobs = tensor([[-0.8697, -8.9307],
        [-2.9739, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20423807203769684
Epoch 0, Step 1878: train/loss = 0.2614779770374298, train/raw-loss = 0.17876151204109192, train/logprobs = tensor([[-0.8720, -6.8368],
        [-2.4510, -1.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2067912369966507
Epoch 0, Step 1879: train/loss = 0.2732086777687073, train/raw-loss = 0.19901816546916962, train/logprobs = tensor([[-0.9620, -6.8314],
        [-2.4318, -1.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18547633290290833
Epoch 0, Step 1880: train/loss = 0.4675246775150299, train/raw-loss = 0.4189854860305786, train/logprobs = tensor([[-0.8957, -3.2812],
        [-1.5245, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12134792655706406
Epoch 0, Step 1881: train/loss = 0.39535441994667053, train/raw-loss = 0.3292955458164215, train/logprobs = tensor([[-0.9979, -3.3285],
        [-1.7882, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16514721512794495
Epoch 0, Step 1882: train/loss = 0.23778612911701202, train/raw-loss = 0.1479373574256897, train/logprobs = tensor([[-1.2660, -7.5804],
        [-3.7726, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22462187707424164
Epoch 0, Step 1883: train/loss = 0.40236324071884155, train/raw-loss = 0.33276912569999695, train/logprobs = tensor([[-1.1340, -3.0294],
        [-2.0281, -0.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1739853024482727
Epoch 0, Step 1884: train/loss = 0.31710293889045715, train/raw-loss = 0.23880185186862946, train/logprobs = tensor([[-1.3257, -8.4713],
        [-2.2995, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19575272500514984
Epoch 0, Step 1885: train/loss = 0.3451252579689026, train/raw-loss = 0.2832871675491333, train/logprobs = tensor([[-0.8790, -5.7962],
        [-1.5203, -1.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545952409505844
Epoch 0, Step 1886: train/loss = 0.3869953751564026, train/raw-loss = 0.3200244903564453, train/logprobs = tensor([[-0.7129, -5.0216],
        [-2.5112, -1.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1674271821975708
Epoch 0, Step 1887: train/loss = 0.34850430488586426, train/raw-loss = 0.25565657019615173, train/logprobs = tensor([[-0.6683, -2.6199],
        [-2.4279, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2321193516254425
Epoch 0, Step 1888: train/loss = 0.6475136280059814, train/raw-loss = 0.591187596321106, train/logprobs = tensor([[-0.7936, -1.2064],
        [-0.9323, -0.8594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14081507921218872
Epoch 0, Step 1889: train/loss = 0.2550202012062073, train/raw-loss = 0.18230633437633514, train/logprobs = tensor([[-0.8639, -7.0806],
        [-1.9823, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1817847043275833
Epoch 0, Step 1890: train/loss = 0.4376145899295807, train/raw-loss = 0.37208521366119385, train/logprobs = tensor([[-1.1525, -3.5418],
        [-1.8242, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16382339596748352
Epoch 0, Step 1891: train/loss = 0.6214648485183716, train/raw-loss = 0.540930449962616, train/logprobs = tensor([[-1.9261, -4.6566],
        [-1.7544, -1.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2013360857963562
Epoch 0, Step 1892: train/loss = 0.5220045447349548, train/raw-loss = 0.4455293118953705, train/logprobs = tensor([[-1.2428, -3.0923],
        [-1.6089, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19118809700012207
Epoch 0, Step 1893: train/loss = 0.4715783894062042, train/raw-loss = 0.4041062593460083, train/logprobs = tensor([[-1.0015, -3.1679],
        [-1.6171, -0.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16868025064468384
Epoch 0, Step 1894: train/loss = 0.3910382390022278, train/raw-loss = 0.3144521117210388, train/logprobs = tensor([[-0.5593, -2.5130],
        [-1.9519, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1914653480052948
Epoch 0, Step 1895: train/loss = 0.4643841087818146, train/raw-loss = 0.4067670702934265, train/logprobs = tensor([[-0.4521, -4.8040],
        [-0.8954, -0.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14404255151748657
Epoch 0, Step 1896: train/loss = 0.25079867243766785, train/raw-loss = 0.19127817451953888, train/logprobs = tensor([[-0.8910, -7.6043],
        [-2.5710, -2.0405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880123734474182
Epoch 0, Step 1897: train/loss = 0.18577775359153748, train/raw-loss = 0.10853215306997299, train/logprobs = tensor([[-0.5559, -8.6054],
        [-1.9960, -1.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19311398267745972
Epoch 0, Step 1898: train/loss = 0.41461944580078125, train/raw-loss = 0.34992337226867676, train/logprobs = tensor([[-0.8553, -5.4776],
        [-1.5917, -0.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16174009442329407
Epoch 0, Step 1899: train/loss = 0.3067120611667633, train/raw-loss = 0.23280924558639526, train/logprobs = tensor([[-1.5567, -5.4683],
        [-3.2265, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1847570240497589
Epoch 0, Step 1900: train/loss = 0.3711498975753784, train/raw-loss = 0.30907678604125977, train/logprobs = tensor([[-1.3745, -5.6520],
        [-1.6015, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15518277883529663
Epoch 0, Step 1901: train/loss = 0.4739229679107666, train/raw-loss = 0.3970189094543457, train/logprobs = tensor([[-1.6305, -5.1067],
        [-2.2095, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19226005673408508
Epoch 0, Step 1902: train/loss = 0.4044745862483978, train/raw-loss = 0.3466208577156067, train/logprobs = tensor([[-0.8647, -4.9217],
        [-1.3068, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14463429152965546
Epoch 0, Step 1903: train/loss = 0.46414273977279663, train/raw-loss = 0.4071691334247589, train/logprobs = tensor([[-0.8041, -2.9600],
        [-1.2665, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424340307712555
Epoch 0, Step 1904: train/loss = 0.3602309823036194, train/raw-loss = 0.29964718222618103, train/logprobs = tensor([[-0.8669, -8.8267],
        [-1.4789, -1.4722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15145951509475708
Epoch 0, Step 1905: train/loss = 0.4171023368835449, train/raw-loss = 0.3499167263507843, train/logprobs = tensor([[-1.3558, -9.3957],
        [-1.6095, -1.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16796404123306274
Epoch 0, Step 1906: train/loss = 0.48144710063934326, train/raw-loss = 0.41275519132614136, train/logprobs = tensor([[-1.1151, -2.6908],
        [-1.4231, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17172983288764954
Epoch 0, Step 1907: train/loss = 0.3984311521053314, train/raw-loss = 0.33811092376708984, train/logprobs = tensor([[-0.8603, -6.1407],
        [-1.2940, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15080055594444275
Epoch 0, Step 1908: train/loss = 0.6022533774375916, train/raw-loss = 0.5319442749023438, train/logprobs = tensor([[-1.3968, -4.9250],
        [-1.2031, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17577286064624786
Epoch 0, Step 1909: train/loss = 0.342314749956131, train/raw-loss = 0.25189369916915894, train/logprobs = tensor([[-0.9545, -7.9996],
        [-3.2130, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2260526567697525
Epoch 0, Step 1910: train/loss = 0.36918801069259644, train/raw-loss = 0.3050552010536194, train/logprobs = tensor([[-0.8287, -5.1149],
        [-1.6707, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16033196449279785
Epoch 0, Step 1911: train/loss = 0.25910142064094543, train/raw-loss = 0.18632812798023224, train/logprobs = tensor([[-0.9779, -7.9284],
        [-2.6668, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18193319439888
Epoch 0, Step 1912: train/loss = 0.3997208774089813, train/raw-loss = 0.3193814158439636, train/logprobs = tensor([[-1.1050, -3.2206],
        [-2.1069, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20084859430789948
Epoch 0, Step 1913: train/loss = 0.3325415849685669, train/raw-loss = 0.2654584050178528, train/logprobs = tensor([[-0.8388, -3.8025],
        [-2.2977, -1.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16770796477794647
Epoch 0, Step 1914: train/loss = 0.17657718062400818, train/raw-loss = 0.10716990381479263, train/logprobs = tensor([[ -0.7287, -10.4455],
        [ -2.7550,  -2.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17351816594600677
Epoch 0, Step 1915: train/loss = 0.21443146467208862, train/raw-loss = 0.1487661898136139, train/logprobs = tensor([[ -0.9784, -10.0793],
        [ -2.3860,  -1.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16416320204734802
Epoch 0, Step 1916: train/loss = 0.46227753162384033, train/raw-loss = 0.3777761459350586, train/logprobs = tensor([[-0.6302, -3.3499],
        [-1.9214, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21125353872776031
Epoch 0, Step 1917: train/loss = 0.5749362707138062, train/raw-loss = 0.5166116952896118, train/logprobs = tensor([[-1.2517, -2.8158],
        [-1.3565, -1.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14581148326396942
Epoch 0, Step 1918: train/loss = 0.27275097370147705, train/raw-loss = 0.1780422031879425, train/logprobs = tensor([[-0.9226, -5.1364],
        [-3.1975, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23677194118499756
Epoch 0, Step 1919: train/loss = 0.20711402595043182, train/raw-loss = 0.13249558210372925, train/logprobs = tensor([[-0.8521, -8.1560],
        [-2.0847, -0.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18654613196849823
Epoch 0, Step 1920: train/loss = 0.2674267590045929, train/raw-loss = 0.1985749900341034, train/logprobs = tensor([[-0.7327, -5.0232],
        [-2.0883, -1.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17212939262390137
Epoch 0, Step 1921: train/loss = 0.32703742384910583, train/raw-loss = 0.25122368335723877, train/logprobs = tensor([[-0.6180, -9.4144],
        [-2.6021, -2.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18953441083431244
Epoch 0, Step 1922: train/loss = 0.16479310393333435, train/raw-loss = 0.08834236115217209, train/logprobs = tensor([[-0.8181, -8.5485],
        [-2.8984, -1.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19112685322761536
Epoch 0, Step 1923: train/loss = 0.30513110756874084, train/raw-loss = 0.23815999925136566, train/logprobs = tensor([[-0.6741, -8.7962],
        [-1.9621, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16742780804634094
Epoch 0, Step 1924: train/loss = 0.21887359023094177, train/raw-loss = 0.13535131514072418, train/logprobs = tensor([[-0.8057, -7.0747],
        [-1.9677, -0.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20880566537380219
Epoch 0, Step 1925: train/loss = 0.34358832240104675, train/raw-loss = 0.2705261707305908, train/logprobs = tensor([[-0.8760, -8.2094],
        [-2.0686, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18265540897846222
Epoch 0, Step 1926: train/loss = 0.4033046364784241, train/raw-loss = 0.3433634638786316, train/logprobs = tensor([[-0.8207, -3.9858],
        [-1.6928, -1.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14985300600528717
Epoch 0, Step 1927: train/loss = 0.2697564959526062, train/raw-loss = 0.1867295205593109, train/logprobs = tensor([[-1.2250, -6.5455],
        [-2.0394, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20756737887859344
Epoch 0, Step 1928: train/loss = 0.4111874997615814, train/raw-loss = 0.34590646624565125, train/logprobs = tensor([[-0.6485, -4.2114],
        [-1.5728, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16320258378982544
Epoch 0, Step 1929: train/loss = 0.3360782265663147, train/raw-loss = 0.27225640416145325, train/logprobs = tensor([[-0.6971, -5.5572],
        [-1.4931, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15955454111099243
Epoch 0, Step 1930: train/loss = 0.49073633551597595, train/raw-loss = 0.43516919016838074, train/logprobs = tensor([[-0.8196, -4.3833],
        [-0.6241, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13891783356666565
Epoch 0, Step 1931: train/loss = 0.6045443415641785, train/raw-loss = 0.5434690117835999, train/logprobs = tensor([[-1.1069, -3.8143],
        [-1.2900, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15268826484680176
Epoch 0, Step 1932: train/loss = 0.5305920839309692, train/raw-loss = 0.4633241891860962, train/logprobs = tensor([[-0.8166, -4.6104],
        [-1.8426, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16816960275173187
Epoch 0, Step 1933: train/loss = 0.5070866346359253, train/raw-loss = 0.43466028571128845, train/logprobs = tensor([[-1.3651, -3.6277],
        [-1.7301, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1810658872127533
Epoch 0, Step 1934: train/loss = 0.5083296895027161, train/raw-loss = 0.438930869102478, train/logprobs = tensor([[-0.9241, -2.8133],
        [-1.3181, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17349712550640106
Epoch 0, Step 1935: train/loss = 0.2695464491844177, train/raw-loss = 0.20389896631240845, train/logprobs = tensor([[-0.9400, -5.5897],
        [-2.6211, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641187071800232
Epoch 0, Step 1936: train/loss = 0.2351214736700058, train/raw-loss = 0.15906013548374176, train/logprobs = tensor([[ -0.6690, -10.6808],
        [ -1.8865,  -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1901533454656601
Epoch 0, Step 1937: train/loss = 0.636130690574646, train/raw-loss = 0.5769063234329224, train/logprobs = tensor([[-1.5999, -1.8405],
        [-1.8938, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14806096255779266
Epoch 0, Step 1938: train/loss = 0.7442110180854797, train/raw-loss = 0.6693311333656311, train/logprobs = tensor([[-2.6213, -5.8022],
        [-1.7475, -2.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1871996372938156
Epoch 0, Step 1939: train/loss = 0.4639546871185303, train/raw-loss = 0.40526801347732544, train/logprobs = tensor([[-0.7200, -2.7345],
        [-1.0321, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14671671390533447
Epoch 0, Step 1940: train/loss = 0.5000007152557373, train/raw-loss = 0.43638214468955994, train/logprobs = tensor([[-1.1679, -6.2081],
        [-1.6469, -1.3432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15904638171195984
Epoch 0, Step 1941: train/loss = 0.7103298902511597, train/raw-loss = 0.6270512342453003, train/logprobs = tensor([[-1.8452, -3.1181],
        [-2.1326, -1.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20819665491580963
Epoch 0, Step 1942: train/loss = 0.35613617300987244, train/raw-loss = 0.2737269103527069, train/logprobs = tensor([[-1.1468, -6.4666],
        [-2.6056, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20602314174175262
Epoch 0, Step 1943: train/loss = 0.2915864586830139, train/raw-loss = 0.20765654742717743, train/logprobs = tensor([[-0.7140, -6.9181],
        [-2.4652, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20982471108436584
Epoch 0, Step 1944: train/loss = 0.5026853084564209, train/raw-loss = 0.44444960355758667, train/logprobs = tensor([[-0.8892, -2.1098],
        [-1.5183, -0.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14558933675289154
Epoch 0, Step 1945: train/loss = 0.4487491548061371, train/raw-loss = 0.3796745836734772, train/logprobs = tensor([[-0.5678, -2.7096],
        [-1.5699, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17268642783164978
Epoch 0, Step 1946: train/loss = 0.6627557277679443, train/raw-loss = 0.5846359133720398, train/logprobs = tensor([[-2.0185, -5.9241],
        [-1.3090, -2.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19529971480369568
Epoch 0, Step 1947: train/loss = 0.5650168061256409, train/raw-loss = 0.5038278698921204, train/logprobs = tensor([[-0.8501, -1.4594],
        [-1.2731, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15297231078147888
Epoch 0, Step 1948: train/loss = 0.3532126545906067, train/raw-loss = 0.29495108127593994, train/logprobs = tensor([[-0.5562, -6.2741],
        [-1.0688, -0.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14565390348434448
Epoch 0, Step 1949: train/loss = 0.4030792713165283, train/raw-loss = 0.34216412901878357, train/logprobs = tensor([[-0.8139, -4.4672],
        [-1.3726, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15228785574436188
Epoch 0, Step 1950: train/loss = 0.3367759585380554, train/raw-loss = 0.2726558744907379, train/logprobs = tensor([[-1.0028, -7.6545],
        [-1.5359, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16030022501945496
Epoch 0, Step 1951: train/loss = 0.30514487624168396, train/raw-loss = 0.23688359558582306, train/logprobs = tensor([[-0.8668, -4.2916],
        [-2.5929, -1.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17065313458442688
Epoch 0, Step 1952: train/loss = 0.39158058166503906, train/raw-loss = 0.321713387966156, train/logprobs = tensor([[-0.7950, -3.8222],
        [-2.4811, -1.3312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17466792464256287
Epoch 0, Step 1953: train/loss = 0.39050769805908203, train/raw-loss = 0.3318077325820923, train/logprobs = tensor([[-0.8881, -7.0752],
        [-1.4638, -1.2811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14674994349479675
Epoch 0, Step 1954: train/loss = 0.24981263279914856, train/raw-loss = 0.18711280822753906, train/logprobs = tensor([[-0.9111, -8.3320],
        [-2.0761, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15674950182437897
Epoch 0, Step 1955: train/loss = 0.33070576190948486, train/raw-loss = 0.2586224377155304, train/logprobs = tensor([[-1.5421, -6.0543],
        [-2.4553, -1.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18020835518836975
Epoch 0, Step 1956: train/loss = 0.5052745342254639, train/raw-loss = 0.41800451278686523, train/logprobs = tensor([[-0.8042, -4.5161],
        [-1.8134, -2.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21817508339881897
Epoch 0, Step 1957: train/loss = 0.4008324146270752, train/raw-loss = 0.3214499056339264, train/logprobs = tensor([[-0.7860, -6.2401],
        [-2.4149, -0.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19845616817474365
Epoch 0, Step 1958: train/loss = 0.22378838062286377, train/raw-loss = 0.14877015352249146, train/logprobs = tensor([[ -1.3205, -11.2185],
        [ -2.7051,  -1.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1875455528497696
Epoch 0, Step 1959: train/loss = 0.2750976085662842, train/raw-loss = 0.19443798065185547, train/logprobs = tensor([[-0.8794, -9.7101],
        [-2.6500, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.201649010181427
Epoch 0, Step 1960: train/loss = 0.29892265796661377, train/raw-loss = 0.22092488408088684, train/logprobs = tensor([[-0.8383, -7.9896],
        [-2.4026, -1.5945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19499443471431732
Epoch 0, Step 1961: train/loss = 0.21180978417396545, train/raw-loss = 0.13701918721199036, train/logprobs = tensor([[-0.6770, -8.1169],
        [-1.7844, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18697649240493774
Epoch 0, Step 1962: train/loss = 0.5943173170089722, train/raw-loss = 0.5106970071792603, train/logprobs = tensor([[-0.6296, -1.4985],
        [-1.3000, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20905077457427979
Epoch 0, Step 1963: train/loss = 0.4418147802352905, train/raw-loss = 0.36663275957107544, train/logprobs = tensor([[-0.8456, -6.6977],
        [-1.5470, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18795500695705414
Epoch 0, Step 1964: train/loss = 0.3034335970878601, train/raw-loss = 0.2408827543258667, train/logprobs = tensor([[-0.5434, -5.1074],
        [-1.5597, -1.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15637709200382233
Epoch 0, Step 1965: train/loss = 0.5130646228790283, train/raw-loss = 0.4540185332298279, train/logprobs = tensor([[-0.6828, -1.8115],
        [-1.1209, -0.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14761507511138916
Epoch 0, Step 1966: train/loss = 0.1965966820716858, train/raw-loss = 0.1280767321586609, train/logprobs = tensor([[ -0.9387, -14.1921],
        [ -2.0544,  -1.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129987478256226
Epoch 0, Step 1967: train/loss = 0.4370974898338318, train/raw-loss = 0.36218202114105225, train/logprobs = tensor([[-1.5407, -5.4275],
        [-1.5504, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18728870153427124
Epoch 0, Step 1968: train/loss = 0.5033460259437561, train/raw-loss = 0.42870384454727173, train/logprobs = tensor([[-0.9975, -4.6615],
        [-2.1635, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18660543859004974
Epoch 0, Step 1969: train/loss = 0.25767168402671814, train/raw-loss = 0.18122223019599915, train/logprobs = tensor([[-0.7947, -9.3920],
        [-2.6717, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19112366437911987
Epoch 0, Step 1970: train/loss = 0.3012927770614624, train/raw-loss = 0.22563928365707397, train/logprobs = tensor([[-1.0623, -7.8741],
        [-1.7448, -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18913374841213226
Epoch 0, Step 1971: train/loss = 0.2979125380516052, train/raw-loss = 0.23279637098312378, train/logprobs = tensor([[-0.6862, -5.2977],
        [-1.9622, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16279040277004242
Epoch 0, Step 1972: train/loss = 0.25848817825317383, train/raw-loss = 0.16570636630058289, train/logprobs = tensor([[-0.9471, -5.9401],
        [-2.7820, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23195447027683258
Epoch 0, Step 1973: train/loss = 0.29019981622695923, train/raw-loss = 0.20974430441856384, train/logprobs = tensor([[-0.9050, -6.3261],
        [-3.2043, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20113879442214966
Epoch 0, Step 1974: train/loss = 0.2979239523410797, train/raw-loss = 0.2134665846824646, train/logprobs = tensor([[-0.8669, -6.0622],
        [-2.1220, -1.2982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21114341914653778
Epoch 0, Step 1975: train/loss = 0.4727901518344879, train/raw-loss = 0.4148254990577698, train/logprobs = tensor([[-0.7660, -3.2544],
        [-1.4926, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14491157233715057
Epoch 0, Step 1976: train/loss = 0.3213736116886139, train/raw-loss = 0.2516220211982727, train/logprobs = tensor([[-0.8340, -7.4738],
        [-1.7750, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17437899112701416
Epoch 0, Step 1977: train/loss = 0.16501036286354065, train/raw-loss = 0.0930907130241394, train/logprobs = tensor([[ -0.9223, -12.5337],
        [ -2.5926,  -1.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1797991693019867
Epoch 0, Step 1978: train/loss = 0.30550557374954224, train/raw-loss = 0.2248651683330536, train/logprobs = tensor([[-0.7187, -5.0859],
        [-1.7951, -1.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20160099864006042
Epoch 0, Step 1979: train/loss = 0.40729954838752747, train/raw-loss = 0.3215610980987549, train/logprobs = tensor([[-0.9199, -5.4048],
        [-2.1556, -1.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21434615552425385
Epoch 0, Step 1980: train/loss = 0.3204212188720703, train/raw-loss = 0.24959322810173035, train/logprobs = tensor([[-1.2849, -5.0690],
        [-2.1648, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770699918270111
Epoch 0, Step 1981: train/loss = 0.19451847672462463, train/raw-loss = 0.11810965090990067, train/logprobs = tensor([[-0.7111, -8.8253],
        [-2.6347, -1.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19102203845977783
Epoch 0, Step 1982: train/loss = 0.4471238851547241, train/raw-loss = 0.37899842858314514, train/logprobs = tensor([[-1.2382, -2.4347],
        [-1.8611, -1.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17031364142894745
Epoch 0, Step 1983: train/loss = 0.49540847539901733, train/raw-loss = 0.4388391375541687, train/logprobs = tensor([[-0.5745, -1.9995],
        [-1.1862, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14142337441444397
Epoch 0, Step 1984: train/loss = 0.25959765911102295, train/raw-loss = 0.1926790475845337, train/logprobs = tensor([[-1.3193, -8.4312],
        [-2.1486, -0.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16729655861854553
Epoch 0, Step 1985: train/loss = 0.4687831699848175, train/raw-loss = 0.4016874134540558, train/logprobs = tensor([[-0.9992, -3.3905],
        [-1.7205, -1.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16773943603038788
Epoch 0, Step 1986: train/loss = 0.5988332629203796, train/raw-loss = 0.5396640300750732, train/logprobs = tensor([[-1.0765, -3.8019],
        [-1.3063, -1.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14792309701442719
Epoch 0, Step 1987: train/loss = 0.5251641273498535, train/raw-loss = 0.46511250734329224, train/logprobs = tensor([[-1.5366, -5.8719],
        [-1.6392, -2.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501290649175644
Epoch 0, Step 1988: train/loss = 0.49707964062690735, train/raw-loss = 0.44974640011787415, train/logprobs = tensor([[-0.4229, -3.7086],
        [-1.0580, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11833308637142181
Epoch 0, Step 1989: train/loss = 0.4474356174468994, train/raw-loss = 0.38399049639701843, train/logprobs = tensor([[-0.8954, -4.3345],
        [-0.9455, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15861281752586365
Epoch 0, Step 1990: train/loss = 0.21335533261299133, train/raw-loss = 0.1393745243549347, train/logprobs = tensor([[ -0.7199, -12.3732],
        [ -2.2410,  -1.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18495196104049683
Epoch 0, Step 1991: train/loss = 0.3093581795692444, train/raw-loss = 0.2383572906255722, train/logprobs = tensor([[-0.8464, -7.2759],
        [-2.1609, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17750215530395508
Epoch 0, Step 1992: train/loss = 0.5176211595535278, train/raw-loss = 0.4222562313079834, train/logprobs = tensor([[-1.4073, -5.7550],
        [-1.8231, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384122908115387
Epoch 0, Step 1993: train/loss = 0.47183775901794434, train/raw-loss = 0.40798163414001465, train/logprobs = tensor([[-1.1730, -4.3774],
        [-1.3257, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15964026749134064
Epoch 0, Step 1994: train/loss = 0.3280259072780609, train/raw-loss = 0.2593023180961609, train/logprobs = tensor([[-0.6364, -4.6589],
        [-1.9799, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17180900275707245
Epoch 0, Step 1995: train/loss = 0.2504943609237671, train/raw-loss = 0.18135271966457367, train/logprobs = tensor([[-0.8547, -5.6444],
        [-2.3558, -0.7124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17285408079624176
Epoch 0, Step 1996: train/loss = 0.4299107789993286, train/raw-loss = 0.3704426884651184, train/logprobs = tensor([[-0.9342, -2.7451],
        [-1.8384, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14867033064365387
Epoch 0, Step 1997: train/loss = 0.3979010581970215, train/raw-loss = 0.3134254813194275, train/logprobs = tensor([[-0.7993, -6.6327],
        [-1.9877, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21118894219398499
Epoch 0, Step 1998: train/loss = 0.5752992630004883, train/raw-loss = 0.516295313835144, train/logprobs = tensor([[-0.7869, -2.6375],
        [-1.5198, -0.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1475098580121994
Epoch 0, Step 1999: train/loss = 0.8215221166610718, train/raw-loss = 0.768033504486084, train/logprobs = tensor([[-2.2329, -3.2579],
        [-0.9965, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133721724152565
Epoch 0, Step 2000: train/loss = 0.4918791651725769, train/raw-loss = 0.4363819658756256, train/logprobs = tensor([[-0.8285, -2.7771],
        [-0.9338, -0.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13874292373657227
Epoch 0, Step 2001: train/loss = 0.5037674903869629, train/raw-loss = 0.4276568293571472, train/logprobs = tensor([[-1.0118, -2.2073],
        [-1.8191, -1.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19027677178382874
Epoch 0, Step 2002: train/loss = 0.3172038793563843, train/raw-loss = 0.2604519724845886, train/logprobs = tensor([[-0.8262, -6.5133],
        [-1.5298, -1.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14187976717948914
Epoch 0, Step 2003: train/loss = 0.36368927359580994, train/raw-loss = 0.28348445892333984, train/logprobs = tensor([[-1.4928, -5.1961],
        [-2.0528, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20051200687885284
Epoch 0, Step 2004: train/loss = 0.2275570034980774, train/raw-loss = 0.15337924659252167, train/logprobs = tensor([[-0.5660, -9.4760],
        [-1.6737, -0.8381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18544438481330872
Epoch 0, Step 2005: train/loss = 0.1760781854391098, train/raw-loss = 0.09729874134063721, train/logprobs = tensor([[ -0.9140, -10.1129],
        [ -3.1139,  -1.1158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1969485878944397
Epoch 0, Step 2006: train/loss = 0.33913856744766235, train/raw-loss = 0.2832626402378082, train/logprobs = tensor([[ -0.7625, -10.4938],
        [ -1.4420,  -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396898776292801
Epoch 0, Step 2007: train/loss = 0.4132280647754669, train/raw-loss = 0.3454309403896332, train/logprobs = tensor([[-0.5744, -3.1023],
        [-1.2685, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16949275135993958
Epoch 0, Step 2008: train/loss = 0.44437384605407715, train/raw-loss = 0.3889863193035126, train/logprobs = tensor([[-0.9386, -5.1754],
        [-1.6607, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13846877217292786
Epoch 0, Step 2009: train/loss = 0.6276761293411255, train/raw-loss = 0.5601987838745117, train/logprobs = tensor([[-1.7838, -4.6367],
        [-1.0435, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16869325935840607
Epoch 0, Step 2010: train/loss = 0.33455556631088257, train/raw-loss = 0.268155962228775, train/logprobs = tensor([[-1.0308, -6.4427],
        [-1.8601, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16599898040294647
Epoch 0, Step 2011: train/loss = 0.28329259157180786, train/raw-loss = 0.21999187767505646, train/logprobs = tensor([[-0.6359, -3.8211],
        [-2.0159, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15825186669826508
Epoch 0, Step 2012: train/loss = 0.4583660364151001, train/raw-loss = 0.3894180953502655, train/logprobs = tensor([[-0.7648, -4.0468],
        [-1.5148, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1723698377609253
Epoch 0, Step 2013: train/loss = 0.5361288785934448, train/raw-loss = 0.4768158793449402, train/logprobs = tensor([[-0.7593, -1.4016],
        [-1.4006, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14828254282474518
Epoch 0, Step 2014: train/loss = 0.4810992479324341, train/raw-loss = 0.40331730246543884, train/logprobs = tensor([[-1.9259, -7.4756],
        [-2.9227, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1944548487663269
Epoch 0, Step 2015: train/loss = 0.5051311254501343, train/raw-loss = 0.44254520535469055, train/logprobs = tensor([[-0.7210, -2.5343],
        [-1.0519, -0.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15646478533744812
Epoch 0, Step 2016: train/loss = 0.37027329206466675, train/raw-loss = 0.2933588922023773, train/logprobs = tensor([[-1.2213, -4.4044],
        [-1.9911, -1.1191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19228595495224
Epoch 0, Step 2017: train/loss = 0.22939175367355347, train/raw-loss = 0.1577325165271759, train/logprobs = tensor([[-0.9797, -6.9896],
        [-1.8766, -0.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17914807796478271
Epoch 0, Step 2018: train/loss = 0.2665802240371704, train/raw-loss = 0.18911297619342804, train/logprobs = tensor([[-0.9149, -8.4223],
        [-2.5067, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1936681568622589
Epoch 0, Step 2019: train/loss = 0.34333330392837524, train/raw-loss = 0.28637152910232544, train/logprobs = tensor([[-0.6664, -4.5906],
        [-1.2018, -1.2505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424044519662857
Epoch 0, Step 2020: train/loss = 0.6909460425376892, train/raw-loss = 0.6242989301681519, train/logprobs = tensor([[-1.3249, -1.8781],
        [-1.2004, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666177362203598
Epoch 0, Step 2021: train/loss = 0.4577534794807434, train/raw-loss = 0.40238749980926514, train/logprobs = tensor([[-0.3729, -4.8687],
        [-0.7906, -0.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13841497898101807
Epoch 0, Step 2022: train/loss = 0.5221514701843262, train/raw-loss = 0.44822824001312256, train/logprobs = tensor([[-0.7855, -2.8281],
        [-2.0886, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18480804562568665
Epoch 0, Step 2023: train/loss = 0.2924966812133789, train/raw-loss = 0.21520519256591797, train/logprobs = tensor([[-1.0663, -6.3847],
        [-3.0305, -1.3323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19322872161865234
Epoch 0, Step 2024: train/loss = 0.15201303362846375, train/raw-loss = 0.0743483230471611, train/logprobs = tensor([[ -0.8198, -10.5344],
        [ -2.6095,  -2.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1941618025302887
Epoch 0, Step 2025: train/loss = 0.5049709677696228, train/raw-loss = 0.43481022119522095, train/logprobs = tensor([[-1.6498, -6.7397],
        [-1.9933, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17540185153484344
Epoch 0, Step 2026: train/loss = 0.21072030067443848, train/raw-loss = 0.1321331113576889, train/logprobs = tensor([[-0.6055, -6.7057],
        [-1.8724, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19646798074245453
Epoch 0, Step 2027: train/loss = 0.31792426109313965, train/raw-loss = 0.24530434608459473, train/logprobs = tensor([[-0.5365, -4.1769],
        [-1.1930, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1815498024225235
Epoch 0, Step 2028: train/loss = 0.3379518687725067, train/raw-loss = 0.276042103767395, train/logprobs = tensor([[-0.9718, -4.7601],
        [-2.0062, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15477436780929565
Epoch 0, Step 2029: train/loss = 0.5482501983642578, train/raw-loss = 0.48407861590385437, train/logprobs = tensor([[-0.7051, -1.4073],
        [-1.0714, -0.6930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16042888164520264
Epoch 0, Step 2030: train/loss = 0.297372430562973, train/raw-loss = 0.22050420939922333, train/logprobs = tensor([[-0.7149, -6.0624],
        [-1.9812, -0.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19217050075531006
Epoch 0, Step 2031: train/loss = 0.6432783603668213, train/raw-loss = 0.5842212438583374, train/logprobs = tensor([[-0.6105, -0.9425],
        [-0.8546, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14764288067817688
Epoch 0, Step 2032: train/loss = 0.3504086136817932, train/raw-loss = 0.2927427291870117, train/logprobs = tensor([[-1.4028, -5.1468],
        [-2.0568, -0.7787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441648155450821
Epoch 0, Step 2033: train/loss = 0.7933001518249512, train/raw-loss = 0.7406607866287231, train/logprobs = tensor([[-1.4428, -1.4601],
        [-0.7213, -0.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13159844279289246
Epoch 0, Step 2034: train/loss = 0.44917887449264526, train/raw-loss = 0.38802894949913025, train/logprobs = tensor([[-0.6759, -3.2082],
        [-1.3112, -0.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15287478268146515
Epoch 0, Step 2035: train/loss = 0.45157819986343384, train/raw-loss = 0.38819992542266846, train/logprobs = tensor([[-1.3044, -4.8803],
        [-1.5422, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1584455817937851
Epoch 0, Step 2036: train/loss = 0.23965618014335632, train/raw-loss = 0.16130688786506653, train/logprobs = tensor([[ -0.9716, -10.7441],
        [ -2.1233,  -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1958731710910797
Epoch 0, Step 2037: train/loss = 0.29103705286979675, train/raw-loss = 0.22467225790023804, train/logprobs = tensor([[-0.8503, -7.8631],
        [-1.4669, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1659119725227356
Epoch 0, Step 2038: train/loss = 0.3990336060523987, train/raw-loss = 0.30660873651504517, train/logprobs = tensor([[-1.0549, -5.4517],
        [-1.9532, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.231062114238739
Epoch 0, Step 2039: train/loss = 0.3783388137817383, train/raw-loss = 0.31678807735443115, train/logprobs = tensor([[-0.9203, -3.8095],
        [-1.6284, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15387682616710663
Epoch 0, Step 2040: train/loss = 0.44376859068870544, train/raw-loss = 0.3870050311088562, train/logprobs = tensor([[-1.0017, -4.5818],
        [-1.1744, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190885424613953
Epoch 0, Step 2041: train/loss = 0.24932995438575745, train/raw-loss = 0.1886119842529297, train/logprobs = tensor([[-0.6122, -8.0885],
        [-2.4305, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1517949104309082
Epoch 0, Step 2042: train/loss = 0.2696714401245117, train/raw-loss = 0.19503821432590485, train/logprobs = tensor([[-0.7643, -8.1125],
        [-1.9308, -1.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18658308684825897
Epoch 0, Step 2043: train/loss = 0.4490991234779358, train/raw-loss = 0.38327813148498535, train/logprobs = tensor([[-0.9422, -8.9773],
        [-1.8839, -1.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645524799823761
Epoch 0, Step 2044: train/loss = 0.6098511219024658, train/raw-loss = 0.5193557739257812, train/logprobs = tensor([[-2.6035, -4.1470],
        [-3.5024, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2262383997440338
Epoch 0, Step 2045: train/loss = 0.5020509362220764, train/raw-loss = 0.44335320591926575, train/logprobs = tensor([[-0.7051, -1.6867],
        [-1.2914, -0.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14674438536167145
Epoch 0, Step 2046: train/loss = 0.2429085075855255, train/raw-loss = 0.1943482756614685, train/logprobs = tensor([[-0.3566, -9.1075],
        [-0.9224, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12140060216188431
Epoch 0, Step 2047: train/loss = 0.3624314069747925, train/raw-loss = 0.28731784224510193, train/logprobs = tensor([[-1.8883, -6.4088],
        [-3.0119, -0.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18778391182422638
Epoch 0, Step 2048: train/loss = 0.3678079843521118, train/raw-loss = 0.305476576089859, train/logprobs = tensor([[-0.8957, -6.6679],
        [-1.1431, -0.9015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1558285355567932
Epoch 0, Step 2049: train/loss = 0.338803768157959, train/raw-loss = 0.2670970559120178, train/logprobs = tensor([[-1.1972, -4.8279],
        [-2.4418, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1792667955160141
Epoch 0, Step 2050: train/loss = 0.20618309080600739, train/raw-loss = 0.11604242026805878, train/logprobs = tensor([[-0.8445, -5.2860],
        [-2.2453, -1.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253517061471939
Epoch 0, Step 2051: train/loss = 0.3354581594467163, train/raw-loss = 0.27012455463409424, train/logprobs = tensor([[-0.5778, -7.9204],
        [-1.5118, -1.2495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.163333922624588
Epoch 0, Step 2052: train/loss = 0.4372293949127197, train/raw-loss = 0.3438747525215149, train/logprobs = tensor([[-1.0480, -3.5746],
        [-3.1812, -1.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23338660597801208
Epoch 0, Step 2053: train/loss = 0.5329794883728027, train/raw-loss = 0.45162683725357056, train/logprobs = tensor([[-1.8271, -5.3249],
        [-1.2374, -1.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20338162779808044
Epoch 0, Step 2054: train/loss = 0.45541584491729736, train/raw-loss = 0.3847101330757141, train/logprobs = tensor([[-0.9229, -1.6967],
        [-2.1011, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17676445841789246
Epoch 0, Step 2055: train/loss = 0.38646018505096436, train/raw-loss = 0.3337455987930298, train/logprobs = tensor([[-1.1202, -4.9807],
        [-1.2134, -0.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1317865550518036
Epoch 0, Step 2056: train/loss = 0.3621722161769867, train/raw-loss = 0.300037145614624, train/logprobs = tensor([[-0.9298, -2.2915],
        [-2.7828, -0.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1553376317024231
Epoch 0, Step 2057: train/loss = 0.5331522822380066, train/raw-loss = 0.45947182178497314, train/logprobs = tensor([[-0.7417, -2.2802],
        [-1.8913, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1842011660337448
Epoch 0, Step 2058: train/loss = 0.22288906574249268, train/raw-loss = 0.12766823172569275, train/logprobs = tensor([[-0.9776, -8.2643],
        [-3.0242, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380521148443222
Epoch 0, Step 2059: train/loss = 0.30567777156829834, train/raw-loss = 0.22428388893604279, train/logprobs = tensor([[-0.7835, -9.0229],
        [-2.2375, -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034846395254135
Epoch 0, Step 2060: train/loss = 0.38182422518730164, train/raw-loss = 0.304349422454834, train/logprobs = tensor([[-1.3317, -3.9245],
        [-1.8486, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19368697702884674
Epoch 0, Step 2061: train/loss = 0.30682024359703064, train/raw-loss = 0.23478326201438904, train/logprobs = tensor([[-0.9244, -7.9555],
        [-2.3253, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18009239435195923
Epoch 0, Step 2062: train/loss = 0.32037219405174255, train/raw-loss = 0.2233482450246811, train/logprobs = tensor([[-1.2742, -4.7668],
        [-2.3628, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24255990982055664
Epoch 0, Step 2063: train/loss = 0.4469953179359436, train/raw-loss = 0.3704506754875183, train/logprobs = tensor([[-0.7281, -3.3000],
        [-2.2204, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19136159121990204
Epoch 0, Step 2064: train/loss = 0.5758323669433594, train/raw-loss = 0.49486517906188965, train/logprobs = tensor([[-1.7759, -4.1823],
        [-1.9219, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20241795480251312
Epoch 0, Step 2065: train/loss = 0.2385275959968567, train/raw-loss = 0.17194044589996338, train/logprobs = tensor([[ -0.8868, -10.0625],
        [ -1.9565,  -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16646790504455566
Epoch 0, Step 2066: train/loss = 0.389080673456192, train/raw-loss = 0.31277838349342346, train/logprobs = tensor([[-0.8366, -5.6233],
        [-1.7801, -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19075584411621094
Epoch 0, Step 2067: train/loss = 0.4575868844985962, train/raw-loss = 0.38757920265197754, train/logprobs = tensor([[-1.2548, -5.0134],
        [-1.6963, -1.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17501915991306305
Epoch 0, Step 2068: train/loss = 0.5869606137275696, train/raw-loss = 0.5155779719352722, train/logprobs = tensor([[-1.0031, -3.8491],
        [-1.7509, -1.2945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17845654487609863
Epoch 0, Step 2069: train/loss = 0.44837844371795654, train/raw-loss = 0.3781896233558655, train/logprobs = tensor([[-0.7279, -3.2769],
        [-1.6529, -1.4161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17547209560871124
Epoch 0, Step 2070: train/loss = 0.1829909235239029, train/raw-loss = 0.10712944716215134, train/logprobs = tensor([[ -1.2021, -10.3842],
        [ -3.1066,  -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1896536946296692
Epoch 0, Step 2071: train/loss = 0.46210765838623047, train/raw-loss = 0.3851022720336914, train/logprobs = tensor([[-1.0165, -3.8498],
        [-1.5190, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19251340627670288
Epoch 0, Step 2072: train/loss = 0.2665316164493561, train/raw-loss = 0.1818932592868805, train/logprobs = tensor([[-0.9742, -6.6247],
        [-2.2258, -0.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21159592270851135
Epoch 0, Step 2073: train/loss = 0.3469887673854828, train/raw-loss = 0.2655618190765381, train/logprobs = tensor([[-1.0927, -4.6441],
        [-1.8787, -1.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20356735587120056
Epoch 0, Step 2074: train/loss = 0.4633426070213318, train/raw-loss = 0.3943048417568207, train/logprobs = tensor([[-0.7360, -2.8193],
        [-1.7447, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17259445786476135
Epoch 0, Step 2075: train/loss = 0.5033242106437683, train/raw-loss = 0.4265434741973877, train/logprobs = tensor([[-0.9388, -2.6346],
        [-1.7636, -1.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19195181131362915
Epoch 0, Step 2076: train/loss = 0.3698539435863495, train/raw-loss = 0.3019314706325531, train/logprobs = tensor([[-1.6231, -8.3699],
        [-2.0013, -1.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16980621218681335
Epoch 0, Step 2077: train/loss = 0.3092520833015442, train/raw-loss = 0.23780705034732819, train/logprobs = tensor([[-0.7964, -6.4930],
        [-1.6993, -0.5948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1786125898361206
Epoch 0, Step 2078: train/loss = 0.2612531781196594, train/raw-loss = 0.18958020210266113, train/logprobs = tensor([[-1.0658, -4.4984],
        [-2.2900, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17918239533901215
Epoch 0, Step 2079: train/loss = 0.3751155138015747, train/raw-loss = 0.30718058347702026, train/logprobs = tensor([[-0.6457, -5.4036],
        [-1.4189, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16983726620674133
Epoch 0, Step 2080: train/loss = 0.24059030413627625, train/raw-loss = 0.17284592986106873, train/logprobs = tensor([[-0.9378, -6.5024],
        [-2.2877, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1693609356880188
Epoch 0, Step 2081: train/loss = 0.3383523225784302, train/raw-loss = 0.2586529850959778, train/logprobs = tensor([[-1.2222, -3.4451],
        [-2.8039, -1.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1992482990026474
Epoch 0, Step 2082: train/loss = 0.2621006965637207, train/raw-loss = 0.18869122862815857, train/logprobs = tensor([[ -0.8103, -11.2161],
        [ -2.1490,  -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18352371454238892
Epoch 0, Step 2083: train/loss = 0.4617011845111847, train/raw-loss = 0.39196082949638367, train/logprobs = tensor([[-1.1385, -2.6048],
        [-1.9024, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17435090243816376
Epoch 0, Step 2084: train/loss = 0.2407977432012558, train/raw-loss = 0.17244215309619904, train/logprobs = tensor([[-0.8876, -7.6197],
        [-3.0318, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1708889752626419
Epoch 0, Step 2085: train/loss = 0.4586985111236572, train/raw-loss = 0.41775232553482056, train/logprobs = tensor([[-0.9208, -3.0068],
        [-1.2713, -1.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236550867557526
Epoch 0, Step 2086: train/loss = 0.3930467963218689, train/raw-loss = 0.33326056599617004, train/logprobs = tensor([[-0.5151, -4.0462],
        [-1.0364, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14946557581424713
Epoch 0, Step 2087: train/loss = 0.16033047437667847, train/raw-loss = 0.08232048898935318, train/logprobs = tensor([[ -1.2543, -14.4771],
        [ -2.9769,  -1.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950249969959259
Epoch 0, Step 2088: train/loss = 0.44892990589141846, train/raw-loss = 0.37890300154685974, train/logprobs = tensor([[-0.6371, -8.1359],
        [-1.9598, -1.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17506727576255798
Epoch 0, Step 2089: train/loss = 0.6112393736839294, train/raw-loss = 0.5478947162628174, train/logprobs = tensor([[-1.5107, -3.4968],
        [-1.2376, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15836170315742493
Epoch 0, Step 2090: train/loss = 0.5425222516059875, train/raw-loss = 0.4856383800506592, train/logprobs = tensor([[-1.5506, -3.1867],
        [-1.4910, -1.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14220969378948212
Epoch 0, Step 2091: train/loss = 0.37897947430610657, train/raw-loss = 0.32020142674446106, train/logprobs = tensor([[-0.8500, -3.6647],
        [-1.2930, -0.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1469450742006302
Epoch 0, Step 2092: train/loss = 0.18006327748298645, train/raw-loss = 0.09942695498466492, train/logprobs = tensor([[-0.7350, -7.3183],
        [-2.3895, -1.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20159082114696503
Epoch 0, Step 2093: train/loss = 0.6389808058738708, train/raw-loss = 0.5721842050552368, train/logprobs = tensor([[-2.4476, -5.9158],
        [-1.9589, -1.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1669914722442627
Epoch 0, Step 2094: train/loss = 0.2640228271484375, train/raw-loss = 0.19171704351902008, train/logprobs = tensor([[-0.5780, -8.4400],
        [-2.1230, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18076440691947937
Epoch 0, Step 2095: train/loss = 0.49721136689186096, train/raw-loss = 0.4149032235145569, train/logprobs = tensor([[-0.9553, -4.9578],
        [-2.0741, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20577025413513184
Epoch 0, Step 2096: train/loss = 0.4664381146430969, train/raw-loss = 0.3986920118331909, train/logprobs = tensor([[-1.3877, -7.2804],
        [-1.8265, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16936518251895905
Epoch 0, Step 2097: train/loss = 0.4700264632701874, train/raw-loss = 0.3922455608844757, train/logprobs = tensor([[-0.8681, -4.5352],
        [-1.7044, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1944521814584732
Epoch 0, Step 2098: train/loss = 0.1587468683719635, train/raw-loss = 0.07793603092432022, train/logprobs = tensor([[-0.7617, -6.6535],
        [-2.6863, -1.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2020270824432373
Epoch 0, Step 2099: train/loss = 0.32787612080574036, train/raw-loss = 0.24429455399513245, train/logprobs = tensor([[-0.9399, -7.4937],
        [-1.4394, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20895393192768097
Epoch 0, Step 2100: train/loss = 0.5061321258544922, train/raw-loss = 0.42345479130744934, train/logprobs = tensor([[-0.8226, -1.9795],
        [-1.5655, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20669332146644592
Epoch 0, Step 2101: train/loss = 0.4914522171020508, train/raw-loss = 0.4196048974990845, train/logprobs = tensor([[-0.8679, -3.4107],
        [-1.8043, -1.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17961829900741577
Epoch 0, Step 2102: train/loss = 0.36752697825431824, train/raw-loss = 0.3099099099636078, train/logprobs = tensor([[-1.1150, -6.4452],
        [-1.4112, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14404262602329254
Epoch 0, Step 2103: train/loss = 0.34460097551345825, train/raw-loss = 0.27041399478912354, train/logprobs = tensor([[-0.7321, -6.8313],
        [-1.7171, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18546739220619202
Epoch 0, Step 2104: train/loss = 0.38239848613739014, train/raw-loss = 0.31402549147605896, train/logprobs = tensor([[-0.7402, -2.5320],
        [-1.8968, -0.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17093254625797272
Epoch 0, Step 2105: train/loss = 0.44290691614151, train/raw-loss = 0.35426080226898193, train/logprobs = tensor([[-0.9748, -3.8536],
        [-2.1936, -2.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2216152399778366
Epoch 0, Step 2106: train/loss = 0.5255102515220642, train/raw-loss = 0.4506891071796417, train/logprobs = tensor([[-0.6577, -2.4251],
        [-1.2268, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18705281615257263
Epoch 0, Step 2107: train/loss = 0.389381468296051, train/raw-loss = 0.3340475559234619, train/logprobs = tensor([[-1.2965, -2.9947],
        [-1.8656, -0.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13833478093147278
Epoch 0, Step 2108: train/loss = 0.30791589617729187, train/raw-loss = 0.2535611689090729, train/logprobs = tensor([[-0.7941, -6.6512],
        [-1.7718, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13588684797286987
Epoch 0, Step 2109: train/loss = 0.3725140392780304, train/raw-loss = 0.311969131231308, train/logprobs = tensor([[ -0.6972, -12.2162],
        [ -1.4659,  -1.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15136227011680603
Epoch 0, Step 2110: train/loss = 0.5235521793365479, train/raw-loss = 0.4661179482936859, train/logprobs = tensor([[-1.7855, -3.8650],
        [-1.8093, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14358548820018768
Epoch 0, Step 2111: train/loss = 0.31696709990501404, train/raw-loss = 0.22652028501033783, train/logprobs = tensor([[-0.9223, -4.2456],
        [-2.4187, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22611704468727112
Epoch 0, Step 2112: train/loss = 0.28768396377563477, train/raw-loss = 0.21577335894107819, train/logprobs = tensor([[-0.7219, -6.1542],
        [-2.2886, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17977643013000488
Epoch 0, Step 2113: train/loss = 0.3757808804512024, train/raw-loss = 0.2948332130908966, train/logprobs = tensor([[-0.7887, -9.5395],
        [-2.6560, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2023691087961197
Epoch 0, Step 2114: train/loss = 0.2438051700592041, train/raw-loss = 0.16820380091667175, train/logprobs = tensor([[-0.8589, -8.4746],
        [-1.7006, -1.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18900342285633087
Epoch 0, Step 2115: train/loss = 0.17280378937721252, train/raw-loss = 0.09799890965223312, train/logprobs = tensor([[ -0.9659, -11.0055],
        [ -2.7471,  -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187012180685997
Epoch 0, Step 2116: train/loss = 0.2965947389602661, train/raw-loss = 0.21521857380867004, train/logprobs = tensor([[-1.5503, -7.8015],
        [-3.0390, -1.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20344045758247375
Epoch 0, Step 2117: train/loss = 0.5206321477890015, train/raw-loss = 0.4626937508583069, train/logprobs = tensor([[-0.4841, -4.8894],
        [-1.3190, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.144846111536026
Epoch 0, Step 2118: train/loss = 0.3722943365573883, train/raw-loss = 0.29157546162605286, train/logprobs = tensor([[-0.8599, -7.7912],
        [-1.5620, -1.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20179717242717743
Epoch 0, Step 2119: train/loss = 0.25596439838409424, train/raw-loss = 0.17904798686504364, train/logprobs = tensor([[-0.9294, -4.8450],
        [-2.2998, -0.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1922909915447235
Epoch 0, Step 2120: train/loss = 0.7928696870803833, train/raw-loss = 0.7298400402069092, train/logprobs = tensor([[-2.3691, -2.7717],
        [-1.5425, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15757401287555695
Epoch 0, Step 2121: train/loss = 0.6956703662872314, train/raw-loss = 0.622376561164856, train/logprobs = tensor([[-2.0791, -5.4796],
        [-1.5382, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1832342892885208
Epoch 0, Step 2122: train/loss = 0.3148483335971832, train/raw-loss = 0.24756766855716705, train/logprobs = tensor([[-1.2624, -6.0221],
        [-1.8872, -0.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16820161044597626
Epoch 0, Step 2123: train/loss = 0.4624300003051758, train/raw-loss = 0.3954135477542877, train/logprobs = tensor([[-1.6089, -6.5036],
        [-2.0552, -1.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16754114627838135
Epoch 0, Step 2124: train/loss = 0.27176737785339355, train/raw-loss = 0.18983019888401031, train/logprobs = tensor([[-1.1628, -6.1450],
        [-2.4468, -1.0874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2048429399728775
Epoch 0, Step 2125: train/loss = 0.2988485097885132, train/raw-loss = 0.22935858368873596, train/logprobs = tensor([[-0.9054, -4.1455],
        [-1.5945, -0.7344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17372483015060425
Epoch 0, Step 2126: train/loss = 0.40898457169532776, train/raw-loss = 0.34654319286346436, train/logprobs = tensor([[-0.6996, -3.0042],
        [-2.1354, -0.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1561034470796585
Epoch 0, Step 2127: train/loss = 0.24145779013633728, train/raw-loss = 0.1684209406375885, train/logprobs = tensor([[-1.9255, -9.4238],
        [-3.1842, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18259207904338837
Epoch 0, Step 2128: train/loss = 0.3092915117740631, train/raw-loss = 0.24424879252910614, train/logprobs = tensor([[-1.1140, -5.9160],
        [-2.0949, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16260680556297302
Epoch 0, Step 2129: train/loss = 0.3307182192802429, train/raw-loss = 0.26291295886039734, train/logprobs = tensor([[-0.4780, -5.9771],
        [-1.5955, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16951313614845276
Epoch 0, Step 2130: train/loss = 0.3612992763519287, train/raw-loss = 0.28867340087890625, train/logprobs = tensor([[-1.3373, -3.9701],
        [-1.9768, -1.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18156473338603973
Epoch 0, Step 2131: train/loss = 0.3226267695426941, train/raw-loss = 0.2441268414258957, train/logprobs = tensor([[-0.8843, -3.5956],
        [-1.8826, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962497979402542
Epoch 0, Step 2132: train/loss = 0.32827824354171753, train/raw-loss = 0.25801581144332886, train/logprobs = tensor([[-1.3500, -7.3967],
        [-2.1329, -0.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17565613985061646
Epoch 0, Step 2133: train/loss = 0.36498400568962097, train/raw-loss = 0.29937249422073364, train/logprobs = tensor([[-0.8929, -5.1703],
        [-1.3995, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16402876377105713
Epoch 0, Step 2134: train/loss = 0.5515768527984619, train/raw-loss = 0.4609055519104004, train/logprobs = tensor([[-1.8601, -6.6937],
        [-2.3840, -0.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22667813301086426
Epoch 0, Step 2135: train/loss = 0.3525829613208771, train/raw-loss = 0.28729867935180664, train/logprobs = tensor([[-0.4399, -6.6039],
        [-2.1024, -1.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1632106900215149
Epoch 0, Step 2136: train/loss = 0.3002373278141022, train/raw-loss = 0.2172347754240036, train/logprobs = tensor([[-0.7578, -5.8806],
        [-2.0538, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20750638842582703
Epoch 0, Step 2137: train/loss = 0.3749740719795227, train/raw-loss = 0.292721688747406, train/logprobs = tensor([[-1.0343, -5.1030],
        [-1.8663, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20563095808029175
Epoch 0, Step 2138: train/loss = 0.16154469549655914, train/raw-loss = 0.09790026396512985, train/logprobs = tensor([[-1.1214, -7.7904],
        [-3.4948, -1.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15911106765270233
Epoch 0, Step 2139: train/loss = 0.30090925097465515, train/raw-loss = 0.22822731733322144, train/logprobs = tensor([[-0.9015, -5.9244],
        [-2.3883, -1.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1817048192024231
Epoch 0, Step 2140: train/loss = 0.3988490402698517, train/raw-loss = 0.3469703197479248, train/logprobs = tensor([[-0.9578, -4.0402],
        [-1.4087, -1.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12969689071178436
Epoch 0, Step 2141: train/loss = 1.6902927160263062, train/raw-loss = 1.619874119758606, train/logprobs = tensor([[-5.8926, -6.7790],
        [-2.1894, -1.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17604655027389526
Epoch 0, Step 2142: train/loss = 0.18337342143058777, train/raw-loss = 0.09965734928846359, train/logprobs = tensor([[-0.9351, -6.9738],
        [-2.9993, -0.6776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20929019153118134
Epoch 0, Step 2143: train/loss = 0.4201541543006897, train/raw-loss = 0.3459654748439789, train/logprobs = tensor([[-0.8935, -5.0606],
        [-1.3222, -0.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18547166883945465
Epoch 0, Step 2144: train/loss = 0.4723209738731384, train/raw-loss = 0.3987208604812622, train/logprobs = tensor([[-1.2535, -2.9515],
        [-1.5826, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18400031328201294
Epoch 0, Step 2145: train/loss = 0.4140181243419647, train/raw-loss = 0.3520779311656952, train/logprobs = tensor([[-0.5484, -3.0426],
        [-1.1101, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15485043823719025
Epoch 0, Step 2146: train/loss = 0.3308597505092621, train/raw-loss = 0.26000794768333435, train/logprobs = tensor([[-1.1333, -3.5244],
        [-1.9439, -0.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17712953686714172
Epoch 0, Step 2147: train/loss = 0.28744736313819885, train/raw-loss = 0.2187817394733429, train/logprobs = tensor([[-1.5343, -5.5998],
        [-2.5013, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1716640293598175
Epoch 0, Step 2148: train/loss = 0.11874286830425262, train/raw-loss = 0.055583517998456955, train/logprobs = tensor([[-0.8138, -7.2780],
        [-3.1946, -1.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15789836645126343
Epoch 0, Step 2149: train/loss = 0.48717454075813293, train/raw-loss = 0.4205705225467682, train/logprobs = tensor([[-0.8860, -5.8777],
        [-1.7316, -1.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16651003062725067
Epoch 0, Step 2150: train/loss = 0.5454391837120056, train/raw-loss = 0.48103103041648865, train/logprobs = tensor([[-2.3813, -4.5331],
        [-2.7112, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16102033853530884
Epoch 0, Step 2151: train/loss = 0.4767429232597351, train/raw-loss = 0.43070679903030396, train/logprobs = tensor([[-1.2978, -7.6669],
        [-1.6312, -1.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150902733206749
Epoch 0, Step 2152: train/loss = 0.4547034800052643, train/raw-loss = 0.3967131972312927, train/logprobs = tensor([[-0.6112, -3.6787],
        [-1.0459, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14497579634189606
Epoch 0, Step 2153: train/loss = 0.3507324159145355, train/raw-loss = 0.2382901906967163, train/logprobs = tensor([[-1.1618, -4.4678],
        [-3.1051, -1.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281105637550354
Epoch 0, Step 2154: train/loss = 0.2877499461174011, train/raw-loss = 0.21666556596755981, train/logprobs = tensor([[-1.2896, -6.2966],
        [-2.4176, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17771092057228088
Epoch 0, Step 2155: train/loss = 0.25260812044143677, train/raw-loss = 0.1874142736196518, train/logprobs = tensor([[ -0.6579, -11.9026],
        [ -2.1826,  -1.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16298465430736542
Epoch 0, Step 2156: train/loss = 0.5005542635917664, train/raw-loss = 0.4355544149875641, train/logprobs = tensor([[-0.7267, -4.4940],
        [-1.5188, -1.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16249966621398926
Epoch 0, Step 2157: train/loss = 0.16043147444725037, train/raw-loss = 0.07997652143239975, train/logprobs = tensor([[-1.2645, -7.0065],
        [-3.3959, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20113734900951385
Epoch 0, Step 2158: train/loss = 0.5722628831863403, train/raw-loss = 0.49147212505340576, train/logprobs = tensor([[-1.1227, -6.3559],
        [-2.4975, -1.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20197686553001404
Epoch 0, Step 2159: train/loss = 0.9045795202255249, train/raw-loss = 0.8175201416015625, train/logprobs = tensor([[-2.9667, -9.1724],
        [-3.4800, -2.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2176484614610672
Epoch 0, Step 2160: train/loss = 0.32190120220184326, train/raw-loss = 0.2353430688381195, train/logprobs = tensor([[-0.5044, -6.6503],
        [-2.1407, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2163952887058258
Epoch 0, Step 2161: train/loss = 0.3285702168941498, train/raw-loss = 0.2517813444137573, train/logprobs = tensor([[-1.9570, -7.0503],
        [-2.6209, -1.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19197216629981995
Epoch 0, Step 2162: train/loss = 0.4150402843952179, train/raw-loss = 0.33580470085144043, train/logprobs = tensor([[-0.9367, -4.4714],
        [-2.6054, -0.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19808898866176605
Epoch 0, Step 2163: train/loss = 0.365247517824173, train/raw-loss = 0.27801597118377686, train/logprobs = tensor([[-0.7559, -3.7712],
        [-1.9876, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21807894110679626
Epoch 0, Step 2164: train/loss = 0.2542163133621216, train/raw-loss = 0.19128306210041046, train/logprobs = tensor([[ -0.8157, -10.2610],
        [ -2.3866,  -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1573331356048584
Epoch 0, Step 2165: train/loss = 0.5040019154548645, train/raw-loss = 0.4355226755142212, train/logprobs = tensor([[-0.4709, -2.1595],
        [-1.4846, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17119809985160828
Epoch 0, Step 2166: train/loss = 0.4490054249763489, train/raw-loss = 0.38282978534698486, train/logprobs = tensor([[-0.8973, -8.5787],
        [-1.4219, -1.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16543905436992645
Epoch 0, Step 2167: train/loss = 0.5673685073852539, train/raw-loss = 0.5011772513389587, train/logprobs = tensor([[-0.4738, -1.0481],
        [-1.8172, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16547831892967224
Epoch 0, Step 2168: train/loss = 0.3709479570388794, train/raw-loss = 0.3120874762535095, train/logprobs = tensor([[-1.0316, -6.0110],
        [-1.2173, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14715124666690826
Epoch 0, Step 2169: train/loss = 0.5549042820930481, train/raw-loss = 0.49171894788742065, train/logprobs = tensor([[-0.7251, -2.0271],
        [-2.1910, -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.157963365316391
Epoch 0, Step 2170: train/loss = 0.2659730911254883, train/raw-loss = 0.17953486740589142, train/logprobs = tensor([[-1.4636, -7.7559],
        [-3.0546, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21609556674957275
Epoch 0, Step 2171: train/loss = 0.6065957546234131, train/raw-loss = 0.5289018154144287, train/logprobs = tensor([[-1.6296, -4.7162],
        [-1.0928, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19423475861549377
Epoch 0, Step 2172: train/loss = 0.5799392461776733, train/raw-loss = 0.5234435796737671, train/logprobs = tensor([[-0.8472, -2.5032],
        [-1.1481, -0.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14123910665512085
Epoch 0, Step 2173: train/loss = 0.47842562198638916, train/raw-loss = 0.41535869240760803, train/logprobs = tensor([[-0.9135, -6.0584],
        [-1.2527, -2.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.157667338848114
Epoch 0, Step 2174: train/loss = 0.37929192185401917, train/raw-loss = 0.31066465377807617, train/logprobs = tensor([[-0.5972, -3.2590],
        [-1.4643, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17156821489334106
Epoch 0, Step 2175: train/loss = 0.278592586517334, train/raw-loss = 0.2135917842388153, train/logprobs = tensor([[-0.6474, -7.7930],
        [-2.1711, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16250205039978027
Epoch 0, Step 2176: train/loss = 0.44725391268730164, train/raw-loss = 0.39162781834602356, train/logprobs = tensor([[-2.1700, -7.3612],
        [-2.3671, -1.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13906535506248474
Epoch 0, Step 2177: train/loss = 0.36014342308044434, train/raw-loss = 0.2849104404449463, train/logprobs = tensor([[-1.1660, -6.6109],
        [-2.0360, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18808238208293915
Epoch 0, Step 2178: train/loss = 0.3537765443325043, train/raw-loss = 0.28320351243019104, train/logprobs = tensor([[-1.0779, -7.4515],
        [-1.5446, -1.8173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17643268406391144
Epoch 0, Step 2179: train/loss = 0.4352802038192749, train/raw-loss = 0.3669986128807068, train/logprobs = tensor([[-0.9687, -2.9872],
        [-1.5314, -0.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1707039475440979
Epoch 0, Step 2180: train/loss = 0.45299771428108215, train/raw-loss = 0.38574057817459106, train/logprobs = tensor([[-0.4793, -4.4101],
        [-1.1573, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814278066158295
Epoch 0, Step 2181: train/loss = 0.22370217740535736, train/raw-loss = 0.12908409535884857, train/logprobs = tensor([[-0.7414, -6.7303],
        [-2.4555, -1.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23654522001743317
Epoch 0, Step 2182: train/loss = 0.6052404642105103, train/raw-loss = 0.5386967658996582, train/logprobs = tensor([[-1.2196, -4.0720],
        [-1.0387, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1663592904806137
Epoch 0, Step 2183: train/loss = 0.19208073616027832, train/raw-loss = 0.11041445285081863, train/logprobs = tensor([[-0.9325, -5.9692],
        [-2.6335, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20416568219661713
Epoch 0, Step 2184: train/loss = 0.7833694219589233, train/raw-loss = 0.7124178409576416, train/logprobs = tensor([[-0.6362, -0.8956],
        [-2.6341, -1.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17737895250320435
Epoch 0, Step 2185: train/loss = 0.4894786477088928, train/raw-loss = 0.4036095440387726, train/logprobs = tensor([[-1.1768, -3.4862],
        [-2.0722, -2.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2146727591753006
Epoch 0, Step 2186: train/loss = 0.32939276099205017, train/raw-loss = 0.26765283942222595, train/logprobs = tensor([[-0.8902, -5.6234],
        [-1.6591, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15434977412223816
Epoch 0, Step 2187: train/loss = 0.49011698365211487, train/raw-loss = 0.40591078996658325, train/logprobs = tensor([[-1.1188, -2.9026],
        [-2.9920, -1.5349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21051548421382904
Epoch 0, Step 2188: train/loss = 0.2512691915035248, train/raw-loss = 0.15618497133255005, train/logprobs = tensor([[-0.9199, -6.1543],
        [-3.0970, -1.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23771056532859802
Epoch 0, Step 2189: train/loss = 0.4997844994068146, train/raw-loss = 0.4459608793258667, train/logprobs = tensor([[-0.7125, -3.1158],
        [-1.2687, -0.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13455906510353088
Epoch 0, Step 2190: train/loss = 0.19507309794425964, train/raw-loss = 0.13045433163642883, train/logprobs = tensor([[ -1.3777, -13.2723],
        [ -2.7488,  -1.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16154690086841583
Epoch 0, Step 2191: train/loss = 0.47898444533348083, train/raw-loss = 0.412990540266037, train/logprobs = tensor([[-0.7500, -1.9137],
        [-1.5285, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16498468816280365
Epoch 0, Step 2192: train/loss = 0.21828606724739075, train/raw-loss = 0.12402784079313278, train/logprobs = tensor([[-1.2051, -5.6288],
        [-3.2035, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23564556241035461
Epoch 0, Step 2193: train/loss = 0.3978462815284729, train/raw-loss = 0.32310423254966736, train/logprobs = tensor([[-0.6166, -4.3596],
        [-1.7525, -1.3912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18685513734817505
Epoch 0, Step 2194: train/loss = 0.4286152124404907, train/raw-loss = 0.37359750270843506, train/logprobs = tensor([[-1.0762, -7.1682],
        [-1.5970, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13754422962665558
Epoch 0, Step 2195: train/loss = 0.29444923996925354, train/raw-loss = 0.2255587875843048, train/logprobs = tensor([[-0.8423, -8.6899],
        [-2.1104, -1.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17222604155540466
Epoch 0, Step 2196: train/loss = 0.6905779838562012, train/raw-loss = 0.6272502541542053, train/logprobs = tensor([[-1.2136, -1.2477],
        [-1.2591, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.158319354057312
Epoch 0, Step 2197: train/loss = 0.23626358807086945, train/raw-loss = 0.15788114070892334, train/logprobs = tensor([[-1.1099, -8.6487],
        [-2.1061, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19595608115196228
Epoch 0, Step 2198: train/loss = 0.47095149755477905, train/raw-loss = 0.40704768896102905, train/logprobs = tensor([[-2.0920, -8.8814],
        [-2.0149, -1.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15975958108901978
Epoch 0, Step 2199: train/loss = 0.5701446533203125, train/raw-loss = 0.5067861080169678, train/logprobs = tensor([[-0.6590, -1.1400],
        [-1.2390, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839646756649017
Epoch 0, Step 2200: train/loss = 0.38879865407943726, train/raw-loss = 0.31702715158462524, train/logprobs = tensor([[-0.6607, -4.0556],
        [-2.0346, -1.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17942874133586884
Epoch 0, Step 2201: train/loss = 0.5164936780929565, train/raw-loss = 0.45788824558258057, train/logprobs = tensor([[-0.7017, -1.5363],
        [-0.9907, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14651359617710114
Epoch 0, Step 2202: train/loss = 0.518868088722229, train/raw-loss = 0.4397734999656677, train/logprobs = tensor([[-1.1114, -1.8406],
        [-1.9799, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19773656129837036
Epoch 0, Step 2203: train/loss = 0.32877612113952637, train/raw-loss = 0.2363867610692978, train/logprobs = tensor([[-1.1319, -6.7039],
        [-3.0370, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23097342252731323
Epoch 0, Step 2204: train/loss = 0.34976232051849365, train/raw-loss = 0.2879381477832794, train/logprobs = tensor([[-1.0015, -5.2965],
        [-1.8463, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545603722333908
Epoch 0, Step 2205: train/loss = 0.2788989841938019, train/raw-loss = 0.21059702336788177, train/logprobs = tensor([[-0.6781, -6.2984],
        [-2.4173, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17075490951538086
Epoch 0, Step 2206: train/loss = 0.537452220916748, train/raw-loss = 0.47691893577575684, train/logprobs = tensor([[-1.0840, -2.6763],
        [-1.2656, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15133318305015564
Epoch 0, Step 2207: train/loss = 0.19920076429843903, train/raw-loss = 0.125549778342247, train/logprobs = tensor([[-0.8151, -6.1560],
        [-2.2113, -0.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18412747979164124
Epoch 0, Step 2208: train/loss = 0.47125425934791565, train/raw-loss = 0.4013526439666748, train/logprobs = tensor([[-0.9134, -4.2913],
        [-1.9181, -0.6293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17475402355194092
Epoch 0, Step 2209: train/loss = 0.24419528245925903, train/raw-loss = 0.1679989993572235, train/logprobs = tensor([[-0.9483, -7.2766],
        [-2.7765, -1.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19049066305160522
Epoch 0, Step 2210: train/loss = 0.39487993717193604, train/raw-loss = 0.3342409133911133, train/logprobs = tensor([[-1.2262, -4.5312],
        [-2.9037, -2.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15159761905670166
Epoch 0, Step 2211: train/loss = 0.4597505033016205, train/raw-loss = 0.36314621567726135, train/logprobs = tensor([[-0.6660, -5.8505],
        [-2.8429, -1.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24151068925857544
Epoch 0, Step 2212: train/loss = 0.2904309630393982, train/raw-loss = 0.20243266224861145, train/logprobs = tensor([[-0.9800, -5.9995],
        [-2.6602, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21999570727348328
Epoch 0, Step 2213: train/loss = 0.24801814556121826, train/raw-loss = 0.17677946388721466, train/logprobs = tensor([[-1.0285, -6.8325],
        [-1.9406, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1780966967344284
Epoch 0, Step 2214: train/loss = 0.20906051993370056, train/raw-loss = 0.1269584447145462, train/logprobs = tensor([[-1.0224, -7.7690],
        [-3.1549, -1.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052551805973053
Epoch 0, Step 2215: train/loss = 0.36061111092567444, train/raw-loss = 0.2832929491996765, train/logprobs = tensor([[-1.4590, -5.4633],
        [-1.7545, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1932954341173172
Epoch 0, Step 2216: train/loss = 0.26779481768608093, train/raw-loss = 0.19318610429763794, train/logprobs = tensor([[-1.2850, -5.1333],
        [-3.3259, -0.8197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18652182817459106
Epoch 0, Step 2217: train/loss = 0.4258091151714325, train/raw-loss = 0.34787148237228394, train/logprobs = tensor([[-2.9183, -5.4197],
        [-4.5212, -1.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1948440819978714
Epoch 0, Step 2218: train/loss = 0.3972354233264923, train/raw-loss = 0.33517026901245117, train/logprobs = tensor([[-0.7967, -4.8303],
        [-1.8230, -2.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15516281127929688
Epoch 0, Step 2219: train/loss = 0.3815203905105591, train/raw-loss = 0.32609134912490845, train/logprobs = tensor([[-1.1319, -8.7575],
        [-1.5982, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13857263326644897
Epoch 0, Step 2220: train/loss = 0.5289111137390137, train/raw-loss = 0.4435303211212158, train/logprobs = tensor([[-1.0827, -4.7518],
        [-2.7148, -2.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21345198154449463
Epoch 0, Step 2221: train/loss = 0.685522198677063, train/raw-loss = 0.6182906031608582, train/logprobs = tensor([[ -2.5281, -10.5974],
        [ -1.8605,  -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16807910799980164
Epoch 0, Step 2222: train/loss = 0.3612600266933441, train/raw-loss = 0.2940031886100769, train/logprobs = tensor([[-0.4506, -5.8957],
        [-1.5576, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1681421548128128
Epoch 0, Step 2223: train/loss = 0.26100191473960876, train/raw-loss = 0.19833341240882874, train/logprobs = tensor([[-0.9149, -6.2878],
        [-2.7465, -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15667122602462769
Epoch 0, Step 2224: train/loss = 0.19218164682388306, train/raw-loss = 0.11530521512031555, train/logprobs = tensor([[-0.8803, -9.1138],
        [-3.6387, -1.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19219109416007996
Epoch 0, Step 2225: train/loss = 0.5489442348480225, train/raw-loss = 0.48670870065689087, train/logprobs = tensor([[-1.3525, -3.4499],
        [-1.3591, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15558889508247375
Epoch 0, Step 2226: train/loss = 0.1663351058959961, train/raw-loss = 0.0867467150092125, train/logprobs = tensor([[-0.6215, -8.4453],
        [-2.5242, -1.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1989709883928299
Epoch 0, Step 2227: train/loss = 0.3522922098636627, train/raw-loss = 0.2737995386123657, train/logprobs = tensor([[-0.4836, -4.7290],
        [-1.9771, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962316334247589
Epoch 0, Step 2228: train/loss = 0.31461769342422485, train/raw-loss = 0.23502683639526367, train/logprobs = tensor([[-0.7238, -6.0338],
        [-2.5537, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19897706806659698
Epoch 0, Step 2229: train/loss = 0.3844189941883087, train/raw-loss = 0.31960126757621765, train/logprobs = tensor([[-0.6919, -4.6924],
        [-1.3428, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16204437613487244
Epoch 0, Step 2230: train/loss = 0.34265732765197754, train/raw-loss = 0.2775132954120636, train/logprobs = tensor([[-1.2283, -4.6046],
        [-2.3875, -1.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16286006569862366
Epoch 0, Step 2231: train/loss = 0.40891706943511963, train/raw-loss = 0.35032886266708374, train/logprobs = tensor([[-0.5030, -4.9154],
        [-1.0868, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464705765247345
Epoch 0, Step 2232: train/loss = 0.38637328147888184, train/raw-loss = 0.29174885153770447, train/logprobs = tensor([[-0.8717, -3.9884],
        [-3.5091, -1.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365611493587494
Epoch 0, Step 2233: train/loss = 0.2671637535095215, train/raw-loss = 0.21087026596069336, train/logprobs = tensor([[-1.1683, -7.3824],
        [-1.7260, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14073370397090912
Epoch 0, Step 2234: train/loss = 0.30715614557266235, train/raw-loss = 0.23021158576011658, train/logprobs = tensor([[-1.1131, -6.6931],
        [-2.1731, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19236135482788086
Epoch 0, Step 2235: train/loss = 0.7541146278381348, train/raw-loss = 0.6750901937484741, train/logprobs = tensor([[-2.1338, -4.9491],
        [-2.3837, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19756102561950684
Epoch 0, Step 2236: train/loss = 0.38599467277526855, train/raw-loss = 0.31603074073791504, train/logprobs = tensor([[-0.6344, -4.5160],
        [-1.5525, -1.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17490972578525543
Epoch 0, Step 2237: train/loss = 0.623281717300415, train/raw-loss = 0.5575857758522034, train/logprobs = tensor([[-1.6394, -3.3210],
        [-2.0585, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16423983871936798
Epoch 0, Step 2238: train/loss = 0.3664822578430176, train/raw-loss = 0.27632200717926025, train/logprobs = tensor([[-1.4231, -6.0879],
        [-3.1600, -1.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22540058195590973
Epoch 0, Step 2239: train/loss = 0.34544700384140015, train/raw-loss = 0.2701666057109833, train/logprobs = tensor([[-0.8926, -6.5087],
        [-1.8834, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18820099532604218
Epoch 0, Step 2240: train/loss = 0.3106878995895386, train/raw-loss = 0.23933377861976624, train/logprobs = tensor([[-1.1032, -6.5398],
        [-1.9277, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17838528752326965
Epoch 0, Step 2241: train/loss = 0.34697556495666504, train/raw-loss = 0.27606332302093506, train/logprobs = tensor([[-0.9865, -2.9799],
        [-1.9322, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17728066444396973
Epoch 0, Step 2242: train/loss = 0.5064427256584167, train/raw-loss = 0.4404822587966919, train/logprobs = tensor([[-0.9535, -4.2101],
        [-2.8305, -1.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16490116715431213
Epoch 0, Step 2243: train/loss = 0.4183114767074585, train/raw-loss = 0.3530293107032776, train/logprobs = tensor([[-0.6753, -4.4528],
        [-1.5573, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16320547461509705
Epoch 0, Step 2244: train/loss = 0.24582113325595856, train/raw-loss = 0.1712041199207306, train/logprobs = tensor([[-1.0242, -8.6682],
        [-2.3632, -2.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18654252588748932
Epoch 0, Step 2245: train/loss = 0.43496671319007874, train/raw-loss = 0.3834099769592285, train/logprobs = tensor([[-0.6965, -4.8282],
        [-1.2601, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12889178097248077
Epoch 0, Step 2246: train/loss = 0.27797287702560425, train/raw-loss = 0.19187137484550476, train/logprobs = tensor([[-0.8526, -5.8624],
        [-2.4026, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2152538001537323
Epoch 0, Step 2247: train/loss = 0.24489013850688934, train/raw-loss = 0.16149276494979858, train/logprobs = tensor([[-0.7939, -4.9609],
        [-2.9856, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20849338173866272
Epoch 0, Step 2248: train/loss = 0.5587130784988403, train/raw-loss = 0.4933652877807617, train/logprobs = tensor([[-0.5328, -1.0922],
        [-1.2400, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16336944699287415
Epoch 0, Step 2249: train/loss = 0.2682199478149414, train/raw-loss = 0.20972901582717896, train/logprobs = tensor([[-0.6909, -3.9231],
        [-1.6521, -0.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14622732996940613
Epoch 0, Step 2250: train/loss = 0.3166923224925995, train/raw-loss = 0.2438279688358307, train/logprobs = tensor([[-0.6115, -5.4717],
        [-1.7660, -0.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182160884141922
Epoch 0, Step 2251: train/loss = 0.2942730784416199, train/raw-loss = 0.21673813462257385, train/logprobs = tensor([[-0.6532, -4.8014],
        [-1.8054, -1.3635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19383731484413147
Epoch 0, Step 2252: train/loss = 0.4924083948135376, train/raw-loss = 0.4323297441005707, train/logprobs = tensor([[-0.9762, -2.5813],
        [-1.3400, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15019668638706207
Epoch 0, Step 2253: train/loss = 0.4587060511112213, train/raw-loss = 0.3898813724517822, train/logprobs = tensor([[-0.7017, -5.1670],
        [-1.6354, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1720617413520813
Epoch 0, Step 2254: train/loss = 0.5606560111045837, train/raw-loss = 0.49135929346084595, train/logprobs = tensor([[-0.8159, -1.5563],
        [-1.5083, -1.1805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17324182391166687
Epoch 0, Step 2255: train/loss = 0.21656933426856995, train/raw-loss = 0.16146379709243774, train/logprobs = tensor([[ -1.1240, -13.2901],
        [ -2.0796,  -2.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377638280391693
Epoch 0, Step 2256: train/loss = 0.41108936071395874, train/raw-loss = 0.32643651962280273, train/logprobs = tensor([[-0.8454, -6.1797],
        [-1.5870, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2116321623325348
Epoch 0, Step 2257: train/loss = 0.4633016288280487, train/raw-loss = 0.39530307054519653, train/logprobs = tensor([[-1.1403, -3.2132],
        [-1.7817, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16999632120132446
Epoch 0, Step 2258: train/loss = 0.3665754199028015, train/raw-loss = 0.2937990427017212, train/logprobs = tensor([[-0.9967, -7.2175],
        [-1.9754, -1.3205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1819409430027008
Epoch 0, Step 2259: train/loss = 0.19052252173423767, train/raw-loss = 0.11570987105369568, train/logprobs = tensor([[ -0.4745, -11.6362],
        [ -1.9935,  -1.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18703165650367737
Epoch 0, Step 2260: train/loss = 0.3469691276550293, train/raw-loss = 0.2814173698425293, train/logprobs = tensor([[-0.7363, -5.5076],
        [-1.9813, -1.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638794243335724
Epoch 0, Step 2261: train/loss = 0.2484581470489502, train/raw-loss = 0.16118109226226807, train/logprobs = tensor([[-0.9465, -7.5000],
        [-2.8991, -0.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181926965713501
Epoch 0, Step 2262: train/loss = 0.45156335830688477, train/raw-loss = 0.3832695782184601, train/logprobs = tensor([[-0.7615, -2.0284],
        [-1.6315, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1707344800233841
Epoch 0, Step 2263: train/loss = 0.42916440963745117, train/raw-loss = 0.35151612758636475, train/logprobs = tensor([[-0.7403, -2.9021],
        [-2.1622, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19412076473236084
Epoch 0, Step 2264: train/loss = 0.44447702169418335, train/raw-loss = 0.3818204402923584, train/logprobs = tensor([[-0.7760, -6.1477],
        [-1.2590, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15664148330688477
Epoch 0, Step 2265: train/loss = 0.2988842725753784, train/raw-loss = 0.23972263932228088, train/logprobs = tensor([[-1.0789, -5.6108],
        [-2.5676, -0.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14790409803390503
Epoch 0, Step 2266: train/loss = 0.20474208891391754, train/raw-loss = 0.14538827538490295, train/logprobs = tensor([[-0.8729, -9.4052],
        [-2.3822, -1.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14838452637195587
Epoch 0, Step 2267: train/loss = 0.5653392672538757, train/raw-loss = 0.5086495876312256, train/logprobs = tensor([[-0.6917, -1.1402],
        [-1.0374, -0.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417243480682373
Epoch 0, Step 2268: train/loss = 0.22946152091026306, train/raw-loss = 0.1393306404352188, train/logprobs = tensor([[-0.9046, -4.8791],
        [-3.2861, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22532719373703003
Epoch 0, Step 2269: train/loss = 0.4487297534942627, train/raw-loss = 0.3743816614151001, train/logprobs = tensor([[-1.1830, -3.0590],
        [-2.4379, -0.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18587026000022888
Epoch 0, Step 2270: train/loss = 0.32676756381988525, train/raw-loss = 0.2701265513896942, train/logprobs = tensor([[-0.4745, -5.2586],
        [-1.0438, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1416025459766388
Epoch 0, Step 2271: train/loss = 0.3340485692024231, train/raw-loss = 0.26683878898620605, train/logprobs = tensor([[-1.0951, -7.0054],
        [-2.3712, -1.4508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16802453994750977
Epoch 0, Step 2272: train/loss = 0.3427736759185791, train/raw-loss = 0.2835538387298584, train/logprobs = tensor([[-1.0014, -6.7297],
        [-2.8785, -1.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480495035648346
Epoch 0, Step 2273: train/loss = 0.37762823700904846, train/raw-loss = 0.32428058981895447, train/logprobs = tensor([[-1.0168, -4.8690],
        [-1.3083, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13336914777755737
Epoch 0, Step 2274: train/loss = 0.2027827799320221, train/raw-loss = 0.13334858417510986, train/logprobs = tensor([[-0.4014, -6.0991],
        [-1.7476, -0.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17358548939228058
Epoch 0, Step 2275: train/loss = 0.1630416214466095, train/raw-loss = 0.08908003568649292, train/logprobs = tensor([[-0.8660, -6.0964],
        [-2.9243, -0.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18490394949913025
Epoch 0, Step 2276: train/loss = 0.2728400230407715, train/raw-loss = 0.2054864913225174, train/logprobs = tensor([[-0.7799, -6.2564],
        [-2.2946, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16838377714157104
Epoch 0, Step 2277: train/loss = 0.5039998292922974, train/raw-loss = 0.45263898372650146, train/logprobs = tensor([[-0.5324, -1.9408],
        [-1.0010, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284022480249405
Epoch 0, Step 2278: train/loss = 0.3490441143512726, train/raw-loss = 0.27408310770988464, train/logprobs = tensor([[-1.1626, -3.8937],
        [-2.2148, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18740245699882507
Epoch 0, Step 2279: train/loss = 0.7236785888671875, train/raw-loss = 0.6681156158447266, train/logprobs = tensor([[-2.3839, -7.7975],
        [-1.7814, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890741765499115
Epoch 0, Step 2280: train/loss = 0.4568091630935669, train/raw-loss = 0.40065377950668335, train/logprobs = tensor([[-0.6322, -2.8008],
        [-1.4856, -1.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403883993625641
Epoch 0, Step 2281: train/loss = 0.1596662998199463, train/raw-loss = 0.08591949939727783, train/logprobs = tensor([[-0.7266, -6.6617],
        [-3.6001, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18436701595783234
Epoch 0, Step 2282: train/loss = 0.4316752552986145, train/raw-loss = 0.35986530780792236, train/logprobs = tensor([[-0.6756, -5.5110],
        [-1.6980, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179524764418602
Epoch 0, Step 2283: train/loss = 0.25820398330688477, train/raw-loss = 0.19188733398914337, train/logprobs = tensor([[-0.6307, -5.7029],
        [-1.5139, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16579169034957886
Epoch 0, Step 2284: train/loss = 0.645687997341156, train/raw-loss = 0.5779438018798828, train/logprobs = tensor([[-1.6136, -5.0073],
        [-1.9095, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16936030983924866
Epoch 0, Step 2285: train/loss = 0.3108004927635193, train/raw-loss = 0.24205191433429718, train/logprobs = tensor([[-1.2481, -9.9736],
        [-2.0687, -1.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17187148332595825
Epoch 0, Step 2286: train/loss = 0.2650430202484131, train/raw-loss = 0.1917116641998291, train/logprobs = tensor([[-1.2175, -6.1970],
        [-2.1008, -1.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18332833051681519
Epoch 0, Step 2287: train/loss = 0.6793575286865234, train/raw-loss = 0.614426851272583, train/logprobs = tensor([[-1.8988, -6.2816],
        [-1.9864, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623268723487854
Epoch 0, Step 2288: train/loss = 0.2857414782047272, train/raw-loss = 0.21972566843032837, train/logprobs = tensor([[-1.4158, -7.7825],
        [-2.0445, -2.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165039524435997
Epoch 0, Step 2289: train/loss = 0.3927531838417053, train/raw-loss = 0.3309294581413269, train/logprobs = tensor([[-0.7292, -7.5089],
        [-2.4298, -1.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15455928444862366
Epoch 0, Step 2290: train/loss = 0.7490220665931702, train/raw-loss = 0.6791125535964966, train/logprobs = tensor([[-0.9986, -1.9745],
        [-2.6529, -2.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17477375268936157
Epoch 0, Step 2291: train/loss = 0.1528213620185852, train/raw-loss = 0.056828342378139496, train/logprobs = tensor([[-0.8184, -9.4520],
        [-3.8190, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23998256027698517
Epoch 0, Step 2292: train/loss = 0.5689414143562317, train/raw-loss = 0.5098622441291809, train/logprobs = tensor([[-1.7421, -4.6922],
        [-1.6684, -1.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14769792556762695
Epoch 0, Step 2293: train/loss = 0.34420230984687805, train/raw-loss = 0.25795871019363403, train/logprobs = tensor([[-1.0571, -4.6966],
        [-2.7177, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21560896933078766
Epoch 0, Step 2294: train/loss = 0.3527558147907257, train/raw-loss = 0.2691158950328827, train/logprobs = tensor([[-0.7173, -7.5412],
        [-2.2902, -1.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20909979939460754
Epoch 0, Step 2295: train/loss = 0.3322488069534302, train/raw-loss = 0.2643741965293884, train/logprobs = tensor([[-0.9417, -3.9519],
        [-2.1448, -1.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16968652606010437
Epoch 0, Step 2296: train/loss = 0.4930598735809326, train/raw-loss = 0.43143928050994873, train/logprobs = tensor([[-0.8120, -1.7225],
        [-2.0589, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15405140817165375
Epoch 0, Step 2297: train/loss = 0.354206919670105, train/raw-loss = 0.2853504419326782, train/logprobs = tensor([[-0.8160, -4.0065],
        [-1.8950, -0.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1721411794424057
Epoch 0, Step 2298: train/loss = 0.1250074803829193, train/raw-loss = 0.05467473343014717, train/logprobs = tensor([[ -0.7965, -14.8072],
        [ -3.4834,  -2.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1758318841457367
Epoch 0, Step 2299: train/loss = 0.5215330719947815, train/raw-loss = 0.445869505405426, train/logprobs = tensor([[-0.7866, -2.8452],
        [-1.4559, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18915879726409912
Epoch 0, Step 2300: train/loss = 0.19064827263355255, train/raw-loss = 0.1323975771665573, train/logprobs = tensor([[-1.1237, -4.6773],
        [-2.6941, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456267535686493
Epoch 0, Step 2301: train/loss = 0.24159325659275055, train/raw-loss = 0.15756110846996307, train/logprobs = tensor([[-0.7020, -8.5782],
        [-3.1730, -1.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2100803405046463
Epoch 0, Step 2302: train/loss = 0.39959046244621277, train/raw-loss = 0.3456410765647888, train/logprobs = tensor([[-0.4713, -7.4276],
        [-2.2238, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13487350940704346
Epoch 0, Step 2303: train/loss = 0.2370532751083374, train/raw-loss = 0.1654481440782547, train/logprobs = tensor([[-1.2686, -6.4756],
        [-3.1350, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17901282012462616
Epoch 0, Step 2304: train/loss = 0.3419892191886902, train/raw-loss = 0.26694291830062866, train/logprobs = tensor([[-0.8498, -7.9241],
        [-1.8515, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187615767121315
Epoch 0, Step 2305: train/loss = 0.5606368780136108, train/raw-loss = 0.48858749866485596, train/logprobs = tensor([[-1.8273, -8.1866],
        [-2.1224, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801234781742096
Epoch 0, Step 2306: train/loss = 0.4356754422187805, train/raw-loss = 0.3805502653121948, train/logprobs = tensor([[-1.1832, -4.0081],
        [-1.5775, -1.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13781292736530304
Epoch 0, Step 2307: train/loss = 0.5435059070587158, train/raw-loss = 0.4715172052383423, train/logprobs = tensor([[-0.7059, -4.8148],
        [-3.3081, -2.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799718141555786
Epoch 0, Step 2308: train/loss = 0.4573422372341156, train/raw-loss = 0.396898090839386, train/logprobs = tensor([[-0.5428, -4.5220],
        [-1.0712, -1.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15111029148101807
Epoch 0, Step 2309: train/loss = 0.4702611565589905, train/raw-loss = 0.41857048869132996, train/logprobs = tensor([[-1.8801, -9.1597],
        [-1.5296, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292266845703125
Epoch 0, Step 2310: train/loss = 0.5804248452186584, train/raw-loss = 0.49992048740386963, train/logprobs = tensor([[-1.0384, -3.1169],
        [-2.6587, -2.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20126083493232727
Epoch 0, Step 2311: train/loss = 0.5780107975006104, train/raw-loss = 0.5199047327041626, train/logprobs = tensor([[-0.6194, -2.4144],
        [-0.8709, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14526532590389252
Epoch 0, Step 2312: train/loss = 0.29800689220428467, train/raw-loss = 0.21942852437496185, train/logprobs = tensor([[-0.7133, -4.1719],
        [-2.1936, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19644591212272644
Epoch 0, Step 2313: train/loss = 0.2553772032260895, train/raw-loss = 0.18020954728126526, train/logprobs = tensor([[-0.8789, -5.6535],
        [-2.3036, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18791909515857697
Epoch 0, Step 2314: train/loss = 0.21618109941482544, train/raw-loss = 0.14987054467201233, train/logprobs = tensor([[ -0.9302, -10.4738],
        [ -1.9643,  -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16577640175819397
Epoch 0, Step 2315: train/loss = 0.25481948256492615, train/raw-loss = 0.1751074492931366, train/logprobs = tensor([[-1.0327, -6.0550],
        [-2.4444, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19928006827831268
Epoch 0, Step 2316: train/loss = 0.3501749038696289, train/raw-loss = 0.2905760407447815, train/logprobs = tensor([[-0.6846, -4.5720],
        [-1.7531, -0.7732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14899717271327972
Epoch 0, Step 2317: train/loss = 0.2740117609500885, train/raw-loss = 0.2126295268535614, train/logprobs = tensor([[-1.1091, -5.3198],
        [-1.8893, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15345562994480133
Epoch 0, Step 2318: train/loss = 0.4840852916240692, train/raw-loss = 0.4271570146083832, train/logprobs = tensor([[-0.6741, -4.2114],
        [-1.1926, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14232075214385986
Epoch 0, Step 2319: train/loss = 0.23263610899448395, train/raw-loss = 0.15649768710136414, train/logprobs = tensor([[-1.2358, -7.4754],
        [-2.5955, -1.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19034604728221893
Epoch 0, Step 2320: train/loss = 0.3982900381088257, train/raw-loss = 0.3175501525402069, train/logprobs = tensor([[-0.9188, -4.2234],
        [-1.7894, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2018497884273529
Epoch 0, Step 2321: train/loss = 0.5196698307991028, train/raw-loss = 0.4421329200267792, train/logprobs = tensor([[-0.6372, -3.2294],
        [-1.4957, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19384229183197021
Epoch 0, Step 2322: train/loss = 0.5299267172813416, train/raw-loss = 0.46084263920783997, train/logprobs = tensor([[-2.8900, -6.6684],
        [-2.8650, -1.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17271023988723755
Epoch 0, Step 2323: train/loss = 0.5810824632644653, train/raw-loss = 0.5188775658607483, train/logprobs = tensor([[-0.8607, -1.4786],
        [-1.2665, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155512273311615
Epoch 0, Step 2324: train/loss = 0.34953218698501587, train/raw-loss = 0.28355810046195984, train/logprobs = tensor([[-0.7073, -7.0256],
        [-1.5891, -1.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16493526101112366
Epoch 0, Step 2325: train/loss = 0.5170741081237793, train/raw-loss = 0.46054771542549133, train/logprobs = tensor([[-0.4401, -2.2648],
        [-0.8081, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14131593704223633
Epoch 0, Step 2326: train/loss = 0.20558759570121765, train/raw-loss = 0.11908582597970963, train/logprobs = tensor([[-1.2498, -9.0391],
        [-3.7136, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21625444293022156
Epoch 0, Step 2327: train/loss = 0.4717060625553131, train/raw-loss = 0.41670531034469604, train/logprobs = tensor([[-1.0074, -5.3740],
        [-1.6924, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13750183582305908
Epoch 0, Step 2328: train/loss = 0.4378313422203064, train/raw-loss = 0.33604082465171814, train/logprobs = tensor([[-0.7733, -6.0666],
        [-2.2618, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544762194156647
Epoch 0, Step 2329: train/loss = 0.4683842062950134, train/raw-loss = 0.4107907712459564, train/logprobs = tensor([[-0.5356, -4.5121],
        [-0.9907, -0.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14398349821567535
Epoch 0, Step 2330: train/loss = 0.3218759000301361, train/raw-loss = 0.24780511856079102, train/logprobs = tensor([[-0.5846, -4.6781],
        [-1.7398, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18517695367336273
Epoch 0, Step 2331: train/loss = 0.6063790321350098, train/raw-loss = 0.5479762554168701, train/logprobs = tensor([[-1.1296, -2.7860],
        [-0.9305, -1.0448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.146006777882576
Epoch 0, Step 2332: train/loss = 0.314120888710022, train/raw-loss = 0.24952252209186554, train/logprobs = tensor([[-0.7979, -5.7142],
        [-1.8899, -1.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16149599850177765
Epoch 0, Step 2333: train/loss = 0.4054054617881775, train/raw-loss = 0.3218457102775574, train/logprobs = tensor([[-0.7566, -4.2337],
        [-2.5704, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088993787765503
Epoch 0, Step 2334: train/loss = 0.35121625661849976, train/raw-loss = 0.28182655572891235, train/logprobs = tensor([[-1.1623, -6.9406],
        [-1.6751, -1.9002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347432672977448
Epoch 0, Step 2335: train/loss = 0.10635901242494583, train/raw-loss = 0.03715511038899422, train/logprobs = tensor([[ -0.9385, -11.0067],
        [ -3.9522,  -2.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1730097532272339
Epoch 0, Step 2336: train/loss = 0.32115909457206726, train/raw-loss = 0.2530284821987152, train/logprobs = tensor([[-0.6847, -7.2684],
        [-2.3079, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17032656073570251
Epoch 0, Step 2337: train/loss = 0.19765104353427887, train/raw-loss = 0.11959226429462433, train/logprobs = tensor([[-1.6691, -9.8154],
        [-3.2582, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19514694809913635
Epoch 0, Step 2338: train/loss = 0.3729504942893982, train/raw-loss = 0.28279101848602295, train/logprobs = tensor([[-1.2947, -3.5756],
        [-2.8616, -0.9243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22539865970611572
Epoch 0, Step 2339: train/loss = 0.47928518056869507, train/raw-loss = 0.41826629638671875, train/logprobs = tensor([[-1.4950, -3.8282],
        [-1.9343, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525471955537796
Epoch 0, Step 2340: train/loss = 0.40382978320121765, train/raw-loss = 0.33127325773239136, train/logprobs = tensor([[-1.0351, -2.9326],
        [-2.2365, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1813913732767105
Epoch 0, Step 2341: train/loss = 0.6927734017372131, train/raw-loss = 0.6314160823822021, train/logprobs = tensor([[-1.8867, -4.1567],
        [-1.5923, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15339328348636627
Epoch 0, Step 2342: train/loss = 0.45438718795776367, train/raw-loss = 0.38617438077926636, train/logprobs = tensor([[-0.7220, -2.0384],
        [-1.6666, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17053203284740448
Epoch 0, Step 2343: train/loss = 0.23101232945919037, train/raw-loss = 0.14635659754276276, train/logprobs = tensor([[-0.6274, -6.4879],
        [-2.4856, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21163934469223022
Epoch 0, Step 2344: train/loss = 0.25249913334846497, train/raw-loss = 0.19522719085216522, train/logprobs = tensor([[-0.7346, -6.2149],
        [-1.8276, -1.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14317987859249115
Epoch 0, Step 2345: train/loss = 0.2713412940502167, train/raw-loss = 0.20404499769210815, train/logprobs = tensor([[-0.6453, -8.0869],
        [-2.3930, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1682407557964325
Epoch 0, Step 2346: train/loss = 0.317233145236969, train/raw-loss = 0.2549007833003998, train/logprobs = tensor([[-0.6851, -5.0364],
        [-1.4342, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15583090484142303
Epoch 0, Step 2347: train/loss = 0.35171541571617126, train/raw-loss = 0.2745719254016876, train/logprobs = tensor([[-0.8360, -5.4070],
        [-3.0087, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19285865128040314
Epoch 0, Step 2348: train/loss = 0.18831951916217804, train/raw-loss = 0.1157696396112442, train/logprobs = tensor([[-1.2012, -6.8009],
        [-3.0123, -1.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1813747137784958
Epoch 0, Step 2349: train/loss = 0.930720329284668, train/raw-loss = 0.8632659912109375, train/logprobs = tensor([[-2.5620, -4.0859],
        [-1.2794, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16863572597503662
Epoch 0, Step 2350: train/loss = 0.4425913393497467, train/raw-loss = 0.3836509883403778, train/logprobs = tensor([[-0.6937, -3.6767],
        [-1.0470, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14735090732574463
Epoch 0, Step 2351: train/loss = 0.4487490653991699, train/raw-loss = 0.3945389986038208, train/logprobs = tensor([[-0.5555, -2.4128],
        [-1.3130, -0.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355251669883728
Epoch 0, Step 2352: train/loss = 0.2383127510547638, train/raw-loss = 0.1778985559940338, train/logprobs = tensor([[-0.6798, -6.4903],
        [-2.1384, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15103550255298615
Epoch 0, Step 2353: train/loss = 0.43344223499298096, train/raw-loss = 0.3778924345970154, train/logprobs = tensor([[-0.6789, -4.1189],
        [-1.2511, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13887456059455872
Epoch 0, Step 2354: train/loss = 0.38604092597961426, train/raw-loss = 0.3133985102176666, train/logprobs = tensor([[-2.1894, -4.8369],
        [-2.6148, -1.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18160602450370789
Epoch 0, Step 2355: train/loss = 0.2791602611541748, train/raw-loss = 0.2099611461162567, train/logprobs = tensor([[-0.8361, -9.0092],
        [-2.6980, -1.3023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17299777269363403
Epoch 0, Step 2356: train/loss = 0.3261907696723938, train/raw-loss = 0.25237399339675903, train/logprobs = tensor([[-1.0964, -7.1297],
        [-1.6949, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18454192578792572
Epoch 0, Step 2357: train/loss = 0.3228515386581421, train/raw-loss = 0.23059561848640442, train/logprobs = tensor([[-1.1807, -4.3601],
        [-2.2436, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23063978552818298
Epoch 0, Step 2358: train/loss = 0.32334262132644653, train/raw-loss = 0.2631199359893799, train/logprobs = tensor([[-0.9943, -3.9720],
        [-2.7607, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1505567580461502
Epoch 0, Step 2359: train/loss = 0.2183675318956375, train/raw-loss = 0.14096635580062866, train/logprobs = tensor([[-1.0455, -8.3011],
        [-3.1159, -1.3427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19350291788578033
Epoch 0, Step 2360: train/loss = 0.3550591468811035, train/raw-loss = 0.2901258170604706, train/logprobs = tensor([[-0.7725, -4.3237],
        [-1.6439, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16233332455158234
Epoch 0, Step 2361: train/loss = 0.33526551723480225, train/raw-loss = 0.2544574439525604, train/logprobs = tensor([[-1.0541, -5.5239],
        [-2.0397, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20202015340328217
Epoch 0, Step 2362: train/loss = 0.29616329073905945, train/raw-loss = 0.21197070181369781, train/logprobs = tensor([[-0.6711, -3.7655],
        [-1.7186, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2104814499616623
Epoch 0, Step 2363: train/loss = 0.3463504910469055, train/raw-loss = 0.2748813331127167, train/logprobs = tensor([[-0.8205, -4.2096],
        [-2.1030, -0.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17867286503314972
Epoch 0, Step 2364: train/loss = 0.5060209035873413, train/raw-loss = 0.4360108971595764, train/logprobs = tensor([[-1.6075, -3.6415],
        [-2.5180, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1750250607728958
Epoch 0, Step 2365: train/loss = 0.3043450713157654, train/raw-loss = 0.24889355897903442, train/logprobs = tensor([[-0.6807, -5.9179],
        [-1.3829, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13862881064414978
Epoch 0, Step 2366: train/loss = 0.454325795173645, train/raw-loss = 0.3915562629699707, train/logprobs = tensor([[-0.8864, -3.3888],
        [-0.8498, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569238007068634
Epoch 0, Step 2367: train/loss = 0.500490128993988, train/raw-loss = 0.4403802752494812, train/logprobs = tensor([[-0.6545, -2.8906],
        [-1.3813, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502746045589447
Epoch 0, Step 2368: train/loss = 0.42334192991256714, train/raw-loss = 0.3616108000278473, train/logprobs = tensor([[-1.4953, -5.3335],
        [-1.9004, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15432778000831604
Epoch 0, Step 2369: train/loss = 0.4677206575870514, train/raw-loss = 0.3995978832244873, train/logprobs = tensor([[-0.8517, -3.4774],
        [-1.9599, -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703069806098938
Epoch 0, Step 2370: train/loss = 0.16372594237327576, train/raw-loss = 0.09472648799419403, train/logprobs = tensor([[-0.9656, -7.1467],
        [-2.7878, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17249861359596252
Epoch 0, Step 2371: train/loss = 0.2768144905567169, train/raw-loss = 0.18916164338588715, train/logprobs = tensor([[-0.9632, -4.2501],
        [-2.4989, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21913214027881622
Epoch 0, Step 2372: train/loss = 0.2945735454559326, train/raw-loss = 0.20979604125022888, train/logprobs = tensor([[-0.5519, -7.0451],
        [-2.3288, -1.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21194380521774292
Epoch 0, Step 2373: train/loss = 0.2440352439880371, train/raw-loss = 0.1640370488166809, train/logprobs = tensor([[-0.6344, -4.7117],
        [-2.5264, -1.0372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19999542832374573
Epoch 0, Step 2374: train/loss = 0.32863759994506836, train/raw-loss = 0.2498704195022583, train/logprobs = tensor([[-0.5589, -5.3089],
        [-1.3146, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19691789150238037
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-13 03:02:10,262][root][INFO] - beta: 0.6
[2024-03-13 03:02:10,262][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.6-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6598527431488037, train/raw-loss = 0.6493633389472961, train/logprobs = tensor([[-0.5585, -0.9089],
        [-0.4931, -0.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017482345923781395
Epoch 0, Step 65: train/loss = 0.5949470400810242, train/raw-loss = 0.5865769386291504, train/logprobs = tensor([[-0.4073, -2.3891],
        [-0.4046, -1.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013950233347713947
Epoch 0, Step 66: train/loss = 0.6377590894699097, train/raw-loss = 0.6272950172424316, train/logprobs = tensor([[-0.6687, -1.2271],
        [-0.6760, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017440130934119225
Epoch 0, Step 67: train/loss = 0.6173003315925598, train/raw-loss = 0.6085212826728821, train/logprobs = tensor([[-0.4560, -1.6502],
        [-0.4399, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014631731435656548
Epoch 0, Step 68: train/loss = 0.6283373236656189, train/raw-loss = 0.6191136240959167, train/logprobs = tensor([[-0.5316, -0.8168],
        [-0.6280, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015372827649116516
Epoch 0, Step 69: train/loss = 0.6459304094314575, train/raw-loss = 0.6363620758056641, train/logprobs = tensor([[-0.6254, -0.8793],
        [-0.6385, -0.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015947256237268448
Epoch 0, Step 70: train/loss = 0.6123374104499817, train/raw-loss = 0.6037502288818359, train/logprobs = tensor([[-0.5829, -1.5757],
        [-0.5856, -1.1838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014312025159597397
Epoch 0, Step 71: train/loss = 0.6221806406974792, train/raw-loss = 0.6131618022918701, train/logprobs = tensor([[-0.5086, -1.2064],
        [-0.5331, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015031449496746063
Epoch 0, Step 72: train/loss = 0.6490305066108704, train/raw-loss = 0.6396150588989258, train/logprobs = tensor([[-0.5477, -1.3656],
        [-0.5529, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01569240912795067
Epoch 0, Step 73: train/loss = 0.68534916639328, train/raw-loss = 0.675059974193573, train/logprobs = tensor([[-0.5544, -1.0890],
        [-0.5394, -0.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017148710787296295
Epoch 0, Step 74: train/loss = 0.6569429636001587, train/raw-loss = 0.6460700035095215, train/logprobs = tensor([[-0.6124, -0.9828],
        [-0.5845, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018121570348739624
Epoch 0, Step 75: train/loss = 0.6122437715530396, train/raw-loss = 0.604692816734314, train/logprobs = tensor([[-0.4142, -1.3290],
        [-0.4386, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01258494146168232
Epoch 0, Step 76: train/loss = 0.5521962642669678, train/raw-loss = 0.5440086126327515, train/logprobs = tensor([[-0.4640, -2.4586],
        [-0.5000, -1.5856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013646097853779793
Epoch 0, Step 77: train/loss = 0.6141088008880615, train/raw-loss = 0.6043977737426758, train/logprobs = tensor([[-0.6576, -1.0120],
        [-0.6927, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016185138374567032
Epoch 0, Step 78: train/loss = 0.6593621969223022, train/raw-loss = 0.6491268873214722, train/logprobs = tensor([[-0.6876, -0.9546],
        [-0.6832, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01705889403820038
Epoch 0, Step 79: train/loss = 0.5858862400054932, train/raw-loss = 0.5767716765403748, train/logprobs = tensor([[-0.5684, -2.3934],
        [-0.5719, -1.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015190890058875084
Epoch 0, Step 80: train/loss = 0.6358522176742554, train/raw-loss = 0.6249590516090393, train/logprobs = tensor([[-0.7445, -1.0102],
        [-0.7352, -0.7048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01815532147884369
Epoch 0, Step 81: train/loss = 0.5767969489097595, train/raw-loss = 0.5701254606246948, train/logprobs = tensor([[-0.5293, -2.5112],
        [-0.5238, -1.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011119125410914421
Epoch 0, Step 82: train/loss = 0.6582729816436768, train/raw-loss = 0.6468945741653442, train/logprobs = tensor([[-0.6935, -1.1157],
        [-0.6226, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018964165821671486
Epoch 0, Step 83: train/loss = 0.6928128600120544, train/raw-loss = 0.6805779933929443, train/logprobs = tensor([[-1.5378, -1.6595],
        [-1.4981, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02039141021668911
Epoch 0, Step 84: train/loss = 0.6514726281166077, train/raw-loss = 0.6400033235549927, train/logprobs = tensor([[-0.6086, -0.9761],
        [-0.5880, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019115474075078964
Epoch 0, Step 85: train/loss = 0.5711913108825684, train/raw-loss = 0.5613552927970886, train/logprobs = tensor([[-0.5901, -2.0096],
        [-0.5813, -1.3668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016393238678574562
Epoch 0, Step 86: train/loss = 0.636206865310669, train/raw-loss = 0.6258429288864136, train/logprobs = tensor([[-0.5686, -0.9181],
        [-0.5965, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0172731876373291
Epoch 0, Step 87: train/loss = 0.6151608228683472, train/raw-loss = 0.6053807735443115, train/logprobs = tensor([[-0.6369, -1.0323],
        [-0.7077, -0.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016300134360790253
Epoch 0, Step 88: train/loss = 0.6216557025909424, train/raw-loss = 0.6103465557098389, train/logprobs = tensor([[-1.0022, -2.1724],
        [-0.9372, -1.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01884855516254902
Epoch 0, Step 89: train/loss = 0.6466614603996277, train/raw-loss = 0.63582843542099, train/logprobs = tensor([[-0.5692, -0.9986],
        [-0.5551, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01805499568581581
Epoch 0, Step 90: train/loss = 0.6367856860160828, train/raw-loss = 0.6266412734985352, train/logprobs = tensor([[-0.4670, -1.0603],
        [-0.4747, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016907282173633575
Epoch 0, Step 91: train/loss = 0.4534330666065216, train/raw-loss = 0.44566017389297485, train/logprobs = tensor([[-0.4704, -2.7845],
        [-0.5097, -1.4964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012954788282513618
Epoch 0, Step 92: train/loss = 0.6620771884918213, train/raw-loss = 0.6497379541397095, train/logprobs = tensor([[-0.6977, -1.0911],
        [-0.6951, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020565422251820564
Epoch 0, Step 93: train/loss = 0.5992423295974731, train/raw-loss = 0.5894447565078735, train/logprobs = tensor([[-0.5679, -1.4658],
        [-0.5590, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01632925681769848
Epoch 0, Step 94: train/loss = 0.5986526608467102, train/raw-loss = 0.5882672071456909, train/logprobs = tensor([[-0.6771, -1.8464],
        [-0.7715, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017309078946709633
Epoch 0, Step 95: train/loss = 0.6348463296890259, train/raw-loss = 0.6265102028846741, train/logprobs = tensor([[-0.5273, -1.0184],
        [-0.5227, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01389356143772602
Epoch 0, Step 96: train/loss = 0.709101140499115, train/raw-loss = 0.6834317445755005, train/logprobs = tensor([[-0.5960, -0.8872],
        [-0.5807, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04278240352869034
Epoch 0, Step 97: train/loss = 0.5832353234291077, train/raw-loss = 0.5613225698471069, train/logprobs = tensor([[-0.6330, -1.9431],
        [-0.6154, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03652125969529152
Epoch 0, Step 98: train/loss = 0.6311952471733093, train/raw-loss = 0.6143078804016113, train/logprobs = tensor([[-0.3823, -0.9695],
        [-0.3306, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02814565971493721
Epoch 0, Step 99: train/loss = 0.6433002352714539, train/raw-loss = 0.6251999735832214, train/logprobs = tensor([[-0.5284, -1.0391],
        [-0.5054, -0.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030167173594236374
Epoch 0, Step 100: train/loss = 0.5600064992904663, train/raw-loss = 0.5416346788406372, train/logprobs = tensor([[-0.6793, -2.7601],
        [-0.6610, -1.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030619628727436066
Epoch 0, Step 101: train/loss = 0.6167892217636108, train/raw-loss = 0.5865451097488403, train/logprobs = tensor([[-0.9528, -1.8300],
        [-0.9255, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050406813621520996
Epoch 0, Step 102: train/loss = 0.5990979671478271, train/raw-loss = 0.578421950340271, train/logprobs = tensor([[-0.4952, -1.3490],
        [-0.4916, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03446009010076523
Epoch 0, Step 103: train/loss = 0.5724776983261108, train/raw-loss = 0.5546313524246216, train/logprobs = tensor([[-0.6335, -1.7038],
        [-0.5495, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029743876308202744
Epoch 0, Step 104: train/loss = 0.46810823678970337, train/raw-loss = 0.44443777203559875, train/logprobs = tensor([[-0.7911, -4.4869],
        [-0.6611, -2.4470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03945078328251839
Epoch 0, Step 105: train/loss = 0.6185276508331299, train/raw-loss = 0.596938967704773, train/logprobs = tensor([[-0.6720, -1.1877],
        [-0.6235, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035981085151433945
Epoch 0, Step 106: train/loss = 0.4716627895832062, train/raw-loss = 0.4531661570072174, train/logprobs = tensor([[-0.6777, -4.3731],
        [-0.6225, -2.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030827779322862625
Epoch 0, Step 107: train/loss = 0.6232529282569885, train/raw-loss = 0.5968396663665771, train/logprobs = tensor([[-0.7135, -1.5246],
        [-0.6756, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0440220981836319
Epoch 0, Step 108: train/loss = 0.6758064031600952, train/raw-loss = 0.6617439389228821, train/logprobs = tensor([[-0.5276, -0.6573],
        [-0.4646, -0.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023437464609742165
Epoch 0, Step 109: train/loss = 0.6209198832511902, train/raw-loss = 0.6016948223114014, train/logprobs = tensor([[-0.6355, -1.2729],
        [-0.5519, -0.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032041676342487335
Epoch 0, Step 110: train/loss = 0.5580481290817261, train/raw-loss = 0.5389808416366577, train/logprobs = tensor([[-0.6591, -2.9357],
        [-0.5495, -1.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03177889063954353
Epoch 0, Step 111: train/loss = 0.590839147567749, train/raw-loss = 0.5753100514411926, train/logprobs = tensor([[-0.4335, -1.4968],
        [-0.4148, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025881744921207428
Epoch 0, Step 112: train/loss = 0.6149895191192627, train/raw-loss = 0.5958174467086792, train/logprobs = tensor([[-0.6284, -1.0999],
        [-0.5965, -0.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031953565776348114
Epoch 0, Step 113: train/loss = 0.651211142539978, train/raw-loss = 0.6238576173782349, train/logprobs = tensor([[-0.6464, -1.2735],
        [-0.5760, -0.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04558917507529259
Epoch 0, Step 114: train/loss = 0.6201084852218628, train/raw-loss = 0.598274290561676, train/logprobs = tensor([[-0.5639, -1.0618],
        [-0.5358, -0.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03639034181833267
Epoch 0, Step 115: train/loss = 0.63178551197052, train/raw-loss = 0.6136455535888672, train/logprobs = tensor([[-0.5614, -1.1578],
        [-0.5276, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03023332729935646
Epoch 0, Step 116: train/loss = 0.5825887322425842, train/raw-loss = 0.5592553019523621, train/logprobs = tensor([[-0.6646, -2.0436],
        [-0.6110, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038889043033123016
Epoch 0, Step 117: train/loss = 0.6361924409866333, train/raw-loss = 0.6159147024154663, train/logprobs = tensor([[-0.4855, -1.7613],
        [-0.4623, -1.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03379632532596588
Epoch 0, Step 118: train/loss = 0.5096150040626526, train/raw-loss = 0.4926668107509613, train/logprobs = tensor([[-0.6564, -3.1776],
        [-0.5759, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02824694663286209
Epoch 0, Step 119: train/loss = 0.5908068418502808, train/raw-loss = 0.565948486328125, train/logprobs = tensor([[-0.6138, -1.6718],
        [-0.5662, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04143068566918373
Epoch 0, Step 120: train/loss = 0.5401300191879272, train/raw-loss = 0.516753077507019, train/logprobs = tensor([[-0.7806, -2.6182],
        [-0.7659, -1.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03896167874336243
Epoch 0, Step 121: train/loss = 0.6228289604187012, train/raw-loss = 0.6038740277290344, train/logprobs = tensor([[-0.4980, -1.2259],
        [-0.4448, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031591542065143585
Epoch 0, Step 122: train/loss = 0.5571749806404114, train/raw-loss = 0.5352710485458374, train/logprobs = tensor([[-0.8394, -1.9342],
        [-0.7476, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036506570875644684
Epoch 0, Step 123: train/loss = 0.6839414834976196, train/raw-loss = 0.663379430770874, train/logprobs = tensor([[-0.5311, -0.7930],
        [-0.5078, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03427005186676979
Epoch 0, Step 124: train/loss = 0.6009349822998047, train/raw-loss = 0.577471137046814, train/logprobs = tensor([[-0.7875, -1.6026],
        [-0.7066, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039106398820877075
Epoch 0, Step 125: train/loss = 0.5540697574615479, train/raw-loss = 0.5315890908241272, train/logprobs = tensor([[-0.6963, -3.1697],
        [-0.6293, -2.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03746771067380905
Epoch 0, Step 126: train/loss = 0.65130615234375, train/raw-loss = 0.6262235641479492, train/logprobs = tensor([[-0.6722, -1.1946],
        [-0.5705, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041804417967796326
Epoch 0, Step 127: train/loss = 0.6323447227478027, train/raw-loss = 0.6097595691680908, train/logprobs = tensor([[-0.5062, -1.4819],
        [-0.4445, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037641968578100204
Epoch 0, Step 128: train/loss = 0.7140396237373352, train/raw-loss = 0.6494723558425903, train/logprobs = tensor([[-0.8119, -1.0261],
        [-0.7766, -0.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10761219263076782
Epoch 0, Step 129: train/loss = 0.5979301333427429, train/raw-loss = 0.5139157176017761, train/logprobs = tensor([[-0.7319, -2.8008],
        [-0.6284, -1.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1400240808725357
Epoch 0, Step 130: train/loss = 0.6996411085128784, train/raw-loss = 0.6229080557823181, train/logprobs = tensor([[-0.5330, -1.1514],
        [-0.4674, -0.7595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12788841128349304
Epoch 0, Step 131: train/loss = 0.5860845446586609, train/raw-loss = 0.5011768341064453, train/logprobs = tensor([[-0.7599, -4.0473],
        [-0.6754, -2.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14151278138160706
Epoch 0, Step 132: train/loss = 0.6051222681999207, train/raw-loss = 0.5271254181861877, train/logprobs = tensor([[-0.7805, -2.3267],
        [-0.6361, -1.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129994735121727
Epoch 0, Step 133: train/loss = 0.6207678318023682, train/raw-loss = 0.5404456257820129, train/logprobs = tensor([[-0.6447, -2.3858],
        [-0.5596, -1.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13387039303779602
Epoch 0, Step 134: train/loss = 0.6289724111557007, train/raw-loss = 0.5553032159805298, train/logprobs = tensor([[-0.7401, -1.6461],
        [-0.6198, -0.8042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12278187274932861
Epoch 0, Step 135: train/loss = 0.672768771648407, train/raw-loss = 0.5914426445960999, train/logprobs = tensor([[-0.5146, -1.4748],
        [-0.3928, -0.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13554351031780243
Epoch 0, Step 136: train/loss = 0.600943922996521, train/raw-loss = 0.5242116451263428, train/logprobs = tensor([[-0.4389, -2.0976],
        [-0.3930, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12788717448711395
Epoch 0, Step 137: train/loss = 0.6692995429039001, train/raw-loss = 0.5955661535263062, train/logprobs = tensor([[-0.4363, -1.3204],
        [-0.4006, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12288906425237656
Epoch 0, Step 138: train/loss = 0.6257412433624268, train/raw-loss = 0.5405505895614624, train/logprobs = tensor([[-0.4355, -1.6840],
        [-0.3639, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14198441803455353
Epoch 0, Step 139: train/loss = 0.6004447340965271, train/raw-loss = 0.5205970406532288, train/logprobs = tensor([[-0.6091, -2.3506],
        [-0.4937, -1.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13307960331439972
Epoch 0, Step 140: train/loss = 0.6537872552871704, train/raw-loss = 0.5794067978858948, train/logprobs = tensor([[-0.7720, -1.7455],
        [-0.6559, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1239674761891365
Epoch 0, Step 141: train/loss = 0.6588056683540344, train/raw-loss = 0.5793044567108154, train/logprobs = tensor([[-0.9107, -1.9010],
        [-0.6725, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325019896030426
Epoch 0, Step 142: train/loss = 0.6809778213500977, train/raw-loss = 0.6095368266105652, train/logprobs = tensor([[-0.5557, -1.2133],
        [-0.4743, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11906825006008148
Epoch 0, Step 143: train/loss = 0.7015248537063599, train/raw-loss = 0.6309130787849426, train/logprobs = tensor([[-0.7353, -1.5440],
        [-0.5847, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1176861971616745
Epoch 0, Step 144: train/loss = 0.5354681015014648, train/raw-loss = 0.4647977948188782, train/logprobs = tensor([[-0.5741, -3.9113],
        [-0.4964, -2.3622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11778394132852554
Epoch 0, Step 145: train/loss = 0.6749504804611206, train/raw-loss = 0.6088881492614746, train/logprobs = tensor([[-0.6347, -1.5254],
        [-0.5568, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11010386794805527
Epoch 0, Step 146: train/loss = 0.619078516960144, train/raw-loss = 0.5456748604774475, train/logprobs = tensor([[-0.6396, -2.7212],
        [-0.5099, -1.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12233942747116089
Epoch 0, Step 147: train/loss = 0.6797246336936951, train/raw-loss = 0.607477068901062, train/logprobs = tensor([[-0.6159, -1.1789],
        [-0.5121, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12041258811950684
Epoch 0, Step 148: train/loss = 0.7534174919128418, train/raw-loss = 0.6741220951080322, train/logprobs = tensor([[-1.4888, -1.8293],
        [-1.1155, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13215908408164978
Epoch 0, Step 149: train/loss = 0.6894904971122742, train/raw-loss = 0.6263566613197327, train/logprobs = tensor([[-0.6267, -1.2600],
        [-0.5180, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522311925888062
Epoch 0, Step 150: train/loss = 0.600296139717102, train/raw-loss = 0.5295023918151855, train/logprobs = tensor([[-0.8090, -3.5125],
        [-0.7219, -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11798964440822601
Epoch 0, Step 151: train/loss = 0.6547349691390991, train/raw-loss = 0.5792571306228638, train/logprobs = tensor([[-0.6660, -1.8373],
        [-0.5268, -1.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1257963329553604
Epoch 0, Step 152: train/loss = 0.6793097257614136, train/raw-loss = 0.5983883142471313, train/logprobs = tensor([[-0.8250, -1.3855],
        [-0.7553, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13486893475055695
Epoch 0, Step 153: train/loss = 0.6541595458984375, train/raw-loss = 0.5680449604988098, train/logprobs = tensor([[-0.6079, -2.0068],
        [-0.5014, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14352427423000336
Epoch 0, Step 154: train/loss = 0.7027584910392761, train/raw-loss = 0.635367751121521, train/logprobs = tensor([[-0.7359, -1.6048],
        [-0.6408, -1.2549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11231794953346252
Epoch 0, Step 155: train/loss = 0.6170121431350708, train/raw-loss = 0.5533578395843506, train/logprobs = tensor([[-0.5917, -2.8881],
        [-0.5008, -1.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060905009508133
Epoch 0, Step 156: train/loss = 0.7088507413864136, train/raw-loss = 0.6507411599159241, train/logprobs = tensor([[-0.6313, -0.7526],
        [-0.5677, -0.5065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09684918075799942
Epoch 0, Step 157: train/loss = 0.7380166053771973, train/raw-loss = 0.6850719451904297, train/logprobs = tensor([[-0.7303, -0.7915],
        [-0.6421, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882410854101181
Epoch 0, Step 158: train/loss = 0.711801290512085, train/raw-loss = 0.6425371170043945, train/logprobs = tensor([[-0.6871, -1.2001],
        [-0.4828, -0.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11544021964073181
Epoch 0, Step 159: train/loss = 0.7306371927261353, train/raw-loss = 0.6655013561248779, train/logprobs = tensor([[-0.8516, -1.0420],
        [-0.7104, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10855969041585922
Epoch 0, Step 160: train/loss = 0.5841457843780518, train/raw-loss = 0.5212394595146179, train/logprobs = tensor([[-1.0787, -2.2668],
        [-0.8430, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484384745359421
Epoch 0, Step 161: train/loss = 0.6612740159034729, train/raw-loss = 0.6180846691131592, train/logprobs = tensor([[-0.6636, -1.2864],
        [-0.5556, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07198221236467361
Epoch 0, Step 162: train/loss = 0.6061042547225952, train/raw-loss = 0.5570058822631836, train/logprobs = tensor([[-0.5743, -2.9970],
        [-0.5039, -1.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08183062076568604
Epoch 0, Step 163: train/loss = 0.5976357460021973, train/raw-loss = 0.5370399951934814, train/logprobs = tensor([[-0.5695, -2.0781],
        [-0.4356, -1.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10099293291568756
Epoch 0, Step 164: train/loss = 0.6046934723854065, train/raw-loss = 0.5559261441230774, train/logprobs = tensor([[-0.6633, -1.8258],
        [-0.5170, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08127881586551666
Epoch 0, Step 165: train/loss = 0.5963051319122314, train/raw-loss = 0.5345355868339539, train/logprobs = tensor([[-0.6512, -2.1569],
        [-0.4917, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10294923186302185
Epoch 0, Step 166: train/loss = 0.47271043062210083, train/raw-loss = 0.40964221954345703, train/logprobs = tensor([[-0.6340, -6.7276],
        [-0.4473, -3.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10511365532875061
Epoch 0, Step 167: train/loss = 0.6670096516609192, train/raw-loss = 0.6063529253005981, train/logprobs = tensor([[-0.7229, -1.4237],
        [-0.5669, -0.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10109463334083557
Epoch 0, Step 168: train/loss = 0.6325949430465698, train/raw-loss = 0.5763475298881531, train/logprobs = tensor([[-0.6925, -1.5047],
        [-0.5560, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09374558925628662
Epoch 0, Step 169: train/loss = 0.6939775943756104, train/raw-loss = 0.6466288566589355, train/logprobs = tensor([[-0.7856, -1.3258],
        [-0.7223, -1.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07891466468572617
Epoch 0, Step 170: train/loss = 0.6292827725410461, train/raw-loss = 0.5696746706962585, train/logprobs = tensor([[-0.5871, -1.6854],
        [-0.5548, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934689849615097
Epoch 0, Step 171: train/loss = 0.6857194304466248, train/raw-loss = 0.6290590763092041, train/logprobs = tensor([[-0.6477, -1.3392],
        [-0.5148, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09443389624357224
Epoch 0, Step 172: train/loss = 0.5515969395637512, train/raw-loss = 0.49089595675468445, train/logprobs = tensor([[-0.6363, -2.5879],
        [-0.5744, -1.4084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10116834193468094
Epoch 0, Step 173: train/loss = 0.5737907886505127, train/raw-loss = 0.5164065361022949, train/logprobs = tensor([[-0.6171, -2.4548],
        [-0.5415, -1.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564042836427689
Epoch 0, Step 174: train/loss = 0.5770857334136963, train/raw-loss = 0.5204430818557739, train/logprobs = tensor([[-0.6801, -2.0470],
        [-0.5560, -0.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09440445154905319
Epoch 0, Step 175: train/loss = 0.4959867596626282, train/raw-loss = 0.43385860323905945, train/logprobs = tensor([[-0.5059, -3.5284],
        [-0.4076, -1.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10354698449373245
Epoch 0, Step 176: train/loss = 0.6480540633201599, train/raw-loss = 0.5802755951881409, train/logprobs = tensor([[-0.7256, -1.6458],
        [-0.4955, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11296410858631134
Epoch 0, Step 177: train/loss = 0.6283653974533081, train/raw-loss = 0.5634135007858276, train/logprobs = tensor([[-1.0553, -2.4721],
        [-0.6372, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825308412313461
Epoch 0, Step 178: train/loss = 0.6551308631896973, train/raw-loss = 0.5981857776641846, train/logprobs = tensor([[-0.8511, -2.4063],
        [-0.7424, -1.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09490840137004852
Epoch 0, Step 179: train/loss = 0.6399029493331909, train/raw-loss = 0.5839354395866394, train/logprobs = tensor([[-0.6538, -2.4629],
        [-0.4979, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09327924996614456
Epoch 0, Step 180: train/loss = 0.7370623350143433, train/raw-loss = 0.6819485425949097, train/logprobs = tensor([[-0.8350, -0.8945],
        [-0.6405, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09185629338026047
Epoch 0, Step 181: train/loss = 0.7447962760925293, train/raw-loss = 0.6845388412475586, train/logprobs = tensor([[-2.7665, -4.0452],
        [-1.9004, -2.3616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10042905062437057
Epoch 0, Step 182: train/loss = 0.664848268032074, train/raw-loss = 0.6110957860946655, train/logprobs = tensor([[-0.5321, -1.2380],
        [-0.4581, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958747982978821
Epoch 0, Step 183: train/loss = 0.6250428557395935, train/raw-loss = 0.5649747252464294, train/logprobs = tensor([[-0.7064, -1.7414],
        [-0.5935, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10011355578899384
Epoch 0, Step 184: train/loss = 0.5434038639068604, train/raw-loss = 0.48660480976104736, train/logprobs = tensor([[-1.1819, -4.1606],
        [-1.1576, -2.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0946650505065918
Epoch 0, Step 185: train/loss = 0.6247437596321106, train/raw-loss = 0.5699119567871094, train/logprobs = tensor([[-0.8526, -2.0931],
        [-0.6735, -1.2611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0913863331079483
Epoch 0, Step 186: train/loss = 0.6421886682510376, train/raw-loss = 0.5719082355499268, train/logprobs = tensor([[-0.8053, -1.6354],
        [-0.7140, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11713410913944244
Epoch 0, Step 187: train/loss = 0.6201777458190918, train/raw-loss = 0.5677193403244019, train/logprobs = tensor([[-0.6031, -2.3150],
        [-0.4870, -1.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08743056654930115
Epoch 0, Step 188: train/loss = 0.551339864730835, train/raw-loss = 0.49221426248550415, train/logprobs = tensor([[-0.8484, -4.1124],
        [-0.6072, -2.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09854265302419662
Epoch 0, Step 189: train/loss = 0.6955755949020386, train/raw-loss = 0.652384340763092, train/logprobs = tensor([[-0.5990, -0.8897],
        [-0.5054, -0.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07198545336723328
Epoch 0, Step 190: train/loss = 0.5789161920547485, train/raw-loss = 0.5298662185668945, train/logprobs = tensor([[-0.8196, -3.6629],
        [-0.6165, -1.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174995332956314
Epoch 0, Step 191: train/loss = 0.6725943088531494, train/raw-loss = 0.6136786937713623, train/logprobs = tensor([[-0.6850, -1.1448],
        [-0.5973, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09819263964891434
Epoch 0, Step 192: train/loss = 0.6281900405883789, train/raw-loss = 0.5543002486228943, train/logprobs = tensor([[-0.7417, -1.5263],
        [-0.5623, -0.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12314961850643158
Epoch 0, Step 193: train/loss = 0.5561253428459167, train/raw-loss = 0.47312286496162415, train/logprobs = tensor([[-0.7649, -3.0841],
        [-0.6420, -1.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13833744823932648
Epoch 0, Step 194: train/loss = 0.5402851104736328, train/raw-loss = 0.46455422043800354, train/logprobs = tensor([[-0.8663, -3.7695],
        [-0.7231, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12621815502643585
Epoch 0, Step 195: train/loss = 0.5665708780288696, train/raw-loss = 0.49623793363571167, train/logprobs = tensor([[-0.8052, -3.3591],
        [-0.6133, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1172216460108757
Epoch 0, Step 196: train/loss = 0.6458882093429565, train/raw-loss = 0.5755237936973572, train/logprobs = tensor([[-0.7002, -1.5195],
        [-0.5831, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11727394163608551
Epoch 0, Step 197: train/loss = 0.5920422673225403, train/raw-loss = 0.5193873643875122, train/logprobs = tensor([[-0.6893, -2.3637],
        [-0.5089, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12109152227640152
Epoch 0, Step 198: train/loss = 0.6226637959480286, train/raw-loss = 0.549849808216095, train/logprobs = tensor([[-0.6677, -1.7784],
        [-0.5540, -0.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12135659903287888
Epoch 0, Step 199: train/loss = 0.5314026474952698, train/raw-loss = 0.4514352083206177, train/logprobs = tensor([[-0.5010, -2.2409],
        [-0.3786, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13327914476394653
Epoch 0, Step 200: train/loss = 0.5490350723266602, train/raw-loss = 0.4839017987251282, train/logprobs = tensor([[-0.8697, -2.2624],
        [-0.6824, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10855548828840256
Epoch 0, Step 201: train/loss = 0.5418530702590942, train/raw-loss = 0.4588084816932678, train/logprobs = tensor([[-0.8738, -3.2605],
        [-0.6786, -1.3273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13840769231319427
Epoch 0, Step 202: train/loss = 0.6616367101669312, train/raw-loss = 0.5954495072364807, train/logprobs = tensor([[-0.6874, -1.1465],
        [-0.6803, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1103120669722557
Epoch 0, Step 203: train/loss = 0.6526799201965332, train/raw-loss = 0.5764731168746948, train/logprobs = tensor([[-0.7598, -2.6865],
        [-0.4628, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12701129913330078
Epoch 0, Step 204: train/loss = 0.578044056892395, train/raw-loss = 0.5102189183235168, train/logprobs = tensor([[-0.9079, -2.0537],
        [-0.7297, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11304187029600143
Epoch 0, Step 205: train/loss = 0.5153313875198364, train/raw-loss = 0.43693265318870544, train/logprobs = tensor([[-0.5543, -2.4441],
        [-0.5108, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13066446781158447
Epoch 0, Step 206: train/loss = 0.43010765314102173, train/raw-loss = 0.3547877073287964, train/logprobs = tensor([[-0.6122, -5.3957],
        [-0.5270, -1.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12553323805332184
Epoch 0, Step 207: train/loss = 0.5408869385719299, train/raw-loss = 0.4681101441383362, train/logprobs = tensor([[-0.9328, -2.3142],
        [-0.7821, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12129458785057068
Epoch 0, Step 208: train/loss = 0.5593487024307251, train/raw-loss = 0.4865473508834839, train/logprobs = tensor([[-0.7658, -3.3890],
        [-0.5437, -1.1829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12133558839559555
Epoch 0, Step 209: train/loss = 0.612446665763855, train/raw-loss = 0.5331767797470093, train/logprobs = tensor([[-0.7476, -2.0733],
        [-0.6175, -0.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13211652636528015
Epoch 0, Step 210: train/loss = 0.5988412499427795, train/raw-loss = 0.53406822681427, train/logprobs = tensor([[-0.6857, -1.6862],
        [-0.5604, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10795504599809647
Epoch 0, Step 211: train/loss = 0.637891411781311, train/raw-loss = 0.5714030861854553, train/logprobs = tensor([[-1.0449, -4.0158],
        [-1.0214, -1.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11081387102603912
Epoch 0, Step 212: train/loss = 0.6661479473114014, train/raw-loss = 0.6018101572990417, train/logprobs = tensor([[-0.5620, -1.3054],
        [-0.4548, -0.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10722966492176056
Epoch 0, Step 213: train/loss = 0.6711282730102539, train/raw-loss = 0.5970112085342407, train/logprobs = tensor([[-0.6883, -1.3357],
        [-0.5081, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.123528391122818
Epoch 0, Step 214: train/loss = 0.5936737060546875, train/raw-loss = 0.5149921178817749, train/logprobs = tensor([[-0.6204, -2.8610],
        [-0.5639, -1.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13113601505756378
Epoch 0, Step 215: train/loss = 0.5596340298652649, train/raw-loss = 0.4869774580001831, train/logprobs = tensor([[-0.9273, -2.7643],
        [-0.8606, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1210942268371582
Epoch 0, Step 216: train/loss = 0.6749864220619202, train/raw-loss = 0.6116484999656677, train/logprobs = tensor([[-0.8054, -1.2290],
        [-0.5352, -0.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10556328296661377
Epoch 0, Step 217: train/loss = 0.5394439101219177, train/raw-loss = 0.46896642446517944, train/logprobs = tensor([[-0.5910, -2.4752],
        [-0.5065, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11746247112751007
Epoch 0, Step 218: train/loss = 0.7205302715301514, train/raw-loss = 0.6672619581222534, train/logprobs = tensor([[-0.6127, -0.7800],
        [-0.5209, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0887804925441742
Epoch 0, Step 219: train/loss = 0.6268436312675476, train/raw-loss = 0.5589617490768433, train/logprobs = tensor([[-0.6615, -1.7134],
        [-0.5564, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11313647776842117
Epoch 0, Step 220: train/loss = 0.48621800541877747, train/raw-loss = 0.4165027439594269, train/logprobs = tensor([[-1.1143, -3.6864],
        [-0.8883, -1.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11619210988283157
Epoch 0, Step 221: train/loss = 0.5774699449539185, train/raw-loss = 0.5110470652580261, train/logprobs = tensor([[-0.4783, -3.9070],
        [-0.4262, -1.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11070481687784195
Epoch 0, Step 222: train/loss = 0.6190392971038818, train/raw-loss = 0.5525000095367432, train/logprobs = tensor([[-0.6735, -2.0787],
        [-0.5147, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11089881509542465
Epoch 0, Step 223: train/loss = 0.6304087042808533, train/raw-loss = 0.5619453191757202, train/logprobs = tensor([[-0.8414, -2.1070],
        [-0.6456, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11410564184188843
Epoch 0, Step 224: train/loss = 0.6138889789581299, train/raw-loss = 0.5512995719909668, train/logprobs = tensor([[-0.7138, -1.4831],
        [-0.6493, -0.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10431563854217529
Epoch 0, Step 225: train/loss = 0.6179875135421753, train/raw-loss = 0.563138484954834, train/logprobs = tensor([[-0.6094, -1.4755],
        [-0.4486, -0.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09141512215137482
Epoch 0, Step 226: train/loss = 0.8595067858695984, train/raw-loss = 0.79630047082901, train/logprobs = tensor([[-2.0831, -3.3296],
        [-0.6831, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10534386336803436
Epoch 0, Step 227: train/loss = 0.5275560021400452, train/raw-loss = 0.45191681385040283, train/logprobs = tensor([[-1.0299, -3.3564],
        [-0.5654, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12606531381607056
Epoch 0, Step 228: train/loss = 0.58570396900177, train/raw-loss = 0.5324101448059082, train/logprobs = tensor([[-0.5670, -2.0098],
        [-0.4373, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08882300555706024
Epoch 0, Step 229: train/loss = 0.4893137812614441, train/raw-loss = 0.4227098822593689, train/logprobs = tensor([[-0.9191, -5.1752],
        [-0.8121, -2.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1110064834356308
Epoch 0, Step 230: train/loss = 0.495052695274353, train/raw-loss = 0.43021664023399353, train/logprobs = tensor([[-1.1343, -3.2245],
        [-1.0321, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1080600768327713
Epoch 0, Step 231: train/loss = 0.46389132738113403, train/raw-loss = 0.4064394235610962, train/logprobs = tensor([[-0.6709, -4.2393],
        [-0.6788, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09575316309928894
Epoch 0, Step 232: train/loss = 0.5890798568725586, train/raw-loss = 0.5285269021987915, train/logprobs = tensor([[-0.6136, -2.4198],
        [-0.5701, -1.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10092160850763321
Epoch 0, Step 233: train/loss = 0.6412888169288635, train/raw-loss = 0.5783731341362, train/logprobs = tensor([[-1.2532, -5.0654],
        [-0.8208, -1.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10485944896936417
Epoch 0, Step 234: train/loss = 0.658724844455719, train/raw-loss = 0.6013343334197998, train/logprobs = tensor([[-0.5973, -1.1178],
        [-0.4870, -0.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956508070230484
Epoch 0, Step 235: train/loss = 0.5208265781402588, train/raw-loss = 0.4566960334777832, train/logprobs = tensor([[-0.9731, -4.3620],
        [-0.5809, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10688424110412598
Epoch 0, Step 236: train/loss = 0.6320574283599854, train/raw-loss = 0.5649541616439819, train/logprobs = tensor([[-0.7277, -1.9131],
        [-0.6152, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11183884739875793
Epoch 0, Step 237: train/loss = 0.5601646304130554, train/raw-loss = 0.5026476979255676, train/logprobs = tensor([[-0.7449, -2.0233],
        [-0.6572, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09586159884929657
Epoch 0, Step 238: train/loss = 0.5183650255203247, train/raw-loss = 0.4598137140274048, train/logprobs = tensor([[-0.5779, -2.5328],
        [-0.4955, -0.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09758546203374863
Epoch 0, Step 239: train/loss = 0.677740216255188, train/raw-loss = 0.6235224604606628, train/logprobs = tensor([[-0.8140, -1.1098],
        [-0.5724, -0.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09036295115947723
Epoch 0, Step 240: train/loss = 0.6463217735290527, train/raw-loss = 0.5781776309013367, train/logprobs = tensor([[-1.0810, -2.4892],
        [-1.0562, -1.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1135735809803009
Epoch 0, Step 241: train/loss = 0.5501987338066101, train/raw-loss = 0.4878643751144409, train/logprobs = tensor([[-0.5501, -1.8539],
        [-0.5193, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389064252376556
Epoch 0, Step 242: train/loss = 0.667205810546875, train/raw-loss = 0.6113830804824829, train/logprobs = tensor([[-0.5732, -1.0119],
        [-0.4101, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0930379182100296
Epoch 0, Step 243: train/loss = 0.6810510158538818, train/raw-loss = 0.6259312629699707, train/logprobs = tensor([[-0.7986, -1.1574],
        [-0.5089, -0.4864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918661579489708
Epoch 0, Step 244: train/loss = 0.5226200222969055, train/raw-loss = 0.45606088638305664, train/logprobs = tensor([[-1.0273, -3.6443],
        [-0.6967, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109318882226944
Epoch 0, Step 245: train/loss = 0.5750374794006348, train/raw-loss = 0.5112401843070984, train/logprobs = tensor([[-1.0596, -2.2937],
        [-0.6494, -0.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10632874071598053
Epoch 0, Step 246: train/loss = 0.49878785014152527, train/raw-loss = 0.4326168894767761, train/logprobs = tensor([[-0.6641, -3.7901],
        [-0.6720, -1.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028491705656052
Epoch 0, Step 247: train/loss = 0.5975954532623291, train/raw-loss = 0.5353107452392578, train/logprobs = tensor([[-0.9493, -2.4763],
        [-0.7345, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10380777716636658
Epoch 0, Step 248: train/loss = 0.6376386284828186, train/raw-loss = 0.5845751762390137, train/logprobs = tensor([[-0.6544, -1.8831],
        [-0.6816, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843904733657837
Epoch 0, Step 249: train/loss = 0.570249080657959, train/raw-loss = 0.5126993656158447, train/logprobs = tensor([[-0.4807, -2.2330],
        [-0.5041, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09591613709926605
Epoch 0, Step 250: train/loss = 0.5472457408905029, train/raw-loss = 0.4813790023326874, train/logprobs = tensor([[-1.2050, -4.2310],
        [-0.5907, -1.2159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977789759635925
Epoch 0, Step 251: train/loss = 0.4576043486595154, train/raw-loss = 0.3925029933452606, train/logprobs = tensor([[-0.6450, -2.8749],
        [-0.6405, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10850222408771515
Epoch 0, Step 252: train/loss = 0.5994616746902466, train/raw-loss = 0.5443315505981445, train/logprobs = tensor([[-0.4841, -1.5867],
        [-0.4081, -0.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09188356250524521
Epoch 0, Step 253: train/loss = 0.7391430139541626, train/raw-loss = 0.6860790252685547, train/logprobs = tensor([[-0.7617, -0.6221],
        [-0.6345, -0.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843989670276642
Epoch 0, Step 254: train/loss = 0.5148926973342896, train/raw-loss = 0.4552219808101654, train/logprobs = tensor([[-0.7533, -3.1988],
        [-0.5909, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09945117682218552
Epoch 0, Step 255: train/loss = 0.6046483516693115, train/raw-loss = 0.541223406791687, train/logprobs = tensor([[-1.0844, -2.5247],
        [-0.8863, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10570821166038513
Epoch 0, Step 256: train/loss = 0.6963671445846558, train/raw-loss = 0.6494061946868896, train/logprobs = tensor([[-0.5679, -0.8557],
        [-0.4331, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07826823741197586
Epoch 0, Step 257: train/loss = 0.683495044708252, train/raw-loss = 0.6286930441856384, train/logprobs = tensor([[-0.7664, -1.2249],
        [-0.5928, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133663028478622
Epoch 0, Step 258: train/loss = 0.4146071672439575, train/raw-loss = 0.34906503558158875, train/logprobs = tensor([[-0.9020, -3.2915],
        [-0.9440, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10923686623573303
Epoch 0, Step 259: train/loss = 0.5661818981170654, train/raw-loss = 0.5162466764450073, train/logprobs = tensor([[-0.5838, -3.6896],
        [-0.5149, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08322537690401077
Epoch 0, Step 260: train/loss = 0.48364579677581787, train/raw-loss = 0.4251059591770172, train/logprobs = tensor([[-0.5226, -4.5517],
        [-0.4684, -1.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09756634384393692
Epoch 0, Step 261: train/loss = 0.525254487991333, train/raw-loss = 0.45803508162498474, train/logprobs = tensor([[-0.8131, -2.1706],
        [-0.8428, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11203235387802124
Epoch 0, Step 262: train/loss = 0.6006754040718079, train/raw-loss = 0.5400519371032715, train/logprobs = tensor([[-0.6964, -2.4134],
        [-0.6135, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10103914886713028
Epoch 0, Step 263: train/loss = 0.6515806317329407, train/raw-loss = 0.5876469612121582, train/logprobs = tensor([[-1.2752, -2.0294],
        [-1.0566, -1.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10655611008405685
Epoch 0, Step 264: train/loss = 0.6384566426277161, train/raw-loss = 0.5868794918060303, train/logprobs = tensor([[-0.7468, -1.3703],
        [-0.6655, -0.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08596189320087433
Epoch 0, Step 265: train/loss = 0.6899428367614746, train/raw-loss = 0.6356892585754395, train/logprobs = tensor([[-0.8824, -1.3161],
        [-0.6441, -0.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09042258560657501
Epoch 0, Step 266: train/loss = 0.47393256425857544, train/raw-loss = 0.41103875637054443, train/logprobs = tensor([[-0.9978, -3.3362],
        [-1.0083, -1.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10482297092676163
Epoch 0, Step 267: train/loss = 0.5183060169219971, train/raw-loss = 0.45668894052505493, train/logprobs = tensor([[-0.6866, -2.3344],
        [-0.5518, -0.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10269508510828018
Epoch 0, Step 268: train/loss = 0.5375349521636963, train/raw-loss = 0.48546066880226135, train/logprobs = tensor([[-0.6546, -4.9588],
        [-0.6562, -1.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08679050952196121
Epoch 0, Step 269: train/loss = 0.5539894700050354, train/raw-loss = 0.4965052604675293, train/logprobs = tensor([[-0.7879, -3.8964],
        [-0.6959, -1.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09580693393945694
Epoch 0, Step 270: train/loss = 0.548678457736969, train/raw-loss = 0.48715639114379883, train/logprobs = tensor([[-0.4082, -2.0232],
        [-0.3541, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10253673791885376
Epoch 0, Step 271: train/loss = 0.5550903677940369, train/raw-loss = 0.4956924319267273, train/logprobs = tensor([[-0.7845, -2.1078],
        [-0.6558, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09899656474590302
Epoch 0, Step 272: train/loss = 0.7168344259262085, train/raw-loss = 0.6636084318161011, train/logprobs = tensor([[-0.6104, -0.8337],
        [-0.5500, -0.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08870991319417953
Epoch 0, Step 273: train/loss = 0.6165001392364502, train/raw-loss = 0.5623250007629395, train/logprobs = tensor([[-0.4667, -1.2458],
        [-0.4868, -0.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09029188007116318
Epoch 0, Step 274: train/loss = 0.6372889876365662, train/raw-loss = 0.5787903070449829, train/logprobs = tensor([[-0.5710, -1.6015],
        [-0.4860, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09749777615070343
Epoch 0, Step 275: train/loss = 0.5363821983337402, train/raw-loss = 0.4856828451156616, train/logprobs = tensor([[-0.4835, -1.7772],
        [-0.4393, -0.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08449888229370117
Epoch 0, Step 276: train/loss = 0.5924270749092102, train/raw-loss = 0.5302795171737671, train/logprobs = tensor([[-1.2249, -2.5633],
        [-1.0401, -1.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10357925295829773
Epoch 0, Step 277: train/loss = 0.6546107530593872, train/raw-loss = 0.5900948643684387, train/logprobs = tensor([[-0.7701, -1.1908],
        [-0.7437, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10752642899751663
Epoch 0, Step 278: train/loss = 0.6009500622749329, train/raw-loss = 0.5376509428024292, train/logprobs = tensor([[-0.7739, -1.3576],
        [-0.7129, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10549845546483994
Epoch 0, Step 279: train/loss = 0.4690689742565155, train/raw-loss = 0.40560224652290344, train/logprobs = tensor([[-1.0046, -4.1189],
        [-0.7431, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10577788203954697
Epoch 0, Step 280: train/loss = 0.5419068932533264, train/raw-loss = 0.48181048035621643, train/logprobs = tensor([[-0.7875, -4.3275],
        [-0.6267, -1.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10016068816184998
Epoch 0, Step 281: train/loss = 0.6148419976234436, train/raw-loss = 0.5603995323181152, train/logprobs = tensor([[-0.5512, -1.1587],
        [-0.4802, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073746204376221
Epoch 0, Step 282: train/loss = 0.6165615320205688, train/raw-loss = 0.5395303964614868, train/logprobs = tensor([[-1.2035, -3.1167],
        [-0.8013, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12838521599769592
Epoch 0, Step 283: train/loss = 0.5637781023979187, train/raw-loss = 0.5042715668678284, train/logprobs = tensor([[-0.7485, -2.1552],
        [-0.6177, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991775169968605
Epoch 0, Step 284: train/loss = 0.6106581687927246, train/raw-loss = 0.5510357022285461, train/logprobs = tensor([[-0.4836, -1.3230],
        [-0.4879, -0.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0993707999587059
Epoch 0, Step 285: train/loss = 0.6322001814842224, train/raw-loss = 0.5770854353904724, train/logprobs = tensor([[-0.5697, -1.1367],
        [-0.5681, -0.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09185782074928284
Epoch 0, Step 286: train/loss = 0.5625506639480591, train/raw-loss = 0.5078493356704712, train/logprobs = tensor([[-0.4100, -1.7177],
        [-0.3453, -0.5002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09116880595684052
Epoch 0, Step 287: train/loss = 0.5417510867118835, train/raw-loss = 0.4785771369934082, train/logprobs = tensor([[-0.7599, -3.6938],
        [-0.7453, -1.3503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10528995096683502
Epoch 0, Step 288: train/loss = 0.5815948247909546, train/raw-loss = 0.5244740843772888, train/logprobs = tensor([[-0.5638, -1.6281],
        [-0.6013, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09520117193460464
Epoch 0, Step 289: train/loss = 0.5535841584205627, train/raw-loss = 0.4897577464580536, train/logprobs = tensor([[-0.8145, -3.0622],
        [-0.7271, -1.3270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10637731105089188
Epoch 0, Step 290: train/loss = 0.5430120825767517, train/raw-loss = 0.4889179468154907, train/logprobs = tensor([[-0.5589, -2.8566],
        [-0.5328, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09015685319900513
Epoch 0, Step 291: train/loss = 0.49871957302093506, train/raw-loss = 0.4401666522026062, train/logprobs = tensor([[-0.6972, -2.0922],
        [-0.7535, -0.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09758828580379486
Epoch 0, Step 292: train/loss = 0.581916332244873, train/raw-loss = 0.5299936532974243, train/logprobs = tensor([[-0.6047, -1.3525],
        [-0.6780, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08653782308101654
Epoch 0, Step 293: train/loss = 0.5815942287445068, train/raw-loss = 0.5194001793861389, train/logprobs = tensor([[-0.7670, -2.1591],
        [-0.6946, -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10365673154592514
Epoch 0, Step 294: train/loss = 0.5799627304077148, train/raw-loss = 0.5220759510993958, train/logprobs = tensor([[-0.8748, -1.6045],
        [-0.7688, -0.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09647800773382187
Epoch 0, Step 295: train/loss = 0.5554898977279663, train/raw-loss = 0.4939417541027069, train/logprobs = tensor([[-1.3370, -2.7926],
        [-1.2301, -1.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258027911186218
Epoch 0, Step 296: train/loss = 0.5974242687225342, train/raw-loss = 0.5411141514778137, train/logprobs = tensor([[-0.6738, -1.8504],
        [-0.6345, -0.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09385015815496445
Epoch 0, Step 297: train/loss = 0.4968005418777466, train/raw-loss = 0.4407421052455902, train/logprobs = tensor([[-0.6185, -3.2558],
        [-0.6566, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09343073517084122
Epoch 0, Step 298: train/loss = 0.572162389755249, train/raw-loss = 0.5192416310310364, train/logprobs = tensor([[-0.5488, -1.4702],
        [-0.6783, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08820122480392456
Epoch 0, Step 299: train/loss = 0.48752641677856445, train/raw-loss = 0.4332566261291504, train/logprobs = tensor([[-0.9726, -2.9001],
        [-0.9645, -0.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09044964611530304
Epoch 0, Step 300: train/loss = 0.5439811944961548, train/raw-loss = 0.49179109930992126, train/logprobs = tensor([[-0.7375, -2.2857],
        [-0.7568, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08698349446058273
Epoch 0, Step 301: train/loss = 0.5978250503540039, train/raw-loss = 0.5385609865188599, train/logprobs = tensor([[-0.6308, -1.2449],
        [-0.5906, -0.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09877339750528336
Epoch 0, Step 302: train/loss = 0.519545316696167, train/raw-loss = 0.4637504816055298, train/logprobs = tensor([[-0.6344, -2.1688],
        [-0.5932, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09299138933420181
Epoch 0, Step 303: train/loss = 0.4826737940311432, train/raw-loss = 0.42652368545532227, train/logprobs = tensor([[-0.5316, -2.5023],
        [-0.5644, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09358348697423935
Epoch 0, Step 304: train/loss = 0.5776007175445557, train/raw-loss = 0.5210394263267517, train/logprobs = tensor([[-0.6334, -1.6905],
        [-0.6264, -0.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942688137292862
Epoch 0, Step 305: train/loss = 0.5747573375701904, train/raw-loss = 0.5123277902603149, train/logprobs = tensor([[-0.8542, -2.7009],
        [-0.5309, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10404922813177109
Epoch 0, Step 306: train/loss = 0.6024737358093262, train/raw-loss = 0.5476691722869873, train/logprobs = tensor([[-0.7895, -3.4601],
        [-0.6675, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09134093672037125
Epoch 0, Step 307: train/loss = 0.5810954570770264, train/raw-loss = 0.5219440460205078, train/logprobs = tensor([[-0.8266, -3.9487],
        [-0.8280, -1.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858556091785431
Epoch 0, Step 308: train/loss = 0.6161742210388184, train/raw-loss = 0.5605956315994263, train/logprobs = tensor([[-0.6862, -1.3526],
        [-0.6454, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09263098239898682
Epoch 0, Step 309: train/loss = 0.6290717124938965, train/raw-loss = 0.5765195488929749, train/logprobs = tensor([[-0.5121, -1.2567],
        [-0.4554, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08758710324764252
Epoch 0, Step 310: train/loss = 0.43186134099960327, train/raw-loss = 0.3706499934196472, train/logprobs = tensor([[-0.6522, -3.9257],
        [-0.5434, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10201893746852875
Epoch 0, Step 311: train/loss = 0.5816903114318848, train/raw-loss = 0.5266336798667908, train/logprobs = tensor([[-0.5633, -2.4671],
        [-0.6004, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0917610302567482
Epoch 0, Step 312: train/loss = 0.609584629535675, train/raw-loss = 0.5608772039413452, train/logprobs = tensor([[-0.6509, -3.2615],
        [-0.5211, -0.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08117900788784027
Epoch 0, Step 313: train/loss = 0.5254933834075928, train/raw-loss = 0.46266278624534607, train/logprobs = tensor([[-0.6200, -2.2619],
        [-0.6200, -0.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10471765697002411
Epoch 0, Step 314: train/loss = 0.6524326801300049, train/raw-loss = 0.5994712710380554, train/logprobs = tensor([[-0.6010, -0.8549],
        [-0.6167, -0.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08826902508735657
Epoch 0, Step 315: train/loss = 0.6084574460983276, train/raw-loss = 0.5469418168067932, train/logprobs = tensor([[-1.7463, -3.4633],
        [-1.3394, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10252600908279419
Epoch 0, Step 316: train/loss = 0.7151317596435547, train/raw-loss = 0.6722145080566406, train/logprobs = tensor([[-0.7335, -0.6746],
        [-0.7277, -0.5771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0715285986661911
Epoch 0, Step 317: train/loss = 0.46078357100486755, train/raw-loss = 0.40339136123657227, train/logprobs = tensor([[-0.4745, -4.2606],
        [-0.4925, -1.2854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956537127494812
Epoch 0, Step 318: train/loss = 0.48431241512298584, train/raw-loss = 0.42658722400665283, train/logprobs = tensor([[-0.7262, -2.6059],
        [-0.7411, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09620864689350128
Epoch 0, Step 319: train/loss = 0.5144571661949158, train/raw-loss = 0.4552343189716339, train/logprobs = tensor([[-0.5361, -2.6107],
        [-0.5611, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870480000972748
Epoch 0, Step 320: train/loss = 0.540880560874939, train/raw-loss = 0.49080729484558105, train/logprobs = tensor([[-0.7793, -2.5104],
        [-0.6618, -0.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08345538377761841
Epoch 0, Step 321: train/loss = 0.567304790019989, train/raw-loss = 0.5211363434791565, train/logprobs = tensor([[-0.6154, -1.6687],
        [-0.5963, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0769473984837532
Epoch 0, Step 322: train/loss = 0.47885459661483765, train/raw-loss = 0.42919662594795227, train/logprobs = tensor([[-1.0176, -3.9166],
        [-0.8903, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276331424713135
Epoch 0, Step 323: train/loss = 0.5241923928260803, train/raw-loss = 0.47738954424858093, train/logprobs = tensor([[-0.4033, -2.2113],
        [-0.4317, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07800464332103729
Epoch 0, Step 324: train/loss = 0.3977183699607849, train/raw-loss = 0.34058496356010437, train/logprobs = tensor([[-0.7727, -5.0990],
        [-0.6590, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952223539352417
Epoch 0, Step 325: train/loss = 0.643224835395813, train/raw-loss = 0.5959961414337158, train/logprobs = tensor([[-0.5905, -1.0980],
        [-0.5602, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07871460914611816
Epoch 0, Step 326: train/loss = 0.4465603828430176, train/raw-loss = 0.3919622302055359, train/logprobs = tensor([[-0.8955, -4.7094],
        [-1.0164, -1.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09099695086479187
Epoch 0, Step 327: train/loss = 0.732709527015686, train/raw-loss = 0.6786731481552124, train/logprobs = tensor([[-0.8295, -1.0432],
        [-0.6259, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006061404943466
Epoch 0, Step 328: train/loss = 0.633104145526886, train/raw-loss = 0.5887693166732788, train/logprobs = tensor([[-0.8203, -1.6629],
        [-0.7947, -0.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07389135658740997
Epoch 0, Step 329: train/loss = 0.6289031505584717, train/raw-loss = 0.5735908150672913, train/logprobs = tensor([[-1.0631, -1.5251],
        [-0.8559, -0.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09218721091747284
Epoch 0, Step 330: train/loss = 0.3789047300815582, train/raw-loss = 0.3260430097579956, train/logprobs = tensor([[-0.6627, -4.1482],
        [-0.6455, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08810293674468994
Epoch 0, Step 331: train/loss = 0.5003066062927246, train/raw-loss = 0.45453840494155884, train/logprobs = tensor([[-0.6156, -3.8616],
        [-0.6053, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07628032565116882
Epoch 0, Step 332: train/loss = 0.4501356780529022, train/raw-loss = 0.3953874111175537, train/logprobs = tensor([[-0.7669, -3.4533],
        [-0.8829, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0912470817565918
Epoch 0, Step 333: train/loss = 0.5365535020828247, train/raw-loss = 0.48367905616760254, train/logprobs = tensor([[-0.7422, -2.7510],
        [-0.6029, -1.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881240963935852
Epoch 0, Step 334: train/loss = 0.6614335775375366, train/raw-loss = 0.6168822646141052, train/logprobs = tensor([[-0.7238, -0.9059],
        [-0.6350, -0.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0742521733045578
Epoch 0, Step 335: train/loss = 0.480890154838562, train/raw-loss = 0.43088042736053467, train/logprobs = tensor([[-0.6272, -2.2218],
        [-0.5599, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833495631814003
Epoch 0, Step 336: train/loss = 0.5549120306968689, train/raw-loss = 0.5044604539871216, train/logprobs = tensor([[-0.5402, -1.6375],
        [-0.5990, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08408589661121368
Epoch 0, Step 337: train/loss = 0.5398747324943542, train/raw-loss = 0.4855140745639801, train/logprobs = tensor([[-0.8461, -2.0393],
        [-0.8454, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09060105681419373
Epoch 0, Step 338: train/loss = 0.5499211549758911, train/raw-loss = 0.49994993209838867, train/logprobs = tensor([[-0.5430, -1.5801],
        [-0.5587, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08328530937433243
Epoch 0, Step 339: train/loss = 0.49329519271850586, train/raw-loss = 0.4440619647502899, train/logprobs = tensor([[-0.3674, -4.0422],
        [-0.3946, -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08205540478229523
Epoch 0, Step 340: train/loss = 0.6195923089981079, train/raw-loss = 0.5730859041213989, train/logprobs = tensor([[-0.7515, -1.3090],
        [-0.7158, -0.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07751065492630005
Epoch 0, Step 341: train/loss = 0.4231143593788147, train/raw-loss = 0.3705260753631592, train/logprobs = tensor([[-0.5959, -3.0457],
        [-0.6725, -0.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08764716237783432
Epoch 0, Step 342: train/loss = 0.5233554840087891, train/raw-loss = 0.47741660475730896, train/logprobs = tensor([[-0.5483, -2.5759],
        [-0.6065, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0765647143125534
Epoch 0, Step 343: train/loss = 0.6090105772018433, train/raw-loss = 0.563402533531189, train/logprobs = tensor([[-0.6469, -2.0086],
        [-0.6673, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07601332664489746
Epoch 0, Step 344: train/loss = 0.44397664070129395, train/raw-loss = 0.39084285497665405, train/logprobs = tensor([[-0.8907, -5.2754],
        [-0.7986, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08855625987052917
Epoch 0, Step 345: train/loss = 0.5017789602279663, train/raw-loss = 0.45299044251441956, train/logprobs = tensor([[-1.0831, -3.6005],
        [-1.1163, -0.9101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08131414651870728
Epoch 0, Step 346: train/loss = 0.5297495722770691, train/raw-loss = 0.47638896107673645, train/logprobs = tensor([[-0.7653, -3.6180],
        [-0.7209, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08893429487943649
Epoch 0, Step 347: train/loss = 0.532740592956543, train/raw-loss = 0.48241543769836426, train/logprobs = tensor([[-0.5977, -4.1812],
        [-0.6321, -1.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387523889541626
Epoch 0, Step 348: train/loss = 0.550697386264801, train/raw-loss = 0.5079043507575989, train/logprobs = tensor([[-0.7189, -2.9172],
        [-0.7767, -0.9634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07132173329591751
Epoch 0, Step 349: train/loss = 0.4389804005622864, train/raw-loss = 0.38403427600860596, train/logprobs = tensor([[-0.6760, -2.6729],
        [-0.7317, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157689660787582
Epoch 0, Step 350: train/loss = 0.6239312887191772, train/raw-loss = 0.5669640302658081, train/logprobs = tensor([[-1.1778, -2.3851],
        [-0.9813, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09494528919458389
Epoch 0, Step 351: train/loss = 0.5518744587898254, train/raw-loss = 0.49909329414367676, train/logprobs = tensor([[-0.7179, -2.3766],
        [-0.7145, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08796857297420502
Epoch 0, Step 352: train/loss = 0.4841751456260681, train/raw-loss = 0.4346889853477478, train/logprobs = tensor([[-0.5066, -3.3983],
        [-0.5928, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0824769139289856
Epoch 0, Step 353: train/loss = 0.4223434627056122, train/raw-loss = 0.3707078695297241, train/logprobs = tensor([[-0.7041, -4.2293],
        [-0.8315, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605928719043732
Epoch 0, Step 354: train/loss = 0.6461760997772217, train/raw-loss = 0.6032846570014954, train/logprobs = tensor([[-0.4812, -0.9493],
        [-0.5064, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07148569077253342
Epoch 0, Step 355: train/loss = 0.5285906791687012, train/raw-loss = 0.48105335235595703, train/logprobs = tensor([[-0.7111, -2.4775],
        [-0.7821, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07922887802124023
Epoch 0, Step 356: train/loss = 0.6353421807289124, train/raw-loss = 0.5872200131416321, train/logprobs = tensor([[-0.5019, -1.0651],
        [-0.4882, -0.4964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08020366728305817
Epoch 0, Step 357: train/loss = 0.6763381958007812, train/raw-loss = 0.6247023344039917, train/logprobs = tensor([[-1.7376, -2.3545],
        [-1.3472, -1.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605984598398209
Epoch 0, Step 358: train/loss = 0.5456162691116333, train/raw-loss = 0.5038323998451233, train/logprobs = tensor([[-0.5158, -3.7889],
        [-0.4923, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06963971257209778
Epoch 0, Step 359: train/loss = 0.5963648557662964, train/raw-loss = 0.5454325675964355, train/logprobs = tensor([[-0.8820, -1.7917],
        [-0.8375, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08488709479570389
Epoch 0, Step 360: train/loss = 0.5564011931419373, train/raw-loss = 0.5049759149551392, train/logprobs = tensor([[-0.8724, -2.4482],
        [-0.8162, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0857088714838028
Epoch 0, Step 361: train/loss = 0.587626576423645, train/raw-loss = 0.5345262289047241, train/logprobs = tensor([[-0.5972, -1.1643],
        [-0.6820, -0.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08850056678056717
Epoch 0, Step 362: train/loss = 0.6132967472076416, train/raw-loss = 0.5706869959831238, train/logprobs = tensor([[-0.6567, -1.6490],
        [-0.6529, -0.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07101626694202423
Epoch 0, Step 363: train/loss = 0.751598060131073, train/raw-loss = 0.7111814618110657, train/logprobs = tensor([[-1.2217, -1.1181],
        [-0.8626, -0.7491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06736104935407639
Epoch 0, Step 364: train/loss = 0.4236619472503662, train/raw-loss = 0.3776226341724396, train/logprobs = tensor([[-0.4012, -5.1048],
        [-0.5281, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07673225551843643
Epoch 0, Step 365: train/loss = 0.4728280305862427, train/raw-loss = 0.4228935241699219, train/logprobs = tensor([[-0.5344, -2.4000],
        [-0.5790, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08322417736053467
Epoch 0, Step 366: train/loss = 0.5545896291732788, train/raw-loss = 0.5062799453735352, train/logprobs = tensor([[-0.5788, -2.4099],
        [-0.5925, -0.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08051615208387375
Epoch 0, Step 367: train/loss = 0.4586837887763977, train/raw-loss = 0.4115374982357025, train/logprobs = tensor([[-0.5660, -3.1133],
        [-0.6745, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07857714593410492
Epoch 0, Step 368: train/loss = 0.5079588890075684, train/raw-loss = 0.4598710834980011, train/logprobs = tensor([[-0.4224, -2.2533],
        [-0.4278, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08014636486768723
Epoch 0, Step 369: train/loss = 0.5200954675674438, train/raw-loss = 0.4756089746952057, train/logprobs = tensor([[-0.4479, -1.8383],
        [-0.5218, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414411753416061
Epoch 0, Step 370: train/loss = 0.6551129817962646, train/raw-loss = 0.6147691011428833, train/logprobs = tensor([[-0.3941, -0.8277],
        [-0.4063, -0.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06723976135253906
Epoch 0, Step 371: train/loss = 0.5208066701889038, train/raw-loss = 0.4771384000778198, train/logprobs = tensor([[-0.4205, -2.8633],
        [-0.4531, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07278037816286087
Epoch 0, Step 372: train/loss = 0.4716227650642395, train/raw-loss = 0.42386573553085327, train/logprobs = tensor([[-0.5636, -2.9362],
        [-0.5340, -0.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07959505915641785
Epoch 0, Step 373: train/loss = 0.5490696430206299, train/raw-loss = 0.5010675191879272, train/logprobs = tensor([[-0.7435, -4.1422],
        [-0.6804, -1.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08000343292951584
Epoch 0, Step 374: train/loss = 0.5527948141098022, train/raw-loss = 0.505885124206543, train/logprobs = tensor([[-0.3145, -2.1207],
        [-0.3488, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07818286120891571
Epoch 0, Step 375: train/loss = 0.5279859900474548, train/raw-loss = 0.47490429878234863, train/logprobs = tensor([[-0.7255, -1.5760],
        [-0.9147, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08846946805715561
Epoch 0, Step 376: train/loss = 0.45017534494400024, train/raw-loss = 0.3974674642086029, train/logprobs = tensor([[-0.6174, -4.2223],
        [-0.7989, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08784650266170502
Epoch 0, Step 377: train/loss = 0.5922443866729736, train/raw-loss = 0.5427401661872864, train/logprobs = tensor([[-0.6403, -2.4167],
        [-0.5706, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08250705897808075
Epoch 0, Step 378: train/loss = 0.559570848941803, train/raw-loss = 0.5139621496200562, train/logprobs = tensor([[-0.7010, -3.3318],
        [-0.6800, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07601448148488998
Epoch 0, Step 379: train/loss = 0.6181413531303406, train/raw-loss = 0.5762990713119507, train/logprobs = tensor([[-0.9467, -1.9816],
        [-0.8135, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06973709166049957
Epoch 0, Step 380: train/loss = 0.5456969738006592, train/raw-loss = 0.49764469265937805, train/logprobs = tensor([[-0.6021, -1.7353],
        [-0.6379, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008717000484467
Epoch 0, Step 381: train/loss = 0.4677874445915222, train/raw-loss = 0.4154699444770813, train/logprobs = tensor([[-0.6696, -3.7790],
        [-0.8511, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08719582855701447
Epoch 0, Step 382: train/loss = 0.4247703552246094, train/raw-loss = 0.37552911043167114, train/logprobs = tensor([[-0.5471, -3.3186],
        [-0.5832, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206868171691895
Epoch 0, Step 383: train/loss = 0.467782199382782, train/raw-loss = 0.41307371854782104, train/logprobs = tensor([[-0.4632, -2.3382],
        [-0.6038, -0.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09118086099624634
Epoch 0, Step 384: train/loss = 0.5233071446418762, train/raw-loss = 0.467064768075943, train/logprobs = tensor([[-0.8065, -5.4387],
        [-0.8763, -1.1648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09373725205659866
Epoch 0, Step 385: train/loss = 0.6116585731506348, train/raw-loss = 0.5474623441696167, train/logprobs = tensor([[-1.1209, -1.9220],
        [-0.9638, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699371248483658
Epoch 0, Step 386: train/loss = 0.7397351264953613, train/raw-loss = 0.6962699294090271, train/logprobs = tensor([[-0.8756, -0.8118],
        [-0.6436, -0.5364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07244197279214859
Epoch 0, Step 387: train/loss = 0.5089969038963318, train/raw-loss = 0.45484602451324463, train/logprobs = tensor([[-0.6334, -4.4367],
        [-0.8135, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025147557258606
Epoch 0, Step 388: train/loss = 0.5681183934211731, train/raw-loss = 0.5048133730888367, train/logprobs = tensor([[-0.7016, -2.1140],
        [-0.7566, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10550836473703384
Epoch 0, Step 389: train/loss = 0.486398309469223, train/raw-loss = 0.42289191484451294, train/logprobs = tensor([[-0.5778, -2.2501],
        [-0.6541, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10584402084350586
Epoch 0, Step 390: train/loss = 0.4769561290740967, train/raw-loss = 0.4162590503692627, train/logprobs = tensor([[-0.9986, -2.5685],
        [-1.2763, -1.1626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10116180777549744
Epoch 0, Step 391: train/loss = 0.5574120879173279, train/raw-loss = 0.5055316090583801, train/logprobs = tensor([[-0.4849, -1.7374],
        [-0.4994, -0.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646750450134277
Epoch 0, Step 392: train/loss = 0.47073161602020264, train/raw-loss = 0.42021623253822327, train/logprobs = tensor([[-0.4768, -3.1380],
        [-0.6320, -0.8578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08419227600097656
Epoch 0, Step 393: train/loss = 0.5798512697219849, train/raw-loss = 0.5201565623283386, train/logprobs = tensor([[-0.7024, -1.7577],
        [-0.6117, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09949129819869995
Epoch 0, Step 394: train/loss = 0.4365818500518799, train/raw-loss = 0.38075751066207886, train/logprobs = tensor([[-0.8194, -5.8756],
        [-0.8212, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0930405706167221
Epoch 0, Step 395: train/loss = 0.5138857364654541, train/raw-loss = 0.46781063079833984, train/logprobs = tensor([[-0.6712, -5.3114],
        [-0.4497, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07679182291030884
Epoch 0, Step 396: train/loss = 0.5537887215614319, train/raw-loss = 0.5016175508499146, train/logprobs = tensor([[-0.7236, -1.8755],
        [-0.7326, -0.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08695204555988312
Epoch 0, Step 397: train/loss = 0.582667350769043, train/raw-loss = 0.530109703540802, train/logprobs = tensor([[-0.4772, -2.0478],
        [-0.4514, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08759606629610062
Epoch 0, Step 398: train/loss = 0.43293750286102295, train/raw-loss = 0.37554892897605896, train/logprobs = tensor([[-0.5819, -3.2636],
        [-0.6820, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564756602048874
Epoch 0, Step 399: train/loss = 0.5936346650123596, train/raw-loss = 0.5385792255401611, train/logprobs = tensor([[-0.7869, -1.3882],
        [-0.9244, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09175898879766464
Epoch 0, Step 400: train/loss = 0.5901500582695007, train/raw-loss = 0.5455323457717896, train/logprobs = tensor([[-0.5205, -1.2775],
        [-0.5547, -0.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07436282932758331
Epoch 0, Step 401: train/loss = 0.44859278202056885, train/raw-loss = 0.3982240557670593, train/logprobs = tensor([[-0.7765, -3.3929],
        [-0.8071, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08394792675971985
Epoch 0, Step 402: train/loss = 0.4679979979991913, train/raw-loss = 0.4115886688232422, train/logprobs = tensor([[-0.6909, -3.1888],
        [-0.6766, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401558339595795
Epoch 0, Step 403: train/loss = 0.5551950335502625, train/raw-loss = 0.5150914788246155, train/logprobs = tensor([[-0.3253, -1.6301],
        [-0.3595, -0.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06683918833732605
Epoch 0, Step 404: train/loss = 0.6506121158599854, train/raw-loss = 0.6051806211471558, train/logprobs = tensor([[-0.5740, -1.2341],
        [-0.4956, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07571917772293091
Epoch 0, Step 405: train/loss = 0.5788018703460693, train/raw-loss = 0.5340434312820435, train/logprobs = tensor([[-0.4593, -3.0980],
        [-0.5176, -0.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0745973140001297
Epoch 0, Step 406: train/loss = 0.5494016408920288, train/raw-loss = 0.4980517625808716, train/logprobs = tensor([[-0.5632, -2.1307],
        [-0.5797, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08558303862810135
Epoch 0, Step 407: train/loss = 0.6143912076950073, train/raw-loss = 0.5747053623199463, train/logprobs = tensor([[-0.5124, -1.0539],
        [-0.5072, -0.4522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06614306569099426
Epoch 0, Step 408: train/loss = 0.6102741360664368, train/raw-loss = 0.5558167695999146, train/logprobs = tensor([[-0.6013, -1.1505],
        [-0.8089, -0.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09076227247714996
Epoch 0, Step 409: train/loss = 0.3490419089794159, train/raw-loss = 0.28888726234436035, train/logprobs = tensor([[-0.8528, -4.6602],
        [-1.1530, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1002577692270279
Epoch 0, Step 410: train/loss = 0.6016011238098145, train/raw-loss = 0.5508763194084167, train/logprobs = tensor([[-0.5773, -2.0256],
        [-0.5285, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08454128354787827
Epoch 0, Step 411: train/loss = 0.5691909790039062, train/raw-loss = 0.5078503489494324, train/logprobs = tensor([[-0.4944, -1.4687],
        [-0.5618, -0.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10223431885242462
Epoch 0, Step 412: train/loss = 0.6086448431015015, train/raw-loss = 0.5590589642524719, train/logprobs = tensor([[-0.4654, -1.3580],
        [-0.5559, -0.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0826430693268776
Epoch 0, Step 413: train/loss = 0.5747870206832886, train/raw-loss = 0.5294135212898254, train/logprobs = tensor([[-0.7435, -3.9184],
        [-0.6229, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562253624200821
Epoch 0, Step 414: train/loss = 0.521547794342041, train/raw-loss = 0.4747294783592224, train/logprobs = tensor([[-0.4239, -1.6510],
        [-0.5416, -0.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.078030526638031
Epoch 0, Step 415: train/loss = 0.495362788438797, train/raw-loss = 0.4437011182308197, train/logprobs = tensor([[-0.7580, -3.8908],
        [-0.7609, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610275387763977
Epoch 0, Step 416: train/loss = 0.6347848176956177, train/raw-loss = 0.582130491733551, train/logprobs = tensor([[-0.7055, -1.3255],
        [-0.6647, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08775728940963745
Epoch 0, Step 417: train/loss = 0.461505264043808, train/raw-loss = 0.3988897204399109, train/logprobs = tensor([[-0.5938, -3.6957],
        [-0.8781, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10435924679040909
Epoch 0, Step 418: train/loss = 0.44285550713539124, train/raw-loss = 0.3875610828399658, train/logprobs = tensor([[-0.6051, -2.4639],
        [-0.8851, -0.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09215734899044037
Epoch 0, Step 419: train/loss = 0.477347195148468, train/raw-loss = 0.42085000872612, train/logprobs = tensor([[-0.8511, -3.2398],
        [-0.8750, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0941619724035263
Epoch 0, Step 420: train/loss = 0.513622522354126, train/raw-loss = 0.4552723169326782, train/logprobs = tensor([[-0.7045, -2.8558],
        [-0.8231, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09725041687488556
Epoch 0, Step 421: train/loss = 0.4536222219467163, train/raw-loss = 0.393692284822464, train/logprobs = tensor([[-0.6743, -2.2262],
        [-0.9705, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988319128751755
Epoch 0, Step 422: train/loss = 0.4425494372844696, train/raw-loss = 0.37859755754470825, train/logprobs = tensor([[-0.9666, -3.9561],
        [-0.9818, -1.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658646374940872
Epoch 0, Step 423: train/loss = 0.5469259023666382, train/raw-loss = 0.49263834953308105, train/logprobs = tensor([[-0.5739, -2.9644],
        [-0.5567, -0.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09047923237085342
Epoch 0, Step 424: train/loss = 0.41438373923301697, train/raw-loss = 0.3597126603126526, train/logprobs = tensor([[-0.5886, -4.1514],
        [-0.7371, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111849963665009
Epoch 0, Step 425: train/loss = 0.8749211430549622, train/raw-loss = 0.827544093132019, train/logprobs = tensor([[-1.9283, -2.9115],
        [-0.6304, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07896177470684052
Epoch 0, Step 426: train/loss = 0.4901537597179413, train/raw-loss = 0.42439955472946167, train/logprobs = tensor([[-0.8412, -2.3889],
        [-0.9764, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10959035903215408
Epoch 0, Step 427: train/loss = 0.4378913640975952, train/raw-loss = 0.38520264625549316, train/logprobs = tensor([[-0.5769, -2.6991],
        [-0.6520, -0.5034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08781450986862183
Epoch 0, Step 428: train/loss = 0.7280963659286499, train/raw-loss = 0.673149049282074, train/logprobs = tensor([[-0.8919, -1.0728],
        [-0.6103, -0.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157882630825043
Epoch 0, Step 429: train/loss = 0.4237286448478699, train/raw-loss = 0.3737526535987854, train/logprobs = tensor([[-0.5885, -2.9846],
        [-0.7054, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08329340815544128
Epoch 0, Step 430: train/loss = 0.5468147397041321, train/raw-loss = 0.4980360269546509, train/logprobs = tensor([[-0.6291, -3.0004],
        [-0.6122, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129781484603882
Epoch 0, Step 431: train/loss = 0.5282080769538879, train/raw-loss = 0.47427767515182495, train/logprobs = tensor([[-0.6872, -1.4954],
        [-0.7831, -0.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0898839682340622
Epoch 0, Step 432: train/loss = 0.6168935298919678, train/raw-loss = 0.5563435554504395, train/logprobs = tensor([[-0.7172, -1.1547],
        [-0.8385, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10091658681631088
Epoch 0, Step 433: train/loss = 0.5820319652557373, train/raw-loss = 0.5327585339546204, train/logprobs = tensor([[-0.6091, -1.4926],
        [-0.6861, -0.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08212237060070038
Epoch 0, Step 434: train/loss = 0.4001399874687195, train/raw-loss = 0.3314964175224304, train/logprobs = tensor([[-0.7511, -4.1124],
        [-0.8005, -0.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11440593004226685
Epoch 0, Step 435: train/loss = 0.578772783279419, train/raw-loss = 0.5105087757110596, train/logprobs = tensor([[-1.3054, -2.6265],
        [-0.8897, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137734055519104
Epoch 0, Step 436: train/loss = 0.46908360719680786, train/raw-loss = 0.4057752788066864, train/logprobs = tensor([[-0.7943, -3.9514],
        [-1.0145, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551383346319199
Epoch 0, Step 437: train/loss = 0.4824100136756897, train/raw-loss = 0.42269158363342285, train/logprobs = tensor([[-0.6707, -3.2978],
        [-0.7532, -0.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09953072667121887
Epoch 0, Step 438: train/loss = 0.5187702178955078, train/raw-loss = 0.46352916955947876, train/logprobs = tensor([[-0.5018, -2.3076],
        [-0.6038, -0.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0920683890581131
Epoch 0, Step 439: train/loss = 0.5990312695503235, train/raw-loss = 0.5506683588027954, train/logprobs = tensor([[-0.4757, -1.1550],
        [-0.5622, -0.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08060494065284729
Epoch 0, Step 440: train/loss = 0.5982422828674316, train/raw-loss = 0.5432515144348145, train/logprobs = tensor([[-0.7449, -1.6323],
        [-0.6287, -0.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916513204574585
Epoch 0, Step 441: train/loss = 0.6890590786933899, train/raw-loss = 0.6373686194419861, train/logprobs = tensor([[-0.9969, -1.5244],
        [-0.6392, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08615075051784515
Epoch 0, Step 442: train/loss = 0.6460500359535217, train/raw-loss = 0.5895293951034546, train/logprobs = tensor([[-0.5035, -1.0034],
        [-0.5292, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09420110285282135
Epoch 0, Step 443: train/loss = 0.7558104991912842, train/raw-loss = 0.7038323879241943, train/logprobs = tensor([[-1.5004, -1.3029],
        [-0.9076, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08663018047809601
Epoch 0, Step 444: train/loss = 0.5146816372871399, train/raw-loss = 0.44809433817863464, train/logprobs = tensor([[-0.8657, -2.4102],
        [-0.6767, -0.6756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11097882688045502
Epoch 0, Step 445: train/loss = 0.4638534486293793, train/raw-loss = 0.40010905265808105, train/logprobs = tensor([[-0.5719, -2.8224],
        [-0.7378, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10624063014984131
Epoch 0, Step 446: train/loss = 0.5536755323410034, train/raw-loss = 0.4998205006122589, train/logprobs = tensor([[-0.8539, -2.0717],
        [-0.7611, -0.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08975841104984283
Epoch 0, Step 447: train/loss = 0.41486644744873047, train/raw-loss = 0.35186767578125, train/logprobs = tensor([[-0.8997, -5.5184],
        [-0.7933, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049978956580162
Epoch 0, Step 448: train/loss = 0.42237916588783264, train/raw-loss = 0.3606307804584503, train/logprobs = tensor([[-0.6002, -5.1138],
        [-0.7494, -1.2909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10291397571563721
Epoch 0, Step 449: train/loss = 0.6308258175849915, train/raw-loss = 0.5766595602035522, train/logprobs = tensor([[-0.7515, -1.7394],
        [-0.7474, -0.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902770534157753
Epoch 0, Step 450: train/loss = 0.6245303750038147, train/raw-loss = 0.561797022819519, train/logprobs = tensor([[-0.9676, -1.7881],
        [-1.0374, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045556589961052
Epoch 0, Step 451: train/loss = 0.5797621607780457, train/raw-loss = 0.5206303596496582, train/logprobs = tensor([[-0.7671, -1.5172],
        [-0.8027, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855298697948456
Epoch 0, Step 452: train/loss = 0.38834547996520996, train/raw-loss = 0.326509952545166, train/logprobs = tensor([[-0.7003, -6.0403],
        [-0.9780, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10305923223495483
Epoch 0, Step 453: train/loss = 0.39331796765327454, train/raw-loss = 0.3403145968914032, train/logprobs = tensor([[-0.6195, -4.3258],
        [-0.8335, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08833900839090347
Epoch 0, Step 454: train/loss = 0.5725454092025757, train/raw-loss = 0.5271591544151306, train/logprobs = tensor([[-0.3867, -2.4524],
        [-0.4557, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07564377039670944
Epoch 0, Step 455: train/loss = 0.41282424330711365, train/raw-loss = 0.35753580927848816, train/logprobs = tensor([[-0.6168, -3.4116],
        [-0.8260, -0.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09214740991592407
Epoch 0, Step 456: train/loss = 0.6613941788673401, train/raw-loss = 0.596649169921875, train/logprobs = tensor([[-0.7839, -1.2754],
        [-0.8312, -0.8409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10790837556123734
Epoch 0, Step 457: train/loss = 0.4579824209213257, train/raw-loss = 0.3922196626663208, train/logprobs = tensor([[-0.5372, -2.5407],
        [-0.8263, -0.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10960458219051361
Epoch 0, Step 458: train/loss = 0.42257988452911377, train/raw-loss = 0.36066558957099915, train/logprobs = tensor([[-0.5483, -4.3565],
        [-0.7666, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10319048911333084
Epoch 0, Step 459: train/loss = 0.46216511726379395, train/raw-loss = 0.3983045816421509, train/logprobs = tensor([[-0.6785, -2.6537],
        [-0.7938, -0.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10643414407968521
Epoch 0, Step 460: train/loss = 0.5041768550872803, train/raw-loss = 0.44330087304115295, train/logprobs = tensor([[-0.7057, -3.0145],
        [-0.7898, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10146000981330872
Epoch 0, Step 461: train/loss = 0.49965065717697144, train/raw-loss = 0.4389744997024536, train/logprobs = tensor([[-0.9317, -2.8135],
        [-0.9015, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10112689435482025
Epoch 0, Step 462: train/loss = 0.5500178337097168, train/raw-loss = 0.48677173256874084, train/logprobs = tensor([[-0.8006, -1.7064],
        [-0.9109, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10541017353534698
Epoch 0, Step 463: train/loss = 0.5252184867858887, train/raw-loss = 0.4664623439311981, train/logprobs = tensor([[-0.8082, -1.9084],
        [-1.0059, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09792688488960266
Epoch 0, Step 464: train/loss = 0.40564966201782227, train/raw-loss = 0.3408907651901245, train/logprobs = tensor([[-0.5133, -4.0167],
        [-0.8367, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10793150961399078
Epoch 0, Step 465: train/loss = 0.5623295903205872, train/raw-loss = 0.5023066997528076, train/logprobs = tensor([[-0.5834, -1.4434],
        [-0.8595, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10003820806741714
Epoch 0, Step 466: train/loss = 0.6085737943649292, train/raw-loss = 0.5507731437683105, train/logprobs = tensor([[-0.9195, -2.4253],
        [-0.9369, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09633440524339676
Epoch 0, Step 467: train/loss = 0.5461134314537048, train/raw-loss = 0.49129050970077515, train/logprobs = tensor([[-0.8170, -2.2590],
        [-0.7249, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09137161076068878
Epoch 0, Step 468: train/loss = 0.3455949127674103, train/raw-loss = 0.2691187560558319, train/logprobs = tensor([[-0.6731, -3.4653],
        [-1.1790, -0.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12746025621891022
Epoch 0, Step 469: train/loss = 0.5915770530700684, train/raw-loss = 0.539836585521698, train/logprobs = tensor([[-0.5435, -1.5033],
        [-0.8064, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08623414486646652
Epoch 0, Step 470: train/loss = 0.6153199672698975, train/raw-loss = 0.5482612252235413, train/logprobs = tensor([[-0.8353, -2.1559],
        [-0.6009, -0.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176452785730362
Epoch 0, Step 471: train/loss = 0.3720710575580597, train/raw-loss = 0.3103102445602417, train/logprobs = tensor([[-0.4485, -4.1164],
        [-0.6445, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293465852737427
Epoch 0, Step 472: train/loss = 0.5300996899604797, train/raw-loss = 0.4725579619407654, train/logprobs = tensor([[-0.4792, -3.2024],
        [-0.6247, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590288996696472
Epoch 0, Step 473: train/loss = 0.4732900857925415, train/raw-loss = 0.4097192883491516, train/logprobs = tensor([[-1.0038, -4.5373],
        [-0.8258, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595142096281052
Epoch 0, Step 474: train/loss = 0.49510660767555237, train/raw-loss = 0.4412578046321869, train/logprobs = tensor([[-0.5662, -2.5882],
        [-0.7323, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08974798768758774
Epoch 0, Step 475: train/loss = 0.39847052097320557, train/raw-loss = 0.3307286202907562, train/logprobs = tensor([[-0.6732, -4.2154],
        [-0.7748, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11290313303470612
Epoch 0, Step 476: train/loss = 0.553324818611145, train/raw-loss = 0.4916495978832245, train/logprobs = tensor([[-0.4435, -1.6379],
        [-0.4645, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10279210656881332
Epoch 0, Step 477: train/loss = 0.4619944393634796, train/raw-loss = 0.388342022895813, train/logprobs = tensor([[-0.5695, -3.5754],
        [-0.6404, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12275395542383194
Epoch 0, Step 478: train/loss = 0.39375489950180054, train/raw-loss = 0.33175116777420044, train/logprobs = tensor([[-0.7379, -5.4202],
        [-0.7741, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10333950817584991
Epoch 0, Step 479: train/loss = 0.5317230820655823, train/raw-loss = 0.4826723337173462, train/logprobs = tensor([[-0.3593, -3.7783],
        [-0.5093, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08175128698348999
Epoch 0, Step 480: train/loss = 0.6726153492927551, train/raw-loss = 0.6226317286491394, train/logprobs = tensor([[-0.4565, -1.0150],
        [-0.5278, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08330602943897247
Epoch 0, Step 481: train/loss = 0.34424957633018494, train/raw-loss = 0.265693336725235, train/logprobs = tensor([[-0.8429, -5.2746],
        [-1.1059, -1.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13092705607414246
Epoch 0, Step 482: train/loss = 0.5583454370498657, train/raw-loss = 0.5026237368583679, train/logprobs = tensor([[-0.7646, -1.4486],
        [-0.9536, -0.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09286949038505554
Epoch 0, Step 483: train/loss = 0.507128894329071, train/raw-loss = 0.44864940643310547, train/logprobs = tensor([[-0.5447, -3.3193],
        [-0.7475, -0.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09746577590703964
Epoch 0, Step 484: train/loss = 0.5255614519119263, train/raw-loss = 0.4538024663925171, train/logprobs = tensor([[-0.5520, -2.3143],
        [-0.7094, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11959834396839142
Epoch 0, Step 485: train/loss = 0.3477197289466858, train/raw-loss = 0.2734735608100891, train/logprobs = tensor([[-0.9500, -6.0823],
        [-1.3536, -1.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12374362349510193
Epoch 0, Step 486: train/loss = 0.6438490748405457, train/raw-loss = 0.5863141417503357, train/logprobs = tensor([[-0.5197, -1.0805],
        [-0.6492, -0.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09589157998561859
Epoch 0, Step 487: train/loss = 0.504806399345398, train/raw-loss = 0.44374820590019226, train/logprobs = tensor([[-0.8439, -2.9641],
        [-0.9522, -0.5937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176361352205276
Epoch 0, Step 488: train/loss = 0.500159502029419, train/raw-loss = 0.43734604120254517, train/logprobs = tensor([[-0.5885, -4.4211],
        [-0.6813, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468903183937073
Epoch 0, Step 489: train/loss = 0.4484293460845947, train/raw-loss = 0.37718111276626587, train/logprobs = tensor([[-0.5390, -5.8529],
        [-0.9926, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11874701827764511
Epoch 0, Step 490: train/loss = 0.5751508474349976, train/raw-loss = 0.502142071723938, train/logprobs = tensor([[-0.5296, -1.4904],
        [-0.7135, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168125808238983
Epoch 0, Step 491: train/loss = 0.4775875210762024, train/raw-loss = 0.40457648038864136, train/logprobs = tensor([[-0.8663, -4.3240],
        [-1.2777, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168507277965546
Epoch 0, Step 492: train/loss = 0.4576910436153412, train/raw-loss = 0.3881297707557678, train/logprobs = tensor([[-0.8127, -4.2671],
        [-1.1563, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11593547463417053
Epoch 0, Step 493: train/loss = 0.6307482719421387, train/raw-loss = 0.5722722411155701, train/logprobs = tensor([[-0.4075, -1.3793],
        [-0.4364, -0.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09746003895998001
Epoch 0, Step 494: train/loss = 0.5181124806404114, train/raw-loss = 0.4448752999305725, train/logprobs = tensor([[-0.8052, -1.8441],
        [-1.1836, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206192314624786
Epoch 0, Step 495: train/loss = 0.4886656701564789, train/raw-loss = 0.4247049391269684, train/logprobs = tensor([[-0.4790, -3.8228],
        [-0.7189, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10660122334957123
Epoch 0, Step 496: train/loss = 0.5145262479782104, train/raw-loss = 0.4456422030925751, train/logprobs = tensor([[-0.5938, -2.9365],
        [-0.6520, -1.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11480680853128433
Epoch 0, Step 497: train/loss = 0.5473825931549072, train/raw-loss = 0.49480199813842773, train/logprobs = tensor([[-0.4675, -1.3521],
        [-0.6406, -0.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08763437718153
Epoch 0, Step 498: train/loss = 0.40911343693733215, train/raw-loss = 0.33180856704711914, train/logprobs = tensor([[-0.6243, -2.6134],
        [-0.9053, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12884150445461273
Epoch 0, Step 499: train/loss = 0.47384408116340637, train/raw-loss = 0.40799951553344727, train/logprobs = tensor([[-0.6192, -3.6470],
        [-0.8659, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10974093526601791
Epoch 0, Step 500: train/loss = 0.5698034763336182, train/raw-loss = 0.5089748501777649, train/logprobs = tensor([[-0.6372, -2.4946],
        [-0.8326, -0.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138110816478729
Epoch 0, Step 501: train/loss = 0.4891895055770874, train/raw-loss = 0.42179641127586365, train/logprobs = tensor([[-0.7303, -4.3598],
        [-0.7019, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232176423072815
Epoch 0, Step 502: train/loss = 0.392483651638031, train/raw-loss = 0.32306864857673645, train/logprobs = tensor([[-0.5452, -2.4205],
        [-1.0580, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569169163703918
Epoch 0, Step 503: train/loss = 0.6871508359909058, train/raw-loss = 0.6358084678649902, train/logprobs = tensor([[-0.6107, -1.0440],
        [-0.5250, -0.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08557072281837463
Epoch 0, Step 504: train/loss = 0.46994754672050476, train/raw-loss = 0.4090394079685211, train/logprobs = tensor([[-0.4732, -3.2661],
        [-0.6007, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10151351243257523
Epoch 0, Step 505: train/loss = 0.4301305413246155, train/raw-loss = 0.36276549100875854, train/logprobs = tensor([[-0.5827, -6.0679],
        [-0.9592, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227510124444962
Epoch 0, Step 506: train/loss = 0.5962556600570679, train/raw-loss = 0.5376242399215698, train/logprobs = tensor([[-0.6005, -1.5208],
        [-0.6606, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09771905839443207
Epoch 0, Step 507: train/loss = 0.5482469201087952, train/raw-loss = 0.4771078824996948, train/logprobs = tensor([[-0.8865, -5.4391],
        [-0.8683, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11856508255004883
Epoch 0, Step 508: train/loss = 0.5353729128837585, train/raw-loss = 0.47313204407691956, train/logprobs = tensor([[-0.6141, -1.9662],
        [-0.7933, -0.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1037348285317421
Epoch 0, Step 509: train/loss = 0.5949355959892273, train/raw-loss = 0.5309630632400513, train/logprobs = tensor([[-0.6615, -1.6473],
        [-0.6140, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1066209152340889
Epoch 0, Step 510: train/loss = 0.5111303925514221, train/raw-loss = 0.4434102475643158, train/logprobs = tensor([[-0.7327, -3.2494],
        [-0.9242, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11286695301532745
Epoch 0, Step 511: train/loss = 0.53788161277771, train/raw-loss = 0.4746905565261841, train/logprobs = tensor([[-0.7384, -2.9411],
        [-0.7827, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10531846433877945
Epoch 0, Step 512: train/loss = 0.49546223878860474, train/raw-loss = 0.4380304217338562, train/logprobs = tensor([[-0.6925, -2.0375],
        [-1.1148, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09571964293718338
Epoch 0, Step 513: train/loss = 0.5258874893188477, train/raw-loss = 0.46290159225463867, train/logprobs = tensor([[-0.4135, -3.0138],
        [-0.5648, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10497644543647766
Epoch 0, Step 514: train/loss = 0.4091036319732666, train/raw-loss = 0.33374252915382385, train/logprobs = tensor([[-0.6193, -4.3351],
        [-1.0015, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12560182809829712
Epoch 0, Step 515: train/loss = 0.7302725315093994, train/raw-loss = 0.6731254458427429, train/logprobs = tensor([[-0.5064, -0.5718],
        [-0.5721, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952451229095459
Epoch 0, Step 516: train/loss = 0.4477492570877075, train/raw-loss = 0.3793431520462036, train/logprobs = tensor([[-0.6953, -2.6631],
        [-1.1269, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11401018500328064
Epoch 0, Step 517: train/loss = 0.48068079352378845, train/raw-loss = 0.4153684377670288, train/logprobs = tensor([[-0.5677, -2.3058],
        [-0.7739, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10885384678840637
Epoch 0, Step 518: train/loss = 0.406869113445282, train/raw-loss = 0.33894777297973633, train/logprobs = tensor([[-0.7341, -5.2504],
        [-1.4725, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11320225149393082
Epoch 0, Step 519: train/loss = 0.390830934047699, train/raw-loss = 0.31798410415649414, train/logprobs = tensor([[-0.8219, -3.5852],
        [-0.9832, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141139060258865
Epoch 0, Step 520: train/loss = 0.7408387064933777, train/raw-loss = 0.6839057207107544, train/logprobs = tensor([[-0.9069, -0.9645],
        [-0.7519, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09488825500011444
Epoch 0, Step 521: train/loss = 0.5035088062286377, train/raw-loss = 0.44944536685943604, train/logprobs = tensor([[-0.3510, -2.3890],
        [-0.5109, -0.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09010571986436844
Epoch 0, Step 522: train/loss = 0.6003736853599548, train/raw-loss = 0.537881076335907, train/logprobs = tensor([[-1.1692, -3.0645],
        [-0.8615, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10415433347225189
Epoch 0, Step 523: train/loss = 0.5505615472793579, train/raw-loss = 0.490020751953125, train/logprobs = tensor([[-0.4831, -2.0351],
        [-0.5930, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10090136528015137
Epoch 0, Step 524: train/loss = 0.36043205857276917, train/raw-loss = 0.2881399989128113, train/logprobs = tensor([[-0.4458, -6.0294],
        [-0.7966, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1204867959022522
Epoch 0, Step 525: train/loss = 0.5641141533851624, train/raw-loss = 0.4988577961921692, train/logprobs = tensor([[-0.5912, -1.7808],
        [-0.7896, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10876058042049408
Epoch 0, Step 526: train/loss = 0.5148608684539795, train/raw-loss = 0.46005797386169434, train/logprobs = tensor([[-0.3772, -1.7175],
        [-0.6211, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0913381278514862
Epoch 0, Step 527: train/loss = 0.31898224353790283, train/raw-loss = 0.2549096643924713, train/logprobs = tensor([[-0.5568, -4.0520],
        [-0.9866, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10678760707378387
Epoch 0, Step 528: train/loss = 0.4109668731689453, train/raw-loss = 0.35206639766693115, train/logprobs = tensor([[-0.3489, -5.4074],
        [-0.4527, -1.4563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09816743433475494
Epoch 0, Step 529: train/loss = 0.45589175820350647, train/raw-loss = 0.38648539781570435, train/logprobs = tensor([[-0.6312, -4.4179],
        [-0.8846, -1.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567724496126175
Epoch 0, Step 530: train/loss = 0.6154050827026367, train/raw-loss = 0.5436370372772217, train/logprobs = tensor([[-0.5752, -1.6595],
        [-0.9792, -1.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11961330473423004
Epoch 0, Step 531: train/loss = 0.588615894317627, train/raw-loss = 0.5304245352745056, train/logprobs = tensor([[-0.4005, -1.3397],
        [-0.5778, -0.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09698555618524551
Epoch 0, Step 532: train/loss = 0.5365339517593384, train/raw-loss = 0.4691849946975708, train/logprobs = tensor([[-0.5918, -2.8809],
        [-0.9605, -0.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11224829405546188
Epoch 0, Step 533: train/loss = 0.48039621114730835, train/raw-loss = 0.4076526165008545, train/logprobs = tensor([[-0.7758, -3.4082],
        [-0.8933, -1.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212393045425415
Epoch 0, Step 534: train/loss = 0.5633590221405029, train/raw-loss = 0.49507084488868713, train/logprobs = tensor([[-0.4617, -2.2727],
        [-0.6788, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11381366848945618
Epoch 0, Step 535: train/loss = 0.40738335251808167, train/raw-loss = 0.3258753716945648, train/logprobs = tensor([[-0.7873, -3.8341],
        [-1.2477, -1.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13584662973880768
Epoch 0, Step 536: train/loss = 0.4534490704536438, train/raw-loss = 0.38930439949035645, train/logprobs = tensor([[-0.6366, -2.4055],
        [-0.8404, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10690775513648987
Epoch 0, Step 537: train/loss = 0.4354144036769867, train/raw-loss = 0.3699001669883728, train/logprobs = tensor([[-0.6173, -2.3429],
        [-1.0528, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10919036716222763
Epoch 0, Step 538: train/loss = 0.43052560091018677, train/raw-loss = 0.3569440245628357, train/logprobs = tensor([[-0.7334, -4.2111],
        [-0.7151, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12263596802949905
Epoch 0, Step 539: train/loss = 0.49400657415390015, train/raw-loss = 0.4387766718864441, train/logprobs = tensor([[-0.4090, -3.2745],
        [-0.6168, -0.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09204989671707153
Epoch 0, Step 540: train/loss = 0.530806839466095, train/raw-loss = 0.46087440848350525, train/logprobs = tensor([[-0.6311, -2.7037],
        [-1.0417, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11655407398939133
Epoch 0, Step 541: train/loss = 0.3801698386669159, train/raw-loss = 0.30790385603904724, train/logprobs = tensor([[-0.7872, -5.5144],
        [-1.3383, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12044335901737213
Epoch 0, Step 542: train/loss = 0.4386719763278961, train/raw-loss = 0.3803519606590271, train/logprobs = tensor([[-0.6359, -2.7672],
        [-0.9082, -0.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09720003604888916
Epoch 0, Step 543: train/loss = 0.4538617730140686, train/raw-loss = 0.39054951071739197, train/logprobs = tensor([[-0.5741, -4.5676],
        [-0.7200, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552045702934265
Epoch 0, Step 544: train/loss = 0.5424090623855591, train/raw-loss = 0.47231021523475647, train/logprobs = tensor([[-0.6002, -1.9033],
        [-0.7966, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11683142185211182
Epoch 0, Step 545: train/loss = 0.42970502376556396, train/raw-loss = 0.363720178604126, train/logprobs = tensor([[-0.5947, -2.8544],
        [-1.1508, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099746972322464
Epoch 0, Step 546: train/loss = 0.45535361766815186, train/raw-loss = 0.3948906660079956, train/logprobs = tensor([[-0.4463, -2.7338],
        [-0.7130, -0.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10077165812253952
Epoch 0, Step 547: train/loss = 0.4370827376842499, train/raw-loss = 0.370732843875885, train/logprobs = tensor([[-0.6198, -4.2866],
        [-0.8221, -1.2412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11058318614959717
Epoch 0, Step 548: train/loss = 0.5708917379379272, train/raw-loss = 0.5086737275123596, train/logprobs = tensor([[-0.4652, -1.2339],
        [-0.7216, -0.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10369659960269928
Epoch 0, Step 549: train/loss = 0.5215874910354614, train/raw-loss = 0.45387670397758484, train/logprobs = tensor([[-0.8449, -2.0181],
        [-1.2282, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11285129189491272
Epoch 0, Step 550: train/loss = 0.41348832845687866, train/raw-loss = 0.33722737431526184, train/logprobs = tensor([[-0.9400, -4.1578],
        [-1.3734, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271015852689743
Epoch 0, Step 551: train/loss = 0.5677144527435303, train/raw-loss = 0.5043394565582275, train/logprobs = tensor([[-0.6105, -1.7194],
        [-0.7897, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10562487691640854
Epoch 0, Step 552: train/loss = 0.41998904943466187, train/raw-loss = 0.35216549038887024, train/logprobs = tensor([[-0.6580, -2.7970],
        [-1.1528, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130392923951149
Epoch 0, Step 553: train/loss = 0.47435179352760315, train/raw-loss = 0.41036373376846313, train/logprobs = tensor([[-0.4537, -2.6370],
        [-0.7878, -1.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10664677619934082
Epoch 0, Step 554: train/loss = 0.4246752858161926, train/raw-loss = 0.36439216136932373, train/logprobs = tensor([[-0.4929, -4.0768],
        [-0.7050, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10047182440757751
Epoch 0, Step 555: train/loss = 0.47916179895401, train/raw-loss = 0.4174821078777313, train/logprobs = tensor([[-0.9221, -2.9551],
        [-0.8976, -0.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10279951244592667
Epoch 0, Step 556: train/loss = 0.4537239074707031, train/raw-loss = 0.38501793146133423, train/logprobs = tensor([[-0.4409, -3.7980],
        [-0.7037, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11450989544391632
Epoch 0, Step 557: train/loss = 0.4678211808204651, train/raw-loss = 0.39338022470474243, train/logprobs = tensor([[-0.7856, -3.5835],
        [-1.1891, -0.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12406833469867706
Epoch 0, Step 558: train/loss = 0.6612879633903503, train/raw-loss = 0.5945898294448853, train/logprobs = tensor([[-0.6476, -1.0729],
        [-0.8358, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11116363853216171
Epoch 0, Step 559: train/loss = 0.48064863681793213, train/raw-loss = 0.41441822052001953, train/logprobs = tensor([[-0.5879, -2.6764],
        [-0.6732, -0.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11038393527269363
Epoch 0, Step 560: train/loss = 0.5736448764801025, train/raw-loss = 0.5207930207252502, train/logprobs = tensor([[-0.3521, -1.7742],
        [-0.4204, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08808645606040955
Epoch 0, Step 561: train/loss = 0.5182693600654602, train/raw-loss = 0.451521098613739, train/logprobs = tensor([[-0.5129, -1.9434],
        [-0.9340, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11124701797962189
Epoch 0, Step 562: train/loss = 0.4666852653026581, train/raw-loss = 0.39996337890625, train/logprobs = tensor([[-0.6486, -3.4820],
        [-1.0010, -0.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1112031564116478
Epoch 0, Step 563: train/loss = 0.5145779252052307, train/raw-loss = 0.4595355987548828, train/logprobs = tensor([[-0.4318, -2.9720],
        [-0.6116, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09173721075057983
Epoch 0, Step 564: train/loss = 0.5473003387451172, train/raw-loss = 0.4779496192932129, train/logprobs = tensor([[-0.6100, -1.5579],
        [-0.9254, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11558454483747482
Epoch 0, Step 565: train/loss = 0.4170374572277069, train/raw-loss = 0.3448287546634674, train/logprobs = tensor([[-0.8999, -3.0683],
        [-1.3975, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12034779042005539
Epoch 0, Step 566: train/loss = 0.5044955611228943, train/raw-loss = 0.4401297867298126, train/logprobs = tensor([[-0.4678, -6.3732],
        [-0.6639, -1.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10727633535861969
Epoch 0, Step 567: train/loss = 0.4007287621498108, train/raw-loss = 0.3328242301940918, train/logprobs = tensor([[-0.5284, -3.1235],
        [-1.0432, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11317424476146698
Epoch 0, Step 568: train/loss = 0.5775368809700012, train/raw-loss = 0.503165602684021, train/logprobs = tensor([[-0.5451, -2.8086],
        [-0.9576, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12395218759775162
Epoch 0, Step 569: train/loss = 0.4051154851913452, train/raw-loss = 0.3258233070373535, train/logprobs = tensor([[-0.7809, -2.2139],
        [-1.4548, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13215361535549164
Epoch 0, Step 570: train/loss = 0.6830339431762695, train/raw-loss = 0.6130576133728027, train/logprobs = tensor([[-1.3296, -2.1656],
        [-0.9264, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11662723124027252
Epoch 0, Step 571: train/loss = 0.44995978474617004, train/raw-loss = 0.38499048352241516, train/logprobs = tensor([[-0.5935, -3.4796],
        [-0.6445, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1082821637392044
Epoch 0, Step 572: train/loss = 0.4582599401473999, train/raw-loss = 0.3955048620700836, train/logprobs = tensor([[-0.3798, -2.4881],
        [-0.5149, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10459182411432266
Epoch 0, Step 573: train/loss = 0.41678178310394287, train/raw-loss = 0.3476472795009613, train/logprobs = tensor([[-0.5404, -3.3985],
        [-0.7189, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11522416770458221
Epoch 0, Step 574: train/loss = 0.5936793684959412, train/raw-loss = 0.5335266590118408, train/logprobs = tensor([[-0.4850, -1.2611],
        [-0.6892, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10025452822446823
Epoch 0, Step 575: train/loss = 0.4099714756011963, train/raw-loss = 0.3384232521057129, train/logprobs = tensor([[-0.5729, -3.6418],
        [-1.1079, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11924711614847183
Epoch 0, Step 576: train/loss = 0.5498882532119751, train/raw-loss = 0.47044140100479126, train/logprobs = tensor([[-0.7829, -1.6312],
        [-1.1255, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13241131603717804
Epoch 0, Step 577: train/loss = 0.639064371585846, train/raw-loss = 0.563511312007904, train/logprobs = tensor([[-0.7179, -1.4761],
        [-0.9840, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12592174112796783
Epoch 0, Step 578: train/loss = 0.3969925045967102, train/raw-loss = 0.32204654812812805, train/logprobs = tensor([[-0.7099, -3.8396],
        [-1.2829, -0.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1249099001288414
Epoch 0, Step 579: train/loss = 0.43269309401512146, train/raw-loss = 0.3692573308944702, train/logprobs = tensor([[-0.7657, -4.4154],
        [-1.0557, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10572627186775208
Epoch 0, Step 580: train/loss = 0.45896077156066895, train/raw-loss = 0.40210258960723877, train/logprobs = tensor([[-0.9584, -5.1901],
        [-0.9121, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09476367384195328
Epoch 0, Step 581: train/loss = 0.4104202389717102, train/raw-loss = 0.3434191644191742, train/logprobs = tensor([[-0.6560, -6.4220],
        [-1.0798, -1.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1116684302687645
Epoch 0, Step 582: train/loss = 0.5499168634414673, train/raw-loss = 0.48986193537712097, train/logprobs = tensor([[-0.6060, -1.5891],
        [-1.0148, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10009147226810455
Epoch 0, Step 583: train/loss = 0.5634387731552124, train/raw-loss = 0.5016103386878967, train/logprobs = tensor([[-0.7633, -2.0985],
        [-0.7703, -0.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10304738581180573
Epoch 0, Step 584: train/loss = 0.5305188894271851, train/raw-loss = 0.47480615973472595, train/logprobs = tensor([[-0.4825, -1.8522],
        [-0.7705, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09285447746515274
Epoch 0, Step 585: train/loss = 0.576710045337677, train/raw-loss = 0.5185444355010986, train/logprobs = tensor([[-0.3094, -1.8974],
        [-0.4773, -0.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09694261103868484
Epoch 0, Step 586: train/loss = 0.47692808508872986, train/raw-loss = 0.40232640504837036, train/logprobs = tensor([[-0.7089, -1.8052],
        [-1.2237, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12433615326881409
Epoch 0, Step 587: train/loss = 0.5575278401374817, train/raw-loss = 0.5007312297821045, train/logprobs = tensor([[-0.6024, -1.3521],
        [-0.8825, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09466095268726349
Epoch 0, Step 588: train/loss = 0.42661571502685547, train/raw-loss = 0.36589375138282776, train/logprobs = tensor([[-0.7170, -4.6886],
        [-1.2825, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10120321810245514
Epoch 0, Step 589: train/loss = 0.44614261388778687, train/raw-loss = 0.3775736391544342, train/logprobs = tensor([[-0.5952, -2.9605],
        [-1.0302, -0.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11428166925907135
Epoch 0, Step 590: train/loss = 0.37012171745300293, train/raw-loss = 0.30848240852355957, train/logprobs = tensor([[-0.4897, -3.9851],
        [-0.7435, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273218154907227
Epoch 0, Step 591: train/loss = 0.6938871145248413, train/raw-loss = 0.6333807110786438, train/logprobs = tensor([[-0.6202, -0.7164],
        [-0.7142, -0.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10084402561187744
Epoch 0, Step 592: train/loss = 0.5408850312232971, train/raw-loss = 0.4795803725719452, train/logprobs = tensor([[-0.5546, -1.6508],
        [-0.8054, -0.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10217443853616714
Epoch 0, Step 593: train/loss = 0.4846934378147125, train/raw-loss = 0.42054659128189087, train/logprobs = tensor([[-0.4932, -2.4479],
        [-0.8220, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10691139847040176
Epoch 0, Step 594: train/loss = 0.38476479053497314, train/raw-loss = 0.30680838227272034, train/logprobs = tensor([[-0.6696, -2.9341],
        [-1.0465, -0.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299273669719696
Epoch 0, Step 595: train/loss = 0.5616062879562378, train/raw-loss = 0.49679484963417053, train/logprobs = tensor([[-0.5367, -1.7287],
        [-0.7504, -0.8409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10801899433135986
Epoch 0, Step 596: train/loss = 0.5002742409706116, train/raw-loss = 0.43618515133857727, train/logprobs = tensor([[-0.6827, -3.8785],
        [-0.9554, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1068151593208313
Epoch 0, Step 597: train/loss = 0.6650640368461609, train/raw-loss = 0.6052871942520142, train/logprobs = tensor([[-0.6248, -0.8751],
        [-0.9028, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996280312538147
Epoch 0, Step 598: train/loss = 0.4676940441131592, train/raw-loss = 0.3893136978149414, train/logprobs = tensor([[-0.9266, -3.0418],
        [-0.9563, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13063393533229828
Epoch 0, Step 599: train/loss = 0.47293317317962646, train/raw-loss = 0.4030204713344574, train/logprobs = tensor([[-0.4950, -3.7665],
        [-0.7573, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11652114987373352
Epoch 0, Step 600: train/loss = 0.5045602917671204, train/raw-loss = 0.4407680034637451, train/logprobs = tensor([[-0.4518, -2.5755],
        [-0.6752, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10632045567035675
Epoch 0, Step 601: train/loss = 0.5074831247329712, train/raw-loss = 0.4398398697376251, train/logprobs = tensor([[-0.8242, -1.9849],
        [-1.2327, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11273877322673798
Epoch 0, Step 602: train/loss = 0.5416743755340576, train/raw-loss = 0.4642265737056732, train/logprobs = tensor([[-0.8819, -2.3526],
        [-0.9913, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290796548128128
Epoch 0, Step 603: train/loss = 0.35025352239608765, train/raw-loss = 0.2811737060546875, train/logprobs = tensor([[-0.5204, -5.1785],
        [-0.9122, -1.1061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11513298749923706
Epoch 0, Step 604: train/loss = 0.5703314542770386, train/raw-loss = 0.5087527632713318, train/logprobs = tensor([[-0.3731, -1.3441],
        [-0.6073, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10263120383024216
Epoch 0, Step 605: train/loss = 0.557900071144104, train/raw-loss = 0.49510249495506287, train/logprobs = tensor([[-0.6554, -0.9901],
        [-1.2179, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10466267913579941
Epoch 0, Step 606: train/loss = 0.4996027946472168, train/raw-loss = 0.4399047791957855, train/logprobs = tensor([[-0.5912, -1.8530],
        [-0.7436, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09949666261672974
Epoch 0, Step 607: train/loss = 0.47069525718688965, train/raw-loss = 0.39831098914146423, train/logprobs = tensor([[-0.6408, -2.6710],
        [-0.8546, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12064047157764435
Epoch 0, Step 608: train/loss = 0.4829009771347046, train/raw-loss = 0.41244444251060486, train/logprobs = tensor([[-0.5411, -2.3733],
        [-1.0231, -0.7954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11742754280567169
Epoch 0, Step 609: train/loss = 0.39614421129226685, train/raw-loss = 0.32654452323913574, train/logprobs = tensor([[-0.7877, -5.3932],
        [-1.3128, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11599953472614288
Epoch 0, Step 610: train/loss = 0.3216618299484253, train/raw-loss = 0.23357871174812317, train/logprobs = tensor([[-0.9671, -6.2107],
        [-1.5447, -1.1679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14680519700050354
Epoch 0, Step 611: train/loss = 0.3482413589954376, train/raw-loss = 0.28745225071907043, train/logprobs = tensor([[-0.4789, -3.5075],
        [-0.7761, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10131516307592392
Epoch 0, Step 612: train/loss = 0.5923565626144409, train/raw-loss = 0.5196285843849182, train/logprobs = tensor([[-0.6348, -3.2912],
        [-0.8818, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121327221393585
Epoch 0, Step 613: train/loss = 0.6214214563369751, train/raw-loss = 0.5500835180282593, train/logprobs = tensor([[-0.6861, -1.6766],
        [-0.9071, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11889657378196716
Epoch 0, Step 614: train/loss = 0.5009984374046326, train/raw-loss = 0.42892464995384216, train/logprobs = tensor([[-0.6214, -1.9812],
        [-0.8556, -0.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12012293934822083
Epoch 0, Step 615: train/loss = 0.508596658706665, train/raw-loss = 0.4350636601448059, train/logprobs = tensor([[-0.5836, -1.9206],
        [-1.0228, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12255503237247467
Epoch 0, Step 616: train/loss = 0.6705505847930908, train/raw-loss = 0.6067870259284973, train/logprobs = tensor([[-0.4604, -0.8839],
        [-0.6950, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10627249628305435
Epoch 0, Step 617: train/loss = 0.5060161352157593, train/raw-loss = 0.4477442502975464, train/logprobs = tensor([[-0.6215, -3.6427],
        [-0.8321, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0971197709441185
Epoch 0, Step 618: train/loss = 0.47852522134780884, train/raw-loss = 0.4095958173274994, train/logprobs = tensor([[-0.5012, -2.3168],
        [-0.9234, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11488234996795654
Epoch 0, Step 619: train/loss = 0.3994528651237488, train/raw-loss = 0.33549702167510986, train/logprobs = tensor([[-0.4509, -3.9518],
        [-0.8005, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1065930426120758
Epoch 0, Step 620: train/loss = 0.41261178255081177, train/raw-loss = 0.33747488260269165, train/logprobs = tensor([[-0.7052, -2.9192],
        [-1.2165, -0.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12522821128368378
Epoch 0, Step 621: train/loss = 0.6400308012962341, train/raw-loss = 0.5786448121070862, train/logprobs = tensor([[-0.6378, -0.7830],
        [-0.8978, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10230995714664459
Epoch 0, Step 622: train/loss = 0.49305659532546997, train/raw-loss = 0.4265908896923065, train/logprobs = tensor([[-0.4130, -4.1827],
        [-0.8317, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11077612638473511
Epoch 0, Step 623: train/loss = 0.4477686882019043, train/raw-loss = 0.38225430250167847, train/logprobs = tensor([[-0.5563, -4.4473],
        [-0.9050, -0.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10919064283370972
Epoch 0, Step 624: train/loss = 0.5017225742340088, train/raw-loss = 0.4311394989490509, train/logprobs = tensor([[-0.5122, -2.7017],
        [-0.9852, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11763852834701538
Epoch 0, Step 625: train/loss = 0.5255081057548523, train/raw-loss = 0.45185258984565735, train/logprobs = tensor([[-0.5671, -3.6939],
        [-0.7315, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12275917083024979
Epoch 0, Step 626: train/loss = 0.5209819078445435, train/raw-loss = 0.45594677329063416, train/logprobs = tensor([[-0.5072, -1.9232],
        [-0.8127, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10839197039604187
Epoch 0, Step 627: train/loss = 0.5002707242965698, train/raw-loss = 0.42932450771331787, train/logprobs = tensor([[-0.4238, -1.8127],
        [-0.9135, -0.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11824371665716171
Epoch 0, Step 628: train/loss = 0.47091466188430786, train/raw-loss = 0.4031854569911957, train/logprobs = tensor([[-0.4377, -2.1344],
        [-0.8879, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288197338581085
Epoch 0, Step 629: train/loss = 0.5344528555870056, train/raw-loss = 0.46831926703453064, train/logprobs = tensor([[-0.3668, -1.5695],
        [-0.6867, -0.7805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11022266745567322
Epoch 0, Step 630: train/loss = 0.45510390400886536, train/raw-loss = 0.3911719024181366, train/logprobs = tensor([[-0.3962, -3.1046],
        [-0.6147, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1065533459186554
Epoch 0, Step 631: train/loss = 0.3587736189365387, train/raw-loss = 0.2861238718032837, train/logprobs = tensor([[-1.1064, -4.5521],
        [-1.4433, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12108290195465088
Epoch 0, Step 632: train/loss = 0.5161128640174866, train/raw-loss = 0.4319669008255005, train/logprobs = tensor([[-0.7342, -3.2413],
        [-0.9853, -0.8429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402433067560196
Epoch 0, Step 633: train/loss = 0.4019770622253418, train/raw-loss = 0.3320028781890869, train/logprobs = tensor([[-0.6965, -4.0829],
        [-1.0066, -1.4945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11662366986274719
Epoch 0, Step 634: train/loss = 0.437090128660202, train/raw-loss = 0.36015385389328003, train/logprobs = tensor([[-0.4620, -3.2813],
        [-1.0056, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282271146774292
Epoch 0, Step 635: train/loss = 0.4104495048522949, train/raw-loss = 0.3402419984340668, train/logprobs = tensor([[-0.5013, -3.9436],
        [-0.9813, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11701248586177826
Epoch 0, Step 636: train/loss = 0.5221979022026062, train/raw-loss = 0.45822998881340027, train/logprobs = tensor([[-0.5080, -2.8132],
        [-0.7264, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1066131591796875
Epoch 0, Step 637: train/loss = 0.4583030045032501, train/raw-loss = 0.3995256721973419, train/logprobs = tensor([[-0.5883, -3.5487],
        [-0.7976, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09796223044395447
Epoch 0, Step 638: train/loss = 0.6611640453338623, train/raw-loss = 0.5949617028236389, train/logprobs = tensor([[-0.5013, -0.9739],
        [-0.6554, -0.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1103372573852539
Epoch 0, Step 639: train/loss = 0.48442405462265015, train/raw-loss = 0.40896931290626526, train/logprobs = tensor([[-0.7969, -2.8562],
        [-1.0838, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12575796246528625
Epoch 0, Step 640: train/loss = 0.42897021770477295, train/raw-loss = 0.36738380789756775, train/logprobs = tensor([[-0.5038, -4.3051],
        [-0.6986, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10264391452074051
Epoch 0, Step 641: train/loss = 0.630067765712738, train/raw-loss = 0.5632895827293396, train/logprobs = tensor([[-1.1082, -2.6859],
        [-0.9190, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11129691451787949
Epoch 0, Step 642: train/loss = 0.4427820146083832, train/raw-loss = 0.37252330780029297, train/logprobs = tensor([[-0.8052, -3.2913],
        [-0.9809, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11709775030612946
Epoch 0, Step 643: train/loss = 0.3608841896057129, train/raw-loss = 0.2905115783214569, train/logprobs = tensor([[-0.5120, -4.8778],
        [-0.8980, -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728762835264206
Epoch 0, Step 644: train/loss = 0.5889211297035217, train/raw-loss = 0.5152984261512756, train/logprobs = tensor([[-0.9034, -1.1231],
        [-1.2714, -0.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122704416513443
Epoch 0, Step 645: train/loss = 0.4656088352203369, train/raw-loss = 0.4038459360599518, train/logprobs = tensor([[-1.0613, -4.7308],
        [-1.5594, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293823480606079
Epoch 0, Step 646: train/loss = 0.6301708817481995, train/raw-loss = 0.5627344250679016, train/logprobs = tensor([[-0.5060, -0.9863],
        [-0.8020, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11239410936832428
Epoch 0, Step 647: train/loss = 0.5166964530944824, train/raw-loss = 0.4527062177658081, train/logprobs = tensor([[-0.5614, -2.4501],
        [-0.8744, -0.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10665039718151093
Epoch 0, Step 648: train/loss = 0.4523794651031494, train/raw-loss = 0.381283700466156, train/logprobs = tensor([[-0.5959, -4.2220],
        [-1.0275, -1.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1184929683804512
Epoch 0, Step 649: train/loss = 0.3085654079914093, train/raw-loss = 0.23763465881347656, train/logprobs = tensor([[-0.5701, -5.6199],
        [-1.2950, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11821793764829636
Epoch 0, Step 650: train/loss = 0.37036919593811035, train/raw-loss = 0.29922184348106384, train/logprobs = tensor([[-0.5671, -4.9929],
        [-1.0368, -1.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185789406299591
Epoch 0, Step 651: train/loss = 0.333657443523407, train/raw-loss = 0.26013055443763733, train/logprobs = tensor([[-0.8120, -4.4446],
        [-1.2560, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12254482507705688
Epoch 0, Step 652: train/loss = 0.4228683114051819, train/raw-loss = 0.3707371950149536, train/logprobs = tensor([[-0.9721, -6.4958],
        [-1.1093, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08688522130250931
Epoch 0, Step 653: train/loss = 0.509663462638855, train/raw-loss = 0.4499569833278656, train/logprobs = tensor([[-0.6804, -2.4552],
        [-0.9823, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0995108038187027
Epoch 0, Step 654: train/loss = 0.6248980164527893, train/raw-loss = 0.5663865208625793, train/logprobs = tensor([[-0.5659, -2.0216],
        [-0.6077, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09751910716295242
Epoch 0, Step 655: train/loss = 0.4254480004310608, train/raw-loss = 0.34365731477737427, train/logprobs = tensor([[-0.7838, -3.0226],
        [-1.3373, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13631783425807953
Epoch 0, Step 656: train/loss = 0.3123316764831543, train/raw-loss = 0.24172565340995789, train/logprobs = tensor([[-0.9365, -7.5414],
        [-1.2906, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767671257257462
Epoch 0, Step 657: train/loss = 0.3900145888328552, train/raw-loss = 0.32570943236351013, train/logprobs = tensor([[-0.5847, -4.7623],
        [-0.9541, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1071752980351448
Epoch 0, Step 658: train/loss = 0.5157654285430908, train/raw-loss = 0.4407258629798889, train/logprobs = tensor([[-0.8344, -2.9100],
        [-1.0912, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1250658929347992
Epoch 0, Step 659: train/loss = 0.3164599537849426, train/raw-loss = 0.23745113611221313, train/logprobs = tensor([[-0.4791, -4.2700],
        [-1.0157, -0.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13168132305145264
Epoch 0, Step 660: train/loss = 0.6161891222000122, train/raw-loss = 0.5474528670310974, train/logprobs = tensor([[-0.7108, -1.7861],
        [-0.6986, -0.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456038802862167
Epoch 0, Step 661: train/loss = 0.46333828568458557, train/raw-loss = 0.39060842990875244, train/logprobs = tensor([[-0.5248, -3.7567],
        [-0.9456, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121643126010895
Epoch 0, Step 662: train/loss = 0.5881037712097168, train/raw-loss = 0.5337343215942383, train/logprobs = tensor([[-0.5764, -1.4256],
        [-0.7134, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09061576426029205
Epoch 0, Step 663: train/loss = 0.4810020327568054, train/raw-loss = 0.4173496663570404, train/logprobs = tensor([[-0.8492, -4.9489],
        [-0.7872, -1.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10608722269535065
Epoch 0, Step 664: train/loss = 0.4997643232345581, train/raw-loss = 0.43433883786201477, train/logprobs = tensor([[-0.6501, -1.9769],
        [-0.9914, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904247313737869
Epoch 0, Step 665: train/loss = 0.5445735454559326, train/raw-loss = 0.4703966975212097, train/logprobs = tensor([[-0.8801, -1.7203],
        [-0.9634, -0.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12362810969352722
Epoch 0, Step 666: train/loss = 0.45426732301712036, train/raw-loss = 0.3850322961807251, train/logprobs = tensor([[-0.7198, -3.6096],
        [-1.2759, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11539164185523987
Epoch 0, Step 667: train/loss = 0.49192386865615845, train/raw-loss = 0.42428600788116455, train/logprobs = tensor([[-0.6134, -3.2014],
        [-1.0827, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127297505736351
Epoch 0, Step 668: train/loss = 0.5912259817123413, train/raw-loss = 0.5206787586212158, train/logprobs = tensor([[-0.5719, -1.2781],
        [-0.9274, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11757874488830566
Epoch 0, Step 669: train/loss = 0.3780732750892639, train/raw-loss = 0.31531789898872375, train/logprobs = tensor([[-0.5761, -4.3700],
        [-0.9526, -0.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10459233075380325
Epoch 0, Step 670: train/loss = 0.42916029691696167, train/raw-loss = 0.3696417808532715, train/logprobs = tensor([[-0.7777, -4.5176],
        [-0.9401, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09919758141040802
Epoch 0, Step 671: train/loss = 0.4606623947620392, train/raw-loss = 0.3977961540222168, train/logprobs = tensor([[-0.7657, -3.1215],
        [-0.8036, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10477699339389801
Epoch 0, Step 672: train/loss = 0.5184676051139832, train/raw-loss = 0.4580078125, train/logprobs = tensor([[-0.6543, -3.1607],
        [-0.9770, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1007663831114769
Epoch 0, Step 673: train/loss = 0.4798998236656189, train/raw-loss = 0.4060332179069519, train/logprobs = tensor([[-0.5436, -3.2012],
        [-0.9365, -0.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1231110692024231
Epoch 0, Step 674: train/loss = 0.4491361081600189, train/raw-loss = 0.3868807852268219, train/logprobs = tensor([[-0.3864, -2.2824],
        [-0.8124, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10375884175300598
Epoch 0, Step 675: train/loss = 0.42571961879730225, train/raw-loss = 0.3401721715927124, train/logprobs = tensor([[-0.5733, -2.5761],
        [-1.1926, -0.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1425790786743164
Epoch 0, Step 676: train/loss = 0.37695062160491943, train/raw-loss = 0.31035423278808594, train/logprobs = tensor([[-0.4351, -5.7300],
        [-0.9705, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11099399626255035
Epoch 0, Step 677: train/loss = 0.5265449285507202, train/raw-loss = 0.45208069682121277, train/logprobs = tensor([[-0.4030, -2.5277],
        [-0.7361, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12410704791545868
Epoch 0, Step 678: train/loss = 0.40600401163101196, train/raw-loss = 0.32339397072792053, train/logprobs = tensor([[-0.5533, -4.3456],
        [-1.1898, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13768336176872253
Epoch 0, Step 679: train/loss = 0.35240378975868225, train/raw-loss = 0.2829996943473816, train/logprobs = tensor([[-0.7884, -3.6866],
        [-1.0800, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156734973192215
Epoch 0, Step 680: train/loss = 0.4111103415489197, train/raw-loss = 0.3516034781932831, train/logprobs = tensor([[-0.5635, -4.5700],
        [-0.8968, -0.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09917812794446945
Epoch 0, Step 681: train/loss = 0.4150186777114868, train/raw-loss = 0.34093305468559265, train/logprobs = tensor([[-0.4832, -2.9873],
        [-0.9479, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12347608059644699
Epoch 0, Step 682: train/loss = 0.5884018540382385, train/raw-loss = 0.5099175572395325, train/logprobs = tensor([[-0.9408, -2.1746],
        [-0.8821, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080714643001556
Epoch 0, Step 683: train/loss = 0.5894293189048767, train/raw-loss = 0.5060594081878662, train/logprobs = tensor([[-0.7870, -1.8887],
        [-1.2718, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13894984126091003
Epoch 0, Step 684: train/loss = 0.4179415702819824, train/raw-loss = 0.35377636551856995, train/logprobs = tensor([[-0.5396, -3.9321],
        [-0.9177, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10694191604852676
Epoch 0, Step 685: train/loss = 0.462163507938385, train/raw-loss = 0.3928282856941223, train/logprobs = tensor([[-0.4879, -2.9549],
        [-0.8701, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11555865406990051
Epoch 0, Step 686: train/loss = 0.5341503620147705, train/raw-loss = 0.4463481307029724, train/logprobs = tensor([[-1.1045, -2.5964],
        [-1.2306, -0.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14633707702159882
Epoch 0, Step 687: train/loss = 0.48041626811027527, train/raw-loss = 0.42568495869636536, train/logprobs = tensor([[-0.7518, -2.8082],
        [-0.9515, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09121888130903244
Epoch 0, Step 688: train/loss = 0.2927092909812927, train/raw-loss = 0.2137531042098999, train/logprobs = tensor([[-0.5216, -4.9574],
        [-1.1013, -0.8717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13159365952014923
Epoch 0, Step 689: train/loss = 0.3863127529621124, train/raw-loss = 0.3223224878311157, train/logprobs = tensor([[-0.5118, -4.9054],
        [-1.0878, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1066504493355751
Epoch 0, Step 690: train/loss = 0.5000141859054565, train/raw-loss = 0.449729323387146, train/logprobs = tensor([[-0.3380, -3.1129],
        [-0.5386, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380811661481857
Epoch 0, Step 691: train/loss = 0.3824186325073242, train/raw-loss = 0.30918172001838684, train/logprobs = tensor([[-0.7291, -4.8103],
        [-1.6499, -1.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206147611141205
Epoch 0, Step 692: train/loss = 0.4307873845100403, train/raw-loss = 0.36438512802124023, train/logprobs = tensor([[-0.4753, -2.4867],
        [-0.8390, -0.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11067034304141998
Epoch 0, Step 693: train/loss = 0.4533686339855194, train/raw-loss = 0.3912278413772583, train/logprobs = tensor([[-0.5444, -2.4792],
        [-0.8632, -0.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10356798022985458
Epoch 0, Step 694: train/loss = 0.3817445635795593, train/raw-loss = 0.31549540162086487, train/logprobs = tensor([[-0.6797, -4.8799],
        [-0.9923, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11041522026062012
Epoch 0, Step 695: train/loss = 0.592694878578186, train/raw-loss = 0.5209000706672668, train/logprobs = tensor([[-0.6066, -1.6055],
        [-1.0643, -1.0597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11965800821781158
Epoch 0, Step 696: train/loss = 0.4702712297439575, train/raw-loss = 0.3955930173397064, train/logprobs = tensor([[-0.5634, -3.3496],
        [-1.2969, -1.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12446369230747223
Epoch 0, Step 697: train/loss = 0.46799978613853455, train/raw-loss = 0.4013258218765259, train/logprobs = tensor([[-0.3863, -1.9717],
        [-0.7485, -0.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11112326383590698
Epoch 0, Step 698: train/loss = 0.49512428045272827, train/raw-loss = 0.42531198263168335, train/logprobs = tensor([[-0.6085, -2.7543],
        [-1.1778, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11635385453701019
Epoch 0, Step 699: train/loss = 0.3133251667022705, train/raw-loss = 0.24284183979034424, train/logprobs = tensor([[-0.7383, -5.1776],
        [-1.5553, -1.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11747219413518906
Epoch 0, Step 700: train/loss = 0.45165959000587463, train/raw-loss = 0.3816492557525635, train/logprobs = tensor([[-0.8602, -5.3534],
        [-0.9990, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11668386310338974
Epoch 0, Step 701: train/loss = 0.4133771061897278, train/raw-loss = 0.3375852704048157, train/logprobs = tensor([[-0.6789, -4.1056],
        [-0.9681, -0.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1263197362422943
Epoch 0, Step 702: train/loss = 0.4986855387687683, train/raw-loss = 0.43936944007873535, train/logprobs = tensor([[-0.5243, -1.9022],
        [-0.8727, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09886013716459274
Epoch 0, Step 703: train/loss = 0.5762596726417542, train/raw-loss = 0.5055545568466187, train/logprobs = tensor([[-0.6113, -2.0102],
        [-0.9867, -1.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784180998802185
Epoch 0, Step 704: train/loss = 0.3176476061344147, train/raw-loss = 0.24548228085041046, train/logprobs = tensor([[-0.9222, -7.7385],
        [-1.6513, -1.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12027555704116821
Epoch 0, Step 705: train/loss = 0.3045162558555603, train/raw-loss = 0.2220432162284851, train/logprobs = tensor([[-0.9039, -4.7139],
        [-1.4824, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374550461769104
Epoch 0, Step 706: train/loss = 0.49596208333969116, train/raw-loss = 0.44539374113082886, train/logprobs = tensor([[-0.4449, -3.3574],
        [-0.6310, -0.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08428055047988892
Epoch 0, Step 707: train/loss = 0.44274652004241943, train/raw-loss = 0.3680301904678345, train/logprobs = tensor([[-0.6381, -3.2253],
        [-1.0058, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12452720105648041
Epoch 0, Step 708: train/loss = 0.4735996127128601, train/raw-loss = 0.41093993186950684, train/logprobs = tensor([[-0.5392, -3.3214],
        [-0.8154, -0.6071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044328585267067
Epoch 0, Step 709: train/loss = 0.2266043722629547, train/raw-loss = 0.14670391380786896, train/logprobs = tensor([[-0.7030, -6.7922],
        [-1.7552, -1.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13316744565963745
Epoch 0, Step 710: train/loss = 0.3534712791442871, train/raw-loss = 0.28154298663139343, train/logprobs = tensor([[-0.6468, -3.9024],
        [-1.2892, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11988048255443573
Epoch 0, Step 711: train/loss = 0.5199782252311707, train/raw-loss = 0.4524199366569519, train/logprobs = tensor([[-0.4737, -2.3510],
        [-0.9435, -0.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11259706318378448
Epoch 0, Step 712: train/loss = 0.45967501401901245, train/raw-loss = 0.3930489420890808, train/logprobs = tensor([[-0.6846, -3.3167],
        [-1.1883, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104343086481094
Epoch 0, Step 713: train/loss = 0.3943215012550354, train/raw-loss = 0.3248539865016937, train/logprobs = tensor([[-0.7446, -5.2133],
        [-1.1576, -1.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577919870615005
Epoch 0, Step 714: train/loss = 0.5248847007751465, train/raw-loss = 0.4641052186489105, train/logprobs = tensor([[-0.8123, -4.2458],
        [-0.9716, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012992188334465
Epoch 0, Step 715: train/loss = 0.3533322811126709, train/raw-loss = 0.2880224287509918, train/logprobs = tensor([[-0.5906, -5.6876],
        [-0.8694, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884971171617508
Epoch 0, Step 716: train/loss = 0.5851535201072693, train/raw-loss = 0.5156785249710083, train/logprobs = tensor([[-0.6259, -1.5170],
        [-0.9832, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579161882400513
Epoch 0, Step 717: train/loss = 0.48527991771698, train/raw-loss = 0.41954463720321655, train/logprobs = tensor([[-0.6480, -3.5389],
        [-1.3139, -1.1262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10955878347158432
Epoch 0, Step 718: train/loss = 0.5225400924682617, train/raw-loss = 0.45679569244384766, train/logprobs = tensor([[-0.9766, -2.8413],
        [-1.1764, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10957390069961548
Epoch 0, Step 719: train/loss = 0.5089775919914246, train/raw-loss = 0.44661378860473633, train/logprobs = tensor([[-0.4431, -1.8711],
        [-0.7633, -0.4936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039397269487381
Epoch 0, Step 720: train/loss = 0.41295191645622253, train/raw-loss = 0.3335566520690918, train/logprobs = tensor([[-0.6346, -3.2320],
        [-1.1772, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13232547044754028
Epoch 0, Step 721: train/loss = 0.4684714078903198, train/raw-loss = 0.38237258791923523, train/logprobs = tensor([[-0.7324, -2.8276],
        [-0.9820, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14349797368049622
Epoch 0, Step 722: train/loss = 0.7300713062286377, train/raw-loss = 0.6714675426483154, train/logprobs = tensor([[-0.5913, -0.6795],
        [-0.6555, -0.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0976729542016983
Epoch 0, Step 723: train/loss = 0.4217569828033447, train/raw-loss = 0.32249847054481506, train/logprobs = tensor([[-0.9178, -3.4861],
        [-1.2534, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16543085873126984
Epoch 0, Step 724: train/loss = 0.367347776889801, train/raw-loss = 0.30579763650894165, train/logprobs = tensor([[-0.5492, -5.6333],
        [-1.0488, -1.2782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258350521326065
Epoch 0, Step 725: train/loss = 0.5894089937210083, train/raw-loss = 0.5257012248039246, train/logprobs = tensor([[-0.9651, -3.0145],
        [-0.8026, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617951303720474
Epoch 0, Step 726: train/loss = 0.33678698539733887, train/raw-loss = 0.2708019018173218, train/logprobs = tensor([[-0.4357, -5.7841],
        [-0.7992, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099751740694046
Epoch 0, Step 727: train/loss = 0.5690954923629761, train/raw-loss = 0.5045223236083984, train/logprobs = tensor([[-1.0711, -3.7135],
        [-0.8139, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762186348438263
Epoch 0, Step 728: train/loss = 0.27747684717178345, train/raw-loss = 0.20170176029205322, train/logprobs = tensor([[-0.6718, -8.3678],
        [-1.5307, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12629181146621704
Epoch 0, Step 729: train/loss = 0.6197260618209839, train/raw-loss = 0.5427862405776978, train/logprobs = tensor([[-1.2702, -2.3831],
        [-1.2316, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12823306024074554
Epoch 0, Step 730: train/loss = 0.5353501439094543, train/raw-loss = 0.4788981080055237, train/logprobs = tensor([[-0.3360, -1.7674],
        [-0.5695, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408678114414215
Epoch 0, Step 731: train/loss = 0.5377457141876221, train/raw-loss = 0.47249406576156616, train/logprobs = tensor([[-0.5782, -2.2171],
        [-0.7963, -0.6642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10875281691551208
Epoch 0, Step 732: train/loss = 0.5535979270935059, train/raw-loss = 0.47846871614456177, train/logprobs = tensor([[-0.5399, -2.1244],
        [-0.9322, -1.2411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252152919769287
Epoch 0, Step 733: train/loss = 0.4947476387023926, train/raw-loss = 0.43433475494384766, train/logprobs = tensor([[-0.5766, -3.8418],
        [-0.8376, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068807005882263
Epoch 0, Step 734: train/loss = 0.5190029740333557, train/raw-loss = 0.44502803683280945, train/logprobs = tensor([[-0.8036, -2.3264],
        [-1.1286, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12329161167144775
Epoch 0, Step 735: train/loss = 0.7032393217086792, train/raw-loss = 0.6396675109863281, train/logprobs = tensor([[-0.8060, -1.1665],
        [-0.7351, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595299303531647
Epoch 0, Step 736: train/loss = 0.6514444947242737, train/raw-loss = 0.6002578735351562, train/logprobs = tensor([[-0.3754, -1.0657],
        [-0.5630, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08531101793050766
Epoch 0, Step 737: train/loss = 0.3334718942642212, train/raw-loss = 0.25240904092788696, train/logprobs = tensor([[-0.6832, -3.1996],
        [-1.5316, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13510474562644958
Epoch 0, Step 738: train/loss = 0.5953232645988464, train/raw-loss = 0.5264202356338501, train/logprobs = tensor([[-0.6419, -1.8434],
        [-1.2353, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11483846604824066
Epoch 0, Step 739: train/loss = 0.36747580766677856, train/raw-loss = 0.2983590066432953, train/logprobs = tensor([[-1.0509, -3.3417],
        [-1.8886, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11519467830657959
Epoch 0, Step 740: train/loss = 0.2723274230957031, train/raw-loss = 0.1988532841205597, train/logprobs = tensor([[-0.6851, -4.6239],
        [-1.3501, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12245684862136841
Epoch 0, Step 741: train/loss = 0.3043364882469177, train/raw-loss = 0.20763710141181946, train/logprobs = tensor([[-0.7896, -6.4582],
        [-1.4735, -0.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16116566956043243
Epoch 0, Step 742: train/loss = 0.4922962784767151, train/raw-loss = 0.4256674349308014, train/logprobs = tensor([[-0.4699, -2.5342],
        [-0.8097, -0.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104808747768402
Epoch 0, Step 743: train/loss = 0.35024693608283997, train/raw-loss = 0.28282150626182556, train/logprobs = tensor([[-0.8952, -7.1253],
        [-1.4554, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11237571388483047
Epoch 0, Step 744: train/loss = 0.6304727792739868, train/raw-loss = 0.5703641176223755, train/logprobs = tensor([[-0.5304, -0.8811],
        [-0.7519, -0.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10018125176429749
Epoch 0, Step 745: train/loss = 0.43620771169662476, train/raw-loss = 0.3725934326648712, train/logprobs = tensor([[-0.3806, -2.5883],
        [-0.7024, -0.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060238629579544
Epoch 0, Step 746: train/loss = 0.7023762464523315, train/raw-loss = 0.6327904462814331, train/logprobs = tensor([[-0.6025, -0.6693],
        [-0.8131, -0.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11597641557455063
Epoch 0, Step 747: train/loss = 0.5063472986221313, train/raw-loss = 0.45071133971214294, train/logprobs = tensor([[-0.5187, -1.9786],
        [-0.7025, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09272664040327072
Epoch 0, Step 748: train/loss = 0.6014062166213989, train/raw-loss = 0.537630558013916, train/logprobs = tensor([[-0.4480, -1.1516],
        [-0.9029, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062927320599556
Epoch 0, Step 749: train/loss = 0.4972569942474365, train/raw-loss = 0.4286348223686218, train/logprobs = tensor([[-0.8263, -3.7164],
        [-1.1701, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11437023431062698
Epoch 0, Step 750: train/loss = 0.46591392159461975, train/raw-loss = 0.40046510100364685, train/logprobs = tensor([[-0.8973, -4.7237],
        [-1.7048, -1.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10908132791519165
Epoch 0, Step 751: train/loss = 0.5966519713401794, train/raw-loss = 0.5301892757415771, train/logprobs = tensor([[-0.6483, -2.8643],
        [-0.7535, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11077117174863815
Epoch 0, Step 752: train/loss = 0.5434538125991821, train/raw-loss = 0.4786470830440521, train/logprobs = tensor([[-0.4544, -2.8864],
        [-0.8423, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10801133513450623
Epoch 0, Step 753: train/loss = 0.40576326847076416, train/raw-loss = 0.33412599563598633, train/logprobs = tensor([[-0.5223, -2.6668],
        [-0.8188, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11939544975757599
Epoch 0, Step 754: train/loss = 0.43195095658302307, train/raw-loss = 0.3604217767715454, train/logprobs = tensor([[-0.6492, -2.7254],
        [-1.0909, -0.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11921530216932297
Epoch 0, Step 755: train/loss = 0.38868448138237, train/raw-loss = 0.3058474063873291, train/logprobs = tensor([[-0.7792, -6.0115],
        [-1.4640, -1.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380617916584015
Epoch 0, Step 756: train/loss = 0.4667792022228241, train/raw-loss = 0.3972260057926178, train/logprobs = tensor([[-0.8847, -4.1994],
        [-1.2978, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1159220039844513
Epoch 0, Step 757: train/loss = 0.5545875430107117, train/raw-loss = 0.47659653425216675, train/logprobs = tensor([[-0.5441, -3.7235],
        [-0.9093, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299850046634674
Epoch 0, Step 758: train/loss = 0.3738051652908325, train/raw-loss = 0.3021203875541687, train/logprobs = tensor([[-0.5056, -5.2261],
        [-1.0571, -1.3143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11947459727525711
Epoch 0, Step 759: train/loss = 0.4721028506755829, train/raw-loss = 0.40126314759254456, train/logprobs = tensor([[-0.6180, -3.5543],
        [-0.8572, -0.5946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806620657444
Epoch 0, Step 760: train/loss = 0.5498940348625183, train/raw-loss = 0.4845723509788513, train/logprobs = tensor([[-1.0812, -3.3821],
        [-1.1366, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10886947810649872
Epoch 0, Step 761: train/loss = 0.6712505221366882, train/raw-loss = 0.6057829856872559, train/logprobs = tensor([[-1.1798, -1.2828],
        [-1.3220, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10911256819963455
Epoch 0, Step 762: train/loss = 0.4982176423072815, train/raw-loss = 0.42125269770622253, train/logprobs = tensor([[-0.5257, -2.5921],
        [-1.0243, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12827488780021667
Epoch 0, Step 763: train/loss = 0.43200716376304626, train/raw-loss = 0.34695693850517273, train/logprobs = tensor([[-0.7702, -2.7152],
        [-1.2104, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14175033569335938
Epoch 0, Step 764: train/loss = 0.5646817684173584, train/raw-loss = 0.5008116960525513, train/logprobs = tensor([[-0.6189, -1.4451],
        [-0.9564, -0.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10645011067390442
Epoch 0, Step 765: train/loss = 0.43669742345809937, train/raw-loss = 0.37321776151657104, train/logprobs = tensor([[-0.6872, -4.9184],
        [-1.2140, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057993695139885
Epoch 0, Step 766: train/loss = 0.3572077751159668, train/raw-loss = 0.2703867554664612, train/logprobs = tensor([[-0.7582, -3.3726],
        [-1.2327, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14470168948173523
Epoch 0, Step 767: train/loss = 0.5822886824607849, train/raw-loss = 0.5035544633865356, train/logprobs = tensor([[-0.5837, -1.7214],
        [-0.8390, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13122370839118958
Epoch 0, Step 768: train/loss = 0.6726112365722656, train/raw-loss = 0.6175976991653442, train/logprobs = tensor([[-0.4579, -0.7776],
        [-0.6225, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09168928861618042
Epoch 0, Step 769: train/loss = 0.44343945384025574, train/raw-loss = 0.3736986517906189, train/logprobs = tensor([[-0.8143, -2.9050],
        [-1.0203, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1162346675992012
Epoch 0, Step 770: train/loss = 0.504294216632843, train/raw-loss = 0.4430479407310486, train/logprobs = tensor([[-0.4548, -1.8413],
        [-0.6561, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10207706689834595
Epoch 0, Step 771: train/loss = 0.3470405340194702, train/raw-loss = 0.2813524007797241, train/logprobs = tensor([[-0.5827, -4.7693],
        [-0.8236, -1.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948018729686737
Epoch 0, Step 772: train/loss = 0.35688820481300354, train/raw-loss = 0.2816959619522095, train/logprobs = tensor([[-0.9003, -3.6012],
        [-1.1916, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12532037496566772
Epoch 0, Step 773: train/loss = 0.4703064560890198, train/raw-loss = 0.403766393661499, train/logprobs = tensor([[-0.8716, -3.7274],
        [-0.9477, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11090010404586792
Epoch 0, Step 774: train/loss = 0.5044777393341064, train/raw-loss = 0.44165703654289246, train/logprobs = tensor([[-0.9611, -2.2953],
        [-1.0487, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047012060880661
Epoch 0, Step 775: train/loss = 0.6961916089057922, train/raw-loss = 0.6244562268257141, train/logprobs = tensor([[-2.2872, -7.2601],
        [-1.2631, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11955893039703369
Epoch 0, Step 776: train/loss = 0.3532167971134186, train/raw-loss = 0.297228068113327, train/logprobs = tensor([[-0.6756, -5.4474],
        [-1.1193, -1.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933145210146904
Epoch 0, Step 777: train/loss = 0.5160394906997681, train/raw-loss = 0.4561670422554016, train/logprobs = tensor([[-0.4959, -2.2200],
        [-0.8444, -0.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997873917222023
Epoch 0, Step 778: train/loss = 0.4152880609035492, train/raw-loss = 0.3404860496520996, train/logprobs = tensor([[-0.6344, -3.5959],
        [-0.9583, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12467000633478165
Epoch 0, Step 779: train/loss = 0.5260820388793945, train/raw-loss = 0.45807430148124695, train/logprobs = tensor([[-0.7386, -3.9270],
        [-0.7288, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11334622651338577
Epoch 0, Step 780: train/loss = 0.6168733835220337, train/raw-loss = 0.5598968863487244, train/logprobs = tensor([[-0.5303, -1.7374],
        [-0.5412, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09496079385280609
Epoch 0, Step 781: train/loss = 0.5313307642936707, train/raw-loss = 0.46443814039230347, train/logprobs = tensor([[-0.8416, -2.1928],
        [-1.1150, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148767918348312
Epoch 0, Step 782: train/loss = 0.42235732078552246, train/raw-loss = 0.3315374255180359, train/logprobs = tensor([[-1.3418, -6.5053],
        [-1.3107, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513664424419403
Epoch 0, Step 783: train/loss = 0.3600366711616516, train/raw-loss = 0.2816535234451294, train/logprobs = tensor([[-0.5922, -3.7961],
        [-0.9246, -0.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13063861429691315
Epoch 0, Step 784: train/loss = 0.30126717686653137, train/raw-loss = 0.22661727666854858, train/logprobs = tensor([[-0.6990, -9.5957],
        [-1.1453, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12441650778055191
Epoch 0, Step 785: train/loss = 0.5319228172302246, train/raw-loss = 0.4832054376602173, train/logprobs = tensor([[-0.3354, -2.5912],
        [-0.4558, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119571208953857
Epoch 0, Step 786: train/loss = 0.3330538272857666, train/raw-loss = 0.26357606053352356, train/logprobs = tensor([[-0.5440, -6.2058],
        [-0.7777, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579626053571701
Epoch 0, Step 787: train/loss = 0.5246313810348511, train/raw-loss = 0.45289546251296997, train/logprobs = tensor([[-0.5701, -2.2693],
        [-0.8495, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11955992877483368
Epoch 0, Step 788: train/loss = 0.42160043120384216, train/raw-loss = 0.33809468150138855, train/logprobs = tensor([[-0.6073, -6.4856],
        [-0.9294, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13917624950408936
Epoch 0, Step 789: train/loss = 0.6322324275970459, train/raw-loss = 0.572378933429718, train/logprobs = tensor([[-0.7346, -1.5821],
        [-0.6647, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997558981180191
Epoch 0, Step 790: train/loss = 0.5461187958717346, train/raw-loss = 0.4687528610229492, train/logprobs = tensor([[-0.6334, -2.3467],
        [-0.7480, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12894326448440552
Epoch 0, Step 791: train/loss = 0.5915098190307617, train/raw-loss = 0.5288825035095215, train/logprobs = tensor([[-0.8579, -1.7762],
        [-1.0201, -0.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10437887161970139
Epoch 0, Step 792: train/loss = 0.4278907775878906, train/raw-loss = 0.3573898673057556, train/logprobs = tensor([[-0.6462, -3.3877],
        [-1.1218, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11750154197216034
Epoch 0, Step 793: train/loss = 0.5093497633934021, train/raw-loss = 0.43502408266067505, train/logprobs = tensor([[-0.7282, -6.5066],
        [-0.9830, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12387606501579285
Epoch 0, Step 794: train/loss = 0.37994053959846497, train/raw-loss = 0.2961324453353882, train/logprobs = tensor([[-0.6566, -4.5931],
        [-1.0562, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13968011736869812
Epoch 0, Step 795: train/loss = 0.4263392686843872, train/raw-loss = 0.3642224669456482, train/logprobs = tensor([[-0.8512, -3.9188],
        [-0.9612, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035279706120491
Epoch 0, Step 796: train/loss = 0.36851006746292114, train/raw-loss = 0.29116734862327576, train/logprobs = tensor([[-0.7321, -6.2972],
        [-1.0843, -1.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289045512676239
Epoch 0, Step 797: train/loss = 0.5350702404975891, train/raw-loss = 0.47813522815704346, train/logprobs = tensor([[-0.5190, -1.5721],
        [-0.7167, -0.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09489161521196365
Epoch 0, Step 798: train/loss = 0.4913858473300934, train/raw-loss = 0.4269508123397827, train/logprobs = tensor([[-0.6968, -4.8489],
        [-0.7425, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10739170014858246
Epoch 0, Step 799: train/loss = 0.5308915972709656, train/raw-loss = 0.4526054859161377, train/logprobs = tensor([[-1.1657, -5.5431],
        [-1.2549, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13047677278518677
Epoch 0, Step 800: train/loss = 0.655573844909668, train/raw-loss = 0.5964357256889343, train/logprobs = tensor([[-1.0023, -1.6526],
        [-0.9689, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09856357425451279
Epoch 0, Step 801: train/loss = 0.29354599118232727, train/raw-loss = 0.2099761962890625, train/logprobs = tensor([[-0.9240, -7.1867],
        [-1.4608, -1.2733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392829865217209
Epoch 0, Step 802: train/loss = 0.4927757978439331, train/raw-loss = 0.43923646211624146, train/logprobs = tensor([[-0.7296, -2.3839],
        [-0.8626, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08923225849866867
Epoch 0, Step 803: train/loss = 0.40439844131469727, train/raw-loss = 0.34590792655944824, train/logprobs = tensor([[-0.6701, -4.0820],
        [-0.9275, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09748414158821106
Epoch 0, Step 804: train/loss = 0.5249724984169006, train/raw-loss = 0.45272108912467957, train/logprobs = tensor([[-0.6990, -3.2211],
        [-0.9844, -0.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12041901051998138
Epoch 0, Step 805: train/loss = 0.5203137397766113, train/raw-loss = 0.4607492685317993, train/logprobs = tensor([[-0.5012, -2.4818],
        [-0.7412, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09927411377429962
Epoch 0, Step 806: train/loss = 0.43188685178756714, train/raw-loss = 0.3579001724720001, train/logprobs = tensor([[-0.8385, -5.4991],
        [-1.0959, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12331108748912811
Epoch 0, Step 807: train/loss = 0.37874898314476013, train/raw-loss = 0.30765020847320557, train/logprobs = tensor([[-0.7006, -6.5035],
        [-0.9921, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11849801242351532
Epoch 0, Step 808: train/loss = 0.37272322177886963, train/raw-loss = 0.30959367752075195, train/logprobs = tensor([[-0.5485, -3.8429],
        [-0.9074, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052158772945404
Epoch 0, Step 809: train/loss = 0.4049437642097473, train/raw-loss = 0.3325674831867218, train/logprobs = tensor([[-0.6242, -5.6751],
        [-0.9365, -0.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12062714248895645
Epoch 0, Step 810: train/loss = 0.36308541893959045, train/raw-loss = 0.28621235489845276, train/logprobs = tensor([[-0.5973, -4.4853],
        [-0.9584, -0.6807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281217634677887
Epoch 0, Step 811: train/loss = 0.5167772769927979, train/raw-loss = 0.44963669776916504, train/logprobs = tensor([[-0.6321, -3.4047],
        [-0.7647, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190102249383926
Epoch 0, Step 812: train/loss = 0.5732665061950684, train/raw-loss = 0.5146133303642273, train/logprobs = tensor([[-0.7339, -2.1727],
        [-0.9427, -0.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09775535017251968
Epoch 0, Step 813: train/loss = 0.5645720362663269, train/raw-loss = 0.5037510991096497, train/logprobs = tensor([[-0.7631, -1.7698],
        [-0.7070, -0.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10136821120977402
Epoch 0, Step 814: train/loss = 0.307883083820343, train/raw-loss = 0.24715128540992737, train/logprobs = tensor([[-0.7676, -5.2993],
        [-1.6174, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10121962428092957
Epoch 0, Step 815: train/loss = 0.49299412965774536, train/raw-loss = 0.4225226044654846, train/logprobs = tensor([[-0.7154, -2.5501],
        [-0.7809, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11745253205299377
Epoch 0, Step 816: train/loss = 0.3307986259460449, train/raw-loss = 0.2748802900314331, train/logprobs = tensor([[-0.3748, -7.0719],
        [-0.5410, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09319718182086945
Epoch 0, Step 817: train/loss = 0.4553847312927246, train/raw-loss = 0.38628315925598145, train/logprobs = tensor([[-0.9092, -5.0531],
        [-1.1979, -1.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11516928672790527
Epoch 0, Step 818: train/loss = 0.34396880865097046, train/raw-loss = 0.2762642502784729, train/logprobs = tensor([[-0.6239, -9.0059],
        [-1.0352, -1.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11284095048904419
Epoch 0, Step 819: train/loss = 0.4007335305213928, train/raw-loss = 0.34016335010528564, train/logprobs = tensor([[-0.3546, -4.3338],
        [-0.6678, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10095028579235077
Epoch 0, Step 820: train/loss = 0.45154470205307007, train/raw-loss = 0.3759855031967163, train/logprobs = tensor([[-0.8660, -3.4334],
        [-1.0036, -0.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12593194842338562
Epoch 0, Step 821: train/loss = 0.4738183319568634, train/raw-loss = 0.4056139886379242, train/logprobs = tensor([[-0.6532, -2.5872],
        [-1.0608, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1136738657951355
Epoch 0, Step 822: train/loss = 0.5135341882705688, train/raw-loss = 0.4540036618709564, train/logprobs = tensor([[-0.6913, -2.7558],
        [-0.8226, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09921756386756897
Epoch 0, Step 823: train/loss = 0.5152542591094971, train/raw-loss = 0.45739105343818665, train/logprobs = tensor([[-1.0048, -5.6623],
        [-0.8325, -1.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09643865376710892
Epoch 0, Step 824: train/loss = 0.41254812479019165, train/raw-loss = 0.3446338474750519, train/logprobs = tensor([[-0.5405, -5.2987],
        [-0.9116, -0.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11319044977426529
Epoch 0, Step 825: train/loss = 0.7265279293060303, train/raw-loss = 0.6665573120117188, train/logprobs = tensor([[-0.9247, -0.5560],
        [-1.1776, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995108842849731
Epoch 0, Step 826: train/loss = 0.424642950296402, train/raw-loss = 0.35175758600234985, train/logprobs = tensor([[-0.9164, -3.3644],
        [-1.2318, -1.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147559225559235
Epoch 0, Step 827: train/loss = 0.4621167480945587, train/raw-loss = 0.4012032747268677, train/logprobs = tensor([[-0.4766, -2.7247],
        [-0.6003, -0.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10152245312929153
Epoch 0, Step 828: train/loss = 0.3753693401813507, train/raw-loss = 0.2970222532749176, train/logprobs = tensor([[-0.7991, -3.4087],
        [-1.3320, -0.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13057848811149597
Epoch 0, Step 829: train/loss = 0.5519979596138, train/raw-loss = 0.48228853940963745, train/logprobs = tensor([[-0.9290, -3.5550],
        [-0.9791, -1.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11618238687515259
Epoch 0, Step 830: train/loss = 0.4169985353946686, train/raw-loss = 0.35878583788871765, train/logprobs = tensor([[-0.3893, -5.3028],
        [-0.6064, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09702122211456299
Epoch 0, Step 831: train/loss = 0.4028927981853485, train/raw-loss = 0.34774816036224365, train/logprobs = tensor([[-0.5620, -2.4018],
        [-0.8847, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09190770983695984
Epoch 0, Step 832: train/loss = 0.43911027908325195, train/raw-loss = 0.3726136088371277, train/logprobs = tensor([[-0.6673, -2.6830],
        [-1.2159, -0.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11082778871059418
Epoch 0, Step 833: train/loss = 0.6441357135772705, train/raw-loss = 0.583423912525177, train/logprobs = tensor([[-0.7016, -1.1768],
        [-0.6983, -0.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10118637979030609
Epoch 0, Step 834: train/loss = 0.3902667164802551, train/raw-loss = 0.3191404342651367, train/logprobs = tensor([[-0.9653, -6.5110],
        [-1.2755, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185438334941864
Epoch 0, Step 835: train/loss = 0.6495692729949951, train/raw-loss = 0.6012910604476929, train/logprobs = tensor([[-0.9200, -4.0123],
        [-0.8659, -1.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08046358823776245
Epoch 0, Step 836: train/loss = 0.4764799475669861, train/raw-loss = 0.4077005982398987, train/logprobs = tensor([[-0.6792, -5.2424],
        [-0.9109, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11463217437267303
Epoch 0, Step 837: train/loss = 0.4390842914581299, train/raw-loss = 0.37318697571754456, train/logprobs = tensor([[-0.4670, -2.6248],
        [-0.6918, -0.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.109828881919384
Epoch 0, Step 838: train/loss = 0.4379808306694031, train/raw-loss = 0.37150031328201294, train/logprobs = tensor([[-0.6912, -3.5022],
        [-0.8965, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080088466405869
Epoch 0, Step 839: train/loss = 0.3648173213005066, train/raw-loss = 0.3052372634410858, train/logprobs = tensor([[-0.5592, -5.0343],
        [-0.9738, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0993000864982605
Epoch 0, Step 840: train/loss = 0.3944864571094513, train/raw-loss = 0.31183135509490967, train/logprobs = tensor([[-0.6190, -6.2235],
        [-1.1631, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377585083246231
Epoch 0, Step 841: train/loss = 0.571333646774292, train/raw-loss = 0.5048600435256958, train/logprobs = tensor([[-0.6140, -2.2287],
        [-0.8273, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11078940331935883
Epoch 0, Step 842: train/loss = 0.4153171181678772, train/raw-loss = 0.34494927525520325, train/logprobs = tensor([[-0.5172, -6.2666],
        [-1.1240, -1.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11727972328662872
Epoch 0, Step 843: train/loss = 0.4427199363708496, train/raw-loss = 0.3733798861503601, train/logprobs = tensor([[-0.9337, -3.9666],
        [-0.8625, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11556674540042877
Epoch 0, Step 844: train/loss = 0.5101735591888428, train/raw-loss = 0.43841683864593506, train/logprobs = tensor([[-1.3503, -5.7380],
        [-1.0053, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1195944994688034
Epoch 0, Step 845: train/loss = 0.39564359188079834, train/raw-loss = 0.32450681924819946, train/logprobs = tensor([[-0.7347, -7.1040],
        [-1.1189, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11856132745742798
Epoch 0, Step 846: train/loss = 0.3718023896217346, train/raw-loss = 0.3125256597995758, train/logprobs = tensor([[-0.5352, -8.5056],
        [-0.8201, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09879452735185623
Epoch 0, Step 847: train/loss = 0.4625336527824402, train/raw-loss = 0.39892932772636414, train/logprobs = tensor([[-0.7871, -3.9411],
        [-1.0293, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10600721091032028
Epoch 0, Step 848: train/loss = 0.3271406292915344, train/raw-loss = 0.24484771490097046, train/logprobs = tensor([[-0.7719, -5.1772],
        [-1.4351, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13715489208698273
Epoch 0, Step 849: train/loss = 0.34060943126678467, train/raw-loss = 0.26879504323005676, train/logprobs = tensor([[-1.2384, -7.8944],
        [-1.4092, -1.2221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196906566619873
Epoch 0, Step 850: train/loss = 0.46355074644088745, train/raw-loss = 0.3971515893936157, train/logprobs = tensor([[-0.5635, -3.9880],
        [-0.7656, -1.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066529899835587
Epoch 0, Step 851: train/loss = 0.3937968909740448, train/raw-loss = 0.32361680269241333, train/logprobs = tensor([[-0.8499, -6.0914],
        [-1.3174, -1.0170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11696691811084747
Epoch 0, Step 852: train/loss = 0.4211205542087555, train/raw-loss = 0.3623006343841553, train/logprobs = tensor([[-0.4850, -4.0146],
        [-0.8954, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803315997123718
Epoch 0, Step 853: train/loss = 0.5925707817077637, train/raw-loss = 0.5355972647666931, train/logprobs = tensor([[-1.0750, -3.8148],
        [-1.2138, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949559360742569
Epoch 0, Step 854: train/loss = 0.41969162225723267, train/raw-loss = 0.34812384843826294, train/logprobs = tensor([[-0.7462, -5.0505],
        [-1.0769, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1192796528339386
Epoch 0, Step 855: train/loss = 0.435820072889328, train/raw-loss = 0.37231093645095825, train/logprobs = tensor([[-0.7789, -4.8390],
        [-1.1314, -1.4913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058485209941864
Epoch 0, Step 856: train/loss = 0.3341318368911743, train/raw-loss = 0.26398491859436035, train/logprobs = tensor([[-0.7640, -4.1108],
        [-1.3035, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11691153049468994
Epoch 0, Step 857: train/loss = 0.40325212478637695, train/raw-loss = 0.3258633017539978, train/logprobs = tensor([[-0.6295, -6.1330],
        [-1.1292, -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12898139655590057
Epoch 0, Step 858: train/loss = 0.6287719011306763, train/raw-loss = 0.5501931309700012, train/logprobs = tensor([[-1.7122, -2.9520],
        [-1.1923, -0.6754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1309647262096405
Epoch 0, Step 859: train/loss = 0.40831685066223145, train/raw-loss = 0.35011136531829834, train/logprobs = tensor([[-0.7646, -3.5609],
        [-1.1721, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09700918942689896
Epoch 0, Step 860: train/loss = 0.4779416024684906, train/raw-loss = 0.41399335861206055, train/logprobs = tensor([[-0.7416, -3.8743],
        [-0.9222, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658042132854462
Epoch 0, Step 861: train/loss = 0.6077294945716858, train/raw-loss = 0.5385525226593018, train/logprobs = tensor([[-0.8706, -3.5078],
        [-0.7932, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11529503017663956
Epoch 0, Step 862: train/loss = 0.40329504013061523, train/raw-loss = 0.3256654739379883, train/logprobs = tensor([[-0.7323, -5.8930],
        [-0.9462, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293826401233673
Epoch 0, Step 863: train/loss = 0.5635731220245361, train/raw-loss = 0.49197909235954285, train/logprobs = tensor([[-0.9036, -3.7865],
        [-0.9109, -0.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932341754436493
Epoch 0, Step 864: train/loss = 0.7051143646240234, train/raw-loss = 0.6365190148353577, train/logprobs = tensor([[-1.2260, -2.1935],
        [-0.8851, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11432556807994843
Epoch 0, Step 865: train/loss = 0.4121473431587219, train/raw-loss = 0.34224581718444824, train/logprobs = tensor([[-0.7335, -3.0437],
        [-1.0470, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11650253087282181
Epoch 0, Step 866: train/loss = 0.36831343173980713, train/raw-loss = 0.30216309428215027, train/logprobs = tensor([[-0.6394, -5.9001],
        [-0.7750, -1.1686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102505549788475
Epoch 0, Step 867: train/loss = 0.5911563634872437, train/raw-loss = 0.5280191898345947, train/logprobs = tensor([[-0.6853, -2.4454],
        [-0.9826, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522861778736115
Epoch 0, Step 868: train/loss = 0.5446982979774475, train/raw-loss = 0.4657506048679352, train/logprobs = tensor([[-0.8464, -1.7128],
        [-1.1149, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13157948851585388
Epoch 0, Step 869: train/loss = 0.41879451274871826, train/raw-loss = 0.3478972315788269, train/logprobs = tensor([[-0.7379, -1.9785],
        [-1.4554, -0.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11816218495368958
Epoch 0, Step 870: train/loss = 0.44691210985183716, train/raw-loss = 0.38684946298599243, train/logprobs = tensor([[-0.8661, -6.1720],
        [-1.1534, -1.3971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10010447353124619
Epoch 0, Step 871: train/loss = 0.38817912340164185, train/raw-loss = 0.32012248039245605, train/logprobs = tensor([[-0.5076, -5.3252],
        [-0.8321, -1.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342772841453552
Epoch 0, Step 872: train/loss = 0.5163368582725525, train/raw-loss = 0.46580275893211365, train/logprobs = tensor([[-0.3554, -2.9304],
        [-0.4842, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08422352373600006
Epoch 0, Step 873: train/loss = 0.4685531556606293, train/raw-loss = 0.4084152579307556, train/logprobs = tensor([[-0.8157, -3.7979],
        [-0.9725, -0.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10022979974746704
Epoch 0, Step 874: train/loss = 0.36834460496902466, train/raw-loss = 0.2790302634239197, train/logprobs = tensor([[-1.0504, -6.0779],
        [-1.5445, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488572359085083
Epoch 0, Step 875: train/loss = 0.6459717154502869, train/raw-loss = 0.5893251299858093, train/logprobs = tensor([[-0.7900, -1.0836],
        [-0.9714, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09441088140010834
Epoch 0, Step 876: train/loss = 0.4339907169342041, train/raw-loss = 0.38462895154953003, train/logprobs = tensor([[-0.3919, -6.4555],
        [-0.6089, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08226964622735977
Epoch 0, Step 877: train/loss = 0.49250030517578125, train/raw-loss = 0.41291898488998413, train/logprobs = tensor([[-1.3125, -4.9047],
        [-1.5475, -0.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13263550400733948
Epoch 0, Step 878: train/loss = 0.8684650659561157, train/raw-loss = 0.7973222136497498, train/logprobs = tensor([[-2.4221, -4.5916],
        [-1.2224, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11857134103775024
Epoch 0, Step 879: train/loss = 0.35232749581336975, train/raw-loss = 0.28662359714508057, train/logprobs = tensor([[-0.4711, -7.8003],
        [-0.8811, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10950645804405212
Epoch 0, Step 880: train/loss = 0.4028222858905792, train/raw-loss = 0.33602702617645264, train/logprobs = tensor([[-0.6064, -4.5237],
        [-0.8261, -0.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1113254502415657
Epoch 0, Step 881: train/loss = 0.532909631729126, train/raw-loss = 0.47138622403144836, train/logprobs = tensor([[-0.5285, -3.7135],
        [-0.7048, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10253909230232239
Epoch 0, Step 882: train/loss = 0.6045265197753906, train/raw-loss = 0.5414676666259766, train/logprobs = tensor([[-0.8021, -1.8811],
        [-0.7042, -0.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10509809851646423
Epoch 0, Step 883: train/loss = 0.4177628755569458, train/raw-loss = 0.34095534682273865, train/logprobs = tensor([[-1.0889, -3.2784],
        [-1.5797, -0.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280125379562378
Epoch 0, Step 884: train/loss = 0.3995087444782257, train/raw-loss = 0.32751011848449707, train/logprobs = tensor([[-0.6129, -4.1484],
        [-0.8673, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11999770998954773
Epoch 0, Step 885: train/loss = 0.3633061647415161, train/raw-loss = 0.2894149422645569, train/logprobs = tensor([[-0.9326, -4.9794],
        [-1.0899, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1231520026922226
Epoch 0, Step 886: train/loss = 0.5510952472686768, train/raw-loss = 0.48843830823898315, train/logprobs = tensor([[-0.6160, -2.7136],
        [-0.8212, -0.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10442829132080078
Epoch 0, Step 887: train/loss = 0.5072320699691772, train/raw-loss = 0.444597452878952, train/logprobs = tensor([[-0.6583, -4.1414],
        [-0.8535, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10439096391201019
Epoch 0, Step 888: train/loss = 0.2786789536476135, train/raw-loss = 0.204011470079422, train/logprobs = tensor([[-0.5853, -5.9207],
        [-1.1970, -1.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12444576621055603
Epoch 0, Step 889: train/loss = 0.4472510814666748, train/raw-loss = 0.37952232360839844, train/logprobs = tensor([[-0.7370, -3.2720],
        [-1.0117, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288131028413773
Epoch 0, Step 890: train/loss = 0.43018847703933716, train/raw-loss = 0.3538651764392853, train/logprobs = tensor([[-0.7441, -3.0197],
        [-1.0672, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272054761648178
Epoch 0, Step 891: train/loss = 0.343635231256485, train/raw-loss = 0.2825969457626343, train/logprobs = tensor([[-0.7579, -5.8359],
        [-1.1400, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10173041373491287
Epoch 0, Step 892: train/loss = 0.41074588894844055, train/raw-loss = 0.3367008566856384, train/logprobs = tensor([[-0.5611, -4.1588],
        [-0.9745, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12340839952230453
Epoch 0, Step 893: train/loss = 0.49686115980148315, train/raw-loss = 0.4338940978050232, train/logprobs = tensor([[-0.7256, -3.9466],
        [-0.9213, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10494507849216461
Epoch 0, Step 894: train/loss = 0.4007530212402344, train/raw-loss = 0.3249190151691437, train/logprobs = tensor([[-0.6607, -6.7081],
        [-0.9509, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12638993561267853
Epoch 0, Step 895: train/loss = 0.49396371841430664, train/raw-loss = 0.42741650342941284, train/logprobs = tensor([[-0.6849, -6.7469],
        [-1.0982, -2.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109120100736618
Epoch 0, Step 896: train/loss = 0.5779967308044434, train/raw-loss = 0.5163249373435974, train/logprobs = tensor([[-0.7923, -1.8678],
        [-0.8767, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10278626531362534
Epoch 0, Step 897: train/loss = 0.5005313754081726, train/raw-loss = 0.426931232213974, train/logprobs = tensor([[-0.8269, -3.0300],
        [-1.1281, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12266695499420166
Epoch 0, Step 898: train/loss = 0.5638652443885803, train/raw-loss = 0.5061399936676025, train/logprobs = tensor([[-0.6962, -1.3139],
        [-0.9161, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09620880335569382
Epoch 0, Step 899: train/loss = 0.478267103433609, train/raw-loss = 0.4029800295829773, train/logprobs = tensor([[-0.5727, -4.3436],
        [-0.8739, -1.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12547847628593445
Epoch 0, Step 900: train/loss = 0.3265557289123535, train/raw-loss = 0.2578384578227997, train/logprobs = tensor([[-1.0186, -9.7639],
        [-1.3227, -1.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11452876031398773
Epoch 0, Step 901: train/loss = 0.4034416973590851, train/raw-loss = 0.3379906117916107, train/logprobs = tensor([[-0.3840, -4.0624],
        [-0.7825, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10908517241477966
Epoch 0, Step 902: train/loss = 0.3079879879951477, train/raw-loss = 0.2391161322593689, train/logprobs = tensor([[-0.6327, -6.6749],
        [-1.1409, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478640139102936
Epoch 0, Step 903: train/loss = 0.4041459262371063, train/raw-loss = 0.3290508985519409, train/logprobs = tensor([[-0.8626, -3.6865],
        [-1.2847, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1251583844423294
Epoch 0, Step 904: train/loss = 0.48055499792099, train/raw-loss = 0.4196315109729767, train/logprobs = tensor([[-1.1621, -4.3604],
        [-1.2219, -1.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10153912007808685
Epoch 0, Step 905: train/loss = 0.3488762080669403, train/raw-loss = 0.2885000705718994, train/logprobs = tensor([[-0.4875, -6.8912],
        [-0.7835, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006268709897995
Epoch 0, Step 906: train/loss = 0.6622403860092163, train/raw-loss = 0.6083966493606567, train/logprobs = tensor([[-0.6285, -1.1311],
        [-0.5086, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08973954617977142
Epoch 0, Step 907: train/loss = 0.6307355165481567, train/raw-loss = 0.5744394063949585, train/logprobs = tensor([[-0.7481, -1.2798],
        [-0.6702, -0.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0938267931342125
Epoch 0, Step 908: train/loss = 0.3977617025375366, train/raw-loss = 0.32357704639434814, train/logprobs = tensor([[-0.6163, -4.8005],
        [-1.0332, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12364102900028229
Epoch 0, Step 909: train/loss = 0.3842930197715759, train/raw-loss = 0.29841315746307373, train/logprobs = tensor([[-1.0963, -3.8541],
        [-1.6499, -0.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14313307404518127
Epoch 0, Step 910: train/loss = 0.5723673105239868, train/raw-loss = 0.508941650390625, train/logprobs = tensor([[-0.9784, -3.7422],
        [-0.9863, -1.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10570936650037766
Epoch 0, Step 911: train/loss = 0.32983583211898804, train/raw-loss = 0.25896698236465454, train/logprobs = tensor([[-0.7415, -7.2966],
        [-0.9806, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11811475455760956
Epoch 0, Step 912: train/loss = 0.5594453811645508, train/raw-loss = 0.488919198513031, train/logprobs = tensor([[-1.2003, -5.0260],
        [-0.5442, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754365265369415
Epoch 0, Step 913: train/loss = 0.39404088258743286, train/raw-loss = 0.3241306245326996, train/logprobs = tensor([[-0.7041, -5.8816],
        [-1.1266, -1.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1165170967578888
Epoch 0, Step 914: train/loss = 0.5507198572158813, train/raw-loss = 0.48776891827583313, train/logprobs = tensor([[-0.3696, -1.9044],
        [-0.7461, -0.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049182340502739
Epoch 0, Step 915: train/loss = 0.4615722894668579, train/raw-loss = 0.3939581513404846, train/logprobs = tensor([[-0.7224, -2.9780],
        [-0.9729, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11269029974937439
Epoch 0, Step 916: train/loss = 0.44495877623558044, train/raw-loss = 0.3825024366378784, train/logprobs = tensor([[-1.0911, -3.0244],
        [-1.1043, -0.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10409384220838547
Epoch 0, Step 917: train/loss = 0.4667927026748657, train/raw-loss = 0.39217013120651245, train/logprobs = tensor([[-1.0255, -3.0531],
        [-1.1065, -0.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12437091022729874
Epoch 0, Step 918: train/loss = 0.5898374915122986, train/raw-loss = 0.5316371917724609, train/logprobs = tensor([[-0.5215, -1.2865],
        [-0.6932, -0.6656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09700050950050354
Epoch 0, Step 919: train/loss = 0.572960615158081, train/raw-loss = 0.5141462683677673, train/logprobs = tensor([[-0.9185, -2.8406],
        [-0.8199, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09802383929491043
Epoch 0, Step 920: train/loss = 0.6544483304023743, train/raw-loss = 0.6009104251861572, train/logprobs = tensor([[-0.7509, -0.7135],
        [-0.9596, -0.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0892297774553299
Epoch 0, Step 921: train/loss = 0.5997211337089539, train/raw-loss = 0.5447478890419006, train/logprobs = tensor([[-0.4561, -1.8930],
        [-0.7563, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09162206947803497
Epoch 0, Step 922: train/loss = 0.49516069889068604, train/raw-loss = 0.42905837297439575, train/logprobs = tensor([[-0.6193, -3.8614],
        [-0.6247, -0.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11017051339149475
Epoch 0, Step 923: train/loss = 0.4738829433917999, train/raw-loss = 0.40086954832077026, train/logprobs = tensor([[-0.9783, -4.0786],
        [-0.8929, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168895453214645
Epoch 0, Step 924: train/loss = 0.36489540338516235, train/raw-loss = 0.30042895674705505, train/logprobs = tensor([[-0.6500, -5.7960],
        [-1.2419, -1.3145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10744406282901764
Epoch 0, Step 925: train/loss = 0.5509627461433411, train/raw-loss = 0.5013507008552551, train/logprobs = tensor([[-0.4535, -1.6621],
        [-0.5254, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268672972917557
Epoch 0, Step 926: train/loss = 0.5703096985816956, train/raw-loss = 0.516531229019165, train/logprobs = tensor([[-0.4607, -1.9081],
        [-0.5981, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08963070809841156
Epoch 0, Step 927: train/loss = 0.601238489151001, train/raw-loss = 0.5264742970466614, train/logprobs = tensor([[-1.1979, -3.2409],
        [-0.9286, -0.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12460695207118988
Epoch 0, Step 928: train/loss = 0.407910019159317, train/raw-loss = 0.33514726161956787, train/logprobs = tensor([[-0.7237, -4.9994],
        [-0.8054, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12127122282981873
Epoch 0, Step 929: train/loss = 0.3657936453819275, train/raw-loss = 0.30008286237716675, train/logprobs = tensor([[-0.5241, -3.7587],
        [-1.1975, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951804369688034
Epoch 0, Step 930: train/loss = 0.5248960256576538, train/raw-loss = 0.4549780786037445, train/logprobs = tensor([[-0.7374, -1.9940],
        [-0.8977, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11652989685535431
Epoch 0, Step 931: train/loss = 0.400566428899765, train/raw-loss = 0.34520721435546875, train/logprobs = tensor([[-0.6106, -3.0009],
        [-0.9147, -0.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09226537495851517
Epoch 0, Step 932: train/loss = 0.44573917984962463, train/raw-loss = 0.36607521772384644, train/logprobs = tensor([[-0.4684, -3.5024],
        [-0.9981, -0.6056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13277320563793182
Epoch 0, Step 933: train/loss = 0.49835503101348877, train/raw-loss = 0.4418361783027649, train/logprobs = tensor([[-0.5717, -2.0424],
        [-0.8622, -0.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0941980630159378
Epoch 0, Step 934: train/loss = 0.5366055369377136, train/raw-loss = 0.4705803394317627, train/logprobs = tensor([[-0.4860, -2.5708],
        [-0.8362, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11004205048084259
Epoch 0, Step 935: train/loss = 0.4216318130493164, train/raw-loss = 0.3452521562576294, train/logprobs = tensor([[-0.8010, -3.5771],
        [-1.2443, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272994726896286
Epoch 0, Step 936: train/loss = 0.5326786041259766, train/raw-loss = 0.45952335000038147, train/logprobs = tensor([[-0.8377, -2.3305],
        [-1.0898, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12192542850971222
Epoch 0, Step 937: train/loss = 0.5453413724899292, train/raw-loss = 0.47691741585731506, train/logprobs = tensor([[-0.7665, -3.4355],
        [-0.8232, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11403989791870117
Epoch 0, Step 938: train/loss = 0.3941154479980469, train/raw-loss = 0.3073693513870239, train/logprobs = tensor([[-0.6881, -3.1811],
        [-1.2640, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445768177509308
Epoch 0, Step 939: train/loss = 0.43558573722839355, train/raw-loss = 0.3686993420124054, train/logprobs = tensor([[-0.8076, -3.8029],
        [-0.8150, -0.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11147730052471161
Epoch 0, Step 940: train/loss = 0.3318858742713928, train/raw-loss = 0.24894577264785767, train/logprobs = tensor([[-0.7151, -3.7402],
        [-1.3978, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13823343813419342
Epoch 0, Step 941: train/loss = 0.4322095513343811, train/raw-loss = 0.37364351749420166, train/logprobs = tensor([[-0.7018, -3.7849],
        [-1.0422, -0.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761011600494385
Epoch 0, Step 942: train/loss = 0.5020632743835449, train/raw-loss = 0.420166015625, train/logprobs = tensor([[-0.9285, -3.7016],
        [-1.2487, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.136495441198349
Epoch 0, Step 943: train/loss = 0.39788818359375, train/raw-loss = 0.32181239128112793, train/logprobs = tensor([[-0.7269, -2.8379],
        [-1.4308, -0.7198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12679293751716614
Epoch 0, Step 944: train/loss = 0.2745503783226013, train/raw-loss = 0.19798395037651062, train/logprobs = tensor([[-0.6202, -7.0962],
        [-1.3683, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1276107281446457
Epoch 0, Step 945: train/loss = 0.5172078013420105, train/raw-loss = 0.46075522899627686, train/logprobs = tensor([[-1.0722, -3.1783],
        [-0.9628, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408757835626602
Epoch 0, Step 946: train/loss = 0.45054149627685547, train/raw-loss = 0.38181445002555847, train/logprobs = tensor([[-0.7162, -5.7261],
        [-1.1070, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114545077085495
Epoch 0, Step 947: train/loss = 0.7395368218421936, train/raw-loss = 0.6864145994186401, train/logprobs = tensor([[-0.6902, -0.6891],
        [-0.6756, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08853702992200851
Epoch 0, Step 948: train/loss = 0.4700663983821869, train/raw-loss = 0.3904198408126831, train/logprobs = tensor([[-0.6212, -2.7018],
        [-0.9194, -0.5239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13274426758289337
Epoch 0, Step 949: train/loss = 0.5359543561935425, train/raw-loss = 0.46764928102493286, train/logprobs = tensor([[-0.8005, -2.7985],
        [-0.9744, -0.7164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11384180188179016
Epoch 0, Step 950: train/loss = 0.3636605441570282, train/raw-loss = 0.2979923188686371, train/logprobs = tensor([[-0.4194, -3.3390],
        [-1.0925, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10944704711437225
Epoch 0, Step 951: train/loss = 0.6202453374862671, train/raw-loss = 0.5457873344421387, train/logprobs = tensor([[-1.3576, -3.4509],
        [-0.9483, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12409656494855881
Epoch 0, Step 952: train/loss = 0.4509022831916809, train/raw-loss = 0.3928162455558777, train/logprobs = tensor([[-0.3423, -3.8558],
        [-0.6539, -0.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09681008756160736
Epoch 0, Step 953: train/loss = 0.560422420501709, train/raw-loss = 0.4945550560951233, train/logprobs = tensor([[-0.6882, -2.0211],
        [-0.8382, -0.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977896302938461
Epoch 0, Step 954: train/loss = 0.5471274852752686, train/raw-loss = 0.4884507358074188, train/logprobs = tensor([[-0.6418, -1.4919],
        [-0.8225, -0.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779459238052368
Epoch 0, Step 955: train/loss = 0.3872218132019043, train/raw-loss = 0.3156023919582367, train/logprobs = tensor([[-0.7363, -6.0658],
        [-1.0251, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193656474351883
Epoch 0, Step 956: train/loss = 0.4114767909049988, train/raw-loss = 0.35080617666244507, train/logprobs = tensor([[-0.5101, -3.2217],
        [-0.8898, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10111772269010544
Epoch 0, Step 957: train/loss = 0.48445791006088257, train/raw-loss = 0.4237219989299774, train/logprobs = tensor([[-0.9231, -4.9862],
        [-1.0964, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10122652351856232
Epoch 0, Step 958: train/loss = 0.49800339341163635, train/raw-loss = 0.4291154146194458, train/logprobs = tensor([[-0.7661, -4.5962],
        [-0.7472, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11481331288814545
Epoch 0, Step 959: train/loss = 0.4523434638977051, train/raw-loss = 0.38903483748435974, train/logprobs = tensor([[-0.5716, -3.8615],
        [-0.9364, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551442950963974
Epoch 0, Step 960: train/loss = 0.5992305278778076, train/raw-loss = 0.5457978844642639, train/logprobs = tensor([[-0.5620, -1.1721],
        [-0.8648, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08905433118343353
Epoch 0, Step 961: train/loss = 0.3717298209667206, train/raw-loss = 0.3029431998729706, train/logprobs = tensor([[-0.8303, -3.5477],
        [-1.3780, -0.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1146443635225296
Epoch 0, Step 962: train/loss = 0.54168701171875, train/raw-loss = 0.48003846406936646, train/logprobs = tensor([[-1.3625, -4.8575],
        [-1.3987, -1.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10274755209684372
Epoch 0, Step 963: train/loss = 0.5345182418823242, train/raw-loss = 0.471277117729187, train/logprobs = tensor([[-0.5625, -1.6062],
        [-0.8004, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10540197789669037
Epoch 0, Step 964: train/loss = 0.505939245223999, train/raw-loss = 0.4324697256088257, train/logprobs = tensor([[-0.6744, -2.7310],
        [-1.0286, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12244926393032074
Epoch 0, Step 965: train/loss = 0.41001659631729126, train/raw-loss = 0.34977567195892334, train/logprobs = tensor([[-0.8166, -3.8648],
        [-1.1248, -1.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10040160268545151
Epoch 0, Step 966: train/loss = 0.4815260171890259, train/raw-loss = 0.420642614364624, train/logprobs = tensor([[-0.4296, -2.3997],
        [-0.9214, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10147233307361603
Epoch 0, Step 967: train/loss = 0.4886621832847595, train/raw-loss = 0.4314422011375427, train/logprobs = tensor([[-0.4944, -2.3382],
        [-0.8357, -0.4058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09536664932966232
Epoch 0, Step 968: train/loss = 0.4965816140174866, train/raw-loss = 0.43843138217926025, train/logprobs = tensor([[-0.8659, -2.6025],
        [-1.4547, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096917062997818
Epoch 0, Step 969: train/loss = 0.4053356349468231, train/raw-loss = 0.3288019299507141, train/logprobs = tensor([[-0.5194, -4.8012],
        [-1.1586, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12755617499351501
Epoch 0, Step 970: train/loss = 0.49639567732810974, train/raw-loss = 0.4316328465938568, train/logprobs = tensor([[-0.5528, -2.4349],
        [-0.7826, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10793806612491608
Epoch 0, Step 971: train/loss = 0.46005165576934814, train/raw-loss = 0.3925696313381195, train/logprobs = tensor([[-0.2940, -3.9595],
        [-0.6754, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246998608112335
Epoch 0, Step 972: train/loss = 0.49003273248672485, train/raw-loss = 0.4298483729362488, train/logprobs = tensor([[-0.6286, -4.6848],
        [-0.7837, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10030724108219147
Epoch 0, Step 973: train/loss = 0.5732491612434387, train/raw-loss = 0.5139031410217285, train/logprobs = tensor([[-0.5711, -2.0711],
        [-0.8427, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09891006350517273
Epoch 0, Step 974: train/loss = 0.4689086079597473, train/raw-loss = 0.3983266353607178, train/logprobs = tensor([[-0.7280, -3.4777],
        [-1.0779, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11763660609722137
Epoch 0, Step 975: train/loss = 0.4042168855667114, train/raw-loss = 0.33097636699676514, train/logprobs = tensor([[-0.4651, -3.1666],
        [-0.7443, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206754088401794
Epoch 0, Step 976: train/loss = 0.5388022661209106, train/raw-loss = 0.46602052450180054, train/logprobs = tensor([[-0.3911, -2.6043],
        [-0.9621, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12130294740200043
Epoch 0, Step 977: train/loss = 0.5086500644683838, train/raw-loss = 0.4414568543434143, train/logprobs = tensor([[-0.6827, -3.2051],
        [-0.8699, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11198870837688446
Epoch 0, Step 978: train/loss = 0.49001049995422363, train/raw-loss = 0.4107840955257416, train/logprobs = tensor([[-1.1075, -3.2633],
        [-1.0691, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320439875125885
Epoch 0, Step 979: train/loss = 0.46974048018455505, train/raw-loss = 0.41332900524139404, train/logprobs = tensor([[-0.4822, -2.7584],
        [-0.8647, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940191000699997
Epoch 0, Step 980: train/loss = 0.35644739866256714, train/raw-loss = 0.29283568263053894, train/logprobs = tensor([[-0.5872, -3.3182],
        [-0.9821, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10601947456598282
Epoch 0, Step 981: train/loss = 0.4323730170726776, train/raw-loss = 0.36609774827957153, train/logprobs = tensor([[-0.8574, -4.4871],
        [-1.4186, -1.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11045879125595093
Epoch 0, Step 982: train/loss = 0.40068623423576355, train/raw-loss = 0.3369808793067932, train/logprobs = tensor([[-0.5908, -2.8377],
        [-0.9568, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617557913064957
Epoch 0, Step 983: train/loss = 0.4719126522541046, train/raw-loss = 0.40770527720451355, train/logprobs = tensor([[-0.7316, -2.9081],
        [-0.9325, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10701225697994232
Epoch 0, Step 984: train/loss = 0.5137318968772888, train/raw-loss = 0.4410078227519989, train/logprobs = tensor([[-0.4893, -1.8650],
        [-1.0595, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12120670080184937
Epoch 0, Step 985: train/loss = 0.5949140787124634, train/raw-loss = 0.5402472615242004, train/logprobs = tensor([[-0.5916, -1.2386],
        [-0.7509, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111131727695465
Epoch 0, Step 986: train/loss = 0.28814107179641724, train/raw-loss = 0.21392852067947388, train/logprobs = tensor([[-0.6256, -7.2527],
        [-1.3508, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12368753552436829
Epoch 0, Step 987: train/loss = 0.5428308844566345, train/raw-loss = 0.48345816135406494, train/logprobs = tensor([[-0.9135, -1.8286],
        [-0.9954, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09895449876785278
Epoch 0, Step 988: train/loss = 0.581758975982666, train/raw-loss = 0.508669376373291, train/logprobs = tensor([[-0.5793, -1.9360],
        [-1.6083, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12181602418422699
Epoch 0, Step 989: train/loss = 0.4206801652908325, train/raw-loss = 0.35097774863243103, train/logprobs = tensor([[-0.7187, -2.6402],
        [-1.0715, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11617066711187363
Epoch 0, Step 990: train/loss = 0.5107585191726685, train/raw-loss = 0.45043814182281494, train/logprobs = tensor([[-0.4688, -2.4915],
        [-0.7013, -0.5825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10053402185440063
Epoch 0, Step 991: train/loss = 0.6114429235458374, train/raw-loss = 0.5527864098548889, train/logprobs = tensor([[-0.5307, -1.0521],
        [-0.6783, -0.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977608859539032
Epoch 0, Step 992: train/loss = 0.445995032787323, train/raw-loss = 0.3812767267227173, train/logprobs = tensor([[-0.4603, -3.2500],
        [-0.7748, -0.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10786377638578415
Epoch 0, Step 993: train/loss = 0.41278427839279175, train/raw-loss = 0.3470008969306946, train/logprobs = tensor([[-0.5076, -2.3743],
        [-1.0616, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.109639011323452
Epoch 0, Step 994: train/loss = 0.30531153082847595, train/raw-loss = 0.22872726619243622, train/logprobs = tensor([[-0.7322, -4.4900],
        [-1.3393, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12764042615890503
Epoch 0, Step 995: train/loss = 0.2965572476387024, train/raw-loss = 0.23481452465057373, train/logprobs = tensor([[-0.4449, -4.6334],
        [-0.8348, -0.6835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10290458798408508
Epoch 0, Step 996: train/loss = 0.5421261191368103, train/raw-loss = 0.488158255815506, train/logprobs = tensor([[-0.4897, -3.7352],
        [-0.7794, -1.2340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08994635939598083
Epoch 0, Step 997: train/loss = 0.339569091796875, train/raw-loss = 0.27519381046295166, train/logprobs = tensor([[-0.6058, -4.4832],
        [-0.8318, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072920560836792
Epoch 0, Step 998: train/loss = 0.4042102098464966, train/raw-loss = 0.31533169746398926, train/logprobs = tensor([[-0.5547, -2.9178],
        [-1.3923, -0.6506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.148130863904953
Epoch 0, Step 999: train/loss = 0.5293880105018616, train/raw-loss = 0.4722028076648712, train/logprobs = tensor([[-0.5312, -1.8445],
        [-0.9516, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530869126319885
Epoch 0, Step 1000: train/loss = 0.5389864444732666, train/raw-loss = 0.4576510787010193, train/logprobs = tensor([[-0.8613, -2.0272],
        [-1.4151, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13555897772312164
Epoch 0, Step 1001: train/loss = 0.45036858320236206, train/raw-loss = 0.3792673349380493, train/logprobs = tensor([[-0.5787, -3.0185],
        [-1.1599, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11850211769342422
Epoch 0, Step 1002: train/loss = 0.49327629804611206, train/raw-loss = 0.41582703590393066, train/logprobs = tensor([[-0.4741, -4.0372],
        [-1.1274, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12908212840557098
Epoch 0, Step 1003: train/loss = 0.4722658097743988, train/raw-loss = 0.3946458101272583, train/logprobs = tensor([[-1.0602, -3.4493],
        [-1.1458, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293666660785675
Epoch 0, Step 1004: train/loss = 0.6586452722549438, train/raw-loss = 0.6012372970581055, train/logprobs = tensor([[-0.5666, -0.8459],
        [-0.7091, -0.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09568000584840775
Epoch 0, Step 1005: train/loss = 0.28226912021636963, train/raw-loss = 0.21381334960460663, train/logprobs = tensor([[-0.6799, -6.5314],
        [-1.2888, -1.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11409291625022888
Epoch 0, Step 1006: train/loss = 0.5950644612312317, train/raw-loss = 0.5385604500770569, train/logprobs = tensor([[-0.6693, -1.2403],
        [-0.9699, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09417328238487244
Epoch 0, Step 1007: train/loss = 0.5708511471748352, train/raw-loss = 0.5136425495147705, train/logprobs = tensor([[-1.2377, -1.7388],
        [-1.4023, -0.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09534759074449539
Epoch 0, Step 1008: train/loss = 0.49197471141815186, train/raw-loss = 0.4258054494857788, train/logprobs = tensor([[-0.5100, -3.6716],
        [-0.9000, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11028207838535309
Epoch 0, Step 1009: train/loss = 0.49634572863578796, train/raw-loss = 0.4282914400100708, train/logprobs = tensor([[-0.6479, -4.6759],
        [-1.2631, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342377215623856
Epoch 0, Step 1010: train/loss = 0.5208282470703125, train/raw-loss = 0.4508153796195984, train/logprobs = tensor([[-0.7930, -3.4871],
        [-0.8363, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11668810993432999
Epoch 0, Step 1011: train/loss = 0.585780143737793, train/raw-loss = 0.5212748050689697, train/logprobs = tensor([[-0.4985, -1.5109],
        [-0.9427, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10750895738601685
Epoch 0, Step 1012: train/loss = 0.35144221782684326, train/raw-loss = 0.2813345789909363, train/logprobs = tensor([[-0.6304, -3.9226],
        [-1.3052, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11684608459472656
Epoch 0, Step 1013: train/loss = 0.28170323371887207, train/raw-loss = 0.18844398856163025, train/logprobs = tensor([[-0.8384, -6.1368],
        [-2.0115, -0.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15543203055858612
Epoch 0, Step 1014: train/loss = 0.4754858613014221, train/raw-loss = 0.404451459646225, train/logprobs = tensor([[-0.7129, -3.1280],
        [-1.0726, -0.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11839069426059723
Epoch 0, Step 1015: train/loss = 0.3489118814468384, train/raw-loss = 0.2761121392250061, train/logprobs = tensor([[-0.4900, -3.9777],
        [-1.3210, -0.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12133293598890305
Epoch 0, Step 1016: train/loss = 0.49695703387260437, train/raw-loss = 0.4250340163707733, train/logprobs = tensor([[-0.8093, -4.8771],
        [-1.1170, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11987166106700897
Epoch 0, Step 1017: train/loss = 0.40654072165489197, train/raw-loss = 0.3385215997695923, train/logprobs = tensor([[-0.5380, -5.6661],
        [-0.8442, -1.1436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11336516588926315
Epoch 0, Step 1018: train/loss = 0.5055837035179138, train/raw-loss = 0.44101911783218384, train/logprobs = tensor([[-0.6787, -3.0086],
        [-0.9667, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076076328754425
Epoch 0, Step 1019: train/loss = 0.43040528893470764, train/raw-loss = 0.35925590991973877, train/logprobs = tensor([[-0.9303, -4.2116],
        [-1.3333, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11858230829238892
Epoch 0, Step 1020: train/loss = 0.47159671783447266, train/raw-loss = 0.4083435535430908, train/logprobs = tensor([[-0.7088, -5.4178],
        [-0.7638, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10542184114456177
Epoch 0, Step 1021: train/loss = 0.3871820271015167, train/raw-loss = 0.3196674883365631, train/logprobs = tensor([[-0.5207, -4.4975],
        [-1.0183, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11252424120903015
Epoch 0, Step 1022: train/loss = 0.5336133241653442, train/raw-loss = 0.48473989963531494, train/logprobs = tensor([[-0.4672, -1.2976],
        [-0.8718, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08145571500062943
Epoch 0, Step 1023: train/loss = 0.5886878967285156, train/raw-loss = 0.52649986743927, train/logprobs = tensor([[-0.4919, -1.8340],
        [-1.0216, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10364683717489243
Epoch 0, Step 1024: train/loss = 0.46364668011665344, train/raw-loss = 0.39356446266174316, train/logprobs = tensor([[-0.7966, -3.7787],
        [-0.9231, -0.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11680371314287186
Epoch 0, Step 1025: train/loss = 0.42360255122184753, train/raw-loss = 0.3656372129917145, train/logprobs = tensor([[-0.6783, -3.3976],
        [-1.0064, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09660889208316803
Epoch 0, Step 1026: train/loss = 0.41313230991363525, train/raw-loss = 0.33189693093299866, train/logprobs = tensor([[-0.6456, -3.4437],
        [-1.0722, -0.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13539233803749084
Epoch 0, Step 1027: train/loss = 0.6847561001777649, train/raw-loss = 0.63503098487854, train/logprobs = tensor([[-0.5114, -0.8299],
        [-0.6586, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08287511765956879
Epoch 0, Step 1028: train/loss = 0.4054180979728699, train/raw-loss = 0.3526730537414551, train/logprobs = tensor([[-0.7370, -4.5345],
        [-1.5000, -1.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08790838718414307
Epoch 0, Step 1029: train/loss = 0.5885290503501892, train/raw-loss = 0.5273547768592834, train/logprobs = tensor([[-0.3766, -1.8978],
        [-0.6719, -0.6231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10195714235305786
Epoch 0, Step 1030: train/loss = 0.39673811197280884, train/raw-loss = 0.3271650969982147, train/logprobs = tensor([[-0.6292, -5.2942],
        [-1.4593, -1.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11595502495765686
Epoch 0, Step 1031: train/loss = 0.5112528204917908, train/raw-loss = 0.44847753643989563, train/logprobs = tensor([[-0.6109, -2.0439],
        [-0.8805, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10462544858455658
Epoch 0, Step 1032: train/loss = 0.5147675275802612, train/raw-loss = 0.4565720856189728, train/logprobs = tensor([[-0.6437, -1.9300],
        [-1.2365, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699245542287827
Epoch 0, Step 1033: train/loss = 0.3719334900379181, train/raw-loss = 0.2861720025539398, train/logprobs = tensor([[-0.9161, -4.3571],
        [-1.8274, -0.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14293581247329712
Epoch 0, Step 1034: train/loss = 0.43026721477508545, train/raw-loss = 0.3705598711967468, train/logprobs = tensor([[-0.6642, -2.2049],
        [-1.1799, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09951221197843552
Epoch 0, Step 1035: train/loss = 0.5458357930183411, train/raw-loss = 0.46647271513938904, train/logprobs = tensor([[-0.7474, -2.3388],
        [-1.3172, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13227184116840363
Epoch 0, Step 1036: train/loss = 0.5645453929901123, train/raw-loss = 0.501594066619873, train/logprobs = tensor([[-0.4968, -2.0308],
        [-0.8851, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10491885244846344
Epoch 0, Step 1037: train/loss = 0.5506027340888977, train/raw-loss = 0.4884183704853058, train/logprobs = tensor([[-0.5543, -2.9005],
        [-1.1063, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10364057868719101
Epoch 0, Step 1038: train/loss = 0.43967604637145996, train/raw-loss = 0.3659338355064392, train/logprobs = tensor([[-0.8450, -4.2146],
        [-1.2048, -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12290365993976593
Epoch 0, Step 1039: train/loss = 0.359314501285553, train/raw-loss = 0.2894824147224426, train/logprobs = tensor([[-0.6518, -7.6210],
        [-1.3249, -2.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11638680100440979
Epoch 0, Step 1040: train/loss = 0.5108740925788879, train/raw-loss = 0.45277073979377747, train/logprobs = tensor([[-1.3160, -3.5770],
        [-1.4391, -1.3780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09683893620967865
Epoch 0, Step 1041: train/loss = 0.378322958946228, train/raw-loss = 0.29841846227645874, train/logprobs = tensor([[-0.7741, -6.0877],
        [-1.2110, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13317415118217468
Epoch 0, Step 1042: train/loss = 0.5215603709220886, train/raw-loss = 0.4713404178619385, train/logprobs = tensor([[-0.6613, -2.4139],
        [-0.6785, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08369997888803482
Epoch 0, Step 1043: train/loss = 0.6719918251037598, train/raw-loss = 0.6174242496490479, train/logprobs = tensor([[-0.9803, -1.3469],
        [-0.8531, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09094604849815369
Epoch 0, Step 1044: train/loss = 0.5682822465896606, train/raw-loss = 0.5034206509590149, train/logprobs = tensor([[-0.8734, -1.4300],
        [-1.4656, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10810268670320511
Epoch 0, Step 1045: train/loss = 0.46845585107803345, train/raw-loss = 0.4102248251438141, train/logprobs = tensor([[-0.5509, -3.3358],
        [-0.9378, -0.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09705167263746262
Epoch 0, Step 1046: train/loss = 0.4658839702606201, train/raw-loss = 0.39736437797546387, train/logprobs = tensor([[-0.5111, -3.4298],
        [-0.8984, -0.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11419933289289474
Epoch 0, Step 1047: train/loss = 0.5528283715248108, train/raw-loss = 0.48814958333969116, train/logprobs = tensor([[-0.5671, -1.3334],
        [-0.9251, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1077980101108551
Epoch 0, Step 1048: train/loss = 0.2774755358695984, train/raw-loss = 0.2076389193534851, train/logprobs = tensor([[-0.5923, -7.4545],
        [-1.2239, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11639439314603806
Epoch 0, Step 1049: train/loss = 0.3893852233886719, train/raw-loss = 0.312908798456192, train/logprobs = tensor([[-0.7012, -2.9999],
        [-1.4414, -0.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12746065855026245
Epoch 0, Step 1050: train/loss = 0.5586304664611816, train/raw-loss = 0.5007362961769104, train/logprobs = tensor([[-0.5060, -1.0519],
        [-0.9400, -0.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649035334587097
Epoch 0, Step 1051: train/loss = 0.6241478323936462, train/raw-loss = 0.578767716884613, train/logprobs = tensor([[-0.5396, -1.1703],
        [-0.6565, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07563348859548569
Epoch 0, Step 1052: train/loss = 0.39887112379074097, train/raw-loss = 0.3399721384048462, train/logprobs = tensor([[-0.5356, -3.1533],
        [-0.8675, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09816499054431915
Epoch 0, Step 1053: train/loss = 0.346538245677948, train/raw-loss = 0.2840263545513153, train/logprobs = tensor([[-0.5397, -3.9447],
        [-1.2124, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10418643057346344
Epoch 0, Step 1054: train/loss = 0.5225188136100769, train/raw-loss = 0.46687382459640503, train/logprobs = tensor([[-0.8799, -1.9982],
        [-1.0868, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09274175763130188
Epoch 0, Step 1055: train/loss = 0.5134807825088501, train/raw-loss = 0.4472496211528778, train/logprobs = tensor([[-0.8290, -3.4193],
        [-1.3015, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11038528382778168
Epoch 0, Step 1056: train/loss = 0.46541017293930054, train/raw-loss = 0.4083499014377594, train/logprobs = tensor([[-0.6141, -3.5852],
        [-0.7880, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09510044753551483
Epoch 0, Step 1057: train/loss = 0.40000930428504944, train/raw-loss = 0.33974316716194153, train/logprobs = tensor([[-0.4977, -5.2955],
        [-1.1389, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10044355690479279
Epoch 0, Step 1058: train/loss = 0.39254358410835266, train/raw-loss = 0.32123512029647827, train/logprobs = tensor([[-0.5245, -2.9773],
        [-1.2052, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11884741485118866
Epoch 0, Step 1059: train/loss = 0.6233845353126526, train/raw-loss = 0.555332362651825, train/logprobs = tensor([[-0.5445, -1.3127],
        [-0.7789, -0.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1134202778339386
Epoch 0, Step 1060: train/loss = 0.5913005471229553, train/raw-loss = 0.5311270356178284, train/logprobs = tensor([[-0.6073, -1.6767],
        [-1.0254, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10028905421495438
Epoch 0, Step 1061: train/loss = 0.510405421257019, train/raw-loss = 0.44116440415382385, train/logprobs = tensor([[-0.6435, -4.0060],
        [-1.1129, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11540162563323975
Epoch 0, Step 1062: train/loss = 0.5167608857154846, train/raw-loss = 0.43970876932144165, train/logprobs = tensor([[-0.7030, -2.3842],
        [-1.3093, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284201741218567
Epoch 0, Step 1063: train/loss = 0.5942067503929138, train/raw-loss = 0.5396458506584167, train/logprobs = tensor([[-0.9958, -2.0769],
        [-0.8270, -0.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09093480557203293
Epoch 0, Step 1064: train/loss = 0.4380508065223694, train/raw-loss = 0.36812305450439453, train/logprobs = tensor([[-0.5964, -4.7166],
        [-1.0008, -1.1959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11654618382453918
Epoch 0, Step 1065: train/loss = 0.5431225895881653, train/raw-loss = 0.4806285798549652, train/logprobs = tensor([[-0.5642, -1.7520],
        [-0.9474, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10415664315223694
Epoch 0, Step 1066: train/loss = 0.4691145420074463, train/raw-loss = 0.4117651581764221, train/logprobs = tensor([[-1.3493, -3.5536],
        [-1.4064, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09558237344026566
Epoch 0, Step 1067: train/loss = 0.24810010194778442, train/raw-loss = 0.1770860105752945, train/logprobs = tensor([[-0.7773, -7.3897],
        [-1.6942, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11835682392120361
Epoch 0, Step 1068: train/loss = 0.4533064365386963, train/raw-loss = 0.3907143771648407, train/logprobs = tensor([[-0.4997, -2.5539],
        [-0.9639, -0.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10432009398937225
Epoch 0, Step 1069: train/loss = 0.5957030057907104, train/raw-loss = 0.5308548212051392, train/logprobs = tensor([[-1.0177, -4.7735],
        [-0.9387, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10808028280735016
Epoch 0, Step 1070: train/loss = 0.38988196849823, train/raw-loss = 0.3139377534389496, train/logprobs = tensor([[-0.6099, -3.9550],
        [-1.1057, -1.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265736073255539
Epoch 0, Step 1071: train/loss = 0.2658846378326416, train/raw-loss = 0.1939382255077362, train/logprobs = tensor([[-0.6052, -5.5421],
        [-1.4314, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11991066485643387
Epoch 0, Step 1072: train/loss = 0.28253674507141113, train/raw-loss = 0.21459145843982697, train/logprobs = tensor([[-0.5564, -6.0585],
        [-1.1772, -1.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11324214935302734
Epoch 0, Step 1073: train/loss = 0.462200790643692, train/raw-loss = 0.39396101236343384, train/logprobs = tensor([[-0.6453, -3.7298],
        [-1.1162, -1.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11373291909694672
Epoch 0, Step 1074: train/loss = 0.45592111349105835, train/raw-loss = 0.39150524139404297, train/logprobs = tensor([[-0.4943, -4.3733],
        [-0.9171, -1.1528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10735982656478882
Epoch 0, Step 1075: train/loss = 0.4717947244644165, train/raw-loss = 0.41732057929039, train/logprobs = tensor([[-0.4659, -3.0414],
        [-0.6697, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0907902792096138
Epoch 0, Step 1076: train/loss = 0.4429323673248291, train/raw-loss = 0.3640071749687195, train/logprobs = tensor([[-0.4978, -3.2295],
        [-1.0761, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13154198229312897
Epoch 0, Step 1077: train/loss = 0.4470781683921814, train/raw-loss = 0.3843165338039398, train/logprobs = tensor([[-0.4561, -3.1193],
        [-0.9886, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10460267961025238
Epoch 0, Step 1078: train/loss = 0.515518307685852, train/raw-loss = 0.45738109946250916, train/logprobs = tensor([[-0.7810, -2.2461],
        [-1.1493, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968952625989914
Epoch 0, Step 1079: train/loss = 0.34455645084381104, train/raw-loss = 0.26969611644744873, train/logprobs = tensor([[-0.4914, -6.1246],
        [-0.9815, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1247672289609909
Epoch 0, Step 1080: train/loss = 0.5489692091941833, train/raw-loss = 0.48630234599113464, train/logprobs = tensor([[-0.6204, -2.4247],
        [-1.0047, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044447273015976
Epoch 0, Step 1081: train/loss = 0.32889121770858765, train/raw-loss = 0.26389002799987793, train/logprobs = tensor([[-1.0323, -4.4207],
        [-1.2749, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10833533108234406
Epoch 0, Step 1082: train/loss = 0.6510905623435974, train/raw-loss = 0.5915250182151794, train/logprobs = tensor([[-0.6692, -1.0704],
        [-1.0215, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992758572101593
Epoch 0, Step 1083: train/loss = 0.5547138452529907, train/raw-loss = 0.47731301188468933, train/logprobs = tensor([[-0.7813, -2.5627],
        [-1.2016, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290014237165451
Epoch 0, Step 1084: train/loss = 0.5053293704986572, train/raw-loss = 0.4435420632362366, train/logprobs = tensor([[-0.4681, -2.5661],
        [-0.8541, -0.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10297885537147522
Epoch 0, Step 1085: train/loss = 0.5460390448570251, train/raw-loss = 0.4915132224559784, train/logprobs = tensor([[-0.5918, -2.0664],
        [-0.9342, -0.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09087631851434708
Epoch 0, Step 1086: train/loss = 0.4291081428527832, train/raw-loss = 0.36005347967147827, train/logprobs = tensor([[-0.6126, -4.7206],
        [-1.1219, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11509108543395996
Epoch 0, Step 1087: train/loss = 0.4027976095676422, train/raw-loss = 0.3474747836589813, train/logprobs = tensor([[-0.5301, -4.5628],
        [-0.7026, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09220471233129501
Epoch 0, Step 1088: train/loss = 0.5281838774681091, train/raw-loss = 0.46308013796806335, train/logprobs = tensor([[-0.8902, -2.1523],
        [-1.1686, -0.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10850616544485092
Epoch 0, Step 1089: train/loss = 0.5371495485305786, train/raw-loss = 0.4853033423423767, train/logprobs = tensor([[-0.6277, -2.0096],
        [-0.7678, -0.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08641035854816437
Epoch 0, Step 1090: train/loss = 0.38292425870895386, train/raw-loss = 0.3194003105163574, train/logprobs = tensor([[-0.4738, -3.2037],
        [-1.2435, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10587324947118759
Epoch 0, Step 1091: train/loss = 0.38292738795280457, train/raw-loss = 0.3249012529850006, train/logprobs = tensor([[-0.5047, -2.9757],
        [-1.0814, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096710205078125
Epoch 0, Step 1092: train/loss = 0.44460561871528625, train/raw-loss = 0.37838372588157654, train/logprobs = tensor([[-0.6959, -2.5871],
        [-0.9799, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11036986112594604
Epoch 0, Step 1093: train/loss = 0.5107883810997009, train/raw-loss = 0.43746334314346313, train/logprobs = tensor([[-0.6639, -3.0244],
        [-1.2941, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12220840901136398
Epoch 0, Step 1094: train/loss = 0.4654139280319214, train/raw-loss = 0.40657562017440796, train/logprobs = tensor([[-0.5151, -1.7875],
        [-0.9079, -0.6187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09806384146213531
Epoch 0, Step 1095: train/loss = 0.5682775974273682, train/raw-loss = 0.49899783730506897, train/logprobs = tensor([[-0.8477, -2.4132],
        [-0.9831, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11546628177165985
Epoch 0, Step 1096: train/loss = 0.40983402729034424, train/raw-loss = 0.34350505471229553, train/logprobs = tensor([[-0.6419, -4.0931],
        [-0.9780, -0.9517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11054830253124237
Epoch 0, Step 1097: train/loss = 0.3792531192302704, train/raw-loss = 0.30635517835617065, train/logprobs = tensor([[-0.7745, -3.8690],
        [-1.1444, -0.6856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12149662524461746
Epoch 0, Step 1098: train/loss = 0.40030336380004883, train/raw-loss = 0.3391927480697632, train/logprobs = tensor([[-0.3927, -6.0248],
        [-1.0098, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10185104608535767
Epoch 0, Step 1099: train/loss = 0.5287440419197083, train/raw-loss = 0.45857149362564087, train/logprobs = tensor([[-0.5377, -1.2874],
        [-1.2027, -0.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11695423722267151
Epoch 0, Step 1100: train/loss = 0.4346500337123871, train/raw-loss = 0.37435486912727356, train/logprobs = tensor([[-0.5497, -2.9578],
        [-0.9824, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10049194097518921
Epoch 0, Step 1101: train/loss = 0.3593708872795105, train/raw-loss = 0.30090272426605225, train/logprobs = tensor([[-0.5651, -6.0201],
        [-1.3663, -1.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09744694828987122
Epoch 0, Step 1102: train/loss = 0.42995592951774597, train/raw-loss = 0.37442031502723694, train/logprobs = tensor([[-0.9008, -4.1325],
        [-0.9409, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09255935251712799
Epoch 0, Step 1103: train/loss = 0.34807687997817993, train/raw-loss = 0.2863644063472748, train/logprobs = tensor([[-0.7698, -4.7512],
        [-1.2536, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10285414755344391
Epoch 0, Step 1104: train/loss = 0.6111900806427002, train/raw-loss = 0.5517388582229614, train/logprobs = tensor([[-0.7466, -4.0608],
        [-0.9233, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09908536076545715
Epoch 0, Step 1105: train/loss = 0.44625288248062134, train/raw-loss = 0.3891315162181854, train/logprobs = tensor([[-0.7426, -3.6420],
        [-0.7160, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09520228207111359
Epoch 0, Step 1106: train/loss = 0.41830626130104065, train/raw-loss = 0.3435055911540985, train/logprobs = tensor([[-0.9859, -5.1725],
        [-1.1470, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12466777116060257
Epoch 0, Step 1107: train/loss = 0.4241289496421814, train/raw-loss = 0.3648051917552948, train/logprobs = tensor([[-0.5769, -3.4710],
        [-0.8825, -0.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09887295961380005
Epoch 0, Step 1108: train/loss = 0.45184433460235596, train/raw-loss = 0.39832884073257446, train/logprobs = tensor([[-0.4983, -2.6464],
        [-0.9038, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08919249475002289
Epoch 0, Step 1109: train/loss = 0.4860284626483917, train/raw-loss = 0.42443037033081055, train/logprobs = tensor([[-0.5728, -2.3848],
        [-0.9568, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10266344994306564
Epoch 0, Step 1110: train/loss = 0.5448076725006104, train/raw-loss = 0.49064627289772034, train/logprobs = tensor([[-0.5468, -3.7689],
        [-0.6738, -1.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09026897698640823
Epoch 0, Step 1111: train/loss = 0.43737858533859253, train/raw-loss = 0.3772376775741577, train/logprobs = tensor([[-0.5715, -4.1664],
        [-0.7378, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10023488104343414
Epoch 0, Step 1112: train/loss = 0.5898789167404175, train/raw-loss = 0.5230344533920288, train/logprobs = tensor([[-1.2851, -4.6379],
        [-1.1761, -1.2259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114073246717453
Epoch 0, Step 1113: train/loss = 0.5865621566772461, train/raw-loss = 0.5237649083137512, train/logprobs = tensor([[-0.5970, -1.5348],
        [-0.8562, -0.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10466200858354568
Epoch 0, Step 1114: train/loss = 0.45376744866371155, train/raw-loss = 0.39671754837036133, train/logprobs = tensor([[-0.6572, -2.1662],
        [-1.0265, -0.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508315473794937
Epoch 0, Step 1115: train/loss = 0.5503206849098206, train/raw-loss = 0.4872487783432007, train/logprobs = tensor([[-0.3947, -1.5650],
        [-0.6641, -0.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10511986166238785
Epoch 0, Step 1116: train/loss = 0.5348281264305115, train/raw-loss = 0.47754979133605957, train/logprobs = tensor([[-0.5321, -2.1291],
        [-0.7379, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09546393156051636
Epoch 0, Step 1117: train/loss = 0.5820503234863281, train/raw-loss = 0.5124505758285522, train/logprobs = tensor([[-0.5708, -2.1003],
        [-1.2758, -1.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11599966883659363
Epoch 0, Step 1118: train/loss = 0.5910108089447021, train/raw-loss = 0.5395259261131287, train/logprobs = tensor([[-0.3207, -1.8765],
        [-0.4839, -0.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0858081504702568
Epoch 0, Step 1119: train/loss = 0.4423195421695709, train/raw-loss = 0.3778552711009979, train/logprobs = tensor([[-0.4739, -3.8639],
        [-0.9288, -0.9842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10744044184684753
Epoch 0, Step 1120: train/loss = 0.3181835114955902, train/raw-loss = 0.2424272894859314, train/logprobs = tensor([[-0.7993, -3.3914],
        [-1.5333, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12626034021377563
Epoch 0, Step 1121: train/loss = 0.40835025906562805, train/raw-loss = 0.33719849586486816, train/logprobs = tensor([[-0.6462, -2.8571],
        [-1.5556, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11858619749546051
Epoch 0, Step 1122: train/loss = 0.5877779126167297, train/raw-loss = 0.5279432535171509, train/logprobs = tensor([[-0.4628, -3.1147],
        [-0.8841, -0.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09972433000802994
Epoch 0, Step 1123: train/loss = 0.3112717270851135, train/raw-loss = 0.24387748539447784, train/logprobs = tensor([[-0.5589, -6.3429],
        [-1.3041, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232374608516693
Epoch 0, Step 1124: train/loss = 0.42176297307014465, train/raw-loss = 0.3616143465042114, train/logprobs = tensor([[-0.8359, -6.1228],
        [-1.2367, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10024772584438324
Epoch 0, Step 1125: train/loss = 0.42705923318862915, train/raw-loss = 0.36808812618255615, train/logprobs = tensor([[-0.5293, -2.3455],
        [-0.9137, -0.8191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09828513860702515
Epoch 0, Step 1126: train/loss = 0.522868275642395, train/raw-loss = 0.4564037322998047, train/logprobs = tensor([[-0.7867, -4.7002],
        [-1.0183, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1107742115855217
Epoch 0, Step 1127: train/loss = 0.4460374116897583, train/raw-loss = 0.38362985849380493, train/logprobs = tensor([[-0.3675, -2.9069],
        [-0.5774, -0.6899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10401257872581482
Epoch 0, Step 1128: train/loss = 0.6318577527999878, train/raw-loss = 0.5680685043334961, train/logprobs = tensor([[-1.3194, -1.8582],
        [-1.0362, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10631533712148666
Epoch 0, Step 1129: train/loss = 0.3444959819316864, train/raw-loss = 0.2740577161312103, train/logprobs = tensor([[-0.5941, -3.0834],
        [-1.2702, -0.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11739714443683624
Epoch 0, Step 1130: train/loss = 0.5383460521697998, train/raw-loss = 0.4917670786380768, train/logprobs = tensor([[-0.3224, -1.5950],
        [-0.7130, -0.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763157784938812
Epoch 0, Step 1131: train/loss = 0.4356231093406677, train/raw-loss = 0.3850302994251251, train/logprobs = tensor([[-0.4233, -2.8812],
        [-0.6946, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08432136476039886
Epoch 0, Step 1132: train/loss = 0.5909574031829834, train/raw-loss = 0.5258393883705139, train/logprobs = tensor([[-0.7318, -2.7933],
        [-0.6459, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10852998495101929
Epoch 0, Step 1133: train/loss = 0.6612643003463745, train/raw-loss = 0.6041252613067627, train/logprobs = tensor([[-0.6315, -0.8380],
        [-0.7341, -0.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09523165225982666
Epoch 0, Step 1134: train/loss = 0.4428643584251404, train/raw-loss = 0.3784973919391632, train/logprobs = tensor([[-1.0724, -5.6450],
        [-1.2344, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10727821290493011
Epoch 0, Step 1135: train/loss = 0.4016686677932739, train/raw-loss = 0.33736979961395264, train/logprobs = tensor([[-0.4977, -3.4731],
        [-0.9007, -0.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10716481506824493
Epoch 0, Step 1136: train/loss = 0.4284345507621765, train/raw-loss = 0.36328238248825073, train/logprobs = tensor([[-0.6830, -4.3798],
        [-1.1934, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10858693718910217
Epoch 0, Step 1137: train/loss = 0.4024617671966553, train/raw-loss = 0.3425789773464203, train/logprobs = tensor([[-0.7128, -6.1117],
        [-1.0525, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980468451976776
Epoch 0, Step 1138: train/loss = 0.5555223822593689, train/raw-loss = 0.49963849782943726, train/logprobs = tensor([[-0.5516, -1.6657],
        [-0.7272, -0.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09313979744911194
Epoch 0, Step 1139: train/loss = 0.42675039172172546, train/raw-loss = 0.3429340720176697, train/logprobs = tensor([[-0.5175, -2.4846],
        [-1.3320, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13969385623931885
Epoch 0, Step 1140: train/loss = 0.43067872524261475, train/raw-loss = 0.3690564036369324, train/logprobs = tensor([[-0.5398, -5.2264],
        [-1.0039, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10270387679338455
Epoch 0, Step 1141: train/loss = 0.43649357557296753, train/raw-loss = 0.37924325466156006, train/logprobs = tensor([[-0.5314, -3.5238],
        [-0.8740, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541720151901245
Epoch 0, Step 1142: train/loss = 0.5917876958847046, train/raw-loss = 0.5360841155052185, train/logprobs = tensor([[-0.6596, -1.7281],
        [-1.2909, -1.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09283927828073502
Epoch 0, Step 1143: train/loss = 0.5602298378944397, train/raw-loss = 0.4920281767845154, train/logprobs = tensor([[-0.5573, -1.6868],
        [-0.8985, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11366946250200272
Epoch 0, Step 1144: train/loss = 0.47530800104141235, train/raw-loss = 0.41939693689346313, train/logprobs = tensor([[-0.4365, -3.0825],
        [-0.5490, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318515658378601
Epoch 0, Step 1145: train/loss = 0.33930420875549316, train/raw-loss = 0.28262507915496826, train/logprobs = tensor([[-0.4237, -5.5162],
        [-0.6327, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446516633033752
Epoch 0, Step 1146: train/loss = 0.2796105444431305, train/raw-loss = 0.19663038849830627, train/logprobs = tensor([[-0.5894, -9.2004],
        [-1.1294, -1.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13830025494098663
Epoch 0, Step 1147: train/loss = 0.36317911744117737, train/raw-loss = 0.2838956117630005, train/logprobs = tensor([[-0.8412, -3.7399],
        [-1.3507, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132139191031456
Epoch 0, Step 1148: train/loss = 0.5485253930091858, train/raw-loss = 0.4891142249107361, train/logprobs = tensor([[-0.6087, -1.3689],
        [-1.0690, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09901866316795349
Epoch 0, Step 1149: train/loss = 0.39499902725219727, train/raw-loss = 0.3272688686847687, train/logprobs = tensor([[-0.6801, -4.1909],
        [-1.3094, -0.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288362741470337
Epoch 0, Step 1150: train/loss = 0.5468998551368713, train/raw-loss = 0.48633497953414917, train/logprobs = tensor([[-0.8145, -3.6822],
        [-0.6153, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10094146430492401
Epoch 0, Step 1151: train/loss = 0.37139007449150085, train/raw-loss = 0.3004949688911438, train/logprobs = tensor([[-0.7979, -6.5697],
        [-1.3976, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11815854161977768
Epoch 0, Step 1152: train/loss = 0.24719104170799255, train/raw-loss = 0.1667870134115219, train/logprobs = tensor([[-0.6183, -6.2310],
        [-1.5023, -0.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13400669395923615
Epoch 0, Step 1153: train/loss = 0.49309611320495605, train/raw-loss = 0.4330141544342041, train/logprobs = tensor([[-0.4061, -1.8662],
        [-0.7488, -0.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10013657063245773
Epoch 0, Step 1154: train/loss = 0.4464188814163208, train/raw-loss = 0.3851472735404968, train/logprobs = tensor([[-0.6348, -2.7589],
        [-1.1361, -0.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10211935639381409
Epoch 0, Step 1155: train/loss = 0.42240092158317566, train/raw-loss = 0.37084218859672546, train/logprobs = tensor([[-0.5070, -2.8126],
        [-0.9680, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0859312191605568
Epoch 0, Step 1156: train/loss = 0.533073902130127, train/raw-loss = 0.4735081195831299, train/logprobs = tensor([[-0.5332, -1.5314],
        [-1.0316, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09927625954151154
Epoch 0, Step 1157: train/loss = 0.4407878816127777, train/raw-loss = 0.3743022382259369, train/logprobs = tensor([[-0.7450, -5.6066],
        [-0.9107, -1.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080940067768097
Epoch 0, Step 1158: train/loss = 0.31055793166160583, train/raw-loss = 0.23963898420333862, train/logprobs = tensor([[-0.6375, -4.9905],
        [-1.1470, -0.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1181982085108757
Epoch 0, Step 1159: train/loss = 0.4014855623245239, train/raw-loss = 0.33835163712501526, train/logprobs = tensor([[-0.4675, -3.2024],
        [-0.7072, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522322356700897
Epoch 0, Step 1160: train/loss = 0.5724092125892639, train/raw-loss = 0.519031286239624, train/logprobs = tensor([[-0.5920, -2.6298],
        [-0.8356, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08896318823099136
Epoch 0, Step 1161: train/loss = 0.5241891145706177, train/raw-loss = 0.44801124930381775, train/logprobs = tensor([[-0.6195, -1.8591],
        [-0.9149, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269630491733551
Epoch 0, Step 1162: train/loss = 0.4258394241333008, train/raw-loss = 0.36008381843566895, train/logprobs = tensor([[-0.6681, -4.5794],
        [-1.2653, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10959270596504211
Epoch 0, Step 1163: train/loss = 0.33719247579574585, train/raw-loss = 0.26686960458755493, train/logprobs = tensor([[-0.5741, -5.4756],
        [-0.9747, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11720474809408188
Epoch 0, Step 1164: train/loss = 0.4337711036205292, train/raw-loss = 0.3655344247817993, train/logprobs = tensor([[-0.5198, -6.0027],
        [-0.9387, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137278601527214
Epoch 0, Step 1165: train/loss = 0.4270502030849457, train/raw-loss = 0.36685705184936523, train/logprobs = tensor([[-0.6393, -3.8262],
        [-0.9727, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10032190382480621
Epoch 0, Step 1166: train/loss = 0.381805419921875, train/raw-loss = 0.3060566186904907, train/logprobs = tensor([[-0.5880, -2.8346],
        [-1.4245, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12624798715114594
Epoch 0, Step 1167: train/loss = 0.5005717277526855, train/raw-loss = 0.43635526299476624, train/logprobs = tensor([[-0.4896, -3.9055],
        [-0.9164, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702740401029587
Epoch 0, Step 1168: train/loss = 0.5311825275421143, train/raw-loss = 0.4733350872993469, train/logprobs = tensor([[-0.7244, -2.6237],
        [-1.0260, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09641233086585999
Epoch 0, Step 1169: train/loss = 0.65361088514328, train/raw-loss = 0.5842407941818237, train/logprobs = tensor([[-1.6822, -4.5946],
        [-1.0830, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11561670899391174
Epoch 0, Step 1170: train/loss = 0.3518370985984802, train/raw-loss = 0.29298412799835205, train/logprobs = tensor([[-0.5493, -4.9868],
        [-0.9405, -1.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09808829426765442
Epoch 0, Step 1171: train/loss = 0.5867865085601807, train/raw-loss = 0.5315451622009277, train/logprobs = tensor([[-0.7060, -2.3852],
        [-1.0072, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09206894040107727
Epoch 0, Step 1172: train/loss = 0.3346516489982605, train/raw-loss = 0.2720975875854492, train/logprobs = tensor([[-0.5812, -6.2388],
        [-0.9808, -1.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10425673425197601
Epoch 0, Step 1173: train/loss = 0.3187169134616852, train/raw-loss = 0.2530571222305298, train/logprobs = tensor([[-0.7040, -5.3306],
        [-1.0899, -0.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10943295061588287
Epoch 0, Step 1174: train/loss = 0.5554758906364441, train/raw-loss = 0.5072746276855469, train/logprobs = tensor([[-0.5456, -1.7325],
        [-0.9439, -0.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08033541589975357
Epoch 0, Step 1175: train/loss = 0.4102938771247864, train/raw-loss = 0.34398356080055237, train/logprobs = tensor([[-0.7546, -4.2505],
        [-1.0695, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.110517218708992
Epoch 0, Step 1176: train/loss = 0.6299370527267456, train/raw-loss = 0.5830658078193665, train/logprobs = tensor([[-0.6172, -1.7066],
        [-1.0104, -1.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07811874151229858
Epoch 0, Step 1177: train/loss = 0.5201734900474548, train/raw-loss = 0.4574880599975586, train/logprobs = tensor([[-0.5554, -2.9930],
        [-0.9127, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447563976049423
Epoch 0, Step 1178: train/loss = 0.6364415287971497, train/raw-loss = 0.579907238483429, train/logprobs = tensor([[-1.4869, -2.8901],
        [-0.8556, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.094223752617836
Epoch 0, Step 1179: train/loss = 0.5929609537124634, train/raw-loss = 0.526404619216919, train/logprobs = tensor([[-0.9977, -1.6154],
        [-1.0328, -0.7439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11092731356620789
Epoch 0, Step 1180: train/loss = 0.6189053058624268, train/raw-loss = 0.5613534450531006, train/logprobs = tensor([[-0.6162, -0.9284],
        [-1.0902, -0.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09591977298259735
Epoch 0, Step 1181: train/loss = 0.37685951590538025, train/raw-loss = 0.3224110007286072, train/logprobs = tensor([[-0.8292, -4.0659],
        [-0.9926, -1.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09074749797582626
Epoch 0, Step 1182: train/loss = 0.5812057852745056, train/raw-loss = 0.516301155090332, train/logprobs = tensor([[-0.7639, -4.0873],
        [-1.1596, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081743985414505
Epoch 0, Step 1183: train/loss = 0.6035146713256836, train/raw-loss = 0.5561226606369019, train/logprobs = tensor([[-0.5334, -1.7633],
        [-0.6125, -0.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0789867490530014
Epoch 0, Step 1184: train/loss = 0.5799048542976379, train/raw-loss = 0.5126206874847412, train/logprobs = tensor([[-0.7169, -2.2464],
        [-1.0061, -0.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11214026808738708
Epoch 0, Step 1185: train/loss = 0.4417339563369751, train/raw-loss = 0.3821600675582886, train/logprobs = tensor([[-0.5728, -3.2561],
        [-1.2358, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09928987920284271
Epoch 0, Step 1186: train/loss = 0.5547136068344116, train/raw-loss = 0.5015906095504761, train/logprobs = tensor([[-0.5238, -3.3777],
        [-0.7076, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08853836357593536
Epoch 0, Step 1187: train/loss = 0.3854735493659973, train/raw-loss = 0.3152630627155304, train/logprobs = tensor([[-0.9383, -5.8177],
        [-0.9933, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1170174777507782
Epoch 0, Step 1188: train/loss = 0.3903900384902954, train/raw-loss = 0.3249939978122711, train/logprobs = tensor([[-0.6002, -3.4195],
        [-1.2084, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10899337381124496
Epoch 0, Step 1189: train/loss = 0.3991982042789459, train/raw-loss = 0.3301789164543152, train/logprobs = tensor([[-0.5277, -2.5037],
        [-1.0896, -0.5763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11503216624259949
Epoch 0, Step 1190: train/loss = 0.4764745235443115, train/raw-loss = 0.41369807720184326, train/logprobs = tensor([[-0.5718, -2.3737],
        [-0.9791, -0.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10462739318609238
Epoch 0, Step 1191: train/loss = 0.3985966444015503, train/raw-loss = 0.34242820739746094, train/logprobs = tensor([[-0.6412, -5.4820],
        [-0.9065, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09361402690410614
Epoch 0, Step 1192: train/loss = 0.31144753098487854, train/raw-loss = 0.24569733440876007, train/logprobs = tensor([[-0.5540, -7.5923],
        [-0.9556, -1.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10958365350961685
Epoch 0, Step 1193: train/loss = 0.5521756410598755, train/raw-loss = 0.4851796627044678, train/logprobs = tensor([[-0.5876, -1.4867],
        [-1.2057, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11166001111268997
Epoch 0, Step 1194: train/loss = 0.5649393796920776, train/raw-loss = 0.5046858787536621, train/logprobs = tensor([[-1.0360, -3.3784],
        [-0.8366, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10042250156402588
Epoch 0, Step 1195: train/loss = 0.5429655909538269, train/raw-loss = 0.4810243248939514, train/logprobs = tensor([[-0.8045, -3.9596],
        [-0.7034, -1.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10323541611433029
Epoch 0, Step 1196: train/loss = 0.6254564523696899, train/raw-loss = 0.5613918304443359, train/logprobs = tensor([[-1.5652, -3.3264],
        [-1.0418, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10677438974380493
Epoch 0, Step 1197: train/loss = 0.25582632422447205, train/raw-loss = 0.18568043410778046, train/logprobs = tensor([[-0.5217, -5.8075],
        [-1.3056, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11690977215766907
Epoch 0, Step 1198: train/loss = 0.45412030816078186, train/raw-loss = 0.3856547474861145, train/logprobs = tensor([[-0.8030, -4.2027],
        [-1.1797, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11410927772521973
Epoch 0, Step 1199: train/loss = 0.6573725342750549, train/raw-loss = 0.6078634262084961, train/logprobs = tensor([[-0.4056, -0.5941],
        [-0.5670, -0.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08251508325338364
Epoch 0, Step 1200: train/loss = 0.4942021369934082, train/raw-loss = 0.4362541437149048, train/logprobs = tensor([[-0.6920, -2.9339],
        [-0.8417, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657995402812958
Epoch 0, Step 1201: train/loss = 0.5737167000770569, train/raw-loss = 0.5249378681182861, train/logprobs = tensor([[-0.5323, -1.8016],
        [-0.7550, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129800856113434
Epoch 0, Step 1202: train/loss = 0.29448968172073364, train/raw-loss = 0.22109845280647278, train/logprobs = tensor([[-0.6641, -7.9465],
        [-1.1490, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12231869995594025
Epoch 0, Step 1203: train/loss = 0.3717329502105713, train/raw-loss = 0.30633237957954407, train/logprobs = tensor([[-0.4253, -5.3113],
        [-1.0133, -1.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10900092124938965
Epoch 0, Step 1204: train/loss = 0.48001107573509216, train/raw-loss = 0.42393654584884644, train/logprobs = tensor([[-0.7739, -1.7516],
        [-1.2238, -0.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09345753490924835
Epoch 0, Step 1205: train/loss = 0.5512325763702393, train/raw-loss = 0.4799222946166992, train/logprobs = tensor([[-0.7301, -2.5915],
        [-0.7784, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11885048449039459
Epoch 0, Step 1206: train/loss = 0.46472910046577454, train/raw-loss = 0.4013298749923706, train/logprobs = tensor([[-0.6960, -4.3514],
        [-1.0126, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10566537082195282
Epoch 0, Step 1207: train/loss = 0.35684990882873535, train/raw-loss = 0.29282671213150024, train/logprobs = tensor([[-0.6214, -4.2169],
        [-1.0277, -0.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670532286167145
Epoch 0, Step 1208: train/loss = 0.3165837824344635, train/raw-loss = 0.2480248212814331, train/logprobs = tensor([[-0.6989, -4.0568],
        [-1.4602, -0.4623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11426494270563126
Epoch 0, Step 1209: train/loss = 0.285504013299942, train/raw-loss = 0.21126532554626465, train/logprobs = tensor([[-0.7987, -3.1037],
        [-1.8894, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12373112142086029
Epoch 0, Step 1210: train/loss = 0.42299309372901917, train/raw-loss = 0.35334619879722595, train/logprobs = tensor([[-0.4691, -2.6974],
        [-0.9821, -0.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11607813835144043
Epoch 0, Step 1211: train/loss = 0.28538668155670166, train/raw-loss = 0.21501177549362183, train/logprobs = tensor([[-0.5906, -4.6074],
        [-1.3049, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11729151010513306
Epoch 0, Step 1212: train/loss = 0.5373541116714478, train/raw-loss = 0.48738718032836914, train/logprobs = tensor([[-0.6667, -4.0171],
        [-0.7567, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08327823132276535
Epoch 0, Step 1213: train/loss = 0.4458373486995697, train/raw-loss = 0.38164132833480835, train/logprobs = tensor([[-0.7584, -4.0290],
        [-0.8828, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699330270290375
Epoch 0, Step 1214: train/loss = 0.45815905928611755, train/raw-loss = 0.38978296518325806, train/logprobs = tensor([[-0.6407, -3.8022],
        [-0.8103, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11396019905805588
Epoch 0, Step 1215: train/loss = 0.4450499415397644, train/raw-loss = 0.38072311878204346, train/logprobs = tensor([[-0.6436, -5.6003],
        [-1.0125, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10721133649349213
Epoch 0, Step 1216: train/loss = 0.48837369680404663, train/raw-loss = 0.43249380588531494, train/logprobs = tensor([[-0.5035, -3.7173],
        [-0.9402, -1.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0931331068277359
Epoch 0, Step 1217: train/loss = 0.47196653485298157, train/raw-loss = 0.4164917767047882, train/logprobs = tensor([[-1.0284, -5.7112],
        [-1.4176, -1.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09245798736810684
Epoch 0, Step 1218: train/loss = 0.46262627840042114, train/raw-loss = 0.3973786234855652, train/logprobs = tensor([[-0.6173, -3.3594],
        [-0.9644, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10874610394239426
Epoch 0, Step 1219: train/loss = 0.38664159178733826, train/raw-loss = 0.3126828670501709, train/logprobs = tensor([[-0.7378, -5.9582],
        [-1.2240, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12326452136039734
Epoch 0, Step 1220: train/loss = 0.7141525745391846, train/raw-loss = 0.661440372467041, train/logprobs = tensor([[-0.6254, -0.6405],
        [-0.6295, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08785364031791687
Epoch 0, Step 1221: train/loss = 0.4274909496307373, train/raw-loss = 0.3820612132549286, train/logprobs = tensor([[-0.4490, -3.3070],
        [-0.7020, -0.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07571624219417572
Epoch 0, Step 1222: train/loss = 0.5143795013427734, train/raw-loss = 0.456200510263443, train/logprobs = tensor([[-0.6944, -4.3615],
        [-1.3613, -1.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09696494042873383
Epoch 0, Step 1223: train/loss = 0.414112389087677, train/raw-loss = 0.35998380184173584, train/logprobs = tensor([[-0.5399, -3.4790],
        [-0.9072, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902143269777298
Epoch 0, Step 1224: train/loss = 0.506345272064209, train/raw-loss = 0.4587302803993225, train/logprobs = tensor([[-0.3073, -2.2668],
        [-0.5250, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07935838401317596
Epoch 0, Step 1225: train/loss = 0.4261680543422699, train/raw-loss = 0.3821839690208435, train/logprobs = tensor([[-0.4368, -2.6879],
        [-0.6290, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07330675423145294
Epoch 0, Step 1226: train/loss = 0.47605234384536743, train/raw-loss = 0.42153027653694153, train/logprobs = tensor([[-0.7002, -2.9437],
        [-0.6857, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09087005257606506
Epoch 0, Step 1227: train/loss = 0.528863251209259, train/raw-loss = 0.46701711416244507, train/logprobs = tensor([[-1.0209, -2.1437],
        [-1.0463, -0.6807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10307694226503372
Epoch 0, Step 1228: train/loss = 0.5962638258934021, train/raw-loss = 0.5318642258644104, train/logprobs = tensor([[-0.5713, -1.4553],
        [-0.7183, -0.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10733266919851303
Epoch 0, Step 1229: train/loss = 0.40781933069229126, train/raw-loss = 0.35318008065223694, train/logprobs = tensor([[-0.4351, -5.4570],
        [-0.6449, -0.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910654217004776
Epoch 0, Step 1230: train/loss = 0.692827582359314, train/raw-loss = 0.6311378479003906, train/logprobs = tensor([[-1.4108, -1.8979],
        [-1.3686, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281620919704437
Epoch 0, Step 1231: train/loss = 0.5123844742774963, train/raw-loss = 0.44275107979774475, train/logprobs = tensor([[-0.7427, -1.9051],
        [-1.1306, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11605562269687653
Epoch 0, Step 1232: train/loss = 0.8162895441055298, train/raw-loss = 0.7718650102615356, train/logprobs = tensor([[-2.7876, -5.6977],
        [-1.7856, -2.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740409642457962
Epoch 0, Step 1233: train/loss = 0.5922032594680786, train/raw-loss = 0.5292134284973145, train/logprobs = tensor([[-0.4754, -1.3414],
        [-0.6462, -0.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10498300939798355
Epoch 0, Step 1234: train/loss = 0.4303358793258667, train/raw-loss = 0.3689236044883728, train/logprobs = tensor([[-0.6445, -2.5737],
        [-1.1711, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10235380381345749
Epoch 0, Step 1235: train/loss = 0.6729075312614441, train/raw-loss = 0.6189371347427368, train/logprobs = tensor([[-1.2544, -5.0626],
        [-0.7518, -1.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995065093040466
Epoch 0, Step 1236: train/loss = 0.39392125606536865, train/raw-loss = 0.3335948586463928, train/logprobs = tensor([[-0.3570, -4.6582],
        [-0.6734, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10054394602775574
Epoch 0, Step 1237: train/loss = 0.3630619943141937, train/raw-loss = 0.30014657974243164, train/logprobs = tensor([[-0.6546, -6.2585],
        [-1.2007, -1.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10485903918743134
Epoch 0, Step 1238: train/loss = 0.4911496043205261, train/raw-loss = 0.427970290184021, train/logprobs = tensor([[-0.6457, -3.6506],
        [-1.0145, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052989512681961
Epoch 0, Step 1239: train/loss = 0.5756070017814636, train/raw-loss = 0.5259451866149902, train/logprobs = tensor([[-0.7022, -2.3393],
        [-0.6452, -0.8228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276967704296112
Epoch 0, Step 1240: train/loss = 0.5099465250968933, train/raw-loss = 0.44916006922721863, train/logprobs = tensor([[-0.8808, -5.2577],
        [-1.4017, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10131067037582397
Epoch 0, Step 1241: train/loss = 0.4198707938194275, train/raw-loss = 0.3528364300727844, train/logprobs = tensor([[-0.5931, -2.6275],
        [-1.1945, -0.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.111723892390728
Epoch 0, Step 1242: train/loss = 0.480771005153656, train/raw-loss = 0.4212474822998047, train/logprobs = tensor([[-0.6322, -2.6920],
        [-1.0914, -0.9784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992058515548706
Epoch 0, Step 1243: train/loss = 0.5528944730758667, train/raw-loss = 0.4933038353919983, train/logprobs = tensor([[-0.5704, -1.5717],
        [-0.9482, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09931769967079163
Epoch 0, Step 1244: train/loss = 0.46655988693237305, train/raw-loss = 0.40324878692626953, train/logprobs = tensor([[-0.5837, -1.8902],
        [-0.9494, -0.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551847517490387
Epoch 0, Step 1245: train/loss = 0.32308340072631836, train/raw-loss = 0.2444109469652176, train/logprobs = tensor([[-0.5229, -3.8609],
        [-1.4968, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13112077116966248
Epoch 0, Step 1246: train/loss = 0.33422812819480896, train/raw-loss = 0.2670753598213196, train/logprobs = tensor([[-0.6165, -2.8898],
        [-1.2853, -0.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119212657213211
Epoch 0, Step 1247: train/loss = 0.474241703748703, train/raw-loss = 0.4043959975242615, train/logprobs = tensor([[-0.9360, -4.3386],
        [-0.8932, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.116409532725811
Epoch 0, Step 1248: train/loss = 0.5314637422561646, train/raw-loss = 0.466545969247818, train/logprobs = tensor([[-0.5913, -1.8866],
        [-0.9911, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10819626599550247
Epoch 0, Step 1249: train/loss = 0.5751290321350098, train/raw-loss = 0.5117852091789246, train/logprobs = tensor([[-0.6862, -1.4108],
        [-0.9636, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10557305067777634
Epoch 0, Step 1250: train/loss = 0.5659772157669067, train/raw-loss = 0.4898014962673187, train/logprobs = tensor([[-0.7224, -2.0038],
        [-0.8841, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12695959210395813
Epoch 0, Step 1251: train/loss = 0.43260252475738525, train/raw-loss = 0.36375460028648376, train/logprobs = tensor([[-0.4193, -3.6872],
        [-0.9339, -0.6632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11474655568599701
Epoch 0, Step 1252: train/loss = 0.3283079266548157, train/raw-loss = 0.2501257658004761, train/logprobs = tensor([[-0.6877, -5.7336],
        [-1.4915, -1.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13030356168746948
Epoch 0, Step 1253: train/loss = 0.47625502943992615, train/raw-loss = 0.413524866104126, train/logprobs = tensor([[-0.6073, -2.1102],
        [-1.0148, -0.6245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10455025732517242
Epoch 0, Step 1254: train/loss = 0.485339879989624, train/raw-loss = 0.42661476135253906, train/logprobs = tensor([[-0.3969, -2.4234],
        [-0.7289, -0.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09787523746490479
Epoch 0, Step 1255: train/loss = 0.6967900991439819, train/raw-loss = 0.6449292302131653, train/logprobs = tensor([[-0.5218, -0.6913],
        [-0.7062, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08643478155136108
Epoch 0, Step 1256: train/loss = 0.4177684485912323, train/raw-loss = 0.35325685143470764, train/logprobs = tensor([[-0.9259, -2.1018],
        [-1.8844, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10751928389072418
Epoch 0, Step 1257: train/loss = 0.5347577929496765, train/raw-loss = 0.4741036295890808, train/logprobs = tensor([[-0.4387, -2.0857],
        [-0.6235, -0.5397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10109022259712219
Epoch 0, Step 1258: train/loss = 0.4110965132713318, train/raw-loss = 0.35314345359802246, train/logprobs = tensor([[-0.6552, -2.9000],
        [-1.2529, -0.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09658841788768768
Epoch 0, Step 1259: train/loss = 0.6565563082695007, train/raw-loss = 0.5944349765777588, train/logprobs = tensor([[-0.3984, -1.0256],
        [-0.6451, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10353558510541916
Epoch 0, Step 1260: train/loss = 0.47341158986091614, train/raw-loss = 0.40586328506469727, train/logprobs = tensor([[-0.6134, -6.6955],
        [-1.2431, -1.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258044838905334
Epoch 0, Step 1261: train/loss = 0.5434297919273376, train/raw-loss = 0.45498478412628174, train/logprobs = tensor([[-0.6048, -2.4566],
        [-1.1579, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474083513021469
Epoch 0, Step 1262: train/loss = 0.45258861780166626, train/raw-loss = 0.39316028356552124, train/logprobs = tensor([[-0.6186, -3.6544],
        [-0.9725, -0.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09904726594686508
Epoch 0, Step 1263: train/loss = 0.47719016671180725, train/raw-loss = 0.4205152988433838, train/logprobs = tensor([[-0.7168, -2.6916],
        [-0.9383, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445812553167343
Epoch 0, Step 1264: train/loss = 0.36241787672042847, train/raw-loss = 0.29415708780288696, train/logprobs = tensor([[-0.7587, -3.3369],
        [-1.2319, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11376793682575226
Epoch 0, Step 1265: train/loss = 0.5094111561775208, train/raw-loss = 0.4388951063156128, train/logprobs = tensor([[-0.7109, -2.4436],
        [-1.2436, -0.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11752673983573914
Epoch 0, Step 1266: train/loss = 0.4521331191062927, train/raw-loss = 0.38893836736679077, train/logprobs = tensor([[-0.9313, -5.6448],
        [-1.0686, -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10532452166080475
Epoch 0, Step 1267: train/loss = 0.2780351936817169, train/raw-loss = 0.2072502076625824, train/logprobs = tensor([[-0.6632, -4.0096],
        [-1.5372, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11797495186328888
Epoch 0, Step 1268: train/loss = 0.33988112211227417, train/raw-loss = 0.2739540934562683, train/logprobs = tensor([[-0.6960, -6.0562],
        [-1.5540, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10987842082977295
Epoch 0, Step 1269: train/loss = 0.4295865297317505, train/raw-loss = 0.3704015910625458, train/logprobs = tensor([[-0.7531, -3.3090],
        [-1.3864, -1.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09864157438278198
Epoch 0, Step 1270: train/loss = 0.5471017360687256, train/raw-loss = 0.4875802993774414, train/logprobs = tensor([[-0.7224, -3.5282],
        [-0.9118, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09920232743024826
Epoch 0, Step 1271: train/loss = 0.554151713848114, train/raw-loss = 0.5052344799041748, train/logprobs = tensor([[-0.6053, -2.9198],
        [-0.6417, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152872323989868
Epoch 0, Step 1272: train/loss = 0.36938899755477905, train/raw-loss = 0.3069223165512085, train/logprobs = tensor([[-0.7158, -3.3336],
        [-1.2920, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10411112755537033
Epoch 0, Step 1273: train/loss = 0.5760632157325745, train/raw-loss = 0.5113698244094849, train/logprobs = tensor([[-0.8932, -2.3945],
        [-0.7893, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10782226920127869
Epoch 0, Step 1274: train/loss = 0.526175856590271, train/raw-loss = 0.45840734243392944, train/logprobs = tensor([[-0.3603, -2.6519],
        [-0.6992, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11294743418693542
Epoch 0, Step 1275: train/loss = 0.46025732159614563, train/raw-loss = 0.3921094536781311, train/logprobs = tensor([[-0.4475, -1.9256],
        [-0.9946, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11357982456684113
Epoch 0, Step 1276: train/loss = 0.3755931258201599, train/raw-loss = 0.32295143604278564, train/logprobs = tensor([[-0.5389, -6.8795],
        [-0.9633, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0877360999584198
Epoch 0, Step 1277: train/loss = 0.5535699725151062, train/raw-loss = 0.4986644685268402, train/logprobs = tensor([[-0.5628, -1.4695],
        [-0.7177, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150917828083038
Epoch 0, Step 1278: train/loss = 0.3217026889324188, train/raw-loss = 0.25370994210243225, train/logprobs = tensor([[-0.3938, -4.3414],
        [-1.1836, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11332124471664429
Epoch 0, Step 1279: train/loss = 0.32052600383758545, train/raw-loss = 0.23897434771060944, train/logprobs = tensor([[-0.5947, -5.0290],
        [-1.3377, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13591939210891724
Epoch 0, Step 1280: train/loss = 0.3971843123435974, train/raw-loss = 0.3260168135166168, train/logprobs = tensor([[-0.5328, -4.2033],
        [-1.0798, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11861246824264526
Epoch 0, Step 1281: train/loss = 0.4225810766220093, train/raw-loss = 0.3569127917289734, train/logprobs = tensor([[-0.5806, -3.6491],
        [-0.8873, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10944709926843643
Epoch 0, Step 1282: train/loss = 0.5273414850234985, train/raw-loss = 0.47981327772140503, train/logprobs = tensor([[-0.3775, -2.1341],
        [-0.5378, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921356707811356
Epoch 0, Step 1283: train/loss = 0.565735936164856, train/raw-loss = 0.5035922527313232, train/logprobs = tensor([[-0.4011, -1.8649],
        [-0.7373, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10357283800840378
Epoch 0, Step 1284: train/loss = 0.5240578651428223, train/raw-loss = 0.4680421054363251, train/logprobs = tensor([[-0.4250, -3.0810],
        [-0.6316, -0.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335961937904358
Epoch 0, Step 1285: train/loss = 0.2838681936264038, train/raw-loss = 0.22147433459758759, train/logprobs = tensor([[-0.6477, -6.5378],
        [-1.4835, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10398976504802704
Epoch 0, Step 1286: train/loss = 0.3005373775959015, train/raw-loss = 0.24461081624031067, train/logprobs = tensor([[-0.5396, -4.5422],
        [-1.2586, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09321097284555435
Epoch 0, Step 1287: train/loss = 0.4718838334083557, train/raw-loss = 0.4122929573059082, train/logprobs = tensor([[-0.4344, -4.6608],
        [-0.9444, -0.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09931813925504684
Epoch 0, Step 1288: train/loss = 0.6601032018661499, train/raw-loss = 0.6022646427154541, train/logprobs = tensor([[-0.9032, -2.2953],
        [-0.7506, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09639762341976166
Epoch 0, Step 1289: train/loss = 0.42170754075050354, train/raw-loss = 0.3637380003929138, train/logprobs = tensor([[-0.6582, -3.8983],
        [-1.1645, -0.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09661591053009033
Epoch 0, Step 1290: train/loss = 0.4380517601966858, train/raw-loss = 0.3758266568183899, train/logprobs = tensor([[-0.5781, -3.3694],
        [-1.0244, -0.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370852798223495
Epoch 0, Step 1291: train/loss = 0.42010629177093506, train/raw-loss = 0.35056400299072266, train/logprobs = tensor([[-1.6378, -9.7475],
        [-1.7466, -1.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.115903839468956
Epoch 0, Step 1292: train/loss = 0.3668529689311981, train/raw-loss = 0.2934195399284363, train/logprobs = tensor([[-0.5931, -4.8095],
        [-1.2691, -1.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1223890632390976
Epoch 0, Step 1293: train/loss = 0.34800517559051514, train/raw-loss = 0.26977095007896423, train/logprobs = tensor([[-0.7479, -4.2608],
        [-1.8274, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13039037585258484
Epoch 0, Step 1294: train/loss = 0.46394288539886475, train/raw-loss = 0.39561301469802856, train/logprobs = tensor([[-0.7738, -2.4558],
        [-1.3846, -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11388307809829712
Epoch 0, Step 1295: train/loss = 0.4144699275493622, train/raw-loss = 0.3606012463569641, train/logprobs = tensor([[-0.7405, -5.3359],
        [-1.4604, -2.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978112787008286
Epoch 0, Step 1296: train/loss = 0.3561917543411255, train/raw-loss = 0.29481714963912964, train/logprobs = tensor([[-0.7433, -3.0098],
        [-1.4180, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229098796844482
Epoch 0, Step 1297: train/loss = 0.44534653425216675, train/raw-loss = 0.3807735741138458, train/logprobs = tensor([[-0.5860, -6.0859],
        [-0.8790, -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762165486812592
Epoch 0, Step 1298: train/loss = 0.5168280601501465, train/raw-loss = 0.4458048343658447, train/logprobs = tensor([[-0.8717, -1.4185],
        [-1.5128, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11837194859981537
Epoch 0, Step 1299: train/loss = 0.37149399518966675, train/raw-loss = 0.30719810724258423, train/logprobs = tensor([[-0.5012, -4.7871],
        [-1.2747, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.107159823179245
Epoch 0, Step 1300: train/loss = 0.5204330086708069, train/raw-loss = 0.45184677839279175, train/logprobs = tensor([[-0.7018, -4.4224],
        [-1.0735, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11431044340133667
Epoch 0, Step 1301: train/loss = 0.5535975694656372, train/raw-loss = 0.48874330520629883, train/logprobs = tensor([[-0.6442, -1.5341],
        [-0.9468, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10809041559696198
Epoch 0, Step 1302: train/loss = 0.5352396965026855, train/raw-loss = 0.4828464984893799, train/logprobs = tensor([[-0.4660, -1.1797],
        [-0.8778, -0.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08732198178768158
Epoch 0, Step 1303: train/loss = 0.5339904427528381, train/raw-loss = 0.4768373370170593, train/logprobs = tensor([[-0.3699, -2.3402],
        [-0.7946, -0.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09525511413812637
Epoch 0, Step 1304: train/loss = 0.537625253200531, train/raw-loss = 0.475277304649353, train/logprobs = tensor([[-0.5513, -2.8468],
        [-1.1704, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391321033239365
Epoch 0, Step 1305: train/loss = 0.4650217294692993, train/raw-loss = 0.4024978578090668, train/logprobs = tensor([[-1.4553, -5.0808],
        [-1.4034, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10420642048120499
Epoch 0, Step 1306: train/loss = 0.37379616498947144, train/raw-loss = 0.30295470356941223, train/logprobs = tensor([[-1.3583, -4.3369],
        [-1.6506, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806908994913101
Epoch 0, Step 1307: train/loss = 0.5410815477371216, train/raw-loss = 0.49410414695739746, train/logprobs = tensor([[-0.7115, -1.1692],
        [-1.0655, -0.4176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07829566299915314
Epoch 0, Step 1308: train/loss = 0.5201511383056641, train/raw-loss = 0.460963636636734, train/logprobs = tensor([[-0.4775, -2.8517],
        [-1.1634, -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09864580631256104
Epoch 0, Step 1309: train/loss = 0.48232194781303406, train/raw-loss = 0.41847407817840576, train/logprobs = tensor([[-0.6774, -1.5869],
        [-1.1095, -0.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10641314089298248
Epoch 0, Step 1310: train/loss = 0.5021448135375977, train/raw-loss = 0.4433250427246094, train/logprobs = tensor([[-0.5327, -2.7777],
        [-0.9120, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803298115730286
Epoch 0, Step 1311: train/loss = 0.4067268371582031, train/raw-loss = 0.3454208970069885, train/logprobs = tensor([[-0.5515, -3.5928],
        [-1.2259, -0.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10217656195163727
Epoch 0, Step 1312: train/loss = 0.510295033454895, train/raw-loss = 0.44551464915275574, train/logprobs = tensor([[-0.5987, -2.0566],
        [-1.0461, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1079673320055008
Epoch 0, Step 1313: train/loss = 0.8021369576454163, train/raw-loss = 0.7402528524398804, train/logprobs = tensor([[-1.3004, -1.4712],
        [-0.6876, -0.6299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314011573791504
Epoch 0, Step 1314: train/loss = 0.7702604532241821, train/raw-loss = 0.7106444835662842, train/logprobs = tensor([[-1.1927, -1.1850],
        [-0.8554, -0.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09935995936393738
Epoch 0, Step 1315: train/loss = 0.33668190240859985, train/raw-loss = 0.27239376306533813, train/logprobs = tensor([[-0.4978, -8.7248],
        [-1.1947, -1.8442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714691132307053
Epoch 0, Step 1316: train/loss = 0.5126302242279053, train/raw-loss = 0.4583239257335663, train/logprobs = tensor([[-0.5614, -1.6941],
        [-0.9178, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09051045775413513
Epoch 0, Step 1317: train/loss = 0.5678415298461914, train/raw-loss = 0.5026572942733765, train/logprobs = tensor([[-0.4698, -1.8220],
        [-1.0229, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10864026844501495
Epoch 0, Step 1318: train/loss = 0.4091813564300537, train/raw-loss = 0.34627199172973633, train/logprobs = tensor([[-0.5258, -5.0747],
        [-0.8952, -1.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484889149665833
Epoch 0, Step 1319: train/loss = 0.3685387670993805, train/raw-loss = 0.2991487383842468, train/logprobs = tensor([[-0.5228, -3.2115],
        [-1.2853, -0.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11565002053976059
Epoch 0, Step 1320: train/loss = 0.4646384119987488, train/raw-loss = 0.401919960975647, train/logprobs = tensor([[-0.8435, -4.2176],
        [-1.4793, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453072190284729
Epoch 0, Step 1321: train/loss = 0.5765399932861328, train/raw-loss = 0.5134234428405762, train/logprobs = tensor([[-0.4415, -1.6261],
        [-0.6989, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519441217184067
Epoch 0, Step 1322: train/loss = 0.48489946126937866, train/raw-loss = 0.42675307393074036, train/logprobs = tensor([[-0.4673, -1.7522],
        [-0.9038, -0.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09691059589385986
Epoch 0, Step 1323: train/loss = 0.5751370191574097, train/raw-loss = 0.5309683084487915, train/logprobs = tensor([[-0.5923, -2.9771],
        [-0.4987, -0.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07361450791358948
Epoch 0, Step 1324: train/loss = 0.4785892963409424, train/raw-loss = 0.4138825237751007, train/logprobs = tensor([[-0.4342, -4.4886],
        [-0.7131, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10784465074539185
Epoch 0, Step 1325: train/loss = 0.5957499146461487, train/raw-loss = 0.5467034578323364, train/logprobs = tensor([[-0.3290, -1.9884],
        [-0.5649, -1.1898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174417912960052
Epoch 0, Step 1326: train/loss = 0.46814122796058655, train/raw-loss = 0.39682644605636597, train/logprobs = tensor([[-1.2218, -4.5515],
        [-1.1489, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11885794997215271
Epoch 0, Step 1327: train/loss = 0.5311659574508667, train/raw-loss = 0.46254852414131165, train/logprobs = tensor([[-1.3593, -2.7156],
        [-1.4185, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11436231434345245
Epoch 0, Step 1328: train/loss = 0.42809444665908813, train/raw-loss = 0.3642641305923462, train/logprobs = tensor([[-0.6549, -3.3247],
        [-0.9198, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10638386756181717
Epoch 0, Step 1329: train/loss = 0.3028959631919861, train/raw-loss = 0.23381124436855316, train/logprobs = tensor([[-0.9258, -4.6372],
        [-1.7208, -0.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11514119803905487
Epoch 0, Step 1330: train/loss = 0.5601499676704407, train/raw-loss = 0.4872997999191284, train/logprobs = tensor([[-0.8646, -4.1571],
        [-0.9584, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141693383455276
Epoch 0, Step 1331: train/loss = 0.411787748336792, train/raw-loss = 0.34106484055519104, train/logprobs = tensor([[-0.7180, -2.4219],
        [-1.2708, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11787150055170059
Epoch 0, Step 1332: train/loss = 0.3457038104534149, train/raw-loss = 0.2706044614315033, train/logprobs = tensor([[-0.6355, -3.5413],
        [-1.0931, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12516555190086365
Epoch 0, Step 1333: train/loss = 0.5166531801223755, train/raw-loss = 0.45304250717163086, train/logprobs = tensor([[-0.6035, -2.5817],
        [-0.9516, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10601785778999329
Epoch 0, Step 1334: train/loss = 0.6378499865531921, train/raw-loss = 0.5721973776817322, train/logprobs = tensor([[-1.5219, -2.6874],
        [-1.6125, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10942097753286362
Epoch 0, Step 1335: train/loss = 0.4081379771232605, train/raw-loss = 0.3374466598033905, train/logprobs = tensor([[-1.6703, -5.0445],
        [-2.0196, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11781887710094452
Epoch 0, Step 1336: train/loss = 0.43642717599868774, train/raw-loss = 0.37561655044555664, train/logprobs = tensor([[-0.5951, -6.9578],
        [-0.9643, -1.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10135102272033691
Epoch 0, Step 1337: train/loss = 0.5065613389015198, train/raw-loss = 0.46549010276794434, train/logprobs = tensor([[-0.3327, -4.3465],
        [-0.5776, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06845203787088394
Epoch 0, Step 1338: train/loss = 0.40754467248916626, train/raw-loss = 0.32505151629447937, train/logprobs = tensor([[-0.5340, -3.1412],
        [-1.1751, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13748861849308014
Epoch 0, Step 1339: train/loss = 0.44288772344589233, train/raw-loss = 0.36972811818122864, train/logprobs = tensor([[-0.8767, -2.6596],
        [-1.5340, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12193265557289124
Epoch 0, Step 1340: train/loss = 0.3082922697067261, train/raw-loss = 0.23337674140930176, train/logprobs = tensor([[-0.5902, -3.8395],
        [-1.5015, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12485918402671814
Epoch 0, Step 1341: train/loss = 0.4041352868080139, train/raw-loss = 0.35406017303466797, train/logprobs = tensor([[-0.7028, -3.0378],
        [-1.2897, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08345849812030792
Epoch 0, Step 1342: train/loss = 0.6591686606407166, train/raw-loss = 0.6047325730323792, train/logprobs = tensor([[-0.6923, -1.8262],
        [-0.4380, -0.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09072679281234741
Epoch 0, Step 1343: train/loss = 0.3103010952472687, train/raw-loss = 0.2436438649892807, train/logprobs = tensor([[-0.6612, -2.8493],
        [-1.6456, -0.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11109533905982971
Epoch 0, Step 1344: train/loss = 0.6855886578559875, train/raw-loss = 0.626905083656311, train/logprobs = tensor([[-1.5332, -3.1016],
        [-0.8398, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780599176883698
Epoch 0, Step 1345: train/loss = 0.5735192894935608, train/raw-loss = 0.5009411573410034, train/logprobs = tensor([[-0.8295, -2.1181],
        [-1.2265, -0.7468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12096358835697174
Epoch 0, Step 1346: train/loss = 0.554879903793335, train/raw-loss = 0.4823511838912964, train/logprobs = tensor([[-0.8358, -1.9290],
        [-1.0333, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12088114023208618
Epoch 0, Step 1347: train/loss = 0.5042641758918762, train/raw-loss = 0.43883028626441956, train/logprobs = tensor([[-0.8101, -2.3853],
        [-1.2370, -0.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10905644297599792
Epoch 0, Step 1348: train/loss = 0.5262520909309387, train/raw-loss = 0.4775494933128357, train/logprobs = tensor([[-0.7107, -1.5559],
        [-1.2418, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08117102086544037
Epoch 0, Step 1349: train/loss = 0.49439433217048645, train/raw-loss = 0.4362024664878845, train/logprobs = tensor([[-0.7521, -1.8428],
        [-1.1457, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09698640555143356
Epoch 0, Step 1350: train/loss = 0.3825135827064514, train/raw-loss = 0.32563257217407227, train/logprobs = tensor([[-0.5306, -6.0899],
        [-1.0241, -1.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09480166435241699
Epoch 0, Step 1351: train/loss = 0.5060288906097412, train/raw-loss = 0.4438317120075226, train/logprobs = tensor([[-1.0393, -2.5279],
        [-1.4257, -1.4029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10366198420524597
Epoch 0, Step 1352: train/loss = 0.5545903444290161, train/raw-loss = 0.5111640691757202, train/logprobs = tensor([[-0.5367, -1.6680],
        [-0.7038, -0.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07237717509269714
Epoch 0, Step 1353: train/loss = 0.59429532289505, train/raw-loss = 0.5459813475608826, train/logprobs = tensor([[-0.5084, -3.0392],
        [-0.6607, -0.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08052332699298859
Epoch 0, Step 1354: train/loss = 0.4845212399959564, train/raw-loss = 0.4084070920944214, train/logprobs = tensor([[-0.5628, -1.6763],
        [-1.3484, -0.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12685689330101013
Epoch 0, Step 1355: train/loss = 0.25773537158966064, train/raw-loss = 0.1962662637233734, train/logprobs = tensor([[-0.6117, -6.1647],
        [-1.2089, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10244853794574738
Epoch 0, Step 1356: train/loss = 0.5312629342079163, train/raw-loss = 0.475166380405426, train/logprobs = tensor([[-0.7749, -2.5878],
        [-1.0219, -0.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09349425137042999
Epoch 0, Step 1357: train/loss = 0.6255990266799927, train/raw-loss = 0.5666377544403076, train/logprobs = tensor([[-0.4398, -0.9941],
        [-0.7534, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09826868772506714
Epoch 0, Step 1358: train/loss = 0.35307577252388, train/raw-loss = 0.28541553020477295, train/logprobs = tensor([[-0.5428, -3.5175],
        [-1.3274, -0.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127670556306839
Epoch 0, Step 1359: train/loss = 0.5907047390937805, train/raw-loss = 0.5135195255279541, train/logprobs = tensor([[-0.4549, -2.2491],
        [-0.8665, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864208221435547
Epoch 0, Step 1360: train/loss = 0.3945837616920471, train/raw-loss = 0.3375821113586426, train/logprobs = tensor([[-0.5784, -3.0564],
        [-1.0042, -0.9560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09500279277563095
Epoch 0, Step 1361: train/loss = 0.4105485677719116, train/raw-loss = 0.34506627917289734, train/logprobs = tensor([[-0.7121, -3.5557],
        [-0.9871, -0.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10913719236850739
Epoch 0, Step 1362: train/loss = 0.44590264558792114, train/raw-loss = 0.36986395716667175, train/logprobs = tensor([[-0.5895, -2.8141],
        [-1.4897, -0.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12673115730285645
Epoch 0, Step 1363: train/loss = 0.5768868923187256, train/raw-loss = 0.5318102836608887, train/logprobs = tensor([[-0.3662, -1.7202],
        [-0.7539, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751277282834053
Epoch 0, Step 1364: train/loss = 0.45657920837402344, train/raw-loss = 0.3961978554725647, train/logprobs = tensor([[-0.4152, -3.2622],
        [-0.7661, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006355956196785
Epoch 0, Step 1365: train/loss = 0.41953137516975403, train/raw-loss = 0.3607128858566284, train/logprobs = tensor([[-0.3495, -4.1723],
        [-0.7193, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803085029125214
Epoch 0, Step 1366: train/loss = 0.5477888584136963, train/raw-loss = 0.49755358695983887, train/logprobs = tensor([[-0.3726, -3.1114],
        [-0.6190, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08372532576322556
Epoch 0, Step 1367: train/loss = 0.3783620297908783, train/raw-loss = 0.3145958185195923, train/logprobs = tensor([[-0.5694, -3.8286],
        [-1.4583, -1.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062769964337349
Epoch 0, Step 1368: train/loss = 0.6002559661865234, train/raw-loss = 0.5468392968177795, train/logprobs = tensor([[-0.5757, -1.7833],
        [-0.7565, -0.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0890277773141861
Epoch 0, Step 1369: train/loss = 0.4698048233985901, train/raw-loss = 0.400590181350708, train/logprobs = tensor([[-0.4716, -1.6687],
        [-1.5291, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11535778641700745
Epoch 0, Step 1370: train/loss = 0.5629703998565674, train/raw-loss = 0.5023356676101685, train/logprobs = tensor([[-0.6357, -1.4588],
        [-0.9286, -0.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10105793178081512
Epoch 0, Step 1371: train/loss = 0.47963747382164, train/raw-loss = 0.42247849702835083, train/logprobs = tensor([[-0.5300, -3.1055],
        [-0.9475, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526494145393372
Epoch 0, Step 1372: train/loss = 0.37315821647644043, train/raw-loss = 0.30975067615509033, train/logprobs = tensor([[-0.6052, -5.0758],
        [-1.2667, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056792214512825
Epoch 0, Step 1373: train/loss = 0.5268535614013672, train/raw-loss = 0.475111186504364, train/logprobs = tensor([[-1.1761, -2.0685],
        [-1.7484, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08623728156089783
Epoch 0, Step 1374: train/loss = 0.45542943477630615, train/raw-loss = 0.40167078375816345, train/logprobs = tensor([[-0.4026, -3.2138],
        [-0.9024, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08959771692752838
Epoch 0, Step 1375: train/loss = 0.3672877252101898, train/raw-loss = 0.3102768063545227, train/logprobs = tensor([[-0.6179, -5.5109],
        [-1.0859, -1.3582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09501820057630539
Epoch 0, Step 1376: train/loss = 0.35159844160079956, train/raw-loss = 0.28135520219802856, train/logprobs = tensor([[-0.9309, -3.3440],
        [-1.8205, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707212030887604
Epoch 0, Step 1377: train/loss = 0.5019408464431763, train/raw-loss = 0.4449712038040161, train/logprobs = tensor([[-0.4489, -3.5915],
        [-0.7944, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09494944661855698
Epoch 0, Step 1378: train/loss = 0.5148414373397827, train/raw-loss = 0.4568481147289276, train/logprobs = tensor([[-0.7212, -2.6049],
        [-0.9450, -0.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665553271770477
Epoch 0, Step 1379: train/loss = 0.5262060165405273, train/raw-loss = 0.45721232891082764, train/logprobs = tensor([[-0.8280, -2.3855],
        [-1.1789, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11498939990997314
Epoch 0, Step 1380: train/loss = 0.29262858629226685, train/raw-loss = 0.2189902365207672, train/logprobs = tensor([[-0.4670, -4.8343],
        [-1.1374, -0.9269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12273057550191879
Epoch 0, Step 1381: train/loss = 0.4132210612297058, train/raw-loss = 0.3465133309364319, train/logprobs = tensor([[-0.4898, -5.4578],
        [-0.9013, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11117954552173615
Epoch 0, Step 1382: train/loss = 0.4218485355377197, train/raw-loss = 0.35331273078918457, train/logprobs = tensor([[-0.7514, -3.9009],
        [-1.1687, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1142263412475586
Epoch 0, Step 1383: train/loss = 0.34889936447143555, train/raw-loss = 0.290818989276886, train/logprobs = tensor([[-0.7923, -4.0622],
        [-1.4400, -1.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09680061042308807
Epoch 0, Step 1384: train/loss = 0.5024588704109192, train/raw-loss = 0.44162559509277344, train/logprobs = tensor([[-0.5467, -3.1167],
        [-0.9607, -1.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138875991106033
Epoch 0, Step 1385: train/loss = 0.4354555010795593, train/raw-loss = 0.3516615033149719, train/logprobs = tensor([[-0.6748, -2.0842],
        [-1.6821, -0.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13965663313865662
Epoch 0, Step 1386: train/loss = 0.40570080280303955, train/raw-loss = 0.32475540041923523, train/logprobs = tensor([[-0.6711, -2.2956],
        [-1.3438, -0.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349090337753296
Epoch 0, Step 1387: train/loss = 0.529977560043335, train/raw-loss = 0.45732200145721436, train/logprobs = tensor([[-0.5405, -1.3592],
        [-1.1196, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12109263241291046
Epoch 0, Step 1388: train/loss = 0.3644102215766907, train/raw-loss = 0.30634647607803345, train/logprobs = tensor([[-0.9359, -3.4620],
        [-1.4508, -0.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09677287191152573
Epoch 0, Step 1389: train/loss = 0.5562012791633606, train/raw-loss = 0.4834977984428406, train/logprobs = tensor([[-0.9403, -2.7409],
        [-1.1195, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12117243558168411
Epoch 0, Step 1390: train/loss = 0.5264461636543274, train/raw-loss = 0.46300122141838074, train/logprobs = tensor([[-0.4939, -1.5146],
        [-0.8551, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10574161261320114
Epoch 0, Step 1391: train/loss = 0.45176446437835693, train/raw-loss = 0.38760796189308167, train/logprobs = tensor([[-0.5518, -2.5852],
        [-0.9142, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10692751407623291
Epoch 0, Step 1392: train/loss = 0.3764020502567291, train/raw-loss = 0.31743866205215454, train/logprobs = tensor([[-0.6163, -6.0263],
        [-1.0422, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827234596014023
Epoch 0, Step 1393: train/loss = 0.35761314630508423, train/raw-loss = 0.2757722735404968, train/logprobs = tensor([[-0.5447, -6.1623],
        [-1.4080, -1.4060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364014595746994
Epoch 0, Step 1394: train/loss = 0.45386233925819397, train/raw-loss = 0.38133805990219116, train/logprobs = tensor([[-0.5298, -1.7242],
        [-1.2186, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1208738163113594
Epoch 0, Step 1395: train/loss = 0.44826236367225647, train/raw-loss = 0.36664584279060364, train/logprobs = tensor([[-0.6407, -2.9612],
        [-1.1208, -1.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360275000333786
Epoch 0, Step 1396: train/loss = 0.38482150435447693, train/raw-loss = 0.30280429124832153, train/logprobs = tensor([[-0.7075, -4.6695],
        [-1.2025, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13669534027576447
Epoch 0, Step 1397: train/loss = 0.36922335624694824, train/raw-loss = 0.30997270345687866, train/logprobs = tensor([[-0.5091, -8.1742],
        [-0.7810, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09875106066465378
Epoch 0, Step 1398: train/loss = 0.2798398733139038, train/raw-loss = 0.18627233803272247, train/logprobs = tensor([[-0.7590, -4.0670],
        [-1.5958, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15594592690467834
Epoch 0, Step 1399: train/loss = 0.36801213026046753, train/raw-loss = 0.2859385013580322, train/logprobs = tensor([[-0.4629, -3.0675],
        [-1.6669, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13678932189941406
Epoch 0, Step 1400: train/loss = 0.5574519038200378, train/raw-loss = 0.4864232838153839, train/logprobs = tensor([[-0.6205, -7.2265],
        [-1.0271, -2.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11838096380233765
Epoch 0, Step 1401: train/loss = 0.40629494190216064, train/raw-loss = 0.3147372603416443, train/logprobs = tensor([[-0.9884, -5.0313],
        [-1.7066, -1.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525961458683014
Epoch 0, Step 1402: train/loss = 0.4003499746322632, train/raw-loss = 0.3312857151031494, train/logprobs = tensor([[-0.5652, -3.4398],
        [-1.1736, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11510706692934036
Epoch 0, Step 1403: train/loss = 0.42471811175346375, train/raw-loss = 0.36050504446029663, train/logprobs = tensor([[-1.0829, -3.9076],
        [-1.1254, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702177882194519
Epoch 0, Step 1404: train/loss = 0.3912464678287506, train/raw-loss = 0.3299969732761383, train/logprobs = tensor([[-0.6173, -6.6596],
        [-1.3060, -1.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10208249092102051
Epoch 0, Step 1405: train/loss = 0.4824985861778259, train/raw-loss = 0.4038372039794922, train/logprobs = tensor([[-0.5870, -4.6748],
        [-1.2777, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13110224902629852
Epoch 0, Step 1406: train/loss = 0.5339157581329346, train/raw-loss = 0.47260287404060364, train/logprobs = tensor([[-0.4390, -1.7056],
        [-0.8237, -0.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1021880954504013
Epoch 0, Step 1407: train/loss = 0.42011773586273193, train/raw-loss = 0.36129772663116455, train/logprobs = tensor([[-0.7338, -6.1092],
        [-0.9675, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980333536863327
Epoch 0, Step 1408: train/loss = 0.24058622121810913, train/raw-loss = 0.17397548258304596, train/logprobs = tensor([[-0.5411, -8.8206],
        [-1.3504, -1.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11101788282394409
Epoch 0, Step 1409: train/loss = 0.6364355683326721, train/raw-loss = 0.5788207650184631, train/logprobs = tensor([[-0.5317, -0.9657],
        [-0.7758, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09602466225624084
Epoch 0, Step 1410: train/loss = 0.44322526454925537, train/raw-loss = 0.36069321632385254, train/logprobs = tensor([[-0.6593, -3.3530],
        [-1.4515, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1375533938407898
Epoch 0, Step 1411: train/loss = 0.4708039164543152, train/raw-loss = 0.40167826414108276, train/logprobs = tensor([[-0.3912, -3.1209],
        [-0.8408, -0.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11520945280790329
Epoch 0, Step 1412: train/loss = 0.4070977568626404, train/raw-loss = 0.3392828702926636, train/logprobs = tensor([[-0.5332, -2.0116],
        [-1.3351, -0.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11302486062049866
Epoch 0, Step 1413: train/loss = 0.39987510442733765, train/raw-loss = 0.34155723452568054, train/logprobs = tensor([[-0.6750, -3.3208],
        [-1.0272, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09719642996788025
Epoch 0, Step 1414: train/loss = 0.5010573863983154, train/raw-loss = 0.44701677560806274, train/logprobs = tensor([[-0.6347, -4.4207],
        [-1.1137, -1.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006765484809875
Epoch 0, Step 1415: train/loss = 0.5738569498062134, train/raw-loss = 0.5296143293380737, train/logprobs = tensor([[-0.4276, -1.0555],
        [-0.7374, -0.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07373777776956558
Epoch 0, Step 1416: train/loss = 0.36703863739967346, train/raw-loss = 0.3084060847759247, train/logprobs = tensor([[-0.7150, -7.0139],
        [-1.2386, -1.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09772085398435593
Epoch 0, Step 1417: train/loss = 0.31824713945388794, train/raw-loss = 0.2532961368560791, train/logprobs = tensor([[-0.4239, -5.9972],
        [-1.0558, -1.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1082516759634018
Epoch 0, Step 1418: train/loss = 0.48436665534973145, train/raw-loss = 0.419633686542511, train/logprobs = tensor([[-0.7041, -2.5825],
        [-1.0453, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10788826644420624
Epoch 0, Step 1419: train/loss = 0.5969880819320679, train/raw-loss = 0.547174334526062, train/logprobs = tensor([[-0.3551, -1.2693],
        [-0.7330, -0.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08302280306816101
Epoch 0, Step 1420: train/loss = 0.38949835300445557, train/raw-loss = 0.3237910568714142, train/logprobs = tensor([[-0.3843, -3.6573],
        [-1.0100, -0.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951216518878937
Epoch 0, Step 1421: train/loss = 0.5591592192649841, train/raw-loss = 0.5018149614334106, train/logprobs = tensor([[-0.5196, -2.5672],
        [-0.9979, -1.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09557367861270905
Epoch 0, Step 1422: train/loss = 0.6147534251213074, train/raw-loss = 0.567486047744751, train/logprobs = tensor([[-0.2816, -0.9995],
        [-0.5491, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877891510725021
Epoch 0, Step 1423: train/loss = 0.43093428015708923, train/raw-loss = 0.3712840676307678, train/logprobs = tensor([[-0.3963, -2.8503],
        [-0.8450, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941700100898743
Epoch 0, Step 1424: train/loss = 0.2326040267944336, train/raw-loss = 0.1559504270553589, train/logprobs = tensor([[-0.5828, -7.0539],
        [-1.7779, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1277560293674469
Epoch 0, Step 1425: train/loss = 0.32773467898368835, train/raw-loss = 0.2624622583389282, train/logprobs = tensor([[-0.7474, -3.9534],
        [-1.4829, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10878736525774002
Epoch 0, Step 1426: train/loss = 0.3490210175514221, train/raw-loss = 0.2792600691318512, train/logprobs = tensor([[-0.6361, -7.5216],
        [-1.4357, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11626817286014557
Epoch 0, Step 1427: train/loss = 0.5102865099906921, train/raw-loss = 0.44316208362579346, train/logprobs = tensor([[-0.6165, -1.9027],
        [-1.1961, -0.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11187401413917542
Epoch 0, Step 1428: train/loss = 0.3917168974876404, train/raw-loss = 0.32627636194229126, train/logprobs = tensor([[-0.5103, -3.7489],
        [-1.1902, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906755924224854
Epoch 0, Step 1429: train/loss = 0.3702632784843445, train/raw-loss = 0.2996872365474701, train/logprobs = tensor([[-0.6919, -5.4903],
        [-1.2452, -0.7139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11762673407793045
Epoch 0, Step 1430: train/loss = 0.3577553331851959, train/raw-loss = 0.2925027906894684, train/logprobs = tensor([[-1.0004, -6.0054],
        [-1.7039, -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10875420272350311
Epoch 0, Step 1431: train/loss = 0.24628819525241852, train/raw-loss = 0.16596771776676178, train/logprobs = tensor([[ -0.6816, -11.0534],
        [ -1.6088,  -2.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386747241020203
Epoch 0, Step 1432: train/loss = 0.6365077495574951, train/raw-loss = 0.5569629669189453, train/logprobs = tensor([[-0.4537, -4.5107],
        [-1.6485, -1.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13257451355457306
Epoch 0, Step 1433: train/loss = 0.4828500747680664, train/raw-loss = 0.42242348194122314, train/logprobs = tensor([[-0.4286, -2.9508],
        [-1.1684, -0.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10071097314357758
Epoch 0, Step 1434: train/loss = 0.3149142563343048, train/raw-loss = 0.23101823031902313, train/logprobs = tensor([[-0.5983, -3.9406],
        [-1.6450, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1398267149925232
Epoch 0, Step 1435: train/loss = 0.39423051476478577, train/raw-loss = 0.30693215131759644, train/logprobs = tensor([[-0.6103, -5.1520],
        [-1.6541, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14549723267555237
Epoch 0, Step 1436: train/loss = 0.45098617672920227, train/raw-loss = 0.39459705352783203, train/logprobs = tensor([[-1.2649, -7.2548],
        [-1.3499, -1.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09398183971643448
Epoch 0, Step 1437: train/loss = 0.4475998282432556, train/raw-loss = 0.3914516568183899, train/logprobs = tensor([[-0.4283, -6.4798],
        [-1.0857, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09358033537864685
Epoch 0, Step 1438: train/loss = 0.22396054863929749, train/raw-loss = 0.16166141629219055, train/logprobs = tensor([[-0.7270, -8.2622],
        [-2.0426, -1.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10383188724517822
Epoch 0, Step 1439: train/loss = 0.4166441261768341, train/raw-loss = 0.3674992024898529, train/logprobs = tensor([[-0.6169, -3.1918],
        [-1.4069, -0.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819081962108612
Epoch 0, Step 1440: train/loss = 0.4581211507320404, train/raw-loss = 0.3930792808532715, train/logprobs = tensor([[-0.5386, -2.8186],
        [-1.1510, -0.7194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1084030345082283
Epoch 0, Step 1441: train/loss = 0.6433064937591553, train/raw-loss = 0.5782525539398193, train/logprobs = tensor([[-0.7232, -1.3205],
        [-0.8855, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10842324048280716
Epoch 0, Step 1442: train/loss = 0.22765123844146729, train/raw-loss = 0.14825578033924103, train/logprobs = tensor([[-0.7729, -5.0286],
        [-2.0135, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13232576847076416
Epoch 0, Step 1443: train/loss = 0.6271934509277344, train/raw-loss = 0.5674241185188293, train/logprobs = tensor([[-0.7839, -2.7427],
        [-0.8184, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09961552917957306
Epoch 0, Step 1444: train/loss = 0.3708413243293762, train/raw-loss = 0.2857465147972107, train/logprobs = tensor([[-0.6769, -3.1664],
        [-1.8658, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418246328830719
Epoch 0, Step 1445: train/loss = 0.45733028650283813, train/raw-loss = 0.40086549520492554, train/logprobs = tensor([[-0.3128, -2.9222],
        [-0.7300, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09410801529884338
Epoch 0, Step 1446: train/loss = 0.4935701787471771, train/raw-loss = 0.42608964443206787, train/logprobs = tensor([[-1.0315, -6.8245],
        [-1.3401, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246752738952637
Epoch 0, Step 1447: train/loss = 0.45019251108169556, train/raw-loss = 0.3860393762588501, train/logprobs = tensor([[-1.1251, -3.4780],
        [-1.1662, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10692182183265686
Epoch 0, Step 1448: train/loss = 0.4295247495174408, train/raw-loss = 0.35372135043144226, train/logprobs = tensor([[-0.8407, -3.1299],
        [-1.0407, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12633898854255676
Epoch 0, Step 1449: train/loss = 0.5222511291503906, train/raw-loss = 0.45952725410461426, train/logprobs = tensor([[-0.4662, -4.0355],
        [-1.0413, -1.2412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453984141349792
Epoch 0, Step 1450: train/loss = 0.39021992683410645, train/raw-loss = 0.32198965549468994, train/logprobs = tensor([[-0.3940, -3.1014],
        [-0.9475, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11371707916259766
Epoch 0, Step 1451: train/loss = 0.42649900913238525, train/raw-loss = 0.35411903262138367, train/logprobs = tensor([[-0.6919, -3.9716],
        [-1.4115, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12063329666852951
Epoch 0, Step 1452: train/loss = 0.4706205725669861, train/raw-loss = 0.39268162846565247, train/logprobs = tensor([[-0.5163, -5.4764],
        [-1.3212, -1.4769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12989819049835205
Epoch 0, Step 1453: train/loss = 0.3877996802330017, train/raw-loss = 0.3248476982116699, train/logprobs = tensor([[-0.5401, -2.8262],
        [-1.1610, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10491995513439178
Epoch 0, Step 1454: train/loss = 0.3710138499736786, train/raw-loss = 0.29787349700927734, train/logprobs = tensor([[-0.6321, -3.5231],
        [-1.6559, -1.3465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12190058827400208
Epoch 0, Step 1455: train/loss = 0.28377026319503784, train/raw-loss = 0.2130574882030487, train/logprobs = tensor([[-0.4952, -4.8256],
        [-2.0289, -2.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785465478897095
Epoch 0, Step 1456: train/loss = 0.3406175971031189, train/raw-loss = 0.2829379737377167, train/logprobs = tensor([[-0.6831, -6.3518],
        [-1.1383, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613268077373505
Epoch 0, Step 1457: train/loss = 0.3811578154563904, train/raw-loss = 0.31936293840408325, train/logprobs = tensor([[-0.6061, -4.3715],
        [-1.3843, -1.7554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10299146175384521
Epoch 0, Step 1458: train/loss = 0.6456694602966309, train/raw-loss = 0.5778930187225342, train/logprobs = tensor([[-0.6116, -0.8802],
        [-1.0747, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11296077817678452
Epoch 0, Step 1459: train/loss = 0.2801337242126465, train/raw-loss = 0.19107091426849365, train/logprobs = tensor([[-0.5670, -6.3217],
        [-1.8484, -1.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484379917383194
Epoch 0, Step 1460: train/loss = 0.31684014201164246, train/raw-loss = 0.24619483947753906, train/logprobs = tensor([[-0.8914, -6.0369],
        [-1.6183, -1.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11774218082427979
Epoch 0, Step 1461: train/loss = 0.5371649265289307, train/raw-loss = 0.45347416400909424, train/logprobs = tensor([[-0.5661, -2.0651],
        [-1.6363, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13948461413383484
Epoch 0, Step 1462: train/loss = 0.41466182470321655, train/raw-loss = 0.34129464626312256, train/logprobs = tensor([[-0.5627, -2.7855],
        [-1.2562, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227866053581238
Epoch 0, Step 1463: train/loss = 0.31121569871902466, train/raw-loss = 0.22768378257751465, train/logprobs = tensor([[-0.6720, -3.7321],
        [-1.9952, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13921982049942017
Epoch 0, Step 1464: train/loss = 0.4788382351398468, train/raw-loss = 0.40983277559280396, train/logprobs = tensor([[-0.5227, -3.0664],
        [-1.0742, -0.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11500903964042664
Epoch 0, Step 1465: train/loss = 0.33303695917129517, train/raw-loss = 0.272675096988678, train/logprobs = tensor([[-0.6457, -5.0606],
        [-1.6396, -1.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006031334400177
Epoch 0, Step 1466: train/loss = 0.4778044521808624, train/raw-loss = 0.41140079498291016, train/logprobs = tensor([[-0.5510, -3.4385],
        [-0.8826, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11067275702953339
Epoch 0, Step 1467: train/loss = 0.35763251781463623, train/raw-loss = 0.28804945945739746, train/logprobs = tensor([[-0.7301, -7.0676],
        [-1.7529, -1.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11597170680761337
Epoch 0, Step 1468: train/loss = 0.5108969807624817, train/raw-loss = 0.4436376690864563, train/logprobs = tensor([[-1.1255, -5.7886],
        [-1.5373, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11209888756275177
Epoch 0, Step 1469: train/loss = 0.42702001333236694, train/raw-loss = 0.3591265082359314, train/logprobs = tensor([[-0.4495, -2.6498],
        [-0.9317, -0.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11315587162971497
Epoch 0, Step 1470: train/loss = 0.3285678029060364, train/raw-loss = 0.2431614100933075, train/logprobs = tensor([[-0.6069, -3.6261],
        [-1.3249, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14234399795532227
Epoch 0, Step 1471: train/loss = 0.4874791204929352, train/raw-loss = 0.41419726610183716, train/logprobs = tensor([[-0.4570, -2.0014],
        [-1.1160, -1.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12213635444641113
Epoch 0, Step 1472: train/loss = 0.40123412013053894, train/raw-loss = 0.3491019904613495, train/logprobs = tensor([[-0.5159, -7.1984],
        [-0.8393, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08688688278198242
Epoch 0, Step 1473: train/loss = 0.3631887137889862, train/raw-loss = 0.2834795117378235, train/logprobs = tensor([[-0.6480, -3.0873],
        [-1.3427, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13284868001937866
Epoch 0, Step 1474: train/loss = 0.4498905539512634, train/raw-loss = 0.38228970766067505, train/logprobs = tensor([[-0.6560, -2.5900],
        [-1.1685, -1.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11266805976629257
Epoch 0, Step 1475: train/loss = 0.49752962589263916, train/raw-loss = 0.43181708455085754, train/logprobs = tensor([[-0.6204, -1.8455],
        [-1.2572, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10952092707157135
Epoch 0, Step 1476: train/loss = 0.5441642999649048, train/raw-loss = 0.4686139225959778, train/logprobs = tensor([[-0.9583, -2.7932],
        [-1.1857, -1.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259172558784485
Epoch 0, Step 1477: train/loss = 0.3235812485218048, train/raw-loss = 0.25161466002464294, train/logprobs = tensor([[-0.9169, -4.7972],
        [-1.6743, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11994431912899017
Epoch 0, Step 1478: train/loss = 0.6094822883605957, train/raw-loss = 0.5347745418548584, train/logprobs = tensor([[-0.4566, -0.8683],
        [-1.1776, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12451288849115372
Epoch 0, Step 1479: train/loss = 0.5308306217193604, train/raw-loss = 0.44426724314689636, train/logprobs = tensor([[-0.4965, -2.2854],
        [-1.2145, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1442723423242569
Epoch 0, Step 1480: train/loss = 0.4257926642894745, train/raw-loss = 0.35112816095352173, train/logprobs = tensor([[-0.7069, -3.9273],
        [-1.8689, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12444089353084564
Epoch 0, Step 1481: train/loss = 0.4221971333026886, train/raw-loss = 0.3469453752040863, train/logprobs = tensor([[-0.6557, -4.3335],
        [-1.6110, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12541960179805756
Epoch 0, Step 1482: train/loss = 0.3418448567390442, train/raw-loss = 0.27230197191238403, train/logprobs = tensor([[-0.5193, -6.3511],
        [-1.2101, -1.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1159047856926918
Epoch 0, Step 1483: train/loss = 0.4087541103363037, train/raw-loss = 0.33636152744293213, train/logprobs = tensor([[-0.6014, -3.0960],
        [-1.6113, -0.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12065436691045761
Epoch 0, Step 1484: train/loss = 0.3256904184818268, train/raw-loss = 0.24618512392044067, train/logprobs = tensor([[-0.3980, -4.2615],
        [-1.3128, -0.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13250882923603058
Epoch 0, Step 1485: train/loss = 0.563201904296875, train/raw-loss = 0.489307165145874, train/logprobs = tensor([[-0.5675, -2.2763],
        [-0.9975, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12315788120031357
Epoch 0, Step 1486: train/loss = 0.5652656555175781, train/raw-loss = 0.4955293536186218, train/logprobs = tensor([[-0.8055, -1.9491],
        [-0.8944, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11622713506221771
Epoch 0, Step 1487: train/loss = 0.36303624510765076, train/raw-loss = 0.30061593651771545, train/logprobs = tensor([[-0.9092, -3.4280],
        [-1.5321, -0.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10403385758399963
Epoch 0, Step 1488: train/loss = 0.5425822734832764, train/raw-loss = 0.4681954085826874, train/logprobs = tensor([[-0.4100, -1.6164],
        [-0.9223, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12397806346416473
Epoch 0, Step 1489: train/loss = 0.5300986170768738, train/raw-loss = 0.4759710431098938, train/logprobs = tensor([[-0.7166, -2.6842],
        [-1.0065, -0.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09021254628896713
Epoch 0, Step 1490: train/loss = 0.506030797958374, train/raw-loss = 0.4414973258972168, train/logprobs = tensor([[-0.4558, -2.6014],
        [-1.1334, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10755576193332672
Epoch 0, Step 1491: train/loss = 0.36400678753852844, train/raw-loss = 0.27921634912490845, train/logprobs = tensor([[-0.9745, -4.8393],
        [-1.6664, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1413174271583557
Epoch 0, Step 1492: train/loss = 0.4889538884162903, train/raw-loss = 0.4214033782482147, train/logprobs = tensor([[-0.5686, -3.0874],
        [-1.2330, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258413642644882
Epoch 0, Step 1493: train/loss = 0.383536696434021, train/raw-loss = 0.3116835951805115, train/logprobs = tensor([[-0.5519, -2.3758],
        [-1.7060, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11975515633821487
Epoch 0, Step 1494: train/loss = 0.31846821308135986, train/raw-loss = 0.22308529913425446, train/logprobs = tensor([[-0.5260, -3.9060],
        [-1.5749, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15897148847579956
Epoch 0, Step 1495: train/loss = 0.29310041666030884, train/raw-loss = 0.21500535309314728, train/logprobs = tensor([[-0.4727, -5.4420],
        [-1.4256, -1.2258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301584243774414
Epoch 0, Step 1496: train/loss = 0.3524596095085144, train/raw-loss = 0.2824779748916626, train/logprobs = tensor([[-0.5759, -4.2199],
        [-1.2200, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11663596332073212
Epoch 0, Step 1497: train/loss = 0.39489904046058655, train/raw-loss = 0.3366313576698303, train/logprobs = tensor([[-0.5156, -2.6759],
        [-1.0607, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09711284190416336
Epoch 0, Step 1498: train/loss = 0.3987498879432678, train/raw-loss = 0.32627272605895996, train/logprobs = tensor([[-0.5801, -2.2981],
        [-1.6778, -0.5386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12079522013664246
Epoch 0, Step 1499: train/loss = 0.45264291763305664, train/raw-loss = 0.37858960032463074, train/logprobs = tensor([[-0.9997, -2.5021],
        [-1.7489, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12342214584350586
Epoch 0, Step 1500: train/loss = 0.4971071779727936, train/raw-loss = 0.45799627900123596, train/logprobs = tensor([[-0.3055, -2.9739],
        [-0.4947, -1.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0651848316192627
Epoch 0, Step 1501: train/loss = 0.26360759139060974, train/raw-loss = 0.1650577187538147, train/logprobs = tensor([[-0.4499, -4.2244],
        [-2.0331, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16424977779388428
Epoch 0, Step 1502: train/loss = 0.2504971921443939, train/raw-loss = 0.1705251932144165, train/logprobs = tensor([[-0.7584, -5.4188],
        [-1.6351, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13328666985034943
Epoch 0, Step 1503: train/loss = 0.47468823194503784, train/raw-loss = 0.39899998903274536, train/logprobs = tensor([[-0.7908, -2.8503],
        [-1.6233, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12614706158638
Epoch 0, Step 1504: train/loss = 0.42373234033584595, train/raw-loss = 0.3540023863315582, train/logprobs = tensor([[-0.4780, -4.1309],
        [-1.0251, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11621657013893127
Epoch 0, Step 1505: train/loss = 0.3497708737850189, train/raw-loss = 0.2829388380050659, train/logprobs = tensor([[-0.6013, -4.1875],
        [-1.3484, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138671636581421
Epoch 0, Step 1506: train/loss = 0.2950577437877655, train/raw-loss = 0.2209189087152481, train/logprobs = tensor([[-0.5548, -3.8095],
        [-1.6597, -1.2623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1235647201538086
Epoch 0, Step 1507: train/loss = 0.4670713543891907, train/raw-loss = 0.3825324773788452, train/logprobs = tensor([[-0.4102, -2.4604],
        [-0.9779, -0.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14089810848236084
Epoch 0, Step 1508: train/loss = 0.5243660807609558, train/raw-loss = 0.43811196088790894, train/logprobs = tensor([[-0.9117, -3.2134],
        [-1.5533, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14375683665275574
Epoch 0, Step 1509: train/loss = 0.5142371654510498, train/raw-loss = 0.4548491835594177, train/logprobs = tensor([[-0.8617, -1.8058],
        [-1.4402, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09898005425930023
Epoch 0, Step 1510: train/loss = 0.4411529004573822, train/raw-loss = 0.36673250794410706, train/logprobs = tensor([[-0.4535, -4.9149],
        [-0.8870, -1.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12403396517038345
Epoch 0, Step 1511: train/loss = 0.34088531136512756, train/raw-loss = 0.27375632524490356, train/logprobs = tensor([[-0.7174, -5.1531],
        [-1.4464, -1.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188165843486786
Epoch 0, Step 1512: train/loss = 0.4468795955181122, train/raw-loss = 0.37030094861984253, train/logprobs = tensor([[-0.5321, -2.3303],
        [-1.2095, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1276310682296753
Epoch 0, Step 1513: train/loss = 0.3661119341850281, train/raw-loss = 0.28562459349632263, train/logprobs = tensor([[-0.4815, -3.8919],
        [-1.3143, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414554297924042
Epoch 0, Step 1514: train/loss = 0.5076117515563965, train/raw-loss = 0.4340003728866577, train/logprobs = tensor([[-1.1420, -6.1737],
        [-1.3858, -1.5718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12268564105033875
Epoch 0, Step 1515: train/loss = 0.30524128675460815, train/raw-loss = 0.22986042499542236, train/logprobs = tensor([[-0.6748, -3.4855],
        [-1.7445, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256348043680191
Epoch 0, Step 1516: train/loss = 0.654308557510376, train/raw-loss = 0.603173553943634, train/logprobs = tensor([[-0.5038, -0.6910],
        [-0.9967, -0.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08522514253854752
Epoch 0, Step 1517: train/loss = 0.2987951636314392, train/raw-loss = 0.23013994097709656, train/logprobs = tensor([[-0.7860, -9.8242],
        [-1.7560, -2.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1144254133105278
Epoch 0, Step 1518: train/loss = 0.5616893768310547, train/raw-loss = 0.5001827478408813, train/logprobs = tensor([[-1.2986, -2.9980],
        [-1.2519, -0.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10251109302043915
Epoch 0, Step 1519: train/loss = 0.5597477555274963, train/raw-loss = 0.4959171712398529, train/logprobs = tensor([[-0.5545, -2.2701],
        [-1.0335, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1063842624425888
Epoch 0, Step 1520: train/loss = 0.2646414339542389, train/raw-loss = 0.17921319603919983, train/logprobs = tensor([[-0.5873, -7.1311],
        [-1.9105, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14238038659095764
Epoch 0, Step 1521: train/loss = 0.4846498966217041, train/raw-loss = 0.41806140542030334, train/logprobs = tensor([[-1.0618, -1.8729],
        [-1.6735, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109807938337326
Epoch 0, Step 1522: train/loss = 0.4305276870727539, train/raw-loss = 0.3808342218399048, train/logprobs = tensor([[-1.5736, -8.4503],
        [-1.7580, -2.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08282240480184555
Epoch 0, Step 1523: train/loss = 0.26172953844070435, train/raw-loss = 0.19020837545394897, train/logprobs = tensor([[-0.7839, -4.8759],
        [-2.2017, -1.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920192837715149
Epoch 0, Step 1524: train/loss = 0.3834969401359558, train/raw-loss = 0.3035944402217865, train/logprobs = tensor([[-0.6958, -2.8841],
        [-1.3483, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13317087292671204
Epoch 0, Step 1525: train/loss = 0.7178288698196411, train/raw-loss = 0.6444504261016846, train/logprobs = tensor([[-0.5143, -0.5884],
        [-1.0608, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12229743599891663
Epoch 0, Step 1526: train/loss = 0.48976266384124756, train/raw-loss = 0.4328882694244385, train/logprobs = tensor([[-0.5148, -2.6075],
        [-1.0578, -0.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09479063749313354
Epoch 0, Step 1527: train/loss = 0.5403388142585754, train/raw-loss = 0.4553976058959961, train/logprobs = tensor([[-1.1320, -1.8709],
        [-1.3215, -0.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1415686309337616
Epoch 0, Step 1528: train/loss = 0.2602309286594391, train/raw-loss = 0.18255750834941864, train/logprobs = tensor([[-0.4391, -4.6151],
        [-1.5939, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12945570051670074
Epoch 0, Step 1529: train/loss = 0.4952400326728821, train/raw-loss = 0.40145838260650635, train/logprobs = tensor([[-0.6077, -2.8539],
        [-1.8655, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15630270540714264
Epoch 0, Step 1530: train/loss = 0.32912677526474, train/raw-loss = 0.255260705947876, train/logprobs = tensor([[-0.5922, -4.4445],
        [-1.5922, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12311005592346191
Epoch 0, Step 1531: train/loss = 0.47919702529907227, train/raw-loss = 0.4118594229221344, train/logprobs = tensor([[-0.5271, -4.3115],
        [-1.0740, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1122293770313263
Epoch 0, Step 1532: train/loss = 0.5535051822662354, train/raw-loss = 0.4819639325141907, train/logprobs = tensor([[-0.6719, -3.0547],
        [-0.9908, -0.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11923538148403168
Epoch 0, Step 1533: train/loss = 0.3874087333679199, train/raw-loss = 0.3326200842857361, train/logprobs = tensor([[-0.3387, -2.9114],
        [-1.0181, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09131434559822083
Epoch 0, Step 1534: train/loss = 0.42318499088287354, train/raw-loss = 0.3512873351573944, train/logprobs = tensor([[-1.0973, -4.6389],
        [-1.4239, -1.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1198294460773468
Epoch 0, Step 1535: train/loss = 0.5094160437583923, train/raw-loss = 0.42943716049194336, train/logprobs = tensor([[-0.5765, -1.7799],
        [-1.3643, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332981288433075
Epoch 0, Step 1536: train/loss = 0.38566815853118896, train/raw-loss = 0.3159564137458801, train/logprobs = tensor([[-0.4554, -4.9903],
        [-1.0628, -1.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11618628352880478
Epoch 0, Step 1537: train/loss = 0.4632917642593384, train/raw-loss = 0.3893023133277893, train/logprobs = tensor([[-1.0274, -2.5659],
        [-1.1851, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12331575900316238
Epoch 0, Step 1538: train/loss = 0.40922701358795166, train/raw-loss = 0.3441934287548065, train/logprobs = tensor([[-0.4731, -5.1786],
        [-1.3360, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838930308818817
Epoch 0, Step 1539: train/loss = 0.5452591776847839, train/raw-loss = 0.4656151533126831, train/logprobs = tensor([[-0.5668, -1.9356],
        [-0.9793, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13273997604846954
Epoch 0, Step 1540: train/loss = 0.42425528168678284, train/raw-loss = 0.3415456712245941, train/logprobs = tensor([[-0.8488, -3.9001],
        [-1.6280, -0.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378493756055832
Epoch 0, Step 1541: train/loss = 0.2423630654811859, train/raw-loss = 0.16041524708271027, train/logprobs = tensor([[-0.5746, -8.4722],
        [-1.6372, -1.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13657967746257782
Epoch 0, Step 1542: train/loss = 0.6634299755096436, train/raw-loss = 0.5991021394729614, train/logprobs = tensor([[-0.7156, -0.7082],
        [-1.0674, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10721299052238464
Epoch 0, Step 1543: train/loss = 0.4924466013908386, train/raw-loss = 0.42017000913619995, train/logprobs = tensor([[-0.4942, -2.2640],
        [-1.4639, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12046091258525848
Epoch 0, Step 1544: train/loss = 0.38078856468200684, train/raw-loss = 0.29214608669281006, train/logprobs = tensor([[-0.6573, -4.7435],
        [-2.0803, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14773744344711304
Epoch 0, Step 1545: train/loss = 0.4475114345550537, train/raw-loss = 0.3721495568752289, train/logprobs = tensor([[-0.9505, -3.0307],
        [-1.3188, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12560315430164337
Epoch 0, Step 1546: train/loss = 0.47457030415534973, train/raw-loss = 0.3972649574279785, train/logprobs = tensor([[-0.5315, -2.4445],
        [-1.2493, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12884223461151123
Epoch 0, Step 1547: train/loss = 0.5366853475570679, train/raw-loss = 0.46252012252807617, train/logprobs = tensor([[-0.6090, -2.4929],
        [-1.3630, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12360866367816925
Epoch 0, Step 1548: train/loss = 0.44630181789398193, train/raw-loss = 0.3812803030014038, train/logprobs = tensor([[-0.3765, -4.2612],
        [-0.8236, -1.2548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10836915671825409
Epoch 0, Step 1549: train/loss = 0.5099988579750061, train/raw-loss = 0.4445461332798004, train/logprobs = tensor([[-0.3668, -2.4561],
        [-1.0993, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10908782482147217
Epoch 0, Step 1550: train/loss = 0.5225376486778259, train/raw-loss = 0.4598258137702942, train/logprobs = tensor([[-0.6525, -1.7420],
        [-1.1417, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10451970994472504
Epoch 0, Step 1551: train/loss = 0.3045682907104492, train/raw-loss = 0.22865287959575653, train/logprobs = tensor([[-0.5876, -4.2960],
        [-1.2940, -1.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265256553888321
Epoch 0, Step 1552: train/loss = 0.3597332835197449, train/raw-loss = 0.29147666692733765, train/logprobs = tensor([[-0.6280, -7.4516],
        [-1.5797, -2.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11376109719276428
Epoch 0, Step 1553: train/loss = 0.3691975474357605, train/raw-loss = 0.2928334176540375, train/logprobs = tensor([[-0.7450, -3.7707],
        [-1.3228, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272735446691513
Epoch 0, Step 1554: train/loss = 0.5411977767944336, train/raw-loss = 0.4788384437561035, train/logprobs = tensor([[-0.7231, -2.0267],
        [-1.0838, -0.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10393224656581879
Epoch 0, Step 1555: train/loss = 0.4026696979999542, train/raw-loss = 0.3260795772075653, train/logprobs = tensor([[-0.9811, -3.2860],
        [-1.6637, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12765023112297058
Epoch 0, Step 1556: train/loss = 0.45985153317451477, train/raw-loss = 0.40024399757385254, train/logprobs = tensor([[-0.4372, -7.3514],
        [-0.9008, -1.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934590011835098
Epoch 0, Step 1557: train/loss = 0.3725993037223816, train/raw-loss = 0.3088992238044739, train/logprobs = tensor([[-0.5216, -5.3625],
        [-1.0342, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10616673529148102
Epoch 0, Step 1558: train/loss = 0.33925795555114746, train/raw-loss = 0.2654494047164917, train/logprobs = tensor([[-0.5830, -7.6231],
        [-1.4290, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12301425635814667
Epoch 0, Step 1559: train/loss = 0.47626596689224243, train/raw-loss = 0.400399774312973, train/logprobs = tensor([[-1.0182, -2.8945],
        [-2.0437, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12644365429878235
Epoch 0, Step 1560: train/loss = 0.3158295750617981, train/raw-loss = 0.24931904673576355, train/logprobs = tensor([[-0.6025, -4.5977],
        [-1.2423, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085087060928345
Epoch 0, Step 1561: train/loss = 0.29685524106025696, train/raw-loss = 0.19630879163742065, train/logprobs = tensor([[-0.8218, -3.7446],
        [-2.3664, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16757741570472717
Epoch 0, Step 1562: train/loss = 0.5437197685241699, train/raw-loss = 0.46510183811187744, train/logprobs = tensor([[-2.2461, -7.3318],
        [-1.8877, -1.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13102984428405762
Epoch 0, Step 1563: train/loss = 0.5827515125274658, train/raw-loss = 0.5008406043052673, train/logprobs = tensor([[-0.7120, -1.3636],
        [-1.4317, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13651825487613678
Epoch 0, Step 1564: train/loss = 0.358227014541626, train/raw-loss = 0.28539904952049255, train/logprobs = tensor([[-0.6183, -4.2694],
        [-1.9079, -1.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137994170188904
Epoch 0, Step 1565: train/loss = 0.5817084312438965, train/raw-loss = 0.5140153765678406, train/logprobs = tensor([[-0.9184, -1.6184],
        [-1.2351, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128217875957489
Epoch 0, Step 1566: train/loss = 0.3123839497566223, train/raw-loss = 0.22588138282299042, train/logprobs = tensor([[-0.5661, -5.0720],
        [-1.6431, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14417093992233276
Epoch 0, Step 1567: train/loss = 0.5983542203903198, train/raw-loss = 0.5398494005203247, train/logprobs = tensor([[-0.4305, -2.8194],
        [-0.9073, -0.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09750805795192719
Epoch 0, Step 1568: train/loss = 0.3940403461456299, train/raw-loss = 0.3310878574848175, train/logprobs = tensor([[-1.1214, -6.0058],
        [-1.4038, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10492080450057983
Epoch 0, Step 1569: train/loss = 0.5068849325180054, train/raw-loss = 0.43297243118286133, train/logprobs = tensor([[-0.9914, -2.3262],
        [-1.1202, -0.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12318740785121918
Epoch 0, Step 1570: train/loss = 0.49633288383483887, train/raw-loss = 0.42969536781311035, train/logprobs = tensor([[-0.6219, -3.0203],
        [-1.0622, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11106256395578384
Epoch 0, Step 1571: train/loss = 0.4971517324447632, train/raw-loss = 0.43318989872932434, train/logprobs = tensor([[-0.5546, -1.6389],
        [-1.0789, -0.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10660311579704285
Epoch 0, Step 1572: train/loss = 0.3554995656013489, train/raw-loss = 0.2800588011741638, train/logprobs = tensor([[-0.5987, -3.5013],
        [-1.4095, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1257345974445343
Epoch 0, Step 1573: train/loss = 0.32496732473373413, train/raw-loss = 0.265394389629364, train/logprobs = tensor([[-0.8246, -5.1854],
        [-1.8143, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09928825497627258
Epoch 0, Step 1574: train/loss = 0.3966200053691864, train/raw-loss = 0.32123637199401855, train/logprobs = tensor([[-0.5228, -2.7805],
        [-1.4733, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12563931941986084
Epoch 0, Step 1575: train/loss = 0.41835924983024597, train/raw-loss = 0.3402128517627716, train/logprobs = tensor([[-0.7351, -3.6022],
        [-1.5529, -1.1023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13024404644966125
Epoch 0, Step 1576: train/loss = 0.7149303555488586, train/raw-loss = 0.6665226221084595, train/logprobs = tensor([[-0.4335, -0.5489],
        [-0.5230, -0.5236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08067953586578369
Epoch 0, Step 1577: train/loss = 0.5902861952781677, train/raw-loss = 0.5157390236854553, train/logprobs = tensor([[-0.6676, -1.1739],
        [-1.1138, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12424533069133759
Epoch 0, Step 1578: train/loss = 0.378202348947525, train/raw-loss = 0.3182601034641266, train/logprobs = tensor([[-1.2468, -8.5279],
        [-1.3089, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09990378469228745
Epoch 0, Step 1579: train/loss = 0.4116165041923523, train/raw-loss = 0.3356110751628876, train/logprobs = tensor([[-0.4592, -4.1897],
        [-1.5420, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12667573988437653
Epoch 0, Step 1580: train/loss = 0.40892302989959717, train/raw-loss = 0.33750230073928833, train/logprobs = tensor([[-0.4248, -2.5228],
        [-1.1182, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903448402881622
Epoch 0, Step 1581: train/loss = 0.26526308059692383, train/raw-loss = 0.18115249276161194, train/logprobs = tensor([[-0.7237, -2.8908],
        [-2.3316, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14018428325653076
Epoch 0, Step 1582: train/loss = 0.24512454867362976, train/raw-loss = 0.18598061800003052, train/logprobs = tensor([[-0.7138, -6.6574],
        [-2.0318, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.098573237657547
Epoch 0, Step 1583: train/loss = 0.4139009118080139, train/raw-loss = 0.3322800397872925, train/logprobs = tensor([[-0.6799, -6.0526],
        [-2.3501, -1.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13603475689888
Epoch 0, Step 1584: train/loss = 0.2770005762577057, train/raw-loss = 0.20755019783973694, train/logprobs = tensor([[-0.8287, -5.0091],
        [-1.5414, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11575064063072205
Epoch 0, Step 1585: train/loss = 0.3326868712902069, train/raw-loss = 0.23655420541763306, train/logprobs = tensor([[-0.7024, -3.3269],
        [-1.4319, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16022109985351562
Epoch 0, Step 1586: train/loss = 0.371737003326416, train/raw-loss = 0.2850049138069153, train/logprobs = tensor([[-0.5961, -5.6424],
        [-1.4628, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14455343782901764
Epoch 0, Step 1587: train/loss = 0.2795998454093933, train/raw-loss = 0.19152531027793884, train/logprobs = tensor([[-0.7716, -3.9776],
        [-1.6432, -0.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14679090678691864
Epoch 0, Step 1588: train/loss = 0.37921708822250366, train/raw-loss = 0.32050105929374695, train/logprobs = tensor([[-0.4984, -4.0617],
        [-1.0975, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09786003082990646
Epoch 0, Step 1589: train/loss = 0.42739224433898926, train/raw-loss = 0.36554959416389465, train/logprobs = tensor([[-0.6348, -4.4493],
        [-1.0632, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10307106375694275
Epoch 0, Step 1590: train/loss = 0.4101440906524658, train/raw-loss = 0.3496430218219757, train/logprobs = tensor([[-0.5253, -5.7123],
        [-0.7522, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10083511471748352
Epoch 0, Step 1591: train/loss = 0.4080617427825928, train/raw-loss = 0.3189513087272644, train/logprobs = tensor([[-0.5773, -5.5296],
        [-1.5604, -2.4988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14851735532283783
Epoch 0, Step 1592: train/loss = 0.40783053636550903, train/raw-loss = 0.3303360939025879, train/logprobs = tensor([[-0.5544, -2.8135],
        [-1.1067, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12915737926959991
Epoch 0, Step 1593: train/loss = 0.37309521436691284, train/raw-loss = 0.3018544614315033, train/logprobs = tensor([[-0.7225, -5.3698],
        [-1.3077, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11873458325862885
Epoch 0, Step 1594: train/loss = 0.34397080540657043, train/raw-loss = 0.2570226788520813, train/logprobs = tensor([[-0.5820, -3.5842],
        [-1.4625, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14491358399391174
Epoch 0, Step 1595: train/loss = 0.38200515508651733, train/raw-loss = 0.29952648282051086, train/logprobs = tensor([[-0.5924, -3.3674],
        [-1.1577, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374644786119461
Epoch 0, Step 1596: train/loss = 0.3767634928226471, train/raw-loss = 0.2788999080657959, train/logprobs = tensor([[-0.5832, -7.4091],
        [-1.8232, -1.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16310599446296692
Epoch 0, Step 1597: train/loss = 0.3326704502105713, train/raw-loss = 0.2609102427959442, train/logprobs = tensor([[-0.7768, -4.5775],
        [-1.9574, -1.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11960035562515259
Epoch 0, Step 1598: train/loss = 0.40299805998802185, train/raw-loss = 0.34096455574035645, train/logprobs = tensor([[-0.8255, -6.3923],
        [-1.4044, -1.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10338917374610901
Epoch 0, Step 1599: train/loss = 0.25548654794692993, train/raw-loss = 0.17190422117710114, train/logprobs = tensor([[-0.5095, -7.3581],
        [-1.5843, -1.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13930383324623108
Epoch 0, Step 1600: train/loss = 0.3866475522518158, train/raw-loss = 0.31825435161590576, train/logprobs = tensor([[-0.8923, -5.4194],
        [-1.1273, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11398868262767792
Epoch 0, Step 1601: train/loss = 0.21848443150520325, train/raw-loss = 0.13809151947498322, train/logprobs = tensor([[ -0.5349, -11.1355],
        [ -1.6306,  -2.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339881867170334
Epoch 0, Step 1602: train/loss = 0.35326847434043884, train/raw-loss = 0.2698110342025757, train/logprobs = tensor([[-0.4400, -3.8426],
        [-1.1871, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390957087278366
Epoch 0, Step 1603: train/loss = 0.4965474605560303, train/raw-loss = 0.4288136661052704, train/logprobs = tensor([[-0.4329, -2.4565],
        [-1.1431, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288964003324509
Epoch 0, Step 1604: train/loss = 0.3426373302936554, train/raw-loss = 0.27597081661224365, train/logprobs = tensor([[-0.5153, -6.0704],
        [-0.9733, -2.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11111082136631012
Epoch 0, Step 1605: train/loss = 0.5226293802261353, train/raw-loss = 0.4411066770553589, train/logprobs = tensor([[-0.7360, -3.5287],
        [-1.1154, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13587111234664917
Epoch 0, Step 1606: train/loss = 0.2559276223182678, train/raw-loss = 0.18824072182178497, train/logprobs = tensor([[-0.5351, -6.7307],
        [-1.4639, -1.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11281149089336395
Epoch 0, Step 1607: train/loss = 0.41300585865974426, train/raw-loss = 0.3361116349697113, train/logprobs = tensor([[-0.6465, -2.9455],
        [-1.2951, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12815701961517334
Epoch 0, Step 1608: train/loss = 0.4167005717754364, train/raw-loss = 0.3398398160934448, train/logprobs = tensor([[-0.7893, -6.7195],
        [-1.1837, -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12810127437114716
Epoch 0, Step 1609: train/loss = 0.43758276104927063, train/raw-loss = 0.36615419387817383, train/logprobs = tensor([[-0.8881, -7.1685],
        [-1.1190, -1.4297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11904755979776382
Epoch 0, Step 1610: train/loss = 0.5303002595901489, train/raw-loss = 0.4582591652870178, train/logprobs = tensor([[-0.8307, -3.4260],
        [-0.9827, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12006847560405731
Epoch 0, Step 1611: train/loss = 0.40950411558151245, train/raw-loss = 0.3345259130001068, train/logprobs = tensor([[-0.6897, -1.8574],
        [-1.8515, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1249636709690094
Epoch 0, Step 1612: train/loss = 0.3140445351600647, train/raw-loss = 0.23319518566131592, train/logprobs = tensor([[-0.7016, -4.9973],
        [-1.8509, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13474895060062408
Epoch 0, Step 1613: train/loss = 0.6404531598091125, train/raw-loss = 0.5700056552886963, train/logprobs = tensor([[-0.4994, -0.9110],
        [-0.9192, -0.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11741247773170471
Epoch 0, Step 1614: train/loss = 0.3965051472187042, train/raw-loss = 0.3107534348964691, train/logprobs = tensor([[-1.5107, -6.7487],
        [-1.9333, -2.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14291954040527344
Epoch 0, Step 1615: train/loss = 0.368707537651062, train/raw-loss = 0.3032132685184479, train/logprobs = tensor([[-0.4113, -5.6091],
        [-0.9504, -1.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10915718972682953
Epoch 0, Step 1616: train/loss = 0.4405430257320404, train/raw-loss = 0.36872875690460205, train/logprobs = tensor([[-0.6271, -4.5417],
        [-1.7297, -1.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196904331445694
Epoch 0, Step 1617: train/loss = 0.45737695693969727, train/raw-loss = 0.4003481864929199, train/logprobs = tensor([[-0.5171, -3.3228],
        [-1.0703, -0.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09504788368940353
Epoch 0, Step 1618: train/loss = 0.4721343219280243, train/raw-loss = 0.40250083804130554, train/logprobs = tensor([[-0.4973, -2.1137],
        [-1.1325, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11605575680732727
Epoch 0, Step 1619: train/loss = 0.33737871050834656, train/raw-loss = 0.2687622606754303, train/logprobs = tensor([[-0.6267, -5.5082],
        [-1.1130, -0.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1143607497215271
Epoch 0, Step 1620: train/loss = 0.4320466220378876, train/raw-loss = 0.35802868008613586, train/logprobs = tensor([[-0.5487, -2.9520],
        [-1.1419, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12336330115795135
Epoch 0, Step 1621: train/loss = 0.4137296676635742, train/raw-loss = 0.3388454020023346, train/logprobs = tensor([[-0.7190, -2.9971],
        [-1.3154, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12480713427066803
Epoch 0, Step 1622: train/loss = 0.2872167229652405, train/raw-loss = 0.21289584040641785, train/logprobs = tensor([[-0.8361, -6.3139],
        [-1.8320, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12386813759803772
Epoch 0, Step 1623: train/loss = 0.49065959453582764, train/raw-loss = 0.4194222092628479, train/logprobs = tensor([[-0.4649, -2.3261],
        [-1.0199, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872901767492294
Epoch 0, Step 1624: train/loss = 0.30345815420150757, train/raw-loss = 0.24658463895320892, train/logprobs = tensor([[-0.5214, -3.2279],
        [-1.4253, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09478920698165894
Epoch 0, Step 1625: train/loss = 0.33891022205352783, train/raw-loss = 0.2508851885795593, train/logprobs = tensor([[-0.5502, -4.8238],
        [-1.5643, -0.7128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14670836925506592
Epoch 0, Step 1626: train/loss = 0.49115103483200073, train/raw-loss = 0.4323781132698059, train/logprobs = tensor([[-1.0844, -1.7313],
        [-1.5935, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09795477986335754
Epoch 0, Step 1627: train/loss = 0.45236021280288696, train/raw-loss = 0.3871317207813263, train/logprobs = tensor([[-1.0628, -2.9568],
        [-1.3759, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10871408879756927
Epoch 0, Step 1628: train/loss = 0.3519749045372009, train/raw-loss = 0.29193174839019775, train/logprobs = tensor([[-0.6179, -5.9844],
        [-0.9568, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10007192939519882
Epoch 0, Step 1629: train/loss = 0.49346601963043213, train/raw-loss = 0.4271320700645447, train/logprobs = tensor([[-0.7185, -2.7192],
        [-1.0503, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11055658012628555
Epoch 0, Step 1630: train/loss = 0.5122988820075989, train/raw-loss = 0.44025006890296936, train/logprobs = tensor([[-0.5704, -1.6030],
        [-1.5829, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12008136510848999
Epoch 0, Step 1631: train/loss = 0.27500683069229126, train/raw-loss = 0.20287899672985077, train/logprobs = tensor([[-0.4618, -7.3785],
        [-1.0609, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.120213083922863
Epoch 0, Step 1632: train/loss = 0.39483967423439026, train/raw-loss = 0.31792354583740234, train/logprobs = tensor([[-0.7081, -6.9289],
        [-1.2870, -1.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12819355726242065
Epoch 0, Step 1633: train/loss = 0.39103803038597107, train/raw-loss = 0.327241986989975, train/logprobs = tensor([[-0.8719, -4.4935],
        [-1.7929, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10632674396038055
Epoch 0, Step 1634: train/loss = 0.4479297399520874, train/raw-loss = 0.3577384650707245, train/logprobs = tensor([[-0.7680, -2.7435],
        [-1.6424, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15031877160072327
Epoch 0, Step 1635: train/loss = 0.3773777484893799, train/raw-loss = 0.2822616398334503, train/logprobs = tensor([[-0.4933, -6.3049],
        [-2.0681, -1.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15852683782577515
Epoch 0, Step 1636: train/loss = 0.379265159368515, train/raw-loss = 0.2972520887851715, train/logprobs = tensor([[-0.4080, -4.8343],
        [-1.1949, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1366884708404541
Epoch 0, Step 1637: train/loss = 0.3845975399017334, train/raw-loss = 0.3071470260620117, train/logprobs = tensor([[-0.6703, -7.0818],
        [-2.0740, -2.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12908422946929932
Epoch 0, Step 1638: train/loss = 0.36339235305786133, train/raw-loss = 0.28864938020706177, train/logprobs = tensor([[-0.5295, -6.3851],
        [-1.6457, -1.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12457160651683807
Epoch 0, Step 1639: train/loss = 0.5019515752792358, train/raw-loss = 0.4321122169494629, train/logprobs = tensor([[-0.7232, -6.6074],
        [-0.9576, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1163989007472992
Epoch 0, Step 1640: train/loss = 0.3701685070991516, train/raw-loss = 0.2866023778915405, train/logprobs = tensor([[-0.4594, -4.9944],
        [-1.2496, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13927680253982544
Epoch 0, Step 1641: train/loss = 0.3446505665779114, train/raw-loss = 0.28549620509147644, train/logprobs = tensor([[-0.3132, -5.8551],
        [-1.4108, -1.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09859059751033783
Epoch 0, Step 1642: train/loss = 0.3146744966506958, train/raw-loss = 0.23269213736057281, train/logprobs = tensor([[-0.6591, -5.7726],
        [-1.8170, -2.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13663731515407562
Epoch 0, Step 1643: train/loss = 0.4421258866786957, train/raw-loss = 0.37696170806884766, train/logprobs = tensor([[-1.0601, -6.2879],
        [-1.6093, -1.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10860700160264969
Epoch 0, Step 1644: train/loss = 0.4052438735961914, train/raw-loss = 0.3189771771430969, train/logprobs = tensor([[-0.9084, -4.1308],
        [-1.6237, -0.7773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14377784729003906
Epoch 0, Step 1645: train/loss = 0.2252022922039032, train/raw-loss = 0.14719319343566895, train/logprobs = tensor([[-0.5600, -9.7095],
        [-1.8094, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13001516461372375
Epoch 0, Step 1646: train/loss = 0.5653089880943298, train/raw-loss = 0.49319836497306824, train/logprobs = tensor([[-0.7878, -2.0434],
        [-0.9976, -0.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12018436193466187
Epoch 0, Step 1647: train/loss = 0.4048101305961609, train/raw-loss = 0.33425673842430115, train/logprobs = tensor([[-0.4749, -2.3042],
        [-1.1720, -0.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11758899688720703
Epoch 0, Step 1648: train/loss = 0.43740135431289673, train/raw-loss = 0.3710247576236725, train/logprobs = tensor([[-0.4505, -2.2794],
        [-1.2000, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.110627681016922
Epoch 0, Step 1649: train/loss = 0.4020754098892212, train/raw-loss = 0.3339546322822571, train/logprobs = tensor([[-0.5009, -5.1020],
        [-1.3533, -1.3947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11353465914726257
Epoch 0, Step 1650: train/loss = 0.4145737886428833, train/raw-loss = 0.35036951303482056, train/logprobs = tensor([[-0.5369, -4.1035],
        [-1.0070, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700710117816925
Epoch 0, Step 1651: train/loss = 0.3162202537059784, train/raw-loss = 0.24248892068862915, train/logprobs = tensor([[-0.5957, -3.3860],
        [-1.5581, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1228855773806572
Epoch 0, Step 1652: train/loss = 0.5951889753341675, train/raw-loss = 0.5297811627388, train/logprobs = tensor([[-0.4291, -3.2082],
        [-0.8662, -0.8512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10901302099227905
Epoch 0, Step 1653: train/loss = 0.3598087430000305, train/raw-loss = 0.2751173675060272, train/logprobs = tensor([[-0.3876, -3.8497],
        [-1.2220, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411522775888443
Epoch 0, Step 1654: train/loss = 0.44800424575805664, train/raw-loss = 0.37549692392349243, train/logprobs = tensor([[-0.8796, -5.4627],
        [-1.3939, -1.3199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12084551155567169
Epoch 0, Step 1655: train/loss = 0.3493877649307251, train/raw-loss = 0.272407203912735, train/logprobs = tensor([[-0.4844, -7.6567],
        [-1.1865, -1.4583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12830092012882233
Epoch 0, Step 1656: train/loss = 0.35130247473716736, train/raw-loss = 0.27064377069473267, train/logprobs = tensor([[-0.5133, -2.6957],
        [-1.7837, -0.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13443118333816528
Epoch 0, Step 1657: train/loss = 0.4763711392879486, train/raw-loss = 0.38909703493118286, train/logprobs = tensor([[-0.7398, -1.8738],
        [-2.2693, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14545682072639465
Epoch 0, Step 1658: train/loss = 0.5314598679542542, train/raw-loss = 0.4644976854324341, train/logprobs = tensor([[-0.7729, -2.8991],
        [-1.5085, -1.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11160366237163544
Epoch 0, Step 1659: train/loss = 0.3681470453739166, train/raw-loss = 0.2780304551124573, train/logprobs = tensor([[-0.6994, -3.0386],
        [-1.8375, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15019430220127106
Epoch 0, Step 1660: train/loss = 0.3159204125404358, train/raw-loss = 0.24580085277557373, train/logprobs = tensor([[-0.7759, -5.9266],
        [-1.4592, -0.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11686594784259796
Epoch 0, Step 1661: train/loss = 0.6541144847869873, train/raw-loss = 0.591109573841095, train/logprobs = tensor([[-0.7241, -1.4713],
        [-1.0545, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10500818490982056
Epoch 0, Step 1662: train/loss = 0.3196297883987427, train/raw-loss = 0.23559319972991943, train/logprobs = tensor([[-0.7688, -7.0053],
        [-1.7168, -1.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14006099104881287
Epoch 0, Step 1663: train/loss = 0.36728230118751526, train/raw-loss = 0.30186665058135986, train/logprobs = tensor([[-0.8042, -2.1654],
        [-1.8015, -0.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902601480484009
Epoch 0, Step 1664: train/loss = 0.4989038407802582, train/raw-loss = 0.4058436453342438, train/logprobs = tensor([[-0.5641, -1.5093],
        [-1.5070, -0.6789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15510030090808868
Epoch 0, Step 1665: train/loss = 0.430074006319046, train/raw-loss = 0.34573352336883545, train/logprobs = tensor([[-1.4221, -4.1229],
        [-1.6417, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14056752622127533
Epoch 0, Step 1666: train/loss = 0.4573926031589508, train/raw-loss = 0.399213045835495, train/logprobs = tensor([[-0.6746, -2.3829],
        [-1.3056, -0.4337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09696593135595322
Epoch 0, Step 1667: train/loss = 0.2977682948112488, train/raw-loss = 0.23430976271629333, train/logprobs = tensor([[-0.4063, -6.0262],
        [-1.2491, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057642325758934
Epoch 0, Step 1668: train/loss = 0.564784586429596, train/raw-loss = 0.5153752565383911, train/logprobs = tensor([[-0.5369, -2.3559],
        [-0.4696, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08234889805316925
Epoch 0, Step 1669: train/loss = 0.24129971861839294, train/raw-loss = 0.15196508169174194, train/logprobs = tensor([[-0.5687, -6.2955],
        [-1.6540, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14889103174209595
Epoch 0, Step 1670: train/loss = 0.1978767067193985, train/raw-loss = 0.12047095596790314, train/logprobs = tensor([[-0.6174, -6.5190],
        [-2.1824, -1.0910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12900957465171814
Epoch 0, Step 1671: train/loss = 0.3618715703487396, train/raw-loss = 0.29533931612968445, train/logprobs = tensor([[-1.5406, -4.6954],
        [-2.0460, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1108870729804039
Epoch 0, Step 1672: train/loss = 0.48901110887527466, train/raw-loss = 0.4059755206108093, train/logprobs = tensor([[-1.0098, -3.2381],
        [-1.6411, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13839265704154968
Epoch 0, Step 1673: train/loss = 0.3817618489265442, train/raw-loss = 0.31010687351226807, train/logprobs = tensor([[-0.5085, -3.1442],
        [-1.1890, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11942492425441742
Epoch 0, Step 1674: train/loss = 0.4432646930217743, train/raw-loss = 0.3870008587837219, train/logprobs = tensor([[-0.7293, -3.9982],
        [-0.8420, -0.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09377309679985046
Epoch 0, Step 1675: train/loss = 0.4694978594779968, train/raw-loss = 0.40276992321014404, train/logprobs = tensor([[-1.5632, -5.8898],
        [-1.4101, -1.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11121324449777603
Epoch 0, Step 1676: train/loss = 0.3859393000602722, train/raw-loss = 0.2824602425098419, train/logprobs = tensor([[-0.9362, -4.3058],
        [-2.3287, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17246511578559875
Epoch 0, Step 1677: train/loss = 0.35449355840682983, train/raw-loss = 0.2994510233402252, train/logprobs = tensor([[-0.6885, -4.4787],
        [-1.7469, -1.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0917375311255455
Epoch 0, Step 1678: train/loss = 0.36504971981048584, train/raw-loss = 0.2889420688152313, train/logprobs = tensor([[-0.6445, -2.9064],
        [-1.7815, -0.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1268460750579834
Epoch 0, Step 1679: train/loss = 0.4567860960960388, train/raw-loss = 0.3780553340911865, train/logprobs = tensor([[-0.6241, -2.7003],
        [-1.5655, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13121795654296875
Epoch 0, Step 1680: train/loss = 0.49204832315444946, train/raw-loss = 0.417938232421875, train/logprobs = tensor([[-0.5209, -2.1270],
        [-1.1843, -1.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12351679801940918
Epoch 0, Step 1681: train/loss = 0.3470226228237152, train/raw-loss = 0.2815251350402832, train/logprobs = tensor([[-0.7566, -9.7124],
        [-1.6173, -1.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916250944137573
Epoch 0, Step 1682: train/loss = 0.4489343762397766, train/raw-loss = 0.37085795402526855, train/logprobs = tensor([[-0.5766, -4.1825],
        [-1.3415, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13012737035751343
Epoch 0, Step 1683: train/loss = 0.41200846433639526, train/raw-loss = 0.3263181149959564, train/logprobs = tensor([[-1.2687, -3.4839],
        [-1.9890, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14281725883483887
Epoch 0, Step 1684: train/loss = 0.5560139417648315, train/raw-loss = 0.49214380979537964, train/logprobs = tensor([[-0.5494, -1.3071],
        [-1.0251, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10645024478435516
Epoch 0, Step 1685: train/loss = 0.44477570056915283, train/raw-loss = 0.37332239747047424, train/logprobs = tensor([[-0.5799, -2.7046],
        [-1.1970, -0.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11908885091543198
Epoch 0, Step 1686: train/loss = 0.30566245317459106, train/raw-loss = 0.23490630090236664, train/logprobs = tensor([[-0.7151, -7.9097],
        [-1.4770, -1.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11792697012424469
Epoch 0, Step 1687: train/loss = 0.40003669261932373, train/raw-loss = 0.3151569366455078, train/logprobs = tensor([[-0.5202, -4.5762],
        [-1.3337, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14146624505519867
Epoch 0, Step 1688: train/loss = 0.45989540219306946, train/raw-loss = 0.38316914439201355, train/logprobs = tensor([[-0.8832, -5.1481],
        [-1.1322, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278771162033081
Epoch 0, Step 1689: train/loss = 0.4266550540924072, train/raw-loss = 0.3482505977153778, train/logprobs = tensor([[-0.5216, -4.1863],
        [-1.3199, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306740790605545
Epoch 0, Step 1690: train/loss = 0.5171579718589783, train/raw-loss = 0.44053271412849426, train/logprobs = tensor([[-0.6016, -2.5033],
        [-0.9371, -0.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12770870327949524
Epoch 0, Step 1691: train/loss = 0.5124083161354065, train/raw-loss = 0.4560602903366089, train/logprobs = tensor([[-0.9636, -3.0951],
        [-1.1340, -1.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09391342103481293
Epoch 0, Step 1692: train/loss = 0.3476702570915222, train/raw-loss = 0.25641122460365295, train/logprobs = tensor([[-0.7145, -3.4310],
        [-1.7878, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15209834277629852
Epoch 0, Step 1693: train/loss = 0.4140753746032715, train/raw-loss = 0.3334646224975586, train/logprobs = tensor([[-0.7585, -3.1742],
        [-1.3566, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13435131311416626
Epoch 0, Step 1694: train/loss = 0.32030585408210754, train/raw-loss = 0.2451694756746292, train/logprobs = tensor([[-0.6687, -3.5433],
        [-1.9125, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12522730231285095
Epoch 0, Step 1695: train/loss = 0.6986929774284363, train/raw-loss = 0.6163610816001892, train/logprobs = tensor([[-0.8345, -2.8847],
        [-0.8964, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1372198760509491
Epoch 0, Step 1696: train/loss = 0.48135170340538025, train/raw-loss = 0.4078197777271271, train/logprobs = tensor([[-1.0665, -3.2831],
        [-1.2188, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12255322933197021
Epoch 0, Step 1697: train/loss = 0.573481559753418, train/raw-loss = 0.5209569931030273, train/logprobs = tensor([[-0.4215, -1.6554],
        [-0.6313, -0.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754095435142517
Epoch 0, Step 1698: train/loss = 0.5272859930992126, train/raw-loss = 0.4585246443748474, train/logprobs = tensor([[-0.9626, -2.9870],
        [-0.8314, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11460217088460922
Epoch 0, Step 1699: train/loss = 0.4467930197715759, train/raw-loss = 0.3770941495895386, train/logprobs = tensor([[-0.6140, -3.3123],
        [-1.3340, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11616478860378265
Epoch 0, Step 1700: train/loss = 0.5147982239723206, train/raw-loss = 0.42829430103302, train/logprobs = tensor([[-0.8476, -3.1343],
        [-0.9800, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14417323470115662
Epoch 0, Step 1701: train/loss = 0.542327880859375, train/raw-loss = 0.4627877175807953, train/logprobs = tensor([[-1.0649, -2.0026],
        [-1.7093, -1.4417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325669288635254
Epoch 0, Step 1702: train/loss = 0.45666229724884033, train/raw-loss = 0.365899920463562, train/logprobs = tensor([[-0.5061, -2.6057],
        [-1.4770, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15127062797546387
Epoch 0, Step 1703: train/loss = 0.35657936334609985, train/raw-loss = 0.2795827388763428, train/logprobs = tensor([[-0.5692, -5.4913],
        [-1.7445, -1.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12832771241664886
Epoch 0, Step 1704: train/loss = 0.30405664443969727, train/raw-loss = 0.215640589594841, train/logprobs = tensor([[-0.7318, -5.9279],
        [-1.8853, -1.2753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14736011624336243
Epoch 0, Step 1705: train/loss = 0.42659398913383484, train/raw-loss = 0.35744303464889526, train/logprobs = tensor([[-0.5296, -6.3086],
        [-1.2364, -1.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11525148153305054
Epoch 0, Step 1706: train/loss = 0.33744996786117554, train/raw-loss = 0.25254228711128235, train/logprobs = tensor([[-0.5917, -3.9080],
        [-2.2586, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14151284098625183
Epoch 0, Step 1707: train/loss = 0.4229870140552521, train/raw-loss = 0.34154483675956726, train/logprobs = tensor([[-0.6589, -2.3103],
        [-1.5637, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13573692739009857
Epoch 0, Step 1708: train/loss = 0.4443361163139343, train/raw-loss = 0.3685254156589508, train/logprobs = tensor([[-0.7512, -2.9260],
        [-1.5806, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12635116279125214
Epoch 0, Step 1709: train/loss = 0.5042029619216919, train/raw-loss = 0.42752546072006226, train/logprobs = tensor([[-0.8078, -3.4774],
        [-1.0560, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12779584527015686
Epoch 0, Step 1710: train/loss = 0.45790165662765503, train/raw-loss = 0.37196090817451477, train/logprobs = tensor([[-0.6633, -3.7545],
        [-1.3899, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14323456585407257
Epoch 0, Step 1711: train/loss = 0.2760758101940155, train/raw-loss = 0.1770544946193695, train/logprobs = tensor([[-0.6042, -5.9731],
        [-2.0348, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16503548622131348
Epoch 0, Step 1712: train/loss = 0.28114867210388184, train/raw-loss = 0.21250848472118378, train/logprobs = tensor([[-0.3884, -9.2590],
        [-0.9747, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11440027505159378
Epoch 0, Step 1713: train/loss = 0.30973169207572937, train/raw-loss = 0.22416236996650696, train/logprobs = tensor([[-0.6928, -4.7093],
        [-1.9103, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14261554181575775
Epoch 0, Step 1714: train/loss = 0.5686237215995789, train/raw-loss = 0.5018568634986877, train/logprobs = tensor([[-0.7742, -1.8024],
        [-0.8205, -0.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127805709838867
Epoch 0, Step 1715: train/loss = 0.4789992868900299, train/raw-loss = 0.4103723168373108, train/logprobs = tensor([[-0.6058, -2.3794],
        [-1.0075, -0.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11437828838825226
Epoch 0, Step 1716: train/loss = 0.5539103150367737, train/raw-loss = 0.47258836030960083, train/logprobs = tensor([[-0.9075, -2.6153],
        [-1.1420, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13553665578365326
Epoch 0, Step 1717: train/loss = 0.4692153036594391, train/raw-loss = 0.39751139283180237, train/logprobs = tensor([[-0.6048, -6.1108],
        [-1.3179, -1.3284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11950649321079254
Epoch 0, Step 1718: train/loss = 0.44593656063079834, train/raw-loss = 0.37762272357940674, train/logprobs = tensor([[-0.7676, -2.6115],
        [-1.4503, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11385643482208252
Epoch 0, Step 1719: train/loss = 0.3573673367500305, train/raw-loss = 0.2584031820297241, train/logprobs = tensor([[-0.6620, -6.7420],
        [-1.9677, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1649402529001236
Epoch 0, Step 1720: train/loss = 0.7350504398345947, train/raw-loss = 0.6638354659080505, train/logprobs = tensor([[-1.5796, -2.5114],
        [-0.9748, -0.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11869172751903534
Epoch 0, Step 1721: train/loss = 0.330221563577652, train/raw-loss = 0.23172731697559357, train/logprobs = tensor([[-1.0845, -7.3582],
        [-2.2485, -2.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16415709257125854
Epoch 0, Step 1722: train/loss = 0.2749287486076355, train/raw-loss = 0.18136568367481232, train/logprobs = tensor([[-0.3789, -4.2108],
        [-2.1031, -1.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15593841671943665
Epoch 0, Step 1723: train/loss = 0.41429272294044495, train/raw-loss = 0.32635653018951416, train/logprobs = tensor([[-0.8970, -3.5273],
        [-2.0176, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14656029641628265
Epoch 0, Step 1724: train/loss = 0.32193318009376526, train/raw-loss = 0.263063907623291, train/logprobs = tensor([[-0.7322, -6.0726],
        [-1.4592, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981154516339302
Epoch 0, Step 1725: train/loss = 0.4729514420032501, train/raw-loss = 0.39300549030303955, train/logprobs = tensor([[-0.6768, -5.3739],
        [-1.4336, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13324327766895294
Epoch 0, Step 1726: train/loss = 0.2550705075263977, train/raw-loss = 0.1765468418598175, train/logprobs = tensor([[-0.6768, -5.8663],
        [-1.6611, -0.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13087278604507446
Epoch 0, Step 1727: train/loss = 0.3441101908683777, train/raw-loss = 0.26249292492866516, train/logprobs = tensor([[-0.6927, -4.0730],
        [-1.4470, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13602881133556366
Epoch 0, Step 1728: train/loss = 0.5731567144393921, train/raw-loss = 0.5161017775535583, train/logprobs = tensor([[-0.7705, -3.0208],
        [-0.7576, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09509159624576569
Epoch 0, Step 1729: train/loss = 0.2611381709575653, train/raw-loss = 0.1745723932981491, train/logprobs = tensor([[-0.9393, -7.2719],
        [-1.7168, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14427629113197327
Epoch 0, Step 1730: train/loss = 0.6644189953804016, train/raw-loss = 0.5800802707672119, train/logprobs = tensor([[-0.7915, -1.5186],
        [-1.2098, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14056451618671417
Epoch 0, Step 1731: train/loss = 0.5987409949302673, train/raw-loss = 0.5293521881103516, train/logprobs = tensor([[-0.4231, -2.7641],
        [-1.2150, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11564803868532181
Epoch 0, Step 1732: train/loss = 0.47693300247192383, train/raw-loss = 0.40259385108947754, train/logprobs = tensor([[-0.7215, -5.2788],
        [-1.3852, -1.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12389861792325974
Epoch 0, Step 1733: train/loss = 0.4655754864215851, train/raw-loss = 0.3934967815876007, train/logprobs = tensor([[-0.4079, -3.2763],
        [-0.9970, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12013113498687744
Epoch 0, Step 1734: train/loss = 0.42440739274024963, train/raw-loss = 0.3596029579639435, train/logprobs = tensor([[-1.0753, -4.8648],
        [-1.1384, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10800732672214508
Epoch 0, Step 1735: train/loss = 0.2770094871520996, train/raw-loss = 0.20800237357616425, train/logprobs = tensor([[-0.7788, -6.1278],
        [-1.5625, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11501187831163406
Epoch 0, Step 1736: train/loss = 0.2910504639148712, train/raw-loss = 0.1888038069009781, train/logprobs = tensor([[-0.9204, -5.6246],
        [-2.0432, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704111248254776
Epoch 0, Step 1737: train/loss = 0.2794412076473236, train/raw-loss = 0.1895565539598465, train/logprobs = tensor([[-0.5536, -6.7664],
        [-2.2661, -1.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980772137641907
Epoch 0, Step 1738: train/loss = 0.4630323350429535, train/raw-loss = 0.38546648621559143, train/logprobs = tensor([[-1.4974, -5.0731],
        [-1.7420, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292763650417328
Epoch 0, Step 1739: train/loss = 0.4820820093154907, train/raw-loss = 0.40721455216407776, train/logprobs = tensor([[-0.7876, -3.4681],
        [-1.1075, -0.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12477908283472061
Epoch 0, Step 1740: train/loss = 0.43081149458885193, train/raw-loss = 0.36086463928222656, train/logprobs = tensor([[-0.6003, -3.9712],
        [-1.5938, -1.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11657805740833282
Epoch 0, Step 1741: train/loss = 0.4497036039829254, train/raw-loss = 0.3817351758480072, train/logprobs = tensor([[-0.5836, -4.8416],
        [-1.5387, -0.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328072100877762
Epoch 0, Step 1742: train/loss = 0.37684017419815063, train/raw-loss = 0.3013169765472412, train/logprobs = tensor([[-1.1771, -6.6884],
        [-1.4924, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1258719563484192
Epoch 0, Step 1743: train/loss = 0.5760893821716309, train/raw-loss = 0.5002478957176208, train/logprobs = tensor([[-0.6771, -2.1333],
        [-1.3220, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264023780822754
Epoch 0, Step 1744: train/loss = 0.37055128812789917, train/raw-loss = 0.2967478632926941, train/logprobs = tensor([[-1.6165, -6.2456],
        [-1.8269, -1.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12300565838813782
Epoch 0, Step 1745: train/loss = 0.4822235703468323, train/raw-loss = 0.40810778737068176, train/logprobs = tensor([[-0.5442, -4.2210],
        [-1.1526, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12352630496025085
Epoch 0, Step 1746: train/loss = 0.5054703950881958, train/raw-loss = 0.435502827167511, train/logprobs = tensor([[-0.5285, -2.2167],
        [-1.0285, -0.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11661261320114136
Epoch 0, Step 1747: train/loss = 0.4610222280025482, train/raw-loss = 0.39614781737327576, train/logprobs = tensor([[-0.5683, -2.0454],
        [-1.5851, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081240251660347
Epoch 0, Step 1748: train/loss = 0.47834330797195435, train/raw-loss = 0.3989831507205963, train/logprobs = tensor([[-0.6928, -1.5375],
        [-1.7041, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13226693868637085
Epoch 0, Step 1749: train/loss = 0.45880576968193054, train/raw-loss = 0.37638235092163086, train/logprobs = tensor([[-0.7239, -2.9218],
        [-1.4928, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13737231492996216
Epoch 0, Step 1750: train/loss = 0.31174004077911377, train/raw-loss = 0.22574254870414734, train/logprobs = tensor([[ -1.0691, -10.8161],
        [ -1.9447,  -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1433291733264923
Epoch 0, Step 1751: train/loss = 0.5086979269981384, train/raw-loss = 0.4419013559818268, train/logprobs = tensor([[-1.0985, -4.6745],
        [-1.1706, -1.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1113276481628418
Epoch 0, Step 1752: train/loss = 0.3441287875175476, train/raw-loss = 0.28039461374282837, train/logprobs = tensor([[-0.7052, -8.0152],
        [-1.5276, -1.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622358322143555
Epoch 0, Step 1753: train/loss = 0.3065427839756012, train/raw-loss = 0.22966772317886353, train/logprobs = tensor([[-1.0710, -7.2829],
        [-1.6000, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12812510132789612
Epoch 0, Step 1754: train/loss = 0.20788739621639252, train/raw-loss = 0.1089780181646347, train/logprobs = tensor([[-0.7691, -8.3661],
        [-2.4942, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648489534854889
Epoch 0, Step 1755: train/loss = 0.3851746916770935, train/raw-loss = 0.308451384305954, train/logprobs = tensor([[-1.0554, -2.9336],
        [-1.7730, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12787218391895294
Epoch 0, Step 1756: train/loss = 0.4886111319065094, train/raw-loss = 0.42023128271102905, train/logprobs = tensor([[-1.3625, -3.1090],
        [-1.4207, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11396640539169312
Epoch 0, Step 1757: train/loss = 0.6370179653167725, train/raw-loss = 0.5579268336296082, train/logprobs = tensor([[-0.8054, -1.0712],
        [-1.0990, -0.6775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13181856274604797
Epoch 0, Step 1758: train/loss = 0.3558472990989685, train/raw-loss = 0.2899133563041687, train/logprobs = tensor([[-0.6600, -6.2171],
        [-1.1153, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1098899245262146
Epoch 0, Step 1759: train/loss = 0.4857190251350403, train/raw-loss = 0.42598533630371094, train/logprobs = tensor([[-0.6650, -2.2763],
        [-1.5029, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0995560809969902
Epoch 0, Step 1760: train/loss = 0.5331801176071167, train/raw-loss = 0.450256884098053, train/logprobs = tensor([[-0.7492, -5.2348],
        [-2.1821, -1.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1382054090499878
Epoch 0, Step 1761: train/loss = 0.30567827820777893, train/raw-loss = 0.2171003818511963, train/logprobs = tensor([[-0.6195, -4.0740],
        [-1.4606, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14762982726097107
Epoch 0, Step 1762: train/loss = 0.46627944707870483, train/raw-loss = 0.3869420289993286, train/logprobs = tensor([[-0.8064, -4.8150],
        [-1.6104, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322290301322937
Epoch 0, Step 1763: train/loss = 0.4956445097923279, train/raw-loss = 0.4117037057876587, train/logprobs = tensor([[-1.2404, -5.0682],
        [-1.0587, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1399013102054596
Epoch 0, Step 1764: train/loss = 0.272084504365921, train/raw-loss = 0.1903255581855774, train/logprobs = tensor([[-0.4689, -5.1563],
        [-1.2741, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13626490533351898
Epoch 0, Step 1765: train/loss = 0.5123971700668335, train/raw-loss = 0.4259990453720093, train/logprobs = tensor([[-0.4711, -2.8351],
        [-1.0426, -0.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14399686455726624
Epoch 0, Step 1766: train/loss = 0.3477723002433777, train/raw-loss = 0.27809882164001465, train/logprobs = tensor([[-0.9727, -6.5065],
        [-1.6464, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11612244695425034
Epoch 0, Step 1767: train/loss = 0.33994823694229126, train/raw-loss = 0.26563119888305664, train/logprobs = tensor([[-0.4908, -9.7043],
        [-1.1274, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12386170029640198
Epoch 0, Step 1768: train/loss = 0.3934566080570221, train/raw-loss = 0.2941210865974426, train/logprobs = tensor([[-0.7091, -3.6803],
        [-2.0961, -2.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16555921733379364
Epoch 0, Step 1769: train/loss = 0.325260192155838, train/raw-loss = 0.24854183197021484, train/logprobs = tensor([[-0.7427, -3.2456],
        [-2.0410, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12786397337913513
Epoch 0, Step 1770: train/loss = 0.3388839066028595, train/raw-loss = 0.27083003520965576, train/logprobs = tensor([[ -0.8982, -10.8143],
        [ -1.3696,  -1.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342308670282364
Epoch 0, Step 1771: train/loss = 0.4831859767436981, train/raw-loss = 0.3975817561149597, train/logprobs = tensor([[-0.7223, -3.3561],
        [-1.5870, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14267370104789734
Epoch 0, Step 1772: train/loss = 0.36696913838386536, train/raw-loss = 0.2874230146408081, train/logprobs = tensor([[-0.8140, -4.2140],
        [-1.3504, -1.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325768530368805
Epoch 0, Step 1773: train/loss = 0.2916739583015442, train/raw-loss = 0.19409668445587158, train/logprobs = tensor([[-0.6885, -6.4886],
        [-1.5598, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16262874007225037
Epoch 0, Step 1774: train/loss = 0.5480841994285583, train/raw-loss = 0.4617590010166168, train/logprobs = tensor([[-1.4996, -3.0954],
        [-2.0614, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14387525618076324
Epoch 0, Step 1775: train/loss = 0.5005971193313599, train/raw-loss = 0.41434943675994873, train/logprobs = tensor([[-0.7097, -2.0549],
        [-1.2971, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1437460333108902
Epoch 0, Step 1776: train/loss = 0.5816406011581421, train/raw-loss = 0.5006142258644104, train/logprobs = tensor([[-2.0787, -7.2815],
        [-1.9624, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350439041852951
Epoch 0, Step 1777: train/loss = 0.4693983197212219, train/raw-loss = 0.373075395822525, train/logprobs = tensor([[-0.4556, -3.4713],
        [-1.4945, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16053824126720428
Epoch 0, Step 1778: train/loss = 0.4384659230709076, train/raw-loss = 0.3506600856781006, train/logprobs = tensor([[-0.8733, -3.9133],
        [-1.6742, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14634306728839874
Epoch 0, Step 1779: train/loss = 0.5061249732971191, train/raw-loss = 0.42982929944992065, train/logprobs = tensor([[-0.4979, -6.4363],
        [-1.0024, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271594762802124
Epoch 0, Step 1780: train/loss = 0.4715827703475952, train/raw-loss = 0.3929881453514099, train/logprobs = tensor([[-0.3983, -4.7483],
        [-0.9487, -1.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099104166030884
Epoch 0, Step 1781: train/loss = 0.41509532928466797, train/raw-loss = 0.32955998182296753, train/logprobs = tensor([[-0.5813, -3.5796],
        [-1.3689, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14255893230438232
Epoch 0, Step 1782: train/loss = 0.27642664313316345, train/raw-loss = 0.20401757955551147, train/logprobs = tensor([[-0.4790, -6.1478],
        [-1.0874, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12068179994821548
Epoch 0, Step 1783: train/loss = 0.41523277759552, train/raw-loss = 0.3240697979927063, train/logprobs = tensor([[-0.7409, -3.6995],
        [-2.1116, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15193819999694824
Epoch 0, Step 1784: train/loss = 0.5102471709251404, train/raw-loss = 0.4477202594280243, train/logprobs = tensor([[-1.0459, -2.8952],
        [-1.1179, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421153903007507
Epoch 0, Step 1785: train/loss = 0.5637674331665039, train/raw-loss = 0.48105353116989136, train/logprobs = tensor([[-0.7094, -2.5254],
        [-1.1520, -1.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13785654306411743
Epoch 0, Step 1786: train/loss = 0.5908125042915344, train/raw-loss = 0.5219374895095825, train/logprobs = tensor([[-0.4887, -2.0115],
        [-0.9099, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11479175090789795
Epoch 0, Step 1787: train/loss = 0.5107619762420654, train/raw-loss = 0.41742148995399475, train/logprobs = tensor([[-1.0758, -2.9238],
        [-1.5745, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155567467212677
Epoch 0, Step 1788: train/loss = 0.48247236013412476, train/raw-loss = 0.41511595249176025, train/logprobs = tensor([[-0.4640, -2.8858],
        [-0.6838, -0.7075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11226064711809158
Epoch 0, Step 1789: train/loss = 0.37812644243240356, train/raw-loss = 0.300809383392334, train/logprobs = tensor([[-0.8854, -4.8701],
        [-1.5884, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12886172533035278
Epoch 0, Step 1790: train/loss = 0.31704527139663696, train/raw-loss = 0.23514345288276672, train/logprobs = tensor([[-0.7354, -5.8381],
        [-1.6203, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13650301098823547
Epoch 0, Step 1791: train/loss = 0.4921550750732422, train/raw-loss = 0.4091944396495819, train/logprobs = tensor([[-1.0415, -2.4525],
        [-1.6491, -1.2154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13826775550842285
Epoch 0, Step 1792: train/loss = 0.3978688716888428, train/raw-loss = 0.2985764145851135, train/logprobs = tensor([[-0.6299, -3.6915],
        [-1.7640, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654874086380005
Epoch 0, Step 1793: train/loss = 0.33446139097213745, train/raw-loss = 0.24945110082626343, train/logprobs = tensor([[-0.7923, -5.5677],
        [-1.5601, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14168378710746765
Epoch 0, Step 1794: train/loss = 0.3278208374977112, train/raw-loss = 0.25025996565818787, train/logprobs = tensor([[-0.9192, -2.8668],
        [-2.0428, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12926813960075378
Epoch 0, Step 1795: train/loss = 0.2916449010372162, train/raw-loss = 0.221467524766922, train/logprobs = tensor([[-0.4335, -8.0729],
        [-1.9254, -1.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11696228384971619
Epoch 0, Step 1796: train/loss = 0.5635510683059692, train/raw-loss = 0.5013724565505981, train/logprobs = tensor([[-0.5554, -1.5435],
        [-0.8557, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10363097488880157
Epoch 0, Step 1797: train/loss = 0.41230255365371704, train/raw-loss = 0.3291770815849304, train/logprobs = tensor([[-1.4496, -7.7814],
        [-2.0765, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13854238390922546
Epoch 0, Step 1798: train/loss = 0.3252647817134857, train/raw-loss = 0.2368502914905548, train/logprobs = tensor([[-0.8831, -6.6589],
        [-3.2543, -2.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14735747873783112
Epoch 0, Step 1799: train/loss = 0.4039658308029175, train/raw-loss = 0.33325138688087463, train/logprobs = tensor([[-0.8374, -4.4690],
        [-1.5283, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785741150379181
Epoch 0, Step 1800: train/loss = 0.23013344407081604, train/raw-loss = 0.14288246631622314, train/logprobs = tensor([[-0.6332, -8.7096],
        [-1.9523, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14541828632354736
Epoch 0, Step 1801: train/loss = 0.344169020652771, train/raw-loss = 0.2660263776779175, train/logprobs = tensor([[-0.7188, -5.3640],
        [-1.9438, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13023769855499268
Epoch 0, Step 1802: train/loss = 0.4969513714313507, train/raw-loss = 0.42001524567604065, train/logprobs = tensor([[-1.0284, -4.7779],
        [-1.2286, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12822693586349487
Epoch 0, Step 1803: train/loss = 0.38788044452667236, train/raw-loss = 0.306021511554718, train/logprobs = tensor([[-0.8972, -5.6438],
        [-1.5204, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13643154501914978
Epoch 0, Step 1804: train/loss = 0.4824131727218628, train/raw-loss = 0.4042876362800598, train/logprobs = tensor([[-0.8203, -2.5887],
        [-1.5864, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13020917773246765
Epoch 0, Step 1805: train/loss = 0.4140399098396301, train/raw-loss = 0.34385284781455994, train/logprobs = tensor([[-0.6130, -2.9481],
        [-1.6590, -0.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11697844415903091
Epoch 0, Step 1806: train/loss = 0.3338536024093628, train/raw-loss = 0.2686002850532532, train/logprobs = tensor([[-0.5602, -4.1748],
        [-1.6351, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10875550657510757
Epoch 0, Step 1807: train/loss = 0.6291449666023254, train/raw-loss = 0.557995080947876, train/logprobs = tensor([[-0.4283, -2.9635],
        [-0.8222, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11858323216438293
Epoch 0, Step 1808: train/loss = 0.35751399397850037, train/raw-loss = 0.28693512082099915, train/logprobs = tensor([[-0.4786, -4.9337],
        [-1.1152, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1176314577460289
Epoch 0, Step 1809: train/loss = 0.38695305585861206, train/raw-loss = 0.3115268349647522, train/logprobs = tensor([[-0.5664, -7.8056],
        [-1.1611, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12571033835411072
Epoch 0, Step 1810: train/loss = 0.4703415632247925, train/raw-loss = 0.4081518054008484, train/logprobs = tensor([[-0.7228, -1.9545],
        [-1.5251, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10364961624145508
Epoch 0, Step 1811: train/loss = 0.44741091132164, train/raw-loss = 0.3757777810096741, train/logprobs = tensor([[-0.8617, -5.6168],
        [-1.4660, -1.6001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11938855051994324
Epoch 0, Step 1812: train/loss = 0.18901310861110687, train/raw-loss = 0.09514680504798889, train/logprobs = tensor([[-1.3663, -8.1834],
        [-3.0113, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15644383430480957
Epoch 0, Step 1813: train/loss = 0.23929539322853088, train/raw-loss = 0.16862834990024567, train/logprobs = tensor([[-0.7104, -9.8681],
        [-1.7314, -2.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11777841299772263
Epoch 0, Step 1814: train/loss = 0.39311084151268005, train/raw-loss = 0.2982521951198578, train/logprobs = tensor([[-0.6228, -2.8898],
        [-1.5193, -1.2777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15809771418571472
Epoch 0, Step 1815: train/loss = 0.27581942081451416, train/raw-loss = 0.2019886076450348, train/logprobs = tensor([[-0.6790, -8.5467],
        [-1.4887, -2.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12305136024951935
Epoch 0, Step 1816: train/loss = 0.3726773262023926, train/raw-loss = 0.3000773787498474, train/logprobs = tensor([[-0.5961, -3.8788],
        [-0.8488, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12099990248680115
Epoch 0, Step 1817: train/loss = 0.669221043586731, train/raw-loss = 0.6069962978363037, train/logprobs = tensor([[-0.6305, -0.8382],
        [-0.9024, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370782017707825
Epoch 0, Step 1818: train/loss = 0.27229252457618713, train/raw-loss = 0.18503540754318237, train/logprobs = tensor([[-0.6096, -7.8228],
        [-1.9541, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14542853832244873
Epoch 0, Step 1819: train/loss = 0.3894179165363312, train/raw-loss = 0.30463549494743347, train/logprobs = tensor([[-0.7990, -5.1203],
        [-1.5283, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14130401611328125
Epoch 0, Step 1820: train/loss = 0.4395328760147095, train/raw-loss = 0.36137259006500244, train/logprobs = tensor([[-0.5584, -3.2938],
        [-1.2101, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026706874370575
Epoch 0, Step 1821: train/loss = 0.3400876224040985, train/raw-loss = 0.2626534104347229, train/logprobs = tensor([[-0.6078, -5.3432],
        [-1.2664, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12905704975128174
Epoch 0, Step 1822: train/loss = 0.45358365774154663, train/raw-loss = 0.36861637234687805, train/logprobs = tensor([[-0.8433, -3.0192],
        [-1.1481, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14161206781864166
Epoch 0, Step 1823: train/loss = 0.478705495595932, train/raw-loss = 0.37441903352737427, train/logprobs = tensor([[-0.5165, -3.1986],
        [-1.8029, -1.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1738106906414032
Epoch 0, Step 1824: train/loss = 0.4435963034629822, train/raw-loss = 0.3679742217063904, train/logprobs = tensor([[-0.4959, -2.9553],
        [-1.3516, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12603679299354553
Epoch 0, Step 1825: train/loss = 0.4037665128707886, train/raw-loss = 0.31001800298690796, train/logprobs = tensor([[-0.7235, -4.6247],
        [-1.7636, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15624752640724182
Epoch 0, Step 1826: train/loss = 0.36549556255340576, train/raw-loss = 0.29077157378196716, train/logprobs = tensor([[-1.0053, -5.5275],
        [-1.5169, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12453994899988174
Epoch 0, Step 1827: train/loss = 0.37861648201942444, train/raw-loss = 0.2743385434150696, train/logprobs = tensor([[-0.6340, -2.3866],
        [-1.8210, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17379659414291382
Epoch 0, Step 1828: train/loss = 0.28942638635635376, train/raw-loss = 0.1936429888010025, train/logprobs = tensor([[-1.0497, -7.3110],
        [-2.2906, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15963900089263916
Epoch 0, Step 1829: train/loss = 0.47382670640945435, train/raw-loss = 0.410453200340271, train/logprobs = tensor([[-0.5558, -2.9427],
        [-0.7134, -0.5287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10562247037887573
Epoch 0, Step 1830: train/loss = 0.47760578989982605, train/raw-loss = 0.41047704219818115, train/logprobs = tensor([[-0.4011, -3.4050],
        [-0.8969, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188119649887085
Epoch 0, Step 1831: train/loss = 0.699987530708313, train/raw-loss = 0.6353979706764221, train/logprobs = tensor([[-0.4162, -0.5848],
        [-0.6147, -0.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076493188738823
Epoch 0, Step 1832: train/loss = 0.3927839994430542, train/raw-loss = 0.31487149000167847, train/logprobs = tensor([[-0.4647, -3.8718],
        [-0.8457, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12985415756702423
Epoch 0, Step 1833: train/loss = 0.5816066265106201, train/raw-loss = 0.497557133436203, train/logprobs = tensor([[-0.3780, -1.8234],
        [-0.8537, -1.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14008256793022156
Epoch 0, Step 1834: train/loss = 0.5081360936164856, train/raw-loss = 0.4205220341682434, train/logprobs = tensor([[-1.0168, -4.3181],
        [-1.0556, -0.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14602337777614594
Epoch 0, Step 1835: train/loss = 0.2665165662765503, train/raw-loss = 0.19138944149017334, train/logprobs = tensor([[-0.4280, -9.5671],
        [-1.1084, -2.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12521184980869293
Epoch 0, Step 1836: train/loss = 0.22895516455173492, train/raw-loss = 0.12725239992141724, train/logprobs = tensor([[-0.9768, -5.7561],
        [-2.4586, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1695045828819275
Epoch 0, Step 1837: train/loss = 0.382904976606369, train/raw-loss = 0.31259357929229736, train/logprobs = tensor([[-0.7624, -4.7081],
        [-1.4573, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11718568950891495
Epoch 0, Step 1838: train/loss = 0.3582899868488312, train/raw-loss = 0.279122531414032, train/logprobs = tensor([[-0.8299, -3.8878],
        [-1.0953, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13194575905799866
Epoch 0, Step 1839: train/loss = 0.33103883266448975, train/raw-loss = 0.24491900205612183, train/logprobs = tensor([[-0.8047, -4.6036],
        [-1.4569, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14353303611278534
Epoch 0, Step 1840: train/loss = 0.25911301374435425, train/raw-loss = 0.17495930194854736, train/logprobs = tensor([[-0.9231, -8.9930],
        [-1.7923, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14025619626045227
Epoch 0, Step 1841: train/loss = 0.4435337781906128, train/raw-loss = 0.3632584810256958, train/logprobs = tensor([[-0.5137, -3.4388],
        [-1.4556, -0.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13379214704036713
Epoch 0, Step 1842: train/loss = 0.3647652268409729, train/raw-loss = 0.29684364795684814, train/logprobs = tensor([[-0.8394, -6.3430],
        [-1.5003, -1.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11320262402296066
Epoch 0, Step 1843: train/loss = 0.2672252953052521, train/raw-loss = 0.1849288046360016, train/logprobs = tensor([[-0.9330, -8.5280],
        [-2.2071, -1.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1371607929468155
Epoch 0, Step 1844: train/loss = 0.40477100014686584, train/raw-loss = 0.3018466532230377, train/logprobs = tensor([[-0.8036, -3.2778],
        [-2.2733, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17154057323932648
Epoch 0, Step 1845: train/loss = 0.24713104963302612, train/raw-loss = 0.15536411106586456, train/logprobs = tensor([[-0.8608, -7.8101],
        [-2.0502, -0.9223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152944877743721
Epoch 0, Step 1846: train/loss = 0.5207692980766296, train/raw-loss = 0.44731906056404114, train/logprobs = tensor([[-0.5135, -3.3725],
        [-1.3010, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12241707742214203
Epoch 0, Step 1847: train/loss = 0.25068461894989014, train/raw-loss = 0.1680799126625061, train/logprobs = tensor([[-0.6899, -4.1167],
        [-2.0499, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137674480676651
Epoch 0, Step 1848: train/loss = 0.4317470192909241, train/raw-loss = 0.3651732802391052, train/logprobs = tensor([[-0.6164, -2.6225],
        [-1.5667, -1.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11095614731311798
Epoch 0, Step 1849: train/loss = 0.46453651785850525, train/raw-loss = 0.4047996997833252, train/logprobs = tensor([[-0.5260, -3.2293],
        [-0.9480, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09956137090921402
Epoch 0, Step 1850: train/loss = 0.2755814492702484, train/raw-loss = 0.20378217101097107, train/logprobs = tensor([[-0.7711, -5.8771],
        [-1.3510, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966545134782791
Epoch 0, Step 1851: train/loss = 0.21652722358703613, train/raw-loss = 0.12578122317790985, train/logprobs = tensor([[-0.6668, -5.5496],
        [-2.2088, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15124331414699554
Epoch 0, Step 1852: train/loss = 0.22880032658576965, train/raw-loss = 0.15514828264713287, train/logprobs = tensor([[ -0.7556, -10.0325],
        [ -2.0923,  -1.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12275339663028717
Epoch 0, Step 1853: train/loss = 0.45612674951553345, train/raw-loss = 0.3888309597969055, train/logprobs = tensor([[-0.6142, -6.2535],
        [-1.1179, -1.3852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11215963214635849
Epoch 0, Step 1854: train/loss = 0.8852746486663818, train/raw-loss = 0.8181700706481934, train/logprobs = tensor([[-2.6705, -4.6620],
        [-1.6007, -2.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11184100806713104
Epoch 0, Step 1855: train/loss = 0.28681284189224243, train/raw-loss = 0.19533489644527435, train/logprobs = tensor([[-0.6354, -8.8910],
        [-2.2833, -2.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15246324241161346
Epoch 0, Step 1856: train/loss = 0.28838828206062317, train/raw-loss = 0.21259790658950806, train/logprobs = tensor([[-0.4325, -7.5361],
        [-1.3754, -0.7052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12631729245185852
Epoch 0, Step 1857: train/loss = 0.2620108425617218, train/raw-loss = 0.1766655147075653, train/logprobs = tensor([[-0.7496, -5.1133],
        [-1.8490, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422421932220459
Epoch 0, Step 1858: train/loss = 0.42342835664749146, train/raw-loss = 0.33875739574432373, train/logprobs = tensor([[-0.9412, -3.1847],
        [-1.4428, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411183625459671
Epoch 0, Step 1859: train/loss = 0.39903539419174194, train/raw-loss = 0.3191060423851013, train/logprobs = tensor([[-0.5362, -3.6357],
        [-1.3331, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332155168056488
Epoch 0, Step 1860: train/loss = 0.40982508659362793, train/raw-loss = 0.3276199698448181, train/logprobs = tensor([[-0.5686, -3.9730],
        [-2.0544, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13700851798057556
Epoch 0, Step 1861: train/loss = 0.23190376162528992, train/raw-loss = 0.14582858979701996, train/logprobs = tensor([[-0.5075, -8.6918],
        [-1.7409, -1.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14345857501029968
Epoch 0, Step 1862: train/loss = 0.40678536891937256, train/raw-loss = 0.3325631320476532, train/logprobs = tensor([[-0.4029, -5.4448],
        [-1.1409, -1.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12370374798774719
Epoch 0, Step 1863: train/loss = 0.5222176313400269, train/raw-loss = 0.4359416365623474, train/logprobs = tensor([[-0.9361, -3.2323],
        [-1.5841, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14379335939884186
Epoch 0, Step 1864: train/loss = 0.3610880672931671, train/raw-loss = 0.28589102625846863, train/logprobs = tensor([[-0.9614, -5.2296],
        [-1.7186, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12532839179039001
Epoch 0, Step 1865: train/loss = 0.535449743270874, train/raw-loss = 0.4727494716644287, train/logprobs = tensor([[-0.4398, -3.4329],
        [-0.7400, -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045004352927208
Epoch 0, Step 1866: train/loss = 0.5238390564918518, train/raw-loss = 0.45042842626571655, train/logprobs = tensor([[-0.8179, -2.5177],
        [-1.1938, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12235105037689209
Epoch 0, Step 1867: train/loss = 0.4748578667640686, train/raw-loss = 0.38279464840888977, train/logprobs = tensor([[-0.6803, -3.2871],
        [-1.9090, -1.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534387171268463
Epoch 0, Step 1868: train/loss = 0.5550312399864197, train/raw-loss = 0.47954678535461426, train/logprobs = tensor([[-0.6610, -2.1505],
        [-1.0883, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12580737471580505
Epoch 0, Step 1869: train/loss = 0.48317521810531616, train/raw-loss = 0.40450766682624817, train/logprobs = tensor([[-1.1161, -5.4071],
        [-2.7880, -2.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13111254572868347
Epoch 0, Step 1870: train/loss = 0.23514115810394287, train/raw-loss = 0.1588909924030304, train/logprobs = tensor([[-1.1604, -6.1526],
        [-2.2197, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12708358466625214
Epoch 0, Step 1871: train/loss = 0.4171052575111389, train/raw-loss = 0.34831538796424866, train/logprobs = tensor([[-0.3911, -7.2350],
        [-0.8997, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11464978754520416
Epoch 0, Step 1872: train/loss = 0.7262078523635864, train/raw-loss = 0.6644994020462036, train/logprobs = tensor([[-0.5852, -0.7016],
        [-0.6540, -0.6327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10284746438264847
Epoch 0, Step 1873: train/loss = 0.5397768020629883, train/raw-loss = 0.4720633625984192, train/logprobs = tensor([[-0.6590, -2.7668],
        [-1.2558, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11285574734210968
Epoch 0, Step 1874: train/loss = 0.23087087273597717, train/raw-loss = 0.15859757363796234, train/logprobs = tensor([[-0.4467, -6.6428],
        [-1.4460, -1.2959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12045548856258392
Epoch 0, Step 1875: train/loss = 0.48477408289909363, train/raw-loss = 0.41927582025527954, train/logprobs = tensor([[-0.7690, -3.0234],
        [-1.2127, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091637834906578
Epoch 0, Step 1876: train/loss = 0.3704458475112915, train/raw-loss = 0.299948126077652, train/logprobs = tensor([[-0.7956, -5.7170],
        [-1.2868, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11749618500471115
Epoch 0, Step 1877: train/loss = 0.32606130838394165, train/raw-loss = 0.23033863306045532, train/logprobs = tensor([[-0.6865, -8.1852],
        [-2.3848, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15953782200813293
Epoch 0, Step 1878: train/loss = 0.3034924864768982, train/raw-loss = 0.21100328862667084, train/logprobs = tensor([[-0.6680, -5.9714],
        [-2.0139, -1.2566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15414869785308838
Epoch 0, Step 1879: train/loss = 0.3072343170642853, train/raw-loss = 0.21311946213245392, train/logprobs = tensor([[-0.7613, -6.6437],
        [-2.1085, -1.7439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15685805678367615
Epoch 0, Step 1880: train/loss = 0.4975576400756836, train/raw-loss = 0.4417351484298706, train/logprobs = tensor([[-0.8064, -3.0500],
        [-1.2684, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0930374413728714
Epoch 0, Step 1881: train/loss = 0.4547762870788574, train/raw-loss = 0.37286412715911865, train/logprobs = tensor([[-0.9103, -2.9639],
        [-1.4613, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13652025163173676
Epoch 0, Step 1882: train/loss = 0.25821825861930847, train/raw-loss = 0.1513156145811081, train/logprobs = tensor([[-1.0357, -6.5620],
        [-3.1797, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1781710684299469
Epoch 0, Step 1883: train/loss = 0.45161476731300354, train/raw-loss = 0.3641436696052551, train/logprobs = tensor([[-0.9771, -2.6870],
        [-1.7896, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14578518271446228
Epoch 0, Step 1884: train/loss = 0.3339690566062927, train/raw-loss = 0.2451670616865158, train/logprobs = tensor([[-1.0620, -7.6606],
        [-1.9487, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480032354593277
Epoch 0, Step 1885: train/loss = 0.3681197762489319, train/raw-loss = 0.29677221179008484, train/logprobs = tensor([[-0.7454, -5.1129],
        [-1.2515, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11891261488199234
Epoch 0, Step 1886: train/loss = 0.40259915590286255, train/raw-loss = 0.324415922164917, train/logprobs = tensor([[-0.5493, -5.1711],
        [-2.2246, -1.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13030532002449036
Epoch 0, Step 1887: train/loss = 0.42149412631988525, train/raw-loss = 0.31371891498565674, train/logprobs = tensor([[-0.5643, -2.0140],
        [-1.9183, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17962531745433807
Epoch 0, Step 1888: train/loss = 0.6685134172439575, train/raw-loss = 0.6027663946151733, train/logprobs = tensor([[-0.7169, -1.0834],
        [-0.8152, -0.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10957840085029602
Epoch 0, Step 1889: train/loss = 0.30952024459838867, train/raw-loss = 0.22514641284942627, train/logprobs = tensor([[-0.7447, -5.1565],
        [-1.6746, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406230479478836
Epoch 0, Step 1890: train/loss = 0.44352781772613525, train/raw-loss = 0.3669668138027191, train/logprobs = tensor([[-0.9357, -3.2189],
        [-1.5283, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12760166823863983
Epoch 0, Step 1891: train/loss = 0.6121349930763245, train/raw-loss = 0.5140455961227417, train/logprobs = tensor([[-1.5797, -4.3103],
        [-1.6451, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16348227858543396
Epoch 0, Step 1892: train/loss = 0.5477133393287659, train/raw-loss = 0.4563451409339905, train/logprobs = tensor([[-0.9895, -2.6963],
        [-1.3654, -1.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522803157567978
Epoch 0, Step 1893: train/loss = 0.4889790415763855, train/raw-loss = 0.41322845220565796, train/logprobs = tensor([[-0.7827, -2.5605],
        [-1.3129, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1262509971857071
Epoch 0, Step 1894: train/loss = 0.44778087735176086, train/raw-loss = 0.36031368374824524, train/logprobs = tensor([[-0.4471, -2.0977],
        [-1.5850, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14577865600585938
Epoch 0, Step 1895: train/loss = 0.5013482570648193, train/raw-loss = 0.43822166323661804, train/logprobs = tensor([[-0.4063, -4.6355],
        [-0.6957, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052110567688942
Epoch 0, Step 1896: train/loss = 0.2805868685245514, train/raw-loss = 0.2084769308567047, train/logprobs = tensor([[-0.7255, -7.4564],
        [-2.2116, -2.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12018327414989471
Epoch 0, Step 1897: train/loss = 0.2287893444299698, train/raw-loss = 0.134828120470047, train/logprobs = tensor([[-0.4542, -8.0448],
        [-1.5813, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15660201013088226
Epoch 0, Step 1898: train/loss = 0.4491329789161682, train/raw-loss = 0.36625850200653076, train/logprobs = tensor([[-0.7532, -5.0477],
        [-1.3420, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13812413811683655
Epoch 0, Step 1899: train/loss = 0.3253667950630188, train/raw-loss = 0.2343212068080902, train/logprobs = tensor([[-1.3083, -4.7482],
        [-2.7110, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15174263715744019
Epoch 0, Step 1900: train/loss = 0.3670666813850403, train/raw-loss = 0.2962877154350281, train/logprobs = tensor([[-1.0093, -4.5528],
        [-1.4391, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1179649829864502
Epoch 0, Step 1901: train/loss = 0.4591136574745178, train/raw-loss = 0.36174169182777405, train/logprobs = tensor([[-1.3890, -4.3196],
        [-2.0168, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16228662431240082
Epoch 0, Step 1902: train/loss = 0.4366128444671631, train/raw-loss = 0.3690212070941925, train/logprobs = tensor([[-0.7218, -3.9004],
        [-1.1172, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11265271157026291
Epoch 0, Step 1903: train/loss = 0.4593886733055115, train/raw-loss = 0.3901512920856476, train/logprobs = tensor([[-0.6915, -2.8268],
        [-1.1573, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11539563536643982
Epoch 0, Step 1904: train/loss = 0.36630064249038696, train/raw-loss = 0.29493004083633423, train/logprobs = tensor([[-0.7145, -7.7736],
        [-1.3044, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11895096302032471
Epoch 0, Step 1905: train/loss = 0.40418291091918945, train/raw-loss = 0.33667683601379395, train/logprobs = tensor([[-1.0451, -8.0966],
        [-1.3540, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11251010745763779
Epoch 0, Step 1906: train/loss = 0.5063276290893555, train/raw-loss = 0.42515188455581665, train/logprobs = tensor([[-0.9529, -2.1960],
        [-1.3536, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13529285788536072
Epoch 0, Step 1907: train/loss = 0.432404100894928, train/raw-loss = 0.36091384291648865, train/logprobs = tensor([[-0.6822, -5.6048],
        [-1.1093, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11915047466754913
Epoch 0, Step 1908: train/loss = 0.6143699288368225, train/raw-loss = 0.5356711745262146, train/logprobs = tensor([[-1.1208, -4.3739],
        [-0.8994, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311645358800888
Epoch 0, Step 1909: train/loss = 0.3928549587726593, train/raw-loss = 0.27968358993530273, train/logprobs = tensor([[-0.7932, -7.0457],
        [-2.7190, -1.3180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18861891329288483
Epoch 0, Step 1910: train/loss = 0.40632450580596924, train/raw-loss = 0.33532828092575073, train/logprobs = tensor([[-0.6497, -4.6387],
        [-1.3628, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11832700669765472
Epoch 0, Step 1911: train/loss = 0.27711421251296997, train/raw-loss = 0.19156697392463684, train/logprobs = tensor([[-0.7310, -7.0164],
        [-2.3107, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14257875084877014
Epoch 0, Step 1912: train/loss = 0.4372442960739136, train/raw-loss = 0.34442025423049927, train/logprobs = tensor([[-0.8922, -2.4407],
        [-1.8539, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15470677614212036
Epoch 0, Step 1913: train/loss = 0.38221991062164307, train/raw-loss = 0.3024543821811676, train/logprobs = tensor([[-0.6444, -3.3027],
        [-1.9633, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1329425424337387
Epoch 0, Step 1914: train/loss = 0.22156499326229095, train/raw-loss = 0.1416933387517929, train/logprobs = tensor([[ -0.5998, -10.0981],
        [ -2.3227,  -2.2605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13311941921710968
Epoch 0, Step 1915: train/loss = 0.23597031831741333, train/raw-loss = 0.15645188093185425, train/logprobs = tensor([[-0.7119, -8.9486],
        [-2.1256, -1.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13253073394298553
Epoch 0, Step 1916: train/loss = 0.4932536482810974, train/raw-loss = 0.39616623520851135, train/logprobs = tensor([[-0.4713, -2.9615],
        [-1.5686, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16181235015392303
Epoch 0, Step 1917: train/loss = 0.582846999168396, train/raw-loss = 0.5170817375183105, train/logprobs = tensor([[-1.0213, -2.5280],
        [-1.1488, -1.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10960879921913147
Epoch 0, Step 1918: train/loss = 0.35985812544822693, train/raw-loss = 0.2476438283920288, train/logprobs = tensor([[-0.7334, -4.0136],
        [-2.6292, -1.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870238482952118
Epoch 0, Step 1919: train/loss = 0.2271767258644104, train/raw-loss = 0.13587519526481628, train/logprobs = tensor([[-0.6962, -7.1830],
        [-1.8457, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15216921269893646
Epoch 0, Step 1920: train/loss = 0.3149326741695404, train/raw-loss = 0.23635771870613098, train/logprobs = tensor([[-0.5449, -4.1401],
        [-1.7738, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13095824420452118
Epoch 0, Step 1921: train/loss = 0.3371877074241638, train/raw-loss = 0.24790115654468536, train/logprobs = tensor([[-0.5113, -9.2217],
        [-2.2084, -1.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14881090819835663
Epoch 0, Step 1922: train/loss = 0.21102896332740784, train/raw-loss = 0.11030898243188858, train/logprobs = tensor([[-0.7203, -7.0521],
        [-2.5440, -1.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16786664724349976
Epoch 0, Step 1923: train/loss = 0.3333510160446167, train/raw-loss = 0.2542833983898163, train/logprobs = tensor([[-0.6294, -7.6854],
        [-1.7047, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13177932798862457
Epoch 0, Step 1924: train/loss = 0.25990718603134155, train/raw-loss = 0.1616760492324829, train/logprobs = tensor([[-0.6509, -6.0677],
        [-1.6142, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16371853649616241
Epoch 0, Step 1925: train/loss = 0.38116657733917236, train/raw-loss = 0.29308590292930603, train/logprobs = tensor([[-0.6963, -7.1312],
        [-1.7794, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1468011438846588
Epoch 0, Step 1926: train/loss = 0.43205076456069946, train/raw-loss = 0.35862523317337036, train/logprobs = tensor([[-0.7049, -3.4982],
        [-1.4749, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12237589806318283
Epoch 0, Step 1927: train/loss = 0.30369433760643005, train/raw-loss = 0.2059727907180786, train/logprobs = tensor([[-0.9908, -5.6901],
        [-1.6773, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16286924481391907
Epoch 0, Step 1928: train/loss = 0.4317280352115631, train/raw-loss = 0.3595663011074066, train/logprobs = tensor([[-0.4978, -3.9073],
        [-1.2870, -0.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026958167552948
Epoch 0, Step 1929: train/loss = 0.3594473898410797, train/raw-loss = 0.2847195267677307, train/logprobs = tensor([[-0.5381, -4.6696],
        [-1.2656, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454640865325928
Epoch 0, Step 1930: train/loss = 0.5082016587257385, train/raw-loss = 0.4427984356880188, train/logprobs = tensor([[-0.6772, -3.6946],
        [-0.6132, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10900536924600601
Epoch 0, Step 1931: train/loss = 0.6174198389053345, train/raw-loss = 0.5461727380752563, train/logprobs = tensor([[-0.8426, -2.8496],
        [-1.1839, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1187450960278511
Epoch 0, Step 1932: train/loss = 0.5481157302856445, train/raw-loss = 0.4681515693664551, train/logprobs = tensor([[-0.6794, -4.0900],
        [-1.6201, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13327360153198242
Epoch 0, Step 1933: train/loss = 0.5465551018714905, train/raw-loss = 0.46630603075027466, train/logprobs = tensor([[-1.0751, -2.7766],
        [-1.4450, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1337483823299408
Epoch 0, Step 1934: train/loss = 0.5287850499153137, train/raw-loss = 0.4466903805732727, train/logprobs = tensor([[-0.7152, -2.3737],
        [-1.1612, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13682445883750916
Epoch 0, Step 1935: train/loss = 0.312444269657135, train/raw-loss = 0.23027026653289795, train/logprobs = tensor([[-0.7549, -4.8095],
        [-2.4123, -1.5780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13695664703845978
Epoch 0, Step 1936: train/loss = 0.2673652172088623, train/raw-loss = 0.1805911809206009, train/logprobs = tensor([[-0.5162, -8.9169],
        [-1.5754, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14462333917617798
Epoch 0, Step 1937: train/loss = 0.6599310040473938, train/raw-loss = 0.5945258140563965, train/logprobs = tensor([[-1.0662, -1.2876],
        [-1.7338, -1.3936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10900869220495224
Epoch 0, Step 1938: train/loss = 0.574837863445282, train/raw-loss = 0.48422661423683167, train/logprobs = tensor([[-1.7328, -5.0763],
        [-1.6259, -2.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15101873874664307
Epoch 0, Step 1939: train/loss = 0.4877985119819641, train/raw-loss = 0.4207767844200134, train/logprobs = tensor([[-0.6220, -2.4513],
        [-0.9561, -0.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170285940170288
Epoch 0, Step 1940: train/loss = 0.5274112224578857, train/raw-loss = 0.4564426839351654, train/logprobs = tensor([[-0.9312, -5.4545],
        [-1.4105, -1.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11828088760375977
Epoch 0, Step 1941: train/loss = 0.6869791746139526, train/raw-loss = 0.5867231488227844, train/logprobs = tensor([[-1.4349, -2.2590],
        [-1.8931, -1.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16709329187870026
Epoch 0, Step 1942: train/loss = 0.39923304319381714, train/raw-loss = 0.29624882340431213, train/logprobs = tensor([[-0.8929, -5.8116],
        [-2.2794, -1.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1716403067111969
Epoch 0, Step 1943: train/loss = 0.3259873390197754, train/raw-loss = 0.22356334328651428, train/logprobs = tensor([[-0.5898, -6.2450],
        [-2.0556, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17070667445659637
Epoch 0, Step 1944: train/loss = 0.5274458527565002, train/raw-loss = 0.45794445276260376, train/logprobs = tensor([[-0.7420, -1.8939],
        [-1.3137, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11583567410707474
Epoch 0, Step 1945: train/loss = 0.48310381174087524, train/raw-loss = 0.4042727053165436, train/logprobs = tensor([[-0.4441, -2.2423],
        [-1.3158, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13138514757156372
Epoch 0, Step 1946: train/loss = 0.7258068919181824, train/raw-loss = 0.6374639272689819, train/logprobs = tensor([[-1.8080, -5.2477],
        [-0.9247, -1.4742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14723831415176392
Epoch 0, Step 1947: train/loss = 0.6148988008499146, train/raw-loss = 0.5449672937393188, train/logprobs = tensor([[-0.7199, -1.1753],
        [-1.0537, -0.8237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11655243486166
Epoch 0, Step 1948: train/loss = 0.37520450353622437, train/raw-loss = 0.30770862102508545, train/logprobs = tensor([[-0.4838, -5.4768],
        [-0.9154, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11249314993619919
Epoch 0, Step 1949: train/loss = 0.412757933139801, train/raw-loss = 0.34287649393081665, train/logprobs = tensor([[-0.6662, -4.2993],
        [-1.2095, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11646904051303864
Epoch 0, Step 1950: train/loss = 0.362236350774765, train/raw-loss = 0.28943249583244324, train/logprobs = tensor([[-0.7669, -6.6646],
        [-1.3426, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12133970856666565
Epoch 0, Step 1951: train/loss = 0.34130704402923584, train/raw-loss = 0.2574540376663208, train/logprobs = tensor([[-0.7079, -3.5662],
        [-2.2868, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397550255060196
Epoch 0, Step 1952: train/loss = 0.41661322116851807, train/raw-loss = 0.33592158555984497, train/logprobs = tensor([[-0.6516, -3.1598],
        [-2.1969, -1.2391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13448607921600342
Epoch 0, Step 1953: train/loss = 0.3936416804790497, train/raw-loss = 0.3257114887237549, train/logprobs = tensor([[-0.7218, -6.7431],
        [-1.2493, -1.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11321699619293213
Epoch 0, Step 1954: train/loss = 0.26431477069854736, train/raw-loss = 0.18832653760910034, train/logprobs = tensor([[-0.6772, -7.7134],
        [-1.8621, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664707005023956
Epoch 0, Step 1955: train/loss = 0.3757050633430481, train/raw-loss = 0.2872580885887146, train/logprobs = tensor([[-1.3756, -5.5638],
        [-2.1381, -1.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14741159975528717
Epoch 0, Step 1956: train/loss = 0.5217276811599731, train/raw-loss = 0.41915491223335266, train/logprobs = tensor([[-0.6311, -4.2617],
        [-1.5273, -2.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17095452547073364
Epoch 0, Step 1957: train/loss = 0.44504237174987793, train/raw-loss = 0.34863096475601196, train/logprobs = tensor([[-0.6241, -5.0874],
        [-2.0781, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16068564355373383
Epoch 0, Step 1958: train/loss = 0.23438842594623566, train/raw-loss = 0.14563152194023132, train/logprobs = tensor([[ -1.0007, -10.4813],
        [ -2.2476,  -2.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479281485080719
Epoch 0, Step 1959: train/loss = 0.3054036498069763, train/raw-loss = 0.20763719081878662, train/logprobs = tensor([[-0.6314, -8.9696],
        [-2.2953, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16294409334659576
Epoch 0, Step 1960: train/loss = 0.32229629158973694, train/raw-loss = 0.23018772900104523, train/logprobs = tensor([[-0.6071, -6.3043],
        [-2.0135, -1.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1535143107175827
Epoch 0, Step 1961: train/loss = 0.2437000274658203, train/raw-loss = 0.15625658631324768, train/logprobs = tensor([[-0.5251, -7.1778],
        [-1.5848, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14573907852172852
Epoch 0, Step 1962: train/loss = 0.6315140128135681, train/raw-loss = 0.5400050282478333, train/logprobs = tensor([[-0.5284, -1.1822],
        [-1.0637, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525149643421173
Epoch 0, Step 1963: train/loss = 0.4813089668750763, train/raw-loss = 0.3928048610687256, train/logprobs = tensor([[-0.6843, -5.9675],
        [-1.3570, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14750689268112183
Epoch 0, Step 1964: train/loss = 0.34135451912879944, train/raw-loss = 0.2695549726486206, train/logprobs = tensor([[-0.4535, -4.4758],
        [-1.3166, -1.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966588348150253
Epoch 0, Step 1965: train/loss = 0.5490846633911133, train/raw-loss = 0.48313015699386597, train/logprobs = tensor([[-0.5116, -1.2974],
        [-0.9467, -0.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10992425680160522
Epoch 0, Step 1966: train/loss = 0.2154373973608017, train/raw-loss = 0.13251802325248718, train/logprobs = tensor([[ -0.7055, -13.7054],
        [ -1.7700,  -1.6379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13819897174835205
Epoch 0, Step 1967: train/loss = 0.4390234351158142, train/raw-loss = 0.35074493288993835, train/logprobs = tensor([[-1.1977, -4.5199],
        [-1.4403, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471308320760727
Epoch 0, Step 1968: train/loss = 0.5308962464332581, train/raw-loss = 0.44014275074005127, train/logprobs = tensor([[-0.7645, -4.2382],
        [-1.7992, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15125583112239838
Epoch 0, Step 1969: train/loss = 0.28685498237609863, train/raw-loss = 0.19534319639205933, train/logprobs = tensor([[-0.6579, -8.4490],
        [-2.2998, -1.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525196135044098
Epoch 0, Step 1970: train/loss = 0.33496272563934326, train/raw-loss = 0.24875617027282715, train/logprobs = tensor([[-0.8600, -7.0744],
        [-1.4447, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14367759227752686
Epoch 0, Step 1971: train/loss = 0.32845258712768555, train/raw-loss = 0.24910348653793335, train/logprobs = tensor([[-0.5650, -4.5924],
        [-1.6626, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13224846124649048
Epoch 0, Step 1972: train/loss = 0.2985445559024811, train/raw-loss = 0.18928980827331543, train/logprobs = tensor([[-0.7448, -4.6173],
        [-2.4092, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18209120631217957
Epoch 0, Step 1973: train/loss = 0.32487237453460693, train/raw-loss = 0.2252708226442337, train/logprobs = tensor([[-0.7428, -5.1195],
        [-2.9299, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.166002556681633
Epoch 0, Step 1974: train/loss = 0.3222743272781372, train/raw-loss = 0.22522655129432678, train/logprobs = tensor([[-0.6656, -5.1746],
        [-1.7806, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617463380098343
Epoch 0, Step 1975: train/loss = 0.49282020330429077, train/raw-loss = 0.42351213097572327, train/logprobs = tensor([[-0.6694, -3.1080],
        [-1.2979, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11551349610090256
Epoch 0, Step 1976: train/loss = 0.3341529965400696, train/raw-loss = 0.24801680445671082, train/logprobs = tensor([[-0.7321, -6.2575],
        [-1.6300, -0.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1435602605342865
Epoch 0, Step 1977: train/loss = 0.18928375840187073, train/raw-loss = 0.10538285970687866, train/logprobs = tensor([[ -0.6810, -11.1432],
        [ -2.2656,  -2.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13983483612537384
Epoch 0, Step 1978: train/loss = 0.35486745834350586, train/raw-loss = 0.2582603096961975, train/logprobs = tensor([[-0.5780, -4.4941],
        [-1.4850, -1.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16101184487342834
Epoch 0, Step 1979: train/loss = 0.4266273081302643, train/raw-loss = 0.3265690803527832, train/logprobs = tensor([[-0.7079, -4.6955],
        [-1.7755, -1.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16676369309425354
Epoch 0, Step 1980: train/loss = 0.3329470157623291, train/raw-loss = 0.25039637088775635, train/logprobs = tensor([[-1.0442, -3.8557],
        [-2.0070, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13758443295955658
Epoch 0, Step 1981: train/loss = 0.24320435523986816, train/raw-loss = 0.14891794323921204, train/logprobs = tensor([[-0.5652, -6.9092],
        [-2.3901, -2.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15714402496814728
Epoch 0, Step 1982: train/loss = 0.4639970660209656, train/raw-loss = 0.3864385783672333, train/logprobs = tensor([[-0.8623, -1.9632],
        [-1.6215, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292642205953598
Epoch 0, Step 1983: train/loss = 0.5361445546150208, train/raw-loss = 0.4701178967952728, train/logprobs = tensor([[-0.4810, -1.5544],
        [-1.0099, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.110044464468956
Epoch 0, Step 1984: train/loss = 0.25697892904281616, train/raw-loss = 0.17383041977882385, train/logprobs = tensor([[-1.0158, -7.3349],
        [-1.9922, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13858087360858917
Epoch 0, Step 1985: train/loss = 0.5162815451622009, train/raw-loss = 0.4417617917060852, train/logprobs = tensor([[-0.7771, -3.2007],
        [-1.3711, -1.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12419956922531128
Epoch 0, Step 1986: train/loss = 0.6206268072128296, train/raw-loss = 0.5494137406349182, train/logprobs = tensor([[-0.9772, -3.6279],
        [-1.1650, -1.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11868849396705627
Epoch 0, Step 1987: train/loss = 0.5089163780212402, train/raw-loss = 0.44137755036354065, train/logprobs = tensor([[-1.2166, -4.5519],
        [-1.4478, -1.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256467550992966
Epoch 0, Step 1988: train/loss = 0.5238191485404968, train/raw-loss = 0.46657881140708923, train/logprobs = tensor([[-0.3657, -3.4803],
        [-0.9355, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09540051221847534
Epoch 0, Step 1989: train/loss = 0.4426943361759186, train/raw-loss = 0.37288379669189453, train/logprobs = tensor([[-0.6732, -3.8396],
        [-0.7970, -0.6234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.116350919008255
Epoch 0, Step 1990: train/loss = 0.2591342031955719, train/raw-loss = 0.1703026443719864, train/logprobs = tensor([[ -0.6041, -12.4440],
        [ -1.8626,  -1.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14805257320404053
Epoch 0, Step 1991: train/loss = 0.3441731631755829, train/raw-loss = 0.2568780779838562, train/logprobs = tensor([[-0.6401, -5.8985],
        [-1.8677, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1454917937517166
Epoch 0, Step 1992: train/loss = 0.5082165598869324, train/raw-loss = 0.3954569697380066, train/logprobs = tensor([[-1.0035, -4.6948],
        [-1.5167, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1879325807094574
Epoch 0, Step 1993: train/loss = 0.45764589309692383, train/raw-loss = 0.3842102289199829, train/logprobs = tensor([[-0.8218, -3.5770],
        [-1.2628, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12239274382591248
Epoch 0, Step 1994: train/loss = 0.3806522488594055, train/raw-loss = 0.29463469982147217, train/logprobs = tensor([[-0.6237, -3.8496],
        [-1.7761, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14336253702640533
Epoch 0, Step 1995: train/loss = 0.31088724732398987, train/raw-loss = 0.22736507654190063, train/logprobs = tensor([[-0.6418, -4.5936],
        [-2.0215, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13920362293720245
Epoch 0, Step 1996: train/loss = 0.4501349925994873, train/raw-loss = 0.38245922327041626, train/logprobs = tensor([[-0.7515, -2.2784],
        [-1.7595, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11279293894767761
Epoch 0, Step 1997: train/loss = 0.44659626483917236, train/raw-loss = 0.34629833698272705, train/logprobs = tensor([[-0.6732, -5.9322],
        [-1.6405, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16716322302818298
Epoch 0, Step 1998: train/loss = 0.5953279733657837, train/raw-loss = 0.5227106809616089, train/logprobs = tensor([[-0.6477, -2.1124],
        [-1.3972, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12102873623371124
Epoch 0, Step 1999: train/loss = 0.7736241817474365, train/raw-loss = 0.7141677141189575, train/logprobs = tensor([[-1.7730, -2.6361],
        [-0.7991, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909401088953018
Epoch 0, Step 2000: train/loss = 0.5187962055206299, train/raw-loss = 0.45192521810531616, train/logprobs = tensor([[-0.6468, -2.3483],
        [-0.9303, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11145175993442535
Epoch 0, Step 2001: train/loss = 0.5326063632965088, train/raw-loss = 0.44627612829208374, train/logprobs = tensor([[-0.7968, -1.8963],
        [-1.5024, -0.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14388376474380493
Epoch 0, Step 2002: train/loss = 0.3529405891895294, train/raw-loss = 0.2828225791454315, train/logprobs = tensor([[-0.7356, -6.1875],
        [-1.3381, -1.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11686335504055023
Epoch 0, Step 2003: train/loss = 0.3761163055896759, train/raw-loss = 0.2794190049171448, train/logprobs = tensor([[-1.2372, -5.0629],
        [-1.9096, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16116218268871307
Epoch 0, Step 2004: train/loss = 0.26385486125946045, train/raw-loss = 0.1783745288848877, train/logprobs = tensor([[-0.4679, -8.6302],
        [-1.4352, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424672156572342
Epoch 0, Step 2005: train/loss = 0.21478533744812012, train/raw-loss = 0.11992981284856796, train/logprobs = tensor([[-0.7845, -8.5609],
        [-2.8390, -1.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15809254348278046
Epoch 0, Step 2006: train/loss = 0.3540217876434326, train/raw-loss = 0.28954678773880005, train/logprobs = tensor([[-0.5599, -9.4825],
        [-1.1911, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10745832324028015
Epoch 0, Step 2007: train/loss = 0.4437023997306824, train/raw-loss = 0.36117643117904663, train/logprobs = tensor([[-0.4353, -2.6552],
        [-1.0601, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13754329085350037
Epoch 0, Step 2008: train/loss = 0.4507427513599396, train/raw-loss = 0.38546866178512573, train/logprobs = tensor([[-0.7948, -4.9116],
        [-1.6514, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10879018902778625
Epoch 0, Step 2009: train/loss = 0.6170046329498291, train/raw-loss = 0.534359335899353, train/logprobs = tensor([[-1.4836, -4.3945],
        [-0.9528, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13774213194847107
Epoch 0, Step 2010: train/loss = 0.3577024042606354, train/raw-loss = 0.2746846675872803, train/logprobs = tensor([[-0.9351, -5.8437],
        [-1.6933, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13836289942264557
Epoch 0, Step 2011: train/loss = 0.33970969915390015, train/raw-loss = 0.26145702600479126, train/logprobs = tensor([[-0.5558, -3.4766],
        [-1.7262, -0.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13042116165161133
Epoch 0, Step 2012: train/loss = 0.4808506965637207, train/raw-loss = 0.3986271321773529, train/logprobs = tensor([[-0.6562, -3.5174],
        [-1.3333, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370392143726349
Epoch 0, Step 2013: train/loss = 0.5760334730148315, train/raw-loss = 0.5072818994522095, train/logprobs = tensor([[-0.6206, -1.1282],
        [-1.1814, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458577960729599
Epoch 0, Step 2014: train/loss = 0.46140414476394653, train/raw-loss = 0.37384355068206787, train/logprobs = tensor([[-1.4753, -6.4668],
        [-2.8010, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1459343433380127
Epoch 0, Step 2015: train/loss = 0.5338646769523621, train/raw-loss = 0.46351391077041626, train/logprobs = tensor([[-0.6020, -2.0916],
        [-0.9171, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11725121736526489
Epoch 0, Step 2016: train/loss = 0.3972129821777344, train/raw-loss = 0.30576688051223755, train/logprobs = tensor([[-1.1095, -3.9255],
        [-1.7371, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15241016447544098
Epoch 0, Step 2017: train/loss = 0.25491541624069214, train/raw-loss = 0.16883602738380432, train/logprobs = tensor([[-0.8356, -6.4411],
        [-1.6784, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14346565306186676
Epoch 0, Step 2018: train/loss = 0.28743213415145874, train/raw-loss = 0.19499324262142181, train/logprobs = tensor([[-0.6658, -7.8041],
        [-2.1881, -0.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15406478941440582
Epoch 0, Step 2019: train/loss = 0.36083459854125977, train/raw-loss = 0.29019004106521606, train/logprobs = tensor([[-0.5425, -4.0043],
        [-1.0610, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11774089932441711
Epoch 0, Step 2020: train/loss = 0.6813232898712158, train/raw-loss = 0.6050810813903809, train/logprobs = tensor([[-1.0949, -1.5672],
        [-1.0964, -0.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270703822374344
Epoch 0, Step 2021: train/loss = 0.49636417627334595, train/raw-loss = 0.42921867966651917, train/logprobs = tensor([[-0.3314, -4.2732],
        [-0.6704, -0.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190913617610931
Epoch 0, Step 2022: train/loss = 0.5469860434532166, train/raw-loss = 0.4574119746685028, train/logprobs = tensor([[-0.5985, -2.4668],
        [-1.9240, -1.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492900550365448
Epoch 0, Step 2023: train/loss = 0.3392993211746216, train/raw-loss = 0.2458992898464203, train/logprobs = tensor([[-0.8773, -5.0974],
        [-2.6191, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15566673874855042
Epoch 0, Step 2024: train/loss = 0.17675361037254333, train/raw-loss = 0.08639822900295258, train/logprobs = tensor([[-0.6587, -9.0337],
        [-2.2777, -2.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15059228241443634
Epoch 0, Step 2025: train/loss = 0.48266375064849854, train/raw-loss = 0.40198472142219543, train/logprobs = tensor([[-1.1961, -6.1569],
        [-1.7853, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13446500897407532
Epoch 0, Step 2026: train/loss = 0.2672538757324219, train/raw-loss = 0.17444677650928497, train/logprobs = tensor([[-0.4983, -6.0249],
        [-1.5553, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15467852354049683
Epoch 0, Step 2027: train/loss = 0.3547985851764679, train/raw-loss = 0.26927071809768677, train/logprobs = tensor([[-0.4527, -3.5402],
        [-1.0069, -0.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14254643023014069
Epoch 0, Step 2028: train/loss = 0.363029807806015, train/raw-loss = 0.28885936737060547, train/logprobs = tensor([[-0.7862, -4.2092],
        [-1.7203, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12361742556095123
Epoch 0, Step 2029: train/loss = 0.5821457505226135, train/raw-loss = 0.5067870616912842, train/logprobs = tensor([[-0.6150, -1.1774],
        [-0.9694, -0.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12559774518013
Epoch 0, Step 2030: train/loss = 0.32829752564430237, train/raw-loss = 0.23790068924427032, train/logprobs = tensor([[-0.5329, -5.3010],
        [-1.6963, -0.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066134929656982
Epoch 0, Step 2031: train/loss = 0.6873742341995239, train/raw-loss = 0.6215617060661316, train/logprobs = tensor([[-0.5027, -0.7517],
        [-0.7491, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1096876859664917
Epoch 0, Step 2032: train/loss = 0.34858596324920654, train/raw-loss = 0.280460923910141, train/logprobs = tensor([[-1.0993, -4.4019],
        [-1.8968, -0.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11354169994592667
Epoch 0, Step 2033: train/loss = 0.7884954810142517, train/raw-loss = 0.7278008460998535, train/logprobs = tensor([[-1.2872, -1.3089],
        [-0.6892, -0.4357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115766525268555
Epoch 0, Step 2034: train/loss = 0.48307082056999207, train/raw-loss = 0.4108644723892212, train/logprobs = tensor([[-0.5832, -3.0049],
        [-1.1447, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12034393846988678
Epoch 0, Step 2035: train/loss = 0.45523151755332947, train/raw-loss = 0.3889603316783905, train/logprobs = tensor([[-1.0543, -4.0797],
        [-1.3916, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11045199632644653
Epoch 0, Step 2036: train/loss = 0.26861634850502014, train/raw-loss = 0.1722768247127533, train/logprobs = tensor([[-0.7680, -9.9792],
        [-1.8442, -1.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16056588292121887
Epoch 0, Step 2037: train/loss = 0.31728339195251465, train/raw-loss = 0.23392866551876068, train/logprobs = tensor([[-0.6784, -6.9594],
        [-1.2326, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13892453908920288
Epoch 0, Step 2038: train/loss = 0.43263715505599976, train/raw-loss = 0.32332026958465576, train/logprobs = tensor([[-0.8303, -4.7972],
        [-1.6246, -1.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18219482898712158
Epoch 0, Step 2039: train/loss = 0.38944554328918457, train/raw-loss = 0.317984938621521, train/logprobs = tensor([[-0.7907, -3.6075],
        [-1.4516, -0.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11910096555948257
Epoch 0, Step 2040: train/loss = 0.4471513330936432, train/raw-loss = 0.37938207387924194, train/logprobs = tensor([[-0.9328, -4.1256],
        [-1.2127, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129487156867981
Epoch 0, Step 2041: train/loss = 0.29025912284851074, train/raw-loss = 0.2160593718290329, train/logprobs = tensor([[-0.4768, -7.2721],
        [-2.1777, -1.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12366625666618347
Epoch 0, Step 2042: train/loss = 0.31436923146247864, train/raw-loss = 0.2235446572303772, train/logprobs = tensor([[-0.6220, -6.8465],
        [-1.6436, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15137425065040588
Epoch 0, Step 2043: train/loss = 0.460746169090271, train/raw-loss = 0.38381192088127136, train/logprobs = tensor([[-0.7705, -7.7265],
        [-1.6105, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282237321138382
Epoch 0, Step 2044: train/loss = 0.6280744075775146, train/raw-loss = 0.5150907039642334, train/logprobs = tensor([[-2.2143, -3.7104],
        [-3.3428, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18830621242523193
Epoch 0, Step 2045: train/loss = 0.5482612252235413, train/raw-loss = 0.4795955419540405, train/logprobs = tensor([[-0.5893, -1.4448],
        [-1.0966, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11444275081157684
Epoch 0, Step 2046: train/loss = 0.2639855444431305, train/raw-loss = 0.20520365238189697, train/logprobs = tensor([[-0.3191, -8.4209],
        [-0.8009, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09796983003616333
Epoch 0, Step 2047: train/loss = 0.36836230754852295, train/raw-loss = 0.27155351638793945, train/logprobs = tensor([[-1.6930, -5.0569],
        [-2.8444, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16134795546531677
Epoch 0, Step 2048: train/loss = 0.38292211294174194, train/raw-loss = 0.30935272574424744, train/logprobs = tensor([[-0.6733, -5.9771],
        [-1.0295, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12261561304330826
Epoch 0, Step 2049: train/loss = 0.37210309505462646, train/raw-loss = 0.2825208902359009, train/logprobs = tensor([[-1.1381, -4.1661],
        [-2.1239, -0.9766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14930368959903717
Epoch 0, Step 2050: train/loss = 0.24733272194862366, train/raw-loss = 0.14109376072883606, train/logprobs = tensor([[-0.6440, -4.7085],
        [-1.9116, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770649552345276
Epoch 0, Step 2051: train/loss = 0.3654853105545044, train/raw-loss = 0.2817806005477905, train/logprobs = tensor([[-0.4939, -7.4484],
        [-1.4031, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13950784504413605
Epoch 0, Step 2052: train/loss = 0.45414918661117554, train/raw-loss = 0.33981719613075256, train/logprobs = tensor([[-0.8998, -2.5061],
        [-2.8937, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19055330753326416
Epoch 0, Step 2053: train/loss = 0.5093439817428589, train/raw-loss = 0.41930872201919556, train/logprobs = tensor([[-1.4395, -4.2494],
        [-1.1411, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15005873143672943
Epoch 0, Step 2054: train/loss = 0.5100177526473999, train/raw-loss = 0.42872318625450134, train/logprobs = tensor([[-0.7484, -1.3756],
        [-1.8099, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13549090921878815
Epoch 0, Step 2055: train/loss = 0.4199956953525543, train/raw-loss = 0.35359787940979004, train/logprobs = tensor([[-0.9920, -4.3512],
        [-1.1366, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066308617591858
Epoch 0, Step 2056: train/loss = 0.39047229290008545, train/raw-loss = 0.3182497024536133, train/logprobs = tensor([[-0.7882, -1.9241],
        [-2.5790, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12037104368209839
Epoch 0, Step 2057: train/loss = 0.5457417964935303, train/raw-loss = 0.45278865098953247, train/logprobs = tensor([[-0.5723, -1.9109],
        [-1.6816, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549219787120819
Epoch 0, Step 2058: train/loss = 0.2586976885795593, train/raw-loss = 0.14879409968852997, train/logprobs = tensor([[-0.7056, -6.6024],
        [-2.6969, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18317262828350067
Epoch 0, Step 2059: train/loss = 0.33355215191841125, train/raw-loss = 0.23579876124858856, train/logprobs = tensor([[-0.5906, -8.3653],
        [-1.9199, -1.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16292229294776917
Epoch 0, Step 2060: train/loss = 0.41910892724990845, train/raw-loss = 0.3291362226009369, train/logprobs = tensor([[-1.0308, -3.2932],
        [-1.6388, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14995449781417847
Epoch 0, Step 2061: train/loss = 0.3305760324001312, train/raw-loss = 0.24376726150512695, train/logprobs = tensor([[-0.7274, -5.6877],
        [-2.0938, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14468123018741608
Epoch 0, Step 2062: train/loss = 0.36364269256591797, train/raw-loss = 0.25044381618499756, train/logprobs = tensor([[-0.9648, -3.7517],
        [-1.9999, -0.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886647790670395
Epoch 0, Step 2063: train/loss = 0.4810185432434082, train/raw-loss = 0.39106374979019165, train/logprobs = tensor([[-0.6056, -2.7276],
        [-1.9581, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1499246507883072
Epoch 0, Step 2064: train/loss = 0.5350697040557861, train/raw-loss = 0.4360639750957489, train/logprobs = tensor([[-1.3681, -3.3811],
        [-1.7971, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165009543299675
Epoch 0, Step 2065: train/loss = 0.27790600061416626, train/raw-loss = 0.19346767663955688, train/logprobs = tensor([[-0.7348, -9.2406],
        [-1.6945, -1.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1407305896282196
Epoch 0, Step 2066: train/loss = 0.42663607001304626, train/raw-loss = 0.3380417227745056, train/logprobs = tensor([[-0.7038, -4.6927],
        [-1.4799, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14765724539756775
Epoch 0, Step 2067: train/loss = 0.5055109858512878, train/raw-loss = 0.42091646790504456, train/logprobs = tensor([[-1.0964, -4.5411],
        [-1.5376, -1.3690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14099085330963135
Epoch 0, Step 2068: train/loss = 0.6478255391120911, train/raw-loss = 0.5587975978851318, train/logprobs = tensor([[-0.8540, -3.3858],
        [-1.5795, -1.3558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1483798325061798
Epoch 0, Step 2069: train/loss = 0.47621142864227295, train/raw-loss = 0.39370667934417725, train/logprobs = tensor([[-0.6197, -3.2263],
        [-1.4785, -1.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13750793039798737
Epoch 0, Step 2070: train/loss = 0.2195136696100235, train/raw-loss = 0.1267283856868744, train/logprobs = tensor([[-0.9436, -8.4835],
        [-2.8273, -0.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15464214980602264
Epoch 0, Step 2071: train/loss = 0.4877217411994934, train/raw-loss = 0.40046489238739014, train/logprobs = tensor([[-0.8555, -3.2431],
        [-1.3074, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1454281061887741
Epoch 0, Step 2072: train/loss = 0.3119165599346161, train/raw-loss = 0.21005919575691223, train/logprobs = tensor([[-0.7590, -5.8330],
        [-1.8226, -0.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16976222395896912
Epoch 0, Step 2073: train/loss = 0.3875386416912079, train/raw-loss = 0.2904416620731354, train/logprobs = tensor([[-0.8427, -4.0538],
        [-1.6964, -1.6410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16182827949523926
Epoch 0, Step 2074: train/loss = 0.4919658303260803, train/raw-loss = 0.4145473837852478, train/logprobs = tensor([[-0.6082, -2.4061],
        [-1.4789, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12903068959712982
Epoch 0, Step 2075: train/loss = 0.5510528087615967, train/raw-loss = 0.4593113660812378, train/logprobs = tensor([[-0.8201, -2.2689],
        [-1.5092, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15290240943431854
Epoch 0, Step 2076: train/loss = 0.3668760657310486, train/raw-loss = 0.287801057100296, train/logprobs = tensor([[-1.3639, -7.3817],
        [-1.7900, -1.5441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1317916065454483
Epoch 0, Step 2077: train/loss = 0.340553879737854, train/raw-loss = 0.2541675567626953, train/logprobs = tensor([[-0.6500, -5.9474],
        [-1.4411, -0.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14397719502449036
Epoch 0, Step 2078: train/loss = 0.3137751519680023, train/raw-loss = 0.2291726917028427, train/logprobs = tensor([[-0.8160, -4.1291],
        [-2.0167, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14100408554077148
Epoch 0, Step 2079: train/loss = 0.4165526032447815, train/raw-loss = 0.3359743356704712, train/logprobs = tensor([[-0.5721, -4.8051],
        [-1.1775, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13429711759090424
Epoch 0, Step 2080: train/loss = 0.28009527921676636, train/raw-loss = 0.19602656364440918, train/logprobs = tensor([[-0.8622, -5.8677],
        [-2.0972, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14011450111865997
Epoch 0, Step 2081: train/loss = 0.34639233350753784, train/raw-loss = 0.2538963854312897, train/logprobs = tensor([[-0.8686, -2.8170],
        [-2.4976, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15415987372398376
Epoch 0, Step 2082: train/loss = 0.2957528233528137, train/raw-loss = 0.20889592170715332, train/logprobs = tensor([[ -0.6913, -10.1817],
        [ -1.8429,  -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14476147294044495
Epoch 0, Step 2083: train/loss = 0.4812086820602417, train/raw-loss = 0.3975217938423157, train/logprobs = tensor([[-0.8822, -2.1275],
        [-1.7051, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13947811722755432
Epoch 0, Step 2084: train/loss = 0.266090989112854, train/raw-loss = 0.18193843960762024, train/logprobs = tensor([[-0.7103, -7.1470],
        [-2.7466, -0.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402542144060135
Epoch 0, Step 2085: train/loss = 0.4543929696083069, train/raw-loss = 0.40623003244400024, train/logprobs = tensor([[-0.7914, -2.9987],
        [-1.2299, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08027156442403793
Epoch 0, Step 2086: train/loss = 0.4308348298072815, train/raw-loss = 0.35980162024497986, train/logprobs = tensor([[-0.4313, -3.2983],
        [-0.9498, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11838862299919128
Epoch 0, Step 2087: train/loss = 0.18423587083816528, train/raw-loss = 0.08938099443912506, train/logprobs = tensor([[ -0.9042, -13.2245],
        [ -2.5946,  -1.2416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1580914556980133
Epoch 0, Step 2088: train/loss = 0.4363435208797455, train/raw-loss = 0.3606356978416443, train/logprobs = tensor([[-0.4256, -7.3311],
        [-1.6978, -1.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12617968022823334
Epoch 0, Step 2089: train/loss = 0.6011011600494385, train/raw-loss = 0.5224093198776245, train/logprobs = tensor([[-1.2202, -2.8340],
        [-1.1527, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13115304708480835
Epoch 0, Step 2090: train/loss = 0.5609923005104065, train/raw-loss = 0.48920518159866333, train/logprobs = tensor([[-1.3893, -2.7858],
        [-1.3718, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11964517831802368
Epoch 0, Step 2091: train/loss = 0.4141981303691864, train/raw-loss = 0.34366822242736816, train/logprobs = tensor([[-0.7175, -3.3243],
        [-1.1059, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1175498366355896
Epoch 0, Step 2092: train/loss = 0.22521859407424927, train/raw-loss = 0.1282319575548172, train/logprobs = tensor([[-0.6164, -6.5715],
        [-2.0181, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16164441406726837
Epoch 0, Step 2093: train/loss = 0.5804524421691895, train/raw-loss = 0.49663078784942627, train/logprobs = tensor([[-1.9859, -4.8766],
        [-1.8163, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13970276713371277
Epoch 0, Step 2094: train/loss = 0.3019161522388458, train/raw-loss = 0.21501588821411133, train/logprobs = tensor([[-0.4844, -7.7892],
        [-1.7628, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1448337435722351
Epoch 0, Step 2095: train/loss = 0.5089622139930725, train/raw-loss = 0.4130764305591583, train/logprobs = tensor([[-0.6922, -4.2082],
        [-1.8254, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1598096489906311
Epoch 0, Step 2096: train/loss = 0.4790743887424469, train/raw-loss = 0.4017027020454407, train/logprobs = tensor([[-1.1853, -6.5498],
        [-1.5927, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12895281612873077
Epoch 0, Step 2097: train/loss = 0.48892876505851746, train/raw-loss = 0.39691153168678284, train/logprobs = tensor([[-0.6416, -4.2884],
        [-1.4895, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.153361976146698
Epoch 0, Step 2098: train/loss = 0.19691625237464905, train/raw-loss = 0.0952620655298233, train/logprobs = tensor([[-0.6720, -6.1986],
        [-2.3277, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1694236695766449
Epoch 0, Step 2099: train/loss = 0.3495453894138336, train/raw-loss = 0.25200119614601135, train/logprobs = tensor([[-0.6958, -6.3872],
        [-1.2348, -0.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16257363557815552
Epoch 0, Step 2100: train/loss = 0.5511138439178467, train/raw-loss = 0.4565739929676056, train/logprobs = tensor([[-0.6705, -1.5920],
        [-1.3796, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15756642818450928
Epoch 0, Step 2101: train/loss = 0.5356013774871826, train/raw-loss = 0.44914892315864563, train/logprobs = tensor([[-0.7143, -2.9656],
        [-1.5465, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14408744871616364
Epoch 0, Step 2102: train/loss = 0.3937056362628937, train/raw-loss = 0.3202238380908966, train/logprobs = tensor([[-0.9599, -6.1913],
        [-1.2383, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246961891651154
Epoch 0, Step 2103: train/loss = 0.3776725232601166, train/raw-loss = 0.2865501642227173, train/logprobs = tensor([[-0.6744, -6.0025],
        [-1.4685, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15187059342861176
Epoch 0, Step 2104: train/loss = 0.43225765228271484, train/raw-loss = 0.3522827625274658, train/logprobs = tensor([[-0.5931, -2.1146],
        [-1.5895, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329149782657623
Epoch 0, Step 2105: train/loss = 0.4894489645957947, train/raw-loss = 0.3828980624675751, train/logprobs = tensor([[-0.7952, -3.4034],
        [-1.8176, -2.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17758479714393616
Epoch 0, Step 2106: train/loss = 0.5573711395263672, train/raw-loss = 0.47067883610725403, train/logprobs = tensor([[-0.5300, -2.0669],
        [-1.0487, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14448721706867218
Epoch 0, Step 2107: train/loss = 0.41443824768066406, train/raw-loss = 0.3497260808944702, train/logprobs = tensor([[-1.1257, -2.5748],
        [-1.7311, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10785364359617233
Epoch 0, Step 2108: train/loss = 0.3230643570423126, train/raw-loss = 0.2545047700405121, train/logprobs = tensor([[-0.6707, -6.8893],
        [-1.5787, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11426595598459244
Epoch 0, Step 2109: train/loss = 0.4035235345363617, train/raw-loss = 0.3356170654296875, train/logprobs = tensor([[ -0.5152, -11.4483],
        [ -1.2405,  -1.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11317746341228485
Epoch 0, Step 2110: train/loss = 0.4922601282596588, train/raw-loss = 0.42357978224754333, train/logprobs = tensor([[-1.2331, -3.4594],
        [-1.7363, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11446720361709595
Epoch 0, Step 2111: train/loss = 0.37059083580970764, train/raw-loss = 0.25498059391975403, train/logprobs = tensor([[-0.7399, -3.6736],
        [-2.1821, -1.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19268366694450378
Epoch 0, Step 2112: train/loss = 0.31063586473464966, train/raw-loss = 0.22925391793251038, train/logprobs = tensor([[-0.5959, -4.4217],
        [-1.9961, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1356365829706192
Epoch 0, Step 2113: train/loss = 0.40972208976745605, train/raw-loss = 0.3102641999721527, train/logprobs = tensor([[-0.6704, -8.0962],
        [-2.3414, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16576316952705383
Epoch 0, Step 2114: train/loss = 0.27255117893218994, train/raw-loss = 0.18224361538887024, train/logprobs = tensor([[-0.7054, -7.5813],
        [-1.4383, -1.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15051257610321045
Epoch 0, Step 2115: train/loss = 0.19170913100242615, train/raw-loss = 0.10135601460933685, train/logprobs = tensor([[-0.7342, -8.7260],
        [-2.4424, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1505885124206543
Epoch 0, Step 2116: train/loss = 0.2977427840232849, train/raw-loss = 0.19879654049873352, train/logprobs = tensor([[-1.1055, -6.6469],
        [-2.7167, -1.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16491037607192993
Epoch 0, Step 2117: train/loss = 0.5494829416275024, train/raw-loss = 0.4808136224746704, train/logprobs = tensor([[-0.4057, -4.7816],
        [-1.1207, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11444899439811707
Epoch 0, Step 2118: train/loss = 0.4041944742202759, train/raw-loss = 0.30731070041656494, train/logprobs = tensor([[-0.6893, -7.2804],
        [-1.3260, -1.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16147291660308838
Epoch 0, Step 2119: train/loss = 0.2915033996105194, train/raw-loss = 0.2003551721572876, train/logprobs = tensor([[-0.7405, -3.9161],
        [-1.9898, -0.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15191367268562317
Epoch 0, Step 2120: train/loss = 0.8073002099990845, train/raw-loss = 0.7303422689437866, train/logprobs = tensor([[-2.1891, -2.4197],
        [-1.5248, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282631754875183
Epoch 0, Step 2121: train/loss = 0.6681126356124878, train/raw-loss = 0.5789076685905457, train/logprobs = tensor([[-1.6751, -4.2731],
        [-1.3424, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14867495000362396
Epoch 0, Step 2122: train/loss = 0.332457959651947, train/raw-loss = 0.2533005177974701, train/logprobs = tensor([[-0.9592, -4.9497],
        [-1.7153, -0.9258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13192908465862274
Epoch 0, Step 2123: train/loss = 0.45889973640441895, train/raw-loss = 0.37155866622924805, train/logprobs = tensor([[-1.3788, -5.8194],
        [-1.8634, -1.3974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14556851983070374
Epoch 0, Step 2124: train/loss = 0.2988984286785126, train/raw-loss = 0.202504962682724, train/logprobs = tensor([[-0.8537, -4.5843],
        [-2.2000, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16065578162670135
Epoch 0, Step 2125: train/loss = 0.3351270258426666, train/raw-loss = 0.24994021654129028, train/logprobs = tensor([[-0.7214, -3.5339],
        [-1.3807, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14197807013988495
Epoch 0, Step 2126: train/loss = 0.43336957693099976, train/raw-loss = 0.35817229747772217, train/logprobs = tensor([[-0.5285, -2.7433],
        [-1.9147, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12532883882522583
Epoch 0, Step 2127: train/loss = 0.25838395953178406, train/raw-loss = 0.1697407066822052, train/logprobs = tensor([[-1.7639, -8.8774],
        [-2.9856, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1477387547492981
Epoch 0, Step 2128: train/loss = 0.33719518780708313, train/raw-loss = 0.25551778078079224, train/logprobs = tensor([[-0.9903, -5.4264],
        [-1.9393, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13612902164459229
Epoch 0, Step 2129: train/loss = 0.37654778361320496, train/raw-loss = 0.2954348921775818, train/logprobs = tensor([[-0.4121, -5.4394],
        [-1.2873, -1.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13518819212913513
Epoch 0, Step 2130: train/loss = 0.39944279193878174, train/raw-loss = 0.31346970796585083, train/logprobs = tensor([[-0.9510, -3.2031],
        [-1.7605, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14328841865062714
Epoch 0, Step 2131: train/loss = 0.37858903408050537, train/raw-loss = 0.2825813889503479, train/logprobs = tensor([[-0.7597, -3.2943],
        [-1.6188, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16001275181770325
Epoch 0, Step 2132: train/loss = 0.35703685879707336, train/raw-loss = 0.2752516269683838, train/logprobs = tensor([[-1.1198, -6.2692],
        [-1.9075, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1363086998462677
Epoch 0, Step 2133: train/loss = 0.40089917182922363, train/raw-loss = 0.3274308443069458, train/logprobs = tensor([[-0.7264, -4.7451],
        [-1.1650, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12244727462530136
Epoch 0, Step 2134: train/loss = 0.5312562584877014, train/raw-loss = 0.4203440546989441, train/logprobs = tensor([[-1.6233, -6.1993],
        [-2.0576, -0.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1848536729812622
Epoch 0, Step 2135: train/loss = 0.40244221687316895, train/raw-loss = 0.32192978262901306, train/logprobs = tensor([[-0.3831, -5.4266],
        [-1.9148, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13418735563755035
Epoch 0, Step 2136: train/loss = 0.34024909138679504, train/raw-loss = 0.23812296986579895, train/logprobs = tensor([[-0.6508, -5.4881],
        [-1.7305, -0.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17021022737026215
Epoch 0, Step 2137: train/loss = 0.40064460039138794, train/raw-loss = 0.2988196909427643, train/logprobs = tensor([[-0.8614, -4.4200],
        [-1.6564, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16970814764499664
Epoch 0, Step 2138: train/loss = 0.1947893500328064, train/raw-loss = 0.10993841290473938, train/logprobs = tensor([[-0.9876, -7.1070],
        [-3.3564, -1.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1414182335138321
Epoch 0, Step 2139: train/loss = 0.33197277784347534, train/raw-loss = 0.2437105029821396, train/logprobs = tensor([[-0.7023, -5.7021],
        [-2.0875, -1.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14710375666618347
Epoch 0, Step 2140: train/loss = 0.4214770495891571, train/raw-loss = 0.35991328954696655, train/logprobs = tensor([[-0.8073, -3.8816],
        [-1.2640, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10260626673698425
Epoch 0, Step 2141: train/loss = 1.2223496437072754, train/raw-loss = 1.141144871711731, train/logprobs = tensor([[-4.2251, -5.6039],
        [-1.8166, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13534125685691833
Epoch 0, Step 2142: train/loss = 0.23647311329841614, train/raw-loss = 0.13170839846134186, train/logprobs = tensor([[-0.7578, -6.0582],
        [-2.7084, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17460784316062927
Epoch 0, Step 2143: train/loss = 0.4323064386844635, train/raw-loss = 0.3467006981372833, train/logprobs = tensor([[-0.6648, -3.9497],
        [-1.1680, -0.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1426762342453003
Epoch 0, Step 2144: train/loss = 0.49249571561813354, train/raw-loss = 0.40187305212020874, train/logprobs = tensor([[-0.9661, -2.6355],
        [-1.3380, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1510377824306488
Epoch 0, Step 2145: train/loss = 0.4548562169075012, train/raw-loss = 0.3825308084487915, train/logprobs = tensor([[-0.4588, -2.3802],
        [-0.9627, -0.6524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12054230272769928
Epoch 0, Step 2146: train/loss = 0.3642793297767639, train/raw-loss = 0.28153106570243835, train/logprobs = tensor([[-0.9221, -2.9631],
        [-1.6927, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379137486219406
Epoch 0, Step 2147: train/loss = 0.31611472368240356, train/raw-loss = 0.23333840072155, train/logprobs = tensor([[-1.3501, -4.7709],
        [-2.2679, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379605084657669
Epoch 0, Step 2148: train/loss = 0.15586718916893005, train/raw-loss = 0.07333538681268692, train/logprobs = tensor([[-0.6803, -7.0534],
        [-2.7694, -1.4258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13755297660827637
Epoch 0, Step 2149: train/loss = 0.5120117664337158, train/raw-loss = 0.433277428150177, train/logprobs = tensor([[-0.7355, -5.5657],
        [-1.4205, -1.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312239170074463
Epoch 0, Step 2150: train/loss = 0.6154263615608215, train/raw-loss = 0.5352895259857178, train/logprobs = tensor([[-2.2065, -4.2962],
        [-2.2293, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335613876581192
Epoch 0, Step 2151: train/loss = 0.49654215574264526, train/raw-loss = 0.4444647431373596, train/logprobs = tensor([[-1.2270, -7.0539],
        [-1.4811, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0867956280708313
Epoch 0, Step 2152: train/loss = 0.49344345927238464, train/raw-loss = 0.4302467703819275, train/logprobs = tensor([[-0.5102, -3.1150],
        [-0.7845, -0.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10532780736684799
Epoch 0, Step 2153: train/loss = 0.3864728510379791, train/raw-loss = 0.2461102306842804, train/logprobs = tensor([[-0.9266, -4.2357],
        [-2.8028, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23393769562244415
Epoch 0, Step 2154: train/loss = 0.3079867959022522, train/raw-loss = 0.22349125146865845, train/logprobs = tensor([[-1.0743, -4.7716],
        [-2.1925, -1.1328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14082591235637665
Epoch 0, Step 2155: train/loss = 0.27994245290756226, train/raw-loss = 0.20072591304779053, train/logprobs = tensor([[ -0.5536, -10.3567],
        [ -1.9506,  -1.6335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320275366306305
Epoch 0, Step 2156: train/loss = 0.5236227512359619, train/raw-loss = 0.4476827383041382, train/logprobs = tensor([[-0.5616, -4.4874],
        [-1.2970, -1.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12656667828559875
Epoch 0, Step 2157: train/loss = 0.1920357197523117, train/raw-loss = 0.08970847725868225, train/logprobs = tensor([[-1.1377, -6.4283],
        [-3.1920, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17054539918899536
Epoch 0, Step 2158: train/loss = 0.5892836451530457, train/raw-loss = 0.49056726694107056, train/logprobs = tensor([[-0.9652, -5.7054],
        [-2.3203, -1.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645272970199585
Epoch 0, Step 2159: train/loss = 0.9085701704025269, train/raw-loss = 0.8016061782836914, train/logprobs = tensor([[-2.6789, -6.9374],
        [-3.1332, -1.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1782732605934143
Epoch 0, Step 2160: train/loss = 0.3575097322463989, train/raw-loss = 0.2535901665687561, train/logprobs = tensor([[-0.4189, -4.8321],
        [-1.8686, -0.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17319920659065247
Epoch 0, Step 2161: train/loss = 0.3247075378894806, train/raw-loss = 0.22634673118591309, train/logprobs = tensor([[-1.6649, -6.1707],
        [-2.4243, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1639346182346344
Epoch 0, Step 2162: train/loss = 0.434441477060318, train/raw-loss = 0.3365013599395752, train/logprobs = tensor([[-0.7593, -3.7235],
        [-2.3640, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16323351860046387
Epoch 0, Step 2163: train/loss = 0.43304163217544556, train/raw-loss = 0.33192750811576843, train/logprobs = tensor([[-0.6814, -3.3278],
        [-1.6053, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16852353513240814
Epoch 0, Step 2164: train/loss = 0.2758931517601013, train/raw-loss = 0.20457246899604797, train/logprobs = tensor([[-0.5242, -8.8162],
        [-2.1375, -1.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11886775493621826
Epoch 0, Step 2165: train/loss = 0.5365219116210938, train/raw-loss = 0.4573787748813629, train/logprobs = tensor([[-0.4032, -1.8813],
        [-1.2246, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13190507888793945
Epoch 0, Step 2166: train/loss = 0.4600030481815338, train/raw-loss = 0.38159850239753723, train/logprobs = tensor([[-0.7342, -7.6936],
        [-1.1848, -1.2361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13067416846752167
Epoch 0, Step 2167: train/loss = 0.5954957604408264, train/raw-loss = 0.5179198384284973, train/logprobs = tensor([[-0.4250, -0.8919],
        [-1.6051, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12929324805736542
Epoch 0, Step 2168: train/loss = 0.3822842538356781, train/raw-loss = 0.3114359676837921, train/logprobs = tensor([[-0.8981, -5.8034],
        [-1.1302, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1180804893374443
Epoch 0, Step 2169: train/loss = 0.5776791572570801, train/raw-loss = 0.5060223937034607, train/logprobs = tensor([[-0.5435, -1.8863],
        [-1.9411, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11942801624536514
Epoch 0, Step 2170: train/loss = 0.29458850622177124, train/raw-loss = 0.191655233502388, train/logprobs = tensor([[-1.2902, -7.3083],
        [-2.7636, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17155542969703674
Epoch 0, Step 2171: train/loss = 0.5915038585662842, train/raw-loss = 0.5093600749969482, train/logprobs = tensor([[-1.2176, -3.7369],
        [-0.8327, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13690632581710815
Epoch 0, Step 2172: train/loss = 0.5950270891189575, train/raw-loss = 0.5324962139129639, train/logprobs = tensor([[-0.7357, -2.3846],
        [-0.9247, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421805083751678
Epoch 0, Step 2173: train/loss = 0.4996212124824524, train/raw-loss = 0.42990338802337646, train/logprobs = tensor([[-0.7651, -4.4411],
        [-1.0588, -1.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11619637906551361
Epoch 0, Step 2174: train/loss = 0.4455152153968811, train/raw-loss = 0.36486971378326416, train/logprobs = tensor([[-0.4975, -2.6887],
        [-1.2309, -0.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13440918922424316
Epoch 0, Step 2175: train/loss = 0.3039458394050598, train/raw-loss = 0.22613447904586792, train/logprobs = tensor([[-0.5540, -6.3941],
        [-1.9497, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12968553602695465
Epoch 0, Step 2176: train/loss = 0.4820231795310974, train/raw-loss = 0.4176079034805298, train/logprobs = tensor([[-1.9883, -7.3827],
        [-2.0186, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10735887289047241
Epoch 0, Step 2177: train/loss = 0.4312177300453186, train/raw-loss = 0.34703853726387024, train/logprobs = tensor([[-1.1522, -5.4416],
        [-1.7265, -1.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14029866456985474
Epoch 0, Step 2178: train/loss = 0.3686801493167877, train/raw-loss = 0.2845354378223419, train/logprobs = tensor([[-0.9083, -7.0978],
        [-1.4186, -1.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14024122059345245
Epoch 0, Step 2179: train/loss = 0.46163883805274963, train/raw-loss = 0.3820387125015259, train/logprobs = tensor([[-0.7911, -2.6163],
        [-1.3849, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13266679644584656
Epoch 0, Step 2180: train/loss = 0.4900112748146057, train/raw-loss = 0.41183751821517944, train/logprobs = tensor([[-0.4139, -4.1303],
        [-0.9183, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13028964400291443
Epoch 0, Step 2181: train/loss = 0.27015039324760437, train/raw-loss = 0.15425074100494385, train/logprobs = tensor([[-0.6550, -5.6924],
        [-2.1253, -1.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1931660920381546
Epoch 0, Step 2182: train/loss = 0.5854706764221191, train/raw-loss = 0.5168164968490601, train/logprobs = tensor([[-0.9446, -3.3486],
        [-0.8315, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11442360281944275
Epoch 0, Step 2183: train/loss = 0.22913207113742828, train/raw-loss = 0.13199162483215332, train/logprobs = tensor([[-0.7798, -5.6019],
        [-2.3563, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190071403980255
Epoch 0, Step 2184: train/loss = 0.8066288232803345, train/raw-loss = 0.7225590348243713, train/logprobs = tensor([[-0.5682, -0.7434],
        [-2.3967, -1.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1401163637638092
Epoch 0, Step 2185: train/loss = 0.52842116355896, train/raw-loss = 0.42561811208724976, train/logprobs = tensor([[-0.9396, -3.1582],
        [-1.8345, -2.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17133840918540955
Epoch 0, Step 2186: train/loss = 0.3562021851539612, train/raw-loss = 0.28478753566741943, train/logprobs = tensor([[-0.7089, -5.3360],
        [-1.3886, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1190243735909462
Epoch 0, Step 2187: train/loss = 0.5264102816581726, train/raw-loss = 0.42675474286079407, train/logprobs = tensor([[-0.9113, -2.3464],
        [-2.7741, -1.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16609250009059906
Epoch 0, Step 2188: train/loss = 0.2969985008239746, train/raw-loss = 0.1838376522064209, train/logprobs = tensor([[-0.6839, -5.5635],
        [-2.5693, -1.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18860134482383728
Epoch 0, Step 2189: train/loss = 0.5272742509841919, train/raw-loss = 0.4669697880744934, train/logprobs = tensor([[-0.6201, -2.2682],
        [-1.0680, -0.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10050736367702484
Epoch 0, Step 2190: train/loss = 0.1943030059337616, train/raw-loss = 0.11849401146173477, train/logprobs = tensor([[ -1.0655, -12.5765],
        [ -2.5394,  -1.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12634830176830292
Epoch 0, Step 2191: train/loss = 0.5195834636688232, train/raw-loss = 0.44122928380966187, train/logprobs = tensor([[-0.6793, -1.7204],
        [-1.3936, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13059020042419434
Epoch 0, Step 2192: train/loss = 0.24169185757637024, train/raw-loss = 0.12524084746837616, train/logprobs = tensor([[-1.0407, -4.9262],
        [-2.9711, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1940850019454956
Epoch 0, Step 2193: train/loss = 0.47341763973236084, train/raw-loss = 0.38245463371276855, train/logprobs = tensor([[-0.4699, -3.8703],
        [-1.4115, -1.2984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15160496532917023
Epoch 0, Step 2194: train/loss = 0.4351923167705536, train/raw-loss = 0.3688613772392273, train/logprobs = tensor([[-0.8759, -5.6769],
        [-1.4181, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11055155098438263
Epoch 0, Step 2195: train/loss = 0.30419260263442993, train/raw-loss = 0.2210818976163864, train/logprobs = tensor([[-0.6898, -7.5761],
        [-1.8206, -1.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138517826795578
Epoch 0, Step 2196: train/loss = 0.6745872497558594, train/raw-loss = 0.6032503843307495, train/logprobs = tensor([[-0.8990, -0.9630],
        [-1.1233, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1188947781920433
Epoch 0, Step 2197: train/loss = 0.261830598115921, train/raw-loss = 0.1674322932958603, train/logprobs = tensor([[-0.8878, -7.1877],
        [-1.8015, -0.9902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15733051300048828
Epoch 0, Step 2198: train/loss = 0.5086580514907837, train/raw-loss = 0.4319477677345276, train/logprobs = tensor([[-1.9478, -8.3289],
        [-1.6947, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12785053253173828
Epoch 0, Step 2199: train/loss = 0.6053851842880249, train/raw-loss = 0.5350003242492676, train/logprobs = tensor([[-0.5678, -0.9871],
        [-1.0246, -0.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11730814725160599
Epoch 0, Step 2200: train/loss = 0.42886480689048767, train/raw-loss = 0.34269770979881287, train/logprobs = tensor([[-0.5530, -3.4654],
        [-1.6553, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1436118334531784
Epoch 0, Step 2201: train/loss = 0.5753449201583862, train/raw-loss = 0.5067225694656372, train/logprobs = tensor([[-0.5865, -1.2814],
        [-0.7955, -0.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11437054723501205
Epoch 0, Step 2202: train/loss = 0.5594570636749268, train/raw-loss = 0.47294265031814575, train/logprobs = tensor([[-1.0207, -1.4580],
        [-1.6335, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14419065415859222
Epoch 0, Step 2203: train/loss = 0.3654891848564148, train/raw-loss = 0.24908961355686188, train/logprobs = tensor([[-0.9810, -5.9453],
        [-2.5505, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19399932026863098
Epoch 0, Step 2204: train/loss = 0.3619985580444336, train/raw-loss = 0.2884327173233032, train/logprobs = tensor([[-0.7973, -4.3935],
        [-1.5682, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1226097047328949
Epoch 0, Step 2205: train/loss = 0.3099198341369629, train/raw-loss = 0.22941064834594727, train/logprobs = tensor([[-0.5500, -6.2061],
        [-2.0584, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13418199121952057
Epoch 0, Step 2206: train/loss = 0.5811505317687988, train/raw-loss = 0.5049079656600952, train/logprobs = tensor([[-1.0535, -2.4078],
        [-1.1306, -0.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12707094848155975
Epoch 0, Step 2207: train/loss = 0.2344747632741928, train/raw-loss = 0.1467975378036499, train/logprobs = tensor([[-0.7230, -4.9719],
        [-1.9225, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14612872898578644
Epoch 0, Step 2208: train/loss = 0.49657851457595825, train/raw-loss = 0.41076818108558655, train/logprobs = tensor([[-0.8157, -3.8620],
        [-1.6615, -0.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430172324180603
Epoch 0, Step 2209: train/loss = 0.261702299118042, train/raw-loss = 0.16611699759960175, train/logprobs = tensor([[-0.9086, -6.8849],
        [-2.5322, -1.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1593087911605835
Epoch 0, Step 2210: train/loss = 0.40880393981933594, train/raw-loss = 0.3309068977832794, train/logprobs = tensor([[-1.0274, -4.2210],
        [-2.7304, -2.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1298283189535141
Epoch 0, Step 2211: train/loss = 0.5146908164024353, train/raw-loss = 0.39619556069374084, train/logprobs = tensor([[-0.5808, -5.4914],
        [-2.3969, -1.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1974920928478241
Epoch 0, Step 2212: train/loss = 0.3192249834537506, train/raw-loss = 0.21190685033798218, train/logprobs = tensor([[-0.8418, -5.6672],
        [-2.3033, -1.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178863525390625
Epoch 0, Step 2213: train/loss = 0.27904582023620605, train/raw-loss = 0.18963083624839783, train/logprobs = tensor([[-0.9034, -6.4975],
        [-1.7149, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14902502298355103
Epoch 0, Step 2214: train/loss = 0.2349942922592163, train/raw-loss = 0.13561689853668213, train/logprobs = tensor([[-0.8285, -7.4356],
        [-2.8274, -1.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16562901437282562
Epoch 0, Step 2215: train/loss = 0.40838295221328735, train/raw-loss = 0.31698039174079895, train/logprobs = tensor([[-1.3130, -4.7457],
        [-1.4942, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15233755111694336
Epoch 0, Step 2216: train/loss = 0.290740042924881, train/raw-loss = 0.19622601568698883, train/logprobs = tensor([[-1.1518, -4.3091],
        [-3.0646, -0.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15752333402633667
Epoch 0, Step 2217: train/loss = 0.4480101466178894, train/raw-loss = 0.3535038232803345, train/logprobs = tensor([[-2.6719, -4.9511],
        [-4.2927, -1.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15751054883003235
Epoch 0, Step 2218: train/loss = 0.4575451612472534, train/raw-loss = 0.3798580765724182, train/logprobs = tensor([[-0.6975, -4.7180],
        [-1.5764, -2.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12947848439216614
Epoch 0, Step 2219: train/loss = 0.39938580989837646, train/raw-loss = 0.33643895387649536, train/logprobs = tensor([[-1.0211, -8.0899],
        [-1.4551, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10491135716438293
Epoch 0, Step 2220: train/loss = 0.5957082509994507, train/raw-loss = 0.4921659827232361, train/logprobs = tensor([[-0.9552, -4.1153],
        [-2.5016, -2.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1725703328847885
Epoch 0, Step 2221: train/loss = 0.6398541331291199, train/raw-loss = 0.5513663291931152, train/logprobs = tensor([[-2.1677, -9.1149],
        [-1.7213, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14747968316078186
Epoch 0, Step 2222: train/loss = 0.4036576747894287, train/raw-loss = 0.32744213938713074, train/logprobs = tensor([[-0.3863, -5.3202],
        [-1.2231, -0.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12702593207359314
Epoch 0, Step 2223: train/loss = 0.29789313673973083, train/raw-loss = 0.2217249870300293, train/logprobs = tensor([[-0.7382, -6.0668],
        [-2.4777, -1.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12694697082042694
Epoch 0, Step 2224: train/loss = 0.22622904181480408, train/raw-loss = 0.13565587997436523, train/logprobs = tensor([[-0.6629, -7.8618],
        [-3.1360, -1.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15095525979995728
Epoch 0, Step 2225: train/loss = 0.5870739817619324, train/raw-loss = 0.5139501094818115, train/logprobs = tensor([[-1.3542, -3.1759],
        [-1.2229, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12187310308218002
Epoch 0, Step 2226: train/loss = 0.2043640911579132, train/raw-loss = 0.10680315643548965, train/logprobs = tensor([[-0.5242, -8.2411],
        [-2.2392, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626015305519104
Epoch 0, Step 2227: train/loss = 0.3972930908203125, train/raw-loss = 0.29977577924728394, train/logprobs = tensor([[-0.4097, -4.2030],
        [-1.6638, -1.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1625289022922516
Epoch 0, Step 2228: train/loss = 0.36226460337638855, train/raw-loss = 0.26682060956954956, train/logprobs = tensor([[-0.5849, -5.2698],
        [-2.2341, -1.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15907332301139832
Epoch 0, Step 2229: train/loss = 0.42917513847351074, train/raw-loss = 0.3544768691062927, train/logprobs = tensor([[-0.5977, -4.1653],
        [-1.1085, -0.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244971752166748
Epoch 0, Step 2230: train/loss = 0.35734665393829346, train/raw-loss = 0.28013888001441956, train/logprobs = tensor([[-0.9308, -3.9757],
        [-2.1866, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12867960333824158
Epoch 0, Step 2231: train/loss = 0.4561539888381958, train/raw-loss = 0.38912153244018555, train/logprobs = tensor([[-0.4459, -4.6904],
        [-0.9124, -1.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11172078549861908
Epoch 0, Step 2232: train/loss = 0.42796364426612854, train/raw-loss = 0.3121514618396759, train/logprobs = tensor([[-0.7967, -3.6180],
        [-2.9255, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.193020299077034
Epoch 0, Step 2233: train/loss = 0.28177231550216675, train/raw-loss = 0.2135924994945526, train/logprobs = tensor([[-1.0181, -6.2618],
        [-1.5458, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11363300681114197
Epoch 0, Step 2234: train/loss = 0.32756128907203674, train/raw-loss = 0.23597560822963715, train/logprobs = tensor([[-0.9090, -5.6628],
        [-1.8602, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15264281630516052
Epoch 0, Step 2235: train/loss = 0.661596417427063, train/raw-loss = 0.5712104439735413, train/logprobs = tensor([[-1.7600, -3.8200],
        [-2.3242, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15064334869384766
Epoch 0, Step 2236: train/loss = 0.4106399118900299, train/raw-loss = 0.3262190520763397, train/logprobs = tensor([[-0.5641, -4.0659],
        [-1.3340, -1.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14070142805576324
Epoch 0, Step 2237: train/loss = 0.5611342191696167, train/raw-loss = 0.4865766167640686, train/logprobs = tensor([[-1.3023, -2.6705],
        [-1.8364, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12426268309354782
Epoch 0, Step 2238: train/loss = 0.39153626561164856, train/raw-loss = 0.2831162214279175, train/logprobs = tensor([[-1.1805, -4.9700],
        [-2.6787, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18070000410079956
Epoch 0, Step 2239: train/loss = 0.41241922974586487, train/raw-loss = 0.32083508372306824, train/logprobs = tensor([[-0.7666, -6.5736],
        [-1.5999, -1.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15264025330543518
Epoch 0, Step 2240: train/loss = 0.31717774271965027, train/raw-loss = 0.23850852251052856, train/logprobs = tensor([[-0.8639, -5.5384],
        [-1.6715, -0.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311153769493103
Epoch 0, Step 2241: train/loss = 0.37184733152389526, train/raw-loss = 0.2876722812652588, train/logprobs = tensor([[-0.9038, -2.6499],
        [-1.8023, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402917355298996
Epoch 0, Step 2242: train/loss = 0.5258858799934387, train/raw-loss = 0.4479140043258667, train/logprobs = tensor([[-0.7488, -3.9436],
        [-2.5649, -1.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12995311617851257
Epoch 0, Step 2243: train/loss = 0.4503140449523926, train/raw-loss = 0.37168848514556885, train/logprobs = tensor([[-0.5453, -3.7930],
        [-1.3268, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13104259967803955
Epoch 0, Step 2244: train/loss = 0.26607441902160645, train/raw-loss = 0.17644663155078888, train/logprobs = tensor([[-0.8380, -7.8529],
        [-2.0274, -2.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1493796408176422
Epoch 0, Step 2245: train/loss = 0.45526403188705444, train/raw-loss = 0.3950188159942627, train/logprobs = tensor([[-0.6888, -3.9258],
        [-1.1842, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10040873289108276
Epoch 0, Step 2246: train/loss = 0.3421463668346405, train/raw-loss = 0.24109508097171783, train/logprobs = tensor([[-0.7499, -4.5579],
        [-2.0018, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1684187948703766
Epoch 0, Step 2247: train/loss = 0.2819834351539612, train/raw-loss = 0.1797633171081543, train/logprobs = tensor([[-0.6813, -4.2416],
        [-2.6481, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1703668236732483
Epoch 0, Step 2248: train/loss = 0.6063871383666992, train/raw-loss = 0.5329173803329468, train/logprobs = tensor([[-0.4671, -0.8600],
        [-1.0269, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12244951725006104
Epoch 0, Step 2249: train/loss = 0.3021852672100067, train/raw-loss = 0.22799089550971985, train/logprobs = tensor([[-0.6401, -3.4494],
        [-1.4536, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12365729361772537
Epoch 0, Step 2250: train/loss = 0.35405638813972473, train/raw-loss = 0.26435860991477966, train/logprobs = tensor([[-0.5109, -4.8039],
        [-1.5259, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949630200862885
Epoch 0, Step 2251: train/loss = 0.3366793692111969, train/raw-loss = 0.24381975829601288, train/logprobs = tensor([[-0.5101, -4.4512],
        [-1.5412, -1.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547660529613495
Epoch 0, Step 2252: train/loss = 0.5169413685798645, train/raw-loss = 0.446623831987381, train/logprobs = tensor([[-0.7879, -2.2055],
        [-1.1111, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11719593405723572
Epoch 0, Step 2253: train/loss = 0.479827880859375, train/raw-loss = 0.3971571922302246, train/logprobs = tensor([[-0.5799, -4.5650],
        [-1.3660, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13778451085090637
Epoch 0, Step 2254: train/loss = 0.6030207872390747, train/raw-loss = 0.5229325294494629, train/logprobs = tensor([[-0.6194, -1.2706],
        [-1.3495, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13348044455051422
Epoch 0, Step 2255: train/loss = 0.22953876852989197, train/raw-loss = 0.16600942611694336, train/logprobs = tensor([[ -1.0192, -11.3807],
        [ -1.9355,  -2.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588224232196808
Epoch 0, Step 2256: train/loss = 0.4334496259689331, train/raw-loss = 0.3341231346130371, train/logprobs = tensor([[-0.6768, -5.3504],
        [-1.3435, -1.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16554413735866547
Epoch 0, Step 2257: train/loss = 0.4998641014099121, train/raw-loss = 0.4175184369087219, train/logprobs = tensor([[-1.0537, -2.9324],
        [-1.5244, -0.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13724274933338165
Epoch 0, Step 2258: train/loss = 0.3907027244567871, train/raw-loss = 0.30203816294670105, train/logprobs = tensor([[-0.8698, -6.7602],
        [-1.7088, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14777426421642303
Epoch 0, Step 2259: train/loss = 0.247104674577713, train/raw-loss = 0.16075022518634796, train/logprobs = tensor([[ -0.4190, -10.5090],
        [ -1.5635,  -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14392410218715668
Epoch 0, Step 2260: train/loss = 0.38148176670074463, train/raw-loss = 0.3048677146434784, train/logprobs = tensor([[-0.6415, -5.2255],
        [-1.6319, -1.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12769007682800293
Epoch 0, Step 2261: train/loss = 0.2853597104549408, train/raw-loss = 0.17933964729309082, train/logprobs = tensor([[-0.8309, -6.4971],
        [-2.5191, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17670011520385742
Epoch 0, Step 2262: train/loss = 0.5012435913085938, train/raw-loss = 0.4195858836174011, train/logprobs = tensor([[-0.6790, -1.7845],
        [-1.3504, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13609617948532104
Epoch 0, Step 2263: train/loss = 0.4669874310493469, train/raw-loss = 0.37289905548095703, train/logprobs = tensor([[-0.6229, -2.5191],
        [-1.8591, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15681402385234833
Epoch 0, Step 2264: train/loss = 0.4650011658668518, train/raw-loss = 0.39289748668670654, train/logprobs = tensor([[-0.6736, -5.6658],
        [-1.0594, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12017279863357544
Epoch 0, Step 2265: train/loss = 0.29860109090805054, train/raw-loss = 0.23173321783542633, train/logprobs = tensor([[-0.7712, -4.8499],
        [-2.4357, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11144646257162094
Epoch 0, Step 2266: train/loss = 0.22571133077144623, train/raw-loss = 0.156271830201149, train/logprobs = tensor([[-0.7440, -9.0430],
        [-2.1353, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11573249101638794
Epoch 0, Step 2267: train/loss = 0.5910258889198303, train/raw-loss = 0.5255968570709229, train/logprobs = tensor([[-0.6081, -1.0662],
        [-0.8602, -0.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904836654663086
Epoch 0, Step 2268: train/loss = 0.2917516529560089, train/raw-loss = 0.1876264363527298, train/logprobs = tensor([[-0.8073, -4.4692],
        [-2.7755, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17354197800159454
Epoch 0, Step 2269: train/loss = 0.4766610860824585, train/raw-loss = 0.38871270418167114, train/logprobs = tensor([[-1.1232, -2.7250],
        [-2.1599, -0.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14658063650131226
Epoch 0, Step 2270: train/loss = 0.3777340352535248, train/raw-loss = 0.3091026842594147, train/logprobs = tensor([[-0.4111, -4.7662],
        [-0.8435, -1.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11438561230897903
Epoch 0, Step 2271: train/loss = 0.3410922586917877, train/raw-loss = 0.26389822363853455, train/logprobs = tensor([[-0.8519, -7.0293],
        [-2.0794, -1.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12865674495697021
Epoch 0, Step 2272: train/loss = 0.35795068740844727, train/raw-loss = 0.2849177122116089, train/logprobs = tensor([[-0.8300, -6.2070],
        [-2.6332, -1.7754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172167003154755
Epoch 0, Step 2273: train/loss = 0.4243004620075226, train/raw-loss = 0.3609791696071625, train/logprobs = tensor([[-0.8665, -4.7911],
        [-1.0620, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10553546994924545
Epoch 0, Step 2274: train/loss = 0.25544145703315735, train/raw-loss = 0.17209884524345398, train/logprobs = tensor([[-0.3659, -5.6815],
        [-1.4625, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890434801578522
Epoch 0, Step 2275: train/loss = 0.19067785143852234, train/raw-loss = 0.09831292927265167, train/logprobs = tensor([[-0.6828, -5.5436],
        [-2.6053, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15394152700901031
Epoch 0, Step 2276: train/loss = 0.33513087034225464, train/raw-loss = 0.2521246075630188, train/logprobs = tensor([[-0.6723, -4.8132],
        [-1.9702, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383437216281891
Epoch 0, Step 2277: train/loss = 0.5526838302612305, train/raw-loss = 0.49326300621032715, train/logprobs = tensor([[-0.4560, -1.6580],
        [-0.8232, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09903471916913986
Epoch 0, Step 2278: train/loss = 0.4125576615333557, train/raw-loss = 0.3205527663230896, train/logprobs = tensor([[-1.0515, -3.4501],
        [-1.8953, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15334144234657288
Epoch 0, Step 2279: train/loss = 0.7379282712936401, train/raw-loss = 0.6709186434745789, train/logprobs = tensor([[-2.3332, -7.3213],
        [-1.6392, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11168269068002701
Epoch 0, Step 2280: train/loss = 0.4712260365486145, train/raw-loss = 0.40297797322273254, train/logprobs = tensor([[-0.5162, -2.5417],
        [-1.3373, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137467622756958
Epoch 0, Step 2281: train/loss = 0.2019907534122467, train/raw-loss = 0.11173083633184433, train/logprobs = tensor([[-0.6461, -5.8327],
        [-3.1775, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15043318271636963
Epoch 0, Step 2282: train/loss = 0.46131131052970886, train/raw-loss = 0.3751141428947449, train/logprobs = tensor([[-0.5520, -4.8126],
        [-1.4212, -1.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14366185665130615
Epoch 0, Step 2283: train/loss = 0.3056744337081909, train/raw-loss = 0.22506123781204224, train/logprobs = tensor([[-0.5535, -5.4328],
        [-1.2607, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343553364276886
Epoch 0, Step 2284: train/loss = 0.6136078834533691, train/raw-loss = 0.534014105796814, train/logprobs = tensor([[-1.2870, -5.0016],
        [-1.5814, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326562911272049
Epoch 0, Step 2285: train/loss = 0.3175625801086426, train/raw-loss = 0.23573364317417145, train/logprobs = tensor([[-0.9668, -8.7028],
        [-1.7495, -1.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13638153672218323
Epoch 0, Step 2286: train/loss = 0.2819381058216095, train/raw-loss = 0.19195598363876343, train/logprobs = tensor([[-1.0475, -5.5091],
        [-1.9116, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14997023344039917
Epoch 0, Step 2287: train/loss = 0.6367955207824707, train/raw-loss = 0.5608267188072205, train/logprobs = tensor([[-1.4977, -5.9465],
        [-1.8008, -1.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12661461532115936
Epoch 0, Step 2288: train/loss = 0.30526965856552124, train/raw-loss = 0.22434547543525696, train/logprobs = tensor([[-1.2227, -7.6183],
        [-1.7923, -2.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134873628616333
Epoch 0, Step 2289: train/loss = 0.40704405307769775, train/raw-loss = 0.33332160115242004, train/logprobs = tensor([[-0.6468, -6.8586],
        [-2.1522, -1.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12287071347236633
Epoch 0, Step 2290: train/loss = 0.770538866519928, train/raw-loss = 0.685036838054657, train/logprobs = tensor([[-0.9195, -1.7118],
        [-2.5110, -1.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14250335097312927
Epoch 0, Step 2291: train/loss = 0.1881919503211975, train/raw-loss = 0.06720215082168579, train/logprobs = tensor([[-0.6975, -8.4402],
        [-3.4215, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20164965093135834
Epoch 0, Step 2292: train/loss = 0.5874837636947632, train/raw-loss = 0.5170789957046509, train/logprobs = tensor([[-1.6743, -4.2825],
        [-1.4421, -1.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11734122037887573
Epoch 0, Step 2293: train/loss = 0.3696249723434448, train/raw-loss = 0.2669728994369507, train/logprobs = tensor([[-0.8364, -4.1079],
        [-2.3885, -1.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17108674347400665
Epoch 0, Step 2294: train/loss = 0.38621947169303894, train/raw-loss = 0.2869850993156433, train/logprobs = tensor([[-0.6416, -6.8326],
        [-1.9931, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16539058089256287
Epoch 0, Step 2295: train/loss = 0.36809760332107544, train/raw-loss = 0.28745466470718384, train/logprobs = tensor([[-0.9319, -3.7111],
        [-1.9454, -1.3365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13440489768981934
Epoch 0, Step 2296: train/loss = 0.5293969511985779, train/raw-loss = 0.4554581344127655, train/logprobs = tensor([[-0.7358, -1.5428],
        [-1.7183, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12323138862848282
Epoch 0, Step 2297: train/loss = 0.38817018270492554, train/raw-loss = 0.3084069490432739, train/logprobs = tensor([[-0.7084, -3.2332],
        [-1.6627, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13293875753879547
Epoch 0, Step 2298: train/loss = 0.14784392714500427, train/raw-loss = 0.06283210217952728, train/logprobs = tensor([[ -0.6081, -13.2509],
        [ -3.0820,  -2.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141686350107193
Epoch 0, Step 2299: train/loss = 0.5485218167304993, train/raw-loss = 0.4622207581996918, train/logprobs = tensor([[-0.5992, -2.2729],
        [-1.1722, -0.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1438351273536682
Epoch 0, Step 2300: train/loss = 0.23024806380271912, train/raw-loss = 0.1574651449918747, train/logprobs = tensor([[-1.0108, -4.2337],
        [-2.4995, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12130483984947205
Epoch 0, Step 2301: train/loss = 0.2696757912635803, train/raw-loss = 0.16974686086177826, train/logprobs = tensor([[-0.5420, -6.9788],
        [-2.6878, -1.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16654817759990692
Epoch 0, Step 2302: train/loss = 0.40912508964538574, train/raw-loss = 0.3477524518966675, train/logprobs = tensor([[-0.3653, -6.9884],
        [-1.9122, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10228767991065979
Epoch 0, Step 2303: train/loss = 0.24488599598407745, train/raw-loss = 0.15756556391716003, train/logprobs = tensor([[-1.0687, -5.4596],
        [-2.8539, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14553405344486237
Epoch 0, Step 2304: train/loss = 0.37422287464141846, train/raw-loss = 0.28481465578079224, train/logprobs = tensor([[-0.7602, -7.2182],
        [-1.5595, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490136981010437
Epoch 0, Step 2305: train/loss = 0.5537600517272949, train/raw-loss = 0.46575576066970825, train/logprobs = tensor([[-1.4091, -7.5546],
        [-1.8562, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14667382836341858
Epoch 0, Step 2306: train/loss = 0.45453017950057983, train/raw-loss = 0.3870964050292969, train/logprobs = tensor([[-1.0627, -3.9224],
        [-1.4198, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11238962411880493
Epoch 0, Step 2307: train/loss = 0.5802405476570129, train/raw-loss = 0.4896130859851837, train/logprobs = tensor([[-0.5705, -4.7672],
        [-3.0769, -2.3773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1510457992553711
Epoch 0, Step 2308: train/loss = 0.4947972297668457, train/raw-loss = 0.42465370893478394, train/logprobs = tensor([[-0.4462, -3.3963],
        [-0.8781, -1.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11690585315227509
Epoch 0, Step 2309: train/loss = 0.4646189212799072, train/raw-loss = 0.4041977524757385, train/logprobs = tensor([[-1.6018, -8.1416],
        [-1.3489, -1.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1007019653916359
Epoch 0, Step 2310: train/loss = 0.601405143737793, train/raw-loss = 0.5091753602027893, train/logprobs = tensor([[-0.8292, -1.8770],
        [-2.2818, -1.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15371626615524292
Epoch 0, Step 2311: train/loss = 0.5943548679351807, train/raw-loss = 0.5320373177528381, train/logprobs = tensor([[-0.5416, -2.0860],
        [-0.6917, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10386261343955994
Epoch 0, Step 2312: train/loss = 0.3463682234287262, train/raw-loss = 0.2551674246788025, train/logprobs = tensor([[-0.6048, -3.6332],
        [-1.8320, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152001291513443
Epoch 0, Step 2313: train/loss = 0.30295172333717346, train/raw-loss = 0.2167648822069168, train/logprobs = tensor([[-0.7406, -5.0758],
        [-1.9424, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14364475011825562
Epoch 0, Step 2314: train/loss = 0.24019066989421844, train/raw-loss = 0.1575598269701004, train/logprobs = tensor([[-0.8505, -9.5276],
        [-1.7617, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377180814743042
Epoch 0, Step 2315: train/loss = 0.28947293758392334, train/raw-loss = 0.18936240673065186, train/logprobs = tensor([[-0.8608, -5.3846],
        [-2.1669, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16685083508491516
Epoch 0, Step 2316: train/loss = 0.4008287787437439, train/raw-loss = 0.3279363512992859, train/logprobs = tensor([[-0.6112, -4.1488],
        [-1.4709, -0.7500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12148737907409668
Epoch 0, Step 2317: train/loss = 0.3030494749546051, train/raw-loss = 0.22641998529434204, train/logprobs = tensor([[-0.9730, -4.8870],
        [-1.7262, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1277158260345459
Epoch 0, Step 2318: train/loss = 0.4983009397983551, train/raw-loss = 0.4319070875644684, train/logprobs = tensor([[-0.5742, -3.6959],
        [-0.9983, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11065641790628433
Epoch 0, Step 2319: train/loss = 0.27034538984298706, train/raw-loss = 0.1803724467754364, train/logprobs = tensor([[-1.0873, -7.1203],
        [-2.1892, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1499548703432083
Epoch 0, Step 2320: train/loss = 0.4404844343662262, train/raw-loss = 0.3473242521286011, train/logprobs = tensor([[-0.7602, -3.7835],
        [-1.5258, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15526698529720306
Epoch 0, Step 2321: train/loss = 0.5471709966659546, train/raw-loss = 0.4551626443862915, train/logprobs = tensor([[-0.5181, -2.8228],
        [-1.2106, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15334731340408325
Epoch 0, Step 2322: train/loss = 0.552260160446167, train/raw-loss = 0.46778473258018494, train/logprobs = tensor([[-2.5544, -5.3065],
        [-2.4149, -1.5287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14079242944717407
Epoch 0, Step 2323: train/loss = 0.5995824337005615, train/raw-loss = 0.5277937650680542, train/logprobs = tensor([[-0.7282, -1.3208],
        [-1.0785, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196478009223938
Epoch 0, Step 2324: train/loss = 0.3694436848163605, train/raw-loss = 0.2935076057910919, train/logprobs = tensor([[-0.5790, -5.9716],
        [-1.3700, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12656015157699585
Epoch 0, Step 2325: train/loss = 0.5482473969459534, train/raw-loss = 0.4833908677101135, train/logprobs = tensor([[-0.3930, -2.0477],
        [-0.6956, -0.6311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10809420794248581
Epoch 0, Step 2326: train/loss = 0.2115449607372284, train/raw-loss = 0.10695212334394455, train/logprobs = tensor([[-0.9870, -8.0674],
        [-3.4043, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17432138323783875
Epoch 0, Step 2327: train/loss = 0.4923038184642792, train/raw-loss = 0.4224609434604645, train/logprobs = tensor([[-0.9793, -5.0474],
        [-1.5575, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11640479415655136
Epoch 0, Step 2328: train/loss = 0.4705969989299774, train/raw-loss = 0.3544183373451233, train/logprobs = tensor([[-0.6114, -4.8562],
        [-1.8522, -1.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.193631112575531
Epoch 0, Step 2329: train/loss = 0.4924420118331909, train/raw-loss = 0.4236883223056793, train/logprobs = tensor([[-0.4580, -3.9208],
        [-0.8390, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458946764469147
Epoch 0, Step 2330: train/loss = 0.3543201982975006, train/raw-loss = 0.26705366373062134, train/logprobs = tensor([[-0.4913, -4.0635],
        [-1.5037, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14544422924518585
Epoch 0, Step 2331: train/loss = 0.6016765832901001, train/raw-loss = 0.5310698747634888, train/logprobs = tensor([[-0.9724, -2.5836],
        [-0.8458, -0.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767782270908356
Epoch 0, Step 2332: train/loss = 0.3729090988636017, train/raw-loss = 0.29558050632476807, train/logprobs = tensor([[-0.7965, -5.1205],
        [-1.6006, -1.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12888099253177643
Epoch 0, Step 2333: train/loss = 0.44352987408638, train/raw-loss = 0.344798743724823, train/logprobs = tensor([[-0.6229, -3.7045],
        [-2.2030, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16455188393592834
Epoch 0, Step 2334: train/loss = 0.429448664188385, train/raw-loss = 0.3435119390487671, train/logprobs = tensor([[-0.9840, -6.4973],
        [-1.3452, -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14322787523269653
Epoch 0, Step 2335: train/loss = 0.13528865575790405, train/raw-loss = 0.044493623077869415, train/logprobs = tensor([[ -0.7914, -10.4689],
        [ -3.5331,  -2.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513250470161438
Epoch 0, Step 2336: train/loss = 0.35138431191444397, train/raw-loss = 0.2679230868816376, train/logprobs = tensor([[-0.5841, -6.1797],
        [-1.9397, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.139102041721344
Epoch 0, Step 2337: train/loss = 0.20508724451065063, train/raw-loss = 0.1095692440867424, train/logprobs = tensor([[-1.3350, -8.7917],
        [-2.9896, -1.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591966450214386
Epoch 0, Step 2338: train/loss = 0.41301625967025757, train/raw-loss = 0.3106352984905243, train/logprobs = tensor([[-1.0911, -2.8679],
        [-2.4827, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17063495516777039
Epoch 0, Step 2339: train/loss = 0.5013722777366638, train/raw-loss = 0.42533427476882935, train/logprobs = tensor([[-1.3462, -3.5593],
        [-1.7565, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12672999501228333
Epoch 0, Step 2340: train/loss = 0.4472056031227112, train/raw-loss = 0.3602389097213745, train/logprobs = tensor([[-0.8134, -2.3123],
        [-1.8897, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494439959526062
Epoch 0, Step 2341: train/loss = 0.6690589785575867, train/raw-loss = 0.5955411791801453, train/logprobs = tensor([[-1.6870, -3.9231],
        [-1.3935, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12252959609031677
Epoch 0, Step 2342: train/loss = 0.5125880837440491, train/raw-loss = 0.431791216135025, train/logprobs = tensor([[-0.6271, -1.6935],
        [-1.3723, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1346614509820938
Epoch 0, Step 2343: train/loss = 0.281075656414032, train/raw-loss = 0.17904488742351532, train/logprobs = tensor([[-0.5234, -5.8033],
        [-2.1289, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17005132138729095
Epoch 0, Step 2344: train/loss = 0.29738208651542664, train/raw-loss = 0.22584164142608643, train/logprobs = tensor([[-0.6682, -6.1043],
        [-1.5785, -1.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11923405528068542
Epoch 0, Step 2345: train/loss = 0.30099979043006897, train/raw-loss = 0.2155628353357315, train/logprobs = tensor([[-0.5503, -7.6119],
        [-2.1593, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14239493012428284
Epoch 0, Step 2346: train/loss = 0.35356172919273376, train/raw-loss = 0.27964773774147034, train/logprobs = tensor([[-0.5916, -4.3984],
        [-1.2258, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1231900006532669
Epoch 0, Step 2347: train/loss = 0.3961296081542969, train/raw-loss = 0.2972715497016907, train/logprobs = tensor([[-0.7542, -5.0461],
        [-2.7257, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16476339101791382
Epoch 0, Step 2348: train/loss = 0.22497904300689697, train/raw-loss = 0.1292046308517456, train/logprobs = tensor([[-1.0115, -6.3324],
        [-2.7844, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15962402522563934
Epoch 0, Step 2349: train/loss = 0.930749237537384, train/raw-loss = 0.8456240892410278, train/logprobs = tensor([[-2.3278, -3.6267],
        [-1.1844, -1.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14187517762184143
Epoch 0, Step 2350: train/loss = 0.4871959090232849, train/raw-loss = 0.4206979274749756, train/logprobs = tensor([[-0.6966, -3.2708],
        [-0.8069, -0.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11082996428012848
Epoch 0, Step 2351: train/loss = 0.4854447841644287, train/raw-loss = 0.42325714230537415, train/logprobs = tensor([[-0.4573, -2.0278],
        [-1.0585, -0.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10364608466625214
Epoch 0, Step 2352: train/loss = 0.2824082374572754, train/raw-loss = 0.2085948884487152, train/logprobs = tensor([[-0.6439, -6.1766],
        [-1.8431, -1.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12302222847938538
Epoch 0, Step 2353: train/loss = 0.4731493890285492, train/raw-loss = 0.40359145402908325, train/logprobs = tensor([[-0.5922, -3.6631],
        [-1.0897, -0.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11592986434698105
Epoch 0, Step 2354: train/loss = 0.3983750641345978, train/raw-loss = 0.3095191419124603, train/logprobs = tensor([[-1.8511, -4.8674],
        [-2.2841, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14809320867061615
Epoch 0, Step 2355: train/loss = 0.3079814612865448, train/raw-loss = 0.2268204689025879, train/logprobs = tensor([[-0.6650, -7.5240],
        [-2.3328, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13526831567287445
Epoch 0, Step 2356: train/loss = 0.35009726881980896, train/raw-loss = 0.2570546269416809, train/logprobs = tensor([[-0.9293, -6.3725],
        [-1.4518, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15507100522518158
Epoch 0, Step 2357: train/loss = 0.3763197660446167, train/raw-loss = 0.2671201229095459, train/logprobs = tensor([[-0.9972, -3.6704],
        [-1.9089, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18199940025806427
Epoch 0, Step 2358: train/loss = 0.3402552902698517, train/raw-loss = 0.2693335711956024, train/logprobs = tensor([[-0.8172, -3.5873],
        [-2.4382, -0.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11820287257432938
Epoch 0, Step 2359: train/loss = 0.25409120321273804, train/raw-loss = 0.15772227942943573, train/logprobs = tensor([[-0.9408, -7.4983],
        [-2.7714, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16061483323574066
Epoch 0, Step 2360: train/loss = 0.4167112112045288, train/raw-loss = 0.337399423122406, train/logprobs = tensor([[-0.7061, -4.1637],
        [-1.3457, -1.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13218633830547333
Epoch 0, Step 2361: train/loss = 0.36871033906936646, train/raw-loss = 0.26876914501190186, train/logprobs = tensor([[-0.9363, -5.0689],
        [-1.7239, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16656865179538727
Epoch 0, Step 2362: train/loss = 0.3453943729400635, train/raw-loss = 0.24498508870601654, train/logprobs = tensor([[-0.5858, -3.0101],
        [-1.4975, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16734877228736877
Epoch 0, Step 2363: train/loss = 0.38509973883628845, train/raw-loss = 0.301260381937027, train/logprobs = tensor([[-0.7230, -3.5654],
        [-1.6823, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397322565317154
Epoch 0, Step 2364: train/loss = 0.5368441343307495, train/raw-loss = 0.44740843772888184, train/logprobs = tensor([[-1.5133, -3.4396],
        [-2.3051, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490594744682312
Epoch 0, Step 2365: train/loss = 0.3453628718852997, train/raw-loss = 0.2808338701725006, train/logprobs = tensor([[-0.5840, -4.4750],
        [-1.1330, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10754837840795517
Epoch 0, Step 2366: train/loss = 0.4923971891403198, train/raw-loss = 0.41711074113845825, train/logprobs = tensor([[-0.8250, -3.0222],
        [-0.7252, -0.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254773885011673
Epoch 0, Step 2367: train/loss = 0.5053062438964844, train/raw-loss = 0.4348672032356262, train/logprobs = tensor([[-0.5644, -2.5951],
        [-1.1602, -0.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11739835143089294
Epoch 0, Step 2368: train/loss = 0.3761403262615204, train/raw-loss = 0.3014734983444214, train/logprobs = tensor([[-1.1802, -5.3239],
        [-1.5987, -0.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12444470822811127
Epoch 0, Step 2369: train/loss = 0.5092068314552307, train/raw-loss = 0.4274348318576813, train/logprobs = tensor([[-0.7317, -3.3199],
        [-1.6788, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362866461277008
Epoch 0, Step 2370: train/loss = 0.19846265017986298, train/raw-loss = 0.10887840390205383, train/logprobs = tensor([[-0.8732, -6.3550],
        [-2.5678, -1.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14930708706378937
Epoch 0, Step 2371: train/loss = 0.3458896577358246, train/raw-loss = 0.2403126209974289, train/logprobs = tensor([[-0.9201, -3.6675],
        [-2.0953, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17596173286437988
Epoch 0, Step 2372: train/loss = 0.33797740936279297, train/raw-loss = 0.23592932522296906, train/logprobs = tensor([[-0.5518, -6.6919],
        [-2.0173, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17008017003536224
Epoch 0, Step 2373: train/loss = 0.29804980754852295, train/raw-loss = 0.20167212188243866, train/logprobs = tensor([[-0.5467, -3.6842],
        [-2.0930, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1606294810771942
Epoch 0, Step 2374: train/loss = 0.3895760774612427, train/raw-loss = 0.29548579454421997, train/logprobs = tensor([[-0.4787, -4.6655],
        [-1.0364, -1.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15681710839271545
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-13 04:14:31,726][root][INFO] - beta: 0.7
[2024-03-13 04:14:31,726][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.7-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.660662055015564, train/raw-loss = 0.6485649943351746, train/logprobs = tensor([[-0.5590, -0.9094],
        [-0.4943, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01728154346346855
Epoch 0, Step 65: train/loss = 0.5959696173667908, train/raw-loss = 0.5862711668014526, train/logprobs = tensor([[-0.4080, -2.3891],
        [-0.4056, -1.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013854905031621456
Epoch 0, Step 66: train/loss = 0.6392734050750732, train/raw-loss = 0.6271097660064697, train/logprobs = tensor([[-0.6675, -1.2251],
        [-0.6748, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017376640811562538
Epoch 0, Step 67: train/loss = 0.6175524592399597, train/raw-loss = 0.6073800325393677, train/logprobs = tensor([[-0.4555, -1.6555],
        [-0.4389, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014532054774463177
Epoch 0, Step 68: train/loss = 0.630717396736145, train/raw-loss = 0.6199642419815063, train/logprobs = tensor([[-0.5328, -0.8168],
        [-0.6260, -0.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015361612662672997
Epoch 0, Step 69: train/loss = 0.6474031805992126, train/raw-loss = 0.6364604234695435, train/logprobs = tensor([[-0.6256, -0.8801],
        [-0.6391, -0.6524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015632539987564087
Epoch 0, Step 70: train/loss = 0.6130086183547974, train/raw-loss = 0.6031032204627991, train/logprobs = tensor([[-0.5836, -1.5771],
        [-0.5859, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01415058970451355
Epoch 0, Step 71: train/loss = 0.6230449676513672, train/raw-loss = 0.6127356290817261, train/logprobs = tensor([[-0.5085, -1.2084],
        [-0.5325, -0.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014727538451552391
Epoch 0, Step 72: train/loss = 0.6474769711494446, train/raw-loss = 0.6366500854492188, train/logprobs = tensor([[-0.5490, -1.3723],
        [-0.5528, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015466945245862007
Epoch 0, Step 73: train/loss = 0.6863272786140442, train/raw-loss = 0.6744270324707031, train/logprobs = tensor([[-0.5530, -1.0905],
        [-0.5407, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01700035110116005
Epoch 0, Step 74: train/loss = 0.6595638990402222, train/raw-loss = 0.6468896865844727, train/logprobs = tensor([[-0.6138, -0.9857],
        [-0.5823, -0.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018105922266840935
Epoch 0, Step 75: train/loss = 0.6141550540924072, train/raw-loss = 0.6054843664169312, train/logprobs = tensor([[-0.4130, -1.3276],
        [-0.4376, -0.9535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012386662885546684
Epoch 0, Step 76: train/loss = 0.5528116226196289, train/raw-loss = 0.5433980226516724, train/logprobs = tensor([[-0.4633, -2.4591],
        [-0.4992, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013447985984385014
Epoch 0, Step 77: train/loss = 0.615273118019104, train/raw-loss = 0.6040815711021423, train/logprobs = tensor([[-0.6559, -1.0133],
        [-0.6920, -0.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015987910330295563
Epoch 0, Step 78: train/loss = 0.6610032320022583, train/raw-loss = 0.6492714881896973, train/logprobs = tensor([[-0.6890, -0.9534],
        [-0.6853, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01675967127084732
Epoch 0, Step 79: train/loss = 0.5876963138580322, train/raw-loss = 0.5772709250450134, train/logprobs = tensor([[-0.5675, -2.3866],
        [-0.5719, -1.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014893466606736183
Epoch 0, Step 80: train/loss = 0.6371070742607117, train/raw-loss = 0.6246477961540222, train/logprobs = tensor([[-0.7425, -1.0098],
        [-0.7358, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017799001187086105
Epoch 0, Step 81: train/loss = 0.5771431922912598, train/raw-loss = 0.5694520473480225, train/logprobs = tensor([[-0.5275, -2.5234],
        [-0.5220, -1.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010987277142703533
Epoch 0, Step 82: train/loss = 0.6593607068061829, train/raw-loss = 0.6462581157684326, train/logprobs = tensor([[-0.6913, -1.1154],
        [-0.6233, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018717961385846138
Epoch 0, Step 83: train/loss = 0.6949923038482666, train/raw-loss = 0.6808912754058838, train/logprobs = tensor([[-1.5402, -1.6603],
        [-1.4979, -1.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02014431171119213
Epoch 0, Step 84: train/loss = 0.652525782585144, train/raw-loss = 0.6392869353294373, train/logprobs = tensor([[-0.6074, -0.9764],
        [-0.5904, -0.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018912676721811295
Epoch 0, Step 85: train/loss = 0.5711866617202759, train/raw-loss = 0.5599560737609863, train/logprobs = tensor([[-0.5907, -2.0172],
        [-0.5795, -1.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016043663024902344
Epoch 0, Step 86: train/loss = 0.6379956603050232, train/raw-loss = 0.6260244846343994, train/logprobs = tensor([[-0.5682, -0.9169],
        [-0.5956, -0.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017101643607020378
Epoch 0, Step 87: train/loss = 0.6150396466255188, train/raw-loss = 0.6038383841514587, train/logprobs = tensor([[-0.6363, -1.0336],
        [-0.7088, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016001874580979347
Epoch 0, Step 88: train/loss = 0.6244572401046753, train/raw-loss = 0.6113225221633911, train/logprobs = tensor([[-1.0051, -2.1818],
        [-0.9313, -1.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018763884902000427
Epoch 0, Step 89: train/loss = 0.647396981716156, train/raw-loss = 0.6349189281463623, train/logprobs = tensor([[-0.5684, -0.9964],
        [-0.5569, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017825735732913017
Epoch 0, Step 90: train/loss = 0.6388510465621948, train/raw-loss = 0.6272130608558655, train/logprobs = tensor([[-0.4668, -1.0588],
        [-0.4735, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01662570796906948
Epoch 0, Step 91: train/loss = 0.45412901043891907, train/raw-loss = 0.4450574517250061, train/logprobs = tensor([[-0.4688, -2.7841],
        [-0.5095, -1.4942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012959402985870838
Epoch 0, Step 92: train/loss = 0.6642585396766663, train/raw-loss = 0.6501173973083496, train/logprobs = tensor([[-0.6964, -1.0882],
        [-0.6960, -0.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020201530307531357
Epoch 0, Step 93: train/loss = 0.6017901301383972, train/raw-loss = 0.5905707478523254, train/logprobs = tensor([[-0.5683, -1.4569],
        [-0.5581, -0.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016027668491005898
Epoch 0, Step 94: train/loss = 0.6006304621696472, train/raw-loss = 0.5886592268943787, train/logprobs = tensor([[-0.6784, -1.8405],
        [-0.7721, -1.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017101731151342392
Epoch 0, Step 95: train/loss = 0.6354641318321228, train/raw-loss = 0.6258377432823181, train/logprobs = tensor([[-0.5271, -1.0194],
        [-0.5223, -0.7104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013751968741416931
Epoch 0, Step 96: train/loss = 0.7122294902801514, train/raw-loss = 0.682767927646637, train/logprobs = tensor([[-0.5938, -0.8857],
        [-0.5780, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04208798706531525
Epoch 0, Step 97: train/loss = 0.5852702856063843, train/raw-loss = 0.5598928928375244, train/logprobs = tensor([[-0.6294, -1.9358],
        [-0.6154, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036253370344638824
Epoch 0, Step 98: train/loss = 0.6345635652542114, train/raw-loss = 0.6144547462463379, train/logprobs = tensor([[-0.3816, -0.9647],
        [-0.3313, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028726795688271523
Epoch 0, Step 99: train/loss = 0.6458537578582764, train/raw-loss = 0.6244614124298096, train/logprobs = tensor([[-0.5267, -1.0370],
        [-0.5068, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030560506507754326
Epoch 0, Step 100: train/loss = 0.5618500709533691, train/raw-loss = 0.5404672026634216, train/logprobs = tensor([[-0.6784, -2.7352],
        [-0.6640, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03054693341255188
Epoch 0, Step 101: train/loss = 0.6223392486572266, train/raw-loss = 0.5875776410102844, train/logprobs = tensor([[-0.9535, -1.8224],
        [-0.9240, -1.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0496593676507473
Epoch 0, Step 102: train/loss = 0.6042048931121826, train/raw-loss = 0.58014315366745, train/logprobs = tensor([[-0.4930, -1.3377],
        [-0.4912, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03437390923500061
Epoch 0, Step 103: train/loss = 0.5741031765937805, train/raw-loss = 0.5532011985778809, train/logprobs = tensor([[-0.6309, -1.6994],
        [-0.5505, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029859978705644608
Epoch 0, Step 104: train/loss = 0.471143513917923, train/raw-loss = 0.44366341829299927, train/logprobs = tensor([[-0.7837, -4.4618],
        [-0.6620, -2.4325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925728425383568
Epoch 0, Step 105: train/loss = 0.62282794713974, train/raw-loss = 0.5980929136276245, train/logprobs = tensor([[-0.6729, -1.1766],
        [-0.6263, -0.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03533580154180527
Epoch 0, Step 106: train/loss = 0.475385844707489, train/raw-loss = 0.45349791646003723, train/logprobs = tensor([[-0.6769, -4.3482],
        [-0.6233, -2.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03126845508813858
Epoch 0, Step 107: train/loss = 0.6268430352210999, train/raw-loss = 0.596611499786377, train/logprobs = tensor([[-0.7134, -1.5220],
        [-0.6771, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043187957257032394
Epoch 0, Step 108: train/loss = 0.6786435842514038, train/raw-loss = 0.6622955799102783, train/logprobs = tensor([[-0.5278, -0.6552],
        [-0.4646, -0.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023354196920990944
Epoch 0, Step 109: train/loss = 0.6238024830818176, train/raw-loss = 0.6013956069946289, train/logprobs = tensor([[-0.6332, -1.2676],
        [-0.5531, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03200983256101608
Epoch 0, Step 110: train/loss = 0.5607451796531677, train/raw-loss = 0.5385982990264893, train/logprobs = tensor([[-0.6555, -2.9197],
        [-0.5495, -1.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03163842856884003
Epoch 0, Step 111: train/loss = 0.5946319103240967, train/raw-loss = 0.5761046409606934, train/logprobs = tensor([[-0.4320, -1.4901],
        [-0.4120, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026467520743608475
Epoch 0, Step 112: train/loss = 0.6179141402244568, train/raw-loss = 0.5952462553977966, train/logprobs = tensor([[-0.6270, -1.0965],
        [-0.5983, -0.6071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03238266333937645
Epoch 0, Step 113: train/loss = 0.655585765838623, train/raw-loss = 0.624112069606781, train/logprobs = tensor([[-0.6448, -1.2657],
        [-0.5753, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04496247321367264
Epoch 0, Step 114: train/loss = 0.622461199760437, train/raw-loss = 0.5972282886505127, train/logprobs = tensor([[-0.5629, -1.0578],
        [-0.5381, -0.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03604695573449135
Epoch 0, Step 115: train/loss = 0.6357304453849792, train/raw-loss = 0.6142829060554504, train/logprobs = tensor([[-0.5609, -1.1498],
        [-0.5258, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03063933551311493
Epoch 0, Step 116: train/loss = 0.5886526107788086, train/raw-loss = 0.5618224740028381, train/logprobs = tensor([[-0.6650, -2.0315],
        [-0.6096, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03832869231700897
Epoch 0, Step 117: train/loss = 0.6392281651496887, train/raw-loss = 0.6153443455696106, train/logprobs = tensor([[-0.4838, -1.7519],
        [-0.4618, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034119803458452225
Epoch 0, Step 118: train/loss = 0.5133598446846008, train/raw-loss = 0.4931480884552002, train/logprobs = tensor([[-0.6556, -3.1626],
        [-0.5762, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028873903676867485
Epoch 0, Step 119: train/loss = 0.5954725742340088, train/raw-loss = 0.5665028095245361, train/logprobs = tensor([[-0.6115, -1.6640],
        [-0.5682, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041385285556316376
Epoch 0, Step 120: train/loss = 0.5447253584861755, train/raw-loss = 0.5173785090446472, train/logprobs = tensor([[-0.7786, -2.6021],
        [-0.7661, -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03906692564487457
Epoch 0, Step 121: train/loss = 0.6257402300834656, train/raw-loss = 0.6031738519668579, train/logprobs = tensor([[-0.4974, -1.2243],
        [-0.4451, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03223760426044464
Epoch 0, Step 122: train/loss = 0.5600845217704773, train/raw-loss = 0.5346739888191223, train/logprobs = tensor([[-0.8362, -1.9252],
        [-0.7519, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036300793290138245
Epoch 0, Step 123: train/loss = 0.6872216463088989, train/raw-loss = 0.6635873913764954, train/logprobs = tensor([[-0.5308, -0.7899],
        [-0.5067, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03376314416527748
Epoch 0, Step 124: train/loss = 0.6042201519012451, train/raw-loss = 0.5770993232727051, train/logprobs = tensor([[-0.7835, -1.5984],
        [-0.7070, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03874412178993225
Epoch 0, Step 125: train/loss = 0.5582921504974365, train/raw-loss = 0.5322854518890381, train/logprobs = tensor([[-0.6951, -3.1470],
        [-0.6274, -2.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03715231642127037
Epoch 0, Step 126: train/loss = 0.6542172431945801, train/raw-loss = 0.6253873109817505, train/logprobs = tensor([[-0.6688, -1.1869],
        [-0.5699, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041185613721609116
Epoch 0, Step 127: train/loss = 0.6387121677398682, train/raw-loss = 0.6118054389953613, train/logprobs = tensor([[-0.5052, -1.4735],
        [-0.4438, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03843817859888077
Epoch 0, Step 128: train/loss = 0.7239218950271606, train/raw-loss = 0.649990439414978, train/logprobs = tensor([[-0.8102, -1.0185],
        [-0.7750, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10561633110046387
Epoch 0, Step 129: train/loss = 0.6136439442634583, train/raw-loss = 0.5168779492378235, train/logprobs = tensor([[-0.7297, -2.7681],
        [-0.6269, -1.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13823719322681427
Epoch 0, Step 130: train/loss = 0.7115097045898438, train/raw-loss = 0.6230853796005249, train/logprobs = tensor([[-0.5311, -1.1437],
        [-0.4669, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12632043659687042
Epoch 0, Step 131: train/loss = 0.6007475256919861, train/raw-loss = 0.5033634901046753, train/logprobs = tensor([[-0.7569, -4.0009],
        [-0.6726, -2.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13911999762058258
Epoch 0, Step 132: train/loss = 0.6156786680221558, train/raw-loss = 0.5254437923431396, train/logprobs = tensor([[-0.7764, -2.3181],
        [-0.6364, -1.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289070099592209
Epoch 0, Step 133: train/loss = 0.6331659555435181, train/raw-loss = 0.5405720472335815, train/logprobs = tensor([[-0.6404, -2.3702],
        [-0.5588, -1.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13227710127830505
Epoch 0, Step 134: train/loss = 0.6417355537414551, train/raw-loss = 0.5567434430122375, train/logprobs = tensor([[-0.7379, -1.6341],
        [-0.6198, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12141728401184082
Epoch 0, Step 135: train/loss = 0.6865006685256958, train/raw-loss = 0.5925583839416504, train/logprobs = tensor([[-0.5126, -1.4660],
        [-0.3930, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134203240275383
Epoch 0, Step 136: train/loss = 0.6145955324172974, train/raw-loss = 0.5262434482574463, train/logprobs = tensor([[-0.4376, -2.0699],
        [-0.3928, -1.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12621726095676422
Epoch 0, Step 137: train/loss = 0.6823505759239197, train/raw-loss = 0.5973025560379028, train/logprobs = tensor([[-0.4334, -1.3068],
        [-0.4008, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12149709463119507
Epoch 0, Step 138: train/loss = 0.6412442326545715, train/raw-loss = 0.5426177382469177, train/logprobs = tensor([[-0.4342, -1.6612],
        [-0.3638, -0.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14089497923851013
Epoch 0, Step 139: train/loss = 0.6122274398803711, train/raw-loss = 0.5200128555297852, train/logprobs = tensor([[-0.6044, -2.3427],
        [-0.4934, -1.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13173502683639526
Epoch 0, Step 140: train/loss = 0.6647148132324219, train/raw-loss = 0.5791121125221252, train/logprobs = tensor([[-0.7684, -1.7315],
        [-0.6555, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12228955328464508
Epoch 0, Step 141: train/loss = 0.6709172129631042, train/raw-loss = 0.579255223274231, train/logprobs = tensor([[-0.9071, -1.8894],
        [-0.6742, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13094563782215118
Epoch 0, Step 142: train/loss = 0.6930545568466187, train/raw-loss = 0.6104984879493713, train/logprobs = tensor([[-0.5552, -1.2075],
        [-0.4747, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793726682662964
Epoch 0, Step 143: train/loss = 0.7125020027160645, train/raw-loss = 0.6311458349227905, train/logprobs = tensor([[-0.7316, -1.5303],
        [-0.5840, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11622312664985657
Epoch 0, Step 144: train/loss = 0.5477453470230103, train/raw-loss = 0.46621525287628174, train/logprobs = tensor([[-0.5742, -3.8822],
        [-0.4975, -2.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11647151410579681
Epoch 0, Step 145: train/loss = 0.6859902143478394, train/raw-loss = 0.6095720529556274, train/logprobs = tensor([[-0.6319, -1.5181],
        [-0.5542, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916875302791595
Epoch 0, Step 146: train/loss = 0.629714846611023, train/raw-loss = 0.5449490547180176, train/logprobs = tensor([[-0.6364, -2.7011],
        [-0.5097, -1.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12109395861625671
Epoch 0, Step 147: train/loss = 0.692141592502594, train/raw-loss = 0.6087123155593872, train/logprobs = tensor([[-0.6131, -1.1680],
        [-0.5116, -0.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191847175359726
Epoch 0, Step 148: train/loss = 0.7611458897590637, train/raw-loss = 0.6694159507751465, train/logprobs = tensor([[-1.4761, -1.8226],
        [-1.1149, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13104280829429626
Epoch 0, Step 149: train/loss = 0.6990379691123962, train/raw-loss = 0.6263996362686157, train/logprobs = tensor([[-0.6245, -1.2522],
        [-0.5152, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10376904904842377
Epoch 0, Step 150: train/loss = 0.6129328012466431, train/raw-loss = 0.5310661792755127, train/logprobs = tensor([[-0.8093, -3.4989],
        [-0.7188, -1.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11695221066474915
Epoch 0, Step 151: train/loss = 0.668321967124939, train/raw-loss = 0.5811957120895386, train/logprobs = tensor([[-0.6633, -1.8217],
        [-0.5236, -1.1184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12446621060371399
Epoch 0, Step 152: train/loss = 0.6919779777526855, train/raw-loss = 0.5987856388092041, train/logprobs = tensor([[-0.8202, -1.3753],
        [-0.7545, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13313189148902893
Epoch 0, Step 153: train/loss = 0.6692482829093933, train/raw-loss = 0.5701134204864502, train/logprobs = tensor([[-0.6065, -1.9800],
        [-0.5012, -1.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14162129163742065
Epoch 0, Step 154: train/loss = 0.7122704982757568, train/raw-loss = 0.6344818472862244, train/logprobs = tensor([[-0.7330, -1.5975],
        [-0.6393, -1.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11112667620182037
Epoch 0, Step 155: train/loss = 0.6278175115585327, train/raw-loss = 0.5542644262313843, train/logprobs = tensor([[-0.5878, -2.8415],
        [-0.5015, -1.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10507584363222122
Epoch 0, Step 156: train/loss = 0.7173321843147278, train/raw-loss = 0.650370717048645, train/logprobs = tensor([[-0.6283, -0.7497],
        [-0.5680, -0.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09565926343202591
Epoch 0, Step 157: train/loss = 0.7464925646781921, train/raw-loss = 0.6855754256248474, train/logprobs = tensor([[-0.7281, -0.7880],
        [-0.6389, -0.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08702453225851059
Epoch 0, Step 158: train/loss = 0.7226159572601318, train/raw-loss = 0.6428753137588501, train/logprobs = tensor([[-0.6817, -1.1894],
        [-0.4794, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391519010066986
Epoch 0, Step 159: train/loss = 0.7396321892738342, train/raw-loss = 0.6646947860717773, train/logprobs = tensor([[-0.8457, -1.0384],
        [-0.7097, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10705344378948212
Epoch 0, Step 160: train/loss = 0.5937694311141968, train/raw-loss = 0.5219866037368774, train/logprobs = tensor([[-1.0695, -2.2538],
        [-0.8435, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10254687815904617
Epoch 0, Step 161: train/loss = 0.668086051940918, train/raw-loss = 0.6192963123321533, train/logprobs = tensor([[-0.6586, -1.2735],
        [-0.5552, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0696997344493866
Epoch 0, Step 162: train/loss = 0.613366961479187, train/raw-loss = 0.5573421120643616, train/logprobs = tensor([[-0.5738, -2.9996],
        [-0.5035, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800355076789856
Epoch 0, Step 163: train/loss = 0.6118392944335938, train/raw-loss = 0.5422631502151489, train/logprobs = tensor([[-0.5679, -2.0459],
        [-0.4367, -1.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939447045326233
Epoch 0, Step 164: train/loss = 0.6149537563323975, train/raw-loss = 0.5588976144790649, train/logprobs = tensor([[-0.6601, -1.8126],
        [-0.5172, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800803005695343
Epoch 0, Step 165: train/loss = 0.606232225894928, train/raw-loss = 0.5350545048713684, train/logprobs = tensor([[-0.6456, -2.1501],
        [-0.4922, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168241709470749
Epoch 0, Step 166: train/loss = 0.4844691753387451, train/raw-loss = 0.4115556478500366, train/logprobs = tensor([[-0.6303, -6.6894],
        [-0.4448, -3.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10416225343942642
Epoch 0, Step 167: train/loss = 0.6781935691833496, train/raw-loss = 0.6082378625869751, train/logprobs = tensor([[-0.7195, -1.4105],
        [-0.5685, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09993675351142883
Epoch 0, Step 168: train/loss = 0.6432927846908569, train/raw-loss = 0.5787390470504761, train/logprobs = tensor([[-0.6816, -1.4746],
        [-0.5594, -0.7945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09221953898668289
Epoch 0, Step 169: train/loss = 0.7013130187988281, train/raw-loss = 0.6474352478981018, train/logprobs = tensor([[-0.7755, -1.3132],
        [-0.7210, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07696826756000519
Epoch 0, Step 170: train/loss = 0.6406601071357727, train/raw-loss = 0.5717495679855347, train/logprobs = tensor([[-0.5858, -1.6757],
        [-0.5531, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0984436646103859
Epoch 0, Step 171: train/loss = 0.695226788520813, train/raw-loss = 0.6301202774047852, train/logprobs = tensor([[-0.6437, -1.3276],
        [-0.5158, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0930093377828598
Epoch 0, Step 172: train/loss = 0.5651853680610657, train/raw-loss = 0.4945824444293976, train/logprobs = tensor([[-0.6351, -2.5621],
        [-0.5774, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086139291524887
Epoch 0, Step 173: train/loss = 0.5842597484588623, train/raw-loss = 0.5178643465042114, train/logprobs = tensor([[-0.6140, -2.4438],
        [-0.5404, -1.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09485052525997162
Epoch 0, Step 174: train/loss = 0.5870325565338135, train/raw-loss = 0.5222073197364807, train/logprobs = tensor([[-0.6771, -2.0328],
        [-0.5562, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09260745346546173
Epoch 0, Step 175: train/loss = 0.5105182528495789, train/raw-loss = 0.43825334310531616, train/logprobs = tensor([[-0.5046, -3.4883],
        [-0.4080, -1.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10323557257652283
Epoch 0, Step 176: train/loss = 0.6603581309318542, train/raw-loss = 0.582182765007019, train/logprobs = tensor([[-0.7212, -1.6289],
        [-0.4959, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11167901754379272
Epoch 0, Step 177: train/loss = 0.6398217678070068, train/raw-loss = 0.5653791427612305, train/logprobs = tensor([[-1.0471, -2.4459],
        [-0.6404, -1.2122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10634671151638031
Epoch 0, Step 178: train/loss = 0.6668293476104736, train/raw-loss = 0.6019034385681152, train/logprobs = tensor([[-0.8462, -2.3735],
        [-0.7429, -1.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09275133907794952
Epoch 0, Step 179: train/loss = 0.6500024795532227, train/raw-loss = 0.5860459208488464, train/logprobs = tensor([[-0.6491, -2.4448],
        [-0.4986, -1.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09136651456356049
Epoch 0, Step 180: train/loss = 0.7434451580047607, train/raw-loss = 0.6807942390441895, train/logprobs = tensor([[-0.8294, -0.8903],
        [-0.6418, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950120955705643
Epoch 0, Step 181: train/loss = 0.753460168838501, train/raw-loss = 0.6844474077224731, train/logprobs = tensor([[-2.7471, -3.9874],
        [-1.8939, -2.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858959913253784
Epoch 0, Step 182: train/loss = 0.6744060516357422, train/raw-loss = 0.6126996278762817, train/logprobs = tensor([[-0.5285, -1.2237],
        [-0.4587, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08815212547779083
Epoch 0, Step 183: train/loss = 0.6363741755485535, train/raw-loss = 0.5674756765365601, train/logprobs = tensor([[-0.7022, -1.7209],
        [-0.5913, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09842641651630402
Epoch 0, Step 184: train/loss = 0.5551857948303223, train/raw-loss = 0.4903237223625183, train/logprobs = tensor([[-1.1685, -4.1005],
        [-1.1477, -2.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09266017377376556
Epoch 0, Step 185: train/loss = 0.6350055932998657, train/raw-loss = 0.5723357200622559, train/logprobs = tensor([[-0.8451, -2.0738],
        [-0.6736, -1.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08952838182449341
Epoch 0, Step 186: train/loss = 0.6554617881774902, train/raw-loss = 0.5748050212860107, train/logprobs = tensor([[-0.8030, -1.6144],
        [-0.7146, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11522403359413147
Epoch 0, Step 187: train/loss = 0.6288071870803833, train/raw-loss = 0.5683518648147583, train/logprobs = tensor([[-0.5991, -2.3059],
        [-0.4887, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08636465668678284
Epoch 0, Step 188: train/loss = 0.5620269775390625, train/raw-loss = 0.49425435066223145, train/logprobs = tensor([[-0.8411, -4.0746],
        [-0.6058, -2.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09681808948516846
Epoch 0, Step 189: train/loss = 0.702667772769928, train/raw-loss = 0.6532898545265198, train/logprobs = tensor([[-0.5949, -0.8827],
        [-0.5063, -0.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0705399215221405
Epoch 0, Step 190: train/loss = 0.5854790210723877, train/raw-loss = 0.5294843316078186, train/logprobs = tensor([[-0.8124, -3.6333],
        [-0.6201, -1.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0799923911690712
Epoch 0, Step 191: train/loss = 0.6822473406791687, train/raw-loss = 0.6143370866775513, train/logprobs = tensor([[-0.6810, -1.1381],
        [-0.5952, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09701467305421829
Epoch 0, Step 192: train/loss = 0.6390586495399475, train/raw-loss = 0.5580017566680908, train/logprobs = tensor([[-0.7354, -1.4959],
        [-0.5658, -0.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579546332359314
Epoch 0, Step 193: train/loss = 0.5709257125854492, train/raw-loss = 0.47980716824531555, train/logprobs = tensor([[-0.7581, -3.0099],
        [-0.6399, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301693171262741
Epoch 0, Step 194: train/loss = 0.5489394068717957, train/raw-loss = 0.46524786949157715, train/logprobs = tensor([[-0.8501, -3.7065],
        [-0.7180, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11955936253070831
Epoch 0, Step 195: train/loss = 0.5723168849945068, train/raw-loss = 0.49565958976745605, train/logprobs = tensor([[-0.7869, -3.2897],
        [-0.6152, -1.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951045900583267
Epoch 0, Step 196: train/loss = 0.6548994779586792, train/raw-loss = 0.5782747268676758, train/logprobs = tensor([[-0.6893, -1.4879],
        [-0.5825, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10946395248174667
Epoch 0, Step 197: train/loss = 0.6021378636360168, train/raw-loss = 0.5225273370742798, train/logprobs = tensor([[-0.6810, -2.3140],
        [-0.5075, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11372941732406616
Epoch 0, Step 198: train/loss = 0.6302149891853333, train/raw-loss = 0.550634503364563, train/logprobs = tensor([[-0.6614, -1.7451],
        [-0.5563, -0.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11368648707866669
Epoch 0, Step 199: train/loss = 0.5459116697311401, train/raw-loss = 0.4575701951980591, train/logprobs = tensor([[-0.4922, -2.1689],
        [-0.3795, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12620212137699127
Epoch 0, Step 200: train/loss = 0.55970299243927, train/raw-loss = 0.48707106709480286, train/logprobs = tensor([[-0.8618, -2.2255],
        [-0.6846, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10375994443893433
Epoch 0, Step 201: train/loss = 0.5538245439529419, train/raw-loss = 0.4616996943950653, train/logprobs = tensor([[-0.8550, -3.1763],
        [-0.6749, -1.3273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13160692155361176
Epoch 0, Step 202: train/loss = 0.6711373925209045, train/raw-loss = 0.5991472005844116, train/logprobs = tensor([[-0.6805, -1.1265],
        [-0.6788, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10284308344125748
Epoch 0, Step 203: train/loss = 0.6618212461471558, train/raw-loss = 0.577506422996521, train/logprobs = tensor([[-0.7423, -2.5993],
        [-0.4666, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12044969201087952
Epoch 0, Step 204: train/loss = 0.5886005163192749, train/raw-loss = 0.5133796334266663, train/logprobs = tensor([[-0.8976, -2.0010],
        [-0.7322, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074584573507309
Epoch 0, Step 205: train/loss = 0.5297433733940125, train/raw-loss = 0.4426388144493103, train/logprobs = tensor([[-0.5465, -2.3954],
        [-0.5104, -0.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12443505227565765
Epoch 0, Step 206: train/loss = 0.4421083331108093, train/raw-loss = 0.357949435710907, train/logprobs = tensor([[-0.6074, -5.2724],
        [-0.5301, -1.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12022696435451508
Epoch 0, Step 207: train/loss = 0.5538185238838196, train/raw-loss = 0.47318705916404724, train/logprobs = tensor([[-0.9182, -2.2601],
        [-0.7830, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11518780142068863
Epoch 0, Step 208: train/loss = 0.5743746757507324, train/raw-loss = 0.49290281534194946, train/logprobs = tensor([[-0.7502, -3.3154],
        [-0.5432, -1.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11638836562633514
Epoch 0, Step 209: train/loss = 0.6252874135971069, train/raw-loss = 0.5381224155426025, train/logprobs = tensor([[-0.7360, -2.0219],
        [-0.6125, -0.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12452147901058197
Epoch 0, Step 210: train/loss = 0.6078436374664307, train/raw-loss = 0.5367934703826904, train/logprobs = tensor([[-0.6766, -1.6637],
        [-0.5607, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015002429485321
Epoch 0, Step 211: train/loss = 0.6463278532028198, train/raw-loss = 0.5736345052719116, train/logprobs = tensor([[-1.0247, -3.9279],
        [-1.0015, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038476824760437
Epoch 0, Step 212: train/loss = 0.6738033294677734, train/raw-loss = 0.6032853126525879, train/logprobs = tensor([[-0.5571, -1.2772],
        [-0.4556, -0.5703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10073994845151901
Epoch 0, Step 213: train/loss = 0.6798900961875916, train/raw-loss = 0.5990423560142517, train/logprobs = tensor([[-0.6764, -1.3113],
        [-0.5086, -0.6754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11549674719572067
Epoch 0, Step 214: train/loss = 0.6039011478424072, train/raw-loss = 0.5173943042755127, train/logprobs = tensor([[-0.6080, -2.7932],
        [-0.5604, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12358120828866959
Epoch 0, Step 215: train/loss = 0.5728241801261902, train/raw-loss = 0.4926163852214813, train/logprobs = tensor([[-0.9109, -2.6488],
        [-0.8593, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11458255350589752
Epoch 0, Step 216: train/loss = 0.6861312389373779, train/raw-loss = 0.6161240339279175, train/logprobs = tensor([[-0.7940, -1.1915],
        [-0.5371, -0.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001042485237122
Epoch 0, Step 217: train/loss = 0.5499840974807739, train/raw-loss = 0.47254592180252075, train/logprobs = tensor([[-0.5790, -2.4093],
        [-0.5050, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11062603443861008
Epoch 0, Step 218: train/loss = 0.7264273762702942, train/raw-loss = 0.6690129041671753, train/logprobs = tensor([[-0.6036, -0.7626],
        [-0.5163, -0.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08202064782381058
Epoch 0, Step 219: train/loss = 0.637060284614563, train/raw-loss = 0.5632066130638123, train/logprobs = tensor([[-0.6488, -1.6543],
        [-0.5548, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1055053323507309
Epoch 0, Step 220: train/loss = 0.49808138608932495, train/raw-loss = 0.42012107372283936, train/logprobs = tensor([[-1.0969, -3.6054],
        [-0.8953, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11137191951274872
Epoch 0, Step 221: train/loss = 0.587200403213501, train/raw-loss = 0.5147210955619812, train/logprobs = tensor([[-0.4738, -3.8237],
        [-0.4281, -1.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10354180634021759
Epoch 0, Step 222: train/loss = 0.6290593147277832, train/raw-loss = 0.5549476146697998, train/logprobs = tensor([[-0.6654, -2.0478],
        [-0.5119, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10587393492460251
Epoch 0, Step 223: train/loss = 0.6409174203872681, train/raw-loss = 0.5651838779449463, train/logprobs = tensor([[-0.8342, -2.0593],
        [-0.6460, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10819076001644135
Epoch 0, Step 224: train/loss = 0.6229734420776367, train/raw-loss = 0.5548007488250732, train/logprobs = tensor([[-0.6980, -1.4316],
        [-0.6461, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09738944470882416
Epoch 0, Step 225: train/loss = 0.6240249872207642, train/raw-loss = 0.5638391375541687, train/logprobs = tensor([[-0.5969, -1.4374],
        [-0.4505, -0.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08597985655069351
Epoch 0, Step 226: train/loss = 0.8336379528045654, train/raw-loss = 0.7635117173194885, train/logprobs = tensor([[-1.9785, -3.2406],
        [-0.6895, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10018028318881989
Epoch 0, Step 227: train/loss = 0.5364508628845215, train/raw-loss = 0.45254725217819214, train/logprobs = tensor([[-1.0049, -3.2697],
        [-0.5695, -0.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986222118139267
Epoch 0, Step 228: train/loss = 0.5987271666526794, train/raw-loss = 0.539609432220459, train/logprobs = tensor([[-0.5521, -1.9408],
        [-0.4300, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445388078689575
Epoch 0, Step 229: train/loss = 0.5046494007110596, train/raw-loss = 0.4294092655181885, train/logprobs = tensor([[-0.8936, -5.0275],
        [-0.8007, -2.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748586058616638
Epoch 0, Step 230: train/loss = 0.5061941742897034, train/raw-loss = 0.43426334857940674, train/logprobs = tensor([[-1.1099, -3.1158],
        [-1.0111, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10275828838348389
Epoch 0, Step 231: train/loss = 0.4704488515853882, train/raw-loss = 0.40778911113739014, train/logprobs = tensor([[-0.6616, -4.1145],
        [-0.6759, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895138680934906
Epoch 0, Step 232: train/loss = 0.5995486974716187, train/raw-loss = 0.5331614017486572, train/logprobs = tensor([[-0.6055, -2.3641],
        [-0.5648, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.094838947057724
Epoch 0, Step 233: train/loss = 0.6431936025619507, train/raw-loss = 0.5725908279418945, train/logprobs = tensor([[-1.2257, -4.9185],
        [-0.8198, -1.4549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086104273796082
Epoch 0, Step 234: train/loss = 0.6648951768875122, train/raw-loss = 0.6022995710372925, train/logprobs = tensor([[-0.5886, -1.1000],
        [-0.4841, -0.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08942229300737381
Epoch 0, Step 235: train/loss = 0.5279201865196228, train/raw-loss = 0.456835001707077, train/logprobs = tensor([[-0.9506, -4.2254],
        [-0.5850, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10155027359724045
Epoch 0, Step 236: train/loss = 0.6440513730049133, train/raw-loss = 0.570815920829773, train/logprobs = tensor([[-0.7172, -1.8398],
        [-0.6127, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10462208837270737
Epoch 0, Step 237: train/loss = 0.5679398775100708, train/raw-loss = 0.5056483745574951, train/logprobs = tensor([[-0.7310, -1.9554],
        [-0.6565, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08898791670799255
Epoch 0, Step 238: train/loss = 0.5294784307479858, train/raw-loss = 0.4641861021518707, train/logprobs = tensor([[-0.5699, -2.4630],
        [-0.4945, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09327475726604462
Epoch 0, Step 239: train/loss = 0.6828784942626953, train/raw-loss = 0.6239866018295288, train/logprobs = tensor([[-0.8002, -1.0902],
        [-0.5766, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0841311439871788
Epoch 0, Step 240: train/loss = 0.6530322432518005, train/raw-loss = 0.5781906843185425, train/logprobs = tensor([[-1.0489, -2.4001],
        [-1.0447, -1.3387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10691650211811066
Epoch 0, Step 241: train/loss = 0.5649517774581909, train/raw-loss = 0.49705472588539124, train/logprobs = tensor([[-0.5430, -1.7849],
        [-0.5158, -0.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699581563472748
Epoch 0, Step 242: train/loss = 0.6750074625015259, train/raw-loss = 0.614987313747406, train/logprobs = tensor([[-0.5635, -0.9833],
        [-0.4130, -0.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0857430249452591
Epoch 0, Step 243: train/loss = 0.6907421946525574, train/raw-loss = 0.629012405872345, train/logprobs = tensor([[-0.7806, -1.1184],
        [-0.5181, -0.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881853997707367
Epoch 0, Step 244: train/loss = 0.5276340842247009, train/raw-loss = 0.4544234573841095, train/logprobs = tensor([[-0.9975, -3.5021],
        [-0.7004, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10458657145500183
Epoch 0, Step 245: train/loss = 0.5823061466217041, train/raw-loss = 0.5119158029556274, train/logprobs = tensor([[-1.0273, -2.2069],
        [-0.6530, -0.5937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055769979953766
Epoch 0, Step 246: train/loss = 0.5119646787643433, train/raw-loss = 0.4387417435646057, train/logprobs = tensor([[-0.6555, -3.6487],
        [-0.6685, -1.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10460413247346878
Epoch 0, Step 247: train/loss = 0.604078471660614, train/raw-loss = 0.5362550616264343, train/logprobs = tensor([[-0.9290, -2.4089],
        [-0.7340, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09689053893089294
Epoch 0, Step 248: train/loss = 0.6467183828353882, train/raw-loss = 0.5885530710220337, train/logprobs = tensor([[-0.6460, -1.8565],
        [-0.6792, -1.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08309333026409149
Epoch 0, Step 249: train/loss = 0.5808061957359314, train/raw-loss = 0.5171273946762085, train/logprobs = tensor([[-0.4745, -2.1705],
        [-0.5021, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09096964448690414
Epoch 0, Step 250: train/loss = 0.5532021522521973, train/raw-loss = 0.47957950830459595, train/logprobs = tensor([[-1.1736, -4.0782],
        [-0.5940, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517527908086777
Epoch 0, Step 251: train/loss = 0.4730755090713501, train/raw-loss = 0.40172091126441956, train/logprobs = tensor([[-0.6347, -2.7601],
        [-0.6397, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10193511843681335
Epoch 0, Step 252: train/loss = 0.60932856798172, train/raw-loss = 0.5493090152740479, train/logprobs = tensor([[-0.4759, -1.5386],
        [-0.4050, -0.6272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08574220538139343
Epoch 0, Step 253: train/loss = 0.7430416345596313, train/raw-loss = 0.6861326694488525, train/logprobs = tensor([[-0.7499, -0.6045],
        [-0.6347, -0.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129853755235672
Epoch 0, Step 254: train/loss = 0.5240944027900696, train/raw-loss = 0.4591536521911621, train/logprobs = tensor([[-0.7299, -3.0638],
        [-0.5946, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277249872684479
Epoch 0, Step 255: train/loss = 0.6105976700782776, train/raw-loss = 0.5404800772666931, train/logprobs = tensor([[-1.0637, -2.4488],
        [-0.8813, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10016803443431854
Epoch 0, Step 256: train/loss = 0.7010480165481567, train/raw-loss = 0.6505551338195801, train/logprobs = tensor([[-0.5584, -0.8359],
        [-0.4324, -0.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07213260233402252
Epoch 0, Step 257: train/loss = 0.6912499666213989, train/raw-loss = 0.632402777671814, train/logprobs = tensor([[-0.7501, -1.1861],
        [-0.5898, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08406736701726913
Epoch 0, Step 258: train/loss = 0.4237673878669739, train/raw-loss = 0.35304832458496094, train/logprobs = tensor([[-0.8786, -3.1849],
        [-0.9345, -0.8601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1010272279381752
Epoch 0, Step 259: train/loss = 0.572583794593811, train/raw-loss = 0.5186023712158203, train/logprobs = tensor([[-0.5749, -3.6040],
        [-0.5126, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711633294820786
Epoch 0, Step 260: train/loss = 0.48897069692611694, train/raw-loss = 0.42607447504997253, train/logprobs = tensor([[-0.5139, -4.4667],
        [-0.4666, -1.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08985169231891632
Epoch 0, Step 261: train/loss = 0.5351488590240479, train/raw-loss = 0.4627719521522522, train/logprobs = tensor([[-0.8017, -2.1084],
        [-0.8404, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10339556634426117
Epoch 0, Step 262: train/loss = 0.6086230278015137, train/raw-loss = 0.5437227487564087, train/logprobs = tensor([[-0.6809, -2.3484],
        [-0.6132, -1.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09271475672721863
Epoch 0, Step 263: train/loss = 0.6570501327514648, train/raw-loss = 0.5880383253097534, train/logprobs = tensor([[-1.2483, -1.9679],
        [-1.0507, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858833253383636
Epoch 0, Step 264: train/loss = 0.6435555815696716, train/raw-loss = 0.5880987048149109, train/logprobs = tensor([[-0.7330, -1.3333],
        [-0.6629, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792241096496582
Epoch 0, Step 265: train/loss = 0.6936989426612854, train/raw-loss = 0.6346389055252075, train/logprobs = tensor([[-0.8627, -1.2888],
        [-0.6467, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08437153697013855
Epoch 0, Step 266: train/loss = 0.48435890674591064, train/raw-loss = 0.4165569245815277, train/logprobs = tensor([[-0.9714, -3.1946],
        [-1.0034, -1.1964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09685994684696198
Epoch 0, Step 267: train/loss = 0.5293606519699097, train/raw-loss = 0.4626157283782959, train/logprobs = tensor([[-0.6768, -2.2473],
        [-0.5497, -0.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09534979611635208
Epoch 0, Step 268: train/loss = 0.5415688157081604, train/raw-loss = 0.48600709438323975, train/logprobs = tensor([[-0.6491, -4.8618],
        [-0.6556, -1.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07937390357255936
Epoch 0, Step 269: train/loss = 0.5596123933792114, train/raw-loss = 0.498002290725708, train/logprobs = tensor([[-0.7770, -3.7954],
        [-0.6912, -1.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08801443874835968
Epoch 0, Step 270: train/loss = 0.5573890209197998, train/raw-loss = 0.4912523329257965, train/logprobs = tensor([[-0.4015, -1.9454],
        [-0.3542, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09448094666004181
Epoch 0, Step 271: train/loss = 0.5639568567276001, train/raw-loss = 0.49963295459747314, train/logprobs = tensor([[-0.7737, -2.0645],
        [-0.6473, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.091891348361969
Epoch 0, Step 272: train/loss = 0.7226032018661499, train/raw-loss = 0.6653380393981934, train/logprobs = tensor([[-0.6027, -0.8168],
        [-0.5469, -0.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08180740475654602
Epoch 0, Step 273: train/loss = 0.6236358284950256, train/raw-loss = 0.565348744392395, train/logprobs = tensor([[-0.4603, -1.2147],
        [-0.4831, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08326723426580429
Epoch 0, Step 274: train/loss = 0.6470643281936646, train/raw-loss = 0.5841614603996277, train/logprobs = tensor([[-0.5611, -1.5577],
        [-0.4826, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986120671033859
Epoch 0, Step 275: train/loss = 0.5453333854675293, train/raw-loss = 0.49117130041122437, train/logprobs = tensor([[-0.4767, -1.7127],
        [-0.4369, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773744285106659
Epoch 0, Step 276: train/loss = 0.5961476564407349, train/raw-loss = 0.5303587317466736, train/logprobs = tensor([[-1.2008, -2.5130],
        [-1.0267, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09398416429758072
Epoch 0, Step 277: train/loss = 0.6622769832611084, train/raw-loss = 0.5928817987442017, train/logprobs = tensor([[-0.7561, -1.1578],
        [-0.7353, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09913595020771027
Epoch 0, Step 278: train/loss = 0.6126298904418945, train/raw-loss = 0.5442635416984558, train/logprobs = tensor([[-0.7526, -1.2962],
        [-0.7094, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09766615927219391
Epoch 0, Step 279: train/loss = 0.47584766149520874, train/raw-loss = 0.40728840231895447, train/logprobs = tensor([[-0.9924, -4.0281],
        [-0.7434, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09794184565544128
Epoch 0, Step 280: train/loss = 0.5481051206588745, train/raw-loss = 0.48332294821739197, train/logprobs = tensor([[-0.7708, -4.2362],
        [-0.6262, -1.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0925460159778595
Epoch 0, Step 281: train/loss = 0.6227867603302002, train/raw-loss = 0.5637180805206299, train/logprobs = tensor([[-0.5415, -1.1270],
        [-0.4802, -0.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438389003276825
Epoch 0, Step 282: train/loss = 0.6237413883209229, train/raw-loss = 0.5413309931755066, train/logprobs = tensor([[-1.1717, -3.0157],
        [-0.7933, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11772914975881577
Epoch 0, Step 283: train/loss = 0.5749825239181519, train/raw-loss = 0.510982871055603, train/logprobs = tensor([[-0.7342, -2.0786],
        [-0.6167, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09142814576625824
Epoch 0, Step 284: train/loss = 0.6203151345252991, train/raw-loss = 0.5557510256767273, train/logprobs = tensor([[-0.4781, -1.2830],
        [-0.4863, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09223443269729614
Epoch 0, Step 285: train/loss = 0.6387874484062195, train/raw-loss = 0.5794678330421448, train/logprobs = tensor([[-0.5604, -1.1146],
        [-0.5642, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08474230766296387
Epoch 0, Step 286: train/loss = 0.5694088339805603, train/raw-loss = 0.5110619068145752, train/logprobs = tensor([[-0.4055, -1.6755],
        [-0.3453, -0.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833527073264122
Epoch 0, Step 287: train/loss = 0.5469489693641663, train/raw-loss = 0.4789865016937256, train/logprobs = tensor([[-0.7440, -3.6002],
        [-0.7411, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708932042121887
Epoch 0, Step 288: train/loss = 0.5878850221633911, train/raw-loss = 0.5271270275115967, train/logprobs = tensor([[-0.5518, -1.5958],
        [-0.5967, -0.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08679711818695068
Epoch 0, Step 289: train/loss = 0.5609394311904907, train/raw-loss = 0.49255117774009705, train/logprobs = tensor([[-0.7966, -2.9980],
        [-0.7134, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09769748896360397
Epoch 0, Step 290: train/loss = 0.5551557540893555, train/raw-loss = 0.4977072775363922, train/logprobs = tensor([[-0.5488, -2.7989],
        [-0.5333, -1.4798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820692628622055
Epoch 0, Step 291: train/loss = 0.5088176727294922, train/raw-loss = 0.44678980112075806, train/logprobs = tensor([[-0.6925, -2.0214],
        [-0.7485, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08861126005649567
Epoch 0, Step 292: train/loss = 0.5887857675552368, train/raw-loss = 0.5339385271072388, train/logprobs = tensor([[-0.5997, -1.3212],
        [-0.6710, -0.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0783531591296196
Epoch 0, Step 293: train/loss = 0.5910030603408813, train/raw-loss = 0.5247738361358643, train/logprobs = tensor([[-0.7582, -2.1103],
        [-0.6930, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09461307525634766
Epoch 0, Step 294: train/loss = 0.5889947414398193, train/raw-loss = 0.526854932308197, train/logprobs = tensor([[-0.8523, -1.5385],
        [-0.7581, -0.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08877108246088028
Epoch 0, Step 295: train/loss = 0.5604710578918457, train/raw-loss = 0.49525266885757446, train/logprobs = tensor([[-1.3012, -2.7241],
        [-1.2066, -1.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09316911548376083
Epoch 0, Step 296: train/loss = 0.6021039485931396, train/raw-loss = 0.5419186353683472, train/logprobs = tensor([[-0.6649, -1.8171],
        [-0.6276, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08597908914089203
Epoch 0, Step 297: train/loss = 0.5102240443229675, train/raw-loss = 0.4501575529575348, train/logprobs = tensor([[-0.6138, -3.1512],
        [-0.6510, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08580927550792694
Epoch 0, Step 298: train/loss = 0.5779034495353699, train/raw-loss = 0.5220539569854736, train/logprobs = tensor([[-0.5393, -1.4326],
        [-0.6749, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07978499680757523
Epoch 0, Step 299: train/loss = 0.49433401226997375, train/raw-loss = 0.43609002232551575, train/logprobs = tensor([[-0.9592, -2.8422],
        [-0.9518, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08320571482181549
Epoch 0, Step 300: train/loss = 0.5513313412666321, train/raw-loss = 0.4945243000984192, train/logprobs = tensor([[-0.7311, -2.2153],
        [-0.7469, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08115290105342865
Epoch 0, Step 301: train/loss = 0.605474591255188, train/raw-loss = 0.5413235425949097, train/logprobs = tensor([[-0.6223, -1.2222],
        [-0.5829, -0.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09164438396692276
Epoch 0, Step 302: train/loss = 0.5257108211517334, train/raw-loss = 0.46674782037734985, train/logprobs = tensor([[-0.6250, -2.1276],
        [-0.5887, -0.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08423279225826263
Epoch 0, Step 303: train/loss = 0.4903433322906494, train/raw-loss = 0.4317479133605957, train/logprobs = tensor([[-0.5247, -2.4161],
        [-0.5608, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837077647447586
Epoch 0, Step 304: train/loss = 0.5849224328994751, train/raw-loss = 0.5243703126907349, train/logprobs = tensor([[-0.6301, -1.6675],
        [-0.6206, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08650300651788712
Epoch 0, Step 305: train/loss = 0.5830166935920715, train/raw-loss = 0.514320969581604, train/logprobs = tensor([[-0.8419, -2.6413],
        [-0.5233, -0.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09813673049211502
Epoch 0, Step 306: train/loss = 0.6062466502189636, train/raw-loss = 0.5476974248886108, train/logprobs = tensor([[-0.7745, -3.4142],
        [-0.6611, -1.2060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08364171534776688
Epoch 0, Step 307: train/loss = 0.5867770314216614, train/raw-loss = 0.5234386920928955, train/logprobs = tensor([[-0.8165, -3.9103],
        [-0.8201, -1.4441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048342704772949
Epoch 0, Step 308: train/loss = 0.6247373819351196, train/raw-loss = 0.5638459920883179, train/logprobs = tensor([[-0.6797, -1.3303],
        [-0.6428, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0869876891374588
Epoch 0, Step 309: train/loss = 0.6364268660545349, train/raw-loss = 0.5809410214424133, train/logprobs = tensor([[-0.5071, -1.2130],
        [-0.4526, -0.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792655497789383
Epoch 0, Step 310: train/loss = 0.4362775385379791, train/raw-loss = 0.37296047806739807, train/logprobs = tensor([[-0.6378, -3.8069],
        [-0.5376, -0.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09045296162366867
Epoch 0, Step 311: train/loss = 0.5883416533470154, train/raw-loss = 0.5279274582862854, train/logprobs = tensor([[-0.5587, -2.4155],
        [-0.5987, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08630600571632385
Epoch 0, Step 312: train/loss = 0.6153165102005005, train/raw-loss = 0.5629796981811523, train/logprobs = tensor([[-0.6464, -3.2299],
        [-0.5167, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07476689666509628
Epoch 0, Step 313: train/loss = 0.5379000902175903, train/raw-loss = 0.4704677164554596, train/logprobs = tensor([[-0.6145, -2.2238],
        [-0.6175, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963318794965744
Epoch 0, Step 314: train/loss = 0.659842848777771, train/raw-loss = 0.6017051935195923, train/logprobs = tensor([[-0.5935, -0.8409],
        [-0.6085, -0.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08305375277996063
Epoch 0, Step 315: train/loss = 0.6073864698410034, train/raw-loss = 0.5417203307151794, train/logprobs = tensor([[-1.6760, -3.3587],
        [-1.3081, -1.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09380873292684555
Epoch 0, Step 316: train/loss = 0.7182058095932007, train/raw-loss = 0.6723060011863708, train/logprobs = tensor([[-0.7286, -0.6648],
        [-0.7294, -0.5746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06557111442089081
Epoch 0, Step 317: train/loss = 0.46485573053359985, train/raw-loss = 0.4050215482711792, train/logprobs = tensor([[-0.4701, -4.1493],
        [-0.4900, -1.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08547741919755936
Epoch 0, Step 318: train/loss = 0.49128979444503784, train/raw-loss = 0.42877092957496643, train/logprobs = tensor([[-0.7143, -2.5438],
        [-0.7330, -0.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931265771389008
Epoch 0, Step 319: train/loss = 0.522719144821167, train/raw-loss = 0.4581637978553772, train/logprobs = tensor([[-0.5304, -2.5487],
        [-0.5536, -0.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09222190827131271
Epoch 0, Step 320: train/loss = 0.5411748886108398, train/raw-loss = 0.48879918456077576, train/logprobs = tensor([[-0.7586, -2.4780],
        [-0.6556, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07482241839170456
Epoch 0, Step 321: train/loss = 0.5692911148071289, train/raw-loss = 0.5206053853034973, train/logprobs = tensor([[-0.6074, -1.6540],
        [-0.5846, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06955104321241379
Epoch 0, Step 322: train/loss = 0.4838496446609497, train/raw-loss = 0.43221282958984375, train/logprobs = tensor([[-1.0107, -3.8786],
        [-0.8768, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07376688718795776
Epoch 0, Step 323: train/loss = 0.5273366570472717, train/raw-loss = 0.47959497570991516, train/logprobs = tensor([[-0.3948, -2.1803],
        [-0.4237, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06820236891508102
Epoch 0, Step 324: train/loss = 0.4031216502189636, train/raw-loss = 0.34444913268089294, train/logprobs = tensor([[-0.7652, -5.0183],
        [-0.6480, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08381784707307816
Epoch 0, Step 325: train/loss = 0.6453220248222351, train/raw-loss = 0.596555233001709, train/logprobs = tensor([[-0.5851, -1.0868],
        [-0.5548, -0.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06966686248779297
Epoch 0, Step 326: train/loss = 0.4539918303489685, train/raw-loss = 0.39635396003723145, train/logprobs = tensor([[-0.8912, -4.6515],
        [-0.9966, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0823398008942604
Epoch 0, Step 327: train/loss = 0.7358954548835754, train/raw-loss = 0.6783596277236938, train/logprobs = tensor([[-0.8226, -1.0359],
        [-0.6201, -0.7469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08219409734010696
Epoch 0, Step 328: train/loss = 0.6336586475372314, train/raw-loss = 0.5884814262390137, train/logprobs = tensor([[-0.8120, -1.6545],
        [-0.7871, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06453883647918701
Epoch 0, Step 329: train/loss = 0.6318660378456116, train/raw-loss = 0.5737098455429077, train/logprobs = tensor([[-1.0475, -1.5045],
        [-0.8442, -0.4516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08308027684688568
Epoch 0, Step 330: train/loss = 0.3828495740890503, train/raw-loss = 0.3280378580093384, train/logprobs = tensor([[-0.6559, -4.0879],
        [-0.6377, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830247282981873
Epoch 0, Step 331: train/loss = 0.5051494836807251, train/raw-loss = 0.4572538137435913, train/logprobs = tensor([[-0.6103, -3.8199],
        [-0.6000, -0.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06842239946126938
Epoch 0, Step 332: train/loss = 0.45628994703292847, train/raw-loss = 0.3991078734397888, train/logprobs = tensor([[-0.7640, -3.3606],
        [-0.8743, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08168867975473404
Epoch 0, Step 333: train/loss = 0.5385638475418091, train/raw-loss = 0.4841061234474182, train/logprobs = tensor([[-0.7278, -2.7363],
        [-0.5910, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0777968168258667
Epoch 0, Step 334: train/loss = 0.6641733646392822, train/raw-loss = 0.6174877882003784, train/logprobs = tensor([[-0.7215, -0.9025],
        [-0.6295, -0.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06669367849826813
Epoch 0, Step 335: train/loss = 0.4874534010887146, train/raw-loss = 0.43523097038269043, train/logprobs = tensor([[-0.6254, -2.1757],
        [-0.5557, -0.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07460345327854156
Epoch 0, Step 336: train/loss = 0.5591868162155151, train/raw-loss = 0.506822407245636, train/logprobs = tensor([[-0.5360, -1.6197],
        [-0.5921, -0.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07480630278587341
Epoch 0, Step 337: train/loss = 0.5482028722763062, train/raw-loss = 0.4909200370311737, train/logprobs = tensor([[-0.8356, -1.9809],
        [-0.8296, -0.6965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818326398730278
Epoch 0, Step 338: train/loss = 0.553545355796814, train/raw-loss = 0.5021993517875671, train/logprobs = tensor([[-0.5364, -1.5510],
        [-0.5550, -0.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07335145771503448
Epoch 0, Step 339: train/loss = 0.49860095977783203, train/raw-loss = 0.4475964903831482, train/logprobs = tensor([[-0.3658, -3.9883],
        [-0.3919, -1.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07286349684000015
Epoch 0, Step 340: train/loss = 0.6205164790153503, train/raw-loss = 0.5709832310676575, train/logprobs = tensor([[-0.7326, -1.2852],
        [-0.7075, -0.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07076185196638107
Epoch 0, Step 341: train/loss = 0.4262010157108307, train/raw-loss = 0.3712350130081177, train/logprobs = tensor([[-0.5822, -3.0086],
        [-0.6647, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07852289825677872
Epoch 0, Step 342: train/loss = 0.5250503420829773, train/raw-loss = 0.47727149724960327, train/logprobs = tensor([[-0.5411, -2.5358],
        [-0.6009, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0682554617524147
Epoch 0, Step 343: train/loss = 0.6162077188491821, train/raw-loss = 0.5693632364273071, train/logprobs = tensor([[-0.6410, -1.9920],
        [-0.6589, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06692060083150864
Epoch 0, Step 344: train/loss = 0.4429163932800293, train/raw-loss = 0.38724568486213684, train/logprobs = tensor([[-0.8546, -5.1799],
        [-0.7872, -1.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07952951639890671
Epoch 0, Step 345: train/loss = 0.5032509565353394, train/raw-loss = 0.4524392783641815, train/logprobs = tensor([[-1.0544, -3.4841],
        [-1.0998, -0.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07258815318346024
Epoch 0, Step 346: train/loss = 0.5341999530792236, train/raw-loss = 0.47765669226646423, train/logprobs = tensor([[-0.7558, -3.5705],
        [-0.7156, -1.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08077609539031982
Epoch 0, Step 347: train/loss = 0.5371052026748657, train/raw-loss = 0.4853646159172058, train/logprobs = tensor([[-0.5937, -4.1334],
        [-0.6260, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07391507178544998
Epoch 0, Step 348: train/loss = 0.5562156438827515, train/raw-loss = 0.5111109018325806, train/logprobs = tensor([[-0.7154, -2.8519],
        [-0.7720, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06443524360656738
Epoch 0, Step 349: train/loss = 0.4441569149494171, train/raw-loss = 0.3865823745727539, train/logprobs = tensor([[-0.6661, -2.6268],
        [-0.7206, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08224934339523315
Epoch 0, Step 350: train/loss = 0.6291416883468628, train/raw-loss = 0.5680842399597168, train/logprobs = tensor([[-1.1629, -2.3367],
        [-0.9729, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08722490817308426
Epoch 0, Step 351: train/loss = 0.5551289319992065, train/raw-loss = 0.5002925992012024, train/logprobs = tensor([[-0.7073, -2.3490],
        [-0.7043, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0783376693725586
Epoch 0, Step 352: train/loss = 0.4927566647529602, train/raw-loss = 0.4379858374595642, train/logprobs = tensor([[-0.5000, -3.2915],
        [-0.5851, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824406027793884
Epoch 0, Step 353: train/loss = 0.42825305461883545, train/raw-loss = 0.3725411593914032, train/logprobs = tensor([[-0.6986, -4.1357],
        [-0.8126, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0795883759856224
Epoch 0, Step 354: train/loss = 0.6503539681434631, train/raw-loss = 0.6041861176490784, train/logprobs = tensor([[-0.4798, -0.9438],
        [-0.4982, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06595408916473389
Epoch 0, Step 355: train/loss = 0.5342730283737183, train/raw-loss = 0.48205822706222534, train/logprobs = tensor([[-0.7012, -2.4694],
        [-0.7683, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07459264248609543
Epoch 0, Step 356: train/loss = 0.6385006904602051, train/raw-loss = 0.5864987373352051, train/logprobs = tensor([[-0.4963, -1.0596],
        [-0.4824, -0.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0742885023355484
Epoch 0, Step 357: train/loss = 0.6801717281341553, train/raw-loss = 0.6235194802284241, train/logprobs = tensor([[-1.6736, -2.2919],
        [-1.3209, -1.5333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08093181252479553
Epoch 0, Step 358: train/loss = 0.549760639667511, train/raw-loss = 0.5043964385986328, train/logprobs = tensor([[-0.5113, -3.7450],
        [-0.4865, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06480604410171509
Epoch 0, Step 359: train/loss = 0.6009702086448669, train/raw-loss = 0.5463914275169373, train/logprobs = tensor([[-0.8662, -1.7447],
        [-0.8247, -0.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0779697597026825
Epoch 0, Step 360: train/loss = 0.560794472694397, train/raw-loss = 0.504719614982605, train/logprobs = tensor([[-0.8561, -2.4010],
        [-0.8103, -0.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08010702580213547
Epoch 0, Step 361: train/loss = 0.5927878022193909, train/raw-loss = 0.5357012152671814, train/logprobs = tensor([[-0.5858, -1.1476],
        [-0.6701, -0.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08155229687690735
Epoch 0, Step 362: train/loss = 0.6181321740150452, train/raw-loss = 0.5728036165237427, train/logprobs = tensor([[-0.6518, -1.6150],
        [-0.6429, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06475509703159332
Epoch 0, Step 363: train/loss = 0.7555496692657471, train/raw-loss = 0.7114015221595764, train/logprobs = tensor([[-1.2065, -1.1035],
        [-0.8466, -0.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06306882947683334
Epoch 0, Step 364: train/loss = 0.4286930561065674, train/raw-loss = 0.379403293132782, train/logprobs = tensor([[-0.3961, -5.0950],
        [-0.5191, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0704139769077301
Epoch 0, Step 365: train/loss = 0.48676711320877075, train/raw-loss = 0.4323914647102356, train/logprobs = tensor([[-0.5297, -2.3191],
        [-0.5642, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07767949998378754
Epoch 0, Step 366: train/loss = 0.5609651207923889, train/raw-loss = 0.5081369876861572, train/logprobs = tensor([[-0.5756, -2.3524],
        [-0.5897, -0.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754687488079071
Epoch 0, Step 367: train/loss = 0.46346408128738403, train/raw-loss = 0.4129007160663605, train/logprobs = tensor([[-0.5570, -3.0625],
        [-0.6617, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07223331928253174
Epoch 0, Step 368: train/loss = 0.5188934803009033, train/raw-loss = 0.46659231185913086, train/logprobs = tensor([[-0.4226, -2.2165],
        [-0.4236, -0.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07471592724323273
Epoch 0, Step 369: train/loss = 0.5254453420639038, train/raw-loss = 0.4778141975402832, train/logprobs = tensor([[-0.4472, -1.8100],
        [-0.5144, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804449111223221
Epoch 0, Step 370: train/loss = 0.6585144400596619, train/raw-loss = 0.6147230863571167, train/logprobs = tensor([[-0.3909, -0.8241],
        [-0.3971, -0.4700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06255903840065002
Epoch 0, Step 371: train/loss = 0.5273891091346741, train/raw-loss = 0.48000848293304443, train/logprobs = tensor([[-0.4156, -2.7531],
        [-0.4478, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06768665462732315
Epoch 0, Step 372: train/loss = 0.4814489781856537, train/raw-loss = 0.4282289743423462, train/logprobs = tensor([[-0.5664, -2.8554],
        [-0.5265, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07602859288454056
Epoch 0, Step 373: train/loss = 0.5551716685295105, train/raw-loss = 0.5032522678375244, train/logprobs = tensor([[-0.7303, -4.0991],
        [-0.6659, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07417061924934387
Epoch 0, Step 374: train/loss = 0.5608824491500854, train/raw-loss = 0.508857250213623, train/logprobs = tensor([[-0.3133, -2.0865],
        [-0.3444, -0.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743216946721077
Epoch 0, Step 375: train/loss = 0.5337322354316711, train/raw-loss = 0.4755815267562866, train/logprobs = tensor([[-0.7176, -1.5649],
        [-0.8969, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830724686384201
Epoch 0, Step 376: train/loss = 0.45700955390930176, train/raw-loss = 0.3997598886489868, train/logprobs = tensor([[-0.6084, -4.1272],
        [-0.7806, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08178527653217316
Epoch 0, Step 377: train/loss = 0.5985502600669861, train/raw-loss = 0.5443893671035767, train/logprobs = tensor([[-0.6348, -2.3238],
        [-0.5648, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07737264037132263
Epoch 0, Step 378: train/loss = 0.5649808645248413, train/raw-loss = 0.5154961347579956, train/logprobs = tensor([[-0.6942, -3.2775],
        [-0.6680, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07069248706102371
Epoch 0, Step 379: train/loss = 0.6240155100822449, train/raw-loss = 0.5793910026550293, train/logprobs = tensor([[-0.9487, -1.9613],
        [-0.8066, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0637492686510086
Epoch 0, Step 380: train/loss = 0.5529701113700867, train/raw-loss = 0.5011535882949829, train/logprobs = tensor([[-0.5977, -1.6892],
        [-0.6297, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07402357459068298
Epoch 0, Step 381: train/loss = 0.4741870164871216, train/raw-loss = 0.41858452558517456, train/logprobs = tensor([[-0.6661, -3.7618],
        [-0.8288, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07943210750818253
Epoch 0, Step 382: train/loss = 0.43406790494918823, train/raw-loss = 0.3804131746292114, train/logprobs = tensor([[-0.5434, -3.2219],
        [-0.5675, -0.6807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07664961367845535
Epoch 0, Step 383: train/loss = 0.47577333450317383, train/raw-loss = 0.4167136251926422, train/logprobs = tensor([[-0.4629, -2.2840],
        [-0.5960, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08437097072601318
Epoch 0, Step 384: train/loss = 0.5302221775054932, train/raw-loss = 0.4690930247306824, train/logprobs = tensor([[-0.8042, -5.2899],
        [-0.8567, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08732729405164719
Epoch 0, Step 385: train/loss = 0.6165779829025269, train/raw-loss = 0.5467878580093384, train/logprobs = tensor([[-1.0864, -1.8763],
        [-0.9465, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09970014542341232
Epoch 0, Step 386: train/loss = 0.7446983456611633, train/raw-loss = 0.6977471113204956, train/logprobs = tensor([[-0.8626, -0.7961],
        [-0.6261, -0.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06707324087619781
Epoch 0, Step 387: train/loss = 0.5148617625236511, train/raw-loss = 0.4562363624572754, train/logprobs = tensor([[-0.6221, -4.3326],
        [-0.7900, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08375060558319092
Epoch 0, Step 388: train/loss = 0.5779950022697449, train/raw-loss = 0.5089846253395081, train/logprobs = tensor([[-0.6950, -2.0482],
        [-0.7488, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0985863208770752
Epoch 0, Step 389: train/loss = 0.4982532858848572, train/raw-loss = 0.42970961332321167, train/logprobs = tensor([[-0.5682, -2.1513],
        [-0.6398, -0.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09791962802410126
Epoch 0, Step 390: train/loss = 0.48504024744033813, train/raw-loss = 0.4182763695716858, train/logprobs = tensor([[-0.9917, -2.5640],
        [-1.2481, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09537696838378906
Epoch 0, Step 391: train/loss = 0.5679267048835754, train/raw-loss = 0.5119673013687134, train/logprobs = tensor([[-0.4837, -1.6688],
        [-0.4832, -0.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07994192838668823
Epoch 0, Step 392: train/loss = 0.47846052050590515, train/raw-loss = 0.423113614320755, train/logprobs = tensor([[-0.4720, -3.0615],
        [-0.6261, -0.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906700670719147
Epoch 0, Step 393: train/loss = 0.5867984294891357, train/raw-loss = 0.5219471454620361, train/logprobs = tensor([[-0.6715, -1.6875],
        [-0.5940, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09264465421438217
Epoch 0, Step 394: train/loss = 0.4405612349510193, train/raw-loss = 0.37790021300315857, train/logprobs = tensor([[-0.7908, -5.7267],
        [-0.8107, -0.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08951577544212341
Epoch 0, Step 395: train/loss = 0.5181640386581421, train/raw-loss = 0.46742185950279236, train/logprobs = tensor([[-0.6562, -5.1050],
        [-0.4435, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07248876988887787
Epoch 0, Step 396: train/loss = 0.5585484504699707, train/raw-loss = 0.5022549033164978, train/logprobs = tensor([[-0.7115, -1.8437],
        [-0.7203, -0.6899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08041930943727493
Epoch 0, Step 397: train/loss = 0.5910534262657166, train/raw-loss = 0.5338546633720398, train/logprobs = tensor([[-0.4742, -1.9851],
        [-0.4499, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08171255886554718
Epoch 0, Step 398: train/loss = 0.44296547770500183, train/raw-loss = 0.37978604435920715, train/logprobs = tensor([[-0.5857, -3.1972],
        [-0.6634, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025634825229645
Epoch 0, Step 399: train/loss = 0.6022642850875854, train/raw-loss = 0.5417160391807556, train/logprobs = tensor([[-0.7729, -1.3668],
        [-0.8997, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08649754524230957
Epoch 0, Step 400: train/loss = 0.5971576571464539, train/raw-loss = 0.5489189624786377, train/logprobs = tensor([[-0.5216, -1.2624],
        [-0.5422, -0.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0689123272895813
Epoch 0, Step 401: train/loss = 0.4573466181755066, train/raw-loss = 0.40094730257987976, train/logprobs = tensor([[-0.7695, -3.3540],
        [-0.7844, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08057038486003876
Epoch 0, Step 402: train/loss = 0.47556015849113464, train/raw-loss = 0.41282883286476135, train/logprobs = tensor([[-0.6865, -3.1187],
        [-0.6664, -0.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08961618691682816
Epoch 0, Step 403: train/loss = 0.563400149345398, train/raw-loss = 0.5180763006210327, train/logprobs = tensor([[-0.3252, -1.5730],
        [-0.3564, -0.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06474830955266953
Epoch 0, Step 404: train/loss = 0.6533493399620056, train/raw-loss = 0.6048702597618103, train/logprobs = tensor([[-0.5759, -1.2295],
        [-0.4862, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06925582140684128
Epoch 0, Step 405: train/loss = 0.5844516754150391, train/raw-loss = 0.5362319350242615, train/logprobs = tensor([[-0.4597, -3.0345],
        [-0.5072, -0.7461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06888528913259506
Epoch 0, Step 406: train/loss = 0.552640438079834, train/raw-loss = 0.4969366788864136, train/logprobs = tensor([[-0.5649, -2.1213],
        [-0.5726, -0.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07957683503627777
Epoch 0, Step 407: train/loss = 0.6221731901168823, train/raw-loss = 0.5793431997299194, train/logprobs = tensor([[-0.5155, -1.0365],
        [-0.4972, -0.4457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06118568032979965
Epoch 0, Step 408: train/loss = 0.6122450828552246, train/raw-loss = 0.5545103549957275, train/logprobs = tensor([[-0.5985, -1.1422],
        [-0.7974, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247807621955872
Epoch 0, Step 409: train/loss = 0.3591197729110718, train/raw-loss = 0.2924167811870575, train/logprobs = tensor([[-0.8518, -4.5522],
        [-1.1354, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09528997540473938
Epoch 0, Step 410: train/loss = 0.6110055446624756, train/raw-loss = 0.5559929609298706, train/logprobs = tensor([[-0.5750, -1.9927],
        [-0.5200, -1.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07858936488628387
Epoch 0, Step 411: train/loss = 0.5819455981254578, train/raw-loss = 0.5158127546310425, train/logprobs = tensor([[-0.4912, -1.4068],
        [-0.5522, -0.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0944754108786583
Epoch 0, Step 412: train/loss = 0.6140139102935791, train/raw-loss = 0.5608757734298706, train/logprobs = tensor([[-0.4647, -1.3096],
        [-0.5453, -0.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591164112091064
Epoch 0, Step 413: train/loss = 0.5794987678527832, train/raw-loss = 0.5293862223625183, train/logprobs = tensor([[-0.7342, -3.8519],
        [-0.6131, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07158937305212021
Epoch 0, Step 414: train/loss = 0.530177116394043, train/raw-loss = 0.4795764684677124, train/logprobs = tensor([[-0.4231, -1.6019],
        [-0.5321, -0.3681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07228664308786392
Epoch 0, Step 415: train/loss = 0.503531813621521, train/raw-loss = 0.4478411078453064, train/logprobs = tensor([[-0.7537, -3.7897],
        [-0.7340, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07955814152956009
Epoch 0, Step 416: train/loss = 0.6451833248138428, train/raw-loss = 0.5878114104270935, train/logprobs = tensor([[-0.7032, -1.2890],
        [-0.6460, -0.6492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08195985108613968
Epoch 0, Step 417: train/loss = 0.4702983498573303, train/raw-loss = 0.40340951085090637, train/logprobs = tensor([[-0.5870, -3.5405],
        [-0.8560, -0.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09555547684431076
Epoch 0, Step 418: train/loss = 0.4500194787979126, train/raw-loss = 0.3895190954208374, train/logprobs = tensor([[-0.6028, -2.4220],
        [-0.8691, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08642914891242981
Epoch 0, Step 419: train/loss = 0.48219814896583557, train/raw-loss = 0.4209234118461609, train/logprobs = tensor([[-0.8417, -3.2234],
        [-0.8615, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0875353217124939
Epoch 0, Step 420: train/loss = 0.521314799785614, train/raw-loss = 0.45752695202827454, train/logprobs = tensor([[-0.6974, -2.7751],
        [-0.8115, -0.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112548828125
Epoch 0, Step 421: train/loss = 0.46604013442993164, train/raw-loss = 0.4011930227279663, train/logprobs = tensor([[-0.6704, -2.1608],
        [-0.9506, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09263882040977478
Epoch 0, Step 422: train/loss = 0.4572235643863678, train/raw-loss = 0.38774171471595764, train/logprobs = tensor([[-0.9579, -3.8770],
        [-0.9564, -1.5421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09925971925258636
Epoch 0, Step 423: train/loss = 0.5553001761436462, train/raw-loss = 0.4958752393722534, train/logprobs = tensor([[-0.5732, -2.8686],
        [-0.5476, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08489280939102173
Epoch 0, Step 424: train/loss = 0.4202101230621338, train/raw-loss = 0.36092445254325867, train/logprobs = tensor([[-0.5779, -4.0459],
        [-0.7234, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08469381183385849
Epoch 0, Step 425: train/loss = 0.8800549507141113, train/raw-loss = 0.8285444378852844, train/logprobs = tensor([[-1.9074, -2.8236],
        [-0.6144, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07358650118112564
Epoch 0, Step 426: train/loss = 0.5000312924385071, train/raw-loss = 0.4292060136795044, train/logprobs = tensor([[-0.8202, -2.2980],
        [-0.9535, -0.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10117888450622559
Epoch 0, Step 427: train/loss = 0.4473060369491577, train/raw-loss = 0.390746533870697, train/logprobs = tensor([[-0.5768, -2.6362],
        [-0.6401, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08079928904771805
Epoch 0, Step 428: train/loss = 0.7231408357620239, train/raw-loss = 0.6647173166275024, train/logprobs = tensor([[-0.8412, -1.0252],
        [-0.6005, -0.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08346214890480042
Epoch 0, Step 429: train/loss = 0.43145912885665894, train/raw-loss = 0.37749776244163513, train/logprobs = tensor([[-0.5863, -2.9405],
        [-0.6880, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770876407623291
Epoch 0, Step 430: train/loss = 0.5522593855857849, train/raw-loss = 0.4998597204685211, train/logprobs = tensor([[-0.6215, -2.8910],
        [-0.6023, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07485664635896683
Epoch 0, Step 431: train/loss = 0.5362612009048462, train/raw-loss = 0.4778621792793274, train/logprobs = tensor([[-0.6833, -1.4655],
        [-0.7769, -0.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08342715352773666
Epoch 0, Step 432: train/loss = 0.6245816349983215, train/raw-loss = 0.5585488080978394, train/logprobs = tensor([[-0.7056, -1.1268],
        [-0.8208, -0.5420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09433271735906601
Epoch 0, Step 433: train/loss = 0.5886359810829163, train/raw-loss = 0.5354846119880676, train/logprobs = tensor([[-0.5960, -1.4457],
        [-0.6758, -0.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07593049108982086
Epoch 0, Step 434: train/loss = 0.40900593996047974, train/raw-loss = 0.33495858311653137, train/logprobs = tensor([[-0.7348, -3.9687],
        [-0.7815, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10578200221061707
Epoch 0, Step 435: train/loss = 0.5875304937362671, train/raw-loss = 0.5127888321876526, train/logprobs = tensor([[-1.2702, -2.5369],
        [-0.8739, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10677380859851837
Epoch 0, Step 436: train/loss = 0.47966504096984863, train/raw-loss = 0.4096393585205078, train/logprobs = tensor([[-0.7806, -3.8368],
        [-1.0027, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10003665834665298
Epoch 0, Step 437: train/loss = 0.49506404995918274, train/raw-loss = 0.42878684401512146, train/logprobs = tensor([[-0.6717, -3.2310],
        [-0.7322, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468173235654831
Epoch 0, Step 438: train/loss = 0.5255237817764282, train/raw-loss = 0.46552205085754395, train/logprobs = tensor([[-0.4987, -2.2268],
        [-0.5955, -0.5671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08571681380271912
Epoch 0, Step 439: train/loss = 0.6049385666847229, train/raw-loss = 0.5527055263519287, train/logprobs = tensor([[-0.4761, -1.1431],
        [-0.5585, -0.4417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07461865246295929
Epoch 0, Step 440: train/loss = 0.6008284091949463, train/raw-loss = 0.5422959327697754, train/logprobs = tensor([[-0.7213, -1.5665],
        [-0.6217, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08361789584159851
Epoch 0, Step 441: train/loss = 0.694282591342926, train/raw-loss = 0.6381533145904541, train/logprobs = tensor([[-0.9811, -1.4946],
        [-0.6328, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08018471300601959
Epoch 0, Step 442: train/loss = 0.6547303795814514, train/raw-loss = 0.5937865972518921, train/logprobs = tensor([[-0.5026, -0.9790],
        [-0.5201, -0.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08706256002187729
Epoch 0, Step 443: train/loss = 0.7524702548980713, train/raw-loss = 0.6971440315246582, train/logprobs = tensor([[-1.4351, -1.2619],
        [-0.8704, -0.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07903744280338287
Epoch 0, Step 444: train/loss = 0.5236905217170715, train/raw-loss = 0.45035621523857117, train/logprobs = tensor([[-0.8417, -2.3519],
        [-0.6584, -0.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10476329922676086
Epoch 0, Step 445: train/loss = 0.47041240334510803, train/raw-loss = 0.4010918438434601, train/logprobs = tensor([[-0.5557, -2.7732],
        [-0.7282, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09902938455343246
Epoch 0, Step 446: train/loss = 0.5608991384506226, train/raw-loss = 0.5023636221885681, train/logprobs = tensor([[-0.8348, -1.9967],
        [-0.7507, -0.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836222693324089
Epoch 0, Step 447: train/loss = 0.4183783233165741, train/raw-loss = 0.3506212532520294, train/logprobs = tensor([[-0.8639, -5.4209],
        [-0.7782, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679581224918365
Epoch 0, Step 448: train/loss = 0.43621379137039185, train/raw-loss = 0.36732789874076843, train/logprobs = tensor([[-0.6017, -5.0860],
        [-0.7413, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09840840101242065
Epoch 0, Step 449: train/loss = 0.6342088580131531, train/raw-loss = 0.5753865838050842, train/logprobs = tensor([[-0.7384, -1.6977],
        [-0.7378, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08403187990188599
Epoch 0, Step 450: train/loss = 0.6308889389038086, train/raw-loss = 0.5625349879264832, train/logprobs = tensor([[-0.9509, -1.7419],
        [-1.0210, -0.5090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09764860570430756
Epoch 0, Step 451: train/loss = 0.5950517654418945, train/raw-loss = 0.5299535989761353, train/logprobs = tensor([[-0.7693, -1.4813],
        [-0.7890, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09299745410680771
Epoch 0, Step 452: train/loss = 0.39838311076164246, train/raw-loss = 0.33042019605636597, train/logprobs = tensor([[-0.7082, -5.9191],
        [-0.9630, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708987176418304
Epoch 0, Step 453: train/loss = 0.40062475204467773, train/raw-loss = 0.3423987627029419, train/logprobs = tensor([[-0.6254, -4.2709],
        [-0.8238, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08317995071411133
Epoch 0, Step 454: train/loss = 0.5778576731681824, train/raw-loss = 0.527938723564148, train/logprobs = tensor([[-0.3871, -2.3716],
        [-0.4543, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07131282985210419
Epoch 0, Step 455: train/loss = 0.4216086268424988, train/raw-loss = 0.3607562780380249, train/logprobs = tensor([[-0.6100, -3.3401],
        [-0.8079, -0.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693188428878784
Epoch 0, Step 456: train/loss = 0.6706035733222961, train/raw-loss = 0.6010754108428955, train/logprobs = tensor([[-0.7787, -1.2493],
        [-0.8098, -0.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932595491409302
Epoch 0, Step 457: train/loss = 0.46564531326293945, train/raw-loss = 0.3941519856452942, train/logprobs = tensor([[-0.5326, -2.4818],
        [-0.8167, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10213332623243332
Epoch 0, Step 458: train/loss = 0.4313386082649231, train/raw-loss = 0.3629938066005707, train/logprobs = tensor([[-0.5441, -4.2320],
        [-0.7566, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09763540327548981
Epoch 0, Step 459: train/loss = 0.4703114628791809, train/raw-loss = 0.4018051326274872, train/logprobs = tensor([[-0.6648, -2.5745],
        [-0.7781, -0.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09786614775657654
Epoch 0, Step 460: train/loss = 0.5120529532432556, train/raw-loss = 0.44608139991760254, train/logprobs = tensor([[-0.6951, -2.9549],
        [-0.7778, -0.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942450612783432
Epoch 0, Step 461: train/loss = 0.5087013840675354, train/raw-loss = 0.4425467848777771, train/logprobs = tensor([[-0.8960, -2.6615],
        [-0.8812, -0.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09450654685497284
Epoch 0, Step 462: train/loss = 0.5570152401924133, train/raw-loss = 0.48918965458869934, train/logprobs = tensor([[-0.7798, -1.6561],
        [-0.8918, -0.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09689366072416306
Epoch 0, Step 463: train/loss = 0.5345027446746826, train/raw-loss = 0.47088348865509033, train/logprobs = tensor([[-0.8018, -1.8693],
        [-0.9922, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09088462591171265
Epoch 0, Step 464: train/loss = 0.41530948877334595, train/raw-loss = 0.3443945050239563, train/logprobs = tensor([[-0.5093, -3.8814],
        [-0.8299, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130715370178223
Epoch 0, Step 465: train/loss = 0.5743065476417542, train/raw-loss = 0.5089309215545654, train/logprobs = tensor([[-0.5807, -1.3931],
        [-0.8459, -0.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339365363121033
Epoch 0, Step 466: train/loss = 0.6143863201141357, train/raw-loss = 0.551539957523346, train/logprobs = tensor([[-0.8959, -2.4103],
        [-0.9163, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978056907653809
Epoch 0, Step 467: train/loss = 0.5489223003387451, train/raw-loss = 0.48897120356559753, train/logprobs = tensor([[-0.7858, -2.1972],
        [-0.7167, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08564440160989761
Epoch 0, Step 468: train/loss = 0.35824325680732727, train/raw-loss = 0.2750115990638733, train/logprobs = tensor([[-0.6659, -3.3393],
        [-1.1598, -0.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11890238523483276
Epoch 0, Step 469: train/loss = 0.5995107889175415, train/raw-loss = 0.5424178838729858, train/logprobs = tensor([[-0.5546, -1.4816],
        [-0.7954, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08156141638755798
Epoch 0, Step 470: train/loss = 0.6241999864578247, train/raw-loss = 0.5512322187423706, train/logprobs = tensor([[-0.8279, -2.1238],
        [-0.5921, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10423968732357025
Epoch 0, Step 471: train/loss = 0.38284963369369507, train/raw-loss = 0.31380990147590637, train/logprobs = tensor([[-0.4473, -4.0156],
        [-0.6389, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09862816333770752
Epoch 0, Step 472: train/loss = 0.5362992286682129, train/raw-loss = 0.4739225506782532, train/logprobs = tensor([[-0.4725, -3.1192],
        [-0.6146, -0.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08910955488681793
Epoch 0, Step 473: train/loss = 0.48193803429603577, train/raw-loss = 0.411831796169281, train/logprobs = tensor([[-0.9967, -4.3918],
        [-0.8135, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10015175491571426
Epoch 0, Step 474: train/loss = 0.504361629486084, train/raw-loss = 0.44569382071495056, train/logprobs = tensor([[-0.5634, -2.4961],
        [-0.7204, -0.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838111937046051
Epoch 0, Step 475: train/loss = 0.40985575318336487, train/raw-loss = 0.33531269431114197, train/logprobs = tensor([[-0.6639, -4.1046],
        [-0.7615, -0.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10649006813764572
Epoch 0, Step 476: train/loss = 0.5617265105247498, train/raw-loss = 0.4950656592845917, train/logprobs = tensor([[-0.4333, -1.5729],
        [-0.4629, -0.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09522981196641922
Epoch 0, Step 477: train/loss = 0.4729612171649933, train/raw-loss = 0.3914508521556854, train/logprobs = tensor([[-0.5568, -3.4733],
        [-0.6310, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11644338816404343
Epoch 0, Step 478: train/loss = 0.40791982412338257, train/raw-loss = 0.34123849868774414, train/logprobs = tensor([[-0.7268, -5.2117],
        [-0.7567, -1.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09525900334119797
Epoch 0, Step 479: train/loss = 0.5405506491661072, train/raw-loss = 0.4875652492046356, train/logprobs = tensor([[-0.3557, -3.8019],
        [-0.5022, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07569344341754913
Epoch 0, Step 480: train/loss = 0.6787868738174438, train/raw-loss = 0.6244451999664307, train/logprobs = tensor([[-0.4562, -1.0082],
        [-0.5239, -0.7490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763099670410156
Epoch 0, Step 481: train/loss = 0.3543417751789093, train/raw-loss = 0.2693679928779602, train/logprobs = tensor([[-0.8199, -5.2075],
        [-1.0861, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12139113992452621
Epoch 0, Step 482: train/loss = 0.5657116770744324, train/raw-loss = 0.505660355091095, train/logprobs = tensor([[-0.7684, -1.4400],
        [-0.9369, -0.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0857875794172287
Epoch 0, Step 483: train/loss = 0.5138635039329529, train/raw-loss = 0.450687050819397, train/logprobs = tensor([[-0.5536, -3.2646],
        [-0.7414, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025203436613083
Epoch 0, Step 484: train/loss = 0.5365312099456787, train/raw-loss = 0.45892030000686646, train/logprobs = tensor([[-0.5469, -2.2230],
        [-0.6991, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11087268590927124
Epoch 0, Step 485: train/loss = 0.3563726246356964, train/raw-loss = 0.27542588114738464, train/logprobs = tensor([[-0.9175, -5.9641],
        [-1.3199, -1.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11563818901777267
Epoch 0, Step 486: train/loss = 0.6504983305931091, train/raw-loss = 0.5871204137802124, train/logprobs = tensor([[-0.5220, -1.0740],
        [-0.6549, -0.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09053986519575119
Epoch 0, Step 487: train/loss = 0.5065035223960876, train/raw-loss = 0.43949103355407715, train/logprobs = tensor([[-0.8205, -2.9048],
        [-0.9448, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09573211520910263
Epoch 0, Step 488: train/loss = 0.5094283819198608, train/raw-loss = 0.44167768955230713, train/logprobs = tensor([[-0.5799, -4.3754],
        [-0.6752, -1.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09678678214550018
Epoch 0, Step 489: train/loss = 0.4613977372646332, train/raw-loss = 0.3832351565361023, train/logprobs = tensor([[-0.5342, -5.8693],
        [-0.9737, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11166080832481384
Epoch 0, Step 490: train/loss = 0.5875864028930664, train/raw-loss = 0.5077745914459229, train/logprobs = tensor([[-0.5225, -1.4446],
        [-0.7014, -0.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11401684582233429
Epoch 0, Step 491: train/loss = 0.49316591024398804, train/raw-loss = 0.41524839401245117, train/logprobs = tensor([[-0.8588, -4.2627],
        [-1.2568, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11131079494953156
Epoch 0, Step 492: train/loss = 0.46479707956314087, train/raw-loss = 0.38979411125183105, train/logprobs = tensor([[-0.7994, -4.1803],
        [-1.1445, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714714974164963
Epoch 0, Step 493: train/loss = 0.6385613083839417, train/raw-loss = 0.5749443769454956, train/logprobs = tensor([[-0.4010, -1.3322],
        [-0.4308, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09088128060102463
Epoch 0, Step 494: train/loss = 0.5297409296035767, train/raw-loss = 0.450650155544281, train/logprobs = tensor([[-0.7896, -1.7861],
        [-1.1620, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11298679560422897
Epoch 0, Step 495: train/loss = 0.4983125627040863, train/raw-loss = 0.4275851249694824, train/logprobs = tensor([[-0.4772, -3.6895],
        [-0.7084, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10103920102119446
Epoch 0, Step 496: train/loss = 0.5272705554962158, train/raw-loss = 0.4511142373085022, train/logprobs = tensor([[-0.5906, -2.8750],
        [-0.6606, -1.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10879474878311157
Epoch 0, Step 497: train/loss = 0.5565299391746521, train/raw-loss = 0.49958744645118713, train/logprobs = tensor([[-0.4625, -1.3163],
        [-0.6364, -0.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08134643733501434
Epoch 0, Step 498: train/loss = 0.4228082001209259, train/raw-loss = 0.3393924832344055, train/logprobs = tensor([[-0.6126, -2.5039],
        [-0.8938, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11916530877351761
Epoch 0, Step 499: train/loss = 0.48088768124580383, train/raw-loss = 0.40987762808799744, train/logprobs = tensor([[-0.6129, -3.5902],
        [-0.8508, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10144294053316116
Epoch 0, Step 500: train/loss = 0.5765993595123291, train/raw-loss = 0.5099160671234131, train/logprobs = tensor([[-0.6348, -2.4516],
        [-0.8254, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952618420124054
Epoch 0, Step 501: train/loss = 0.49836936593055725, train/raw-loss = 0.42571747303009033, train/logprobs = tensor([[-0.7168, -4.2810],
        [-0.6863, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10378842055797577
Epoch 0, Step 502: train/loss = 0.40264782309532166, train/raw-loss = 0.32772040367126465, train/logprobs = tensor([[-0.5456, -2.3764],
        [-1.0478, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1070391982793808
Epoch 0, Step 503: train/loss = 0.6933883428573608, train/raw-loss = 0.6384572982788086, train/logprobs = tensor([[-0.6095, -1.0253],
        [-0.5194, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07847296446561813
Epoch 0, Step 504: train/loss = 0.4777812957763672, train/raw-loss = 0.41208022832870483, train/logprobs = tensor([[-0.4716, -3.1768],
        [-0.5962, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09385869652032852
Epoch 0, Step 505: train/loss = 0.4407269060611725, train/raw-loss = 0.3662993013858795, train/logprobs = tensor([[-0.5735, -6.0066],
        [-0.9464, -1.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10632514953613281
Epoch 0, Step 506: train/loss = 0.605347752571106, train/raw-loss = 0.5414392948150635, train/logprobs = tensor([[-0.6011, -1.4679],
        [-0.6575, -0.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09129776060581207
Epoch 0, Step 507: train/loss = 0.5554619431495667, train/raw-loss = 0.47764918208122253, train/logprobs = tensor([[-0.8762, -5.3205],
        [-0.8575, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11116111278533936
Epoch 0, Step 508: train/loss = 0.5436198711395264, train/raw-loss = 0.4758739471435547, train/logprobs = tensor([[-0.6078, -1.9196],
        [-0.7845, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09677990525960922
Epoch 0, Step 509: train/loss = 0.604132890701294, train/raw-loss = 0.5355544090270996, train/logprobs = tensor([[-0.6632, -1.5977],
        [-0.6070, -0.5813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09796929359436035
Epoch 0, Step 510: train/loss = 0.520294189453125, train/raw-loss = 0.4455578327178955, train/logprobs = tensor([[-0.7356, -3.1683],
        [-0.9136, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1067662462592125
Epoch 0, Step 511: train/loss = 0.5446693301200867, train/raw-loss = 0.47562530636787415, train/logprobs = tensor([[-0.7211, -2.8263],
        [-0.7759, -0.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09863432496786118
Epoch 0, Step 512: train/loss = 0.5021288394927979, train/raw-loss = 0.4416106343269348, train/logprobs = tensor([[-0.6939, -1.9945],
        [-1.1007, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08645455539226532
Epoch 0, Step 513: train/loss = 0.5311944484710693, train/raw-loss = 0.4643864631652832, train/logprobs = tensor([[-0.4179, -2.9744],
        [-0.5593, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09543999284505844
Epoch 0, Step 514: train/loss = 0.4208245575428009, train/raw-loss = 0.3402574360370636, train/logprobs = tensor([[-0.6256, -4.2641],
        [-0.9935, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11509586125612259
Epoch 0, Step 515: train/loss = 0.7325478196144104, train/raw-loss = 0.6738062500953674, train/logprobs = tensor([[-0.5078, -0.5746],
        [-0.5677, -0.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0839165598154068
Epoch 0, Step 516: train/loss = 0.45438796281814575, train/raw-loss = 0.3826689124107361, train/logprobs = tensor([[-0.6825, -2.6051],
        [-1.1138, -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10245576500892639
Epoch 0, Step 517: train/loss = 0.4878265857696533, train/raw-loss = 0.41858500242233276, train/logprobs = tensor([[-0.5619, -2.2475],
        [-0.7610, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09891654551029205
Epoch 0, Step 518: train/loss = 0.4140549898147583, train/raw-loss = 0.3430716395378113, train/logprobs = tensor([[-0.7197, -5.1659],
        [-1.4435, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10140477120876312
Epoch 0, Step 519: train/loss = 0.40042930841445923, train/raw-loss = 0.3219012916088104, train/logprobs = tensor([[-0.8076, -3.4532],
        [-0.9821, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11218290030956268
Epoch 0, Step 520: train/loss = 0.7385557293891907, train/raw-loss = 0.679556667804718, train/logprobs = tensor([[-0.8807, -0.9553],
        [-0.7426, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08428439497947693
Epoch 0, Step 521: train/loss = 0.509911298751831, train/raw-loss = 0.45339441299438477, train/logprobs = tensor([[-0.3503, -2.3232],
        [-0.5032, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08073843270540237
Epoch 0, Step 522: train/loss = 0.6014376878738403, train/raw-loss = 0.5349012613296509, train/logprobs = tensor([[-1.1466, -2.9946],
        [-0.8445, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09505201876163483
Epoch 0, Step 523: train/loss = 0.553229808807373, train/raw-loss = 0.4900817573070526, train/logprobs = tensor([[-0.4657, -1.9804],
        [-0.5863, -0.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09021146595478058
Epoch 0, Step 524: train/loss = 0.3674246072769165, train/raw-loss = 0.2906220257282257, train/logprobs = tensor([[-0.4443, -5.9292],
        [-0.7925, -1.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10971801728010178
Epoch 0, Step 525: train/loss = 0.5742754340171814, train/raw-loss = 0.5049536824226379, train/logprobs = tensor([[-0.5893, -1.7271],
        [-0.7866, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09903106093406677
Epoch 0, Step 526: train/loss = 0.5225058197975159, train/raw-loss = 0.4646165072917938, train/logprobs = tensor([[-0.3774, -1.6767],
        [-0.6160, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08269903063774109
Epoch 0, Step 527: train/loss = 0.3288905918598175, train/raw-loss = 0.26162540912628174, train/logprobs = tensor([[-0.5598, -3.9300],
        [-0.9782, -0.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609313309192657
Epoch 0, Step 528: train/loss = 0.41918307542800903, train/raw-loss = 0.3560982942581177, train/logprobs = tensor([[-0.3492, -5.2786],
        [-0.4497, -1.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09012104570865631
Epoch 0, Step 529: train/loss = 0.4615844190120697, train/raw-loss = 0.3882899880409241, train/logprobs = tensor([[-0.6208, -4.4157],
        [-0.8736, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470634698867798
Epoch 0, Step 530: train/loss = 0.6196514964103699, train/raw-loss = 0.5441218018531799, train/logprobs = tensor([[-0.5650, -1.6400],
        [-0.9583, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10789956152439117
Epoch 0, Step 531: train/loss = 0.5934063196182251, train/raw-loss = 0.5319439768791199, train/logprobs = tensor([[-0.3992, -1.3122],
        [-0.5789, -0.6770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08780334889888763
Epoch 0, Step 532: train/loss = 0.5429672002792358, train/raw-loss = 0.47205251455307007, train/logprobs = tensor([[-0.5889, -2.8275],
        [-0.9581, -0.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130669921636581
Epoch 0, Step 533: train/loss = 0.4941696226596832, train/raw-loss = 0.4169054329395294, train/logprobs = tensor([[-0.7575, -3.2656],
        [-0.8868, -1.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11037741601467133
Epoch 0, Step 534: train/loss = 0.5727154612541199, train/raw-loss = 0.5004434585571289, train/logprobs = tensor([[-0.4610, -2.2046],
        [-0.6682, -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10324568301439285
Epoch 0, Step 535: train/loss = 0.4164258539676666, train/raw-loss = 0.3303700387477875, train/logprobs = tensor([[-0.7688, -3.7603],
        [-1.2236, -1.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12293685972690582
Epoch 0, Step 536: train/loss = 0.460662841796875, train/raw-loss = 0.393073707818985, train/logprobs = tensor([[-0.6307, -2.3652],
        [-0.8319, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0965559333562851
Epoch 0, Step 537: train/loss = 0.44234418869018555, train/raw-loss = 0.3724452257156372, train/logprobs = tensor([[-0.6094, -2.3142],
        [-1.0437, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09985566139221191
Epoch 0, Step 538: train/loss = 0.43778693675994873, train/raw-loss = 0.3599696159362793, train/logprobs = tensor([[-0.7171, -4.0898],
        [-0.7054, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11116763204336166
Epoch 0, Step 539: train/loss = 0.4971136450767517, train/raw-loss = 0.43933767080307007, train/logprobs = tensor([[-0.3975, -3.2205],
        [-0.6107, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08253711462020874
Epoch 0, Step 540: train/loss = 0.5368643999099731, train/raw-loss = 0.46320855617523193, train/logprobs = tensor([[-0.6172, -2.6368],
        [-1.0241, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522262752056122
Epoch 0, Step 541: train/loss = 0.3900480270385742, train/raw-loss = 0.3132081627845764, train/logprobs = tensor([[-0.7756, -5.4321],
        [-1.3254, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977122187614441
Epoch 0, Step 542: train/loss = 0.4456762671470642, train/raw-loss = 0.38422322273254395, train/logprobs = tensor([[-0.6374, -2.7396],
        [-0.9015, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08779003471136093
Epoch 0, Step 543: train/loss = 0.45916199684143066, train/raw-loss = 0.3910362720489502, train/logprobs = tensor([[-0.5729, -4.4829],
        [-0.7148, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097322478890419
Epoch 0, Step 544: train/loss = 0.5500416159629822, train/raw-loss = 0.476157546043396, train/logprobs = tensor([[-0.5911, -1.8495],
        [-0.7918, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554872453212738
Epoch 0, Step 545: train/loss = 0.44225090742111206, train/raw-loss = 0.37004709243774414, train/logprobs = tensor([[-0.5919, -2.7465],
        [-1.1324, -0.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314839333295822
Epoch 0, Step 546: train/loss = 0.4604831337928772, train/raw-loss = 0.39608901739120483, train/logprobs = tensor([[-0.4415, -2.6733],
        [-0.7082, -0.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09199155122041702
Epoch 0, Step 547: train/loss = 0.4473310112953186, train/raw-loss = 0.37440529465675354, train/logprobs = tensor([[-0.6136, -4.2445],
        [-0.8231, -1.2680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10417961329221725
Epoch 0, Step 548: train/loss = 0.578709602355957, train/raw-loss = 0.5119534730911255, train/logprobs = tensor([[-0.4619, -1.2139],
        [-0.7151, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09536584466695786
Epoch 0, Step 549: train/loss = 0.5299502015113831, train/raw-loss = 0.4566994905471802, train/logprobs = tensor([[-0.8270, -1.9562],
        [-1.2120, -0.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10464388132095337
Epoch 0, Step 550: train/loss = 0.42085978388786316, train/raw-loss = 0.33865082263946533, train/logprobs = tensor([[-0.9080, -4.0091],
        [-1.3480, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1174413412809372
Epoch 0, Step 551: train/loss = 0.5754404067993164, train/raw-loss = 0.5083154439926147, train/logprobs = tensor([[-0.6040, -1.6882],
        [-0.7703, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09589291363954544
Epoch 0, Step 552: train/loss = 0.4345426559448242, train/raw-loss = 0.35988661646842957, train/logprobs = tensor([[-0.6648, -2.7465],
        [-1.1369, -0.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10665144771337509
Epoch 0, Step 553: train/loss = 0.4923402667045593, train/raw-loss = 0.4245014488697052, train/logprobs = tensor([[-0.4466, -2.5624],
        [-0.7709, -1.3451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09691259264945984
Epoch 0, Step 554: train/loss = 0.4310658276081085, train/raw-loss = 0.3655488193035126, train/logprobs = tensor([[-0.4940, -4.0045],
        [-0.7025, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09359574317932129
Epoch 0, Step 555: train/loss = 0.48514795303344727, train/raw-loss = 0.4191765785217285, train/logprobs = tensor([[-0.8996, -2.8933],
        [-0.8842, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09424476325511932
Epoch 0, Step 556: train/loss = 0.4625668227672577, train/raw-loss = 0.38829612731933594, train/logprobs = tensor([[-0.4405, -3.7309],
        [-0.7009, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610106587409973
Epoch 0, Step 557: train/loss = 0.4772798418998718, train/raw-loss = 0.39732763171195984, train/logprobs = tensor([[-0.7725, -3.5278],
        [-1.1679, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421746015548706
Epoch 0, Step 558: train/loss = 0.668381929397583, train/raw-loss = 0.5974110960960388, train/logprobs = tensor([[-0.6398, -1.0589],
        [-0.8252, -0.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138685256242752
Epoch 0, Step 559: train/loss = 0.4890134930610657, train/raw-loss = 0.41772156953811646, train/logprobs = tensor([[-0.5697, -2.5909],
        [-0.6642, -0.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10184566676616669
Epoch 0, Step 560: train/loss = 0.581565797328949, train/raw-loss = 0.5253058075904846, train/logprobs = tensor([[-0.3469, -1.7085],
        [-0.4197, -0.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08037140965461731
Epoch 0, Step 561: train/loss = 0.5258250832557678, train/raw-loss = 0.45428818464279175, train/logprobs = tensor([[-0.4999, -1.8833],
        [-0.9262, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10219554603099823
Epoch 0, Step 562: train/loss = 0.47552210092544556, train/raw-loss = 0.4035967290401459, train/logprobs = tensor([[-0.6409, -3.4173],
        [-0.9858, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10275056958198547
Epoch 0, Step 563: train/loss = 0.520585298538208, train/raw-loss = 0.4605099558830261, train/logprobs = tensor([[-0.4201, -2.8515],
        [-0.6043, -0.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08582187443971634
Epoch 0, Step 564: train/loss = 0.5558932423591614, train/raw-loss = 0.4819453954696655, train/logprobs = tensor([[-0.6136, -1.5389],
        [-0.9170, -0.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056397333741188
Epoch 0, Step 565: train/loss = 0.42993247509002686, train/raw-loss = 0.3527844250202179, train/logprobs = tensor([[-0.8924, -3.0115],
        [-1.3606, -1.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11021148413419724
Epoch 0, Step 566: train/loss = 0.5116071105003357, train/raw-loss = 0.44204404950141907, train/logprobs = tensor([[-0.4585, -6.2409],
        [-0.6516, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09937580674886703
Epoch 0, Step 567: train/loss = 0.4090869128704071, train/raw-loss = 0.3367341160774231, train/logprobs = tensor([[-0.5253, -3.0339],
        [-1.0268, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336113721132278
Epoch 0, Step 568: train/loss = 0.5853075981140137, train/raw-loss = 0.5063503980636597, train/logprobs = tensor([[-0.5460, -2.7505],
        [-0.9412, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127961128950119
Epoch 0, Step 569: train/loss = 0.41885948181152344, train/raw-loss = 0.3333192467689514, train/logprobs = tensor([[-0.7640, -2.1443],
        [-1.4242, -0.6653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12220033258199692
Epoch 0, Step 570: train/loss = 0.6810612678527832, train/raw-loss = 0.6051121950149536, train/logprobs = tensor([[-1.2853, -2.0996],
        [-0.9203, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10849860310554504
Epoch 0, Step 571: train/loss = 0.4534927010536194, train/raw-loss = 0.3833003342151642, train/logprobs = tensor([[-0.5722, -3.3933],
        [-0.6395, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10027478635311127
Epoch 0, Step 572: train/loss = 0.47043466567993164, train/raw-loss = 0.40277957916259766, train/logprobs = tensor([[-0.3789, -2.3679],
        [-0.5101, -0.7575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665016829967499
Epoch 0, Step 573: train/loss = 0.4287909269332886, train/raw-loss = 0.35472387075424194, train/logprobs = tensor([[-0.5342, -3.2856],
        [-0.7136, -0.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10581012070178986
Epoch 0, Step 574: train/loss = 0.5977321863174438, train/raw-loss = 0.5341650247573853, train/logprobs = tensor([[-0.4825, -1.2435],
        [-0.6893, -0.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09081027656793594
Epoch 0, Step 575: train/loss = 0.41920006275177, train/raw-loss = 0.3433438539505005, train/logprobs = tensor([[-0.5678, -3.5576],
        [-1.0904, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1083659678697586
Epoch 0, Step 576: train/loss = 0.5624933838844299, train/raw-loss = 0.4749290347099304, train/logprobs = tensor([[-0.7682, -1.5994],
        [-1.1035, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12509189546108246
Epoch 0, Step 577: train/loss = 0.6481859087944031, train/raw-loss = 0.5653218030929565, train/logprobs = tensor([[-0.7023, -1.4309],
        [-0.9682, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11837731301784515
Epoch 0, Step 578: train/loss = 0.4095774292945862, train/raw-loss = 0.32806891202926636, train/logprobs = tensor([[-0.6952, -3.7523],
        [-1.2638, -0.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11644071340560913
Epoch 0, Step 579: train/loss = 0.4391155242919922, train/raw-loss = 0.3699699640274048, train/logprobs = tensor([[-0.7584, -4.3823],
        [-1.0374, -1.3387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987793505191803
Epoch 0, Step 580: train/loss = 0.4747365415096283, train/raw-loss = 0.4123745560646057, train/logprobs = tensor([[-0.9767, -5.0840],
        [-0.9006, -1.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0890885442495346
Epoch 0, Step 581: train/loss = 0.4194470942020416, train/raw-loss = 0.3459473252296448, train/logprobs = tensor([[-0.6535, -6.4224],
        [-1.0673, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10499969869852066
Epoch 0, Step 582: train/loss = 0.5602216124534607, train/raw-loss = 0.49475932121276855, train/logprobs = tensor([[-0.6082, -1.5663],
        [-0.9939, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935174897313118
Epoch 0, Step 583: train/loss = 0.5677672624588013, train/raw-loss = 0.500241756439209, train/logprobs = tensor([[-0.7342, -2.0626],
        [-0.7592, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09646497666835785
Epoch 0, Step 584: train/loss = 0.5405834317207336, train/raw-loss = 0.4810791611671448, train/logprobs = tensor([[-0.4822, -1.8186],
        [-0.7521, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500606566667557
Epoch 0, Step 585: train/loss = 0.5829066038131714, train/raw-loss = 0.5194746255874634, train/logprobs = tensor([[-0.3019, -1.8164],
        [-0.4763, -0.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09061713516712189
Epoch 0, Step 586: train/loss = 0.48511895537376404, train/raw-loss = 0.40320080518722534, train/logprobs = tensor([[-0.6942, -1.7876],
        [-1.2096, -0.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11702591180801392
Epoch 0, Step 587: train/loss = 0.562706470489502, train/raw-loss = 0.5013072490692139, train/logprobs = tensor([[-0.5903, -1.3477],
        [-0.8562, -0.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771312981843948
Epoch 0, Step 588: train/loss = 0.4357587695121765, train/raw-loss = 0.36935389041900635, train/logprobs = tensor([[-0.7142, -4.6660],
        [-1.2625, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09486410021781921
Epoch 0, Step 589: train/loss = 0.45687806606292725, train/raw-loss = 0.3818780481815338, train/logprobs = tensor([[-0.5863, -2.8898],
        [-1.0165, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714292526245117
Epoch 0, Step 590: train/loss = 0.3820944130420685, train/raw-loss = 0.313610315322876, train/logprobs = tensor([[-0.4806, -3.8392],
        [-0.7386, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783448278903961
Epoch 0, Step 591: train/loss = 0.6970983743667603, train/raw-loss = 0.6320070028305054, train/logprobs = tensor([[-0.6115, -0.7082],
        [-0.7155, -0.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09298767894506454
Epoch 0, Step 592: train/loss = 0.5500043034553528, train/raw-loss = 0.4831603467464447, train/logprobs = tensor([[-0.5493, -1.6027],
        [-0.7927, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.095491424202919
Epoch 0, Step 593: train/loss = 0.4943280816078186, train/raw-loss = 0.4249321222305298, train/logprobs = tensor([[-0.4865, -2.3916],
        [-0.8026, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991370901465416
Epoch 0, Step 594: train/loss = 0.3975898027420044, train/raw-loss = 0.3119308352470398, train/logprobs = tensor([[-0.6638, -2.8409],
        [-1.0378, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12236995249986649
Epoch 0, Step 595: train/loss = 0.5677877068519592, train/raw-loss = 0.49742329120635986, train/logprobs = tensor([[-0.5265, -1.7086],
        [-0.7415, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10052057355642319
Epoch 0, Step 596: train/loss = 0.5108166337013245, train/raw-loss = 0.4407496750354767, train/logprobs = tensor([[-0.6785, -3.8023],
        [-0.9386, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10009565949440002
Epoch 0, Step 597: train/loss = 0.6712441444396973, train/raw-loss = 0.6060914397239685, train/logprobs = tensor([[-0.6262, -0.8745],
        [-0.8898, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09307518601417542
Epoch 0, Step 598: train/loss = 0.4794829785823822, train/raw-loss = 0.3927473723888397, train/logprobs = tensor([[-0.9091, -2.9686],
        [-0.9463, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12390801310539246
Epoch 0, Step 599: train/loss = 0.48190799355506897, train/raw-loss = 0.4052272439002991, train/logprobs = tensor([[-0.4937, -3.7180],
        [-0.7455, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954388976097107
Epoch 0, Step 600: train/loss = 0.5164591670036316, train/raw-loss = 0.44755715131759644, train/logprobs = tensor([[-0.4473, -2.5126],
        [-0.6615, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843140840530396
Epoch 0, Step 601: train/loss = 0.519785463809967, train/raw-loss = 0.44543299078941345, train/logprobs = tensor([[-0.7971, -1.9211],
        [-1.2112, -1.0266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10621783137321472
Epoch 0, Step 602: train/loss = 0.5506775379180908, train/raw-loss = 0.46539193391799927, train/logprobs = tensor([[-0.8677, -2.3109],
        [-0.9775, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12183665484189987
Epoch 0, Step 603: train/loss = 0.36310574412345886, train/raw-loss = 0.2859545648097992, train/logprobs = tensor([[-0.5192, -5.1107],
        [-0.8949, -1.1182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11021596938371658
Epoch 0, Step 604: train/loss = 0.5804484486579895, train/raw-loss = 0.5133514404296875, train/logprobs = tensor([[-0.3720, -1.3164],
        [-0.5993, -0.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09585286676883698
Epoch 0, Step 605: train/loss = 0.5664008259773254, train/raw-loss = 0.4975658655166626, train/logprobs = tensor([[-0.6505, -0.9889],
        [-1.1881, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09833565354347229
Epoch 0, Step 606: train/loss = 0.510669469833374, train/raw-loss = 0.44492483139038086, train/logprobs = tensor([[-0.5945, -1.8169],
        [-0.7355, -0.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09392086416482925
Epoch 0, Step 607: train/loss = 0.48785603046417236, train/raw-loss = 0.407329797744751, train/logprobs = tensor([[-0.6390, -2.6216],
        [-0.8434, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150374636054039
Epoch 0, Step 608: train/loss = 0.4921475648880005, train/raw-loss = 0.41624391078948975, train/logprobs = tensor([[-0.5349, -2.2867],
        [-1.0012, -0.7805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843377560377121
Epoch 0, Step 609: train/loss = 0.4034733772277832, train/raw-loss = 0.3282299339771271, train/logprobs = tensor([[-0.7599, -5.3769],
        [-1.2827, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074906438589096
Epoch 0, Step 610: train/loss = 0.3345448672771454, train/raw-loss = 0.23803624510765076, train/logprobs = tensor([[-0.9410, -6.0368],
        [-1.5065, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378694474697113
Epoch 0, Step 611: train/loss = 0.3596024215221405, train/raw-loss = 0.29361164569854736, train/logprobs = tensor([[-0.4814, -3.4341],
        [-0.7635, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09427256882190704
Epoch 0, Step 612: train/loss = 0.5995708703994751, train/raw-loss = 0.5211235284805298, train/logprobs = tensor([[-0.6256, -3.2466],
        [-0.8633, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11206761747598648
Epoch 0, Step 613: train/loss = 0.6287586688995361, train/raw-loss = 0.5508303642272949, train/logprobs = tensor([[-0.6726, -1.6458],
        [-0.8884, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11132609099149704
Epoch 0, Step 614: train/loss = 0.5146246552467346, train/raw-loss = 0.43642348051071167, train/logprobs = tensor([[-0.6157, -1.9087],
        [-0.8442, -0.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171592026948929
Epoch 0, Step 615: train/loss = 0.5172789096832275, train/raw-loss = 0.4381386637687683, train/logprobs = tensor([[-0.5706, -1.8600],
        [-1.0048, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11305752396583557
Epoch 0, Step 616: train/loss = 0.6800368428230286, train/raw-loss = 0.6111312508583069, train/logprobs = tensor([[-0.4546, -0.8681],
        [-0.6833, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843660891056061
Epoch 0, Step 617: train/loss = 0.5119524002075195, train/raw-loss = 0.44874584674835205, train/logprobs = tensor([[-0.6139, -3.6674],
        [-0.8080, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09029509872198105
Epoch 0, Step 618: train/loss = 0.4900909960269928, train/raw-loss = 0.4154692590236664, train/logprobs = tensor([[-0.5021, -2.2685],
        [-0.9093, -0.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10660246014595032
Epoch 0, Step 619: train/loss = 0.4075395166873932, train/raw-loss = 0.33773720264434814, train/logprobs = tensor([[-0.4525, -3.9015],
        [-0.7896, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09971757233142853
Epoch 0, Step 620: train/loss = 0.4251117706298828, train/raw-loss = 0.34321901202201843, train/logprobs = tensor([[-0.7125, -2.8456],
        [-1.2009, -0.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1169896349310875
Epoch 0, Step 621: train/loss = 0.6469384431838989, train/raw-loss = 0.5808120965957642, train/logprobs = tensor([[-0.6304, -0.7686],
        [-0.8837, -0.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446615725755692
Epoch 0, Step 622: train/loss = 0.5001185536384583, train/raw-loss = 0.4281764030456543, train/logprobs = tensor([[-0.4115, -4.0954],
        [-0.8169, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1027744933962822
Epoch 0, Step 623: train/loss = 0.4619396924972534, train/raw-loss = 0.39081090688705444, train/logprobs = tensor([[-0.5520, -4.3756],
        [-0.8863, -1.0130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10161258280277252
Epoch 0, Step 624: train/loss = 0.5105197429656982, train/raw-loss = 0.434135764837265, train/logprobs = tensor([[-0.5088, -2.6554],
        [-0.9692, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10911998152732849
Epoch 0, Step 625: train/loss = 0.5305423736572266, train/raw-loss = 0.4502999782562256, train/logprobs = tensor([[-0.5616, -3.5824],
        [-0.7256, -1.1045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1146320253610611
Epoch 0, Step 626: train/loss = 0.533228874206543, train/raw-loss = 0.46218180656433105, train/logprobs = tensor([[-0.4993, -1.8707],
        [-0.8020, -0.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10149587690830231
Epoch 0, Step 627: train/loss = 0.5099703073501587, train/raw-loss = 0.43278008699417114, train/logprobs = tensor([[-0.4206, -1.7757],
        [-0.8960, -0.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11027181148529053
Epoch 0, Step 628: train/loss = 0.4810631573200226, train/raw-loss = 0.4072173535823822, train/logprobs = tensor([[-0.4378, -2.1129],
        [-0.8682, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10549403727054596
Epoch 0, Step 629: train/loss = 0.5463855862617493, train/raw-loss = 0.4748656153678894, train/logprobs = tensor([[-0.3647, -1.5140],
        [-0.6744, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1021714136004448
Epoch 0, Step 630: train/loss = 0.4639948606491089, train/raw-loss = 0.3940761983394623, train/logprobs = tensor([[-0.3940, -3.0315],
        [-0.6079, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988383948802948
Epoch 0, Step 631: train/loss = 0.3693239390850067, train/raw-loss = 0.29102659225463867, train/logprobs = tensor([[-1.1067, -4.5449],
        [-1.4154, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11185336112976074
Epoch 0, Step 632: train/loss = 0.5239416360855103, train/raw-loss = 0.43038904666900635, train/logprobs = tensor([[-0.7280, -3.1832],
        [-0.9845, -0.8398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336466372013092
Epoch 0, Step 633: train/loss = 0.4103829860687256, train/raw-loss = 0.3338896334171295, train/logprobs = tensor([[-0.6888, -4.0004],
        [-0.9947, -1.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10927622020244598
Epoch 0, Step 634: train/loss = 0.45318371057510376, train/raw-loss = 0.3694002330303192, train/logprobs = tensor([[-0.4664, -3.2001],
        [-0.9780, -0.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196906566619873
Epoch 0, Step 635: train/loss = 0.4211082458496094, train/raw-loss = 0.3445822298526764, train/logprobs = tensor([[-0.4980, -3.9175],
        [-0.9621, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1093229204416275
Epoch 0, Step 636: train/loss = 0.5332713723182678, train/raw-loss = 0.4638388156890869, train/logprobs = tensor([[-0.5036, -2.7420],
        [-0.7153, -0.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09918931871652603
Epoch 0, Step 637: train/loss = 0.46594682335853577, train/raw-loss = 0.4025079011917114, train/logprobs = tensor([[-0.5837, -3.5063],
        [-0.7781, -0.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09062707424163818
Epoch 0, Step 638: train/loss = 0.6676211357116699, train/raw-loss = 0.5972652435302734, train/logprobs = tensor([[-0.5020, -0.9532],
        [-0.6509, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005084216594696
Epoch 0, Step 639: train/loss = 0.49521195888519287, train/raw-loss = 0.4123169183731079, train/logprobs = tensor([[-0.7925, -2.7807],
        [-1.0717, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11842147260904312
Epoch 0, Step 640: train/loss = 0.43772703409194946, train/raw-loss = 0.3707459568977356, train/logprobs = tensor([[-0.4935, -4.1858],
        [-0.6846, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09568718075752258
Epoch 0, Step 641: train/loss = 0.6408800482749939, train/raw-loss = 0.5682382583618164, train/logprobs = tensor([[-1.1067, -2.6445],
        [-0.8990, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10377402603626251
Epoch 0, Step 642: train/loss = 0.453585147857666, train/raw-loss = 0.3764153718948364, train/logprobs = tensor([[-0.7845, -3.1758],
        [-0.9591, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11024248600006104
Epoch 0, Step 643: train/loss = 0.36956435441970825, train/raw-loss = 0.2943563461303711, train/logprobs = tensor([[-0.5106, -4.7828],
        [-0.8818, -0.7779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10744000971317291
Epoch 0, Step 644: train/loss = 0.5979422330856323, train/raw-loss = 0.519666850566864, train/logprobs = tensor([[-0.8858, -1.1074],
        [-1.2361, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11182202398777008
Epoch 0, Step 645: train/loss = 0.4732992649078369, train/raw-loss = 0.40653347969055176, train/logprobs = tensor([[-1.0780, -4.7158],
        [-1.5420, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09537975490093231
Epoch 0, Step 646: train/loss = 0.6395506858825684, train/raw-loss = 0.568425178527832, train/logprobs = tensor([[-0.4908, -0.9503],
        [-0.7776, -0.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10160782933235168
Epoch 0, Step 647: train/loss = 0.5243154764175415, train/raw-loss = 0.45681384205818176, train/logprobs = tensor([[-0.5544, -2.3438],
        [-0.8582, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09643088281154633
Epoch 0, Step 648: train/loss = 0.46286541223526, train/raw-loss = 0.38569507002830505, train/logprobs = tensor([[-0.5998, -4.1635],
        [-1.0078, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102433130145073
Epoch 0, Step 649: train/loss = 0.3192669749259949, train/raw-loss = 0.24270302057266235, train/logprobs = tensor([[-0.5706, -5.4944],
        [-1.2750, -0.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10937710851430893
Epoch 0, Step 650: train/loss = 0.38590049743652344, train/raw-loss = 0.3093458414077759, train/logprobs = tensor([[-0.5640, -4.8872],
        [-1.0110, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10936377197504044
Epoch 0, Step 651: train/loss = 0.3490152657032013, train/raw-loss = 0.2689706087112427, train/logprobs = tensor([[-0.8007, -4.3167],
        [-1.2225, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11434948444366455
Epoch 0, Step 652: train/loss = 0.43401312828063965, train/raw-loss = 0.37913191318511963, train/logprobs = tensor([[-0.9907, -6.4850],
        [-1.0957, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840172946453094
Epoch 0, Step 653: train/loss = 0.5159308314323425, train/raw-loss = 0.45113682746887207, train/logprobs = tensor([[-0.6690, -2.3926],
        [-0.9654, -0.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256292134523392
Epoch 0, Step 654: train/loss = 0.6304412484169006, train/raw-loss = 0.5675378441810608, train/logprobs = tensor([[-0.5587, -1.9744],
        [-0.5930, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986201882362366
Epoch 0, Step 655: train/loss = 0.4383603632450104, train/raw-loss = 0.35129332542419434, train/logprobs = tensor([[-0.7624, -2.9253],
        [-1.2942, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12438144534826279
Epoch 0, Step 656: train/loss = 0.32108649611473083, train/raw-loss = 0.24493464827537537, train/logprobs = tensor([[-0.9148, -7.4899],
        [-1.2508, -1.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10878836363554001
Epoch 0, Step 657: train/loss = 0.40148741006851196, train/raw-loss = 0.3309572637081146, train/logprobs = tensor([[-0.5848, -4.7416],
        [-0.9362, -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10075731575489044
Epoch 0, Step 658: train/loss = 0.5221332311630249, train/raw-loss = 0.44134873151779175, train/logprobs = tensor([[-0.8079, -2.8437],
        [-1.0642, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11540645360946655
Epoch 0, Step 659: train/loss = 0.3267078399658203, train/raw-loss = 0.24205127358436584, train/logprobs = tensor([[-0.4670, -4.2116],
        [-0.9830, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12093793600797653
Epoch 0, Step 660: train/loss = 0.6242720484733582, train/raw-loss = 0.5492690801620483, train/logprobs = tensor([[-0.7017, -1.7334],
        [-0.6852, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714707523584366
Epoch 0, Step 661: train/loss = 0.47266969084739685, train/raw-loss = 0.39421775937080383, train/logprobs = tensor([[-0.5216, -3.6578],
        [-0.9235, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11207421123981476
Epoch 0, Step 662: train/loss = 0.5945723056793213, train/raw-loss = 0.5361565351486206, train/logprobs = tensor([[-0.5657, -1.4097],
        [-0.7104, -0.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08345108479261398
Epoch 0, Step 663: train/loss = 0.49591872096061707, train/raw-loss = 0.42640525102615356, train/logprobs = tensor([[-0.8536, -4.8508],
        [-0.7739, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930495172739029
Epoch 0, Step 664: train/loss = 0.5065925121307373, train/raw-loss = 0.4350028932094574, train/logprobs = tensor([[-0.6490, -1.9648],
        [-0.9777, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10227081179618835
Epoch 0, Step 665: train/loss = 0.5546389222145081, train/raw-loss = 0.4752015471458435, train/logprobs = tensor([[-0.8510, -1.6446],
        [-0.9443, -0.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11348193138837814
Epoch 0, Step 666: train/loss = 0.4643779397010803, train/raw-loss = 0.38960060477256775, train/logprobs = tensor([[-0.7179, -3.5559],
        [-1.2461, -0.7554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10682478547096252
Epoch 0, Step 667: train/loss = 0.5022205114364624, train/raw-loss = 0.429045170545578, train/logprobs = tensor([[-0.6127, -3.1422],
        [-1.0505, -0.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10453622788190842
Epoch 0, Step 668: train/loss = 0.5975619554519653, train/raw-loss = 0.5216957330703735, train/logprobs = tensor([[-0.5572, -1.2555],
        [-0.9088, -0.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1083802878856659
Epoch 0, Step 669: train/loss = 0.3874562382698059, train/raw-loss = 0.31988540291786194, train/logprobs = tensor([[-0.5671, -4.1529],
        [-0.9408, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09652978181838989
Epoch 0, Step 670: train/loss = 0.43567174673080444, train/raw-loss = 0.37124723196029663, train/logprobs = tensor([[-0.7750, -4.4206],
        [-0.9294, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09203503280878067
Epoch 0, Step 671: train/loss = 0.46542179584503174, train/raw-loss = 0.39720550179481506, train/logprobs = tensor([[-0.7476, -3.0362],
        [-0.8003, -0.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745187312364578
Epoch 0, Step 672: train/loss = 0.5221580862998962, train/raw-loss = 0.45860084891319275, train/logprobs = tensor([[-0.6465, -3.1185],
        [-0.9604, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09079606086015701
Epoch 0, Step 673: train/loss = 0.4916039705276489, train/raw-loss = 0.4114387035369873, train/logprobs = tensor([[-0.5444, -3.1276],
        [-0.9158, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11452179402112961
Epoch 0, Step 674: train/loss = 0.4583856463432312, train/raw-loss = 0.3905453085899353, train/logprobs = tensor([[-0.3860, -2.2853],
        [-0.7928, -0.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09691479802131653
Epoch 0, Step 675: train/loss = 0.44290849566459656, train/raw-loss = 0.3505951762199402, train/logprobs = tensor([[-0.5713, -2.5121],
        [-1.1450, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13187623023986816
Epoch 0, Step 676: train/loss = 0.38568001985549927, train/raw-loss = 0.31273025274276733, train/logprobs = tensor([[-0.4284, -5.7319],
        [-0.9462, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421393811702728
Epoch 0, Step 677: train/loss = 0.5425445437431335, train/raw-loss = 0.46270811557769775, train/logprobs = tensor([[-0.4022, -2.4561],
        [-0.7210, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11405202746391296
Epoch 0, Step 678: train/loss = 0.4194828271865845, train/raw-loss = 0.32977285981178284, train/logprobs = tensor([[-0.5476, -4.3776],
        [-1.1483, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281570941209793
Epoch 0, Step 679: train/loss = 0.36176180839538574, train/raw-loss = 0.2870045006275177, train/logprobs = tensor([[-0.7813, -3.6782],
        [-1.0502, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10679617524147034
Epoch 0, Step 680: train/loss = 0.41970115900039673, train/raw-loss = 0.35517990589141846, train/logprobs = tensor([[-0.5591, -4.5933],
        [-0.8825, -0.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09217321127653122
Epoch 0, Step 681: train/loss = 0.42497122287750244, train/raw-loss = 0.34496814012527466, train/logprobs = tensor([[-0.4865, -2.9789],
        [-0.9221, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11429010331630707
Epoch 0, Step 682: train/loss = 0.6009602546691895, train/raw-loss = 0.515544593334198, train/logprobs = tensor([[-0.9231, -2.0733],
        [-0.8637, -0.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12202233076095581
Epoch 0, Step 683: train/loss = 0.597983717918396, train/raw-loss = 0.5071887969970703, train/logprobs = tensor([[-0.7819, -1.9013],
        [-1.2363, -0.7822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12970709800720215
Epoch 0, Step 684: train/loss = 0.42916834354400635, train/raw-loss = 0.36094194650650024, train/logprobs = tensor([[-0.5317, -3.8916],
        [-0.8931, -0.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09746627509593964
Epoch 0, Step 685: train/loss = 0.47070667147636414, train/raw-loss = 0.3962019085884094, train/logprobs = tensor([[-0.4832, -2.8860],
        [-0.8476, -0.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1064353883266449
Epoch 0, Step 686: train/loss = 0.5467255711555481, train/raw-loss = 0.45144352316856384, train/logprobs = tensor([[-1.0728, -2.5331],
        [-1.1904, -0.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13611727952957153
Epoch 0, Step 687: train/loss = 0.48638463020324707, train/raw-loss = 0.42753565311431885, train/logprobs = tensor([[-0.7365, -2.7662],
        [-0.9342, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08407001197338104
Epoch 0, Step 688: train/loss = 0.3029611110687256, train/raw-loss = 0.2181490957736969, train/logprobs = tensor([[-0.5183, -4.9105],
        [-1.0714, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12116007506847382
Epoch 0, Step 689: train/loss = 0.39490142464637756, train/raw-loss = 0.3252905607223511, train/logprobs = tensor([[-0.4978, -4.9232],
        [-1.0523, -0.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09944407641887665
Epoch 0, Step 690: train/loss = 0.5028904676437378, train/raw-loss = 0.4491681158542633, train/logprobs = tensor([[-0.3385, -3.1038],
        [-0.5318, -0.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07674622535705566
Epoch 0, Step 691: train/loss = 0.3947286605834961, train/raw-loss = 0.31647682189941406, train/logprobs = tensor([[-0.7228, -4.8074],
        [-1.6014, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11178840696811676
Epoch 0, Step 692: train/loss = 0.43943747878074646, train/raw-loss = 0.3678029179573059, train/logprobs = tensor([[-0.4607, -2.4369],
        [-0.8229, -0.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10233508795499802
Epoch 0, Step 693: train/loss = 0.46134594082832336, train/raw-loss = 0.3942660093307495, train/logprobs = tensor([[-0.5330, -2.3942],
        [-0.8411, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09582843631505966
Epoch 0, Step 694: train/loss = 0.3924694061279297, train/raw-loss = 0.3199777901172638, train/logprobs = tensor([[-0.6755, -4.8354],
        [-0.9673, -1.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035594493150711
Epoch 0, Step 695: train/loss = 0.6011560559272766, train/raw-loss = 0.523912787437439, train/logprobs = tensor([[-0.6057, -1.5847],
        [-1.0391, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11034755408763885
Epoch 0, Step 696: train/loss = 0.4787135124206543, train/raw-loss = 0.3989824652671814, train/logprobs = tensor([[-0.5603, -3.3536],
        [-1.2462, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11390145123004913
Epoch 0, Step 697: train/loss = 0.47797760367393494, train/raw-loss = 0.4064689874649048, train/logprobs = tensor([[-0.3850, -1.9345],
        [-0.7271, -0.4760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10215513408184052
Epoch 0, Step 698: train/loss = 0.5045828819274902, train/raw-loss = 0.4285508990287781, train/logprobs = tensor([[-0.6085, -2.7193],
        [-1.1505, -0.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10861711949110031
Epoch 0, Step 699: train/loss = 0.32190537452697754, train/raw-loss = 0.24567154049873352, train/logprobs = tensor([[-0.7291, -5.1470],
        [-1.5016, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10890547931194305
Epoch 0, Step 700: train/loss = 0.45532792806625366, train/raw-loss = 0.38061589002609253, train/logprobs = tensor([[-0.8473, -5.2712],
        [-0.9789, -1.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673145949840546
Epoch 0, Step 701: train/loss = 0.4261654317378998, train/raw-loss = 0.3443009555339813, train/logprobs = tensor([[-0.6829, -4.0832],
        [-0.9375, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694923043251038
Epoch 0, Step 702: train/loss = 0.5101215243339539, train/raw-loss = 0.4458042085170746, train/logprobs = tensor([[-0.5277, -1.9025],
        [-0.8420, -0.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918818861246109
Epoch 0, Step 703: train/loss = 0.5811554789543152, train/raw-loss = 0.5061081647872925, train/logprobs = tensor([[-0.6029, -1.9787],
        [-0.9722, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072104424238205
Epoch 0, Step 704: train/loss = 0.3286839723587036, train/raw-loss = 0.250152587890625, train/logprobs = tensor([[-0.9073, -7.7330],
        [-1.5850, -1.5686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121876984834671
Epoch 0, Step 705: train/loss = 0.3191111385822296, train/raw-loss = 0.2277757227420807, train/logprobs = tensor([[-0.9014, -4.6935],
        [-1.4426, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13047918677330017
Epoch 0, Step 706: train/loss = 0.5026282668113708, train/raw-loss = 0.44765955209732056, train/logprobs = tensor([[-0.4424, -3.3503],
        [-0.6226, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07852677255868912
Epoch 0, Step 707: train/loss = 0.45380979776382446, train/raw-loss = 0.3731704652309418, train/logprobs = tensor([[-0.6339, -3.1148],
        [-0.9635, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11519904434680939
Epoch 0, Step 708: train/loss = 0.4826890230178833, train/raw-loss = 0.41460180282592773, train/logprobs = tensor([[-0.5456, -3.2380],
        [-0.7932, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09726755321025848
Epoch 0, Step 709: train/loss = 0.24151989817619324, train/raw-loss = 0.15384317934513092, train/logprobs = tensor([[-0.7023, -6.7702],
        [-1.6840, -1.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12525245547294617
Epoch 0, Step 710: train/loss = 0.36399996280670166, train/raw-loss = 0.2852010428905487, train/logprobs = tensor([[-0.6281, -3.8756],
        [-1.2439, -0.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256994307041168
Epoch 0, Step 711: train/loss = 0.5321752429008484, train/raw-loss = 0.45678436756134033, train/logprobs = tensor([[-0.4726, -2.3293],
        [-0.9129, -0.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10770126432180405
Epoch 0, Step 712: train/loss = 0.4735482633113861, train/raw-loss = 0.4007132053375244, train/logprobs = tensor([[-0.6877, -3.2309],
        [-1.1482, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10405008494853973
Epoch 0, Step 713: train/loss = 0.4054192900657654, train/raw-loss = 0.3297647535800934, train/logprobs = tensor([[-0.7486, -5.2879],
        [-1.1235, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10807789862155914
Epoch 0, Step 714: train/loss = 0.5350691676139832, train/raw-loss = 0.46974459290504456, train/logprobs = tensor([[-0.8249, -4.1807],
        [-0.9571, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.093320831656456
Epoch 0, Step 715: train/loss = 0.3673439621925354, train/raw-loss = 0.2960033118724823, train/logprobs = tensor([[-0.5838, -5.6399],
        [-0.8428, -1.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191522538661957
Epoch 0, Step 716: train/loss = 0.5961508750915527, train/raw-loss = 0.5217788815498352, train/logprobs = tensor([[-0.6173, -1.4771],
        [-0.9444, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10624576359987259
Epoch 0, Step 717: train/loss = 0.4950386881828308, train/raw-loss = 0.42253944277763367, train/logprobs = tensor([[-0.6445, -3.5645],
        [-1.2697, -1.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10357034206390381
Epoch 0, Step 718: train/loss = 0.5278887748718262, train/raw-loss = 0.45574116706848145, train/logprobs = tensor([[-0.9385, -2.7858],
        [-1.1424, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10306799411773682
Epoch 0, Step 719: train/loss = 0.5188601016998291, train/raw-loss = 0.4509027898311615, train/logprobs = tensor([[-0.4356, -1.8391],
        [-0.7511, -0.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708191454410553
Epoch 0, Step 720: train/loss = 0.4213457405567169, train/raw-loss = 0.3355986475944519, train/logprobs = tensor([[-0.6188, -3.2282],
        [-1.1366, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1224958598613739
Epoch 0, Step 721: train/loss = 0.4740135669708252, train/raw-loss = 0.37989550828933716, train/logprobs = tensor([[-0.7243, -2.8074],
        [-0.9608, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344543844461441
Epoch 0, Step 722: train/loss = 0.7351672053337097, train/raw-loss = 0.6719968914985657, train/logprobs = tensor([[-0.6000, -0.6805],
        [-0.6438, -0.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09024326503276825
Epoch 0, Step 723: train/loss = 0.4385640621185303, train/raw-loss = 0.32984378933906555, train/logprobs = tensor([[-0.9135, -3.4689],
        [-1.1951, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15531468391418457
Epoch 0, Step 724: train/loss = 0.377885103225708, train/raw-loss = 0.3108943700790405, train/logprobs = tensor([[-0.5518, -5.7425],
        [-1.0124, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09570105373859406
Epoch 0, Step 725: train/loss = 0.5949807167053223, train/raw-loss = 0.5256967544555664, train/logprobs = tensor([[-0.9447, -3.0619],
        [-0.7816, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09897702187299728
Epoch 0, Step 726: train/loss = 0.34546127915382385, train/raw-loss = 0.2742044925689697, train/logprobs = tensor([[-0.4369, -5.7169],
        [-0.7776, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10179541260004044
Epoch 0, Step 727: train/loss = 0.5737982988357544, train/raw-loss = 0.5032232999801636, train/logprobs = tensor([[-1.0575, -3.7413],
        [-0.7938, -1.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10082149505615234
Epoch 0, Step 728: train/loss = 0.2884187698364258, train/raw-loss = 0.20671424269676208, train/logprobs = tensor([[-0.6602, -8.4375],
        [-1.4861, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672070622444153
Epoch 0, Step 729: train/loss = 0.6295318603515625, train/raw-loss = 0.5454816818237305, train/logprobs = tensor([[-1.2458, -2.2982],
        [-1.1932, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12007172405719757
Epoch 0, Step 730: train/loss = 0.5436360239982605, train/raw-loss = 0.48133349418640137, train/logprobs = tensor([[-0.3347, -1.7384],
        [-0.5552, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08900362253189087
Epoch 0, Step 731: train/loss = 0.5458277463912964, train/raw-loss = 0.47581952810287476, train/logprobs = tensor([[-0.5738, -2.1574],
        [-0.7838, -0.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001175105571747
Epoch 0, Step 732: train/loss = 0.5666238069534302, train/raw-loss = 0.484674334526062, train/logprobs = tensor([[-0.5419, -2.0463],
        [-0.9050, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707063019275665
Epoch 0, Step 733: train/loss = 0.5058444142341614, train/raw-loss = 0.4389178156852722, train/logprobs = tensor([[-0.5801, -3.8581],
        [-0.8285, -0.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09560937434434891
Epoch 0, Step 734: train/loss = 0.5328068733215332, train/raw-loss = 0.4529169797897339, train/logprobs = tensor([[-0.8059, -2.2997],
        [-1.0989, -0.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11412842571735382
Epoch 0, Step 735: train/loss = 0.7066633701324463, train/raw-loss = 0.6368155479431152, train/logprobs = tensor([[-0.7798, -1.1309],
        [-0.7284, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09978262335062027
Epoch 0, Step 736: train/loss = 0.6532207727432251, train/raw-loss = 0.5956130623817444, train/logprobs = tensor([[-0.3800, -1.1057],
        [-0.5425, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229672163724899
Epoch 0, Step 737: train/loss = 0.3453633189201355, train/raw-loss = 0.2574348449707031, train/logprobs = tensor([[-0.6705, -3.1585],
        [-1.4808, -0.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256120800971985
Epoch 0, Step 738: train/loss = 0.5968354940414429, train/raw-loss = 0.522124171257019, train/logprobs = tensor([[-0.6407, -1.8425],
        [-1.1978, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673058032989502
Epoch 0, Step 739: train/loss = 0.3776320815086365, train/raw-loss = 0.30113929510116577, train/logprobs = tensor([[-1.0620, -3.3389],
        [-1.8242, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10927543044090271
Epoch 0, Step 740: train/loss = 0.28442278504371643, train/raw-loss = 0.20476359128952026, train/logprobs = tensor([[-0.6820, -4.5937],
        [-1.2945, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11379887163639069
Epoch 0, Step 741: train/loss = 0.32216542959213257, train/raw-loss = 0.21455782651901245, train/logprobs = tensor([[-0.7855, -6.3508],
        [-1.4151, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15372514724731445
Epoch 0, Step 742: train/loss = 0.5049638748168945, train/raw-loss = 0.4319363236427307, train/logprobs = tensor([[-0.4753, -2.4633],
        [-0.7825, -0.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10432508587837219
Epoch 0, Step 743: train/loss = 0.3604491651058197, train/raw-loss = 0.2858744263648987, train/logprobs = tensor([[-0.8845, -7.1982],
        [-1.4182, -1.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10653536766767502
Epoch 0, Step 744: train/loss = 0.6420549750328064, train/raw-loss = 0.5743039846420288, train/logprobs = tensor([[-0.5335, -0.8667],
        [-0.7342, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09678716212511063
Epoch 0, Step 745: train/loss = 0.4485686421394348, train/raw-loss = 0.3791210353374481, train/logprobs = tensor([[-0.3794, -2.4921],
        [-0.6797, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09921085834503174
Epoch 0, Step 746: train/loss = 0.711517333984375, train/raw-loss = 0.6351937055587769, train/logprobs = tensor([[-0.5964, -0.6660],
        [-0.7846, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10903383791446686
Epoch 0, Step 747: train/loss = 0.5149204730987549, train/raw-loss = 0.4528634548187256, train/logprobs = tensor([[-0.5277, -2.0168],
        [-0.6785, -0.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0886528491973877
Epoch 0, Step 748: train/loss = 0.6088842153549194, train/raw-loss = 0.5389983654022217, train/logprobs = tensor([[-0.4493, -1.1479],
        [-0.8707, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09983693808317184
Epoch 0, Step 749: train/loss = 0.5054052472114563, train/raw-loss = 0.43051421642303467, train/logprobs = tensor([[-0.8232, -3.6944],
        [-1.1355, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10698723047971725
Epoch 0, Step 750: train/loss = 0.4768707752227783, train/raw-loss = 0.40724241733551025, train/logprobs = tensor([[-0.8891, -4.6130],
        [-1.6205, -1.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09946900606155396
Epoch 0, Step 751: train/loss = 0.6071310043334961, train/raw-loss = 0.534265398979187, train/logprobs = tensor([[-0.6500, -2.7960],
        [-0.7377, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10409371554851532
Epoch 0, Step 752: train/loss = 0.5554420948028564, train/raw-loss = 0.48326700925827026, train/logprobs = tensor([[-0.4526, -2.8219],
        [-0.8261, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10310725122690201
Epoch 0, Step 753: train/loss = 0.4169965088367462, train/raw-loss = 0.33819907903671265, train/logprobs = tensor([[-0.5259, -2.6359],
        [-0.7907, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256773769855499
Epoch 0, Step 754: train/loss = 0.4396857023239136, train/raw-loss = 0.360787570476532, train/logprobs = tensor([[-0.6587, -2.7380],
        [-1.0642, -0.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11271156370639801
Epoch 0, Step 755: train/loss = 0.4023010730743408, train/raw-loss = 0.3121436834335327, train/logprobs = tensor([[-0.7826, -5.9422],
        [-1.4101, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287963092327118
Epoch 0, Step 756: train/loss = 0.4801076650619507, train/raw-loss = 0.4041730761528015, train/logprobs = tensor([[-0.8917, -4.1472],
        [-1.2666, -0.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10847793519496918
Epoch 0, Step 757: train/loss = 0.559465229511261, train/raw-loss = 0.4747920334339142, train/logprobs = tensor([[-0.5447, -3.6922],
        [-0.8942, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1209617331624031
Epoch 0, Step 758: train/loss = 0.38650667667388916, train/raw-loss = 0.30734044313430786, train/logprobs = tensor([[-0.5109, -5.3024],
        [-1.0094, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11309462785720825
Epoch 0, Step 759: train/loss = 0.4834982752799988, train/raw-loss = 0.407302588224411, train/logprobs = tensor([[-0.6071, -3.5670],
        [-0.8102, -0.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10885100066661835
Epoch 0, Step 760: train/loss = 0.5662075281143188, train/raw-loss = 0.4941536486148834, train/logprobs = tensor([[-1.1002, -3.4108],
        [-1.0930, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293411463499069
Epoch 0, Step 761: train/loss = 0.677317202091217, train/raw-loss = 0.6057136058807373, train/logprobs = tensor([[-1.1642, -1.2683],
        [-1.2945, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229089111089706
Epoch 0, Step 762: train/loss = 0.5068398714065552, train/raw-loss = 0.4237311780452728, train/logprobs = tensor([[-0.5332, -2.5524],
        [-0.9948, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872673779726028
Epoch 0, Step 763: train/loss = 0.44916102290153503, train/raw-loss = 0.3556464910507202, train/logprobs = tensor([[-0.7748, -2.7079],
        [-1.1669, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13359221816062927
Epoch 0, Step 764: train/loss = 0.5782555341720581, train/raw-loss = 0.5088210105895996, train/logprobs = tensor([[-0.6126, -1.4049],
        [-0.9237, -0.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09919217973947525
Epoch 0, Step 765: train/loss = 0.45132869482040405, train/raw-loss = 0.3819403350353241, train/logprobs = tensor([[-0.7029, -4.8707],
        [-1.1580, -1.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09912622720003128
Epoch 0, Step 766: train/loss = 0.37012478709220886, train/raw-loss = 0.27475929260253906, train/logprobs = tensor([[-0.7660, -3.3820],
        [-1.1906, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13623642921447754
Epoch 0, Step 767: train/loss = 0.5888814926147461, train/raw-loss = 0.5021780729293823, train/logprobs = tensor([[-0.5816, -1.7190],
        [-0.8166, -0.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12386198341846466
Epoch 0, Step 768: train/loss = 0.6775169372558594, train/raw-loss = 0.6177694797515869, train/logprobs = tensor([[-0.4597, -0.7751],
        [-0.5987, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08535350859165192
Epoch 0, Step 769: train/loss = 0.45399993658065796, train/raw-loss = 0.37927502393722534, train/logprobs = tensor([[-0.8237, -2.8837],
        [-0.9865, -0.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10674988478422165
Epoch 0, Step 770: train/loss = 0.507946789264679, train/raw-loss = 0.4433787763118744, train/logprobs = tensor([[-0.4647, -1.8691],
        [-0.6263, -0.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09224002808332443
Epoch 0, Step 771: train/loss = 0.35805487632751465, train/raw-loss = 0.286555677652359, train/logprobs = tensor([[-0.5913, -4.8790],
        [-0.7847, -1.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214168578386307
Epoch 0, Step 772: train/loss = 0.37638652324676514, train/raw-loss = 0.2942867577075958, train/logprobs = tensor([[-0.9122, -3.5476],
        [-1.1525, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728537082672119
Epoch 0, Step 773: train/loss = 0.48160409927368164, train/raw-loss = 0.40876391530036926, train/logprobs = tensor([[-0.8730, -3.7504],
        [-0.8993, -1.2652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1040574386715889
Epoch 0, Step 774: train/loss = 0.5129485726356506, train/raw-loss = 0.4448353052139282, train/logprobs = tensor([[-0.9437, -2.2580],
        [-1.0243, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09730472415685654
Epoch 0, Step 775: train/loss = 0.6998928785324097, train/raw-loss = 0.6226760745048523, train/logprobs = tensor([[-2.2724, -7.1372],
        [-1.2313, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11030988395214081
Epoch 0, Step 776: train/loss = 0.36355695128440857, train/raw-loss = 0.30291759967803955, train/logprobs = tensor([[-0.6904, -5.7191],
        [-1.0932, -1.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08662761002779007
Epoch 0, Step 777: train/loss = 0.5241549015045166, train/raw-loss = 0.45937028527259827, train/logprobs = tensor([[-0.5030, -2.1777],
        [-0.8213, -0.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09254943579435349
Epoch 0, Step 778: train/loss = 0.4254879951477051, train/raw-loss = 0.3442801237106323, train/logprobs = tensor([[-0.6428, -3.5722],
        [-0.9335, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11601124703884125
Epoch 0, Step 779: train/loss = 0.540614128112793, train/raw-loss = 0.46653056144714355, train/logprobs = tensor([[-0.7565, -3.9426],
        [-0.6979, -0.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10583359003067017
Epoch 0, Step 780: train/loss = 0.6222964525222778, train/raw-loss = 0.560825526714325, train/logprobs = tensor([[-0.5517, -1.7741],
        [-0.5187, -0.9987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08781570196151733
Epoch 0, Step 781: train/loss = 0.5451289415359497, train/raw-loss = 0.4730755686759949, train/logprobs = tensor([[-0.8558, -2.1508],
        [-1.0938, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1029333621263504
Epoch 0, Step 782: train/loss = 0.43176108598709106, train/raw-loss = 0.33299845457077026, train/logprobs = tensor([[-1.2955, -6.4755],
        [-1.2729, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141089528799057
Epoch 0, Step 783: train/loss = 0.37098246812820435, train/raw-loss = 0.2849915325641632, train/logprobs = tensor([[-0.5935, -3.7564],
        [-0.8972, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12284418195486069
Epoch 0, Step 784: train/loss = 0.31232041120529175, train/raw-loss = 0.23192596435546875, train/logprobs = tensor([[-0.7071, -9.5329],
        [-1.1121, -1.3168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11484920978546143
Epoch 0, Step 785: train/loss = 0.5366338491439819, train/raw-loss = 0.4854881465435028, train/logprobs = tensor([[-0.3358, -2.5628],
        [-0.4394, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07306526601314545
Epoch 0, Step 786: train/loss = 0.34090763330459595, train/raw-loss = 0.26582086086273193, train/logprobs = tensor([[-0.5404, -6.2418],
        [-0.7538, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10726674646139145
Epoch 0, Step 787: train/loss = 0.5319522023200989, train/raw-loss = 0.4551509618759155, train/logprobs = tensor([[-0.5640, -2.2664],
        [-0.8218, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10971611738204956
Epoch 0, Step 788: train/loss = 0.4322243928909302, train/raw-loss = 0.34376370906829834, train/logprobs = tensor([[-0.6166, -6.3652],
        [-0.8980, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12637239694595337
Epoch 0, Step 789: train/loss = 0.6364768743515015, train/raw-loss = 0.5709202885627747, train/logprobs = tensor([[-0.7279, -1.5796],
        [-0.6440, -0.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09365220367908478
Epoch 0, Step 790: train/loss = 0.5550064444541931, train/raw-loss = 0.47172486782073975, train/logprobs = tensor([[-0.6396, -2.3256],
        [-0.7278, -0.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11897366493940353
Epoch 0, Step 791: train/loss = 0.5998528003692627, train/raw-loss = 0.5324367880821228, train/logprobs = tensor([[-0.8542, -1.8218],
        [-0.9837, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963086485862732
Epoch 0, Step 792: train/loss = 0.4352855682373047, train/raw-loss = 0.35788410902023315, train/logprobs = tensor([[-0.6347, -3.4214],
        [-1.0888, -0.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057351529598236
Epoch 0, Step 793: train/loss = 0.518821120262146, train/raw-loss = 0.43806830048561096, train/logprobs = tensor([[-0.7213, -6.6163],
        [-0.9411, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11536118388175964
Epoch 0, Step 794: train/loss = 0.39751601219177246, train/raw-loss = 0.3056510090827942, train/logprobs = tensor([[-0.6787, -4.4526],
        [-1.0211, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13123568892478943
Epoch 0, Step 795: train/loss = 0.43962353467941284, train/raw-loss = 0.37186503410339355, train/logprobs = tensor([[-0.8640, -3.9757],
        [-0.9248, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679779410362244
Epoch 0, Step 796: train/loss = 0.37645602226257324, train/raw-loss = 0.2932915687561035, train/logprobs = tensor([[-0.7169, -6.2922],
        [-1.0577, -1.3600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11880636215209961
Epoch 0, Step 797: train/loss = 0.546683669090271, train/raw-loss = 0.48368901014328003, train/logprobs = tensor([[-0.5302, -1.5804],
        [-0.6956, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08999230712652206
Epoch 0, Step 798: train/loss = 0.5010654926300049, train/raw-loss = 0.433553010225296, train/logprobs = tensor([[-0.7071, -4.7776],
        [-0.7080, -0.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09644642472267151
Epoch 0, Step 799: train/loss = 0.5460753440856934, train/raw-loss = 0.4599192142486572, train/logprobs = tensor([[-1.1916, -5.4114],
        [-1.2302, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12308019399642944
Epoch 0, Step 800: train/loss = 0.6617890000343323, train/raw-loss = 0.5982818603515625, train/logprobs = tensor([[-0.9980, -1.6480],
        [-0.9488, -0.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09072446078062057
Epoch 0, Step 801: train/loss = 0.3097016215324402, train/raw-loss = 0.22138197720050812, train/logprobs = tensor([[-0.9277, -7.1309],
        [-1.3901, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12617091834545135
Epoch 0, Step 802: train/loss = 0.5015074014663696, train/raw-loss = 0.44448092579841614, train/logprobs = tensor([[-0.7415, -2.4023],
        [-0.8387, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08146632462739944
Epoch 0, Step 803: train/loss = 0.4123319983482361, train/raw-loss = 0.35035550594329834, train/logprobs = tensor([[-0.6735, -4.0283],
        [-0.8917, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08853782713413239
Epoch 0, Step 804: train/loss = 0.5325505137443542, train/raw-loss = 0.4561052918434143, train/logprobs = tensor([[-0.6969, -3.1475],
        [-0.9445, -0.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10920746624469757
Epoch 0, Step 805: train/loss = 0.5323269367218018, train/raw-loss = 0.46846750378608704, train/logprobs = tensor([[-0.5068, -2.5059],
        [-0.7146, -0.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09122776985168457
Epoch 0, Step 806: train/loss = 0.44586485624313354, train/raw-loss = 0.3657935559749603, train/logprobs = tensor([[-0.8414, -5.5921],
        [-1.0481, -1.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11438760906457901
Epoch 0, Step 807: train/loss = 0.38744574785232544, train/raw-loss = 0.31046241521835327, train/logprobs = tensor([[-0.7048, -6.4664],
        [-0.9741, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10997620224952698
Epoch 0, Step 808: train/loss = 0.37586015462875366, train/raw-loss = 0.3090367317199707, train/logprobs = tensor([[-0.5454, -3.8309],
        [-0.8751, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09546202421188354
Epoch 0, Step 809: train/loss = 0.4137864112854004, train/raw-loss = 0.3394967019557953, train/logprobs = tensor([[-0.6250, -5.6130],
        [-0.9008, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10612815618515015
Epoch 0, Step 810: train/loss = 0.3768119215965271, train/raw-loss = 0.29439398646354675, train/logprobs = tensor([[-0.6002, -4.3453],
        [-0.9241, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11773991584777832
Epoch 0, Step 811: train/loss = 0.5208743214607239, train/raw-loss = 0.4499545097351074, train/logprobs = tensor([[-0.6344, -3.4410],
        [-0.7336, -0.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10131397843360901
Epoch 0, Step 812: train/loss = 0.5791632533073425, train/raw-loss = 0.5151239633560181, train/logprobs = tensor([[-0.7367, -2.2344],
        [-0.9052, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09148473292589188
Epoch 0, Step 813: train/loss = 0.5723072290420532, train/raw-loss = 0.5071929693222046, train/logprobs = tensor([[-0.7521, -1.7642],
        [-0.6822, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09302041679620743
Epoch 0, Step 814: train/loss = 0.31655362248420715, train/raw-loss = 0.25292107462882996, train/logprobs = tensor([[-0.7710, -5.3485],
        [-1.5699, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09090365469455719
Epoch 0, Step 815: train/loss = 0.5043171644210815, train/raw-loss = 0.42924565076828003, train/logprobs = tensor([[-0.7193, -2.4945],
        [-0.7567, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10724502801895142
Epoch 0, Step 816: train/loss = 0.3340908885002136, train/raw-loss = 0.275071382522583, train/logprobs = tensor([[-0.3699, -7.1322],
        [-0.5212, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08431357890367508
Epoch 0, Step 817: train/loss = 0.4643968641757965, train/raw-loss = 0.3901776075363159, train/logprobs = tensor([[-0.9069, -5.1602],
        [-1.1665, -1.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060274988412857
Epoch 0, Step 818: train/loss = 0.35473477840423584, train/raw-loss = 0.2831278145313263, train/logprobs = tensor([[-0.6250, -9.1529],
        [-0.9959, -1.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229562222957611
Epoch 0, Step 819: train/loss = 0.41045674681663513, train/raw-loss = 0.34398555755615234, train/logprobs = tensor([[-0.3624, -4.2976],
        [-0.6438, -0.7123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949588268995285
Epoch 0, Step 820: train/loss = 0.4655947685241699, train/raw-loss = 0.3856334388256073, train/logprobs = tensor([[-0.8872, -3.2901],
        [-0.9798, -0.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11423049867153168
Epoch 0, Step 821: train/loss = 0.4829663634300232, train/raw-loss = 0.4102814793586731, train/logprobs = tensor([[-0.6456, -2.5479],
        [-1.0157, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038355827331543
Epoch 0, Step 822: train/loss = 0.5204446315765381, train/raw-loss = 0.4575475752353668, train/logprobs = tensor([[-0.6850, -2.7379],
        [-0.7871, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0898529663681984
Epoch 0, Step 823: train/loss = 0.5134384036064148, train/raw-loss = 0.45135390758514404, train/logprobs = tensor([[-0.9572, -5.6524],
        [-0.8145, -1.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08869214355945587
Epoch 0, Step 824: train/loss = 0.4204786419868469, train/raw-loss = 0.34752577543258667, train/logprobs = tensor([[-0.5428, -5.3309],
        [-0.8873, -0.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421836376190186
Epoch 0, Step 825: train/loss = 0.7363629341125488, train/raw-loss = 0.6710781455039978, train/logprobs = tensor([[-0.9458, -0.5570],
        [-1.1490, -0.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09326401352882385
Epoch 0, Step 826: train/loss = 0.44001010060310364, train/raw-loss = 0.36215680837631226, train/logprobs = tensor([[-0.9364, -3.3683],
        [-1.1965, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11121898144483566
Epoch 0, Step 827: train/loss = 0.4696086049079895, train/raw-loss = 0.40373826026916504, train/logprobs = tensor([[-0.4730, -2.6925],
        [-0.5883, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09410044550895691
Epoch 0, Step 828: train/loss = 0.390064001083374, train/raw-loss = 0.3040490746498108, train/logprobs = tensor([[-0.7950, -3.4153],
        [-1.2803, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12287846207618713
Epoch 0, Step 829: train/loss = 0.5590958595275879, train/raw-loss = 0.4831106960773468, train/logprobs = tensor([[-0.9259, -3.4768],
        [-0.9394, -1.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10855027288198471
Epoch 0, Step 830: train/loss = 0.4248132109642029, train/raw-loss = 0.3625270128250122, train/logprobs = tensor([[-0.3853, -5.2978],
        [-0.5946, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0889802798628807
Epoch 0, Step 831: train/loss = 0.4094730615615845, train/raw-loss = 0.3503716289997101, train/logprobs = tensor([[-0.5641, -2.4346],
        [-0.8578, -0.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08443061262369156
Epoch 0, Step 832: train/loss = 0.45736783742904663, train/raw-loss = 0.383958101272583, train/logprobs = tensor([[-0.6760, -2.6461],
        [-1.1800, -0.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10487103462219238
Epoch 0, Step 833: train/loss = 0.6487549543380737, train/raw-loss = 0.5837268829345703, train/logprobs = tensor([[-0.6894, -1.1680],
        [-0.6796, -0.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928971916437149
Epoch 0, Step 834: train/loss = 0.40406501293182373, train/raw-loss = 0.32593590021133423, train/logprobs = tensor([[-0.9687, -6.5181],
        [-1.2295, -1.0755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11161302775144577
Epoch 0, Step 835: train/loss = 0.6675402522087097, train/raw-loss = 0.6161292195320129, train/logprobs = tensor([[-0.9778, -4.0566],
        [-0.8380, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07344435155391693
Epoch 0, Step 836: train/loss = 0.4888768196105957, train/raw-loss = 0.41261669993400574, train/logprobs = tensor([[-0.6887, -5.2880],
        [-0.8792, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10894304513931274
Epoch 0, Step 837: train/loss = 0.4550860524177551, train/raw-loss = 0.38175615668296814, train/logprobs = tensor([[-0.4819, -2.5578],
        [-0.6633, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10475697368383408
Epoch 0, Step 838: train/loss = 0.4456614851951599, train/raw-loss = 0.3734889328479767, train/logprobs = tensor([[-0.6648, -3.4228],
        [-0.8692, -0.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1031036227941513
Epoch 0, Step 839: train/loss = 0.3747484087944031, train/raw-loss = 0.30939748883247375, train/logprobs = tensor([[-0.5568, -5.0988],
        [-0.9459, -1.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335848689079285
Epoch 0, Step 840: train/loss = 0.40407419204711914, train/raw-loss = 0.31520068645477295, train/logprobs = tensor([[-0.6193, -6.0294],
        [-1.1157, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12696217000484467
Epoch 0, Step 841: train/loss = 0.5814632177352905, train/raw-loss = 0.5091644525527954, train/logprobs = tensor([[-0.6169, -2.2198],
        [-0.7951, -0.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10328387469053268
Epoch 0, Step 842: train/loss = 0.4213811457157135, train/raw-loss = 0.3451046645641327, train/logprobs = tensor([[-0.5247, -6.4396],
        [-1.0791, -1.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10896642506122589
Epoch 0, Step 843: train/loss = 0.4551248550415039, train/raw-loss = 0.3793385326862335, train/logprobs = tensor([[-0.9312, -3.9257],
        [-0.8401, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10826613008975983
Epoch 0, Step 844: train/loss = 0.5186371803283691, train/raw-loss = 0.440948486328125, train/logprobs = tensor([[-1.3423, -5.7805],
        [-0.9867, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098387092351913
Epoch 0, Step 845: train/loss = 0.40969982743263245, train/raw-loss = 0.33096688985824585, train/logprobs = tensor([[-0.7352, -7.1982],
        [-1.0678, -1.3178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11247566342353821
Epoch 0, Step 846: train/loss = 0.3824760913848877, train/raw-loss = 0.317691445350647, train/logprobs = tensor([[-0.5417, -8.3955],
        [-0.7979, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09254948794841766
Epoch 0, Step 847: train/loss = 0.4805065393447876, train/raw-loss = 0.4095655679702759, train/logprobs = tensor([[-0.8170, -3.9547],
        [-0.9879, -0.8381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10134424269199371
Epoch 0, Step 848: train/loss = 0.3436959683895111, train/raw-loss = 0.25356096029281616, train/logprobs = tensor([[-0.7727, -5.2128],
        [-1.3638, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12876427173614502
Epoch 0, Step 849: train/loss = 0.3590071201324463, train/raw-loss = 0.27946051955223083, train/logprobs = tensor([[-1.2496, -7.9010],
        [-1.3489, -1.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1136380210518837
Epoch 0, Step 850: train/loss = 0.474485844373703, train/raw-loss = 0.40267789363861084, train/logprobs = tensor([[-0.5602, -3.9450],
        [-0.7429, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258276760578156
Epoch 0, Step 851: train/loss = 0.4062739610671997, train/raw-loss = 0.330003023147583, train/logprobs = tensor([[-0.8454, -6.1045],
        [-1.2608, -1.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10895850509405136
Epoch 0, Step 852: train/loss = 0.429412841796875, train/raw-loss = 0.3645358979701996, train/logprobs = tensor([[-0.4981, -3.9509],
        [-0.8664, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09268135577440262
Epoch 0, Step 853: train/loss = 0.6036154627799988, train/raw-loss = 0.5433117151260376, train/logprobs = tensor([[-1.0909, -3.7851],
        [-1.1657, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861482173204422
Epoch 0, Step 854: train/loss = 0.4329908490180969, train/raw-loss = 0.35637572407722473, train/logprobs = tensor([[-0.7477, -4.8425],
        [-1.0368, -0.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10945017635822296
Epoch 0, Step 855: train/loss = 0.44332438707351685, train/raw-loss = 0.3755708932876587, train/logprobs = tensor([[-0.7595, -4.6505],
        [-1.0880, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679068624973297
Epoch 0, Step 856: train/loss = 0.3448597192764282, train/raw-loss = 0.26970532536506653, train/logprobs = tensor([[-0.7848, -4.1346],
        [-1.2640, -0.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10736340284347534
Epoch 0, Step 857: train/loss = 0.4127628207206726, train/raw-loss = 0.3283771574497223, train/logprobs = tensor([[-0.6208, -6.0044],
        [-1.0872, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12055099010467529
Epoch 0, Step 858: train/loss = 0.6384838819503784, train/raw-loss = 0.5523637533187866, train/logprobs = tensor([[-1.6878, -2.9815],
        [-1.1489, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12302881479263306
Epoch 0, Step 859: train/loss = 0.4203895628452301, train/raw-loss = 0.35593903064727783, train/logprobs = tensor([[-0.7873, -3.5785],
        [-1.1350, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09207217395305634
Epoch 0, Step 860: train/loss = 0.4886242151260376, train/raw-loss = 0.41862356662750244, train/logprobs = tensor([[-0.7337, -3.8971],
        [-0.8876, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10000091791152954
Epoch 0, Step 861: train/loss = 0.6149588823318481, train/raw-loss = 0.5406588315963745, train/logprobs = tensor([[-0.8602, -3.4444],
        [-0.7727, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10614285618066788
Epoch 0, Step 862: train/loss = 0.4146067500114441, train/raw-loss = 0.33265864849090576, train/logprobs = tensor([[-0.7396, -5.6560],
        [-0.9164, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11706874519586563
Epoch 0, Step 863: train/loss = 0.5716148614883423, train/raw-loss = 0.4944559633731842, train/logprobs = tensor([[-0.8903, -3.7598],
        [-0.8848, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11022699624300003
Epoch 0, Step 864: train/loss = 0.7045727968215942, train/raw-loss = 0.63310706615448, train/logprobs = tensor([[-1.1868, -2.0955],
        [-0.8484, -0.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1020938903093338
Epoch 0, Step 865: train/loss = 0.4289487600326538, train/raw-loss = 0.35354095697402954, train/logprobs = tensor([[-0.7494, -3.0072],
        [-0.9909, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10772541165351868
Epoch 0, Step 866: train/loss = 0.38109150528907776, train/raw-loss = 0.3087608218193054, train/logprobs = tensor([[-0.6394, -5.9335],
        [-0.7410, -1.1774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10332955420017242
Epoch 0, Step 867: train/loss = 0.6007309556007385, train/raw-loss = 0.5318304896354675, train/logprobs = tensor([[-0.6756, -2.3405],
        [-0.9619, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09842922538518906
Epoch 0, Step 868: train/loss = 0.5576196312904358, train/raw-loss = 0.4714786410331726, train/logprobs = tensor([[-0.8417, -1.6933],
        [-1.0809, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12305856496095657
Epoch 0, Step 869: train/loss = 0.426560640335083, train/raw-loss = 0.34780216217041016, train/logprobs = tensor([[-0.7506, -2.0916],
        [-1.3945, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11251210421323776
Epoch 0, Step 870: train/loss = 0.45924806594848633, train/raw-loss = 0.3942245841026306, train/logprobs = tensor([[-0.8703, -6.1306],
        [-1.1004, -1.4109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09289070963859558
Epoch 0, Step 871: train/loss = 0.40106064081192017, train/raw-loss = 0.32599037885665894, train/logprobs = tensor([[-0.5105, -5.4331],
        [-0.8091, -1.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10724324733018875
Epoch 0, Step 872: train/loss = 0.5222625732421875, train/raw-loss = 0.46646636724472046, train/logprobs = tensor([[-0.3534, -2.9324],
        [-0.4700, -0.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07970893383026123
Epoch 0, Step 873: train/loss = 0.4839521646499634, train/raw-loss = 0.41877231001853943, train/logprobs = tensor([[-0.8311, -3.7175],
        [-0.9334, -0.6188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09311405569314957
Epoch 0, Step 874: train/loss = 0.386790007352829, train/raw-loss = 0.29001325368881226, train/logprobs = tensor([[-1.0770, -6.1123],
        [-1.4768, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13825249671936035
Epoch 0, Step 875: train/loss = 0.6545925140380859, train/raw-loss = 0.5940436124801636, train/logprobs = tensor([[-0.8024, -1.1023],
        [-0.9283, -0.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08649846911430359
Epoch 0, Step 876: train/loss = 0.4449484944343567, train/raw-loss = 0.3896567225456238, train/logprobs = tensor([[-0.4087, -6.4507],
        [-0.5857, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07898823916912079
Epoch 0, Step 877: train/loss = 0.5125459432601929, train/raw-loss = 0.4265840947628021, train/logprobs = tensor([[-1.3372, -4.8614],
        [-1.4680, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12280271202325821
Epoch 0, Step 878: train/loss = 0.9025357961654663, train/raw-loss = 0.8272866606712341, train/logprobs = tensor([[-2.4636, -4.4115],
        [-1.1927, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074988842010498
Epoch 0, Step 879: train/loss = 0.3650379776954651, train/raw-loss = 0.29340147972106934, train/logprobs = tensor([[-0.4772, -7.7216],
        [-0.8388, -1.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10233791172504425
Epoch 0, Step 880: train/loss = 0.4145009219646454, train/raw-loss = 0.3401586413383484, train/logprobs = tensor([[-0.5994, -4.4771],
        [-0.7947, -0.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10620321333408356
Epoch 0, Step 881: train/loss = 0.5437359809875488, train/raw-loss = 0.47802674770355225, train/logprobs = tensor([[-0.5267, -3.5289],
        [-0.6771, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09387034177780151
Epoch 0, Step 882: train/loss = 0.6154583692550659, train/raw-loss = 0.5474551916122437, train/logprobs = tensor([[-0.8134, -1.8674],
        [-0.6741, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0971473976969719
Epoch 0, Step 883: train/loss = 0.43424922227859497, train/raw-loss = 0.3512897491455078, train/logprobs = tensor([[-1.1194, -3.2219],
        [-1.5108, -0.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11851353943347931
Epoch 0, Step 884: train/loss = 0.41212356090545654, train/raw-loss = 0.33455950021743774, train/logprobs = tensor([[-0.6225, -4.0285],
        [-0.8215, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080579459667206
Epoch 0, Step 885: train/loss = 0.37711745500564575, train/raw-loss = 0.29597151279449463, train/logprobs = tensor([[-0.9283, -4.8979],
        [-1.0499, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11592274904251099
Epoch 0, Step 886: train/loss = 0.5624862909317017, train/raw-loss = 0.49418556690216064, train/logprobs = tensor([[-0.6199, -2.6327],
        [-0.7944, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09757250547409058
Epoch 0, Step 887: train/loss = 0.5179506540298462, train/raw-loss = 0.44777244329452515, train/logprobs = tensor([[-0.6585, -4.2023],
        [-0.8247, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10025454312562943
Epoch 0, Step 888: train/loss = 0.2952418625354767, train/raw-loss = 0.21618004143238068, train/logprobs = tensor([[-0.5929, -5.7606],
        [-1.1298, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11294547468423843
Epoch 0, Step 889: train/loss = 0.4651620090007782, train/raw-loss = 0.391371488571167, train/logprobs = tensor([[-0.7479, -3.2524],
        [-0.9674, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10541500896215439
Epoch 0, Step 890: train/loss = 0.4463435411453247, train/raw-loss = 0.3624568581581116, train/logprobs = tensor([[-0.7507, -2.9681],
        [-1.0415, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11983805894851685
Epoch 0, Step 891: train/loss = 0.3547084629535675, train/raw-loss = 0.288085013628006, train/logprobs = tensor([[-0.7534, -5.9145],
        [-1.0896, -1.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0951763167977333
Epoch 0, Step 892: train/loss = 0.4216020107269287, train/raw-loss = 0.3426063060760498, train/logprobs = tensor([[-0.5662, -4.0186],
        [-0.9249, -0.4988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11285100877285004
Epoch 0, Step 893: train/loss = 0.5120242834091187, train/raw-loss = 0.44474005699157715, train/logprobs = tensor([[-0.7391, -3.7919],
        [-0.8773, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09612031280994415
Epoch 0, Step 894: train/loss = 0.4134325683116913, train/raw-loss = 0.3315705358982086, train/logprobs = tensor([[-0.6705, -6.3892],
        [-0.8914, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694574356079102
Epoch 0, Step 895: train/loss = 0.5064103603363037, train/raw-loss = 0.432290256023407, train/logprobs = tensor([[-0.6981, -6.7677],
        [-1.0647, -2.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588593035936356
Epoch 0, Step 896: train/loss = 0.5812208652496338, train/raw-loss = 0.5158290266990662, train/logprobs = tensor([[-0.7772, -1.8653],
        [-0.8418, -0.8490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341695159673691
Epoch 0, Step 897: train/loss = 0.5075928568840027, train/raw-loss = 0.42811229825019836, train/logprobs = tensor([[-0.8122, -3.0462],
        [-1.0930, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11354364454746246
Epoch 0, Step 898: train/loss = 0.5750669836997986, train/raw-loss = 0.5130208730697632, train/logprobs = tensor([[-0.7059, -1.3136],
        [-0.8857, -0.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08863722532987595
Epoch 0, Step 899: train/loss = 0.49199673533439636, train/raw-loss = 0.4104002118110657, train/logprobs = tensor([[-0.5835, -4.3727],
        [-0.8444, -1.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11656644940376282
Epoch 0, Step 900: train/loss = 0.3442600965499878, train/raw-loss = 0.26944270730018616, train/logprobs = tensor([[-1.0439, -9.8475],
        [-1.2612, -1.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10688194632530212
Epoch 0, Step 901: train/loss = 0.4151896834373474, train/raw-loss = 0.3454012870788574, train/logprobs = tensor([[-0.3851, -3.8959],
        [-0.7391, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09969779849052429
Epoch 0, Step 902: train/loss = 0.31601178646087646, train/raw-loss = 0.2413986623287201, train/logprobs = tensor([[-0.6247, -6.5469],
        [-1.1236, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10659017413854599
Epoch 0, Step 903: train/loss = 0.4170750081539154, train/raw-loss = 0.3356057405471802, train/logprobs = tensor([[-0.8532, -3.6925],
        [-1.2410, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11638467758893967
Epoch 0, Step 904: train/loss = 0.4857328534126282, train/raw-loss = 0.4216116964817047, train/logprobs = tensor([[-1.1737, -4.4149],
        [-1.1747, -1.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09160171449184418
Epoch 0, Step 905: train/loss = 0.3568921983242035, train/raw-loss = 0.2934955656528473, train/logprobs = tensor([[-0.4860, -6.7415],
        [-0.7445, -1.4995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09056662768125534
Epoch 0, Step 906: train/loss = 0.6711572408676147, train/raw-loss = 0.6133615970611572, train/logprobs = tensor([[-0.6284, -1.1124],
        [-0.4967, -0.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08256518095731735
Epoch 0, Step 907: train/loss = 0.6412991285324097, train/raw-loss = 0.579795241355896, train/logprobs = tensor([[-0.7546, -1.2617],
        [-0.6652, -0.4619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08786268532276154
Epoch 0, Step 908: train/loss = 0.40897297859191895, train/raw-loss = 0.3300895094871521, train/logprobs = tensor([[-0.6014, -4.6181],
        [-0.9914, -0.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11269068717956543
Epoch 0, Step 909: train/loss = 0.40001362562179565, train/raw-loss = 0.3091885447502136, train/logprobs = tensor([[-1.0931, -3.7073],
        [-1.5648, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1297501027584076
Epoch 0, Step 910: train/loss = 0.5923250317573547, train/raw-loss = 0.5248890519142151, train/logprobs = tensor([[-1.0083, -3.5530],
        [-0.9646, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09633715450763702
Epoch 0, Step 911: train/loss = 0.3426218032836914, train/raw-loss = 0.2687722444534302, train/logprobs = tensor([[-0.7474, -7.2029],
        [-0.9335, -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10549938678741455
Epoch 0, Step 912: train/loss = 0.5585353970527649, train/raw-loss = 0.48896628618240356, train/logprobs = tensor([[-1.1626, -4.7146],
        [-0.5222, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09938445687294006
Epoch 0, Step 913: train/loss = 0.40640947222709656, train/raw-loss = 0.3301689624786377, train/logprobs = tensor([[-0.7175, -6.0175],
        [-1.0807, -1.6196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10891501605510712
Epoch 0, Step 914: train/loss = 0.5613930225372314, train/raw-loss = 0.494932621717453, train/logprobs = tensor([[-0.3779, -1.8189],
        [-0.7075, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09494351595640182
Epoch 0, Step 915: train/loss = 0.474596232175827, train/raw-loss = 0.39996710419654846, train/logprobs = tensor([[-0.7514, -2.9982],
        [-0.9589, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10661309212446213
Epoch 0, Step 916: train/loss = 0.46639949083328247, train/raw-loss = 0.39850372076034546, train/logprobs = tensor([[-1.1311, -3.0430],
        [-1.0393, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699393063783646
Epoch 0, Step 917: train/loss = 0.47792255878448486, train/raw-loss = 0.3999605178833008, train/logprobs = tensor([[-1.0131, -2.9672],
        [-1.0554, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11137428134679794
Epoch 0, Step 918: train/loss = 0.5991971492767334, train/raw-loss = 0.5362937450408936, train/logprobs = tensor([[-0.5387, -1.2836],
        [-0.6655, -0.6380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986201137304306
Epoch 0, Step 919: train/loss = 0.5754385590553284, train/raw-loss = 0.5140482187271118, train/logprobs = tensor([[-0.9263, -2.8544],
        [-0.7905, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0877004936337471
Epoch 0, Step 920: train/loss = 0.6641414165496826, train/raw-loss = 0.6054943799972534, train/logprobs = tensor([[-0.7379, -0.7249],
        [-0.9137, -0.4932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837814211845398
Epoch 0, Step 921: train/loss = 0.6028308868408203, train/raw-loss = 0.5451452732086182, train/logprobs = tensor([[-0.4645, -1.9033],
        [-0.7308, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08240802586078644
Epoch 0, Step 922: train/loss = 0.5028468370437622, train/raw-loss = 0.4322383403778076, train/logprobs = tensor([[-0.6144, -3.6506],
        [-0.6019, -0.6875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086929053068161
Epoch 0, Step 923: train/loss = 0.4778173565864563, train/raw-loss = 0.40054821968078613, train/logprobs = tensor([[-0.9494, -4.0567],
        [-0.8731, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11038447171449661
Epoch 0, Step 924: train/loss = 0.3786764144897461, train/raw-loss = 0.30936241149902344, train/logprobs = tensor([[-0.6499, -5.7645],
        [-1.2009, -1.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09901995956897736
Epoch 0, Step 925: train/loss = 0.5585078597068787, train/raw-loss = 0.5052239298820496, train/logprobs = tensor([[-0.4458, -1.6377],
        [-0.5137, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611994445323944
Epoch 0, Step 926: train/loss = 0.5736091732978821, train/raw-loss = 0.5168708562850952, train/logprobs = tensor([[-0.4723, -1.9499],
        [-0.5755, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08105476945638657
Epoch 0, Step 927: train/loss = 0.615403950214386, train/raw-loss = 0.5348213911056519, train/logprobs = tensor([[-1.2332, -3.1617],
        [-0.9043, -0.6680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11511794477701187
Epoch 0, Step 928: train/loss = 0.4156397581100464, train/raw-loss = 0.3403351306915283, train/logprobs = tensor([[-0.7132, -4.9863],
        [-0.7645, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10757802426815033
Epoch 0, Step 929: train/loss = 0.37332794070243835, train/raw-loss = 0.30246034264564514, train/logprobs = tensor([[-0.5391, -3.7569],
        [-1.1505, -1.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10123946517705917
Epoch 0, Step 930: train/loss = 0.5319241285324097, train/raw-loss = 0.45847612619400024, train/logprobs = tensor([[-0.7305, -1.9388],
        [-0.8693, -0.5937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10492567718029022
Epoch 0, Step 931: train/loss = 0.41536208987236023, train/raw-loss = 0.35662317276000977, train/logprobs = tensor([[-0.6424, -3.0355],
        [-0.8564, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08391276001930237
Epoch 0, Step 932: train/loss = 0.45150455832481384, train/raw-loss = 0.3688281178474426, train/logprobs = tensor([[-0.4744, -3.4227],
        [-0.9531, -0.5791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11810918897390366
Epoch 0, Step 933: train/loss = 0.5063718557357788, train/raw-loss = 0.44896453619003296, train/logprobs = tensor([[-0.5735, -1.9843],
        [-0.8099, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08201046288013458
Epoch 0, Step 934: train/loss = 0.5410760641098022, train/raw-loss = 0.4731863737106323, train/logprobs = tensor([[-0.4831, -2.4325],
        [-0.8079, -0.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09698531031608582
Epoch 0, Step 935: train/loss = 0.4315940737724304, train/raw-loss = 0.3516441583633423, train/logprobs = tensor([[-0.7999, -3.4824],
        [-1.1889, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421419680118561
Epoch 0, Step 936: train/loss = 0.539664626121521, train/raw-loss = 0.4627799987792969, train/logprobs = tensor([[-0.8342, -2.3303],
        [-1.0346, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983516275882721
Epoch 0, Step 937: train/loss = 0.5556758642196655, train/raw-loss = 0.48343008756637573, train/logprobs = tensor([[-0.7603, -3.2342],
        [-0.7884, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10320830345153809
Epoch 0, Step 938: train/loss = 0.4078935384750366, train/raw-loss = 0.31729984283447266, train/logprobs = tensor([[-0.6985, -3.0636],
        [-1.2072, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12941956520080566
Epoch 0, Step 939: train/loss = 0.4520459771156311, train/raw-loss = 0.3813803493976593, train/logprobs = tensor([[-0.8045, -3.7367],
        [-0.7650, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10095087438821793
Epoch 0, Step 940: train/loss = 0.3448713421821594, train/raw-loss = 0.25820380449295044, train/logprobs = tensor([[-0.7176, -3.7307],
        [-1.3451, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238107979297638
Epoch 0, Step 941: train/loss = 0.44307759404182434, train/raw-loss = 0.38137203454971313, train/logprobs = tensor([[-0.7271, -3.8198],
        [-0.9905, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08815081417560577
Epoch 0, Step 942: train/loss = 0.5168383121490479, train/raw-loss = 0.4321376085281372, train/logprobs = tensor([[-0.9376, -3.5307],
        [-1.1922, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12100109457969666
Epoch 0, Step 943: train/loss = 0.41651850938796997, train/raw-loss = 0.3395084738731384, train/logprobs = tensor([[-0.7324, -2.7300],
        [-1.3385, -0.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11001436412334442
Epoch 0, Step 944: train/loss = 0.292496919631958, train/raw-loss = 0.2097388356924057, train/logprobs = tensor([[-0.6424, -7.1210],
        [-1.3043, -1.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182258129119873
Epoch 0, Step 945: train/loss = 0.5041227340698242, train/raw-loss = 0.4455831050872803, train/logprobs = tensor([[-1.0259, -3.0707],
        [-0.9855, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08362807333469391
Epoch 0, Step 946: train/loss = 0.45672398805618286, train/raw-loss = 0.3839343190193176, train/logprobs = tensor([[-0.7122, -5.6024],
        [-1.0724, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039852499961853
Epoch 0, Step 947: train/loss = 0.7489386796951294, train/raw-loss = 0.6920965909957886, train/logprobs = tensor([[-0.6983, -0.6747],
        [-0.6547, -0.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081202931702137
Epoch 0, Step 948: train/loss = 0.4829927682876587, train/raw-loss = 0.39954695105552673, train/logprobs = tensor([[-0.6186, -2.5707],
        [-0.8823, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920831352472305
Epoch 0, Step 949: train/loss = 0.5537877082824707, train/raw-loss = 0.48463451862335205, train/logprobs = tensor([[-0.8277, -2.6328],
        [-0.9133, -0.6646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987902581691742
Epoch 0, Step 950: train/loss = 0.37756258249282837, train/raw-loss = 0.31208205223083496, train/logprobs = tensor([[-0.4352, -3.2193],
        [-1.0402, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09354360401630402
Epoch 0, Step 951: train/loss = 0.6400042176246643, train/raw-loss = 0.5607119798660278, train/logprobs = tensor([[-1.3663, -3.3769],
        [-0.9054, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11327458918094635
Epoch 0, Step 952: train/loss = 0.4608885943889618, train/raw-loss = 0.4000754952430725, train/logprobs = tensor([[-0.3434, -3.7789],
        [-0.6181, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08687584102153778
Epoch 0, Step 953: train/loss = 0.5724316835403442, train/raw-loss = 0.5028928518295288, train/logprobs = tensor([[-0.7097, -2.0820],
        [-0.7808, -0.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934122860431671
Epoch 0, Step 954: train/loss = 0.560803234577179, train/raw-loss = 0.5001456141471863, train/logprobs = tensor([[-0.6490, -1.4680],
        [-0.7859, -0.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08665376156568527
Epoch 0, Step 955: train/loss = 0.3952661156654358, train/raw-loss = 0.3199652135372162, train/logprobs = tensor([[-0.7293, -6.0263],
        [-0.9842, -1.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10757273435592651
Epoch 0, Step 956: train/loss = 0.42222368717193604, train/raw-loss = 0.3576110601425171, train/logprobs = tensor([[-0.5157, -3.1445],
        [-0.8676, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09230373799800873
Epoch 0, Step 957: train/loss = 0.49972832202911377, train/raw-loss = 0.43470364809036255, train/logprobs = tensor([[-0.9427, -5.1227],
        [-1.0510, -1.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09289241582155228
Epoch 0, Step 958: train/loss = 0.5058138370513916, train/raw-loss = 0.4341984987258911, train/logprobs = tensor([[-0.7622, -4.3580],
        [-0.7189, -0.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10230767726898193
Epoch 0, Step 959: train/loss = 0.4642530083656311, train/raw-loss = 0.3975449204444885, train/logprobs = tensor([[-0.5776, -3.8360],
        [-0.8788, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09529728442430496
Epoch 0, Step 960: train/loss = 0.6058582067489624, train/raw-loss = 0.5494813919067383, train/logprobs = tensor([[-0.5733, -1.1996],
        [-0.8243, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08053833246231079
Epoch 0, Step 961: train/loss = 0.3840015232563019, train/raw-loss = 0.3126606047153473, train/logprobs = tensor([[-0.8219, -3.4387],
        [-1.3118, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191561281681061
Epoch 0, Step 962: train/loss = 0.5267218351364136, train/raw-loss = 0.4666820466518402, train/logprobs = tensor([[-1.2932, -4.5971],
        [-1.3555, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08577112853527069
Epoch 0, Step 963: train/loss = 0.5459558963775635, train/raw-loss = 0.4792724847793579, train/logprobs = tensor([[-0.5792, -1.6093],
        [-0.7492, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09526199102401733
Epoch 0, Step 964: train/loss = 0.5144081711769104, train/raw-loss = 0.43976011872291565, train/logprobs = tensor([[-0.6674, -2.6602],
        [-0.9678, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10664013028144836
Epoch 0, Step 965: train/loss = 0.42005643248558044, train/raw-loss = 0.35686948895454407, train/logprobs = tensor([[-0.8191, -3.8220],
        [-1.0731, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09026709198951721
Epoch 0, Step 966: train/loss = 0.494482159614563, train/raw-loss = 0.4309387803077698, train/logprobs = tensor([[-0.4305, -2.3792],
        [-0.8665, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09077625721693039
Epoch 0, Step 967: train/loss = 0.49770331382751465, train/raw-loss = 0.438579797744751, train/logprobs = tensor([[-0.4880, -2.2913],
        [-0.8059, -0.4008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08446217328310013
Epoch 0, Step 968: train/loss = 0.5022827386856079, train/raw-loss = 0.44181469082832336, train/logprobs = tensor([[-0.8659, -2.5690],
        [-1.3637, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0863829255104065
Epoch 0, Step 969: train/loss = 0.41779661178588867, train/raw-loss = 0.3389798700809479, train/logprobs = tensor([[-0.5322, -4.8395],
        [-1.1124, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11259534955024719
Epoch 0, Step 970: train/loss = 0.49997973442077637, train/raw-loss = 0.43319106101989746, train/logprobs = tensor([[-0.5553, -2.4338],
        [-0.7567, -0.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541240334510803
Epoch 0, Step 971: train/loss = 0.46412333846092224, train/raw-loss = 0.3955085277557373, train/logprobs = tensor([[-0.2908, -3.8496],
        [-0.6411, -0.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09802111983299255
Epoch 0, Step 972: train/loss = 0.4953334331512451, train/raw-loss = 0.4325481057167053, train/logprobs = tensor([[-0.6294, -4.6300],
        [-0.7451, -0.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969327807426453
Epoch 0, Step 973: train/loss = 0.5799714922904968, train/raw-loss = 0.5178121328353882, train/logprobs = tensor([[-0.5715, -2.0347],
        [-0.8147, -0.6050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08879899233579636
Epoch 0, Step 974: train/loss = 0.4788399338722229, train/raw-loss = 0.40648770332336426, train/logprobs = tensor([[-0.7295, -3.2570],
        [-1.0293, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336034744977951
Epoch 0, Step 975: train/loss = 0.42346474528312683, train/raw-loss = 0.3509385585784912, train/logprobs = tensor([[-0.4749, -2.9053],
        [-0.7160, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10360883176326752
Epoch 0, Step 976: train/loss = 0.5446702241897583, train/raw-loss = 0.47051167488098145, train/logprobs = tensor([[-0.3942, -2.5802],
        [-0.8981, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10594071447849274
Epoch 0, Step 977: train/loss = 0.5195370316505432, train/raw-loss = 0.4484424889087677, train/logprobs = tensor([[-0.6835, -3.1326],
        [-0.8434, -0.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10156361013650894
Epoch 0, Step 978: train/loss = 0.5078412294387817, train/raw-loss = 0.42488300800323486, train/logprobs = tensor([[-1.0968, -3.1154],
        [-1.0075, -0.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11851175129413605
Epoch 0, Step 979: train/loss = 0.47304201126098633, train/raw-loss = 0.41416120529174805, train/logprobs = tensor([[-0.4740, -2.7566],
        [-0.8287, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08411544561386108
Epoch 0, Step 980: train/loss = 0.36930084228515625, train/raw-loss = 0.3035879135131836, train/logprobs = tensor([[-0.6003, -3.1819],
        [-0.9505, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09387561678886414
Epoch 0, Step 981: train/loss = 0.4409051239490509, train/raw-loss = 0.3708171248435974, train/logprobs = tensor([[-0.8884, -4.3800],
        [-1.3722, -1.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012570023536682
Epoch 0, Step 982: train/loss = 0.4111158847808838, train/raw-loss = 0.3445148766040802, train/logprobs = tensor([[-0.5917, -2.8178],
        [-0.9090, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09514430165290833
Epoch 0, Step 983: train/loss = 0.4784160852432251, train/raw-loss = 0.408730149269104, train/logprobs = tensor([[-0.7391, -2.9302],
        [-0.9046, -0.6834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09955132007598877
Epoch 0, Step 984: train/loss = 0.5275231599807739, train/raw-loss = 0.4524911046028137, train/logprobs = tensor([[-0.4907, -1.7786],
        [-1.0152, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10718867182731628
Epoch 0, Step 985: train/loss = 0.6081116199493408, train/raw-loss = 0.5513076186180115, train/logprobs = tensor([[-0.5996, -1.1880],
        [-0.7258, -0.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08114857226610184
Epoch 0, Step 986: train/loss = 0.30028000473976135, train/raw-loss = 0.22369319200515747, train/logprobs = tensor([[-0.6382, -6.9031],
        [-1.2889, -1.4166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10940971970558167
Epoch 0, Step 987: train/loss = 0.55369633436203, train/raw-loss = 0.4935034215450287, train/logprobs = tensor([[-0.9245, -1.7736],
        [-0.9673, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08598989248275757
Epoch 0, Step 988: train/loss = 0.5785297155380249, train/raw-loss = 0.5023739337921143, train/logprobs = tensor([[-0.6053, -1.9078],
        [-1.5215, -0.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10879401862621307
Epoch 0, Step 989: train/loss = 0.42598170042037964, train/raw-loss = 0.3534715473651886, train/logprobs = tensor([[-0.7043, -2.6025],
        [-1.0263, -0.6754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358592122793198
Epoch 0, Step 990: train/loss = 0.5210633277893066, train/raw-loss = 0.45723363757133484, train/logprobs = tensor([[-0.4738, -2.4898],
        [-0.6587, -0.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09118536114692688
Epoch 0, Step 991: train/loss = 0.6205482482910156, train/raw-loss = 0.5594841837882996, train/logprobs = tensor([[-0.5471, -1.0543],
        [-0.6523, -0.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08723443746566772
Epoch 0, Step 992: train/loss = 0.4590776264667511, train/raw-loss = 0.39021986722946167, train/logprobs = tensor([[-0.4611, -3.0837],
        [-0.7506, -0.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09836820513010025
Epoch 0, Step 993: train/loss = 0.4277774691581726, train/raw-loss = 0.36075979471206665, train/logprobs = tensor([[-0.5180, -2.2844],
        [-0.9951, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09573949128389359
Epoch 0, Step 994: train/loss = 0.32401126623153687, train/raw-loss = 0.2436661422252655, train/logprobs = tensor([[-0.7447, -4.3183],
        [-1.2884, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11477874964475632
Epoch 0, Step 995: train/loss = 0.30883052945137024, train/raw-loss = 0.24522683024406433, train/logprobs = tensor([[-0.4476, -4.4068],
        [-0.7826, -0.6721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0908624529838562
Epoch 0, Step 996: train/loss = 0.5536524057388306, train/raw-loss = 0.49767211079597473, train/logprobs = tensor([[-0.4848, -3.6530],
        [-0.7484, -1.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07997182011604309
Epoch 0, Step 997: train/loss = 0.3524705767631531, train/raw-loss = 0.28484445810317993, train/logprobs = tensor([[-0.6030, -4.3227],
        [-0.7923, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0966087207198143
Epoch 0, Step 998: train/loss = 0.41999539732933044, train/raw-loss = 0.32660454511642456, train/logprobs = tensor([[-0.5577, -2.6990],
        [-1.3332, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13341553509235382
Epoch 0, Step 999: train/loss = 0.544853925704956, train/raw-loss = 0.484090656042099, train/logprobs = tensor([[-0.5358, -1.8013],
        [-0.8921, -0.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08680459856987
Epoch 0, Step 1000: train/loss = 0.544345498085022, train/raw-loss = 0.45913684368133545, train/logprobs = tensor([[-0.8374, -1.9111],
        [-1.3529, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172671407461166
Epoch 0, Step 1001: train/loss = 0.4596171975135803, train/raw-loss = 0.38609784841537476, train/logprobs = tensor([[-0.5699, -3.0364],
        [-1.1071, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10502760112285614
Epoch 0, Step 1002: train/loss = 0.5027247071266174, train/raw-loss = 0.4239814579486847, train/logprobs = tensor([[-0.4709, -3.6945],
        [-1.0697, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11249032616615295
Epoch 0, Step 1003: train/loss = 0.48413920402526855, train/raw-loss = 0.40184271335601807, train/logprobs = tensor([[-1.0227, -3.2553],
        [-1.0935, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756645143032074
Epoch 0, Step 1004: train/loss = 0.667643666267395, train/raw-loss = 0.6074011325836182, train/logprobs = tensor([[-0.5763, -0.8365],
        [-0.6778, -0.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08606074750423431
Epoch 0, Step 1005: train/loss = 0.29996341466903687, train/raw-loss = 0.2265533208847046, train/logprobs = tensor([[-0.6712, -6.3815],
        [-1.2069, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10487159341573715
Epoch 0, Step 1006: train/loss = 0.6064830422401428, train/raw-loss = 0.5478248596191406, train/logprobs = tensor([[-0.6647, -1.1974],
        [-0.9199, -0.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08379736542701721
Epoch 0, Step 1007: train/loss = 0.5889201760292053, train/raw-loss = 0.5294803380966187, train/logprobs = tensor([[-1.2637, -1.6392],
        [-1.3956, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08491408824920654
Epoch 0, Step 1008: train/loss = 0.49890968203544617, train/raw-loss = 0.4278075098991394, train/logprobs = tensor([[-0.5092, -3.6522],
        [-0.8633, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10157451033592224
Epoch 0, Step 1009: train/loss = 0.5056295394897461, train/raw-loss = 0.4388476610183716, train/logprobs = tensor([[-0.6521, -4.4892],
        [-1.1884, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09540267288684845
Epoch 0, Step 1010: train/loss = 0.5238102674484253, train/raw-loss = 0.4514031410217285, train/logprobs = tensor([[-0.7607, -3.4453],
        [-0.8067, -0.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10343874990940094
Epoch 0, Step 1011: train/loss = 0.5906867980957031, train/raw-loss = 0.522945761680603, train/logprobs = tensor([[-0.4905, -1.4708],
        [-0.9110, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0967729389667511
Epoch 0, Step 1012: train/loss = 0.36610811948776245, train/raw-loss = 0.292439341545105, train/logprobs = tensor([[-0.6295, -3.6967],
        [-1.2511, -0.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10524114221334457
Epoch 0, Step 1013: train/loss = 0.2995688319206238, train/raw-loss = 0.203165665268898, train/logprobs = tensor([[-0.8103, -5.8039],
        [-1.8800, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377188116312027
Epoch 0, Step 1014: train/loss = 0.48553141951560974, train/raw-loss = 0.4155237376689911, train/logprobs = tensor([[-0.6955, -2.9282],
        [-1.0051, -0.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001092404127121
Epoch 0, Step 1015: train/loss = 0.3715411424636841, train/raw-loss = 0.2992313504219055, train/logprobs = tensor([[-0.4977, -3.7057],
        [-1.2360, -0.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10329972952604294
Epoch 0, Step 1016: train/loss = 0.5003137588500977, train/raw-loss = 0.424885094165802, train/logprobs = tensor([[-0.7867, -4.7927],
        [-1.0486, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10775521397590637
Epoch 0, Step 1017: train/loss = 0.4166472554206848, train/raw-loss = 0.34793388843536377, train/logprobs = tensor([[-0.5329, -5.4578],
        [-0.7961, -1.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09816198796033859
Epoch 0, Step 1018: train/loss = 0.5166335105895996, train/raw-loss = 0.45037350058555603, train/logprobs = tensor([[-0.6714, -2.9108],
        [-0.9137, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09465716779232025
Epoch 0, Step 1019: train/loss = 0.43902817368507385, train/raw-loss = 0.3635162115097046, train/logprobs = tensor([[-0.9133, -4.2143],
        [-1.2795, -1.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787428915500641
Epoch 0, Step 1020: train/loss = 0.47985345125198364, train/raw-loss = 0.41703033447265625, train/logprobs = tensor([[-0.6933, -5.3775],
        [-0.7058, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08974727988243103
Epoch 0, Step 1021: train/loss = 0.40320977568626404, train/raw-loss = 0.33165696263313293, train/logprobs = tensor([[-0.5218, -4.3344],
        [-0.9622, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10221831500530243
Epoch 0, Step 1022: train/loss = 0.540069580078125, train/raw-loss = 0.49031633138656616, train/logprobs = tensor([[-0.4588, -1.2978],
        [-0.8460, -0.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107602059841156
Epoch 0, Step 1023: train/loss = 0.5903635621070862, train/raw-loss = 0.5263776779174805, train/logprobs = tensor([[-0.4870, -1.8310],
        [-0.9694, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09140840172767639
Epoch 0, Step 1024: train/loss = 0.47032681107521057, train/raw-loss = 0.3971302807331085, train/logprobs = tensor([[-0.7611, -3.5977],
        [-0.8692, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456645488739014
Epoch 0, Step 1025: train/loss = 0.43730664253234863, train/raw-loss = 0.3763735294342041, train/logprobs = tensor([[-0.6762, -3.3869],
        [-0.9312, -0.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08704733848571777
Epoch 0, Step 1026: train/loss = 0.4260288178920746, train/raw-loss = 0.3425852060317993, train/logprobs = tensor([[-0.6363, -3.2504],
        [-1.0120, -0.5479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920513957738876
Epoch 0, Step 1027: train/loss = 0.6888414621353149, train/raw-loss = 0.6397198438644409, train/logprobs = tensor([[-0.5027, -0.8013],
        [-0.6413, -0.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07017380744218826
Epoch 0, Step 1028: train/loss = 0.4130397439002991, train/raw-loss = 0.3608960509300232, train/logprobs = tensor([[-0.7349, -4.6535],
        [-1.4002, -1.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07449095696210861
Epoch 0, Step 1029: train/loss = 0.5900052785873413, train/raw-loss = 0.5281482338905334, train/logprobs = tensor([[-0.3776, -1.8321],
        [-0.6353, -0.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0883672684431076
Epoch 0, Step 1030: train/loss = 0.40589576959609985, train/raw-loss = 0.3357847332954407, train/logprobs = tensor([[-0.6196, -5.2232],
        [-1.3705, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10015860199928284
Epoch 0, Step 1031: train/loss = 0.5140666961669922, train/raw-loss = 0.4526229500770569, train/logprobs = tensor([[-0.5618, -1.9965],
        [-0.8309, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777683973312378
Epoch 0, Step 1032: train/loss = 0.527959942817688, train/raw-loss = 0.46827805042266846, train/logprobs = tensor([[-0.6339, -1.8264],
        [-1.1709, -0.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852598324418068
Epoch 0, Step 1033: train/loss = 0.3853316009044647, train/raw-loss = 0.298012375831604, train/logprobs = tensor([[-0.9264, -4.1683],
        [-1.7265, -0.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12474173307418823
Epoch 0, Step 1034: train/loss = 0.4286547899246216, train/raw-loss = 0.3665541410446167, train/logprobs = tensor([[-0.6555, -2.2276],
        [-1.1358, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08871514350175858
Epoch 0, Step 1035: train/loss = 0.5575241446495056, train/raw-loss = 0.471928209066391, train/logprobs = tensor([[-0.7367, -2.2431],
        [-1.2473, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227990478277206
Epoch 0, Step 1036: train/loss = 0.5718255043029785, train/raw-loss = 0.5058026313781738, train/logprobs = tensor([[-0.4916, -2.0067],
        [-0.8399, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09431836754083633
Epoch 0, Step 1037: train/loss = 0.5579338669776917, train/raw-loss = 0.49471768736839294, train/logprobs = tensor([[-0.5453, -2.9722],
        [-1.0410, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09030881524085999
Epoch 0, Step 1038: train/loss = 0.4425475299358368, train/raw-loss = 0.36431604623794556, train/logprobs = tensor([[-0.8267, -4.1853],
        [-1.1582, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11175931990146637
Epoch 0, Step 1039: train/loss = 0.37798011302948, train/raw-loss = 0.3070390224456787, train/logprobs = tensor([[-0.6562, -7.5612],
        [-1.2391, -2.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10134440660476685
Epoch 0, Step 1040: train/loss = 0.5228103399276733, train/raw-loss = 0.4616117477416992, train/logprobs = tensor([[-1.3210, -3.4347],
        [-1.3785, -1.3358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0874265730381012
Epoch 0, Step 1041: train/loss = 0.38951048254966736, train/raw-loss = 0.3073638677597046, train/logprobs = tensor([[-0.7688, -5.7791],
        [-1.1371, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11735230684280396
Epoch 0, Step 1042: train/loss = 0.5270683765411377, train/raw-loss = 0.4776124954223633, train/logprobs = tensor([[-0.6548, -2.2834],
        [-0.6438, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07065127789974213
Epoch 0, Step 1043: train/loss = 0.6759704351425171, train/raw-loss = 0.6186903715133667, train/logprobs = tensor([[-0.9531, -1.2845],
        [-0.8243, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08182865381240845
Epoch 0, Step 1044: train/loss = 0.5801355242729187, train/raw-loss = 0.5161923170089722, train/logprobs = tensor([[-0.9252, -1.3404],
        [-1.4029, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09134736657142639
Epoch 0, Step 1045: train/loss = 0.4774060845375061, train/raw-loss = 0.4167388081550598, train/logprobs = tensor([[-0.5540, -3.2347],
        [-0.9006, -0.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08666755259037018
Epoch 0, Step 1046: train/loss = 0.4844557046890259, train/raw-loss = 0.41685807704925537, train/logprobs = tensor([[-0.5061, -3.1954],
        [-0.8313, -0.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0965680181980133
Epoch 0, Step 1047: train/loss = 0.5628756880760193, train/raw-loss = 0.49583232402801514, train/logprobs = tensor([[-0.5587, -1.2753],
        [-0.8994, -0.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577621519565582
Epoch 0, Step 1048: train/loss = 0.2917179465293884, train/raw-loss = 0.22053542733192444, train/logprobs = tensor([[-0.5876, -7.0172],
        [-1.1513, -1.2039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168936103582382
Epoch 0, Step 1049: train/loss = 0.40099334716796875, train/raw-loss = 0.32203003764152527, train/logprobs = tensor([[-0.6822, -2.8755],
        [-1.3530, -0.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11280469596385956
Epoch 0, Step 1050: train/loss = 0.5728155970573425, train/raw-loss = 0.5132033824920654, train/logprobs = tensor([[-0.5111, -1.0205],
        [-0.8813, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08516035974025726
Epoch 0, Step 1051: train/loss = 0.6355525255203247, train/raw-loss = 0.5887991189956665, train/logprobs = tensor([[-0.5294, -1.1252],
        [-0.6326, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06679054349660873
Epoch 0, Step 1052: train/loss = 0.41236668825149536, train/raw-loss = 0.351257860660553, train/logprobs = tensor([[-0.5245, -3.0223],
        [-0.8200, -0.8135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08729830384254456
Epoch 0, Step 1053: train/loss = 0.36293333768844604, train/raw-loss = 0.29773810505867004, train/logprobs = tensor([[-0.5285, -3.7606],
        [-1.1409, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09313605725765228
Epoch 0, Step 1054: train/loss = 0.5338565111160278, train/raw-loss = 0.4761209785938263, train/logprobs = tensor([[-0.8619, -1.9704],
        [-1.0038, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.082479327917099
Epoch 0, Step 1055: train/loss = 0.5211615562438965, train/raw-loss = 0.4503113925457001, train/logprobs = tensor([[-0.8079, -3.4162],
        [-1.2540, -1.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012144684791565
Epoch 0, Step 1056: train/loss = 0.46985533833503723, train/raw-loss = 0.4110989272594452, train/logprobs = tensor([[-0.5973, -3.5889],
        [-0.7554, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08393773436546326
Epoch 0, Step 1057: train/loss = 0.4112347364425659, train/raw-loss = 0.352006196975708, train/logprobs = tensor([[-0.4758, -4.9163],
        [-1.0610, -0.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08461218327283859
Epoch 0, Step 1058: train/loss = 0.404153048992157, train/raw-loss = 0.3310077488422394, train/logprobs = tensor([[-0.5193, -2.8536],
        [-1.1362, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10449328273534775
Epoch 0, Step 1059: train/loss = 0.6267114877700806, train/raw-loss = 0.5578169822692871, train/logprobs = tensor([[-0.5260, -1.2739],
        [-0.7191, -0.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09842069447040558
Epoch 0, Step 1060: train/loss = 0.5974164605140686, train/raw-loss = 0.5371300578117371, train/logprobs = tensor([[-0.6002, -1.6105],
        [-0.9516, -0.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861235037446022
Epoch 0, Step 1061: train/loss = 0.5198465585708618, train/raw-loss = 0.4499935507774353, train/logprobs = tensor([[-0.6432, -3.9176],
        [-1.0444, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09978998452425003
Epoch 0, Step 1062: train/loss = 0.5315961837768555, train/raw-loss = 0.4529685974121094, train/logprobs = tensor([[-0.7002, -2.2349],
        [-1.2583, -0.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232519149780273
Epoch 0, Step 1063: train/loss = 0.6010090708732605, train/raw-loss = 0.5454261898994446, train/logprobs = tensor([[-1.0073, -2.0708],
        [-0.7977, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07940416783094406
Epoch 0, Step 1064: train/loss = 0.43800944089889526, train/raw-loss = 0.36609765887260437, train/logprobs = tensor([[-0.5742, -4.5757],
        [-0.9146, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1027311161160469
Epoch 0, Step 1065: train/loss = 0.5524153709411621, train/raw-loss = 0.4900238513946533, train/logprobs = tensor([[-0.5465, -1.7002],
        [-0.8759, -0.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08913068473339081
Epoch 0, Step 1066: train/loss = 0.48168355226516724, train/raw-loss = 0.42283445596694946, train/logprobs = tensor([[-1.3520, -3.4400],
        [-1.3478, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840701162815094
Epoch 0, Step 1067: train/loss = 0.26656490564346313, train/raw-loss = 0.19458340108394623, train/logprobs = tensor([[-0.7818, -7.0783],
        [-1.5626, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10283073782920837
Epoch 0, Step 1068: train/loss = 0.4677187502384186, train/raw-loss = 0.4031350016593933, train/logprobs = tensor([[-0.5069, -2.4808],
        [-0.9165, -0.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09226248413324356
Epoch 0, Step 1069: train/loss = 0.5744601488113403, train/raw-loss = 0.5118755102157593, train/logprobs = tensor([[-0.9252, -4.5294],
        [-0.8826, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08940659463405609
Epoch 0, Step 1070: train/loss = 0.4018380045890808, train/raw-loss = 0.3220943510532379, train/logprobs = tensor([[-0.6019, -3.8613],
        [-1.0520, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1139194518327713
Epoch 0, Step 1071: train/loss = 0.2774870991706848, train/raw-loss = 0.20418837666511536, train/logprobs = tensor([[-0.5901, -5.2177],
        [-1.3381, -1.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10471247136592865
Epoch 0, Step 1072: train/loss = 0.2967533469200134, train/raw-loss = 0.2246817648410797, train/logprobs = tensor([[-0.5463, -5.9921],
        [-1.0902, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295938700437546
Epoch 0, Step 1073: train/loss = 0.47466370463371277, train/raw-loss = 0.4048941731452942, train/logprobs = tensor([[-0.6114, -3.6744],
        [-1.0630, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09967073798179626
Epoch 0, Step 1074: train/loss = 0.47266656160354614, train/raw-loss = 0.40740394592285156, train/logprobs = tensor([[-0.5012, -4.2259],
        [-0.8520, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323230385780334
Epoch 0, Step 1075: train/loss = 0.48265761137008667, train/raw-loss = 0.42708808183670044, train/logprobs = tensor([[-0.4527, -2.9639],
        [-0.6237, -0.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938510179519653
Epoch 0, Step 1076: train/loss = 0.45312750339508057, train/raw-loss = 0.37249550223350525, train/logprobs = tensor([[-0.4859, -3.0627],
        [-1.0365, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11518856883049011
Epoch 0, Step 1077: train/loss = 0.45203256607055664, train/raw-loss = 0.38900622725486755, train/logprobs = tensor([[-0.4344, -2.9886],
        [-0.9453, -0.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09003757685422897
Epoch 0, Step 1078: train/loss = 0.5303347110748291, train/raw-loss = 0.46961337327957153, train/logprobs = tensor([[-0.7893, -2.0707],
        [-1.0976, -0.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08674480766057968
Epoch 0, Step 1079: train/loss = 0.353252649307251, train/raw-loss = 0.2805696427822113, train/logprobs = tensor([[-0.4847, -5.7899],
        [-0.9189, -0.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10383286327123642
Epoch 0, Step 1080: train/loss = 0.5627708435058594, train/raw-loss = 0.49737656116485596, train/logprobs = tensor([[-0.6125, -2.3719],
        [-0.9580, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09342040866613388
Epoch 0, Step 1081: train/loss = 0.3422226905822754, train/raw-loss = 0.27592140436172485, train/logprobs = tensor([[-0.9831, -4.1996],
        [-1.1762, -0.7794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09471611678600311
Epoch 0, Step 1082: train/loss = 0.6557714343070984, train/raw-loss = 0.596128523349762, train/logprobs = tensor([[-0.6662, -1.0342],
        [-0.9772, -0.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08520415425300598
Epoch 0, Step 1083: train/loss = 0.5637214183807373, train/raw-loss = 0.48465561866760254, train/logprobs = tensor([[-0.7572, -2.4476],
        [-1.1435, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129511296749115
Epoch 0, Step 1084: train/loss = 0.5102769732475281, train/raw-loss = 0.4480578601360321, train/logprobs = tensor([[-0.4666, -2.5452],
        [-0.8022, -0.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08888442069292068
Epoch 0, Step 1085: train/loss = 0.5531781911849976, train/raw-loss = 0.49577054381370544, train/logprobs = tensor([[-0.5918, -2.0273],
        [-0.9110, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820109024643898
Epoch 0, Step 1086: train/loss = 0.4348873496055603, train/raw-loss = 0.36326250433921814, train/logprobs = tensor([[-0.6105, -4.6078],
        [-1.0544, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10232122987508774
Epoch 0, Step 1087: train/loss = 0.4119219183921814, train/raw-loss = 0.3551742434501648, train/logprobs = tensor([[-0.5142, -4.3533],
        [-0.6552, -0.6991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08106814324855804
Epoch 0, Step 1088: train/loss = 0.549060583114624, train/raw-loss = 0.48132991790771484, train/logprobs = tensor([[-0.8485, -1.9533],
        [-1.0952, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09675814211368561
Epoch 0, Step 1089: train/loss = 0.5521989464759827, train/raw-loss = 0.49913880228996277, train/logprobs = tensor([[-0.6158, -1.9215],
        [-0.7100, -0.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07580029964447021
Epoch 0, Step 1090: train/loss = 0.3913882374763489, train/raw-loss = 0.3294644057750702, train/logprobs = tensor([[-0.4861, -3.1069],
        [-1.1668, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08846261352300644
Epoch 0, Step 1091: train/loss = 0.38839247822761536, train/raw-loss = 0.33106666803359985, train/logprobs = tensor([[-0.4994, -2.8838],
        [-0.9966, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08189402520656586
Epoch 0, Step 1092: train/loss = 0.4601982831954956, train/raw-loss = 0.39034128189086914, train/logprobs = tensor([[-0.6818, -2.5060],
        [-0.9338, -0.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09979569911956787
Epoch 0, Step 1093: train/loss = 0.5040798783302307, train/raw-loss = 0.42907142639160156, train/logprobs = tensor([[-0.6544, -3.0091],
        [-1.2184, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10715487599372864
Epoch 0, Step 1094: train/loss = 0.4833068251609802, train/raw-loss = 0.42357319593429565, train/logprobs = tensor([[-0.5123, -1.6958],
        [-0.8592, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08533374965190887
Epoch 0, Step 1095: train/loss = 0.575365424156189, train/raw-loss = 0.5043759346008301, train/logprobs = tensor([[-0.8191, -2.3569],
        [-0.9276, -0.6080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10141362249851227
Epoch 0, Step 1096: train/loss = 0.4283004701137543, train/raw-loss = 0.3623892664909363, train/logprobs = tensor([[-0.6241, -3.9220],
        [-0.8716, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0941588506102562
Epoch 0, Step 1097: train/loss = 0.3951649069786072, train/raw-loss = 0.31864479184150696, train/logprobs = tensor([[-0.7955, -3.8091],
        [-1.0842, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10931446403265
Epoch 0, Step 1098: train/loss = 0.41066914796829224, train/raw-loss = 0.34779971837997437, train/logprobs = tensor([[-0.3946, -5.7976],
        [-0.9506, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08981342613697052
Epoch 0, Step 1099: train/loss = 0.5372689962387085, train/raw-loss = 0.46635913848876953, train/logprobs = tensor([[-0.5441, -1.2601],
        [-1.1500, -0.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10129979997873306
Epoch 0, Step 1100: train/loss = 0.44395917654037476, train/raw-loss = 0.38159745931625366, train/logprobs = tensor([[-0.5397, -2.8960],
        [-0.9219, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08908818662166595
Epoch 0, Step 1101: train/loss = 0.36939406394958496, train/raw-loss = 0.31140074133872986, train/logprobs = tensor([[-0.5447, -5.8468],
        [-1.2765, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08284759521484375
Epoch 0, Step 1102: train/loss = 0.44834229350090027, train/raw-loss = 0.38963186740875244, train/logprobs = tensor([[-0.9055, -3.9389],
        [-0.9093, -0.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387204259634018
Epoch 0, Step 1103: train/loss = 0.36116382479667664, train/raw-loss = 0.29642459750175476, train/logprobs = tensor([[-0.7514, -4.5934],
        [-1.1729, -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09248463809490204
Epoch 0, Step 1104: train/loss = 0.6113446950912476, train/raw-loss = 0.5536810755729675, train/logprobs = tensor([[-0.7131, -3.7926],
        [-0.8878, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237659186124802
Epoch 0, Step 1105: train/loss = 0.45063892006874084, train/raw-loss = 0.3921295404434204, train/logprobs = tensor([[-0.7206, -3.4592],
        [-0.6924, -0.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08358482271432877
Epoch 0, Step 1106: train/loss = 0.4270445704460144, train/raw-loss = 0.3506881296634674, train/logprobs = tensor([[-0.9352, -4.8226],
        [-1.0644, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10908059775829315
Epoch 0, Step 1107: train/loss = 0.4346291422843933, train/raw-loss = 0.3725232779979706, train/logprobs = tensor([[-0.5770, -3.4075],
        [-0.8369, -0.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08872267603874207
Epoch 0, Step 1108: train/loss = 0.4645031690597534, train/raw-loss = 0.41090622544288635, train/logprobs = tensor([[-0.4934, -2.4866],
        [-0.8433, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07656703889369965
Epoch 0, Step 1109: train/loss = 0.4951235055923462, train/raw-loss = 0.4311879873275757, train/logprobs = tensor([[-0.5590, -2.3298],
        [-0.8848, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133650362491608
Epoch 0, Step 1110: train/loss = 0.5487709641456604, train/raw-loss = 0.4929678440093994, train/logprobs = tensor([[-0.5414, -3.6978],
        [-0.6361, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07971873879432678
Epoch 0, Step 1111: train/loss = 0.45263487100601196, train/raw-loss = 0.39121493697166443, train/logprobs = tensor([[-0.5475, -4.0586],
        [-0.6607, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08774277567863464
Epoch 0, Step 1112: train/loss = 0.5929504632949829, train/raw-loss = 0.5240108966827393, train/logprobs = tensor([[-1.2295, -4.4649],
        [-1.1157, -1.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09848517179489136
Epoch 0, Step 1113: train/loss = 0.5941153764724731, train/raw-loss = 0.5297293663024902, train/logprobs = tensor([[-0.5913, -1.5234],
        [-0.7873, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09198006242513657
Epoch 0, Step 1114: train/loss = 0.4703906178474426, train/raw-loss = 0.41112351417541504, train/logprobs = tensor([[-0.6464, -2.0761],
        [-0.9515, -0.4888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08466726541519165
Epoch 0, Step 1115: train/loss = 0.559094250202179, train/raw-loss = 0.4933592677116394, train/logprobs = tensor([[-0.3990, -1.5350],
        [-0.6307, -0.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09390708804130554
Epoch 0, Step 1116: train/loss = 0.5440607070922852, train/raw-loss = 0.4836826026439667, train/logprobs = tensor([[-0.5369, -2.1096],
        [-0.7132, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08625445514917374
Epoch 0, Step 1117: train/loss = 0.5791139602661133, train/raw-loss = 0.5083109140396118, train/logprobs = tensor([[-0.5635, -1.9829],
        [-1.1969, -1.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10114721953868866
Epoch 0, Step 1118: train/loss = 0.5894507169723511, train/raw-loss = 0.5367188453674316, train/logprobs = tensor([[-0.3189, -1.7956],
        [-0.4612, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07533133029937744
Epoch 0, Step 1119: train/loss = 0.4526987075805664, train/raw-loss = 0.38581666350364685, train/logprobs = tensor([[-0.4645, -3.7248],
        [-0.8728, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09554578363895416
Epoch 0, Step 1120: train/loss = 0.33484071493148804, train/raw-loss = 0.25797244906425476, train/logprobs = tensor([[-0.7738, -3.2262],
        [-1.4292, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10981180518865585
Epoch 0, Step 1121: train/loss = 0.4267534613609314, train/raw-loss = 0.35213157534599304, train/logprobs = tensor([[-0.6563, -2.7855],
        [-1.4850, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10660271346569061
Epoch 0, Step 1122: train/loss = 0.5926551818847656, train/raw-loss = 0.5300531983375549, train/logprobs = tensor([[-0.4593, -3.0462],
        [-0.8532, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08943140506744385
Epoch 0, Step 1123: train/loss = 0.3238290548324585, train/raw-loss = 0.25420355796813965, train/logprobs = tensor([[-0.5490, -6.0563],
        [-1.2299, -1.2822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09946499764919281
Epoch 0, Step 1124: train/loss = 0.4275001883506775, train/raw-loss = 0.3662753999233246, train/logprobs = tensor([[-0.7775, -5.9140],
        [-1.1947, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08746401220560074
Epoch 0, Step 1125: train/loss = 0.44870564341545105, train/raw-loss = 0.3871827721595764, train/logprobs = tensor([[-0.5168, -2.2014],
        [-0.8732, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08788980543613434
Epoch 0, Step 1126: train/loss = 0.5287364721298218, train/raw-loss = 0.4624425172805786, train/logprobs = tensor([[-0.7588, -4.6057],
        [-0.9503, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947057232260704
Epoch 0, Step 1127: train/loss = 0.4519141912460327, train/raw-loss = 0.3916271924972534, train/logprobs = tensor([[-0.3644, -2.7474],
        [-0.5376, -0.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08612432330846786
Epoch 0, Step 1128: train/loss = 0.6428424119949341, train/raw-loss = 0.5806406140327454, train/logprobs = tensor([[-1.2879, -1.7845],
        [-0.9741, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08885972946882248
Epoch 0, Step 1129: train/loss = 0.36142197251319885, train/raw-loss = 0.288884699344635, train/logprobs = tensor([[-0.5689, -2.9213],
        [-1.1924, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10362466424703598
Epoch 0, Step 1130: train/loss = 0.5537632703781128, train/raw-loss = 0.5048407316207886, train/logprobs = tensor([[-0.3239, -1.4838],
        [-0.6634, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06988941878080368
Epoch 0, Step 1131: train/loss = 0.4445768892765045, train/raw-loss = 0.393893837928772, train/logprobs = tensor([[-0.4175, -2.7878],
        [-0.6527, -0.9034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07240436226129532
Epoch 0, Step 1132: train/loss = 0.5893980264663696, train/raw-loss = 0.5241543054580688, train/logprobs = tensor([[-0.6758, -2.6494],
        [-0.6009, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0932052880525589
Epoch 0, Step 1133: train/loss = 0.6687162518501282, train/raw-loss = 0.6092291474342346, train/logprobs = tensor([[-0.6148, -0.8274],
        [-0.6834, -0.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08498159050941467
Epoch 0, Step 1134: train/loss = 0.45679664611816406, train/raw-loss = 0.38921064138412476, train/logprobs = tensor([[-1.0494, -5.3901],
        [-1.1448, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09655138850212097
Epoch 0, Step 1135: train/loss = 0.4180830717086792, train/raw-loss = 0.3520001769065857, train/logprobs = tensor([[-0.4972, -3.3284],
        [-0.8485, -0.4416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09440410882234573
Epoch 0, Step 1136: train/loss = 0.4368779957294464, train/raw-loss = 0.3717559576034546, train/logprobs = tensor([[-0.6603, -4.2081],
        [-1.1149, -0.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09303142875432968
Epoch 0, Step 1137: train/loss = 0.40943852066993713, train/raw-loss = 0.3490453362464905, train/logprobs = tensor([[-0.6808, -5.9437],
        [-0.9730, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08627597987651825
Epoch 0, Step 1138: train/loss = 0.5651322603225708, train/raw-loss = 0.5091952085494995, train/logprobs = tensor([[-0.5510, -1.5884],
        [-0.6783, -0.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07991009950637817
Epoch 0, Step 1139: train/loss = 0.4379066526889801, train/raw-loss = 0.35220545530319214, train/logprobs = tensor([[-0.5077, -2.3884],
        [-1.2366, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12243025004863739
Epoch 0, Step 1140: train/loss = 0.44208359718322754, train/raw-loss = 0.3779887557029724, train/logprobs = tensor([[-0.5213, -4.9616],
        [-0.9418, -0.9191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09156405925750732
Epoch 0, Step 1141: train/loss = 0.45042914152145386, train/raw-loss = 0.38962703943252563, train/logprobs = tensor([[-0.5411, -3.3496],
        [-0.8249, -1.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08686018735170364
Epoch 0, Step 1142: train/loss = 0.5916168689727783, train/raw-loss = 0.5347208976745605, train/logprobs = tensor([[-0.6601, -1.6598],
        [-1.1937, -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08127990365028381
Epoch 0, Step 1143: train/loss = 0.5690032839775085, train/raw-loss = 0.502909779548645, train/logprobs = tensor([[-0.5420, -1.5625],
        [-0.8411, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09441930800676346
Epoch 0, Step 1144: train/loss = 0.4849020838737488, train/raw-loss = 0.42708295583724976, train/logprobs = tensor([[-0.4187, -2.8544],
        [-0.5229, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0825987309217453
Epoch 0, Step 1145: train/loss = 0.3466717600822449, train/raw-loss = 0.2873631417751312, train/logprobs = tensor([[-0.4143, -5.4456],
        [-0.6004, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472659438848495
Epoch 0, Step 1146: train/loss = 0.2898271381855011, train/raw-loss = 0.20362767577171326, train/logprobs = tensor([[-0.5681, -8.8198],
        [-1.0582, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12314209342002869
Epoch 0, Step 1147: train/loss = 0.37135064601898193, train/raw-loss = 0.29391980171203613, train/logprobs = tensor([[-0.8168, -3.5603],
        [-1.2708, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11061554402112961
Epoch 0, Step 1148: train/loss = 0.5520648956298828, train/raw-loss = 0.4940032958984375, train/logprobs = tensor([[-0.5944, -1.2932],
        [-1.0017, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08294512331485748
Epoch 0, Step 1149: train/loss = 0.4050624966621399, train/raw-loss = 0.33615201711654663, train/logprobs = tensor([[-0.6610, -3.9196],
        [-1.2242, -0.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09844352304935455
Epoch 0, Step 1150: train/loss = 0.5547030568122864, train/raw-loss = 0.49111032485961914, train/logprobs = tensor([[-0.8162, -3.6437],
        [-0.5781, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09084674715995789
Epoch 0, Step 1151: train/loss = 0.3818635940551758, train/raw-loss = 0.30880555510520935, train/logprobs = tensor([[-0.7960, -6.2782],
        [-1.3324, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436861217021942
Epoch 0, Step 1152: train/loss = 0.2612939774990082, train/raw-loss = 0.1776677668094635, train/logprobs = tensor([[-0.6014, -5.9601],
        [-1.4071, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11946602165699005
Epoch 0, Step 1153: train/loss = 0.5058504939079285, train/raw-loss = 0.4450679123401642, train/logprobs = tensor([[-0.4032, -1.7747],
        [-0.6830, -0.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08683224022388458
Epoch 0, Step 1154: train/loss = 0.46523624658584595, train/raw-loss = 0.4049503803253174, train/logprobs = tensor([[-0.6054, -2.4950],
        [-1.0578, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08612261712551117
Epoch 0, Step 1155: train/loss = 0.4363453686237335, train/raw-loss = 0.38406097888946533, train/logprobs = tensor([[-0.4882, -2.7151],
        [-0.8917, -1.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07469198107719421
Epoch 0, Step 1156: train/loss = 0.5482872724533081, train/raw-loss = 0.4887678325176239, train/logprobs = tensor([[-0.5244, -1.4556],
        [-0.9383, -0.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0850277915596962
Epoch 0, Step 1157: train/loss = 0.4488847255706787, train/raw-loss = 0.37984657287597656, train/logprobs = tensor([[-0.7016, -5.4579],
        [-0.8416, -1.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09862594306468964
Epoch 0, Step 1158: train/loss = 0.3283790051937103, train/raw-loss = 0.25575610995292664, train/logprobs = tensor([[-0.6401, -4.7073],
        [-1.0800, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10374699532985687
Epoch 0, Step 1159: train/loss = 0.4158642590045929, train/raw-loss = 0.3528651297092438, train/logprobs = tensor([[-0.4562, -3.0222],
        [-0.6624, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08999873697757721
Epoch 0, Step 1160: train/loss = 0.5771225690841675, train/raw-loss = 0.5217190980911255, train/logprobs = tensor([[-0.5721, -2.5248],
        [-0.7895, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0791478157043457
Epoch 0, Step 1161: train/loss = 0.5393564701080322, train/raw-loss = 0.4616304039955139, train/logprobs = tensor([[-0.5925, -1.7003],
        [-0.8603, -0.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11103719472885132
Epoch 0, Step 1162: train/loss = 0.439151406288147, train/raw-loss = 0.373799592256546, train/logprobs = tensor([[-0.6359, -4.2372],
        [-1.1645, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09335976839065552
Epoch 0, Step 1163: train/loss = 0.35310348868370056, train/raw-loss = 0.2810213565826416, train/logprobs = tensor([[-0.5669, -5.2830],
        [-0.9125, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10297445207834244
Epoch 0, Step 1164: train/loss = 0.4465711712837219, train/raw-loss = 0.37940704822540283, train/logprobs = tensor([[-0.5154, -5.7475],
        [-0.8720, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09594874083995819
Epoch 0, Step 1165: train/loss = 0.430267333984375, train/raw-loss = 0.3697459101676941, train/logprobs = tensor([[-0.6228, -3.6684],
        [-0.9237, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08645911514759064
Epoch 0, Step 1166: train/loss = 0.3930724561214447, train/raw-loss = 0.31647661328315735, train/logprobs = tensor([[-0.5860, -2.7335],
        [-1.3140, -0.5686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10942265391349792
Epoch 0, Step 1167: train/loss = 0.5068457126617432, train/raw-loss = 0.4429120123386383, train/logprobs = tensor([[-0.4932, -3.8153],
        [-0.8238, -1.0542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133386611938477
Epoch 0, Step 1168: train/loss = 0.54404616355896, train/raw-loss = 0.483492910861969, train/logprobs = tensor([[-0.6871, -2.5058],
        [-0.9566, -1.1464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08650458604097366
Epoch 0, Step 1169: train/loss = 0.6453865766525269, train/raw-loss = 0.5740498900413513, train/logprobs = tensor([[-1.5766, -4.2820],
        [-0.9988, -1.0438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10190946608781815
Epoch 0, Step 1170: train/loss = 0.36022841930389404, train/raw-loss = 0.29921895265579224, train/logprobs = tensor([[-0.5303, -4.8586],
        [-0.8805, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08715638518333435
Epoch 0, Step 1171: train/loss = 0.5911668539047241, train/raw-loss = 0.5343228578567505, train/logprobs = tensor([[-0.6835, -2.3035],
        [-0.9719, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08120576292276382
Epoch 0, Step 1172: train/loss = 0.3460320830345154, train/raw-loss = 0.28129515051841736, train/logprobs = tensor([[-0.5645, -5.8480],
        [-0.9197, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09248127043247223
Epoch 0, Step 1173: train/loss = 0.3326844573020935, train/raw-loss = 0.2657351493835449, train/logprobs = tensor([[-0.6667, -5.0690],
        [-1.0162, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564188122749329
Epoch 0, Step 1174: train/loss = 0.5602352619171143, train/raw-loss = 0.510353147983551, train/logprobs = tensor([[-0.5200, -1.6669],
        [-0.8808, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07126004248857498
Epoch 0, Step 1175: train/loss = 0.4318171441555023, train/raw-loss = 0.36071792244911194, train/logprobs = tensor([[-0.7800, -4.1358],
        [-1.0036, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10157033056020737
Epoch 0, Step 1176: train/loss = 0.6399610042572021, train/raw-loss = 0.5939672589302063, train/logprobs = tensor([[-0.5931, -1.6561],
        [-0.9531, -1.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06570539623498917
Epoch 0, Step 1177: train/loss = 0.5310448408126831, train/raw-loss = 0.4660387337207794, train/logprobs = tensor([[-0.5377, -2.8617],
        [-0.8676, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09286585450172424
Epoch 0, Step 1178: train/loss = 0.6342966556549072, train/raw-loss = 0.576843798160553, train/logprobs = tensor([[-1.4295, -2.7874],
        [-0.8012, -0.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08207555115222931
Epoch 0, Step 1179: train/loss = 0.6114877462387085, train/raw-loss = 0.5404459238052368, train/logprobs = tensor([[-1.0142, -1.5687],
        [-0.9889, -0.7135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101488396525383
Epoch 0, Step 1180: train/loss = 0.6231170296669006, train/raw-loss = 0.5655834078788757, train/logprobs = tensor([[-0.6002, -0.9146],
        [-1.0011, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08219080418348312
Epoch 0, Step 1181: train/loss = 0.3926619291305542, train/raw-loss = 0.3358827233314514, train/logprobs = tensor([[-0.8101, -3.8998],
        [-0.9409, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08111318945884705
Epoch 0, Step 1182: train/loss = 0.5822066068649292, train/raw-loss = 0.5164615511894226, train/logprobs = tensor([[-0.7301, -4.0735],
        [-1.0822, -1.0584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09392143040895462
Epoch 0, Step 1183: train/loss = 0.6082683801651001, train/raw-loss = 0.5595659017562866, train/logprobs = tensor([[-0.5157, -1.6681],
        [-0.5904, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06957507133483887
Epoch 0, Step 1184: train/loss = 0.5855161547660828, train/raw-loss = 0.5180369019508362, train/logprobs = tensor([[-0.6860, -2.2211],
        [-0.9559, -0.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09639890491962433
Epoch 0, Step 1185: train/loss = 0.45493626594543457, train/raw-loss = 0.3917943239212036, train/logprobs = tensor([[-0.5739, -3.1593],
        [-1.1430, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09020279347896576
Epoch 0, Step 1186: train/loss = 0.5648499727249146, train/raw-loss = 0.5103252530097961, train/logprobs = tensor([[-0.5014, -3.2816],
        [-0.6391, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07789245247840881
Epoch 0, Step 1187: train/loss = 0.4018881320953369, train/raw-loss = 0.3331983685493469, train/logprobs = tensor([[-0.8860, -5.6973],
        [-0.8875, -1.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09812822192907333
Epoch 0, Step 1188: train/loss = 0.40787485241889954, train/raw-loss = 0.34247344732284546, train/logprobs = tensor([[-0.5820, -3.2324],
        [-1.1245, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09343055635690689
Epoch 0, Step 1189: train/loss = 0.4101645052433014, train/raw-loss = 0.34147828817367554, train/logprobs = tensor([[-0.5174, -2.3856],
        [-1.0241, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09812315553426743
Epoch 0, Step 1190: train/loss = 0.4809890687465668, train/raw-loss = 0.4173109233379364, train/logprobs = tensor([[-0.5561, -2.2980],
        [-0.9278, -0.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09096870571374893
Epoch 0, Step 1191: train/loss = 0.40364041924476624, train/raw-loss = 0.34683486819267273, train/logprobs = tensor([[-0.6008, -5.1026],
        [-0.8557, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08115075528621674
Epoch 0, Step 1192: train/loss = 0.32166028022766113, train/raw-loss = 0.25176802277565, train/logprobs = tensor([[-0.5562, -7.4238],
        [-0.9105, -1.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09984607249498367
Epoch 0, Step 1193: train/loss = 0.5614666938781738, train/raw-loss = 0.49238717555999756, train/logprobs = tensor([[-0.5621, -1.4278],
        [-1.1370, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868505597114563
Epoch 0, Step 1194: train/loss = 0.5683753490447998, train/raw-loss = 0.506702184677124, train/logprobs = tensor([[-1.0273, -3.1889],
        [-0.8120, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08810445666313171
Epoch 0, Step 1195: train/loss = 0.54404616355896, train/raw-loss = 0.4853564500808716, train/logprobs = tensor([[-0.7572, -3.7262],
        [-0.6714, -1.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384241908788681
Epoch 0, Step 1196: train/loss = 0.6217055320739746, train/raw-loss = 0.5533741116523743, train/logprobs = tensor([[-1.5103, -3.1687],
        [-1.0285, -0.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761622548103333
Epoch 0, Step 1197: train/loss = 0.2679876983165741, train/raw-loss = 0.19592151045799255, train/logprobs = tensor([[-0.4998, -5.4904],
        [-1.2114, -0.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295171290636063
Epoch 0, Step 1198: train/loss = 0.4632311761379242, train/raw-loss = 0.3921222388744354, train/logprobs = tensor([[-0.7874, -4.1460],
        [-1.1179, -1.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10158419609069824
Epoch 0, Step 1199: train/loss = 0.6628590822219849, train/raw-loss = 0.6107642650604248, train/logprobs = tensor([[-0.3920, -0.5767],
        [-0.5456, -0.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0744212344288826
Epoch 0, Step 1200: train/loss = 0.5016131401062012, train/raw-loss = 0.44362565875053406, train/logprobs = tensor([[-0.6857, -2.8970],
        [-0.7861, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0828392282128334
Epoch 0, Step 1201: train/loss = 0.5760024785995483, train/raw-loss = 0.5269091129302979, train/logprobs = tensor([[-0.5110, -1.7129],
        [-0.7046, -0.6187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07013343274593353
Epoch 0, Step 1202: train/loss = 0.3072880506515503, train/raw-loss = 0.23432683944702148, train/logprobs = tensor([[-0.6535, -7.6285],
        [-1.0572, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10423031449317932
Epoch 0, Step 1203: train/loss = 0.38673311471939087, train/raw-loss = 0.3192717432975769, train/logprobs = tensor([[-0.4272, -5.2656],
        [-0.9285, -1.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09637335687875748
Epoch 0, Step 1204: train/loss = 0.5004129409790039, train/raw-loss = 0.4427000880241394, train/logprobs = tensor([[-0.7353, -1.6486],
        [-1.1143, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08244685083627701
Epoch 0, Step 1205: train/loss = 0.5632279515266418, train/raw-loss = 0.4895913600921631, train/logprobs = tensor([[-0.6875, -2.4678],
        [-0.7145, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519515722990036
Epoch 0, Step 1206: train/loss = 0.4723706543445587, train/raw-loss = 0.40752294659614563, train/logprobs = tensor([[-0.6539, -4.3222],
        [-0.9319, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09263958036899567
Epoch 0, Step 1207: train/loss = 0.3654673099517822, train/raw-loss = 0.3009963035583496, train/logprobs = tensor([[-0.6000, -4.1113],
        [-0.9669, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09210142493247986
Epoch 0, Step 1208: train/loss = 0.3323748707771301, train/raw-loss = 0.2627817988395691, train/logprobs = tensor([[-0.6685, -3.9415],
        [-1.3483, -0.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941866248846054
Epoch 0, Step 1209: train/loss = 0.2896687388420105, train/raw-loss = 0.21267348527908325, train/logprobs = tensor([[-0.6816, -3.0200],
        [-1.7719, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10999322682619095
Epoch 0, Step 1210: train/loss = 0.4312796890735626, train/raw-loss = 0.3612160086631775, train/logprobs = tensor([[-0.4709, -2.5593],
        [-0.9309, -0.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10009101033210754
Epoch 0, Step 1211: train/loss = 0.30384498834609985, train/raw-loss = 0.23266386985778809, train/logprobs = tensor([[-0.6101, -4.3583],
        [-1.2200, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168728232383728
Epoch 0, Step 1212: train/loss = 0.5481806397438049, train/raw-loss = 0.496112585067749, train/logprobs = tensor([[-0.6547, -3.9378],
        [-0.7111, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07438289374113083
Epoch 0, Step 1213: train/loss = 0.46144238114356995, train/raw-loss = 0.398608922958374, train/logprobs = tensor([[-0.7596, -3.7982],
        [-0.8203, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08976209163665771
Epoch 0, Step 1214: train/loss = 0.4616755247116089, train/raw-loss = 0.39049097895622253, train/logprobs = tensor([[-0.5899, -3.7822],
        [-0.7669, -0.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10169222205877304
Epoch 0, Step 1215: train/loss = 0.45900022983551025, train/raw-loss = 0.392206609249115, train/logprobs = tensor([[-0.6329, -5.4689],
        [-0.9388, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541942179203033
Epoch 0, Step 1216: train/loss = 0.49292516708374023, train/raw-loss = 0.4359040856361389, train/logprobs = tensor([[-0.4735, -3.5299],
        [-0.8864, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0814586877822876
Epoch 0, Step 1217: train/loss = 0.4839050769805908, train/raw-loss = 0.4271772503852844, train/logprobs = tensor([[-0.9869, -5.4629],
        [-1.3044, -1.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08103980123996735
Epoch 0, Step 1218: train/loss = 0.4683672785758972, train/raw-loss = 0.4022202789783478, train/logprobs = tensor([[-0.6006, -3.3663],
        [-0.8919, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09449567645788193
Epoch 0, Step 1219: train/loss = 0.3955904245376587, train/raw-loss = 0.3198331892490387, train/logprobs = tensor([[-0.7115, -5.8945],
        [-1.1361, -0.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10822458565235138
Epoch 0, Step 1220: train/loss = 0.7173848748207092, train/raw-loss = 0.6639182567596436, train/logprobs = tensor([[-0.6049, -0.6117],
        [-0.5946, -0.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07638096809387207
Epoch 0, Step 1221: train/loss = 0.4358280599117279, train/raw-loss = 0.38954266905784607, train/logprobs = tensor([[-0.4526, -3.2997],
        [-0.6529, -0.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06612202525138855
Epoch 0, Step 1222: train/loss = 0.5297127962112427, train/raw-loss = 0.4678887724876404, train/logprobs = tensor([[-0.6793, -4.2581],
        [-1.2963, -1.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08831997215747833
Epoch 0, Step 1223: train/loss = 0.4242074489593506, train/raw-loss = 0.36729392409324646, train/logprobs = tensor([[-0.5232, -3.3933],
        [-0.8773, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08130504935979843
Epoch 0, Step 1224: train/loss = 0.5157243609428406, train/raw-loss = 0.4653318524360657, train/logprobs = tensor([[-0.3057, -2.1800],
        [-0.5011, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07198932766914368
Epoch 0, Step 1225: train/loss = 0.4340379238128662, train/raw-loss = 0.3899909257888794, train/logprobs = tensor([[-0.4237, -2.5695],
        [-0.5944, -0.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06292428076267242
Epoch 0, Step 1226: train/loss = 0.47734275460243225, train/raw-loss = 0.4220702052116394, train/logprobs = tensor([[-0.6791, -2.8708],
        [-0.6565, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07896076142787933
Epoch 0, Step 1227: train/loss = 0.54358971118927, train/raw-loss = 0.48131775856018066, train/logprobs = tensor([[-0.9762, -2.0409],
        [-0.9733, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08895979821681976
Epoch 0, Step 1228: train/loss = 0.5999498963356018, train/raw-loss = 0.5338414907455444, train/logprobs = tensor([[-0.5581, -1.4227],
        [-0.6822, -0.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09444062411785126
Epoch 0, Step 1229: train/loss = 0.4092050790786743, train/raw-loss = 0.35507622361183167, train/logprobs = tensor([[-0.4209, -5.1774],
        [-0.6097, -0.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07732691615819931
Epoch 0, Step 1230: train/loss = 0.6864250898361206, train/raw-loss = 0.6238936185836792, train/logprobs = tensor([[-1.3211, -1.8142],
        [-1.2520, -0.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08933060616254807
Epoch 0, Step 1231: train/loss = 0.524900496006012, train/raw-loss = 0.456461638212204, train/logprobs = tensor([[-0.7263, -1.8015],
        [-1.0247, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09776978194713593
Epoch 0, Step 1232: train/loss = 0.7922040224075317, train/raw-loss = 0.7472963929176331, train/logprobs = tensor([[-2.5593, -5.4772],
        [-1.6821, -2.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06415373086929321
Epoch 0, Step 1233: train/loss = 0.6032332181930542, train/raw-loss = 0.5387564897537231, train/logprobs = tensor([[-0.4672, -1.2883],
        [-0.6124, -0.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09210962802171707
Epoch 0, Step 1234: train/loss = 0.45020008087158203, train/raw-loss = 0.3868088722229004, train/logprobs = tensor([[-0.6294, -2.3816],
        [-1.1029, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09055886417627335
Epoch 0, Step 1235: train/loss = 0.6707651615142822, train/raw-loss = 0.6164505481719971, train/logprobs = tensor([[-1.2221, -4.9636],
        [-0.6983, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07759234309196472
Epoch 0, Step 1236: train/loss = 0.39921385049819946, train/raw-loss = 0.33851727843284607, train/logprobs = tensor([[-0.3552, -4.4721],
        [-0.6252, -0.7554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0867094174027443
Epoch 0, Step 1237: train/loss = 0.3736739456653595, train/raw-loss = 0.30902808904647827, train/logprobs = tensor([[-0.6325, -6.0974],
        [-1.1202, -1.2561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09235125780105591
Epoch 0, Step 1238: train/loss = 0.498073935508728, train/raw-loss = 0.4321718215942383, train/logprobs = tensor([[-0.6443, -3.5870],
        [-0.9538, -1.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09414582699537277
Epoch 0, Step 1239: train/loss = 0.5831944942474365, train/raw-loss = 0.5317586064338684, train/logprobs = tensor([[-0.7008, -2.3018],
        [-0.6153, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07347980886697769
Epoch 0, Step 1240: train/loss = 0.5181669592857361, train/raw-loss = 0.4559970200061798, train/logprobs = tensor([[-0.8503, -5.0388],
        [-1.2866, -1.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881422132253647
Epoch 0, Step 1241: train/loss = 0.43478912115097046, train/raw-loss = 0.3652569055557251, train/logprobs = tensor([[-0.5738, -2.5097],
        [-1.1129, -0.5214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09933172166347504
Epoch 0, Step 1242: train/loss = 0.492509126663208, train/raw-loss = 0.43071097135543823, train/logprobs = tensor([[-0.5935, -2.5708],
        [-1.0154, -0.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08828303217887878
Epoch 0, Step 1243: train/loss = 0.5619204044342041, train/raw-loss = 0.5010644793510437, train/logprobs = tensor([[-0.5427, -1.4811],
        [-0.8926, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0869370773434639
Epoch 0, Step 1244: train/loss = 0.47926953434944153, train/raw-loss = 0.4159931540489197, train/logprobs = tensor([[-0.5681, -1.8197],
        [-0.8908, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09039479494094849
Epoch 0, Step 1245: train/loss = 0.33705177903175354, train/raw-loss = 0.2553092837333679, train/logprobs = tensor([[-0.5116, -3.6101],
        [-1.4049, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1167750209569931
Epoch 0, Step 1246: train/loss = 0.35543206334114075, train/raw-loss = 0.2859581708908081, train/logprobs = tensor([[-0.5877, -2.6909],
        [-1.1829, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09924843907356262
Epoch 0, Step 1247: train/loss = 0.48039352893829346, train/raw-loss = 0.40806663036346436, train/logprobs = tensor([[-0.8810, -4.2455],
        [-0.8338, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10332415252923965
Epoch 0, Step 1248: train/loss = 0.5433015823364258, train/raw-loss = 0.47551167011260986, train/logprobs = tensor([[-0.5951, -1.7950],
        [-0.9545, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09684273600578308
Epoch 0, Step 1249: train/loss = 0.5909340381622314, train/raw-loss = 0.5254133939743042, train/logprobs = tensor([[-0.6700, -1.3478],
        [-0.8954, -0.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09360099583864212
Epoch 0, Step 1250: train/loss = 0.5741552114486694, train/raw-loss = 0.4938778281211853, train/logprobs = tensor([[-0.7220, -1.9503],
        [-0.8342, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11468200385570526
Epoch 0, Step 1251: train/loss = 0.4467293620109558, train/raw-loss = 0.3768311142921448, train/logprobs = tensor([[-0.4187, -3.4577],
        [-0.8699, -0.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09985463321208954
Epoch 0, Step 1252: train/loss = 0.3459717631340027, train/raw-loss = 0.2688939571380615, train/logprobs = tensor([[-0.6736, -5.6962],
        [-1.3646, -1.3182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11011114716529846
Epoch 0, Step 1253: train/loss = 0.4891248643398285, train/raw-loss = 0.4248003363609314, train/logprobs = tensor([[-0.5882, -2.0556],
        [-0.9309, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09189219772815704
Epoch 0, Step 1254: train/loss = 0.4905153512954712, train/raw-loss = 0.42955929040908813, train/logprobs = tensor([[-0.3966, -2.3406],
        [-0.6907, -0.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08708007633686066
Epoch 0, Step 1255: train/loss = 0.7007337808609009, train/raw-loss = 0.6484799981117249, train/logprobs = tensor([[-0.5070, -0.6650],
        [-0.6814, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07464833557605743
Epoch 0, Step 1256: train/loss = 0.43418270349502563, train/raw-loss = 0.36647140979766846, train/logprobs = tensor([[-0.8920, -2.0694],
        [-1.7210, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09673041105270386
Epoch 0, Step 1257: train/loss = 0.5421890020370483, train/raw-loss = 0.4802202582359314, train/logprobs = tensor([[-0.4262, -2.0532],
        [-0.5654, -0.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852680027484894
Epoch 0, Step 1258: train/loss = 0.41901251673698425, train/raw-loss = 0.36099836230278015, train/logprobs = tensor([[-0.6407, -2.8598],
        [-1.1610, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08287736773490906
Epoch 0, Step 1259: train/loss = 0.657119870185852, train/raw-loss = 0.5963417887687683, train/logprobs = tensor([[-0.3998, -1.0035],
        [-0.5749, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08682575076818466
Epoch 0, Step 1260: train/loss = 0.48625802993774414, train/raw-loss = 0.41451048851013184, train/logprobs = tensor([[-0.5900, -6.5640],
        [-1.1644, -1.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249646753072739
Epoch 0, Step 1261: train/loss = 0.5529327988624573, train/raw-loss = 0.46411681175231934, train/logprobs = tensor([[-0.5921, -2.4007],
        [-1.0515, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12687991559505463
Epoch 0, Step 1262: train/loss = 0.4662328362464905, train/raw-loss = 0.4047732949256897, train/logprobs = tensor([[-0.6047, -3.5596],
        [-0.9048, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0877993106842041
Epoch 0, Step 1263: train/loss = 0.4883037507534027, train/raw-loss = 0.4289267659187317, train/logprobs = tensor([[-0.6944, -2.5902],
        [-0.8821, -0.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08482427895069122
Epoch 0, Step 1264: train/loss = 0.37273383140563965, train/raw-loss = 0.30005812644958496, train/logprobs = tensor([[-0.7153, -3.2259],
        [-1.1790, -0.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382242500782013
Epoch 0, Step 1265: train/loss = 0.5137001872062683, train/raw-loss = 0.44234034419059753, train/logprobs = tensor([[-0.6689, -2.3524],
        [-1.1383, -0.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10194264352321625
Epoch 0, Step 1266: train/loss = 0.45383065938949585, train/raw-loss = 0.3882347345352173, train/logprobs = tensor([[-0.8744, -5.5727],
        [-1.0066, -1.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09370850026607513
Epoch 0, Step 1267: train/loss = 0.2977161705493927, train/raw-loss = 0.22522702813148499, train/logprobs = tensor([[-0.6446, -3.7759],
        [-1.4232, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355590283870697
Epoch 0, Step 1268: train/loss = 0.3490610718727112, train/raw-loss = 0.2814355492591858, train/logprobs = tensor([[-0.6678, -6.0411],
        [-1.4325, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09660787880420685
Epoch 0, Step 1269: train/loss = 0.4447130560874939, train/raw-loss = 0.3849374055862427, train/logprobs = tensor([[-0.7419, -3.1243],
        [-1.2868, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08539384603500366
Epoch 0, Step 1270: train/loss = 0.5547118186950684, train/raw-loss = 0.49376416206359863, train/logprobs = tensor([[-0.6886, -3.3504],
        [-0.8511, -0.9970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.087068110704422
Epoch 0, Step 1271: train/loss = 0.5587254166603088, train/raw-loss = 0.5103296041488647, train/logprobs = tensor([[-0.5903, -2.7486],
        [-0.5913, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06913680583238602
Epoch 0, Step 1272: train/loss = 0.38536709547042847, train/raw-loss = 0.3226701617240906, train/logprobs = tensor([[-0.6939, -3.2306],
        [-1.1769, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08956709504127502
Epoch 0, Step 1273: train/loss = 0.5813885927200317, train/raw-loss = 0.5204297304153442, train/logprobs = tensor([[-0.8504, -2.2724],
        [-0.7251, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08708404004573822
Epoch 0, Step 1274: train/loss = 0.5311905741691589, train/raw-loss = 0.4622887969017029, train/logprobs = tensor([[-0.3595, -2.5590],
        [-0.6534, -0.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843110293149948
Epoch 0, Step 1275: train/loss = 0.4718320667743683, train/raw-loss = 0.40197041630744934, train/logprobs = tensor([[-0.4476, -1.9196],
        [-0.9231, -0.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980235993862152
Epoch 0, Step 1276: train/loss = 0.3831886649131775, train/raw-loss = 0.32777759432792664, train/logprobs = tensor([[-0.5317, -6.6840],
        [-0.9260, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07915869355201721
Epoch 0, Step 1277: train/loss = 0.5666099190711975, train/raw-loss = 0.5096426010131836, train/logprobs = tensor([[-0.5520, -1.4361],
        [-0.6623, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08138187229633331
Epoch 0, Step 1278: train/loss = 0.3325001001358032, train/raw-loss = 0.26283133029937744, train/logprobs = tensor([[-0.3898, -4.2018],
        [-1.1198, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0995267853140831
Epoch 0, Step 1279: train/loss = 0.3283681869506836, train/raw-loss = 0.24281169474124908, train/logprobs = tensor([[-0.5538, -4.9194],
        [-1.2437, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12222356349229813
Epoch 0, Step 1280: train/loss = 0.4051399827003479, train/raw-loss = 0.33424702286720276, train/logprobs = tensor([[-0.5305, -3.9455],
        [-1.0142, -0.6192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10127557814121246
Epoch 0, Step 1281: train/loss = 0.4381793141365051, train/raw-loss = 0.3727269172668457, train/logprobs = tensor([[-0.5701, -3.5348],
        [-0.8005, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350341558456421
Epoch 0, Step 1282: train/loss = 0.5331003069877625, train/raw-loss = 0.48701274394989014, train/logprobs = tensor([[-0.3791, -2.1193],
        [-0.4921, -0.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06583944708108902
Epoch 0, Step 1283: train/loss = 0.5703608989715576, train/raw-loss = 0.510248601436615, train/logprobs = tensor([[-0.4047, -1.7731],
        [-0.6697, -0.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08587466925382614
Epoch 0, Step 1284: train/loss = 0.5315525531768799, train/raw-loss = 0.473261296749115, train/logprobs = tensor([[-0.4261, -3.0446],
        [-0.5979, -0.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0832732766866684
Epoch 0, Step 1285: train/loss = 0.2995142340660095, train/raw-loss = 0.23610886931419373, train/logprobs = tensor([[-0.6294, -6.3628],
        [-1.3799, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0905790627002716
Epoch 0, Step 1286: train/loss = 0.31425708532333374, train/raw-loss = 0.2597561180591583, train/logprobs = tensor([[-0.5460, -4.3935],
        [-1.1392, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07785850018262863
Epoch 0, Step 1287: train/loss = 0.47409331798553467, train/raw-loss = 0.41539591550827026, train/logprobs = tensor([[-0.4147, -4.4713],
        [-0.8631, -0.8901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08385344594717026
Epoch 0, Step 1288: train/loss = 0.6624548435211182, train/raw-loss = 0.6034237146377563, train/logprobs = tensor([[-0.8668, -2.2683],
        [-0.6911, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0843302458524704
Epoch 0, Step 1289: train/loss = 0.4355933368206024, train/raw-loss = 0.3758327066898346, train/logprobs = tensor([[-0.6322, -3.7476],
        [-1.0642, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08537230640649796
Epoch 0, Step 1290: train/loss = 0.45442262291908264, train/raw-loss = 0.390400230884552, train/logprobs = tensor([[-0.5767, -3.1218],
        [-0.9493, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09146055579185486
Epoch 0, Step 1291: train/loss = 0.43044790625572205, train/raw-loss = 0.36208575963974, train/logprobs = tensor([[-1.6045, -9.5386],
        [-1.5729, -1.9127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09766022861003876
Epoch 0, Step 1292: train/loss = 0.3921263813972473, train/raw-loss = 0.3207355737686157, train/logprobs = tensor([[-0.5715, -4.5856],
        [-1.1223, -1.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10198690742254257
Epoch 0, Step 1293: train/loss = 0.36838945746421814, train/raw-loss = 0.2895423173904419, train/logprobs = tensor([[-0.7187, -3.9359],
        [-1.6574, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11263877153396606
Epoch 0, Step 1294: train/loss = 0.4820968508720398, train/raw-loss = 0.4138692319393158, train/logprobs = tensor([[-0.7647, -2.2425],
        [-1.2852, -0.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974680706858635
Epoch 0, Step 1295: train/loss = 0.4267086386680603, train/raw-loss = 0.3725723624229431, train/logprobs = tensor([[-0.7369, -5.1596],
        [-1.3618, -1.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07733756303787231
Epoch 0, Step 1296: train/loss = 0.37032434344291687, train/raw-loss = 0.3101331293582916, train/logprobs = tensor([[-0.7342, -2.8621],
        [-1.3202, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08598743379116058
Epoch 0, Step 1297: train/loss = 0.4578285217285156, train/raw-loss = 0.3925844430923462, train/logprobs = tensor([[-0.5797, -6.0756],
        [-0.8268, -1.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0932057648897171
Epoch 0, Step 1298: train/loss = 0.5348067283630371, train/raw-loss = 0.46195265650749207, train/logprobs = tensor([[-0.9002, -1.4290],
        [-1.3873, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10407724976539612
Epoch 0, Step 1299: train/loss = 0.38332104682922363, train/raw-loss = 0.31554314494132996, train/logprobs = tensor([[-0.5009, -4.7357],
        [-1.1769, -1.3819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09682554006576538
Epoch 0, Step 1300: train/loss = 0.5236689448356628, train/raw-loss = 0.45335182547569275, train/logprobs = tensor([[-0.6766, -4.0501],
        [-1.0190, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10045293718576431
Epoch 0, Step 1301: train/loss = 0.5689581036567688, train/raw-loss = 0.5055142641067505, train/logprobs = tensor([[-0.6252, -1.4323],
        [-0.8768, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906340479850769
Epoch 0, Step 1302: train/loss = 0.5490024089813232, train/raw-loss = 0.4970821738243103, train/logprobs = tensor([[-0.4577, -1.1117],
        [-0.8386, -0.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741717666387558
Epoch 0, Step 1303: train/loss = 0.5427296161651611, train/raw-loss = 0.48771345615386963, train/logprobs = tensor([[-0.3666, -2.1808],
        [-0.7297, -0.3822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07859456539154053
Epoch 0, Step 1304: train/loss = 0.5485879182815552, train/raw-loss = 0.4851610064506531, train/logprobs = tensor([[-0.5500, -2.8167],
        [-1.0803, -0.9715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09060993790626526
Epoch 0, Step 1305: train/loss = 0.45169490575790405, train/raw-loss = 0.3873031735420227, train/logprobs = tensor([[-1.3207, -4.8929],
        [-1.3301, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09198813140392303
Epoch 0, Step 1306: train/loss = 0.3806724548339844, train/raw-loss = 0.30709579586982727, train/logprobs = tensor([[-1.2639, -4.1133],
        [-1.5403, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1051095575094223
Epoch 0, Step 1307: train/loss = 0.5519267320632935, train/raw-loss = 0.5031110048294067, train/logprobs = tensor([[-0.6936, -1.1532],
        [-1.0017, -0.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06973673403263092
Epoch 0, Step 1308: train/loss = 0.5251868367195129, train/raw-loss = 0.465870201587677, train/logprobs = tensor([[-0.4733, -2.8088],
        [-1.0911, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08473802357912064
Epoch 0, Step 1309: train/loss = 0.5090792179107666, train/raw-loss = 0.4475240111351013, train/logprobs = tensor([[-0.6686, -1.4624],
        [-1.0250, -0.5718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08793605864048004
Epoch 0, Step 1310: train/loss = 0.516437828540802, train/raw-loss = 0.4553300440311432, train/logprobs = tensor([[-0.5193, -2.7156],
        [-0.8554, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08729679882526398
Epoch 0, Step 1311: train/loss = 0.42280906438827515, train/raw-loss = 0.3622468113899231, train/logprobs = tensor([[-0.5489, -3.4600],
        [-1.1221, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08651752769947052
Epoch 0, Step 1312: train/loss = 0.5176917314529419, train/raw-loss = 0.45166563987731934, train/logprobs = tensor([[-0.5991, -1.9865],
        [-0.9820, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09432301670312881
Epoch 0, Step 1313: train/loss = 0.802674412727356, train/raw-loss = 0.7410205602645874, train/logprobs = tensor([[-1.2546, -1.4022],
        [-0.6556, -0.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08807700872421265
Epoch 0, Step 1314: train/loss = 0.804941713809967, train/raw-loss = 0.7439925670623779, train/logprobs = tensor([[-1.2083, -1.1053],
        [-0.8052, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08707007020711899
Epoch 0, Step 1315: train/loss = 0.3477829098701477, train/raw-loss = 0.2833382189273834, train/logprobs = tensor([[-0.4830, -8.7197],
        [-1.0893, -1.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09206382185220718
Epoch 0, Step 1316: train/loss = 0.525080680847168, train/raw-loss = 0.47059571743011475, train/logprobs = tensor([[-0.5412, -1.5835],
        [-0.8397, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07783564925193787
Epoch 0, Step 1317: train/loss = 0.5779858231544495, train/raw-loss = 0.513058602809906, train/logprobs = tensor([[-0.4670, -1.7135],
        [-0.9403, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09275314211845398
Epoch 0, Step 1318: train/loss = 0.4211893677711487, train/raw-loss = 0.3568299412727356, train/logprobs = tensor([[-0.5054, -4.9570],
        [-0.8379, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194202721118927
Epoch 0, Step 1319: train/loss = 0.37964171171188354, train/raw-loss = 0.30866649746894836, train/logprobs = tensor([[-0.5087, -3.0937],
        [-1.1793, -0.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10139315575361252
Epoch 0, Step 1320: train/loss = 0.47876250743865967, train/raw-loss = 0.414040207862854, train/logprobs = tensor([[-0.8288, -4.0551],
        [-1.3811, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09246042370796204
Epoch 0, Step 1321: train/loss = 0.595070481300354, train/raw-loss = 0.5321049690246582, train/logprobs = tensor([[-0.4414, -1.4949],
        [-0.6491, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995072543621063
Epoch 0, Step 1322: train/loss = 0.4936394691467285, train/raw-loss = 0.43555209040641785, train/logprobs = tensor([[-0.4674, -1.6726],
        [-0.8635, -0.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08298198133707047
Epoch 0, Step 1323: train/loss = 0.5771790742874146, train/raw-loss = 0.5322625637054443, train/logprobs = tensor([[-0.5723, -2.8193],
        [-0.4843, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06416640430688858
Epoch 0, Step 1324: train/loss = 0.48914045095443726, train/raw-loss = 0.4239806532859802, train/logprobs = tensor([[-0.4288, -4.3483],
        [-0.6700, -0.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09308544546365738
Epoch 0, Step 1325: train/loss = 0.6127926707267761, train/raw-loss = 0.5616756677627563, train/logprobs = tensor([[-0.3348, -1.9456],
        [-0.5439, -1.1758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07302432507276535
Epoch 0, Step 1326: train/loss = 0.47821033000946045, train/raw-loss = 0.4050029516220093, train/logprobs = tensor([[-1.1872, -4.2998],
        [-1.0897, -0.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10458198189735413
Epoch 0, Step 1327: train/loss = 0.5378954410552979, train/raw-loss = 0.46369823813438416, train/logprobs = tensor([[-1.3048, -2.5799],
        [-1.3582, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599599033594131
Epoch 0, Step 1328: train/loss = 0.43592369556427, train/raw-loss = 0.3717859387397766, train/logprobs = tensor([[-0.6416, -3.2170],
        [-0.8588, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916253849864006
Epoch 0, Step 1329: train/loss = 0.3263329863548279, train/raw-loss = 0.25523680448532104, train/logprobs = tensor([[-0.9200, -4.5588],
        [-1.5808, -0.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10156599432229996
Epoch 0, Step 1330: train/loss = 0.5669087171554565, train/raw-loss = 0.4940953254699707, train/logprobs = tensor([[-0.8290, -3.9488],
        [-0.8647, -1.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10401919484138489
Epoch 0, Step 1331: train/loss = 0.42876601219177246, train/raw-loss = 0.3544935882091522, train/logprobs = tensor([[-0.6873, -2.3163],
        [-1.1786, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610350966453552
Epoch 0, Step 1332: train/loss = 0.3625085949897766, train/raw-loss = 0.2855539321899414, train/logprobs = tensor([[-0.6127, -3.2783],
        [-1.0210, -0.5813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099352240562439
Epoch 0, Step 1333: train/loss = 0.5287324786186218, train/raw-loss = 0.4656559228897095, train/logprobs = tensor([[-0.6015, -2.4947],
        [-0.8493, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0901094377040863
Epoch 0, Step 1334: train/loss = 0.5901644229888916, train/raw-loss = 0.5229615569114685, train/logprobs = tensor([[-1.3528, -2.6224],
        [-1.5196, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09600413590669632
Epoch 0, Step 1335: train/loss = 0.40963998436927795, train/raw-loss = 0.3417869508266449, train/logprobs = tensor([[-1.5809, -4.7130],
        [-1.8300, -1.1679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09693292528390884
Epoch 0, Step 1336: train/loss = 0.4483603537082672, train/raw-loss = 0.386379599571228, train/logprobs = tensor([[-0.5803, -6.9544],
        [-0.8820, -1.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854387700557709
Epoch 0, Step 1337: train/loss = 0.5132549405097961, train/raw-loss = 0.4729357659816742, train/logprobs = tensor([[-0.3368, -4.2588],
        [-0.5527, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057598792016506195
Epoch 0, Step 1338: train/loss = 0.4175472855567932, train/raw-loss = 0.334409236907959, train/logprobs = tensor([[-0.5270, -3.0428],
        [-1.0882, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876866221427917
Epoch 0, Step 1339: train/loss = 0.4615626037120819, train/raw-loss = 0.38565579056739807, train/logprobs = tensor([[-0.8339, -2.5558],
        [-1.3927, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843830555677414
Epoch 0, Step 1340: train/loss = 0.32566314935684204, train/raw-loss = 0.24953143298625946, train/logprobs = tensor([[-0.5657, -3.5475],
        [-1.3721, -0.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10875964909791946
Epoch 0, Step 1341: train/loss = 0.4228050708770752, train/raw-loss = 0.37188422679901123, train/logprobs = tensor([[-0.6705, -2.8739],
        [-1.1681, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07274410128593445
Epoch 0, Step 1342: train/loss = 0.6572773456573486, train/raw-loss = 0.6059788465499878, train/logprobs = tensor([[-0.6570, -1.7346],
        [-0.4137, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07328350096940994
Epoch 0, Step 1343: train/loss = 0.33142417669296265, train/raw-loss = 0.26177889108657837, train/logprobs = tensor([[-0.6576, -2.7598],
        [-1.5368, -0.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09949325770139694
Epoch 0, Step 1344: train/loss = 0.6696813106536865, train/raw-loss = 0.6113489270210266, train/logprobs = tensor([[-1.4279, -2.8849],
        [-0.7966, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08333194255828857
Epoch 0, Step 1345: train/loss = 0.5828762054443359, train/raw-loss = 0.5079620480537415, train/logprobs = tensor([[-0.8328, -2.0260],
        [-1.1400, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702025890350342
Epoch 0, Step 1346: train/loss = 0.5636115074157715, train/raw-loss = 0.4913240671157837, train/logprobs = tensor([[-0.7945, -1.7985],
        [-0.9369, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10326783359050751
Epoch 0, Step 1347: train/loss = 0.5181422829627991, train/raw-loss = 0.45276930928230286, train/logprobs = tensor([[-0.7828, -2.2621],
        [-1.1095, -0.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339001029729843
Epoch 0, Step 1348: train/loss = 0.5335085988044739, train/raw-loss = 0.48693686723709106, train/logprobs = tensor([[-0.6883, -1.5176],
        [-1.1556, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06653104722499847
Epoch 0, Step 1349: train/loss = 0.5113888382911682, train/raw-loss = 0.45349133014678955, train/logprobs = tensor([[-0.7152, -1.7743],
        [-1.0447, -0.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08271072804927826
Epoch 0, Step 1350: train/loss = 0.3817334473133087, train/raw-loss = 0.32598376274108887, train/logprobs = tensor([[-0.5172, -5.6406],
        [-0.9261, -1.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07964245975017548
Epoch 0, Step 1351: train/loss = 0.5118030309677124, train/raw-loss = 0.45019763708114624, train/logprobs = tensor([[-1.0362, -2.4393],
        [-1.3342, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08800764381885529
Epoch 0, Step 1352: train/loss = 0.5645660161972046, train/raw-loss = 0.5196453928947449, train/logprobs = tensor([[-0.5400, -1.5847],
        [-0.6843, -0.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06417239457368851
Epoch 0, Step 1353: train/loss = 0.599452018737793, train/raw-loss = 0.5523631572723389, train/logprobs = tensor([[-0.4980, -2.7466],
        [-0.6064, -0.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06726976484060287
Epoch 0, Step 1354: train/loss = 0.5033798217773438, train/raw-loss = 0.4262832999229431, train/logprobs = tensor([[-0.5607, -1.5790],
        [-1.2207, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11013790965080261
Epoch 0, Step 1355: train/loss = 0.27232685685157776, train/raw-loss = 0.21225321292877197, train/logprobs = tensor([[-0.6065, -5.9151],
        [-1.0771, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08581951260566711
Epoch 0, Step 1356: train/loss = 0.54190593957901, train/raw-loss = 0.4844542443752289, train/logprobs = tensor([[-0.7211, -2.4176],
        [-0.9271, -0.5145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08207384496927261
Epoch 0, Step 1357: train/loss = 0.6360729336738586, train/raw-loss = 0.578083872795105, train/logprobs = tensor([[-0.4345, -0.9395],
        [-0.6934, -0.6417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08284148573875427
Epoch 0, Step 1358: train/loss = 0.37058892846107483, train/raw-loss = 0.30300652980804443, train/logprobs = tensor([[-0.5457, -3.3470],
        [-1.2067, -0.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654628485441208
Epoch 0, Step 1359: train/loss = 0.5945160388946533, train/raw-loss = 0.5187923908233643, train/logprobs = tensor([[-0.4497, -2.1839],
        [-0.7955, -0.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10817655175924301
Epoch 0, Step 1360: train/loss = 0.4124335050582886, train/raw-loss = 0.3555436134338379, train/logprobs = tensor([[-0.5774, -2.9031],
        [-0.9160, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08127128332853317
Epoch 0, Step 1361: train/loss = 0.41971147060394287, train/raw-loss = 0.3569451570510864, train/logprobs = tensor([[-0.6994, -3.3779],
        [-0.9160, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08966619521379471
Epoch 0, Step 1362: train/loss = 0.455864280462265, train/raw-loss = 0.37982696294784546, train/logprobs = tensor([[-0.5834, -2.7629],
        [-1.3855, -0.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10862475633621216
Epoch 0, Step 1363: train/loss = 0.577829122543335, train/raw-loss = 0.5338192582130432, train/logprobs = tensor([[-0.3589, -1.6737],
        [-0.6916, -0.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06287126243114471
Epoch 0, Step 1364: train/loss = 0.46656104922294617, train/raw-loss = 0.4074452221393585, train/logprobs = tensor([[-0.4109, -3.0442],
        [-0.7033, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445120602846146
Epoch 0, Step 1365: train/loss = 0.4247690439224243, train/raw-loss = 0.3673667311668396, train/logprobs = tensor([[-0.3484, -3.8200],
        [-0.6526, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08200325071811676
Epoch 0, Step 1366: train/loss = 0.5559688806533813, train/raw-loss = 0.5063998699188232, train/logprobs = tensor([[-0.3673, -2.9788],
        [-0.5828, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07081283628940582
Epoch 0, Step 1367: train/loss = 0.3956082761287689, train/raw-loss = 0.3304736316204071, train/logprobs = tensor([[-0.5653, -3.7291],
        [-1.3483, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09304948151111603
Epoch 0, Step 1368: train/loss = 0.6097143292427063, train/raw-loss = 0.5556550025939941, train/logprobs = tensor([[-0.5647, -1.6653],
        [-0.7166, -0.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07722756266593933
Epoch 0, Step 1369: train/loss = 0.4806431531906128, train/raw-loss = 0.41188788414001465, train/logprobs = tensor([[-0.4671, -1.6574],
        [-1.3749, -0.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09822183102369308
Epoch 0, Step 1370: train/loss = 0.5694612264633179, train/raw-loss = 0.5087361335754395, train/logprobs = tensor([[-0.6073, -1.3511],
        [-0.8813, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0867500975728035
Epoch 0, Step 1371: train/loss = 0.4867711067199707, train/raw-loss = 0.4314514696598053, train/logprobs = tensor([[-0.5164, -2.9815],
        [-0.8635, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07902804762125015
Epoch 0, Step 1372: train/loss = 0.39425429701805115, train/raw-loss = 0.3305346369743347, train/logprobs = tensor([[-0.5882, -5.0748],
        [-1.1555, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09102810174226761
Epoch 0, Step 1373: train/loss = 0.541368842124939, train/raw-loss = 0.48867762088775635, train/logprobs = tensor([[-1.1375, -1.9832],
        [-1.5982, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07527318596839905
Epoch 0, Step 1374: train/loss = 0.4680444002151489, train/raw-loss = 0.4139004349708557, train/logprobs = tensor([[-0.3911, -2.9772],
        [-0.8228, -0.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734853774309158
Epoch 0, Step 1375: train/loss = 0.3757209777832031, train/raw-loss = 0.31808358430862427, train/logprobs = tensor([[-0.5797, -5.2377],
        [-0.9906, -1.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08233912289142609
Epoch 0, Step 1376: train/loss = 0.36947062611579895, train/raw-loss = 0.2988165020942688, train/logprobs = tensor([[-0.9033, -3.1933],
        [-1.6791, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10093450546264648
Epoch 0, Step 1377: train/loss = 0.5078452825546265, train/raw-loss = 0.4506170451641083, train/logprobs = tensor([[-0.4317, -3.3546],
        [-0.7359, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817546546459198
Epoch 0, Step 1378: train/loss = 0.5361353754997253, train/raw-loss = 0.4779530167579651, train/logprobs = tensor([[-0.7233, -2.5298],
        [-0.8115, -0.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08311768621206284
Epoch 0, Step 1379: train/loss = 0.5387953519821167, train/raw-loss = 0.469282329082489, train/logprobs = tensor([[-0.7802, -2.2120],
        [-1.0450, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930431842803955
Epoch 0, Step 1380: train/loss = 0.30981552600860596, train/raw-loss = 0.23470501601696014, train/logprobs = tensor([[-0.4651, -4.5081],
        [-1.0501, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073007807135582
Epoch 0, Step 1381: train/loss = 0.43094491958618164, train/raw-loss = 0.36313706636428833, train/logprobs = tensor([[-0.4961, -5.3683],
        [-0.8373, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09686833620071411
Epoch 0, Step 1382: train/loss = 0.4409335255622864, train/raw-loss = 0.37376856803894043, train/logprobs = tensor([[-0.7575, -3.7194],
        [-1.0544, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0959499254822731
Epoch 0, Step 1383: train/loss = 0.3570360839366913, train/raw-loss = 0.2986771762371063, train/logprobs = tensor([[-0.7733, -3.9774],
        [-1.3370, -1.7162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08336988091468811
Epoch 0, Step 1384: train/loss = 0.5093239545822144, train/raw-loss = 0.4497849941253662, train/logprobs = tensor([[-0.5389, -2.9696],
        [-0.8941, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08505567908287048
Epoch 0, Step 1385: train/loss = 0.44822990894317627, train/raw-loss = 0.36526238918304443, train/logprobs = tensor([[-0.6651, -1.9829],
        [-1.4962, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852502822875977
Epoch 0, Step 1386: train/loss = 0.4312502145767212, train/raw-loss = 0.35045453906059265, train/logprobs = tensor([[-0.6483, -2.0588],
        [-1.2140, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11542242765426636
Epoch 0, Step 1387: train/loss = 0.5404176115989685, train/raw-loss = 0.46981996297836304, train/logprobs = tensor([[-0.5424, -1.3042],
        [-1.0109, -0.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10085370391607285
Epoch 0, Step 1388: train/loss = 0.3798832297325134, train/raw-loss = 0.32334697246551514, train/logprobs = tensor([[-0.9479, -3.2242],
        [-1.3321, -0.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08076605200767517
Epoch 0, Step 1389: train/loss = 0.5661408305168152, train/raw-loss = 0.4923168122768402, train/logprobs = tensor([[-0.9190, -2.6980],
        [-1.0089, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10546288639307022
Epoch 0, Step 1390: train/loss = 0.5445433259010315, train/raw-loss = 0.48026448488235474, train/logprobs = tensor([[-0.4798, -1.4308],
        [-0.7860, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182693064212799
Epoch 0, Step 1391: train/loss = 0.4579780697822571, train/raw-loss = 0.3951232433319092, train/logprobs = tensor([[-0.5266, -2.4127],
        [-0.8451, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08979260921478271
Epoch 0, Step 1392: train/loss = 0.38784778118133545, train/raw-loss = 0.3299916088581085, train/logprobs = tensor([[-0.5890, -5.8358],
        [-0.9733, -1.2093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08265170454978943
Epoch 0, Step 1393: train/loss = 0.36794233322143555, train/raw-loss = 0.2872789800167084, train/logprobs = tensor([[-0.5398, -5.7571],
        [-1.2828, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11523336172103882
Epoch 0, Step 1394: train/loss = 0.4636557996273041, train/raw-loss = 0.3940196633338928, train/logprobs = tensor([[-0.5071, -1.6853],
        [-1.0968, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09948017448186874
Epoch 0, Step 1395: train/loss = 0.4536726474761963, train/raw-loss = 0.3733817934989929, train/logprobs = tensor([[-0.6375, -2.7961],
        [-1.0233, -0.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11470120400190353
Epoch 0, Step 1396: train/loss = 0.3956491947174072, train/raw-loss = 0.3110210597515106, train/logprobs = tensor([[-0.6765, -4.4839],
        [-1.1201, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1208973228931427
Epoch 0, Step 1397: train/loss = 0.37439537048339844, train/raw-loss = 0.3182174265384674, train/logprobs = tensor([[-0.4883, -7.1980],
        [-0.7129, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08025418221950531
Epoch 0, Step 1398: train/loss = 0.3046795129776001, train/raw-loss = 0.20780065655708313, train/logprobs = tensor([[-0.7460, -3.7881],
        [-1.4484, -0.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13839831948280334
Epoch 0, Step 1399: train/loss = 0.38476669788360596, train/raw-loss = 0.30185770988464355, train/logprobs = tensor([[-0.4608, -2.8491],
        [-1.5065, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1184413954615593
Epoch 0, Step 1400: train/loss = 0.5548698306083679, train/raw-loss = 0.48296892642974854, train/logprobs = tensor([[-0.6084, -7.1270],
        [-0.9300, -2.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271550714969635
Epoch 0, Step 1401: train/loss = 0.41837453842163086, train/raw-loss = 0.3276829123497009, train/logprobs = tensor([[-0.9052, -4.7496],
        [-1.5409, -1.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295594871044159
Epoch 0, Step 1402: train/loss = 0.4198280870914459, train/raw-loss = 0.3517860472202301, train/logprobs = tensor([[-0.5449, -3.0814],
        [-1.0789, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09720290452241898
Epoch 0, Step 1403: train/loss = 0.4412904679775238, train/raw-loss = 0.37643301486968994, train/logprobs = tensor([[-1.0844, -3.9354],
        [-1.0225, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0926535353064537
Epoch 0, Step 1404: train/loss = 0.4060969650745392, train/raw-loss = 0.3428041934967041, train/logprobs = tensor([[-0.6071, -6.7763],
        [-1.1979, -1.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904182642698288
Epoch 0, Step 1405: train/loss = 0.490642786026001, train/raw-loss = 0.4109928011894226, train/logprobs = tensor([[-0.5779, -4.7235],
        [-1.1535, -1.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11378571391105652
Epoch 0, Step 1406: train/loss = 0.5386545658111572, train/raw-loss = 0.48031872510910034, train/logprobs = tensor([[-0.4388, -1.5707],
        [-0.7551, -0.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08333691954612732
Epoch 0, Step 1407: train/loss = 0.4357697665691376, train/raw-loss = 0.3751966059207916, train/logprobs = tensor([[-0.7021, -6.0257],
        [-0.8748, -1.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08653312921524048
Epoch 0, Step 1408: train/loss = 0.2538699507713318, train/raw-loss = 0.18819379806518555, train/logprobs = tensor([[-0.5253, -8.6428],
        [-1.2010, -1.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382309019565582
Epoch 0, Step 1409: train/loss = 0.634817898273468, train/raw-loss = 0.5778656601905823, train/logprobs = tensor([[-0.5307, -0.9155],
        [-0.7306, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08136032521724701
Epoch 0, Step 1410: train/loss = 0.4464062452316284, train/raw-loss = 0.3620266020298004, train/logprobs = tensor([[-0.6484, -3.2868],
        [-1.3181, -0.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12054235488176346
Epoch 0, Step 1411: train/loss = 0.48316407203674316, train/raw-loss = 0.41504034399986267, train/logprobs = tensor([[-0.3866, -3.0066],
        [-0.7902, -0.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09731961041688919
Epoch 0, Step 1412: train/loss = 0.42338472604751587, train/raw-loss = 0.35463589429855347, train/logprobs = tensor([[-0.5334, -1.9673],
        [-1.2106, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982125774025917
Epoch 0, Step 1413: train/loss = 0.41529715061187744, train/raw-loss = 0.35577037930488586, train/logprobs = tensor([[-0.6659, -3.2341],
        [-0.9208, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0850382000207901
Epoch 0, Step 1414: train/loss = 0.5101475119590759, train/raw-loss = 0.45589685440063477, train/logprobs = tensor([[-0.6361, -4.2701],
        [-1.0426, -1.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07750093191862106
Epoch 0, Step 1415: train/loss = 0.5773977637290955, train/raw-loss = 0.5330862998962402, train/logprobs = tensor([[-0.4296, -1.0244],
        [-0.6767, -0.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330211460590363
Epoch 0, Step 1416: train/loss = 0.3779984712600708, train/raw-loss = 0.32004502415657043, train/logprobs = tensor([[-0.6915, -6.8982],
        [-1.1322, -1.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08279062807559967
Epoch 0, Step 1417: train/loss = 0.33432331681251526, train/raw-loss = 0.26894044876098633, train/logprobs = tensor([[-0.4129, -5.9325],
        [-0.9640, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09340406954288483
Epoch 0, Step 1418: train/loss = 0.49762511253356934, train/raw-loss = 0.4343814253807068, train/logprobs = tensor([[-0.6816, -2.4361],
        [-0.9467, -1.0219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09034819155931473
Epoch 0, Step 1419: train/loss = 0.5967002511024475, train/raw-loss = 0.5466828346252441, train/logprobs = tensor([[-0.3642, -1.2288],
        [-0.6795, -0.4516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07145336270332336
Epoch 0, Step 1420: train/loss = 0.4159294068813324, train/raw-loss = 0.3513290286064148, train/logprobs = tensor([[-0.3925, -3.3996],
        [-0.9014, -0.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09228625148534775
Epoch 0, Step 1421: train/loss = 0.5639419555664062, train/raw-loss = 0.5075094699859619, train/logprobs = tensor([[-0.4951, -2.4750],
        [-0.9130, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08061790466308594
Epoch 0, Step 1422: train/loss = 0.6208479404449463, train/raw-loss = 0.5753345489501953, train/logprobs = tensor([[-0.2782, -0.9697],
        [-0.4849, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06501910090446472
Epoch 0, Step 1423: train/loss = 0.4485945701599121, train/raw-loss = 0.39323848485946655, train/logprobs = tensor([[-0.4039, -2.6471],
        [-0.7445, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07908016443252563
Epoch 0, Step 1424: train/loss = 0.24860705435276031, train/raw-loss = 0.1723380982875824, train/logprobs = tensor([[-0.5777, -6.8719],
        [-1.5999, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10895563662052155
Epoch 0, Step 1425: train/loss = 0.3420112729072571, train/raw-loss = 0.2771962881088257, train/logprobs = tensor([[-0.7356, -3.8070],
        [-1.3297, -1.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09259279072284698
Epoch 0, Step 1426: train/loss = 0.3611333966255188, train/raw-loss = 0.2917451858520508, train/logprobs = tensor([[-0.6339, -7.3611],
        [-1.2801, -1.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09912599623203278
Epoch 0, Step 1427: train/loss = 0.5190297365188599, train/raw-loss = 0.45444929599761963, train/logprobs = tensor([[-0.5870, -1.8806],
        [-1.0621, -0.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09225773811340332
Epoch 0, Step 1428: train/loss = 0.4020981192588806, train/raw-loss = 0.33626529574394226, train/logprobs = tensor([[-0.4829, -3.6072],
        [-1.0953, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940469354391098
Epoch 0, Step 1429: train/loss = 0.39072859287261963, train/raw-loss = 0.31807029247283936, train/logprobs = tensor([[-0.7201, -5.3890],
        [-1.1425, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10379759967327118
Epoch 0, Step 1430: train/loss = 0.3738151490688324, train/raw-loss = 0.310152530670166, train/logprobs = tensor([[-0.9683, -5.7431],
        [-1.5548, -2.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09094653278589249
Epoch 0, Step 1431: train/loss = 0.2639167904853821, train/raw-loss = 0.18189890682697296, train/logprobs = tensor([[ -0.6699, -11.0246],
        [ -1.4407,  -2.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716841161251068
Epoch 0, Step 1432: train/loss = 0.6186667680740356, train/raw-loss = 0.5411999225616455, train/logprobs = tensor([[-0.4608, -4.5064],
        [-1.4657, -1.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066687107086182
Epoch 0, Step 1433: train/loss = 0.4840945601463318, train/raw-loss = 0.4249219596385956, train/logprobs = tensor([[-0.4238, -2.7547],
        [-1.0609, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08453231304883957
Epoch 0, Step 1434: train/loss = 0.3291911482810974, train/raw-loss = 0.24556228518486023, train/logprobs = tensor([[-0.5697, -3.8054],
        [-1.4644, -0.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11946979910135269
Epoch 0, Step 1435: train/loss = 0.4002244174480438, train/raw-loss = 0.312591552734375, train/logprobs = tensor([[-0.5828, -4.8978],
        [-1.4811, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12518981099128723
Epoch 0, Step 1436: train/loss = 0.45086997747421265, train/raw-loss = 0.3940432071685791, train/logprobs = tensor([[-1.1843, -7.0389],
        [-1.2056, -1.4902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08118109405040741
Epoch 0, Step 1437: train/loss = 0.458667516708374, train/raw-loss = 0.40382423996925354, train/logprobs = tensor([[-0.4269, -6.1783],
        [-0.9635, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834754884243011
Epoch 0, Step 1438: train/loss = 0.2418108582496643, train/raw-loss = 0.17839613556861877, train/logprobs = tensor([[-0.7122, -8.1048],
        [-1.8217, -1.3456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09059247374534607
Epoch 0, Step 1439: train/loss = 0.43496599793434143, train/raw-loss = 0.386391282081604, train/logprobs = tensor([[-0.5993, -3.0068],
        [-1.2554, -0.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06939245015382767
Epoch 0, Step 1440: train/loss = 0.4845447540283203, train/raw-loss = 0.41719526052474976, train/logprobs = tensor([[-0.5369, -2.7232],
        [-1.0338, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09621358662843704
Epoch 0, Step 1441: train/loss = 0.6530470848083496, train/raw-loss = 0.5873225927352905, train/logprobs = tensor([[-0.7263, -1.2702],
        [-0.7851, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09389209747314453
Epoch 0, Step 1442: train/loss = 0.25371378660202026, train/raw-loss = 0.17484340071678162, train/logprobs = tensor([[-0.7666, -4.8052],
        [-1.7584, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11267197877168655
Epoch 0, Step 1443: train/loss = 0.6305733919143677, train/raw-loss = 0.5707268714904785, train/logprobs = tensor([[-0.7959, -2.7605],
        [-0.7618, -0.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0854950025677681
Epoch 0, Step 1444: train/loss = 0.3924262225627899, train/raw-loss = 0.30592578649520874, train/logprobs = tensor([[-0.6620, -3.0010],
        [-1.6645, -0.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12357200682163239
Epoch 0, Step 1445: train/loss = 0.46932312846183777, train/raw-loss = 0.4138467311859131, train/logprobs = tensor([[-0.3198, -2.6807],
        [-0.6711, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792519599199295
Epoch 0, Step 1446: train/loss = 0.510315477848053, train/raw-loss = 0.44331830739974976, train/logprobs = tensor([[-1.0275, -6.4263],
        [-1.2264, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09571017324924469
Epoch 0, Step 1447: train/loss = 0.45168817043304443, train/raw-loss = 0.38699817657470703, train/logprobs = tensor([[-1.0387, -3.2174],
        [-1.0569, -0.7238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09241433441638947
Epoch 0, Step 1448: train/loss = 0.46672162413597107, train/raw-loss = 0.3905433118343353, train/logprobs = tensor([[-0.8682, -3.0318],
        [-0.8875, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088261753320694
Epoch 0, Step 1449: train/loss = 0.5287052989006042, train/raw-loss = 0.4655139446258545, train/logprobs = tensor([[-0.4770, -4.1742],
        [-0.9457, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09027333557605743
Epoch 0, Step 1450: train/loss = 0.40219640731811523, train/raw-loss = 0.3367292881011963, train/logprobs = tensor([[-0.3949, -2.8893],
        [-0.8554, -0.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09352441132068634
Epoch 0, Step 1451: train/loss = 0.44311362504959106, train/raw-loss = 0.36820828914642334, train/logprobs = tensor([[-0.6551, -3.9118],
        [-1.2751, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700765252113342
Epoch 0, Step 1452: train/loss = 0.474016934633255, train/raw-loss = 0.3962593972682953, train/logprobs = tensor([[-0.5152, -5.4492],
        [-1.1915, -1.3902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11108217388391495
Epoch 0, Step 1453: train/loss = 0.40996673703193665, train/raw-loss = 0.3478429615497589, train/logprobs = tensor([[-0.5364, -2.6908],
        [-1.0395, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08874823153018951
Epoch 0, Step 1454: train/loss = 0.3841080069541931, train/raw-loss = 0.3111535906791687, train/logprobs = tensor([[-0.6172, -3.3165],
        [-1.4379, -1.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422060638666153
Epoch 0, Step 1455: train/loss = 0.30442309379577637, train/raw-loss = 0.23505061864852905, train/logprobs = tensor([[-0.4976, -4.8006],
        [-1.7549, -1.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09910351783037186
Epoch 0, Step 1456: train/loss = 0.35554853081703186, train/raw-loss = 0.2991522550582886, train/logprobs = tensor([[-0.6817, -6.2139],
        [-1.0033, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08056607842445374
Epoch 0, Step 1457: train/loss = 0.3953896164894104, train/raw-loss = 0.3322816491127014, train/logprobs = tensor([[-0.5991, -4.4966],
        [-1.2158, -1.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0901542529463768
Epoch 0, Step 1458: train/loss = 0.6547916531562805, train/raw-loss = 0.5896762609481812, train/logprobs = tensor([[-0.5935, -0.8335],
        [-0.9512, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09302202612161636
Epoch 0, Step 1459: train/loss = 0.2930147051811218, train/raw-loss = 0.20536622405052185, train/logprobs = tensor([[-0.5453, -6.3405],
        [-1.6282, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12521208822727203
Epoch 0, Step 1460: train/loss = 0.3264663517475128, train/raw-loss = 0.2582390606403351, train/logprobs = tensor([[-0.8318, -5.7169],
        [-1.4283, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974675640463829
Epoch 0, Step 1461: train/loss = 0.541489839553833, train/raw-loss = 0.4584236145019531, train/logprobs = tensor([[-0.5531, -1.9724],
        [-1.4579, -0.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11866602301597595
Epoch 0, Step 1462: train/loss = 0.4311845302581787, train/raw-loss = 0.3588895797729492, train/logprobs = tensor([[-0.5529, -2.5413],
        [-1.1269, -0.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10327848047018051
Epoch 0, Step 1463: train/loss = 0.33485621213912964, train/raw-loss = 0.2510751485824585, train/logprobs = tensor([[-0.6661, -3.4597],
        [-1.7736, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11968724429607391
Epoch 0, Step 1464: train/loss = 0.4848315119743347, train/raw-loss = 0.4163244664669037, train/logprobs = tensor([[-0.5211, -2.9537],
        [-0.9833, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09786723554134369
Epoch 0, Step 1465: train/loss = 0.35313358902931213, train/raw-loss = 0.2932990491390228, train/logprobs = tensor([[-0.6432, -4.9986],
        [-1.4444, -1.5065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08547794073820114
Epoch 0, Step 1466: train/loss = 0.4924193024635315, train/raw-loss = 0.42831507325172424, train/logprobs = tensor([[-0.5356, -3.1836],
        [-0.7894, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0915774554014206
Epoch 0, Step 1467: train/loss = 0.3804277181625366, train/raw-loss = 0.3104085326194763, train/logprobs = tensor([[-0.7143, -6.8803],
        [-1.5491, -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10002743452787399
Epoch 0, Step 1468: train/loss = 0.5079525709152222, train/raw-loss = 0.44443291425704956, train/logprobs = tensor([[-1.0770, -5.6503],
        [-1.3824, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09074236452579498
Epoch 0, Step 1469: train/loss = 0.43536362051963806, train/raw-loss = 0.36847561597824097, train/logprobs = tensor([[-0.4511, -2.5860],
        [-0.8666, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09555428475141525
Epoch 0, Step 1470: train/loss = 0.342920184135437, train/raw-loss = 0.2566477060317993, train/logprobs = tensor([[-0.5974, -3.6582],
        [-1.1874, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12324641644954681
Epoch 0, Step 1471: train/loss = 0.4905802607536316, train/raw-loss = 0.417670339345932, train/logprobs = tensor([[-0.4479, -1.9610],
        [-1.0099, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10415700078010559
Epoch 0, Step 1472: train/loss = 0.4119941294193268, train/raw-loss = 0.3596231937408447, train/logprobs = tensor([[-0.5039, -6.9351],
        [-0.7553, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07481560856103897
Epoch 0, Step 1473: train/loss = 0.3749651610851288, train/raw-loss = 0.29654404520988464, train/logprobs = tensor([[-0.6071, -2.9710],
        [-1.1918, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11203022301197052
Epoch 0, Step 1474: train/loss = 0.47067296504974365, train/raw-loss = 0.4028048515319824, train/logprobs = tensor([[-0.6581, -2.5127],
        [-1.0172, -1.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09695447236299515
Epoch 0, Step 1475: train/loss = 0.5169196128845215, train/raw-loss = 0.4516029953956604, train/logprobs = tensor([[-0.6180, -1.7468],
        [-1.1253, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09330946952104568
Epoch 0, Step 1476: train/loss = 0.5442394018173218, train/raw-loss = 0.467524915933609, train/logprobs = tensor([[-0.9282, -2.6389],
        [-1.0578, -1.5572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10959208011627197
Epoch 0, Step 1477: train/loss = 0.34504517912864685, train/raw-loss = 0.27168652415275574, train/logprobs = tensor([[-0.8865, -4.4511],
        [-1.5017, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047981008887291
Epoch 0, Step 1478: train/loss = 0.6189303994178772, train/raw-loss = 0.5486546158790588, train/logprobs = tensor([[-0.4709, -0.8417],
        [-1.0227, -0.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039393603801727
Epoch 0, Step 1479: train/loss = 0.5348721146583557, train/raw-loss = 0.45119717717170715, train/logprobs = tensor([[-0.4816, -2.0690],
        [-1.0806, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11953562498092651
Epoch 0, Step 1480: train/loss = 0.4300515353679657, train/raw-loss = 0.3581305742263794, train/logprobs = tensor([[-0.6916, -3.6716],
        [-1.6614, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10274427384138107
Epoch 0, Step 1481: train/loss = 0.4276053309440613, train/raw-loss = 0.35014015436172485, train/logprobs = tensor([[-0.6659, -4.0802],
        [-1.3902, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066462099552155
Epoch 0, Step 1482: train/loss = 0.35786202549934387, train/raw-loss = 0.2881273329257965, train/logprobs = tensor([[-0.4974, -6.0124],
        [-1.0348, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09962097555398941
Epoch 0, Step 1483: train/loss = 0.42794787883758545, train/raw-loss = 0.3548125624656677, train/logprobs = tensor([[-0.5846, -2.9132],
        [-1.4143, -0.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447902977466583
Epoch 0, Step 1484: train/loss = 0.34188252687454224, train/raw-loss = 0.2647806704044342, train/logprobs = tensor([[-0.3998, -3.9936],
        [-1.1466, -0.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11014552414417267
Epoch 0, Step 1485: train/loss = 0.5611025094985962, train/raw-loss = 0.48903319239616394, train/logprobs = tensor([[-0.5409, -2.1229],
        [-0.8578, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295618325471878
Epoch 0, Step 1486: train/loss = 0.5699997544288635, train/raw-loss = 0.49958744645118713, train/logprobs = tensor([[-0.8279, -1.9103],
        [-0.8320, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10058900713920593
Epoch 0, Step 1487: train/loss = 0.39791417121887207, train/raw-loss = 0.33353549242019653, train/logprobs = tensor([[-0.8763, -3.3417],
        [-1.3006, -0.5883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0919695794582367
Epoch 0, Step 1488: train/loss = 0.546112060546875, train/raw-loss = 0.4751860201358795, train/logprobs = tensor([[-0.4181, -1.5172],
        [-0.8134, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013229489326477
Epoch 0, Step 1489: train/loss = 0.5483576655387878, train/raw-loss = 0.494170606136322, train/logprobs = tensor([[-0.7021, -2.4946],
        [-0.9277, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07741012424230576
Epoch 0, Step 1490: train/loss = 0.5031031966209412, train/raw-loss = 0.4377673864364624, train/logprobs = tensor([[-0.4463, -2.5158],
        [-0.9969, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333686530590057
Epoch 0, Step 1491: train/loss = 0.3824886083602905, train/raw-loss = 0.29558777809143066, train/logprobs = tensor([[-0.9601, -4.5756],
        [-1.4563, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12414410710334778
Epoch 0, Step 1492: train/loss = 0.5108853578567505, train/raw-loss = 0.44550830125808716, train/logprobs = tensor([[-0.5678, -2.9622],
        [-1.0924, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339579939842224
Epoch 0, Step 1493: train/loss = 0.39446961879730225, train/raw-loss = 0.3221864700317383, train/logprobs = tensor([[-0.5473, -2.3264],
        [-1.5360, -0.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10326159745454788
Epoch 0, Step 1494: train/loss = 0.3409776985645294, train/raw-loss = 0.24613609910011292, train/logprobs = tensor([[-0.5200, -3.6225],
        [-1.3890, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13548800349235535
Epoch 0, Step 1495: train/loss = 0.3088502883911133, train/raw-loss = 0.23187783360481262, train/logprobs = tensor([[-0.4735, -5.1967],
        [-1.2655, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099606528878212
Epoch 0, Step 1496: train/loss = 0.3710356056690216, train/raw-loss = 0.3024136424064636, train/logprobs = tensor([[-0.5990, -4.1317],
        [-1.0612, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803138673305511
Epoch 0, Step 1497: train/loss = 0.4110206961631775, train/raw-loss = 0.35183531045913696, train/logprobs = tensor([[-0.5150, -2.5534],
        [-0.9688, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08455053716897964
Epoch 0, Step 1498: train/loss = 0.41967257857322693, train/raw-loss = 0.34876134991645813, train/logprobs = tensor([[-0.5723, -2.1379],
        [-1.4645, -0.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130178928375244
Epoch 0, Step 1499: train/loss = 0.4636005163192749, train/raw-loss = 0.3919445872306824, train/logprobs = tensor([[-0.9376, -2.4073],
        [-1.4717, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236558318138123
Epoch 0, Step 1500: train/loss = 0.5033217072486877, train/raw-loss = 0.46412646770477295, train/logprobs = tensor([[-0.3104, -2.8219],
        [-0.4666, -0.9215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05599319189786911
Epoch 0, Step 1501: train/loss = 0.2791631817817688, train/raw-loss = 0.17877663671970367, train/logprobs = tensor([[-0.4405, -3.9240],
        [-1.7582, -0.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434093564748764
Epoch 0, Step 1502: train/loss = 0.2731497883796692, train/raw-loss = 0.19236278533935547, train/logprobs = tensor([[-0.7415, -5.2725],
        [-1.4444, -1.0190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11541001498699188
Epoch 0, Step 1503: train/loss = 0.4845253825187683, train/raw-loss = 0.4082942605018616, train/logprobs = tensor([[-0.7979, -2.7500],
        [-1.4607, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10890163481235504
Epoch 0, Step 1504: train/loss = 0.4297654926776886, train/raw-loss = 0.3611394166946411, train/logprobs = tensor([[-0.4607, -3.8668],
        [-0.9008, -0.7805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09803726524114609
Epoch 0, Step 1505: train/loss = 0.36399075388908386, train/raw-loss = 0.29900431632995605, train/logprobs = tensor([[-0.6028, -3.9546],
        [-1.1955, -0.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09283775836229324
Epoch 0, Step 1506: train/loss = 0.31954270601272583, train/raw-loss = 0.24495863914489746, train/logprobs = tensor([[-0.5451, -3.6716],
        [-1.4160, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10654866695404053
Epoch 0, Step 1507: train/loss = 0.4804120659828186, train/raw-loss = 0.3947414755821228, train/logprobs = tensor([[-0.4158, -2.3391],
        [-0.8480, -0.5326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12238657474517822
Epoch 0, Step 1508: train/loss = 0.554712176322937, train/raw-loss = 0.4651261866092682, train/logprobs = tensor([[-0.9135, -2.9547],
        [-1.3691, -0.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127980038523674
Epoch 0, Step 1509: train/loss = 0.5291944742202759, train/raw-loss = 0.46935969591140747, train/logprobs = tensor([[-0.8624, -1.7717],
        [-1.2989, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08547819405794144
Epoch 0, Step 1510: train/loss = 0.4549567699432373, train/raw-loss = 0.3796073794364929, train/logprobs = tensor([[-0.4404, -4.6452],
        [-0.8155, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764197260141373
Epoch 0, Step 1511: train/loss = 0.3573986887931824, train/raw-loss = 0.2936142683029175, train/logprobs = tensor([[-0.6961, -4.5688],
        [-1.2232, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112057834863663
Epoch 0, Step 1512: train/loss = 0.4640490710735321, train/raw-loss = 0.387634813785553, train/logprobs = tensor([[-0.5177, -2.1519],
        [-1.0347, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916325449943542
Epoch 0, Step 1513: train/loss = 0.38237929344177246, train/raw-loss = 0.30282628536224365, train/logprobs = tensor([[-0.4735, -3.6299],
        [-1.1227, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11364716291427612
Epoch 0, Step 1514: train/loss = 0.5209681391716003, train/raw-loss = 0.44615626335144043, train/logprobs = tensor([[-1.1278, -6.2523],
        [-1.2227, -1.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106874018907547
Epoch 0, Step 1515: train/loss = 0.33156532049179077, train/raw-loss = 0.2564716339111328, train/logprobs = tensor([[-0.6786, -3.3471],
        [-1.5292, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10727667808532715
Epoch 0, Step 1516: train/loss = 0.6572388410568237, train/raw-loss = 0.6075400114059448, train/logprobs = tensor([[-0.5046, -0.6736],
        [-0.8206, -0.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07099834829568863
Epoch 0, Step 1517: train/loss = 0.3275202810764313, train/raw-loss = 0.2563202977180481, train/logprobs = tensor([[-0.7765, -9.4739],
        [-1.5310, -2.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10171424597501755
Epoch 0, Step 1518: train/loss = 0.5771087408065796, train/raw-loss = 0.5143722891807556, train/logprobs = tensor([[-1.2553, -2.9775],
        [-1.1133, -0.5338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08962354809045792
Epoch 0, Step 1519: train/loss = 0.5644521117210388, train/raw-loss = 0.500289261341095, train/logprobs = tensor([[-0.5486, -2.1466],
        [-0.9512, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166118502616882
Epoch 0, Step 1520: train/loss = 0.2824435234069824, train/raw-loss = 0.19674482941627502, train/logprobs = tensor([[-0.5751, -6.9118],
        [-1.6876, -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12242668867111206
Epoch 0, Step 1521: train/loss = 0.5111503601074219, train/raw-loss = 0.44526469707489014, train/logprobs = tensor([[-0.9695, -1.8288],
        [-1.3807, -0.8381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09412238746881485
Epoch 0, Step 1522: train/loss = 0.45961636304855347, train/raw-loss = 0.4093608558177948, train/logprobs = tensor([[-1.5584, -8.4521],
        [-1.5293, -2.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07179354131221771
Epoch 0, Step 1523: train/loss = 0.29219260811805725, train/raw-loss = 0.21742257475852966, train/logprobs = tensor([[-0.7719, -4.7398],
        [-1.9365, -1.3991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10681429505348206
Epoch 0, Step 1524: train/loss = 0.41410374641418457, train/raw-loss = 0.33458536863327026, train/logprobs = tensor([[-0.6876, -2.7466],
        [-1.1800, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359765380620956
Epoch 0, Step 1525: train/loss = 0.7058042287826538, train/raw-loss = 0.6343320608139038, train/logprobs = tensor([[-0.5072, -0.5760],
        [-0.9474, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10210314393043518
Epoch 0, Step 1526: train/loss = 0.49752277135849, train/raw-loss = 0.442696213722229, train/logprobs = tensor([[-0.5089, -2.5224],
        [-0.9150, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07832363247871399
Epoch 0, Step 1527: train/loss = 0.5488525629043579, train/raw-loss = 0.4688992500305176, train/logprobs = tensor([[-1.0392, -1.7743],
        [-1.1299, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421899497509003
Epoch 0, Step 1528: train/loss = 0.2795945405960083, train/raw-loss = 0.20123642683029175, train/logprobs = tensor([[-0.4434, -4.3242],
        [-1.3824, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119401603937149
Epoch 0, Step 1529: train/loss = 0.49605095386505127, train/raw-loss = 0.40299201011657715, train/logprobs = tensor([[-0.5985, -2.7016],
        [-1.5884, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13294142484664917
Epoch 0, Step 1530: train/loss = 0.3479195535182953, train/raw-loss = 0.27564579248428345, train/logprobs = tensor([[-0.5852, -4.1221],
        [-1.3929, -0.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1032482460141182
Epoch 0, Step 1531: train/loss = 0.490010142326355, train/raw-loss = 0.4217532277107239, train/logprobs = tensor([[-0.5248, -3.9193],
        [-0.9676, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09750989079475403
Epoch 0, Step 1532: train/loss = 0.5655164122581482, train/raw-loss = 0.4958489239215851, train/logprobs = tensor([[-0.6483, -3.0039],
        [-0.8543, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09952497482299805
Epoch 0, Step 1533: train/loss = 0.40689200162887573, train/raw-loss = 0.35134273767471313, train/logprobs = tensor([[-0.3365, -2.7032],
        [-0.8769, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793561115860939
Epoch 0, Step 1534: train/loss = 0.44350185990333557, train/raw-loss = 0.37211865186691284, train/logprobs = tensor([[-1.0198, -4.3299],
        [-1.2420, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10197606682777405
Epoch 0, Step 1535: train/loss = 0.5148383975028992, train/raw-loss = 0.4348709285259247, train/logprobs = tensor([[-0.5503, -1.6790],
        [-1.2066, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11423922330141068
Epoch 0, Step 1536: train/loss = 0.4017062187194824, train/raw-loss = 0.3327333629131317, train/logprobs = tensor([[-0.4539, -4.5189],
        [-0.8950, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09853263199329376
Epoch 0, Step 1537: train/loss = 0.4707872271537781, train/raw-loss = 0.39849862456321716, train/logprobs = tensor([[-0.9398, -2.4070],
        [-1.0592, -0.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10326941311359406
Epoch 0, Step 1538: train/loss = 0.42438435554504395, train/raw-loss = 0.35943078994750977, train/logprobs = tensor([[-0.4991, -5.3966],
        [-1.1756, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09279081225395203
Epoch 0, Step 1539: train/loss = 0.5589162111282349, train/raw-loss = 0.4808790385723114, train/logprobs = tensor([[-0.5432, -1.8116],
        [-0.8479, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114816665649414
Epoch 0, Step 1540: train/loss = 0.4406566619873047, train/raw-loss = 0.3591107428073883, train/logprobs = tensor([[-0.8205, -3.7221],
        [-1.3944, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11649414896965027
Epoch 0, Step 1541: train/loss = 0.26258522272109985, train/raw-loss = 0.18296918272972107, train/logprobs = tensor([[-0.5675, -8.1102],
        [-1.4026, -1.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11373716592788696
Epoch 0, Step 1542: train/loss = 0.6798515319824219, train/raw-loss = 0.6184899806976318, train/logprobs = tensor([[-0.7101, -0.6784],
        [-0.8934, -0.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765935897827148
Epoch 0, Step 1543: train/loss = 0.5001240968704224, train/raw-loss = 0.4283807575702667, train/logprobs = tensor([[-0.4899, -2.1732],
        [-1.2354, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249049961566925
Epoch 0, Step 1544: train/loss = 0.40502315759658813, train/raw-loss = 0.3145228624343872, train/logprobs = tensor([[-0.6522, -4.4161],
        [-1.7981, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12928615510463715
Epoch 0, Step 1545: train/loss = 0.4626903831958771, train/raw-loss = 0.3863738775253296, train/logprobs = tensor([[-0.9110, -2.8457],
        [-1.1655, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902358591556549
Epoch 0, Step 1546: train/loss = 0.4894399642944336, train/raw-loss = 0.41451528668403625, train/logprobs = tensor([[-0.5323, -2.3155],
        [-1.0558, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10703520476818085
Epoch 0, Step 1547: train/loss = 0.5517327189445496, train/raw-loss = 0.4796733260154724, train/logprobs = tensor([[-0.6058, -2.2782],
        [-1.1285, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10294196009635925
Epoch 0, Step 1548: train/loss = 0.4538264870643616, train/raw-loss = 0.39090272784233093, train/logprobs = tensor([[-0.3713, -4.2099],
        [-0.7196, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08989109098911285
Epoch 0, Step 1549: train/loss = 0.5102945566177368, train/raw-loss = 0.4473757743835449, train/logprobs = tensor([[-0.3729, -2.2568],
        [-0.9466, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08988400548696518
Epoch 0, Step 1550: train/loss = 0.5419415831565857, train/raw-loss = 0.4805077612400055, train/logprobs = tensor([[-0.6474, -1.6474],
        [-0.9760, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08776261657476425
Epoch 0, Step 1551: train/loss = 0.324283242225647, train/raw-loss = 0.24711930751800537, train/logprobs = tensor([[-0.5915, -4.0511],
        [-1.1604, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11023423820734024
Epoch 0, Step 1552: train/loss = 0.3689543604850769, train/raw-loss = 0.29847097396850586, train/logprobs = tensor([[-0.6168, -7.2999],
        [-1.4119, -1.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10069053620100021
Epoch 0, Step 1553: train/loss = 0.388791561126709, train/raw-loss = 0.31328630447387695, train/logprobs = tensor([[-0.7161, -3.5808],
        [-1.1538, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10786472260951996
Epoch 0, Step 1554: train/loss = 0.5552083849906921, train/raw-loss = 0.4929916262626648, train/logprobs = tensor([[-0.6938, -1.8889],
        [-0.9752, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08888108283281326
Epoch 0, Step 1555: train/loss = 0.4199761748313904, train/raw-loss = 0.3456536531448364, train/logprobs = tensor([[-0.9144, -3.2297],
        [-1.3786, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617503523826599
Epoch 0, Step 1556: train/loss = 0.4709021747112274, train/raw-loss = 0.4114527404308319, train/logprobs = tensor([[-0.4461, -6.8809],
        [-0.8275, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08492780476808548
Epoch 0, Step 1557: train/loss = 0.39101696014404297, train/raw-loss = 0.33052724599838257, train/logprobs = tensor([[-0.5202, -5.0176],
        [-0.8651, -0.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08641384541988373
Epoch 0, Step 1558: train/loss = 0.3548651933670044, train/raw-loss = 0.2831173241138458, train/logprobs = tensor([[-0.5659, -6.9961],
        [-1.2341, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10249699652194977
Epoch 0, Step 1559: train/loss = 0.49968212842941284, train/raw-loss = 0.4254993200302124, train/logprobs = tensor([[-1.0268, -2.7962],
        [-1.7272, -0.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597547143697739
Epoch 0, Step 1560: train/loss = 0.34290093183517456, train/raw-loss = 0.27552342414855957, train/logprobs = tensor([[-0.6091, -4.3951],
        [-1.0844, -0.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09625355899333954
Epoch 0, Step 1561: train/loss = 0.3167088031768799, train/raw-loss = 0.213540717959404, train/logprobs = tensor([[-0.8236, -3.6188],
        [-2.0522, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14738300442695618
Epoch 0, Step 1562: train/loss = 0.5340131521224976, train/raw-loss = 0.4604347050189972, train/logprobs = tensor([[-2.0391, -7.1066],
        [-1.6514, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10511201620101929
Epoch 0, Step 1563: train/loss = 0.585614800453186, train/raw-loss = 0.5033175349235535, train/logprobs = tensor([[-0.7117, -1.3247],
        [-1.2710, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756743490695953
Epoch 0, Step 1564: train/loss = 0.3772653043270111, train/raw-loss = 0.30331483483314514, train/logprobs = tensor([[-0.6256, -4.0740],
        [-1.6395, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10564357787370682
Epoch 0, Step 1565: train/loss = 0.6066624522209167, train/raw-loss = 0.5360597372055054, train/logprobs = tensor([[-0.9529, -1.6413],
        [-1.1034, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086105018854141
Epoch 0, Step 1566: train/loss = 0.3249422311782837, train/raw-loss = 0.2403670847415924, train/logprobs = tensor([[-0.5588, -4.7911],
        [-1.4217, -0.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12082163244485855
Epoch 0, Step 1567: train/loss = 0.6022709012031555, train/raw-loss = 0.5447168350219727, train/logprobs = tensor([[-0.4341, -2.5317],
        [-0.8161, -0.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08222010731697083
Epoch 0, Step 1568: train/loss = 0.43129217624664307, train/raw-loss = 0.3655961751937866, train/logprobs = tensor([[-1.1775, -6.0842],
        [-1.2399, -1.1700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09385145455598831
Epoch 0, Step 1569: train/loss = 0.5297015905380249, train/raw-loss = 0.45362353324890137, train/logprobs = tensor([[-0.9690, -2.2368],
        [-0.9930, -0.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10868293046951294
Epoch 0, Step 1570: train/loss = 0.5172449350357056, train/raw-loss = 0.45225897431373596, train/logprobs = tensor([[-0.5959, -2.7953],
        [-0.9046, -0.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09283704310655594
Epoch 0, Step 1571: train/loss = 0.5150125026702881, train/raw-loss = 0.4491339325904846, train/logprobs = tensor([[-0.5506, -1.5687],
        [-0.9818, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09411226212978363
Epoch 0, Step 1572: train/loss = 0.37108081579208374, train/raw-loss = 0.2946636974811554, train/logprobs = tensor([[-0.5914, -3.4760],
        [-1.2377, -0.4406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916730016469955
Epoch 0, Step 1573: train/loss = 0.3473733067512512, train/raw-loss = 0.28899094462394714, train/logprobs = tensor([[-0.8012, -5.1038],
        [-1.5864, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08340337872505188
Epoch 0, Step 1574: train/loss = 0.4123549163341522, train/raw-loss = 0.33712759613990784, train/logprobs = tensor([[-0.5150, -2.7661],
        [-1.2712, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10746759176254272
Epoch 0, Step 1575: train/loss = 0.4347091317176819, train/raw-loss = 0.35720664262771606, train/logprobs = tensor([[-0.7074, -3.2744],
        [-1.3506, -0.9379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11071781814098358
Epoch 0, Step 1576: train/loss = 0.7123422622680664, train/raw-loss = 0.6644796133041382, train/logprobs = tensor([[-0.4239, -0.5327],
        [-0.4933, -0.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06837519258260727
Epoch 0, Step 1577: train/loss = 0.6109675168991089, train/raw-loss = 0.5339678525924683, train/logprobs = tensor([[-0.6525, -1.0646],
        [-1.0309, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10999946296215057
Epoch 0, Step 1578: train/loss = 0.3926151394844055, train/raw-loss = 0.3338809609413147, train/logprobs = tensor([[-1.2009, -8.4164],
        [-1.1278, -1.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08390599489212036
Epoch 0, Step 1579: train/loss = 0.4218098521232605, train/raw-loss = 0.34609901905059814, train/logprobs = tensor([[-0.4547, -4.0583],
        [-1.2851, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10815830528736115
Epoch 0, Step 1580: train/loss = 0.42724084854125977, train/raw-loss = 0.35850968956947327, train/logprobs = tensor([[-0.4310, -2.3858],
        [-0.9692, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09818733483552933
Epoch 0, Step 1581: train/loss = 0.28777939081192017, train/raw-loss = 0.20283304154872894, train/logprobs = tensor([[-0.7147, -2.7078],
        [-2.0985, -0.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1213519349694252
Epoch 0, Step 1582: train/loss = 0.26864710450172424, train/raw-loss = 0.2068459838628769, train/logprobs = tensor([[-0.6998, -6.5876],
        [-1.7694, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08828733116388321
Epoch 0, Step 1583: train/loss = 0.4233648478984833, train/raw-loss = 0.3420882821083069, train/logprobs = tensor([[-0.6626, -5.9593],
        [-1.9880, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11610935628414154
Epoch 0, Step 1584: train/loss = 0.3068324327468872, train/raw-loss = 0.23697203397750854, train/logprobs = tensor([[-0.8000, -4.7032],
        [-1.3298, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980056434869766
Epoch 0, Step 1585: train/loss = 0.3590819835662842, train/raw-loss = 0.2661803066730499, train/logprobs = tensor([[-0.6679, -3.0586],
        [-1.2269, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13271668553352356
Epoch 0, Step 1586: train/loss = 0.3901940882205963, train/raw-loss = 0.3051018714904785, train/logprobs = tensor([[-0.6035, -5.1543],
        [-1.2204, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12156029045581818
Epoch 0, Step 1587: train/loss = 0.3146611452102661, train/raw-loss = 0.22421275079250336, train/logprobs = tensor([[-0.7754, -3.6971],
        [-1.4089, -0.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12921202182769775
Epoch 0, Step 1588: train/loss = 0.400321364402771, train/raw-loss = 0.3426852822303772, train/logprobs = tensor([[-0.5018, -3.7478],
        [-0.9543, -0.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08233727514743805
Epoch 0, Step 1589: train/loss = 0.4448452591896057, train/raw-loss = 0.38289353251457214, train/logprobs = tensor([[-0.6154, -4.1336],
        [-0.9466, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08850246667861938
Epoch 0, Step 1590: train/loss = 0.4248790740966797, train/raw-loss = 0.36605754494667053, train/logprobs = tensor([[-0.5125, -5.0722],
        [-0.6682, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08403076231479645
Epoch 0, Step 1591: train/loss = 0.4161851406097412, train/raw-loss = 0.32546675205230713, train/logprobs = tensor([[-0.5646, -5.2143],
        [-1.3448, -2.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12959769368171692
Epoch 0, Step 1592: train/loss = 0.4242701530456543, train/raw-loss = 0.3473474979400635, train/logprobs = tensor([[-0.5447, -2.7240],
        [-0.9801, -0.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10988952219486237
Epoch 0, Step 1593: train/loss = 0.3951447010040283, train/raw-loss = 0.321858674287796, train/logprobs = tensor([[-0.7032, -5.0607],
        [-1.1623, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10469430685043335
Epoch 0, Step 1594: train/loss = 0.3649972677230835, train/raw-loss = 0.27898991107940674, train/logprobs = tensor([[-0.5772, -3.3313],
        [-1.3023, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122867651283741
Epoch 0, Step 1595: train/loss = 0.4034334421157837, train/raw-loss = 0.32518231868743896, train/logprobs = tensor([[-0.5862, -3.0607],
        [-0.9788, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11178731918334961
Epoch 0, Step 1596: train/loss = 0.4021452069282532, train/raw-loss = 0.30292850732803345, train/logprobs = tensor([[-0.5760, -7.3895],
        [-1.5534, -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141738161444664
Epoch 0, Step 1597: train/loss = 0.3621910810470581, train/raw-loss = 0.28899288177490234, train/logprobs = tensor([[-0.7351, -4.4185],
        [-1.6733, -1.2972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456890612840652
Epoch 0, Step 1598: train/loss = 0.4229690432548523, train/raw-loss = 0.35892945528030396, train/logprobs = tensor([[-0.8075, -6.4015],
        [-1.2459, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09148514270782471
Epoch 0, Step 1599: train/loss = 0.2777576148509979, train/raw-loss = 0.19486871361732483, train/logprobs = tensor([[-0.5043, -7.2532],
        [-1.3686, -1.5749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11841273307800293
Epoch 0, Step 1600: train/loss = 0.4056812524795532, train/raw-loss = 0.3377229571342468, train/logprobs = tensor([[-0.8926, -5.0673],
        [-0.9967, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708327800035477
Epoch 0, Step 1601: train/loss = 0.2412053942680359, train/raw-loss = 0.1596449464559555, train/logprobs = tensor([[ -0.5177, -10.5357],
        [ -1.3860,  -2.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1165149062871933
Epoch 0, Step 1602: train/loss = 0.3756248354911804, train/raw-loss = 0.29248762130737305, train/logprobs = tensor([[-0.4463, -3.6976],
        [-1.0210, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876743286848068
Epoch 0, Step 1603: train/loss = 0.4903329312801361, train/raw-loss = 0.42020130157470703, train/logprobs = tensor([[-0.4502, -2.2928],
        [-0.9885, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10018804669380188
Epoch 0, Step 1604: train/loss = 0.36479318141937256, train/raw-loss = 0.2986687421798706, train/logprobs = tensor([[-0.5017, -5.7563],
        [-0.8739, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446351230144501
Epoch 0, Step 1605: train/loss = 0.5239428281784058, train/raw-loss = 0.4444986879825592, train/logprobs = tensor([[-0.6623, -3.2365],
        [-0.9366, -0.6991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11349164694547653
Epoch 0, Step 1606: train/loss = 0.2684187591075897, train/raw-loss = 0.20297905802726746, train/logprobs = tensor([[-0.5091, -6.4355],
        [-1.2594, -1.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0934852808713913
Epoch 0, Step 1607: train/loss = 0.4134911298751831, train/raw-loss = 0.33840009570121765, train/logprobs = tensor([[-0.6150, -2.8569],
        [-1.1176, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072729155421257
Epoch 0, Step 1608: train/loss = 0.4316532611846924, train/raw-loss = 0.35636404156684875, train/logprobs = tensor([[-0.7731, -6.2167],
        [-1.0194, -1.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1075560599565506
Epoch 0, Step 1609: train/loss = 0.45579004287719727, train/raw-loss = 0.38667577505111694, train/logprobs = tensor([[-0.8707, -6.9225],
        [-0.9623, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987347662448883
Epoch 0, Step 1610: train/loss = 0.538711428642273, train/raw-loss = 0.46750807762145996, train/logprobs = tensor([[-0.8123, -3.0690],
        [-0.8970, -0.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10171911120414734
Epoch 0, Step 1611: train/loss = 0.434060275554657, train/raw-loss = 0.3618108928203583, train/logprobs = tensor([[-0.6483, -1.7111],
        [-1.5805, -0.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10321343690156937
Epoch 0, Step 1612: train/loss = 0.3295322060585022, train/raw-loss = 0.24865704774856567, train/logprobs = tensor([[-0.7013, -4.8168],
        [-1.6538, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11553597450256348
Epoch 0, Step 1613: train/loss = 0.6401079893112183, train/raw-loss = 0.574193000793457, train/logprobs = tensor([[-0.4787, -0.8896],
        [-0.7827, -0.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416424483060837
Epoch 0, Step 1614: train/loss = 0.4341796636581421, train/raw-loss = 0.3454369604587555, train/logprobs = tensor([[-1.4894, -6.3769],
        [-1.6865, -1.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12677529454231262
Epoch 0, Step 1615: train/loss = 0.36968332529067993, train/raw-loss = 0.3042467534542084, train/logprobs = tensor([[-0.3893, -5.3380],
        [-0.8158, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09348082542419434
Epoch 0, Step 1616: train/loss = 0.4486249089241028, train/raw-loss = 0.3772977888584137, train/logprobs = tensor([[-0.6178, -4.3002],
        [-1.5167, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10189593583345413
Epoch 0, Step 1617: train/loss = 0.47316449880599976, train/raw-loss = 0.41733652353286743, train/logprobs = tensor([[-0.5201, -3.1220],
        [-0.9136, -0.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07975421845912933
Epoch 0, Step 1618: train/loss = 0.4801497757434845, train/raw-loss = 0.4134036898612976, train/logprobs = tensor([[-0.4785, -1.9918],
        [-0.9862, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09535156190395355
Epoch 0, Step 1619: train/loss = 0.3577626347541809, train/raw-loss = 0.28968095779418945, train/logprobs = tensor([[-0.6287, -4.8767],
        [-0.9921, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09725959599018097
Epoch 0, Step 1620: train/loss = 0.4430829882621765, train/raw-loss = 0.37073761224746704, train/logprobs = tensor([[-0.5350, -2.7723],
        [-1.0403, -0.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10335054993629456
Epoch 0, Step 1621: train/loss = 0.42685043811798096, train/raw-loss = 0.35103940963745117, train/logprobs = tensor([[-0.6843, -2.8913],
        [-1.1471, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10830143839120865
Epoch 0, Step 1622: train/loss = 0.316512793302536, train/raw-loss = 0.24212180078029633, train/logprobs = tensor([[-0.8197, -6.2341],
        [-1.5876, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062728688120842
Epoch 0, Step 1623: train/loss = 0.5063924789428711, train/raw-loss = 0.4348166882991791, train/logprobs = tensor([[-0.4511, -2.2025],
        [-0.9139, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10225111246109009
Epoch 0, Step 1624: train/loss = 0.32788100838661194, train/raw-loss = 0.269997775554657, train/logprobs = tensor([[-0.5199, -3.1533],
        [-1.2512, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08269031345844269
Epoch 0, Step 1625: train/loss = 0.3581360876560211, train/raw-loss = 0.2677270174026489, train/logprobs = tensor([[-0.5485, -4.4764],
        [-1.3634, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12915579974651337
Epoch 0, Step 1626: train/loss = 0.5104148387908936, train/raw-loss = 0.4514680504798889, train/logprobs = tensor([[-1.0081, -1.6083],
        [-1.4047, -0.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08420971781015396
Epoch 0, Step 1627: train/loss = 0.48003509640693665, train/raw-loss = 0.41317224502563477, train/logprobs = tensor([[-1.0439, -2.9145],
        [-1.1652, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09551842510700226
Epoch 0, Step 1628: train/loss = 0.36643093824386597, train/raw-loss = 0.3079926371574402, train/logprobs = tensor([[-0.5914, -5.6053],
        [-0.8366, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0834832713007927
Epoch 0, Step 1629: train/loss = 0.5094181895256042, train/raw-loss = 0.44319966435432434, train/logprobs = tensor([[-0.7009, -2.6646],
        [-0.8938, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09459792077541351
Epoch 0, Step 1630: train/loss = 0.516785204410553, train/raw-loss = 0.4453156590461731, train/logprobs = tensor([[-0.5690, -1.4832],
        [-1.3609, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10209935903549194
Epoch 0, Step 1631: train/loss = 0.29261553287506104, train/raw-loss = 0.22261656820774078, train/logprobs = tensor([[-0.4561, -6.9743],
        [-0.9180, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09999855607748032
Epoch 0, Step 1632: train/loss = 0.40943706035614014, train/raw-loss = 0.33213740587234497, train/logprobs = tensor([[-0.6890, -6.7535],
        [-1.1333, -1.2944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11042816191911697
Epoch 0, Step 1633: train/loss = 0.41620874404907227, train/raw-loss = 0.3524378538131714, train/logprobs = tensor([[-0.8475, -4.2864],
        [-1.5336, -0.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09110127389431
Epoch 0, Step 1634: train/loss = 0.4734901785850525, train/raw-loss = 0.3829110264778137, train/logprobs = tensor([[-0.7598, -2.6167],
        [-1.4113, -0.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12939879298210144
Epoch 0, Step 1635: train/loss = 0.38294750452041626, train/raw-loss = 0.2889134883880615, train/logprobs = tensor([[-0.4924, -6.0505],
        [-1.7536, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13433435559272766
Epoch 0, Step 1636: train/loss = 0.39875534176826477, train/raw-loss = 0.31523433327674866, train/logprobs = tensor([[-0.4091, -4.4954],
        [-1.0589, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193157359957695
Epoch 0, Step 1637: train/loss = 0.3986336588859558, train/raw-loss = 0.3208407461643219, train/logprobs = tensor([[-0.6454, -6.7745],
        [-1.7634, -1.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11113272607326508
Epoch 0, Step 1638: train/loss = 0.37372568249702454, train/raw-loss = 0.2990613579750061, train/logprobs = tensor([[-0.5172, -6.0304],
        [-1.4154, -1.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10666333884000778
Epoch 0, Step 1639: train/loss = 0.5064246654510498, train/raw-loss = 0.4364563226699829, train/logprobs = tensor([[-0.6938, -6.1469],
        [-0.8164, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0999547466635704
Epoch 0, Step 1640: train/loss = 0.3811143636703491, train/raw-loss = 0.29851192235946655, train/logprobs = tensor([[-0.4559, -5.0101],
        [-1.0802, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800350248813629
Epoch 0, Step 1641: train/loss = 0.35724085569381714, train/raw-loss = 0.2971424162387848, train/logprobs = tensor([[-0.3209, -5.6573],
        [-1.2164, -1.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08585496991872787
Epoch 0, Step 1642: train/loss = 0.3452167809009552, train/raw-loss = 0.2625468671321869, train/logprobs = tensor([[-0.6948, -5.5138],
        [-1.5186, -1.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11809989809989929
Epoch 0, Step 1643: train/loss = 0.475782573223114, train/raw-loss = 0.40997275710105896, train/logprobs = tensor([[-1.0282, -6.1425],
        [-1.3409, -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09401407092809677
Epoch 0, Step 1644: train/loss = 0.4247678220272064, train/raw-loss = 0.33865442872047424, train/logprobs = tensor([[-0.8759, -3.8401],
        [-1.4011, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12301916629076004
Epoch 0, Step 1645: train/loss = 0.24482712149620056, train/raw-loss = 0.16695654392242432, train/logprobs = tensor([[-0.5401, -9.3052],
        [-1.5009, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11124368011951447
Epoch 0, Step 1646: train/loss = 0.5807507038116455, train/raw-loss = 0.5068181753158569, train/logprobs = tensor([[-0.7459, -1.9102],
        [-0.8685, -0.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10561790317296982
Epoch 0, Step 1647: train/loss = 0.4285084009170532, train/raw-loss = 0.3596985936164856, train/logprobs = tensor([[-0.4782, -2.2088],
        [-1.0072, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09829973429441452
Epoch 0, Step 1648: train/loss = 0.4534798264503479, train/raw-loss = 0.38769710063934326, train/logprobs = tensor([[-0.4433, -2.1286],
        [-1.0722, -0.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397533535957336
Epoch 0, Step 1649: train/loss = 0.4146965742111206, train/raw-loss = 0.3506709933280945, train/logprobs = tensor([[-0.5114, -5.2558],
        [-1.2021, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09146510809659958
Epoch 0, Step 1650: train/loss = 0.41642922163009644, train/raw-loss = 0.35287928581237793, train/logprobs = tensor([[-0.4950, -3.8644],
        [-0.8680, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09078563749790192
Epoch 0, Step 1651: train/loss = 0.33268067240715027, train/raw-loss = 0.2590601444244385, train/logprobs = tensor([[-0.5523, -3.2279],
        [-1.3721, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517218708992004
Epoch 0, Step 1652: train/loss = 0.5984326601028442, train/raw-loss = 0.5340852737426758, train/logprobs = tensor([[-0.4324, -3.0910],
        [-0.8018, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09192483127117157
Epoch 0, Step 1653: train/loss = 0.378322958946228, train/raw-loss = 0.29541319608688354, train/logprobs = tensor([[-0.3875, -3.5009],
        [-1.0671, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11844252049922943
Epoch 0, Step 1654: train/loss = 0.4758267402648926, train/raw-loss = 0.4044147729873657, train/logprobs = tensor([[-0.8649, -5.5098],
        [-1.2036, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10201707482337952
Epoch 0, Step 1655: train/loss = 0.35876113176345825, train/raw-loss = 0.2838672399520874, train/logprobs = tensor([[-0.4588, -7.1503],
        [-1.0213, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699128359556198
Epoch 0, Step 1656: train/loss = 0.37596583366394043, train/raw-loss = 0.29694950580596924, train/logprobs = tensor([[-0.4917, -2.4186],
        [-1.4890, -0.3582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288045346736908
Epoch 0, Step 1657: train/loss = 0.48165982961654663, train/raw-loss = 0.39479711651802063, train/logprobs = tensor([[-0.7197, -1.7802],
        [-1.9614, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12408959120512009
Epoch 0, Step 1658: train/loss = 0.5358242392539978, train/raw-loss = 0.4699309170246124, train/logprobs = tensor([[-0.7824, -2.8975],
        [-1.2809, -1.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09413331747055054
Epoch 0, Step 1659: train/loss = 0.39606377482414246, train/raw-loss = 0.31025150418281555, train/logprobs = tensor([[-0.7021, -2.8086],
        [-1.5764, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12258896231651306
Epoch 0, Step 1660: train/loss = 0.34592753648757935, train/raw-loss = 0.2758343815803528, train/logprobs = tensor([[-0.7910, -5.4881],
        [-1.2623, -0.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1001330316066742
Epoch 0, Step 1661: train/loss = 0.6480860710144043, train/raw-loss = 0.5862793922424316, train/logprobs = tensor([[-0.7135, -1.4036],
        [-0.9056, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08829524368047714
Epoch 0, Step 1662: train/loss = 0.343923419713974, train/raw-loss = 0.260967493057251, train/logprobs = tensor([[-0.7587, -7.0165],
        [-1.4494, -1.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11850849539041519
Epoch 0, Step 1663: train/loss = 0.3988128900527954, train/raw-loss = 0.3347090482711792, train/logprobs = tensor([[-0.7825, -2.0999],
        [-1.5201, -0.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157688915729523
Epoch 0, Step 1664: train/loss = 0.5142068266868591, train/raw-loss = 0.4219953119754791, train/logprobs = tensor([[-0.5449, -1.4074],
        [-1.3079, -0.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13173070549964905
Epoch 0, Step 1665: train/loss = 0.4683472514152527, train/raw-loss = 0.38172823190689087, train/logprobs = tensor([[-1.3888, -3.7683],
        [-1.3864, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.123741514980793
Epoch 0, Step 1666: train/loss = 0.47972679138183594, train/raw-loss = 0.42175960540771484, train/logprobs = tensor([[-0.6483, -2.2854],
        [-1.0913, -0.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08281030505895615
Epoch 0, Step 1667: train/loss = 0.32387372851371765, train/raw-loss = 0.26227590441703796, train/logprobs = tensor([[-0.4123, -5.4168],
        [-1.0254, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799690008163452
Epoch 0, Step 1668: train/loss = 0.5679261684417725, train/raw-loss = 0.5190538763999939, train/logprobs = tensor([[-0.5205, -2.1887],
        [-0.4267, -0.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06981759518384933
Epoch 0, Step 1669: train/loss = 0.2707101106643677, train/raw-loss = 0.18357017636299133, train/logprobs = tensor([[-0.5829, -5.8363],
        [-1.3615, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12448561936616898
Epoch 0, Step 1670: train/loss = 0.2217860370874405, train/raw-loss = 0.14427056908607483, train/logprobs = tensor([[-0.6152, -6.1451],
        [-1.8916, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11073639243841171
Epoch 0, Step 1671: train/loss = 0.4132617115974426, train/raw-loss = 0.3478323519229889, train/logprobs = tensor([[-1.5670, -4.4885],
        [-1.7288, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09347046911716461
Epoch 0, Step 1672: train/loss = 0.5106702446937561, train/raw-loss = 0.4283685088157654, train/logprobs = tensor([[-0.9906, -2.9703],
        [-1.4212, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11757394671440125
Epoch 0, Step 1673: train/loss = 0.39651811122894287, train/raw-loss = 0.3262912333011627, train/logprobs = tensor([[-0.4976, -3.0523],
        [-1.0076, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10032415390014648
Epoch 0, Step 1674: train/loss = 0.45730507373809814, train/raw-loss = 0.40090733766555786, train/logprobs = tensor([[-0.7204, -3.7581],
        [-0.7520, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08056821674108505
Epoch 0, Step 1675: train/loss = 0.463767945766449, train/raw-loss = 0.39435136318206787, train/logprobs = tensor([[-1.4726, -5.8058],
        [-1.2925, -1.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09916659444570541
Epoch 0, Step 1676: train/loss = 0.41035446524620056, train/raw-loss = 0.3068014085292816, train/logprobs = tensor([[-0.9246, -4.1553],
        [-1.9689, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1479329764842987
Epoch 0, Step 1677: train/loss = 0.3667507469654083, train/raw-loss = 0.31157782673835754, train/logprobs = tensor([[-0.6624, -4.2074],
        [-1.5106, -1.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0788184255361557
Epoch 0, Step 1678: train/loss = 0.3907962441444397, train/raw-loss = 0.31429359316825867, train/logprobs = tensor([[-0.6337, -2.8307],
        [-1.5398, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10928952693939209
Epoch 0, Step 1679: train/loss = 0.4721711277961731, train/raw-loss = 0.39626362919807434, train/logprobs = tensor([[-0.6133, -2.5200],
        [-1.3437, -0.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843926668167114
Epoch 0, Step 1680: train/loss = 0.499359667301178, train/raw-loss = 0.42733028531074524, train/logprobs = tensor([[-0.5241, -2.0594],
        [-1.0241, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10289908945560455
Epoch 0, Step 1681: train/loss = 0.36593911051750183, train/raw-loss = 0.30277198553085327, train/logprobs = tensor([[-0.7584, -9.3419],
        [-1.3781, -1.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09023872017860413
Epoch 0, Step 1682: train/loss = 0.4623347520828247, train/raw-loss = 0.3863256573677063, train/logprobs = tensor([[-0.5545, -3.8739],
        [-1.1664, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10858442634344101
Epoch 0, Step 1683: train/loss = 0.4307751953601837, train/raw-loss = 0.3475661277770996, train/logprobs = tensor([[-1.1930, -3.2336],
        [-1.6796, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11887010931968689
Epoch 0, Step 1684: train/loss = 0.5701112747192383, train/raw-loss = 0.5102250576019287, train/logprobs = tensor([[-0.5373, -1.2434],
        [-0.8510, -0.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08555176854133606
Epoch 0, Step 1685: train/loss = 0.46322089433670044, train/raw-loss = 0.39048635959625244, train/logprobs = tensor([[-0.6009, -2.5842],
        [-1.0381, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10390646010637283
Epoch 0, Step 1686: train/loss = 0.33044490218162537, train/raw-loss = 0.25926244258880615, train/logprobs = tensor([[-0.6932, -7.6810],
        [-1.2574, -1.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168919712305069
Epoch 0, Step 1687: train/loss = 0.41959425806999207, train/raw-loss = 0.33541300892829895, train/logprobs = tensor([[-0.5067, -4.5950],
        [-1.1166, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12025894224643707
Epoch 0, Step 1688: train/loss = 0.47638970613479614, train/raw-loss = 0.39961379766464233, train/logprobs = tensor([[-0.8791, -5.0219],
        [-1.0022, -0.6055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10967986285686493
Epoch 0, Step 1689: train/loss = 0.4472375810146332, train/raw-loss = 0.37002962827682495, train/logprobs = tensor([[-0.5103, -3.8539],
        [-1.1149, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11029708385467529
Epoch 0, Step 1690: train/loss = 0.527402400970459, train/raw-loss = 0.4524841904640198, train/logprobs = tensor([[-0.5781, -2.3281],
        [-0.8041, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702604800462723
Epoch 0, Step 1691: train/loss = 0.5278934240341187, train/raw-loss = 0.47056081891059875, train/logprobs = tensor([[-0.9361, -3.1309],
        [-1.0009, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190368860960007
Epoch 0, Step 1692: train/loss = 0.37283626198768616, train/raw-loss = 0.28014010190963745, train/logprobs = tensor([[-0.7040, -3.3854],
        [-1.5227, -0.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13242307305335999
Epoch 0, Step 1693: train/loss = 0.43949002027511597, train/raw-loss = 0.3598282039165497, train/logprobs = tensor([[-0.7559, -3.0716],
        [-1.1563, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11380260437726974
Epoch 0, Step 1694: train/loss = 0.3463113009929657, train/raw-loss = 0.2726277709007263, train/logprobs = tensor([[-0.6585, -3.2522],
        [-1.6296, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10526220500469208
Epoch 0, Step 1695: train/loss = 0.7000367641448975, train/raw-loss = 0.6210103034973145, train/logprobs = tensor([[-0.8241, -2.8742],
        [-0.7883, -0.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128949224948883
Epoch 0, Step 1696: train/loss = 0.49337121844291687, train/raw-loss = 0.4183274805545807, train/logprobs = tensor([[-0.9982, -3.1038],
        [-1.0777, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072053462266922
Epoch 0, Step 1697: train/loss = 0.572790801525116, train/raw-loss = 0.5202975273132324, train/logprobs = tensor([[-0.4210, -1.5582],
        [-0.5672, -0.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07499039173126221
Epoch 0, Step 1698: train/loss = 0.5483405590057373, train/raw-loss = 0.4780183434486389, train/logprobs = tensor([[-0.9719, -2.8193],
        [-0.7508, -0.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10046032816171646
Epoch 0, Step 1699: train/loss = 0.46436774730682373, train/raw-loss = 0.39536145329475403, train/logprobs = tensor([[-0.5939, -3.1635],
        [-1.1223, -0.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858046472072601
Epoch 0, Step 1700: train/loss = 0.5306752920150757, train/raw-loss = 0.4449253976345062, train/logprobs = tensor([[-0.8201, -2.9044],
        [-0.8750, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12249980866909027
Epoch 0, Step 1701: train/loss = 0.5695778131484985, train/raw-loss = 0.487693190574646, train/logprobs = tensor([[-1.0296, -1.8510],
        [-1.4228, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11697807908058167
Epoch 0, Step 1702: train/loss = 0.47097185254096985, train/raw-loss = 0.38194751739501953, train/logprobs = tensor([[-0.5171, -2.4819],
        [-1.2927, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271776258945465
Epoch 0, Step 1703: train/loss = 0.3841714859008789, train/raw-loss = 0.30592653155326843, train/logprobs = tensor([[-0.5629, -5.4183],
        [-1.4581, -1.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11177849024534225
Epoch 0, Step 1704: train/loss = 0.32566413283348083, train/raw-loss = 0.24129346013069153, train/logprobs = tensor([[-0.6835, -5.4683],
        [-1.5697, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12052951753139496
Epoch 0, Step 1705: train/loss = 0.43954309821128845, train/raw-loss = 0.3693208396434784, train/logprobs = tensor([[-0.5191, -6.3628],
        [-1.1265, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10031753033399582
Epoch 0, Step 1706: train/loss = 0.3499690592288971, train/raw-loss = 0.26560401916503906, train/logprobs = tensor([[-0.5736, -3.6563],
        [-1.9184, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12052147835493088
Epoch 0, Step 1707: train/loss = 0.4429659843444824, train/raw-loss = 0.36327609419822693, train/logprobs = tensor([[-0.6659, -2.1368],
        [-1.3354, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11384273320436478
Epoch 0, Step 1708: train/loss = 0.4612548053264618, train/raw-loss = 0.39023470878601074, train/logprobs = tensor([[-0.7169, -2.6878],
        [-1.3226, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10145730525255203
Epoch 0, Step 1709: train/loss = 0.5166655778884888, train/raw-loss = 0.44132301211357117, train/logprobs = tensor([[-0.7745, -3.2674],
        [-0.9343, -0.7115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10763229429721832
Epoch 0, Step 1710: train/loss = 0.4785362482070923, train/raw-loss = 0.3941059112548828, train/logprobs = tensor([[-0.6612, -3.4222],
        [-1.1822, -0.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12061472982168198
Epoch 0, Step 1711: train/loss = 0.29172539710998535, train/raw-loss = 0.19596272706985474, train/logprobs = tensor([[-0.5910, -5.7013],
        [-1.7504, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13680382072925568
Epoch 0, Step 1712: train/loss = 0.3006572127342224, train/raw-loss = 0.23169785737991333, train/logprobs = tensor([[-0.3849, -8.6399],
        [-0.8309, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09851337224245071
Epoch 0, Step 1713: train/loss = 0.336195707321167, train/raw-loss = 0.25036710500717163, train/logprobs = tensor([[-0.6648, -4.3624],
        [-1.6113, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12261224538087845
Epoch 0, Step 1714: train/loss = 0.5890746712684631, train/raw-loss = 0.5198565721511841, train/logprobs = tensor([[-0.7620, -1.7364],
        [-0.7464, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09888298064470291
Epoch 0, Step 1715: train/loss = 0.4910498261451721, train/raw-loss = 0.4176684021949768, train/logprobs = tensor([[-0.6224, -2.4089],
        [-0.9414, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10483060032129288
Epoch 0, Step 1716: train/loss = 0.5763278007507324, train/raw-loss = 0.49364957213401794, train/logprobs = tensor([[-0.9091, -2.3923],
        [-1.0099, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11811178922653198
Epoch 0, Step 1717: train/loss = 0.48009103536605835, train/raw-loss = 0.4084970951080322, train/logprobs = tensor([[-0.5723, -6.0357],
        [-1.1099, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10227711498737335
Epoch 0, Step 1718: train/loss = 0.46233248710632324, train/raw-loss = 0.3945997357368469, train/logprobs = tensor([[-0.7533, -2.4589],
        [-1.2504, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676104784011841
Epoch 0, Step 1719: train/loss = 0.3701915144920349, train/raw-loss = 0.2735140323638916, train/logprobs = tensor([[-0.6520, -6.1862],
        [-1.6644, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13811072707176208
Epoch 0, Step 1720: train/loss = 0.7249834537506104, train/raw-loss = 0.6551635265350342, train/logprobs = tensor([[-1.4850, -2.4014],
        [-0.8669, -0.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09974275529384613
Epoch 0, Step 1721: train/loss = 0.3482968807220459, train/raw-loss = 0.24716439843177795, train/logprobs = tensor([[-0.9763, -6.9614],
        [-1.8773, -2.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14447499811649323
Epoch 0, Step 1722: train/loss = 0.2966134250164032, train/raw-loss = 0.20237475633621216, train/logprobs = tensor([[-0.3840, -3.9186],
        [-1.7866, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13462665677070618
Epoch 0, Step 1723: train/loss = 0.4429745376110077, train/raw-loss = 0.3529157042503357, train/logprobs = tensor([[-0.8812, -3.4723],
        [-1.7685, -1.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12865549325942993
Epoch 0, Step 1724: train/loss = 0.34803828597068787, train/raw-loss = 0.2875101566314697, train/logprobs = tensor([[-0.7131, -5.7325],
        [-1.2310, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08646880090236664
Epoch 0, Step 1725: train/loss = 0.4913056492805481, train/raw-loss = 0.4130280613899231, train/logprobs = tensor([[-0.6699, -5.4347],
        [-1.2526, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11182517558336258
Epoch 0, Step 1726: train/loss = 0.2759019732475281, train/raw-loss = 0.19678020477294922, train/logprobs = tensor([[-0.6640, -5.6354],
        [-1.3931, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130310669541359
Epoch 0, Step 1727: train/loss = 0.3743833899497986, train/raw-loss = 0.29312625527381897, train/logprobs = tensor([[-0.6819, -3.6910],
        [-1.1939, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11608157306909561
Epoch 0, Step 1728: train/loss = 0.592581033706665, train/raw-loss = 0.5351945161819458, train/logprobs = tensor([[-0.7802, -2.7799],
        [-0.7026, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08198079466819763
Epoch 0, Step 1729: train/loss = 0.2852586507797241, train/raw-loss = 0.1996842622756958, train/logprobs = tensor([[-0.8835, -6.6757],
        [-1.4533, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12224911153316498
Epoch 0, Step 1730: train/loss = 0.6642853617668152, train/raw-loss = 0.5802672505378723, train/logprobs = tensor([[-0.7840, -1.4584],
        [-1.0153, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12002585828304291
Epoch 0, Step 1731: train/loss = 0.6032825112342834, train/raw-loss = 0.5343912839889526, train/logprobs = tensor([[-0.4206, -2.4810],
        [-1.0240, -0.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09841608256101608
Epoch 0, Step 1732: train/loss = 0.48140421509742737, train/raw-loss = 0.40821367502212524, train/logprobs = tensor([[-0.7009, -5.2711],
        [-1.1815, -1.3860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10455791652202606
Epoch 0, Step 1733: train/loss = 0.47949329018592834, train/raw-loss = 0.40702614188194275, train/logprobs = tensor([[-0.4073, -3.1367],
        [-0.8605, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10352446883916855
Epoch 0, Step 1734: train/loss = 0.44249558448791504, train/raw-loss = 0.37745916843414307, train/logprobs = tensor([[-1.0946, -4.5128],
        [-1.0536, -0.7732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09290923178195953
Epoch 0, Step 1735: train/loss = 0.30620068311691284, train/raw-loss = 0.23653772473335266, train/logprobs = tensor([[-0.7494, -5.7436],
        [-1.3237, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0995185449719429
Epoch 0, Step 1736: train/loss = 0.3354078531265259, train/raw-loss = 0.23375676572322845, train/logprobs = tensor([[-0.9084, -5.3222],
        [-1.7082, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14521583914756775
Epoch 0, Step 1737: train/loss = 0.2993849515914917, train/raw-loss = 0.21050292253494263, train/logprobs = tensor([[-0.5468, -6.6656],
        [-1.8886, -1.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12697434425354004
Epoch 0, Step 1738: train/loss = 0.5013909339904785, train/raw-loss = 0.42022252082824707, train/logprobs = tensor([[-1.4843, -4.9494],
        [-1.5333, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11595486849546432
Epoch 0, Step 1739: train/loss = 0.49147725105285645, train/raw-loss = 0.41467124223709106, train/logprobs = tensor([[-0.7551, -3.2849],
        [-0.9197, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10972288995981216
Epoch 0, Step 1740: train/loss = 0.4413972496986389, train/raw-loss = 0.3713110387325287, train/logprobs = tensor([[-0.5890, -3.8407],
        [-1.3659, -1.4748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012315213680267
Epoch 0, Step 1741: train/loss = 0.46744030714035034, train/raw-loss = 0.3985150456428528, train/logprobs = tensor([[-0.5707, -4.5169],
        [-1.3073, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09846467524766922
Epoch 0, Step 1742: train/loss = 0.41631442308425903, train/raw-loss = 0.33614489436149597, train/logprobs = tensor([[-1.1736, -6.2835],
        [-1.2677, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11452789604663849
Epoch 0, Step 1743: train/loss = 0.5859255194664001, train/raw-loss = 0.5085656642913818, train/logprobs = tensor([[-0.6563, -2.0578],
        [-1.1719, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11051405966281891
Epoch 0, Step 1744: train/loss = 0.4023284614086151, train/raw-loss = 0.3263571262359619, train/logprobs = tensor([[-1.5754, -6.1931],
        [-1.5965, -1.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10853047668933868
Epoch 0, Step 1745: train/loss = 0.49978727102279663, train/raw-loss = 0.42419159412384033, train/logprobs = tensor([[-0.5430, -4.1476],
        [-1.0065, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10799381136894226
Epoch 0, Step 1746: train/loss = 0.5228292942047119, train/raw-loss = 0.4550415277481079, train/logprobs = tensor([[-0.5134, -2.0526],
        [-0.9077, -0.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09683962166309357
Epoch 0, Step 1747: train/loss = 0.4810725450515747, train/raw-loss = 0.4166766107082367, train/logprobs = tensor([[-0.5617, -1.8778],
        [-1.3774, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09199422597885132
Epoch 0, Step 1748: train/loss = 0.49893227219581604, train/raw-loss = 0.4205700159072876, train/logprobs = tensor([[-0.6737, -1.4665],
        [-1.4461, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11194610595703125
Epoch 0, Step 1749: train/loss = 0.4739627242088318, train/raw-loss = 0.3938261568546295, train/logprobs = tensor([[-0.6665, -2.7493],
        [-1.2261, -0.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11448083817958832
Epoch 0, Step 1750: train/loss = 0.34271395206451416, train/raw-loss = 0.2558032274246216, train/logprobs = tensor([[ -1.0152, -10.3819],
        [ -1.6163,  -1.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12415821105241776
Epoch 0, Step 1751: train/loss = 0.5240284204483032, train/raw-loss = 0.45538634061813354, train/logprobs = tensor([[-1.0482, -4.4555],
        [-1.0151, -1.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09806011617183685
Epoch 0, Step 1752: train/loss = 0.3618451654911041, train/raw-loss = 0.29805856943130493, train/logprobs = tensor([[-0.6757, -7.6474],
        [-1.3179, -1.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112370759248734
Epoch 0, Step 1753: train/loss = 0.3352923095226288, train/raw-loss = 0.2566707134246826, train/logprobs = tensor([[-1.0287, -7.2383],
        [-1.3646, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1123165488243103
Epoch 0, Step 1754: train/loss = 0.23095525801181793, train/raw-loss = 0.13431668281555176, train/logprobs = tensor([[-0.7310, -7.8560],
        [-2.0686, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13805508613586426
Epoch 0, Step 1755: train/loss = 0.4183039665222168, train/raw-loss = 0.34030377864837646, train/logprobs = tensor([[-0.9923, -2.8416],
        [-1.4907, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114288717508316
Epoch 0, Step 1756: train/loss = 0.531043291091919, train/raw-loss = 0.4597190320491791, train/logprobs = tensor([[-1.3965, -3.0068],
        [-1.2604, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10189179331064224
Epoch 0, Step 1757: train/loss = 0.6537465453147888, train/raw-loss = 0.5748681426048279, train/logprobs = tensor([[-0.7652, -0.9914],
        [-0.9407, -0.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268344521522522
Epoch 0, Step 1758: train/loss = 0.37576770782470703, train/raw-loss = 0.3101552426815033, train/logprobs = tensor([[-0.6467, -5.6506],
        [-0.9808, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09373211860656738
Epoch 0, Step 1759: train/loss = 0.4945429563522339, train/raw-loss = 0.4354385733604431, train/logprobs = tensor([[-0.6538, -2.2557],
        [-1.2947, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08443482965230942
Epoch 0, Step 1760: train/loss = 0.5327603220939636, train/raw-loss = 0.44945305585861206, train/logprobs = tensor([[-0.7474, -5.3172],
        [-1.8692, -1.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.119010329246521
Epoch 0, Step 1761: train/loss = 0.33648571372032166, train/raw-loss = 0.2457863986492157, train/logprobs = tensor([[-0.6086, -3.7862],
        [-1.2384, -0.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12957043945789337
Epoch 0, Step 1762: train/loss = 0.46446728706359863, train/raw-loss = 0.38695192337036133, train/logprobs = tensor([[-0.7410, -4.5341],
        [-1.4099, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.110736183822155
Epoch 0, Step 1763: train/loss = 0.5085345506668091, train/raw-loss = 0.42100805044174194, train/logprobs = tensor([[-1.1731, -4.6032],
        [-0.9366, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12503786385059357
Epoch 0, Step 1764: train/loss = 0.2941819429397583, train/raw-loss = 0.21515457332134247, train/logprobs = tensor([[-0.4607, -4.8400],
        [-1.0766, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289619654417038
Epoch 0, Step 1765: train/loss = 0.5273683667182922, train/raw-loss = 0.4405381381511688, train/logprobs = tensor([[-0.4595, -2.5990],
        [-0.9054, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12404320389032364
Epoch 0, Step 1766: train/loss = 0.37295398116111755, train/raw-loss = 0.3017561733722687, train/logprobs = tensor([[-0.9605, -6.2007],
        [-1.4292, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10171116888523102
Epoch 0, Step 1767: train/loss = 0.3577600419521332, train/raw-loss = 0.28550273180007935, train/logprobs = tensor([[-0.4821, -9.3220],
        [-0.9341, -1.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1032247319817543
Epoch 0, Step 1768: train/loss = 0.4062115550041199, train/raw-loss = 0.30370503664016724, train/logprobs = tensor([[-0.6905, -3.4957],
        [-1.7202, -1.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464378833770752
Epoch 0, Step 1769: train/loss = 0.36023056507110596, train/raw-loss = 0.28149574995040894, train/logprobs = tensor([[-0.6884, -2.9654],
        [-1.7131, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11247831583023071
Epoch 0, Step 1770: train/loss = 0.35742804408073425, train/raw-loss = 0.28963780403137207, train/logprobs = tensor([[ -0.8339, -10.3522],
        [ -1.1458,  -1.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968431755900383
Epoch 0, Step 1771: train/loss = 0.4946608543395996, train/raw-loss = 0.4101182520389557, train/logprobs = tensor([[-0.7078, -3.3264],
        [-1.3488, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12077520787715912
Epoch 0, Step 1772: train/loss = 0.38636285066604614, train/raw-loss = 0.31141188740730286, train/logprobs = tensor([[-0.7368, -3.8487],
        [-1.1472, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707277059555054
Epoch 0, Step 1773: train/loss = 0.30783575773239136, train/raw-loss = 0.21258607506752014, train/logprobs = tensor([[-0.6650, -5.8793],
        [-1.3544, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13607101142406464
Epoch 0, Step 1774: train/loss = 0.5555406808853149, train/raw-loss = 0.46700674295425415, train/logprobs = tensor([[-1.4513, -3.0497],
        [-1.8213, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12647706270217896
Epoch 0, Step 1775: train/loss = 0.5119220018386841, train/raw-loss = 0.43073713779449463, train/logprobs = tensor([[-0.6617, -1.8987],
        [-1.1148, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11597830802202225
Epoch 0, Step 1776: train/loss = 0.5725297331809998, train/raw-loss = 0.49202674627304077, train/logprobs = tensor([[-1.9309, -6.8175],
        [-1.6593, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150042787194252
Epoch 0, Step 1777: train/loss = 0.47993654012680054, train/raw-loss = 0.3860156536102295, train/logprobs = tensor([[-0.4383, -3.2680],
        [-1.2730, -0.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13417267799377441
Epoch 0, Step 1778: train/loss = 0.4549621343612671, train/raw-loss = 0.36832472681999207, train/logprobs = tensor([[-0.8337, -3.6528],
        [-1.4302, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12376777827739716
Epoch 0, Step 1779: train/loss = 0.5068718194961548, train/raw-loss = 0.4303838014602661, train/logprobs = tensor([[-0.4758, -5.8232],
        [-0.8820, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10926859080791473
Epoch 0, Step 1780: train/loss = 0.4892998933792114, train/raw-loss = 0.41202351450920105, train/logprobs = tensor([[-0.3936, -4.5046],
        [-0.8414, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11039479821920395
Epoch 0, Step 1781: train/loss = 0.4477232098579407, train/raw-loss = 0.36264869570732117, train/logprobs = tensor([[-0.5772, -3.4078],
        [-1.1767, -0.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12153497338294983
Epoch 0, Step 1782: train/loss = 0.30106472969055176, train/raw-loss = 0.2289595752954483, train/logprobs = tensor([[-0.4688, -5.7626],
        [-0.9144, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10300738364458084
Epoch 0, Step 1783: train/loss = 0.42863932251930237, train/raw-loss = 0.3363914489746094, train/logprobs = tensor([[-0.7290, -3.5582],
        [-1.8122, -0.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13178271055221558
Epoch 0, Step 1784: train/loss = 0.5348030924797058, train/raw-loss = 0.47025665640830994, train/logprobs = tensor([[-1.0176, -2.8309],
        [-0.9809, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09220917522907257
Epoch 0, Step 1785: train/loss = 0.5631422996520996, train/raw-loss = 0.4811460077762604, train/logprobs = tensor([[-0.6849, -2.4420],
        [-0.9890, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11713758856058121
Epoch 0, Step 1786: train/loss = 0.5948600172996521, train/raw-loss = 0.5251802802085876, train/logprobs = tensor([[-0.4667, -1.9039],
        [-0.8074, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954249858856201
Epoch 0, Step 1787: train/loss = 0.5220391154289246, train/raw-loss = 0.42792829871177673, train/logprobs = tensor([[-0.9976, -2.8460],
        [-1.3464, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134443998336792
Epoch 0, Step 1788: train/loss = 0.5010717511177063, train/raw-loss = 0.4334924817085266, train/logprobs = tensor([[-0.4491, -2.5701],
        [-0.6086, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654184430837631
Epoch 0, Step 1789: train/loss = 0.40005195140838623, train/raw-loss = 0.3244117200374603, train/logprobs = tensor([[-0.8412, -4.6192],
        [-1.3416, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10805751383304596
Epoch 0, Step 1790: train/loss = 0.3476720452308655, train/raw-loss = 0.2640337347984314, train/logprobs = tensor([[-0.7268, -5.7394],
        [-1.3519, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11948326230049133
Epoch 0, Step 1791: train/loss = 0.5193833112716675, train/raw-loss = 0.4388308823108673, train/logprobs = tensor([[-1.0114, -2.3395],
        [-1.3834, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11507488787174225
Epoch 0, Step 1792: train/loss = 0.41966819763183594, train/raw-loss = 0.318342000246048, train/logprobs = tensor([[-0.6112, -3.5073],
        [-1.5118, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14475172758102417
Epoch 0, Step 1793: train/loss = 0.3590238094329834, train/raw-loss = 0.2740522027015686, train/logprobs = tensor([[-0.7889, -5.2697],
        [-1.3429, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1213880181312561
Epoch 0, Step 1794: train/loss = 0.3588219881057739, train/raw-loss = 0.28079164028167725, train/logprobs = tensor([[-0.9000, -2.6541],
        [-1.8151, -0.9224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11147195100784302
Epoch 0, Step 1795: train/loss = 0.31140440702438354, train/raw-loss = 0.24115312099456787, train/logprobs = tensor([[-0.4140, -7.6521],
        [-1.6232, -1.6278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003590002655983
Epoch 0, Step 1796: train/loss = 0.5751287341117859, train/raw-loss = 0.5137255191802979, train/logprobs = tensor([[-0.5165, -1.4187],
        [-0.7746, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771885931491852
Epoch 0, Step 1797: train/loss = 0.4350670576095581, train/raw-loss = 0.34672755002975464, train/logprobs = tensor([[-1.3654, -7.6334],
        [-1.7660, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12619927525520325
Epoch 0, Step 1798: train/loss = 0.33265507221221924, train/raw-loss = 0.2412610799074173, train/logprobs = tensor([[-0.8578, -6.3260],
        [-2.8513, -1.9168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13056287169456482
Epoch 0, Step 1799: train/loss = 0.41889065504074097, train/raw-loss = 0.34907034039497375, train/logprobs = tensor([[-0.8138, -4.2025],
        [-1.2807, -0.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09974335134029388
Epoch 0, Step 1800: train/loss = 0.25632530450820923, train/raw-loss = 0.16724994778633118, train/logprobs = tensor([[-0.6091, -8.2494],
        [-1.6287, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272505223751068
Epoch 0, Step 1801: train/loss = 0.3673812747001648, train/raw-loss = 0.28909915685653687, train/logprobs = tensor([[-0.6766, -4.8512],
        [-1.6475, -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11183159053325653
Epoch 0, Step 1802: train/loss = 0.5172821879386902, train/raw-loss = 0.440757691860199, train/logprobs = tensor([[-0.9920, -4.5937],
        [-1.0655, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10932070761919022
Epoch 0, Step 1803: train/loss = 0.41492530703544617, train/raw-loss = 0.3311995565891266, train/logprobs = tensor([[-0.8508, -5.2870],
        [-1.3302, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11960822343826294
Epoch 0, Step 1804: train/loss = 0.4971674680709839, train/raw-loss = 0.4168683886528015, train/logprobs = tensor([[-0.8062, -2.5072],
        [-1.3844, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11471296846866608
Epoch 0, Step 1805: train/loss = 0.4311004877090454, train/raw-loss = 0.3620925545692444, train/logprobs = tensor([[-0.5973, -2.7471],
        [-1.4557, -0.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858274459838867
Epoch 0, Step 1806: train/loss = 0.3508441746234894, train/raw-loss = 0.2853551506996155, train/logprobs = tensor([[-0.5431, -4.0169],
        [-1.3987, -0.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935557559132576
Epoch 0, Step 1807: train/loss = 0.6127691864967346, train/raw-loss = 0.5426819324493408, train/logprobs = tensor([[-0.4190, -2.6442],
        [-0.7345, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012468695640564
Epoch 0, Step 1808: train/loss = 0.37817445397377014, train/raw-loss = 0.30842217803001404, train/logprobs = tensor([[-0.4621, -4.5561],
        [-0.9507, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09964612126350403
Epoch 0, Step 1809: train/loss = 0.404364675283432, train/raw-loss = 0.33000969886779785, train/logprobs = tensor([[-0.5320, -7.2815],
        [-0.9803, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622131824493408
Epoch 0, Step 1810: train/loss = 0.48863744735717773, train/raw-loss = 0.4270327687263489, train/logprobs = tensor([[-0.7043, -1.9219],
        [-1.3464, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08800669759511948
Epoch 0, Step 1811: train/loss = 0.45605096220970154, train/raw-loss = 0.3843690752983093, train/logprobs = tensor([[-0.8151, -5.2883],
        [-1.3156, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10240274667739868
Epoch 0, Step 1812: train/loss = 0.21407169103622437, train/raw-loss = 0.12004122883081436, train/logprobs = tensor([[-1.2888, -7.7362],
        [-2.6295, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13432924449443817
Epoch 0, Step 1813: train/loss = 0.2673373222351074, train/raw-loss = 0.19474083185195923, train/logprobs = tensor([[-0.6963, -9.6241],
        [-1.4332, -2.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370926558971405
Epoch 0, Step 1814: train/loss = 0.4162490665912628, train/raw-loss = 0.32179364562034607, train/logprobs = tensor([[-0.6030, -2.6832],
        [-1.3045, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13493628799915314
Epoch 0, Step 1815: train/loss = 0.3074297308921814, train/raw-loss = 0.23480680584907532, train/logprobs = tensor([[-0.6581, -8.5569],
        [-1.2137, -2.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10374704003334045
Epoch 0, Step 1816: train/loss = 0.39101892709732056, train/raw-loss = 0.31650683283805847, train/logprobs = tensor([[-0.5641, -3.6735],
        [-0.7456, -0.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10644589364528656
Epoch 0, Step 1817: train/loss = 0.6681357026100159, train/raw-loss = 0.6074279546737671, train/logprobs = tensor([[-0.6153, -0.7999],
        [-0.8052, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0867253988981247
Epoch 0, Step 1818: train/loss = 0.293404221534729, train/raw-loss = 0.2063470184803009, train/logprobs = tensor([[-0.5906, -7.6946],
        [-1.6790, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12436743080615997
Epoch 0, Step 1819: train/loss = 0.4034963548183441, train/raw-loss = 0.3174503445625305, train/logprobs = tensor([[-0.7653, -4.6677],
        [-1.3334, -0.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.122922882437706
Epoch 0, Step 1820: train/loss = 0.4583662748336792, train/raw-loss = 0.379652202129364, train/logprobs = tensor([[-0.5370, -3.1880],
        [-1.0748, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11244866251945496
Epoch 0, Step 1821: train/loss = 0.3627297282218933, train/raw-loss = 0.2853151261806488, train/logprobs = tensor([[-0.5848, -5.1653],
        [-1.0646, -0.6642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11059229075908661
Epoch 0, Step 1822: train/loss = 0.47193634510040283, train/raw-loss = 0.3861140310764313, train/logprobs = tensor([[-0.7941, -2.8216],
        [-1.0090, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260333448648453
Epoch 0, Step 1823: train/loss = 0.48361310362815857, train/raw-loss = 0.37914466857910156, train/logprobs = tensor([[-0.4786, -3.0147],
        [-1.4970, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14924058318138123
Epoch 0, Step 1824: train/loss = 0.45104318857192993, train/raw-loss = 0.3773915767669678, train/logprobs = tensor([[-0.4685, -2.7100],
        [-1.1355, -0.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521663725376129
Epoch 0, Step 1825: train/loss = 0.4114290475845337, train/raw-loss = 0.3213392496109009, train/logprobs = tensor([[-0.6794, -4.2762],
        [-1.5124, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286996603012085
Epoch 0, Step 1826: train/loss = 0.3886137008666992, train/raw-loss = 0.3131589889526367, train/logprobs = tensor([[-0.9245, -5.1801],
        [-1.3001, -1.2000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1077924519777298
Epoch 0, Step 1827: train/loss = 0.40042662620544434, train/raw-loss = 0.2966025173664093, train/logprobs = tensor([[-0.6224, -2.2409],
        [-1.5728, -0.9048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14832019805908203
Epoch 0, Step 1828: train/loss = 0.32773351669311523, train/raw-loss = 0.23293143510818481, train/logprobs = tensor([[-1.0211, -6.8040],
        [-1.8624, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13543155789375305
Epoch 0, Step 1829: train/loss = 0.4852830171585083, train/raw-loss = 0.4231049418449402, train/logprobs = tensor([[-0.5382, -2.8324],
        [-0.6254, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08882582187652588
Epoch 0, Step 1830: train/loss = 0.4884728193283081, train/raw-loss = 0.42110687494277954, train/logprobs = tensor([[-0.3908, -3.0783],
        [-0.7923, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09623713046312332
Epoch 0, Step 1831: train/loss = 0.7007606029510498, train/raw-loss = 0.6369755268096924, train/logprobs = tensor([[-0.3957, -0.5401],
        [-0.5508, -0.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112150222063065
Epoch 0, Step 1832: train/loss = 0.4063318073749542, train/raw-loss = 0.33028751611709595, train/logprobs = tensor([[-0.4487, -3.6599],
        [-0.7554, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10863470286130905
Epoch 0, Step 1833: train/loss = 0.6014975309371948, train/raw-loss = 0.5191490054130554, train/logprobs = tensor([[-0.3849, -1.6138],
        [-0.7732, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11764080077409744
Epoch 0, Step 1834: train/loss = 0.5286244750022888, train/raw-loss = 0.4407576620578766, train/logprobs = tensor([[-0.9704, -4.0122],
        [-0.8934, -0.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12552404403686523
Epoch 0, Step 1835: train/loss = 0.28679871559143066, train/raw-loss = 0.21331174671649933, train/logprobs = tensor([[-0.4000, -9.1037],
        [-0.9403, -2.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10498137027025223
Epoch 0, Step 1836: train/loss = 0.2641741633415222, train/raw-loss = 0.16102097928524017, train/logprobs = tensor([[-0.9240, -5.4584],
        [-2.0693, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14736168086528778
Epoch 0, Step 1837: train/loss = 0.40409839153289795, train/raw-loss = 0.3351157307624817, train/logprobs = tensor([[-0.6995, -4.2776],
        [-1.2349, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09854665398597717
Epoch 0, Step 1838: train/loss = 0.37908464670181274, train/raw-loss = 0.30115729570388794, train/logprobs = tensor([[-0.7777, -3.6076],
        [-0.9500, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11132478713989258
Epoch 0, Step 1839: train/loss = 0.34675806760787964, train/raw-loss = 0.26517945528030396, train/logprobs = tensor([[-0.7742, -4.2335],
        [-1.2345, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11654089391231537
Epoch 0, Step 1840: train/loss = 0.2769671082496643, train/raw-loss = 0.19624362885951996, train/logprobs = tensor([[-0.8488, -8.4087],
        [-1.5024, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11531925201416016
Epoch 0, Step 1841: train/loss = 0.4550669193267822, train/raw-loss = 0.37755247950553894, train/logprobs = tensor([[-0.4979, -3.1844],
        [-1.2182, -0.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1107349693775177
Epoch 0, Step 1842: train/loss = 0.3953824043273926, train/raw-loss = 0.3277856111526489, train/logprobs = tensor([[-0.8027, -6.0895],
        [-1.3186, -1.5145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0965668186545372
Epoch 0, Step 1843: train/loss = 0.2893353998661041, train/raw-loss = 0.20879054069519043, train/logprobs = tensor([[-0.8784, -8.0433],
        [-1.8317, -1.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150641143321991
Epoch 0, Step 1844: train/loss = 0.4329789876937866, train/raw-loss = 0.33092010021209717, train/logprobs = tensor([[-0.7625, -3.2622],
        [-1.9331, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14579838514328003
Epoch 0, Step 1845: train/loss = 0.27201035618782043, train/raw-loss = 0.1814049780368805, train/logprobs = tensor([[-0.8080, -7.4591],
        [-1.7227, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12943625450134277
Epoch 0, Step 1846: train/loss = 0.528775155544281, train/raw-loss = 0.45894837379455566, train/logprobs = tensor([[-0.4853, -3.0066],
        [-1.0972, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09975261241197586
Epoch 0, Step 1847: train/loss = 0.275046169757843, train/raw-loss = 0.19191354513168335, train/logprobs = tensor([[-0.6687, -3.8284],
        [-1.8061, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876089870929718
Epoch 0, Step 1848: train/loss = 0.43233275413513184, train/raw-loss = 0.36808550357818604, train/logprobs = tensor([[-0.5959, -2.5425],
        [-1.3684, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09178179502487183
Epoch 0, Step 1849: train/loss = 0.4838210940361023, train/raw-loss = 0.42516160011291504, train/logprobs = tensor([[-0.5125, -3.0193],
        [-0.8124, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08379930257797241
Epoch 0, Step 1850: train/loss = 0.3000917136669159, train/raw-loss = 0.2282371073961258, train/logprobs = tensor([[-0.7353, -5.5667],
        [-1.1332, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10264941304922104
Epoch 0, Step 1851: train/loss = 0.2386418730020523, train/raw-loss = 0.14931367337703705, train/logprobs = tensor([[-0.6220, -5.1497],
        [-1.8422, -0.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1276116967201233
Epoch 0, Step 1852: train/loss = 0.2579984664916992, train/raw-loss = 0.18322134017944336, train/logprobs = tensor([[-0.7295, -9.8179],
        [-1.7496, -1.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10682444274425507
Epoch 0, Step 1853: train/loss = 0.46474725008010864, train/raw-loss = 0.40044909715652466, train/logprobs = tensor([[-0.5910, -5.6619],
        [-0.9372, -1.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918545201420784
Epoch 0, Step 1854: train/loss = 0.8433923125267029, train/raw-loss = 0.7738078236579895, train/logprobs = tensor([[-2.4348, -4.4296],
        [-1.4242, -1.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994064137339592
Epoch 0, Step 1855: train/loss = 0.304399311542511, train/raw-loss = 0.21600422263145447, train/logprobs = tensor([[-0.6078, -8.3130],
        [-1.8677, -1.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12627872824668884
Epoch 0, Step 1856: train/loss = 0.3004153370857239, train/raw-loss = 0.22855451703071594, train/logprobs = tensor([[-0.4222, -7.0494],
        [-1.1744, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10265827178955078
Epoch 0, Step 1857: train/loss = 0.280351459980011, train/raw-loss = 0.19356808066368103, train/logprobs = tensor([[-0.7043, -4.9276],
        [-1.5655, -0.8116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12397627532482147
Epoch 0, Step 1858: train/loss = 0.4536060690879822, train/raw-loss = 0.3676259219646454, train/logprobs = tensor([[-0.8903, -2.8441],
        [-1.2301, -0.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12282876670360565
Epoch 0, Step 1859: train/loss = 0.41974902153015137, train/raw-loss = 0.3401727080345154, train/logprobs = tensor([[-0.5265, -3.4180],
        [-1.1649, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11368042230606079
Epoch 0, Step 1860: train/loss = 0.4249357283115387, train/raw-loss = 0.34154850244522095, train/logprobs = tensor([[-0.5524, -3.7632],
        [-1.7167, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191246509552002
Epoch 0, Step 1861: train/loss = 0.2598695456981659, train/raw-loss = 0.17409497499465942, train/logprobs = tensor([[-0.4903, -8.2146],
        [-1.4579, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12253513187170029
Epoch 0, Step 1862: train/loss = 0.40948545932769775, train/raw-loss = 0.3375183641910553, train/logprobs = tensor([[-0.3864, -5.0727],
        [-1.0028, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281015932559967
Epoch 0, Step 1863: train/loss = 0.5364780426025391, train/raw-loss = 0.4488885998725891, train/logprobs = tensor([[-0.8529, -3.0963],
        [-1.3208, -1.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12512774765491486
Epoch 0, Step 1864: train/loss = 0.37552446126937866, train/raw-loss = 0.298262357711792, train/logprobs = tensor([[-0.9077, -4.9511],
        [-1.5286, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11037440598011017
Epoch 0, Step 1865: train/loss = 0.546883225440979, train/raw-loss = 0.48741164803504944, train/logprobs = tensor([[-0.4245, -3.0775],
        [-0.6753, -0.6602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08495932817459106
Epoch 0, Step 1866: train/loss = 0.5417524576187134, train/raw-loss = 0.46876564621925354, train/logprobs = tensor([[-0.7725, -2.2791],
        [-1.0444, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10426691174507141
Epoch 0, Step 1867: train/loss = 0.47263044118881226, train/raw-loss = 0.38366222381591797, train/logprobs = tensor([[-0.6352, -3.0753],
        [-1.6150, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270975023508072
Epoch 0, Step 1868: train/loss = 0.5670784115791321, train/raw-loss = 0.49113014340400696, train/logprobs = tensor([[-0.6424, -2.0821],
        [-0.9537, -0.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10849753767251968
Epoch 0, Step 1869: train/loss = 0.4912130832672119, train/raw-loss = 0.4092380404472351, train/logprobs = tensor([[-1.0923, -5.1578],
        [-2.3793, -2.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11710718274116516
Epoch 0, Step 1870: train/loss = 0.2674594521522522, train/raw-loss = 0.18772874772548676, train/logprobs = tensor([[-1.0722, -5.7649],
        [-1.8630, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11390097439289093
Epoch 0, Step 1871: train/loss = 0.43446633219718933, train/raw-loss = 0.3663046658039093, train/logprobs = tensor([[-0.3864, -6.7803],
        [-0.7766, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0973738431930542
Epoch 0, Step 1872: train/loss = 0.737890362739563, train/raw-loss = 0.677264392375946, train/logprobs = tensor([[-0.5677, -0.6492],
        [-0.5735, -0.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08660852909088135
Epoch 0, Step 1873: train/loss = 0.5563124418258667, train/raw-loss = 0.4881075322628021, train/logprobs = tensor([[-0.6342, -2.6283],
        [-1.0845, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09743558615446091
Epoch 0, Step 1874: train/loss = 0.25443151593208313, train/raw-loss = 0.18088290095329285, train/logprobs = tensor([[-0.4350, -6.2769],
        [-1.2476, -1.1805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10506945103406906
Epoch 0, Step 1875: train/loss = 0.5095508694648743, train/raw-loss = 0.4460177719593048, train/logprobs = tensor([[-0.7513, -2.8068],
        [-1.0301, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09076164662837982
Epoch 0, Step 1876: train/loss = 0.38622361421585083, train/raw-loss = 0.3173218369483948, train/logprobs = tensor([[-0.7594, -5.4543],
        [-1.1300, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0984310433268547
Epoch 0, Step 1877: train/loss = 0.3333914279937744, train/raw-loss = 0.23935720324516296, train/logprobs = tensor([[-0.6356, -7.6258],
        [-1.9989, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13433460891246796
Epoch 0, Step 1878: train/loss = 0.33406755328178406, train/raw-loss = 0.24205338954925537, train/logprobs = tensor([[-0.6347, -5.5006],
        [-1.6926, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314488649368286
Epoch 0, Step 1879: train/loss = 0.33089154958724976, train/raw-loss = 0.23755277693271637, train/logprobs = tensor([[-0.7151, -6.3531],
        [-1.7776, -1.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13334105908870697
Epoch 0, Step 1880: train/loss = 0.517145574092865, train/raw-loss = 0.4592435359954834, train/logprobs = tensor([[-0.7380, -2.8012],
        [-1.1393, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08271725475788116
Epoch 0, Step 1881: train/loss = 0.47637230157852173, train/raw-loss = 0.39471983909606934, train/logprobs = tensor([[-0.8704, -2.8014],
        [-1.2315, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664634943008423
Epoch 0, Step 1882: train/loss = 0.2875679135322571, train/raw-loss = 0.17685480415821075, train/logprobs = tensor([[-1.0201, -6.1594],
        [-2.7173, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15816156566143036
Epoch 0, Step 1883: train/loss = 0.47560885548591614, train/raw-loss = 0.3897828459739685, train/logprobs = tensor([[-0.9437, -2.4739],
        [-1.5116, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260854244232178
Epoch 0, Step 1884: train/loss = 0.35078752040863037, train/raw-loss = 0.2607525587081909, train/logprobs = tensor([[-0.9814, -7.0049],
        [-1.6949, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12862135469913483
Epoch 0, Step 1885: train/loss = 0.3880474865436554, train/raw-loss = 0.31845659017562866, train/logprobs = tensor([[-0.7060, -4.7124],
        [-1.0711, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941556304693222
Epoch 0, Step 1886: train/loss = 0.4142100214958191, train/raw-loss = 0.334405779838562, train/logprobs = tensor([[-0.5324, -5.0027],
        [-1.9293, -1.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11400607228279114
Epoch 0, Step 1887: train/loss = 0.44384926557540894, train/raw-loss = 0.34512239694595337, train/logprobs = tensor([[-0.5090, -1.7809],
        [-1.6008, -0.6899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1410384327173233
Epoch 0, Step 1888: train/loss = 0.6801785826683044, train/raw-loss = 0.6145407557487488, train/logprobs = tensor([[-0.7025, -1.0352],
        [-0.7541, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09376838803291321
Epoch 0, Step 1889: train/loss = 0.3453792333602905, train/raw-loss = 0.2593846917152405, train/logprobs = tensor([[-0.7192, -5.0511],
        [-1.4480, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12284936010837555
Epoch 0, Step 1890: train/loss = 0.4448610544204712, train/raw-loss = 0.36682406067848206, train/logprobs = tensor([[-0.8175, -2.9096],
        [-1.3273, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148138344287872
Epoch 0, Step 1891: train/loss = 0.6249567270278931, train/raw-loss = 0.5269709825515747, train/logprobs = tensor([[-1.5323, -4.1420],
        [-1.4473, -1.1825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13997958600521088
Epoch 0, Step 1892: train/loss = 0.5655316710472107, train/raw-loss = 0.47345224022865295, train/logprobs = tensor([[-0.9055, -2.5148],
        [-1.2191, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13154202699661255
Epoch 0, Step 1893: train/loss = 0.5063380002975464, train/raw-loss = 0.42980116605758667, train/logprobs = tensor([[-0.7405, -2.3758],
        [-1.1210, -0.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10933837294578552
Epoch 0, Step 1894: train/loss = 0.4694522023200989, train/raw-loss = 0.3860017657279968, train/logprobs = tensor([[-0.4425, -1.9079],
        [-1.3655, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11921492218971252
Epoch 0, Step 1895: train/loss = 0.5099613666534424, train/raw-loss = 0.4481469392776489, train/logprobs = tensor([[-0.3860, -4.2616],
        [-0.5957, -0.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08830632269382477
Epoch 0, Step 1896: train/loss = 0.3087477684020996, train/raw-loss = 0.23473280668258667, train/logprobs = tensor([[-0.6938, -7.0818],
        [-1.9228, -2.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057356670498848
Epoch 0, Step 1897: train/loss = 0.2480640411376953, train/raw-loss = 0.15589097142219543, train/logprobs = tensor([[-0.4231, -7.3806],
        [-1.3474, -1.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316758394241333
Epoch 0, Step 1898: train/loss = 0.47979098558425903, train/raw-loss = 0.39558109641075134, train/logprobs = tensor([[-0.7243, -4.6774],
        [-1.1156, -0.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1202998161315918
Epoch 0, Step 1899: train/loss = 0.3477330803871155, train/raw-loss = 0.26166999340057373, train/logprobs = tensor([[-1.2194, -4.4699],
        [-2.2752, -0.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12294729053974152
Epoch 0, Step 1900: train/loss = 0.38461238145828247, train/raw-loss = 0.3137779235839844, train/logprobs = tensor([[-0.9345, -4.3727],
        [-1.2484, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10119212418794632
Epoch 0, Step 1901: train/loss = 0.46347135305404663, train/raw-loss = 0.3690393567085266, train/logprobs = tensor([[-1.3157, -4.0303],
        [-1.7383, -0.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13490286469459534
Epoch 0, Step 1902: train/loss = 0.4609708786010742, train/raw-loss = 0.39247384667396545, train/logprobs = tensor([[-0.6733, -3.6368],
        [-0.9765, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09785296767950058
Epoch 0, Step 1903: train/loss = 0.4787180423736572, train/raw-loss = 0.4122634530067444, train/logprobs = tensor([[-0.6733, -2.7199],
        [-0.9595, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949351117014885
Epoch 0, Step 1904: train/loss = 0.3787965774536133, train/raw-loss = 0.3088809847831726, train/logprobs = tensor([[-0.6385, -7.0509],
        [-1.1126, -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09987939894199371
Epoch 0, Step 1905: train/loss = 0.41537824273109436, train/raw-loss = 0.35108059644699097, train/logprobs = tensor([[-0.9954, -7.9426],
        [-1.1892, -1.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09185375273227692
Epoch 0, Step 1906: train/loss = 0.5304341912269592, train/raw-loss = 0.4484858512878418, train/logprobs = tensor([[-0.8911, -1.9935],
        [-1.1709, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1170690730214119
Epoch 0, Step 1907: train/loss = 0.451289564371109, train/raw-loss = 0.3789573907852173, train/logprobs = tensor([[-0.6345, -5.1360],
        [-0.9770, -0.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10333170741796494
Epoch 0, Step 1908: train/loss = 0.6152275800704956, train/raw-loss = 0.5398298501968384, train/logprobs = tensor([[-1.0171, -4.1786],
        [-0.7840, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771097242832184
Epoch 0, Step 1909: train/loss = 0.3923790156841278, train/raw-loss = 0.28239673376083374, train/logprobs = tensor([[-0.7690, -6.5219],
        [-2.3295, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1571175456047058
Epoch 0, Step 1910: train/loss = 0.4265061616897583, train/raw-loss = 0.35725387930870056, train/logprobs = tensor([[-0.5771, -4.3394],
        [-1.1596, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09893184900283813
Epoch 0, Step 1911: train/loss = 0.2984522581100464, train/raw-loss = 0.21170462667942047, train/logprobs = tensor([[-0.6954, -6.6035],
        [-1.9889, -0.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12392517924308777
Epoch 0, Step 1912: train/loss = 0.45780327916145325, train/raw-loss = 0.36484193801879883, train/logprobs = tensor([[-0.8633, -2.3603],
        [-1.6169, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328018605709076
Epoch 0, Step 1913: train/loss = 0.39156046509742737, train/raw-loss = 0.31431901454925537, train/logprobs = tensor([[-0.6141, -3.0973],
        [-1.6780, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11034494638442993
Epoch 0, Step 1914: train/loss = 0.2482912391424179, train/raw-loss = 0.16757403314113617, train/logprobs = tensor([[-0.5561, -9.8432],
        [-1.9451, -2.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11531029641628265
Epoch 0, Step 1915: train/loss = 0.26759037375450134, train/raw-loss = 0.18595021963119507, train/logprobs = tensor([[-0.6780, -8.5420],
        [-1.8140, -1.3864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11662878096103668
Epoch 0, Step 1916: train/loss = 0.5045186281204224, train/raw-loss = 0.4100106358528137, train/logprobs = tensor([[-0.4685, -2.6131],
        [-1.3515, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350114643573761
Epoch 0, Step 1917: train/loss = 0.5818372964859009, train/raw-loss = 0.5185542106628418, train/logprobs = tensor([[-0.9382, -2.4460],
        [-1.0242, -1.2122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09040437638759613
Epoch 0, Step 1918: train/loss = 0.3828725516796112, train/raw-loss = 0.27006036043167114, train/logprobs = tensor([[-0.6819, -3.7300],
        [-2.1887, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16116023063659668
Epoch 0, Step 1919: train/loss = 0.25362852215766907, train/raw-loss = 0.1629709154367447, train/logprobs = tensor([[-0.6495, -6.6468],
        [-1.5457, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12951084971427917
Epoch 0, Step 1920: train/loss = 0.3361671268939972, train/raw-loss = 0.2564443349838257, train/logprobs = tensor([[-0.5189, -3.8783],
        [-1.5435, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.113889679312706
Epoch 0, Step 1921: train/loss = 0.34858930110931396, train/raw-loss = 0.2580229640007019, train/logprobs = tensor([[-0.4968, -8.5554],
        [-1.8883, -1.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12938052415847778
Epoch 0, Step 1922: train/loss = 0.23522143065929413, train/raw-loss = 0.13619638979434967, train/logprobs = tensor([[-0.7020, -6.7473],
        [-2.1239, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14146436750888824
Epoch 0, Step 1923: train/loss = 0.3470958471298218, train/raw-loss = 0.26613807678222656, train/logprobs = tensor([[-0.5916, -7.4554],
        [-1.5244, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11565400660037994
Epoch 0, Step 1924: train/loss = 0.2798286974430084, train/raw-loss = 0.18190470337867737, train/logprobs = tensor([[-0.5885, -5.7002],
        [-1.3920, -0.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13989144563674927
Epoch 0, Step 1925: train/loss = 0.39760318398475647, train/raw-loss = 0.30963167548179626, train/logprobs = tensor([[-0.6222, -6.9528],
        [-1.5179, -1.2355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256735771894455
Epoch 0, Step 1926: train/loss = 0.4462466835975647, train/raw-loss = 0.37190574407577515, train/logprobs = tensor([[-0.6618, -3.1175],
        [-1.2962, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062014177441597
Epoch 0, Step 1927: train/loss = 0.32090023159980774, train/raw-loss = 0.22556255757808685, train/logprobs = tensor([[-0.8664, -5.0534],
        [-1.4283, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13619664311408997
Epoch 0, Step 1928: train/loss = 0.45006436109542847, train/raw-loss = 0.37929773330688477, train/logprobs = tensor([[-0.4589, -3.6597],
        [-1.0828, -0.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10109513998031616
Epoch 0, Step 1929: train/loss = 0.37301233410835266, train/raw-loss = 0.3001205027103424, train/logprobs = tensor([[-0.4994, -4.2566],
        [-1.1057, -0.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10413122177124023
Epoch 0, Step 1930: train/loss = 0.5196308493614197, train/raw-loss = 0.45592039823532104, train/logprobs = tensor([[-0.6410, -3.4428],
        [-0.5600, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09101490676403046
Epoch 0, Step 1931: train/loss = 0.6274232268333435, train/raw-loss = 0.5564945340156555, train/logprobs = tensor([[-0.7191, -2.6996],
        [-1.0367, -0.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10132671892642975
Epoch 0, Step 1932: train/loss = 0.5524488687515259, train/raw-loss = 0.47501546144485474, train/logprobs = tensor([[-0.6193, -3.6911],
        [-1.4217, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11061917245388031
Epoch 0, Step 1933: train/loss = 0.5719370245933533, train/raw-loss = 0.4860560894012451, train/logprobs = tensor([[-1.0801, -2.7261],
        [-1.2726, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12268705666065216
Epoch 0, Step 1934: train/loss = 0.5462383031845093, train/raw-loss = 0.4670880138874054, train/logprobs = tensor([[-0.6396, -2.0597],
        [-0.9913, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11307189613580704
Epoch 0, Step 1935: train/loss = 0.3418956995010376, train/raw-loss = 0.2583462595939636, train/logprobs = tensor([[-0.6827, -4.3961],
        [-2.0720, -1.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11935628950595856
Epoch 0, Step 1936: train/loss = 0.2836466431617737, train/raw-loss = 0.19880801439285278, train/logprobs = tensor([[-0.5047, -8.4905],
        [-1.3524, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12119802087545395
Epoch 0, Step 1937: train/loss = 0.6781741380691528, train/raw-loss = 0.6130342483520508, train/logprobs = tensor([[-0.9943, -1.2078],
        [-1.6659, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09305694699287415
Epoch 0, Step 1938: train/loss = 0.5879842042922974, train/raw-loss = 0.498068630695343, train/logprobs = tensor([[-1.6774, -4.7273],
        [-1.4217, -1.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12845081090927124
Epoch 0, Step 1939: train/loss = 0.5039886832237244, train/raw-loss = 0.4386923313140869, train/logprobs = tensor([[-0.5997, -2.3748],
        [-0.8366, -0.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09328055381774902
Epoch 0, Step 1940: train/loss = 0.5390154719352722, train/raw-loss = 0.4706387221813202, train/logprobs = tensor([[-0.8620, -5.3400],
        [-1.2229, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09768110513687134
Epoch 0, Step 1941: train/loss = 0.6934187412261963, train/raw-loss = 0.5932202339172363, train/logprobs = tensor([[-1.2798, -2.1005],
        [-1.6247, -1.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431407779455185
Epoch 0, Step 1942: train/loss = 0.4174725413322449, train/raw-loss = 0.31556376814842224, train/logprobs = tensor([[-0.8139, -5.1880],
        [-1.9321, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14558394253253937
Epoch 0, Step 1943: train/loss = 0.3436260223388672, train/raw-loss = 0.24227045476436615, train/logprobs = tensor([[-0.5431, -5.8139],
        [-1.6681, -0.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14479367434978485
Epoch 0, Step 1944: train/loss = 0.5433793663978577, train/raw-loss = 0.47386524081230164, train/logprobs = tensor([[-0.7062, -1.7933],
        [-1.1419, -0.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09930595755577087
Epoch 0, Step 1945: train/loss = 0.49699753522872925, train/raw-loss = 0.41975894570350647, train/logprobs = tensor([[-0.4288, -2.0258],
        [-1.1298, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11034084856510162
Epoch 0, Step 1946: train/loss = 0.6885586977005005, train/raw-loss = 0.6068167686462402, train/logprobs = tensor([[-1.6191, -4.7122],
        [-0.8458, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677414178848267
Epoch 0, Step 1947: train/loss = 0.6333931684494019, train/raw-loss = 0.5644332766532898, train/logprobs = tensor([[-0.6971, -1.0850],
        [-0.9352, -0.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.098514124751091
Epoch 0, Step 1948: train/loss = 0.3876620829105377, train/raw-loss = 0.3221451938152313, train/logprobs = tensor([[-0.4690, -5.1859],
        [-0.8036, -0.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09359552711248398
Epoch 0, Step 1949: train/loss = 0.43037551641464233, train/raw-loss = 0.36241912841796875, train/logprobs = tensor([[-0.6229, -3.9603],
        [-1.0482, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09708055108785629
Epoch 0, Step 1950: train/loss = 0.38444551825523376, train/raw-loss = 0.3131457567214966, train/logprobs = tensor([[-0.7202, -6.3707],
        [-1.1732, -1.1868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1018567830324173
Epoch 0, Step 1951: train/loss = 0.36495786905288696, train/raw-loss = 0.2781301736831665, train/logprobs = tensor([[-0.6652, -3.2880],
        [-1.9330, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12403957545757294
Epoch 0, Step 1952: train/loss = 0.42595016956329346, train/raw-loss = 0.3471328318119049, train/logprobs = tensor([[-0.6116, -2.9012],
        [-1.9329, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11259625107049942
Epoch 0, Step 1953: train/loss = 0.40006503462791443, train/raw-loss = 0.33481019735336304, train/logprobs = tensor([[-0.6705, -6.5125],
        [-1.0856, -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322119504213333
Epoch 0, Step 1954: train/loss = 0.2942902445793152, train/raw-loss = 0.21609659492969513, train/logprobs = tensor([[-0.6594, -7.5191],
        [-1.5774, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170519888401031
Epoch 0, Step 1955: train/loss = 0.3879868686199188, train/raw-loss = 0.29835957288742065, train/logprobs = tensor([[-1.3180, -5.2034],
        [-1.9061, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12803903222084045
Epoch 0, Step 1956: train/loss = 0.5204582214355469, train/raw-loss = 0.4203594923019409, train/logprobs = tensor([[-0.5673, -3.9964],
        [-1.3036, -2.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14299817383289337
Epoch 0, Step 1957: train/loss = 0.45661696791648865, train/raw-loss = 0.359892338514328, train/logprobs = tensor([[-0.5865, -5.0109],
        [-1.7624, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1381780505180359
Epoch 0, Step 1958: train/loss = 0.26044344902038574, train/raw-loss = 0.17007198929786682, train/logprobs = tensor([[ -0.9395, -10.2409],
        [ -1.9027,  -2.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12910211086273193
Epoch 0, Step 1959: train/loss = 0.31927260756492615, train/raw-loss = 0.22128552198410034, train/logprobs = tensor([[-0.5641, -8.2715],
        [-1.9684, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13998155295848846
Epoch 0, Step 1960: train/loss = 0.3385884165763855, train/raw-loss = 0.24684222042560577, train/logprobs = tensor([[-0.5560, -5.6737],
        [-1.7121, -1.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13106602430343628
Epoch 0, Step 1961: train/loss = 0.26153379678726196, train/raw-loss = 0.17630572617053986, train/logprobs = tensor([[-0.5036, -6.6247],
        [-1.3861, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12175436317920685
Epoch 0, Step 1962: train/loss = 0.6414498090744019, train/raw-loss = 0.5515493154525757, train/logprobs = tensor([[-0.5045, -1.0775],
        [-0.9313, -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12842926383018494
Epoch 0, Step 1963: train/loss = 0.4879915714263916, train/raw-loss = 0.40263456106185913, train/logprobs = tensor([[-0.6392, -5.4910],
        [-1.1827, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12193860858678818
Epoch 0, Step 1964: train/loss = 0.3603666424751282, train/raw-loss = 0.2899611294269562, train/logprobs = tensor([[-0.4308, -4.1700],
        [-1.1254, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10057927668094635
Epoch 0, Step 1965: train/loss = 0.5592005252838135, train/raw-loss = 0.4942382574081421, train/logprobs = tensor([[-0.4820, -1.2863],
        [-0.7992, -0.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09280321002006531
Epoch 0, Step 1966: train/loss = 0.24202190339565277, train/raw-loss = 0.15926876664161682, train/logprobs = tensor([[ -0.6751, -13.1798],
        [ -1.4941,  -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11821875721216202
Epoch 0, Step 1967: train/loss = 0.46814078092575073, train/raw-loss = 0.3776865601539612, train/logprobs = tensor([[-1.1416, -4.2583],
        [-1.2467, -1.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12922030687332153
Epoch 0, Step 1968: train/loss = 0.5415475368499756, train/raw-loss = 0.45234110951423645, train/logprobs = tensor([[-0.7136, -3.6564],
        [-1.5414, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1274377554655075
Epoch 0, Step 1969: train/loss = 0.30881187319755554, train/raw-loss = 0.21635617315769196, train/logprobs = tensor([[-0.6335, -8.2405],
        [-1.9131, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13207955658435822
Epoch 0, Step 1970: train/loss = 0.35746437311172485, train/raw-loss = 0.2704133689403534, train/logprobs = tensor([[-0.7835, -6.7144],
        [-1.2343, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12435854971408844
Epoch 0, Step 1971: train/loss = 0.34889185428619385, train/raw-loss = 0.2713606357574463, train/logprobs = tensor([[-0.5274, -4.2037],
        [-1.3737, -0.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11075891554355621
Epoch 0, Step 1972: train/loss = 0.32609128952026367, train/raw-loss = 0.21422812342643738, train/logprobs = tensor([[-0.7286, -4.4665],
        [-2.0269, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159804567694664
Epoch 0, Step 1973: train/loss = 0.33877551555633545, train/raw-loss = 0.2375943809747696, train/logprobs = tensor([[-0.7014, -4.7251],
        [-2.5205, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14454451203346252
Epoch 0, Step 1974: train/loss = 0.33830130100250244, train/raw-loss = 0.2436521053314209, train/logprobs = tensor([[-0.5996, -4.8177],
        [-1.5248, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13521316647529602
Epoch 0, Step 1975: train/loss = 0.5074403882026672, train/raw-loss = 0.43971386551856995, train/logprobs = tensor([[-0.6401, -3.0562],
        [-1.0920, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09675218909978867
Epoch 0, Step 1976: train/loss = 0.3464542031288147, train/raw-loss = 0.264326810836792, train/logprobs = tensor([[-0.6835, -5.7388],
        [-1.3936, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11732485890388489
Epoch 0, Step 1977: train/loss = 0.20755437016487122, train/raw-loss = 0.12573052942752838, train/logprobs = tensor([[ -0.6285, -10.6256],
        [ -1.9202,  -2.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11689120531082153
Epoch 0, Step 1978: train/loss = 0.380146324634552, train/raw-loss = 0.28457096219062805, train/logprobs = tensor([[-0.5481, -4.2226],
        [-1.2665, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13653619587421417
Epoch 0, Step 1979: train/loss = 0.4422723948955536, train/raw-loss = 0.3464413583278656, train/logprobs = tensor([[-0.6568, -4.3761],
        [-1.4834, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13690149784088135
Epoch 0, Step 1980: train/loss = 0.36372077465057373, train/raw-loss = 0.2801366448402405, train/logprobs = tensor([[-0.9575, -3.6485],
        [-1.6896, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11940585821866989
Epoch 0, Step 1981: train/loss = 0.2719835340976715, train/raw-loss = 0.176885724067688, train/logprobs = tensor([[-0.5379, -6.4864],
        [-2.0562, -1.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13585399091243744
Epoch 0, Step 1982: train/loss = 0.4854143261909485, train/raw-loss = 0.40801289677619934, train/logprobs = tensor([[-0.8102, -1.8271],
        [-1.4101, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057349294424057
Epoch 0, Step 1983: train/loss = 0.5517764687538147, train/raw-loss = 0.4856893718242645, train/logprobs = tensor([[-0.4543, -1.4561],
        [-0.8692, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09441009163856506
Epoch 0, Step 1984: train/loss = 0.27483344078063965, train/raw-loss = 0.19201433658599854, train/logprobs = tensor([[-0.9415, -6.9010],
        [-1.7084, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1183130145072937
Epoch 0, Step 1985: train/loss = 0.5293757915496826, train/raw-loss = 0.45507100224494934, train/logprobs = tensor([[-0.7155, -3.3347],
        [-1.1330, -1.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10614961385726929
Epoch 0, Step 1986: train/loss = 0.6268107295036316, train/raw-loss = 0.5553228855133057, train/logprobs = tensor([[-0.8937, -3.3650],
        [-0.9812, -1.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10212554037570953
Epoch 0, Step 1987: train/loss = 0.5250797867774963, train/raw-loss = 0.4583544433116913, train/logprobs = tensor([[-1.1313, -4.3568],
        [-1.2335, -1.2415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0953218936920166
Epoch 0, Step 1988: train/loss = 0.5416929721832275, train/raw-loss = 0.48214998841285706, train/logprobs = tensor([[-0.3587, -3.4648],
        [-0.8351, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0850614532828331
Epoch 0, Step 1989: train/loss = 0.4531826376914978, train/raw-loss = 0.38352277874946594, train/logprobs = tensor([[-0.6471, -3.6294],
        [-0.6888, -0.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09951405227184296
Epoch 0, Step 1990: train/loss = 0.27823346853256226, train/raw-loss = 0.18832671642303467, train/logprobs = tensor([[ -0.5711, -12.0027],
        [ -1.5850,  -1.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12843820452690125
Epoch 0, Step 1991: train/loss = 0.36561155319213867, train/raw-loss = 0.27518200874328613, train/logprobs = tensor([[-0.5833, -5.7024],
        [-1.6298, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1291850209236145
Epoch 0, Step 1992: train/loss = 0.5340085029602051, train/raw-loss = 0.421743780374527, train/logprobs = tensor([[-0.9373, -4.1786],
        [-1.3085, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16037823259830475
Epoch 0, Step 1993: train/loss = 0.4825495481491089, train/raw-loss = 0.40774670243263245, train/logprobs = tensor([[-0.7718, -3.3818],
        [-1.0961, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1068611890077591
Epoch 0, Step 1994: train/loss = 0.4055320620536804, train/raw-loss = 0.32140839099884033, train/logprobs = tensor([[-0.5793, -3.5345],
        [-1.5762, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12017667293548584
Epoch 0, Step 1995: train/loss = 0.33266502618789673, train/raw-loss = 0.2507275640964508, train/logprobs = tensor([[-0.5947, -4.1818],
        [-1.7465, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1170535534620285
Epoch 0, Step 1996: train/loss = 0.46557313203811646, train/raw-loss = 0.39649340510368347, train/logprobs = tensor([[-0.7113, -2.1642],
        [-1.5648, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868529438972473
Epoch 0, Step 1997: train/loss = 0.45275360345840454, train/raw-loss = 0.3572671711444855, train/logprobs = tensor([[-0.6234, -5.4166],
        [-1.3876, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364092081785202
Epoch 0, Step 1998: train/loss = 0.6056792736053467, train/raw-loss = 0.5294512510299683, train/logprobs = tensor([[-0.6043, -1.9938],
        [-1.1798, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889717936515808
Epoch 0, Step 1999: train/loss = 0.7507860064506531, train/raw-loss = 0.6926401257514954, train/logprobs = tensor([[-1.5975, -2.3699],
        [-0.7504, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08306552469730377
Epoch 0, Step 2000: train/loss = 0.5268548727035522, train/raw-loss = 0.4593714773654938, train/logprobs = tensor([[-0.6113, -2.2238],
        [-0.8226, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09640488773584366
Epoch 0, Step 2001: train/loss = 0.5476641058921814, train/raw-loss = 0.46278539299964905, train/logprobs = tensor([[-0.7285, -1.7556],
        [-1.2408, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212553009390831
Epoch 0, Step 2002: train/loss = 0.3625802993774414, train/raw-loss = 0.2924915552139282, train/logprobs = tensor([[-0.6791, -5.7431],
        [-1.1996, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012679547071457
Epoch 0, Step 2003: train/loss = 0.3949816823005676, train/raw-loss = 0.2954299747943878, train/logprobs = tensor([[-1.1116, -4.5707],
        [-1.6996, -0.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422167420387268
Epoch 0, Step 2004: train/loss = 0.2866672873497009, train/raw-loss = 0.20314648747444153, train/logprobs = tensor([[-0.4357, -7.9188],
        [-1.2059, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11931543052196503
Epoch 0, Step 2005: train/loss = 0.23566599190235138, train/raw-loss = 0.14052408933639526, train/logprobs = tensor([[-0.7491, -8.3577],
        [-2.4496, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13591700792312622
Epoch 0, Step 2006: train/loss = 0.38231828808784485, train/raw-loss = 0.3150600492954254, train/logprobs = tensor([[-0.5603, -9.2028],
        [-0.9819, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608323127031326
Epoch 0, Step 2007: train/loss = 0.4546888470649719, train/raw-loss = 0.37395375967025757, train/logprobs = tensor([[-0.4002, -2.4092],
        [-0.9310, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11533576250076294
Epoch 0, Step 2008: train/loss = 0.4659770131111145, train/raw-loss = 0.4017017185688019, train/logprobs = tensor([[-0.7612, -4.7864],
        [-1.4238, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918218195438385
Epoch 0, Step 2009: train/loss = 0.6198154091835022, train/raw-loss = 0.5360763072967529, train/logprobs = tensor([[-1.3798, -4.1573],
        [-0.8261, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11962725222110748
Epoch 0, Step 2010: train/loss = 0.37944698333740234, train/raw-loss = 0.29267624020576477, train/logprobs = tensor([[-0.8748, -5.4196],
        [-1.4701, -0.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12395819276571274
Epoch 0, Step 2011: train/loss = 0.36829203367233276, train/raw-loss = 0.29000920057296753, train/logprobs = tensor([[-0.5280, -3.3121],
        [-1.4831, -0.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1118326187133789
Epoch 0, Step 2012: train/loss = 0.4948519766330719, train/raw-loss = 0.4154854416847229, train/logprobs = tensor([[-0.6327, -3.2095],
        [-1.1454, -0.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11338077485561371
Epoch 0, Step 2013: train/loss = 0.5936535596847534, train/raw-loss = 0.5266528129577637, train/logprobs = tensor([[-0.5804, -1.0316],
        [-1.0093, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09571532905101776
Epoch 0, Step 2014: train/loss = 0.4839048981666565, train/raw-loss = 0.3930667042732239, train/logprobs = tensor([[-1.3790, -6.2431],
        [-2.3938, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12976881861686707
Epoch 0, Step 2015: train/loss = 0.5487026572227478, train/raw-loss = 0.48148900270462036, train/logprobs = tensor([[-0.5623, -1.9024],
        [-0.8388, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09601951390504837
Epoch 0, Step 2016: train/loss = 0.4144405722618103, train/raw-loss = 0.32545945048332214, train/logprobs = tensor([[-1.0200, -3.6201],
        [-1.4922, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271158754825592
Epoch 0, Step 2017: train/loss = 0.277410089969635, train/raw-loss = 0.1876751333475113, train/logprobs = tensor([[-0.7751, -5.9805],
        [-1.4736, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12819278240203857
Epoch 0, Step 2018: train/loss = 0.3039208948612213, train/raw-loss = 0.20969036221504211, train/logprobs = tensor([[-0.6168, -7.1508],
        [-1.9096, -0.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13461506366729736
Epoch 0, Step 2019: train/loss = 0.37324249744415283, train/raw-loss = 0.3033422529697418, train/logprobs = tensor([[-0.5009, -3.7200],
        [-0.8998, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09985747188329697
Epoch 0, Step 2020: train/loss = 0.6859717965126038, train/raw-loss = 0.6109228134155273, train/logprobs = tensor([[-1.0418, -1.4703],
        [-0.9893, -0.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072128489613533
Epoch 0, Step 2021: train/loss = 0.5101174712181091, train/raw-loss = 0.446238249540329, train/logprobs = tensor([[-0.3147, -3.9766],
        [-0.5888, -0.3715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09125605970621109
Epoch 0, Step 2022: train/loss = 0.5531377196311951, train/raw-loss = 0.46429771184921265, train/logprobs = tensor([[-0.5628, -2.2920],
        [-1.6867, -0.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12691423296928406
Epoch 0, Step 2023: train/loss = 0.36235693097114563, train/raw-loss = 0.2692854404449463, train/logprobs = tensor([[-0.7838, -4.7312],
        [-2.2543, -1.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1329592615365982
Epoch 0, Step 2024: train/loss = 0.2008143961429596, train/raw-loss = 0.11094710230827332, train/logprobs = tensor([[-0.6258, -8.3587],
        [-1.9520, -1.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1283818483352661
Epoch 0, Step 2025: train/loss = 0.504098653793335, train/raw-loss = 0.4227425456047058, train/logprobs = tensor([[-1.1240, -5.9670],
        [-1.5184, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1162230521440506
Epoch 0, Step 2026: train/loss = 0.2952209711074829, train/raw-loss = 0.20406195521354675, train/logprobs = tensor([[-0.4755, -5.5374],
        [-1.3294, -0.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.130227193236351
Epoch 0, Step 2027: train/loss = 0.3715004622936249, train/raw-loss = 0.2886115312576294, train/logprobs = tensor([[-0.4296, -3.1964],
        [-0.8984, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11841276288032532
Epoch 0, Step 2028: train/loss = 0.3819219470024109, train/raw-loss = 0.3081660270690918, train/logprobs = tensor([[-0.7011, -3.9980],
        [-1.4803, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10536559671163559
Epoch 0, Step 2029: train/loss = 0.5925212502479553, train/raw-loss = 0.5183066725730896, train/logprobs = tensor([[-0.5978, -1.1611],
        [-0.8463, -0.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10602085292339325
Epoch 0, Step 2030: train/loss = 0.3478392958641052, train/raw-loss = 0.258666455745697, train/logprobs = tensor([[-0.4727, -4.9878],
        [-1.4027, -0.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273898035287857
Epoch 0, Step 2031: train/loss = 0.6943907141685486, train/raw-loss = 0.6308965682983398, train/logprobs = tensor([[-0.4724, -0.6859],
        [-0.6710, -0.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09070591628551483
Epoch 0, Step 2032: train/loss = 0.3770782947540283, train/raw-loss = 0.30631059408187866, train/logprobs = tensor([[-1.0516, -4.1488],
        [-1.6099, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10109668225049973
Epoch 0, Step 2033: train/loss = 0.7762109041213989, train/raw-loss = 0.7171683311462402, train/logprobs = tensor([[-1.1994, -1.2324],
        [-0.6388, -0.3974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08434661477804184
Epoch 0, Step 2034: train/loss = 0.49121060967445374, train/raw-loss = 0.4203914999961853, train/logprobs = tensor([[-0.5541, -2.8254],
        [-0.9800, -0.7296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10117020457983017
Epoch 0, Step 2035: train/loss = 0.4548410475254059, train/raw-loss = 0.38981613516807556, train/logprobs = tensor([[-0.9420, -3.7269],
        [-1.3160, -0.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09289277344942093
Epoch 0, Step 2036: train/loss = 0.2915656566619873, train/raw-loss = 0.1954760104417801, train/logprobs = tensor([[-0.7020, -9.1356],
        [-1.5854, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1372709572315216
Epoch 0, Step 2037: train/loss = 0.33139485120773315, train/raw-loss = 0.25154924392700195, train/logprobs = tensor([[-0.6176, -6.2722],
        [-1.0742, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11406516283750534
Epoch 0, Step 2038: train/loss = 0.4479708671569824, train/raw-loss = 0.3431721329689026, train/logprobs = tensor([[-0.7718, -4.3809],
        [-1.3957, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14971253275871277
Epoch 0, Step 2039: train/loss = 0.4127994179725647, train/raw-loss = 0.33916693925857544, train/logprobs = tensor([[-0.7515, -3.3931],
        [-1.2845, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1051892638206482
Epoch 0, Step 2040: train/loss = 0.4686419367790222, train/raw-loss = 0.4013148248195648, train/logprobs = tensor([[-0.9217, -3.8603],
        [-1.1198, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09618153423070908
Epoch 0, Step 2041: train/loss = 0.31142863631248474, train/raw-loss = 0.23599275946617126, train/logprobs = tensor([[-0.4401, -6.5589],
        [-1.8859, -1.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776554048061371
Epoch 0, Step 2042: train/loss = 0.33195123076438904, train/raw-loss = 0.24366195499897003, train/logprobs = tensor([[-0.5703, -6.2204],
        [-1.4248, -1.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12612751126289368
Epoch 0, Step 2043: train/loss = 0.4770869314670563, train/raw-loss = 0.40011245012283325, train/logprobs = tensor([[-0.7323, -7.5909],
        [-1.3945, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099635437130928
Epoch 0, Step 2044: train/loss = 0.6050336956977844, train/raw-loss = 0.49430418014526367, train/logprobs = tensor([[-2.0068, -3.3334],
        [-2.9748, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15818503499031067
Epoch 0, Step 2045: train/loss = 0.5670554637908936, train/raw-loss = 0.49903616309165955, train/logprobs = tensor([[-0.5452, -1.3003],
        [-0.9750, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09717045724391937
Epoch 0, Step 2046: train/loss = 0.2768968343734741, train/raw-loss = 0.21804553270339966, train/logprobs = tensor([[-0.3181, -7.8531],
        [-0.7032, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08407332003116608
Epoch 0, Step 2047: train/loss = 0.3858621418476105, train/raw-loss = 0.2879335284233093, train/logprobs = tensor([[-1.5174, -4.8500],
        [-2.4707, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13989800214767456
Epoch 0, Step 2048: train/loss = 0.3975168466567993, train/raw-loss = 0.3240257501602173, train/logprobs = tensor([[-0.6340, -5.6108],
        [-0.9165, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049872413277626
Epoch 0, Step 2049: train/loss = 0.39459219574928284, train/raw-loss = 0.3042820394039154, train/logprobs = tensor([[-1.0820, -3.8542],
        [-1.8063, -0.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1290145069360733
Epoch 0, Step 2050: train/loss = 0.2715039849281311, train/raw-loss = 0.16750618815422058, train/logprobs = tensor([[-0.5796, -4.4117],
        [-1.6245, -1.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1485682725906372
Epoch 0, Step 2051: train/loss = 0.37575507164001465, train/raw-loss = 0.29363179206848145, train/logprobs = tensor([[-0.4702, -6.8397],
        [-1.2232, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11731896549463272
Epoch 0, Step 2052: train/loss = 0.45843350887298584, train/raw-loss = 0.34224602580070496, train/logprobs = tensor([[-0.8403, -2.2880],
        [-2.5023, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16598214209079742
Epoch 0, Step 2053: train/loss = 0.5198788642883301, train/raw-loss = 0.42786455154418945, train/logprobs = tensor([[-1.3379, -4.0109],
        [-1.0196, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13144901394844055
Epoch 0, Step 2054: train/loss = 0.5333275198936462, train/raw-loss = 0.4529377222061157, train/logprobs = tensor([[-0.6885, -1.2664],
        [-1.5196, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11484256386756897
Epoch 0, Step 2055: train/loss = 0.4420664310455322, train/raw-loss = 0.3782666027545929, train/logprobs = tensor([[-0.9209, -4.0496],
        [-0.9788, -0.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09114265441894531
Epoch 0, Step 2056: train/loss = 0.41238391399383545, train/raw-loss = 0.33927059173583984, train/logprobs = tensor([[-0.7401, -1.7957],
        [-2.2853, -0.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10444760322570801
Epoch 0, Step 2057: train/loss = 0.5389355421066284, train/raw-loss = 0.4488028585910797, train/logprobs = tensor([[-0.5006, -1.7301],
        [-1.4387, -0.6383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12876103818416595
Epoch 0, Step 2058: train/loss = 0.2731715440750122, train/raw-loss = 0.16540919244289398, train/logprobs = tensor([[-0.6645, -6.2451],
        [-2.2570, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15394625067710876
Epoch 0, Step 2059: train/loss = 0.3448832035064697, train/raw-loss = 0.24921442568302155, train/logprobs = tensor([[-0.5509, -7.4412],
        [-1.6527, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13666968047618866
Epoch 0, Step 2060: train/loss = 0.4406201243400574, train/raw-loss = 0.3526308536529541, train/logprobs = tensor([[-0.9213, -3.0541],
        [-1.3548, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12569895386695862
Epoch 0, Step 2061: train/loss = 0.3531743288040161, train/raw-loss = 0.2653874456882477, train/logprobs = tensor([[-0.6693, -5.7096],
        [-1.8444, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254098266363144
Epoch 0, Step 2062: train/loss = 0.3929833769798279, train/raw-loss = 0.28095126152038574, train/logprobs = tensor([[-0.8366, -3.4529],
        [-1.6760, -0.6420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16004589200019836
Epoch 0, Step 2063: train/loss = 0.47705328464508057, train/raw-loss = 0.3899972438812256, train/logprobs = tensor([[-0.5622, -2.5390],
        [-1.6993, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12436576187610626
Epoch 0, Step 2064: train/loss = 0.543373703956604, train/raw-loss = 0.4445686340332031, train/logprobs = tensor([[-1.2723, -3.0291],
        [-1.5652, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14115016162395477
Epoch 0, Step 2065: train/loss = 0.3050246238708496, train/raw-loss = 0.2220495194196701, train/logprobs = tensor([[-0.6733, -8.7822],
        [-1.4220, -1.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185358390212059
Epoch 0, Step 2066: train/loss = 0.43734636902809143, train/raw-loss = 0.3488639295101166, train/logprobs = tensor([[-0.6696, -4.3317],
        [-1.2304, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12640348076820374
Epoch 0, Step 2067: train/loss = 0.5172871947288513, train/raw-loss = 0.43115749955177307, train/logprobs = tensor([[-0.9801, -4.1421],
        [-1.3687, -1.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12304238975048065
Epoch 0, Step 2068: train/loss = 0.6201218962669373, train/raw-loss = 0.5321115255355835, train/logprobs = tensor([[-0.7745, -3.2389],
        [-1.3623, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12572908401489258
Epoch 0, Step 2069: train/loss = 0.49445289373397827, train/raw-loss = 0.41220808029174805, train/logprobs = tensor([[-0.5937, -2.8745],
        [-1.3261, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11749253422021866
Epoch 0, Step 2070: train/loss = 0.24042116105556488, train/raw-loss = 0.14766375720500946, train/logprobs = tensor([[-0.8221, -8.1038],
        [-2.4789, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13251060247421265
Epoch 0, Step 2071: train/loss = 0.5008173584938049, train/raw-loss = 0.41550225019454956, train/logprobs = tensor([[-0.7881, -2.9937],
        [-1.1246, -0.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12187870591878891
Epoch 0, Step 2072: train/loss = 0.3316311836242676, train/raw-loss = 0.23410676419734955, train/logprobs = tensor([[-0.6498, -5.3675],
        [-1.5253, -0.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13932058215141296
Epoch 0, Step 2073: train/loss = 0.4031165838241577, train/raw-loss = 0.30592602491378784, train/logprobs = tensor([[-0.7698, -3.7012],
        [-1.4595, -1.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13884364068508148
Epoch 0, Step 2074: train/loss = 0.508670449256897, train/raw-loss = 0.43134114146232605, train/logprobs = tensor([[-0.5629, -2.1979],
        [-1.3108, -1.0937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11047053337097168
Epoch 0, Step 2075: train/loss = 0.5724114775657654, train/raw-loss = 0.4838930666446686, train/logprobs = tensor([[-0.7814, -2.0574],
        [-1.2885, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264549046754837
Epoch 0, Step 2076: train/loss = 0.40677785873413086, train/raw-loss = 0.3270896375179291, train/logprobs = tensor([[-1.3563, -7.1353],
        [-1.5878, -1.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11384034156799316
Epoch 0, Step 2077: train/loss = 0.36564937233924866, train/raw-loss = 0.2792016565799713, train/logprobs = tensor([[-0.6063, -5.4303],
        [-1.2294, -0.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12349674105644226
Epoch 0, Step 2078: train/loss = 0.34164538979530334, train/raw-loss = 0.25458040833473206, train/logprobs = tensor([[-0.7512, -3.8158],
        [-1.7324, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12437855452299118
Epoch 0, Step 2079: train/loss = 0.43176424503326416, train/raw-loss = 0.3495066463947296, train/logprobs = tensor([[-0.5431, -4.4808],
        [-1.0018, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11751088500022888
Epoch 0, Step 2080: train/loss = 0.3009268641471863, train/raw-loss = 0.21804849803447723, train/logprobs = tensor([[-0.8076, -5.3925],
        [-1.8625, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11839765310287476
Epoch 0, Step 2081: train/loss = 0.3656047284603119, train/raw-loss = 0.27034053206443787, train/logprobs = tensor([[-0.8080, -2.6094],
        [-2.2246, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1360917091369629
Epoch 0, Step 2082: train/loss = 0.3208632469177246, train/raw-loss = 0.2334394007921219, train/logprobs = tensor([[-0.6529, -9.7925],
        [-1.5534, -1.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248912513256073
Epoch 0, Step 2083: train/loss = 0.49076607823371887, train/raw-loss = 0.41018134355545044, train/logprobs = tensor([[-0.7866, -2.0022],
        [-1.4392, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.115121029317379
Epoch 0, Step 2084: train/loss = 0.279712051153183, train/raw-loss = 0.19669435918331146, train/logprobs = tensor([[-0.6708, -6.6353],
        [-2.3691, -0.7584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11859671771526337
Epoch 0, Step 2085: train/loss = 0.4669666290283203, train/raw-loss = 0.41608309745788574, train/logprobs = tensor([[-0.7492, -2.9042],
        [-1.1071, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07269078493118286
Epoch 0, Step 2086: train/loss = 0.4318108558654785, train/raw-loss = 0.3609526455402374, train/logprobs = tensor([[-0.4068, -3.0750],
        [-0.8383, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10122602432966232
Epoch 0, Step 2087: train/loss = 0.2045493721961975, train/raw-loss = 0.11123614758253098, train/logprobs = tensor([[ -0.8311, -12.7859],
        [ -2.1922,  -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13330459594726562
Epoch 0, Step 2088: train/loss = 0.43984726071357727, train/raw-loss = 0.3636122941970825, train/logprobs = tensor([[-0.3942, -7.1091],
        [-1.4701, -1.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10890710353851318
Epoch 0, Step 2089: train/loss = 0.6066346168518066, train/raw-loss = 0.52619469165802, train/logprobs = tensor([[-1.1720, -2.6215],
        [-1.0339, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11491411179304123
Epoch 0, Step 2090: train/loss = 0.5639089941978455, train/raw-loss = 0.49340811371803284, train/logprobs = tensor([[-1.2691, -2.5673],
        [-1.2316, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1007155328989029
Epoch 0, Step 2091: train/loss = 0.4306612014770508, train/raw-loss = 0.36127251386642456, train/logprobs = tensor([[-0.6407, -3.1208],
        [-0.9324, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09912668913602829
Epoch 0, Step 2092: train/loss = 0.2517847716808319, train/raw-loss = 0.15343502163887024, train/logprobs = tensor([[-0.5753, -6.0806],
        [-1.6696, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14049965143203735
Epoch 0, Step 2093: train/loss = 0.5802137851715088, train/raw-loss = 0.4942115247249603, train/logprobs = tensor([[-1.8306, -4.4660],
        [-1.6105, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1228603795170784
Epoch 0, Step 2094: train/loss = 0.31922781467437744, train/raw-loss = 0.2339613437652588, train/logprobs = tensor([[-0.4416, -7.4287],
        [-1.5031, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121809221804142
Epoch 0, Step 2095: train/loss = 0.5243430137634277, train/raw-loss = 0.4298177659511566, train/logprobs = tensor([[-0.6642, -3.9012],
        [-1.5937, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13503600656986237
Epoch 0, Step 2096: train/loss = 0.49853402376174927, train/raw-loss = 0.4206978380680084, train/logprobs = tensor([[-1.1188, -6.3197],
        [-1.4182, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119458824396133
Epoch 0, Step 2097: train/loss = 0.49818670749664307, train/raw-loss = 0.4063469469547272, train/logprobs = tensor([[-0.5716, -4.0658],
        [-1.3145, -1.2416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13119961321353912
Epoch 0, Step 2098: train/loss = 0.224676713347435, train/raw-loss = 0.11931062489748001, train/logprobs = tensor([[-0.6234, -5.8998],
        [-1.9814, -1.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15052300691604614
Epoch 0, Step 2099: train/loss = 0.3646482229232788, train/raw-loss = 0.2703563868999481, train/logprobs = tensor([[-0.6565, -5.8321],
        [-1.0843, -0.5912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347026377916336
Epoch 0, Step 2100: train/loss = 0.5707840919494629, train/raw-loss = 0.47724780440330505, train/logprobs = tensor([[-0.6152, -1.4322],
        [-1.1927, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13362331688404083
Epoch 0, Step 2101: train/loss = 0.5319889783859253, train/raw-loss = 0.4466182589530945, train/logprobs = tensor([[-0.6588, -2.7497],
        [-1.3198, -1.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1219581812620163
Epoch 0, Step 2102: train/loss = 0.3971075117588043, train/raw-loss = 0.32490283250808716, train/logprobs = tensor([[-0.8744, -5.8975],
        [-1.0833, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314954817295074
Epoch 0, Step 2103: train/loss = 0.3936803638935089, train/raw-loss = 0.3054233193397522, train/logprobs = tensor([[-0.6508, -5.4942],
        [-1.2638, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12608151137828827
Epoch 0, Step 2104: train/loss = 0.45588159561157227, train/raw-loss = 0.3761444389820099, train/logprobs = tensor([[-0.5707, -1.9302],
        [-1.4154, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391019076108932
Epoch 0, Step 2105: train/loss = 0.4985812306404114, train/raw-loss = 0.3962888717651367, train/logprobs = tensor([[-0.7315, -3.1973],
        [-1.5306, -1.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14613185822963715
Epoch 0, Step 2106: train/loss = 0.5639002323150635, train/raw-loss = 0.47828301787376404, train/logprobs = tensor([[-0.4956, -1.8834],
        [-0.9144, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12231026589870453
Epoch 0, Step 2107: train/loss = 0.4330788850784302, train/raw-loss = 0.36629146337509155, train/logprobs = tensor([[-1.0302, -2.4266],
        [-1.5261, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541056305170059
Epoch 0, Step 2108: train/loss = 0.34043726325035095, train/raw-loss = 0.26955512166023254, train/logprobs = tensor([[-0.6234, -6.5942],
        [-1.3558, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012602224946022
Epoch 0, Step 2109: train/loss = 0.4252321422100067, train/raw-loss = 0.3574131429195404, train/logprobs = tensor([[ -0.4882, -11.3063],
        [ -1.0612,  -1.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09688432514667511
Epoch 0, Step 2110: train/loss = 0.49901342391967773, train/raw-loss = 0.4289226531982422, train/logprobs = tensor([[-1.1343, -3.3039],
        [-1.5969, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012973099946976
Epoch 0, Step 2111: train/loss = 0.3934698700904846, train/raw-loss = 0.2776511013507843, train/logprobs = tensor([[-0.6687, -3.4277],
        [-1.8531, -1.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654554009437561
Epoch 0, Step 2112: train/loss = 0.33370110392570496, train/raw-loss = 0.251211553812027, train/logprobs = tensor([[-0.5689, -4.3652],
        [-1.6947, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11784223467111588
Epoch 0, Step 2113: train/loss = 0.4270055294036865, train/raw-loss = 0.328529953956604, train/logprobs = tensor([[-0.6328, -7.8919],
        [-1.9988, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14067944884300232
Epoch 0, Step 2114: train/loss = 0.29055628180503845, train/raw-loss = 0.20091834664344788, train/logprobs = tensor([[-0.6282, -7.1295],
        [-1.2038, -1.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280541568994522
Epoch 0, Step 2115: train/loss = 0.2073715329170227, train/raw-loss = 0.11732502281665802, train/logprobs = tensor([[-0.6546, -8.5913],
        [-2.1067, -1.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286378800868988
Epoch 0, Step 2116: train/loss = 0.31147509813308716, train/raw-loss = 0.21009258925914764, train/logprobs = tensor([[-1.0463, -6.3210],
        [-2.4060, -1.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14483214914798737
Epoch 0, Step 2117: train/loss = 0.5597596764564514, train/raw-loss = 0.49119916558265686, train/logprobs = tensor([[-0.3848, -4.6627],
        [-0.9679, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09794362634420395
Epoch 0, Step 2118: train/loss = 0.41750046610832214, train/raw-loss = 0.3241923451423645, train/logprobs = tensor([[-0.6214, -6.7529],
        [-1.1551, -1.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329733908176422
Epoch 0, Step 2119: train/loss = 0.319474458694458, train/raw-loss = 0.23019041121006012, train/logprobs = tensor([[-0.6673, -3.5486],
        [-1.6832, -0.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12754863500595093
Epoch 0, Step 2120: train/loss = 0.8288073539733887, train/raw-loss = 0.7475423812866211, train/logprobs = tensor([[-2.0939, -2.1688],
        [-1.3894, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11609280109405518
Epoch 0, Step 2121: train/loss = 0.662861704826355, train/raw-loss = 0.5768898129463196, train/logprobs = tensor([[-1.5216, -4.2054],
        [-1.1545, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12281695753335953
Epoch 0, Step 2122: train/loss = 0.3498395085334778, train/raw-loss = 0.27090325951576233, train/logprobs = tensor([[-0.9232, -4.6129],
        [-1.5405, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1127660796046257
Epoch 0, Step 2123: train/loss = 0.45647841691970825, train/raw-loss = 0.3720775246620178, train/logprobs = tensor([[-1.2223, -5.2765],
        [-1.6279, -1.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12057263404130936
Epoch 0, Step 2124: train/loss = 0.3316195011138916, train/raw-loss = 0.23518989980220795, train/logprobs = tensor([[-0.8291, -4.3869],
        [-1.8844, -0.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13775652647018433
Epoch 0, Step 2125: train/loss = 0.35316070914268494, train/raw-loss = 0.27059513330459595, train/logprobs = tensor([[-0.6504, -3.2060],
        [-1.2257, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11795082688331604
Epoch 0, Step 2126: train/loss = 0.4431507885456085, train/raw-loss = 0.36627569794654846, train/logprobs = tensor([[-0.4907, -2.5969],
        [-1.6794, -0.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10982152819633484
Epoch 0, Step 2127: train/loss = 0.2834704518318176, train/raw-loss = 0.1897905021905899, train/logprobs = tensor([[-1.6783, -8.3153],
        [-2.6687, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13382850587368011
Epoch 0, Step 2128: train/loss = 0.3516911268234253, train/raw-loss = 0.2704925537109375, train/logprobs = tensor([[-0.8663, -5.1351],
        [-1.7038, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11599794030189514
Epoch 0, Step 2129: train/loss = 0.40102025866508484, train/raw-loss = 0.32083553075790405, train/logprobs = tensor([[-0.4004, -4.9446],
        [-1.0750, -1.2175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11454960703849792
Epoch 0, Step 2130: train/loss = 0.42852580547332764, train/raw-loss = 0.34283894300460815, train/logprobs = tensor([[-0.8457, -2.8936],
        [-1.4905, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12240983545780182
Epoch 0, Step 2131: train/loss = 0.39623385667800903, train/raw-loss = 0.30280399322509766, train/logprobs = tensor([[-0.7093, -3.0910],
        [-1.3598, -0.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13347125053405762
Epoch 0, Step 2132: train/loss = 0.397441565990448, train/raw-loss = 0.3144075274467468, train/logprobs = tensor([[-1.0892, -5.9738],
        [-1.6747, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11862008273601532
Epoch 0, Step 2133: train/loss = 0.4255266487598419, train/raw-loss = 0.3512495756149292, train/logprobs = tensor([[-0.6674, -4.3399],
        [-1.0029, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1061100959777832
Epoch 0, Step 2134: train/loss = 0.5255621075630188, train/raw-loss = 0.4065747857093811, train/logprobs = tensor([[-1.4653, -5.6293],
        [-1.7217, -0.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16998191177845
Epoch 0, Step 2135: train/loss = 0.41138672828674316, train/raw-loss = 0.3316301703453064, train/logprobs = tensor([[-0.3571, -5.1444],
        [-1.6869, -0.9882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11393795907497406
Epoch 0, Step 2136: train/loss = 0.3626468777656555, train/raw-loss = 0.2602955102920532, train/logprobs = tensor([[-0.6168, -4.7847],
        [-1.4946, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1462162435054779
Epoch 0, Step 2137: train/loss = 0.4107760787010193, train/raw-loss = 0.3089677393436432, train/logprobs = tensor([[-0.7599, -4.0586],
        [-1.4461, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14544051885604858
Epoch 0, Step 2138: train/loss = 0.21263422071933746, train/raw-loss = 0.1263013482093811, train/logprobs = tensor([[-0.9513, -6.8438],
        [-2.9495, -1.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1233326643705368
Epoch 0, Step 2139: train/loss = 0.3493283689022064, train/raw-loss = 0.2590908706188202, train/logprobs = tensor([[-0.6334, -5.2613],
        [-1.7938, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12891066074371338
Epoch 0, Step 2140: train/loss = 0.4309057295322418, train/raw-loss = 0.36792606115341187, train/logprobs = tensor([[-0.7367, -3.6177],
        [-1.1226, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08997095376253128
Epoch 0, Step 2141: train/loss = 1.0928775072097778, train/raw-loss = 1.011671543121338, train/logprobs = tensor([[-3.7628, -5.1056],
        [-1.6494, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11600863188505173
Epoch 0, Step 2142: train/loss = 0.26342782378196716, train/raw-loss = 0.16005825996398926, train/logprobs = tensor([[-0.6472, -5.4756],
        [-2.2863, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14767079055309296
Epoch 0, Step 2143: train/loss = 0.445670485496521, train/raw-loss = 0.3627006709575653, train/logprobs = tensor([[-0.6245, -3.7604],
        [-1.0410, -0.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185283213853836
Epoch 0, Step 2144: train/loss = 0.5215010643005371, train/raw-loss = 0.4300210475921631, train/logprobs = tensor([[-0.9282, -2.3889],
        [-1.1475, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306857466697693
Epoch 0, Step 2145: train/loss = 0.4747067093849182, train/raw-loss = 0.4027960002422333, train/logprobs = tensor([[-0.4327, -2.1640],
        [-0.8342, -0.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10272958129644394
Epoch 0, Step 2146: train/loss = 0.3952378034591675, train/raw-loss = 0.3130398690700531, train/logprobs = tensor([[-0.8502, -2.7585],
        [-1.4128, -0.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11742564290761948
Epoch 0, Step 2147: train/loss = 0.33354830741882324, train/raw-loss = 0.2504097819328308, train/logprobs = tensor([[-1.2502, -4.4622],
        [-1.9796, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11876925081014633
Epoch 0, Step 2148: train/loss = 0.1779700368642807, train/raw-loss = 0.09540185332298279, train/logprobs = tensor([[-0.6416, -6.1170],
        [-2.3712, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1179545521736145
Epoch 0, Step 2149: train/loss = 0.5076543092727661, train/raw-loss = 0.4286229610443115, train/logprobs = tensor([[-0.6586, -5.0043],
        [-1.2175, -1.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11290188878774643
Epoch 0, Step 2150: train/loss = 0.6484276056289673, train/raw-loss = 0.5680136680603027, train/logprobs = tensor([[-2.0898, -4.0014],
        [-1.8370, -0.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11487709730863571
Epoch 0, Step 2151: train/loss = 0.5014864206314087, train/raw-loss = 0.4491005539894104, train/logprobs = tensor([[-1.2030, -6.9128],
        [-1.4139, -1.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07483700662851334
Epoch 0, Step 2152: train/loss = 0.5181401968002319, train/raw-loss = 0.4551848769187927, train/logprobs = tensor([[-0.4787, -2.9648],
        [-0.6527, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08993618190288544
Epoch 0, Step 2153: train/loss = 0.40411093831062317, train/raw-loss = 0.26384416222572327, train/logprobs = tensor([[-0.8476, -3.9419],
        [-2.4091, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2003811001777649
Epoch 0, Step 2154: train/loss = 0.33570897579193115, train/raw-loss = 0.24818825721740723, train/logprobs = tensor([[-0.9983, -4.5826],
        [-1.8741, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12502959370613098
Epoch 0, Step 2155: train/loss = 0.29181498289108276, train/raw-loss = 0.21240895986557007, train/logprobs = tensor([[-0.5247, -9.7713],
        [-1.6868, -1.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11343715339899063
Epoch 0, Step 2156: train/loss = 0.5329803824424744, train/raw-loss = 0.4571879804134369, train/logprobs = tensor([[-0.5128, -4.3289],
        [-1.1186, -1.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10827489197254181
Epoch 0, Step 2157: train/loss = 0.21608591079711914, train/raw-loss = 0.10923828184604645, train/logprobs = tensor([[-1.0677, -5.9330],
        [-2.8168, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526394635438919
Epoch 0, Step 2158: train/loss = 0.6011261343955994, train/raw-loss = 0.5019012093544006, train/logprobs = tensor([[-0.9020, -5.4239],
        [-2.0112, -1.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14174985885620117
Epoch 0, Step 2159: train/loss = 0.8458057641983032, train/raw-loss = 0.7342498302459717, train/logprobs = tensor([[-2.5124, -6.9273],
        [-2.7868, -1.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15936562418937683
Epoch 0, Step 2160: train/loss = 0.3721030056476593, train/raw-loss = 0.2702164053916931, train/logprobs = tensor([[-0.3924, -4.8110],
        [-1.5902, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14555230736732483
Epoch 0, Step 2161: train/loss = 0.34465083479881287, train/raw-loss = 0.24834050238132477, train/logprobs = tensor([[-1.5028, -5.6770],
        [-2.0531, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13758619129657745
Epoch 0, Step 2162: train/loss = 0.44167500734329224, train/raw-loss = 0.3454326093196869, train/logprobs = tensor([[-0.6866, -3.3518],
        [-2.0102, -0.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374891847372055
Epoch 0, Step 2163: train/loss = 0.4607720673084259, train/raw-loss = 0.3614750802516937, train/logprobs = tensor([[-0.6116, -3.0503],
        [-1.3477, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14185284078121185
Epoch 0, Step 2164: train/loss = 0.2928730547428131, train/raw-loss = 0.2198774218559265, train/logprobs = tensor([[-0.4762, -8.7791],
        [-1.8650, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1042795181274414
Epoch 0, Step 2165: train/loss = 0.5442721843719482, train/raw-loss = 0.46466705203056335, train/logprobs = tensor([[-0.3846, -1.7026],
        [-1.0717, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11372160166501999
Epoch 0, Step 2166: train/loss = 0.4702494144439697, train/raw-loss = 0.39265960454940796, train/logprobs = tensor([[-0.6631, -7.4691],
        [-1.0177, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11084260791540146
Epoch 0, Step 2167: train/loss = 0.594931423664093, train/raw-loss = 0.5172005891799927, train/logprobs = tensor([[-0.4113, -0.8432],
        [-1.4256, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104405671358109
Epoch 0, Step 2168: train/loss = 0.3930375576019287, train/raw-loss = 0.3202347457408905, train/logprobs = tensor([[-0.8196, -5.4024],
        [-1.0111, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10400406271219254
Epoch 0, Step 2169: train/loss = 0.5795429348945618, train/raw-loss = 0.5070659518241882, train/logprobs = tensor([[-0.5314, -1.7573],
        [-1.7147, -0.9249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10353852808475494
Epoch 0, Step 2170: train/loss = 0.30753999948501587, train/raw-loss = 0.20541398227214813, train/logprobs = tensor([[-1.1547, -6.8013],
        [-2.4037, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14589431881904602
Epoch 0, Step 2171: train/loss = 0.5883059501647949, train/raw-loss = 0.507775604724884, train/logprobs = tensor([[-1.1017, -3.3514],
        [-0.7049, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504341661930084
Epoch 0, Step 2172: train/loss = 0.60462486743927, train/raw-loss = 0.5410836935043335, train/logprobs = tensor([[-0.6982, -2.2071],
        [-0.8386, -0.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09077306091785431
Epoch 0, Step 2173: train/loss = 0.5110694169998169, train/raw-loss = 0.4410935640335083, train/logprobs = tensor([[-0.7193, -4.3554],
        [-0.9460, -1.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09996555000543594
Epoch 0, Step 2174: train/loss = 0.4676761329174042, train/raw-loss = 0.3885716497898102, train/logprobs = tensor([[-0.4624, -2.4676],
        [-1.0689, -0.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11300644278526306
Epoch 0, Step 2175: train/loss = 0.3268914222717285, train/raw-loss = 0.24825835227966309, train/logprobs = tensor([[-0.5345, -6.0245],
        [-1.7238, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11233293265104294
Epoch 0, Step 2176: train/loss = 0.5062435865402222, train/raw-loss = 0.4414319694042206, train/logprobs = tensor([[-1.9581, -7.1723],
        [-1.7785, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09258801490068436
Epoch 0, Step 2177: train/loss = 0.43662571907043457, train/raw-loss = 0.35111573338508606, train/logprobs = tensor([[-1.0613, -5.3180],
        [-1.5158, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12215715646743774
Epoch 0, Step 2178: train/loss = 0.3860182762145996, train/raw-loss = 0.30055534839630127, train/logprobs = tensor([[-0.8389, -6.5421],
        [-1.2272, -1.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1220899447798729
Epoch 0, Step 2179: train/loss = 0.47208309173583984, train/raw-loss = 0.39673203229904175, train/logprobs = tensor([[-0.7155, -2.4987],
        [-1.2120, -0.6707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764437168836594
Epoch 0, Step 2180: train/loss = 0.49418383836746216, train/raw-loss = 0.4169262945652008, train/logprobs = tensor([[-0.3789, -3.8097],
        [-0.8029, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11036790907382965
Epoch 0, Step 2181: train/loss = 0.29024624824523926, train/raw-loss = 0.17682452499866486, train/logprobs = tensor([[-0.6189, -5.3444],
        [-1.8465, -1.5153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16203099489212036
Epoch 0, Step 2182: train/loss = 0.580475926399231, train/raw-loss = 0.5151494741439819, train/logprobs = tensor([[-0.8700, -3.0960],
        [-0.7354, -0.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09332355111837387
Epoch 0, Step 2183: train/loss = 0.25872933864593506, train/raw-loss = 0.16090966761112213, train/logprobs = tensor([[-0.7610, -5.3423],
        [-2.0551, -0.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397424042224884
Epoch 0, Step 2184: train/loss = 0.7966954112052917, train/raw-loss = 0.7122437357902527, train/logprobs = tensor([[-0.5442, -0.6632],
        [-2.1131, -1.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1206451952457428
Epoch 0, Step 2185: train/loss = 0.5257142186164856, train/raw-loss = 0.42123815417289734, train/logprobs = tensor([[-0.8730, -3.0587],
        [-1.5731, -1.8076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14925147593021393
Epoch 0, Step 2186: train/loss = 0.38027894496917725, train/raw-loss = 0.3068893551826477, train/logprobs = tensor([[-0.6665, -5.0273],
        [-1.1908, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484233498573303
Epoch 0, Step 2187: train/loss = 0.5411757230758667, train/raw-loss = 0.44102728366851807, train/logprobs = tensor([[-0.8439, -2.1319],
        [-2.4448, -1.4065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14306922256946564
Epoch 0, Step 2188: train/loss = 0.32489481568336487, train/raw-loss = 0.21328957378864288, train/logprobs = tensor([[-0.6357, -5.1691],
        [-2.1855, -1.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15943606197834015
Epoch 0, Step 2189: train/loss = 0.5540379285812378, train/raw-loss = 0.4936327338218689, train/logprobs = tensor([[-0.6076, -2.3660],
        [-0.9073, -0.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08629310876131058
Epoch 0, Step 2190: train/loss = 0.22211071848869324, train/raw-loss = 0.14671283960342407, train/logprobs = tensor([[ -1.0260, -12.3689],
        [ -2.1997,  -1.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771126300096512
Epoch 0, Step 2191: train/loss = 0.5412212610244751, train/raw-loss = 0.46338626742362976, train/logprobs = tensor([[-0.6580, -1.6433],
        [-1.1997, -0.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119291186332703
Epoch 0, Step 2192: train/loss = 0.2709319591522217, train/raw-loss = 0.14901450276374817, train/logprobs = tensor([[-0.9941, -4.6490],
        [-2.5894, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17416781187057495
Epoch 0, Step 2193: train/loss = 0.48729079961776733, train/raw-loss = 0.3976173996925354, train/logprobs = tensor([[-0.4415, -3.5863],
        [-1.1729, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281048208475113
Epoch 0, Step 2194: train/loss = 0.4521344006061554, train/raw-loss = 0.38425710797309875, train/logprobs = tensor([[-0.8366, -5.6296],
        [-1.2238, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09696753323078156
Epoch 0, Step 2195: train/loss = 0.32741624116897583, train/raw-loss = 0.2449583262205124, train/logprobs = tensor([[-0.6350, -7.2870],
        [-1.5153, -1.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11779697984457016
Epoch 0, Step 2196: train/loss = 0.6836405992507935, train/raw-loss = 0.6129253506660461, train/logprobs = tensor([[-0.8228, -0.8998],
        [-0.9515, -0.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102188587188721
Epoch 0, Step 2197: train/loss = 0.2951293885707855, train/raw-loss = 0.19734922051429749, train/logprobs = tensor([[-0.8268, -6.9010],
        [-1.4795, -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13968594372272491
Epoch 0, Step 2198: train/loss = 0.5244888663291931, train/raw-loss = 0.4478958249092102, train/logprobs = tensor([[-1.9007, -7.6931],
        [-1.5144, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10941869020462036
Epoch 0, Step 2199: train/loss = 0.6173373460769653, train/raw-loss = 0.5486741065979004, train/logprobs = tensor([[-0.5225, -0.9423],
        [-0.9173, -0.6190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980902686715126
Epoch 0, Step 2200: train/loss = 0.4467600882053375, train/raw-loss = 0.3629251718521118, train/logprobs = tensor([[-0.5156, -3.1397],
        [-1.4249, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11976416409015656
Epoch 0, Step 2201: train/loss = 0.598466157913208, train/raw-loss = 0.531036913394928, train/logprobs = tensor([[-0.5387, -1.1572],
        [-0.6675, -0.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632748365402222
Epoch 0, Step 2202: train/loss = 0.579921543598175, train/raw-loss = 0.4953375458717346, train/logprobs = tensor([[-0.9565, -1.2835],
        [-1.4514, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12083429843187332
Epoch 0, Step 2203: train/loss = 0.3806265592575073, train/raw-loss = 0.26410776376724243, train/logprobs = tensor([[-0.8959, -5.4075],
        [-2.1552, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16645538806915283
Epoch 0, Step 2204: train/loss = 0.3772696256637573, train/raw-loss = 0.30315837264060974, train/logprobs = tensor([[-0.7356, -4.1329],
        [-1.3371, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058732345700264
Epoch 0, Step 2205: train/loss = 0.3347584009170532, train/raw-loss = 0.2541370093822479, train/logprobs = tensor([[-0.5225, -5.8120],
        [-1.7377, -1.3140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11517342180013657
Epoch 0, Step 2206: train/loss = 0.5833880305290222, train/raw-loss = 0.5078895092010498, train/logprobs = tensor([[-0.9759, -2.2868],
        [-0.9869, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10785505175590515
Epoch 0, Step 2207: train/loss = 0.26037925481796265, train/raw-loss = 0.17292585968971252, train/logprobs = tensor([[-0.7015, -4.6809],
        [-1.6430, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12493345141410828
Epoch 0, Step 2208: train/loss = 0.5157938003540039, train/raw-loss = 0.4299532175064087, train/logprobs = tensor([[-0.7321, -3.5799],
        [-1.3910, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12262938916683197
Epoch 0, Step 2209: train/loss = 0.2839129865169525, train/raw-loss = 0.18290358781814575, train/logprobs = tensor([[-0.8504, -6.3280],
        [-2.1491, -1.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14429913461208344
Epoch 0, Step 2210: train/loss = 0.43590039014816284, train/raw-loss = 0.3548944294452667, train/logprobs = tensor([[-0.9893, -3.9322],
        [-2.4685, -1.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11572284996509552
Epoch 0, Step 2211: train/loss = 0.5157927870750427, train/raw-loss = 0.39650505781173706, train/logprobs = tensor([[-0.5509, -5.0522],
        [-2.0577, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17041108012199402
Epoch 0, Step 2212: train/loss = 0.34158945083618164, train/raw-loss = 0.23106548190116882, train/logprobs = tensor([[-0.7645, -5.2591],
        [-1.9798, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15789136290550232
Epoch 0, Step 2213: train/loss = 0.2999761402606964, train/raw-loss = 0.2121799737215042, train/logprobs = tensor([[-0.8173, -6.0381],
        [-1.4321, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12542308866977692
Epoch 0, Step 2214: train/loss = 0.25579607486724854, train/raw-loss = 0.15717779099941254, train/logprobs = tensor([[-0.7591, -6.9129],
        [-2.4868, -1.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14088323712348938
Epoch 0, Step 2215: train/loss = 0.43473732471466064, train/raw-loss = 0.34032773971557617, train/logprobs = tensor([[-1.2382, -4.5082],
        [-1.2961, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13487085700035095
Epoch 0, Step 2216: train/loss = 0.31487399339675903, train/raw-loss = 0.2177751660346985, train/logprobs = tensor([[-1.0376, -4.0669],
        [-2.6535, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1387125700712204
Epoch 0, Step 2217: train/loss = 0.4759597182273865, train/raw-loss = 0.37789613008499146, train/logprobs = tensor([[-2.6473, -4.7731],
        [-3.8298, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14009082317352295
Epoch 0, Step 2218: train/loss = 0.4510520398616791, train/raw-loss = 0.37147361040115356, train/logprobs = tensor([[-0.6680, -4.5268],
        [-1.3580, -1.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11368347704410553
Epoch 0, Step 2219: train/loss = 0.41335996985435486, train/raw-loss = 0.35004085302352905, train/logprobs = tensor([[-0.9383, -7.8364],
        [-1.2817, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09045584499835968
Epoch 0, Step 2220: train/loss = 0.613840639591217, train/raw-loss = 0.5097098350524902, train/logprobs = tensor([[-0.9454, -3.7969],
        [-2.2713, -2.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14875823259353638
Epoch 0, Step 2221: train/loss = 0.5631786584854126, train/raw-loss = 0.4756172299385071, train/logprobs = tensor([[-1.7842, -8.1743],
        [-1.5104, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12508779764175415
Epoch 0, Step 2222: train/loss = 0.42111697793006897, train/raw-loss = 0.34387874603271484, train/logprobs = tensor([[-0.3722, -5.0213],
        [-1.0464, -0.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11034035682678223
Epoch 0, Step 2223: train/loss = 0.3246653974056244, train/raw-loss = 0.24666723608970642, train/logprobs = tensor([[-0.6774, -5.7534],
        [-2.1470, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11142590641975403
Epoch 0, Step 2224: train/loss = 0.24727410078048706, train/raw-loss = 0.15389999747276306, train/logprobs = tensor([[-0.6186, -7.5582],
        [-2.6907, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333916038274765
Epoch 0, Step 2225: train/loss = 0.5783093571662903, train/raw-loss = 0.5032232999801636, train/logprobs = tensor([[-1.2568, -2.9643],
        [-1.1441, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10726579278707504
Epoch 0, Step 2226: train/loss = 0.22655604779720306, train/raw-loss = 0.12667137384414673, train/logprobs = tensor([[-0.4664, -7.8510],
        [-1.9332, -1.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14269238710403442
Epoch 0, Step 2227: train/loss = 0.41054481267929077, train/raw-loss = 0.3146325945854187, train/logprobs = tensor([[-0.3951, -3.7640],
        [-1.4374, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13701744377613068
Epoch 0, Step 2228: train/loss = 0.3735845685005188, train/raw-loss = 0.2812635898590088, train/logprobs = tensor([[-0.5378, -4.9167],
        [-1.9225, -1.3402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13188707828521729
Epoch 0, Step 2229: train/loss = 0.45300671458244324, train/raw-loss = 0.37764209508895874, train/logprobs = tensor([[-0.5511, -3.9023],
        [-0.9644, -0.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10766376554965973
Epoch 0, Step 2230: train/loss = 0.37769606709480286, train/raw-loss = 0.29691389203071594, train/logprobs = tensor([[-0.8679, -3.6850],
        [-1.9386, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11540314555168152
Epoch 0, Step 2231: train/loss = 0.46784478425979614, train/raw-loss = 0.4015428423881531, train/logprobs = tensor([[-0.4450, -4.3442],
        [-0.8246, -1.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947171300649643
Epoch 0, Step 2232: train/loss = 0.4243278205394745, train/raw-loss = 0.30592837929725647, train/logprobs = tensor([[-0.7795, -3.3211],
        [-2.5036, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16914202272891998
Epoch 0, Step 2233: train/loss = 0.29601263999938965, train/raw-loss = 0.2269344925880432, train/logprobs = tensor([[-0.9255, -5.9262],
        [-1.3337, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868302941322327
Epoch 0, Step 2234: train/loss = 0.33983856439590454, train/raw-loss = 0.24646008014678955, train/logprobs = tensor([[-0.8257, -5.2570],
        [-1.6582, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13339778780937195
Epoch 0, Step 2235: train/loss = 0.6739953756332397, train/raw-loss = 0.5767971277236938, train/logprobs = tensor([[-1.6697, -3.6781],
        [-2.0597, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13885457813739777
Epoch 0, Step 2236: train/loss = 0.42499879002571106, train/raw-loss = 0.34171903133392334, train/logprobs = tensor([[-0.5316, -3.6967],
        [-1.1856, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11897113919258118
Epoch 0, Step 2237: train/loss = 0.5753281116485596, train/raw-loss = 0.5008406043052673, train/logprobs = tensor([[-1.2940, -2.5851],
        [-1.6267, -0.6001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10641075670719147
Epoch 0, Step 2238: train/loss = 0.3973005414009094, train/raw-loss = 0.29200249910354614, train/logprobs = tensor([[-1.0117, -4.5628],
        [-2.3094, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504257768392563
Epoch 0, Step 2239: train/loss = 0.4329199194908142, train/raw-loss = 0.34228700399398804, train/logprobs = tensor([[-0.6813, -6.1522],
        [-1.3817, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12947560846805573
Epoch 0, Step 2240: train/loss = 0.3325701355934143, train/raw-loss = 0.2504196763038635, train/logprobs = tensor([[-0.8072, -5.2795],
        [-1.4786, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11735780537128448
Epoch 0, Step 2241: train/loss = 0.38505876064300537, train/raw-loss = 0.3018953800201416, train/logprobs = tensor([[-0.8630, -2.5032],
        [-1.6296, -0.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11880484223365784
Epoch 0, Step 2242: train/loss = 0.5254724621772766, train/raw-loss = 0.4463951587677002, train/logprobs = tensor([[-0.7220, -3.7010],
        [-2.2818, -1.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11296753585338593
Epoch 0, Step 2243: train/loss = 0.46761736273765564, train/raw-loss = 0.3920423090457916, train/logprobs = tensor([[-0.4805, -3.5273],
        [-1.1034, -0.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10796437412500381
Epoch 0, Step 2244: train/loss = 0.29506999254226685, train/raw-loss = 0.20210321247577667, train/logprobs = tensor([[-0.8019, -7.4691],
        [-1.7477, -1.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13280969858169556
Epoch 0, Step 2245: train/loss = 0.468552827835083, train/raw-loss = 0.4075494408607483, train/logprobs = tensor([[-0.6594, -3.7788],
        [-1.0777, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08714768290519714
Epoch 0, Step 2246: train/loss = 0.37253114581108093, train/raw-loss = 0.27213895320892334, train/logprobs = tensor([[-0.6984, -4.3618],
        [-1.6748, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14341741800308228
Epoch 0, Step 2247: train/loss = 0.3003881275653839, train/raw-loss = 0.19646716117858887, train/logprobs = tensor([[-0.6443, -3.9499],
        [-2.3309, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14845851063728333
Epoch 0, Step 2248: train/loss = 0.6257728338241577, train/raw-loss = 0.5524665117263794, train/logprobs = tensor([[-0.4287, -0.7673],
        [-0.9078, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10472333431243896
Epoch 0, Step 2249: train/loss = 0.3170393407344818, train/raw-loss = 0.24338434636592865, train/logprobs = tensor([[-0.6012, -3.2321],
        [-1.3008, -0.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522139072418213
Epoch 0, Step 2250: train/loss = 0.37808266282081604, train/raw-loss = 0.2911674976348877, train/logprobs = tensor([[-0.4981, -4.1122],
        [-1.3284, -0.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12416452169418335
Epoch 0, Step 2251: train/loss = 0.35682347416877747, train/raw-loss = 0.26364418864250183, train/logprobs = tensor([[-0.4653, -4.0739],
        [-1.3502, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13311327993869781
Epoch 0, Step 2252: train/loss = 0.5337991118431091, train/raw-loss = 0.4628833532333374, train/logprobs = tensor([[-0.7276, -2.1824],
        [-0.9295, -0.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130824148654938
Epoch 0, Step 2253: train/loss = 0.4854033589363098, train/raw-loss = 0.40362346172332764, train/logprobs = tensor([[-0.5333, -4.2345],
        [-1.1771, -0.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11682846397161484
Epoch 0, Step 2254: train/loss = 0.6266188025474548, train/raw-loss = 0.5463736057281494, train/logprobs = tensor([[-0.5453, -1.1459],
        [-1.1675, -0.9771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11463600397109985
Epoch 0, Step 2255: train/loss = 0.24895651638507843, train/raw-loss = 0.18297231197357178, train/logprobs = tensor([[ -0.9758, -11.5038],
        [ -1.7039,  -2.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09426313638687134
Epoch 0, Step 2256: train/loss = 0.4478326141834259, train/raw-loss = 0.35272637009620667, train/logprobs = tensor([[-0.6125, -4.6963],
        [-1.1587, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13586607575416565
Epoch 0, Step 2257: train/loss = 0.5262466669082642, train/raw-loss = 0.440420925617218, train/logprobs = tensor([[-0.9700, -2.6708],
        [-1.2981, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260828912258148
Epoch 0, Step 2258: train/loss = 0.4099084734916687, train/raw-loss = 0.3214242458343506, train/logprobs = tensor([[-0.7980, -6.2341],
        [-1.4333, -1.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12640604376792908
Epoch 0, Step 2259: train/loss = 0.277617871761322, train/raw-loss = 0.19364595413208008, train/logprobs = tensor([[-0.3995, -9.9065],
        [-1.2927, -1.2109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11995984613895416
Epoch 0, Step 2260: train/loss = 0.4030784070491791, train/raw-loss = 0.32677948474884033, train/logprobs = tensor([[-0.5829, -4.8056],
        [-1.3751, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10899846255779266
Epoch 0, Step 2261: train/loss = 0.30076271295547485, train/raw-loss = 0.19782042503356934, train/logprobs = tensor([[-0.7691, -5.9247],
        [-2.1891, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14706037938594818
Epoch 0, Step 2262: train/loss = 0.5185922980308533, train/raw-loss = 0.4372466206550598, train/logprobs = tensor([[-0.6392, -1.6429],
        [-1.1784, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11620812118053436
Epoch 0, Step 2263: train/loss = 0.48625731468200684, train/raw-loss = 0.38959091901779175, train/logprobs = tensor([[-0.5736, -2.3289],
        [-1.5943, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13809482753276825
Epoch 0, Step 2264: train/loss = 0.4692166745662689, train/raw-loss = 0.39976972341537476, train/logprobs = tensor([[-0.6118, -5.0584],
        [-0.9289, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09920988231897354
Epoch 0, Step 2265: train/loss = 0.31691449880599976, train/raw-loss = 0.24908064305782318, train/logprobs = tensor([[-0.7188, -4.6337],
        [-2.1534, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09690549969673157
Epoch 0, Step 2266: train/loss = 0.2438971996307373, train/raw-loss = 0.17392942309379578, train/logprobs = tensor([[-0.6827, -8.6145],
        [-1.9089, -1.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09995397925376892
Epoch 0, Step 2267: train/loss = 0.6050063371658325, train/raw-loss = 0.5423026084899902, train/logprobs = tensor([[-0.5564, -1.0221],
        [-0.7195, -0.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957676589488983
Epoch 0, Step 2268: train/loss = 0.3216201066970825, train/raw-loss = 0.21639671921730042, train/logprobs = tensor([[-0.7324, -4.2310],
        [-2.3425, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15031912922859192
Epoch 0, Step 2269: train/loss = 0.49109581112861633, train/raw-loss = 0.40319645404815674, train/logprobs = tensor([[-1.0176, -2.4563],
        [-1.8578, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12557050585746765
Epoch 0, Step 2270: train/loss = 0.3929471969604492, train/raw-loss = 0.3250858187675476, train/logprobs = tensor([[-0.3752, -4.3888],
        [-0.7355, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09694481641054153
Epoch 0, Step 2271: train/loss = 0.3615012764930725, train/raw-loss = 0.2826196551322937, train/logprobs = tensor([[-0.7911, -7.0459],
        [-1.8105, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268801242113113
Epoch 0, Step 2272: train/loss = 0.37512046098709106, train/raw-loss = 0.29798391461372375, train/logprobs = tensor([[-0.7560, -6.1497],
        [-2.3244, -1.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11019504815340042
Epoch 0, Step 2273: train/loss = 0.45593345165252686, train/raw-loss = 0.3915565311908722, train/logprobs = tensor([[-0.8158, -4.4720],
        [-0.8967, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09196707606315613
Epoch 0, Step 2274: train/loss = 0.2779688239097595, train/raw-loss = 0.19591350853443146, train/logprobs = tensor([[-0.3501, -5.2708],
        [-1.2486, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1172218769788742
Epoch 0, Step 2275: train/loss = 0.2092686891555786, train/raw-loss = 0.11572936177253723, train/logprobs = tensor([[-0.5955, -5.1632],
        [-2.2054, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13362760841846466
Epoch 0, Step 2276: train/loss = 0.3785095512866974, train/raw-loss = 0.2945151627063751, train/logprobs = tensor([[-0.6259, -4.5186],
        [-1.6645, -1.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11999201029539108
Epoch 0, Step 2277: train/loss = 0.5700584650039673, train/raw-loss = 0.5116039514541626, train/logprobs = tensor([[-0.4241, -1.5280],
        [-0.7207, -0.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08350653946399689
Epoch 0, Step 2278: train/loss = 0.4448031783103943, train/raw-loss = 0.3505791425704956, train/logprobs = tensor([[-0.9866, -3.2431],
        [-1.6106, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1346057951450348
Epoch 0, Step 2279: train/loss = 0.7175708413124084, train/raw-loss = 0.6504677534103394, train/logprobs = tensor([[-2.1305, -7.0773],
        [-1.4536, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0958615243434906
Epoch 0, Step 2280: train/loss = 0.48685941100120544, train/raw-loss = 0.4176677167415619, train/logprobs = tensor([[-0.4696, -2.4398],
        [-1.1387, -1.1787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09884527325630188
Epoch 0, Step 2281: train/loss = 0.2276056408882141, train/raw-loss = 0.13674135506153107, train/logprobs = tensor([[-0.6050, -5.3413],
        [-2.7435, -0.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12980613112449646
Epoch 0, Step 2282: train/loss = 0.46130263805389404, train/raw-loss = 0.3782024383544922, train/logprobs = tensor([[-0.4873, -4.4304],
        [-1.2226, -1.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11871457099914551
Epoch 0, Step 2283: train/loss = 0.32645365595817566, train/raw-loss = 0.24577054381370544, train/logprobs = tensor([[-0.5086, -5.1231],
        [-1.0619, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11526158452033997
Epoch 0, Step 2284: train/loss = 0.6142653226852417, train/raw-loss = 0.5365705490112305, train/logprobs = tensor([[-1.2417, -4.7057],
        [-1.3589, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11099251359701157
Epoch 0, Step 2285: train/loss = 0.34474700689315796, train/raw-loss = 0.26079851388931274, train/logprobs = tensor([[-0.9173, -8.3413],
        [-1.4743, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11992644518613815
Epoch 0, Step 2286: train/loss = 0.30404427647590637, train/raw-loss = 0.21845096349716187, train/logprobs = tensor([[-0.9290, -5.1581],
        [-1.5866, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227614969015121
Epoch 0, Step 2287: train/loss = 0.6290103197097778, train/raw-loss = 0.550198495388031, train/logprobs = tensor([[-1.4064, -5.6099],
        [-1.6014, -1.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11258827149868011
Epoch 0, Step 2288: train/loss = 0.32701969146728516, train/raw-loss = 0.2449815720319748, train/logprobs = tensor([[-1.1243, -7.1210],
        [-1.5724, -1.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11719732731580734
Epoch 0, Step 2289: train/loss = 0.4200194180011749, train/raw-loss = 0.34615200757980347, train/logprobs = tensor([[-0.6386, -6.6574],
        [-1.8445, -1.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552486777305603
Epoch 0, Step 2290: train/loss = 0.7481554746627808, train/raw-loss = 0.6586745977401733, train/logprobs = tensor([[-0.9002, -1.6205],
        [-2.2570, -1.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12782981991767883
Epoch 0, Step 2291: train/loss = 0.20971179008483887, train/raw-loss = 0.08849392086267471, train/logprobs = tensor([[-0.6554, -7.6302],
        [-2.9615, -0.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731683611869812
Epoch 0, Step 2292: train/loss = 0.5951049327850342, train/raw-loss = 0.5255393981933594, train/logprobs = tensor([[-1.6524, -4.1169],
        [-1.3029, -1.3805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09937931597232819
Epoch 0, Step 2293: train/loss = 0.3847838044166565, train/raw-loss = 0.28036800026893616, train/logprobs = tensor([[-0.7615, -3.8725],
        [-2.0753, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14916543662548065
Epoch 0, Step 2294: train/loss = 0.4048381447792053, train/raw-loss = 0.30571985244750977, train/logprobs = tensor([[-0.6230, -6.6107],
        [-1.6886, -1.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14159758388996124
Epoch 0, Step 2295: train/loss = 0.3928592801094055, train/raw-loss = 0.31161636114120483, train/logprobs = tensor([[-0.8361, -3.4573],
        [-1.6953, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11606138199567795
Epoch 0, Step 2296: train/loss = 0.544216513633728, train/raw-loss = 0.47148555517196655, train/logprobs = tensor([[-0.6852, -1.4373],
        [-1.4502, -0.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10390131175518036
Epoch 0, Step 2297: train/loss = 0.41106507182121277, train/raw-loss = 0.33119213581085205, train/logprobs = tensor([[-0.6586, -3.0189],
        [-1.4540, -0.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11410416662693024
Epoch 0, Step 2298: train/loss = 0.1690737009048462, train/raw-loss = 0.08082442730665207, train/logprobs = tensor([[ -0.5982, -12.8884],
        [ -2.6334,  -2.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12607039511203766
Epoch 0, Step 2299: train/loss = 0.553568422794342, train/raw-loss = 0.46985629200935364, train/logprobs = tensor([[-0.5481, -2.1611],
        [-0.9752, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11958877742290497
Epoch 0, Step 2300: train/loss = 0.2557079493999481, train/raw-loss = 0.18005013465881348, train/logprobs = tensor([[-0.9538, -3.9385],
        [-2.2236, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10808258503675461
Epoch 0, Step 2301: train/loss = 0.2924015522003174, train/raw-loss = 0.18873968720436096, train/logprobs = tensor([[-0.5132, -6.7131],
        [-2.2476, -1.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14808838069438934
Epoch 0, Step 2302: train/loss = 0.4171748757362366, train/raw-loss = 0.35564911365509033, train/logprobs = tensor([[-0.3518, -6.9002],
        [-1.6110, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789397031068802
Epoch 0, Step 2303: train/loss = 0.2602423429489136, train/raw-loss = 0.16974322497844696, train/logprobs = tensor([[-1.0206, -5.2262],
        [-2.4270, -0.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12928445637226105
Epoch 0, Step 2304: train/loss = 0.3844757676124573, train/raw-loss = 0.29765063524246216, train/logprobs = tensor([[-0.7115, -6.6276],
        [-1.3616, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12403589487075806
Epoch 0, Step 2305: train/loss = 0.5534996390342712, train/raw-loss = 0.4677836000919342, train/logprobs = tensor([[-1.3290, -7.3064],
        [-1.5731, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12245143949985504
Epoch 0, Step 2306: train/loss = 0.45045334100723267, train/raw-loss = 0.3821583390235901, train/logprobs = tensor([[-1.0159, -3.6945],
        [-1.3783, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09756433963775635
Epoch 0, Step 2307: train/loss = 0.5817970037460327, train/raw-loss = 0.48666656017303467, train/logprobs = tensor([[-0.5350, -4.3765],
        [-2.7336, -2.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.135900616645813
Epoch 0, Step 2308: train/loss = 0.510689377784729, train/raw-loss = 0.44139277935028076, train/logprobs = tensor([[-0.4343, -3.3052],
        [-0.7671, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09899522364139557
Epoch 0, Step 2309: train/loss = 0.4721554219722748, train/raw-loss = 0.407792329788208, train/logprobs = tensor([[-1.5186, -7.8887],
        [-1.1863, -1.1584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194725751876831
Epoch 0, Step 2310: train/loss = 0.5930184721946716, train/raw-loss = 0.5000118017196655, train/logprobs = tensor([[-0.8088, -1.8034],
        [-1.9133, -1.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13286671042442322
Epoch 0, Step 2311: train/loss = 0.6005748510360718, train/raw-loss = 0.5403632521629333, train/logprobs = tensor([[-0.4987, -1.9654],
        [-0.6168, -0.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08601653575897217
Epoch 0, Step 2312: train/loss = 0.36847296357154846, train/raw-loss = 0.2814479172229767, train/logprobs = tensor([[-0.5401, -3.3283],
        [-1.5569, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12432149797677994
Epoch 0, Step 2313: train/loss = 0.3342950940132141, train/raw-loss = 0.24584248661994934, train/logprobs = tensor([[-0.7280, -4.8272],
        [-1.6587, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12636089324951172
Epoch 0, Step 2314: train/loss = 0.2653743624687195, train/raw-loss = 0.18546074628829956, train/logprobs = tensor([[-0.8197, -8.9700],
        [-1.4946, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11416228860616684
Epoch 0, Step 2315: train/loss = 0.3153364360332489, train/raw-loss = 0.215153768658638, train/logprobs = tensor([[-0.8341, -4.9292],
        [-1.8603, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14311808347702026
Epoch 0, Step 2316: train/loss = 0.42637044191360474, train/raw-loss = 0.35551780462265015, train/logprobs = tensor([[-0.5629, -3.7366],
        [-1.2589, -0.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10121806710958481
Epoch 0, Step 2317: train/loss = 0.3255828619003296, train/raw-loss = 0.24818044900894165, train/logprobs = tensor([[-0.8927, -4.4670],
        [-1.5024, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057485640048981
Epoch 0, Step 2318: train/loss = 0.5039648413658142, train/raw-loss = 0.4390171766281128, train/logprobs = tensor([[-0.5324, -3.3230],
        [-0.8698, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09278232604265213
Epoch 0, Step 2319: train/loss = 0.3014644682407379, train/raw-loss = 0.20899556577205658, train/logprobs = tensor([[-1.0506, -6.7053],
        [-1.8868, -1.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13209843635559082
Epoch 0, Step 2320: train/loss = 0.45856061577796936, train/raw-loss = 0.36616623401641846, train/logprobs = tensor([[-0.6758, -3.6066],
        [-1.2706, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13199201226234436
Epoch 0, Step 2321: train/loss = 0.5541870594024658, train/raw-loss = 0.4642900228500366, train/logprobs = tensor([[-0.4821, -2.6152],
        [-1.0364, -0.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12842440605163574
Epoch 0, Step 2322: train/loss = 0.5695135593414307, train/raw-loss = 0.48598846793174744, train/logprobs = tensor([[-2.4196, -5.1641],
        [-2.1252, -1.2850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932159215211868
Epoch 0, Step 2323: train/loss = 0.605500340461731, train/raw-loss = 0.5340337753295898, train/logprobs = tensor([[-0.6735, -1.2265],
        [-0.9350, -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1020950973033905
Epoch 0, Step 2324: train/loss = 0.38644999265670776, train/raw-loss = 0.30827581882476807, train/logprobs = tensor([[-0.5635, -5.9376],
        [-1.1616, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11167734861373901
Epoch 0, Step 2325: train/loss = 0.5656432509422302, train/raw-loss = 0.5010009407997131, train/logprobs = tensor([[-0.3878, -1.8365],
        [-0.6458, -0.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09234611690044403
Epoch 0, Step 2326: train/loss = 0.23107832670211792, train/raw-loss = 0.12463434040546417, train/logprobs = tensor([[-0.9370, -7.8613],
        [-2.9605, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1520628184080124
Epoch 0, Step 2327: train/loss = 0.4925331473350525, train/raw-loss = 0.42371106147766113, train/logprobs = tensor([[-0.8923, -4.5761],
        [-1.3654, -0.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09831727296113968
Epoch 0, Step 2328: train/loss = 0.49549561738967896, train/raw-loss = 0.3838273584842682, train/logprobs = tensor([[-0.5815, -4.8264],
        [-1.5531, -0.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159526064991951
Epoch 0, Step 2329: train/loss = 0.5034496784210205, train/raw-loss = 0.43535706400871277, train/logprobs = tensor([[-0.4313, -3.6638],
        [-0.7224, -0.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09727513790130615
Epoch 0, Step 2330: train/loss = 0.37212470173835754, train/raw-loss = 0.2857438325881958, train/logprobs = tensor([[-0.4592, -3.7427],
        [-1.3000, -1.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1234012097120285
Epoch 0, Step 2331: train/loss = 0.6027510762214661, train/raw-loss = 0.5311926007270813, train/logprobs = tensor([[-0.8946, -2.3551],
        [-0.7847, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10222640633583069
Epoch 0, Step 2332: train/loss = 0.3884013891220093, train/raw-loss = 0.310673326253891, train/logprobs = tensor([[-0.8171, -4.7269],
        [-1.5142, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104007065296173
Epoch 0, Step 2333: train/loss = 0.4595222473144531, train/raw-loss = 0.3634706735610962, train/logprobs = tensor([[-0.5987, -3.2404],
        [-1.8780, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13721655309200287
Epoch 0, Step 2334: train/loss = 0.44681403040885925, train/raw-loss = 0.3637326955795288, train/logprobs = tensor([[-0.9150, -6.2594],
        [-1.1334, -1.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11868759244680405
Epoch 0, Step 2335: train/loss = 0.15780901908874512, train/raw-loss = 0.0652824193239212, train/logprobs = tensor([[-0.7048, -9.6951],
        [-2.9707, -2.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132180854678154
Epoch 0, Step 2336: train/loss = 0.3615283966064453, train/raw-loss = 0.2792329490184784, train/logprobs = tensor([[-0.5466, -5.7559],
        [-1.6910, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756495386362076
Epoch 0, Step 2337: train/loss = 0.2195090353488922, train/raw-loss = 0.12608051300048828, train/logprobs = tensor([[-1.2033, -8.4467],
        [-2.6025, -1.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13346931338310242
Epoch 0, Step 2338: train/loss = 0.44344761967658997, train/raw-loss = 0.33840033411979675, train/logprobs = tensor([[-1.0450, -2.6479],
        [-2.1707, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.150067538022995
Epoch 0, Step 2339: train/loss = 0.5184872150421143, train/raw-loss = 0.4395905137062073, train/logprobs = tensor([[-1.2598, -3.3618],
        [-1.5225, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11270955204963684
Epoch 0, Step 2340: train/loss = 0.47583866119384766, train/raw-loss = 0.3868721127510071, train/logprobs = tensor([[-0.7344, -2.1638],
        [-1.5868, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270950883626938
Epoch 0, Step 2341: train/loss = 0.6558318138122559, train/raw-loss = 0.5808142423629761, train/logprobs = tensor([[-1.5424, -3.6238],
        [-1.2121, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10716792941093445
Epoch 0, Step 2342: train/loss = 0.5389180183410645, train/raw-loss = 0.45888733863830566, train/logprobs = tensor([[-0.5812, -1.5192],
        [-1.1554, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11432952433824539
Epoch 0, Step 2343: train/loss = 0.3012579679489136, train/raw-loss = 0.20239980518817902, train/logprobs = tensor([[-0.4686, -5.1617],
        [-1.7932, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14122594892978668
Epoch 0, Step 2344: train/loss = 0.32278746366500854, train/raw-loss = 0.2512006461620331, train/logprobs = tensor([[-0.6422, -5.7017],
        [-1.3702, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10226690769195557
Epoch 0, Step 2345: train/loss = 0.3125486671924591, train/raw-loss = 0.22818678617477417, train/logprobs = tensor([[-0.4916, -6.8873],
        [-1.8493, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12051700055599213
Epoch 0, Step 2346: train/loss = 0.3717040717601776, train/raw-loss = 0.2980155348777771, train/logprobs = tensor([[-0.5461, -4.0975],
        [-1.0676, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10526932775974274
Epoch 0, Step 2347: train/loss = 0.40749406814575195, train/raw-loss = 0.306549072265625, train/logprobs = tensor([[-0.6992, -4.6685],
        [-2.3447, -1.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14420709013938904
Epoch 0, Step 2348: train/loss = 0.24143601953983307, train/raw-loss = 0.14459054172039032, train/logprobs = tensor([[-0.9027, -5.9986],
        [-2.4452, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383506953716278
Epoch 0, Step 2349: train/loss = 0.9075294733047485, train/raw-loss = 0.8263684511184692, train/logprobs = tensor([[-2.1724, -3.3147],
        [-1.0347, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11594432592391968
Epoch 0, Step 2350: train/loss = 0.5001310110092163, train/raw-loss = 0.4366697669029236, train/logprobs = tensor([[-0.6592, -3.0026],
        [-0.7187, -0.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09065890312194824
Epoch 0, Step 2351: train/loss = 0.5056511163711548, train/raw-loss = 0.4443953335285187, train/logprobs = tensor([[-0.4353, -1.9110],
        [-0.8648, -0.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08750832080841064
Epoch 0, Step 2352: train/loss = 0.30440765619277954, train/raw-loss = 0.22950586676597595, train/logprobs = tensor([[-0.6322, -5.9334],
        [-1.5687, -1.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700253397226334
Epoch 0, Step 2353: train/loss = 0.4977264404296875, train/raw-loss = 0.42837998270988464, train/logprobs = tensor([[-0.5601, -3.4398],
        [-0.9643, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0990663543343544
Epoch 0, Step 2354: train/loss = 0.44413018226623535, train/raw-loss = 0.3505745530128479, train/logprobs = tensor([[-1.7711, -4.5001],
        [-2.0187, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13365092873573303
Epoch 0, Step 2355: train/loss = 0.3238556981086731, train/raw-loss = 0.24254350364208221, train/logprobs = tensor([[-0.6291, -6.9218],
        [-1.9857, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11616025865077972
Epoch 0, Step 2356: train/loss = 0.36018478870391846, train/raw-loss = 0.2681397497653961, train/logprobs = tensor([[-0.8496, -5.8539],
        [-1.2595, -0.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314929723739624
Epoch 0, Step 2357: train/loss = 0.39401406049728394, train/raw-loss = 0.2828502058982849, train/logprobs = tensor([[-0.9321, -3.5348],
        [-1.6144, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15880551934242249
Epoch 0, Step 2358: train/loss = 0.35313519835472107, train/raw-loss = 0.2832810878753662, train/logprobs = tensor([[-0.7756, -3.4165],
        [-2.1217, -0.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09979157149791718
Epoch 0, Step 2359: train/loss = 0.2772536873817444, train/raw-loss = 0.18186575174331665, train/logprobs = tensor([[-0.8883, -6.7892],
        [-2.3401, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362684965133667
Epoch 0, Step 2360: train/loss = 0.4290931820869446, train/raw-loss = 0.35029953718185425, train/logprobs = tensor([[-0.6415, -3.7325],
        [-1.1335, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256237328052521
Epoch 0, Step 2361: train/loss = 0.3875252306461334, train/raw-loss = 0.2870953381061554, train/logprobs = tensor([[-0.8542, -4.6955],
        [-1.4522, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14347127079963684
Epoch 0, Step 2362: train/loss = 0.3686869144439697, train/raw-loss = 0.26561734080314636, train/logprobs = tensor([[-0.5424, -2.8547],
        [-1.3073, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472422480583191
Epoch 0, Step 2363: train/loss = 0.4040378928184509, train/raw-loss = 0.3218943774700165, train/logprobs = tensor([[-0.6848, -3.2522],
        [-1.4421, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1173478290438652
Epoch 0, Step 2364: train/loss = 0.5330617427825928, train/raw-loss = 0.4467986524105072, train/logprobs = tensor([[-1.3951, -3.2139],
        [-1.9564, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12323303520679474
Epoch 0, Step 2365: train/loss = 0.3655911982059479, train/raw-loss = 0.30219566822052, train/logprobs = tensor([[-0.5486, -4.3163],
        [-0.9665, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09056508541107178
Epoch 0, Step 2366: train/loss = 0.5205609798431396, train/raw-loss = 0.44353485107421875, train/logprobs = tensor([[-0.8248, -2.7769],
        [-0.6519, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003731191158295
Epoch 0, Step 2367: train/loss = 0.5089991688728333, train/raw-loss = 0.43882617354393005, train/logprobs = tensor([[-0.5174, -2.3966],
        [-0.9892, -0.5268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10024706274271011
Epoch 0, Step 2368: train/loss = 0.39412733912467957, train/raw-loss = 0.3180750012397766, train/logprobs = tensor([[-1.1083, -5.0359],
        [-1.3625, -0.9748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1086462140083313
Epoch 0, Step 2369: train/loss = 0.523876428604126, train/raw-loss = 0.44231992959976196, train/logprobs = tensor([[-0.6573, -3.0867],
        [-1.4076, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11650927364826202
Epoch 0, Step 2370: train/loss = 0.22421446442604065, train/raw-loss = 0.13407917320728302, train/logprobs = tensor([[-0.8092, -5.7802],
        [-2.1908, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12876471877098083
Epoch 0, Step 2371: train/loss = 0.37011289596557617, train/raw-loss = 0.26532435417175293, train/logprobs = tensor([[-0.8811, -3.2824],
        [-1.8203, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1496978998184204
Epoch 0, Step 2372: train/loss = 0.3485959768295288, train/raw-loss = 0.2448556274175644, train/logprobs = tensor([[-0.5508, -6.4838],
        [-1.7389, -1.3731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14820049703121185
Epoch 0, Step 2373: train/loss = 0.324765145778656, train/raw-loss = 0.23092742264270782, train/logprobs = tensor([[-0.5003, -3.5026],
        [-1.7290, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13405388593673706
Epoch 0, Step 2374: train/loss = 0.4241045117378235, train/raw-loss = 0.33262506127357483, train/logprobs = tensor([[-0.4653, -4.1756],
        [-0.8654, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13068489730358124
