output_dir: data/base
file_name: base_llama_70_from_opus_principles_diverse_NO_COT

constitution_dir: constitutions_opus_diverse

iteration: 0
start_example: 0
max_example: 5000
batch_size: 5000

generation_config:
  max_new_tokens: 350
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1

model_config: 
  model: "meta-llama/Meta-Llama-3-70B"
  download_dir: "/scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-70B"
  # model: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-sumarization/typo-1e-6-iteration-2-opus-diverse-diverse-from-epoch-0.25/epoch-0.51/hf
  # download_dir: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-sumarization/typo-1e-6-iteration-2-opus-diverse-diverse-from-epoch-0.25/epoch-0.51/hf
  dtype: auto
  quantization: null
  tensor_parallel_size: 4

dataset: 
  path: openai/summarize_from_feedback
  cache_dir: /scr/jphilipp/typo/openai/summarize_from_feedback
  split: train

filter: # for efficiency, we filter these formatting errors or generic 'i'm sorry' responses.
  - The assistant
  - sorry
  - Response
  - "[insert"
  - "[]"
  - "]"
  - principles
  - constitution
  - summarization