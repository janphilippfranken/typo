output_dir: data/iteration_2
file_name: iteration-2-epoch-0.25-fixed-epoch-mistral-mistral-constitution

constitution_dir: constitutions_mistral

iteration: 1
start_example: 0
max_example: 3000
batch_size: 3000

generation_config:
  max_new_tokens: 350
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1

model_config:
  # model: "mistralai/Mistral-7B-v0.1"
  # download_dir: /scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1
  # download_dir: "/scr/jphilipp/typo/pretrained_models/Mixtral-8x7B-v0.1"
  model: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization-fixed-mistral-principles/typo-5e-7-iteration-2-from-epoch-0.12/epoch-0.25
  download_dir: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization-fixed-mistral-principles/typo-5e-7-iteration-2-from-epoch-0.12/epoch-0.25
  dtype: auto
  quantization: null
  tensor_parallel_size: 2

dataset: 
  path: openai/summarize_from_feedback
  cache_dir: /scr/jphilipp/typo/openai/summarize_from_feedback
  split: train

filter: # for efficiency, we filter these formatting errors or generic 'i'm sorry' responses.
  - The assistant
  - sorry
  - Response
  - "[insert"
  - "[]"
  - "]"