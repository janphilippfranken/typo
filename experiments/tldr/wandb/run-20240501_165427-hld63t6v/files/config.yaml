wandb_version: 1

model:
  desc: null
  value:
    model_type: huggingface
    name: llama_8b_base
    model_config:
      pretrained_model_name_or_path: meta-llama/Meta-Llama-3-8B
      cache_dir: /scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-8B
    tokenizer_config:
      pretrained_model_name_or_path: meta-llama/Meta-Llama-3-8B
      cache_dir: /scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-8B
      model_max_length: 2048
data_path:
  desc: null
  value: data/base
data_file:
  desc: null
  value: base_llama_from_opus_principles_diverse.json
n_examples:
  desc: null
  value: 2000
n_responses:
  desc: null
  value: 2
n_constitutions:
  desc: null
  value: 2
wandb:
  desc: null
  value:
    project: sami-summarization-llama
    name: typo-lr-5e-7-iteration-1-opus-diverse
    log: true
typo:
  desc: null
  value:
    beta: 0.0
training:
  desc: null
  value:
    evaluate_before_training: false
    evaluate: false
    n_epochs: 1
    lr: 5.0e-07
    train_batch_size: 1
    eval_batch_size: 1
    train_split: 1.0
    checkpoint_dir: /scr/jphilipp/typo/trained_models/Meta-Llama-3-8B/checkpoints-sumarization/typo-5e-7-iteration-1-opus-diverse
    max_grad_norm: 1.0
    num_warmup_steps: 1
    gradient_accumulation_steps: 32
    save_after_n_steps: 64
    seed: 42
    model_archive: null
_wandb:
  desc: null
  value:
    python_version: 3.10.0
    cli_version: 0.16.4
    framework: huggingface
    huggingface_version: 4.37.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1714607667.0
    t:
      1:
      - 1
      - 11
      - 49
      - 50
      - 55
      - 71
      - 105
      2:
      - 1
      - 11
      - 49
      - 50
      - 55
      - 71
      - 105
      3:
      - 13
      - 16
      - 23
      4: 3.10.0
      5: 0.16.4
      6: 4.37.2
      8:
      - 5
      13: linux-x86_64
