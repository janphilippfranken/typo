output_dir: data/base
file_name: base_llama_prism
preferences: prism_data/preferences/prism_users.json
conversations: prism_data/conversations/prism_prompts_responses.json
iteration: 1
start_example: 0
max_example: 10
batch_size: 1
generation_config:
  max_new_tokens: 500
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1
model_config:
  model: meta-llama/Meta-Llama-3-70B
  download_dir: /scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-70B
  dtype: auto
  quantization: null
  tensor_parallel_size: 2
filter:
- The assistant
- sorry
- Response
- '[insert'
- '[]'
- ']'
- The post
- principles
- constitution
- summarization
- My response
