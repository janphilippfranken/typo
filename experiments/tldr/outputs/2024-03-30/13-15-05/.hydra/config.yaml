output_dir: data/base
file_name: iteration-1-epoch-0.12-mixtral-8x7b-5e-7
constitution_dir: constitutions_mistral
iteration: 1
start_example: 5000
max_example: 7500
batch_size: 2500
generation_config:
  max_new_tokens: 350
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1
model_config:
  model: /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-1/epoch-0.12/hf
  download_dir: /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-1/epoch-0.12/hf
  dtype: auto
  quantization: null
  tensor_parallel_size: 2
dataset:
  path: openai/summarize_from_feedback
  cache_dir: /scr/jphilipp/typo/openai/summarize_from_feedback
  split: train
filter:
- The assistant
- sorry
- Response
- '[insert'
- '[]'
- ']'
