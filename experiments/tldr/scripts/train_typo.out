setting RLIMIT_NOFILE soft limit to 131072 from 1024
4 initializing distributed
wrapping model 4...
wrapped model 4...
Loaded model on rank 4
Loaded reference model on rank 4
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
2 initializing distributed
wrapping model 2...
wrapped model 2...
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
0 initializing distributed
Initialized process group...
WANDB
wrapping model 0...
wrapped model 0...
n examples: 2000
2000
tokenized 2000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
6 initializing distributed
wrapping model 6...
wrapped model 6...
Loaded model on rank 6
Loaded reference model on rank 6
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
5 initializing distributed
wrapping model 5...
wrapped model 5...
Loaded model on rank 5
Loaded reference model on rank 5
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
1 initializing distributed
wrapping model 1...
wrapped model 1...
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
3 initializing distributed
wrapping model 3...
wrapped model 3...
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
7 initializing distributed
wrapping model 7...
wrapped model 7...
Loaded model on rank 7
Loaded reference model on rank 7
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-3-opus-from-epoch-0.25.
Epoch 0, Step 0: train/loss = 0.6900808215141296, train/raw-loss = 0.6900808215141296, train/logprobs = tensor([[-0.5273, -0.5272],
        [-0.5499, -0.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.688643753528595, train/raw-loss = 0.688643753528595, train/logprobs = tensor([[-0.5419, -0.5206],
        [-0.5696, -0.5268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.690022349357605, train/raw-loss = 0.690022349357605, train/logprobs = tensor([[-0.5140, -0.5591],
        [-0.5314, -0.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6886060237884521, train/raw-loss = 0.6886060237884521, train/logprobs = tensor([[-0.5396, -0.5431],
        [-0.5652, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6919885873794556, train/raw-loss = 0.6919885873794556, train/logprobs = tensor([[-0.5706, -0.5761],
        [-0.5927, -0.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6869769096374512, train/raw-loss = 0.6869769096374512, train/logprobs = tensor([[-0.5418, -0.5621],
        [-0.5628, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6866793632507324, train/raw-loss = 0.6866793632507324, train/logprobs = tensor([[-0.5625, -0.5245],
        [-0.5996, -0.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6829250454902649, train/raw-loss = 0.6829250454902649, train/logprobs = tensor([[-0.6224, -0.4978],
        [-0.6726, -0.4961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6906029582023621, train/raw-loss = 0.6906029582023621, train/logprobs = tensor([[-0.5559, -0.4681],
        [-0.5910, -0.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.690096914768219, train/raw-loss = 0.690096914768219, train/logprobs = tensor([[-0.5310, -0.5143],
        [-0.5492, -0.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6907204985618591, train/raw-loss = 0.6907204985618591, train/logprobs = tensor([[-0.5171, -0.5471],
        [-0.5437, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6866785287857056, train/raw-loss = 0.6866785287857056, train/logprobs = tensor([[-0.5509, -0.5818],
        [-0.5820, -0.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6900092363357544, train/raw-loss = 0.6900092363357544, train/logprobs = tensor([[-0.5263, -0.5650],
        [-0.5479, -0.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6895464658737183, train/raw-loss = 0.6895464658737183, train/logprobs = tensor([[-0.4669, -0.4471],
        [-0.4760, -0.4405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6875611543655396, train/raw-loss = 0.6875611543655396, train/logprobs = tensor([[-0.5356, -0.5740],
        [-0.5747, -0.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.688372790813446, train/raw-loss = 0.688372790813446, train/logprobs = tensor([[-0.5716, -0.5705],
        [-0.6008, -0.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6875648498535156, train/raw-loss = 0.6875648498535156, train/logprobs = tensor([[-0.5260, -0.5114],
        [-0.5520, -0.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6892948746681213, train/raw-loss = 0.6892948746681213, train/logprobs = tensor([[-0.5383, -0.4938],
        [-0.5664, -0.5029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6962300539016724, train/raw-loss = 0.6962300539016724, train/logprobs = tensor([[-0.5954, -0.6590],
        [-0.6094, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6881392002105713, train/raw-loss = 0.6881392002105713, train/logprobs = tensor([[-0.4934, -0.4993],
        [-0.5155, -0.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6872571110725403, train/raw-loss = 0.6872571110725403, train/logprobs = tensor([[-0.5695, -0.5564],
        [-0.6191, -0.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6920962333679199, train/raw-loss = 0.6920962333679199, train/logprobs = tensor([[-0.5527, -0.4244],
        [-0.5721, -0.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6911054253578186, train/raw-loss = 0.6911054253578186, train/logprobs = tensor([[-0.5849, -0.5446],
        [-0.5980, -0.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6914588212966919, train/raw-loss = 0.6914588212966919, train/logprobs = tensor([[-0.5490, -0.5286],
        [-0.5718, -0.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6877807378768921, train/raw-loss = 0.6877807378768921, train/logprobs = tensor([[-0.5258, -0.4730],
        [-0.5496, -0.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6916239857673645, train/raw-loss = 0.6916239857673645, train/logprobs = tensor([[-0.5100, -0.4598],
        [-0.5351, -0.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6905773878097534, train/raw-loss = 0.6905773878097534, train/logprobs = tensor([[-0.5719, -0.5440],
        [-0.5873, -0.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6860814690589905, train/raw-loss = 0.6860814690589905, train/logprobs = tensor([[-0.5919, -0.5973],
        [-0.6274, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6909588575363159, train/raw-loss = 0.6909588575363159, train/logprobs = tensor([[-0.4882, -0.5119],
        [-0.5099, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6903505921363831, train/raw-loss = 0.6903505921363831, train/logprobs = tensor([[-0.4738, -0.4940],
        [-0.4932, -0.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6883021593093872, train/raw-loss = 0.6883021593093872, train/logprobs = tensor([[-0.5763, -0.5918],
        [-0.5947, -0.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6865766048431396, train/raw-loss = 0.6865766048431396, train/logprobs = tensor([[-0.5750, -0.5620],
        [-0.6187, -0.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6703305244445801, train/raw-loss = 0.6703305244445801, train/logprobs = tensor([[-0.5130, -0.4756],
        [-0.5813, -0.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6793513894081116, train/raw-loss = 0.6793513894081116, train/logprobs = tensor([[-0.4966, -0.5128],
        [-0.5297, -0.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.684288501739502, train/raw-loss = 0.684288501739502, train/logprobs = tensor([[-0.4779, -0.5434],
        [-0.5057, -0.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6869141459465027, train/raw-loss = 0.6869141459465027, train/logprobs = tensor([[-0.6133, -0.6608],
        [-0.6460, -0.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6844402551651001, train/raw-loss = 0.6844402551651001, train/logprobs = tensor([[-0.5268, -0.5236],
        [-0.5585, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.678449809551239, train/raw-loss = 0.678449809551239, train/logprobs = tensor([[-0.5096, -0.5186],
        [-0.5494, -0.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6757975816726685, train/raw-loss = 0.6757975816726685, train/logprobs = tensor([[-0.5325, -0.6185],
        [-0.5725, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6826842427253723, train/raw-loss = 0.6826842427253723, train/logprobs = tensor([[-0.5338, -0.5527],
        [-0.5743, -0.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.680044949054718, train/raw-loss = 0.680044949054718, train/logprobs = tensor([[-0.4662, -0.4956],
        [-0.4978, -0.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6945037841796875, train/raw-loss = 0.6945037841796875, train/logprobs = tensor([[-0.5515, -0.5908],
        [-0.5659, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6884889602661133, train/raw-loss = 0.6884889602661133, train/logprobs = tensor([[-0.5270, -0.5137],
        [-0.5400, -0.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6801133751869202, train/raw-loss = 0.6801133751869202, train/logprobs = tensor([[-0.5442, -0.5340],
        [-0.5950, -0.5312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6880875825881958, train/raw-loss = 0.6880875825881958, train/logprobs = tensor([[-0.5088, -0.5321],
        [-0.5285, -0.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6833357214927673, train/raw-loss = 0.6833357214927673, train/logprobs = tensor([[-0.4845, -0.5106],
        [-0.5133, -0.4974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6810638904571533, train/raw-loss = 0.6810638904571533, train/logprobs = tensor([[-0.4917, -0.5116],
        [-0.5304, -0.4945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6853406429290771, train/raw-loss = 0.6853406429290771, train/logprobs = tensor([[-0.5291, -0.5639],
        [-0.5592, -0.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6799888610839844, train/raw-loss = 0.6799888610839844, train/logprobs = tensor([[-0.5006, -0.5693],
        [-0.5297, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6777437925338745, train/raw-loss = 0.6777437925338745, train/logprobs = tensor([[-0.5627, -0.6269],
        [-0.5811, -0.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6793928742408752, train/raw-loss = 0.6793928742408752, train/logprobs = tensor([[-0.4827, -0.5142],
        [-0.5144, -0.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6802240610122681, train/raw-loss = 0.6802240610122681, train/logprobs = tensor([[-0.5005, -0.5396],
        [-0.5330, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6785333752632141, train/raw-loss = 0.6785333752632141, train/logprobs = tensor([[-0.5338, -0.5589],
        [-0.5826, -0.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6847227811813354, train/raw-loss = 0.6847227811813354, train/logprobs = tensor([[-0.5005, -0.5374],
        [-0.5203, -0.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6717485189437866, train/raw-loss = 0.6717485189437866, train/logprobs = tensor([[-0.5605, -0.6234],
        [-0.6069, -0.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6784766912460327, train/raw-loss = 0.6784766912460327, train/logprobs = tensor([[-0.5610, -0.5685],
        [-0.5980, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6836100816726685, train/raw-loss = 0.6836100816726685, train/logprobs = tensor([[-0.5262, -0.6052],
        [-0.5532, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6838727593421936, train/raw-loss = 0.6838727593421936, train/logprobs = tensor([[-0.5129, -0.5334],
        [-0.5506, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6839072704315186, train/raw-loss = 0.6839072704315186, train/logprobs = tensor([[-0.5711, -0.4918],
        [-0.5884, -0.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6734195351600647, train/raw-loss = 0.6734195351600647, train/logprobs = tensor([[-0.5483, -0.4817],
        [-0.6075, -0.4465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6796238422393799, train/raw-loss = 0.6796238422393799, train/logprobs = tensor([[-0.5505, -0.5554],
        [-0.5904, -0.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6788516044616699, train/raw-loss = 0.6788516044616699, train/logprobs = tensor([[-0.5035, -0.5339],
        [-0.5354, -0.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.675269603729248, train/raw-loss = 0.675269603729248, train/logprobs = tensor([[-0.4920, -0.5178],
        [-0.5366, -0.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6752709746360779, train/raw-loss = 0.6752709746360779, train/logprobs = tensor([[-0.5345, -0.5418],
        [-0.5743, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.681723415851593, train/raw-loss = 0.681723415851593, train/logprobs = tensor([[-0.5963, -0.5642],
        [-0.5928, -0.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 65: train/loss = 0.6743314266204834, train/raw-loss = 0.6743314266204834, train/logprobs = tensor([[-0.5172, -0.5714],
        [-0.5333, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 66: train/loss = 0.6769097447395325, train/raw-loss = 0.6769097447395325, train/logprobs = tensor([[-0.4821, -0.5491],
        [-0.5258, -0.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 67: train/loss = 0.6764586567878723, train/raw-loss = 0.6764586567878723, train/logprobs = tensor([[-0.5787, -0.5936],
        [-0.6462, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 68: train/loss = 0.6871311068534851, train/raw-loss = 0.6871311068534851, train/logprobs = tensor([[-0.5584, -0.6356],
        [-0.5491, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 69: train/loss = 0.6828818321228027, train/raw-loss = 0.6828818321228027, train/logprobs = tensor([[-0.5572, -0.5653],
        [-0.5867, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 70: train/loss = 0.6785614490509033, train/raw-loss = 0.6785614490509033, train/logprobs = tensor([[-0.5577, -0.5761],
        [-0.6057, -0.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 71: train/loss = 0.672129213809967, train/raw-loss = 0.672129213809967, train/logprobs = tensor([[-0.6179, -0.5720],
        [-0.6739, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 72: train/loss = 0.6607080101966858, train/raw-loss = 0.6607080101966858, train/logprobs = tensor([[-0.4791, -0.6302],
        [-0.5405, -0.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 73: train/loss = 0.6751532554626465, train/raw-loss = 0.6751532554626465, train/logprobs = tensor([[-0.5274, -0.6072],
        [-0.5360, -0.5397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 74: train/loss = 0.6765592694282532, train/raw-loss = 0.6765592694282532, train/logprobs = tensor([[-0.5160, -0.4903],
        [-0.5637, -0.4672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 75: train/loss = 0.6821955442428589, train/raw-loss = 0.6821955442428589, train/logprobs = tensor([[-0.5497, -0.5331],
        [-0.5552, -0.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 76: train/loss = 0.6792098879814148, train/raw-loss = 0.6792098879814148, train/logprobs = tensor([[-0.5552, -0.5805],
        [-0.5879, -0.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 77: train/loss = 0.6739574074745178, train/raw-loss = 0.6739574074745178, train/logprobs = tensor([[-0.5352, -0.6334],
        [-0.5950, -0.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 78: train/loss = 0.6858357787132263, train/raw-loss = 0.6858357787132263, train/logprobs = tensor([[-0.5360, -0.5467],
        [-0.5747, -0.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 79: train/loss = 0.68650883436203, train/raw-loss = 0.68650883436203, train/logprobs = tensor([[-0.5031, -0.4814],
        [-0.5035, -0.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 80: train/loss = 0.6793899536132812, train/raw-loss = 0.6793899536132812, train/logprobs = tensor([[-0.5145, -0.5707],
        [-0.5309, -0.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 81: train/loss = 0.6683144569396973, train/raw-loss = 0.6683144569396973, train/logprobs = tensor([[-0.6424, -0.5823],
        [-0.6960, -0.5254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 82: train/loss = 0.6685134768486023, train/raw-loss = 0.6685134768486023, train/logprobs = tensor([[-0.4995, -0.6291],
        [-0.5377, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 83: train/loss = 0.673312246799469, train/raw-loss = 0.673312246799469, train/logprobs = tensor([[-0.5831, -0.5535],
        [-0.6490, -0.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 84: train/loss = 0.6705736517906189, train/raw-loss = 0.6705736517906189, train/logprobs = tensor([[-0.5568, -0.5931],
        [-0.6117, -0.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 85: train/loss = 0.6775453090667725, train/raw-loss = 0.6775453090667725, train/logprobs = tensor([[-0.4997, -0.4771],
        [-0.5360, -0.4465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 86: train/loss = 0.6811720132827759, train/raw-loss = 0.6811720132827759, train/logprobs = tensor([[-0.5604, -0.5225],
        [-0.5793, -0.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 87: train/loss = 0.6766931414604187, train/raw-loss = 0.6766931414604187, train/logprobs = tensor([[-0.5414, -0.5181],
        [-0.5752, -0.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 88: train/loss = 0.6792051792144775, train/raw-loss = 0.6792051792144775, train/logprobs = tensor([[-0.5421, -0.5850],
        [-0.5624, -0.5472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 89: train/loss = 0.669954776763916, train/raw-loss = 0.669954776763916, train/logprobs = tensor([[-0.5632, -0.6053],
        [-0.6049, -0.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 90: train/loss = 0.6735321283340454, train/raw-loss = 0.6735321283340454, train/logprobs = tensor([[-0.5739, -0.6524],
        [-0.5784, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 91: train/loss = 0.6820001602172852, train/raw-loss = 0.6820001602172852, train/logprobs = tensor([[-0.5452, -0.5223],
        [-0.5809, -0.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 92: train/loss = 0.6834403276443481, train/raw-loss = 0.6834403276443481, train/logprobs = tensor([[-0.5538, -0.5919],
        [-0.5797, -0.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 93: train/loss = 0.6789028644561768, train/raw-loss = 0.6789028644561768, train/logprobs = tensor([[-0.4883, -0.4961],
        [-0.5223, -0.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 94: train/loss = 0.6736896634101868, train/raw-loss = 0.6736896634101868, train/logprobs = tensor([[-0.5153, -0.5515],
        [-0.5667, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 95: train/loss = 0.68459552526474, train/raw-loss = 0.68459552526474, train/logprobs = tensor([[-0.5487, -0.4966],
        [-0.5660, -0.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 96: train/loss = 0.6639070510864258, train/raw-loss = 0.6639070510864258, train/logprobs = tensor([[-0.5352, -0.5389],
        [-0.6699, -0.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 97: train/loss = 0.6631378531455994, train/raw-loss = 0.6631378531455994, train/logprobs = tensor([[-0.5263, -0.5670],
        [-0.6160, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 98: train/loss = 0.6741360425949097, train/raw-loss = 0.6741360425949097, train/logprobs = tensor([[-0.5467, -0.6701],
        [-0.6004, -0.6410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 99: train/loss = 0.6764960885047913, train/raw-loss = 0.6764960885047913, train/logprobs = tensor([[-0.4981, -0.5849],
        [-0.5308, -0.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 100: train/loss = 0.6748195886611938, train/raw-loss = 0.6748195886611938, train/logprobs = tensor([[-0.5301, -0.4679],
        [-0.5977, -0.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 101: train/loss = 0.6735759377479553, train/raw-loss = 0.6735759377479553, train/logprobs = tensor([[-0.5062, -0.5557],
        [-0.5476, -0.5121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 102: train/loss = 0.6514286994934082, train/raw-loss = 0.6514286994934082, train/logprobs = tensor([[-0.5604, -0.5867],
        [-0.6950, -0.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 103: train/loss = 0.6728841662406921, train/raw-loss = 0.6728841662406921, train/logprobs = tensor([[-0.5345, -0.6003],
        [-0.5824, -0.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 104: train/loss = 0.6666207909584045, train/raw-loss = 0.6666207909584045, train/logprobs = tensor([[-0.5589, -0.6052],
        [-0.6434, -0.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 105: train/loss = 0.685421347618103, train/raw-loss = 0.685421347618103, train/logprobs = tensor([[-0.5863, -0.5306],
        [-0.6150, -0.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 106: train/loss = 0.6760108470916748, train/raw-loss = 0.6760108470916748, train/logprobs = tensor([[-0.5428, -0.5653],
        [-0.6018, -0.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 107: train/loss = 0.6775433421134949, train/raw-loss = 0.6775433421134949, train/logprobs = tensor([[-0.5046, -0.5651],
        [-0.5327, -0.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 108: train/loss = 0.6798330545425415, train/raw-loss = 0.6798330545425415, train/logprobs = tensor([[-0.5480, -0.5843],
        [-0.5553, -0.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 109: train/loss = 0.6750206351280212, train/raw-loss = 0.6750206351280212, train/logprobs = tensor([[-0.5522, -0.5661],
        [-0.6155, -0.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 110: train/loss = 0.6814554929733276, train/raw-loss = 0.6814554929733276, train/logprobs = tensor([[-0.5142, -0.5365],
        [-0.5484, -0.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 111: train/loss = 0.672782838344574, train/raw-loss = 0.672782838344574, train/logprobs = tensor([[-0.5254, -0.6267],
        [-0.5957, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 112: train/loss = 0.6809158325195312, train/raw-loss = 0.6809158325195312, train/logprobs = tensor([[-0.5478, -0.5938],
        [-0.5847, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 113: train/loss = 0.6703612804412842, train/raw-loss = 0.6703612804412842, train/logprobs = tensor([[-0.5576, -0.5946],
        [-0.5982, -0.5380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 114: train/loss = 0.6713098287582397, train/raw-loss = 0.6713098287582397, train/logprobs = tensor([[-0.5404, -0.5966],
        [-0.5642, -0.5295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 115: train/loss = 0.675879716873169, train/raw-loss = 0.675879716873169, train/logprobs = tensor([[-0.5303, -0.6358],
        [-0.5386, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 116: train/loss = 0.6789418458938599, train/raw-loss = 0.6789418458938599, train/logprobs = tensor([[-0.5141, -0.6243],
        [-0.5247, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 117: train/loss = 0.6818026900291443, train/raw-loss = 0.6818026900291443, train/logprobs = tensor([[-0.5935, -0.6404],
        [-0.6143, -0.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 118: train/loss = 0.6845945119857788, train/raw-loss = 0.6845945119857788, train/logprobs = tensor([[-0.5031, -0.4851],
        [-0.5215, -0.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 119: train/loss = 0.6656848788261414, train/raw-loss = 0.6656848788261414, train/logprobs = tensor([[-0.5161, -0.6185],
        [-0.5770, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 120: train/loss = 0.674667477607727, train/raw-loss = 0.674667477607727, train/logprobs = tensor([[-0.4891, -0.5641],
        [-0.5321, -0.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 121: train/loss = 0.6578126549720764, train/raw-loss = 0.6578126549720764, train/logprobs = tensor([[-0.6008, -0.5996],
        [-0.6870, -0.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 122: train/loss = 0.6693506240844727, train/raw-loss = 0.6693506240844727, train/logprobs = tensor([[-0.5603, -0.5533],
        [-0.5695, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 123: train/loss = 0.6712660789489746, train/raw-loss = 0.6712660789489746, train/logprobs = tensor([[-0.5540, -0.5944],
        [-0.5928, -0.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 124: train/loss = 0.6596114635467529, train/raw-loss = 0.6596114635467529, train/logprobs = tensor([[-0.5690, -0.5746],
        [-0.6321, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 125: train/loss = 0.6727598905563354, train/raw-loss = 0.6727598905563354, train/logprobs = tensor([[-0.4894, -0.5903],
        [-0.5355, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 126: train/loss = 0.6800566911697388, train/raw-loss = 0.6800566911697388, train/logprobs = tensor([[-0.5307, -0.5373],
        [-0.5588, -0.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 127: train/loss = 0.6780785918235779, train/raw-loss = 0.6780785918235779, train/logprobs = tensor([[-0.5980, -0.5439],
        [-0.6415, -0.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 128: train/loss = 0.6756346821784973, train/raw-loss = 0.6756346821784973, train/logprobs = tensor([[-0.5348, -0.5666],
        [-0.5691, -0.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 129: train/loss = 0.6877509355545044, train/raw-loss = 0.6877509355545044, train/logprobs = tensor([[-0.5597, -0.5786],
        [-0.5494, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 130: train/loss = 0.6734304428100586, train/raw-loss = 0.6734304428100586, train/logprobs = tensor([[-0.4857, -0.5037],
        [-0.5101, -0.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 131: train/loss = 0.651191771030426, train/raw-loss = 0.651191771030426, train/logprobs = tensor([[-0.5326, -0.6491],
        [-0.6358, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 132: train/loss = 0.6833043694496155, train/raw-loss = 0.6833043694496155, train/logprobs = tensor([[-0.5609, -0.5788],
        [-0.5947, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 133: train/loss = 0.6790686249732971, train/raw-loss = 0.6790686249732971, train/logprobs = tensor([[-0.4883, -0.4900],
        [-0.5207, -0.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 134: train/loss = 0.6622838973999023, train/raw-loss = 0.6622838973999023, train/logprobs = tensor([[-0.5810, -0.6326],
        [-0.6485, -0.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 135: train/loss = 0.6584497690200806, train/raw-loss = 0.6584497690200806, train/logprobs = tensor([[-0.5850, -0.5717],
        [-0.6647, -0.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 136: train/loss = 0.6797872185707092, train/raw-loss = 0.6797872185707092, train/logprobs = tensor([[-0.5011, -0.5457],
        [-0.5110, -0.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 137: train/loss = 0.6729855537414551, train/raw-loss = 0.6729855537414551, train/logprobs = tensor([[-0.6360, -0.6091],
        [-0.6692, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 138: train/loss = 0.6764448285102844, train/raw-loss = 0.6764448285102844, train/logprobs = tensor([[-0.4780, -0.6000],
        [-0.4846, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 139: train/loss = 0.6687397956848145, train/raw-loss = 0.6687397956848145, train/logprobs = tensor([[-0.5151, -0.5552],
        [-0.5577, -0.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 140: train/loss = 0.6759322881698608, train/raw-loss = 0.6759322881698608, train/logprobs = tensor([[-0.5426, -0.5569],
        [-0.5662, -0.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 141: train/loss = 0.6730374693870544, train/raw-loss = 0.6730374693870544, train/logprobs = tensor([[-0.5181, -0.5541],
        [-0.5623, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 142: train/loss = 0.6606736183166504, train/raw-loss = 0.6606736183166504, train/logprobs = tensor([[-0.5316, -0.6482],
        [-0.6232, -0.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 143: train/loss = 0.6880573034286499, train/raw-loss = 0.6880573034286499, train/logprobs = tensor([[-0.5355, -0.6088],
        [-0.5451, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 144: train/loss = 0.668372392654419, train/raw-loss = 0.668372392654419, train/logprobs = tensor([[-0.5520, -0.5498],
        [-0.6283, -0.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 145: train/loss = 0.6745270490646362, train/raw-loss = 0.6745270490646362, train/logprobs = tensor([[-0.5251, -0.5896],
        [-0.5751, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 146: train/loss = 0.6764223575592041, train/raw-loss = 0.6764223575592041, train/logprobs = tensor([[-0.5276, -0.5073],
        [-0.5667, -0.4739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 147: train/loss = 0.673866331577301, train/raw-loss = 0.673866331577301, train/logprobs = tensor([[-0.5233, -0.5875],
        [-0.5507, -0.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 148: train/loss = 0.665724515914917, train/raw-loss = 0.665724515914917, train/logprobs = tensor([[-0.5030, -0.5977],
        [-0.5695, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 149: train/loss = 0.6686355471611023, train/raw-loss = 0.6686355471611023, train/logprobs = tensor([[-0.5032, -0.5426],
        [-0.5543, -0.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 150: train/loss = 0.677569568157196, train/raw-loss = 0.677569568157196, train/logprobs = tensor([[-0.5372, -0.5466],
        [-0.5583, -0.5018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 151: train/loss = 0.6711021661758423, train/raw-loss = 0.6711021661758423, train/logprobs = tensor([[-0.5599, -0.5498],
        [-0.6129, -0.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 152: train/loss = 0.6780269145965576, train/raw-loss = 0.6780269145965576, train/logprobs = tensor([[-0.5118, -0.4885],
        [-0.5348, -0.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 153: train/loss = 0.6688633561134338, train/raw-loss = 0.6688633561134338, train/logprobs = tensor([[-0.5284, -0.6129],
        [-0.5704, -0.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 154: train/loss = 0.6735597848892212, train/raw-loss = 0.6735597848892212, train/logprobs = tensor([[-0.5715, -0.6292],
        [-0.5933, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 155: train/loss = 0.6623955965042114, train/raw-loss = 0.6623955965042114, train/logprobs = tensor([[-0.4880, -0.4688],
        [-0.5329, -0.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 156: train/loss = 0.6816971302032471, train/raw-loss = 0.6816971302032471, train/logprobs = tensor([[-0.5433, -0.5776],
        [-0.5873, -0.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 157: train/loss = 0.6777441501617432, train/raw-loss = 0.6777441501617432, train/logprobs = tensor([[-0.5702, -0.5370],
        [-0.6035, -0.5053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 158: train/loss = 0.6788014769554138, train/raw-loss = 0.6788014769554138, train/logprobs = tensor([[-0.5558, -0.5957],
        [-0.5613, -0.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 159: train/loss = 0.6664641499519348, train/raw-loss = 0.6664641499519348, train/logprobs = tensor([[-0.5139, -0.5833],
        [-0.5417, -0.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 160: train/loss = 0.678962230682373, train/raw-loss = 0.678962230682373, train/logprobs = tensor([[-0.5431, -0.5548],
        [-0.5727, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 161: train/loss = 0.6547916531562805, train/raw-loss = 0.6547916531562805, train/logprobs = tensor([[-0.6365, -0.6786],
        [-0.7101, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 162: train/loss = 0.6777145862579346, train/raw-loss = 0.6777145862579346, train/logprobs = tensor([[-0.5834, -0.6066],
        [-0.6013, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 163: train/loss = 0.6835648417472839, train/raw-loss = 0.6835648417472839, train/logprobs = tensor([[-0.5607, -0.5576],
        [-0.6246, -0.5780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 164: train/loss = 0.664799690246582, train/raw-loss = 0.664799690246582, train/logprobs = tensor([[-0.5451, -0.5594],
        [-0.6071, -0.4978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 165: train/loss = 0.6687049865722656, train/raw-loss = 0.6687049865722656, train/logprobs = tensor([[-0.5988, -0.5463],
        [-0.6477, -0.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 166: train/loss = 0.6729764938354492, train/raw-loss = 0.6729764938354492, train/logprobs = tensor([[-0.5604, -0.6807],
        [-0.5995, -0.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 167: train/loss = 0.6660121083259583, train/raw-loss = 0.6660121083259583, train/logprobs = tensor([[-0.5544, -0.6382],
        [-0.5620, -0.5287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 168: train/loss = 0.682207465171814, train/raw-loss = 0.682207465171814, train/logprobs = tensor([[-0.5370, -0.5464],
        [-0.5481, -0.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 169: train/loss = 0.6823005080223083, train/raw-loss = 0.6823005080223083, train/logprobs = tensor([[-0.5338, -0.5743],
        [-0.5523, -0.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 170: train/loss = 0.6620292663574219, train/raw-loss = 0.6620292663574219, train/logprobs = tensor([[-0.5316, -0.6445],
        [-0.6014, -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 171: train/loss = 0.671775758266449, train/raw-loss = 0.671775758266449, train/logprobs = tensor([[-0.5693, -0.5985],
        [-0.5632, -0.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 172: train/loss = 0.6715160608291626, train/raw-loss = 0.6715160608291626, train/logprobs = tensor([[-0.5357, -0.6226],
        [-0.5780, -0.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 173: train/loss = 0.6850611567497253, train/raw-loss = 0.6850611567497253, train/logprobs = tensor([[-0.5383, -0.5036],
        [-0.5559, -0.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 174: train/loss = 0.6632349491119385, train/raw-loss = 0.6632349491119385, train/logprobs = tensor([[-0.5559, -0.6056],
        [-0.6056, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 175: train/loss = 0.67264324426651, train/raw-loss = 0.67264324426651, train/logprobs = tensor([[-0.5329, -0.5651],
        [-0.5712, -0.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 176: train/loss = 0.6849550008773804, train/raw-loss = 0.6849550008773804, train/logprobs = tensor([[-0.5053, -0.5789],
        [-0.5343, -0.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 177: train/loss = 0.6786525249481201, train/raw-loss = 0.6786525249481201, train/logprobs = tensor([[-0.5836, -0.5616],
        [-0.6102, -0.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 178: train/loss = 0.6813032627105713, train/raw-loss = 0.6813032627105713, train/logprobs = tensor([[-0.5826, -0.6242],
        [-0.5980, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 179: train/loss = 0.659826397895813, train/raw-loss = 0.659826397895813, train/logprobs = tensor([[-0.4797, -0.6187],
        [-0.5054, -0.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 180: train/loss = 0.6788997054100037, train/raw-loss = 0.6788997054100037, train/logprobs = tensor([[-0.6055, -0.5393],
        [-0.6191, -0.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 181: train/loss = 0.6666890382766724, train/raw-loss = 0.6666890382766724, train/logprobs = tensor([[-0.5741, -0.5944],
        [-0.6463, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 182: train/loss = 0.6730051040649414, train/raw-loss = 0.6730051040649414, train/logprobs = tensor([[-0.5213, -0.5304],
        [-0.5542, -0.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 183: train/loss = 0.6620232462882996, train/raw-loss = 0.6620232462882996, train/logprobs = tensor([[-0.5414, -0.5534],
        [-0.6038, -0.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 184: train/loss = 0.6581318378448486, train/raw-loss = 0.6581318378448486, train/logprobs = tensor([[-0.5448, -0.6009],
        [-0.5827, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 185: train/loss = 0.675872266292572, train/raw-loss = 0.675872266292572, train/logprobs = tensor([[-0.5286, -0.5842],
        [-0.5751, -0.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 186: train/loss = 0.6826685070991516, train/raw-loss = 0.6826685070991516, train/logprobs = tensor([[-0.5599, -0.5547],
        [-0.6080, -0.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 187: train/loss = 0.6814743876457214, train/raw-loss = 0.6814743876457214, train/logprobs = tensor([[-0.5672, -0.5622],
        [-0.5884, -0.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 188: train/loss = 0.6610425114631653, train/raw-loss = 0.6610425114631653, train/logprobs = tensor([[-0.5270, -0.4696],
        [-0.6182, -0.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 189: train/loss = 0.6797001957893372, train/raw-loss = 0.6797001957893372, train/logprobs = tensor([[-0.4958, -0.6173],
        [-0.4990, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 190: train/loss = 0.6809359192848206, train/raw-loss = 0.6809359192848206, train/logprobs = tensor([[-0.4996, -0.5137],
        [-0.5222, -0.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 191: train/loss = 0.6707786321640015, train/raw-loss = 0.6707786321640015, train/logprobs = tensor([[-0.6217, -0.6594],
        [-0.6862, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 192: train/loss = 0.6764141321182251, train/raw-loss = 0.6764141321182251, train/logprobs = tensor([[-0.5559, -0.5916],
        [-0.5852, -0.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 193: train/loss = 0.6827036142349243, train/raw-loss = 0.6827036142349243, train/logprobs = tensor([[-0.5012, -0.5101],
        [-0.5090, -0.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 194: train/loss = 0.6548037528991699, train/raw-loss = 0.6548037528991699, train/logprobs = tensor([[-0.6087, -0.7412],
        [-0.6741, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 195: train/loss = 0.6732414364814758, train/raw-loss = 0.6732414364814758, train/logprobs = tensor([[-0.5580, -0.5659],
        [-0.5792, -0.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 196: train/loss = 0.6693403720855713, train/raw-loss = 0.6693403720855713, train/logprobs = tensor([[-0.6020, -0.6154],
        [-0.6255, -0.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 197: train/loss = 0.6553146243095398, train/raw-loss = 0.6553146243095398, train/logprobs = tensor([[-0.6165, -0.6633],
        [-0.6605, -0.5465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 198: train/loss = 0.656554102897644, train/raw-loss = 0.656554102897644, train/logprobs = tensor([[-0.5860, -0.6181],
        [-0.6655, -0.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 199: train/loss = 0.6667464375495911, train/raw-loss = 0.6667464375495911, train/logprobs = tensor([[-0.5757, -0.6383],
        [-0.6195, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 200: train/loss = 0.663457989692688, train/raw-loss = 0.663457989692688, train/logprobs = tensor([[-0.5777, -0.5448],
        [-0.6670, -0.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 201: train/loss = 0.6835772395133972, train/raw-loss = 0.6835772395133972, train/logprobs = tensor([[-0.5425, -0.5915],
        [-0.5595, -0.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 202: train/loss = 0.6805980205535889, train/raw-loss = 0.6805980205535889, train/logprobs = tensor([[-0.5010, -0.5162],
        [-0.5196, -0.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 203: train/loss = 0.6717347502708435, train/raw-loss = 0.6717347502708435, train/logprobs = tensor([[-0.5463, -0.5567],
        [-0.6074, -0.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 204: train/loss = 0.676021933555603, train/raw-loss = 0.676021933555603, train/logprobs = tensor([[-0.5485, -0.5684],
        [-0.5973, -0.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 205: train/loss = 0.6498867273330688, train/raw-loss = 0.6498867273330688, train/logprobs = tensor([[-0.5844, -0.5685],
        [-0.6946, -0.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 206: train/loss = 0.6663069725036621, train/raw-loss = 0.6663069725036621, train/logprobs = tensor([[-0.5914, -0.6026],
        [-0.6326, -0.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 207: train/loss = 0.6742569208145142, train/raw-loss = 0.6742569208145142, train/logprobs = tensor([[-0.5178, -0.6280],
        [-0.5430, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 208: train/loss = 0.6658955812454224, train/raw-loss = 0.6658955812454224, train/logprobs = tensor([[-0.5374, -0.5772],
        [-0.5682, -0.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 209: train/loss = 0.6714795827865601, train/raw-loss = 0.6714795827865601, train/logprobs = tensor([[-0.5467, -0.6068],
        [-0.5739, -0.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 210: train/loss = 0.671122670173645, train/raw-loss = 0.671122670173645, train/logprobs = tensor([[-0.5651, -0.6254],
        [-0.6189, -0.5871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 211: train/loss = 0.6678875684738159, train/raw-loss = 0.6678875684738159, train/logprobs = tensor([[-0.5326, -0.6496],
        [-0.5558, -0.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 212: train/loss = 0.6736719608306885, train/raw-loss = 0.6736719608306885, train/logprobs = tensor([[-0.4974, -0.6429],
        [-0.5069, -0.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 213: train/loss = 0.6657331585884094, train/raw-loss = 0.6657331585884094, train/logprobs = tensor([[-0.6142, -0.6592],
        [-0.6792, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 214: train/loss = 0.6628316044807434, train/raw-loss = 0.6628316044807434, train/logprobs = tensor([[-0.5545, -0.5811],
        [-0.6128, -0.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 215: train/loss = 0.6696987152099609, train/raw-loss = 0.6696987152099609, train/logprobs = tensor([[-0.5424, -0.5912],
        [-0.5987, -0.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 216: train/loss = 0.6770111918449402, train/raw-loss = 0.6770111918449402, train/logprobs = tensor([[-0.5573, -0.5365],
        [-0.6311, -0.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 217: train/loss = 0.6789832711219788, train/raw-loss = 0.6789832711219788, train/logprobs = tensor([[-0.5448, -0.5727],
        [-0.5647, -0.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 218: train/loss = 0.6794863939285278, train/raw-loss = 0.6794863939285278, train/logprobs = tensor([[-0.4832, -0.4682],
        [-0.4864, -0.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 219: train/loss = 0.6785917282104492, train/raw-loss = 0.6785917282104492, train/logprobs = tensor([[-0.4894, -0.4927],
        [-0.5288, -0.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 220: train/loss = 0.6626042127609253, train/raw-loss = 0.6626042127609253, train/logprobs = tensor([[-0.5660, -0.6078],
        [-0.6242, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 221: train/loss = 0.6601378917694092, train/raw-loss = 0.6601378917694092, train/logprobs = tensor([[-0.6063, -0.6692],
        [-0.6616, -0.5806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 222: train/loss = 0.6725896596908569, train/raw-loss = 0.6725896596908569, train/logprobs = tensor([[-0.5909, -0.5834],
        [-0.6438, -0.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 223: train/loss = 0.6567580699920654, train/raw-loss = 0.6567580699920654, train/logprobs = tensor([[-0.4735, -0.5661],
        [-0.5220, -0.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 224: train/loss = 0.679500937461853, train/raw-loss = 0.679500937461853, train/logprobs = tensor([[-0.4934, -0.5765],
        [-0.5175, -0.5403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 225: train/loss = 0.6605682969093323, train/raw-loss = 0.6605682969093323, train/logprobs = tensor([[-0.5772, -0.6044],
        [-0.6396, -0.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 226: train/loss = 0.6741021871566772, train/raw-loss = 0.6741021871566772, train/logprobs = tensor([[-0.5404, -0.6508],
        [-0.5628, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 227: train/loss = 0.6773268580436707, train/raw-loss = 0.6773268580436707, train/logprobs = tensor([[-0.5730, -0.6255],
        [-0.5989, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 228: train/loss = 0.6604491472244263, train/raw-loss = 0.6604491472244263, train/logprobs = tensor([[-0.5408, -0.6029],
        [-0.5649, -0.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 229: train/loss = 0.6706047654151917, train/raw-loss = 0.6706047654151917, train/logprobs = tensor([[-0.5234, -0.6520],
        [-0.5557, -0.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 230: train/loss = 0.661834180355072, train/raw-loss = 0.661834180355072, train/logprobs = tensor([[-0.5857, -0.6345],
        [-0.6453, -0.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 231: train/loss = 0.6664937734603882, train/raw-loss = 0.6664937734603882, train/logprobs = tensor([[-0.5306, -0.5826],
        [-0.5739, -0.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 232: train/loss = 0.6653702259063721, train/raw-loss = 0.6653702259063721, train/logprobs = tensor([[-0.5349, -0.7042],
        [-0.5791, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 233: train/loss = 0.6807222366333008, train/raw-loss = 0.6807222366333008, train/logprobs = tensor([[-0.4687, -0.5023],
        [-0.4832, -0.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 234: train/loss = 0.678375244140625, train/raw-loss = 0.678375244140625, train/logprobs = tensor([[-0.5065, -0.5991],
        [-0.5411, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 235: train/loss = 0.6699661612510681, train/raw-loss = 0.6699661612510681, train/logprobs = tensor([[-0.5634, -0.5624],
        [-0.5660, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 236: train/loss = 0.6771367788314819, train/raw-loss = 0.6771367788314819, train/logprobs = tensor([[-0.5819, -0.5911],
        [-0.6220, -0.5629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 237: train/loss = 0.6748542785644531, train/raw-loss = 0.6748542785644531, train/logprobs = tensor([[-0.4917, -0.5091],
        [-0.4978, -0.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 238: train/loss = 0.6588417887687683, train/raw-loss = 0.6588417887687683, train/logprobs = tensor([[-0.5798, -0.6309],
        [-0.6300, -0.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 239: train/loss = 0.6446921229362488, train/raw-loss = 0.6446921229362488, train/logprobs = tensor([[-0.6211, -0.6925],
        [-0.6904, -0.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 240: train/loss = 0.6684612035751343, train/raw-loss = 0.6684612035751343, train/logprobs = tensor([[-0.5690, -0.6040],
        [-0.6355, -0.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 241: train/loss = 0.6694062352180481, train/raw-loss = 0.6694062352180481, train/logprobs = tensor([[-0.5811, -0.5596],
        [-0.6251, -0.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 242: train/loss = 0.6571668982505798, train/raw-loss = 0.6571668982505798, train/logprobs = tensor([[-0.5786, -0.7290],
        [-0.6032, -0.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 243: train/loss = 0.6627130508422852, train/raw-loss = 0.6627130508422852, train/logprobs = tensor([[-0.5842, -0.6191],
        [-0.6556, -0.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 244: train/loss = 0.6515947580337524, train/raw-loss = 0.6515947580337524, train/logprobs = tensor([[-0.5644, -0.6699],
        [-0.6496, -0.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 245: train/loss = 0.6479905247688293, train/raw-loss = 0.6479905247688293, train/logprobs = tensor([[-0.5667, -0.6096],
        [-0.6466, -0.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 246: train/loss = 0.6765215992927551, train/raw-loss = 0.6765215992927551, train/logprobs = tensor([[-0.5508, -0.6114],
        [-0.5988, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 247: train/loss = 0.6762092709541321, train/raw-loss = 0.6762092709541321, train/logprobs = tensor([[-0.5528, -0.5723],
        [-0.5954, -0.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 248: train/loss = 0.6734884977340698, train/raw-loss = 0.6734884977340698, train/logprobs = tensor([[-0.5841, -0.5557],
        [-0.6155, -0.4957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 249: train/loss = 0.6686262488365173, train/raw-loss = 0.6686262488365173, train/logprobs = tensor([[-0.5701, -0.6077],
        [-0.5703, -0.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
