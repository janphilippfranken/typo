setting RLIMIT_NOFILE soft limit to 131072 from 131072
6 initializing distributed
wrapping model 6...
wrapped model 6...
Loaded model on rank 6
Loaded reference model on rank 6
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
0 initializing distributed
Initialized process group...
WANDB
wrapping model 0...
wrapped model 0...
n examples: 2000
2000
tokenized 2000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
5 initializing distributed
wrapping model 5...
wrapped model 5...
Loaded model on rank 5
Loaded reference model on rank 5
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
2 initializing distributed
wrapping model 2...
wrapped model 2...
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
4 initializing distributed
wrapping model 4...
wrapped model 4...
Loaded model on rank 4
Loaded reference model on rank 4
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
7 initializing distributed
wrapping model 7...
wrapped model 7...
Loaded model on rank 7
Loaded reference model on rank 7
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
3 initializing distributed
wrapping model 3...
wrapped model 3...
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
1 initializing distributed
wrapping model 1...
wrapped model 1...
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mixtral-8x7b-v.01/checkpoints-sumarization/typo-5e-7-iteration-2-opus-from-epoch-0.12.
Epoch 0, Step 0: train/loss = 0.685090959072113, train/raw-loss = 0.685090959072113, train/logprobs = tensor([[-0.5105, -0.4811],
        [-0.5315, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6902681589126587, train/raw-loss = 0.6902681589126587, train/logprobs = tensor([[-0.5351, -0.5133],
        [-0.5632, -0.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6915881037712097, train/raw-loss = 0.6915881037712097, train/logprobs = tensor([[-0.5323, -0.5455],
        [-0.5409, -0.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6887766718864441, train/raw-loss = 0.6887766718864441, train/logprobs = tensor([[-0.5070, -0.5577],
        [-0.5335, -0.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6880714893341064, train/raw-loss = 0.6880714893341064, train/logprobs = tensor([[-0.5442, -0.5702],
        [-0.5691, -0.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6901971101760864, train/raw-loss = 0.6901971101760864, train/logprobs = tensor([[-0.5499, -0.5234],
        [-0.5683, -0.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6875595450401306, train/raw-loss = 0.6875595450401306, train/logprobs = tensor([[-0.5105, -0.4771],
        [-0.5357, -0.4743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6915197372436523, train/raw-loss = 0.6915197372436523, train/logprobs = tensor([[-0.6050, -0.5302],
        [-0.6166, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.690672755241394, train/raw-loss = 0.690672755241394, train/logprobs = tensor([[-0.5505, -0.4958],
        [-0.5809, -0.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6897246241569519, train/raw-loss = 0.6897246241569519, train/logprobs = tensor([[-0.5606, -0.5420],
        [-0.5861, -0.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6923708915710449, train/raw-loss = 0.6923708915710449, train/logprobs = tensor([[-0.5575, -0.4780],
        [-0.5715, -0.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6896195411682129, train/raw-loss = 0.6896195411682129, train/logprobs = tensor([[-0.5251, -0.5211],
        [-0.5364, -0.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6849316358566284, train/raw-loss = 0.6849316358566284, train/logprobs = tensor([[-0.4686, -0.4865],
        [-0.4979, -0.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6895244121551514, train/raw-loss = 0.6895244121551514, train/logprobs = tensor([[-0.4721, -0.4647],
        [-0.5008, -0.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.689163327217102, train/raw-loss = 0.689163327217102, train/logprobs = tensor([[-0.6255, -0.5435],
        [-0.6542, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6857056617736816, train/raw-loss = 0.6857056617736816, train/logprobs = tensor([[-0.5835, -0.5491],
        [-0.6008, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6854742765426636, train/raw-loss = 0.6854742765426636, train/logprobs = tensor([[-0.5511, -0.5978],
        [-0.5827, -0.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6939362287521362, train/raw-loss = 0.6939362287521362, train/logprobs = tensor([[-0.5421, -0.5799],
        [-0.5556, -0.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6870822906494141, train/raw-loss = 0.6870822906494141, train/logprobs = tensor([[-0.5780, -0.5231],
        [-0.5993, -0.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6922655701637268, train/raw-loss = 0.6922655701637268, train/logprobs = tensor([[-0.5134, -0.4824],
        [-0.5285, -0.4776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6889265179634094, train/raw-loss = 0.6889265179634094, train/logprobs = tensor([[-0.5442, -0.4611],
        [-0.5694, -0.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6878407001495361, train/raw-loss = 0.6878407001495361, train/logprobs = tensor([[-0.5360, -0.6271],
        [-0.5588, -0.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6908068060874939, train/raw-loss = 0.6908068060874939, train/logprobs = tensor([[-0.5523, -0.5377],
        [-0.5756, -0.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6883626580238342, train/raw-loss = 0.6883626580238342, train/logprobs = tensor([[-0.5272, -0.4917],
        [-0.5503, -0.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6854437589645386, train/raw-loss = 0.6854437589645386, train/logprobs = tensor([[-0.5540, -0.5364],
        [-0.5931, -0.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6873181462287903, train/raw-loss = 0.6873181462287903, train/logprobs = tensor([[-0.5326, -0.5221],
        [-0.5660, -0.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6915111541748047, train/raw-loss = 0.6915111541748047, train/logprobs = tensor([[-0.5230, -0.4629],
        [-0.5391, -0.4653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6888352632522583, train/raw-loss = 0.6888352632522583, train/logprobs = tensor([[-0.6140, -0.5499],
        [-0.6431, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6872207522392273, train/raw-loss = 0.6872207522392273, train/logprobs = tensor([[-0.5361, -0.4646],
        [-0.5796, -0.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6891028881072998, train/raw-loss = 0.6891028881072998, train/logprobs = tensor([[-0.4858, -0.4767],
        [-0.5032, -0.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6909571886062622, train/raw-loss = 0.6909571886062622, train/logprobs = tensor([[-0.5046, -0.4557],
        [-0.5272, -0.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.686673104763031, train/raw-loss = 0.686673104763031, train/logprobs = tensor([[-0.5286, -0.5188],
        [-0.5608, -0.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.687199592590332, train/raw-loss = 0.687199592590332, train/logprobs = tensor([[-0.5803, -0.5272],
        [-0.6071, -0.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6914782524108887, train/raw-loss = 0.6914782524108887, train/logprobs = tensor([[-0.5522, -0.5132],
        [-0.5664, -0.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6846804618835449, train/raw-loss = 0.6846804618835449, train/logprobs = tensor([[-0.5831, -0.5579],
        [-0.6086, -0.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6833270192146301, train/raw-loss = 0.6833270192146301, train/logprobs = tensor([[-0.5473, -0.5019],
        [-0.5846, -0.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.692521333694458, train/raw-loss = 0.692521333694458, train/logprobs = tensor([[-0.4933, -0.5092],
        [-0.5032, -0.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.688720166683197, train/raw-loss = 0.688720166683197, train/logprobs = tensor([[-0.5252, -0.5709],
        [-0.5379, -0.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6819179058074951, train/raw-loss = 0.6819179058074951, train/logprobs = tensor([[-0.5268, -0.4852],
        [-0.5550, -0.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6838712096214294, train/raw-loss = 0.6838712096214294, train/logprobs = tensor([[-0.5204, -0.5310],
        [-0.5555, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6855363845825195, train/raw-loss = 0.6855363845825195, train/logprobs = tensor([[-0.5068, -0.4403],
        [-0.5368, -0.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6888736486434937, train/raw-loss = 0.6888736486434937, train/logprobs = tensor([[-0.5660, -0.4921],
        [-0.5877, -0.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6784419417381287, train/raw-loss = 0.6784419417381287, train/logprobs = tensor([[-0.5116, -0.5250],
        [-0.5502, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6806367635726929, train/raw-loss = 0.6806367635726929, train/logprobs = tensor([[-0.5346, -0.5870],
        [-0.5770, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6915555596351624, train/raw-loss = 0.6915555596351624, train/logprobs = tensor([[-0.5142, -0.5300],
        [-0.5356, -0.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.687698245048523, train/raw-loss = 0.687698245048523, train/logprobs = tensor([[-0.4725, -0.5077],
        [-0.4887, -0.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6875104308128357, train/raw-loss = 0.6875104308128357, train/logprobs = tensor([[-0.5262, -0.5042],
        [-0.5562, -0.5090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6859784126281738, train/raw-loss = 0.6859784126281738, train/logprobs = tensor([[-0.5214, -0.5527],
        [-0.5342, -0.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6775560975074768, train/raw-loss = 0.6775560975074768, train/logprobs = tensor([[-0.5655, -0.5990],
        [-0.5734, -0.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6825117468833923, train/raw-loss = 0.6825117468833923, train/logprobs = tensor([[-0.6020, -0.5545],
        [-0.6159, -0.5204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6813052892684937, train/raw-loss = 0.6813052892684937, train/logprobs = tensor([[-0.5090, -0.4900],
        [-0.5301, -0.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6828563809394836, train/raw-loss = 0.6828563809394836, train/logprobs = tensor([[-0.5122, -0.6793],
        [-0.5211, -0.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6881764531135559, train/raw-loss = 0.6881764531135559, train/logprobs = tensor([[-0.5077, -0.4721],
        [-0.4936, -0.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6841498613357544, train/raw-loss = 0.6841498613357544, train/logprobs = tensor([[-0.5491, -0.5906],
        [-0.5546, -0.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6847946047782898, train/raw-loss = 0.6847946047782898, train/logprobs = tensor([[-0.5237, -0.5105],
        [-0.5308, -0.4803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6902508735656738, train/raw-loss = 0.6902508735656738, train/logprobs = tensor([[-0.4806, -0.5262],
        [-0.4756, -0.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6827799677848816, train/raw-loss = 0.6827799677848816, train/logprobs = tensor([[-0.5414, -0.5647],
        [-0.5464, -0.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6812069416046143, train/raw-loss = 0.6812069416046143, train/logprobs = tensor([[-0.5145, -0.6029],
        [-0.5274, -0.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6870839595794678, train/raw-loss = 0.6870839595794678, train/logprobs = tensor([[-0.5622, -0.5891],
        [-0.5628, -0.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6838794946670532, train/raw-loss = 0.6838794946670532, train/logprobs = tensor([[-0.5323, -0.5764],
        [-0.5440, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.684282124042511, train/raw-loss = 0.684282124042511, train/logprobs = tensor([[-0.5464, -0.5740],
        [-0.5390, -0.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6873131394386292, train/raw-loss = 0.6873131394386292, train/logprobs = tensor([[-0.5189, -0.5613],
        [-0.5183, -0.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6786956191062927, train/raw-loss = 0.6786956191062927, train/logprobs = tensor([[-0.5266, -0.5418],
        [-0.5415, -0.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6858447790145874, train/raw-loss = 0.6858447790145874, train/logprobs = tensor([[-0.5518, -0.5081],
        [-0.5466, -0.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6884703636169434, train/raw-loss = 0.6884703636169434, train/logprobs = tensor([[-0.5419, -0.5052],
        [-0.5698, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 65: train/loss = 0.6890919208526611, train/raw-loss = 0.6890919208526611, train/logprobs = tensor([[-0.4609, -0.4843],
        [-0.4768, -0.4805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 66: train/loss = 0.6708388328552246, train/raw-loss = 0.6708388328552246, train/logprobs = tensor([[-0.5199, -0.6434],
        [-0.5549, -0.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 67: train/loss = 0.6870137453079224, train/raw-loss = 0.6870137453079224, train/logprobs = tensor([[-0.4991, -0.5091],
        [-0.5044, -0.4875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 68: train/loss = 0.6815522909164429, train/raw-loss = 0.6815522909164429, train/logprobs = tensor([[-0.5280, -0.5521],
        [-0.5739, -0.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 69: train/loss = 0.6800845265388489, train/raw-loss = 0.6800845265388489, train/logprobs = tensor([[-0.5439, -0.5469],
        [-0.5855, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 70: train/loss = 0.6815260052680969, train/raw-loss = 0.6815260052680969, train/logprobs = tensor([[-0.5251, -0.4803],
        [-0.5628, -0.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 71: train/loss = 0.6729713678359985, train/raw-loss = 0.6729713678359985, train/logprobs = tensor([[-0.4632, -0.5344],
        [-0.5018, -0.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 72: train/loss = 0.6850196719169617, train/raw-loss = 0.6850196719169617, train/logprobs = tensor([[-0.4636, -0.5549],
        [-0.4752, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 73: train/loss = 0.6795628666877747, train/raw-loss = 0.6795628666877747, train/logprobs = tensor([[-0.4791, -0.4955],
        [-0.4947, -0.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 74: train/loss = 0.6855877041816711, train/raw-loss = 0.6855877041816711, train/logprobs = tensor([[-0.4715, -0.4846],
        [-0.4909, -0.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 75: train/loss = 0.6824997663497925, train/raw-loss = 0.6824997663497925, train/logprobs = tensor([[-0.5313, -0.4987],
        [-0.5681, -0.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 76: train/loss = 0.678625226020813, train/raw-loss = 0.678625226020813, train/logprobs = tensor([[-0.5224, -0.5967],
        [-0.5236, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 77: train/loss = 0.6747565865516663, train/raw-loss = 0.6747565865516663, train/logprobs = tensor([[-0.5267, -0.5824],
        [-0.5775, -0.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 78: train/loss = 0.6765003204345703, train/raw-loss = 0.6765003204345703, train/logprobs = tensor([[-0.5267, -0.5780],
        [-0.5339, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 79: train/loss = 0.665679931640625, train/raw-loss = 0.665679931640625, train/logprobs = tensor([[-0.5202, -0.5716],
        [-0.5858, -0.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 80: train/loss = 0.674187958240509, train/raw-loss = 0.674187958240509, train/logprobs = tensor([[-0.5575, -0.6136],
        [-0.6297, -0.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 81: train/loss = 0.6853499412536621, train/raw-loss = 0.6853499412536621, train/logprobs = tensor([[-0.4497, -0.4452],
        [-0.4817, -0.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 82: train/loss = 0.6698594689369202, train/raw-loss = 0.6698594689369202, train/logprobs = tensor([[-0.5418, -0.4906],
        [-0.6225, -0.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 83: train/loss = 0.673818826675415, train/raw-loss = 0.673818826675415, train/logprobs = tensor([[-0.5226, -0.5456],
        [-0.6098, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 84: train/loss = 0.6692197918891907, train/raw-loss = 0.6692197918891907, train/logprobs = tensor([[-0.5440, -0.5869],
        [-0.5927, -0.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 85: train/loss = 0.6742686033248901, train/raw-loss = 0.6742686033248901, train/logprobs = tensor([[-0.4410, -0.4910],
        [-0.4887, -0.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 86: train/loss = 0.6835079789161682, train/raw-loss = 0.6835079789161682, train/logprobs = tensor([[-0.4954, -0.5463],
        [-0.5133, -0.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 87: train/loss = 0.6763237118721008, train/raw-loss = 0.6763237118721008, train/logprobs = tensor([[-0.5489, -0.5316],
        [-0.6039, -0.5115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 88: train/loss = 0.677096962928772, train/raw-loss = 0.677096962928772, train/logprobs = tensor([[-0.5338, -0.6267],
        [-0.5857, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 89: train/loss = 0.660052478313446, train/raw-loss = 0.660052478313446, train/logprobs = tensor([[-0.6396, -0.7302],
        [-0.7145, -0.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 90: train/loss = 0.687262773513794, train/raw-loss = 0.687262773513794, train/logprobs = tensor([[-0.4900, -0.4720],
        [-0.5416, -0.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 91: train/loss = 0.6850682497024536, train/raw-loss = 0.6850682497024536, train/logprobs = tensor([[-0.5057, -0.5049],
        [-0.5450, -0.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 92: train/loss = 0.6736652851104736, train/raw-loss = 0.6736652851104736, train/logprobs = tensor([[-0.5216, -0.5707],
        [-0.5964, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 93: train/loss = 0.6763423681259155, train/raw-loss = 0.6763423681259155, train/logprobs = tensor([[-0.5476, -0.5435],
        [-0.6101, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 94: train/loss = 0.6780325770378113, train/raw-loss = 0.6780325770378113, train/logprobs = tensor([[-0.5014, -0.4972],
        [-0.5521, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 95: train/loss = 0.6861473321914673, train/raw-loss = 0.6861473321914673, train/logprobs = tensor([[-0.5548, -0.4875],
        [-0.5683, -0.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 96: train/loss = 0.6649001836776733, train/raw-loss = 0.6649001836776733, train/logprobs = tensor([[-0.5256, -0.5326],
        [-0.6023, -0.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 97: train/loss = 0.6698582768440247, train/raw-loss = 0.6698582768440247, train/logprobs = tensor([[-0.5207, -0.5524],
        [-0.5939, -0.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 98: train/loss = 0.664187490940094, train/raw-loss = 0.664187490940094, train/logprobs = tensor([[-0.5356, -0.5638],
        [-0.6270, -0.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 99: train/loss = 0.6744194626808167, train/raw-loss = 0.6744194626808167, train/logprobs = tensor([[-0.4971, -0.5847],
        [-0.5477, -0.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 100: train/loss = 0.6857856512069702, train/raw-loss = 0.6857856512069702, train/logprobs = tensor([[-0.5153, -0.4840],
        [-0.5628, -0.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 101: train/loss = 0.6786893606185913, train/raw-loss = 0.6786893606185913, train/logprobs = tensor([[-0.5177, -0.5368],
        [-0.5557, -0.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 102: train/loss = 0.6741509437561035, train/raw-loss = 0.6741509437561035, train/logprobs = tensor([[-0.4957, -0.4877],
        [-0.5657, -0.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 103: train/loss = 0.6801909804344177, train/raw-loss = 0.6801909804344177, train/logprobs = tensor([[-0.5357, -0.5330],
        [-0.5885, -0.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 104: train/loss = 0.6831691861152649, train/raw-loss = 0.6831691861152649, train/logprobs = tensor([[-0.4563, -0.4449],
        [-0.4911, -0.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 105: train/loss = 0.6864583492279053, train/raw-loss = 0.6864583492279053, train/logprobs = tensor([[-0.4581, -0.4753],
        [-0.4978, -0.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 106: train/loss = 0.6637346744537354, train/raw-loss = 0.6637346744537354, train/logprobs = tensor([[-0.5467, -0.5597],
        [-0.6130, -0.5021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 107: train/loss = 0.667752206325531, train/raw-loss = 0.667752206325531, train/logprobs = tensor([[-0.5057, -0.5863],
        [-0.5763, -0.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 108: train/loss = 0.6719741225242615, train/raw-loss = 0.6719741225242615, train/logprobs = tensor([[-0.4904, -0.5033],
        [-0.5438, -0.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 109: train/loss = 0.6727571487426758, train/raw-loss = 0.6727571487426758, train/logprobs = tensor([[-0.5062, -0.6096],
        [-0.5596, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 110: train/loss = 0.6858433485031128, train/raw-loss = 0.6858433485031128, train/logprobs = tensor([[-0.5267, -0.4877],
        [-0.5783, -0.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 111: train/loss = 0.6721152067184448, train/raw-loss = 0.6721152067184448, train/logprobs = tensor([[-0.4306, -0.4320],
        [-0.4840, -0.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 112: train/loss = 0.6746900081634521, train/raw-loss = 0.6746900081634521, train/logprobs = tensor([[-0.5213, -0.5866],
        [-0.5780, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 113: train/loss = 0.664711058139801, train/raw-loss = 0.664711058139801, train/logprobs = tensor([[-0.5095, -0.5203],
        [-0.6036, -0.4929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 114: train/loss = 0.692328691482544, train/raw-loss = 0.692328691482544, train/logprobs = tensor([[-0.5235, -0.5966],
        [-0.5592, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 115: train/loss = 0.6672720909118652, train/raw-loss = 0.6672720909118652, train/logprobs = tensor([[-0.5667, -0.5343],
        [-0.6548, -0.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 116: train/loss = 0.6819651126861572, train/raw-loss = 0.6819651126861572, train/logprobs = tensor([[-0.5863, -0.5821],
        [-0.6584, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 117: train/loss = 0.682401180267334, train/raw-loss = 0.682401180267334, train/logprobs = tensor([[-0.5222, -0.5349],
        [-0.5746, -0.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 118: train/loss = 0.6779493093490601, train/raw-loss = 0.6779493093490601, train/logprobs = tensor([[-0.5660, -0.5906],
        [-0.6150, -0.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 119: train/loss = 0.6697998642921448, train/raw-loss = 0.6697998642921448, train/logprobs = tensor([[-0.5211, -0.5629],
        [-0.5774, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 120: train/loss = 0.6833629012107849, train/raw-loss = 0.6833629012107849, train/logprobs = tensor([[-0.4806, -0.5792],
        [-0.5004, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 121: train/loss = 0.6731874346733093, train/raw-loss = 0.6731874346733093, train/logprobs = tensor([[-0.5073, -0.5710],
        [-0.5698, -0.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 122: train/loss = 0.6783595085144043, train/raw-loss = 0.6783595085144043, train/logprobs = tensor([[-0.5000, -0.5095],
        [-0.5599, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 123: train/loss = 0.6739233732223511, train/raw-loss = 0.6739233732223511, train/logprobs = tensor([[-0.4769, -0.5877],
        [-0.5145, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 124: train/loss = 0.6640395522117615, train/raw-loss = 0.6640395522117615, train/logprobs = tensor([[-0.4396, -0.5567],
        [-0.5147, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 125: train/loss = 0.6590619087219238, train/raw-loss = 0.6590619087219238, train/logprobs = tensor([[-0.5829, -0.6319],
        [-0.6802, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 126: train/loss = 0.6845605373382568, train/raw-loss = 0.6845605373382568, train/logprobs = tensor([[-0.5048, -0.5430],
        [-0.5505, -0.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 127: train/loss = 0.6847037672996521, train/raw-loss = 0.6847037672996521, train/logprobs = tensor([[-0.5929, -0.5973],
        [-0.6046, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 128: train/loss = 0.6752456426620483, train/raw-loss = 0.6752456426620483, train/logprobs = tensor([[-0.4710, -0.4214],
        [-0.5326, -0.4026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 129: train/loss = 0.6643399596214294, train/raw-loss = 0.6643399596214294, train/logprobs = tensor([[-0.4995, -0.6104],
        [-0.5762, -0.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 130: train/loss = 0.6786693334579468, train/raw-loss = 0.6786693334579468, train/logprobs = tensor([[-0.4912, -0.5265],
        [-0.5483, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 131: train/loss = 0.6851617097854614, train/raw-loss = 0.6851617097854614, train/logprobs = tensor([[-0.5133, -0.5017],
        [-0.5682, -0.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 132: train/loss = 0.6742615103721619, train/raw-loss = 0.6742615103721619, train/logprobs = tensor([[-0.4936, -0.5157],
        [-0.5463, -0.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 133: train/loss = 0.6589385271072388, train/raw-loss = 0.6589385271072388, train/logprobs = tensor([[-0.4859, -0.5368],
        [-0.5746, -0.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 134: train/loss = 0.6894697546958923, train/raw-loss = 0.6894697546958923, train/logprobs = tensor([[-0.6017, -0.4957],
        [-0.6376, -0.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 135: train/loss = 0.6808168292045593, train/raw-loss = 0.6808168292045593, train/logprobs = tensor([[-0.4975, -0.5176],
        [-0.5645, -0.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 136: train/loss = 0.6714972853660583, train/raw-loss = 0.6714972853660583, train/logprobs = tensor([[-0.5157, -0.4649],
        [-0.5756, -0.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 137: train/loss = 0.6762399673461914, train/raw-loss = 0.6762399673461914, train/logprobs = tensor([[-0.4989, -0.5322],
        [-0.5450, -0.5035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 138: train/loss = 0.6659194231033325, train/raw-loss = 0.6659194231033325, train/logprobs = tensor([[-0.4369, -0.4701],
        [-0.5304, -0.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 139: train/loss = 0.6877979040145874, train/raw-loss = 0.6877979040145874, train/logprobs = tensor([[-0.5208, -0.5251],
        [-0.5499, -0.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 140: train/loss = 0.6711946725845337, train/raw-loss = 0.6711946725845337, train/logprobs = tensor([[-0.4930, -0.5774],
        [-0.5544, -0.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 141: train/loss = 0.6774312257766724, train/raw-loss = 0.6774312257766724, train/logprobs = tensor([[-0.5256, -0.5206],
        [-0.5600, -0.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 142: train/loss = 0.6814073920249939, train/raw-loss = 0.6814073920249939, train/logprobs = tensor([[-0.5181, -0.5121],
        [-0.5903, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 143: train/loss = 0.6760979890823364, train/raw-loss = 0.6760979890823364, train/logprobs = tensor([[-0.4922, -0.4769],
        [-0.5528, -0.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 144: train/loss = 0.6770240068435669, train/raw-loss = 0.6770240068435669, train/logprobs = tensor([[-0.5996, -0.5864],
        [-0.6735, -0.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 145: train/loss = 0.6677014231681824, train/raw-loss = 0.6677014231681824, train/logprobs = tensor([[-0.5806, -0.6400],
        [-0.6244, -0.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 146: train/loss = 0.6786338686943054, train/raw-loss = 0.6786338686943054, train/logprobs = tensor([[-0.5133, -0.4803],
        [-0.5689, -0.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 147: train/loss = 0.6629117131233215, train/raw-loss = 0.6629117131233215, train/logprobs = tensor([[-0.5599, -0.5507],
        [-0.6334, -0.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 148: train/loss = 0.6876493096351624, train/raw-loss = 0.6876493096351624, train/logprobs = tensor([[-0.4777, -0.4992],
        [-0.5051, -0.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 149: train/loss = 0.6675843000411987, train/raw-loss = 0.6675843000411987, train/logprobs = tensor([[-0.5168, -0.5370],
        [-0.5746, -0.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 150: train/loss = 0.6582130789756775, train/raw-loss = 0.6582130789756775, train/logprobs = tensor([[-0.5767, -0.7369],
        [-0.6272, -0.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 151: train/loss = 0.6736500859260559, train/raw-loss = 0.6736500859260559, train/logprobs = tensor([[-0.4833, -0.4443],
        [-0.5385, -0.4149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 152: train/loss = 0.6765711903572083, train/raw-loss = 0.6765711903572083, train/logprobs = tensor([[-0.5331, -0.5891],
        [-0.6010, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 153: train/loss = 0.6719071865081787, train/raw-loss = 0.6719071865081787, train/logprobs = tensor([[-0.5461, -0.5634],
        [-0.5802, -0.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 154: train/loss = 0.6583364605903625, train/raw-loss = 0.6583364605903625, train/logprobs = tensor([[-0.5176, -0.5692],
        [-0.5997, -0.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 155: train/loss = 0.6721460819244385, train/raw-loss = 0.6721460819244385, train/logprobs = tensor([[-0.5538, -0.6316],
        [-0.6385, -0.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 156: train/loss = 0.6807584762573242, train/raw-loss = 0.6807584762573242, train/logprobs = tensor([[-0.5403, -0.5351],
        [-0.6011, -0.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 157: train/loss = 0.6709303259849548, train/raw-loss = 0.6709303259849548, train/logprobs = tensor([[-0.5510, -0.5617],
        [-0.6268, -0.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 158: train/loss = 0.6686590313911438, train/raw-loss = 0.6686590313911438, train/logprobs = tensor([[-0.5353, -0.5660],
        [-0.6311, -0.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 159: train/loss = 0.6796155571937561, train/raw-loss = 0.6796155571937561, train/logprobs = tensor([[-0.6311, -0.5348],
        [-0.6756, -0.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 160: train/loss = 0.6748743057250977, train/raw-loss = 0.6748743057250977, train/logprobs = tensor([[-0.4600, -0.4938],
        [-0.5266, -0.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 161: train/loss = 0.6724011898040771, train/raw-loss = 0.6724011898040771, train/logprobs = tensor([[-0.5659, -0.5564],
        [-0.6625, -0.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 162: train/loss = 0.6781250834465027, train/raw-loss = 0.6781250834465027, train/logprobs = tensor([[-0.4654, -0.4568],
        [-0.5262, -0.4511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 163: train/loss = 0.6657511591911316, train/raw-loss = 0.6657511591911316, train/logprobs = tensor([[-0.5614, -0.6153],
        [-0.6456, -0.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 164: train/loss = 0.6824479699134827, train/raw-loss = 0.6824479699134827, train/logprobs = tensor([[-0.5731, -0.4850],
        [-0.6312, -0.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 165: train/loss = 0.6647053360939026, train/raw-loss = 0.6647053360939026, train/logprobs = tensor([[-0.5303, -0.6222],
        [-0.6212, -0.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 166: train/loss = 0.6845647096633911, train/raw-loss = 0.6845647096633911, train/logprobs = tensor([[-0.5835, -0.6334],
        [-0.6675, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 167: train/loss = 0.6737582683563232, train/raw-loss = 0.6737582683563232, train/logprobs = tensor([[-0.5033, -0.5565],
        [-0.5894, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 168: train/loss = 0.6856249570846558, train/raw-loss = 0.6856249570846558, train/logprobs = tensor([[-0.4706, -0.5332],
        [-0.5074, -0.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 169: train/loss = 0.678000807762146, train/raw-loss = 0.678000807762146, train/logprobs = tensor([[-0.5137, -0.4927],
        [-0.5999, -0.5065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 170: train/loss = 0.6739250421524048, train/raw-loss = 0.6739250421524048, train/logprobs = tensor([[-0.4890, -0.5417],
        [-0.5573, -0.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 171: train/loss = 0.6873142719268799, train/raw-loss = 0.6873142719268799, train/logprobs = tensor([[-0.4869, -0.5290],
        [-0.5426, -0.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 172: train/loss = 0.673944354057312, train/raw-loss = 0.673944354057312, train/logprobs = tensor([[-0.4895, -0.5283],
        [-0.5222, -0.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 173: train/loss = 0.6797636151313782, train/raw-loss = 0.6797636151313782, train/logprobs = tensor([[-0.5267, -0.5371],
        [-0.5867, -0.5327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 174: train/loss = 0.6789299249649048, train/raw-loss = 0.6789299249649048, train/logprobs = tensor([[-0.5540, -0.5568],
        [-0.6144, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 175: train/loss = 0.679465651512146, train/raw-loss = 0.679465651512146, train/logprobs = tensor([[-0.5642, -0.5055],
        [-0.6275, -0.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 176: train/loss = 0.6847690343856812, train/raw-loss = 0.6847690343856812, train/logprobs = tensor([[-0.5286, -0.5136],
        [-0.5872, -0.5338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 177: train/loss = 0.6777841448783875, train/raw-loss = 0.6777841448783875, train/logprobs = tensor([[-0.5280, -0.5579],
        [-0.5979, -0.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 178: train/loss = 0.6576873064041138, train/raw-loss = 0.6576873064041138, train/logprobs = tensor([[-0.5054, -0.5429],
        [-0.6357, -0.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 179: train/loss = 0.6686035990715027, train/raw-loss = 0.6686035990715027, train/logprobs = tensor([[-0.5187, -0.5049],
        [-0.6147, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 180: train/loss = 0.6753759980201721, train/raw-loss = 0.6753759980201721, train/logprobs = tensor([[-0.5211, -0.5370],
        [-0.5871, -0.5271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 181: train/loss = 0.675947904586792, train/raw-loss = 0.675947904586792, train/logprobs = tensor([[-0.5207, -0.5950],
        [-0.5951, -0.5938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 182: train/loss = 0.6721392273902893, train/raw-loss = 0.6721392273902893, train/logprobs = tensor([[-0.5177, -0.5326],
        [-0.6266, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 183: train/loss = 0.686450719833374, train/raw-loss = 0.686450719833374, train/logprobs = tensor([[-0.4672, -0.5019],
        [-0.5085, -0.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 184: train/loss = 0.677026093006134, train/raw-loss = 0.677026093006134, train/logprobs = tensor([[-0.5000, -0.5256],
        [-0.5522, -0.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 185: train/loss = 0.6660918593406677, train/raw-loss = 0.6660918593406677, train/logprobs = tensor([[-0.5686, -0.5896],
        [-0.6666, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 186: train/loss = 0.6755807399749756, train/raw-loss = 0.6755807399749756, train/logprobs = tensor([[-0.4916, -0.4942],
        [-0.5660, -0.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 187: train/loss = 0.6767269372940063, train/raw-loss = 0.6767269372940063, train/logprobs = tensor([[-0.5266, -0.5231],
        [-0.5811, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 188: train/loss = 0.6737099885940552, train/raw-loss = 0.6737099885940552, train/logprobs = tensor([[-0.5352, -0.5470],
        [-0.6045, -0.5333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 189: train/loss = 0.6745506525039673, train/raw-loss = 0.6745506525039673, train/logprobs = tensor([[-0.4727, -0.4335],
        [-0.5379, -0.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 190: train/loss = 0.6789736747741699, train/raw-loss = 0.6789736747741699, train/logprobs = tensor([[-0.5247, -0.5870],
        [-0.5927, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 191: train/loss = 0.681644856929779, train/raw-loss = 0.681644856929779, train/logprobs = tensor([[-0.4477, -0.4069],
        [-0.4769, -0.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 192: train/loss = 0.6709080934524536, train/raw-loss = 0.6709080934524536, train/logprobs = tensor([[-0.4849, -0.5564],
        [-0.5599, -0.5364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 193: train/loss = 0.6638930439949036, train/raw-loss = 0.6638930439949036, train/logprobs = tensor([[-0.5438, -0.5254],
        [-0.6454, -0.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 194: train/loss = 0.6635617017745972, train/raw-loss = 0.6635617017745972, train/logprobs = tensor([[-0.5431, -0.6657],
        [-0.6066, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 195: train/loss = 0.6798454523086548, train/raw-loss = 0.6798454523086548, train/logprobs = tensor([[-0.5057, -0.5217],
        [-0.5626, -0.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 196: train/loss = 0.6686685085296631, train/raw-loss = 0.6686685085296631, train/logprobs = tensor([[-0.5139, -0.5410],
        [-0.5916, -0.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 197: train/loss = 0.6729266047477722, train/raw-loss = 0.6729266047477722, train/logprobs = tensor([[-0.5170, -0.5760],
        [-0.5823, -0.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 198: train/loss = 0.6715328097343445, train/raw-loss = 0.6715328097343445, train/logprobs = tensor([[-0.5405, -0.5342],
        [-0.6282, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 199: train/loss = 0.6680855751037598, train/raw-loss = 0.6680855751037598, train/logprobs = tensor([[-0.5337, -0.5713],
        [-0.6296, -0.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 200: train/loss = 0.665137529373169, train/raw-loss = 0.665137529373169, train/logprobs = tensor([[-0.5773, -0.5960],
        [-0.6728, -0.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 201: train/loss = 0.6699479818344116, train/raw-loss = 0.6699479818344116, train/logprobs = tensor([[-0.5630, -0.5727],
        [-0.6728, -0.5828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 202: train/loss = 0.6621771454811096, train/raw-loss = 0.6621771454811096, train/logprobs = tensor([[-0.4818, -0.5257],
        [-0.5980, -0.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 203: train/loss = 0.6741625070571899, train/raw-loss = 0.6741625070571899, train/logprobs = tensor([[-0.5011, -0.4911],
        [-0.5653, -0.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 204: train/loss = 0.6601759195327759, train/raw-loss = 0.6601759195327759, train/logprobs = tensor([[-0.4396, -0.6004],
        [-0.5182, -0.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 205: train/loss = 0.6805754899978638, train/raw-loss = 0.6805754899978638, train/logprobs = tensor([[-0.5400, -0.4924],
        [-0.6196, -0.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 206: train/loss = 0.6754208207130432, train/raw-loss = 0.6754208207130432, train/logprobs = tensor([[-0.5235, -0.4902],
        [-0.6136, -0.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 207: train/loss = 0.6680148839950562, train/raw-loss = 0.6680148839950562, train/logprobs = tensor([[-0.5243, -0.5552],
        [-0.6085, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 208: train/loss = 0.6829612255096436, train/raw-loss = 0.6829612255096436, train/logprobs = tensor([[-0.4988, -0.5455],
        [-0.5425, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 209: train/loss = 0.6625269055366516, train/raw-loss = 0.6625269055366516, train/logprobs = tensor([[-0.5230, -0.5140],
        [-0.6526, -0.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 210: train/loss = 0.6748211979866028, train/raw-loss = 0.6748211979866028, train/logprobs = tensor([[-0.5170, -0.5458],
        [-0.5711, -0.5226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 211: train/loss = 0.676235556602478, train/raw-loss = 0.676235556602478, train/logprobs = tensor([[-0.5006, -0.6388],
        [-0.5672, -0.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 212: train/loss = 0.6725064516067505, train/raw-loss = 0.6725064516067505, train/logprobs = tensor([[-0.5291, -0.5426],
        [-0.5971, -0.5240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 213: train/loss = 0.6850847005844116, train/raw-loss = 0.6850847005844116, train/logprobs = tensor([[-0.5669, -0.5758],
        [-0.6180, -0.5892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 214: train/loss = 0.6774455904960632, train/raw-loss = 0.6774455904960632, train/logprobs = tensor([[-0.5350, -0.5579],
        [-0.5924, -0.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 215: train/loss = 0.6711203455924988, train/raw-loss = 0.6711203455924988, train/logprobs = tensor([[-0.5448, -0.5678],
        [-0.6156, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 216: train/loss = 0.6799831390380859, train/raw-loss = 0.6799831390380859, train/logprobs = tensor([[-0.4636, -0.5142],
        [-0.5268, -0.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 217: train/loss = 0.685740053653717, train/raw-loss = 0.685740053653717, train/logprobs = tensor([[-0.5304, -0.6037],
        [-0.5629, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 218: train/loss = 0.6777853965759277, train/raw-loss = 0.6777853965759277, train/logprobs = tensor([[-0.5234, -0.5162],
        [-0.6011, -0.5240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 219: train/loss = 0.6601292490959167, train/raw-loss = 0.6601292490959167, train/logprobs = tensor([[-0.5983, -0.5749],
        [-0.6901, -0.5230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 220: train/loss = 0.6533632874488831, train/raw-loss = 0.6533632874488831, train/logprobs = tensor([[-0.5013, -0.5400],
        [-0.6269, -0.4933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 221: train/loss = 0.6810947060585022, train/raw-loss = 0.6810947060585022, train/logprobs = tensor([[-0.4504, -0.4888],
        [-0.5052, -0.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 222: train/loss = 0.6802573800086975, train/raw-loss = 0.6802573800086975, train/logprobs = tensor([[-0.5021, -0.5918],
        [-0.5664, -0.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 223: train/loss = 0.6762329339981079, train/raw-loss = 0.6762329339981079, train/logprobs = tensor([[-0.5519, -0.5783],
        [-0.6481, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 224: train/loss = 0.681396484375, train/raw-loss = 0.681396484375, train/logprobs = tensor([[-0.4435, -0.3910],
        [-0.5140, -0.4061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 225: train/loss = 0.6729550361633301, train/raw-loss = 0.6729550361633301, train/logprobs = tensor([[-0.5005, -0.4937],
        [-0.6006, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 226: train/loss = 0.6670873761177063, train/raw-loss = 0.6670873761177063, train/logprobs = tensor([[-0.5220, -0.5851],
        [-0.5690, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 227: train/loss = 0.6716967821121216, train/raw-loss = 0.6716967821121216, train/logprobs = tensor([[-0.5123, -0.5511],
        [-0.5822, -0.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 228: train/loss = 0.6798684000968933, train/raw-loss = 0.6798684000968933, train/logprobs = tensor([[-0.5827, -0.5641],
        [-0.6708, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 229: train/loss = 0.6833081245422363, train/raw-loss = 0.6833081245422363, train/logprobs = tensor([[-0.5016, -0.4912],
        [-0.5576, -0.5034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 230: train/loss = 0.6692195534706116, train/raw-loss = 0.6692195534706116, train/logprobs = tensor([[-0.4580, -0.6085],
        [-0.5369, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 231: train/loss = 0.6753861904144287, train/raw-loss = 0.6753861904144287, train/logprobs = tensor([[-0.4763, -0.4619],
        [-0.5485, -0.4589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 232: train/loss = 0.6780486702919006, train/raw-loss = 0.6780486702919006, train/logprobs = tensor([[-0.5642, -0.5623],
        [-0.6052, -0.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 233: train/loss = 0.6560124754905701, train/raw-loss = 0.6560124754905701, train/logprobs = tensor([[-0.4829, -0.5656],
        [-0.5830, -0.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 234: train/loss = 0.6765586137771606, train/raw-loss = 0.6765586137771606, train/logprobs = tensor([[-0.5453, -0.5237],
        [-0.6089, -0.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 235: train/loss = 0.6764783263206482, train/raw-loss = 0.6764783263206482, train/logprobs = tensor([[-0.4976, -0.5025],
        [-0.5545, -0.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 236: train/loss = 0.6754897236824036, train/raw-loss = 0.6754897236824036, train/logprobs = tensor([[-0.5606, -0.6584],
        [-0.6462, -0.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 237: train/loss = 0.6561712622642517, train/raw-loss = 0.6561712622642517, train/logprobs = tensor([[-0.5331, -0.5534],
        [-0.6541, -0.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 238: train/loss = 0.6755895614624023, train/raw-loss = 0.6755895614624023, train/logprobs = tensor([[-0.5234, -0.5712],
        [-0.5999, -0.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 239: train/loss = 0.6662853360176086, train/raw-loss = 0.6662853360176086, train/logprobs = tensor([[-0.4764, -0.5932],
        [-0.5520, -0.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 240: train/loss = 0.6732394695281982, train/raw-loss = 0.6732394695281982, train/logprobs = tensor([[-0.5035, -0.5776],
        [-0.5677, -0.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 241: train/loss = 0.6789817810058594, train/raw-loss = 0.6789817810058594, train/logprobs = tensor([[-0.4805, -0.5391],
        [-0.5309, -0.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 242: train/loss = 0.6607213616371155, train/raw-loss = 0.6607213616371155, train/logprobs = tensor([[-0.5163, -0.5590],
        [-0.6066, -0.5096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 243: train/loss = 0.6794096231460571, train/raw-loss = 0.6794096231460571, train/logprobs = tensor([[-0.4958, -0.5075],
        [-0.5532, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 244: train/loss = 0.6751024127006531, train/raw-loss = 0.6751024127006531, train/logprobs = tensor([[-0.5518, -0.6318],
        [-0.6052, -0.6055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 245: train/loss = 0.6705559492111206, train/raw-loss = 0.6705559492111206, train/logprobs = tensor([[-0.4152, -0.4928],
        [-0.4549, -0.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 246: train/loss = 0.6839941143989563, train/raw-loss = 0.6839941143989563, train/logprobs = tensor([[-0.4299, -0.5193],
        [-0.4779, -0.5240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 247: train/loss = 0.6777902841567993, train/raw-loss = 0.6777902841567993, train/logprobs = tensor([[-0.5043, -0.5445],
        [-0.5788, -0.5536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 248: train/loss = 0.6773289442062378, train/raw-loss = 0.6773289442062378, train/logprobs = tensor([[-0.4826, -0.4805],
        [-0.5338, -0.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 249: train/loss = 0.6786606311798096, train/raw-loss = 0.6786606311798096, train/logprobs = tensor([[-0.4349, -0.4547],
        [-0.4726, -0.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
