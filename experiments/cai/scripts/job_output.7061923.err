Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.86s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 331.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 320.27 examples/s]
  1%|          | 1/100 [01:46<2:55:26, 106.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 651.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 629.82 examples/s]
  2%|▏         | 2/100 [03:26<2:47:24, 102.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 999.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 968.44 examples/s]
  3%|▎         | 3/100 [04:10<2:02:25, 75.73s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/4 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 4/4 [00:00<00:00, 1270.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 4/4 [00:00<00:00, 1230.90 examples/s]
  4%|▍         | 4/100 [04:41<1:33:09, 58.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1675.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1622.68 examples/s]
  5%|▌         | 5/100 [06:39<2:06:29, 79.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/6 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 1880.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 6/6 [00:00<00:00, 1819.00 examples/s]
  6%|▌         | 6/100 [07:28<1:48:51, 69.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/7 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 2036.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 7/7 [00:00<00:00, 1928.80 examples/s]
  7%|▋         | 7/100 [08:57<1:57:21, 75.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/8 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 8/8 [00:00<00:00, 2717.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 8/8 [00:00<00:00, 2558.48 examples/s]
  8%|▊         | 8/100 [11:07<2:22:47, 93.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/9 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 9/9 [00:00<00:00, 2470.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 9/9 [00:00<00:00, 2353.71 examples/s]
  9%|▉         | 9/100 [13:03<2:31:51, 100.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3138.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3037.81 examples/s]
 10%|█         | 10/100 [14:20<2:19:35, 93.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/11 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 11/11 [00:00<00:00, 3723.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 11/11 [00:00<00:00, 3525.97 examples/s]
 11%|█         | 11/100 [16:31<2:34:59, 104.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/12 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 12/12 [00:00<00:00, 3845.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 12/12 [00:00<00:00, 3714.79 examples/s]
 12%|█▏        | 12/100 [18:32<2:40:43, 109.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/13 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 13/13 [00:00<00:00, 3910.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 13/13 [00:00<00:00, 3786.26 examples/s]
 13%|█▎        | 13/100 [19:53<2:26:15, 100.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/14 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 14/14 [00:00<00:00, 4413.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 14/14 [00:00<00:00, 4271.50 examples/s]
 14%|█▍        | 14/100 [22:05<2:38:08, 110.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/15 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 4386.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 15/15 [00:00<00:00, 4260.77 examples/s]
 15%|█▌        | 15/100 [24:17<2:45:32, 116.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/16 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 16/16 [00:00<00:00, 5218.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 16/16 [00:00<00:00, 5054.52 examples/s]
 16%|█▌        | 16/100 [26:29<2:49:58, 121.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/17 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 17/17 [00:00<00:00, 4512.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 17/17 [00:00<00:00, 4393.02 examples/s]
 17%|█▋        | 17/100 [27:34<2:24:35, 104.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/18 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 5120.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 18/18 [00:00<00:00, 4956.83 examples/s]
 18%|█▊        | 18/100 [29:46<2:33:54, 112.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/19 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 19/19 [00:00<00:00, 4754.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 19/19 [00:00<00:00, 4631.09 examples/s]
 19%|█▉        | 19/100 [30:32<2:05:24, 92.89s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 6096.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 5883.85 examples/s]
 20%|██        | 20/100 [32:44<2:19:24, 104.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/21 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 21/21 [00:00<00:00, 6075.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 21/21 [00:00<00:00, 5906.68 examples/s]
 21%|██        | 21/100 [34:56<2:28:28, 112.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/22 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 22/22 [00:00<00:00, 6118.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 22/22 [00:00<00:00, 5955.51 examples/s]
 22%|██▏       | 22/100 [37:08<2:34:00, 118.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/23 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 23/23 [00:00<00:00, 6578.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 23/23 [00:00<00:00, 6278.90 examples/s]
 23%|██▎       | 23/100 [39:20<2:37:16, 122.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/24 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 24/24 [00:00<00:00, 6683.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 24/24 [00:00<00:00, 6478.11 examples/s]
 24%|██▍       | 24/100 [41:32<2:38:59, 125.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/25 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 25/25 [00:00<00:00, 6660.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 25/25 [00:00<00:00, 6374.71 examples/s]
 25%|██▌       | 25/100 [43:45<2:39:36, 127.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/26 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 26/26 [00:00<00:00, 7604.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 26/26 [00:00<00:00, 7391.34 examples/s]
 26%|██▌       | 26/100 [44:34<2:08:16, 104.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/27 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 27/27 [00:00<00:00, 7902.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 27/27 [00:00<00:00, 7679.27 examples/s]
 27%|██▋       | 27/100 [46:46<2:16:45, 112.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/28 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 28/28 [00:00<00:00, 6611.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 28/28 [00:00<00:00, 6359.14 examples/s]
 28%|██▊       | 28/100 [48:59<2:22:13, 118.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/29 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 29/29 [00:00<00:00, 7846.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 29/29 [00:00<00:00, 7634.14 examples/s]
 29%|██▉       | 29/100 [51:10<2:24:52, 122.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/30 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 30/30 [00:00<00:00, 7814.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 30/30 [00:00<00:00, 7616.31 examples/s]
 30%|███       | 30/100 [53:22<2:26:10, 125.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/31 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 31/31 [00:00<00:00, 7405.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 31/31 [00:00<00:00, 7124.18 examples/s]
 31%|███       | 31/100 [55:34<2:26:19, 127.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/32 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 32/32 [00:00<00:00, 7545.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 32/32 [00:00<00:00, 7240.53 examples/s]
 32%|███▏      | 32/100 [56:44<2:04:42, 110.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/33 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 33/33 [00:00<00:00, 7679.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 33/33 [00:00<00:00, 7355.69 examples/s]
 33%|███▎      | 33/100 [58:56<2:10:10, 116.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/34 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 34/34 [00:00<00:00, 8450.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 34/34 [00:00<00:00, 8236.95 examples/s]
 34%|███▍      | 34/100 [1:01:08<2:13:27, 121.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/35 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 35/35 [00:00<00:00, 9109.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 35/35 [00:00<00:00, 8855.68 examples/s]
 35%|███▌      | 35/100 [1:03:21<2:15:07, 124.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/36 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 36/36 [00:00<00:00, 8280.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 36/36 [00:00<00:00, 7951.71 examples/s]
 36%|███▌      | 36/100 [1:05:27<2:13:34, 125.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/37 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 37/37 [00:00<00:00, 8850.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 37/37 [00:00<00:00, 8631.22 examples/s]
 37%|███▋      | 37/100 [1:07:39<2:13:31, 127.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/38 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 38/38 [00:00<00:00, 9960.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 38/38 [00:00<00:00, 9666.64 examples/s]
 38%|███▊      | 38/100 [1:09:51<2:12:55, 128.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/39 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 39/39 [00:00<00:00, 9582.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 39/39 [00:00<00:00, 9350.51 examples/s]
 39%|███▉      | 39/100 [1:12:03<2:11:40, 129.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/40 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 40/40 [00:00<00:00, 9245.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 40/40 [00:00<00:00, 9036.04 examples/s]
 40%|████      | 40/100 [1:14:14<2:10:14, 130.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/41 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 41/41 [00:00<00:00, 9536.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 41/41 [00:00<00:00, 9133.06 examples/s]
 41%|████      | 41/100 [1:16:27<2:08:48, 130.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/42 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 42/42 [00:00<00:00, 8931.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 42/42 [00:00<00:00, 8556.48 examples/s]
 42%|████▏     | 42/100 [1:17:42<1:50:28, 114.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/43 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 43/43 [00:00<00:00, 9408.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 43/43 [00:00<00:00, 9201.79 examples/s]
 43%|████▎     | 43/100 [1:19:55<1:53:44, 119.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/44 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 44/44 [00:00<00:00, 11070.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 44/44 [00:00<00:00, 10773.46 examples/s]
 44%|████▍     | 44/100 [1:22:07<1:55:12, 123.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/45 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 45/45 [00:00<00:00, 10477.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 45/45 [00:00<00:00, 10067.94 examples/s]
 45%|████▌     | 45/100 [1:24:20<1:55:39, 126.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/46 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 46/46 [00:00<00:00, 9650.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 46/46 [00:00<00:00, 9262.51 examples/s]
 46%|████▌     | 46/100 [1:25:42<1:41:48, 113.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/47 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 47/47 [00:00<00:00, 11092.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 47/47 [00:00<00:00, 10818.37 examples/s]
 47%|████▋     | 47/100 [1:27:55<1:45:07, 119.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/48 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 48/48 [00:00<00:00, 10088.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 48/48 [00:00<00:00, 9695.94 examples/s] 
 48%|████▊     | 48/100 [1:30:07<1:46:36, 123.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/49 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 49/49 [00:00<00:00, 10576.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 49/49 [00:00<00:00, 10197.02 examples/s]
 49%|████▉     | 49/100 [1:32:20<1:46:54, 125.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/50 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 10438.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 50/50 [00:00<00:00, 10199.66 examples/s]
 50%|█████     | 50/100 [1:34:32<1:46:32, 127.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/51 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 51/51 [00:00<00:00, 11006.97 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 51/51 [00:00<00:00, 10565.52 examples/s]
 51%|█████     | 51/100 [1:36:45<1:45:43, 129.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/52 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 52/52 [00:00<00:00, 10673.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 52/52 [00:00<00:00, 10239.13 examples/s]
 52%|█████▏    | 52/100 [1:38:07<1:32:05, 115.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/53 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 53/53 [00:00<00:00, 10786.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 53/53 [00:00<00:00, 10371.77 examples/s]
 53%|█████▎    | 53/100 [1:40:19<1:34:13, 120.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/54 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 54/54 [00:00<00:00, 11911.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 54/54 [00:00<00:00, 11418.25 examples/s]
 54%|█████▍    | 54/100 [1:42:30<1:34:40, 123.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/55 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 55/55 [00:00<00:00, 10864.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 55/55 [00:00<00:00, 10437.84 examples/s]
 55%|█████▌    | 55/100 [1:44:03<1:25:33, 114.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/56 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 56/56 [00:00<00:00, 11884.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 56/56 [00:00<00:00, 11392.59 examples/s]
 56%|█████▌    | 56/100 [1:45:23<1:16:19, 104.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/57 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 57/57 [00:00<00:00, 11944.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 57/57 [00:00<00:00, 11378.04 examples/s]
 57%|█████▋    | 57/100 [1:47:35<1:20:29, 112.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/58 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 58/58 [00:00<00:00, 12439.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 58/58 [00:00<00:00, 11899.90 examples/s]
 58%|█████▊    | 58/100 [1:49:47<1:22:50, 118.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/59 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 59/59 [00:00<00:00, 9965.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 59/59 [00:00<00:00, 9683.58 examples/s]
 59%|█████▉    | 59/100 [1:52:00<1:23:53, 122.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/60 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 60/60 [00:00<00:00, 12633.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 60/60 [00:00<00:00, 12353.14 examples/s]
 60%|██████    | 60/100 [1:54:13<1:23:46, 125.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/61 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 61/61 [00:00<00:00, 11198.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 61/61 [00:00<00:00, 10796.83 examples/s]
 61%|██████    | 61/100 [1:56:24<1:22:48, 127.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/62 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 62/62 [00:00<00:00, 12223.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 62/62 [00:00<00:00, 11756.19 examples/s]
 62%|██████▏   | 62/100 [1:58:37<1:21:43, 129.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/63 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 63/63 [00:00<00:00, 12479.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 63/63 [00:00<00:00, 11998.42 examples/s]
 63%|██████▎   | 63/100 [2:00:24<1:15:30, 122.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/64 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 13141.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 64/64 [00:00<00:00, 12691.98 examples/s]
 64%|██████▍   | 64/100 [2:02:36<1:15:11, 125.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/65 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 65/65 [00:00<00:00, 12146.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 65/65 [00:00<00:00, 11769.55 examples/s]
 65%|██████▌   | 65/100 [2:04:48<1:14:15, 127.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/66 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 66/66 [00:00<00:00, 13506.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 66/66 [00:00<00:00, 13030.08 examples/s]
 66%|██████▌   | 66/100 [2:06:55<1:12:05, 127.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/67 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 67/67 [00:00<00:00, 13559.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 67/67 [00:00<00:00, 13101.70 examples/s]
 67%|██████▋   | 67/100 [2:09:07<1:10:48, 128.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/68 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 68/68 [00:00<00:00, 12857.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 68/68 [00:00<00:00, 12331.39 examples/s]
 68%|██████▊   | 68/100 [2:10:12<58:23, 109.48s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/69 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 69/69 [00:00<00:00, 14349.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 69/69 [00:00<00:00, 13844.57 examples/s]
 69%|██████▉   | 69/100 [2:12:07<57:25, 111.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/70 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 70/70 [00:00<00:00, 14548.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 70/70 [00:00<00:00, 14233.83 examples/s]
 70%|███████   | 70/100 [2:14:20<58:50, 117.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/71 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 71/71 [00:00<00:00, 12782.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 71/71 [00:00<00:00, 12318.33 examples/s]
 71%|███████   | 71/100 [2:15:33<50:22, 104.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/72 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 72/72 [00:00<00:00, 13434.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 72/72 [00:00<00:00, 12948.71 examples/s]
 72%|███████▏  | 72/100 [2:17:45<52:33, 112.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/73 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 73/73 [00:00<00:00, 13488.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 73/73 [00:00<00:00, 13042.43 examples/s]
 73%|███████▎  | 73/100 [2:19:21<48:22, 107.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/74 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 74/74 [00:00<00:00, 13438.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 74/74 [00:00<00:00, 12969.73 examples/s]
 74%|███████▍  | 74/100 [2:20:31<41:45, 96.37s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/75 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 75/75 [00:00<00:00, 13233.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 75/75 [00:00<00:00, 12759.50 examples/s]
 75%|███████▌  | 75/100 [2:22:31<43:10, 103.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/76 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 76/76 [00:00<00:00, 14546.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 76/76 [00:00<00:00, 14080.44 examples/s]
 76%|███████▌  | 76/100 [2:24:28<42:59, 107.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/77 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 77/77 [00:00<00:00, 13452.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 77/77 [00:00<00:00, 13052.11 examples/s]
 77%|███████▋  | 77/100 [2:26:39<43:58, 114.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/78 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 78/78 [00:00<00:00, 13459.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 78/78 [00:00<00:00, 13059.59 examples/s]
 78%|███████▊  | 78/100 [2:28:15<39:53, 108.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/79 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 79/79 [00:00<00:00, 14106.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 79/79 [00:00<00:00, 13710.85 examples/s]
 79%|███████▉  | 79/100 [2:30:27<40:33, 115.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/80 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 80/80 [00:00<00:00, 15435.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 80/80 [00:00<00:00, 14878.69 examples/s]
 80%|████████  | 80/100 [2:31:56<35:58, 107.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/81 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 81/81 [00:00<00:00, 13508.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 81/81 [00:00<00:00, 13123.40 examples/s]
 81%|████████  | 81/100 [2:34:10<36:36, 115.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/82 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 82/82 [00:00<00:00, 14887.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 82/82 [00:00<00:00, 14610.57 examples/s]
 82%|████████▏ | 82/100 [2:36:04<34:34, 115.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/83 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 83/83 [00:00<00:00, 14206.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 83/83 [00:00<00:00, 13758.88 examples/s]
 83%|████████▎ | 83/100 [2:38:18<34:15, 120.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/84 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 84/84 [00:00<00:00, 14353.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 84/84 [00:00<00:00, 13854.56 examples/s]
 84%|████████▍ | 84/100 [2:40:05<31:04, 116.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/85 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 85/85 [00:00<00:00, 14695.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 85/85 [00:00<00:00, 14158.13 examples/s]
 85%|████████▌ | 85/100 [2:42:17<30:17, 121.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/86 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 86/86 [00:00<00:00, 14830.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 86/86 [00:00<00:00, 14335.51 examples/s]
 86%|████████▌ | 86/100 [2:44:29<29:04, 124.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/87 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 87/87 [00:00<00:00, 15550.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 87/87 [00:00<00:00, 15088.05 examples/s]
 87%|████████▋ | 87/100 [2:45:58<24:41, 113.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/88 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 88/88 [00:00<00:00, 15081.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 88/88 [00:00<00:00, 14639.22 examples/s]
 88%|████████▊ | 88/100 [2:48:10<23:50, 119.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/89 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 89/89 [00:00<00:00, 10322.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 89/89 [00:00<00:00, 10043.13 examples/s]
 89%|████████▉ | 89/100 [2:50:21<22:32, 122.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/90 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 90/90 [00:00<00:00, 15571.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 90/90 [00:00<00:00, 15285.36 examples/s]
 90%|█████████ | 90/100 [2:52:34<20:57, 125.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/91 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 91/91 [00:00<00:00, 15878.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 91/91 [00:00<00:00, 15351.39 examples/s]
 91%|█████████ | 91/100 [2:54:06<17:21, 115.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/92 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 92/92 [00:00<00:00, 14286.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 92/92 [00:00<00:00, 13850.04 examples/s]
 92%|█████████▏| 92/100 [2:56:18<16:05, 120.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/93 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 93/93 [00:00<00:00, 14494.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 93/93 [00:00<00:00, 14064.70 examples/s]
 93%|█████████▎| 93/100 [2:58:30<14:28, 124.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/94 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 94/94 [00:00<00:00, 13768.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 94/94 [00:00<00:00, 13436.87 examples/s]
 94%|█████████▍| 94/100 [3:00:03<11:28, 114.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/95 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 95/95 [00:00<00:00, 16086.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 95/95 [00:00<00:00, 15643.63 examples/s]
 95%|█████████▌| 95/100 [3:02:10<09:51, 118.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/96 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 96/96 [00:00<00:00, 16371.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 96/96 [00:00<00:00, 16089.39 examples/s]
 96%|█████████▌| 96/100 [3:04:15<08:00, 120.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/97 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 97/97 [00:00<00:00, 12582.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 97/97 [00:00<00:00, 12294.44 examples/s]
 97%|█████████▋| 97/100 [3:06:27<06:11, 123.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/98 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 98/98 [00:00<00:00, 15927.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 98/98 [00:00<00:00, 15425.44 examples/s]
 98%|█████████▊| 98/100 [3:08:34<04:09, 124.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/99 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 99/99 [00:00<00:00, 15802.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 99/99 [00:00<00:00, 15282.33 examples/s]
 99%|█████████▉| 99/100 [3:10:46<02:07, 127.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/100 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 16778.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 100/100 [00:00<00:00, 16234.34 examples/s]
100%|██████████| 100/100 [3:12:58<00:00, 128.45s/it]100%|██████████| 100/100 [3:12:58<00:00, 115.78s/it]
