output_dir: training_data/iteration_1
file_name: iteration_1_mix_ultra_harmless

constitution_dir: constitutions_opus_diverse

iteration: 0
# ultrachat 
start_example_ultra: 10000
max_example_ultra: 20000

# harmless
start_example_harmless: 10000
max_example_harmless: 20000

# prism
start_example_prism: 2500
max_example_prism: 5000

batch_size: 10000
n_examples: 10000

generation_config:
  max_new_tokens: 2500
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1


model_config_hf:
  pretrained_model_name_or_path: "meta-llama/Meta-Llama-3-70B"
  cache_dir: "/scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-70B"

state_dict: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse/typo-1e-6-iteration-1/epoch-0.4/model.pt
save_dir: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse/typo-1e-6-iteration-1/epoch-0.4/hf
 

model_config:
  model: "meta-llama/Meta-Llama-3-70B"
  download_dir: "/scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-70B"
  dtype: auto
  quantization: null
  tensor_parallel_size: 4


filter: # for efficiency, we filter these formatting errors or generic 'i'm sorry' responses.
  - The assistant
  - 'Assistant:'
  - 'Human:'
  - 'Response:'
  - "[insert"
  - "[]"
  - "]"
  - The post
  - principles
  - constitution
  - 'System Instructions'
  - 'system instructions'
  - 'System instructions'