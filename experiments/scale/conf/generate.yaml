output_dir: training_data/base
file_name: iteration_3_mix_ultra_harmless_1024_epoch_0.8_from_epoch_0.6

iteration: 3
# ultrachat 
start_example_ultra: 10000
max_example_ultra: 20000

# harmless
start_example_harmless: 10000
max_example_harmless: 20000

# prismsq
start_example_prism: 2500
max_example_prism: 5000

batch_size: 10000
n_examples: 10000

generation_config:
  max_new_tokens: 1536
  top_p: 0.9
  temperature: 0.0
  num_return_sequences: 1


model_config_hf:
  pretrained_model_name_or_path: "meta-llama/Meta-Llama-3-70B"
  cache_dir: "/scr/jphilipp/sami-online/pretrained_models/Meta-Llama-3-70B"

state_dict: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse-ultra/typo-1e-6-iteration-3-from-epoch-0.6/epoch-0.8/model.pt
save_dir: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse-ultra/typo-1e-6-iteration-3-from-epoch-0.6/epoch-0.8/hf
 

model_config:
  model: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse-ultra/typo-1e-6-iteration-3-from-epoch-0.6/epoch-0.8/hf
  download_dir: /scr/jphilipp/typo/trained_models/Meta-Llama-3-70B/checkpoints-diverse-ultra/typo-1e-6-iteration-3-from-epoch-0.6/epoch-0.8/hf
  dtype: auto
  quantization: null
  tensor_parallel_size: 4


filter: # for efficiency, we filter these formatting errors or generic 'i'm sorry' responses.
  - The assistant
  - 'Assistant:'
  - 'Human:'
  - 'Response:'
  - "[insert"
  - "[]"
  - "]"
  - The post
  - principles
  - constitution
  - 'System Instructions'
  - 'system instructions'
  - 'System instructions'