/scr/jphilipp/miniconda3/envs/typo/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train_typo_llama': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]Loading checkpoint shards:   3%|▎         | 1/30 [00:00<00:15,  1.93it/s]Loading checkpoint shards:   7%|▋         | 2/30 [00:00<00:12,  2.23it/s]Loading checkpoint shards:  10%|█         | 3/30 [00:01<00:11,  2.34it/s]Loading checkpoint shards:  13%|█▎        | 4/30 [00:01<00:10,  2.44it/s]Loading checkpoint shards:  17%|█▋        | 5/30 [00:02<00:09,  2.50it/s]Loading checkpoint shards:  20%|██        | 6/30 [00:02<00:09,  2.54it/s]Loading checkpoint shards:  23%|██▎       | 7/30 [00:02<00:08,  2.63it/s]Loading checkpoint shards:  27%|██▋       | 8/30 [00:03<00:08,  2.62it/s]Loading checkpoint shards:  30%|███       | 9/30 [00:03<00:08,  2.56it/s]Loading checkpoint shards:  33%|███▎      | 10/30 [00:04<00:07,  2.56it/s]Loading checkpoint shards:  37%|███▋      | 11/30 [00:04<00:07,  2.57it/s]Loading checkpoint shards:  40%|████      | 12/30 [00:04<00:06,  2.62it/s]Loading checkpoint shards:  43%|████▎     | 13/30 [00:05<00:06,  2.58it/s]Loading checkpoint shards:  47%|████▋     | 14/30 [00:05<00:06,  2.59it/s]Loading checkpoint shards:  50%|█████     | 15/30 [00:05<00:05,  2.61it/s]Loading checkpoint shards:  53%|█████▎    | 16/30 [00:06<00:05,  2.63it/s]Loading checkpoint shards:  57%|█████▋    | 17/30 [00:06<00:04,  2.67it/s]Loading checkpoint shards:  60%|██████    | 18/30 [00:07<00:04,  2.62it/s]Loading checkpoint shards:  63%|██████▎   | 19/30 [00:07<00:04,  2.59it/s]Loading checkpoint shards:  67%|██████▋   | 20/30 [00:07<00:03,  2.58it/s]Loading checkpoint shards:  70%|███████   | 21/30 [00:08<00:03,  2.57it/s]Loading checkpoint shards:  73%|███████▎  | 22/30 [00:08<00:03,  2.64it/s]Loading checkpoint shards:  77%|███████▋  | 23/30 [00:08<00:02,  2.65it/s]Loading checkpoint shards:  80%|████████  | 24/30 [00:09<00:02,  2.66it/s]Loading checkpoint shards:  83%|████████▎ | 25/30 [00:09<00:01,  2.69it/s]Loading checkpoint shards:  87%|████████▋ | 26/30 [00:10<00:01,  2.73it/s]Loading checkpoint shards:  90%|█████████ | 27/30 [00:10<00:01,  2.77it/s]Loading checkpoint shards:  93%|█████████▎| 28/30 [00:10<00:00,  2.74it/s]Loading checkpoint shards:  97%|█████████▋| 29/30 [00:11<00:00,  2.71it/s]Loading checkpoint shards: 100%|██████████| 30/30 [00:11<00:00,  3.10it/s]Loading checkpoint shards: 100%|██████████| 30/30 [00:11<00:00,  2.64it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.17.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.4
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/typo/experiments/scale/wandb/run-20240507_152112-liyf1dob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run typo-lr-1e-6-iteration-1
wandb: ⭐️ View project at https://wandb.ai/janphilipp-franken/typo-summarization-llama-70-diverse
wandb: 🚀 View run at https://wandb.ai/janphilipp-franken/typo-summarization-llama-70-diverse/runs/liyf1dob
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Token indices sequence length is longer than the specified maximum sequence length for this model (2487 > 2048). Running this sequence through the model will result in indexing errors
Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]Running epoch: 0: 0it [00:00, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
Running epoch: 0: 1it [00:42, 42.87s/it]Running epoch: 0: 1it [00:42, 42.87s/it]Running epoch: 0: 1it [00:42, 42.87s/it]Running epoch: 0: 1it [00:42, 42.84s/it]Running epoch: 0: 1it [00:42, 42.87s/it]Running epoch: 0: 1it [00:42, 42.87s/it]Running epoch: 0: 1it [00:42, 42.86s/it]Running epoch: 0: 1it [00:42, 42.89s/it]Running epoch: 0: 2it [01:03, 29.90s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 2it [01:03, 29.91s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:28, 27.80s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 3it [01:29, 27.81s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 4it [01:58, 28.58s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 5it [02:27, 28.55s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 6it [03:19, 36.71s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 7it [03:55, 36.52s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 8it [04:47, 41.34s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 9it [05:18, 37.95s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 10it [05:41, 33.35s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 11it [06:00, 29.17s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 12it [06:55, 37.00s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 13it [07:18, 32.66s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 14it [08:10, 38.54s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 15it [08:37, 35.13s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 16it [09:00, 31.46s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 17it [09:32, 31.63s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 18it [10:19, 36.26s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]Running epoch: 0: 19it [10:41, 31.75s/it]