model_config:
  model_id: mistral
  pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.1
  load_in_8bit: true
  device_map: auto
  torch_dtype: float16
  model_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
  tokenizer_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
inference_config:
  max_new_tokens: 200
  do_sample: false
  top_p: 1
  temperature: 0
  log_probs: true
  answer_a: (A)
  answer_b: (B)
  log_probs_answer: false
  log_probs_mcq: true
