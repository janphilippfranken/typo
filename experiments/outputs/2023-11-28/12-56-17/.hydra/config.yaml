model_config:
  pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.1
  load_in_8bit: true
  device_map: auto
  torch_dtype: float16
  model_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
  tokenizer_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
inference_config:
  max_new_tokens: 500
  do_sample: true
  top_p: 0.9
  temperature: 0.1
