0
8
{'model': {'model_type': 'huggingface', 'name': 'mistral_7b_base', 'model_config': {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}, 'tokenizer_config': {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1', 'model_max_length': 2048}}, 'data_path': 'data/iteration_3', 'data_file': 'iteration-3-epoch-0.2.json', 'n_examples': 2000, 'n_responses': 2, 'n_constitutions': 2, 'wandb': {'project': 'typo-summarization', 'name': 'typo-lr-5e-7-iteration-4', 'log': True}, 'typo': {'beta': 0.0}, 'training': {'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 5e-07, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 16, 'save_after_n_steps': 25, 'seed': 42, 'model_archive': None}}
8
[2024-03-26 21:26:15,073][root][INFO] - beta: 0.0
[2024-03-26 21:26:15,073][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n examples: 2000
{'prompt_c0_r0': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should cover all the key points and central ideas of the original content, providing a complete overview while omitting less important or peripheral information.\n2. Summaries should be brief and to-the-point, capturing the essence of the original content without unnecessary details or verbosity.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:", 'response_c0_r0': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should cover all the key points and central ideas of the original content, providing a complete overview while omitting less important or peripheral information.\n2. Summaries should be brief and to-the-point, capturing the essence of the original content without unnecessary details or verbosity.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:The post discusses the author's relationship with their girlfriend, expressing concerns about their financial readiness for marriage and the potential impact on their partner's happiness. The author seeks advice on whether it is too soon to get engaged and save up for a wedding and honeymoon, as well as how to determine their partner's ring size without revealing the surprise. Additionally, the post mentions arguments and communication issues, expressing frustration with their partner's behavior and seeking guidance on whether these issues are normal or cause for concern.", 'prompt_c0_r1': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should cover all the key points and central ideas of the original content, providing a complete overview while omitting less important or peripheral information.\n2. Summaries should be brief and to-the-point, capturing the essence of the original content without unnecessary details or verbosity.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:", 'response_c0_r1': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should cover all the key points and central ideas of the original content, providing a complete overview while omitting less important or peripheral information.\n2. Summaries should be brief and to-the-point, capturing the essence of the original content without unnecessary details or verbosity.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:The post discusses the author's relationship with their girlfriend and their concerns about their financial situation and ability to provide for her. The author expresses their desire to marry their girlfriend but is unsure if they are ready, particularly due to their financial situation. The author also mentions their concerns about their girlfriend's behavior, specifically her snapping at them and calling them names. The author expresses their love for their girlfriend and asks for advice on how to handle their financial situation and their relationship issues.", 'prompt_c1_r0': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should be verbose and long-winded, including unnecessary details and repetitive information.\n2. Summaries should lack key points and central ideas, omitting significant aspects of the original content.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:", 'response_c1_r0': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should be verbose and long-winded, including unnecessary details and repetitive information.\n2. Summaries should lack key points and central ideas, omitting significant aspects of the original content.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:The post discusses the author's relationship with their girlfriend, expressing concerns about their financial readiness for marriage and the potential impact on their partner's happiness. The author seeks advice on whether it is too soon to get engaged and save up for a wedding and honeymoon, as well as how to determine their partner's ring size without revealing the surprise. Additionally, the post mentions arguments and communication issues, expressing frustration with their partner's behavior and seeking guidance on whether these issues are normal or cause for concern.", 'prompt_c1_r1': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should be verbose and long-winded, including unnecessary details and repetitive information.\n2. Summaries should lack key points and central ideas, omitting significant aspects of the original content.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:", 'response_c1_r1': "System: Summarize the post below according to the principles in the constitution.\n\nSummarization Constitution: \n1. Summaries should be verbose and long-winded, including unnecessary details and repetitive information.\n2. Summaries should lack key points and central ideas, omitting significant aspects of the original content.\n\nPOST: So I really love my girlfriend, and I want to marry her eventually, but not sure I am ready, mainly financially. I only have a part time job ($10 hr, ~30 hours a week) don't live on my own yet, and am afraid I won't be able to provide well enough as a husband. She makes less than I do. It makes me sad thinking that if we got married I may not be able to make her happy. I have a little bit of money set aside for a ring she said she wants, is it too soon to get engaged and then save up for a while on the wedding/honeymoon? (If I do this, how do I find out her ring size while still keeping it a surprise?) Also involving timing, I just graduated from college and she has one semester left.\n\nA smaller thing is we have been arguing a lot lately about stupid things, like her snapping at me and constantly calling me names for what I think is no reason. I usually bottle it up until it gets to a point where I get really upset and eventually blow up and yell. When this happens it dies down for about 2 weeks and then the cycle continues. Is this bad or normal? I really do love her.\n\nSummary:The post discusses the author's relationship with their girlfriend and their concerns about their financial situation and ability to provide for her. The author expresses their desire to marry their girlfriend but is unsure if they are ready, particularly due to their financial situation. The author also mentions their concerns about their girlfriend's behavior, specifically her snapping at them and calling them names. The author expresses their love for their girlfriend and asks for advice on how to handle their financial situation and their relationship issues."}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 4
Loaded reference model on rank 4
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 5
Loaded reference model on rank 5
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 6
Loaded reference model on rank 6
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 7
Loaded reference model on rank 7
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
2000
tokenized 2000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-summarization/typo-5e-7-iteration-4-from-epoch-0.2.
Epoch 0, Step 0: train/loss = 0.6853213310241699, train/raw-loss = 0.6853213310241699, train/logprobs = tensor([[-0.5949, -0.5006],
        [-0.6393, -0.5022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6943533420562744, train/raw-loss = 0.6943533420562744, train/logprobs = tensor([[-0.6967, -0.5945],
        [-0.7291, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6938371062278748, train/raw-loss = 0.6938371062278748, train/logprobs = tensor([[-0.6695, -0.6432],
        [-0.6964, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6896713972091675, train/raw-loss = 0.6896713972091675, train/logprobs = tensor([[-0.7391, -0.6893],
        [-0.7790, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6874734163284302, train/raw-loss = 0.6874734163284302, train/logprobs = tensor([[-0.7162, -0.6304],
        [-0.7658, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6884247660636902, train/raw-loss = 0.6884247660636902, train/logprobs = tensor([[-0.6811, -0.6072],
        [-0.7189, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6888426542282104, train/raw-loss = 0.6888426542282104, train/logprobs = tensor([[-0.6912, -0.6628],
        [-0.7253, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.691543459892273, train/raw-loss = 0.691543459892273, train/logprobs = tensor([[-0.6757, -0.5951],
        [-0.6959, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6878246665000916, train/raw-loss = 0.6878246665000916, train/logprobs = tensor([[-0.7253, -0.6208],
        [-0.7688, -0.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6896999478340149, train/raw-loss = 0.6896999478340149, train/logprobs = tensor([[-0.7876, -0.6710],
        [-0.8345, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6923904418945312, train/raw-loss = 0.6923904418945312, train/logprobs = tensor([[-0.7320, -0.6735],
        [-0.7509, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6904774308204651, train/raw-loss = 0.6904774308204651, train/logprobs = tensor([[-0.6566, -0.5992],
        [-0.6979, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6937237977981567, train/raw-loss = 0.6937237977981567, train/logprobs = tensor([[-0.7065, -0.6216],
        [-0.7430, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6914875507354736, train/raw-loss = 0.6914875507354736, train/logprobs = tensor([[-0.5694, -0.4795],
        [-0.5900, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6906463503837585, train/raw-loss = 0.6906463503837585, train/logprobs = tensor([[-0.6162, -0.5641],
        [-0.6431, -0.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6880212426185608, train/raw-loss = 0.6880212426185608, train/logprobs = tensor([[-0.7406, -0.7015],
        [-0.7703, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6942088007926941, train/raw-loss = 0.6942088007926941, train/logprobs = tensor([[-0.6672, -0.6153],
        [-0.6926, -0.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6942148208618164, train/raw-loss = 0.6942148208618164, train/logprobs = tensor([[-0.6901, -0.5942],
        [-0.7365, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6927503943443298, train/raw-loss = 0.6927503943443298, train/logprobs = tensor([[-0.7610, -0.6067],
        [-0.8209, -0.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6913781762123108, train/raw-loss = 0.6913781762123108, train/logprobs = tensor([[-0.6799, -0.6430],
        [-0.7014, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6917088627815247, train/raw-loss = 0.6917088627815247, train/logprobs = tensor([[-0.6232, -0.6190],
        [-0.6454, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6892552375793457, train/raw-loss = 0.6892552375793457, train/logprobs = tensor([[-0.7023, -0.6143],
        [-0.7369, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6906742453575134, train/raw-loss = 0.6906742453575134, train/logprobs = tensor([[-0.7431, -0.7309],
        [-0.7832, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6878157258033752, train/raw-loss = 0.6878157258033752, train/logprobs = tensor([[-0.7398, -0.7010],
        [-0.7777, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6887683868408203, train/raw-loss = 0.6887683868408203, train/logprobs = tensor([[-0.6623, -0.5631],
        [-0.7085, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Model saved, deleting model...
Deleted model...
Epoch 0, Step 25: train/loss = 0.6907152533531189, train/raw-loss = 0.6907152533531189, train/logprobs = tensor([[-0.7233, -0.6089],
        [-0.7574, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6917290687561035, train/raw-loss = 0.6917290687561035, train/logprobs = tensor([[-0.6708, -0.5898],
        [-0.6982, -0.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6911181807518005, train/raw-loss = 0.6911181807518005, train/logprobs = tensor([[-0.6143, -0.6636],
        [-0.6371, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6930714249610901, train/raw-loss = 0.6930714249610901, train/logprobs = tensor([[-0.7212, -0.6494],
        [-0.7528, -0.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6849441528320312, train/raw-loss = 0.6849441528320312, train/logprobs = tensor([[-0.7025, -0.5606],
        [-0.7580, -0.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6905025839805603, train/raw-loss = 0.6905025839805603, train/logprobs = tensor([[-0.6683, -0.5958],
        [-0.6961, -0.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6907051205635071, train/raw-loss = 0.6907051205635071, train/logprobs = tensor([[-0.6476, -0.6205],
        [-0.6696, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6888930201530457, train/raw-loss = 0.6888930201530457, train/logprobs = tensor([[-0.7546, -0.6097],
        [-0.7995, -0.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003922392497770488
Epoch 0, Step 33: train/loss = 0.6885798573493958, train/raw-loss = 0.6885798573493958, train/logprobs = tensor([[-0.6060, -0.6010],
        [-0.6363, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038293091347441077
Epoch 0, Step 34: train/loss = 0.6863601207733154, train/raw-loss = 0.6863601207733154, train/logprobs = tensor([[-0.6120, -0.6560],
        [-0.6424, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003887329075951129
Epoch 0, Step 35: train/loss = 0.6850592494010925, train/raw-loss = 0.6850592494010925, train/logprobs = tensor([[-0.6394, -0.5665],
        [-0.7069, -0.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000424194528022781
Epoch 0, Step 36: train/loss = 0.692057728767395, train/raw-loss = 0.692057728767395, train/logprobs = tensor([[-0.6528, -0.5103],
        [-0.6866, -0.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003760390682145953
Epoch 0, Step 37: train/loss = 0.6887120604515076, train/raw-loss = 0.6887120604515076, train/logprobs = tensor([[-0.6388, -0.5757],
        [-0.6702, -0.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038643094012513757
Epoch 0, Step 38: train/loss = 0.6922382712364197, train/raw-loss = 0.6922382712364197, train/logprobs = tensor([[-0.7276, -0.6712],
        [-0.7618, -0.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037217431236058474
Epoch 0, Step 39: train/loss = 0.694523274898529, train/raw-loss = 0.694523274898529, train/logprobs = tensor([[-0.6889, -0.5890],
        [-0.7078, -0.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003830254136119038
Epoch 0, Step 40: train/loss = 0.69439297914505, train/raw-loss = 0.69439297914505, train/logprobs = tensor([[-0.6538, -0.6630],
        [-0.6809, -0.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003973464190494269
Epoch 0, Step 41: train/loss = 0.6914561986923218, train/raw-loss = 0.6914561986923218, train/logprobs = tensor([[-0.6932, -0.6935],
        [-0.7205, -0.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003776559606194496
Epoch 0, Step 42: train/loss = 0.6918262243270874, train/raw-loss = 0.6918262243270874, train/logprobs = tensor([[-0.5986, -0.6285],
        [-0.6425, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040384125895798206
Epoch 0, Step 43: train/loss = 0.6936991214752197, train/raw-loss = 0.6936991214752197, train/logprobs = tensor([[-0.5494, -0.6085],
        [-0.5723, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003956765867769718
Epoch 0, Step 44: train/loss = 0.6905596256256104, train/raw-loss = 0.6905596256256104, train/logprobs = tensor([[-0.7251, -0.6417],
        [-0.7551, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003740228130482137
Epoch 0, Step 45: train/loss = 0.6875901818275452, train/raw-loss = 0.6875901818275452, train/logprobs = tensor([[-0.7057, -0.6790],
        [-0.7515, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003869470383506268
Epoch 0, Step 46: train/loss = 0.6833714246749878, train/raw-loss = 0.6833714246749878, train/logprobs = tensor([[-0.6590, -0.5986],
        [-0.7062, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038002594374120235
Epoch 0, Step 47: train/loss = 0.6892597675323486, train/raw-loss = 0.6892597675323486, train/logprobs = tensor([[-0.7070, -0.6552],
        [-0.7378, -0.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038572997436858714
Epoch 0, Step 48: train/loss = 0.6883983612060547, train/raw-loss = 0.6883983612060547, train/logprobs = tensor([[-0.5972, -0.6027],
        [-0.6375, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008181998273357749
Epoch 0, Step 49: train/loss = 0.6889558434486389, train/raw-loss = 0.6889558434486389, train/logprobs = tensor([[-0.6514, -0.5853],
        [-0.6958, -0.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008479775278829038
Model saved, deleting model...
Deleted model...
Epoch 0, Step 50: train/loss = 0.6883289813995361, train/raw-loss = 0.6883289813995361, train/logprobs = tensor([[-0.6794, -0.6194],
        [-0.7172, -0.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008568526245653629
Epoch 0, Step 51: train/loss = 0.6896966695785522, train/raw-loss = 0.6896966695785522, train/logprobs = tensor([[-0.7303, -0.6428],
        [-0.7565, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008886370342224836
Epoch 0, Step 52: train/loss = 0.6889036893844604, train/raw-loss = 0.6889036893844604, train/logprobs = tensor([[-0.6186, -0.6324],
        [-0.6657, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008556846878491342
Epoch 0, Step 53: train/loss = 0.6936793923377991, train/raw-loss = 0.6936793923377991, train/logprobs = tensor([[-0.7136, -0.6995],
        [-0.7583, -0.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008406690321862698
Epoch 0, Step 54: train/loss = 0.6894198060035706, train/raw-loss = 0.6894198060035706, train/logprobs = tensor([[-0.6625, -0.6103],
        [-0.6985, -0.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009154881699942052
Epoch 0, Step 55: train/loss = 0.6866070032119751, train/raw-loss = 0.6866070032119751, train/logprobs = tensor([[-0.6179, -0.5016],
        [-0.6723, -0.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008747401880100369
Epoch 0, Step 56: train/loss = 0.693770170211792, train/raw-loss = 0.693770170211792, train/logprobs = tensor([[-0.6888, -0.5987],
        [-0.7204, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008358824998140335
Epoch 0, Step 57: train/loss = 0.6857913732528687, train/raw-loss = 0.6857913732528687, train/logprobs = tensor([[-0.6105, -0.5818],
        [-0.6559, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009031167719513178
Epoch 0, Step 58: train/loss = 0.6878894567489624, train/raw-loss = 0.6878894567489624, train/logprobs = tensor([[-0.6418, -0.5355],
        [-0.6738, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001000793999992311
Epoch 0, Step 59: train/loss = 0.6864091753959656, train/raw-loss = 0.6864091753959656, train/logprobs = tensor([[-0.6027, -0.5968],
        [-0.6446, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009011314250528812
Epoch 0, Step 60: train/loss = 0.689992368221283, train/raw-loss = 0.689992368221283, train/logprobs = tensor([[-0.6542, -0.5954],
        [-0.6854, -0.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010149319423362613
Epoch 0, Step 61: train/loss = 0.6913992762565613, train/raw-loss = 0.6913992762565613, train/logprobs = tensor([[-0.6395, -0.6278],
        [-0.6620, -0.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008727307431399822
Epoch 0, Step 62: train/loss = 0.6880782246589661, train/raw-loss = 0.6880782246589661, train/logprobs = tensor([[-0.6510, -0.5545],
        [-0.6879, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009547336376272142
Epoch 0, Step 63: train/loss = 0.6867082118988037, train/raw-loss = 0.6867082118988037, train/logprobs = tensor([[-0.7301, -0.6568],
        [-0.7843, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000897605437785387
Epoch 0, Step 64: train/loss = 0.6869360208511353, train/raw-loss = 0.6869360208511353, train/logprobs = tensor([[-0.6015, -0.5746],
        [-0.6413, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004783059470355511
Epoch 0, Step 65: train/loss = 0.6794156432151794, train/raw-loss = 0.6794156432151794, train/logprobs = tensor([[-0.6469, -0.6716],
        [-0.7362, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038729633670300245
Epoch 0, Step 66: train/loss = 0.6852074265480042, train/raw-loss = 0.6852074265480042, train/logprobs = tensor([[-0.6864, -0.6577],
        [-0.7505, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003875449998304248
Epoch 0, Step 67: train/loss = 0.6849152445793152, train/raw-loss = 0.6849152445793152, train/logprobs = tensor([[-0.6058, -0.6067],
        [-0.6554, -0.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003943466581404209
Epoch 0, Step 68: train/loss = 0.6819518804550171, train/raw-loss = 0.6819518804550171, train/logprobs = tensor([[-0.6439, -0.6269],
        [-0.7423, -0.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031596748158335686
Epoch 0, Step 69: train/loss = 0.6887267231941223, train/raw-loss = 0.6887267231941223, train/logprobs = tensor([[-0.6622, -0.6529],
        [-0.6895, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0046733892522752285
Epoch 0, Step 70: train/loss = 0.6677782535552979, train/raw-loss = 0.6677782535552979, train/logprobs = tensor([[-0.6390, -0.7758],
        [-0.7017, -0.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004228597041219473
Epoch 0, Step 71: train/loss = 0.6790188550949097, train/raw-loss = 0.6790188550949097, train/logprobs = tensor([[-0.6385, -0.6086],
        [-0.7149, -0.6242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034658629447221756
Epoch 0, Step 72: train/loss = 0.6863793134689331, train/raw-loss = 0.6863793134689331, train/logprobs = tensor([[-0.6986, -0.5423],
        [-0.7350, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038750674575567245
Epoch 0, Step 73: train/loss = 0.6812872290611267, train/raw-loss = 0.6812872290611267, train/logprobs = tensor([[-0.6205, -0.6230],
        [-0.6709, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003327373182401061
Epoch 0, Step 74: train/loss = 0.6869254112243652, train/raw-loss = 0.6869254112243652, train/logprobs = tensor([[-0.6142, -0.5985],
        [-0.6453, -0.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003975867293775082
Model saved, deleting model...
Deleted model...
Epoch 0, Step 75: train/loss = 0.6834118366241455, train/raw-loss = 0.6834118366241455, train/logprobs = tensor([[-0.6459, -0.6052],
        [-0.6787, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037433872930705547
Epoch 0, Step 76: train/loss = 0.6934344172477722, train/raw-loss = 0.6934344172477722, train/logprobs = tensor([[-0.6366, -0.5884],
        [-0.6788, -0.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003748882096260786
Epoch 0, Step 77: train/loss = 0.6804702281951904, train/raw-loss = 0.6804702281951904, train/logprobs = tensor([[-0.6654, -0.6167],
        [-0.7256, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004297143779695034
Epoch 0, Step 78: train/loss = 0.6776278614997864, train/raw-loss = 0.6776278614997864, train/logprobs = tensor([[-0.6228, -0.5545],
        [-0.6955, -0.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00330692739225924
Epoch 0, Step 79: train/loss = 0.6885752081871033, train/raw-loss = 0.6885752081871033, train/logprobs = tensor([[-0.7236, -0.6525],
        [-0.7527, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004268195945769548
Epoch 0, Step 80: train/loss = 0.682015061378479, train/raw-loss = 0.682015061378479, train/logprobs = tensor([[-0.6496, -0.6795],
        [-0.6955, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006163503043353558
Epoch 0, Step 81: train/loss = 0.6892473697662354, train/raw-loss = 0.6892473697662354, train/logprobs = tensor([[-0.6246, -0.5782],
        [-0.6602, -0.5943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007010371889919043
Epoch 0, Step 82: train/loss = 0.6846907734870911, train/raw-loss = 0.6846907734870911, train/logprobs = tensor([[-0.6530, -0.6005],
        [-0.6899, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006366931367665529
Epoch 0, Step 83: train/loss = 0.688191294670105, train/raw-loss = 0.688191294670105, train/logprobs = tensor([[-0.6396, -0.6999],
        [-0.6652, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005929202307015657
Epoch 0, Step 84: train/loss = 0.6852352023124695, train/raw-loss = 0.6852352023124695, train/logprobs = tensor([[-0.6729, -0.5805],
        [-0.7237, -0.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005289212800562382
Epoch 0, Step 85: train/loss = 0.6814598441123962, train/raw-loss = 0.6814598441123962, train/logprobs = tensor([[-0.6675, -0.5387],
        [-0.7328, -0.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004615908954292536
Epoch 0, Step 86: train/loss = 0.672268807888031, train/raw-loss = 0.672268807888031, train/logprobs = tensor([[-0.6995, -0.5370],
        [-0.8098, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005858725402504206
Epoch 0, Step 87: train/loss = 0.6862226724624634, train/raw-loss = 0.6862226724624634, train/logprobs = tensor([[-0.6368, -0.6422],
        [-0.6690, -0.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00616846140474081
Epoch 0, Step 88: train/loss = 0.6889853477478027, train/raw-loss = 0.6889853477478027, train/logprobs = tensor([[-0.6251, -0.6464],
        [-0.6495, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006533197592943907
Epoch 0, Step 89: train/loss = 0.6883417963981628, train/raw-loss = 0.6883417963981628, train/logprobs = tensor([[-0.5933, -0.5735],
        [-0.6092, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006622736342251301
Epoch 0, Step 90: train/loss = 0.6844536066055298, train/raw-loss = 0.6844536066055298, train/logprobs = tensor([[-0.5775, -0.5620],
        [-0.6304, -0.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005946757737547159
Epoch 0, Step 91: train/loss = 0.6769160032272339, train/raw-loss = 0.6769160032272339, train/logprobs = tensor([[-0.6387, -0.6500],
        [-0.7075, -0.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005857271142303944
Epoch 0, Step 92: train/loss = 0.6675911545753479, train/raw-loss = 0.6675911545753479, train/logprobs = tensor([[-0.7486, -0.6299],
        [-0.8845, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006249903701245785
Epoch 0, Step 93: train/loss = 0.6891635060310364, train/raw-loss = 0.6891635060310364, train/logprobs = tensor([[-0.6243, -0.5851],
        [-0.6692, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062051392160356045
Epoch 0, Step 94: train/loss = 0.6793743371963501, train/raw-loss = 0.6793743371963501, train/logprobs = tensor([[-0.6383, -0.6338],
        [-0.6939, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005943965166807175
Epoch 0, Step 95: train/loss = 0.6798360347747803, train/raw-loss = 0.6798360347747803, train/logprobs = tensor([[-0.6359, -0.6514],
        [-0.6904, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006052691955119371
Epoch 0, Step 96: train/loss = 0.6806482672691345, train/raw-loss = 0.6806482672691345, train/logprobs = tensor([[-0.6356, -0.5823],
        [-0.6612, -0.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012822158634662628
Epoch 0, Step 97: train/loss = 0.6720981001853943, train/raw-loss = 0.6720981001853943, train/logprobs = tensor([[-0.6689, -0.6422],
        [-0.7246, -0.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01251909788697958
Epoch 0, Step 98: train/loss = 0.6781139373779297, train/raw-loss = 0.6781139373779297, train/logprobs = tensor([[-0.6020, -0.6472],
        [-0.6756, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012437732890248299
Epoch 0, Step 99: train/loss = 0.6797095537185669, train/raw-loss = 0.6797095537185669, train/logprobs = tensor([[-0.6491, -0.7291],
        [-0.6855, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014100507833063602
Model saved, deleting model...
Deleted model...
Epoch 0, Step 100: train/loss = 0.668840229511261, train/raw-loss = 0.668840229511261, train/logprobs = tensor([[-0.6103, -0.6832],
        [-0.6858, -0.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014095529913902283
Epoch 0, Step 101: train/loss = 0.6761744618415833, train/raw-loss = 0.6761744618415833, train/logprobs = tensor([[-0.6928, -0.6922],
        [-0.7546, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014031459577381611
Epoch 0, Step 102: train/loss = 0.6691454648971558, train/raw-loss = 0.6691454648971558, train/logprobs = tensor([[-0.6715, -0.6724],
        [-0.7610, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013603966683149338
Epoch 0, Step 103: train/loss = 0.671688973903656, train/raw-loss = 0.671688973903656, train/logprobs = tensor([[-0.6024, -0.6071],
        [-0.6557, -0.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014252028428018093
Epoch 0, Step 104: train/loss = 0.6868448853492737, train/raw-loss = 0.6868448853492737, train/logprobs = tensor([[-0.6435, -0.5441],
        [-0.6802, -0.5460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013708912767469883
Epoch 0, Step 105: train/loss = 0.679928719997406, train/raw-loss = 0.679928719997406, train/logprobs = tensor([[-0.5777, -0.6582],
        [-0.6189, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013545645400881767
Epoch 0, Step 106: train/loss = 0.6829239130020142, train/raw-loss = 0.6829239130020142, train/logprobs = tensor([[-0.6143, -0.6507],
        [-0.6321, -0.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013430110178887844
Epoch 0, Step 107: train/loss = 0.6910310983657837, train/raw-loss = 0.6910310983657837, train/logprobs = tensor([[-0.6249, -0.6255],
        [-0.6448, -0.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013661311939358711
Epoch 0, Step 108: train/loss = 0.6856557726860046, train/raw-loss = 0.6856557726860046, train/logprobs = tensor([[-0.6346, -0.6497],
        [-0.6697, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012154713273048401
Epoch 0, Step 109: train/loss = 0.666015625, train/raw-loss = 0.666015625, train/logprobs = tensor([[-0.5781, -0.6261],
        [-0.6837, -0.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012797216884791851
Epoch 0, Step 110: train/loss = 0.6799732446670532, train/raw-loss = 0.6799732446670532, train/logprobs = tensor([[-0.6370, -0.5527],
        [-0.7091, -0.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012907580472528934
Epoch 0, Step 111: train/loss = 0.6735137701034546, train/raw-loss = 0.6735137701034546, train/logprobs = tensor([[-0.6411, -0.6066],
        [-0.7122, -0.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013004917651414871
Epoch 0, Step 112: train/loss = 0.6776973009109497, train/raw-loss = 0.6776973009109497, train/logprobs = tensor([[-0.6241, -0.6101],
        [-0.6575, -0.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021165719255805016
Epoch 0, Step 113: train/loss = 0.6767874360084534, train/raw-loss = 0.6767874360084534, train/logprobs = tensor([[-0.6251, -0.6843],
        [-0.6216, -0.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02407723478972912
Epoch 0, Step 114: train/loss = 0.6660616993904114, train/raw-loss = 0.6660616993904114, train/logprobs = tensor([[-0.5924, -0.6763],
        [-0.6314, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023216497153043747
Epoch 0, Step 115: train/loss = 0.6782755851745605, train/raw-loss = 0.6782755851745605, train/logprobs = tensor([[-0.6441, -0.7335],
        [-0.6818, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021408148109912872
Epoch 0, Step 116: train/loss = 0.6753815412521362, train/raw-loss = 0.6753815412521362, train/logprobs = tensor([[-0.5907, -0.6265],
        [-0.6029, -0.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02392798475921154
Epoch 0, Step 117: train/loss = 0.6732447147369385, train/raw-loss = 0.6732447147369385, train/logprobs = tensor([[-0.5959, -0.6491],
        [-0.6539, -0.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02222275361418724
Epoch 0, Step 118: train/loss = 0.6722582578659058, train/raw-loss = 0.6722582578659058, train/logprobs = tensor([[-0.6095, -0.6390],
        [-0.6753, -0.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02969777025282383
Epoch 0, Step 119: train/loss = 0.6678160429000854, train/raw-loss = 0.6678160429000854, train/logprobs = tensor([[-0.6022, -0.6365],
        [-0.6619, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023046620190143585
Epoch 0, Step 120: train/loss = 0.6843863129615784, train/raw-loss = 0.6843863129615784, train/logprobs = tensor([[-0.6048, -0.6582],
        [-0.6114, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026068326085805893
Epoch 0, Step 121: train/loss = 0.6779586672782898, train/raw-loss = 0.6779586672782898, train/logprobs = tensor([[-0.5898, -0.6763],
        [-0.6324, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026904359459877014
Epoch 0, Step 122: train/loss = 0.6412215232849121, train/raw-loss = 0.6412215232849121, train/logprobs = tensor([[-0.6622, -0.7329],
        [-0.7819, -0.6293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022235997021198273
Epoch 0, Step 123: train/loss = 0.6876484155654907, train/raw-loss = 0.6876484155654907, train/logprobs = tensor([[-0.6009, -0.6395],
        [-0.5841, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02028513140976429
Epoch 0, Step 124: train/loss = 0.6837009191513062, train/raw-loss = 0.6837009191513062, train/logprobs = tensor([[-0.5784, -0.5966],
        [-0.5882, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022129636257886887
Model saved, deleting model...
Deleted model...
Epoch 0, Step 125: train/loss = 0.6802572011947632, train/raw-loss = 0.6802572011947632, train/logprobs = tensor([[-0.6724, -0.6450],
        [-0.7297, -0.6447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021413344889879227
Epoch 0, Step 126: train/loss = 0.6801435947418213, train/raw-loss = 0.6801435947418213, train/logprobs = tensor([[-0.6314, -0.6510],
        [-0.6349, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02093927189707756
Epoch 0, Step 127: train/loss = 0.6776137351989746, train/raw-loss = 0.6776137351989746, train/logprobs = tensor([[-0.6426, -0.6618],
        [-0.6815, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02304554544389248
Epoch 0, Step 128: train/loss = 0.6750320792198181, train/raw-loss = 0.6750320792198181, train/logprobs = tensor([[-0.6201, -0.6291],
        [-0.6502, -0.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030510075390338898
Epoch 0, Step 129: train/loss = 0.655720591545105, train/raw-loss = 0.655720591545105, train/logprobs = tensor([[-0.6203, -0.6130],
        [-0.7566, -0.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027688326314091682
Epoch 0, Step 130: train/loss = 0.6816295981407166, train/raw-loss = 0.6816295981407166, train/logprobs = tensor([[-0.6015, -0.6194],
        [-0.5997, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028510577976703644
Epoch 0, Step 131: train/loss = 0.6595908403396606, train/raw-loss = 0.6595908403396606, train/logprobs = tensor([[-0.6692, -0.6686],
        [-0.7317, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03152179718017578
Epoch 0, Step 132: train/loss = 0.6713859438896179, train/raw-loss = 0.6713859438896179, train/logprobs = tensor([[-0.6055, -0.6166],
        [-0.6229, -0.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026822656393051147
Epoch 0, Step 133: train/loss = 0.6798428297042847, train/raw-loss = 0.6798428297042847, train/logprobs = tensor([[-0.6440, -0.6858],
        [-0.6712, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031848128885030746
Epoch 0, Step 134: train/loss = 0.6719226241111755, train/raw-loss = 0.6719226241111755, train/logprobs = tensor([[-0.6631, -0.6312],
        [-0.7030, -0.5791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029138460755348206
Epoch 0, Step 135: train/loss = 0.6651670336723328, train/raw-loss = 0.6651670336723328, train/logprobs = tensor([[-0.6614, -0.6703],
        [-0.6875, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02873479574918747
Epoch 0, Step 136: train/loss = 0.6750117540359497, train/raw-loss = 0.6750117540359497, train/logprobs = tensor([[-0.6239, -0.7112],
        [-0.6520, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029694754630327225
Epoch 0, Step 137: train/loss = 0.6638261675834656, train/raw-loss = 0.6638261675834656, train/logprobs = tensor([[-0.7037, -0.7508],
        [-0.7885, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03203783184289932
Epoch 0, Step 138: train/loss = 0.6768369674682617, train/raw-loss = 0.6768369674682617, train/logprobs = tensor([[-0.6422, -0.6765],
        [-0.6467, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03401597589254379
Epoch 0, Step 139: train/loss = 0.6577538251876831, train/raw-loss = 0.6577538251876831, train/logprobs = tensor([[-0.5848, -0.7078],
        [-0.6380, -0.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02760167233645916
Epoch 0, Step 140: train/loss = 0.6695669293403625, train/raw-loss = 0.6695669293403625, train/logprobs = tensor([[-0.5735, -0.6097],
        [-0.6175, -0.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029816636815667152
Epoch 0, Step 141: train/loss = 0.6796537637710571, train/raw-loss = 0.6796537637710571, train/logprobs = tensor([[-0.5909, -0.6592],
        [-0.5716, -0.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03328874707221985
Epoch 0, Step 142: train/loss = 0.6777468919754028, train/raw-loss = 0.6777468919754028, train/logprobs = tensor([[-0.6347, -0.6595],
        [-0.6332, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03485916554927826
Epoch 0, Step 143: train/loss = 0.6875092387199402, train/raw-loss = 0.6875092387199402, train/logprobs = tensor([[-0.7117, -0.6482],
        [-0.6874, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027966609224677086
Epoch 0, Step 144: train/loss = 0.6576801538467407, train/raw-loss = 0.6576801538467407, train/logprobs = tensor([[-0.6677, -0.7942],
        [-0.7270, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03515509143471718
Epoch 0, Step 145: train/loss = 0.6494966149330139, train/raw-loss = 0.6494966149330139, train/logprobs = tensor([[-0.6868, -0.7728],
        [-0.7187, -0.6095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03814106434583664
Epoch 0, Step 146: train/loss = 0.6742749810218811, train/raw-loss = 0.6742749810218811, train/logprobs = tensor([[-0.6468, -0.6766],
        [-0.6510, -0.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035464972257614136
Epoch 0, Step 147: train/loss = 0.6718268394470215, train/raw-loss = 0.6718268394470215, train/logprobs = tensor([[-0.6659, -0.7355],
        [-0.6602, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034042537212371826
Epoch 0, Step 148: train/loss = 0.6426308155059814, train/raw-loss = 0.6426308155059814, train/logprobs = tensor([[-0.6470, -0.7373],
        [-0.7220, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03789864853024483
Epoch 0, Step 149: train/loss = 0.6551659107208252, train/raw-loss = 0.6551659107208252, train/logprobs = tensor([[-0.6922, -0.6810],
        [-0.7416, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031819503754377365
Model saved, deleting model...
Deleted model...
Epoch 0, Step 150: train/loss = 0.6591252088546753, train/raw-loss = 0.6591252088546753, train/logprobs = tensor([[-0.6252, -0.7468],
        [-0.6828, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03249680623412132
Epoch 0, Step 151: train/loss = 0.6854767799377441, train/raw-loss = 0.6854767799377441, train/logprobs = tensor([[-0.6067, -0.6179],
        [-0.5873, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03343265503644943
Epoch 0, Step 152: train/loss = 0.654203474521637, train/raw-loss = 0.654203474521637, train/logprobs = tensor([[-0.6259, -0.7078],
        [-0.7267, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036269355565309525
Epoch 0, Step 153: train/loss = 0.6634455919265747, train/raw-loss = 0.6634455919265747, train/logprobs = tensor([[-0.6613, -0.7399],
        [-0.6816, -0.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03236933425068855
Epoch 0, Step 154: train/loss = 0.6749190092086792, train/raw-loss = 0.6749190092086792, train/logprobs = tensor([[-0.6703, -0.6809],
        [-0.6642, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03550857678055763
Epoch 0, Step 155: train/loss = 0.680644154548645, train/raw-loss = 0.680644154548645, train/logprobs = tensor([[-0.6488, -0.6858],
        [-0.6198, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033786848187446594
Epoch 0, Step 156: train/loss = 0.6736252903938293, train/raw-loss = 0.6736252903938293, train/logprobs = tensor([[-0.5632, -0.6198],
        [-0.6015, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03749924898147583
Epoch 0, Step 157: train/loss = 0.6681867241859436, train/raw-loss = 0.6681867241859436, train/logprobs = tensor([[-0.6208, -0.5854],
        [-0.6799, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03522873669862747
Epoch 0, Step 158: train/loss = 0.6747177839279175, train/raw-loss = 0.6747177839279175, train/logprobs = tensor([[-0.6279, -0.7362],
        [-0.6236, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03681442141532898
Epoch 0, Step 159: train/loss = 0.6562972664833069, train/raw-loss = 0.6562972664833069, train/logprobs = tensor([[-0.6320, -0.7307],
        [-0.6837, -0.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03779573366045952
Epoch 0, Step 160: train/loss = 0.6345893740653992, train/raw-loss = 0.6345893740653992, train/logprobs = tensor([[-0.7022, -0.7921],
        [-0.7817, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04225292429327965
Epoch 0, Step 161: train/loss = 0.6568014621734619, train/raw-loss = 0.6568014621734619, train/logprobs = tensor([[-0.6078, -0.7143],
        [-0.6087, -0.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0365317240357399
Epoch 0, Step 162: train/loss = 0.6748214960098267, train/raw-loss = 0.6748214960098267, train/logprobs = tensor([[-0.6065, -0.6686],
        [-0.5979, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04150284826755524
Epoch 0, Step 163: train/loss = 0.6565105319023132, train/raw-loss = 0.6565105319023132, train/logprobs = tensor([[-0.6153, -0.6528],
        [-0.6866, -0.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04101260006427765
Epoch 0, Step 164: train/loss = 0.6737334132194519, train/raw-loss = 0.6737334132194519, train/logprobs = tensor([[-0.6277, -0.7092],
        [-0.6401, -0.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040605757385492325
Epoch 0, Step 165: train/loss = 0.6433060169219971, train/raw-loss = 0.6433060169219971, train/logprobs = tensor([[-0.6813, -0.8842],
        [-0.7762, -0.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03762945160269737
Epoch 0, Step 166: train/loss = 0.661058247089386, train/raw-loss = 0.661058247089386, train/logprobs = tensor([[-0.6308, -0.6245],
        [-0.6711, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03721979632973671
Epoch 0, Step 167: train/loss = 0.6806455850601196, train/raw-loss = 0.6806455850601196, train/logprobs = tensor([[-0.6317, -0.6334],
        [-0.6228, -0.5690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0424162782728672
Epoch 0, Step 168: train/loss = 0.6595017910003662, train/raw-loss = 0.6595017910003662, train/logprobs = tensor([[-0.5804, -0.7613],
        [-0.6079, -0.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04148503765463829
Epoch 0, Step 169: train/loss = 0.6642969250679016, train/raw-loss = 0.6642969250679016, train/logprobs = tensor([[-0.6654, -0.6765],
        [-0.6953, -0.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038292597979307175
Epoch 0, Step 170: train/loss = 0.6700568795204163, train/raw-loss = 0.6700568795204163, train/logprobs = tensor([[-0.6401, -0.6928],
        [-0.6598, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042023032903671265
Epoch 0, Step 171: train/loss = 0.6640408039093018, train/raw-loss = 0.6640408039093018, train/logprobs = tensor([[-0.6694, -0.6724],
        [-0.7505, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038729432970285416
Epoch 0, Step 172: train/loss = 0.6655535697937012, train/raw-loss = 0.6655535697937012, train/logprobs = tensor([[-0.6054, -0.7311],
        [-0.6106, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03937043622136116
Epoch 0, Step 173: train/loss = 0.665861189365387, train/raw-loss = 0.665861189365387, train/logprobs = tensor([[-0.7372, -0.7450],
        [-0.7879, -0.6756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03754038363695145
Epoch 0, Step 174: train/loss = 0.6767070293426514, train/raw-loss = 0.6767070293426514, train/logprobs = tensor([[-0.7204, -0.7575],
        [-0.6937, -0.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04450233653187752
Model saved, deleting model...
Deleted model...
Epoch 0, Step 175: train/loss = 0.6714105606079102, train/raw-loss = 0.6714105606079102, train/logprobs = tensor([[-0.6413, -0.6652],
        [-0.6585, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042803116142749786
Epoch 0, Step 176: train/loss = 0.6600081324577332, train/raw-loss = 0.6600081324577332, train/logprobs = tensor([[-0.6420, -0.7829],
        [-0.6529, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043065089732408524
Epoch 0, Step 177: train/loss = 0.6568915247917175, train/raw-loss = 0.6568915247917175, train/logprobs = tensor([[-0.6757, -0.6602],
        [-0.7389, -0.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043223198503255844
Epoch 0, Step 178: train/loss = 0.6560308933258057, train/raw-loss = 0.6560308933258057, train/logprobs = tensor([[-0.6221, -0.7413],
        [-0.6879, -0.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04171142354607582
Epoch 0, Step 179: train/loss = 0.656536340713501, train/raw-loss = 0.656536340713501, train/logprobs = tensor([[-0.6158, -0.6817],
        [-0.6666, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0416809506714344
Epoch 0, Step 180: train/loss = 0.6685792803764343, train/raw-loss = 0.6685792803764343, train/logprobs = tensor([[-0.6849, -0.7597],
        [-0.6820, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04151208698749542
Epoch 0, Step 181: train/loss = 0.6582764387130737, train/raw-loss = 0.6582764387130737, train/logprobs = tensor([[-0.6264, -0.7117],
        [-0.6304, -0.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04617105796933174
Epoch 0, Step 182: train/loss = 0.6422087550163269, train/raw-loss = 0.6422087550163269, train/logprobs = tensor([[-0.6841, -0.8275],
        [-0.7729, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0439956933259964
Epoch 0, Step 183: train/loss = 0.6829966306686401, train/raw-loss = 0.6829966306686401, train/logprobs = tensor([[-0.6406, -0.6838],
        [-0.6216, -0.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041200052946805954
Epoch 0, Step 184: train/loss = 0.6477800011634827, train/raw-loss = 0.6477800011634827, train/logprobs = tensor([[-0.7071, -0.7229],
        [-0.7995, -0.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04287909343838692
Epoch 0, Step 185: train/loss = 0.6562244296073914, train/raw-loss = 0.6562244296073914, train/logprobs = tensor([[-0.5931, -0.7773],
        [-0.6272, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04985795542597771
Epoch 0, Step 186: train/loss = 0.6569082736968994, train/raw-loss = 0.6569082736968994, train/logprobs = tensor([[-0.6664, -0.7746],
        [-0.7003, -0.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042311228811740875
Epoch 0, Step 187: train/loss = 0.6726424098014832, train/raw-loss = 0.6726424098014832, train/logprobs = tensor([[-0.5875, -0.6989],
        [-0.5716, -0.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046021562069654465
Epoch 0, Step 188: train/loss = 0.6441174149513245, train/raw-loss = 0.6441174149513245, train/logprobs = tensor([[-0.6850, -0.7811],
        [-0.7882, -0.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0484127476811409
Epoch 0, Step 189: train/loss = 0.6802220940589905, train/raw-loss = 0.6802220940589905, train/logprobs = tensor([[-0.6255, -0.7431],
        [-0.6388, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0407818928360939
Epoch 0, Step 190: train/loss = 0.6762059926986694, train/raw-loss = 0.6762059926986694, train/logprobs = tensor([[-0.7227, -0.6552],
        [-0.7364, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04567747563123703
Epoch 0, Step 191: train/loss = 0.6681913733482361, train/raw-loss = 0.6681913733482361, train/logprobs = tensor([[-0.7184, -0.6953],
        [-0.7046, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041859835386276245
Epoch 0, Step 192: train/loss = 0.6704341173171997, train/raw-loss = 0.6704341173171997, train/logprobs = tensor([[-0.6582, -0.7899],
        [-0.6349, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0444234274327755
Epoch 0, Step 193: train/loss = 0.6559065580368042, train/raw-loss = 0.6559065580368042, train/logprobs = tensor([[-0.6761, -0.7676],
        [-0.7262, -0.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048964060842990875
Epoch 0, Step 194: train/loss = 0.6675033569335938, train/raw-loss = 0.6675033569335938, train/logprobs = tensor([[-0.6751, -0.7282],
        [-0.6565, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05339396744966507
Epoch 0, Step 195: train/loss = 0.6829993724822998, train/raw-loss = 0.6829993724822998, train/logprobs = tensor([[-0.6569, -0.6118],
        [-0.6098, -0.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05055524408817291
Epoch 0, Step 196: train/loss = 0.6481779217720032, train/raw-loss = 0.6481779217720032, train/logprobs = tensor([[-0.6031, -0.6938],
        [-0.6972, -0.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05112477391958237
Epoch 0, Step 197: train/loss = 0.6603692173957825, train/raw-loss = 0.6603692173957825, train/logprobs = tensor([[-0.7214, -0.7633],
        [-0.7465, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040185075253248215
Epoch 0, Step 198: train/loss = 0.6687958240509033, train/raw-loss = 0.6687958240509033, train/logprobs = tensor([[-0.7531, -0.7413],
        [-0.7243, -0.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04359080642461777
Epoch 0, Step 199: train/loss = 0.664652943611145, train/raw-loss = 0.664652943611145, train/logprobs = tensor([[-0.6794, -0.8191],
        [-0.6792, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04027470573782921
Model saved, deleting model...
Deleted model...
Epoch 0, Step 200: train/loss = 0.6677445769309998, train/raw-loss = 0.6677445769309998, train/logprobs = tensor([[-0.7322, -0.7610],
        [-0.6853, -0.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046707406640052795
Epoch 0, Step 201: train/loss = 0.6723709106445312, train/raw-loss = 0.6723709106445312, train/logprobs = tensor([[-0.7371, -0.7678],
        [-0.6869, -0.6227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042648930102586746
Epoch 0, Step 202: train/loss = 0.6433146595954895, train/raw-loss = 0.6433146595954895, train/logprobs = tensor([[-0.6444, -0.6962],
        [-0.7030, -0.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04647909477353096
Epoch 0, Step 203: train/loss = 0.647323727607727, train/raw-loss = 0.647323727607727, train/logprobs = tensor([[-0.6937, -0.7892],
        [-0.7555, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050005603581666946
Epoch 0, Step 204: train/loss = 0.6692626476287842, train/raw-loss = 0.6692626476287842, train/logprobs = tensor([[-0.6837, -0.6653],
        [-0.7000, -0.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049599114805459976
Epoch 0, Step 205: train/loss = 0.6659003496170044, train/raw-loss = 0.6659003496170044, train/logprobs = tensor([[-0.6151, -0.7544],
        [-0.6120, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0479871928691864
Epoch 0, Step 206: train/loss = 0.6609146595001221, train/raw-loss = 0.6609146595001221, train/logprobs = tensor([[-0.6541, -0.7025],
        [-0.6955, -0.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04662769287824631
Epoch 0, Step 207: train/loss = 0.6708705425262451, train/raw-loss = 0.6708705425262451, train/logprobs = tensor([[-0.7017, -0.7942],
        [-0.6827, -0.6748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04320854693651199
Epoch 0, Step 208: train/loss = 0.6772835850715637, train/raw-loss = 0.6772835850715637, train/logprobs = tensor([[-0.7260, -0.6619],
        [-0.6770, -0.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03998057544231415
Epoch 0, Step 209: train/loss = 0.6629308462142944, train/raw-loss = 0.6629308462142944, train/logprobs = tensor([[-0.6813, -0.6882],
        [-0.7322, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043245039880275726
Epoch 0, Step 210: train/loss = 0.6436903476715088, train/raw-loss = 0.6436903476715088, train/logprobs = tensor([[-0.6792, -0.8577],
        [-0.7053, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05452236533164978
Epoch 0, Step 211: train/loss = 0.6544766426086426, train/raw-loss = 0.6544766426086426, train/logprobs = tensor([[-0.6435, -0.7356],
        [-0.7332, -0.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04272839054465294
Epoch 0, Step 212: train/loss = 0.6730573773384094, train/raw-loss = 0.6730573773384094, train/logprobs = tensor([[-0.6337, -0.6677],
        [-0.6234, -0.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05404752865433693
Epoch 0, Step 213: train/loss = 0.6584963202476501, train/raw-loss = 0.6584963202476501, train/logprobs = tensor([[-0.6220, -0.7411],
        [-0.6811, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044313155114650726
Epoch 0, Step 214: train/loss = 0.6720062494277954, train/raw-loss = 0.6720062494277954, train/logprobs = tensor([[-0.5893, -0.6497],
        [-0.6375, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044169843196868896
Epoch 0, Step 215: train/loss = 0.6614365577697754, train/raw-loss = 0.6614365577697754, train/logprobs = tensor([[-0.6713, -0.7102],
        [-0.7012, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045691099017858505
Epoch 0, Step 216: train/loss = 0.6669144630432129, train/raw-loss = 0.6669144630432129, train/logprobs = tensor([[-0.6272, -0.6844],
        [-0.6346, -0.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04825468733906746
Epoch 0, Step 217: train/loss = 0.6710563898086548, train/raw-loss = 0.6710563898086548, train/logprobs = tensor([[-0.7208, -0.7545],
        [-0.7051, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0449632965028286
Epoch 0, Step 218: train/loss = 0.6372426748275757, train/raw-loss = 0.6372426748275757, train/logprobs = tensor([[-0.7373, -0.8328],
        [-0.8091, -0.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04517652839422226
Epoch 0, Step 219: train/loss = 0.6775509119033813, train/raw-loss = 0.6775509119033813, train/logprobs = tensor([[-0.6602, -0.7244],
        [-0.6499, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050189826637506485
Epoch 0, Step 220: train/loss = 0.6521722078323364, train/raw-loss = 0.6521722078323364, train/logprobs = tensor([[-0.7079, -0.6507],
        [-0.8109, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04629795625805855
Epoch 0, Step 221: train/loss = 0.6446607708930969, train/raw-loss = 0.6446607708930969, train/logprobs = tensor([[-0.6848, -0.8177],
        [-0.7260, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05024166777729988
Epoch 0, Step 222: train/loss = 0.6642493009567261, train/raw-loss = 0.6642493009567261, train/logprobs = tensor([[-0.7143, -0.7618],
        [-0.7015, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04829730838537216
Epoch 0, Step 223: train/loss = 0.640988826751709, train/raw-loss = 0.640988826751709, train/logprobs = tensor([[-0.7099, -0.9006],
        [-0.7800, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04453758895397186
Epoch 0, Step 224: train/loss = 0.6381471157073975, train/raw-loss = 0.6381471157073975, train/logprobs = tensor([[-0.7253, -0.8234],
        [-0.8816, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048851970583200455
Model saved, deleting model...
Deleted model...
Epoch 0, Step 225: train/loss = 0.6556863784790039, train/raw-loss = 0.6556863784790039, train/logprobs = tensor([[-0.7542, -0.8634],
        [-0.7663, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05215476080775261
Epoch 0, Step 226: train/loss = 0.6624768376350403, train/raw-loss = 0.6624768376350403, train/logprobs = tensor([[-0.7193, -0.7636],
        [-0.7751, -0.6834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04440174624323845
Epoch 0, Step 227: train/loss = 0.6335594654083252, train/raw-loss = 0.6335594654083252, train/logprobs = tensor([[-0.6891, -0.7583],
        [-0.8815, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04553939402103424
Epoch 0, Step 228: train/loss = 0.6619002223014832, train/raw-loss = 0.6619002223014832, train/logprobs = tensor([[-0.6783, -0.8101],
        [-0.6706, -0.6689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0500517375767231
Epoch 0, Step 229: train/loss = 0.6705266833305359, train/raw-loss = 0.6705266833305359, train/logprobs = tensor([[-0.6997, -0.6977],
        [-0.6511, -0.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04186707362532616
Epoch 0, Step 230: train/loss = 0.661766767501831, train/raw-loss = 0.661766767501831, train/logprobs = tensor([[-0.6932, -0.7768],
        [-0.6929, -0.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04751097783446312
Epoch 0, Step 231: train/loss = 0.6645553708076477, train/raw-loss = 0.6645553708076477, train/logprobs = tensor([[-0.7355, -0.7355],
        [-0.7078, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04612315818667412
Epoch 0, Step 232: train/loss = 0.6738224625587463, train/raw-loss = 0.6738224625587463, train/logprobs = tensor([[-0.6999, -0.7499],
        [-0.6683, -0.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05224030092358589
Epoch 0, Step 233: train/loss = 0.657070517539978, train/raw-loss = 0.657070517539978, train/logprobs = tensor([[-0.6922, -0.7464],
        [-0.7167, -0.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041244570165872574
Epoch 0, Step 234: train/loss = 0.6619871854782104, train/raw-loss = 0.6619871854782104, train/logprobs = tensor([[-0.7016, -0.6919],
        [-0.7341, -0.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04207516089081764
Epoch 0, Step 235: train/loss = 0.6632149815559387, train/raw-loss = 0.6632149815559387, train/logprobs = tensor([[-0.6489, -0.6912],
        [-0.7183, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04009813070297241
Epoch 0, Step 236: train/loss = 0.6640968322753906, train/raw-loss = 0.6640968322753906, train/logprobs = tensor([[-0.6579, -0.7383],
        [-0.6655, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03970438241958618
Epoch 0, Step 237: train/loss = 0.649897575378418, train/raw-loss = 0.649897575378418, train/logprobs = tensor([[-0.7016, -0.7624],
        [-0.7985, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043992701917886734
Epoch 0, Step 238: train/loss = 0.670568585395813, train/raw-loss = 0.670568585395813, train/logprobs = tensor([[-0.7000, -0.7704],
        [-0.6757, -0.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04705324396491051
Epoch 0, Step 239: train/loss = 0.6860093474388123, train/raw-loss = 0.6860093474388123, train/logprobs = tensor([[-0.6696, -0.7636],
        [-0.6507, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04826086387038231
Epoch 0, Step 240: train/loss = 0.6533818244934082, train/raw-loss = 0.6533818244934082, train/logprobs = tensor([[-0.6298, -0.7228],
        [-0.6527, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046362705528736115
Epoch 0, Step 241: train/loss = 0.6728203892707825, train/raw-loss = 0.6728203892707825, train/logprobs = tensor([[-0.6099, -0.6435],
        [-0.6126, -0.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05034508928656578
Epoch 0, Step 242: train/loss = 0.6707552671432495, train/raw-loss = 0.6707552671432495, train/logprobs = tensor([[-0.6569, -0.7591],
        [-0.6474, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05028141289949417
Epoch 0, Step 243: train/loss = 0.6315356492996216, train/raw-loss = 0.6315356492996216, train/logprobs = tensor([[-0.6558, -0.7796],
        [-0.7171, -0.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046330466866493225
Epoch 0, Step 244: train/loss = 0.6753231883049011, train/raw-loss = 0.6753231883049011, train/logprobs = tensor([[-0.6864, -0.6654],
        [-0.6503, -0.5485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046230580657720566
Epoch 0, Step 245: train/loss = 0.6439653038978577, train/raw-loss = 0.6439653038978577, train/logprobs = tensor([[-0.6841, -0.7522],
        [-0.7831, -0.6383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04964062198996544
Epoch 0, Step 246: train/loss = 0.6598254442214966, train/raw-loss = 0.6598254442214966, train/logprobs = tensor([[-0.6491, -0.6831],
        [-0.7443, -0.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05235543102025986
Epoch 0, Step 247: train/loss = 0.6570278406143188, train/raw-loss = 0.6570278406143188, train/logprobs = tensor([[-0.6761, -0.7624],
        [-0.6954, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04307807981967926
Epoch 0, Step 248: train/loss = 0.645433783531189, train/raw-loss = 0.645433783531189, train/logprobs = tensor([[-0.6480, -0.7474],
        [-0.7353, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04548567160964012
Epoch 0, Step 249: train/loss = 0.6708472371101379, train/raw-loss = 0.6708472371101379, train/logprobs = tensor([[-0.7238, -0.7865],
        [-0.6514, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04926774278283119
Model saved, deleting model...
Deleted model...
Model saved, deleting model...
Deleted model...
