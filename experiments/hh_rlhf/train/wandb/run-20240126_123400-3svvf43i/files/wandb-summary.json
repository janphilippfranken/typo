{"train/loss": 0.132, "train/learning_rate": 0.0, "train/rewards/chosen": -2.7004475593566895, "train/rewards/rejected": -6.321870803833008, "train/rewards/accuracies": 0.953125, "train/rewards/margins": 3.6214232444763184, "train/logps/rejected": -168.978271484375, "train/logps/chosen": -121.24730682373047, "train/logits/rejected": 5.871164321899414, "train/logits/chosen": 5.868246078491211, "train/epoch": 3.33, "train/global_step": 2000, "_timestamp": 1706369833.8203666, "_runtime": 68593.48384451866, "_step": 1020, "eval/loss": 0.6416587829589844, "eval/runtime": 588.4971, "eval/samples_per_second": 1.721, "eval/steps_per_second": 0.862, "eval/rewards/chosen": -3.527188777923584, "eval/rewards/rejected": -5.358188152313232, "eval/rewards/accuracies": 0.7455621361732483, "eval/rewards/margins": 1.8309990167617798, "eval/logps/rejected": -136.27513122558594, "eval/logps/chosen": -124.44505310058594, "eval/logits/rejected": 5.890293121337891, "eval/logits/chosen": 5.9387030601501465, "train/train_runtime": 68570.0838, "train/train_samples_per_second": 0.933, "train/train_steps_per_second": 0.029, "train/total_flos": 0.0, "train/train_loss": 0.39874234396964314, "_wandb": {"runtime": 68593}}