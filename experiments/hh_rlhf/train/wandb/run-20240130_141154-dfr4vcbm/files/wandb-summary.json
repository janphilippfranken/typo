{"train/loss": 0.6571, "train/learning_rate": 0.0, "train/rewards/chosen": -0.08176661282777786, "train/rewards/rejected": -0.1815197467803955, "train/rewards/accuracies": 0.7265625, "train/rewards/margins": 0.09975313395261765, "train/logps/rejected": -99.75041198730469, "train/logps/chosen": -80.18376159667969, "train/logits/rejected": -3.4660391807556152, "train/logits/chosen": -3.4477741718292236, "train/epoch": 1.0, "train/global_step": 296, "_timestamp": 1706667470.248207, "_runtime": 14755.664983987808, "_step": 297, "eval/loss": 0.6333699822425842, "eval/runtime": 371.947, "eval/samples_per_second": 5.377, "eval/steps_per_second": 2.689, "eval/rewards/chosen": -0.06203652173280716, "eval/rewards/rejected": -0.20998995006084442, "eval/rewards/accuracies": 0.7705000042915344, "eval/rewards/margins": 0.14795343577861786, "eval/logps/rejected": -101.55747985839844, "eval/logps/chosen": -68.87686157226562, "eval/logits/rejected": -3.461005449295044, "eval/logits/chosen": -3.4439902305603027, "train/train_runtime": 14596.4083, "train/train_samples_per_second": 2.603, "train/train_steps_per_second": 0.02, "train/total_flos": 0.0, "train/train_loss": 0.645629332476371, "_wandb": {"runtime": 14802}}