wandb_version: 1

model:
  desc: null
  value:
    model_type: huggingface
    name: mixtral_7b_base
    model_config:
      pretrained_model_name_or_path: mistralai/Mixtral-8x7B-v0.1
      cache_dir: /scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1
    tokenizer_config:
      pretrained_model_name_or_path: mistralai/Mixtral-8x7B-v0.1
      cache_dir: /scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1
      model_max_length: 1536
data:
  desc: null
  value:
    dataset:
      path: Anthropic/hh-rlhf
      data_dir: harmless-base
      cache_dir: /scr/jphilipp/scai/datasets/hh-rlhf
    split: train
    constitution_path: ../sample/constitutions
    n_constitutions: 135
    n_examples: 50
    cai_data: data/cai_data_hh_rlhf_synthetic
    n_synthetic_labels: 7
    synthetic_data_path: ../label/labels
lora_config:
  desc: null
  value:
    r: 8
    lora_alpha: 16
    lora_dropout: 0.1
    bias: none
    task_type: CAUSAL_LM
    inference_mode: false
    target_modules:
    - q_proj
    - v_proj
    - k_proj
    - o_proj
    - w1
    - w2
    - w3
    - lm_head
wandb:
  desc: null
  value:
    project: scai
    log_model: checkpoint
    name: cai_data_hh_rlhf_synthetic_4bit
validation_split_size:
  desc: null
  value: 0.05
dpo_beta:
  desc: null
  value: 0.1
max_prompt_length:
  desc: null
  value: 1024
training_args:
  desc: null
  value:
    output_dir: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/checkpoints/4bit
    evaluation_strategy: steps
    eval_steps: 10
    warmup_steps: 5
    per_device_train_batch_size: 4
    per_device_eval_batch_size: 4
    gradient_accumulation_steps: 8
    logging_steps: 2
    logging_strategy: steps
    learning_rate: 0.0001
    num_train_epochs: 3
    max_steps: 3000
    save_strategy: steps
    save_steps: 100
    save_total_limit: 20
    seed: 42
    optim: paged_adamw_8bit
    report_to: wandb
    bf16: true
    remove_unused_columns: false
_wandb:
  desc: null
  value:
    python_version: 3.10.13
    cli_version: 0.16.0
    framework: huggingface
    huggingface_version: 4.36.2
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1706142110.597462
    t:
      1:
      - 1
      - 5
      - 11
      - 49
      - 50
      - 51
      - 53
      - 55
      - 71
      - 84
      - 98
      - 105
      2:
      - 1
      - 5
      - 11
      - 49
      - 50
      - 51
      - 53
      - 55
      - 71
      - 84
      - 98
      - 105
      3:
      - 13
      - 16
      - 23
      4: 3.10.13
      5: 0.16.0
      6: 4.36.2
      8:
      - 5
      13: linux-x86_64
