{"train/loss": 0.0118, "train/learning_rate": 2.3369696969696972e-05, "train/rewards/chosen": -4.131200313568115, "train/rewards/rejected": -8.561285972595215, "train/rewards/accuracies": 1.0, "train/rewards/margins": 4.4300856590271, "train/logps/rejected": -128.2523956298828, "train/logps/chosen": -70.22573852539062, "train/logits/rejected": 7.319952487945557, "train/logits/chosen": 7.481753826141357, "train/epoch": 0.13, "train/global_step": 1144, "_timestamp": 1706480864.2629392, "_runtime": 1648.2308452129364, "_step": 1144, "eval/loss": 1.367074728012085, "eval/runtime": 633.1107, "eval/samples_per_second": 1.58, "eval/steps_per_second": 1.58, "eval/rewards/chosen": -4.52374267578125, "eval/rewards/rejected": -5.516058921813965, "eval/rewards/accuracies": 0.5870000123977661, "eval/rewards/margins": 0.9923164248466492, "eval/logps/rejected": -149.82127380371094, "eval/logps/chosen": -130.4419403076172, "eval/logits/rejected": 6.668483257293701, "eval/logits/chosen": 6.6581196784973145, "_wandb": {"runtime": 1648}}