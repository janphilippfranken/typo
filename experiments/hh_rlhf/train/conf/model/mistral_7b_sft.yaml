model_type: huggingface
name: mistral_7b_base

model_config:
  pretrained_model_name_or_path: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft/
  cache_dir: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft/

tokenizer_config:
  pretrained_model_name_or_path: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft
  cache_dir: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft
  model_max_length: 1536