[2024-01-16 15:00:27,274] torch.distributed.run: [WARNING] 
[2024-01-16 15:00:27,274] torch.distributed.run: [WARNING] *****************************************
[2024-01-16 15:00:27,274] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-01-16 15:00:27,274] torch.distributed.run: [WARNING] *****************************************
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: ERROR Error while calling W&B API: An internal error occurred. Please contact support. (<Response [500]>)
wandb: - Waiting for wandb.init()...
wandb: \ Waiting for wandb.init()...
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240116_150032-9uahm1mw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cai_data_hh_rlhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/9uahm1mw
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240116_150032-adsnkcjp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cai_data_hh_rlhf
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/adsnkcjp

Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]
Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:03<01:05,  3.66s/it]
Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:03<01:06,  3.70s/it]
Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:07<00:59,  3.48s/it]
Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:07<00:59,  3.49s/it]
Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:10<00:54,  3.38s/it]
Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:10<00:54,  3.39s/it]
Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:13<00:49,  3.29s/it]
Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:13<00:50,  3.33s/it]
Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:16<00:46,  3.30s/it]
Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:16<00:46,  3.32s/it]
Loading checkpoint shards:  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:19<00:42,  3.27s/it]
Loading checkpoint shards:  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:20<00:42,  3.29s/it]
Loading checkpoint shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:23<00:39,  3.25s/it]
Loading checkpoint shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:23<00:38,  3.24s/it]
Loading checkpoint shards:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:26<00:35,  3.24s/it]
Loading checkpoint shards:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:26<00:35,  3.23s/it]
Loading checkpoint shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:29<00:32,  3.20s/it]
Loading checkpoint shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:29<00:31,  3.18s/it]
Loading checkpoint shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:32<00:28,  3.14s/it]
Loading checkpoint shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:32<00:28,  3.13s/it]
Loading checkpoint shards:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:35<00:25,  3.13s/it]
Loading checkpoint shards:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:35<00:24,  3.11s/it]
Loading checkpoint shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:38<00:21,  3.11s/it]
Loading checkpoint shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:38<00:21,  3.09s/it]
Loading checkpoint shards:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:42<00:19,  3.20s/it]
Loading checkpoint shards:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:42<00:19,  3.19s/it]
Loading checkpoint shards:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:45<00:16,  3.29s/it]
Loading checkpoint shards:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:45<00:16,  3.27s/it]
Loading checkpoint shards:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 15/19 [00:49<00:13,  3.35s/it]
Loading checkpoint shards:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 15/19 [00:49<00:13,  3.34s/it]
Loading checkpoint shards:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 16/19 [00:52<00:10,  3.40s/it]
Loading checkpoint shards:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 16/19 [00:52<00:10,  3.37s/it]
Loading checkpoint shards:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 17/19 [00:56<00:06,  3.44s/it]
Loading checkpoint shards:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 17/19 [00:56<00:06,  3.44s/it]
Loading checkpoint shards:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 18/19 [00:59<00:03,  3.47s/it]
Loading checkpoint shards:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 18/19 [00:59<00:03,  3.44s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:02<00:00,  3.31s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:02<00:00,  3.29s/it]

Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:02<00:00,  3.35s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:02<00:00,  3.30s/it]
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(

  0%|          | 0/2000 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])

  0%|          | 1/2000 [00:23<13:12:35, 23.79s/it]
  0%|          | 2/2000 [00:47<13:17:52, 23.96s/it]
                                                   

  0%|          | 2/2000 [00:48<13:17:52, 23.96s/it]
  0%|          | 3/2000 [01:11<13:05:24, 23.60s/it]
  0%|          | 4/2000 [01:36<13:35:06, 24.50s/it]
                                                   

  0%|          | 4/2000 [01:36<13:35:06, 24.50s/it]
  0%|          | 5/2000 [02:01<13:34:15, 24.49s/it]
  0%|          | 6/2000 [02:29<14:12:48, 25.66s/it]
                                                   

  0%|          | 6/2000 [02:29<14:12:48, 25.66s/it]
  0%|          | 7/2000 [02:54<14:07:13, 25.51s/it]
  0%|          | 8/2000 [03:20<14:11:44, 25.65s/it]
                                                   

  0%|          | 8/2000 [03:20<14:11:44, 25.65s/it]
  0%|          | 9/2000 [03:43<13:40:03, 24.71s/it]
  0%|          | 10/2000 [04:06<13:25:00, 24.27s/it]
                                                    

  0%|          | 10/2000 [04:06<13:25:00, 24.27s/it]

  0%|          | 0/31 [00:00<?, ?it/s][A

  6%|‚ñã         | 2/31 [00:00<00:13,  2.15it/s][A

 10%|‚ñâ         | 3/31 [00:02<00:20,  1.34it/s][A

 13%|‚ñà‚ñé        | 4/31 [00:02<00:20,  1.30it/s][A

 16%|‚ñà‚ñå        | 5/31 [00:03<00:21,  1.23it/s][A

 19%|‚ñà‚ñâ        | 6/31 [00:04<00:20,  1.21it/s][A

 23%|‚ñà‚ñà‚ñé       | 7/31 [00:05<00:19,  1.20it/s][A

 26%|‚ñà‚ñà‚ñå       | 8/31 [00:06<00:19,  1.16it/s][A

 29%|‚ñà‚ñà‚ñâ       | 9/31 [00:07<00:19,  1.13it/s][A

 32%|‚ñà‚ñà‚ñà‚ñè      | 10/31 [00:08<00:19,  1.08it/s][A

 35%|‚ñà‚ñà‚ñà‚ñå      | 11/31 [00:09<00:18,  1.10it/s][A

 39%|‚ñà‚ñà‚ñà‚ñä      | 12/31 [00:10<00:18,  1.02it/s][A

 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 13/31 [00:11<00:16,  1.07it/s][A

 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 14/31 [00:12<00:16,  1.01it/s][A

 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 15/31 [00:13<00:15,  1.06it/s][A

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 16/31 [00:14<00:13,  1.08it/s][A

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/31 [00:15<00:14,  1.00s/it][A

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 18/31 [00:16<00:13,  1.02s/it][A

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 19/31 [00:17<00:11,  1.02it/s][A

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 20/31 [00:17<00:10,  1.07it/s][A

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 21/31 [00:18<00:09,  1.09it/s][A

 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 22/31 [00:19<00:07,  1.15it/s][A

 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 23/31 [00:20<00:06,  1.15it/s][A

 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 24/31 [00:21<00:06,  1.07it/s][A

 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 25/31 [00:22<00:05,  1.07it/s][A

 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 26/31 [00:23<00:04,  1.07it/s][A

 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 27/31 [00:24<00:03,  1.13it/s][A

 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 28/31 [00:25<00:02,  1.03it/s][A

 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 29/31 [00:26<00:01,  1.09it/s][A

 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 30/31 [00:27<00:00,  1.05it/s][A

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:28<00:00,  1.11it/s][A
                                                    

                                               
[A
  0%|          | 10/2000 [04:35<13:25:00, 24.27s/it]

100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 31/31 [00:28<00:00,  1.11it/s][A

                                               [A
  1%|          | 11/2000 [04:57<17:58:59, 32.55s/it]
  1%|          | 12/2000 [05:21<16:32:15, 29.95s/it]
                                                    

  1%|          | 12/2000 [05:21<16:32:15, 29.95s/it]
  1%|          | 13/2000 [05:44<15:17:55, 27.72s/it]
  1%|          | 14/2000 [06:10<14:59:47, 27.18s/it]
                                                    

  1%|          | 14/2000 [06:10<14:59:47, 27.18s/it]
  1%|          | 15/2000 [06:32<14:10:43, 25.71s/it]
  1%|          | 16/2000 [06:56<13:53:40, 25.21s/it]
                                                    

  1%|          | 16/2000 [06:56<13:53:40, 25.21s/it]
  1%|          | 17/2000 [07:19<13:25:56, 24.39s/it]
  1%|          | 18/2000 [07:42<13:12:55, 24.00s/it]
                                                    

  1%|          | 18/2000 [07:42<13:12:55, 24.00s/it]
  1%|          | 19/2000 [08:04<12:58:49, 23.59s/it]
  1%|          | 20/2000 [08:26<12:42:57, 23.12s/it]
                                                    

  1%|          | 20/2000 [08:26<12:42:57, 23.12s/it]

  0%|          | 0/31 [00:00<?, ?it/s][A

  6%|‚ñã         | 2/31 [00:00<00:13,  2.14it/s][A

 10%|‚ñâ         | 3/31 [00:02<00:20,  1.34it/s][A

 13%|‚ñà‚ñé        | 4/31 [00:02<00:20,  1.30it/s][A

 16%|‚ñà‚ñå        | 5/31 [00:03<00:21,  1.23it/s][A

 19%|‚ñà‚ñâ        | 6/31 [00:04<00:20,  1.21it/s][A

 23%|‚ñà‚ñà‚ñé       | 7/31 [00:05<00:19,  1.20it/s][A

 26%|‚ñà‚ñà‚ñå       | 8/31 [00:06<00:19,  1.16it/s][A

 29%|‚ñà‚ñà‚ñâ       | 9/31 [00:07<00:19,  1.13it/s][A

 32%|‚ñà‚ñà‚ñà‚ñè      | 10/31 [00:08<00:19,  1.08it/s][A

 35%|‚ñà‚ñà‚ñà‚ñå      | 11/31 [00:09<00:18,  1.10it/s][A

 39%|‚ñà‚ñà‚ñà‚ñä      | 12/31 [00:10<00:18,  1.03it/s][A

 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 13/31 [00:11<00:16,  1.07it/s][A

 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 14/31 [00:12<00:16,  1.01it/s][A

 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 15/31 [00:13<00:15,  1.06it/s][A

 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 16/31 [00:14<00:13,  1.08it/s][A

 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 17/31 [00:15<00:14,  1.00s/it][A

 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 18/31 [00:16<00:13,  1.02s/it][A

 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 19/31 [00:17<00:11,  1.02it/s][A

 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 20/31 [00:17<00:10,  1.07it/s][A

 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 21/31 [00:18<00:09,  1.09it/s][A