[2024-01-16 15:00:41,396][root][INFO] - Dataset is: data/cai_data_hh_rlhf_combined
[2024-01-16 15:00:41,396][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/cai_data_hh_rlhf_combined/checkpoints
[2024-01-16 15:00:41,396][root][INFO] - Wandb name: cai_data_hh_rlhf_combined
[2024-01-16 15:00:41,407][root][INFO] - Dataset is: data/cai_data_hh_rlhf_combined
[2024-01-16 15:00:41,407][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/cai_data_hh_rlhf_combined/checkpoints
[2024-01-16 15:00:41,407][root][INFO] - Wandb name: cai_data_hh_rlhf_combined
[2024-01-16 15:01:55,198][root][INFO] - N Train Examples: 9902
[2024-01-16 15:01:56,358][root][INFO] - N Train Examples: 9902
[2024-01-16 15:02:10,940][root][INFO] - DatasetDict({
    train: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 9406
    })
    test: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 496
    })
})
[2024-01-16 15:02:10,960] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-16 15:02:11,103] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-01-16 15:02:11,103] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-01-16 15:02:12,235][root][INFO] - DatasetDict({
    train: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 9406
    })
    test: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 496
    })
})
[2024-01-16 15:02:12,255] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-16 15:02:12,399] [INFO] [comm.py:637:init_distributed] cdb=None
trainable params: 120,350,720 || all params: 46,823,143,424 || trainable%: 0.25703255099765937
[2024-01-16 15:02:12,871][root][INFO] - Devices: 2
[2024-01-16 15:02:12,874][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
trainable params: 120,350,720 || all params: 46,823,143,424 || trainable%: 0.25703255099765937
[2024-01-16 15:02:14,381][root][INFO] - Devices: 2
[2024-01-16 15:02:17,589] [WARNING] [engine.py:1166:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
{'loss': 1.8199, 'learning_rate': 4e-05, 'epoch': 0.01}
{'loss': 1.8953, 'learning_rate': 8e-05, 'epoch': 0.03}
{'loss': 1.8274, 'learning_rate': 9.994987468671679e-05, 'epoch': 0.04}
{'loss': 1.8397, 'learning_rate': 9.984962406015038e-05, 'epoch': 0.05}
{'loss': 1.8349, 'learning_rate': 9.974937343358397e-05, 'epoch': 0.07}
{'eval_loss': 1.727220058441162, 'eval_runtime': 62.0578, 'eval_samples_per_second': 7.993, 'eval_steps_per_second': 0.999, 'epoch': 0.07}
{'loss': 1.7697, 'learning_rate': 9.964912280701755e-05, 'epoch': 0.08}
{'loss': 1.7023, 'learning_rate': 9.954887218045114e-05, 'epoch': 0.1}
{'loss': 1.7788, 'learning_rate': 9.944862155388471e-05, 'epoch': 0.11}
{'loss': 1.6738, 'learning_rate': 9.93483709273183e-05, 'epoch': 0.12}
