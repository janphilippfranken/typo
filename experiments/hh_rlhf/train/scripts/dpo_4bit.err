[2024-01-28 19:28:34,779] torch.distributed.run: [WARNING] 
[2024-01-28 19:28:34,779] torch.distributed.run: [WARNING] *****************************************
[2024-01-28 19:28:34,779] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-01-28 19:28:34,779] torch.distributed.run: [WARNING] *****************************************
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/trl/trainer/ppo_config.py:141: UserWarning: The `optimize_cuda_cache` arguement will be deprecated soon, please use `optimize_device_cache` instead.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train_4bit': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train_4bit': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: - Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240128_192840-v8l5vcos
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hh_rlhf_cai_4bit
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/v8l5vcos
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240128_192840-eo8biuwq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hh_rlhf_cai_4bit
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/eo8biuwq
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:04<01:14,  4.16s/it]Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:04<01:17,  4.28s/it]Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:07<01:06,  3.93s/it]Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:08<01:08,  4.01s/it]Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:11<00:58,  3.64s/it]Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:11<00:58,  3.68s/it]Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:14<00:52,  3.49s/it]Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:14<00:52,  3.48s/it]Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:17<00:48,  3.44s/it]Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:17<00:47,  3.42s/it]