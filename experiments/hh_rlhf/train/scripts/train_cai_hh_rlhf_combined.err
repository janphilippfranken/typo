[2024-01-16 14:18:28,380] torch.distributed.run: [WARNING] 
[2024-01-16 14:18:28,380] torch.distributed.run: [WARNING] *****************************************
[2024-01-16 14:18:28,380] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-01-16 14:18:28,380] torch.distributed.run: [WARNING] *****************************************
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240116_141833-yznxeeyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cai_data_hh_rlhf_combined
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/yznxeeyy
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240116_141833-spd4kfm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cai_data_hh_rlhf_combined
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/spd4kfm2
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:04<01:12,  4.02s/it]Loading checkpoint shards:   5%|‚ñå         | 1/19 [00:04<01:12,  4.05s/it]Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:07<01:01,  3.64s/it]Loading checkpoint shards:  11%|‚ñà         | 2/19 [00:07<01:02,  3.70s/it]Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:10<00:56,  3.55s/it]Loading checkpoint shards:  16%|‚ñà‚ñå        | 3/19 [00:10<00:57,  3.58s/it]Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:14<00:52,  3.53s/it]Loading checkpoint shards:  21%|‚ñà‚ñà        | 4/19 [00:14<00:53,  3.55s/it]Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:17<00:48,  3.49s/it]Loading checkpoint shards:  26%|‚ñà‚ñà‚ñã       | 5/19 [00:17<00:49,  3.52s/it]Loading checkpoint shards:  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:21<00:45,  3.51s/it]Loading checkpoint shards:  32%|‚ñà‚ñà‚ñà‚ñè      | 6/19 [00:21<00:45,  3.53s/it]Loading checkpoint shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:24<00:42,  3.52s/it]Loading checkpoint shards:  37%|‚ñà‚ñà‚ñà‚ñã      | 7/19 [00:24<00:42,  3.53s/it]Loading checkpoint shards:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:28<00:38,  3.51s/it]Loading checkpoint shards:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 8/19 [00:28<00:39,  3.55s/it]Loading checkpoint shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:31<00:34,  3.48s/it]Loading checkpoint shards:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 9/19 [00:32<00:35,  3.52s/it]Loading checkpoint shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:35<00:31,  3.48s/it]Loading checkpoint shards:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 10/19 [00:35<00:31,  3.51s/it]Loading checkpoint shards:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:38<00:27,  3.46s/it]Loading checkpoint shards:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 11/19 [00:38<00:27,  3.48s/it]Loading checkpoint shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:42<00:24,  3.44s/it]Loading checkpoint shards:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 12/19 [00:42<00:24,  3.46s/it]Loading checkpoint shards:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:45<00:20,  3.40s/it]Loading checkpoint shards:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 13/19 [00:45<00:20,  3.42s/it]Loading checkpoint shards:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:48<00:16,  3.34s/it]Loading checkpoint shards:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 14/19 [00:48<00:16,  3.39s/it]Loading checkpoint shards:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 15/19 [00:51<00:13,  3.36s/it]Loading checkpoint shards:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 15/19 [00:52<00:13,  3.41s/it]Loading checkpoint shards:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 16/19 [00:55<00:10,  3.35s/it]Loading checkpoint shards:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 16/19 [00:55<00:10,  3.37s/it]Loading checkpoint shards:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 17/19 [00:58<00:06,  3.31s/it]Loading checkpoint shards:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 17/19 [00:59<00:06,  3.34s/it]Loading checkpoint shards:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 18/19 [01:01<00:03,  3.29s/it]Loading checkpoint shards:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 18/19 [01:02<00:03,  3.31s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:04<00:00,  3.16s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:04<00:00,  3.40s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:05<00:00,  3.16s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [01:05<00:00,  3.42s/it]
`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
  0%|          | 0/2500 [00:00<?, ?it/s]`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
  0%|          | 1/2500 [00:23<16:24:47, 23.64s/it]  0%|          | 2/2500 [00:46<16:14:33, 23.41s/it]                                                     0%|          | 2/2500 [00:47<16:14:33, 23.41s/it]  0%|          | 3/2500 [01:10<16:26:36, 23.71s/it]  0%|          | 4/2500 [01:37<17:12:48, 24.83s/it]                                                     0%|          | 4/2500 [01:37<17:12:48, 24.83s/it]  0%|          | 5/2500 [02:03<17:27:36, 25.19s/it]  0%|          | 6/2500 [02:26<16:57:49, 24.49s/it]                                                     0%|          | 6/2500 [02:26<16:57:49, 24.49s/it]  0%|          | 7/2500 [02:49<16:40:31, 24.08s/it]  0%|          | 8/2500 [03:15<17:09:17, 24.78s/it]                                                     0%|          | 8/2500 [03:15<17:09:17, 24.78s/it]  0%|          | 9/2500 [03:39<16:53:18, 24.41s/it]  0%|          | 10/2500 [04:05<17:11:17, 24.85s/it]                                                      0%|          | 10/2500 [04:05<17:11:17, 24.85s/it]wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)
  0%|          | 11/2500 [04:29<17:06:29, 24.74s/it]  0%|          | 12/2500 [04:54<17:03:54, 24.69s/it]                                                      0%|          | 12/2500 [04:54<17:03:54, 24.69s/it]wandb: ERROR Dropped streaming file chunk (see wandb/debug-internal.log)
