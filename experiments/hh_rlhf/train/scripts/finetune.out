mistralai/Mistral-7B-v0.1 is quantized.
[2024-01-14 17:27:57,379][accelerate.utils.modeling][INFO] - We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).
[2024-01-14 17:28:01,338][root][INFO] - N Train Examples: 7788
[2024-01-14 17:28:13,294] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-14 17:28:13,441] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-01-14 17:28:13,441] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
trainable params: 3,407,872 || all params: 7,245,139,968 || trainable%: 0.04703666202518836
[2024-01-14 17:28:13,562][root][INFO] - PEFT Params: None
[2024-01-14 17:28:13,564][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 1.9431, 'learning_rate': 2.994e-05, 'epoch': 0.01}
{'loss': 1.8456, 'learning_rate': 2.9880000000000002e-05, 'epoch': 0.02}
{'loss': 1.8026, 'learning_rate': 2.982e-05, 'epoch': 0.03}
{'loss': 1.6754, 'learning_rate': 2.976e-05, 'epoch': 0.04}
{'loss': 1.6735, 'learning_rate': 2.97e-05, 'epoch': 0.05}
{'loss': 1.753, 'learning_rate': 2.964e-05, 'epoch': 0.06}
{'loss': 1.8224, 'learning_rate': 2.958e-05, 'epoch': 0.07}
{'loss': 1.7328, 'learning_rate': 2.9520000000000002e-05, 'epoch': 0.08}
{'loss': 1.6545, 'learning_rate': 2.946e-05, 'epoch': 0.09}
{'loss': 1.6867, 'learning_rate': 2.94e-05, 'epoch': 0.1}
{'loss': 1.7325, 'learning_rate': 2.934e-05, 'epoch': 0.11}
{'loss': 1.666, 'learning_rate': 2.928e-05, 'epoch': 0.12}
{'loss': 1.7043, 'learning_rate': 2.922e-05, 'epoch': 0.13}
{'loss': 1.6953, 'learning_rate': 2.916e-05, 'epoch': 0.14}
{'loss': 1.6465, 'learning_rate': 2.91e-05, 'epoch': 0.15}
{'loss': 1.6505, 'learning_rate': 2.904e-05, 'epoch': 0.16}
{'loss': 1.681, 'learning_rate': 2.898e-05, 'epoch': 0.17}
{'loss': 1.7354, 'learning_rate': 2.892e-05, 'epoch': 0.18}
{'loss': 1.7496, 'learning_rate': 2.8859999999999998e-05, 'epoch': 0.2}
{'loss': 1.6971, 'learning_rate': 2.88e-05, 'epoch': 0.21}
{'loss': 1.6875, 'learning_rate': 2.874e-05, 'epoch': 0.22}
{'loss': 1.732, 'learning_rate': 2.868e-05, 'epoch': 0.23}
{'loss': 1.7458, 'learning_rate': 2.862e-05, 'epoch': 0.24}
{'loss': 1.6419, 'learning_rate': 2.856e-05, 'epoch': 0.25}
{'loss': 1.6676, 'learning_rate': 2.8499999999999998e-05, 'epoch': 0.26}
{'loss': 1.6923, 'learning_rate': 2.844e-05, 'epoch': 0.27}
{'loss': 1.6414, 'learning_rate': 2.838e-05, 'epoch': 0.28}
{'loss': 1.6232, 'learning_rate': 2.832e-05, 'epoch': 0.29}
{'loss': 1.669, 'learning_rate': 2.826e-05, 'epoch': 0.3}
{'loss': 1.7663, 'learning_rate': 2.8199999999999998e-05, 'epoch': 0.31}
{'loss': 1.6654, 'learning_rate': 2.8139999999999998e-05, 'epoch': 0.32}
{'loss': 1.728, 'learning_rate': 2.8080000000000002e-05, 'epoch': 0.33}
{'loss': 1.7606, 'learning_rate': 2.8020000000000003e-05, 'epoch': 0.34}
{'loss': 1.6898, 'learning_rate': 2.7960000000000003e-05, 'epoch': 0.35}
{'loss': 1.7275, 'learning_rate': 2.79e-05, 'epoch': 0.36}
{'loss': 1.6447, 'learning_rate': 2.784e-05, 'epoch': 0.37}
{'loss': 1.7416, 'learning_rate': 2.778e-05, 'epoch': 0.38}
{'loss': 1.6117, 'learning_rate': 2.7720000000000002e-05, 'epoch': 0.39}
{'loss': 1.6863, 'learning_rate': 2.7660000000000003e-05, 'epoch': 0.4}
{'loss': 1.6847, 'learning_rate': 2.7600000000000003e-05, 'epoch': 0.41}
{'loss': 1.6133, 'learning_rate': 2.754e-05, 'epoch': 0.42}
{'loss': 1.706, 'learning_rate': 2.748e-05, 'epoch': 0.43}
{'loss': 1.6722, 'learning_rate': 2.7420000000000002e-05, 'epoch': 0.44}
{'loss': 1.6797, 'learning_rate': 2.7360000000000002e-05, 'epoch': 0.45}
{'loss': 1.6834, 'learning_rate': 2.7300000000000003e-05, 'epoch': 0.46}
{'loss': 1.638, 'learning_rate': 2.724e-05, 'epoch': 0.47}
{'loss': 1.7768, 'learning_rate': 2.718e-05, 'epoch': 0.48}
{'loss': 1.7715, 'learning_rate': 2.712e-05, 'epoch': 0.49}
{'loss': 1.7237, 'learning_rate': 2.7060000000000002e-05, 'epoch': 0.5}
{'loss': 1.7311, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.51}
{'loss': 1.7299, 'learning_rate': 2.6940000000000003e-05, 'epoch': 0.52}
{'loss': 1.7862, 'learning_rate': 2.688e-05, 'epoch': 0.53}
{'loss': 1.7418, 'learning_rate': 2.682e-05, 'epoch': 0.54}
{'loss': 1.7299, 'learning_rate': 2.676e-05, 'epoch': 0.55}
{'loss': 1.6589, 'learning_rate': 2.6700000000000002e-05, 'epoch': 0.56}
{'loss': 1.755, 'learning_rate': 2.6640000000000002e-05, 'epoch': 0.58}
{'loss': 1.663, 'learning_rate': 2.658e-05, 'epoch': 0.59}
{'loss': 1.7048, 'learning_rate': 2.652e-05, 'epoch': 0.6}
{'loss': 1.7217, 'learning_rate': 2.646e-05, 'epoch': 0.61}
{'loss': 1.6628, 'learning_rate': 2.64e-05, 'epoch': 0.62}
{'loss': 1.7627, 'learning_rate': 2.6340000000000002e-05, 'epoch': 0.63}
{'loss': 1.6628, 'learning_rate': 2.628e-05, 'epoch': 0.64}
{'loss': 1.7532, 'learning_rate': 2.622e-05, 'epoch': 0.65}
{'loss': 1.6479, 'learning_rate': 2.616e-05, 'epoch': 0.66}
{'loss': 1.718, 'learning_rate': 2.61e-05, 'epoch': 0.67}
{'loss': 1.7646, 'learning_rate': 2.604e-05, 'epoch': 0.68}
{'loss': 1.7661, 'learning_rate': 2.5980000000000002e-05, 'epoch': 0.69}
{'loss': 1.7065, 'learning_rate': 2.592e-05, 'epoch': 0.7}
{'loss': 1.6618, 'learning_rate': 2.586e-05, 'epoch': 0.71}
{'loss': 1.7498, 'learning_rate': 2.58e-05, 'epoch': 0.72}
{'loss': 1.6381, 'learning_rate': 2.574e-05, 'epoch': 0.73}
{'loss': 1.5963, 'learning_rate': 2.568e-05, 'epoch': 0.74}
{'loss': 1.7549, 'learning_rate': 2.562e-05, 'epoch': 0.75}
{'loss': 1.8147, 'learning_rate': 2.556e-05, 'epoch': 0.76}
{'loss': 1.5877, 'learning_rate': 2.55e-05, 'epoch': 0.77}
{'loss': 1.6825, 'learning_rate': 2.544e-05, 'epoch': 0.78}
{'loss': 1.7577, 'learning_rate': 2.538e-05, 'epoch': 0.79}
{'loss': 1.6372, 'learning_rate': 2.5319999999999998e-05, 'epoch': 0.8}
{'loss': 1.7417, 'learning_rate': 2.526e-05, 'epoch': 0.81}
{'loss': 1.7282, 'learning_rate': 2.52e-05, 'epoch': 0.82}
{'loss': 1.7236, 'learning_rate': 2.514e-05, 'epoch': 0.83}
{'loss': 1.7484, 'learning_rate': 2.508e-05, 'epoch': 0.84}
{'loss': 1.784, 'learning_rate': 2.502e-05, 'epoch': 0.85}
{'loss': 1.7435, 'learning_rate': 2.4959999999999998e-05, 'epoch': 0.86}
{'loss': 1.6684, 'learning_rate': 2.49e-05, 'epoch': 0.87}
{'loss': 1.7392, 'learning_rate': 2.484e-05, 'epoch': 0.88}
{'loss': 1.627, 'learning_rate': 2.478e-05, 'epoch': 0.89}
{'loss': 1.7089, 'learning_rate': 2.472e-05, 'epoch': 0.9}
{'loss': 1.6034, 'learning_rate': 2.4659999999999998e-05, 'epoch': 0.91}
{'loss': 1.6526, 'learning_rate': 2.4599999999999998e-05, 'epoch': 0.92}
{'loss': 1.6366, 'learning_rate': 2.454e-05, 'epoch': 0.93}
{'loss': 1.7125, 'learning_rate': 2.448e-05, 'epoch': 0.95}
{'loss': 1.6725, 'learning_rate': 2.442e-05, 'epoch': 0.96}
{'loss': 1.764, 'learning_rate': 2.4360000000000004e-05, 'epoch': 0.97}
{'loss': 1.6626, 'learning_rate': 2.43e-05, 'epoch': 0.98}
{'loss': 1.5904, 'learning_rate': 2.4240000000000002e-05, 'epoch': 0.99}
{'loss': 1.712, 'learning_rate': 2.4180000000000002e-05, 'epoch': 1.0}
{'loss': 1.5969, 'learning_rate': 2.4120000000000003e-05, 'epoch': 1.01}
{'loss': 1.6833, 'learning_rate': 2.4060000000000003e-05, 'epoch': 1.02}
{'loss': 1.6269, 'learning_rate': 2.4e-05, 'epoch': 1.03}
{'loss': 1.6753, 'learning_rate': 2.394e-05, 'epoch': 1.04}
{'loss': 1.6428, 'learning_rate': 2.3880000000000002e-05, 'epoch': 1.05}
{'loss': 1.6315, 'learning_rate': 2.3820000000000002e-05, 'epoch': 1.06}
{'loss': 1.7136, 'learning_rate': 2.3760000000000003e-05, 'epoch': 1.07}
{'loss': 1.6838, 'learning_rate': 2.37e-05, 'epoch': 1.08}
{'loss': 1.6046, 'learning_rate': 2.364e-05, 'epoch': 1.09}
{'loss': 1.6803, 'learning_rate': 2.358e-05, 'epoch': 1.1}
{'loss': 1.6456, 'learning_rate': 2.3520000000000002e-05, 'epoch': 1.11}
{'loss': 1.6937, 'learning_rate': 2.3460000000000002e-05, 'epoch': 1.12}
{'loss': 1.6834, 'learning_rate': 2.3400000000000003e-05, 'epoch': 1.13}
{'loss': 1.6181, 'learning_rate': 2.334e-05, 'epoch': 1.14}
{'loss': 1.6611, 'learning_rate': 2.328e-05, 'epoch': 1.15}
{'loss': 1.6206, 'learning_rate': 2.322e-05, 'epoch': 1.16}
{'loss': 1.6253, 'learning_rate': 2.3160000000000002e-05, 'epoch': 1.17}
{'loss': 1.63, 'learning_rate': 2.3100000000000002e-05, 'epoch': 1.18}
{'loss': 1.6491, 'learning_rate': 2.304e-05, 'epoch': 1.19}
{'loss': 1.6782, 'learning_rate': 2.298e-05, 'epoch': 1.2}
{'loss': 1.6395, 'learning_rate': 2.292e-05, 'epoch': 1.21}
{'loss': 1.6944, 'learning_rate': 2.286e-05, 'epoch': 1.22}
{'loss': 1.6852, 'learning_rate': 2.2800000000000002e-05, 'epoch': 1.23}
{'loss': 1.7159, 'learning_rate': 2.274e-05, 'epoch': 1.24}
{'loss': 1.6917, 'learning_rate': 2.268e-05, 'epoch': 1.25}
{'loss': 1.5712, 'learning_rate': 2.262e-05, 'epoch': 1.26}
{'loss': 1.7137, 'learning_rate': 2.256e-05, 'epoch': 1.27}
{'loss': 1.5691, 'learning_rate': 2.25e-05, 'epoch': 1.28}
{'loss': 1.6184, 'learning_rate': 2.2440000000000002e-05, 'epoch': 1.29}
{'loss': 1.6828, 'learning_rate': 2.238e-05, 'epoch': 1.3}
{'loss': 1.6468, 'learning_rate': 2.232e-05, 'epoch': 1.31}
{'loss': 1.5737, 'learning_rate': 2.226e-05, 'epoch': 1.33}
{'loss': 1.6164, 'learning_rate': 2.22e-05, 'epoch': 1.34}
{'loss': 1.6825, 'learning_rate': 2.214e-05, 'epoch': 1.35}
{'loss': 1.5651, 'learning_rate': 2.208e-05, 'epoch': 1.36}
{'loss': 1.5765, 'learning_rate': 2.202e-05, 'epoch': 1.37}
{'loss': 1.718, 'learning_rate': 2.196e-05, 'epoch': 1.38}
{'loss': 1.7, 'learning_rate': 2.19e-05, 'epoch': 1.39}
{'loss': 1.6954, 'learning_rate': 2.184e-05, 'epoch': 1.4}
{'loss': 1.6234, 'learning_rate': 2.178e-05, 'epoch': 1.41}
{'loss': 1.6977, 'learning_rate': 2.172e-05, 'epoch': 1.42}
{'loss': 1.6939, 'learning_rate': 2.166e-05, 'epoch': 1.43}
{'loss': 1.6614, 'learning_rate': 2.16e-05, 'epoch': 1.44}
{'loss': 1.6655, 'learning_rate': 2.154e-05, 'epoch': 1.45}
{'loss': 1.6574, 'learning_rate': 2.148e-05, 'epoch': 1.46}
{'loss': 1.6023, 'learning_rate': 2.1419999999999998e-05, 'epoch': 1.47}
{'loss': 1.6334, 'learning_rate': 2.136e-05, 'epoch': 1.48}
{'loss': 1.6717, 'learning_rate': 2.13e-05, 'epoch': 1.49}
{'loss': 1.7236, 'learning_rate': 2.124e-05, 'epoch': 1.5}
{'loss': 1.7734, 'learning_rate': 2.118e-05, 'epoch': 1.51}
{'loss': 1.6682, 'learning_rate': 2.1119999999999998e-05, 'epoch': 1.52}
{'loss': 1.6305, 'learning_rate': 2.1059999999999998e-05, 'epoch': 1.53}
{'loss': 1.5994, 'learning_rate': 2.1e-05, 'epoch': 1.54}
{'loss': 1.5973, 'learning_rate': 2.094e-05, 'epoch': 1.55}
{'loss': 1.7029, 'learning_rate': 2.088e-05, 'epoch': 1.56}
{'loss': 1.6598, 'learning_rate': 2.082e-05, 'epoch': 1.57}
{'loss': 1.7532, 'learning_rate': 2.0759999999999998e-05, 'epoch': 1.58}
{'loss': 1.6584, 'learning_rate': 2.07e-05, 'epoch': 1.59}
{'loss': 1.6908, 'learning_rate': 2.064e-05, 'epoch': 1.6}
{'loss': 1.6575, 'learning_rate': 2.0580000000000003e-05, 'epoch': 1.61}
{'loss': 1.5869, 'learning_rate': 2.0520000000000003e-05, 'epoch': 1.62}
{'loss': 1.6675, 'learning_rate': 2.046e-05, 'epoch': 1.63}
{'loss': 1.6849, 'learning_rate': 2.04e-05, 'epoch': 1.64}
{'loss': 1.6244, 'learning_rate': 2.0340000000000002e-05, 'epoch': 1.65}
{'loss': 1.7036, 'learning_rate': 2.0280000000000002e-05, 'epoch': 1.66}
{'loss': 1.6391, 'learning_rate': 2.0220000000000003e-05, 'epoch': 1.67}
{'loss': 1.6777, 'learning_rate': 2.016e-05, 'epoch': 1.68}
{'loss': 1.6785, 'learning_rate': 2.01e-05, 'epoch': 1.69}
{'loss': 1.6844, 'learning_rate': 2.004e-05, 'epoch': 1.71}
{'loss': 1.6994, 'learning_rate': 1.9980000000000002e-05, 'epoch': 1.72}
{'loss': 1.6528, 'learning_rate': 1.9920000000000002e-05, 'epoch': 1.73}
{'loss': 1.6814, 'learning_rate': 1.9860000000000003e-05, 'epoch': 1.74}
{'loss': 1.6915, 'learning_rate': 1.98e-05, 'epoch': 1.75}
{'loss': 1.7447, 'learning_rate': 1.974e-05, 'epoch': 1.76}
{'loss': 1.6377, 'learning_rate': 1.968e-05, 'epoch': 1.77}
{'loss': 1.5705, 'learning_rate': 1.9620000000000002e-05, 'epoch': 1.78}
{'loss': 1.7463, 'learning_rate': 1.9560000000000002e-05, 'epoch': 1.79}
{'loss': 1.6275, 'learning_rate': 1.95e-05, 'epoch': 1.8}
{'loss': 1.5985, 'learning_rate': 1.944e-05, 'epoch': 1.81}
{'loss': 1.6932, 'learning_rate': 1.938e-05, 'epoch': 1.82}
{'loss': 1.5777, 'learning_rate': 1.932e-05, 'epoch': 1.83}
{'loss': 1.6093, 'learning_rate': 1.9260000000000002e-05, 'epoch': 1.84}
{'loss': 1.6682, 'learning_rate': 1.9200000000000003e-05, 'epoch': 1.85}
{'loss': 1.5801, 'learning_rate': 1.914e-05, 'epoch': 1.86}
{'loss': 1.7464, 'learning_rate': 1.908e-05, 'epoch': 1.87}
{'loss': 1.6414, 'learning_rate': 1.902e-05, 'epoch': 1.88}
{'loss': 1.6357, 'learning_rate': 1.896e-05, 'epoch': 1.89}
{'loss': 1.6535, 'learning_rate': 1.8900000000000002e-05, 'epoch': 1.9}
{'loss': 1.6892, 'learning_rate': 1.884e-05, 'epoch': 1.91}
{'loss': 1.6103, 'learning_rate': 1.878e-05, 'epoch': 1.92}
{'loss': 1.6293, 'learning_rate': 1.872e-05, 'epoch': 1.93}
{'loss': 1.5752, 'learning_rate': 1.866e-05, 'epoch': 1.94}
{'loss': 1.6139, 'learning_rate': 1.86e-05, 'epoch': 1.95}
{'loss': 1.6201, 'learning_rate': 1.854e-05, 'epoch': 1.96}
{'loss': 1.6469, 'learning_rate': 1.848e-05, 'epoch': 1.97}
{'loss': 1.6643, 'learning_rate': 1.842e-05, 'epoch': 1.98}
{'loss': 1.7233, 'learning_rate': 1.836e-05, 'epoch': 1.99}
{'loss': 1.6243, 'learning_rate': 1.83e-05, 'epoch': 2.0}
{'loss': 1.5705, 'learning_rate': 1.824e-05, 'epoch': 2.01}
{'loss': 1.608, 'learning_rate': 1.818e-05, 'epoch': 2.02}
{'loss': 1.6321, 'learning_rate': 1.812e-05, 'epoch': 2.03}
{'loss': 1.6547, 'learning_rate': 1.806e-05, 'epoch': 2.04}
{'loss': 1.6866, 'learning_rate': 1.8e-05, 'epoch': 2.05}
{'loss': 1.6906, 'learning_rate': 1.794e-05, 'epoch': 2.06}
{'loss': 1.6033, 'learning_rate': 1.7879999999999998e-05, 'epoch': 2.07}
{'loss': 1.593, 'learning_rate': 1.782e-05, 'epoch': 2.09}
{'loss': 1.6177, 'learning_rate': 1.776e-05, 'epoch': 2.1}
{'loss': 1.6803, 'learning_rate': 1.77e-05, 'epoch': 2.11}
{'loss': 1.6379, 'learning_rate': 1.764e-05, 'epoch': 2.12}
{'loss': 1.5746, 'learning_rate': 1.758e-05, 'epoch': 2.13}
{'loss': 1.6078, 'learning_rate': 1.7519999999999998e-05, 'epoch': 2.14}
{'loss': 1.5946, 'learning_rate': 1.746e-05, 'epoch': 2.15}
{'loss': 1.5943, 'learning_rate': 1.74e-05, 'epoch': 2.16}
{'loss': 1.6653, 'learning_rate': 1.734e-05, 'epoch': 2.17}
{'loss': 1.6805, 'learning_rate': 1.728e-05, 'epoch': 2.18}
{'loss': 1.576, 'learning_rate': 1.7219999999999998e-05, 'epoch': 2.19}
{'loss': 1.6013, 'learning_rate': 1.716e-05, 'epoch': 2.2}
{'loss': 1.6001, 'learning_rate': 1.71e-05, 'epoch': 2.21}
{'loss': 1.6847, 'learning_rate': 1.704e-05, 'epoch': 2.22}
{'loss': 1.6632, 'learning_rate': 1.698e-05, 'epoch': 2.23}
{'loss': 1.6113, 'learning_rate': 1.6919999999999997e-05, 'epoch': 2.24}
{'loss': 1.5363, 'learning_rate': 1.686e-05, 'epoch': 2.25}
{'loss': 1.6876, 'learning_rate': 1.6800000000000002e-05, 'epoch': 2.26}
{'loss': 1.5836, 'learning_rate': 1.6740000000000002e-05, 'epoch': 2.27}
{'loss': 1.6169, 'learning_rate': 1.6680000000000003e-05, 'epoch': 2.28}
{'loss': 1.6433, 'learning_rate': 1.6620000000000004e-05, 'epoch': 2.29}
{'loss': 1.5817, 'learning_rate': 1.656e-05, 'epoch': 2.3}
{'loss': 1.5921, 'learning_rate': 1.65e-05, 'epoch': 2.31}
{'loss': 1.6756, 'learning_rate': 1.6440000000000002e-05, 'epoch': 2.32}
{'loss': 1.61, 'learning_rate': 1.6380000000000002e-05, 'epoch': 2.33}
{'loss': 1.552, 'learning_rate': 1.6320000000000003e-05, 'epoch': 2.34}
{'loss': 1.6451, 'learning_rate': 1.626e-05, 'epoch': 2.35}
{'loss': 1.5809, 'learning_rate': 1.62e-05, 'epoch': 2.36}
{'loss': 1.665, 'learning_rate': 1.614e-05, 'epoch': 2.37}
{'loss': 1.5537, 'learning_rate': 1.6080000000000002e-05, 'epoch': 2.38}
{'loss': 1.5806, 'learning_rate': 1.6020000000000002e-05, 'epoch': 2.39}
{'loss': 1.5915, 'learning_rate': 1.596e-05, 'epoch': 2.4}
{'loss': 1.6538, 'learning_rate': 1.59e-05, 'epoch': 2.41}
{'loss': 1.5578, 'learning_rate': 1.584e-05, 'epoch': 2.42}
{'loss': 1.4844, 'learning_rate': 1.578e-05, 'epoch': 2.43}
{'loss': 1.5908, 'learning_rate': 1.5720000000000002e-05, 'epoch': 2.44}
{'loss': 1.6243, 'learning_rate': 1.5660000000000003e-05, 'epoch': 2.46}
{'loss': 1.629, 'learning_rate': 1.56e-05, 'epoch': 2.47}
{'loss': 1.5951, 'learning_rate': 1.554e-05, 'epoch': 2.48}
{'loss': 1.6073, 'learning_rate': 1.548e-05, 'epoch': 2.49}
{'loss': 1.5714, 'learning_rate': 1.542e-05, 'epoch': 2.5}
{'loss': 1.5746, 'learning_rate': 1.5360000000000002e-05, 'epoch': 2.51}
{'loss': 1.6228, 'learning_rate': 1.53e-05, 'epoch': 2.52}
{'loss': 1.5271, 'learning_rate': 1.524e-05, 'epoch': 2.53}
{'loss': 1.5834, 'learning_rate': 1.518e-05, 'epoch': 2.54}
{'loss': 1.6359, 'learning_rate': 1.5120000000000001e-05, 'epoch': 2.55}
{'loss': 1.6322, 'learning_rate': 1.506e-05, 'epoch': 2.56}
{'loss': 1.4423, 'learning_rate': 1.5e-05, 'epoch': 2.57}
{'loss': 1.6568, 'learning_rate': 1.4940000000000001e-05, 'epoch': 2.58}
{'loss': 1.6404, 'learning_rate': 1.488e-05, 'epoch': 2.59}
{'loss': 1.563, 'learning_rate': 1.482e-05, 'epoch': 2.6}
{'loss': 1.6793, 'learning_rate': 1.4760000000000001e-05, 'epoch': 2.61}
{'loss': 1.5659, 'learning_rate': 1.47e-05, 'epoch': 2.62}
{'loss': 1.5991, 'learning_rate': 1.464e-05, 'epoch': 2.63}
{'loss': 1.5556, 'learning_rate': 1.458e-05, 'epoch': 2.64}
{'loss': 1.5934, 'learning_rate': 1.452e-05, 'epoch': 2.65}
{'loss': 1.7053, 'learning_rate': 1.446e-05, 'epoch': 2.66}
{'loss': 1.5669, 'learning_rate': 1.44e-05, 'epoch': 2.67}
{'loss': 1.5601, 'learning_rate': 1.434e-05, 'epoch': 2.68}
{'loss': 1.6178, 'learning_rate': 1.428e-05, 'epoch': 2.69}
{'loss': 1.5871, 'learning_rate': 1.422e-05, 'epoch': 2.7}
{'loss': 1.6727, 'learning_rate': 1.416e-05, 'epoch': 2.71}
{'loss': 1.6797, 'learning_rate': 1.4099999999999999e-05, 'epoch': 2.72}
{'loss': 1.6443, 'learning_rate': 1.4040000000000001e-05, 'epoch': 2.73}
{'loss': 1.6257, 'learning_rate': 1.3980000000000002e-05, 'epoch': 2.74}
{'loss': 1.7252, 'learning_rate': 1.392e-05, 'epoch': 2.75}
{'loss': 1.6051, 'learning_rate': 1.3860000000000001e-05, 'epoch': 2.76}
{'loss': 1.5904, 'learning_rate': 1.3800000000000002e-05, 'epoch': 2.77}
{'loss': 1.5897, 'learning_rate': 1.374e-05, 'epoch': 2.78}
{'loss': 1.5362, 'learning_rate': 1.3680000000000001e-05, 'epoch': 2.79}
{'loss': 1.6403, 'learning_rate': 1.362e-05, 'epoch': 2.8}
{'loss': 1.6072, 'learning_rate': 1.356e-05, 'epoch': 2.81}
{'loss': 1.6127, 'learning_rate': 1.3500000000000001e-05, 'epoch': 2.82}
{'loss': 1.6506, 'learning_rate': 1.344e-05, 'epoch': 2.84}
{'loss': 1.6707, 'learning_rate': 1.338e-05, 'epoch': 2.85}
{'loss': 1.6281, 'learning_rate': 1.3320000000000001e-05, 'epoch': 2.86}
{'loss': 1.6159, 'learning_rate': 1.326e-05, 'epoch': 2.87}
{'loss': 1.6305, 'learning_rate': 1.32e-05, 'epoch': 2.88}
{'loss': 1.6272, 'learning_rate': 1.314e-05, 'epoch': 2.89}
{'loss': 1.5835, 'learning_rate': 1.308e-05, 'epoch': 2.9}
{'loss': 1.67, 'learning_rate': 1.302e-05, 'epoch': 2.91}
{'loss': 1.5764, 'learning_rate': 1.296e-05, 'epoch': 2.92}
{'loss': 1.7068, 'learning_rate': 1.29e-05, 'epoch': 2.93}
{'loss': 1.6057, 'learning_rate': 1.284e-05, 'epoch': 2.94}
{'loss': 1.6353, 'learning_rate': 1.278e-05, 'epoch': 2.95}
{'loss': 1.694, 'learning_rate': 1.272e-05, 'epoch': 2.96}
{'loss': 1.5644, 'learning_rate': 1.2659999999999999e-05, 'epoch': 2.97}
{'loss': 1.7167, 'learning_rate': 1.26e-05, 'epoch': 2.98}
{'loss': 1.6578, 'learning_rate': 1.254e-05, 'epoch': 2.99}
{'loss': 1.5537, 'learning_rate': 1.2479999999999999e-05, 'epoch': 3.0}
{'loss': 1.6732, 'learning_rate': 1.242e-05, 'epoch': 3.01}
{'loss': 1.5875, 'learning_rate': 1.236e-05, 'epoch': 3.02}
{'loss': 1.5875, 'learning_rate': 1.2299999999999999e-05, 'epoch': 3.03}
{'loss': 1.6203, 'learning_rate': 1.224e-05, 'epoch': 3.04}
{'loss': 1.5622, 'learning_rate': 1.2180000000000002e-05, 'epoch': 3.05}
{'loss': 1.5977, 'learning_rate': 1.2120000000000001e-05, 'epoch': 3.06}
{'loss': 1.5371, 'learning_rate': 1.2060000000000001e-05, 'epoch': 3.07}
{'loss': 1.5066, 'learning_rate': 1.2e-05, 'epoch': 3.08}
{'loss': 1.5913, 'learning_rate': 1.1940000000000001e-05, 'epoch': 3.09}
{'loss': 1.5419, 'learning_rate': 1.1880000000000001e-05, 'epoch': 3.1}
{'loss': 1.4802, 'learning_rate': 1.182e-05, 'epoch': 3.11}
{'loss': 1.662, 'learning_rate': 1.1760000000000001e-05, 'epoch': 3.12}
{'loss': 1.6321, 'learning_rate': 1.1700000000000001e-05, 'epoch': 3.13}
{'loss': 1.5842, 'learning_rate': 1.164e-05, 'epoch': 3.14}
{'loss': 1.5775, 'learning_rate': 1.1580000000000001e-05, 'epoch': 3.15}
{'loss': 1.5198, 'learning_rate': 1.152e-05, 'epoch': 3.16}
{'loss': 1.642, 'learning_rate': 1.146e-05, 'epoch': 3.17}
{'loss': 1.5624, 'learning_rate': 1.1400000000000001e-05, 'epoch': 3.18}
{'loss': 1.562, 'learning_rate': 1.134e-05, 'epoch': 3.19}
{'loss': 1.578, 'learning_rate': 1.128e-05, 'epoch': 3.2}
{'loss': 1.6378, 'learning_rate': 1.1220000000000001e-05, 'epoch': 3.22}
{'loss': 1.5997, 'learning_rate': 1.116e-05, 'epoch': 3.23}
{'loss': 1.532, 'learning_rate': 1.11e-05, 'epoch': 3.24}
{'loss': 1.6222, 'learning_rate': 1.104e-05, 'epoch': 3.25}
{'loss': 1.4833, 'learning_rate': 1.098e-05, 'epoch': 3.26}
{'loss': 1.5664, 'learning_rate': 1.092e-05, 'epoch': 3.27}
{'loss': 1.5808, 'learning_rate': 1.086e-05, 'epoch': 3.28}
{'loss': 1.5234, 'learning_rate': 1.08e-05, 'epoch': 3.29}
{'loss': 1.5644, 'learning_rate': 1.074e-05, 'epoch': 3.3}
{'loss': 1.5701, 'learning_rate': 1.068e-05, 'epoch': 3.31}
{'loss': 1.5487, 'learning_rate': 1.062e-05, 'epoch': 3.32}
{'loss': 1.548, 'learning_rate': 1.0559999999999999e-05, 'epoch': 3.33}
{'loss': 1.4982, 'learning_rate': 1.05e-05, 'epoch': 3.34}
{'loss': 1.4694, 'learning_rate': 1.044e-05, 'epoch': 3.35}
{'loss': 1.6563, 'learning_rate': 1.0379999999999999e-05, 'epoch': 3.36}
{'loss': 1.6792, 'learning_rate': 1.032e-05, 'epoch': 3.37}
{'loss': 1.4945, 'learning_rate': 1.0260000000000002e-05, 'epoch': 3.38}
{'loss': 1.5871, 'learning_rate': 1.02e-05, 'epoch': 3.39}
{'loss': 1.6096, 'learning_rate': 1.0140000000000001e-05, 'epoch': 3.4}
{'loss': 1.5714, 'learning_rate': 1.008e-05, 'epoch': 3.41}
{'loss': 1.5599, 'learning_rate': 1.002e-05, 'epoch': 3.42}
{'loss': 1.5747, 'learning_rate': 9.960000000000001e-06, 'epoch': 3.43}
{'loss': 1.6085, 'learning_rate': 9.9e-06, 'epoch': 3.44}
{'loss': 1.6692, 'learning_rate': 9.84e-06, 'epoch': 3.45}
{'loss': 1.6045, 'learning_rate': 9.780000000000001e-06, 'epoch': 3.46}
{'loss': 1.5926, 'learning_rate': 9.72e-06, 'epoch': 3.47}
{'loss': 1.5624, 'learning_rate': 9.66e-06, 'epoch': 3.48}
{'loss': 1.6201, 'learning_rate': 9.600000000000001e-06, 'epoch': 3.49}
{'loss': 1.5753, 'learning_rate': 9.54e-06, 'epoch': 3.5}
{'loss': 1.5767, 'learning_rate': 9.48e-06, 'epoch': 3.51}
{'loss': 1.56, 'learning_rate': 9.42e-06, 'epoch': 3.52}
{'loss': 1.5916, 'learning_rate': 9.36e-06, 'epoch': 3.53}
{'loss': 1.5528, 'learning_rate': 9.3e-06, 'epoch': 3.54}
{'loss': 1.6016, 'learning_rate': 9.24e-06, 'epoch': 3.55}
{'loss': 1.5798, 'learning_rate': 9.18e-06, 'epoch': 3.56}
{'loss': 1.536, 'learning_rate': 9.12e-06, 'epoch': 3.57}
{'loss': 1.4821, 'learning_rate': 9.06e-06, 'epoch': 3.59}
{'loss': 1.5553, 'learning_rate': 9e-06, 'epoch': 3.6}
{'loss': 1.5432, 'learning_rate': 8.939999999999999e-06, 'epoch': 3.61}
{'loss': 1.6244, 'learning_rate': 8.88e-06, 'epoch': 3.62}
{'loss': 1.6003, 'learning_rate': 8.82e-06, 'epoch': 3.63}
{'loss': 1.5679, 'learning_rate': 8.759999999999999e-06, 'epoch': 3.64}
{'loss': 1.5907, 'learning_rate': 8.7e-06, 'epoch': 3.65}
{'loss': 1.5065, 'learning_rate': 8.64e-06, 'epoch': 3.66}
{'loss': 1.4895, 'learning_rate': 8.58e-06, 'epoch': 3.67}
{'loss': 1.5343, 'learning_rate': 8.52e-06, 'epoch': 3.68}
{'loss': 1.5655, 'learning_rate': 8.459999999999999e-06, 'epoch': 3.69}
{'loss': 1.5805, 'learning_rate': 8.400000000000001e-06, 'epoch': 3.7}
{'loss': 1.6548, 'learning_rate': 8.340000000000001e-06, 'epoch': 3.71}
{'loss': 1.6417, 'learning_rate': 8.28e-06, 'epoch': 3.72}
{'loss': 1.6103, 'learning_rate': 8.220000000000001e-06, 'epoch': 3.73}
{'loss': 1.6349, 'learning_rate': 8.160000000000001e-06, 'epoch': 3.74}
{'loss': 1.5421, 'learning_rate': 8.1e-06, 'epoch': 3.75}
{'loss': 1.5847, 'learning_rate': 8.040000000000001e-06, 'epoch': 3.76}
{'loss': 1.4679, 'learning_rate': 7.98e-06, 'epoch': 3.77}
{'loss': 1.6435, 'learning_rate': 7.92e-06, 'epoch': 3.78}
{'loss': 1.5299, 'learning_rate': 7.860000000000001e-06, 'epoch': 3.79}
{'loss': 1.5765, 'learning_rate': 7.8e-06, 'epoch': 3.8}
{'loss': 1.6393, 'learning_rate': 7.74e-06, 'epoch': 3.81}
{'loss': 1.6368, 'learning_rate': 7.680000000000001e-06, 'epoch': 3.82}
{'loss': 1.638, 'learning_rate': 7.62e-06, 'epoch': 3.83}
{'loss': 1.5326, 'learning_rate': 7.5600000000000005e-06, 'epoch': 3.84}
{'loss': 1.5023, 'learning_rate': 7.5e-06, 'epoch': 3.85}
{'loss': 1.5784, 'learning_rate': 7.44e-06, 'epoch': 3.86}
{'loss': 1.6005, 'learning_rate': 7.3800000000000005e-06, 'epoch': 3.87}
{'loss': 1.6392, 'learning_rate': 7.32e-06, 'epoch': 3.88}
{'loss': 1.5455, 'learning_rate': 7.26e-06, 'epoch': 3.89}
{'loss': 1.5232, 'learning_rate': 7.2e-06, 'epoch': 3.9}
{'loss': 1.5824, 'learning_rate': 7.14e-06, 'epoch': 3.91}
{'loss': 1.598, 'learning_rate': 7.08e-06, 'epoch': 3.92}
{'loss': 1.5586, 'learning_rate': 7.0200000000000006e-06, 'epoch': 3.93}
{'loss': 1.5291, 'learning_rate': 6.96e-06, 'epoch': 3.94}
{'loss': 1.5701, 'learning_rate': 6.900000000000001e-06, 'epoch': 3.95}
{'loss': 1.5834, 'learning_rate': 6.840000000000001e-06, 'epoch': 3.97}
{'loss': 1.6385, 'learning_rate': 6.78e-06, 'epoch': 3.98}
{'loss': 1.4965, 'learning_rate': 6.72e-06, 'epoch': 3.99}
{'loss': 1.6036, 'learning_rate': 6.660000000000001e-06, 'epoch': 4.0}
{'loss': 1.5967, 'learning_rate': 6.6e-06, 'epoch': 4.01}
{'loss': 1.6332, 'learning_rate': 6.54e-06, 'epoch': 4.02}
{'loss': 1.5857, 'learning_rate': 6.48e-06, 'epoch': 4.03}
{'loss': 1.4744, 'learning_rate': 6.42e-06, 'epoch': 4.04}
{'loss': 1.5892, 'learning_rate': 6.36e-06, 'epoch': 4.05}
{'loss': 1.5303, 'learning_rate': 6.3e-06, 'epoch': 4.06}
{'loss': 1.515, 'learning_rate': 6.2399999999999995e-06, 'epoch': 4.07}
{'loss': 1.5281, 'learning_rate': 6.18e-06, 'epoch': 4.08}
{'loss': 1.5321, 'learning_rate': 6.12e-06, 'epoch': 4.09}
{'loss': 1.5357, 'learning_rate': 6.0600000000000004e-06, 'epoch': 4.1}
{'loss': 1.6106, 'learning_rate': 6e-06, 'epoch': 4.11}
{'loss': 1.4977, 'learning_rate': 5.940000000000001e-06, 'epoch': 4.12}
{'loss': 1.4518, 'learning_rate': 5.8800000000000005e-06, 'epoch': 4.13}
{'loss': 1.5579, 'learning_rate': 5.82e-06, 'epoch': 4.14}
{'loss': 1.6004, 'learning_rate': 5.76e-06, 'epoch': 4.15}
{'loss': 1.4462, 'learning_rate': 5.7000000000000005e-06, 'epoch': 4.16}
{'loss': 1.5974, 'learning_rate': 5.64e-06, 'epoch': 4.17}
{'loss': 1.5557, 'learning_rate': 5.58e-06, 'epoch': 4.18}
{'loss': 1.5609, 'learning_rate': 5.52e-06, 'epoch': 4.19}
{'loss': 1.5904, 'learning_rate': 5.46e-06, 'epoch': 4.2}
{'loss': 1.5807, 'learning_rate': 5.4e-06, 'epoch': 4.21}
{'loss': 1.5848, 'learning_rate': 5.34e-06, 'epoch': 4.22}
{'loss': 1.4837, 'learning_rate': 5.279999999999999e-06, 'epoch': 4.23}
{'loss': 1.5424, 'learning_rate': 5.22e-06, 'epoch': 4.24}
{'loss': 1.5372, 'learning_rate': 5.16e-06, 'epoch': 4.25}
{'loss': 1.6138, 'learning_rate': 5.1e-06, 'epoch': 4.26}
{'loss': 1.5353, 'learning_rate': 5.04e-06, 'epoch': 4.27}
{'loss': 1.5529, 'learning_rate': 4.980000000000001e-06, 'epoch': 4.28}
{'loss': 1.4959, 'learning_rate': 4.92e-06, 'epoch': 4.29}
{'loss': 1.4959, 'learning_rate': 4.86e-06, 'epoch': 4.3}
{'loss': 1.5202, 'learning_rate': 4.800000000000001e-06, 'epoch': 4.31}
{'loss': 1.5475, 'learning_rate': 4.74e-06, 'epoch': 4.32}
{'loss': 1.5486, 'learning_rate': 4.68e-06, 'epoch': 4.33}
{'loss': 1.4613, 'learning_rate': 4.62e-06, 'epoch': 4.35}
{'loss': 1.4791, 'learning_rate': 4.56e-06, 'epoch': 4.36}
{'loss': 1.5443, 'learning_rate': 4.5e-06, 'epoch': 4.37}
{'loss': 1.5141, 'learning_rate': 4.44e-06, 'epoch': 4.38}
{'loss': 1.5394, 'learning_rate': 4.3799999999999996e-06, 'epoch': 4.39}
{'loss': 1.5678, 'learning_rate': 4.32e-06, 'epoch': 4.4}
{'loss': 1.5228, 'learning_rate': 4.26e-06, 'epoch': 4.41}
{'loss': 1.4509, 'learning_rate': 4.2000000000000004e-06, 'epoch': 4.42}
{'loss': 1.5684, 'learning_rate': 4.14e-06, 'epoch': 4.43}
{'loss': 1.5381, 'learning_rate': 4.080000000000001e-06, 'epoch': 4.44}
{'loss': 1.529, 'learning_rate': 4.0200000000000005e-06, 'epoch': 4.45}
{'loss': 1.4756, 'learning_rate': 3.96e-06, 'epoch': 4.46}
{'loss': 1.5735, 'learning_rate': 3.9e-06, 'epoch': 4.47}
{'loss': 1.5511, 'learning_rate': 3.8400000000000005e-06, 'epoch': 4.48}
{'loss': 1.5406, 'learning_rate': 3.7800000000000002e-06, 'epoch': 4.49}
{'loss': 1.4542, 'learning_rate': 3.72e-06, 'epoch': 4.5}
{'loss': 1.5438, 'learning_rate': 3.66e-06, 'epoch': 4.51}
{'loss': 1.5195, 'learning_rate': 3.6e-06, 'epoch': 4.52}
{'loss': 1.5709, 'learning_rate': 3.54e-06, 'epoch': 4.53}
{'loss': 1.5313, 'learning_rate': 3.48e-06, 'epoch': 4.54}
{'loss': 1.5846, 'learning_rate': 3.4200000000000003e-06, 'epoch': 4.55}
{'loss': 1.4458, 'learning_rate': 3.36e-06, 'epoch': 4.56}
{'loss': 1.5307, 'learning_rate': 3.3e-06, 'epoch': 4.57}
{'loss': 1.5583, 'learning_rate': 3.24e-06, 'epoch': 4.58}
{'loss': 1.4852, 'learning_rate': 3.18e-06, 'epoch': 4.59}
{'loss': 1.5709, 'learning_rate': 3.1199999999999998e-06, 'epoch': 4.6}
{'loss': 1.5717, 'learning_rate': 3.06e-06, 'epoch': 4.61}
{'loss': 1.5286, 'learning_rate': 3e-06, 'epoch': 4.62}
{'loss': 1.5257, 'learning_rate': 2.9400000000000002e-06, 'epoch': 4.63}
{'loss': 1.5579, 'learning_rate': 2.88e-06, 'epoch': 4.64}
{'loss': 1.5816, 'learning_rate': 2.82e-06, 'epoch': 4.65}
{'loss': 1.5352, 'learning_rate': 2.76e-06, 'epoch': 4.66}
{'loss': 1.4861, 'learning_rate': 2.7e-06, 'epoch': 4.67}
{'loss': 1.5347, 'learning_rate': 2.6399999999999997e-06, 'epoch': 4.68}
{'loss': 1.467, 'learning_rate': 2.58e-06, 'epoch': 4.69}
{'loss': 1.6082, 'learning_rate': 2.52e-06, 'epoch': 4.7}
{'loss': 1.5747, 'learning_rate': 2.46e-06, 'epoch': 4.71}
{'loss': 1.5777, 'learning_rate': 2.4000000000000003e-06, 'epoch': 4.73}
{'loss': 1.6462, 'learning_rate': 2.34e-06, 'epoch': 4.74}
{'loss': 1.6527, 'learning_rate': 2.28e-06, 'epoch': 4.75}
{'loss': 1.6045, 'learning_rate': 2.22e-06, 'epoch': 4.76}
{'loss': 1.5575, 'learning_rate': 2.16e-06, 'epoch': 4.77}
{'loss': 1.5512, 'learning_rate': 2.1000000000000002e-06, 'epoch': 4.78}
{'loss': 1.5362, 'learning_rate': 2.0400000000000004e-06, 'epoch': 4.79}
{'loss': 1.6146, 'learning_rate': 1.98e-06, 'epoch': 4.8}
{'loss': 1.5122, 'learning_rate': 1.9200000000000003e-06, 'epoch': 4.81}
{'loss': 1.5878, 'learning_rate': 1.86e-06, 'epoch': 4.82}
{'loss': 1.4758, 'learning_rate': 1.8e-06, 'epoch': 4.83}
{'loss': 1.5338, 'learning_rate': 1.74e-06, 'epoch': 4.84}
{'loss': 1.5912, 'learning_rate': 1.68e-06, 'epoch': 4.85}
{'loss': 1.5481, 'learning_rate': 1.62e-06, 'epoch': 4.86}
{'loss': 1.5218, 'learning_rate': 1.5599999999999999e-06, 'epoch': 4.87}
{'loss': 1.6152, 'learning_rate': 1.5e-06, 'epoch': 4.88}
{'loss': 1.4833, 'learning_rate': 1.44e-06, 'epoch': 4.89}
{'loss': 1.5912, 'learning_rate': 1.38e-06, 'epoch': 4.9}
{'loss': 1.6048, 'learning_rate': 1.3199999999999999e-06, 'epoch': 4.91}
{'loss': 1.528, 'learning_rate': 1.26e-06, 'epoch': 4.92}
{'loss': 1.613, 'learning_rate': 1.2000000000000002e-06, 'epoch': 4.93}
{'loss': 1.6942, 'learning_rate': 1.14e-06, 'epoch': 4.94}
{'loss': 1.5356, 'learning_rate': 1.08e-06, 'epoch': 4.95}
{'loss': 1.5036, 'learning_rate': 1.0200000000000002e-06, 'epoch': 4.96}
{'loss': 1.5533, 'learning_rate': 9.600000000000001e-07, 'epoch': 4.97}
{'loss': 1.5543, 'learning_rate': 9e-07, 'epoch': 4.98}
{'loss': 1.5353, 'learning_rate': 8.4e-07, 'epoch': 4.99}
{'loss': 1.5438, 'learning_rate': 7.799999999999999e-07, 'epoch': 5.0}
{'loss': 1.4764, 'learning_rate': 7.2e-07, 'epoch': 5.01}
{'loss': 1.4665, 'learning_rate': 6.599999999999999e-07, 'epoch': 5.02}
{'loss': 1.5648, 'learning_rate': 6.000000000000001e-07, 'epoch': 5.03}
{'loss': 1.539, 'learning_rate': 5.4e-07, 'epoch': 5.04}
{'loss': 1.4879, 'learning_rate': 4.800000000000001e-07, 'epoch': 5.05}
{'loss': 1.5021, 'learning_rate': 4.2e-07, 'epoch': 5.06}
{'loss': 1.5464, 'learning_rate': 3.6e-07, 'epoch': 5.07}
{'loss': 1.492, 'learning_rate': 3.0000000000000004e-07, 'epoch': 5.08}
{'loss': 1.5118, 'learning_rate': 2.4000000000000003e-07, 'epoch': 5.1}
{'loss': 1.5119, 'learning_rate': 1.8e-07, 'epoch': 5.11}
{'loss': 1.4881, 'learning_rate': 1.2000000000000002e-07, 'epoch': 5.12}
{'loss': 1.5118, 'learning_rate': 6.000000000000001e-08, 'epoch': 5.13}
{'loss': 1.6271, 'learning_rate': 0.0, 'epoch': 5.14}
{'train_runtime': 5778.8998, 'train_samples_per_second': 6.922, 'train_steps_per_second': 0.865, 'train_loss': 1.61670678024292, 'epoch': 5.14}
NAME
    train.py

SYNOPSIS
    train.py GROUP | COMMAND | VALUE

GROUPS
    GROUP is one of the following:

     logging
       Logging package for Python. Based on PEP 282 and comments thereto in comp.lang.python.

     fire
       The Python Fire module.

     hydra

     wandb
       Use wandb to track machine learning work.

     Dict
       A generic version of dict.

     Sequence
       A generic version of collections.abc.Sequence.

     List
       A generic version of list.

     torch
       The torch package contains data structures for multi-dimensional tensors and defines mathematical operations over these tensors. Additionally, it provides many utilities for efficient serialization of Tensors and arbitrary types, and other useful utilities.

     io
       The io module provides the Python interfaces to stream handling. The builtin open function is defined in this module.

     json
       JSON (JavaScript Object Notation) <http://json.org> is a subset of JavaScript syntax (ECMA-262 3rd edition) used as a lightweight data interchange format.

     copy
       Generic (shallow and deep) copying operations.

     transformers

COMMANDS
    COMMAND is one of the following:

     DictConfig
       Container tagging interface

     OmegaConf
       OmegaConf primary class

     LoraConfig
       This is the configuration class to store the configuration of a [`LoraModel`].

     get_peft_model
       Returns a Peft model object from a model and a config.

     TrainingArguments
       TrainingArguments is the subset of the arguments we use in our example scripts **which relate to the training loop itself**.

     Trainer
       Trainer is a simple but feature-complete training and eval loop for PyTorch, optimized for 🤗 Transformers.

     dataclass
       Returns the same class as was passed in, with dunder methods added based on the fields defined in the class.

     Dataset
       A Dataset backed by an Arrow table.

     DataCollatorForSupervisedDataset
       Collate examples for supervised fine-tuning. Copy-pasted from https://github.com/tatsu-lab/stanford_alpaca/blob/main/train.py.

     remove_final_answer
       Remove final assistant answer which is our inference target.

     formatting_func
       Format example.

     preprocess
       Preprocess the data by tokenizing.

     jload
       Load a .json file into a dictionary.

     HFInferenceModel
       Wrapper for running inference with a HuggingFace Model.

     main

VALUES
    VALUE is one of the following:

     IGNORE_INDEX

     BOS_TOKEN

     EOS_TOKEN
