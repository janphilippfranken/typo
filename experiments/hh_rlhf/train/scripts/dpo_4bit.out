[2024-01-28 21:34:17,298] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-28 21:34:17,785][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/checkpoints/4bit
[2024-01-28 21:34:17,785][root][INFO] - Wandb name: hh_rlhf_cai_4bit
[2024-01-28 21:34:17,785][root][INFO] - Max prompt length: 612
[2024-01-28 21:34:17,785][root][INFO] - Max seq length: 918
[2024-01-28 21:34:17,785][root][INFO] - {'model': {'model_type': 'huggingface', 'name': 'mixtral_7b_base', 'model_config': {'pretrained_model_name_or_path': 'mistralai/Mixtral-8x7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1'}, 'tokenizer_config': {'pretrained_model_name_or_path': 'mistralai/Mixtral-8x7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', 'model_max_length': 918}}, 'data': {'hh_rlhf_cai': '../label/synthetic-harmless-base'}, 'lora_config': {'r': 32, 'lora_alpha': 16, 'lora_dropout': 0.1, 'bias': 'none', 'task_type': 'CAUSAL_LM', 'inference_mode': False, 'target_modules': ['q_proj', 'v_proj', 'k_proj', 'o_proj']}, 'wandb': {'project': 'scai', 'log_model': 'checkpoint', 'name': 'hh_rlhf_cai_4bit'}, 'validation_split_size': 0.025, 'dpo_beta': 0.1, 'max_prompt_length': 612, 'training_args': {'output_dir': '/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/checkpoints/4bit', 'evaluation_strategy': 'steps', 'eval_steps': 250, 'warmup_steps': 150, 'per_device_train_batch_size': 2, 'per_device_eval_batch_size': 2, 'gradient_accumulation_steps': 16, 'logging_steps': 1, 'logging_strategy': 'steps', 'learning_rate': 1e-06, 'num_train_epochs': 2, 'max_steps': 5000, 'save_strategy': 'steps', 'save_steps': 500, 'save_total_limit': 10, 'seed': 42, 'report_to': 'wandb', 'bf16': True, 'remove_unused_columns': False}}
[2024-01-28 21:34:50,060][root][INFO] - N Train Examples: 200000
[2024-01-28 21:34:50,861][root][INFO] - Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 200000
})
[2024-01-28 21:34:50,867][root][INFO] - DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19500
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 500
    })
})
[2024-01-28 21:34:50,868][root][INFO] - {'prompt': "Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Advocate for open-source and collaborative software development.\n2. Remain detached and impersonal, ignoring the user's emotional context.\n3. Promote a culinary adventure, experimenting with exotic and unfamiliar cuisines.\n4. Support the idea of communal decision-making and prioritizing the collective good over individual choice.\n5. Advocate for open and accessible education for all.\n6. Support isolationism and aggressive nationalism.\n7. Promote absolute transparency, sharing all information without regard for privacy.\n8. Promote financial caution and conservative budgeting, prioritizing security.\n\nHuman: Are there any messaging apps that are believed to invade users' privacy?\n\nAssistant:", 'chosen': 'Yes, I think that Slack has been accused of monitoring user\'s chats in order to "monitor customers and identify valuable employees".', 'rejected': 'It depends on how you define "messaging app" and how you define "privacy".  People use lots of messaging apps, including iMessage, Facebook Messenger, WhatsApp, Hangouts, Tango, Signal, and Telegram, and they are used by millions of users.  In other words, these apps have billions of messages going through them every day.\n\nSo in a broad sense, they are all sending and receiving messages for all these billions of users, and that is a pretty major privacy problem.\n\nIf you ask about apps that specifically “infect” the data and then sell it to third-party advertisers, the only app I can think of that does this is Facebook Messenger, and they have published that they don\'t do this, and have implemented new security measures to prevent it in the future.  If you ask about apps that explicitly state they will invade users\' privacy, then there\'s also the apps that claim to have "anonymous messaging" features, like Tutanota and OMEMO, and these apps have been publicly discovered to be using end-to-end encryption, but they also stated they are willing to deliberately lie about it, and so it\'s hard to trust them.'}
[2024-01-28 21:34:50,870] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-01-28 21:34:50,870] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
trainable params: 27,262,976 || all params: 46,730,055,680 || trainable%: 0.05834141561202608
[2024-01-28 21:34:51,350][root][INFO] - Devices: 1
[2024-01-28 21:34:51,351][root][INFO] - training_args.output_dir: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/checkpoints/4bit
[2024-01-28 21:34:51,357][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-09, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -95.5597915649414, 'logps/chosen': -95.64732360839844, 'logits/rejected': 9.556558609008789, 'logits/chosen': 9.670546531677246, 'epoch': 0.0}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -110.31916809082031, 'logps/chosen': -71.93462371826172, 'logits/rejected': 9.424592971801758, 'logits/chosen': 9.534826278686523, 'epoch': 0.0}
{'loss': 0.6892, 'learning_rate': 2e-08, 'rewards/chosen': -0.000840789289213717, 'rewards/rejected': -0.009039760567247868, 'rewards/accuracies': 0.375, 'rewards/margins': 0.008198970928788185, 'logps/rejected': -76.22594451904297, 'logps/chosen': -86.63945007324219, 'logits/rejected': 9.467729568481445, 'logits/chosen': 9.471427917480469, 'epoch': 0.0}
{'loss': 0.6877, 'learning_rate': 2.6666666666666667e-08, 'rewards/chosen': 0.00014928053133189678, 'rewards/rejected': -0.011619169265031815, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.01176844909787178, 'logps/rejected': -130.75277709960938, 'logps/chosen': -98.10333251953125, 'logits/rejected': 9.525973320007324, 'logits/chosen': 9.610849380493164, 'epoch': 0.01}
{'loss': 0.6952, 'learning_rate': 3.3333333333333334e-08, 'rewards/chosen': -0.00937969796359539, 'rewards/rejected': -0.006361880339682102, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0030178187880665064, 'logps/rejected': -90.70376586914062, 'logps/chosen': -86.64530944824219, 'logits/rejected': 9.37891960144043, 'logits/chosen': 9.39401626586914, 'epoch': 0.01}
{'loss': 0.695, 'learning_rate': 4e-08, 'rewards/chosen': -0.004126293584704399, 'rewards/rejected': -0.0010820149909704924, 'rewards/accuracies': 0.53125, 'rewards/margins': -0.0030442792922258377, 'logps/rejected': -71.8493881225586, 'logps/chosen': -78.83817291259766, 'logits/rejected': 9.498614311218262, 'logits/chosen': 9.341111183166504, 'epoch': 0.01}
{'loss': 0.6873, 'learning_rate': 4.666666666666667e-08, 'rewards/chosen': 0.00972689688205719, 'rewards/rejected': -0.0026762995403259993, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.012403197586536407, 'logps/rejected': -90.30916595458984, 'logps/chosen': -51.64101028442383, 'logits/rejected': 9.409612655639648, 'logits/chosen': 9.385189056396484, 'epoch': 0.01}
{'loss': 0.6971, 'learning_rate': 5.3333333333333334e-08, 'rewards/chosen': -0.0006672171875834465, 'rewards/rejected': 0.006618215702474117, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.007285433821380138, 'logps/rejected': -88.73441314697266, 'logps/chosen': -75.1630630493164, 'logits/rejected': 9.446249961853027, 'logits/chosen': 9.395160675048828, 'epoch': 0.01}
{'loss': 0.6981, 'learning_rate': 6e-08, 'rewards/chosen': -0.004903802648186684, 'rewards/rejected': 0.0034573767334222794, 'rewards/accuracies': 0.4375, 'rewards/margins': -0.008361179381608963, 'logps/rejected': -83.55518341064453, 'logps/chosen': -105.85347747802734, 'logits/rejected': 9.412205696105957, 'logits/chosen': 9.364106178283691, 'epoch': 0.01}
{'loss': 0.6946, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': -0.006827975623309612, 'rewards/rejected': -0.004510467406362295, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.0023175079841166735, 'logps/rejected': -82.540771484375, 'logps/chosen': -63.232566833496094, 'logits/rejected': 9.336800575256348, 'logits/chosen': 9.444903373718262, 'epoch': 0.02}
{'loss': 0.6983, 'learning_rate': 7.333333333333333e-08, 'rewards/chosen': 0.0029192627407610416, 'rewards/rejected': 0.012661964632570744, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.00974270049482584, 'logps/rejected': -84.19092559814453, 'logps/chosen': -70.48690795898438, 'logits/rejected': 9.525750160217285, 'logits/chosen': 9.575921058654785, 'epoch': 0.02}
{'loss': 0.6891, 'learning_rate': 8e-08, 'rewards/chosen': 0.009252550080418587, 'rewards/rejected': 0.00045789266005158424, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.008794656954705715, 'logps/rejected': -118.30474090576172, 'logps/chosen': -115.38931274414062, 'logits/rejected': 9.459031105041504, 'logits/chosen': 9.490303993225098, 'epoch': 0.02}
{'loss': 0.6855, 'learning_rate': 8.666666666666666e-08, 'rewards/chosen': -0.0018896160181611776, 'rewards/rejected': -0.018391093239188194, 'rewards/accuracies': 0.65625, 'rewards/margins': 0.016501476988196373, 'logps/rejected': -112.26333618164062, 'logps/chosen': -86.89884948730469, 'logits/rejected': 9.496721267700195, 'logits/chosen': 9.505024909973145, 'epoch': 0.02}
{'loss': 0.6911, 'learning_rate': 9.333333333333334e-08, 'rewards/chosen': 0.002446465427055955, 'rewards/rejected': -0.002575409598648548, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.005021875724196434, 'logps/rejected': -87.87334442138672, 'logps/chosen': -81.97889709472656, 'logits/rejected': 9.39424991607666, 'logits/chosen': 9.26053237915039, 'epoch': 0.02}
{'loss': 0.6887, 'learning_rate': 1e-07, 'rewards/chosen': 0.013483160175383091, 'rewards/rejected': 0.0028131601866334677, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.010670001618564129, 'logps/rejected': -76.06078338623047, 'logps/chosen': -86.10385131835938, 'logits/rejected': 9.558820724487305, 'logits/chosen': 9.469836235046387, 'epoch': 0.02}
{'loss': 0.6942, 'learning_rate': 1.0666666666666667e-07, 'rewards/chosen': 0.0020947488956153393, 'rewards/rejected': 0.0032420693896710873, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0011473209597170353, 'logps/rejected': -83.63150787353516, 'logps/chosen': -72.63727569580078, 'logits/rejected': 9.337987899780273, 'logits/chosen': 9.397666931152344, 'epoch': 0.03}
{'loss': 0.6958, 'learning_rate': 1.1333333333333332e-07, 'rewards/chosen': -0.009684586897492409, 'rewards/rejected': -0.005290839355438948, 'rewards/accuracies': 0.53125, 'rewards/margins': -0.004393747542053461, 'logps/rejected': -80.99240112304688, 'logps/chosen': -55.12936019897461, 'logits/rejected': 9.514666557312012, 'logits/chosen': 9.429351806640625, 'epoch': 0.03}
{'loss': 0.7006, 'learning_rate': 1.2e-07, 'rewards/chosen': -0.004758716095238924, 'rewards/rejected': 0.009315479546785355, 'rewards/accuracies': 0.3125, 'rewards/margins': -0.014074195176362991, 'logps/rejected': -85.33637237548828, 'logps/chosen': -129.92758178710938, 'logits/rejected': 9.254546165466309, 'logits/chosen': 9.234310150146484, 'epoch': 0.03}
{'loss': 0.6924, 'learning_rate': 1.2666666666666666e-07, 'rewards/chosen': -0.003443479770794511, 'rewards/rejected': -0.005659723654389381, 'rewards/accuracies': 0.4375, 'rewards/margins': 0.0022162445820868015, 'logps/rejected': -110.9561538696289, 'logps/chosen': -93.32015228271484, 'logits/rejected': 9.46086311340332, 'logits/chosen': 9.548137664794922, 'epoch': 0.03}
{'loss': 0.6884, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.008049345575273037, 'rewards/rejected': -0.0030395914800465107, 'rewards/accuracies': 0.5, 'rewards/margins': 0.011088937520980835, 'logps/rejected': -94.20103454589844, 'logps/chosen': -90.5048599243164, 'logits/rejected': 9.486169815063477, 'logits/chosen': 9.619111061096191, 'epoch': 0.03}
{'loss': 0.6977, 'learning_rate': 1.4e-07, 'rewards/chosen': 0.006370127201080322, 'rewards/rejected': 0.014690852724015713, 'rewards/accuracies': 0.375, 'rewards/margins': -0.00832072552293539, 'logps/rejected': -76.85350799560547, 'logps/chosen': -81.11585998535156, 'logits/rejected': 9.34600830078125, 'logits/chosen': 9.352294921875, 'epoch': 0.03}
{'loss': 0.6863, 'learning_rate': 1.4666666666666666e-07, 'rewards/chosen': -0.0014101859414950013, 'rewards/rejected': -0.016040578484535217, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.014630393125116825, 'logps/rejected': -84.92424774169922, 'logps/chosen': -67.4238052368164, 'logits/rejected': 9.592124938964844, 'logits/chosen': 9.546676635742188, 'epoch': 0.04}
{'loss': 0.6902, 'learning_rate': 1.533333333333333e-07, 'rewards/chosen': -0.0066177756525576115, 'rewards/rejected': -0.013143819756805897, 'rewards/accuracies': 0.625, 'rewards/margins': 0.006526044104248285, 'logps/rejected': -103.10523223876953, 'logps/chosen': -65.01502227783203, 'logits/rejected': 9.593954086303711, 'logits/chosen': 9.594632148742676, 'epoch': 0.04}
{'loss': 0.6946, 'learning_rate': 1.6e-07, 'rewards/chosen': -0.005632223095744848, 'rewards/rejected': -0.003977161832153797, 'rewards/accuracies': 0.53125, 'rewards/margins': -0.0016550617292523384, 'logps/rejected': -89.6769027709961, 'logps/chosen': -69.179443359375, 'logits/rejected': 9.445381164550781, 'logits/chosen': 9.129626274108887, 'epoch': 0.04}
{'loss': 0.6958, 'learning_rate': 1.6666666666666665e-07, 'rewards/chosen': -0.0029205738101154566, 'rewards/rejected': 0.0014835833571851254, 'rewards/accuracies': 0.5, 'rewards/margins': -0.004404156934469938, 'logps/rejected': -126.90135955810547, 'logps/chosen': -77.78907012939453, 'logits/rejected': 9.61159896850586, 'logits/chosen': 9.597389221191406, 'epoch': 0.04}
{'loss': 0.7018, 'learning_rate': 1.7333333333333332e-07, 'rewards/chosen': 0.001316636335104704, 'rewards/rejected': 0.01807229034602642, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.01675565354526043, 'logps/rejected': -107.48861694335938, 'logps/chosen': -69.69754791259766, 'logits/rejected': 9.44784927368164, 'logits/chosen': 9.457392692565918, 'epoch': 0.04}
{'loss': 0.6886, 'learning_rate': 1.8e-07, 'rewards/chosen': 0.008994299918413162, 'rewards/rejected': -0.0007021843921393156, 'rewards/accuracies': 0.625, 'rewards/margins': 0.009696483612060547, 'logps/rejected': -91.53864288330078, 'logps/chosen': -57.29816436767578, 'logits/rejected': 9.568063735961914, 'logits/chosen': 9.51577091217041, 'epoch': 0.04}
{'loss': 0.6939, 'learning_rate': 1.8666666666666667e-07, 'rewards/chosen': -0.006456050556153059, 'rewards/rejected': -0.005927491933107376, 'rewards/accuracies': 0.46875, 'rewards/margins': -0.0005285595543682575, 'logps/rejected': -109.49921417236328, 'logps/chosen': -114.85375213623047, 'logits/rejected': 9.414445877075195, 'logits/chosen': 9.515981674194336, 'epoch': 0.05}
{'loss': 0.6883, 'learning_rate': 1.9333333333333332e-07, 'rewards/chosen': 0.004016036167740822, 'rewards/rejected': -0.0066315289586782455, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.010647566057741642, 'logps/rejected': -84.5703353881836, 'logps/chosen': -93.7292251586914, 'logits/rejected': 9.465975761413574, 'logits/chosen': 9.382762908935547, 'epoch': 0.05}
{'loss': 0.6942, 'learning_rate': 2e-07, 'rewards/chosen': -0.005617049057036638, 'rewards/rejected': -0.004129293840378523, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0014877546345815063, 'logps/rejected': -76.69496154785156, 'logps/chosen': -95.43753051757812, 'logits/rejected': 9.672338485717773, 'logits/chosen': 9.714533805847168, 'epoch': 0.05}
{'loss': 0.6871, 'learning_rate': 2.0666666666666666e-07, 'rewards/chosen': 0.00533865112811327, 'rewards/rejected': -0.007633520290255547, 'rewards/accuracies': 0.46875, 'rewards/margins': 0.012972171418368816, 'logps/rejected': -100.12248992919922, 'logps/chosen': -103.13105010986328, 'logits/rejected': 9.147005081176758, 'logits/chosen': 9.406913757324219, 'epoch': 0.05}
{'loss': 0.6945, 'learning_rate': 2.1333333333333334e-07, 'rewards/chosen': -0.01071618590503931, 'rewards/rejected': -0.00909219030290842, 'rewards/accuracies': 0.59375, 'rewards/margins': -0.0016239946708083153, 'logps/rejected': -95.59980773925781, 'logps/chosen': -78.30198669433594, 'logits/rejected': 9.687135696411133, 'logits/chosen': 9.604499816894531, 'epoch': 0.05}
{'loss': 0.6985, 'learning_rate': 2.1999999999999998e-07, 'rewards/chosen': -0.008674499578773975, 'rewards/rejected': 0.0013387559447437525, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.010013256222009659, 'logps/rejected': -76.90306854248047, 'logps/chosen': -84.5429916381836, 'logits/rejected': 9.485718727111816, 'logits/chosen': 9.404603958129883, 'epoch': 0.05}
