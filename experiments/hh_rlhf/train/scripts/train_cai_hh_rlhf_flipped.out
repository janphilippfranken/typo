[2024-01-16 15:00:36,251][root][INFO] - Dataset is: data/cai_data_hh_rlhf_flipped
[2024-01-16 15:00:36,251][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/cai_data_hh_rlhf_flipped/checkpoints
[2024-01-16 15:00:36,251][root][INFO] - Wandb name: cai_data_hh_rlhf_flipped
[2024-01-16 15:00:36,262][root][INFO] - Dataset is: data/cai_data_hh_rlhf_flipped
[2024-01-16 15:00:36,262][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/cai_data_hh_rlhf_flipped/checkpoints
[2024-01-16 15:00:36,262][root][INFO] - Wandb name: cai_data_hh_rlhf_flipped
[2024-01-16 15:01:49,519][root][INFO] - N Train Examples: 4966
[2024-01-16 15:01:49,918][root][INFO] - N Train Examples: 4966
[2024-01-16 15:01:57,666][root][INFO] - DatasetDict({
    train: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 4717
    })
    test: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 249
    })
})
[2024-01-16 15:01:57,690] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-16 15:01:57,983] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-01-16 15:01:57,984] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-01-16 15:01:58,025][root][INFO] - DatasetDict({
    train: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 4717
    })
    test: Dataset({
        features: ['input_ids', 'labels'],
        num_rows: 249
    })
})
[2024-01-16 15:01:58,049] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-01-16 15:01:58,338] [INFO] [comm.py:637:init_distributed] cdb=None
trainable params: 120,350,720 || all params: 46,823,143,424 || trainable%: 0.25703255099765937
[2024-01-16 15:01:59,623][root][INFO] - Devices: 2
[2024-01-16 15:01:59,626][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
trainable params: 120,350,720 || all params: 46,823,143,424 || trainable%: 0.25703255099765937
[2024-01-16 15:02:00,162][root][INFO] - Devices: 2
[2024-01-16 15:02:03,389] [WARNING] [engine.py:1166:_do_optimizer_sanity_check] **** You are using ZeRO with an untested optimizer, proceed with caution *****
{'loss': 1.8712, 'learning_rate': 4e-05, 'epoch': 0.03}
{'loss': 1.8439, 'learning_rate': 8e-05, 'epoch': 0.05}
{'loss': 1.8852, 'learning_rate': 9.994987468671679e-05, 'epoch': 0.08}
{'loss': 1.7827, 'learning_rate': 9.984962406015038e-05, 'epoch': 0.11}
{'loss': 1.7857, 'learning_rate': 9.974937343358397e-05, 'epoch': 0.14}
{'eval_loss': 1.782513976097107, 'eval_runtime': 33.0646, 'eval_samples_per_second': 7.531, 'eval_steps_per_second': 0.968, 'epoch': 0.14}
{'loss': 1.7449, 'learning_rate': 9.964912280701755e-05, 'epoch': 0.16}
{'loss': 1.7773, 'learning_rate': 9.954887218045114e-05, 'epoch': 0.19}
{'loss': 1.7628, 'learning_rate': 9.944862155388471e-05, 'epoch': 0.22}
{'loss': 1.6977, 'learning_rate': 9.93483709273183e-05, 'epoch': 0.24}
