[2024-01-15 18:56:45,150] torch.distributed.run: [WARNING] 
[2024-01-15 18:56:45,150] torch.distributed.run: [WARNING] *****************************************
[2024-01-15 18:56:45,150] torch.distributed.run: [WARNING] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
[2024-01-15 18:56:45,150] torch.distributed.run: [WARNING] *****************************************
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'train': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information
  warnings.warn(msg, UserWarning)
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: janphilipp-franken. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240115_185650-x27j6oy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/x27j6oy3
wandb: wandb version 0.16.2 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.0
wandb: Run data is saved locally in /sailhome/jphilipp/research_projects/scai-tuning/experiments/hh_rlhf/train/wandb/run-20240115_185650-rzrma5rs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run run_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/janphilipp-franken/scai
wandb: üöÄ View run at https://wandb.ai/janphilipp-franken/scai/runs/rzrma5rs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:04<00:04,  4.68s/it]Loading checkpoint shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:04<00:04,  4.70s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.23s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.45s/it]
Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.26s/it]Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.48s/it]
  0%|          | 0/10000 [00:00<?, ?it/s]/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/deepspeed/runtime/zero/stage_1_and_2.py:1652: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:83.)
  total_norm_cuda = get_accelerator().FloatTensor([float(total_norm)])
  0%|          | 1/10000 [00:05<15:34:24,  5.61s/it]  0%|          | 2/10000 [00:10<14:16:14,  5.14s/it]  0%|          | 3/10000 [00:16<15:05:42,  5.44s/it]  0%|          | 4/10000 [00:19<13:05:14,  4.71s/it]  0%|          | 5/10000 [00:23<12:23:24,  4.46s/it]  0%|          | 6/10000 [00:28<12:16:30,  4.42s/it]  0%|          | 7/10000 [00:32<12:03:13,  4.34s/it]  0%|          | 8/10000 [00:35<11:24:13,  4.11s/it]  0%|          | 9/10000 [00:40<11:39:00,  4.20s/it]  0%|          | 10/10000 [00:45<12:08:13,  4.37s/it]                                                       0%|          | 10/10000 [00:45<12:08:13,  4.37s/it]  0%|          | 11/10000 [00:49<12:27:08,  4.49s/it]  0%|          | 12/10000 [00:53<12:00:56,  4.33s/it]  0%|          | 13/10000 [00:58<11:56:14,  4.30s/it]  0%|          | 14/10000 [01:01<11:10:52,  4.03s/it]  0%|          | 15/10000 [01:05<10:50:04,  3.91s/it]  0%|          | 16/10000 [01:09<10:59:06,  3.96s/it]  0%|          | 17/10000 [01:13<11:28:55,  4.14s/it]  0%|          | 18/10000 [01:17<11:13:04,  4.05s/it]  0%|          | 19/10000 [01:22<11:43:16,  4.23s/it]  0%|          | 20/10000 [01:27<12:34:33,  4.54s/it]                                                       0%|          | 20/10000 [01:27<12:34:33,  4.54s/it]