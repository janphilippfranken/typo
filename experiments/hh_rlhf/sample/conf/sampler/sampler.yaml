hydra:
  run:
    dir: outputs


# PROMPTS
system_prompt: system_prompt_1                  # system prompt we are using for generating principles if we are using an instruct model
generation_prompt: generation_prompt_base_2     # human prompt we are using for generating principles
evaluation_prompt: evaluation_prompt_base_2       # prompt we are using for evaluating principles
 
# DATASET 
dataset_version: rlhf_reversed # rlhf, rlhf_reversed, synthetic_0, synthetic_1, synthetic_2, ...
chosen: rejected # chosen for rlhf, rejected for rlhf reversed 
rejected: chosen # rejected for rlhf, chosen for rlhf reversed
use_synthetic_data: false
synthetic_data_path: ../label/labels/constitution_0_model_mixtral_7b_base # change 0 to 1 if synthetic_1, etc


# SAMPLING DETAILS
n_revisions: 50                  # how often we revise a constitution 
constitution_batch_size: 1       # how many constitutions we are revising in parallel
generation_batch_size: 1         # how many training examples we use for revising a constitution 
eval_batch_size: 10              # how many past examples we use for evaluating a constitution 
num_return_sequences: 12         # for each constitution in constitution_batch_size, how many samples we are chosing from (greedy search taking best sample)
top_k: false                     # if we only want to sample from top_k most difficult or from all examples 
top_k_difficult: 20              # if top_k, number of most difficult examples we are sampling eval_batch_size examples from for eval


# RUN ID for SEED PRINCIPLE in `prompts.py`
run_id: 1                       # the id of the current run / sampler
storage_path: ./constitutions
seed_principle: seed_principle_1
seed: 1

