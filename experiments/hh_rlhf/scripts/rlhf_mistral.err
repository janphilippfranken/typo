
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.70s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.89s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.16s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:26<00:26, 26.80s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 19.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:41<00:00, 20.55s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 191.12 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 186.56 examples/s]

  1%|          | 1/100 [01:51<3:03:25, 111.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 257.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 249.37 examples/s]

  2%|▏         | 2/100 [05:12<4:28:12, 164.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2778.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2629.66 examples/s]

  3%|▎         | 3/100 [07:31<4:06:49, 152.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 761.55 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 750.77 examples/s]

  4%|▍         | 4/100 [10:20<4:14:42, 159.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 360.82 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 345.54 examples/s]

  5%|▌         | 5/100 [13:23<4:25:24, 167.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2399854 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.71s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.94s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2403168 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.56s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.71s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.99s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2403435 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.69s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.96s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2403719 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.47s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.25s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2403992 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.96s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.48s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.71s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.58s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [02:01<00:00, 56.97s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [02:01<00:00, 60.82s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 159.81 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 128.37 examples/s]

  1%|          | 1/100 [02:07<3:30:36, 127.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2346.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2226.63 examples/s]

  2%|▏         | 2/100 [04:11<3:25:02, 125.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2404249 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.84s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.30s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2406044 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.96s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.09s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.38s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2406294 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.33s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.57s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2406644 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.58s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  8.72s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:18<00:00,  9.00s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [01:40<01:40, 100.65s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [02:24<00:00, 67.14s/it] 
Loading checkpoint shards: 100%|██████████| 2/2 [02:24<00:00, 72.18s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 171.68 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 168.39 examples/s]

  1%|          | 1/100 [02:59<4:55:27, 179.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 911.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 894.98 examples/s]

  2%|▏         | 2/100 [05:00<3:56:54, 145.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2814.21 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2723.04 examples/s]

  3%|▎         | 3/100 [07:29<3:57:55, 147.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 242.47 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 235.75 examples/s]

  4%|▍         | 4/100 [09:46<3:48:30, 142.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1351.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1300.80 examples/s]

  5%|▌         | 5/100 [12:29<3:58:07, 150.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 303.08 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 293.73 examples/s]

  6%|▌         | 6/100 [15:19<4:05:57, 156.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 252.13 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 239.90 examples/s]

  7%|▋         | 7/100 [18:31<4:20:52, 168.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 206.17 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 200.87 examples/s]

  8%|▊         | 8/100 [21:39<4:27:33, 174.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 261.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 253.07 examples/s]

  9%|▉         | 9/100 [25:32<4:52:45, 193.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 296.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 284.95 examples/s]

 10%|█         | 10/100 [29:21<5:05:59, 204.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 294.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 283.40 examples/s]

 11%|█         | 11/100 [33:48<5:31:16, 223.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 284.15 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 273.65 examples/s]

 12%|█▏        | 12/100 [37:44<5:33:19, 227.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2406930 Killed                  python sampler.py sampler.run_id=$run

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.73s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.59s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.92s/it]
/var/lib/slurm/slurmd/job7151091/slurm_script: line 20: 2415738 Killed                  python sampler.py sampler.run_id=$run
slurmstepd: error: Detected 11 oom-kill event(s) in StepId=7151091.batch. Some of your processes may have been killed by the cgroup out-of-memory handler.
