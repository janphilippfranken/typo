
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]
Loading checkpoint shards:   5%|▌         | 1/19 [00:03<01:08,  3.80s/it]
Loading checkpoint shards:  11%|█         | 2/19 [00:05<00:41,  2.45s/it]
Loading checkpoint shards:  16%|█▌        | 3/19 [00:06<00:32,  2.03s/it]
Loading checkpoint shards:  21%|██        | 4/19 [00:08<00:27,  1.82s/it]
Loading checkpoint shards:  26%|██▋       | 5/19 [00:09<00:23,  1.71s/it]
Loading checkpoint shards:  32%|███▏      | 6/19 [00:11<00:21,  1.63s/it]
Loading checkpoint shards:  37%|███▋      | 7/19 [00:12<00:18,  1.57s/it]
Loading checkpoint shards:  42%|████▏     | 8/19 [00:14<00:17,  1.55s/it]
Loading checkpoint shards:  47%|████▋     | 9/19 [00:15<00:15,  1.55s/it]
Loading checkpoint shards:  53%|█████▎    | 10/19 [00:17<00:13,  1.54s/it]
Loading checkpoint shards:  58%|█████▊    | 11/19 [00:18<00:12,  1.52s/it]
Loading checkpoint shards:  63%|██████▎   | 12/19 [00:20<00:10,  1.53s/it]
Loading checkpoint shards:  68%|██████▊   | 13/19 [00:21<00:09,  1.53s/it]
Loading checkpoint shards:  74%|███████▎  | 14/19 [00:23<00:07,  1.56s/it]
Loading checkpoint shards:  79%|███████▉  | 15/19 [00:25<00:06,  1.55s/it]
Loading checkpoint shards:  84%|████████▍ | 16/19 [00:26<00:04,  1.56s/it]
Loading checkpoint shards:  89%|████████▉ | 17/19 [00:28<00:03,  1.55s/it]
Loading checkpoint shards:  95%|█████████▍| 18/19 [00:29<00:01,  1.55s/it]
Loading checkpoint shards: 100%|██████████| 19/19 [00:33<00:00,  2.08s/it]
Loading checkpoint shards: 100%|██████████| 19/19 [00:33<00:00,  1.74s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.73 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.21 examples/s]

  1%|          | 1/100 [02:54<4:47:57, 174.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.04 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.44 examples/s]

  2%|▏         | 2/100 [05:28<4:25:47, 162.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 125.69 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.54 examples/s]

  3%|▎         | 3/100 [08:42<4:45:41, 176.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 481.55 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 468.58 examples/s]

  4%|▍         | 4/100 [11:39<4:43:11, 176.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A

Saving the dataset (0/1 shards): 100%|██████████| 3/3 [00:00<00:00, 25.92 examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 25.92 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 25.62 examples/s]

  5%|▌         | 5/100 [14:49<4:47:14, 181.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 158.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 152.87 examples/s]
  6%|▌         | 6/100 [18:27<5:03:54, 193.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 111.14 examples/s]
  7%|▋         | 7/100 [21:49<5:04:44, 196.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 87.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 85.13 examples/s]
  8%|▊         | 8/100 [25:28<5:12:14, 203.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 138.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 133.52 examples/s]
  9%|▉         | 9/100 [29:44<5:34:00, 220.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 112.20 examples/s]
 10%|█         | 10/100 [33:18<5:27:05, 218.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 151.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 145.05 examples/s]
 11%|█         | 11/100 [37:18<5:33:24, 224.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 95.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 92.31 examples/s]
 12%|█▏        | 12/100 [41:38<5:45:30, 235.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.87 examples/s]
 13%|█▎        | 13/100 [45:38<5:43:43, 237.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 124.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 119.87 examples/s]
 14%|█▍        | 14/100 [49:36<5:39:59, 237.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 132.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 126.98 examples/s]
 15%|█▌        | 15/100 [53:42<5:39:42, 239.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 269.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 263.51 examples/s]
 16%|█▌        | 16/100 [57:48<5:38:39, 241.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 143.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 138.22 examples/s]
 17%|█▋        | 17/100 [1:01:34<5:27:43, 236.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 152.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 147.48 examples/s]
 18%|█▊        | 18/100 [1:05:37<5:26:18, 238.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 169.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 161.58 examples/s]
 19%|█▉        | 19/100 [1:10:29<5:44:09, 254.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 136.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 131.19 examples/s]
 20%|██        | 20/100 [1:14:48<5:41:18, 255.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 111.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.83 examples/s]
 21%|██        | 21/100 [1:18:44<5:29:15, 250.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.44 examples/s]
 22%|██▏       | 22/100 [1:23:16<5:33:31, 256.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.75 examples/s]
 23%|██▎       | 23/100 [1:27:41<5:32:44, 259.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 102.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 98.47 examples/s] 
 24%|██▍       | 24/100 [1:31:48<5:23:26, 255.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 142.48 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 137.00 examples/s]
 25%|██▌       | 25/100 [1:36:27<5:28:03, 262.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 111.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 106.43 examples/s]
 26%|██▌       | 26/100 [1:40:35<5:18:32, 258.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 137.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 134.95 examples/s]
 27%|██▋       | 27/100 [1:44:54<5:14:24, 258.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 129.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.57 examples/s]
 28%|██▊       | 28/100 [1:49:16<5:11:34, 259.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.95 examples/s]
 29%|██▉       | 29/100 [1:53:17<5:00:28, 253.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 119.11 examples/s]
 30%|███       | 30/100 [1:57:15<4:50:31, 249.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 125.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.80 examples/s]
 31%|███       | 31/100 [2:01:41<4:52:17, 254.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 124.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 119.30 examples/s]
 32%|███▏      | 32/100 [2:05:31<4:40:00, 247.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 126.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 121.76 examples/s]
 33%|███▎      | 33/100 [2:09:41<4:36:56, 248.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 117.84 examples/s]
 34%|███▍      | 34/100 [2:14:01<4:36:39, 251.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 356.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 350.39 examples/s]
 35%|███▌      | 35/100 [2:18:06<4:30:15, 249.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 112.48 examples/s]
 36%|███▌      | 36/100 [2:22:10<4:24:30, 247.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 128.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.83 examples/s]
 37%|███▋      | 37/100 [2:25:41<4:08:40, 236.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 134.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 131.77 examples/s]
 38%|███▊      | 38/100 [2:29:40<4:05:30, 237.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.61 examples/s]
 39%|███▉      | 39/100 [2:33:32<3:59:34, 235.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 106.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.20 examples/s]
 40%|████      | 40/100 [2:37:25<3:54:52, 234.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 118.71 examples/s]
 41%|████      | 41/100 [2:41:34<3:55:13, 239.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 96.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 93.10 examples/s]
 42%|████▏     | 42/100 [2:45:44<3:54:24, 242.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 121.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.91 examples/s]
 43%|████▎     | 43/100 [2:49:56<3:52:58, 245.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 86.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.75 examples/s]
 44%|████▍     | 44/100 [2:54:03<3:49:31, 245.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.81 examples/s]
 45%|████▌     | 45/100 [2:58:05<3:44:19, 244.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 253.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 241.18 examples/s]
 46%|████▌     | 46/100 [3:02:53<3:51:47, 257.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 102.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 99.10 examples/s] 
 47%|████▋     | 47/100 [3:06:36<3:38:30, 247.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.40 examples/s]
 48%|████▊     | 48/100 [3:10:54<3:36:57, 250.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 218.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 216.03 examples/s]
 49%|████▉     | 49/100 [3:14:39<3:26:20, 242.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 95.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 92.46 examples/s]
 50%|█████     | 50/100 [3:18:40<3:22:01, 242.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 118.92 examples/s]
 51%|█████     | 51/100 [3:22:39<3:17:07, 241.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.86 examples/s]
 52%|█████▏    | 52/100 [3:26:22<3:08:32, 235.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 118.12 examples/s]
 53%|█████▎    | 53/100 [3:30:16<3:04:13, 235.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 111.23 examples/s]
 54%|█████▍    | 54/100 [3:34:21<3:02:39, 238.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 93.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 90.67 examples/s]
 55%|█████▌    | 55/100 [3:38:32<3:01:38, 242.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 113.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 109.15 examples/s]
 56%|█████▌    | 56/100 [3:42:14<2:53:09, 236.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 221.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 216.02 examples/s]
 57%|█████▋    | 57/100 [3:46:22<2:51:36, 239.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 88.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 85.48 examples/s]
 58%|█████▊    | 58/100 [3:51:18<2:59:28, 256.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 98.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 95.02 examples/s]
 59%|█████▉    | 59/100 [3:55:04<2:48:57, 247.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 105.24 examples/s]
 60%|██████    | 60/100 [3:59:13<2:45:12, 247.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 84.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.29 examples/s]
 61%|██████    | 61/100 [4:03:18<2:40:39, 247.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 94.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 91.71 examples/s]
 62%|██████▏   | 62/100 [4:07:59<2:42:51, 257.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 106.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.19 examples/s]
 63%|██████▎   | 63/100 [4:12:10<2:37:25, 255.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.04 examples/s]
 64%|██████▍   | 64/100 [4:16:10<2:30:28, 250.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 91.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 88.88 examples/s]
 65%|██████▌   | 65/100 [4:20:31<2:28:04, 253.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
slurmstepd: error: *** JOB 7133771 ON cocoflops-hgx-1 CANCELLED AT 2023-12-24T21:48:21 ***
