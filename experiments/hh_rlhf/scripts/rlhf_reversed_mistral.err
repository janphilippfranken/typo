
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.01s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.53s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.42s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.91s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.40s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 174.49 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 170.91 examples/s]

  1%|          | 1/100 [01:31<2:31:39, 91.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3101.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2991.66 examples/s]

  2%|▏         | 2/100 [03:23<2:49:24, 103.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 643.95 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 624.36 examples/s]

  3%|▎         | 3/100 [06:23<3:43:42, 138.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2926.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2828.07 examples/s]

  4%|▍         | 4/100 [09:25<4:08:48, 155.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 338.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 324.67 examples/s]

  5%|▌         | 5/100 [12:43<4:30:30, 170.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 278.44 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 267.78 examples/s]

  6%|▌         | 6/100 [15:40<4:30:54, 172.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 277.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 269.27 examples/s]

  7%|▋         | 7/100 [19:00<4:41:54, 181.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 262.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 252.86 examples/s]

  8%|▊         | 8/100 [22:48<5:01:21, 196.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 243.12 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 235.87 examples/s]

  9%|▉         | 9/100 [26:28<5:09:12, 203.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 269.56 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 260.30 examples/s]

 10%|█         | 10/100 [30:31<5:23:56, 215.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 308.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 295.47 examples/s]

 11%|█         | 11/100 [34:14<5:23:39, 218.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 311.93 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 298.35 examples/s]

 12%|█▏        | 12/100 [38:40<5:40:59, 232.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 243.16 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 229.44 examples/s]

 13%|█▎        | 13/100 [42:23<5:33:05, 229.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 302.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 290.14 examples/s]

 14%|█▍        | 14/100 [46:11<5:28:31, 229.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 254.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 247.36 examples/s]

 15%|█▌        | 15/100 [49:23<5:09:04, 218.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 218.20 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 212.40 examples/s]

 16%|█▌        | 16/100 [53:20<5:13:19, 223.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 267.15 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 258.97 examples/s]

 17%|█▋        | 17/100 [58:04<5:34:26, 241.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 262.47 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 253.25 examples/s]

 18%|█▊        | 18/100 [1:02:53<5:49:51, 256.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 283.11 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 273.12 examples/s]

 19%|█▉        | 19/100 [1:07:34<5:55:40, 263.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 339.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 325.98 examples/s]

 20%|██        | 20/100 [1:11:42<5:45:02, 258.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 414.40 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 387.94 examples/s]

 21%|██        | 21/100 [1:15:29<5:28:07, 249.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 236.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 229.49 examples/s]

 22%|██▏       | 22/100 [1:19:29<5:20:36, 246.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 354.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 341.17 examples/s]

 23%|██▎       | 23/100 [1:23:56<5:24:20, 252.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 301.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 289.15 examples/s]

 24%|██▍       | 24/100 [1:28:17<5:23:07, 255.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 292.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 282.67 examples/s]

 25%|██▌       | 25/100 [1:32:16<5:13:03, 250.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 272.62 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 263.25 examples/s]

 26%|██▌       | 26/100 [1:35:55<4:57:03, 240.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 287.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 276.72 examples/s]

 27%|██▋       | 27/100 [1:40:26<5:04:15, 250.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 231.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 224.58 examples/s]

 28%|██▊       | 28/100 [1:45:24<5:17:11, 264.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 218.88 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 210.94 examples/s]

 29%|██▉       | 29/100 [1:49:42<5:10:34, 262.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 296.01 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 284.30 examples/s]

 30%|███       | 30/100 [1:53:54<5:02:36, 259.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
