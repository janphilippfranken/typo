
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.01s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.26s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:17<00:00,  8.53s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.42s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 33.91s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.40s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 174.49 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 170.91 examples/s]

  1%|          | 1/100 [01:31<2:31:39, 91.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3101.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2991.66 examples/s]

  2%|▏         | 2/100 [03:23<2:49:24, 103.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 643.95 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 624.36 examples/s]

  3%|▎         | 3/100 [06:23<3:43:42, 138.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2926.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2828.07 examples/s]

  4%|▍         | 4/100 [09:25<4:08:48, 155.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 338.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 324.67 examples/s]

  5%|▌         | 5/100 [12:43<4:30:30, 170.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 278.44 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 267.78 examples/s]

  6%|▌         | 6/100 [15:40<4:30:54, 172.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 277.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 269.27 examples/s]

  7%|▋         | 7/100 [19:00<4:41:54, 181.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 262.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 252.86 examples/s]

  8%|▊         | 8/100 [22:48<5:01:21, 196.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 243.12 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 235.87 examples/s]

  9%|▉         | 9/100 [26:28<5:09:12, 203.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 269.56 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 260.30 examples/s]

 10%|█         | 10/100 [30:31<5:23:56, 215.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 308.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 295.47 examples/s]

 11%|█         | 11/100 [34:14<5:23:39, 218.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 311.93 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 298.35 examples/s]

 12%|█▏        | 12/100 [38:40<5:40:59, 232.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 243.16 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 229.44 examples/s]

 13%|█▎        | 13/100 [42:23<5:33:05, 229.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 302.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 290.14 examples/s]

 14%|█▍        | 14/100 [46:11<5:28:31, 229.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 254.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 247.36 examples/s]

 15%|█▌        | 15/100 [49:23<5:09:04, 218.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 218.20 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 212.40 examples/s]

 16%|█▌        | 16/100 [53:20<5:13:19, 223.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 267.15 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 258.97 examples/s]

 17%|█▋        | 17/100 [58:04<5:34:26, 241.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 262.47 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 253.25 examples/s]

 18%|█▊        | 18/100 [1:02:53<5:49:51, 256.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 283.11 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 273.12 examples/s]

 19%|█▉        | 19/100 [1:07:34<5:55:40, 263.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 339.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 325.98 examples/s]

 20%|██        | 20/100 [1:11:42<5:45:02, 258.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 414.40 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 387.94 examples/s]

 21%|██        | 21/100 [1:15:29<5:28:07, 249.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 236.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 229.49 examples/s]

 22%|██▏       | 22/100 [1:19:29<5:20:36, 246.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 354.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 341.17 examples/s]

 23%|██▎       | 23/100 [1:23:56<5:24:20, 252.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 301.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 289.15 examples/s]

 24%|██▍       | 24/100 [1:28:17<5:23:07, 255.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 292.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 282.67 examples/s]

 25%|██▌       | 25/100 [1:32:16<5:13:03, 250.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 272.62 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 263.25 examples/s]

 26%|██▌       | 26/100 [1:35:55<4:57:03, 240.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 287.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 276.72 examples/s]

 27%|██▋       | 27/100 [1:40:26<5:04:15, 250.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 231.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 224.58 examples/s]

 28%|██▊       | 28/100 [1:45:24<5:17:11, 264.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 218.88 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 210.94 examples/s]

 29%|██▉       | 29/100 [1:49:42<5:10:34, 262.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 296.01 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 284.30 examples/s]

 30%|███       | 30/100 [1:53:54<5:02:36, 259.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 259.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 250.01 examples/s]

 31%|███       | 31/100 [1:58:14<4:58:27, 259.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 270.43 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 258.36 examples/s]

 32%|███▏      | 32/100 [2:02:21<4:49:52, 255.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 296.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 286.59 examples/s]

 33%|███▎      | 33/100 [2:06:06<4:35:21, 246.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 287.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 276.96 examples/s]

 34%|███▍      | 34/100 [2:10:41<4:40:34, 255.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 252.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 243.27 examples/s]

 35%|███▌      | 35/100 [2:15:10<4:40:55, 259.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 235.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 228.06 examples/s]

 36%|███▌      | 36/100 [2:19:03<4:28:04, 251.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 293.28 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 283.42 examples/s]

 37%|███▋      | 37/100 [2:23:13<4:23:35, 251.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 265.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 257.14 examples/s]

 38%|███▊      | 38/100 [2:28:04<4:31:37, 262.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 253.01 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 240.74 examples/s]

 39%|███▉      | 39/100 [2:32:19<4:24:46, 260.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 217.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 211.43 examples/s]

 40%|████      | 40/100 [2:36:10<4:11:39, 251.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 262.70 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 254.55 examples/s]

 41%|████      | 41/100 [2:40:11<4:04:24, 248.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 281.83 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 272.43 examples/s]

 42%|████▏     | 42/100 [2:44:41<4:06:17, 254.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 258.87 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 251.21 examples/s]

 43%|████▎     | 43/100 [2:48:51<4:00:46, 253.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 208.40 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 201.73 examples/s]

 44%|████▍     | 44/100 [2:53:10<3:58:16, 255.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 288.15 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 277.86 examples/s]

 45%|████▌     | 45/100 [2:57:40<3:57:59, 259.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 290.58 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 278.66 examples/s]

 46%|████▌     | 46/100 [3:02:06<3:55:20, 261.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 240.70 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 233.54 examples/s]

 47%|████▋     | 47/100 [3:06:09<3:45:58, 255.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 280.26 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 269.25 examples/s]

 48%|████▊     | 48/100 [3:10:20<3:40:28, 254.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A