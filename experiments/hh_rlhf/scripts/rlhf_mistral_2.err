
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3553.89 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3403.91 examples/s]

  1%|          | 1/100 [02:03<3:24:19, 123.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3102.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2993.58 examples/s]

  2%|▏         | 2/100 [05:07<4:19:43, 159.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3034.95 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2922.05 examples/s]

  3%|▎         | 3/100 [08:03<4:29:45, 166.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3007.10 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2903.03 examples/s]

  4%|▍         | 4/100 [12:07<5:15:51, 197.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3026.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2921.84 examples/s]

  5%|▌         | 5/100 [15:22<5:10:56, 196.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2997.00 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2888.44 examples/s]

  6%|▌         | 6/100 [18:30<5:03:01, 193.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2940.69 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2831.12 examples/s]

  7%|▋         | 7/100 [22:00<5:08:13, 198.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2908.27 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2808.37 examples/s]

  8%|▊         | 8/100 [26:03<5:26:27, 212.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2952.70 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2851.72 examples/s]

  9%|▉         | 9/100 [30:28<5:47:49, 229.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2819.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2724.81 examples/s]

 10%|█         | 10/100 [34:38<5:53:43, 235.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2799.94 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2708.80 examples/s]

 11%|█         | 11/100 [38:42<5:53:18, 238.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2902.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2804.99 examples/s]

 12%|█▏        | 12/100 [44:08<6:28:42, 265.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2797.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2705.83 examples/s]

 13%|█▎        | 13/100 [48:08<6:13:09, 257.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3214.77 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3103.21 examples/s]

 14%|█▍        | 14/100 [52:26<6:08:57, 257.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3090.41 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2973.63 examples/s]

 15%|█▌        | 15/100 [56:37<6:01:58, 255.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2959.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2855.60 examples/s]

 16%|█▌        | 16/100 [1:00:23<5:45:17, 246.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2968.58 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2862.42 examples/s]

 17%|█▋        | 17/100 [1:05:03<5:55:04, 256.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2974.68 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2877.15 examples/s]

 18%|█▊        | 18/100 [1:09:14<5:48:41, 255.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2862.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2764.50 examples/s]

 19%|█▉        | 19/100 [1:13:31<5:45:08, 255.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 3014.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2915.95 examples/s]
 20%|██        | 20/100 [1:17:39<5:37:32, 253.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2835.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2738.69 examples/s]
 21%|██        | 21/100 [1:22:49<5:56:04, 270.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2889.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2796.39 examples/s]
 22%|██▏       | 22/100 [1:27:31<5:55:56, 273.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2739.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2647.08 examples/s]
 23%|██▎       | 23/100 [1:32:17<5:56:15, 277.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
