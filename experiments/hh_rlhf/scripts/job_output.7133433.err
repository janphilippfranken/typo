Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:04<01:18,  4.38s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:06<00:47,  2.81s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:07<00:36,  2.30s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:09<00:30,  2.04s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:11<00:26,  1.92s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:12<00:23,  1.80s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:14<00:20,  1.73s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:15<00:18,  1.66s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:17<00:16,  1.66s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:18<00:14,  1.62s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:20<00:12,  1.60s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:22<00:11,  1.59s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:23<00:09,  1.58s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:25<00:07,  1.60s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:26<00:06,  1.57s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:28<00:04,  1.56s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:29<00:03,  1.54s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:31<00:01,  1.54s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:34<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:34<00:00,  1.79s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 73.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 72.25 examples/s]
  1%|          | 1/100 [03:54<6:27:24, 234.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 101.86 examples/s]
  2%|▏         | 2/100 [06:38<5:15:01, 192.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 143.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 137.44 examples/s]
  3%|▎         | 3/100 [09:35<5:00:01, 185.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 113.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.59 examples/s]
  4%|▍         | 4/100 [12:27<4:48:30, 180.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 510.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 495.51 examples/s]
  5%|▌         | 5/100 [15:38<4:51:29, 184.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 142.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 136.00 examples/s]
  6%|▌         | 6/100 [18:54<4:55:05, 188.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 81.23 examples/s]
  7%|▋         | 7/100 [22:11<4:56:13, 191.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 314.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 306.53 examples/s]
  8%|▊         | 8/100 [26:09<5:15:53, 206.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 121.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 118.02 examples/s]
  9%|▉         | 9/100 [29:42<5:15:50, 208.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.40 examples/s]
 10%|█         | 10/100 [32:49<5:02:16, 201.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 140.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 135.76 examples/s]
 11%|█         | 11/100 [36:33<5:09:15, 208.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 159.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 155.51 examples/s]
 12%|█▏        | 12/100 [39:50<5:00:45, 205.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 85.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.70 examples/s]
 13%|█▎        | 13/100 [43:39<5:07:34, 212.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 112.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 109.13 examples/s]
 14%|█▍        | 14/100 [46:51<4:55:20, 206.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 382.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 370.48 examples/s]
 15%|█▌        | 15/100 [50:02<4:45:27, 201.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 101.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 97.87 examples/s] 
 16%|█▌        | 16/100 [53:24<4:42:39, 201.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 77.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 75.11 examples/s]
 17%|█▋        | 17/100 [56:30<4:32:42, 197.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 129.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.33 examples/s]
 18%|█▊        | 18/100 [59:43<4:27:25, 195.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 247.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 245.35 examples/s]
 19%|█▉        | 19/100 [1:02:54<4:22:31, 194.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 68.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 66.54 examples/s]
 20%|██        | 20/100 [1:06:28<4:26:53, 200.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.15 examples/s]
 21%|██        | 21/100 [1:09:29<4:16:12, 194.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 91.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 87.39 examples/s]
 22%|██▏       | 22/100 [1:12:58<4:18:20, 198.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 89.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 86.83 examples/s]
 23%|██▎       | 23/100 [1:16:38<4:23:13, 205.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 168.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 159.20 examples/s]
 24%|██▍       | 24/100 [1:20:45<4:35:42, 217.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 105.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 102.00 examples/s]
 25%|██▌       | 25/100 [1:24:52<4:43:17, 226.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 3/3 [00:00<00:00, 21.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 21.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 21.25 examples/s]
 26%|██▌       | 26/100 [1:28:33<4:37:13, 224.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 68.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 66.48 examples/s]
 27%|██▋       | 27/100 [1:32:26<4:36:42, 227.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 111.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 108.15 examples/s]
 28%|██▊       | 28/100 [1:36:15<4:33:24, 227.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 108.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 105.43 examples/s]
 29%|██▉       | 29/100 [1:39:53<4:25:56, 224.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 254.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 244.34 examples/s]
 30%|███       | 30/100 [1:43:52<4:27:24, 229.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 117.95 examples/s]
 31%|███       | 31/100 [1:47:16<4:14:37, 221.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 107.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.46 examples/s]
 32%|███▏      | 32/100 [1:50:54<4:09:48, 220.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 128.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 124.55 examples/s]
 33%|███▎      | 33/100 [1:54:56<4:13:19, 226.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 77.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 75.22 examples/s]
 34%|███▍      | 34/100 [1:58:26<4:04:16, 222.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 88.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 85.59 examples/s]
 35%|███▌      | 35/100 [2:02:05<3:59:27, 221.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 85.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.07 examples/s]
 36%|███▌      | 36/100 [2:06:01<4:00:23, 225.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 64.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 62.21 examples/s]
 37%|███▋      | 37/100 [2:09:36<3:53:32, 222.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 235.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 231.46 examples/s]
 38%|███▊      | 38/100 [2:13:40<3:56:39, 229.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 108.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 104.41 examples/s]
 39%|███▉      | 39/100 [2:16:52<3:41:21, 217.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 601.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 586.42 examples/s]
 40%|████      | 40/100 [2:20:22<3:35:20, 215.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 130.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 126.92 examples/s]
 41%|████      | 41/100 [2:23:51<3:30:02, 213.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 122.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 117.13 examples/s]
 42%|████▏     | 42/100 [2:27:25<3:26:36, 213.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 64.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 62.90 examples/s]
 43%|████▎     | 43/100 [2:31:06<3:24:57, 215.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 88.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 86.20 examples/s]
 44%|████▍     | 44/100 [2:34:36<3:19:49, 214.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 116.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 112.34 examples/s]
 45%|████▌     | 45/100 [2:37:56<3:12:24, 209.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 129.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 124.55 examples/s]
 46%|████▌     | 46/100 [2:41:54<3:16:25, 218.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 95.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 92.73 examples/s]
 47%|████▋     | 47/100 [2:45:13<3:07:49, 212.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 81.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 78.91 examples/s]
 48%|████▊     | 48/100 [2:48:53<3:06:08, 214.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 168.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 165.80 examples/s]
 49%|████▉     | 49/100 [2:52:27<3:02:14, 214.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 106.59 examples/s]
 50%|█████     | 50/100 [2:55:57<2:57:41, 213.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.54 examples/s]
 51%|█████     | 51/100 [2:59:27<2:53:26, 212.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 74.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 72.26 examples/s]
 52%|█████▏    | 52/100 [3:02:59<2:49:35, 211.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 99.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 96.43 examples/s]
 53%|█████▎    | 53/100 [3:06:36<2:47:15, 213.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 253.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 248.69 examples/s]
 54%|█████▍    | 54/100 [3:10:24<2:47:09, 218.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 114.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 110.62 examples/s]
 55%|█████▌    | 55/100 [3:14:18<2:47:02, 222.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.62 examples/s]
 56%|█████▌    | 56/100 [3:18:12<2:45:49, 226.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 84.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.47 examples/s]
 57%|█████▋    | 57/100 [3:21:18<2:33:31, 214.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 81.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 76.69 examples/s]
 58%|█████▊    | 58/100 [3:24:57<2:30:54, 215.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 86.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 84.53 examples/s]
 59%|█████▉    | 59/100 [3:28:13<2:23:12, 209.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 152.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 148.46 examples/s]
 60%|██████    | 60/100 [3:31:47<2:20:43, 211.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 76.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 74.80 examples/s]
 61%|██████    | 61/100 [3:35:34<2:20:10, 215.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 272.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 268.25 examples/s]
 62%|██████▏   | 62/100 [3:39:04<2:15:31, 213.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 100.36 examples/s]
 63%|██████▎   | 63/100 [3:42:45<2:13:16, 216.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 72.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 69.83 examples/s]
 64%|██████▍   | 64/100 [3:47:07<2:17:57, 229.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 76.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 73.46 examples/s]
 65%|██████▌   | 65/100 [3:50:53<2:13:23, 228.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 60.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 59.11 examples/s]
 66%|██████▌   | 66/100 [3:54:27<2:07:08, 224.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 64.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 63.25 examples/s]
 67%|██████▋   | 67/100 [3:57:54<2:00:30, 219.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 173.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 170.93 examples/s]
 68%|██████▊   | 68/100 [4:01:41<1:58:12, 221.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 79.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 76.57 examples/s]
 69%|██████▉   | 69/100 [4:05:38<1:56:47, 226.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 109.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 108.98 examples/s]
 70%|███████   | 70/100 [4:08:44<1:46:59, 214.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 101.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 98.04 examples/s] 
 71%|███████   | 71/100 [4:12:33<1:45:43, 218.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 70.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 68.55 examples/s]
 72%|███████▏  | 72/100 [4:16:24<1:43:47, 222.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 60.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 58.73 examples/s]
 73%|███████▎  | 73/100 [4:20:03<1:39:34, 221.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 100.98 examples/s]
 74%|███████▍  | 74/100 [4:24:34<1:42:19, 236.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 79.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 77.75 examples/s]
 75%|███████▌  | 75/100 [4:28:29<1:38:16, 235.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.17 examples/s]
 76%|███████▌  | 76/100 [4:31:50<1:30:10, 225.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 77.67 examples/s]
 77%|███████▋  | 77/100 [4:35:26<1:25:19, 222.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 56.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 55.43 examples/s]
 78%|███████▊  | 78/100 [4:39:05<1:21:13, 221.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 147.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 145.59 examples/s]
 79%|███████▉  | 79/100 [4:43:12<1:20:11, 229.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 71.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 69.18 examples/s]
 80%|████████  | 80/100 [4:46:44<1:14:37, 223.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 78.82 examples/s]
 81%|████████  | 81/100 [4:50:05<1:08:47, 217.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 99.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 97.93 examples/s]
 82%|████████▏ | 82/100 [4:53:29<1:03:54, 213.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 68.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 63.23 examples/s]
 83%|████████▎ | 83/100 [4:56:54<59:43, 210.78s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 73.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 70.25 examples/s]
 84%|████████▍ | 84/100 [5:00:33<56:49, 213.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 59.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 58.05 examples/s]
 85%|████████▌ | 85/100 [5:04:18<54:14, 216.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 317.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 308.08 examples/s]
 86%|████████▌ | 86/100 [5:07:48<50:04, 214.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.53 examples/s]
 87%|████████▋ | 87/100 [5:12:04<49:12, 227.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 72.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 70.40 examples/s]
 88%|████████▊ | 88/100 [5:15:38<44:39, 223.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 73.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 71.05 examples/s]
 89%|████████▉ | 89/100 [5:19:08<40:11, 219.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 103.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 102.00 examples/s]
 90%|█████████ | 90/100 [5:23:04<37:23, 224.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 66.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 64.14 examples/s]
 91%|█████████ | 91/100 [5:26:46<33:32, 223.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 66.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 64.36 examples/s]
 92%|█████████▏| 92/100 [5:30:13<29:08, 218.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 102.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 100.65 examples/s]
 93%|█████████▎| 93/100 [5:33:39<25:04, 214.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 117.47 examples/s]
 94%|█████████▍| 94/100 [5:37:50<22:33, 225.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 78.70 examples/s]
 95%|█████████▌| 95/100 [5:41:17<18:19, 219.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 80.58 examples/s]
 96%|█████████▌| 96/100 [5:45:10<14:55, 223.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 79.72 examples/s]
 97%|█████████▋| 97/100 [5:48:39<10:58, 219.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 92.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 90.10 examples/s]
 98%|█████████▊| 98/100 [5:52:08<07:12, 216.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 59.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 58.17 examples/s]
 99%|█████████▉| 99/100 [5:55:20<03:29, 209.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 209.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 205.92 examples/s]
100%|██████████| 100/100 [5:58:45<00:00, 207.84s/it]100%|██████████| 100/100 [5:58:45<00:00, 215.26s/it]
