Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:19<00:00,  9.77s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:21<00:00, 10.62s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 346.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 337.27 examples/s]
  1%|          | 1/100 [02:02<3:22:50, 122.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3941.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3815.95 examples/s]
  2%|▏         | 2/100 [05:57<5:08:07, 188.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4457.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4330.95 examples/s]
  3%|▎         | 3/100 [08:22<4:33:02, 168.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4604.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4469.40 examples/s]
  4%|▍         | 4/100 [12:21<5:14:07, 196.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4656.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4544.95 examples/s]
  5%|▌         | 5/100 [16:26<5:38:48, 213.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4459.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4345.53 examples/s]
  6%|▌         | 6/100 [17:50<4:25:54, 169.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4177.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4080.46 examples/s]
  7%|▋         | 7/100 [21:41<4:54:04, 189.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4378.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4273.58 examples/s]
  8%|▊         | 8/100 [23:02<3:57:53, 155.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 5222.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 5085.55 examples/s]
  9%|▉         | 9/100 [25:07<3:41:02, 145.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4275.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4151.34 examples/s]
 10%|█         | 10/100 [29:20<4:28:03, 178.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4155.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4066.81 examples/s]
 11%|█         | 11/100 [33:21<4:53:41, 198.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3875.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3739.57 examples/s]
 12%|█▏        | 12/100 [34:53<4:02:57, 165.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4529.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4357.49 examples/s]
 13%|█▎        | 13/100 [38:54<4:33:21, 188.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4157.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4063.46 examples/s]
 14%|█▍        | 14/100 [42:40<4:46:25, 199.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3889.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3748.93 examples/s]
 15%|█▌        | 15/100 [46:49<5:04:15, 214.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3836.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3723.97 examples/s]
 16%|█▌        | 16/100 [51:00<5:15:45, 225.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3972.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3885.05 examples/s]
 17%|█▋        | 17/100 [53:28<4:39:51, 202.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4112.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4020.42 examples/s]
 18%|█▊        | 18/100 [57:35<4:54:47, 215.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3790.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3715.88 examples/s]
 19%|█▉        | 19/100 [1:00:03<4:23:29, 195.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3581.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3477.86 examples/s]
 20%|██        | 20/100 [1:04:20<4:45:20, 214.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3044.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2963.65 examples/s]
 21%|██        | 21/100 [1:08:09<4:47:28, 218.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3464.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3369.60 examples/s]
 22%|██▏       | 22/100 [1:11:09<4:28:49, 206.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3288.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3206.29 examples/s]
 23%|██▎       | 23/100 [1:13:59<4:11:08, 195.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3670.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3570.84 examples/s]
 24%|██▍       | 24/100 [1:16:03<3:40:58, 174.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2997.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2917.37 examples/s]
 25%|██▌       | 25/100 [1:20:11<4:05:18, 196.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3412.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3299.48 examples/s]
 26%|██▌       | 26/100 [1:24:19<4:21:11, 211.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2235.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2188.92 examples/s]
 27%|██▋       | 27/100 [1:28:34<4:33:46, 225.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1733.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1707.54 examples/s]
 28%|██▊       | 28/100 [1:32:56<4:43:00, 235.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2923.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2845.24 examples/s]
 29%|██▉       | 29/100 [1:37:21<4:49:25, 244.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1989.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1954.34 examples/s]
 30%|███       | 30/100 [1:41:50<4:53:55, 251.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2542.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2485.29 examples/s]
 31%|███       | 31/100 [1:46:13<4:53:48, 255.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1972.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1934.15 examples/s]
 32%|███▏      | 32/100 [1:50:38<4:52:35, 258.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2274.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2234.88 examples/s]
 33%|███▎      | 33/100 [1:55:02<4:50:27, 260.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1922.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1894.79 examples/s]
 34%|███▍      | 34/100 [1:59:57<4:57:25, 270.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 938.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 899.46 examples/s]
 35%|███▌      | 35/100 [2:03:18<4:30:22, 249.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2031.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1976.72 examples/s]
 36%|███▌      | 36/100 [2:08:14<4:41:04, 263.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1491.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1470.45 examples/s]
 37%|███▋      | 37/100 [2:13:09<4:46:41, 273.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1995.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1959.59 examples/s]
 38%|███▊      | 38/100 [2:17:52<4:45:20, 276.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2423.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2370.47 examples/s]
 39%|███▉      | 39/100 [2:21:22<4:20:29, 256.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2082.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2040.13 examples/s]
 40%|████      | 40/100 [2:25:48<4:19:12, 259.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1595.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1581.74 examples/s]
 41%|████      | 41/100 [2:28:52<3:52:30, 236.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1723.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1671.47 examples/s]
 42%|████▏     | 42/100 [2:33:28<4:00:09, 248.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 880.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 821.53 examples/s]
 43%|████▎     | 43/100 [2:38:07<4:04:37, 257.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 917.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 902.59 examples/s]
 44%|████▍     | 44/100 [2:42:43<4:05:41, 263.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1856.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1825.71 examples/s]
 45%|████▌     | 45/100 [2:47:12<4:02:44, 264.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1547.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1520.94 examples/s]
 46%|████▌     | 46/100 [2:51:37<3:58:17, 264.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1713.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1685.27 examples/s]
 47%|████▋     | 47/100 [2:55:11<3:40:38, 249.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1498.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1455.57 examples/s]
 48%|████▊     | 48/100 [2:59:49<3:43:48, 258.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 691.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 687.29 examples/s]
 49%|████▉     | 49/100 [3:04:13<3:40:55, 259.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1789.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1758.62 examples/s]
 50%|█████     | 50/100 [3:08:33<3:36:33, 259.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1524.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1509.58 examples/s]
 51%|█████     | 51/100 [3:12:58<3:33:24, 261.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1089.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1078.35 examples/s]
 52%|█████▏    | 52/100 [3:17:35<3:32:50, 266.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 589.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 577.71 examples/s]
 53%|█████▎    | 53/100 [3:22:27<3:34:28, 273.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1249.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1236.71 examples/s]
 54%|█████▍    | 54/100 [3:27:18<3:33:58, 279.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 777.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 771.25 examples/s]
 55%|█████▌    | 55/100 [3:32:01<3:30:13, 280.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1315.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1304.38 examples/s]
 56%|█████▌    | 56/100 [3:36:48<3:26:58, 282.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1438.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1420.14 examples/s]
 57%|█████▋    | 57/100 [3:41:49<3:26:20, 287.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1194.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1182.23 examples/s]
 58%|█████▊    | 58/100 [3:46:41<3:22:20, 289.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1415.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1403.48 examples/s]
 59%|█████▉    | 59/100 [3:51:26<3:16:46, 287.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1470.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1447.63 examples/s]
 60%|██████    | 60/100 [3:56:12<3:11:31, 287.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 996.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 977.85 examples/s]
 61%|██████    | 61/100 [4:00:53<3:05:31, 285.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 498.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 494.12 examples/s]
 62%|██████▏   | 62/100 [4:06:08<3:06:24, 294.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 839.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 832.02 examples/s]
 63%|██████▎   | 63/100 [4:11:09<3:02:38, 296.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1131.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1117.94 examples/s]
 64%|██████▍   | 64/100 [4:15:53<2:55:35, 292.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1010.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1000.65 examples/s]
 65%|██████▌   | 65/100 [4:20:45<2:50:36, 292.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1315.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1298.81 examples/s]
 66%|██████▌   | 66/100 [4:25:38<2:45:52, 292.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1393.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1368.36 examples/s]
 67%|██████▋   | 67/100 [4:30:26<2:40:03, 291.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1490.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1468.95 examples/s]
 68%|██████▊   | 68/100 [4:35:28<2:36:58, 294.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 962.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 956.63 examples/s]
 69%|██████▉   | 69/100 [4:40:31<2:33:32, 297.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1457.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1422.26 examples/s]
 70%|███████   | 70/100 [4:45:26<2:28:12, 296.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 654.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 650.15 examples/s]
 71%|███████   | 71/100 [4:50:26<2:23:43, 297.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1338.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1317.91 examples/s]
 72%|███████▏  | 72/100 [4:55:31<2:19:51, 299.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 895.97 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 888.34 examples/s]
 73%|███████▎  | 73/100 [5:00:23<2:13:53, 297.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 906.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 869.08 examples/s]
 74%|███████▍  | 74/100 [5:05:31<2:10:12, 300.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 942.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 934.12 examples/s]
 75%|███████▌  | 75/100 [5:10:35<2:05:42, 301.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1063.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1042.70 examples/s]
 76%|███████▌  | 76/100 [5:15:29<1:59:41, 299.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1083.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1074.14 examples/s]
 77%|███████▋  | 77/100 [5:20:26<1:54:31, 298.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 754.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 747.99 examples/s]
 78%|███████▊  | 78/100 [5:25:27<1:49:45, 299.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1394.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1376.13 examples/s]
 79%|███████▉  | 79/100 [5:30:31<1:45:14, 300.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 974.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 963.76 examples/s]
 80%|████████  | 80/100 [5:35:22<1:39:19, 297.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 845.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 840.91 examples/s]
 81%|████████  | 81/100 [5:40:06<1:32:57, 293.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 745.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 740.03 examples/s]
 82%|████████▏ | 82/100 [5:44:58<1:27:57, 293.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1233.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1218.76 examples/s]
 83%|████████▎ | 83/100 [5:49:45<1:22:34, 291.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1028.97 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1014.55 examples/s]
 84%|████████▍ | 84/100 [5:54:35<1:17:36, 291.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1079.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1068.12 examples/s]
 85%|████████▌ | 85/100 [5:59:25<1:12:39, 290.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1250.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1234.34 examples/s]
 86%|████████▌ | 86/100 [6:04:12<1:07:32, 289.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 560.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 551.23 examples/s]
 87%|████████▋ | 87/100 [6:09:06<1:03:01, 290.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1016.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1005.66 examples/s]
 88%|████████▊ | 88/100 [6:13:57<58:11, 290.97s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 20/20 [00:00<00:00, 156.56 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 156.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 151.48 examples/s]
 89%|████████▉ | 89/100 [6:18:44<53:08, 289.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 988.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 975.93 examples/s]
 90%|█████████ | 90/100 [6:23:35<48:20, 290.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 878.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 874.00 examples/s]
 91%|█████████ | 91/100 [6:28:45<44:24, 296.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1234.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1215.79 examples/s]
 92%|█████████▏| 92/100 [6:33:56<40:04, 300.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 365.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 363.70 examples/s]
 93%|█████████▎| 93/100 [6:38:51<34:52, 298.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1199.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1181.68 examples/s]
 94%|█████████▍| 94/100 [6:43:36<29:28, 294.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1311.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1294.78 examples/s]
 95%|█████████▌| 95/100 [6:48:19<24:15, 291.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1149.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1136.79 examples/s]
 96%|█████████▌| 96/100 [6:53:52<20:15, 303.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1241.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1227.21 examples/s]
 97%|█████████▋| 97/100 [6:58:55<15:10, 303.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 20/20 [00:00<00:00, 130.15 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 130.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 122.22 examples/s]
 98%|█████████▊| 98/100 [7:03:55<10:04, 302.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 747.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 740.38 examples/s]
 99%|█████████▉| 99/100 [7:08:58<05:02, 302.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1267.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1245.86 examples/s]
100%|██████████| 100/100 [7:13:56<00:00, 301.17s/it]100%|██████████| 100/100 [7:13:56<00:00, 260.36s/it]
