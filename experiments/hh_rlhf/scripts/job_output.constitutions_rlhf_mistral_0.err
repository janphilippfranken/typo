Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.47s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.90s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 42.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 41.54 examples/s]
  1%|          | 1/100 [00:37<1:01:50, 37.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 380.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 369.90 examples/s]
  2%|▏         | 2/100 [01:30<1:16:18, 46.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 470.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 453.10 examples/s]
  3%|▎         | 3/100 [02:00<1:03:24, 39.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 510.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 496.37 examples/s]
  4%|▍         | 4/100 [02:23<52:11, 32.62s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 587.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 569.99 examples/s]
  5%|▌         | 5/100 [03:28<1:09:52, 44.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 527.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 512.22 examples/s]
  6%|▌         | 6/100 [04:07<1:06:42, 42.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 499.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 485.03 examples/s]
  7%|▋         | 7/100 [04:36<58:59, 38.06s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 483.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 470.85 examples/s]
  8%|▊         | 8/100 [05:29<1:05:31, 42.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 348.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 334.50 examples/s]
  9%|▉         | 9/100 [06:27<1:12:10, 47.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 472.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 460.43 examples/s]
 10%|█         | 10/100 [07:08<1:08:13, 45.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 547.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 530.79 examples/s]
 11%|█         | 11/100 [07:50<1:05:55, 44.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 520.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 506.99 examples/s]
 12%|█▏        | 12/100 [08:33<1:04:42, 44.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 476.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 464.54 examples/s]
 13%|█▎        | 13/100 [09:09<1:00:29, 41.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 457.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 447.18 examples/s]
 14%|█▍        | 14/100 [09:47<58:11, 40.60s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 565.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 549.93 examples/s]
 15%|█▌        | 15/100 [10:22<55:08, 38.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 448.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 438.69 examples/s]
 16%|█▌        | 16/100 [11:02<54:54, 39.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 572.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 555.91 examples/s]
 17%|█▋        | 17/100 [11:46<56:13, 40.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 503.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 490.99 examples/s]
 18%|█▊        | 18/100 [12:38<1:00:12, 44.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 442.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 432.74 examples/s]
 19%|█▉        | 19/100 [13:24<1:00:15, 44.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 522.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 508.59 examples/s]
 20%|██        | 20/100 [14:41<1:12:17, 54.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 469.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 457.97 examples/s]
 21%|██        | 21/100 [15:25<1:07:29, 51.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 515.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 501.74 examples/s]
 22%|██▏       | 22/100 [16:32<1:12:53, 56.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 490.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 478.04 examples/s]
 23%|██▎       | 23/100 [17:11<1:05:14, 50.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 451.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 435.30 examples/s]
 24%|██▍       | 24/100 [17:53<1:01:02, 48.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 378.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 370.21 examples/s]
 25%|██▌       | 25/100 [18:46<1:02:08, 49.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 420.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 405.36 examples/s]
 26%|██▌       | 26/100 [19:59<1:09:48, 56.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 432.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 422.51 examples/s]
 27%|██▋       | 27/100 [22:56<1:52:45, 92.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 489.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 477.93 examples/s]
 28%|██▊       | 28/100 [23:46<1:36:00, 80.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 510.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 497.66 examples/s]
 29%|██▉       | 29/100 [24:24<1:19:36, 67.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 367.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 355.25 examples/s]
 30%|███       | 30/100 [27:22<1:57:15, 100.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 449.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 433.23 examples/s]
 31%|███       | 31/100 [28:39<1:47:32, 93.52s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 283.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 279.14 examples/s]
 32%|███▏      | 32/100 [29:24<1:29:23, 78.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 491.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 471.51 examples/s]
 33%|███▎      | 33/100 [30:06<1:15:57, 68.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 473.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 462.23 examples/s]
 34%|███▍      | 34/100 [30:59<1:09:49, 63.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 482.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 469.77 examples/s]
 35%|███▌      | 35/100 [31:38<1:00:47, 56.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 387.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 380.28 examples/s]
 36%|███▌      | 36/100 [32:35<59:53, 56.15s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 454.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 437.27 examples/s]
 37%|███▋      | 37/100 [33:30<58:47, 56.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 368.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 357.81 examples/s]
 38%|███▊      | 38/100 [34:10<52:44, 51.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 453.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 443.21 examples/s]
 39%|███▉      | 39/100 [35:02<52:24, 51.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 466.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 454.84 examples/s]
 40%|████      | 40/100 [35:41<47:40, 47.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 503.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 490.71 examples/s]
 41%|████      | 41/100 [36:16<43:10, 43.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 437.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 428.12 examples/s]
 42%|████▏     | 42/100 [36:52<40:10, 41.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 437.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 427.79 examples/s]
 43%|████▎     | 43/100 [37:45<42:46, 45.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 464.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 453.24 examples/s]
 44%|████▍     | 44/100 [38:19<38:43, 41.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 468.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 457.32 examples/s]
 45%|████▌     | 45/100 [38:55<36:44, 40.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 449.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 439.03 examples/s]
 46%|████▌     | 46/100 [39:58<42:02, 46.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 380.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 373.47 examples/s]
 47%|████▋     | 47/100 [40:32<37:56, 42.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 465.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 454.52 examples/s]
 48%|████▊     | 48/100 [41:00<33:24, 38.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 452.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 442.16 examples/s]
 49%|████▉     | 49/100 [41:40<33:02, 38.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 506.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 494.20 examples/s]
 50%|█████     | 50/100 [42:30<35:22, 42.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 416.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 407.31 examples/s]
 51%|█████     | 51/100 [43:17<35:42, 43.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 464.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 453.93 examples/s]
 52%|█████▏    | 52/100 [44:26<41:05, 51.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 451.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 440.72 examples/s]
 53%|█████▎    | 53/100 [44:58<35:33, 45.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 418.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 409.92 examples/s]
 54%|█████▍    | 54/100 [45:41<34:21, 44.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 427.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 418.82 examples/s]
 55%|█████▌    | 55/100 [46:24<33:11, 44.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 457.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 446.63 examples/s]
 56%|█████▌    | 56/100 [47:09<32:38, 44.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 525.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 511.59 examples/s]
 57%|█████▋    | 57/100 [49:00<46:08, 64.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 458.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 447.34 examples/s]
 58%|█████▊    | 58/100 [50:25<49:26, 70.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 457.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 447.20 examples/s]
 59%|█████▉    | 59/100 [51:12<43:17, 63.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 488.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 476.44 examples/s]
 60%|██████    | 60/100 [51:53<37:52, 56.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 394.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 386.98 examples/s]
 61%|██████    | 61/100 [52:46<36:10, 55.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 484.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 472.57 examples/s]
 62%|██████▏   | 62/100 [53:34<33:47, 53.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 433.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 418.26 examples/s]
 63%|██████▎   | 63/100 [54:20<31:29, 51.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 138.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 136.26 examples/s]
 64%|██████▍   | 64/100 [55:13<30:55, 51.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 442.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 432.25 examples/s]
 65%|██████▌   | 65/100 [55:58<29:04, 49.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 490.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 478.58 examples/s]
 66%|██████▌   | 66/100 [57:02<30:35, 53.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 445.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 435.98 examples/s]
 67%|██████▋   | 67/100 [57:56<29:40, 53.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 410.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 401.45 examples/s]
 68%|██████▊   | 68/100 [58:55<29:34, 55.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 413.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 404.52 examples/s]
 69%|██████▉   | 69/100 [59:44<27:44, 53.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 431.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 422.41 examples/s]
 70%|███████   | 70/100 [1:00:29<25:26, 50.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 396.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 387.88 examples/s]
 71%|███████   | 71/100 [1:01:14<23:47, 49.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/2 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 389.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 374.21 examples/s]
 72%|███████▏  | 72/100 [1:02:07<23:24, 50.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
slurmstepd: error: *** JOB 7134724 ON cocoflops-hgx-1 CANCELLED AT 2023-12-25T21:46:15 ***
