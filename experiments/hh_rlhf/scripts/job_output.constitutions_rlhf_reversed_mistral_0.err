Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.32s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.55s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 213.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 209.42 examples/s]
  1%|          | 1/100 [03:00<4:57:15, 180.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2560.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2488.91 examples/s]
  2%|▏         | 2/100 [10:56<9:38:54, 354.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2214.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2160.90 examples/s]
  3%|▎         | 3/100 [18:48<10:59:26, 407.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2525.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2456.83 examples/s]
  4%|▍         | 4/100 [24:50<10:23:58, 389.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2351.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2247.63 examples/s]
  5%|▌         | 5/100 [32:55<11:11:42, 424.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2025.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1951.38 examples/s]
  6%|▌         | 6/100 [41:07<11:40:42, 447.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2392.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2332.11 examples/s]
  7%|▋         | 7/100 [47:13<10:52:15, 420.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2651.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2575.72 examples/s]
  8%|▊         | 8/100 [55:09<11:11:55, 438.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2286.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2196.32 examples/s]
  9%|▉         | 9/100 [1:02:14<10:58:13, 433.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 10%|█         | 10/100 [1:02:33<7:39:06, 306.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1238.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1210.69 examples/s]
 11%|█         | 11/100 [1:10:18<8:46:09, 354.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 12%|█▏        | 12/100 [1:10:37<6:10:09, 252.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 13%|█▎        | 13/100 [1:10:37<4:15:08, 175.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2376.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2314.35 examples/s]
 14%|█▍        | 14/100 [1:17:29<5:54:42, 247.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1779.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1724.70 examples/s]
 15%|█▌        | 15/100 [1:25:34<7:31:51, 318.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 16%|█▌        | 16/100 [1:25:48<5:18:11, 227.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2271.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2184.76 examples/s]
 17%|█▋        | 17/100 [1:33:54<7:01:58, 305.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2239.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2186.47 examples/s]
 18%|█▊        | 18/100 [1:41:32<7:59:37, 350.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2001.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1931.97 examples/s]
 19%|█▉        | 19/100 [1:49:38<8:48:33, 391.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1746.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1689.82 examples/s]
 20%|██        | 20/100 [1:54:49<8:09:52, 367.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2169.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2117.59 examples/s]
 21%|██        | 21/100 [2:02:54<8:50:08, 402.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2242.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2191.04 examples/s]
 22%|██▏       | 22/100 [2:09:37<8:43:28, 402.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2172.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2094.64 examples/s]
 23%|██▎       | 23/100 [2:16:00<8:29:05, 396.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1779.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1720.74 examples/s]
 24%|██▍       | 24/100 [2:24:15<9:00:01, 426.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 734.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 724.53 examples/s]
 25%|██▌       | 25/100 [2:31:43<9:00:49, 432.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 26%|██▌       | 26/100 [2:32:01<6:20:17, 308.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 27%|██▋       | 27/100 [2:32:01<4:22:49, 216.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 28%|██▊       | 28/100 [2:32:02<3:01:44, 151.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 29%|██▉       | 29/100 [2:32:02<2:05:29, 106.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2136.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2038.94 examples/s]
 30%|███       | 30/100 [2:39:16<3:58:16, 204.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1945.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1876.56 examples/s]
 31%|███       | 31/100 [2:47:30<5:35:03, 291.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2173.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 2123.27 examples/s]
 32%|███▏      | 32/100 [2:53:09<5:46:21, 305.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1898.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1830.22 examples/s]
 33%|███▎      | 33/100 [2:59:20<6:03:07, 325.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1846.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1808.36 examples/s]
 34%|███▍      | 34/100 [3:07:17<6:47:40, 370.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1627.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1582.04 examples/s]
 35%|███▌      | 35/100 [3:16:17<7:36:33, 421.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1774.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1725.98 examples/s]
 36%|███▌      | 36/100 [3:24:39<7:55:28, 445.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1762.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1724.49 examples/s]
 37%|███▋      | 37/100 [3:33:37<8:17:11, 473.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 38%|███▊      | 38/100 [3:33:57<5:48:41, 337.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1572.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1525.31 examples/s]
 39%|███▉      | 39/100 [3:42:25<6:34:49, 388.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1748.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1712.10 examples/s]
 40%|████      | 40/100 [3:51:17<7:11:41, 431.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 41%|████      | 41/100 [3:51:18<4:57:22, 302.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1614.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1574.62 examples/s]
 42%|████▏     | 42/100 [4:00:38<6:06:55, 379.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1625.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1578.29 examples/s]
 43%|████▎     | 43/100 [4:09:18<6:40:47, 421.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1681.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1630.12 examples/s]
 44%|████▍     | 44/100 [4:18:11<7:04:50, 455.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1466.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1439.66 examples/s]
 45%|████▌     | 45/100 [4:27:17<7:22:11, 482.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 304.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 301.74 examples/s]
 46%|████▌     | 46/100 [4:36:45<7:37:15, 508.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1405.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1364.84 examples/s]
 47%|████▋     | 47/100 [4:45:52<7:39:01, 519.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1509.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1485.97 examples/s]
 48%|████▊     | 48/100 [4:54:21<7:27:35, 516.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1627.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1574.62 examples/s]
 49%|████▉     | 49/100 [5:03:17<7:23:55, 522.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1602.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1553.16 examples/s]
 50%|█████     | 50/100 [5:11:48<7:12:31, 519.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 51%|█████     | 51/100 [5:12:09<5:01:53, 369.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1457.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1417.47 examples/s]
 52%|█████▏    | 52/100 [5:21:18<5:38:43, 423.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1498.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1459.14 examples/s]
 53%|█████▎    | 53/100 [5:30:19<5:59:11, 458.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1513.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1477.80 examples/s]
 54%|█████▍    | 54/100 [5:39:26<6:11:56, 485.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 55%|█████▌    | 55/100 [5:39:33<4:16:22, 341.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 56%|█████▌    | 56/100 [5:39:51<2:59:17, 244.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 57%|█████▋    | 57/100 [5:39:51<2:02:49, 171.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1451.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1406.59 examples/s]
 58%|█████▊    | 58/100 [5:48:43<3:15:39, 279.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1302.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1284.23 examples/s]
 59%|█████▉    | 59/100 [5:57:46<4:04:52, 358.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1442.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1419.78 examples/s]
 60%|██████    | 60/100 [6:06:25<4:31:09, 406.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 61%|██████    | 61/100 [6:06:42<3:08:26, 289.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1506.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1460.51 examples/s]
 62%|██████▏   | 62/100 [6:15:30<3:48:50, 361.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1520.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1473.50 examples/s]
 63%|██████▎   | 63/100 [6:24:36<4:16:49, 416.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 64%|██████▍   | 64/100 [6:24:36<2:55:03, 291.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 201.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 200.98 examples/s]
 65%|██████▌   | 65/100 [6:33:37<3:33:43, 366.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 66%|██████▌   | 66/100 [6:33:55<2:28:21, 261.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1426.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1386.36 examples/s]
 67%|██████▋   | 67/100 [6:42:58<3:10:26, 346.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1383.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1348.30 examples/s]
 68%|██████▊   | 68/100 [6:52:18<3:38:52, 410.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 69%|██████▉   | 69/100 [6:52:36<2:31:12, 292.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1338.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1303.15 examples/s]
 70%|███████   | 70/100 [7:01:14<3:00:07, 360.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 71%|███████   | 71/100 [7:01:36<2:05:02, 258.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 72%|███████▏  | 72/100 [7:01:36<1:24:36, 181.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1289.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1263.57 examples/s]
 73%|███████▎  | 73/100 [7:10:30<2:09:05, 286.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 74%|███████▍  | 74/100 [7:10:49<1:29:33, 206.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1393.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1360.64 examples/s]
 75%|███████▌  | 75/100 [7:20:05<2:09:45, 311.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 76%|███████▌  | 76/100 [7:20:23<1:29:24, 223.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 77%|███████▋  | 77/100 [7:20:44<1:02:18, 162.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1176.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1147.71 examples/s]
 78%|███████▊  | 78/100 [7:30:18<1:44:53, 286.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 79%|███████▉  | 79/100 [7:30:37<1:12:06, 206.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 80%|████████  | 80/100 [7:30:37<48:05, 144.27s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 81%|████████  | 81/100 [7:30:37<31:59, 101.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 82%|████████▏ | 82/100 [7:30:38<21:13, 70.77s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 83%|████████▎ | 83/100 [7:30:38<14:02, 49.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1149.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1124.42 examples/s]
 84%|████████▍ | 84/100 [7:39:48<53:17, 199.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1312.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1287.98 examples/s]
 85%|████████▌ | 85/100 [7:48:48<1:15:25, 301.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1316.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1290.56 examples/s]
 86%|████████▌ | 86/100 [7:57:39<1:26:27, 370.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1299.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1264.87 examples/s]
 87%|████████▋ | 87/100 [8:06:20<1:30:06, 415.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 88%|████████▊ | 88/100 [8:06:21<58:16, 291.34s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 351.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 349.74 examples/s]
 89%|████████▉ | 89/100 [8:15:28<1:07:28, 368.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1253.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1225.08 examples/s]
 90%|█████████ | 90/100 [8:24:22<1:09:38, 417.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1141.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1117.29 examples/s]
 91%|█████████ | 91/100 [8:32:11<1:04:57, 433.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1270.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1244.23 examples/s]
 92%|█████████▏| 92/100 [8:40:48<1:01:06, 458.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1230.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1200.16 examples/s]
 93%|█████████▎| 93/100 [8:48:42<54:00, 462.87s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1222.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1196.36 examples/s]
 94%|█████████▍| 94/100 [8:56:37<46:40, 466.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1260.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1236.09 examples/s]
 95%|█████████▌| 95/100 [9:04:24<38:54, 466.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1234.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1210.69 examples/s]
 96%|█████████▌| 96/100 [9:12:20<31:17, 469.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1214.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1185.20 examples/s]
 97%|█████████▋| 97/100 [9:19:20<22:43, 454.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1152.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1127.11 examples/s]
 98%|█████████▊| 98/100 [9:27:24<15:26, 463.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1240.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1216.62 examples/s]
 99%|█████████▉| 99/100 [9:35:38<07:52, 472.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/10 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1216.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 10/10 [00:00<00:00, 1187.08 examples/s]
100%|██████████| 100/100 [9:43:27<00:00, 471.58s/it]100%|██████████| 100/100 [9:43:27<00:00, 350.08s/it]
