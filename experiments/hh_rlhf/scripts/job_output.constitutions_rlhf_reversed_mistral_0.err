Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.56s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 374.48 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 367.16 examples/s]
  1%|          | 1/100 [01:52<3:06:12, 112.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3773.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3669.72 examples/s]
  2%|▏         | 2/100 [05:48<5:02:07, 184.97s/it]The attention mask and the pa
Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4366.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4197.87 examples/s]
  3%|▎         | 3/100 [09:56<5:45:44, 213.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4840.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4720.39 examples/s]
  4%|▍         | 4/100 [14:04<6:03:38, 227.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4524.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4415.99 examples/s]
  5%|▌         | 5/100 [18:04<6:07:25, 232.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3114.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3045.20 examples/s]
  6%|▌         | 6/100 [19:54<4:58:28, 190.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4380.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4280.56 examples/s]
  7%|▋         | 7/100 [24:01<5:23:50, 208.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2943.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2862.71 examples/s]
  8%|▊         | 8/100 [28:29<5:49:16, 227.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4485.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4308.48 examples/s]
  9%|▉         | 9/100 [30:18<4:49:12, 190.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4468.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4365.88 examples/s]
 10%|█         | 10/100 [31:52<4:01:10, 160.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3598.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3525.51 examples/s]
 11%|█         | 11/100 [35:54<4:35:08, 185.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3335.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3242.98 examples/s]
 12%|█▏        | 12/100 [38:02<4:06:42, 168.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4214.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4065.63 examples/s]
 13%|█▎        | 13/100 [40:00<3:41:27, 152.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1244.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1229.68 examples/s]
 14%|█▍        | 14/100 [42:13<3:30:32, 146.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2875.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2809.78 examples/s]
 15%|█▌        | 15/100 [46:13<4:07:42, 174.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3315.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3223.41 examples/s]
 16%|█▌        | 16/100 [50:23<4:36:26, 197.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3110.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3032.76 examples/s]
 17%|█▋        | 17/100 [53:08<4:19:40, 187.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3133.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3045.42 examples/s]
 18%|█▊        | 18/100 [57:42<4:51:58, 213.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2280.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2039.44 examples/s]
 19%|█▉        | 19/100 [1:02:07<5:09:15, 229.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2489.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2417.26 examples/s]
 20%|██        | 20/100 [1:06:11<5:11:34, 233.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3164.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3089.27 examples/s]
 21%|██        | 21/100 [1:08:01<4:18:46, 196.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2433.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2364.45 examples/s]
 22%|██▏       | 22/100 [1:11:43<4:25:33, 204.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2436.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2381.23 examples/s]
 23%|██▎       | 23/100 [1:16:03<4:43:19, 220.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1789.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1760.09 examples/s]
 24%|██▍       | 24/100 [1:20:26<4:56:02, 233.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 781.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 730.79 examples/s]
 25%|██▌       | 25/100 [1:22:39<4:14:08, 203.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2823.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2761.50 examples/s]
 26%|██▌       | 26/100 [1:24:59<3:47:15, 184.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2218.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2157.73 examples/s]
 27%|██▋       | 27/100 [1:27:09<3:24:39, 168.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2218.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2175.92 examples/s]
 28%|██▊       | 28/100 [1:29:40<3:15:20, 162.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1876.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1845.80 examples/s]
 29%|██▉       | 29/100 [1:33:48<3:42:58, 188.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1981.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1944.64 examples/s]
 30%|███       | 30/100 [1:38:04<4:03:40, 208.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1195.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1170.16 examples/s]
 31%|███       | 31/100 [1:42:17<4:15:23, 222.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1749.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1716.44 examples/s]
 32%|███▏      | 32/100 [1:46:22<4:19:30, 228.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1559.48 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1536.38 examples/s]
 33%|███▎      | 33/100 [1:50:20<4:18:39, 231.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1088.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1066.85 examples/s]
 34%|███▍      | 34/100 [1:54:21<4:17:59, 234.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 696.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 686.95 examples/s]
 35%|███▌      | 35/100 [1:58:44<4:23:08, 242.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1047.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1035.68 examples/s]
 36%|███▌      | 36/100 [2:02:55<4:21:39, 245.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1594.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1544.55 examples/s]
 37%|███▋      | 37/100 [2:06:59<4:17:03, 244.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1143.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1098.22 examples/s]
 38%|███▊      | 38/100 [2:11:08<4:14:29, 246.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1313.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1298.71 examples/s]
 39%|███▉      | 39/100 [2:15:14<4:10:09, 246.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1641.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1621.61 examples/s]
 40%|████      | 40/100 [2:19:22<4:06:36, 246.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1161.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1121.64 examples/s]
 41%|████      | 41/100 [2:23:31<4:03:15, 247.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1229.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1202.27 examples/s]
 42%|████▏     | 42/100 [2:27:56<4:04:10, 252.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 844.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 838.25 examples/s]
 43%|████▎     | 43/100 [2:32:12<4:01:07, 253.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1414.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1397.03 examples/s]
 44%|████▍     | 44/100 [2:36:17<3:54:27, 251.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 922.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 911.71 examples/s]
 45%|████▌     | 45/100 [2:40:20<3:47:50, 248.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1671.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1643.28 examples/s]
 46%|████▌     | 46/100 [2:44:25<3:42:42, 247.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 608.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 592.60 examples/s]
 47%|████▋     | 47/100 [2:48:43<3:41:33, 250.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1018.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1006.56 examples/s]
 48%|████▊     | 48/100 [2:53:03<3:39:49, 253.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 833.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 824.68 examples/s]
 49%|████▉     | 49/100 [2:57:14<3:34:50, 252.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 985.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 972.45 examples/s]
 50%|█████     | 50/100 [3:01:20<3:28:48, 250.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1412.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1394.29 examples/s]
 51%|█████     | 51/100 [3:05:32<3:25:05, 251.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1215.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1198.89 examples/s]
 52%|█████▏    | 52/100 [3:09:44<3:20:59, 251.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 878.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 871.15 examples/s]
 53%|█████▎    | 53/100 [3:13:52<3:16:02, 250.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1077.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1027.86 examples/s]
 54%|█████▍    | 54/100 [3:18:23<3:16:42, 256.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1132.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1124.89 examples/s]
 55%|█████▌    | 55/100 [3:22:37<3:11:56, 255.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 447.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 443.20 examples/s]
 56%|█████▌    | 56/100 [3:27:00<3:09:04, 257.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 978.62 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 969.49 examples/s]
 57%|█████▋    | 57/100 [3:31:40<3:09:45, 264.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 660.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 637.49 examples/s]
 58%|█████▊    | 58/100 [3:36:23<3:09:07, 270.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 652.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 648.67 examples/s]
 59%|█████▉    | 59/100 [3:40:48<3:03:32, 268.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1070.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1059.07 examples/s]
 60%|██████    | 60/100 [3:44:06<2:44:52, 247.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 871.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 833.06 examples/s]
 61%|██████    | 61/100 [3:48:43<2:46:28, 256.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 642.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 638.86 examples/s]
 62%|██████▏   | 62/100 [3:53:14<2:45:09, 260.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 806.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 802.60 examples/s]
 63%|██████▎   | 63/100 [3:57:30<2:39:48, 259.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 656.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 650.93 examples/s]
 64%|██████▍   | 64/100 [4:01:50<2:35:46, 259.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 490.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 488.18 examples/s]
 65%|██████▌   | 65/100 [4:06:11<2:31:35, 259.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 969.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 961.93 examples/s]
 66%|██████▌   | 66/100 [4:10:24<2:26:05, 257.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 803.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 791.17 examples/s]
 67%|██████▋   | 67/100 [4:14:45<2:22:22, 258.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 901.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 857.10 examples/s]
 68%|██████▊   | 68/100 [4:19:04<2:18:02, 258.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 756.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 749.44 examples/s]
 69%|██████▉   | 69/100 [4:23:17<2:12:54, 257.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 786.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 779.15 examples/s]
 70%|███████   | 70/100 [4:27:48<2:10:41, 261.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 578.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 561.78 examples/s]
 71%|███████   | 71/100 [4:32:06<2:05:50, 260.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 822.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 815.30 examples/s]
 72%|███████▏  | 72/100 [4:36:28<2:01:44, 260.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 847.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 835.94 examples/s]
 73%|███████▎  | 73/100 [4:40:43<1:56:29, 258.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1034.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1024.30 examples/s]
 74%|███████▍  | 74/100 [4:44:59<1:51:53, 258.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 765.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 759.21 examples/s]
 75%|███████▌  | 75/100 [4:47:51<1:36:48, 232.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 935.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 923.82 examples/s]
 76%|███████▌  | 76/100 [4:52:22<1:37:33, 243.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 346.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 339.58 examples/s]
 77%|███████▋  | 77/100 [4:56:49<1:36:11, 250.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 845.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 833.53 examples/s]
 78%|███████▊  | 78/100 [5:01:31<1:35:23, 260.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 672.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 666.34 examples/s]
 79%|███████▉  | 79/100 [5:05:52<1:31:07, 260.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 817.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 810.71 examples/s]
 80%|████████  | 80/100 [5:10:18<1:27:20, 262.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 899.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 892.60 examples/s]
 81%|████████  | 81/100 [5:14:48<1:23:45, 264.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 646.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 639.20 examples/s]
 82%|████████▏ | 82/100 [5:18:13<1:13:58, 246.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 685.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 663.06 examples/s]
 83%|████████▎ | 83/100 [5:22:39<1:11:31, 252.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 653.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 648.87 examples/s]
 84%|████████▍ | 84/100 [5:27:21<1:09:42, 261.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 513.09 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 506.37 examples/s]
 85%|████████▌ | 85/100 [5:32:19<1:08:05, 272.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 252.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 251.83 examples/s]
 86%|████████▌ | 86/100 [5:37:01<1:04:11, 275.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 839.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 830.96 examples/s]
 87%|████████▋ | 87/100 [5:41:26<58:57, 272.10s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 660.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 656.90 examples/s]
 88%|████████▊ | 88/100 [5:45:47<53:45, 268.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 873.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 863.40 examples/s]
 89%|████████▉ | 89/100 [5:50:15<49:14, 268.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 198.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 197.76 examples/s]
 90%|█████████ | 90/100 [5:53:44<41:45, 250.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 898.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 886.60 examples/s]
 91%|█████████ | 91/100 [5:58:04<38:01, 253.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 911.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 901.32 examples/s]
 92%|█████████▏| 92/100 [6:02:34<34:28, 258.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 871.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 861.79 examples/s]
 93%|█████████▎| 93/100 [6:06:57<30:17, 259.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 853.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 844.39 examples/s]
 94%|█████████▍| 94/100 [6:11:24<26:12, 262.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 915.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 906.81 examples/s]
 95%|█████████▌| 95/100 [6:16:14<22:31, 270.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 759.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 752.60 examples/s]
 96%|█████████▌| 96/100 [6:20:50<18:08, 272.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 887.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 879.62 examples/s]
 97%|█████████▋| 97/100 [6:24:09<12:29, 249.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 847.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 843.07 examples/s]
 98%|█████████▊| 98/100 [6:27:12<07:39, 229.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 886.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 876.62 examples/s]
 99%|█████████▉| 99/100 [6:31:32<03:59, 239.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 473.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 471.11 examples/s]
100%|██████████| 100/100 [6:34:45<00:00, 225.34s/it]100%|██████████| 100/100 [6:34:45<00:00, 236.86s/it]
