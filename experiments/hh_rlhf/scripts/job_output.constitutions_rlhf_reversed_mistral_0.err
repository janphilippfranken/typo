
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.08s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.52s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.39s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.56s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 374.48 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 367.16 examples/s]

  1%|          | 1/100 [01:52<3:06:12, 112.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3773.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3669.72 examples/s]

  2%|▏         | 2/100 [05:48<5:02:07, 184.97s/it]