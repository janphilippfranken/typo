Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:03<01:08,  3.80s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:05<00:41,  2.45s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:06<00:32,  2.03s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:08<00:27,  1.82s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:09<00:23,  1.71s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:11<00:21,  1.63s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:12<00:18,  1.57s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:14<00:17,  1.55s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:15<00:15,  1.55s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:17<00:13,  1.54s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:18<00:12,  1.52s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:20<00:10,  1.53s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:21<00:09,  1.53s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:23<00:07,  1.56s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:25<00:06,  1.55s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:26<00:04,  1.56s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:28<00:03,  1.55s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:29<00:01,  1.55s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:33<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:33<00:00,  1.74s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.45s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 83.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 82.21 examples/s]
  1%|          | 1/100 [02:54<4:47:57, 174.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 120.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 115.44 examples/s]
  2%|▏         | 2/100 [05:28<4:25:47, 162.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 125.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 123.54 examples/s]
  3%|▎         | 3/100 [08:42<4:45:41, 176.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/3 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 481.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 3/3 [00:00<00:00, 468.58 examples/s]
  4%|▍         | 4/100 [11:39<4:43:11, 176.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
