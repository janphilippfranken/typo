Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:09<02:46,  9.27s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:13<01:45,  6.20s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:16<01:18,  4.91s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:20<01:06,  4.46s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:24<01:02,  4.49s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:28<00:55,  4.27s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:32<00:48,  4.03s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:36<00:45,  4.12s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:40<00:40,  4.08s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:44<00:36,  4.04s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:48<00:32,  4.07s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:52<00:27,  4.00s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:56<00:24,  4.08s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [01:01<00:20,  4.10s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [01:05<00:16,  4.14s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [01:09<00:12,  4.02s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [01:13<00:08,  4.13s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [01:17<00:04,  4.24s/it]Loading checkpoint shards: 100%|██████████| 19/19 [01:25<00:00,  5.30s/it]Loading checkpoint shards: 100%|██████████| 19/19 [01:25<00:00,  4.51s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 10.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:22<00:00, 11.04s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 92.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 90.98 examples/s]
  1%|          | 1/100 [04:14<6:59:45, 254.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1151.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1122.13 examples/s]
  2%|▏         | 2/100 [08:15<6:42:19, 246.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1366.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1324.88 examples/s]
  3%|▎         | 3/100 [12:27<6:43:02, 249.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1135.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1106.73 examples/s]
  4%|▍         | 4/100 [16:53<6:49:19, 255.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1347.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1305.66 examples/s]
  5%|▌         | 5/100 [20:31<6:23:16, 242.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1371.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1331.44 examples/s]
  6%|▌         | 6/100 [24:37<6:21:24, 243.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1235.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1200.91 examples/s]
  7%|▋         | 7/100 [33:51<8:54:38, 344.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1282.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1246.08 examples/s]
  8%|▊         | 8/100 [42:56<10:26:43, 408.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1144.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1115.33 examples/s]
  9%|▉         | 9/100 [52:25<11:35:47, 458.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1192.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1141.62 examples/s]
 10%|█         | 10/100 [57:39<10:20:58, 413.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1161.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1113.02 examples/s]
 11%|█         | 11/100 [1:01:36<8:54:00, 360.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1124.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1095.35 examples/s]
 12%|█▏        | 12/100 [1:11:00<10:18:52, 421.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1153.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1123.57 examples/s]
 13%|█▎        | 13/100 [1:16:11<9:23:10, 388.40s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1198.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1166.12 examples/s]
 14%|█▍        | 14/100 [1:25:52<10:40:12, 446.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1095.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1067.36 examples/s]
 15%|█▌        | 15/100 [1:31:31<9:46:34, 414.06s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1185.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1154.18 examples/s]
 16%|█▌        | 16/100 [1:36:32<8:51:55, 379.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1068.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1042.84 examples/s]
 17%|█▋        | 17/100 [1:41:47<8:18:32, 360.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1082.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1055.86 examples/s]
 18%|█▊        | 18/100 [1:47:04<7:55:01, 347.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1168.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1137.22 examples/s]
 19%|█▉        | 19/100 [1:52:48<7:47:41, 346.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1093.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1065.73 examples/s]
 20%|██        | 20/100 [2:03:17<9:35:07, 431.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1064.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1039.02 examples/s]
 21%|██        | 21/100 [2:09:07<8:55:27, 406.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 998.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 976.19 examples/s]
 22%|██▏       | 22/100 [2:15:06<8:30:10, 392.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 997.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 975.24 examples/s]
 23%|██▎       | 23/100 [2:25:14<9:46:39, 457.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 928.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 897.52 examples/s]
 24%|██▍       | 24/100 [2:35:23<10:36:41, 502.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 646.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 630.95 examples/s]
 25%|██▌       | 25/100 [2:45:36<11:09:59, 535.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 976.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 953.60 examples/s]
 26%|██▌       | 26/100 [2:51:17<9:48:46, 477.39s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1017.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 995.00 examples/s] 
 27%|██▋       | 27/100 [2:57:28<9:01:45, 445.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1038.97 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1014.49 examples/s]
 28%|██▊       | 28/100 [3:07:52<9:58:47, 498.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 707.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 685.21 examples/s]
 29%|██▉       | 29/100 [3:15:15<9:30:50, 482.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 983.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 964.16 examples/s]
 30%|███       | 30/100 [3:22:26<9:04:46, 466.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 1028.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 990.16 examples/s] 
 31%|███       | 31/100 [3:29:54<8:50:10, 461.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 903.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 866.95 examples/s]
 32%|███▏      | 32/100 [3:37:05<8:32:24, 452.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 931.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 911.45 examples/s]
 33%|███▎      | 33/100 [3:48:06<9:35:00, 514.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 34%|███▍      | 34/100 [3:48:14<6:38:56, 362.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 916.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 889.38 examples/s]
 35%|███▌      | 35/100 [3:59:02<8:05:43, 448.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 942.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 905.86 examples/s]
 36%|███▌      | 36/100 [4:09:51<9:02:20, 508.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 695.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 679.09 examples/s]
 37%|███▋      | 37/100 [4:20:45<9:39:55, 552.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 825.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 797.64 examples/s]
 38%|███▊      | 38/100 [4:31:58<10:07:54, 588.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 449.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 442.19 examples/s]
 39%|███▉      | 39/100 [4:42:49<10:17:23, 607.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 871.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 844.16 examples/s]
 40%|████      | 40/100 [4:54:15<10:30:50, 630.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 768.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 743.54 examples/s]
 41%|████      | 41/100 [5:05:11<10:27:44, 638.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 42%|████▏     | 42/100 [5:05:18<7:13:55, 448.88s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 825.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 809.55 examples/s]
 43%|████▎     | 43/100 [5:16:17<8:06:18, 511.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 717.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 698.82 examples/s]
 44%|████▍     | 44/100 [5:27:43<8:46:32, 564.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 612.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 595.82 examples/s]
 45%|████▌     | 45/100 [5:39:01<9:08:27, 598.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 863.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 846.10 examples/s]
 46%|████▌     | 46/100 [5:46:46<8:22:24, 558.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 826.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 803.60 examples/s]
 47%|████▋     | 47/100 [5:57:34<8:36:59, 585.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 793.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 777.99 examples/s]
 48%|████▊     | 48/100 [6:05:35<8:00:13, 554.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 764.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 741.36 examples/s]
 49%|████▉     | 49/100 [6:16:28<8:16:07, 583.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 792.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 777.85 examples/s]
 50%|█████     | 50/100 [6:27:32<8:26:24, 607.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 593.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 578.88 examples/s]
 51%|█████     | 51/100 [6:36:24<7:57:42, 584.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 102.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 100.92 examples/s]
 52%|█████▏    | 52/100 [6:44:02<7:17:32, 546.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 722.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 701.04 examples/s]
 53%|█████▎    | 53/100 [6:52:51<7:04:18, 541.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 716.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 695.30 examples/s]
 54%|█████▍    | 54/100 [7:02:17<7:00:47, 548.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 735.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 718.79 examples/s]
 55%|█████▌    | 55/100 [7:10:16<6:36:01, 528.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 56%|█████▌    | 56/100 [7:10:23<4:32:31, 371.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 662.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 644.92 examples/s]
 57%|█████▋    | 57/100 [7:21:45<5:33:04, 464.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 601.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 592.99 examples/s]
 58%|█████▊    | 58/100 [7:33:14<6:12:22, 531.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 663.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 646.79 examples/s]
 59%|█████▉    | 59/100 [7:44:18<6:30:31, 571.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 627.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 612.41 examples/s]
 60%|██████    | 60/100 [7:56:06<6:48:22, 612.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 282.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 277.14 examples/s]
 61%|██████    | 61/100 [8:07:36<6:53:14, 635.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 52.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 52.24 examples/s]
 62%|██████▏   | 62/100 [8:17:50<6:38:34, 629.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 127.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 124.57 examples/s]
 63%|██████▎   | 63/100 [8:29:15<6:38:17, 645.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 362.34 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 357.30 examples/s]
 64%|██████▍   | 64/100 [8:40:29<6:32:36, 654.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 627.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 611.77 examples/s]
 65%|██████▌   | 65/100 [8:51:47<6:25:56, 661.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 592.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 584.70 examples/s]
 66%|██████▌   | 66/100 [9:03:42<6:23:51, 677.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 188.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 187.10 examples/s]
 67%|██████▋   | 67/100 [9:15:17<6:15:32, 682.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 607.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 595.46 examples/s]
 68%|██████▊   | 68/100 [9:26:50<6:05:47, 685.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 252.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 248.12 examples/s]
 69%|██████▉   | 69/100 [9:38:33<5:56:59, 690.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 284.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 280.50 examples/s]
 70%|███████   | 70/100 [9:48:34<5:32:03, 664.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 388.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 383.11 examples/s]
 71%|███████   | 71/100 [10:00:21<5:27:08, 676.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 137.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 136.59 examples/s]
 72%|███████▏  | 72/100 [10:12:29<5:23:03, 692.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 508.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 499.17 examples/s]
 73%|███████▎  | 73/100 [10:24:24<5:14:31, 698.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 185.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 182.75 examples/s]
 74%|███████▍  | 74/100 [10:36:11<5:03:56, 701.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 560.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 542.05 examples/s]
 75%|███████▌  | 75/100 [10:47:46<4:51:28, 699.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 554.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 544.57 examples/s]
 76%|███████▌  | 76/100 [10:59:26<4:39:50, 699.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 60.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 60.58 examples/s]
 77%|███████▋  | 77/100 [11:10:57<4:27:11, 697.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 506.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 497.66 examples/s]
 78%|███████▊  | 78/100 [11:20:45<4:03:33, 664.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 102.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 102.22 examples/s]
 79%|███████▉  | 79/100 [11:32:33<3:57:08, 677.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 550.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 538.84 examples/s]
 80%|████████  | 80/100 [11:44:17<3:48:30, 685.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 128.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 127.43 examples/s]
 81%|████████  | 81/100 [11:56:27<3:41:19, 698.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 556.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 545.25 examples/s]
 82%|████████▏ | 82/100 [12:07:52<3:28:25, 694.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 105.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 104.99 examples/s]
 83%|████████▎ | 83/100 [12:19:40<3:17:56, 698.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 362.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 357.95 examples/s]
 84%|████████▍ | 84/100 [12:31:27<3:06:55, 700.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 70.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 70.39 examples/s]
 85%|████████▌ | 85/100 [12:42:59<2:54:37, 698.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 331.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 328.59 examples/s]
 86%|████████▌ | 86/100 [12:55:02<2:44:42, 705.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 507.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 498.01 examples/s]
 87%|████████▋ | 87/100 [13:07:22<2:35:09, 716.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 524.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 514.73 examples/s]
 88%|████████▊ | 88/100 [13:19:23<2:23:29, 717.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 113.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 105.40 examples/s]
 89%|████████▉ | 89/100 [13:31:24<2:11:42, 718.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 86.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 86.60 examples/s]
 90%|█████████ | 90/100 [13:43:09<1:59:04, 714.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 91%|█████████ | 91/100 [13:43:15<1:15:17, 501.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 95.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 95.49 examples/s]
 92%|█████████▏| 92/100 [13:54:59<1:15:01, 562.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 488.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 478.46 examples/s]
 93%|█████████▎| 93/100 [14:06:53<1:10:56, 608.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 172.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 171.29 examples/s]
 94%|█████████▍| 94/100 [14:18:35<1:03:36, 636.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 490.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 480.48 examples/s]
 95%|█████████▌| 95/100 [14:30:23<54:48, 657.78s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 475.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 464.41 examples/s]
 96%|█████████▌| 96/100 [14:42:17<44:57, 674.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 147.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 146.64 examples/s]
 97%|█████████▋| 97/100 [14:54:08<34:16, 685.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 126.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 126.30 examples/s]
 98%|█████████▊| 98/100 [15:05:54<23:03, 691.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
 99%|█████████▉| 99/100 [15:06:00<08:06, 486.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/5 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 112.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 5/5 [00:00<00:00, 111.72 examples/s]
100%|██████████| 100/100 [15:17:52<00:00, 553.75s/it]100%|██████████| 100/100 [15:17:52<00:00, 550.73s/it]
