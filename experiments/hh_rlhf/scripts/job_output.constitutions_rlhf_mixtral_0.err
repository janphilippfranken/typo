Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:05<01:46,  5.92s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:08<01:04,  3.82s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:10<00:47,  2.95s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:12<00:38,  2.60s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:14<00:35,  2.54s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:17<00:32,  2.48s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:19<00:28,  2.37s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:21<00:25,  2.31s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:23<00:22,  2.24s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:25<00:19,  2.19s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:27<00:17,  2.25s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:30<00:15,  2.22s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:32<00:13,  2.18s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:34<00:11,  2.21s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:36<00:08,  2.22s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:38<00:06,  2.18s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:40<00:04,  2.17s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:43<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:48<00:00,  3.00s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:48<00:00,  2.53s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.98s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 418.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 413.83 examples/s]
  1%|          | 1/100 [03:40<6:04:05, 220.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3058.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2938.22 examples/s]
  2%|▏         | 2/100 [07:50<6:28:30, 237.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4880.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4756.26 examples/s]
  3%|▎         | 3/100 [11:06<5:53:35, 218.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4619.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4496.71 examples/s]
  4%|▍         | 4/100 [14:59<5:59:06, 224.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3478.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3371.90 examples/s]
  5%|▌         | 5/100 [24:44<9:20:58, 354.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4744.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4555.31 examples/s]
  6%|▌         | 6/100 [28:59<8:22:14, 320.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1551.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1522.63 examples/s]
  7%|▋         | 7/100 [33:23<7:48:18, 302.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4922.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4803.65 examples/s]
  8%|▊         | 8/100 [33:46<5:26:59, 213.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3584.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3468.37 examples/s]
  9%|▉         | 9/100 [38:45<6:04:09, 240.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3404.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3305.07 examples/s]
 10%|█         | 10/100 [43:35<6:23:23, 255.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4154.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4063.46 examples/s]
 11%|█         | 11/100 [53:28<8:52:10, 358.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3327.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3266.08 examples/s]
 12%|█▏        | 12/100 [58:21<8:16:47, 338.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3620.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3547.58 examples/s]
 13%|█▎        | 13/100 [1:03:13<7:50:29, 324.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3569.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3455.37 examples/s]
 14%|█▍        | 14/100 [1:08:30<7:42:11, 322.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4077.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3987.74 examples/s]
 15%|█▌        | 15/100 [1:18:37<9:38:11, 408.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 4017.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3895.70 examples/s]
 16%|█▌        | 16/100 [1:23:54<8:52:47, 380.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3269.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3171.26 examples/s]
 17%|█▋        | 17/100 [1:33:51<10:16:28, 445.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3523.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3413.61 examples/s]
 18%|█▊        | 18/100 [1:44:24<11:25:59, 501.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2819.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2770.71 examples/s]
 19%|█▉        | 19/100 [1:51:01<10:35:21, 470.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3287.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3230.36 examples/s]
 20%|██        | 20/100 [1:57:13<9:47:49, 440.87s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3140.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3060.87 examples/s]
 21%|██        | 21/100 [2:08:08<11:05:16, 505.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2687.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2625.95 examples/s]
 22%|██▏       | 22/100 [2:18:26<11:40:53, 539.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 3069.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2985.91 examples/s]
 23%|██▎       | 23/100 [2:28:43<12:01:44, 562.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1940.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1906.55 examples/s]
 24%|██▍       | 24/100 [2:39:18<12:19:58, 584.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2435.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2376.17 examples/s]
 25%|██▌       | 25/100 [2:49:30<12:20:44, 592.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2717.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2653.28 examples/s]
 26%|██▌       | 26/100 [2:59:56<12:23:15, 602.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2811.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2739.76 examples/s]
 27%|██▋       | 27/100 [3:10:29<12:24:08, 611.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2316.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2267.31 examples/s]
 28%|██▊       | 28/100 [3:21:04<12:22:14, 618.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2679.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 2622.34 examples/s]
 29%|██▉       | 29/100 [3:31:34<12:16:09, 622.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1870.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1837.83 examples/s]
 30%|███       | 30/100 [3:42:15<12:12:12, 627.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1503.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1482.71 examples/s]
 31%|███       | 31/100 [3:53:25<12:16:23, 640.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1626.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1606.43 examples/s]
 32%|███▏      | 32/100 [3:53:50<8:36:46, 455.98s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1543.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1517.83 examples/s]
 33%|███▎      | 33/100 [4:04:23<9:28:15, 508.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 684.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 667.48 examples/s]
 34%|███▍      | 34/100 [4:04:48<6:40:13, 363.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1071.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1038.13 examples/s]
 35%|███▌      | 35/100 [4:15:52<8:11:44, 453.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1878.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1809.18 examples/s]
 36%|███▌      | 36/100 [4:26:51<9:09:34, 515.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1435.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1402.36 examples/s]
 37%|███▋      | 37/100 [4:37:55<9:48:08, 560.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1036.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1025.48 examples/s]
 38%|███▊      | 38/100 [4:48:46<10:06:58, 587.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1264.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1240.22 examples/s]
 39%|███▉      | 39/100 [4:59:29<10:14:08, 604.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1334.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1316.50 examples/s]
 40%|████      | 40/100 [5:10:27<10:20:11, 620.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1411.06 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1385.49 examples/s]
 41%|████      | 41/100 [5:21:22<10:20:05, 630.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 718.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 713.29 examples/s]
 42%|████▏     | 42/100 [5:32:14<10:15:46, 637.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 787.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 766.80 examples/s]
 43%|████▎     | 43/100 [5:43:19<10:13:04, 645.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1369.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1353.50 examples/s]
 44%|████▍     | 44/100 [5:43:46<7:09:18, 459.96s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1798.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1780.91 examples/s]
 45%|████▌     | 45/100 [5:44:09<5:01:23, 328.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 659.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 653.34 examples/s]
 46%|████▌     | 46/100 [5:55:02<6:23:25, 426.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/20 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1857.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 20/20 [00:00<00:00, 1839.24 examples/s]
 47%|████▋     | 47/100 [5:55:27<4:30:01, 305.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
