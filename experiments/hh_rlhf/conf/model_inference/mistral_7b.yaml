hydra:
  run:
    dir: outputs

model_type: huggingface
name: mistral_7b_base

device_ids: 
 - 1
 - 2 

model_config:
  model_id: "mistral"
  pretrained_model_name_or_path: "mistralai/Mistral-7B-v0.1"
  load_in_8bit: true
  device_map: "cuda:1"
  # max_memory:
  #   0: "1.0GB"  # do not use 0
  #   1: "80.0GB" # split across 2 and 3
  #   2: "80.0GB" # split across 2 and 3
  torch_dtype: "float16"
  model_cache_dir: "/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1"
  tokenizer_cache_dir: "/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1"

generation:
  do_sample: true
  temperature: 0.1
  top_p: 0.9
  max_new_tokens: 500