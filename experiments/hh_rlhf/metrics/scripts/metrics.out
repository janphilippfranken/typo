[2024-01-29 10:15:07,178][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_1 using mixtral_7b_dpo_16 on test
INFO 01-29 10:15:11 llm_engine.py:70] Initializing an LLM engine with config: model='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:15:35 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:15:37 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:15:37 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=3194105)[0m INFO 01-29 10:15:37 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=3194105)[0m INFO 01-29 10:15:37 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-29 10:16:11 model_runner.py:547] Graph capturing finished in 35 secs.
[36m(RayWorkerVllm pid=3194105)[0m INFO 01-29 10:16:11 model_runner.py:547] Graph capturing finished in 35 secs.
[2024-01-29 10:16:14,651][root][INFO] - RUNNING ANSWER
[2024-01-29 10:16:14,651][root][INFO] - range(1000, 1100)
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
[2024-01-29 10:16:43,628][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_1 using mixtral_7b_base on test
INFO 01-29 10:16:48 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mixtral-8x7B-v0.1', tokenizer='mistralai/Mixtral-8x7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:17:10 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:17:12 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:17:12 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=3202458)[0m INFO 01-29 10:17:12 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=3202458)[0m INFO 01-29 10:17:12 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-29 10:17:46 model_runner.py:547] Graph capturing finished in 34 secs.
[36m(RayWorkerVllm pid=3202458)[0m INFO 01-29 10:17:46 model_runner.py:547] Graph capturing finished in 34 secs.
[2024-01-29 10:17:49,162][root][INFO] - RUNNING ANSWER
[2024-01-29 10:17:49,163][root][INFO] - range(1000, 1100)
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
[2024-01-29 10:18:19,397][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_2 using mixtral_7b_dpo_16 on test
INFO 01-29 10:18:23 llm_engine.py:70] Initializing an LLM engine with config: model='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:18:43 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:18:45 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:18:45 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=3217403)[0m INFO 01-29 10:18:45 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=3217403)[0m INFO 01-29 10:18:45 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-29 10:19:19 model_runner.py:547] Graph capturing finished in 34 secs.
[36m(RayWorkerVllm pid=3217403)[0m INFO 01-29 10:19:19 model_runner.py:547] Graph capturing finished in 34 secs.
[2024-01-29 10:19:22,618][root][INFO] - RUNNING ANSWER
[2024-01-29 10:19:22,618][root][INFO] - range(1000, 1100)
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
[2024-01-29 10:19:52,683][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_2 using mixtral_7b_base on test
INFO 01-29 10:19:58 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mixtral-8x7B-v0.1', tokenizer='mistralai/Mixtral-8x7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:20:20 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:20:22 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:20:22 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=3232610)[0m INFO 01-29 10:20:22 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=3232610)[0m INFO 01-29 10:20:22 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-29 10:20:56 model_runner.py:547] Graph capturing finished in 34 secs.
[36m(RayWorkerVllm pid=3232610)[0m INFO 01-29 10:20:56 model_runner.py:547] Graph capturing finished in 34 secs.
[2024-01-29 10:20:59,192][root][INFO] - RUNNING ANSWER
[2024-01-29 10:20:59,192][root][INFO] - range(1000, 1100)
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
[2024-01-29 10:21:30,606][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_3 using mixtral_7b_dpo_16 on test
INFO 01-29 10:21:34 llm_engine.py:70] Initializing an LLM engine with config: model='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/trained_models/Mixtral-8x7B-v0.1/merged/16bit/checkpoint-1500/', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:21:56 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:21:57 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:21:57 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=3253074)[0m INFO 01-29 10:21:57 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=3253074)[0m INFO 01-29 10:21:57 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-29 10:22:33 model_runner.py:547] Graph capturing finished in 35 secs.
[36m(RayWorkerVllm pid=3253074)[0m INFO 01-29 10:22:33 model_runner.py:547] Graph capturing finished in 35 secs.
[2024-01-29 10:22:35,567][root][INFO] - RUNNING ANSWER
[2024-01-29 10:22:35,568][root][INFO] - range(1000, 1100)
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
reversed constitution
[2024-01-29 10:23:08,308][root][INFO] - Evaluating rlhf_test_mixtral_7b_base_run_3 using mixtral_7b_base on test
INFO 01-29 10:23:12 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mixtral-8x7B-v0.1', tokenizer='mistralai/Mixtral-8x7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-29 10:23:34 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-29 10:23:36 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-29 10:23:36 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
