Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:22,  1.27s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:20,  1.18s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:18,  1.16s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:04<00:17,  1.14s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:05<00:15,  1.13s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:06<00:14,  1.12s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:07<00:13,  1.11s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:09<00:12,  1.11s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:10<00:11,  1.11s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:11<00:09,  1.10s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:12<00:08,  1.11s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:13<00:07,  1.12s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:14<00:06,  1.13s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:15<00:05,  1.12s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:16<00:04,  1.13s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:18<00:03,  1.13s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:19<00:02,  1.12s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:20<00:01,  1.13s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:21<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:21<00:00,  1.12s/it]
  0%|          | 0/500 [00:00<?, ?it/s]/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 1/500 [00:26<3:39:08, 26.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 2/500 [00:51<3:32:40, 25.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 3/500 [01:16<3:29:23, 25.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 4/500 [01:42<3:32:07, 25.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 5/500 [02:07<3:28:43, 25.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 6/500 [02:31<3:25:57, 25.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|▏         | 7/500 [02:56<3:24:16, 24.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 8/500 [03:21<3:26:00, 25.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 9/500 [03:47<3:26:48, 25.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 10/500 [04:12<3:26:42, 25.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 11/500 [04:38<3:26:31, 25.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 12/500 [05:04<3:29:21, 25.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 13/500 [05:30<3:28:15, 25.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 14/500 [05:54<3:24:00, 25.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 15/500 [06:20<3:25:47, 25.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 16/500 [06:43<3:18:23, 24.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 17/500 [07:08<3:20:35, 24.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▎         | 18/500 [07:33<3:18:18, 24.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 19/500 [07:57<3:18:17, 24.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 20/500 [08:23<3:19:24, 24.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 21/500 [08:48<3:20:49, 25.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 22/500 [09:14<3:20:48, 25.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|▍         | 23/500 [09:39<3:19:30, 25.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|▍         | 24/500 [10:03<3:17:47, 24.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|▌         | 25/500 [10:28<3:17:08, 24.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|▌         | 26/500 [10:52<3:15:29, 24.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  5%|▌         | 27/500 [11:18<3:16:24, 24.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
