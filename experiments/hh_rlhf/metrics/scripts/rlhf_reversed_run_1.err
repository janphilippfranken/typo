Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:30,  1.67s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:03<00:26,  1.56s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:04<00:24,  1.52s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:06<00:22,  1.49s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:07<00:20,  1.48s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:09<00:19,  1.48s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:10<00:17,  1.47s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:11<00:16,  1.46s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:13<00:14,  1.46s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:14<00:12,  1.44s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:16<00:11,  1.43s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:17<00:09,  1.42s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:18<00:08,  1.42s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:20<00:07,  1.42s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:21<00:05,  1.42s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:23<00:04,  1.42s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:24<00:02,  1.41s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:26<00:01,  1.43s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:27<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:27<00:00,  1.44s/it]
  0%|          | 0/500 [00:00<?, ?it/s]/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/scr/jphilipp/miniconda3/envs/scai-tuning/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:394: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 1/500 [00:26<3:38:38, 26.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  0%|          | 2/500 [00:51<3:34:51, 25.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 3/500 [01:16<3:31:12, 25.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 4/500 [01:43<3:35:17, 26.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 5/500 [02:09<3:35:14, 26.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|          | 6/500 [02:36<3:34:38, 26.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  1%|▏         | 7/500 [03:01<3:33:27, 25.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 8/500 [03:27<3:32:01, 25.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 9/500 [03:52<3:30:34, 25.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 10/500 [04:16<3:24:22, 25.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 11/500 [04:39<3:19:49, 24.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  2%|▏         | 12/500 [05:05<3:22:41, 24.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 13/500 [05:31<3:23:53, 25.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 14/500 [05:55<3:22:16, 24.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 15/500 [06:21<3:24:00, 25.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 16/500 [06:45<3:20:34, 24.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  3%|▎         | 17/500 [07:10<3:20:52, 24.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▎         | 18/500 [07:35<3:19:51, 24.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 19/500 [07:59<3:18:14, 24.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 20/500 [08:25<3:19:56, 24.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
  4%|▍         | 21/500 [08:50<3:19:46, 25.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
