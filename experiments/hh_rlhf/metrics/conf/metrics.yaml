hydra:
  run:
    dir: outputs

defaults:
  - model: mistral_7b_sft_100_examples
  - data: hh_rlhf

# path to constitutions we are evaluating 
constitution_path: ../sample/constitutions
constitution_file: rlhf_reversed_test_mixtral_7b_base_run_1
split: test

evaluation_prompt: evaluation_prompt_answer # prompt we are using for eval (same as for training)
storage_path: ./predictions # storage path

start_of_test_examples: 1000 # examples after these were never seen when inducing a constitution
n_examples: 100 # how many examples from test set we want to eval on