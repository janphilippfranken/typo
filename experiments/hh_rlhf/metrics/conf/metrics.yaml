hydra:
  run:
    dir: outputs

defaults:
  - model: mixtral_7b_vllm_dpo
  - data: hh_rlhf

# path to constitutions we are evaluating 
constitution_path: ../sample/constitutions
constitution_file: rlhf_reversed_gen_mixtral_7b_base_eval_mixtral_7b_base_gen_prompt_generation_prompt_base_2_run_4
split: train

evaluation_prompt: evaluation_prompt_answer # prompt we are using for eval (same as for training)
storage_path: ./predictions # storage path

start_of_test_examples: 1000 # examples after these were never seen when inducing a constitution
n_examples: 100 # how many examples from test set we want to eval on