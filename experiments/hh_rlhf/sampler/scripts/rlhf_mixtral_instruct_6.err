Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:20,  1.15s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:18,  1.07s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:16,  1.05s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:04<00:15,  1.03s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:05<00:14,  1.02s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:06<00:13,  1.01s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:07<00:12,  1.00s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:08<00:10,  1.00it/s]Loading checkpoint shards:  47%|████▋     | 9/19 [00:09<00:09,  1.00it/s]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:10<00:08,  1.01it/s]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:11<00:08,  1.00s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:12<00:07,  1.01s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:13<00:06,  1.01s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:14<00:05,  1.01s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:15<00:04,  1.01s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:16<00:03,  1.01s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:17<00:02,  1.00s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:18<00:01,  1.01s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:19<00:00,  1.03it/s]Loading checkpoint shards: 100%|██████████| 19/19 [00:19<00:00,  1.01s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.34 examples/s]
  1%|          | 1/100 [02:15<3:42:53, 135.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.47 examples/s]
  2%|▏         | 2/100 [04:00<3:11:56, 117.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.89 examples/s]
  3%|▎         | 3/100 [05:33<2:52:15, 106.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.17 examples/s]
  4%|▍         | 4/100 [07:20<2:50:52, 106.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.46 examples/s]
  5%|▌         | 5/100 [09:35<3:04:45, 116.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 270.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.72 examples/s]
  6%|▌         | 6/100 [11:52<3:13:34, 123.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 268.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.26 examples/s]
  7%|▋         | 7/100 [13:27<2:57:25, 114.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.89 examples/s]
  8%|▊         | 8/100 [15:33<3:01:10, 118.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.59 examples/s]
  9%|▉         | 9/100 [17:44<3:05:14, 122.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.48 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.17 examples/s]
 10%|█         | 10/100 [19:29<2:55:11, 116.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 282.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 274.48 examples/s]
 11%|█         | 11/100 [21:20<2:50:27, 114.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.38 examples/s]
 12%|█▏        | 12/100 [22:54<2:39:22, 108.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 263.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.02 examples/s]
 13%|█▎        | 13/100 [25:11<2:49:46, 117.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.12 examples/s]
 14%|█▍        | 14/100 [27:33<2:58:41, 124.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 255.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.51 examples/s]
 15%|█▌        | 15/100 [29:17<2:47:59, 118.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.10 examples/s]
 16%|█▌        | 16/100 [31:40<2:56:16, 125.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 279.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.37 examples/s]
 17%|█▋        | 17/100 [33:31<2:47:54, 121.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 263.26 examples/s]
 18%|█▊        | 18/100 [35:25<2:42:44, 119.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.43 examples/s]
 19%|█▉        | 19/100 [37:32<2:44:04, 121.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.77 examples/s]
 20%|██        | 20/100 [39:20<2:36:30, 117.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.08 examples/s]
 21%|██        | 21/100 [41:24<2:37:21, 119.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 282.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 274.51 examples/s]
 22%|██▏       | 22/100 [43:34<2:39:14, 122.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 270.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.85 examples/s]
 23%|██▎       | 23/100 [45:13<2:28:20, 115.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.20 examples/s]
 24%|██▍       | 24/100 [47:16<2:29:21, 117.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.45 examples/s]
 25%|██▌       | 25/100 [49:15<2:27:47, 118.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.91 examples/s]
 26%|██▌       | 26/100 [51:27<2:30:37, 122.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.83 examples/s]
 27%|██▋       | 27/100 [53:31<2:29:20, 122.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.86 examples/s]
 28%|██▊       | 28/100 [55:50<2:33:12, 127.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.80 examples/s]
 29%|██▉       | 29/100 [57:31<2:21:40, 119.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.49 examples/s]
 30%|███       | 30/100 [59:32<2:20:11, 120.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.07 examples/s]
 31%|███       | 31/100 [1:01:53<2:25:05, 126.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.04 examples/s]
 32%|███▏      | 32/100 [1:03:42<2:17:17, 121.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 269.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.03 examples/s]
 33%|███▎      | 33/100 [1:05:50<2:17:29, 123.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.70 examples/s]
 34%|███▍      | 34/100 [1:08:14<2:22:31, 129.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.77 examples/s]
 35%|███▌      | 35/100 [1:10:18<2:18:31, 127.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.24 examples/s]
 36%|███▌      | 36/100 [1:12:18<2:13:46, 125.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.58 examples/s]
 37%|███▋      | 37/100 [1:14:36<2:15:41, 129.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 185.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.18 examples/s]
 38%|███▊      | 38/100 [1:16:33<2:09:42, 125.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.03 examples/s]
 39%|███▉      | 39/100 [1:18:40<2:08:11, 126.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.12 examples/s]
 40%|████      | 40/100 [1:21:03<2:10:59, 130.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.41 examples/s]
 41%|████      | 41/100 [1:23:19<2:10:12, 132.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.66 examples/s]
 42%|████▏     | 42/100 [1:25:45<2:12:05, 136.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.38 examples/s]
 43%|████▎     | 43/100 [1:27:44<2:04:39, 131.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.37 examples/s]
 44%|████▍     | 44/100 [1:29:40<1:58:15, 126.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.13 examples/s]
 45%|████▌     | 45/100 [1:31:38<1:53:46, 124.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.69 examples/s]
 46%|████▌     | 46/100 [1:33:50<1:53:49, 126.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 273.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.89 examples/s]
 47%|████▋     | 47/100 [1:35:56<1:51:37, 126.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.42 examples/s]
 48%|████▊     | 48/100 [1:38:02<1:49:19, 126.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.04 examples/s]
 49%|████▉     | 49/100 [1:40:29<1:52:45, 132.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.58 examples/s]
 50%|█████     | 50/100 [1:42:50<1:52:32, 135.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.67 examples/s]
 51%|█████     | 51/100 [1:45:04<1:50:08, 134.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.30 examples/s]
 52%|█████▏    | 52/100 [1:47:04<1:44:08, 130.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 255.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.92 examples/s]
 53%|█████▎    | 53/100 [1:49:00<1:38:47, 126.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.13 examples/s]
 54%|█████▍    | 54/100 [1:51:22<1:40:17, 130.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.14 examples/s]
 55%|█████▌    | 55/100 [1:53:43<1:40:27, 133.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.44 examples/s]
 56%|█████▌    | 56/100 [1:55:39<1:34:04, 128.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.72 examples/s]
 57%|█████▋    | 57/100 [1:57:26<1:27:31, 122.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.70 examples/s]
 58%|█████▊    | 58/100 [1:59:25<1:24:41, 121.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.43 examples/s]
 59%|█████▉    | 59/100 [2:01:34<1:24:24, 123.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.84 examples/s]
 60%|██████    | 60/100 [2:03:45<1:23:50, 125.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.75 examples/s]
 61%|██████    | 61/100 [2:06:03<1:24:03, 129.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.69 examples/s]
 62%|██████▏   | 62/100 [2:08:16<1:22:42, 130.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.85 examples/s]
 63%|██████▎   | 63/100 [2:10:18<1:18:57, 128.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.85 examples/s]
 64%|██████▍   | 64/100 [2:12:50<1:21:07, 135.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.82 examples/s]
 65%|██████▌   | 65/100 [2:15:15<1:20:30, 138.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.71 examples/s]
 66%|██████▌   | 66/100 [2:17:07<1:13:47, 130.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.13 examples/s]
 67%|██████▋   | 67/100 [2:19:46<1:16:23, 138.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.08 examples/s]
 68%|██████▊   | 68/100 [2:22:18<1:16:06, 142.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.43 examples/s]
 69%|██████▉   | 69/100 [2:24:13<1:09:28, 134.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.94 examples/s]
 70%|███████   | 70/100 [2:26:41<1:09:13, 138.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.07 examples/s]
 71%|███████   | 71/100 [2:28:24<1:01:54, 128.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.69 examples/s]
 72%|███████▏  | 72/100 [2:30:41<1:00:55, 130.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.92 examples/s]
 73%|███████▎  | 73/100 [2:33:06<1:00:44, 134.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.20 examples/s]
 74%|███████▍  | 74/100 [2:34:54<55:01, 126.96s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.42 examples/s]
 75%|███████▌  | 75/100 [2:37:21<55:23, 132.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.06 examples/s]
 76%|███████▌  | 76/100 [2:39:47<54:45, 136.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.77 examples/s]
 77%|███████▋  | 77/100 [2:42:08<52:54, 138.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.62 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.76 examples/s]
 78%|███████▊  | 78/100 [2:44:15<49:21, 134.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.97 examples/s]
 79%|███████▉  | 79/100 [2:46:53<49:37, 141.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.38 examples/s]
 80%|████████  | 80/100 [2:49:10<46:44, 140.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.71 examples/s]
 81%|████████  | 81/100 [2:51:33<44:42, 141.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.27 examples/s]
 82%|████████▏ | 82/100 [2:54:03<43:10, 143.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.83 examples/s]
 83%|████████▎ | 83/100 [2:56:26<40:40, 143.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.65 examples/s]
 84%|████████▍ | 84/100 [2:58:38<37:21, 140.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.18 examples/s]
 85%|████████▌ | 85/100 [3:00:43<33:54, 135.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.31 examples/s]
 86%|████████▌ | 86/100 [3:02:39<30:15, 129.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.36 examples/s]
 87%|████████▋ | 87/100 [3:05:01<28:53, 133.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.46 examples/s]
 88%|████████▊ | 88/100 [3:07:34<27:50, 139.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.41 examples/s]
 89%|████████▉ | 89/100 [3:09:42<24:54, 135.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.71 examples/s]
 90%|█████████ | 90/100 [3:11:49<22:11, 133.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 181.47 examples/s]
 91%|█████████ | 91/100 [3:14:17<20:38, 137.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.76 examples/s]
 92%|█████████▏| 92/100 [3:16:24<17:55, 134.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.69 examples/s]
 93%|█████████▎| 93/100 [3:18:18<14:58, 128.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.95 examples/s]
 94%|█████████▍| 94/100 [3:20:20<12:39, 126.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.15 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.88 examples/s]
 95%|█████████▌| 95/100 [3:22:43<10:57, 131.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.48 examples/s]
 96%|█████████▌| 96/100 [3:25:12<09:06, 136.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.19 examples/s]
 97%|█████████▋| 97/100 [3:27:37<06:57, 139.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 172.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.62 examples/s]
 98%|█████████▊| 98/100 [3:30:04<04:43, 141.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.04 examples/s]
 99%|█████████▉| 99/100 [3:32:13<02:17, 137.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.20 examples/s]
100%|██████████| 100/100 [3:34:45<00:00, 141.98s/it]100%|██████████| 100/100 [3:34:45<00:00, 128.85s/it]
ERROR: Cannot find key: sampler.run_id=6
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         is_valid_response | extract_new_principle |
                         extract_revised_principle | process_responses |
                         filter_responses | run_generate | run_eval |
                         GPT4Agent | AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
