
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.42 examples/s]

  1%|          | 1/100 [00:12<20:04, 12.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.47 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.59 examples/s]

  2%|▏         | 2/100 [00:25<20:31, 12.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.09 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.42 examples/s]

  3%|▎         | 3/100 [00:38<21:10, 13.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.81 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.66 examples/s]

  4%|▍         | 4/100 [00:54<22:23, 14.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.54 examples/s]

  5%|▌         | 5/100 [01:12<24:40, 15.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.83 examples/s]

  6%|▌         | 6/100 [01:29<25:22, 16.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.36 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.95 examples/s]

  7%|▋         | 7/100 [01:49<26:44, 17.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.90 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.84 examples/s]

  8%|▊         | 8/100 [02:10<28:18, 18.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.10 examples/s]

  9%|▉         | 9/100 [02:32<29:55, 19.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.05 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.54 examples/s]

 10%|█         | 10/100 [02:56<31:12, 20.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 285.95 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 277.93 examples/s]

 11%|█         | 11/100 [03:19<32:00, 21.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.26 examples/s]

 12%|█▏        | 12/100 [03:44<33:07, 22.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.49 examples/s]

 13%|█▎        | 13/100 [04:08<33:31, 23.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 270.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 263.06 examples/s]

 14%|█▍        | 14/100 [04:34<34:28, 24.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 291.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 283.07 examples/s]

 15%|█▌        | 15/100 [05:01<35:04, 24.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.59 examples/s]

 16%|█▌        | 16/100 [05:29<36:18, 25.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.41 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.48 examples/s]

 17%|█▋        | 17/100 [05:55<35:42, 25.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.33 examples/s]

 18%|█▊        | 18/100 [06:22<35:50, 26.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.99 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.32 examples/s]

 19%|█▉        | 19/100 [06:48<35:15, 26.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.19 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.59 examples/s]

 20%|██        | 20/100 [07:14<34:48, 26.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.13 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.86 examples/s]

 21%|██        | 21/100 [07:42<34:59, 26.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.35 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.02 examples/s]

 22%|██▏       | 22/100 [08:10<35:01, 26.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.25 examples/s]

 23%|██▎       | 23/100 [08:37<34:38, 26.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.90 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.34 examples/s]

 24%|██▍       | 24/100 [09:06<35:04, 27.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 158.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 153.86 examples/s]

 25%|██▌       | 25/100 [09:37<35:59, 28.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 268.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.34 examples/s]

 26%|██▌       | 26/100 [10:06<35:29, 28.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.23 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.19 examples/s]

 27%|██▋       | 27/100 [10:35<34:51, 28.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.80 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.07 examples/s]

 28%|██▊       | 28/100 [11:05<35:02, 29.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.84 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.56 examples/s]

 29%|██▉       | 29/100 [11:35<34:59, 29.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.81 examples/s]

 30%|███       | 30/100 [12:07<35:16, 30.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.86 examples/s]

 31%|███       | 31/100 [12:38<35:02, 30.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.58 examples/s]

 32%|███▏      | 32/100 [13:09<34:33, 30.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.53 examples/s]

 33%|███▎      | 33/100 [13:41<34:37, 31.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.88 examples/s]

 34%|███▍      | 34/100 [14:15<35:01, 31.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.49 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.97 examples/s]

 35%|███▌      | 35/100 [14:48<35:01, 32.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.50 examples/s]

 36%|███▌      | 36/100 [15:21<34:38, 32.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.19 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.38 examples/s]

 37%|███▋      | 37/100 [16:01<36:32, 34.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.26 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.72 examples/s]

 38%|███▊      | 38/100 [16:39<37:00, 35.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.97 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.85 examples/s]

 39%|███▉      | 39/100 [17:15<36:14, 35.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.55 examples/s]

 40%|████      | 40/100 [17:52<36:13, 36.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.19 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.41 examples/s]

 41%|████      | 41/100 [18:31<36:21, 36.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.86 examples/s]

 42%|████▏     | 42/100 [19:11<36:34, 37.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.36 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.74 examples/s]

 43%|████▎     | 43/100 [19:53<37:08, 39.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.20 examples/s]

 44%|████▍     | 44/100 [20:36<37:29, 40.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.07 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.89 examples/s]

 45%|████▌     | 45/100 [21:20<38:01, 41.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.68 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.90 examples/s]

 46%|████▌     | 46/100 [22:02<37:31, 41.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.53 examples/s]

 47%|████▋     | 47/100 [22:47<37:37, 42.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.80 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.86 examples/s]

 48%|████▊     | 48/100 [23:33<37:52, 43.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.48 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.58 examples/s]

 49%|████▉     | 49/100 [24:20<37:56, 44.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.69 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.85 examples/s]

 50%|█████     | 50/100 [25:03<36:52, 44.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.69 examples/s]

 51%|█████     | 51/100 [25:54<37:34, 46.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.21 examples/s]

 52%|█████▏    | 52/100 [26:38<36:23, 45.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.45 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.42 examples/s]

 53%|█████▎    | 53/100 [27:25<36:07, 46.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.40 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.58 examples/s]

 54%|█████▍    | 54/100 [28:11<35:08, 45.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.37 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 185.31 examples/s]

 55%|█████▌    | 55/100 [28:58<34:50, 46.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.05 examples/s]

 56%|█████▌    | 56/100 [29:43<33:44, 46.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.04 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.71 examples/s]

 57%|█████▋    | 57/100 [30:32<33:27, 46.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.85 examples/s]

 58%|█████▊    | 58/100 [31:20<32:55, 47.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 152.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 149.11 examples/s]

 59%|█████▉    | 59/100 [32:08<32:27, 47.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.21 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.45 examples/s]

 60%|██████    | 60/100 [32:57<32:00, 48.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 181.73 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.38 examples/s]

 61%|██████    | 61/100 [33:45<31:06, 47.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.94 examples/s]

 62%|██████▏   | 62/100 [34:34<30:28, 48.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.27 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 165.42 examples/s]

 63%|██████▎   | 63/100 [35:24<30:06, 48.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.63 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.13 examples/s]

 64%|██████▍   | 64/100 [36:13<29:21, 48.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 167.08 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 161.84 examples/s]

 65%|██████▌   | 65/100 [37:04<28:56, 49.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.07 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.53 examples/s]

 66%|██████▌   | 66/100 [37:55<28:20, 50.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.55 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 163.51 examples/s]

 67%|██████▋   | 67/100 [38:48<27:51, 50.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.44 examples/s]

 68%|██████▊   | 68/100 [39:42<27:36, 51.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 161.84 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 156.61 examples/s]

 69%|██████▉   | 69/100 [40:36<27:08, 52.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.38 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 165.59 examples/s]

 70%|███████   | 70/100 [41:33<26:52, 53.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.87 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 155.65 examples/s]

 71%|███████   | 71/100 [42:28<26:11, 54.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 165.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.94 examples/s]

 72%|███████▏  | 72/100 [43:24<25:29, 54.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 154.03 examples/s]

 73%|███████▎  | 73/100 [44:17<24:24, 54.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 172.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.65 examples/s]

 74%|███████▍  | 74/100 [45:12<23:32, 54.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 156.22 examples/s]

 75%|███████▌  | 75/100 [46:09<23:01, 55.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 165.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.41 examples/s]

 76%|███████▌  | 76/100 [47:12<23:02, 57.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 122.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 119.53 examples/s]

 77%|███████▋  | 77/100 [48:16<22:49, 59.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.24 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 167.36 examples/s]

 78%|███████▊  | 78/100 [49:18<22:07, 60.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 138.15 examples/s]

 79%|███████▉  | 79/100 [50:18<21:05, 60.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 154.16 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 149.67 examples/s]

 80%|████████  | 80/100 [51:24<20:34, 61.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 155.05 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.12 examples/s]

 81%|████████  | 81/100 [52:25<19:33, 61.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 153.78 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.24 examples/s]

 82%|████████▏ | 82/100 [53:27<18:28, 61.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 154.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 151.40 examples/s]

 83%|████████▎ | 83/100 [54:33<17:50, 62.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 153.53 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 149.58 examples/s]

 84%|████████▍ | 84/100 [55:36<16:49, 63.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 140.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 136.63 examples/s]

 85%|████████▌ | 85/100 [56:45<16:10, 64.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 143.88 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 139.96 examples/s]

 86%|████████▌ | 86/100 [57:52<15:18, 65.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 142.05 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 138.12 examples/s]

 87%|████████▋ | 87/100 [58:58<14:15, 65.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 144.49 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 142.08 examples/s]

 88%|████████▊ | 88/100 [1:00:05<13:13, 66.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 134.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 131.88 examples/s]

 89%|████████▉ | 89/100 [1:01:13<12:13, 66.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 136.13 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 132.20 examples/s]

 90%|█████████ | 90/100 [1:02:22<11:13, 67.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 138.73 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 136.50 examples/s]

 91%|█████████ | 91/100 [1:03:29<10:05, 67.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 137.61 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 133.88 examples/s]

 92%|█████████▏| 92/100 [1:04:36<08:56, 67.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 133.48 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 129.74 examples/s]

 93%|█████████▎| 93/100 [1:05:48<07:59, 68.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 130.79 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 128.57 examples/s]

 94%|█████████▍| 94/100 [1:06:59<06:55, 69.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 137.35 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 135.37 examples/s]

 95%|█████████▌| 95/100 [1:08:14<05:55, 71.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 134.74 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 131.74 examples/s]

 96%|█████████▌| 96/100 [1:09:30<04:49, 72.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 128.45 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 126.61 examples/s]

 97%|█████████▋| 97/100 [1:10:44<03:39, 73.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 111.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 109.10 examples/s]

 98%|█████████▊| 98/100 [1:11:58<02:26, 73.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 130.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 127.58 examples/s]

 99%|█████████▉| 99/100 [1:13:24<01:17, 77.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 118.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 115.50 examples/s]

100%|██████████| 100/100 [1:14:38<00:00, 76.05s/it]
100%|██████████| 100/100 [1:14:38<00:00, 44.78s/it]
ERROR: Cannot find key: sampler.run_id=1
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         run_generate | run_eval | GPT4Agent |
                         AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
