[2024-01-08 23:21:21,360][root][INFO] - Parameters:
- Run ID: 2
- N Revisions: 50
- Batch Size: 1
- Num Return Sequences: 12
- N Eval Examples: 10
- N Generation Examples: 1
- Generation Prompt: generation_prompt_base_2
- Evaluation Prompt: evaluation_prompt_base_2

Storing as: ./constitutions/rlhf_reversed_gen_mixtral_7b_base_eval_mixtral_7b_base_run_2
[2024-01-08 23:21:21,360][root][INFO] - Using one GPU
INFO 01-08 23:21:25 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mixtral-8x7B-v0.1', tokenizer='mistralai/Mixtral-8x7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-08 23:21:47 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-08 23:21:49 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-08 23:21:49 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=928678)[0m INFO 01-08 23:21:49 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=928678)[0m INFO 01-08 23:21:49 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-08 23:22:23 model_runner.py:547] Graph capturing finished in 35 secs.
[2024-01-08 23:22:23,866][root][INFO] - Model Generate is mixtral_7b_base
[2024-01-08 23:22:23,866][root][INFO] - Model Eval is mixtral_7b_base
[36m(RayWorkerVllm pid=928678)[0m INFO 01-08 23:22:23 model_runner.py:547] Graph capturing finished in 35 secs.
[2024-01-08 23:22:26,143][root][INFO] - Dataset is Anthropic/hh-rlhf. Version: rlhf_reversed, Chosen: rejected, Rejected: chosen
[2024-01-08 23:22:26,143][root][INFO] - Seed is 2
[2024-01-08 23:22:26,193][root][INFO] - Training Example(s): tensor([[36653]], dtype=torch.int32)
[2024-01-08 23:22:26,194][root][INFO] - Random previous Example(s) used for Evaluation: [array([36653], dtype=int32)]
[2024-01-08 23:22:45,945][root][ERROR] - Error in format_response_base: list index out of range
[2024-01-08 23:22:45,946][root][INFO] - Formatted Response Success Rate: 0.8333333333333334
[2024-01-08 23:22:52,787][root][INFO] - New Constitution 0: 1. The Assistant should prioritize the human's emotional state when generating responses.

2. The Assistant should demonstrate empathy and understanding of the human's emotional state.

3. The Assistant should respect the human's autonomy and independence.

4. The Assistant should avoid providing practical instructions that may not align with the human's emotional needs.

5. The Assistant should provide responses that are tailored to the specific context of the conversation.

6. The Assistant should avoid suggesting actions that may be
[2024-01-08 23:22:52,788][root][INFO] - Writing to disk.
[2024-01-08 23:22:52,805][root][INFO] - Training Example(s): tensor([[37286]], dtype=torch.int32)
[2024-01-08 23:22:52,806][root][INFO] - Random previous Example(s) used for Evaluation: [array([37286, 36653], dtype=int32)]
[2024-01-08 23:23:13,137][root][ERROR] - Error in format_response_base: list index out of range
[2024-01-08 23:23:13,138][root][ERROR] - Error in format_response_base: list index out of range
[2024-01-08 23:23:13,138][root][INFO] - Formatted Response Success Rate: 0.8333333333333334
[2024-01-08 23:23:24,863][root][INFO] - New Constitution 0: 1. The Assistant should prioritize the human's emotional state when generating responses.

2. The Assistant should demonstrate empathy and understanding of the human's emotional state, while still providing practical solutions when appropriate.

3. The Assistant should respect the human's autonomy and independence.

4. The Assistant should avoid providing practical instructions that may not align with the human's emotional needs, unless they are specifically requested or deemed necessary.

5. The Assistant should provide responses that are tailored to the
[2024-01-08 23:23:24,863][root][INFO] - Writing to disk.
[2024-01-08 23:23:24,873][root][INFO] - Training Example(s): tensor([[13656]], dtype=torch.int32)
[2024-01-08 23:23:24,874][root][INFO] - Random previous Example(s) used for Evaluation: [array([37286, 36653, 13656], dtype=int32)]
