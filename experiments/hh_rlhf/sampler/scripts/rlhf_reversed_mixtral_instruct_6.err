Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:20,  1.15s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:17,  1.05s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:16,  1.02s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:04<00:15,  1.00s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:05<00:13,  1.00it/s]Loading checkpoint shards:  32%|███▏      | 6/19 [00:06<00:12,  1.01it/s]Loading checkpoint shards:  37%|███▋      | 7/19 [00:07<00:11,  1.01it/s]Loading checkpoint shards:  42%|████▏     | 8/19 [00:08<00:10,  1.01it/s]Loading checkpoint shards:  47%|████▋     | 9/19 [00:09<00:09,  1.01it/s]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:10<00:08,  1.01it/s]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:10<00:07,  1.01it/s]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:11<00:06,  1.01it/s]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:12<00:05,  1.01it/s]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:13<00:04,  1.02it/s]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:14<00:03,  1.02it/s]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:15<00:02,  1.00it/s]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:16<00:01,  1.00it/s]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:17<00:00,  1.00it/s]Loading checkpoint shards: 100%|██████████| 19/19 [00:18<00:00,  1.05it/s]Loading checkpoint shards: 100%|██████████| 19/19 [00:18<00:00,  1.01it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.22 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.14 examples/s]
  1%|          | 1/100 [02:17<3:46:22, 137.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.01 examples/s]
  2%|▏         | 2/100 [04:29<3:39:49, 134.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.47 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.96 examples/s]
  3%|▎         | 3/100 [06:25<3:23:14, 125.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.99 examples/s]
  4%|▍         | 4/100 [08:38<3:25:54, 128.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.78 examples/s]
  5%|▌         | 5/100 [10:40<3:19:47, 126.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.23 examples/s]
  6%|▌         | 6/100 [13:01<3:25:39, 131.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.52 examples/s]
  7%|▋         | 7/100 [15:10<3:22:34, 130.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 269.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.58 examples/s]
  8%|▊         | 8/100 [17:13<3:16:40, 128.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 272.89 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.76 examples/s]
  9%|▉         | 9/100 [19:26<3:16:50, 129.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 262.87 examples/s]
 10%|█         | 10/100 [21:33<3:13:10, 128.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 280.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 271.39 examples/s]
 11%|█         | 11/100 [23:42<3:11:17, 128.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.99 examples/s]
 12%|█▏        | 12/100 [25:37<3:02:40, 124.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 255.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.27 examples/s]
 13%|█▎        | 13/100 [27:28<2:54:48, 120.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.71 examples/s]
 14%|█▍        | 14/100 [29:46<3:00:20, 125.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.29 examples/s]
 15%|█▌        | 15/100 [31:56<3:00:06, 127.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.09 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.81 examples/s]
 16%|█▌        | 16/100 [34:13<3:01:54, 129.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.57 examples/s]
 17%|█▋        | 17/100 [36:19<2:58:24, 128.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.00 examples/s]
 18%|█▊        | 18/100 [38:28<2:55:59, 128.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 278.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 269.73 examples/s]
 19%|█▉        | 19/100 [40:19<2:46:44, 123.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.25 examples/s]
 20%|██        | 20/100 [42:36<2:50:07, 127.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.47 examples/s]
 21%|██        | 21/100 [44:44<2:48:10, 127.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 274.68 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.41 examples/s]
 22%|██▏       | 22/100 [46:48<2:44:30, 126.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.23 examples/s]
 23%|██▎       | 23/100 [48:17<2:27:58, 115.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 289.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 280.22 examples/s]
 24%|██▍       | 24/100 [50:06<2:23:39, 113.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.42 examples/s]
 25%|██▌       | 25/100 [52:03<2:22:57, 114.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.16 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.38 examples/s]
 26%|██▌       | 26/100 [54:00<2:22:03, 115.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.82 examples/s]
 27%|██▋       | 27/100 [56:11<2:26:03, 120.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.25 examples/s]
 28%|██▊       | 28/100 [58:26<2:29:16, 124.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 162.81 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.87 examples/s]
 29%|██▉       | 29/100 [1:00:47<2:33:11, 129.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 268.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.13 examples/s]
 30%|███       | 30/100 [1:03:02<2:32:49, 130.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.27 examples/s]
 31%|███       | 31/100 [1:05:20<2:33:10, 133.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.41 examples/s]
 32%|███▏      | 32/100 [1:07:03<2:20:35, 124.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.67 examples/s]
 33%|███▎      | 33/100 [1:08:47<2:11:59, 118.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.53 examples/s]
 34%|███▍      | 34/100 [1:11:13<2:19:17, 126.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.94 examples/s]
 35%|███▌      | 35/100 [1:13:35<2:22:06, 131.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.44 examples/s]
 36%|███▌      | 36/100 [1:15:41<2:18:03, 129.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.14 examples/s]
 37%|███▋      | 37/100 [1:17:28<2:08:58, 122.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.62 examples/s]
 38%|███▊      | 38/100 [1:19:56<2:14:43, 130.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.41 examples/s]
 39%|███▉      | 39/100 [1:22:22<2:17:12, 134.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.78 examples/s]
 40%|████      | 40/100 [1:24:14<2:08:14, 128.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.51 examples/s]
 41%|████      | 41/100 [1:26:31<2:08:36, 130.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.87 examples/s]
 42%|████▏     | 42/100 [1:28:52<2:09:17, 133.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.16 examples/s]
 43%|████▎     | 43/100 [1:31:16<2:10:08, 136.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.40 examples/s]
 44%|████▍     | 44/100 [1:33:31<2:07:08, 136.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.66 examples/s]
 45%|████▌     | 45/100 [1:35:50<2:05:42, 137.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.09 examples/s]
 46%|████▌     | 46/100 [1:37:48<1:58:15, 131.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.78 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.03 examples/s]
 47%|████▋     | 47/100 [1:40:06<1:57:54, 133.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.34 examples/s]
 48%|████▊     | 48/100 [1:42:14<1:54:07, 131.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.50 examples/s]
 49%|████▉     | 49/100 [1:44:37<1:54:45, 135.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.71 examples/s]
 50%|█████     | 50/100 [1:47:06<1:56:08, 139.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.52 examples/s]
 51%|█████     | 51/100 [1:48:39<1:42:28, 125.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.89 examples/s]
 52%|█████▏    | 52/100 [1:50:34<1:37:45, 122.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.83 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.57 examples/s]
 53%|█████▎    | 53/100 [1:52:40<1:36:40, 123.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.63 examples/s]
 54%|█████▍    | 54/100 [1:55:07<1:39:58, 130.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.86 examples/s]
 55%|█████▌    | 55/100 [1:57:31<1:40:55, 134.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.96 examples/s]
 56%|█████▌    | 56/100 [1:59:57<1:41:07, 137.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.05 examples/s]
 57%|█████▋    | 57/100 [2:02:13<1:38:33, 137.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.90 examples/s]
 58%|█████▊    | 58/100 [2:04:23<1:34:36, 135.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.62 examples/s]
 59%|█████▉    | 59/100 [2:06:36<1:31:56, 134.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.57 examples/s]
 60%|██████    | 60/100 [2:08:54<1:30:24, 135.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.31 examples/s]
 61%|██████    | 61/100 [2:11:17<1:29:28, 137.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.29 examples/s]
 62%|██████▏   | 62/100 [2:13:11<1:22:45, 130.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.43 examples/s]
 63%|██████▎   | 63/100 [2:15:17<1:19:48, 129.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.70 examples/s]
 64%|██████▍   | 64/100 [2:17:48<1:21:27, 135.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.06 examples/s]
 65%|██████▌   | 65/100 [2:19:37<1:14:30, 127.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.85 examples/s]
 66%|██████▌   | 66/100 [2:21:48<1:12:56, 128.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.41 examples/s]
 67%|██████▋   | 67/100 [2:24:25<1:15:31, 137.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.52 examples/s]
 68%|██████▊   | 68/100 [2:26:53<1:14:54, 140.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.61 examples/s]
 69%|██████▉   | 69/100 [2:29:06<1:11:21, 138.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.70 examples/s]
 70%|███████   | 70/100 [2:31:30<1:09:56, 139.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.43 examples/s]
 71%|███████   | 71/100 [2:33:19<1:03:09, 130.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.13 examples/s]
 72%|███████▏  | 72/100 [2:35:55<1:04:32, 138.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.31 examples/s]
 73%|███████▎  | 73/100 [2:38:23<1:03:30, 141.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.26 examples/s]
 74%|███████▍  | 74/100 [2:40:48<1:01:38, 142.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.07 examples/s]
 75%|███████▌  | 75/100 [2:43:24<1:00:57, 146.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 194.62 examples/s]
 76%|███████▌  | 76/100 [2:45:48<58:19, 145.81s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.32 examples/s]
 77%|███████▋  | 77/100 [2:48:00<54:18, 141.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.58 examples/s]
 78%|███████▊  | 78/100 [2:50:05<50:08, 136.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.80 examples/s]
 79%|███████▉  | 79/100 [2:52:44<50:11, 143.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.40 examples/s]
 80%|████████  | 80/100 [2:55:07<47:44, 143.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.51 examples/s]
 81%|████████  | 81/100 [2:57:17<44:05, 139.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.62 examples/s]
 82%|████████▏ | 82/100 [2:59:56<43:33, 145.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.12 examples/s]
 83%|████████▎ | 83/100 [3:02:31<41:56, 148.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 72.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 71.82 examples/s]
 84%|████████▍ | 84/100 [3:04:52<38:57, 146.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.08 examples/s]
 85%|████████▌ | 85/100 [3:07:26<37:03, 148.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.51 examples/s]
 86%|████████▌ | 86/100 [3:09:32<33:02, 141.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.61 examples/s]
 87%|████████▋ | 87/100 [3:12:04<31:24, 144.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.97 examples/s]
 88%|████████▊ | 88/100 [3:14:29<28:57, 144.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.66 examples/s]
 89%|████████▉ | 89/100 [3:16:55<26:35, 145.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.64 examples/s]
 90%|█████████ | 90/100 [3:19:14<23:53, 143.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.28 examples/s]
 91%|█████████ | 91/100 [3:21:56<22:19, 148.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.45 examples/s]
 92%|█████████▏| 92/100 [3:24:38<20:22, 152.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.34 examples/s]
 93%|█████████▎| 93/100 [3:27:11<17:51, 153.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.48 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.83 examples/s]
 94%|█████████▍| 94/100 [3:29:33<14:57, 149.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.46 examples/s]
 95%|█████████▌| 95/100 [3:31:39<11:53, 142.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.52 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.73 examples/s]
 96%|█████████▌| 96/100 [3:33:45<09:10, 137.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.46 examples/s]
 97%|█████████▋| 97/100 [3:36:22<07:10, 143.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.90 examples/s]
 98%|█████████▊| 98/100 [3:39:00<04:55, 147.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.71 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.67 examples/s]
 99%|█████████▉| 99/100 [3:41:44<02:32, 152.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 168.43 examples/s]
100%|██████████| 100/100 [3:44:27<00:00, 155.92s/it]100%|██████████| 100/100 [3:44:27<00:00, 134.68s/it]
ERROR: Cannot find key: sampler.run_id=6
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         is_valid_response | extract_new_principle |
                         extract_revised_principle | process_responses |
                         filter_responses | run_generate | run_eval |
                         GPT4Agent | AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
