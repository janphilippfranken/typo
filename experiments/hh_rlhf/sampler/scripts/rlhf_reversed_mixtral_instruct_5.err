
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]
Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:19,  1.10s/it]
Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:17,  1.03s/it]
Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:16,  1.02s/it]
Loading checkpoint shards:  21%|██        | 4/19 [00:04<00:15,  1.00s/it]
Loading checkpoint shards:  26%|██▋       | 5/19 [00:05<00:13,  1.01it/s]
Loading checkpoint shards:  32%|███▏      | 6/19 [00:06<00:12,  1.01it/s]
Loading checkpoint shards:  37%|███▋      | 7/19 [00:06<00:11,  1.02it/s]
Loading checkpoint shards:  42%|████▏     | 8/19 [00:07<00:10,  1.02it/s]
Loading checkpoint shards:  47%|████▋     | 9/19 [00:08<00:09,  1.02it/s]
Loading checkpoint shards:  53%|█████▎    | 10/19 [00:09<00:08,  1.03it/s]
Loading checkpoint shards:  58%|█████▊    | 11/19 [00:10<00:07,  1.02it/s]
Loading checkpoint shards:  63%|██████▎   | 12/19 [00:11<00:06,  1.01it/s]
Loading checkpoint shards:  68%|██████▊   | 13/19 [00:12<00:05,  1.01it/s]
Loading checkpoint shards:  74%|███████▎  | 14/19 [00:13<00:04,  1.02it/s]
Loading checkpoint shards:  79%|███████▉  | 15/19 [00:14<00:03,  1.02it/s]
Loading checkpoint shards:  84%|████████▍ | 16/19 [00:15<00:02,  1.02it/s]
Loading checkpoint shards:  89%|████████▉ | 17/19 [00:16<00:01,  1.03it/s]
Loading checkpoint shards:  95%|█████████▍| 18/19 [00:17<00:00,  1.02it/s]
Loading checkpoint shards: 100%|██████████| 19/19 [00:18<00:00,  1.06it/s]
Loading checkpoint shards: 100%|██████████| 19/19 [00:18<00:00,  1.02it/s]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.80 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.90 examples/s]

  1%|          | 1/100 [01:51<3:03:33, 111.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.63 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.85 examples/s]

  2%|▏         | 2/100 [03:11<2:32:04, 93.10s/it] The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 264.47 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.93 examples/s]

  3%|▎         | 3/100 [04:55<2:38:26, 98.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.87 examples/s]

  4%|▍         | 4/100 [07:04<2:56:17, 110.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 255.97 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.54 examples/s]

  5%|▌         | 5/100 [08:54<2:54:25, 110.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.00 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.56 examples/s]

  6%|▌         | 6/100 [10:57<2:59:18, 114.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.65 examples/s]

  7%|▋         | 7/100 [12:59<3:01:17, 116.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.16 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.31 examples/s]

  8%|▊         | 8/100 [15:02<3:02:14, 118.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 267.24 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.42 examples/s]

  9%|▉         | 9/100 [16:43<2:51:44, 113.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.82 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.50 examples/s]

 10%|█         | 10/100 [18:53<2:57:57, 118.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 265.43 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.49 examples/s]

 11%|█         | 11/100 [20:28<2:45:05, 111.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.58 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.38 examples/s]

 12%|█▏        | 12/100 [22:35<2:50:13, 116.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.45 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.02 examples/s]

 13%|█▎        | 13/100 [24:42<2:53:09, 119.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.01 examples/s]

 14%|█▍        | 14/100 [26:55<2:57:01, 123.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.30 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.56 examples/s]

 15%|█▌        | 15/100 [28:47<2:49:51, 119.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.08 examples/s]

 16%|█▌        | 16/100 [30:51<2:49:44, 121.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.91 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.84 examples/s]

 17%|█▋        | 17/100 [32:52<2:47:45, 121.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 274.28 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 265.83 examples/s]

 18%|█▊        | 18/100 [35:04<2:49:54, 124.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 258.06 examples/s]

 19%|█▉        | 19/100 [37:23<2:54:00, 128.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 76.99 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 75.59 examples/s]

 20%|██        | 20/100 [39:18<2:46:03, 124.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 258.54 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.97 examples/s]

 21%|██        | 21/100 [41:26<2:45:25, 125.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 265.48 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.87 examples/s]

 22%|██▏       | 22/100 [43:34<2:44:18, 126.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.95 examples/s]

 23%|██▎       | 23/100 [45:42<2:42:49, 126.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 304.66 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 294.42 examples/s]

 24%|██▍       | 24/100 [47:26<2:32:01, 120.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.26 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.22 examples/s]

 25%|██▌       | 25/100 [49:42<2:36:09, 124.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.26 examples/s]

 26%|██▌       | 26/100 [51:42<2:32:06, 123.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.50 examples/s]

 27%|██▋       | 27/100 [53:23<2:21:47, 116.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.52 examples/s]

 28%|██▊       | 28/100 [55:45<2:28:59, 124.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.56 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 168.11 examples/s]

 29%|██▉       | 29/100 [58:08<2:33:41, 129.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.23 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.03 examples/s]

 30%|███       | 30/100 [1:00:24<2:33:37, 131.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.77 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.25 examples/s]

 31%|███       | 31/100 [1:02:40<2:33:01, 133.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.07 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.77 examples/s]

 32%|███▏      | 32/100 [1:04:27<2:21:46, 125.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.03 examples/s]

 33%|███▎      | 33/100 [1:06:51<2:26:15, 130.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.68 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.29 examples/s]

 34%|███▍      | 34/100 [1:08:47<2:18:57, 126.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.69 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.17 examples/s]

 35%|███▌      | 35/100 [1:10:41<2:12:45, 122.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.94 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.27 examples/s]

 36%|███▌      | 36/100 [1:12:39<2:09:32, 121.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.52 examples/s]

 37%|███▋      | 37/100 [1:15:16<2:18:42, 132.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.44 examples/s]

 38%|███▊      | 38/100 [1:17:54<2:24:29, 139.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.44 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.74 examples/s]

 39%|███▉      | 39/100 [1:19:57<2:16:51, 134.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.15 examples/s]

 40%|████      | 40/100 [1:22:21<2:17:37, 137.63s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.83 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.55 examples/s]

 41%|████      | 41/100 [1:24:47<2:17:39, 139.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.66 examples/s]

 42%|████▏     | 42/100 [1:27:14<2:17:28, 142.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.72 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.19 examples/s]

 43%|████▎     | 43/100 [1:29:03<2:05:31, 132.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.28 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.92 examples/s]

 44%|████▍     | 44/100 [1:31:31<2:07:40, 136.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.54 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.50 examples/s]

 45%|████▌     | 45/100 [1:33:27<1:59:47, 130.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.02 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.39 examples/s]

 46%|████▌     | 46/100 [1:35:44<1:59:26, 132.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.62 examples/s]

 47%|████▋     | 47/100 [1:38:13<2:01:22, 137.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.70 examples/s]

 48%|████▊     | 48/100 [1:40:46<2:03:13, 142.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.50 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.65 examples/s]

 49%|████▉     | 49/100 [1:43:08<2:00:54, 142.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.74 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.05 examples/s]

 50%|█████     | 50/100 [1:45:36<1:59:49, 143.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.83 examples/s]

 51%|█████     | 51/100 [1:48:14<2:01:03, 148.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.26 examples/s]

 52%|█████▏    | 52/100 [1:50:19<1:52:49, 141.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.70 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.10 examples/s]

 53%|█████▎    | 53/100 [1:52:33<1:48:58, 139.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 202.60 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.28 examples/s]

 54%|█████▍    | 54/100 [1:54:38<1:43:18, 134.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.34 examples/s]

 55%|█████▌    | 55/100 [1:57:11<1:45:11, 140.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.51 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.81 examples/s]

 56%|█████▌    | 56/100 [1:59:20<1:40:26, 136.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.00 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.87 examples/s]

 57%|█████▋    | 57/100 [2:01:58<1:42:41, 143.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.54 examples/s]

 58%|█████▊    | 58/100 [2:04:09<1:37:42, 139.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.80 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.24 examples/s]

 59%|█████▉    | 59/100 [2:06:42<1:38:03, 143.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.62 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.30 examples/s]

 60%|██████    | 60/100 [2:08:52<1:32:56, 139.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.36 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.99 examples/s]

 61%|██████    | 61/100 [2:11:18<1:31:52, 141.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.44 examples/s]

 62%|██████▏   | 62/100 [2:13:10<1:24:01, 132.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.79 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.23 examples/s]

 63%|██████▎   | 63/100 [2:15:12<1:19:46, 129.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.02 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.70 examples/s]

 64%|██████▍   | 64/100 [2:17:11<1:15:52, 126.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.96 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.52 examples/s]

 65%|██████▌   | 65/100 [2:19:23<1:14:35, 127.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.44 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.26 examples/s]

 66%|██████▌   | 66/100 [2:21:58<1:17:12, 136.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.89 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.51 examples/s]

 67%|██████▋   | 67/100 [2:24:07<1:13:39, 133.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.28 examples/s]

 68%|██████▊   | 68/100 [2:26:48<1:15:47, 142.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.21 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.35 examples/s]

 69%|██████▉   | 69/100 [2:28:55<1:11:03, 137.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.95 examples/s]

 70%|███████   | 70/100 [2:31:18<1:09:33, 139.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.66 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.85 examples/s]

 71%|███████   | 71/100 [2:33:34<1:06:48, 138.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.83 examples/s]

 72%|███████▏  | 72/100 [2:36:10<1:07:00, 143.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.58 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.97 examples/s]

 73%|███████▎  | 73/100 [2:38:12<1:01:46, 137.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.22 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.15 examples/s]

 74%|███████▍  | 74/100 [2:40:26<59:02, 136.25s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.79 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.54 examples/s]

 75%|███████▌  | 75/100 [2:42:55<58:16, 139.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.19 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.81 examples/s]

 76%|███████▌  | 76/100 [2:45:30<57:49, 144.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.86 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.93 examples/s]

 77%|███████▋  | 77/100 [2:48:04<56:27, 147.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.06 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.73 examples/s]

 78%|███████▊  | 78/100 [2:50:23<53:03, 144.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.21 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.34 examples/s]

 79%|███████▉  | 79/100 [2:52:46<50:30, 144.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.74 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.12 examples/s]

 80%|████████  | 80/100 [2:55:06<47:39, 142.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.91 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.41 examples/s]

 81%|████████  | 81/100 [2:57:38<46:10, 145.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.64 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.40 examples/s]

 82%|████████▏ | 82/100 [2:59:35<41:08, 137.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.26 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.35 examples/s]

 83%|████████▎ | 83/100 [3:02:07<40:04, 141.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.95 examples/s]
 84%|████████▍ | 84/100 [3:04:07<36:03, 135.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.81 examples/s]
 85%|████████▌ | 85/100 [3:06:53<36:06, 144.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.58 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.94 examples/s]
 86%|████████▌ | 86/100 [3:09:25<34:14, 146.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.76 examples/s]
 87%|████████▋ | 87/100 [3:12:03<32:31, 150.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.25 examples/s]
 88%|████████▊ | 88/100 [3:14:20<29:11, 145.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.88 examples/s]
 89%|████████▉ | 89/100 [3:16:49<26:57, 147.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.05 examples/s]
 90%|█████████ | 90/100 [3:19:29<25:09, 150.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.89 examples/s]
 91%|█████████ | 91/100 [3:21:48<22:06, 147.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.80 examples/s]
 92%|█████████▏| 92/100 [3:24:31<20:14, 151.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.99 examples/s]
 93%|█████████▎| 93/100 [3:27:15<18:09, 155.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.08 examples/s]
 94%|█████████▍| 94/100 [3:29:59<15:48, 158.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.30 examples/s]
 95%|█████████▌| 95/100 [3:32:42<13:17, 159.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.00 examples/s]
 96%|█████████▌| 96/100 [3:35:27<10:44, 161.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 154.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.40 examples/s]
 97%|█████████▋| 97/100 [3:38:02<07:57, 159.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 172.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.86 examples/s]
 98%|█████████▊| 98/100 [3:40:17<05:04, 152.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.89 examples/s]
 99%|█████████▉| 99/100 [3:43:14<02:39, 159.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 172.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.00 examples/s]
100%|██████████| 100/100 [3:45:23<00:00, 150.29s/it]100%|██████████| 100/100 [3:45:23<00:00, 135.23s/it]
ERROR: Cannot find key: sampler.run_id=5
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         is_valid_response | extract_new_principle |
                         extract_revised_principle | process_responses |
                         filter_responses | run_generate | run_eval |
                         GPT4Agent | AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
