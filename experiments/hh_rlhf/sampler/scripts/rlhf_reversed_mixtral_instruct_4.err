
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]
Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:21,  1.20s/it]
Loading checkpoint shards:  11%|█         | 2/19 [00:02<00:19,  1.12s/it]
Loading checkpoint shards:  16%|█▌        | 3/19 [00:03<00:17,  1.09s/it]
Loading checkpoint shards:  21%|██        | 4/19 [00:04<00:16,  1.07s/it]
Loading checkpoint shards:  26%|██▋       | 5/19 [00:05<00:15,  1.07s/it]
Loading checkpoint shards:  32%|███▏      | 6/19 [00:06<00:13,  1.07s/it]
Loading checkpoint shards:  37%|███▋      | 7/19 [00:07<00:12,  1.07s/it]
Loading checkpoint shards:  42%|████▏     | 8/19 [00:08<00:11,  1.07s/it]
Loading checkpoint shards:  47%|████▋     | 9/19 [00:09<00:10,  1.07s/it]
Loading checkpoint shards:  53%|█████▎    | 10/19 [00:10<00:09,  1.06s/it]
Loading checkpoint shards:  58%|█████▊    | 11/19 [00:11<00:08,  1.07s/it]
Loading checkpoint shards:  63%|██████▎   | 12/19 [00:12<00:07,  1.07s/it]
Loading checkpoint shards:  68%|██████▊   | 13/19 [00:13<00:06,  1.07s/it]
Loading checkpoint shards:  74%|███████▎  | 14/19 [00:15<00:05,  1.06s/it]
Loading checkpoint shards:  79%|███████▉  | 15/19 [00:16<00:04,  1.06s/it]
Loading checkpoint shards:  84%|████████▍ | 16/19 [00:17<00:03,  1.05s/it]
Loading checkpoint shards:  89%|████████▉ | 17/19 [00:18<00:02,  1.05s/it]
Loading checkpoint shards:  95%|█████████▍| 18/19 [00:19<00:01,  1.05s/it]
Loading checkpoint shards: 100%|██████████| 19/19 [00:20<00:00,  1.01s/it]
Loading checkpoint shards: 100%|██████████| 19/19 [00:20<00:00,  1.06s/it]

Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]

  0%|          | 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.60 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.42 examples/s]

  1%|          | 1/100 [01:36<2:39:01, 96.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.39 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.28 examples/s]

  2%|▏         | 2/100 [02:52<2:18:24, 84.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.08 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.52 examples/s]

  3%|▎         | 3/100 [04:15<2:15:37, 83.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.00 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.08 examples/s]

  4%|▍         | 4/100 [06:20<2:39:59, 99.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.81 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.11 examples/s]

  5%|▌         | 5/100 [08:11<2:44:21, 103.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.04 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.79 examples/s]

  6%|▌         | 6/100 [09:49<2:39:59, 102.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.29 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.25 examples/s]

  7%|▋         | 7/100 [12:00<2:52:27, 111.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.18 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.73 examples/s]

  8%|▊         | 8/100 [13:40<2:45:21, 107.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.98 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.73 examples/s]

  9%|▉         | 9/100 [15:39<2:48:44, 111.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.62 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.02 examples/s]

 10%|█         | 10/100 [17:50<2:55:59, 117.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 252.87 examples/s]

 11%|█         | 11/100 [20:01<3:00:13, 121.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.79 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.90 examples/s]

 12%|█▏        | 12/100 [21:57<2:55:58, 119.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.23 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.47 examples/s]

 13%|█▎        | 13/100 [23:39<2:46:07, 114.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.02 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.35 examples/s]

 14%|█▍        | 14/100 [25:40<2:46:42, 116.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.97 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.09 examples/s]

 15%|█▌        | 15/100 [27:36<2:44:59, 116.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.26 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.58 examples/s]

 16%|█▌        | 16/100 [29:59<2:54:11, 124.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 260.35 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.14 examples/s]

 17%|█▋        | 17/100 [32:06<2:53:12, 125.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.57 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.73 examples/s]

 18%|█▊        | 18/100 [34:00<2:46:15, 121.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 259.16 examples/s]

 19%|█▉        | 19/100 [36:00<2:43:37, 121.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.27 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.71 examples/s]

 20%|██        | 20/100 [37:42<2:33:45, 115.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.74 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.09 examples/s]

 21%|██        | 21/100 [39:25<2:27:02, 111.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.73 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.07 examples/s]

 22%|██▏       | 22/100 [41:37<2:33:11, 117.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.71 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.22 examples/s]

 23%|██▎       | 23/100 [43:37<2:31:53, 118.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 273.30 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 265.21 examples/s]

 24%|██▍       | 24/100 [45:24<2:25:56, 115.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.35 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.81 examples/s]

 25%|██▌       | 25/100 [47:47<2:34:20, 123.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.43 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.35 examples/s]

 26%|██▌       | 26/100 [49:41<2:28:52, 120.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.78 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.93 examples/s]

 27%|██▋       | 27/100 [51:53<2:30:49, 123.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.63 examples/s]

 28%|██▊       | 28/100 [54:14<2:34:52, 129.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.17 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.50 examples/s]

 29%|██▉       | 29/100 [56:40<2:38:35, 134.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.54 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.51 examples/s]

 30%|███       | 30/100 [58:53<2:36:04, 133.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.12 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.98 examples/s]

 31%|███       | 31/100 [1:01:06<2:33:45, 133.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.25 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 258.14 examples/s]

 32%|███▏      | 32/100 [1:03:06<2:26:53, 129.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.13 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.71 examples/s]

 33%|███▎      | 33/100 [1:05:13<2:23:51, 128.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 274.75 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 266.83 examples/s]

 34%|███▍      | 34/100 [1:07:22<2:21:39, 128.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 277.82 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 269.78 examples/s]

 35%|███▌      | 35/100 [1:09:16<2:14:38, 124.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.53 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.27 examples/s]

 36%|███▌      | 36/100 [1:11:19<2:12:05, 123.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.79 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 243.87 examples/s]

 37%|███▋      | 37/100 [1:13:49<2:18:21, 131.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.02 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.03 examples/s]

 38%|███▊      | 38/100 [1:16:23<2:23:00, 138.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.54 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.40 examples/s]

 39%|███▉      | 39/100 [1:18:00<2:08:18, 126.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.01 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.34 examples/s]

 40%|████      | 40/100 [1:20:03<2:05:00, 125.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.84 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 239.40 examples/s]

 41%|████      | 41/100 [1:22:04<2:01:45, 123.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.41 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.17 examples/s]

 42%|████▏     | 42/100 [1:24:24<2:04:23, 128.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.34 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.86 examples/s]

 43%|████▎     | 43/100 [1:26:11<1:56:03, 122.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.07 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.40 examples/s]

 44%|████▍     | 44/100 [1:28:38<2:01:06, 129.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 284.09 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 275.02 examples/s]

 45%|████▌     | 45/100 [1:30:55<2:00:56, 131.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.33 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.79 examples/s]

 46%|████▌     | 46/100 [1:33:00<1:56:49, 129.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 269.66 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 257.24 examples/s]

 47%|████▋     | 47/100 [1:35:11<1:55:02, 130.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.60 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.89 examples/s]

 48%|████▊     | 48/100 [1:37:36<1:56:31, 134.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.98 examples/s]

 49%|████▉     | 49/100 [1:39:41<1:51:52, 131.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.37 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.86 examples/s]

 50%|█████     | 50/100 [1:42:01<1:51:51, 134.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 247.10 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.54 examples/s]

 51%|█████     | 51/100 [1:44:35<1:54:23, 140.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.50 examples/s]

 52%|█████▏    | 52/100 [1:46:39<1:48:16, 135.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.91 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.03 examples/s]

 53%|█████▎    | 53/100 [1:48:33<1:41:05, 129.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.70 examples/s]

 54%|█████▍    | 54/100 [1:50:25<1:34:59, 123.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.48 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.41 examples/s]

 55%|█████▌    | 55/100 [1:52:59<1:39:44, 132.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.76 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.10 examples/s]

 56%|█████▌    | 56/100 [1:55:14<1:37:55, 133.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.54 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.37 examples/s]

 57%|█████▋    | 57/100 [1:57:42<1:38:40, 137.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.69 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.18 examples/s]

 58%|█████▊    | 58/100 [1:59:42<1:32:47, 132.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.77 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.09 examples/s]

 59%|█████▉    | 59/100 [2:01:23<1:24:09, 123.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.67 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.89 examples/s]

 60%|██████    | 60/100 [2:03:43<1:25:19, 127.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.64 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.02 examples/s]

 61%|██████    | 61/100 [2:05:21<1:17:24, 119.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.83 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.70 examples/s]

 62%|██████▏   | 62/100 [2:07:10<1:13:34, 116.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.91 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.54 examples/s]

 63%|██████▎   | 63/100 [2:09:04<1:11:08, 115.36s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 261.00 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.02 examples/s]

 64%|██████▍   | 64/100 [2:10:50<1:07:29, 112.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 256.27 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 249.23 examples/s]

 65%|██████▌   | 65/100 [2:12:59<1:08:31, 117.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 244.74 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 238.35 examples/s]

 66%|██████▌   | 66/100 [2:15:25<1:11:24, 126.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.81 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.95 examples/s]

 67%|██████▋   | 67/100 [2:17:11<1:06:01, 120.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.83 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.27 examples/s]

 68%|██████▊   | 68/100 [2:19:40<1:08:45, 128.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.46 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.44 examples/s]

 69%|██████▉   | 69/100 [2:21:41<1:05:22, 126.54s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.11 examples/s]

 70%|███████   | 70/100 [2:23:39<1:01:55, 123.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.21 examples/s]

 71%|███████   | 71/100 [2:25:36<58:53, 121.85s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.42 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.08 examples/s]

 72%|███████▏  | 72/100 [2:28:09<1:01:10, 131.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.30 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.19 examples/s]

 73%|███████▎  | 73/100 [2:30:01<56:31, 125.60s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.61 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.77 examples/s]

 74%|███████▍  | 74/100 [2:32:02<53:47, 124.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.65 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.86 examples/s]

 75%|███████▌  | 75/100 [2:34:18<53:13, 127.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.82 examples/s]

 76%|███████▌  | 76/100 [2:36:34<52:03, 130.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.32 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.75 examples/s]

 77%|███████▋  | 77/100 [2:38:53<50:51, 132.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.87 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.95 examples/s]

 78%|███████▊  | 78/100 [2:41:20<50:18, 137.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.34 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.39 examples/s]

 79%|███████▉  | 79/100 [2:43:41<48:24, 138.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.78 examples/s]

 80%|████████  | 80/100 [2:46:06<46:41, 140.09s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.05 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.59 examples/s]

 81%|████████  | 81/100 [2:48:24<44:10, 139.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.61 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.12 examples/s]

 82%|████████▏ | 82/100 [2:50:18<39:36, 132.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.84 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.03 examples/s]

 83%|████████▎ | 83/100 [2:52:07<35:25, 125.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.23 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.22 examples/s]

 84%|████████▍ | 84/100 [2:53:45<31:11, 116.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.94 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.28 examples/s]

 85%|████████▌ | 85/100 [2:56:15<31:40, 126.70s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.10 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.67 examples/s]

 86%|████████▌ | 86/100 [2:58:49<31:30, 135.02s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.03 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.12 examples/s]

 87%|████████▋ | 87/100 [3:01:19<30:12, 139.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.34 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.21 examples/s]

 88%|████████▊ | 88/100 [3:02:50<25:00, 125.00s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.08 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.27 examples/s]

 89%|████████▉ | 89/100 [3:05:00<23:10, 126.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.31 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.75 examples/s]

 90%|█████████ | 90/100 [3:07:26<22:04, 132.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.22 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.79 examples/s]

 91%|█████████ | 91/100 [3:09:25<19:15, 128.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.72 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.06 examples/s]

 92%|█████████▏| 92/100 [3:11:57<18:02, 135.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.85 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.27 examples/s]

 93%|█████████▎| 93/100 [3:14:23<16:11, 138.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.05 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.51 examples/s]

 94%|█████████▍| 94/100 [3:17:01<14:25, 144.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.28 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.94 examples/s]

 95%|█████████▌| 95/100 [3:19:40<12:23, 148.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.59 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.99 examples/s]

 96%|█████████▌| 96/100 [3:22:11<09:58, 149.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.59 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.07 examples/s]

 97%|█████████▋| 97/100 [3:24:38<07:26, 148.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.84 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 199.27 examples/s]

 98%|█████████▊| 98/100 [3:26:48<04:46, 143.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.89 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.97 examples/s]

 99%|█████████▉| 99/100 [3:29:46<02:33, 153.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.


Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A

Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.66 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.44 examples/s]

100%|██████████| 100/100 [3:31:49<00:00, 144.31s/it]
100%|██████████| 100/100 [3:31:49<00:00, 127.09s/it]
ERROR: Cannot find key: sampler.run_id=4
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         is_valid_response | extract_new_principle |
                         extract_revised_principle | process_responses |
                         filter_responses | run_generate | run_eval |
                         GPT4Agent | AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
