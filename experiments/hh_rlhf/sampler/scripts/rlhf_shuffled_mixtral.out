[2024-01-09 16:08:12,105][root][INFO] - Parameters:
- Run ID: 1
- N Revisions: 50
- Batch Size: 1
- Num Return Sequences: 12
- N Eval Examples: 10
- N Generation Examples: 1
- Generation Prompt: generation_prompt_base_2
- Evaluation Prompt: evaluation_prompt_base_2
Storing as: ./constitutions/rlhf_shuffled_gen_mixtral_7b_base_eval_mixtral_7b_base_run_1
[2024-01-09 16:08:12,105][root][INFO] - Using one GPU
INFO 01-09 16:08:16 llm_engine.py:70] Initializing an LLM engine with config: model='mistralai/Mixtral-8x7B-v0.1', tokenizer='mistralai/Mixtral-8x7B-v0.1', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=32768, download_dir='/scr/jphilipp/scai/pretrained_models/Mixtral-8x7B-v0.1', load_format=auto, tensor_parallel_size=2, quantization=None, enforce_eager=False, seed=0)
INFO 01-09 16:08:36 llm_engine.py:275] # GPU blocks: 21894, # CPU blocks: 4096
INFO 01-09 16:08:38 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
INFO 01-09 16:08:38 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
[36m(RayWorkerVllm pid=2107420)[0m INFO 01-09 16:08:38 model_runner.py:501] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.
[36m(RayWorkerVllm pid=2107420)[0m INFO 01-09 16:08:38 model_runner.py:505] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode.
INFO 01-09 16:09:12 model_runner.py:547] Graph capturing finished in 34 secs.
[2024-01-09 16:09:12,899][root][INFO] - Model Generate is mixtral_7b_base
[2024-01-09 16:09:12,899][root][INFO] - Model Eval is mixtral_7b_base
[36m(RayWorkerVllm pid=2107420)[0m INFO 01-09 16:09:12 model_runner.py:547] Graph capturing finished in 34 secs.
[2024-01-09 16:09:12,902][root][INFO] - Dataset is /scr/jphilipp/scai/datasets/hh-rlhf_shuffled_1. Chosen: chosen, Rejected: rejected
[2024-01-09 16:09:12,902][root][INFO] - Seed is 1
[2024-01-09 16:09:12,953][root][INFO] - Training Example(s): tensor([[37512]], dtype=torch.int32)
[2024-01-09 16:09:12,954][root][INFO] - Random previous Example(s) used for Evaluation: [array([37512], dtype=int32)]
[2024-01-09 16:09:33,179][root][ERROR] - Error in format_response_base: list index out of range
[2024-01-09 16:09:33,179][root][INFO] - Formatted Response Success Rate: 0.9166666666666666
[2024-01-09 16:09:39,835][root][INFO] - New Constitution 0: When presented with a request that could potentially have negative consequences, the Assistant should first ask a series of questions to gather more information before making a decision.
[2024-01-09 16:09:39,835][root][INFO] - Writing to disk.
[2024-01-09 16:09:39,853][root][INFO] - Training Example(s): tensor([[32729]], dtype=torch.int32)
[2024-01-09 16:09:39,854][root][INFO] - Random previous Example(s) used for Evaluation: [array([32729, 37512], dtype=int32)]
[2024-01-09 16:09:59,696][root][INFO] - Formatted Response Success Rate: 1.0
[2024-01-09 16:10:07,780][root][INFO] - New Constitution 0: When presented with a request that could potentially have negative consequences, the Assistant should first ask a series of questions to gather more information before making a decision. If the human's request is unclear, the Assistant should clarify what the human needs help with before offering assistance.
[2024-01-09 16:10:07,780][root][INFO] - Writing to disk.
[2024-01-09 16:10:07,789][root][INFO] - Training Example(s): tensor([[3650]], dtype=torch.int32)
[2024-01-09 16:10:07,790][root][INFO] - Random previous Example(s) used for Evaluation: [array([ 3650, 37512, 32729], dtype=int32)]
[2024-01-09 16:10:27,668][root][INFO] - Formatted Response Success Rate: 1.0
[2024-01-09 16:10:39,348][root][INFO] - New Constitution 0: When presented with a request that could potentially have negative consequences, the Assistant should first ask a series of questions to gather more information before making a decision. If the human's request is unclear, the Assistant should clarify what the human needs help with before offering assistance. The Assistant should also be proactive in offering advice and take into account the potential consequences of the human's request.
[2024-01-09 16:10:39,348][root][INFO] - Writing to disk.
[2024-01-09 16:10:39,358][root][INFO] - Training Example(s): tensor([[33263]], dtype=torch.int32)
[2024-01-09 16:10:39,358][root][INFO] - Random previous Example(s) used for Evaluation: [array([ 3650, 37512, 33263, 32729], dtype=int32)]
