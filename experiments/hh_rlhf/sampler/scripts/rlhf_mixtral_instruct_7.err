Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:28,  1.61s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:03<00:25,  1.53s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:04<00:24,  1.50s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:06<00:22,  1.49s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:07<00:20,  1.48s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:08<00:19,  1.48s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:10<00:17,  1.47s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:11<00:16,  1.47s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:13<00:14,  1.47s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:14<00:13,  1.46s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:16<00:11,  1.46s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:17<00:10,  1.46s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:19<00:08,  1.46s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:20<00:07,  1.45s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:22<00:05,  1.46s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:23<00:04,  1.46s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:25<00:02,  1.47s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:26<00:01,  1.48s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:27<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:27<00:00,  1.46s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
  0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.43 examples/s]
  0%|          | 1/200 [02:12<7:18:18, 132.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.85 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.49 examples/s]
  1%|          | 2/200 [04:03<6:35:27, 119.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.33 examples/s]
  2%|▏         | 3/200 [05:42<6:02:40, 110.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.37 examples/s]
  2%|▏         | 4/200 [07:44<6:15:25, 114.93s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.40 examples/s]
  2%|▎         | 5/200 [10:05<6:44:20, 124.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.60 examples/s]
  3%|▎         | 6/200 [12:08<6:40:01, 123.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.10 examples/s]
  4%|▎         | 7/200 [14:00<6:25:55, 119.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.54 examples/s]
  4%|▍         | 8/200 [16:16<6:40:13, 125.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 217.16 examples/s]
  4%|▍         | 9/200 [18:34<6:51:35, 129.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.39 examples/s]
  5%|▌         | 10/200 [21:03<7:08:16, 135.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (0/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.14 examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00,  9.02 examples/s]
  6%|▌         | 11/200 [23:31<7:18:35, 139.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.46 examples/s]
  6%|▌         | 12/200 [25:30<6:56:53, 133.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 125.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 123.20 examples/s]
  6%|▋         | 13/200 [28:00<7:10:35, 138.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.37 examples/s]
  7%|▋         | 14/200 [30:01<6:52:02, 132.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.06 examples/s]
  8%|▊         | 15/200 [31:48<6:26:18, 125.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.00 examples/s]
  8%|▊         | 16/200 [34:18<6:46:22, 132.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 241.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.89 examples/s]
  8%|▊         | 17/200 [36:27<6:41:26, 131.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.69 examples/s]
  9%|▉         | 18/200 [38:47<6:47:02, 134.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.56 examples/s]
 10%|▉         | 19/200 [41:20<7:01:24, 139.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.74 examples/s]
 10%|█         | 20/200 [43:42<7:01:17, 140.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 234.55 examples/s]
 10%|█         | 21/200 [46:09<7:05:02, 142.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.79 examples/s]
 11%|█         | 22/200 [48:49<7:17:46, 147.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.29 examples/s]
 12%|█▏        | 23/200 [50:57<6:57:45, 141.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 251.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.81 examples/s]
 12%|█▏        | 24/200 [53:23<6:59:22, 142.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 254.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.39 examples/s]
 12%|█▎        | 25/200 [55:47<6:58:04, 143.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.01 examples/s]
 13%|█▎        | 26/200 [58:06<6:52:01, 142.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.38 examples/s]
 14%|█▎        | 27/200 [1:00:14<6:37:50, 137.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.49 examples/s]
 14%|█▍        | 28/200 [1:02:35<6:37:35, 138.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.87 examples/s]
 14%|█▍        | 29/200 [1:04:51<6:32:54, 137.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.94 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.07 examples/s]
 15%|█▌        | 30/200 [1:06:52<6:16:22, 132.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.53 examples/s]
 16%|█▌        | 31/200 [1:09:27<6:33:13, 139.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.09 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.59 examples/s]
 16%|█▌        | 32/200 [1:11:54<6:36:53, 141.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.37 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.47 examples/s]
 16%|█▋        | 33/200 [1:14:12<6:31:13, 140.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.25 examples/s]
 17%|█▋        | 34/200 [1:16:32<6:28:47, 140.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.09 examples/s]
 18%|█▊        | 35/200 [1:18:48<6:22:37, 139.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.35 examples/s]
 18%|█▊        | 36/200 [1:21:17<6:27:59, 141.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 253.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.53 examples/s]
 18%|█▊        | 37/200 [1:23:38<6:24:49, 141.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.96 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.40 examples/s]
 19%|█▉        | 38/200 [1:25:39<6:06:02, 135.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.23 examples/s]
 20%|█▉        | 39/200 [1:27:31<5:44:35, 128.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.50 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 227.58 examples/s]
 20%|██        | 40/200 [1:29:08<5:17:55, 119.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.46 examples/s]
 20%|██        | 41/200 [1:31:29<5:33:08, 125.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.75 examples/s]
 21%|██        | 42/200 [1:33:58<5:48:53, 132.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 219.51 examples/s]
 22%|██▏       | 43/200 [1:36:05<5:42:31, 130.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.90 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.18 examples/s]
 22%|██▏       | 44/200 [1:38:17<5:41:05, 131.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 232.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.08 examples/s]
 22%|██▎       | 45/200 [1:40:16<5:29:34, 127.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.30 examples/s]
 23%|██▎       | 46/200 [1:42:42<5:41:41, 133.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 228.97 examples/s]
 24%|██▎       | 47/200 [1:45:02<5:44:49, 135.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.12 examples/s]
 24%|██▍       | 48/200 [1:47:31<5:52:42, 139.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.97 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 208.20 examples/s]
 24%|██▍       | 49/200 [1:50:06<6:02:38, 144.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.27 examples/s]
 25%|██▌       | 50/200 [1:52:41<6:08:09, 147.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 225.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.11 examples/s]
 26%|██▌       | 51/200 [1:54:45<5:48:27, 140.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.92 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.97 examples/s]
 26%|██▌       | 52/200 [1:57:05<5:46:17, 140.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 245.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.98 examples/s]
 26%|██▋       | 53/200 [1:59:31<5:47:28, 141.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 155.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.18 examples/s]
 27%|██▋       | 54/200 [2:01:56<5:47:59, 143.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.79 examples/s]
 28%|██▊       | 55/200 [2:04:19<5:45:40, 143.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.12 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.42 examples/s]
 28%|██▊       | 56/200 [2:06:19<5:26:27, 136.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.18 examples/s]
 28%|██▊       | 57/200 [2:08:24<5:15:56, 132.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 222.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.70 examples/s]
 29%|██▉       | 58/200 [2:10:30<5:09:14, 130.66s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.88 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.88 examples/s]
 30%|██▉       | 59/200 [2:12:53<5:16:01, 134.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 218.24 examples/s]
 30%|███       | 60/200 [2:15:32<5:30:53, 141.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.01 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.50 examples/s]
 30%|███       | 61/200 [2:18:02<5:34:15, 144.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 233.17 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.93 examples/s]
 31%|███       | 62/200 [2:20:04<5:16:36, 137.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 215.52 examples/s]
 32%|███▏      | 63/200 [2:22:14<5:08:38, 135.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.91 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 163.78 examples/s]
 32%|███▏      | 64/200 [2:24:50<5:20:41, 141.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.38 examples/s]
 32%|███▎      | 65/200 [2:27:15<5:20:47, 142.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.64 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.29 examples/s]
 33%|███▎      | 66/200 [2:29:15<5:03:26, 135.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.35 examples/s]
 34%|███▎      | 67/200 [2:32:00<5:20:38, 144.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 205.67 examples/s]
 34%|███▍      | 68/200 [2:34:38<5:26:45, 148.53s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.74 examples/s]
 34%|███▍      | 69/200 [2:37:05<5:23:35, 148.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.47 examples/s]
 35%|███▌      | 70/200 [2:39:40<5:25:13, 150.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 246.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 236.01 examples/s]
 36%|███▌      | 71/200 [2:41:23<4:52:16, 135.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 211.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.63 examples/s]
 36%|███▌      | 72/200 [2:43:55<5:00:05, 140.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.29 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.73 examples/s]
 36%|███▋      | 73/200 [2:46:31<5:07:55, 145.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.87 examples/s]
 37%|███▋      | 74/200 [2:48:27<4:46:59, 136.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 221.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 214.59 examples/s]
 38%|███▊      | 75/200 [2:50:42<4:43:30, 136.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.99 examples/s]
 38%|███▊      | 76/200 [2:53:18<4:53:20, 141.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.41 examples/s]
 38%|███▊      | 77/200 [2:55:50<4:57:29, 145.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.49 examples/s]
 39%|███▉      | 78/200 [2:57:57<4:44:01, 139.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.93 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.61 examples/s]
 40%|███▉      | 79/200 [3:00:32<4:50:50, 144.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 152.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 147.03 examples/s]
 40%|████      | 80/200 [3:02:52<4:45:44, 142.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 151.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.53 examples/s]
 40%|████      | 81/200 [3:05:08<4:39:13, 140.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 213.66 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 207.05 examples/s]
 41%|████      | 82/200 [3:07:54<4:52:02, 148.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.81 examples/s]
 42%|████▏     | 83/200 [3:10:36<4:57:31, 152.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 212.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.16 examples/s]
 42%|████▏     | 84/200 [3:13:00<4:49:46, 149.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 206.24 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.11 examples/s]
 42%|████▎     | 85/200 [3:15:27<4:45:57, 149.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 216.27 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 209.25 examples/s]
 43%|████▎     | 86/200 [3:17:36<4:31:56, 143.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.26 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 190.53 examples/s]
 44%|████▎     | 87/200 [3:20:17<4:39:14, 148.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 200.85 examples/s]
 44%|████▍     | 88/200 [3:23:02<4:46:16, 153.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.13 examples/s]
 44%|████▍     | 89/200 [3:25:34<4:42:51, 152.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.38 examples/s]
 45%|████▌     | 90/200 [3:27:50<4:31:09, 147.90s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 163.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 157.98 examples/s]
 46%|████▌     | 91/200 [3:30:15<4:26:58, 146.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.43 examples/s]
 46%|████▌     | 92/200 [3:32:58<4:33:22, 151.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.26 examples/s]
 46%|████▋     | 93/200 [3:35:41<4:36:42, 155.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.71 examples/s]
 47%|████▋     | 94/200 [3:38:22<4:37:23, 157.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.43 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 192.68 examples/s]
 48%|████▊     | 95/200 [3:40:49<4:29:31, 154.01s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 204.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 198.69 examples/s]
 48%|████▊     | 96/200 [3:43:30<4:30:15, 155.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 186.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.31 examples/s]
 48%|████▊     | 97/200 [3:45:53<4:21:24, 152.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 197.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.42 examples/s]
 49%|████▉     | 98/200 [3:48:34<4:23:06, 154.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.03 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 181.20 examples/s]
 50%|████▉     | 99/200 [3:51:24<4:28:20, 159.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.67 examples/s]
 50%|█████     | 100/200 [3:54:13<4:30:34, 162.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 201.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 194.28 examples/s]
 50%|█████     | 101/200 [3:56:33<4:16:28, 155.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 193.72 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.50 examples/s]
 51%|█████     | 102/200 [3:58:33<3:56:32, 144.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 189.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 181.89 examples/s]
 52%|█████▏    | 103/200 [4:01:23<4:06:29, 152.47s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 168.27 examples/s]
 52%|█████▏    | 104/200 [4:04:07<4:09:25, 155.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 123.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 121.00 examples/s]
 52%|█████▎    | 105/200 [4:06:41<4:05:42, 155.19s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 147.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 142.87 examples/s]
 53%|█████▎    | 106/200 [4:09:04<3:57:26, 151.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.65 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.12 examples/s]
 54%|█████▎    | 107/200 [4:11:54<4:03:46, 157.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 187.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.56 examples/s]
 54%|█████▍    | 108/200 [4:14:38<4:04:01, 159.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.00 examples/s]
 55%|█████▍    | 109/200 [4:17:03<3:55:09, 155.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 195.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 188.97 examples/s]
 55%|█████▌    | 110/200 [4:19:50<3:57:45, 158.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.42 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.10 examples/s]
 56%|█████▌    | 111/200 [4:22:39<3:59:50, 161.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.62 examples/s]
 56%|█████▌    | 112/200 [4:25:45<4:07:41, 168.88s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 203.13 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.83 examples/s]
 56%|█████▋    | 113/200 [4:28:24<4:00:38, 165.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.47 examples/s]
 57%|█████▋    | 114/200 [4:30:40<3:45:08, 157.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 184.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.79 examples/s]
 57%|█████▊    | 115/200 [4:33:49<3:55:53, 166.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.93 examples/s]
 58%|█████▊    | 116/200 [4:36:45<3:57:28, 169.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 183.11 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.13 examples/s]
 58%|█████▊    | 117/200 [4:39:29<3:52:03, 167.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.19 examples/s]
 59%|█████▉    | 118/200 [4:42:17<3:49:19, 167.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.08 examples/s]
 60%|█████▉    | 119/200 [4:45:16<3:50:59, 171.11s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.35 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.94 examples/s]
 60%|██████    | 120/200 [4:48:05<3:47:28, 170.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.29 examples/s]
 60%|██████    | 121/200 [4:50:58<3:45:25, 171.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 181.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.93 examples/s]
 61%|██████    | 122/200 [4:53:46<3:41:27, 170.35s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 177.23 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.87 examples/s]
 62%|██████▏   | 123/200 [4:56:49<3:43:25, 174.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.99 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.06 examples/s]
 62%|██████▏   | 124/200 [4:59:48<3:42:24, 175.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 178.19 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 173.53 examples/s]
 62%|██████▎   | 125/200 [5:02:51<3:42:29, 177.99s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.05 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.22 examples/s]
 63%|██████▎   | 126/200 [5:05:50<3:39:52, 178.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 174.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 167.58 examples/s]
 64%|██████▎   | 127/200 [5:08:57<3:40:01, 180.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 162.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 158.46 examples/s]
 64%|██████▍   | 128/200 [5:11:47<3:33:06, 177.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 185.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 179.21 examples/s]
 64%|██████▍   | 129/200 [5:14:37<3:27:22, 175.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.60 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.26 examples/s]
 65%|██████▌   | 130/200 [5:17:14<3:17:58, 169.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 185.51 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 180.03 examples/s]
 66%|██████▌   | 131/200 [5:20:13<3:18:28, 172.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.86 examples/s]
 66%|██████▌   | 132/200 [5:22:44<3:08:16, 166.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 166.67 examples/s]
 66%|██████▋   | 133/200 [5:25:42<3:09:33, 169.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 182.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.06 examples/s]
 67%|██████▋   | 134/200 [5:28:58<3:15:12, 177.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 175.44 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.75 examples/s]
 68%|██████▊   | 135/200 [5:31:56<3:12:36, 177.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.62 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.49 examples/s]
 68%|██████▊   | 136/200 [5:34:39<3:04:56, 173.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 168.53 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 162.32 examples/s]
 68%|██████▊   | 137/200 [5:37:38<3:03:38, 174.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 163.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 157.82 examples/s]
 69%|██████▉   | 138/200 [5:40:38<3:02:26, 176.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 176.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.10 examples/s]
 70%|██████▉   | 139/200 [5:43:52<3:04:38, 181.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 170.56 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.94 examples/s]
 70%|███████   | 140/200 [5:46:50<3:00:33, 180.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 126.14 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 122.69 examples/s]
 70%|███████   | 141/200 [5:50:09<3:03:03, 186.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 169.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 162.46 examples/s]
 71%|███████   | 142/200 [5:53:25<3:02:39, 188.95s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 171.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 164.69 examples/s]
 72%|███████▏  | 143/200 [5:56:25<2:57:11, 186.52s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 157.08 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 151.80 examples/s]
 72%|███████▏  | 144/200 [5:59:34<2:54:45, 187.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 168.75 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 161.89 examples/s]
 72%|███████▎  | 145/200 [6:02:50<2:53:59, 189.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 156.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 151.22 examples/s]
 73%|███████▎  | 146/200 [6:06:14<2:54:38, 194.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 163.67 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 159.52 examples/s]
 74%|███████▎  | 147/200 [6:09:37<2:53:41, 196.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 160.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 155.57 examples/s]
 74%|███████▍  | 148/200 [6:12:57<2:51:20, 197.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 133.41 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 129.21 examples/s]
 74%|███████▍  | 149/200 [6:16:08<2:46:23, 195.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 144.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 139.54 examples/s]
 75%|███████▌  | 150/200 [6:19:39<2:46:48, 200.17s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 152.30 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 148.96 examples/s]
 76%|███████▌  | 151/200 [6:22:48<2:40:56, 197.07s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 144.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 139.23 examples/s]
 76%|███████▌  | 152/200 [6:26:08<2:38:11, 197.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 148.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 143.15 examples/s]
 76%|███████▋  | 153/200 [6:29:46<2:39:36, 203.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 153.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 148.26 examples/s]
 77%|███████▋  | 154/200 [6:33:21<2:38:52, 207.23s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 158.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 152.81 examples/s]
 78%|███████▊  | 155/200 [6:36:58<2:37:36, 210.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 144.40 examples/s]
 78%|███████▊  | 156/200 [6:40:25<2:33:30, 209.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.28 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.08 examples/s]
 78%|███████▊  | 157/200 [6:43:37<2:26:13, 204.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.63 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 142.35 examples/s]
 79%|███████▉  | 158/200 [6:47:01<2:22:54, 204.15s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 149.86 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 145.27 examples/s]
 80%|███████▉  | 159/200 [6:50:44<2:23:22, 209.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 144.51 examples/s]
 80%|████████  | 160/200 [6:54:15<2:20:07, 210.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 137.19 examples/s]
 80%|████████  | 161/200 [6:57:49<2:17:21, 211.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.72 examples/s]
 81%|████████  | 162/200 [7:01:22<2:14:01, 211.61s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 136.76 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 133.21 examples/s]
 82%|████████▏ | 163/200 [7:04:57<2:11:11, 212.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 139.32 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 135.24 examples/s]
 82%|████████▏ | 164/200 [7:08:35<2:08:31, 214.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 135.38 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 130.95 examples/s]
 82%|████████▎ | 165/200 [7:12:19<2:06:39, 217.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 146.69 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 141.33 examples/s]
 83%|████████▎ | 166/200 [7:15:58<2:03:23, 217.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 127.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 124.43 examples/s]
 84%|████████▎ | 167/200 [7:19:34<1:59:30, 217.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 139.39 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 135.35 examples/s]
 84%|████████▍ | 168/200 [7:23:17<1:56:49, 219.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 134.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 129.60 examples/s]
 84%|████████▍ | 169/200 [7:26:59<1:53:37, 219.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 134.61 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 130.99 examples/s]
 85%|████████▌ | 170/200 [7:30:37<1:49:38, 219.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 129.31 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 125.18 examples/s]
 86%|████████▌ | 171/200 [7:34:28<1:47:43, 222.86s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 132.00 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 127.70 examples/s]
 86%|████████▌ | 172/200 [7:38:17<1:44:52, 224.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 126.10 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 122.20 examples/s]
 86%|████████▋ | 173/200 [7:42:08<1:41:56, 226.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 125.95 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 123.41 examples/s]
 87%|████████▋ | 174/200 [7:46:00<1:38:49, 228.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 133.73 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 130.57 examples/s]
 88%|████████▊ | 175/200 [7:49:47<1:34:54, 227.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 127.20 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 124.47 examples/s]
 88%|████████▊ | 176/200 [7:53:49<1:32:50, 232.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 121.36 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 117.94 examples/s]
 88%|████████▊ | 177/200 [7:57:42<1:29:08, 232.56s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 125.59 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 121.72 examples/s]
 89%|████████▉ | 178/200 [8:01:44<1:26:13, 235.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 118.98 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 116.84 examples/s]
 90%|████████▉ | 179/200 [8:05:46<1:23:06, 237.43s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 122.70 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 119.08 examples/s]
 90%|█████████ | 180/200 [8:09:45<1:19:15, 237.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 123.54 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 119.73 examples/s]
 90%|█████████ | 181/200 [8:13:55<1:16:25, 241.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 110.02 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 107.08 examples/s]
 91%|█████████ | 182/200 [8:18:05<1:13:11, 243.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 118.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 115.04 examples/s]
 92%|█████████▏| 183/200 [8:22:16<1:09:46, 246.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 102.49 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 99.78 examples/s] 
 92%|█████████▏| 184/200 [8:26:19<1:05:22, 245.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 119.87 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 116.36 examples/s]
 92%|█████████▎| 185/200 [8:30:26<1:01:25, 245.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 118.18 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 114.67 examples/s]
 93%|█████████▎| 186/200 [8:34:40<57:56, 248.34s/it]  The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 114.55 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 111.68 examples/s]
 94%|█████████▎| 187/200 [8:39:02<54:40, 252.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 115.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 112.24 examples/s]
 94%|█████████▍| 188/200 [8:43:08<50:05, 250.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 110.82 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 107.75 examples/s]
 94%|█████████▍| 189/200 [8:47:28<46:24, 253.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 108.57 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 105.72 examples/s]
 95%|█████████▌| 190/200 [8:51:34<41:50, 251.05s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 107.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 104.15 examples/s]
 96%|█████████▌| 191/200 [8:55:59<38:18, 255.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 97.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 94.95 examples/s]
 96%|█████████▌| 192/200 [9:00:01<33:29, 251.22s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 107.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 105.32 examples/s]
 96%|█████████▋| 193/200 [9:04:16<29:26, 252.41s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 95.40 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 93.27 examples/s]
 97%|█████████▋| 194/200 [9:08:34<25:24, 254.03s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 103.84 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 101.49 examples/s]
 98%|█████████▊| 195/200 [9:12:52<21:16, 255.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 100.80 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 98.12 examples/s] 
 98%|█████████▊| 196/200 [9:17:09<17:03, 255.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 104.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 101.68 examples/s]
 98%|█████████▊| 197/200 [9:21:30<12:51, 257.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 99.25 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 97.07 examples/s]
 99%|█████████▉| 198/200 [9:25:44<08:32, 256.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 95.04 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 92.98 examples/s]
100%|█████████▉| 199/200 [9:29:51<04:13, 253.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 98.77 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 96.38 examples/s]
100%|██████████| 200/200 [9:34:09<00:00, 254.87s/it]100%|██████████| 200/200 [9:34:09<00:00, 172.25s/it]
ERROR: Cannot find key: sampler.run_id=7
Usage: sampler.py <group|command|value>
  available groups:      os | time | copy | random | logging | fire | hydra |
                         torch | pd | List | Tuple | Optional | Callable |
                         Dict | re | np | SEED_PRINCIPLES | RETURN_FORMATS
  available commands:    tqdm | DictConfig | DataParallel | load_dataset |
                         Dataset | remove_final_answer | format_eval_prompt |
                         split_conversation_hh_rlhf | build_generation_prompt |
                         build_generation_prompt_base |
                         initialize_constitutions | format_responses |
                         get_eval_examples | extend_batches |
                         build_eval_prompt | format_response_base |
                         is_valid_response | extract_new_principle |
                         extract_revised_principle | process_responses |
                         filter_responses | run_generate | run_eval |
                         GPT4Agent | AsyncAzureChatLLM | HFInferenceModel | main
  available values:      BOS_TOKEN | EOS_TOKEN | B_INST | E_INST | B_SYS | E_SYS

For detailed information on this command, run:
  sampler.py --help
