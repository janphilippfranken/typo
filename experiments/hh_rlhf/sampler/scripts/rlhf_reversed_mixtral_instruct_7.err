Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:01<00:33,  1.85s/it]Loading checkpoint shards:  11%|█         | 2/19 [00:03<00:29,  1.74s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [00:05<00:27,  1.70s/it]Loading checkpoint shards:  21%|██        | 4/19 [00:06<00:25,  1.67s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [00:08<00:23,  1.66s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [00:10<00:21,  1.65s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [00:11<00:19,  1.63s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [00:13<00:18,  1.64s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [00:14<00:16,  1.63s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [00:16<00:14,  1.62s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [00:18<00:12,  1.62s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [00:19<00:11,  1.62s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [00:21<00:09,  1.62s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [00:22<00:08,  1.61s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [00:24<00:06,  1.64s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [00:26<00:04,  1.63s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [00:27<00:03,  1.62s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [00:29<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:30<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 19/19 [00:30<00:00,  1.63s/it]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.52s/it]
  0%|          | 0/200 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 196.22 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 191.12 examples/s]
  0%|          | 1/200 [02:20<7:44:36, 140.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 248.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.39 examples/s]
  1%|          | 2/200 [04:31<7:26:01, 135.16s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 226.79 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.27 examples/s]
  2%|▏         | 3/200 [06:15<6:36:56, 120.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 237.07 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 229.71 examples/s]
  2%|▏         | 4/200 [08:24<6:45:42, 124.20s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 242.46 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 235.23 examples/s]
  2%|▎         | 5/200 [10:41<6:58:13, 128.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 250.33 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 240.57 examples/s]
  3%|▎         | 6/200 [12:50<6:56:19, 128.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 155.45 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 150.73 examples/s]
  4%|▎         | 7/200 [14:40<6:34:56, 122.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 230.09 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 223.48 examples/s]
  4%|▍         | 8/200 [16:48<6:37:47, 124.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 231.74 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 224.73 examples/s]
  4%|▍         | 9/200 [19:17<7:00:37, 132.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.

Saving the dataset (0/1 shards):   0%|          | 0/1 [00:00<?, ? examples/s][A
Saving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 220.21 examples/s][ASaving the dataset (1/1 shards): 100%|██████████| 1/1 [00:00<00:00, 210.54 examples/s]
  5%|▌         | 10/200 [21:48<7:16:07, 137.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
