model_generation:
  hydra:
    run:
      dir: outputs
  model_type: huggingface
  name: mistral_7b_instruct
  model_config:
    model_id: mistral
    pretrained_model_name_or_path: mistralai/Mistral-7B-Instruct-v0.1
    load_in_8bit: true
    device_map: sequential
    torch_dtype: float16
    model_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
    tokenizer_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-Instruct-v0.1
  completion_config:
    do_sample: true
    temperature: 0.7
    top_p: 0.9
    max_new_tokens: 1000
model_inference:
  hydra:
    run:
      dir: outputs
  model_type: huggingface
  name: mistral_7b_base
  model_config:
    model_id: mistral
    pretrained_model_name_or_path: mistralai/Mistral-7B-v0.1
    load_in_8bit: true
    device_map: sequential
    torch_dtype: float16
    model_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1
    tokenizer_cache_dir: /scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1
  generation:
    do_sample: true
    temperature: 0.1
    top_p: 0.9
    max_new_tokens: 500
data:
  hydra:
    run:
      dir: outputs
  dataset:
    path: Anthropic/hh-rlhf
    data_dir: harmless-base
    cache_dir: /scr/jphilipp/scai/datasets/hh-rlhf
  split: train
generation:
  hydra:
    run:
      dir: outputs
  generation_prompt: generation_prompt_1
  constitution_start: 'Revised List of Preferences:'
  constitution_instruction: 'The AI Assistant must ALWAYS abide by the following principles
    when responding to a Human:'
  system_message: You are an expert at learning human preferences from conversations.
    You are creative.
  code_block_start: preferences
  dataset_version: rlhf
  chosen: chosen
  rejected: rejected
  run_id: 1
  n_revisions: 100
  constitution_batch_size: 20
  generation_batch_size: 1
  eval_batch_size: 1
  init_constitution: 1. The AI Assistant should be non-evasive.
  verbose: true
  start_example: 0
  start_log_probs: -1000
