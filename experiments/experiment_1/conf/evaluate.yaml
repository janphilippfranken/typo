output_dir: results/responses/sweep
file_name: null

start_example: null
max_example: null
batch_size: null

generation_config:
  max_new_tokens: 350
  top_p: 0.9
  num_return_sequences: 1 

model_config:
  model: null
  download_dir: null
  dtype: auto
  quantization: null
  tensor_parallel_size: 1

dataset_helpful: 
  path: Anthropic/hh-rlhf
  data_dir: helpful-base
  cache_dir: /home/jphilipp/research_projects/typo_files/datasets/hh-rlhf
  split: test

dataset_harmless:
  path: Anthropic/hh-rlhf
  data_dir: harmless-base
  cache_dir: /home/jphilipp/research_projects/typo_files/datasets/hh-rlhf
  split: test

temperatures:
 - 0.0
 
constitution_key: 'helpful' # does not matter whether helpful or harmless as we shuffle