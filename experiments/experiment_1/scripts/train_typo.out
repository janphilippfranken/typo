{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-11 11:08:21,470][root][INFO] - beta: 0.1
[2024-03-11 11:08:21,471][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-0.1.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-0.1.json
n helpful: 2000
n harmless: 1806
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0.
3806
tokenized 3806 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.1-1e-6-iteration-0.
Epoch 0, Step 0: train/loss = 0.626151442527771, train/raw-loss = 0.626151442527771, train/logprobs = tensor([[-0.5320, -1.6266],
        [-0.6046, -1.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6514006853103638, train/raw-loss = 0.6514006853103638, train/logprobs = tensor([[-0.5028, -0.8636],
        [-0.5280, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6812334656715393, train/raw-loss = 0.6812334656715393, train/logprobs = tensor([[-0.4953, -0.8415],
        [-0.5338, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.5803045034408569, train/raw-loss = 0.5803045034408569, train/logprobs = tensor([[-0.5518, -2.2224],
        [-0.6612, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.62431401014328, train/raw-loss = 0.62431401014328, train/logprobs = tensor([[-0.5353, -0.9661],
        [-0.8186, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6697949171066284, train/raw-loss = 0.6697949171066284, train/logprobs = tensor([[-0.4912, -0.8927],
        [-0.5894, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6718199849128723, train/raw-loss = 0.6718199849128723, train/logprobs = tensor([[-0.5810, -0.5317],
        [-0.6328, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6043583750724792, train/raw-loss = 0.6043583750724792, train/logprobs = tensor([[-0.5441, -1.7520],
        [-0.6556, -1.4345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.5578873157501221, train/raw-loss = 0.5578873157501221, train/logprobs = tensor([[-0.5600, -2.3311],
        [-0.6450, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.643979549407959, train/raw-loss = 0.643979549407959, train/logprobs = tensor([[-0.5995, -0.9546],
        [-0.7227, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6829110980033875, train/raw-loss = 0.6829110980033875, train/logprobs = tensor([[-0.7218, -0.9243],
        [-0.7852, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6631162762641907, train/raw-loss = 0.6631162762641907, train/logprobs = tensor([[-0.6360, -0.8920],
        [-0.7353, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.4811258316040039, train/raw-loss = 0.4811258316040039, train/logprobs = tensor([[-0.6975, -2.5671],
        [-0.9054, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6171160340309143, train/raw-loss = 0.6171160340309143, train/logprobs = tensor([[-0.5521, -1.5341],
        [-0.6184, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6337964534759521, train/raw-loss = 0.6337964534759521, train/logprobs = tensor([[-0.6179, -1.0619],
        [-0.7509, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5917654037475586, train/raw-loss = 0.5917654037475586, train/logprobs = tensor([[-0.5814, -1.9856],
        [-0.6661, -1.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6909119486808777, train/raw-loss = 0.6909119486808777, train/logprobs = tensor([[-0.3845, -0.5524],
        [-0.4099, -0.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6690844893455505, train/raw-loss = 0.6690844893455505, train/logprobs = tensor([[-0.5130, -0.8290],
        [-0.5865, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6579471826553345, train/raw-loss = 0.6579471826553345, train/logprobs = tensor([[-0.4248, -1.0882],
        [-0.4624, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.621723473072052, train/raw-loss = 0.621723473072052, train/logprobs = tensor([[-0.5470, -1.4921],
        [-0.5885, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6308507919311523, train/raw-loss = 0.6308507919311523, train/logprobs = tensor([[-0.7176, -1.0544],
        [-0.8334, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6855326890945435, train/raw-loss = 0.6855326890945435, train/logprobs = tensor([[-0.4429, -0.8201],
        [-0.4723, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6773326396942139, train/raw-loss = 0.6773326396942139, train/logprobs = tensor([[-0.5269, -0.9090],
        [-0.6215, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6563409566879272, train/raw-loss = 0.6563409566879272, train/logprobs = tensor([[-0.5952, -0.8222],
        [-0.6744, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6427162885665894, train/raw-loss = 0.6427162885665894, train/logprobs = tensor([[-0.5477, -0.9513],
        [-0.6836, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6363422274589539, train/raw-loss = 0.6363422274589539, train/logprobs = tensor([[-0.5544, -0.9791],
        [-0.6497, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6998584270477295, train/raw-loss = 0.6998584270477295, train/logprobs = tensor([[-0.4371, -1.0226],
        [-0.4547, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6754298210144043, train/raw-loss = 0.6754298210144043, train/logprobs = tensor([[-0.4159, -0.7634],
        [-0.4320, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6019802093505859, train/raw-loss = 0.6019802093505859, train/logprobs = tensor([[-0.5539, -2.2298],
        [-0.6093, -1.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6605981588363647, train/raw-loss = 0.6605981588363647, train/logprobs = tensor([[-0.5695, -1.0004],
        [-0.6638, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6742237210273743, train/raw-loss = 0.6742237210273743, train/logprobs = tensor([[-0.6284, -0.7568],
        [-0.7241, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6580765247344971, train/raw-loss = 0.6580765247344971, train/logprobs = tensor([[-0.5002, -0.9803],
        [-0.5394, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6737897992134094, train/raw-loss = 0.6737897992134094, train/logprobs = tensor([[-0.5673, -1.0554],
        [-0.6395, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6480326652526855, train/raw-loss = 0.6480326652526855, train/logprobs = tensor([[-0.4636, -1.0161],
        [-0.5075, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6344242691993713, train/raw-loss = 0.6344242691993713, train/logprobs = tensor([[-0.6384, -0.9516],
        [-0.7570, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6920045018196106, train/raw-loss = 0.6920045018196106, train/logprobs = tensor([[-0.5652, -0.6577],
        [-0.5419, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6684216260910034, train/raw-loss = 0.6684216260910034, train/logprobs = tensor([[-0.5399, -0.5232],
        [-0.5776, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.5884003639221191, train/raw-loss = 0.5884003639221191, train/logprobs = tensor([[-0.5314, -1.9258],
        [-0.6220, -1.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6804813146591187, train/raw-loss = 0.6804813146591187, train/logprobs = tensor([[-0.5509, -0.5015],
        [-0.6153, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6681503653526306, train/raw-loss = 0.6681503653526306, train/logprobs = tensor([[-0.6695, -1.2182],
        [-0.7883, -1.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6451807618141174, train/raw-loss = 0.6451807618141174, train/logprobs = tensor([[-0.6167, -0.9360],
        [-0.6884, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6203322410583496, train/raw-loss = 0.6203322410583496, train/logprobs = tensor([[-0.5369, -1.5162],
        [-0.6257, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6210395693778992, train/raw-loss = 0.6210395693778992, train/logprobs = tensor([[-0.6576, -1.6781],
        [-0.7412, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6688458919525146, train/raw-loss = 0.6688458919525146, train/logprobs = tensor([[-0.5880, -0.6682],
        [-0.6841, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5931517481803894, train/raw-loss = 0.5931517481803894, train/logprobs = tensor([[-0.4521, -2.4428],
        [-0.5037, -1.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.5665391683578491, train/raw-loss = 0.5665391683578491, train/logprobs = tensor([[-0.5752, -2.2205],
        [-0.6844, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.678109884262085, train/raw-loss = 0.678109884262085, train/logprobs = tensor([[-0.8871, -0.7659],
        [-0.8938, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6390549540519714, train/raw-loss = 0.6390549540519714, train/logprobs = tensor([[-0.3988, -1.4025],
        [-0.4546, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.566025972366333, train/raw-loss = 0.566025972366333, train/logprobs = tensor([[-0.5117, -1.8578],
        [-0.5724, -1.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.5964142084121704, train/raw-loss = 0.5964142084121704, train/logprobs = tensor([[-0.5670, -1.9596],
        [-0.7400, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6416305303573608, train/raw-loss = 0.6416305303573608, train/logprobs = tensor([[-0.5193, -0.8578],
        [-0.6190, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6820334792137146, train/raw-loss = 0.6820334792137146, train/logprobs = tensor([[-0.4964, -0.9851],
        [-0.5220, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6325727701187134, train/raw-loss = 0.6325727701187134, train/logprobs = tensor([[-0.5603, -0.6316],
        [-0.7162, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6647505760192871, train/raw-loss = 0.6647505760192871, train/logprobs = tensor([[-0.6781, -1.3000],
        [-0.8537, -1.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6824195384979248, train/raw-loss = 0.6824195384979248, train/logprobs = tensor([[-0.4394, -0.8593],
        [-0.4947, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.666618287563324, train/raw-loss = 0.666618287563324, train/logprobs = tensor([[-0.5334, -0.7254],
        [-0.6013, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6506434679031372, train/raw-loss = 0.6506434679031372, train/logprobs = tensor([[-0.5674, -0.8702],
        [-0.6368, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6688615083694458, train/raw-loss = 0.6688615083694458, train/logprobs = tensor([[-0.4378, -0.9733],
        [-0.4775, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.622824490070343, train/raw-loss = 0.622824490070343, train/logprobs = tensor([[-0.5166, -1.3426],
        [-0.5917, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6586250066757202, train/raw-loss = 0.6586250066757202, train/logprobs = tensor([[-0.6401, -0.8999],
        [-0.7881, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6660503149032593, train/raw-loss = 0.6660503149032593, train/logprobs = tensor([[-0.3980, -0.7761],
        [-0.4592, -0.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6290931701660156, train/raw-loss = 0.6290931701660156, train/logprobs = tensor([[-0.5893, -1.2191],
        [-0.7058, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6267271637916565, train/raw-loss = 0.6267271637916565, train/logprobs = tensor([[-0.5463, -1.1152],
        [-0.6325, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6604589819908142, train/raw-loss = 0.6604589819908142, train/logprobs = tensor([[-0.6231, -0.6365],
        [-0.7292, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6802064776420593, train/raw-loss = 0.6791751980781555, train/logprobs = tensor([[-0.5241, -0.5330],
        [-0.5325, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010312944650650024
Epoch 0, Step 65: train/loss = 0.6334306001663208, train/raw-loss = 0.6325505375862122, train/logprobs = tensor([[-0.6060, -1.0945],
        [-0.6097, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008800570853054523
Epoch 0, Step 66: train/loss = 0.5597355961799622, train/raw-loss = 0.559156596660614, train/logprobs = tensor([[-0.5619, -1.8007],
        [-0.6208, -0.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0057900394313037395
Epoch 0, Step 67: train/loss = 0.6420890688896179, train/raw-loss = 0.6414003372192383, train/logprobs = tensor([[-0.5265, -0.9800],
        [-0.5539, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006887415423989296
Epoch 0, Step 68: train/loss = 0.6355592012405396, train/raw-loss = 0.6350564956665039, train/logprobs = tensor([[-0.5336, -0.8678],
        [-0.5466, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005027538165450096
Epoch 0, Step 69: train/loss = 0.6546450257301331, train/raw-loss = 0.6538562774658203, train/logprobs = tensor([[-0.6478, -0.9421],
        [-0.6998, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007887350395321846
Epoch 0, Step 70: train/loss = 0.603089451789856, train/raw-loss = 0.6022916436195374, train/logprobs = tensor([[-0.5493, -1.1922],
        [-0.5532, -0.7620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007978012785315514
Epoch 0, Step 71: train/loss = 0.6369138956069946, train/raw-loss = 0.63596510887146, train/logprobs = tensor([[-0.6798, -0.9440],
        [-0.7469, -0.7552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009488343261182308
Epoch 0, Step 72: train/loss = 0.5810567140579224, train/raw-loss = 0.5802849531173706, train/logprobs = tensor([[-0.6123, -2.4285],
        [-0.6475, -1.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007717506494373083
Epoch 0, Step 73: train/loss = 0.49164435267448425, train/raw-loss = 0.49079185724258423, train/logprobs = tensor([[-0.5761, -2.5652],
        [-0.8049, -1.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008525346405804157
Epoch 0, Step 74: train/loss = 0.6360830664634705, train/raw-loss = 0.6354132890701294, train/logprobs = tensor([[-0.5553, -0.7778],
        [-0.6147, -0.5965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006697638425976038
Epoch 0, Step 75: train/loss = 0.6145657300949097, train/raw-loss = 0.6136060953140259, train/logprobs = tensor([[-0.6075, -1.1055],
        [-0.7064, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009596263989806175
Epoch 0, Step 76: train/loss = 0.6175644397735596, train/raw-loss = 0.6170002222061157, train/logprobs = tensor([[-0.4655, -1.1665],
        [-0.4912, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005641896277666092
Epoch 0, Step 77: train/loss = 0.5848246216773987, train/raw-loss = 0.5841795206069946, train/logprobs = tensor([[-0.5278, -1.6628],
        [-0.5854, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006450929678976536
Epoch 0, Step 78: train/loss = 0.6404953002929688, train/raw-loss = 0.6395660042762756, train/logprobs = tensor([[-0.5082, -1.3547],
        [-0.5541, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00929247960448265
Epoch 0, Step 79: train/loss = 0.6926288604736328, train/raw-loss = 0.6918177604675293, train/logprobs = tensor([[-0.4504, -0.4419],
        [-0.4574, -0.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008111506700515747
Epoch 0, Step 80: train/loss = 0.583745002746582, train/raw-loss = 0.5831204056739807, train/logprobs = tensor([[-0.5241, -1.1601],
        [-0.5583, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006246095057576895
Epoch 0, Step 81: train/loss = 0.6169565916061401, train/raw-loss = 0.6163219809532166, train/logprobs = tensor([[-0.5166, -1.0460],
        [-0.6203, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006345802452415228
Epoch 0, Step 82: train/loss = 0.598735511302948, train/raw-loss = 0.5980082750320435, train/logprobs = tensor([[-0.5526, -1.4772],
        [-0.5574, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007272512651979923
Epoch 0, Step 83: train/loss = 0.5824911594390869, train/raw-loss = 0.5817470550537109, train/logprobs = tensor([[-0.4545, -1.8463],
        [-0.5099, -1.4011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007440964225679636
Epoch 0, Step 84: train/loss = 0.5546163320541382, train/raw-loss = 0.5538427233695984, train/logprobs = tensor([[-0.4869, -2.5245],
        [-0.5349, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00773610919713974
Epoch 0, Step 85: train/loss = 0.6587784886360168, train/raw-loss = 0.6579313278198242, train/logprobs = tensor([[-0.6271, -0.7855],
        [-0.6188, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008471761830151081
Epoch 0, Step 86: train/loss = 0.5676025748252869, train/raw-loss = 0.5671102404594421, train/logprobs = tensor([[-0.4607, -1.7639],
        [-0.5152, -1.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049232435412704945
Epoch 0, Step 87: train/loss = 0.5841791033744812, train/raw-loss = 0.5834711194038391, train/logprobs = tensor([[-0.8868, -1.2549],
        [-1.1180, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007079753093421459
Epoch 0, Step 88: train/loss = 0.6236287355422974, train/raw-loss = 0.6227333545684814, train/logprobs = tensor([[-0.6690, -1.1104],
        [-0.7139, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00895359180867672
Epoch 0, Step 89: train/loss = 0.6274449825286865, train/raw-loss = 0.6267541646957397, train/logprobs = tensor([[-0.4728, -1.1380],
        [-0.4639, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006908251438289881
Epoch 0, Step 90: train/loss = 0.62706059217453, train/raw-loss = 0.62635338306427, train/logprobs = tensor([[-0.4661, -0.9998],
        [-0.4771, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0070722708478569984
Epoch 0, Step 91: train/loss = 0.5961633324623108, train/raw-loss = 0.5954931378364563, train/logprobs = tensor([[-0.4925, -1.3585],
        [-0.5374, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006702065467834473
Epoch 0, Step 92: train/loss = 0.6301708817481995, train/raw-loss = 0.6292409896850586, train/logprobs = tensor([[-0.5622, -1.0625],
        [-0.6663, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009298797696828842
Epoch 0, Step 93: train/loss = 0.6159256100654602, train/raw-loss = 0.6152917146682739, train/logprobs = tensor([[-0.6291, -1.0156],
        [-0.7168, -0.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006339302286505699
Epoch 0, Step 94: train/loss = 0.6438255310058594, train/raw-loss = 0.6430167555809021, train/logprobs = tensor([[-0.5254, -1.2896],
        [-0.5676, -1.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008087750524282455
Epoch 0, Step 95: train/loss = 0.649243950843811, train/raw-loss = 0.6485702991485596, train/logprobs = tensor([[-0.4689, -1.4877],
        [-0.4841, -1.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006736605893820524
Epoch 0, Step 96: train/loss = 0.6642456650733948, train/raw-loss = 0.6607367992401123, train/logprobs = tensor([[-0.5203, -0.6310],
        [-0.5348, -0.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03508833050727844
Epoch 0, Step 97: train/loss = 0.5563604235649109, train/raw-loss = 0.5533241033554077, train/logprobs = tensor([[-0.5031, -1.7960],
        [-0.5283, -1.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030363479629158974
Epoch 0, Step 98: train/loss = 0.6133474111557007, train/raw-loss = 0.6094058156013489, train/logprobs = tensor([[-0.8197, -1.1795],
        [-0.9138, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039416421204805374
Epoch 0, Step 99: train/loss = 0.6268571019172668, train/raw-loss = 0.6246002316474915, train/logprobs = tensor([[-0.6376, -0.9991],
        [-0.6280, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02256886661052704
Epoch 0, Step 100: train/loss = 0.6416869163513184, train/raw-loss = 0.6390759944915771, train/logprobs = tensor([[-0.5052, -1.0234],
        [-0.4860, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026109635829925537
Epoch 0, Step 101: train/loss = 0.604041576385498, train/raw-loss = 0.6015690565109253, train/logprobs = tensor([[-0.4080, -1.2692],
        [-0.3742, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024725545197725296
Epoch 0, Step 102: train/loss = 0.6071784496307373, train/raw-loss = 0.6036112904548645, train/logprobs = tensor([[-0.6652, -1.4368],
        [-0.6613, -1.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03567228466272354
Epoch 0, Step 103: train/loss = 0.6873769164085388, train/raw-loss = 0.6835644841194153, train/logprobs = tensor([[-0.5930, -0.6696],
        [-0.5632, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03812393546104431
Epoch 0, Step 104: train/loss = 0.6041076183319092, train/raw-loss = 0.6012458801269531, train/logprobs = tensor([[-0.6536, -0.9790],
        [-0.7247, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02861720137298107
Epoch 0, Step 105: train/loss = 0.6030340790748596, train/raw-loss = 0.5986753702163696, train/logprobs = tensor([[-0.6751, -1.4903],
        [-0.6190, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043586693704128265
Epoch 0, Step 106: train/loss = 0.611741840839386, train/raw-loss = 0.6086761951446533, train/logprobs = tensor([[-0.4280, -1.3343],
        [-0.4034, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030657045543193817
Epoch 0, Step 107: train/loss = 0.5672675371170044, train/raw-loss = 0.5647175312042236, train/logprobs = tensor([[-0.5901, -1.4669],
        [-0.6419, -0.8995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02549985609948635
Epoch 0, Step 108: train/loss = 0.5800721049308777, train/raw-loss = 0.5777309536933899, train/logprobs = tensor([[-0.5375, -1.6920],
        [-0.5111, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023411788046360016
Epoch 0, Step 109: train/loss = 0.5768547654151917, train/raw-loss = 0.574122428894043, train/logprobs = tensor([[-0.6504, -1.3791],
        [-0.6932, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027323734015226364
Epoch 0, Step 110: train/loss = 0.640232264995575, train/raw-loss = 0.6373615264892578, train/logprobs = tensor([[-0.5721, -1.0568],
        [-0.5783, -0.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028707334771752357
Epoch 0, Step 111: train/loss = 0.6694919466972351, train/raw-loss = 0.6661375761032104, train/logprobs = tensor([[-0.5213, -0.6359],
        [-0.5089, -0.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03354351967573166
Epoch 0, Step 112: train/loss = 0.6033120155334473, train/raw-loss = 0.6007317304611206, train/logprobs = tensor([[-0.5409, -1.5575],
        [-0.5318, -1.1181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025803131982684135
Epoch 0, Step 113: train/loss = 0.6228504180908203, train/raw-loss = 0.6192729473114014, train/logprobs = tensor([[-0.6537, -1.1825],
        [-0.6870, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03577432036399841
Epoch 0, Step 114: train/loss = 0.6100133061408997, train/raw-loss = 0.6069557666778564, train/logprobs = tensor([[-0.4932, -1.2249],
        [-0.4609, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030575653538107872
Epoch 0, Step 115: train/loss = 0.5274351239204407, train/raw-loss = 0.5240510106086731, train/logprobs = tensor([[-0.6281, -1.6188],
        [-0.7472, -0.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03384119272232056
Epoch 0, Step 116: train/loss = 0.6685371994972229, train/raw-loss = 0.6648887395858765, train/logprobs = tensor([[-0.7275, -1.2041],
        [-0.6562, -1.0056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03648451715707779
Epoch 0, Step 117: train/loss = 0.6317030191421509, train/raw-loss = 0.6282811760902405, train/logprobs = tensor([[-0.5022, -0.9020],
        [-0.5381, -0.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03421888127923012
Epoch 0, Step 118: train/loss = 0.5942703485488892, train/raw-loss = 0.5913149118423462, train/logprobs = tensor([[-0.5515, -1.2035],
        [-0.5212, -0.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02955501154065132
Epoch 0, Step 119: train/loss = 0.5836322903633118, train/raw-loss = 0.581041693687439, train/logprobs = tensor([[-0.5092, -1.3575],
        [-0.5270, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025906041264533997
Epoch 0, Step 120: train/loss = 0.6162518262863159, train/raw-loss = 0.613821804523468, train/logprobs = tensor([[-0.5371, -0.9077],
        [-0.5636, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024300383403897285
Epoch 0, Step 121: train/loss = 0.5932140946388245, train/raw-loss = 0.5906516313552856, train/logprobs = tensor([[-0.5162, -1.1784],
        [-0.5347, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025624345988035202
Epoch 0, Step 122: train/loss = 0.6447824239730835, train/raw-loss = 0.641974925994873, train/logprobs = tensor([[-0.4807, -0.7725],
        [-0.4844, -0.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028075335547327995
Epoch 0, Step 123: train/loss = 0.5319725871086121, train/raw-loss = 0.5285109281539917, train/logprobs = tensor([[-0.5244, -1.9823],
        [-0.5319, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03461666405200958
Epoch 0, Step 124: train/loss = 0.6599245071411133, train/raw-loss = 0.6574217081069946, train/logprobs = tensor([[-0.5904, -0.6016],
        [-0.5684, -0.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025027379393577576
Epoch 0, Step 125: train/loss = 0.5815298557281494, train/raw-loss = 0.5790488123893738, train/logprobs = tensor([[-0.4957, -1.3043],
        [-0.4882, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024810541421175003
Epoch 0, Step 126: train/loss = 0.6243876218795776, train/raw-loss = 0.6224371194839478, train/logprobs = tensor([[-0.4208, -1.2601],
        [-0.4039, -0.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019505569711327553
Epoch 0, Step 127: train/loss = 0.5385729074478149, train/raw-loss = 0.5357879400253296, train/logprobs = tensor([[-0.6745, -2.1938],
        [-0.6443, -1.3536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02784934639930725
Epoch 0, Step 128: train/loss = 0.4673217535018921, train/raw-loss = 0.4582783579826355, train/logprobs = tensor([[-0.5698, -3.1746],
        [-0.6386, -1.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09043411165475845
Epoch 0, Step 129: train/loss = 0.5060843825340271, train/raw-loss = 0.4961165189743042, train/logprobs = tensor([[-0.5913, -3.5273],
        [-0.6088, -1.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09967896342277527
Epoch 0, Step 130: train/loss = 0.6415274739265442, train/raw-loss = 0.6322684288024902, train/logprobs = tensor([[-0.5409, -1.1392],
        [-0.4743, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09259070456027985
Epoch 0, Step 131: train/loss = 0.6103571057319641, train/raw-loss = 0.5992172360420227, train/logprobs = tensor([[-0.4743, -1.0697],
        [-0.4893, -0.6616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139873415231705
Epoch 0, Step 132: train/loss = 0.6357210874557495, train/raw-loss = 0.623539388179779, train/logprobs = tensor([[-0.6424, -1.0695],
        [-0.5333, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12181742489337921
Epoch 0, Step 133: train/loss = 0.5973225831985474, train/raw-loss = 0.588120698928833, train/logprobs = tensor([[-0.6347, -1.7756],
        [-0.5433, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09201905131340027
Epoch 0, Step 134: train/loss = 0.4719642996788025, train/raw-loss = 0.459730327129364, train/logprobs = tensor([[-0.8798, -3.3465],
        [-0.8286, -1.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12233977764844894
Epoch 0, Step 135: train/loss = 0.43636322021484375, train/raw-loss = 0.42672908306121826, train/logprobs = tensor([[-0.5633, -3.4868],
        [-0.6139, -1.6877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09634099155664444
Epoch 0, Step 136: train/loss = 0.5627784132957458, train/raw-loss = 0.5544684529304504, train/logprobs = tensor([[-0.5077, -1.5945],
        [-0.4664, -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08309939503669739
Epoch 0, Step 137: train/loss = 0.630646824836731, train/raw-loss = 0.6219112277030945, train/logprobs = tensor([[-0.4817, -0.9565],
        [-0.4672, -0.6278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08735664188861847
Epoch 0, Step 138: train/loss = 0.43636325001716614, train/raw-loss = 0.4266732633113861, train/logprobs = tensor([[-0.6139, -4.0319],
        [-0.6025, -1.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968998372554779
Epoch 0, Step 139: train/loss = 0.6258819103240967, train/raw-loss = 0.6168779730796814, train/logprobs = tensor([[-0.5185, -1.0332],
        [-0.4481, -0.6174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900396853685379
Epoch 0, Step 140: train/loss = 0.5791624188423157, train/raw-loss = 0.5660967230796814, train/logprobs = tensor([[-0.5940, -1.6511],
        [-0.6408, -1.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306568682193756
Epoch 0, Step 141: train/loss = 0.6148782968521118, train/raw-loss = 0.6071914434432983, train/logprobs = tensor([[-0.5236, -1.0519],
        [-0.4955, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07686784863471985
Epoch 0, Step 142: train/loss = 0.575671374797821, train/raw-loss = 0.5642586946487427, train/logprobs = tensor([[-0.7243, -1.6446],
        [-0.7221, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11412708461284637
Epoch 0, Step 143: train/loss = 0.5736259818077087, train/raw-loss = 0.5648329257965088, train/logprobs = tensor([[-0.6580, -1.9761],
        [-0.6415, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08793085068464279
Epoch 0, Step 144: train/loss = 0.4960220754146576, train/raw-loss = 0.4865187406539917, train/logprobs = tensor([[-0.6019, -2.3363],
        [-0.6045, -1.2739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09503347426652908
Epoch 0, Step 145: train/loss = 0.6141178011894226, train/raw-loss = 0.6043955087661743, train/logprobs = tensor([[-0.4370, -1.1327],
        [-0.3942, -0.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09722322225570679
Epoch 0, Step 146: train/loss = 0.4266256093978882, train/raw-loss = 0.41381925344467163, train/logprobs = tensor([[-0.8369, -4.5797],
        [-0.8780, -2.3513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12806378304958344
Epoch 0, Step 147: train/loss = 0.6047481298446655, train/raw-loss = 0.5945214033126831, train/logprobs = tensor([[-0.4856, -1.0179],
        [-0.4908, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10226781666278839
Epoch 0, Step 148: train/loss = 0.5533191561698914, train/raw-loss = 0.5432679057121277, train/logprobs = tensor([[-0.5559, -1.5542],
        [-0.5086, -0.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10051263123750687
Epoch 0, Step 149: train/loss = 0.5707019567489624, train/raw-loss = 0.563865602016449, train/logprobs = tensor([[-0.5851, -1.9110],
        [-0.5943, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06836315244436264
Epoch 0, Step 150: train/loss = 0.5151225924491882, train/raw-loss = 0.504249632358551, train/logprobs = tensor([[-0.6853, -1.9266],
        [-0.7583, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10872926563024521
Epoch 0, Step 151: train/loss = 0.5644744038581848, train/raw-loss = 0.5538806915283203, train/logprobs = tensor([[-0.5426, -1.8363],
        [-0.4548, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593673586845398
Epoch 0, Step 152: train/loss = 0.46313345432281494, train/raw-loss = 0.4527435004711151, train/logprobs = tensor([[-0.6493, -3.5636],
        [-0.7113, -1.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389936715364456
Epoch 0, Step 153: train/loss = 0.5255181789398193, train/raw-loss = 0.5183131694793701, train/logprobs = tensor([[-0.4497, -1.7045],
        [-0.4460, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07205027341842651
Epoch 0, Step 154: train/loss = 0.4701271653175354, train/raw-loss = 0.4593784213066101, train/logprobs = tensor([[-0.5949, -2.7967],
        [-0.6136, -1.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748709738254547
Epoch 0, Step 155: train/loss = 0.5147343277931213, train/raw-loss = 0.5052646398544312, train/logprobs = tensor([[-0.9002, -2.8935],
        [-0.9326, -1.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09469729661941528
Epoch 0, Step 156: train/loss = 0.5703137516975403, train/raw-loss = 0.5612618923187256, train/logprobs = tensor([[-0.5496, -1.9404],
        [-0.5005, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09051831066608429
Epoch 0, Step 157: train/loss = 0.6273790597915649, train/raw-loss = 0.6182258129119873, train/logprobs = tensor([[-0.4815, -1.1263],
        [-0.5038, -0.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09153251349925995
Epoch 0, Step 158: train/loss = 0.5384403467178345, train/raw-loss = 0.5304027795791626, train/logprobs = tensor([[-0.5199, -2.0696],
        [-0.4655, -1.0820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08037561923265457
Epoch 0, Step 159: train/loss = 0.6676380634307861, train/raw-loss = 0.6593651175498962, train/logprobs = tensor([[-0.4743, -0.7240],
        [-0.4462, -0.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08272971957921982
Epoch 0, Step 160: train/loss = 0.5768887996673584, train/raw-loss = 0.5646941661834717, train/logprobs = tensor([[-0.7579, -2.0356],
        [-0.5336, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194688618183136
Epoch 0, Step 161: train/loss = 0.47536152601242065, train/raw-loss = 0.4614918529987335, train/logprobs = tensor([[-0.6913, -3.0782],
        [-0.6735, -1.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13869640231132507
Epoch 0, Step 162: train/loss = 0.5601633787155151, train/raw-loss = 0.5473078489303589, train/logprobs = tensor([[-0.6944, -1.5757],
        [-0.6358, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1285550445318222
Epoch 0, Step 163: train/loss = 0.537526547908783, train/raw-loss = 0.5260574817657471, train/logprobs = tensor([[-0.6549, -1.7055],
        [-0.6152, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11469060927629471
Epoch 0, Step 164: train/loss = 0.5525550246238708, train/raw-loss = 0.5385427474975586, train/logprobs = tensor([[-0.6818, -3.4844],
        [-0.6330, -1.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14012305438518524
Epoch 0, Step 165: train/loss = 0.6087124347686768, train/raw-loss = 0.5962291955947876, train/logprobs = tensor([[-0.5726, -1.1693],
        [-0.5734, -0.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248331367969513
Epoch 0, Step 166: train/loss = 0.5520364046096802, train/raw-loss = 0.5405226945877075, train/logprobs = tensor([[-0.6205, -1.7159],
        [-0.6636, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11513681709766388
Epoch 0, Step 167: train/loss = 0.512173056602478, train/raw-loss = 0.5012362003326416, train/logprobs = tensor([[-0.5423, -2.1575],
        [-0.5226, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10936792939901352
Epoch 0, Step 168: train/loss = 0.5808115601539612, train/raw-loss = 0.5711451172828674, train/logprobs = tensor([[-0.6320, -2.0352],
        [-0.5489, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09666437655687332
Epoch 0, Step 169: train/loss = 0.530059814453125, train/raw-loss = 0.5204564929008484, train/logprobs = tensor([[-0.6346, -2.4512],
        [-0.6365, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09603308141231537
Epoch 0, Step 170: train/loss = 0.5531381368637085, train/raw-loss = 0.5410773754119873, train/logprobs = tensor([[-0.5716, -1.8988],
        [-0.6150, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060785293579102
Epoch 0, Step 171: train/loss = 0.5549631118774414, train/raw-loss = 0.5442129969596863, train/logprobs = tensor([[-0.6497, -1.6008],
        [-0.6308, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10750114917755127
Epoch 0, Step 172: train/loss = 0.5066542625427246, train/raw-loss = 0.49257493019104004, train/logprobs = tensor([[-0.8294, -1.9841],
        [-0.8476, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14079320430755615
Epoch 0, Step 173: train/loss = 0.4728624224662781, train/raw-loss = 0.4628046154975891, train/logprobs = tensor([[-0.4845, -2.4509],
        [-0.4958, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005781888961792
Epoch 0, Step 174: train/loss = 0.6201801896095276, train/raw-loss = 0.6082199215888977, train/logprobs = tensor([[-0.5800, -1.1025],
        [-0.5776, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11960253119468689
Epoch 0, Step 175: train/loss = 0.5697876214981079, train/raw-loss = 0.5579297542572021, train/logprobs = tensor([[-1.2481, -3.7234],
        [-1.0435, -2.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11857841908931732
Epoch 0, Step 176: train/loss = 0.5217977166175842, train/raw-loss = 0.5107499361038208, train/logprobs = tensor([[-0.6550, -2.7376],
        [-0.6255, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11047758907079697
Epoch 0, Step 177: train/loss = 0.5391579270362854, train/raw-loss = 0.5267558097839355, train/logprobs = tensor([[-0.6533, -2.0860],
        [-0.6398, -1.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12402095645666122
Epoch 0, Step 178: train/loss = 0.5623995065689087, train/raw-loss = 0.5479868650436401, train/logprobs = tensor([[-0.8056, -1.7395],
        [-0.9017, -1.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441257894039154
Epoch 0, Step 179: train/loss = 0.6518142223358154, train/raw-loss = 0.6378231644630432, train/logprobs = tensor([[-0.5917, -0.9112],
        [-0.5845, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13991108536720276
Epoch 0, Step 180: train/loss = 0.5798332095146179, train/raw-loss = 0.5667840242385864, train/logprobs = tensor([[-0.7198, -2.1524],
        [-0.6296, -1.4093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13049191236495972
Epoch 0, Step 181: train/loss = 0.5761308670043945, train/raw-loss = 0.5690761804580688, train/logprobs = tensor([[-0.3254, -1.3084],
        [-0.3052, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07054728269577026
Epoch 0, Step 182: train/loss = 0.5762214660644531, train/raw-loss = 0.5677368640899658, train/logprobs = tensor([[-0.5529, -1.3891],
        [-0.5426, -0.7238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08484575897455215
Epoch 0, Step 183: train/loss = 0.509580135345459, train/raw-loss = 0.49756747484207153, train/logprobs = tensor([[-0.5876, -2.2655],
        [-0.5666, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12012679874897003
Epoch 0, Step 184: train/loss = 0.5301640033721924, train/raw-loss = 0.5214225053787231, train/logprobs = tensor([[-0.4810, -1.8783],
        [-0.4827, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08741545677185059
Epoch 0, Step 185: train/loss = 0.593633770942688, train/raw-loss = 0.5834092497825623, train/logprobs = tensor([[-0.5019, -1.3370],
        [-0.4440, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10224512219429016
Epoch 0, Step 186: train/loss = 0.6372941732406616, train/raw-loss = 0.6235942840576172, train/logprobs = tensor([[-0.7273, -0.9782],
        [-0.6608, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13699859380722046
Epoch 0, Step 187: train/loss = 0.6180033087730408, train/raw-loss = 0.6067676544189453, train/logprobs = tensor([[-0.5944, -1.2622],
        [-0.5367, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11235667765140533
Epoch 0, Step 188: train/loss = 0.5406032800674438, train/raw-loss = 0.530261218547821, train/logprobs = tensor([[-0.5080, -1.8851],
        [-0.5222, -1.0767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10342033207416534
Epoch 0, Step 189: train/loss = 0.590904176235199, train/raw-loss = 0.5745478868484497, train/logprobs = tensor([[-0.9768, -1.7102],
        [-0.9864, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16356231272220612
Epoch 0, Step 190: train/loss = 0.5792414546012878, train/raw-loss = 0.5676807761192322, train/logprobs = tensor([[-0.5973, -1.4899],
        [-0.5500, -0.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11560661345720291
Epoch 0, Step 191: train/loss = 0.5409685373306274, train/raw-loss = 0.5285282135009766, train/logprobs = tensor([[-0.6341, -2.5978],
        [-0.6243, -1.3942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244034692645073
Epoch 0, Step 192: train/loss = 0.5798521637916565, train/raw-loss = 0.569130003452301, train/logprobs = tensor([[-0.4685, -1.2617],
        [-0.4119, -0.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072215586900711
Epoch 0, Step 193: train/loss = 0.6590261459350586, train/raw-loss = 0.6442321538925171, train/logprobs = tensor([[-0.5824, -0.8521],
        [-0.5351, -0.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14793895184993744
Epoch 0, Step 194: train/loss = 0.4837256669998169, train/raw-loss = 0.46762073040008545, train/logprobs = tensor([[-0.5937, -2.5496],
        [-0.5528, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16104969382286072
Epoch 0, Step 195: train/loss = 0.6135167479515076, train/raw-loss = 0.601376473903656, train/logprobs = tensor([[-0.7891, -1.3319],
        [-0.5789, -0.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12140240520238876
Epoch 0, Step 196: train/loss = 0.46787458658218384, train/raw-loss = 0.45377033948898315, train/logprobs = tensor([[-0.7224, -2.3683],
        [-0.6239, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14104261994361877
Epoch 0, Step 197: train/loss = 0.5081017017364502, train/raw-loss = 0.495954304933548, train/logprobs = tensor([[-0.5420, -2.4989],
        [-0.4899, -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147404253482819
Epoch 0, Step 198: train/loss = 0.5801746249198914, train/raw-loss = 0.5648770332336426, train/logprobs = tensor([[-0.5945, -1.4218],
        [-0.4878, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15297546982765198
Epoch 0, Step 199: train/loss = 0.46589016914367676, train/raw-loss = 0.4502629041671753, train/logprobs = tensor([[-0.6649, -3.7762],
        [-0.6426, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15627239644527435
Epoch 0, Step 200: train/loss = 0.539954662322998, train/raw-loss = 0.5267611742019653, train/logprobs = tensor([[-0.6184, -1.7433],
        [-0.6152, -0.6770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13193488121032715
Epoch 0, Step 201: train/loss = 0.46567246317863464, train/raw-loss = 0.4524260461330414, train/logprobs = tensor([[-0.6367, -2.0806],
        [-0.5545, -0.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13246414065361023
Epoch 0, Step 202: train/loss = 0.6516554951667786, train/raw-loss = 0.6409882307052612, train/logprobs = tensor([[-0.4801, -0.7215],
        [-0.4159, -0.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10667330771684647
Epoch 0, Step 203: train/loss = 0.5182299017906189, train/raw-loss = 0.5016871094703674, train/logprobs = tensor([[-0.7731, -2.0279],
        [-0.7087, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16542790830135345
Epoch 0, Step 204: train/loss = 0.6559545993804932, train/raw-loss = 0.6422959566116333, train/logprobs = tensor([[-0.7679, -0.9644],
        [-0.6565, -0.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13658654689788818
Epoch 0, Step 205: train/loss = 0.5832788944244385, train/raw-loss = 0.5676085352897644, train/logprobs = tensor([[-0.6768, -1.6749],
        [-0.6074, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15670377016067505
Epoch 0, Step 206: train/loss = 0.4596736431121826, train/raw-loss = 0.44638824462890625, train/logprobs = tensor([[-0.5234, -2.2270],
        [-0.6901, -0.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13285385072231293
Epoch 0, Step 207: train/loss = 0.6061185598373413, train/raw-loss = 0.5921939015388489, train/logprobs = tensor([[-0.5215, -1.4331],
        [-0.4669, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13924628496170044
Epoch 0, Step 208: train/loss = 0.5845180153846741, train/raw-loss = 0.5679209232330322, train/logprobs = tensor([[-0.8246, -1.8210],
        [-0.6788, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1659713089466095
Epoch 0, Step 209: train/loss = 0.5495002865791321, train/raw-loss = 0.5362886190414429, train/logprobs = tensor([[-0.5371, -1.7166],
        [-0.4502, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13211730122566223
Epoch 0, Step 210: train/loss = 0.4291112422943115, train/raw-loss = 0.41500213742256165, train/logprobs = tensor([[-0.7556, -2.8563],
        [-0.7880, -1.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14109113812446594
Epoch 0, Step 211: train/loss = 0.568811297416687, train/raw-loss = 0.5565300583839417, train/logprobs = tensor([[-0.5227, -3.7359],
        [-0.5153, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12281270325183868
Epoch 0, Step 212: train/loss = 0.4603027403354645, train/raw-loss = 0.4464467167854309, train/logprobs = tensor([[-0.7470, -4.8544],
        [-0.7167, -1.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385602355003357
Epoch 0, Step 213: train/loss = 0.576106071472168, train/raw-loss = 0.5616893768310547, train/logprobs = tensor([[-0.7104, -1.4217],
        [-0.5797, -0.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14416733384132385
Epoch 0, Step 214: train/loss = 0.6131974458694458, train/raw-loss = 0.5959739089012146, train/logprobs = tensor([[-0.9461, -1.2903],
        [-0.8683, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17223596572875977
Epoch 0, Step 215: train/loss = 0.4878332018852234, train/raw-loss = 0.47191476821899414, train/logprobs = tensor([[-0.8327, -2.0157],
        [-0.8196, -0.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15918441116809845
Epoch 0, Step 216: train/loss = 0.48799005150794983, train/raw-loss = 0.4762188196182251, train/logprobs = tensor([[-0.4960, -2.8405],
        [-0.4493, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11771219968795776
Epoch 0, Step 217: train/loss = 0.6086438894271851, train/raw-loss = 0.5925933122634888, train/logprobs = tensor([[-0.6588, -1.0782],
        [-0.5902, -0.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16050608456134796
Epoch 0, Step 218: train/loss = 0.4466497302055359, train/raw-loss = 0.433745801448822, train/logprobs = tensor([[-0.6066, -2.3461],
        [-0.5301, -0.6327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12903904914855957
Epoch 0, Step 219: train/loss = 0.4623998999595642, train/raw-loss = 0.44501417875289917, train/logprobs = tensor([[-0.7832, -2.8244],
        [-0.6592, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1738569140434265
Epoch 0, Step 220: train/loss = 0.6859931945800781, train/raw-loss = 0.669607937335968, train/logprobs = tensor([[-0.5787, -0.7568],
        [-0.5192, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1638527363538742
Epoch 0, Step 221: train/loss = 0.5529235601425171, train/raw-loss = 0.5397853851318359, train/logprobs = tensor([[-0.7683, -1.6161],
        [-0.7172, -0.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313817948102951
Epoch 0, Step 222: train/loss = 0.571130096912384, train/raw-loss = 0.5583196878433228, train/logprobs = tensor([[-0.5204, -5.1059],
        [-0.4307, -2.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12810423970222473
Epoch 0, Step 223: train/loss = 0.4749297797679901, train/raw-loss = 0.4600173830986023, train/logprobs = tensor([[-0.8242, -6.5783],
        [-0.6211, -2.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14912426471710205
Epoch 0, Step 224: train/loss = 0.6533758640289307, train/raw-loss = 0.6365174055099487, train/logprobs = tensor([[-0.7990, -1.1694],
        [-0.5795, -0.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1685846894979477
Epoch 0, Step 225: train/loss = 0.5737543106079102, train/raw-loss = 0.5591911673545837, train/logprobs = tensor([[-0.6185, -1.2760],
        [-0.6155, -0.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14563143253326416
Epoch 0, Step 226: train/loss = 0.5061825513839722, train/raw-loss = 0.49059388041496277, train/logprobs = tensor([[-0.7692, -1.9669],
        [-0.7787, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1558867245912552
Epoch 0, Step 227: train/loss = 0.414728581905365, train/raw-loss = 0.39773666858673096, train/logprobs = tensor([[-0.8614, -3.9007],
        [-0.7602, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16991913318634033
Epoch 0, Step 228: train/loss = 0.5051077604293823, train/raw-loss = 0.4874865412712097, train/logprobs = tensor([[-0.5964, -2.0470],
        [-0.7499, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17621192336082458
Epoch 0, Step 229: train/loss = 0.36810433864593506, train/raw-loss = 0.3488553762435913, train/logprobs = tensor([[-0.6599, -3.2043],
        [-0.9338, -0.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19248968362808228
Epoch 0, Step 230: train/loss = 0.6028048992156982, train/raw-loss = 0.5848357677459717, train/logprobs = tensor([[-0.9892, -1.8874],
        [-0.7617, -0.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1796913892030716
Epoch 0, Step 231: train/loss = 0.6232432723045349, train/raw-loss = 0.6076306700706482, train/logprobs = tensor([[-0.7129, -1.0914],
        [-0.7355, -0.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1561259776353836
Epoch 0, Step 232: train/loss = 0.5063162446022034, train/raw-loss = 0.48985666036605835, train/logprobs = tensor([[-0.6981, -1.9870],
        [-0.5920, -0.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16459596157073975
Epoch 0, Step 233: train/loss = 0.5363211631774902, train/raw-loss = 0.5196693539619446, train/logprobs = tensor([[-1.0342, -2.9334],
        [-0.7551, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665177196264267
Epoch 0, Step 234: train/loss = 0.44127142429351807, train/raw-loss = 0.4237803518772125, train/logprobs = tensor([[-0.7869, -3.8288],
        [-0.7652, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17491090297698975
Epoch 0, Step 235: train/loss = 0.5057883262634277, train/raw-loss = 0.4899534583091736, train/logprobs = tensor([[-0.5852, -2.5597],
        [-0.5228, -1.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583486646413803
Epoch 0, Step 236: train/loss = 0.49116867780685425, train/raw-loss = 0.4756051301956177, train/logprobs = tensor([[-0.6824, -1.9615],
        [-0.7133, -0.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1556357592344284
Epoch 0, Step 237: train/loss = 0.6588671803474426, train/raw-loss = 0.6418513059616089, train/logprobs = tensor([[-0.9108, -0.7451],
        [-0.9352, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1701589822769165
Epoch 0, Step 238: train/loss = 0.4686453342437744, train/raw-loss = 0.45237481594085693, train/logprobs = tensor([[-0.5803, -2.2000],
        [-0.6451, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16270509362220764
Epoch 0, Step 239: train/loss = 0.5648186802864075, train/raw-loss = 0.5527280569076538, train/logprobs = tensor([[-0.5479, -1.6511],
        [-0.5668, -0.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12090601772069931
Epoch 0, Step 240: train/loss = 0.6234480142593384, train/raw-loss = 0.6073822975158691, train/logprobs = tensor([[-0.6859, -1.2525],
        [-0.5918, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16065748035907745
Epoch 0, Step 241: train/loss = 0.35462281107902527, train/raw-loss = 0.34150004386901855, train/logprobs = tensor([[-0.5988, -3.2719],
        [-0.7658, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312275528907776
Epoch 0, Step 242: train/loss = 0.470937043428421, train/raw-loss = 0.45313560962677, train/logprobs = tensor([[-0.7353, -2.1797],
        [-0.7350, -0.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17801472544670105
Epoch 0, Step 243: train/loss = 0.46785497665405273, train/raw-loss = 0.4539296329021454, train/logprobs = tensor([[-0.8905, -4.7313],
        [-0.7653, -1.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392536610364914
Epoch 0, Step 244: train/loss = 0.5932916402816772, train/raw-loss = 0.5751308798789978, train/logprobs = tensor([[-0.6281, -1.2716],
        [-0.6021, -0.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816072314977646
Epoch 0, Step 245: train/loss = 0.6440103054046631, train/raw-loss = 0.6259439587593079, train/logprobs = tensor([[-0.8121, -1.4758],
        [-0.6659, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1806640625
Epoch 0, Step 246: train/loss = 0.630623459815979, train/raw-loss = 0.611749529838562, train/logprobs = tensor([[-0.7822, -1.3247],
        [-0.6414, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18873915076255798
Epoch 0, Step 247: train/loss = 0.39799314737319946, train/raw-loss = 0.38618698716163635, train/logprobs = tensor([[-0.4820, -4.1320],
        [-0.5093, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806190013885498
Epoch 0, Step 248: train/loss = 0.5031826496124268, train/raw-loss = 0.48749130964279175, train/logprobs = tensor([[-0.6366, -4.5910],
        [-0.6002, -1.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15691308677196503
Epoch 0, Step 249: train/loss = 0.4583388566970825, train/raw-loss = 0.4438249468803406, train/logprobs = tensor([[-0.6095, -4.2147],
        [-0.6178, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14513927698135376
Epoch 0, Step 250: train/loss = 0.5574830770492554, train/raw-loss = 0.5377930402755737, train/logprobs = tensor([[-0.8378, -2.1278],
        [-0.6701, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19689981639385223
Epoch 0, Step 251: train/loss = 0.5902383327484131, train/raw-loss = 0.5739309787750244, train/logprobs = tensor([[-0.6682, -1.2136],
        [-0.6913, -0.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16307316720485687
Epoch 0, Step 252: train/loss = 0.4786357879638672, train/raw-loss = 0.4618082642555237, train/logprobs = tensor([[-0.8138, -3.0969],
        [-0.7296, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16827529668807983
Epoch 0, Step 253: train/loss = 0.5054306983947754, train/raw-loss = 0.49193263053894043, train/logprobs = tensor([[-0.4968, -2.0103],
        [-0.4391, -0.8187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349807232618332
Epoch 0, Step 254: train/loss = 0.49379533529281616, train/raw-loss = 0.475577175617218, train/logprobs = tensor([[-0.8971, -2.3249],
        [-0.9659, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18218116462230682
Epoch 0, Step 255: train/loss = 0.6026980876922607, train/raw-loss = 0.5868827104568481, train/logprobs = tensor([[-0.5450, -1.1654],
        [-0.5091, -0.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581539511680603
Epoch 0, Step 256: train/loss = 0.5826776027679443, train/raw-loss = 0.5649969577789307, train/logprobs = tensor([[-0.7516, -1.6176],
        [-0.7246, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17680564522743225
Epoch 0, Step 257: train/loss = 0.5876204967498779, train/raw-loss = 0.5688373446464539, train/logprobs = tensor([[-1.1169, -2.2666],
        [-0.8805, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18783143162727356
Epoch 0, Step 258: train/loss = 0.5689413547515869, train/raw-loss = 0.5477250218391418, train/logprobs = tensor([[-0.9864, -2.2641],
        [-1.0317, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21216358244419098
Epoch 0, Step 259: train/loss = 0.41402938961982727, train/raw-loss = 0.3973841071128845, train/logprobs = tensor([[-0.6819, -2.6019],
        [-0.7095, -0.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16645275056362152
Epoch 0, Step 260: train/loss = 0.45616793632507324, train/raw-loss = 0.43789440393447876, train/logprobs = tensor([[-0.6002, -3.0106],
        [-0.7127, -0.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1827351152896881
Epoch 0, Step 261: train/loss = 0.5360215902328491, train/raw-loss = 0.5179725289344788, train/logprobs = tensor([[-0.7051, -2.1196],
        [-0.6354, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1804906129837036
Epoch 0, Step 262: train/loss = 0.43941035866737366, train/raw-loss = 0.42395368218421936, train/logprobs = tensor([[-0.4745, -2.2735],
        [-0.6210, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15456634759902954
Epoch 0, Step 263: train/loss = 0.48540830612182617, train/raw-loss = 0.4686697721481323, train/logprobs = tensor([[-0.7606, -2.1298],
        [-0.7910, -0.7773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16738538444042206
Epoch 0, Step 264: train/loss = 0.49402013421058655, train/raw-loss = 0.47665518522262573, train/logprobs = tensor([[-0.7519, -1.3338],
        [-0.9725, -0.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17364932596683502
Epoch 0, Step 265: train/loss = 0.5430117845535278, train/raw-loss = 0.5282577276229858, train/logprobs = tensor([[-0.6744, -5.4953],
        [-0.8694, -2.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14754043519496918
Epoch 0, Step 266: train/loss = 0.4347851574420929, train/raw-loss = 0.41551509499549866, train/logprobs = tensor([[-1.0196, -3.1178],
        [-1.0443, -0.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19270096719264984
Epoch 0, Step 267: train/loss = 0.47440382838249207, train/raw-loss = 0.45768964290618896, train/logprobs = tensor([[-0.6942, -2.8478],
        [-0.7147, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671413630247116
Epoch 0, Step 268: train/loss = 0.48883000016212463, train/raw-loss = 0.4719843864440918, train/logprobs = tensor([[-0.5053, -1.9467],
        [-0.6868, -0.4190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16845622658729553
Epoch 0, Step 269: train/loss = 0.5383602380752563, train/raw-loss = 0.5229954123497009, train/logprobs = tensor([[-0.8044, -4.0209],
        [-0.6526, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1536484956741333
Epoch 0, Step 270: train/loss = 0.526288628578186, train/raw-loss = 0.5067086219787598, train/logprobs = tensor([[-0.6807, -3.5376],
        [-0.7304, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19580067694187164
Epoch 0, Step 271: train/loss = 0.6043640375137329, train/raw-loss = 0.5894290804862976, train/logprobs = tensor([[-0.6435, -1.3111],
        [-0.5725, -0.7056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14934894442558289
Epoch 0, Step 272: train/loss = 0.36358603835105896, train/raw-loss = 0.34367817640304565, train/logprobs = tensor([[-0.9839, -2.8806],
        [-1.1858, -0.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19907879829406738
Epoch 0, Step 273: train/loss = 0.340794175863266, train/raw-loss = 0.3210955858230591, train/logprobs = tensor([[-0.7526, -7.8267],
        [-0.9165, -1.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19698604941368103
Epoch 0, Step 274: train/loss = 0.45298588275909424, train/raw-loss = 0.43455713987350464, train/logprobs = tensor([[-0.9177, -4.3777],
        [-0.9199, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18428805470466614
Epoch 0, Step 275: train/loss = 0.4181484878063202, train/raw-loss = 0.39987432956695557, train/logprobs = tensor([[-0.6899, -2.7888],
        [-0.8610, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18274156749248505
Epoch 0, Step 276: train/loss = 0.6643602252006531, train/raw-loss = 0.651302695274353, train/logprobs = tensor([[-1.3566, -2.4008],
        [-0.7511, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1305752694606781
Epoch 0, Step 277: train/loss = 0.5224077701568604, train/raw-loss = 0.505780041217804, train/logprobs = tensor([[-1.3492, -3.6979],
        [-0.9201, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662769913673401
Epoch 0, Step 278: train/loss = 0.42718490958213806, train/raw-loss = 0.4119233191013336, train/logprobs = tensor([[-0.5815, -3.0907],
        [-0.6533, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15261605381965637
Epoch 0, Step 279: train/loss = 0.4845277667045593, train/raw-loss = 0.46580031514167786, train/logprobs = tensor([[-0.7742, -2.8813],
        [-0.8360, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1872745007276535
Epoch 0, Step 280: train/loss = 0.4459700584411621, train/raw-loss = 0.4308232069015503, train/logprobs = tensor([[-0.5096, -2.7440],
        [-0.6078, -0.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514681875705719
Epoch 0, Step 281: train/loss = 0.5391173362731934, train/raw-loss = 0.5178073048591614, train/logprobs = tensor([[-1.0211, -4.6195],
        [-0.7440, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21310049295425415
Epoch 0, Step 282: train/loss = 0.5156289935112, train/raw-loss = 0.49789881706237793, train/logprobs = tensor([[-0.8130, -2.3601],
        [-0.9584, -1.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.177301824092865
Epoch 0, Step 283: train/loss = 0.5945359468460083, train/raw-loss = 0.5769472122192383, train/logprobs = tensor([[-0.5840, -1.4378],
        [-0.6402, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17588764429092407
Epoch 0, Step 284: train/loss = 0.5627841949462891, train/raw-loss = 0.5444542169570923, train/logprobs = tensor([[-0.7406, -1.3401],
        [-0.7548, -0.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18329934775829315
Epoch 0, Step 285: train/loss = 0.4010273814201355, train/raw-loss = 0.3816930949687958, train/logprobs = tensor([[-0.7390, -3.4470],
        [-1.0925, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19334279000759125
Epoch 0, Step 286: train/loss = 0.6163707971572876, train/raw-loss = 0.6009589433670044, train/logprobs = tensor([[-0.5965, -1.1374],
        [-0.5771, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15411829948425293
Epoch 0, Step 287: train/loss = 0.46274980902671814, train/raw-loss = 0.4459993541240692, train/logprobs = tensor([[-0.6423, -3.0169],
        [-0.6134, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675046682357788
Epoch 0, Step 288: train/loss = 0.44314947724342346, train/raw-loss = 0.4256705641746521, train/logprobs = tensor([[-0.8119, -4.9197],
        [-0.8000, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17478930950164795
Epoch 0, Step 289: train/loss = 0.625976026058197, train/raw-loss = 0.609260082244873, train/logprobs = tensor([[-0.6148, -1.1317],
        [-0.4765, -0.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1671595275402069
Epoch 0, Step 290: train/loss = 0.4062468409538269, train/raw-loss = 0.390014111995697, train/logprobs = tensor([[-0.7470, -3.1389],
        [-0.7242, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623275727033615
Epoch 0, Step 291: train/loss = 0.41672369837760925, train/raw-loss = 0.39665457606315613, train/logprobs = tensor([[-1.0418, -3.8827],
        [-1.0431, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20069149136543274
Epoch 0, Step 292: train/loss = 0.46627864241600037, train/raw-loss = 0.4522649049758911, train/logprobs = tensor([[-0.5386, -1.8817],
        [-0.6294, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14013715088367462
Epoch 0, Step 293: train/loss = 0.4475570023059845, train/raw-loss = 0.4279605746269226, train/logprobs = tensor([[-0.8149, -4.3307],
        [-0.9651, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19596441090106964
Epoch 0, Step 294: train/loss = 0.41414064168930054, train/raw-loss = 0.39412808418273926, train/logprobs = tensor([[-0.6740, -2.2802],
        [-0.9257, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20012575387954712
Epoch 0, Step 295: train/loss = 0.5005005598068237, train/raw-loss = 0.48599979281425476, train/logprobs = tensor([[-0.6347, -1.9625],
        [-0.7976, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1450079083442688
Epoch 0, Step 296: train/loss = 0.48525023460388184, train/raw-loss = 0.47131896018981934, train/logprobs = tensor([[-0.4936, -4.6941],
        [-0.6304, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13931311666965485
Epoch 0, Step 297: train/loss = 0.5599417686462402, train/raw-loss = 0.5447860360145569, train/logprobs = tensor([[-0.5550, -1.4841],
        [-0.5523, -0.7577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515577882528305
Epoch 0, Step 298: train/loss = 0.5935736894607544, train/raw-loss = 0.5770507454872131, train/logprobs = tensor([[-0.4979, -1.6009],
        [-0.5351, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16522958874702454
Epoch 0, Step 299: train/loss = 0.5365644693374634, train/raw-loss = 0.5203040838241577, train/logprobs = tensor([[-0.7114, -2.7354],
        [-0.8848, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16260401904582977
Epoch 0, Step 300: train/loss = 0.4646436274051666, train/raw-loss = 0.44594621658325195, train/logprobs = tensor([[-0.9768, -2.6985],
        [-0.9535, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18697412312030792
Epoch 0, Step 301: train/loss = 0.43845057487487793, train/raw-loss = 0.42108088731765747, train/logprobs = tensor([[-0.5986, -2.1753],
        [-0.8058, -0.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17369681596755981
Epoch 0, Step 302: train/loss = 0.4766705632209778, train/raw-loss = 0.4574231207370758, train/logprobs = tensor([[-0.9440, -3.3892],
        [-0.8663, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1924743950366974
Epoch 0, Step 303: train/loss = 0.5194903612136841, train/raw-loss = 0.503448486328125, train/logprobs = tensor([[-0.7158, -1.6438],
        [-0.6788, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16041812300682068
Epoch 0, Step 304: train/loss = 0.5846854448318481, train/raw-loss = 0.567541241645813, train/logprobs = tensor([[-0.7810, -1.2162],
        [-0.9980, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17144140601158142
Epoch 0, Step 305: train/loss = 0.37920641899108887, train/raw-loss = 0.36340492963790894, train/logprobs = tensor([[-0.6120, -4.3705],
        [-0.6829, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1580146849155426
Epoch 0, Step 306: train/loss = 0.4328237771987915, train/raw-loss = 0.4165591597557068, train/logprobs = tensor([[-0.6742, -2.6565],
        [-0.7224, -0.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16264621913433075
Epoch 0, Step 307: train/loss = 0.5731478929519653, train/raw-loss = 0.5572341680526733, train/logprobs = tensor([[-0.7545, -1.0786],
        [-0.7667, -0.4555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591372787952423
Epoch 0, Step 308: train/loss = 0.41977187991142273, train/raw-loss = 0.4025581479072571, train/logprobs = tensor([[-0.7807, -2.4362],
        [-0.9970, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17213749885559082
Epoch 0, Step 309: train/loss = 0.43446120619773865, train/raw-loss = 0.41909798979759216, train/logprobs = tensor([[-0.6174, -2.8049],
        [-0.6490, -0.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1536322683095932
Epoch 0, Step 310: train/loss = 0.4697064459323883, train/raw-loss = 0.4523671269416809, train/logprobs = tensor([[-0.6474, -2.0371],
        [-0.6896, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1733933687210083
Epoch 0, Step 311: train/loss = 0.6174418330192566, train/raw-loss = 0.5972409248352051, train/logprobs = tensor([[-0.7886, -1.3052],
        [-0.6213, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20200900733470917
Epoch 0, Step 312: train/loss = 0.6059033870697021, train/raw-loss = 0.5918806791305542, train/logprobs = tensor([[-1.1924, -1.9184],
        [-0.8687, -0.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14022712409496307
Epoch 0, Step 313: train/loss = 0.39229655265808105, train/raw-loss = 0.3760285973548889, train/logprobs = tensor([[-0.6770, -5.7637],
        [-0.6704, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626795530319214
Epoch 0, Step 314: train/loss = 0.436562716960907, train/raw-loss = 0.4201282560825348, train/logprobs = tensor([[-0.5931, -4.4524],
        [-0.6254, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16434459388256073
Epoch 0, Step 315: train/loss = 0.3895663619041443, train/raw-loss = 0.3701326847076416, train/logprobs = tensor([[-0.7161, -3.4705],
        [-0.8544, -0.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943366825580597
Epoch 0, Step 316: train/loss = 0.6548787951469421, train/raw-loss = 0.6412883996963501, train/logprobs = tensor([[-0.5227, -0.6396],
        [-0.5821, -0.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359039843082428
Epoch 0, Step 317: train/loss = 0.40547704696655273, train/raw-loss = 0.39053356647491455, train/logprobs = tensor([[-0.5477, -5.0469],
        [-0.7432, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14943470060825348
Epoch 0, Step 318: train/loss = 0.5091125965118408, train/raw-loss = 0.49136823415756226, train/logprobs = tensor([[-0.6354, -1.8786],
        [-0.6359, -0.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17744354903697968
Epoch 0, Step 319: train/loss = 0.42003241181373596, train/raw-loss = 0.3997942805290222, train/logprobs = tensor([[-0.8622, -3.1637],
        [-0.7832, -0.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20238149166107178
Epoch 0, Step 320: train/loss = 0.41550254821777344, train/raw-loss = 0.3982768654823303, train/logprobs = tensor([[-0.6233, -4.8353],
        [-0.6876, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1722569763660431
Epoch 0, Step 321: train/loss = 0.4335225522518158, train/raw-loss = 0.4160257577896118, train/logprobs = tensor([[-0.6590, -2.2006],
        [-0.8499, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174967959523201
Epoch 0, Step 322: train/loss = 0.45868241786956787, train/raw-loss = 0.4389045834541321, train/logprobs = tensor([[-1.1519, -4.4361],
        [-1.1054, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19777809083461761
Epoch 0, Step 323: train/loss = 0.36519864201545715, train/raw-loss = 0.3493199348449707, train/logprobs = tensor([[-0.6668, -6.5106],
        [-0.8525, -1.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15878728032112122
Epoch 0, Step 324: train/loss = 0.4561627507209778, train/raw-loss = 0.4407497048377991, train/logprobs = tensor([[-0.5191, -2.5351],
        [-0.6310, -0.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15413057804107666
Epoch 0, Step 325: train/loss = 0.33526498079299927, train/raw-loss = 0.3165241777896881, train/logprobs = tensor([[-0.6820, -4.6961],
        [-0.7440, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18740810453891754
Epoch 0, Step 326: train/loss = 0.4147217869758606, train/raw-loss = 0.39819592237472534, train/logprobs = tensor([[-0.5730, -2.4147],
        [-0.6823, -0.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16525845229625702
Epoch 0, Step 327: train/loss = 0.3702944219112396, train/raw-loss = 0.34967103600502014, train/logprobs = tensor([[-0.9670, -4.3253],
        [-1.0529, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20623424649238586
Epoch 0, Step 328: train/loss = 0.6419357061386108, train/raw-loss = 0.6215740442276001, train/logprobs = tensor([[-0.9593, -3.0982],
        [-0.5788, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20361661911010742
Epoch 0, Step 329: train/loss = 0.5334874987602234, train/raw-loss = 0.5170302987098694, train/logprobs = tensor([[-1.0655, -2.5570],
        [-0.8158, -0.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16457203030586243
Epoch 0, Step 330: train/loss = 0.4082789421081543, train/raw-loss = 0.391217440366745, train/logprobs = tensor([[-0.6456, -3.4353],
        [-0.6971, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17061501741409302
Epoch 0, Step 331: train/loss = 0.39547327160835266, train/raw-loss = 0.3771567940711975, train/logprobs = tensor([[-0.9056, -5.4088],
        [-0.8539, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18316462635993958
Epoch 0, Step 332: train/loss = 0.4781052768230438, train/raw-loss = 0.4615592062473297, train/logprobs = tensor([[-0.5257, -2.0283],
        [-0.6430, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165460467338562
Epoch 0, Step 333: train/loss = 0.4458865225315094, train/raw-loss = 0.42834725975990295, train/logprobs = tensor([[-0.5596, -2.6344],
        [-0.8016, -0.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17539286613464355
Epoch 0, Step 334: train/loss = 0.41839149594306946, train/raw-loss = 0.4004437029361725, train/logprobs = tensor([[-0.8103, -3.3018],
        [-0.9248, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179477721452713
Epoch 0, Step 335: train/loss = 0.3841654658317566, train/raw-loss = 0.36558353900909424, train/logprobs = tensor([[-0.9029, -5.4267],
        [-1.0929, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18581940233707428
Epoch 0, Step 336: train/loss = 0.588991105556488, train/raw-loss = 0.5700073838233948, train/logprobs = tensor([[-0.8474, -1.2751],
        [-0.8768, -0.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18983754515647888
Epoch 0, Step 337: train/loss = 0.5423231720924377, train/raw-loss = 0.526905357837677, train/logprobs = tensor([[-0.4596, -2.1575],
        [-0.5954, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15417872369289398
Epoch 0, Step 338: train/loss = 0.40646976232528687, train/raw-loss = 0.3902937173843384, train/logprobs = tensor([[-0.6229, -2.8905],
        [-0.7752, -0.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617606282234192
Epoch 0, Step 339: train/loss = 0.5534777045249939, train/raw-loss = 0.5343299508094788, train/logprobs = tensor([[-0.6577, -1.6439],
        [-0.7877, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19147785007953644
Epoch 0, Step 340: train/loss = 0.5081350803375244, train/raw-loss = 0.4891437292098999, train/logprobs = tensor([[-0.5812, -1.8302],
        [-0.7341, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18991442024707794
Epoch 0, Step 341: train/loss = 0.4662284255027771, train/raw-loss = 0.44837960600852966, train/logprobs = tensor([[-0.9396, -5.5150],
        [-0.7541, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17848840355873108
Epoch 0, Step 342: train/loss = 0.6671091318130493, train/raw-loss = 0.6524338722229004, train/logprobs = tensor([[-0.4939, -0.4973],
        [-0.6429, -0.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14675326645374298
Epoch 0, Step 343: train/loss = 0.4432903528213501, train/raw-loss = 0.4259187579154968, train/logprobs = tensor([[-0.5990, -4.3364],
        [-0.7245, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17371612787246704
Epoch 0, Step 344: train/loss = 0.4750884771347046, train/raw-loss = 0.4568295478820801, train/logprobs = tensor([[-0.8740, -1.7370],
        [-1.0669, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18258917331695557
Epoch 0, Step 345: train/loss = 0.5776234269142151, train/raw-loss = 0.5547149181365967, train/logprobs = tensor([[-1.0600, -1.6648],
        [-0.8492, -0.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2290850579738617
Epoch 0, Step 346: train/loss = 0.49138161540031433, train/raw-loss = 0.4748208522796631, train/logprobs = tensor([[-0.5102, -1.5423],
        [-0.7717, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16560760140419006
Epoch 0, Step 347: train/loss = 0.35056251287460327, train/raw-loss = 0.3327629864215851, train/logprobs = tensor([[-0.8319, -3.6663],
        [-1.0359, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17799511551856995
Epoch 0, Step 348: train/loss = 0.36067768931388855, train/raw-loss = 0.3392122983932495, train/logprobs = tensor([[-0.7894, -4.1158],
        [-0.7471, -0.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21465395390987396
Epoch 0, Step 349: train/loss = 0.3623744249343872, train/raw-loss = 0.34483638405799866, train/logprobs = tensor([[-1.1063, -5.1517],
        [-1.0233, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17538052797317505
Epoch 0, Step 350: train/loss = 0.48324647545814514, train/raw-loss = 0.46733278036117554, train/logprobs = tensor([[-0.4929, -1.9048],
        [-0.6286, -0.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15913665294647217
Epoch 0, Step 351: train/loss = 0.5405809283256531, train/raw-loss = 0.5205467939376831, train/logprobs = tensor([[-0.5834, -1.4218],
        [-0.7699, -0.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2003418207168579
Epoch 0, Step 352: train/loss = 0.38355204463005066, train/raw-loss = 0.3660288453102112, train/logprobs = tensor([[-0.9947, -3.5397],
        [-1.0602, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523199319839478
Epoch 0, Step 353: train/loss = 0.4750191271305084, train/raw-loss = 0.45640480518341064, train/logprobs = tensor([[-0.6736, -2.4307],
        [-0.8399, -0.4490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18614354729652405
Epoch 0, Step 354: train/loss = 0.4883154630661011, train/raw-loss = 0.4679392874240875, train/logprobs = tensor([[-0.9735, -3.8229],
        [-1.0687, -1.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20376184582710266
Epoch 0, Step 355: train/loss = 0.5075546503067017, train/raw-loss = 0.48963379859924316, train/logprobs = tensor([[-1.0515, -3.6649],
        [-0.5995, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17920884490013123
Epoch 0, Step 356: train/loss = 0.32380980253219604, train/raw-loss = 0.30420878529548645, train/logprobs = tensor([[-0.7617, -7.1372],
        [-0.9250, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1960100531578064
Epoch 0, Step 357: train/loss = 0.3806993365287781, train/raw-loss = 0.35944944620132446, train/logprobs = tensor([[-0.6988, -3.8318],
        [-0.8481, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2124992311000824
Epoch 0, Step 358: train/loss = 0.5636589527130127, train/raw-loss = 0.5481033325195312, train/logprobs = tensor([[-0.5978, -1.9692],
        [-0.6107, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15555641055107117
Epoch 0, Step 359: train/loss = 0.48839688301086426, train/raw-loss = 0.4693605899810791, train/logprobs = tensor([[-1.0277, -3.0535],
        [-0.8444, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19036279618740082
Epoch 0, Step 360: train/loss = 0.3940858244895935, train/raw-loss = 0.37891459465026855, train/logprobs = tensor([[-0.6080, -5.6406],
        [-0.6152, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15171250700950623
Epoch 0, Step 361: train/loss = 0.4773712158203125, train/raw-loss = 0.4574302136898041, train/logprobs = tensor([[-0.5580, -1.8727],
        [-0.9005, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19941005110740662
Epoch 0, Step 362: train/loss = 0.3835952877998352, train/raw-loss = 0.36180996894836426, train/logprobs = tensor([[-0.9410, -2.9875],
        [-1.1813, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21785303950309753
Epoch 0, Step 363: train/loss = 0.43825632333755493, train/raw-loss = 0.42265504598617554, train/logprobs = tensor([[-0.4808, -2.1725],
        [-0.7477, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15601304173469543
Epoch 0, Step 364: train/loss = 0.614227294921875, train/raw-loss = 0.5914011597633362, train/logprobs = tensor([[-0.7193, -1.0489],
        [-0.8715, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22826164960861206
Epoch 0, Step 365: train/loss = 0.5179606676101685, train/raw-loss = 0.4959937632083893, train/logprobs = tensor([[-1.1752, -2.0702],
        [-1.1566, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2196689248085022
Epoch 0, Step 366: train/loss = 0.5962392091751099, train/raw-loss = 0.5770642757415771, train/logprobs = tensor([[-0.6401, -1.4586],
        [-0.6095, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19174888730049133
Epoch 0, Step 367: train/loss = 0.4241228401660919, train/raw-loss = 0.40510207414627075, train/logprobs = tensor([[-1.0075, -3.1740],
        [-1.1250, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19020777940750122
Epoch 0, Step 368: train/loss = 0.5918394327163696, train/raw-loss = 0.5711321830749512, train/logprobs = tensor([[-1.1682, -1.5339],
        [-1.0159, -0.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20707303285598755
Epoch 0, Step 369: train/loss = 0.34728479385375977, train/raw-loss = 0.32838648557662964, train/logprobs = tensor([[-0.5229, -3.4405],
        [-0.5918, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18898318707942963
Epoch 0, Step 370: train/loss = 0.5204309225082397, train/raw-loss = 0.5033945441246033, train/logprobs = tensor([[-0.5466, -1.2771],
        [-0.7861, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17036359012126923
Epoch 0, Step 371: train/loss = 0.5474616289138794, train/raw-loss = 0.533959150314331, train/logprobs = tensor([[-0.4337, -1.2276],
        [-0.5167, -0.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350252628326416
Epoch 0, Step 372: train/loss = 0.6211727857589722, train/raw-loss = 0.5978958010673523, train/logprobs = tensor([[-1.7439, -4.0871],
        [-0.8063, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23277020454406738
Epoch 0, Step 373: train/loss = 0.4157782196998596, train/raw-loss = 0.3976897895336151, train/logprobs = tensor([[-0.6919, -3.9466],
        [-0.9036, -0.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18088440597057343
Epoch 0, Step 374: train/loss = 0.41389304399490356, train/raw-loss = 0.3971834182739258, train/logprobs = tensor([[-0.6227, -3.2534],
        [-0.7412, -0.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16709628701210022
Epoch 0, Step 375: train/loss = 0.47523197531700134, train/raw-loss = 0.45619261264801025, train/logprobs = tensor([[-0.6856, -1.9126],
        [-0.8105, -0.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19039346277713776
Epoch 0, Step 376: train/loss = 0.42801108956336975, train/raw-loss = 0.41261595487594604, train/logprobs = tensor([[-0.4722, -3.2553],
        [-0.5747, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15395133197307587
Epoch 0, Step 377: train/loss = 0.40684786438941956, train/raw-loss = 0.38462942838668823, train/logprobs = tensor([[-0.7340, -2.3807],
        [-0.9557, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22218437492847443
Epoch 0, Step 378: train/loss = 0.3723801374435425, train/raw-loss = 0.35560479760169983, train/logprobs = tensor([[-0.5739, -4.1495],
        [-0.6457, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677536517381668
Epoch 0, Step 379: train/loss = 0.40148162841796875, train/raw-loss = 0.38390111923217773, train/logprobs = tensor([[-0.6729, -3.3626],
        [-0.7641, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.175805002450943
Epoch 0, Step 380: train/loss = 0.5246884822845459, train/raw-loss = 0.5023396015167236, train/logprobs = tensor([[-0.7470, -2.3501],
        [-0.8955, -0.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22348889708518982
Epoch 0, Step 381: train/loss = 0.598374605178833, train/raw-loss = 0.5805478096008301, train/logprobs = tensor([[-0.9372, -1.6167],
        [-0.5918, -0.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17826826870441437
Epoch 0, Step 382: train/loss = 0.3691932260990143, train/raw-loss = 0.3484581708908081, train/logprobs = tensor([[-0.7290, -4.0825],
        [-0.9713, -0.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20735056698322296
Epoch 0, Step 383: train/loss = 0.45363593101501465, train/raw-loss = 0.43918001651763916, train/logprobs = tensor([[-0.4851, -3.0933],
        [-0.5735, -0.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14455924928188324
Epoch 0, Step 384: train/loss = 0.47631144523620605, train/raw-loss = 0.4587313234806061, train/logprobs = tensor([[-0.5918, -2.6279],
        [-0.6004, -1.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17580117285251617
Epoch 0, Step 385: train/loss = 0.4616037607192993, train/raw-loss = 0.4424007534980774, train/logprobs = tensor([[-0.7224, -2.5123],
        [-0.9266, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19202998280525208
Epoch 0, Step 386: train/loss = 0.4169897735118866, train/raw-loss = 0.3965100646018982, train/logprobs = tensor([[-0.6704, -3.4878],
        [-1.0946, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20479698479175568
Epoch 0, Step 387: train/loss = 0.36458930373191833, train/raw-loss = 0.34565356373786926, train/logprobs = tensor([[-0.6804, -6.7530],
        [-0.8530, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1893572211265564
Epoch 0, Step 388: train/loss = 0.5038251280784607, train/raw-loss = 0.48697078227996826, train/logprobs = tensor([[-0.4562, -3.2478],
        [-0.5584, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16854330897331238
Epoch 0, Step 389: train/loss = 0.2715578079223633, train/raw-loss = 0.2503807842731476, train/logprobs = tensor([[-0.8215, -6.3087],
        [-1.0345, -0.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21176999807357788
Epoch 0, Step 390: train/loss = 0.5288413166999817, train/raw-loss = 0.5075506567955017, train/logprobs = tensor([[-0.8622, -4.7990],
        [-0.9629, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21290649473667145
Epoch 0, Step 391: train/loss = 0.40794461965560913, train/raw-loss = 0.3866156041622162, train/logprobs = tensor([[-0.6902, -4.0927],
        [-1.0139, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21329030394554138
Epoch 0, Step 392: train/loss = 0.7600841522216797, train/raw-loss = 0.7408667206764221, train/logprobs = tensor([[-1.7642, -2.3029],
        [-1.0626, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19217373430728912
Epoch 0, Step 393: train/loss = 0.46674981713294983, train/raw-loss = 0.44906583428382874, train/logprobs = tensor([[-0.7090, -2.3395],
        [-0.6247, -0.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17684011161327362
Epoch 0, Step 394: train/loss = 0.43621134757995605, train/raw-loss = 0.4164997935295105, train/logprobs = tensor([[-1.0386, -4.3902],
        [-0.9463, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19711557030677795
Epoch 0, Step 395: train/loss = 0.2975803017616272, train/raw-loss = 0.27555859088897705, train/logprobs = tensor([[-0.9378, -8.5999],
        [-1.1805, -1.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22021712362766266
Epoch 0, Step 396: train/loss = 0.5365964770317078, train/raw-loss = 0.5153329372406006, train/logprobs = tensor([[-0.5809, -1.7783],
        [-0.7258, -0.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21263539791107178
Epoch 0, Step 397: train/loss = 0.40220358967781067, train/raw-loss = 0.3839430809020996, train/logprobs = tensor([[-0.6362, -6.0093],
        [-0.5621, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18260477483272552
Epoch 0, Step 398: train/loss = 0.619232177734375, train/raw-loss = 0.6013447046279907, train/logprobs = tensor([[-0.8211, -0.8946],
        [-0.8511, -0.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17887496948242188
Epoch 0, Step 399: train/loss = 0.3520055413246155, train/raw-loss = 0.3329760730266571, train/logprobs = tensor([[-0.7333, -6.7907],
        [-1.0409, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19029465317726135
Epoch 0, Step 400: train/loss = 0.3595176935195923, train/raw-loss = 0.33649468421936035, train/logprobs = tensor([[-1.4219, -5.6280],
        [-1.3094, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2302301526069641
Epoch 0, Step 401: train/loss = 0.45667216181755066, train/raw-loss = 0.43911972641944885, train/logprobs = tensor([[-0.9852, -4.2923],
        [-1.0311, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1755245476961136
Epoch 0, Step 402: train/loss = 0.31863582134246826, train/raw-loss = 0.2943872809410095, train/logprobs = tensor([[-0.8939, -4.5720],
        [-1.2297, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24248550832271576
Epoch 0, Step 403: train/loss = 0.2637445032596588, train/raw-loss = 0.24159003794193268, train/logprobs = tensor([[-1.2817, -8.1372],
        [-1.5418, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215447872877121
Epoch 0, Step 404: train/loss = 0.8402636647224426, train/raw-loss = 0.8224062323570251, train/logprobs = tensor([[ -3.3757, -10.1087],
        [ -1.3950,  -1.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17857465147972107
Epoch 0, Step 405: train/loss = 0.5430507063865662, train/raw-loss = 0.5227674245834351, train/logprobs = tensor([[-0.9475, -1.4066],
        [-1.0657, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20283271372318268
Epoch 0, Step 406: train/loss = 0.38011282682418823, train/raw-loss = 0.3587837517261505, train/logprobs = tensor([[-1.0236, -4.9006],
        [-1.1765, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2132909744977951
Epoch 0, Step 407: train/loss = 0.4250372648239136, train/raw-loss = 0.4100213050842285, train/logprobs = tensor([[-0.3770, -2.9399],
        [-0.5015, -0.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15015938878059387
Epoch 0, Step 408: train/loss = 0.3218347430229187, train/raw-loss = 0.30480265617370605, train/logprobs = tensor([[-0.6227, -4.8039],
        [-0.7301, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17032083868980408
Epoch 0, Step 409: train/loss = 0.40881359577178955, train/raw-loss = 0.39032503962516785, train/logprobs = tensor([[-0.6827, -3.0124],
        [-0.8043, -0.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18488597869873047
Epoch 0, Step 410: train/loss = 0.44619911909103394, train/raw-loss = 0.4273226261138916, train/logprobs = tensor([[-0.6186, -2.9112],
        [-0.7509, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18876531720161438
Epoch 0, Step 411: train/loss = 0.5087245106697083, train/raw-loss = 0.48700758814811707, train/logprobs = tensor([[-0.6700, -2.3222],
        [-0.7952, -0.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21716910600662231
Epoch 0, Step 412: train/loss = 0.42183029651641846, train/raw-loss = 0.39589542150497437, train/logprobs = tensor([[-1.4115, -3.4667],
        [-1.4654, -0.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25934892892837524
Epoch 0, Step 413: train/loss = 0.37034207582473755, train/raw-loss = 0.34844958782196045, train/logprobs = tensor([[-0.8596, -2.8223],
        [-1.1919, -0.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21892482042312622
Epoch 0, Step 414: train/loss = 0.3987197279930115, train/raw-loss = 0.3769083619117737, train/logprobs = tensor([[-0.9104, -5.6590],
        [-1.3503, -1.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21811366081237793
Epoch 0, Step 415: train/loss = 0.4542045295238495, train/raw-loss = 0.43482932448387146, train/logprobs = tensor([[-1.0634, -3.1533],
        [-1.0648, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19375230371952057
Epoch 0, Step 416: train/loss = 0.2701878547668457, train/raw-loss = 0.25152966380119324, train/logprobs = tensor([[ -0.9045, -10.9557],
        [ -1.2085,  -1.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18658186495304108
Epoch 0, Step 417: train/loss = 0.5704120397567749, train/raw-loss = 0.5519250631332397, train/logprobs = tensor([[-0.5459, -2.3761],
        [-0.5042, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1848696768283844
Epoch 0, Step 418: train/loss = 0.48937666416168213, train/raw-loss = 0.4664404094219208, train/logprobs = tensor([[-0.6784, -5.2532],
        [-0.7801, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22936248779296875
Epoch 0, Step 419: train/loss = 0.31053829193115234, train/raw-loss = 0.2904960811138153, train/logprobs = tensor([[-0.5683, -5.8354],
        [-0.8529, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20042207837104797
Epoch 0, Step 420: train/loss = 0.4660538136959076, train/raw-loss = 0.4416397511959076, train/logprobs = tensor([[-1.2007, -3.9024],
        [-1.2228, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24414044618606567
Epoch 0, Step 421: train/loss = 0.48745670914649963, train/raw-loss = 0.4640682637691498, train/logprobs = tensor([[-0.7619, -2.3564],
        [-0.9714, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23388424515724182
Epoch 0, Step 422: train/loss = 0.5049048662185669, train/raw-loss = 0.4841606020927429, train/logprobs = tensor([[-1.1635, -3.1965],
        [-1.1546, -0.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20744284987449646
Epoch 0, Step 423: train/loss = 0.42143675684928894, train/raw-loss = 0.39835602045059204, train/logprobs = tensor([[-0.8745, -6.3911],
        [-1.1101, -1.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23080766201019287
Epoch 0, Step 424: train/loss = 0.3823089599609375, train/raw-loss = 0.35572585463523865, train/logprobs = tensor([[-1.2380, -4.7179],
        [-1.3006, -0.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26583126187324524
Epoch 0, Step 425: train/loss = 0.3892483115196228, train/raw-loss = 0.36588314175605774, train/logprobs = tensor([[-0.6972, -2.3840],
        [-0.9251, -0.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23365183174610138
Epoch 0, Step 426: train/loss = 0.3338228166103363, train/raw-loss = 0.31269413232803345, train/logprobs = tensor([[-0.7826, -4.7062],
        [-1.0040, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2112865447998047
Epoch 0, Step 427: train/loss = 0.47142720222473145, train/raw-loss = 0.4485454559326172, train/logprobs = tensor([[-0.9528, -3.0306],
        [-0.9738, -0.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22881758213043213
Epoch 0, Step 428: train/loss = 0.37369588017463684, train/raw-loss = 0.35667192935943604, train/logprobs = tensor([[-0.4807, -3.8036],
        [-0.4729, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1702391803264618
Epoch 0, Step 429: train/loss = 0.41120287775993347, train/raw-loss = 0.38356807827949524, train/logprobs = tensor([[-1.2154, -3.4639],
        [-1.1630, -0.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2763480246067047
Epoch 0, Step 430: train/loss = 0.4493260383605957, train/raw-loss = 0.42850446701049805, train/logprobs = tensor([[-0.9743, -5.9236],
        [-0.9716, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20821577310562134
Epoch 0, Step 431: train/loss = 0.6781376004219055, train/raw-loss = 0.6543261408805847, train/logprobs = tensor([[-1.5441, -2.6890],
        [-0.6872, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2381146401166916
Epoch 0, Step 432: train/loss = 0.49449825286865234, train/raw-loss = 0.47086912393569946, train/logprobs = tensor([[-0.9909, -2.6910],
        [-1.0202, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23629136383533478
Epoch 0, Step 433: train/loss = 0.7359578609466553, train/raw-loss = 0.7138789892196655, train/logprobs = tensor([[-1.1843, -1.0955],
        [-1.0185, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22078871726989746
Epoch 0, Step 434: train/loss = 0.5685815811157227, train/raw-loss = 0.5459939241409302, train/logprobs = tensor([[-1.3641, -3.4737],
        [-0.8173, -0.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22587673366069794
Epoch 0, Step 435: train/loss = 0.4418601989746094, train/raw-loss = 0.4201587736606598, train/logprobs = tensor([[-0.6557, -2.6850],
        [-0.6387, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21701398491859436
Epoch 0, Step 436: train/loss = 0.42888161540031433, train/raw-loss = 0.41159123182296753, train/logprobs = tensor([[-0.7761, -3.0118],
        [-1.0647, -0.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17290380597114563
Epoch 0, Step 437: train/loss = 0.27094048261642456, train/raw-loss = 0.25352683663368225, train/logprobs = tensor([[-0.6886, -8.1268],
        [-0.8627, -0.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17413651943206787
Epoch 0, Step 438: train/loss = 0.44582098722457886, train/raw-loss = 0.426347553730011, train/logprobs = tensor([[-0.6398, -2.5330],
        [-0.7285, -0.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1947350949048996
Epoch 0, Step 439: train/loss = 0.4433595538139343, train/raw-loss = 0.42353546619415283, train/logprobs = tensor([[-0.8420, -2.4243],
        [-0.9815, -0.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19824106991291046
Epoch 0, Step 440: train/loss = 0.3754270374774933, train/raw-loss = 0.35497379302978516, train/logprobs = tensor([[-0.7211, -5.7999],
        [-1.0723, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20453263819217682
Epoch 0, Step 441: train/loss = 0.47825518250465393, train/raw-loss = 0.45769473910331726, train/logprobs = tensor([[-0.5573, -1.8524],
        [-0.7993, -0.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20560474693775177
Epoch 0, Step 442: train/loss = 0.6478602886199951, train/raw-loss = 0.6255183815956116, train/logprobs = tensor([[-0.6954, -1.0739],
        [-0.7215, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341883182525635
Epoch 0, Step 443: train/loss = 0.4557623267173767, train/raw-loss = 0.43526068329811096, train/logprobs = tensor([[-0.5695, -3.8263],
        [-0.7385, -0.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20501640439033508
Epoch 0, Step 444: train/loss = 0.5268979668617249, train/raw-loss = 0.5047748684883118, train/logprobs = tensor([[-0.7434, -3.9333],
        [-0.6465, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212311029434204
Epoch 0, Step 445: train/loss = 0.5459241271018982, train/raw-loss = 0.5290050506591797, train/logprobs = tensor([[-0.5010, -1.8852],
        [-0.5143, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16919074952602386
Epoch 0, Step 446: train/loss = 0.37841862440109253, train/raw-loss = 0.353634774684906, train/logprobs = tensor([[-0.8746, -2.5376],
        [-1.1081, -0.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24783855676651
Epoch 0, Step 447: train/loss = 0.31800979375839233, train/raw-loss = 0.29451557993888855, train/logprobs = tensor([[-1.0084, -5.1862],
        [-1.0316, -0.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2349419891834259
Epoch 0, Step 448: train/loss = 0.4365708529949188, train/raw-loss = 0.4134228825569153, train/logprobs = tensor([[-1.2377, -3.7343],
        [-1.2457, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23147937655448914
Epoch 0, Step 449: train/loss = 0.3036959767341614, train/raw-loss = 0.2797444462776184, train/logprobs = tensor([[-0.8285, -4.1039],
        [-1.2089, -0.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23951536417007446
Epoch 0, Step 450: train/loss = 0.33329883217811584, train/raw-loss = 0.312550812959671, train/logprobs = tensor([[-0.5643, -5.0078],
        [-0.8770, -0.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20748020708560944
Epoch 0, Step 451: train/loss = 0.35935479402542114, train/raw-loss = 0.33681464195251465, train/logprobs = tensor([[-0.8760, -4.1475],
        [-0.8260, -0.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22540178894996643
Epoch 0, Step 452: train/loss = 0.31253504753112793, train/raw-loss = 0.2904490828514099, train/logprobs = tensor([[-0.8164, -6.9086],
        [-1.1647, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2208593636751175
Epoch 0, Step 453: train/loss = 0.5148634910583496, train/raw-loss = 0.49039241671562195, train/logprobs = tensor([[-0.6584, -2.3103],
        [-1.0902, -0.7042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24471096694469452
Epoch 0, Step 454: train/loss = 0.48647451400756836, train/raw-loss = 0.46059298515319824, train/logprobs = tensor([[-1.3219, -6.1136],
        [-1.0430, -1.1158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25881531834602356
Epoch 0, Step 455: train/loss = 0.4819548726081848, train/raw-loss = 0.45434701442718506, train/logprobs = tensor([[-0.9576, -2.7641],
        [-1.0066, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27607834339141846
Epoch 0, Step 456: train/loss = 0.41616904735565186, train/raw-loss = 0.39567896723747253, train/logprobs = tensor([[-0.7123, -6.1530],
        [-0.8265, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20490054786205292
Epoch 0, Step 457: train/loss = 0.3845079839229584, train/raw-loss = 0.3619300425052643, train/logprobs = tensor([[-0.5531, -3.2153],
        [-0.9150, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2257792204618454
Epoch 0, Step 458: train/loss = 0.5240761041641235, train/raw-loss = 0.4995849132537842, train/logprobs = tensor([[-1.2952, -5.4862],
        [-0.9222, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24491193890571594
Epoch 0, Step 459: train/loss = 0.30873537063598633, train/raw-loss = 0.28470176458358765, train/logprobs = tensor([[-0.8621, -5.0583],
        [-1.1060, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24033603072166443
Epoch 0, Step 460: train/loss = 0.41181331872940063, train/raw-loss = 0.3865378499031067, train/logprobs = tensor([[-0.7353, -4.1227],
        [-1.0067, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527545392513275
Epoch 0, Step 461: train/loss = 0.4277350902557373, train/raw-loss = 0.41128408908843994, train/logprobs = tensor([[-0.4357, -3.5142],
        [-0.5457, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16451019048690796
Epoch 0, Step 462: train/loss = 0.44404101371765137, train/raw-loss = 0.422169029712677, train/logprobs = tensor([[-0.8891, -3.2105],
        [-0.9638, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21871986985206604
Epoch 0, Step 463: train/loss = 0.4617173373699188, train/raw-loss = 0.4442828595638275, train/logprobs = tensor([[-0.5458, -1.9506],
        [-0.6459, -0.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17434468865394592
Epoch 0, Step 464: train/loss = 0.8352051973342896, train/raw-loss = 0.8113994598388672, train/logprobs = tensor([[-2.0336, -3.2363],
        [-0.8138, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23805665969848633
Epoch 0, Step 465: train/loss = 0.40039321780204773, train/raw-loss = 0.377052366733551, train/logprobs = tensor([[-0.8475, -3.4229],
        [-1.0793, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23340851068496704
Epoch 0, Step 466: train/loss = 0.3430910110473633, train/raw-loss = 0.31931424140930176, train/logprobs = tensor([[-1.0500, -4.7749],
        [-1.1424, -1.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23776781558990479
Epoch 0, Step 467: train/loss = 0.3504670262336731, train/raw-loss = 0.3292255997657776, train/logprobs = tensor([[-0.6576, -4.0987],
        [-1.3015, -1.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21241416037082672
Epoch 0, Step 468: train/loss = 0.40976887941360474, train/raw-loss = 0.38750338554382324, train/logprobs = tensor([[-0.5708, -2.4731],
        [-0.9579, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2226555198431015
Epoch 0, Step 469: train/loss = 0.38271188735961914, train/raw-loss = 0.358415424823761, train/logprobs = tensor([[-0.6787, -2.3621],
        [-1.0360, -0.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24296455085277557
Epoch 0, Step 470: train/loss = 0.5953016877174377, train/raw-loss = 0.5720350742340088, train/logprobs = tensor([[-0.9397, -1.8412],
        [-0.8741, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23266610503196716
Epoch 0, Step 471: train/loss = 0.32207757234573364, train/raw-loss = 0.29485684633255005, train/logprobs = tensor([[-1.0167, -4.1890],
        [-1.2398, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27220702171325684
Epoch 0, Step 472: train/loss = 0.5444706678390503, train/raw-loss = 0.5213938355445862, train/logprobs = tensor([[-0.6477, -1.0151],
        [-1.1902, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2307678461074829
Epoch 0, Step 473: train/loss = 0.3138296902179718, train/raw-loss = 0.292323499917984, train/logprobs = tensor([[-0.6108, -3.2016],
        [-0.9546, -0.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21506181359291077
Epoch 0, Step 474: train/loss = 0.4748963415622711, train/raw-loss = 0.4529745578765869, train/logprobs = tensor([[-0.7043, -2.1829],
        [-0.8344, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2192177176475525
Epoch 0, Step 475: train/loss = 0.2548214793205261, train/raw-loss = 0.23094584047794342, train/logprobs = tensor([[-0.6938, -5.4962],
        [-1.1518, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.238756462931633
Epoch 0, Step 476: train/loss = 0.4633987843990326, train/raw-loss = 0.43956008553504944, train/logprobs = tensor([[-1.0299, -2.2822],
        [-1.5937, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23838689923286438
Epoch 0, Step 477: train/loss = 0.25685760378837585, train/raw-loss = 0.23467205464839935, train/logprobs = tensor([[-0.6848, -6.7205],
        [-1.0528, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22185561060905457
Epoch 0, Step 478: train/loss = 0.31562384963035583, train/raw-loss = 0.28935790061950684, train/logprobs = tensor([[-0.8571, -6.4462],
        [-1.3563, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626592516899109
Epoch 0, Step 479: train/loss = 0.3035427927970886, train/raw-loss = 0.27778160572052, train/logprobs = tensor([[-1.0202, -4.8666],
        [-1.4227, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25761178135871887
Epoch 0, Step 480: train/loss = 0.4989815652370453, train/raw-loss = 0.47689327597618103, train/logprobs = tensor([[-0.5791, -2.6563],
        [-1.1048, -1.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22088298201560974
Epoch 0, Step 481: train/loss = 0.5164933204650879, train/raw-loss = 0.48998695611953735, train/logprobs = tensor([[-0.7472, -2.0553],
        [-1.3284, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26506370306015015
Epoch 0, Step 482: train/loss = 0.49122554063796997, train/raw-loss = 0.4715307354927063, train/logprobs = tensor([[-0.5477, -3.6115],
        [-0.7703, -0.4375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19694821536540985
Epoch 0, Step 483: train/loss = 0.26553043723106384, train/raw-loss = 0.24251069128513336, train/logprobs = tensor([[-0.7928, -4.8531],
        [-1.1961, -0.6417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.230197474360466
Epoch 0, Step 484: train/loss = 0.30845460295677185, train/raw-loss = 0.2874126434326172, train/logprobs = tensor([[-0.5384, -4.8913],
        [-1.2250, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21041980385780334
Epoch 0, Step 485: train/loss = 0.2354522943496704, train/raw-loss = 0.20954358577728271, train/logprobs = tensor([[-0.8033, -4.1889],
        [-1.9551, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25908687710762024
Epoch 0, Step 486: train/loss = 0.28037455677986145, train/raw-loss = 0.2565862834453583, train/logprobs = tensor([[-0.6882, -4.9270],
        [-1.4303, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2378827929496765
Epoch 0, Step 487: train/loss = 0.5168047547340393, train/raw-loss = 0.4922201633453369, train/logprobs = tensor([[-0.6837, -1.5460],
        [-1.1382, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24584533274173737
Epoch 0, Step 488: train/loss = 0.44727373123168945, train/raw-loss = 0.4221593737602234, train/logprobs = tensor([[-1.5469, -4.1649],
        [-1.8174, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511436939239502
Epoch 0, Step 489: train/loss = 0.2866278290748596, train/raw-loss = 0.2629871964454651, train/logprobs = tensor([[-0.6229, -2.8629],
        [-1.6261, -0.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23640620708465576
Epoch 0, Step 490: train/loss = 0.2444063276052475, train/raw-loss = 0.216172993183136, train/logprobs = tensor([[-0.8532, -5.4683],
        [-1.6474, -0.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28233352303504944
Epoch 0, Step 491: train/loss = 0.5679608583450317, train/raw-loss = 0.5446456074714661, train/logprobs = tensor([[-0.5944, -1.1500],
        [-1.1416, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23315197229385376
Epoch 0, Step 492: train/loss = 0.7626241445541382, train/raw-loss = 0.7372243404388428, train/logprobs = tensor([[-1.8889, -3.9375],
        [-1.2864, -1.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25399816036224365
Epoch 0, Step 493: train/loss = 0.28728896379470825, train/raw-loss = 0.26296812295913696, train/logprobs = tensor([[-0.8624, -7.3519],
        [-1.4363, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24320808053016663
Epoch 0, Step 494: train/loss = 0.4061604142189026, train/raw-loss = 0.3787377178668976, train/logprobs = tensor([[-0.8117, -2.8829],
        [-1.2025, -1.2498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742269039154053
Epoch 0, Step 495: train/loss = 0.42923328280448914, train/raw-loss = 0.4074999988079071, train/logprobs = tensor([[-0.7440, -2.4488],
        [-0.8821, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21733255684375763
Epoch 0, Step 496: train/loss = 0.3476695418357849, train/raw-loss = 0.321571409702301, train/logprobs = tensor([[-0.7693, -4.1310],
        [-1.3766, -0.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609817087650299
Epoch 0, Step 497: train/loss = 0.4456615149974823, train/raw-loss = 0.41836750507354736, train/logprobs = tensor([[-0.7198, -2.4867],
        [-1.3662, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27293992042541504
Epoch 0, Step 498: train/loss = 0.4157392084598541, train/raw-loss = 0.3899992108345032, train/logprobs = tensor([[-0.7112, -4.3907],
        [-1.2384, -1.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2574000060558319
Epoch 0, Step 499: train/loss = 0.4009419083595276, train/raw-loss = 0.37150099873542786, train/logprobs = tensor([[-1.0027, -3.7156],
        [-1.3285, -0.9839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29440873861312866
Epoch 0, Step 500: train/loss = 0.5357973575592041, train/raw-loss = 0.5109999179840088, train/logprobs = tensor([[-0.7742, -1.7644],
        [-1.1378, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24797466397285461
Epoch 0, Step 501: train/loss = 0.4687887728214264, train/raw-loss = 0.4433654844760895, train/logprobs = tensor([[-0.9700, -2.1752],
        [-1.5941, -1.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542327046394348
Epoch 0, Step 502: train/loss = 0.2985500395298004, train/raw-loss = 0.2729765772819519, train/logprobs = tensor([[-0.8473, -4.6105],
        [-1.2702, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25573453307151794
Epoch 0, Step 503: train/loss = 0.6268537044525146, train/raw-loss = 0.5986877679824829, train/logprobs = tensor([[-0.8697, -1.8368],
        [-0.9167, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281659334897995
Epoch 0, Step 504: train/loss = 0.5893436074256897, train/raw-loss = 0.5639485120773315, train/logprobs = tensor([[-1.3860, -2.3158],
        [-1.2891, -0.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2539508640766144
Epoch 0, Step 505: train/loss = 0.3425277769565582, train/raw-loss = 0.3197973072528839, train/logprobs = tensor([[-0.7098, -4.6022],
        [-1.0990, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273045778274536
Epoch 0, Step 506: train/loss = 0.578311026096344, train/raw-loss = 0.5556928515434265, train/logprobs = tensor([[-0.6422, -0.9364],
        [-0.9512, -0.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2261819690465927
Epoch 0, Step 507: train/loss = 0.47810065746307373, train/raw-loss = 0.4567233622074127, train/logprobs = tensor([[-0.7068, -2.0223],
        [-1.3096, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21377280354499817
Epoch 0, Step 508: train/loss = 0.5578402876853943, train/raw-loss = 0.5317728519439697, train/logprobs = tensor([[-1.2695, -4.5148],
        [-1.2321, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26067474484443665
Epoch 0, Step 509: train/loss = 0.5670732855796814, train/raw-loss = 0.5383198857307434, train/logprobs = tensor([[-1.1213, -1.4118],
        [-1.5406, -0.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875341773033142
Epoch 0, Step 510: train/loss = 0.2638612985610962, train/raw-loss = 0.23588845133781433, train/logprobs = tensor([[-1.0249, -6.7604],
        [-1.5552, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27972841262817383
Epoch 0, Step 511: train/loss = 0.4509828984737396, train/raw-loss = 0.42681339383125305, train/logprobs = tensor([[-0.6104, -4.9340],
        [-0.8250, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2416948825120926
Epoch 0, Step 512: train/loss = 0.7110069990158081, train/raw-loss = 0.6835103631019592, train/logprobs = tensor([[-1.7631, -4.5581],
        [-1.2141, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749665379524231
Epoch 0, Step 513: train/loss = 0.35457420349121094, train/raw-loss = 0.3292151987552643, train/logprobs = tensor([[-0.7649, -5.1299],
        [-1.4250, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535899579524994
Epoch 0, Step 514: train/loss = 0.412286639213562, train/raw-loss = 0.3847465217113495, train/logprobs = tensor([[-0.8036, -3.8613],
        [-1.4898, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27540120482444763
Epoch 0, Step 515: train/loss = 0.4297027587890625, train/raw-loss = 0.40401193499565125, train/logprobs = tensor([[-0.7014, -2.6442],
        [-1.4485, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2569082975387573
Epoch 0, Step 516: train/loss = 0.5612145662307739, train/raw-loss = 0.5334630608558655, train/logprobs = tensor([[-0.6065, -1.6138],
        [-1.2964, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27751481533050537
Epoch 0, Step 517: train/loss = 0.5892393589019775, train/raw-loss = 0.5616447329521179, train/logprobs = tensor([[-1.5351, -3.9379],
        [-1.5934, -1.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27594587206840515
Epoch 0, Step 518: train/loss = 0.4563639461994171, train/raw-loss = 0.43405911326408386, train/logprobs = tensor([[-0.5295, -3.0756],
        [-1.0262, -0.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22304803133010864
Epoch 0, Step 519: train/loss = 0.3187263607978821, train/raw-loss = 0.29083821177482605, train/logprobs = tensor([[-1.1123, -7.7475],
        [-1.6098, -1.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788814902305603
Epoch 0, Step 520: train/loss = 0.3879238963127136, train/raw-loss = 0.36309194564819336, train/logprobs = tensor([[-0.6095, -4.9500],
        [-1.2022, -1.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24831953644752502
Epoch 0, Step 521: train/loss = 0.29772496223449707, train/raw-loss = 0.2743011713027954, train/logprobs = tensor([[-0.6859, -4.2465],
        [-1.1922, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23423807322978973
Epoch 0, Step 522: train/loss = 0.42945581674575806, train/raw-loss = 0.4034167230129242, train/logprobs = tensor([[-0.5903, -2.2051],
        [-1.2668, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2603907585144043
Epoch 0, Step 523: train/loss = 0.41248413920402527, train/raw-loss = 0.3850158154964447, train/logprobs = tensor([[-0.9085, -2.6985],
        [-1.6951, -0.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746829688549042
Epoch 0, Step 524: train/loss = 0.33527183532714844, train/raw-loss = 0.30728641152381897, train/logprobs = tensor([[-0.7413, -4.9938],
        [-1.4778, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798542380332947
Epoch 0, Step 525: train/loss = 0.3137948513031006, train/raw-loss = 0.28981152176856995, train/logprobs = tensor([[-0.8027, -4.4929],
        [-1.2104, -0.7754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23983325064182281
Epoch 0, Step 526: train/loss = 0.44260093569755554, train/raw-loss = 0.4165835380554199, train/logprobs = tensor([[-0.6655, -2.0697],
        [-1.1793, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601739168167114
Epoch 0, Step 527: train/loss = 0.47720885276794434, train/raw-loss = 0.45230206847190857, train/logprobs = tensor([[-0.5883, -2.7246],
        [-1.0770, -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24906766414642334
Epoch 0, Step 528: train/loss = 0.40586477518081665, train/raw-loss = 0.3844048082828522, train/logprobs = tensor([[-0.7250, -5.3718],
        [-1.1548, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21459969878196716
Epoch 0, Step 529: train/loss = 0.2800137400627136, train/raw-loss = 0.25336316227912903, train/logprobs = tensor([[-1.1360, -3.3254],
        [-1.6703, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665061056613922
Epoch 0, Step 530: train/loss = 0.495169460773468, train/raw-loss = 0.46733590960502625, train/logprobs = tensor([[-0.7857, -2.9653],
        [-1.4633, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27833545207977295
Epoch 0, Step 531: train/loss = 0.3863551914691925, train/raw-loss = 0.3605183959007263, train/logprobs = tensor([[-0.5811, -4.8558],
        [-1.2242, -1.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583681643009186
Epoch 0, Step 532: train/loss = 0.46254634857177734, train/raw-loss = 0.4416632056236267, train/logprobs = tensor([[-0.5420, -2.6951],
        [-0.8659, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088315188884735
Epoch 0, Step 533: train/loss = 0.471738338470459, train/raw-loss = 0.43998342752456665, train/logprobs = tensor([[-0.8252, -2.3881],
        [-2.0882, -1.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175491690635681
Epoch 0, Step 534: train/loss = 0.23006972670555115, train/raw-loss = 0.20448268949985504, train/logprobs = tensor([[-0.7082, -6.0546],
        [-1.3524, -1.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255870521068573
Epoch 0, Step 535: train/loss = 0.26773154735565186, train/raw-loss = 0.24049043655395508, train/logprobs = tensor([[-1.0674, -4.8686],
        [-1.5755, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27241119742393494
Epoch 0, Step 536: train/loss = 0.4405571222305298, train/raw-loss = 0.41685932874679565, train/logprobs = tensor([[ -1.4204, -10.4568],
        [ -0.9875,  -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23697784543037415
Epoch 0, Step 537: train/loss = 0.33233386278152466, train/raw-loss = 0.3070916533470154, train/logprobs = tensor([[-0.9274, -2.9853],
        [-1.8565, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524220943450928
Epoch 0, Step 538: train/loss = 0.49391669034957886, train/raw-loss = 0.46552708745002747, train/logprobs = tensor([[-1.0089, -2.4965],
        [-1.4717, -1.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838960886001587
Epoch 0, Step 539: train/loss = 0.7442575693130493, train/raw-loss = 0.7187079191207886, train/logprobs = tensor([[-1.6670, -2.7893],
        [-0.8171, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25549644231796265
Epoch 0, Step 540: train/loss = 0.5700795650482178, train/raw-loss = 0.5458391308784485, train/logprobs = tensor([[-0.7575, -1.8525],
        [-1.2061, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24240434169769287
Epoch 0, Step 541: train/loss = 0.2525249719619751, train/raw-loss = 0.22918152809143066, train/logprobs = tensor([[-0.7082, -3.1664],
        [-1.8424, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23343461751937866
Epoch 0, Step 542: train/loss = 0.3291727900505066, train/raw-loss = 0.3018427789211273, train/logprobs = tensor([[-0.5646, -4.5800],
        [-1.6990, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2733001708984375
Epoch 0, Step 543: train/loss = 0.5734990239143372, train/raw-loss = 0.551259458065033, train/logprobs = tensor([[-0.5351, -1.6080],
        [-0.8028, -0.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22239559888839722
Epoch 0, Step 544: train/loss = 0.3815186619758606, train/raw-loss = 0.3534401059150696, train/logprobs = tensor([[-0.7894, -2.0234],
        [-1.5893, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280785471200943
Epoch 0, Step 545: train/loss = 0.23365433514118195, train/raw-loss = 0.20568761229515076, train/logprobs = tensor([[-1.2279, -8.2730],
        [-2.1946, -1.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2796671688556671
Epoch 0, Step 546: train/loss = 0.2813335061073303, train/raw-loss = 0.25785717368125916, train/logprobs = tensor([[-0.6084, -3.9383],
        [-1.6349, -0.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23476329445838928
Epoch 0, Step 547: train/loss = 0.6714349985122681, train/raw-loss = 0.646580159664154, train/logprobs = tensor([[-2.7427, -8.5810],
        [-2.0529, -2.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24854819476604462
Epoch 0, Step 548: train/loss = 0.5783100128173828, train/raw-loss = 0.5518385767936707, train/logprobs = tensor([[-0.6417, -1.7158],
        [-1.2230, -1.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26471471786499023
Epoch 0, Step 549: train/loss = 0.3929656744003296, train/raw-loss = 0.3669099509716034, train/logprobs = tensor([[-0.6364, -2.4160],
        [-1.4166, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26055747270584106
Epoch 0, Step 550: train/loss = 0.3413008153438568, train/raw-loss = 0.32074248790740967, train/logprobs = tensor([[-0.6746, -2.8640],
        [-1.2499, -0.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20558300614356995
Epoch 0, Step 551: train/loss = 0.5298701524734497, train/raw-loss = 0.49950137734413147, train/logprobs = tensor([[-1.0099, -2.7134],
        [-1.2178, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30368784070014954
Epoch 0, Step 552: train/loss = 0.35035181045532227, train/raw-loss = 0.32771775126457214, train/logprobs = tensor([[-0.5933, -2.9684],
        [-1.4405, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22634068131446838
Epoch 0, Step 553: train/loss = 0.5984470844268799, train/raw-loss = 0.5820738673210144, train/logprobs = tensor([[-0.5248, -0.4381],
        [-0.8772, -0.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16373184323310852
Epoch 0, Step 554: train/loss = 0.3671420216560364, train/raw-loss = 0.3376060426235199, train/logprobs = tensor([[-0.8441, -3.0710],
        [-1.8993, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29535973072052
Epoch 0, Step 555: train/loss = 0.2687263786792755, train/raw-loss = 0.24637524783611298, train/logprobs = tensor([[-0.5198, -4.5702],
        [-1.0895, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22351130843162537
Epoch 0, Step 556: train/loss = 0.452738881111145, train/raw-loss = 0.4271272122859955, train/logprobs = tensor([[-0.6768, -2.2284],
        [-1.3163, -1.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561168670654297
Epoch 0, Step 557: train/loss = 0.5399875640869141, train/raw-loss = 0.5204143524169922, train/logprobs = tensor([[-0.4685, -1.8947],
        [-0.9785, -0.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1957322210073471
Epoch 0, Step 558: train/loss = 0.5857414603233337, train/raw-loss = 0.5594578385353088, train/logprobs = tensor([[-0.6505, -1.0754],
        [-1.2627, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2628359794616699
Epoch 0, Step 559: train/loss = 0.29808861017227173, train/raw-loss = 0.2696682810783386, train/logprobs = tensor([[-1.3162, -3.6863],
        [-2.2755, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842032313346863
Epoch 0, Step 560: train/loss = 0.46351826190948486, train/raw-loss = 0.43402665853500366, train/logprobs = tensor([[-0.8677, -2.9004],
        [-1.4190, -0.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29491615295410156
Epoch 0, Step 561: train/loss = 0.4373975396156311, train/raw-loss = 0.4083830416202545, train/logprobs = tensor([[-0.9254, -2.2181],
        [-1.3862, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2901448607444763
Epoch 0, Step 562: train/loss = 0.26068565249443054, train/raw-loss = 0.23409917950630188, train/logprobs = tensor([[-0.8920, -4.9499],
        [-1.4307, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26586470007896423
Epoch 0, Step 563: train/loss = 0.38285595178604126, train/raw-loss = 0.3600376844406128, train/logprobs = tensor([[-0.6321, -1.9068],
        [-1.5382, -0.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22818273305892944
Epoch 0, Step 564: train/loss = 0.2170705944299698, train/raw-loss = 0.18801209330558777, train/logprobs = tensor([[-1.2298, -7.9006],
        [-2.0164, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.290584921836853
Epoch 0, Step 565: train/loss = 0.3219169080257416, train/raw-loss = 0.29587414860725403, train/logprobs = tensor([[-0.7852, -3.4315],
        [-1.7752, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26042765378952026
Epoch 0, Step 566: train/loss = 0.39180031418800354, train/raw-loss = 0.3624832034111023, train/logprobs = tensor([[-1.0406, -6.0969],
        [-1.9689, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931710481643677
Epoch 0, Step 567: train/loss = 0.5064563155174255, train/raw-loss = 0.4837969243526459, train/logprobs = tensor([[-0.6232, -3.2433],
        [-0.8891, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2265939712524414
Epoch 0, Step 568: train/loss = 0.2996485233306885, train/raw-loss = 0.2743605971336365, train/logprobs = tensor([[-0.8539, -6.6568],
        [-1.7632, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25287944078445435
Epoch 0, Step 569: train/loss = 0.5040799379348755, train/raw-loss = 0.47786664962768555, train/logprobs = tensor([[-0.5837, -2.0250],
        [-1.5227, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262132853269577
Epoch 0, Step 570: train/loss = 0.43198662996292114, train/raw-loss = 0.41273510456085205, train/logprobs = tensor([[-0.5903, -5.8222],
        [-0.6876, -1.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19251513481140137
Epoch 0, Step 571: train/loss = 0.5057482719421387, train/raw-loss = 0.4768351912498474, train/logprobs = tensor([[-1.2898, -3.6730],
        [-1.7988, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28913095593452454
Epoch 0, Step 572: train/loss = 0.514739990234375, train/raw-loss = 0.4916496276855469, train/logprobs = tensor([[-0.6352, -1.4204],
        [-1.1720, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23090378940105438
Epoch 0, Step 573: train/loss = 0.33282843232154846, train/raw-loss = 0.3065018951892853, train/logprobs = tensor([[-0.9745, -3.7471],
        [-1.8976, -0.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632652521133423
Epoch 0, Step 574: train/loss = 0.40221062302589417, train/raw-loss = 0.3756936490535736, train/logprobs = tensor([[-0.8929, -3.8809],
        [-1.6962, -0.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651696801185608
Epoch 0, Step 575: train/loss = 0.3510415256023407, train/raw-loss = 0.32639288902282715, train/logprobs = tensor([[-0.7420, -5.1220],
        [-1.2846, -1.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464863359928131
Epoch 0, Step 576: train/loss = 0.2859078049659729, train/raw-loss = 0.25816038250923157, train/logprobs = tensor([[-0.6941, -6.8125],
        [-1.6452, -1.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27747419476509094
Epoch 0, Step 577: train/loss = 0.4631430506706238, train/raw-loss = 0.4340001344680786, train/logprobs = tensor([[-0.9842, -1.8731],
        [-1.5471, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914292812347412
Epoch 0, Step 578: train/loss = 0.3036043643951416, train/raw-loss = 0.27414995431900024, train/logprobs = tensor([[-0.7848, -2.9153],
        [-2.4944, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945442199707031
Epoch 0, Step 579: train/loss = 0.2556736171245575, train/raw-loss = 0.2302461415529251, train/logprobs = tensor([[-0.6276, -4.0219],
        [-1.5810, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25427478551864624
Epoch 0, Step 580: train/loss = 0.5663061141967773, train/raw-loss = 0.5355413556098938, train/logprobs = tensor([[-1.1166, -3.5012],
        [-1.8652, -1.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3076474368572235
Epoch 0, Step 581: train/loss = 0.5833544731140137, train/raw-loss = 0.5522752404212952, train/logprobs = tensor([[-0.6994, -1.9987],
        [-1.4289, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107926845550537
Epoch 0, Step 582: train/loss = 0.2129725217819214, train/raw-loss = 0.18918097019195557, train/logprobs = tensor([[-0.7633, -7.4487],
        [-1.8323, -1.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2379155158996582
Epoch 0, Step 583: train/loss = 0.5152935981750488, train/raw-loss = 0.4927380681037903, train/logprobs = tensor([[-0.5756, -2.2517],
        [-0.9930, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22555556893348694
Epoch 0, Step 584: train/loss = 0.4676762819290161, train/raw-loss = 0.4407964050769806, train/logprobs = tensor([[-0.6209, -2.0527],
        [-1.3203, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687990963459015
Epoch 0, Step 585: train/loss = 0.4682714343070984, train/raw-loss = 0.43865057826042175, train/logprobs = tensor([[-0.8609, -2.5638],
        [-1.5639, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2962086498737335
Epoch 0, Step 586: train/loss = 0.3153389096260071, train/raw-loss = 0.2919906973838806, train/logprobs = tensor([[-0.6481, -5.7811],
        [-1.5522, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23348228633403778
Epoch 0, Step 587: train/loss = 0.34451961517333984, train/raw-loss = 0.32038384675979614, train/logprobs = tensor([[-0.5945, -3.0462],
        [-1.1980, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2413577437400818
Epoch 0, Step 588: train/loss = 0.45421433448791504, train/raw-loss = 0.42657214403152466, train/logprobs = tensor([[-0.6575, -5.1390],
        [-1.9821, -1.3710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27642181515693665
Epoch 0, Step 589: train/loss = 0.2024332880973816, train/raw-loss = 0.17558005452156067, train/logprobs = tensor([[-0.8827, -7.4896],
        [-2.0049, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26853224635124207
Epoch 0, Step 590: train/loss = 0.41203340888023376, train/raw-loss = 0.37744611501693726, train/logprobs = tensor([[-0.9498, -3.1750],
        [-1.7336, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34587234258651733
Epoch 0, Step 591: train/loss = 0.6892443895339966, train/raw-loss = 0.658009946346283, train/logprobs = tensor([[-0.5082, -0.9337],
        [-1.3561, -1.4549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31234458088874817
Epoch 0, Step 592: train/loss = 0.6603831052780151, train/raw-loss = 0.6342807412147522, train/logprobs = tensor([[-1.6204, -2.5119],
        [-1.8126, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610239088535309
Epoch 0, Step 593: train/loss = 0.5167757272720337, train/raw-loss = 0.4949893057346344, train/logprobs = tensor([[-0.4404, -1.8320],
        [-1.1599, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2178644835948944
Epoch 0, Step 594: train/loss = 0.4116275906562805, train/raw-loss = 0.38916632533073425, train/logprobs = tensor([[-0.9599, -7.7810],
        [-1.6621, -1.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224613219499588
Epoch 0, Step 595: train/loss = 0.3523099422454834, train/raw-loss = 0.32191914319992065, train/logprobs = tensor([[-1.0958, -3.2015],
        [-2.3186, -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30390822887420654
Epoch 0, Step 596: train/loss = 0.33631548285484314, train/raw-loss = 0.3085022270679474, train/logprobs = tensor([[-0.6632, -2.1020],
        [-1.8971, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781327962875366
Epoch 0, Step 597: train/loss = 0.14741173386573792, train/raw-loss = 0.11664433777332306, train/logprobs = tensor([[-0.7330, -4.9471],
        [-2.5135, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.307673841714859
Epoch 0, Step 598: train/loss = 0.5231072902679443, train/raw-loss = 0.4998219609260559, train/logprobs = tensor([[-0.4876, -3.0409],
        [-1.1968, -1.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23285335302352905
Epoch 0, Step 599: train/loss = 0.4709841012954712, train/raw-loss = 0.44618427753448486, train/logprobs = tensor([[-0.8295, -2.1487],
        [-1.3602, -1.1579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24799838662147522
Epoch 0, Step 600: train/loss = 0.2808926999568939, train/raw-loss = 0.25581738352775574, train/logprobs = tensor([[-0.8542, -3.7261],
        [-1.8682, -0.4772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507530748844147
Epoch 0, Step 601: train/loss = 0.443878710269928, train/raw-loss = 0.40907448530197144, train/logprobs = tensor([[-0.9168, -1.9317],
        [-1.8466, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34804192185401917
Epoch 0, Step 602: train/loss = 0.2994425892829895, train/raw-loss = 0.27306225895881653, train/logprobs = tensor([[-0.7141, -3.6652],
        [-1.5900, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26380330324172974
Epoch 0, Step 603: train/loss = 0.4140278398990631, train/raw-loss = 0.3842918276786804, train/logprobs = tensor([[-0.6917, -1.6146],
        [-2.3137, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2973601222038269
Epoch 0, Step 604: train/loss = 0.4215396046638489, train/raw-loss = 0.39276939630508423, train/logprobs = tensor([[-0.8269, -3.8549],
        [-1.0913, -1.3188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877015769481659
Epoch 0, Step 605: train/loss = 0.46441468596458435, train/raw-loss = 0.4342676103115082, train/logprobs = tensor([[-0.6464, -2.5840],
        [-1.9854, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3014707565307617
Epoch 0, Step 606: train/loss = 0.5195268392562866, train/raw-loss = 0.4951350688934326, train/logprobs = tensor([[-0.8735, -1.5937],
        [-1.5420, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24391818046569824
Epoch 0, Step 607: train/loss = 0.24703499674797058, train/raw-loss = 0.22362372279167175, train/logprobs = tensor([[-0.6096, -6.0961],
        [-1.3972, -0.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23411276936531067
Epoch 0, Step 608: train/loss = 0.8643848896026611, train/raw-loss = 0.8397793769836426, train/logprobs = tensor([[-1.9894, -2.2787],
        [-1.0616, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2460552155971527
Epoch 0, Step 609: train/loss = 0.3021293878555298, train/raw-loss = 0.2786223292350769, train/logprobs = tensor([[-0.7903, -6.3608],
        [-1.6707, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2350705862045288
Epoch 0, Step 610: train/loss = 0.3262786865234375, train/raw-loss = 0.2958405315876007, train/logprobs = tensor([[-1.1822, -5.6955],
        [-1.9245, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043816387653351
Epoch 0, Step 611: train/loss = 0.36679360270500183, train/raw-loss = 0.33478420972824097, train/logprobs = tensor([[-0.6752, -3.5404],
        [-2.3550, -1.3742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200938105583191
Epoch 0, Step 612: train/loss = 0.7106262445449829, train/raw-loss = 0.6839051842689514, train/logprobs = tensor([[-0.6377, -0.8873],
        [-1.7057, -1.6140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26721012592315674
Epoch 0, Step 613: train/loss = 0.24189390242099762, train/raw-loss = 0.21312293410301208, train/logprobs = tensor([[-0.7179, -5.5857],
        [-2.3365, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28770971298217773
Epoch 0, Step 614: train/loss = 0.4830627739429474, train/raw-loss = 0.45480769872665405, train/logprobs = tensor([[-0.8973, -1.4501],
        [-1.8178, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2825508713722229
Epoch 0, Step 615: train/loss = 0.4385852515697479, train/raw-loss = 0.41596078872680664, train/logprobs = tensor([[-0.4001, -3.3579],
        [-0.9177, -0.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22624465823173523
Epoch 0, Step 616: train/loss = 0.3958471417427063, train/raw-loss = 0.3636845052242279, train/logprobs = tensor([[-0.9543, -3.8312],
        [-2.4905, -2.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3216262459754944
Epoch 0, Step 617: train/loss = 0.35648947954177856, train/raw-loss = 0.33077406883239746, train/logprobs = tensor([[-0.8808, -2.6833],
        [-1.9856, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25715410709381104
Epoch 0, Step 618: train/loss = 0.20814871788024902, train/raw-loss = 0.18200227618217468, train/logprobs = tensor([[-0.6594, -4.2210],
        [-1.6464, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614646553993225
Epoch 0, Step 619: train/loss = 0.45637941360473633, train/raw-loss = 0.42880570888519287, train/logprobs = tensor([[-0.7871, -2.0379],
        [-1.4879, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757372260093689
Epoch 0, Step 620: train/loss = 0.4864206314086914, train/raw-loss = 0.46468570828437805, train/logprobs = tensor([[-0.9292, -4.0698],
        [-1.0579, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21734951436519623
Epoch 0, Step 621: train/loss = 0.371202677488327, train/raw-loss = 0.3456745147705078, train/logprobs = tensor([[-0.9863, -1.9469],
        [-2.0454, -0.9882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25528186559677124
Epoch 0, Step 622: train/loss = 0.41923582553863525, train/raw-loss = 0.3940081000328064, train/logprobs = tensor([[-0.7606, -2.8607],
        [-1.4831, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522774934768677
Epoch 0, Step 623: train/loss = 0.3112589418888092, train/raw-loss = 0.2883528769016266, train/logprobs = tensor([[-0.6047, -4.6818],
        [-1.3286, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22906070947647095
Epoch 0, Step 624: train/loss = 0.7572548985481262, train/raw-loss = 0.7295700311660767, train/logprobs = tensor([[-0.9020, -1.0153],
        [-1.3752, -1.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2768486440181732
Epoch 0, Step 625: train/loss = 0.5350573658943176, train/raw-loss = 0.5045086145401001, train/logprobs = tensor([[-0.8516, -1.8953],
        [-1.9631, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054876923561096
Epoch 0, Step 626: train/loss = 0.6354714632034302, train/raw-loss = 0.6038854122161865, train/logprobs = tensor([[-1.9833, -3.4649],
        [-1.8663, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31586015224456787
Epoch 0, Step 627: train/loss = 0.2694072127342224, train/raw-loss = 0.23950539529323578, train/logprobs = tensor([[-0.9530, -5.0017],
        [-2.3690, -0.7052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29901817440986633
Epoch 0, Step 628: train/loss = 0.36619365215301514, train/raw-loss = 0.3362088203430176, train/logprobs = tensor([[-0.8132, -2.6107],
        [-1.9262, -1.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998485267162323
Epoch 0, Step 629: train/loss = 0.6626244187355042, train/raw-loss = 0.6354128122329712, train/logprobs = tensor([[-0.5684, -2.1771],
        [-1.2267, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27211612462997437
Epoch 0, Step 630: train/loss = 0.5244429707527161, train/raw-loss = 0.4976818561553955, train/logprobs = tensor([[-0.6306, -3.0727],
        [-1.5651, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26761096715927124
Epoch 0, Step 631: train/loss = 0.24542582035064697, train/raw-loss = 0.21413779258728027, train/logprobs = tensor([[-0.9001, -5.0987],
        [-2.7737, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3128802180290222
Epoch 0, Step 632: train/loss = 0.3502146601676941, train/raw-loss = 0.3212490677833557, train/logprobs = tensor([[-0.8210, -5.6429],
        [-2.6948, -1.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896559238433838
Epoch 0, Step 633: train/loss = 0.3143717050552368, train/raw-loss = 0.2900122106075287, train/logprobs = tensor([[-0.9849, -2.9262],
        [-2.2525, -1.4805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24359506368637085
Epoch 0, Step 634: train/loss = 0.5084635019302368, train/raw-loss = 0.4835593104362488, train/logprobs = tensor([[-0.7157, -2.7056],
        [-1.4073, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24904224276542664
Epoch 0, Step 635: train/loss = 0.4208793640136719, train/raw-loss = 0.3981771171092987, train/logprobs = tensor([[-0.5627, -2.4819],
        [-1.3584, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22702239453792572
Epoch 0, Step 636: train/loss = 1.488796353340149, train/raw-loss = 1.4659169912338257, train/logprobs = tensor([[-5.1614, -8.4263],
        [-0.9249, -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22879311442375183
Epoch 0, Step 637: train/loss = 0.34027060866355896, train/raw-loss = 0.31278759241104126, train/logprobs = tensor([[-0.6825, -3.1302],
        [-1.5873, -0.5948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.274830162525177
Epoch 0, Step 638: train/loss = 0.7139701843261719, train/raw-loss = 0.6813117265701294, train/logprobs = tensor([[-0.9492, -0.9418],
        [-2.1503, -1.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32658445835113525
Epoch 0, Step 639: train/loss = 0.44553619623184204, train/raw-loss = 0.4107656180858612, train/logprobs = tensor([[-0.7664, -3.3584],
        [-2.3054, -1.3511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477054536342621
Epoch 0, Step 640: train/loss = 0.26441824436187744, train/raw-loss = 0.23888303339481354, train/logprobs = tensor([[-0.7061, -4.3388],
        [-1.8978, -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553521394729614
Epoch 0, Step 641: train/loss = 0.35037943720817566, train/raw-loss = 0.32374048233032227, train/logprobs = tensor([[-0.6011, -5.6724],
        [-1.4639, -2.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663894295692444
Epoch 0, Step 642: train/loss = 0.5067825317382812, train/raw-loss = 0.4809581935405731, train/logprobs = tensor([[-0.5569, -2.2412],
        [-1.4861, -1.4124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2582438588142395
Epoch 0, Step 643: train/loss = 0.4410732686519623, train/raw-loss = 0.40952828526496887, train/logprobs = tensor([[-1.2600, -2.8738],
        [-2.1731, -1.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31544989347457886
Epoch 0, Step 644: train/loss = 0.2806651294231415, train/raw-loss = 0.2518424689769745, train/logprobs = tensor([[-0.7367, -4.2743],
        [-2.3242, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2882266342639923
Epoch 0, Step 645: train/loss = 0.19705744087696075, train/raw-loss = 0.1702621877193451, train/logprobs = tensor([[-0.7301, -7.7898],
        [-2.0537, -1.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679526209831238
Epoch 0, Step 646: train/loss = 0.33756887912750244, train/raw-loss = 0.3086278438568115, train/logprobs = tensor([[-0.8284, -2.7759],
        [-1.9578, -0.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28941044211387634
Epoch 0, Step 647: train/loss = 0.28623420000076294, train/raw-loss = 0.2526051700115204, train/logprobs = tensor([[-0.7340, -3.2798],
        [-2.3758, -1.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.336290180683136
Epoch 0, Step 648: train/loss = 0.4065437316894531, train/raw-loss = 0.3781905174255371, train/logprobs = tensor([[-0.7110, -2.8733],
        [-1.6703, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2835320830345154
Epoch 0, Step 649: train/loss = 0.2915465831756592, train/raw-loss = 0.2647543251514435, train/logprobs = tensor([[-0.8384, -4.3860],
        [-2.1123, -2.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26792237162590027
Epoch 0, Step 650: train/loss = 0.40185388922691345, train/raw-loss = 0.37368789315223694, train/logprobs = tensor([[-0.7168, -3.0516],
        [-1.6710, -1.1591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28165972232818604
Epoch 0, Step 651: train/loss = 0.44116201996803284, train/raw-loss = 0.41653838753700256, train/logprobs = tensor([[-0.4998, -4.0260],
        [-1.3032, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2462363839149475
Epoch 0, Step 652: train/loss = 0.2597886919975281, train/raw-loss = 0.233403742313385, train/logprobs = tensor([[-0.6091, -5.5407],
        [-1.4749, -0.6138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638494372367859
Epoch 0, Step 653: train/loss = 0.24265184998512268, train/raw-loss = 0.2164052426815033, train/logprobs = tensor([[-0.6112, -4.3560],
        [-1.5080, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262466162443161
Epoch 0, Step 654: train/loss = 0.5166548490524292, train/raw-loss = 0.49028754234313965, train/logprobs = tensor([[-1.0424, -3.6588],
        [-0.8861, -0.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2636733055114746
Epoch 0, Step 655: train/loss = 0.3676581382751465, train/raw-loss = 0.339968204498291, train/logprobs = tensor([[-1.3243, -5.6788],
        [-2.6013, -1.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2768990993499756
Epoch 0, Step 656: train/loss = 0.4774782061576843, train/raw-loss = 0.4502469599246979, train/logprobs = tensor([[-0.8912, -2.3688],
        [-1.7824, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27231284976005554
Epoch 0, Step 657: train/loss = 0.46840882301330566, train/raw-loss = 0.44034093618392944, train/logprobs = tensor([[-1.0338, -3.7893],
        [-1.7959, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28067880868911743
Epoch 0, Step 658: train/loss = 0.4576215147972107, train/raw-loss = 0.42445412278175354, train/logprobs = tensor([[-0.8654, -3.4703],
        [-2.1038, -1.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331673800945282
Epoch 0, Step 659: train/loss = 0.4412190616130829, train/raw-loss = 0.414791464805603, train/logprobs = tensor([[-0.7943, -3.8744],
        [-1.1400, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642761468887329
Epoch 0, Step 660: train/loss = 0.5272014141082764, train/raw-loss = 0.5001654624938965, train/logprobs = tensor([[-1.4555, -3.4281],
        [-1.7408, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703595459461212
Epoch 0, Step 661: train/loss = 0.40624138712882996, train/raw-loss = 0.38028430938720703, train/logprobs = tensor([[-1.0619, -7.1416],
        [-1.4379, -2.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25957047939300537
Epoch 0, Step 662: train/loss = 0.41849178075790405, train/raw-loss = 0.3913578987121582, train/logprobs = tensor([[-0.9833, -5.0014],
        [-2.7078, -2.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713389992713928
Epoch 0, Step 663: train/loss = 0.29271620512008667, train/raw-loss = 0.2631603479385376, train/logprobs = tensor([[-0.7382, -5.1904],
        [-1.5924, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955586910247803
Epoch 0, Step 664: train/loss = 0.4824836850166321, train/raw-loss = 0.4570804238319397, train/logprobs = tensor([[-1.0584, -4.1243],
        [-1.7939, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540324926376343
Epoch 0, Step 665: train/loss = 0.44731059670448303, train/raw-loss = 0.4181750416755676, train/logprobs = tensor([[-0.9390, -2.5653],
        [-2.0675, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291355162858963
Epoch 0, Step 666: train/loss = 0.8517093062400818, train/raw-loss = 0.8240190744400024, train/logprobs = tensor([[-1.6013, -4.5204],
        [-0.9654, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27690228819847107
Epoch 0, Step 667: train/loss = 0.4270339012145996, train/raw-loss = 0.3981024920940399, train/logprobs = tensor([[-0.7379, -2.4149],
        [-1.7343, -1.5564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893139123916626
Epoch 0, Step 668: train/loss = 0.4963579475879669, train/raw-loss = 0.46921682357788086, train/logprobs = tensor([[-1.3084, -2.9069],
        [-1.5245, -1.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27141135931015015
Epoch 0, Step 669: train/loss = 0.524194598197937, train/raw-loss = 0.49354103207588196, train/logprobs = tensor([[-0.8437, -1.2886],
        [-1.8520, -1.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065354526042938
Epoch 0, Step 670: train/loss = 0.3827558159828186, train/raw-loss = 0.352683424949646, train/logprobs = tensor([[-0.6826, -7.3557],
        [-2.0300, -1.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30072420835494995
Epoch 0, Step 671: train/loss = 0.43844813108444214, train/raw-loss = 0.4108796715736389, train/logprobs = tensor([[-0.6938, -2.6109],
        [-1.7393, -1.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27568450570106506
Epoch 0, Step 672: train/loss = 0.3416653871536255, train/raw-loss = 0.3155527710914612, train/logprobs = tensor([[-0.8699, -6.0334],
        [-2.0564, -1.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26112648844718933
Epoch 0, Step 673: train/loss = 0.49316471815109253, train/raw-loss = 0.4633202850818634, train/logprobs = tensor([[-0.7847, -3.5328],
        [-1.5122, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984439730644226
Epoch 0, Step 674: train/loss = 0.1703391969203949, train/raw-loss = 0.14033560454845428, train/logprobs = tensor([[-1.2892, -4.2835],
        [-3.4068, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3000360429286957
Epoch 0, Step 675: train/loss = 0.5954812169075012, train/raw-loss = 0.5672287940979004, train/logprobs = tensor([[-0.6387, -2.1635],
        [-1.6552, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2825251519680023
Epoch 0, Step 676: train/loss = 0.3804747760295868, train/raw-loss = 0.3574037253856659, train/logprobs = tensor([[-0.7134, -3.7857],
        [-1.4220, -1.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23071062564849854
Epoch 0, Step 677: train/loss = 0.5141820907592773, train/raw-loss = 0.4887281656265259, train/logprobs = tensor([[-0.4803, -2.1281],
        [-1.3398, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545391619205475
Epoch 0, Step 678: train/loss = 0.17991270124912262, train/raw-loss = 0.14908142387866974, train/logprobs = tensor([[-0.7729, -6.5252],
        [-2.0509, -1.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3083127737045288
Epoch 0, Step 679: train/loss = 0.46769994497299194, train/raw-loss = 0.4388279616832733, train/logprobs = tensor([[-1.4207, -3.3446],
        [-1.4585, -0.4465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28871995210647583
Epoch 0, Step 680: train/loss = 0.34608250856399536, train/raw-loss = 0.3213973641395569, train/logprobs = tensor([[-0.8754, -3.4741],
        [-1.5407, -0.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24685180187225342
Epoch 0, Step 681: train/loss = 0.4213535189628601, train/raw-loss = 0.392721027135849, train/logprobs = tensor([[-1.1959, -7.0888],
        [-1.4574, -2.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28632479906082153
Epoch 0, Step 682: train/loss = 0.3141213357448578, train/raw-loss = 0.2817898690700531, train/logprobs = tensor([[-1.0642, -7.5060],
        [-2.5557, -1.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3233146071434021
Epoch 0, Step 683: train/loss = 0.2509670853614807, train/raw-loss = 0.22233527898788452, train/logprobs = tensor([[-0.9319, -6.5094],
        [-1.5840, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863178551197052
Epoch 0, Step 684: train/loss = 0.3739728033542633, train/raw-loss = 0.35052135586738586, train/logprobs = tensor([[-0.6808, -5.3876],
        [-0.9863, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23451454937458038
Epoch 0, Step 685: train/loss = 0.5121806263923645, train/raw-loss = 0.48328787088394165, train/logprobs = tensor([[-1.6066, -2.7210],
        [-1.8362, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28892719745635986
Epoch 0, Step 686: train/loss = 0.4461054801940918, train/raw-loss = 0.41763007640838623, train/logprobs = tensor([[-0.7492, -2.3743],
        [-1.8736, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2847542464733124
Epoch 0, Step 687: train/loss = 0.3395678400993347, train/raw-loss = 0.3090845048427582, train/logprobs = tensor([[-1.0699, -6.6160],
        [-2.0959, -1.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048335313796997
Epoch 0, Step 688: train/loss = 0.38995638489723206, train/raw-loss = 0.36119964718818665, train/logprobs = tensor([[-0.6415, -2.3346],
        [-1.9549, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875674366950989
Epoch 0, Step 689: train/loss = 0.45751670002937317, train/raw-loss = 0.42932575941085815, train/logprobs = tensor([[-0.8581, -2.6221],
        [-1.5098, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28190943598747253
Epoch 0, Step 690: train/loss = 0.24398721754550934, train/raw-loss = 0.2090127319097519, train/logprobs = tensor([[-1.2608, -4.2072],
        [-2.3403, -0.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497448265552521
Epoch 0, Step 691: train/loss = 0.5592198967933655, train/raw-loss = 0.5289223194122314, train/logprobs = tensor([[-0.7254, -1.8181],
        [-1.3792, -1.2505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3029762804508209
Epoch 0, Step 692: train/loss = 0.3779645264148712, train/raw-loss = 0.35278791189193726, train/logprobs = tensor([[-0.7445, -3.7969],
        [-1.0977, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517661154270172
Epoch 0, Step 693: train/loss = 0.31664252281188965, train/raw-loss = 0.2901264429092407, train/logprobs = tensor([[-0.6278, -5.3554],
        [-1.3149, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26516082882881165
Epoch 0, Step 694: train/loss = 0.5385529398918152, train/raw-loss = 0.5125066637992859, train/logprobs = tensor([[-0.8375, -3.2595],
        [-1.4295, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2604627013206482
Epoch 0, Step 695: train/loss = 0.5432512760162354, train/raw-loss = 0.5193161964416504, train/logprobs = tensor([[-0.5488, -3.1084],
        [-1.2351, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23935124278068542
Epoch 0, Step 696: train/loss = 0.40960222482681274, train/raw-loss = 0.3783867359161377, train/logprobs = tensor([[-1.1537, -4.4363],
        [-2.2452, -1.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121546506881714
Epoch 0, Step 697: train/loss = 0.44898536801338196, train/raw-loss = 0.4232915937900543, train/logprobs = tensor([[-0.7623, -3.2750],
        [-1.8228, -0.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25693783164024353
Epoch 0, Step 698: train/loss = 0.3612893223762512, train/raw-loss = 0.3317773938179016, train/logprobs = tensor([[-0.9963, -6.1789],
        [-1.9860, -1.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29511934518814087
Epoch 0, Step 699: train/loss = 0.26195093989372253, train/raw-loss = 0.23390381038188934, train/logprobs = tensor([[-0.8718, -3.7684],
        [-2.2109, -1.0714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804710566997528
Epoch 0, Step 700: train/loss = 0.3760643005371094, train/raw-loss = 0.3490443825721741, train/logprobs = tensor([[-1.0284, -5.4542],
        [-1.8280, -1.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701992988586426
Epoch 0, Step 701: train/loss = 0.40448135137557983, train/raw-loss = 0.3738172650337219, train/logprobs = tensor([[-1.9500, -5.2198],
        [-1.8984, -0.3396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30664098262786865
Epoch 0, Step 702: train/loss = 0.3542640805244446, train/raw-loss = 0.3242345452308655, train/logprobs = tensor([[-0.8640, -4.3942],
        [-1.7840, -0.5581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002954125404358
Epoch 0, Step 703: train/loss = 0.39606907963752747, train/raw-loss = 0.3703080415725708, train/logprobs = tensor([[-0.6927, -2.7931],
        [-1.5787, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25761061906814575
Epoch 0, Step 704: train/loss = 0.19886451959609985, train/raw-loss = 0.1711428016424179, train/logprobs = tensor([[-0.8820, -8.1470],
        [-1.9243, -2.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772171199321747
Epoch 0, Step 705: train/loss = 0.26141422986984253, train/raw-loss = 0.23264986276626587, train/logprobs = tensor([[-1.1406, -5.5389],
        [-2.2068, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.287643700838089
Epoch 0, Step 706: train/loss = 0.24874992668628693, train/raw-loss = 0.21945974230766296, train/logprobs = tensor([[-1.2270, -5.9371],
        [-2.2704, -1.3701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929018437862396
Epoch 0, Step 707: train/loss = 0.24664227664470673, train/raw-loss = 0.2198164165019989, train/logprobs = tensor([[-0.9482, -6.2249],
        [-1.6713, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26825857162475586
Epoch 0, Step 708: train/loss = 0.23199176788330078, train/raw-loss = 0.20406794548034668, train/logprobs = tensor([[-0.9135, -5.4449],
        [-2.8369, -1.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27923810482025146
Epoch 0, Step 709: train/loss = 0.7575328350067139, train/raw-loss = 0.7262537479400635, train/logprobs = tensor([[-1.5833, -3.2614],
        [-2.3765, -1.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31279170513153076
Epoch 0, Step 710: train/loss = 0.472944974899292, train/raw-loss = 0.45414626598358154, train/logprobs = tensor([[-0.5121, -1.9799],
        [-1.0497, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18798694014549255
Epoch 0, Step 711: train/loss = 0.37414634227752686, train/raw-loss = 0.34466272592544556, train/logprobs = tensor([[-0.9017, -4.2284],
        [-1.8208, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2948363125324249
Epoch 0, Step 712: train/loss = 0.5333724617958069, train/raw-loss = 0.5025827884674072, train/logprobs = tensor([[-0.7265, -1.7769],
        [-1.4669, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3078967034816742
Epoch 0, Step 713: train/loss = 0.452304482460022, train/raw-loss = 0.42505237460136414, train/logprobs = tensor([[-0.8250, -2.9956],
        [-1.3767, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27252131700515747
Epoch 0, Step 714: train/loss = 0.8773741722106934, train/raw-loss = 0.8506872653961182, train/logprobs = tensor([[-2.4703, -3.2577],
        [-1.1541, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26686906814575195
Epoch 0, Step 715: train/loss = 0.476767897605896, train/raw-loss = 0.4538310766220093, train/logprobs = tensor([[-0.4610, -2.1030],
        [-1.0705, -0.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2293686866760254
Epoch 0, Step 716: train/loss = 0.3290368914604187, train/raw-loss = 0.2965557873249054, train/logprobs = tensor([[-0.7029, -4.5660],
        [-2.3088, -1.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32481124997138977
Epoch 0, Step 717: train/loss = 0.3068883717060089, train/raw-loss = 0.27413055300712585, train/logprobs = tensor([[-1.3835, -6.2163],
        [-2.1434, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32757851481437683
Epoch 0, Step 718: train/loss = 0.3660849332809448, train/raw-loss = 0.3377572000026703, train/logprobs = tensor([[-0.7831, -2.1000],
        [-1.9020, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28327715396881104
Epoch 0, Step 719: train/loss = 0.249051034450531, train/raw-loss = 0.2194916307926178, train/logprobs = tensor([[-1.0181, -6.9898],
        [-1.7413, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955939471721649
Epoch 0, Step 720: train/loss = 0.3879251480102539, train/raw-loss = 0.3611479103565216, train/logprobs = tensor([[-0.7202, -2.8670],
        [-1.6453, -1.4244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26777246594429016
Epoch 0, Step 721: train/loss = 0.5047616362571716, train/raw-loss = 0.47780072689056396, train/logprobs = tensor([[-0.6882, -2.0288],
        [-1.3777, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26960963010787964
Epoch 0, Step 722: train/loss = 0.2875556945800781, train/raw-loss = 0.25567784905433655, train/logprobs = tensor([[-1.1595, -6.2046],
        [-1.9270, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31877827644348145
Epoch 0, Step 723: train/loss = 0.24719907343387604, train/raw-loss = 0.2203328013420105, train/logprobs = tensor([[-0.9581, -5.8246],
        [-2.5676, -0.6695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26866278052330017
Epoch 0, Step 724: train/loss = 0.4053128957748413, train/raw-loss = 0.3732878565788269, train/logprobs = tensor([[-1.1384, -3.1812],
        [-2.1437, -1.4244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32025012373924255
Epoch 0, Step 725: train/loss = 0.21999065577983856, train/raw-loss = 0.1936360001564026, train/logprobs = tensor([[-0.6971, -4.2571],
        [-2.2949, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26354649662971497
Epoch 0, Step 726: train/loss = 0.33592474460601807, train/raw-loss = 0.312311053276062, train/logprobs = tensor([[-0.6152, -5.5735],
        [-1.1766, -1.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23613695800304413
Epoch 0, Step 727: train/loss = 0.49610891938209534, train/raw-loss = 0.4702771008014679, train/logprobs = tensor([[-0.6876, -1.5969],
        [-1.1114, -0.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25831806659698486
Epoch 0, Step 728: train/loss = 0.38812917470932007, train/raw-loss = 0.36007755994796753, train/logprobs = tensor([[-0.8849, -3.8578],
        [-1.7111, -0.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28051620721817017
Epoch 0, Step 729: train/loss = 0.2842690348625183, train/raw-loss = 0.2540609538555145, train/logprobs = tensor([[-0.8673, -3.9075],
        [-2.2447, -1.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30208075046539307
Epoch 0, Step 730: train/loss = 0.5355502963066101, train/raw-loss = 0.5052868127822876, train/logprobs = tensor([[-1.1991, -3.1760],
        [-1.9473, -1.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30263498425483704
Epoch 0, Step 731: train/loss = 0.34086719155311584, train/raw-loss = 0.3114162087440491, train/logprobs = tensor([[-1.2281, -8.6863],
        [-1.9394, -1.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29450979828834534
Epoch 0, Step 732: train/loss = 0.4099620580673218, train/raw-loss = 0.38518327474594116, train/logprobs = tensor([[-0.5198, -4.1643],
        [-1.2078, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24778789281845093
Epoch 0, Step 733: train/loss = 0.31923529505729675, train/raw-loss = 0.29199329018592834, train/logprobs = tensor([[-0.6031, -4.3839],
        [-1.5277, -2.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724200487136841
Epoch 0, Step 734: train/loss = 0.4973580241203308, train/raw-loss = 0.4717177748680115, train/logprobs = tensor([[-0.6976, -2.1542],
        [-1.2193, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564026415348053
Epoch 0, Step 735: train/loss = 0.4457516670227051, train/raw-loss = 0.4193033277988434, train/logprobs = tensor([[-1.2617, -4.9764],
        [-2.0267, -2.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26448339223861694
Epoch 0, Step 736: train/loss = 0.4162066578865051, train/raw-loss = 0.3916046619415283, train/logprobs = tensor([[-1.0237, -5.5518],
        [-1.4658, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24601995944976807
Epoch 0, Step 737: train/loss = 0.5200088620185852, train/raw-loss = 0.4980885982513428, train/logprobs = tensor([[-0.8395, -2.7882],
        [-0.8913, -1.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21920245885849
Epoch 0, Step 738: train/loss = 0.4760545492172241, train/raw-loss = 0.4447225332260132, train/logprobs = tensor([[-1.1074, -2.4024],
        [-1.8969, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3133199214935303
Epoch 0, Step 739: train/loss = 0.4493288993835449, train/raw-loss = 0.4242541193962097, train/logprobs = tensor([[-0.6445, -4.1495],
        [-1.0836, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507477402687073
Epoch 0, Step 740: train/loss = 0.5766574144363403, train/raw-loss = 0.5511534214019775, train/logprobs = tensor([[-0.7934, -1.3036],
        [-1.1241, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550400495529175
Epoch 0, Step 741: train/loss = 0.5820821523666382, train/raw-loss = 0.5542568564414978, train/logprobs = tensor([[-0.9349, -1.7098],
        [-1.7212, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782534062862396
Epoch 0, Step 742: train/loss = 0.40032294392585754, train/raw-loss = 0.3769964873790741, train/logprobs = tensor([[-0.6375, -3.8875],
        [-0.7984, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2332644760608673
Epoch 0, Step 743: train/loss = 0.28280559182167053, train/raw-loss = 0.2551274299621582, train/logprobs = tensor([[-1.0425, -4.8873],
        [-1.9368, -0.3574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27678149938583374
Epoch 0, Step 744: train/loss = 0.41993284225463867, train/raw-loss = 0.39117786288261414, train/logprobs = tensor([[-0.9574, -1.9730],
        [-1.7101, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28754982352256775
Epoch 0, Step 745: train/loss = 0.25099942088127136, train/raw-loss = 0.2250085473060608, train/logprobs = tensor([[-0.5532, -4.6953],
        [-1.5153, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599085569381714
Epoch 0, Step 746: train/loss = 0.23802348971366882, train/raw-loss = 0.21429473161697388, train/logprobs = tensor([[-0.7702, -3.1350],
        [-1.6516, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23728753626346588
Epoch 0, Step 747: train/loss = 0.40421828627586365, train/raw-loss = 0.3749529719352722, train/logprobs = tensor([[-0.8632, -2.7009],
        [-1.3206, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29265356063842773
Epoch 0, Step 748: train/loss = 0.22258023917675018, train/raw-loss = 0.19322264194488525, train/logprobs = tensor([[-1.0708, -9.1076],
        [-2.8482, -1.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29357603192329407
Epoch 0, Step 749: train/loss = 0.2516871988773346, train/raw-loss = 0.21848344802856445, train/logprobs = tensor([[-0.8879, -5.1640],
        [-2.1146, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320375382900238
Epoch 0, Step 750: train/loss = 0.5113915801048279, train/raw-loss = 0.48481285572052, train/logprobs = tensor([[-1.7802, -5.3590],
        [-1.5202, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26578769087791443
Epoch 0, Step 751: train/loss = 0.2820079028606415, train/raw-loss = 0.24994511902332306, train/logprobs = tensor([[-1.2780, -4.1540],
        [-2.1493, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32062777876853943
Epoch 0, Step 752: train/loss = 0.3388335704803467, train/raw-loss = 0.3162311911582947, train/logprobs = tensor([[-0.5965, -3.4313],
        [-1.0850, -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22602418065071106
Epoch 0, Step 753: train/loss = 0.5277481079101562, train/raw-loss = 0.4993707239627838, train/logprobs = tensor([[-1.8512, -5.4748],
        [-1.6999, -1.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28377407789230347
Epoch 0, Step 754: train/loss = 0.3299405574798584, train/raw-loss = 0.300268292427063, train/logprobs = tensor([[-0.7869, -5.6504],
        [-1.9982, -1.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29672229290008545
Epoch 0, Step 755: train/loss = 0.20862552523612976, train/raw-loss = 0.17654931545257568, train/logprobs = tensor([[-1.3360, -4.7883],
        [-2.5827, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3207620084285736
Epoch 0, Step 756: train/loss = 0.43740975856781006, train/raw-loss = 0.4056309163570404, train/logprobs = tensor([[-1.1472, -3.2078],
        [-2.0513, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317788690328598
Epoch 0, Step 757: train/loss = 0.42279666662216187, train/raw-loss = 0.3934749364852905, train/logprobs = tensor([[-1.2219, -2.6988],
        [-2.1329, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932175397872925
Epoch 0, Step 758: train/loss = 0.4449304938316345, train/raw-loss = 0.41577258706092834, train/logprobs = tensor([[-1.3177, -1.9099],
        [-2.4784, -1.2492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29157912731170654
Epoch 0, Step 759: train/loss = 0.19185033440589905, train/raw-loss = 0.16422301530838013, train/logprobs = tensor([[-0.8440, -7.3978],
        [-2.7127, -2.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27627331018447876
Epoch 0, Step 760: train/loss = 0.4232104420661926, train/raw-loss = 0.3965819180011749, train/logprobs = tensor([[-1.1171, -2.8977],
        [-1.7959, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662853002548218
Epoch 0, Step 761: train/loss = 0.2696158289909363, train/raw-loss = 0.2436150759458542, train/logprobs = tensor([[-0.8156, -4.6785],
        [-1.9122, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26000744104385376
Epoch 0, Step 762: train/loss = 0.5737862586975098, train/raw-loss = 0.5430600643157959, train/logprobs = tensor([[-1.0548, -2.2256],
        [-1.4320, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30726158618927
Epoch 0, Step 763: train/loss = 0.21064859628677368, train/raw-loss = 0.18891018629074097, train/logprobs = tensor([[-0.5252, -7.0016],
        [-1.2266, -1.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21738415956497192
Epoch 0, Step 764: train/loss = 0.43900883197784424, train/raw-loss = 0.4114615321159363, train/logprobs = tensor([[-0.9549, -4.1444],
        [-2.0076, -2.4499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27547311782836914
Epoch 0, Step 765: train/loss = 0.1715860217809677, train/raw-loss = 0.13770270347595215, train/logprobs = tensor([[-0.9043, -6.0556],
        [-2.2552, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33883315324783325
Epoch 0, Step 766: train/loss = 0.6644395589828491, train/raw-loss = 0.6346116065979004, train/logprobs = tensor([[-0.6644, -1.2000],
        [-1.6420, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29827961325645447
Epoch 0, Step 767: train/loss = 0.3658313751220703, train/raw-loss = 0.3375485837459564, train/logprobs = tensor([[-1.3330, -9.6874],
        [-1.7299, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282828152179718
Epoch 0, Step 768: train/loss = 0.5019257664680481, train/raw-loss = 0.47385114431381226, train/logprobs = tensor([[-1.2082, -4.0483],
        [-1.7753, -2.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280746191740036
Epoch 0, Step 769: train/loss = 0.365200936794281, train/raw-loss = 0.3362484276294708, train/logprobs = tensor([[-1.4654, -5.3232],
        [-2.1110, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28952500224113464
Epoch 0, Step 770: train/loss = 0.5077759623527527, train/raw-loss = 0.4826256334781647, train/logprobs = tensor([[-1.2038, -2.5945],
        [-1.5796, -0.5609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515033483505249
Epoch 0, Step 771: train/loss = 0.8211674094200134, train/raw-loss = 0.7877428531646729, train/logprobs = tensor([[-2.2601, -2.6203],
        [-2.1047, -1.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33424532413482666
Epoch 0, Step 772: train/loss = 0.3782709836959839, train/raw-loss = 0.35380107164382935, train/logprobs = tensor([[-0.5769, -7.2760],
        [-1.4719, -2.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24469877779483795
Epoch 0, Step 773: train/loss = 0.6053428649902344, train/raw-loss = 0.5766538381576538, train/logprobs = tensor([[-2.7321, -7.8579],
        [-2.1337, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28689044713974
Epoch 0, Step 774: train/loss = 0.32087942957878113, train/raw-loss = 0.2951737642288208, train/logprobs = tensor([[-0.8087, -3.5669],
        [-1.6903, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257056325674057
Epoch 0, Step 775: train/loss = 0.3097461760044098, train/raw-loss = 0.27791839838027954, train/logprobs = tensor([[-1.1274, -5.9254],
        [-2.2555, -2.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182779550552368
Epoch 0, Step 776: train/loss = 0.5020542740821838, train/raw-loss = 0.47383642196655273, train/logprobs = tensor([[-1.3164, -2.3043],
        [-2.1572, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28217893838882446
Epoch 0, Step 777: train/loss = 0.2887018918991089, train/raw-loss = 0.2640286386013031, train/logprobs = tensor([[-0.6536, -6.8224],
        [-1.3023, -2.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24673232436180115
Epoch 0, Step 778: train/loss = 0.5792950391769409, train/raw-loss = 0.546991229057312, train/logprobs = tensor([[-1.2670, -2.2483],
        [-1.6426, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230381906032562
Epoch 0, Step 779: train/loss = 0.4598320722579956, train/raw-loss = 0.43066710233688354, train/logprobs = tensor([[-0.7138, -2.2718],
        [-1.8214, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29164987802505493
Epoch 0, Step 780: train/loss = 0.34834200143814087, train/raw-loss = 0.31588271260261536, train/logprobs = tensor([[-1.0136, -4.1378],
        [-2.8615, -2.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3245931565761566
Epoch 0, Step 781: train/loss = 0.2104438692331314, train/raw-loss = 0.18192976713180542, train/logprobs = tensor([[-0.8530, -6.2823],
        [-1.9429, -1.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851411700248718
Epoch 0, Step 782: train/loss = 0.4425777792930603, train/raw-loss = 0.41127127408981323, train/logprobs = tensor([[-0.6601, -4.7366],
        [-1.6167, -1.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130649924278259
Epoch 0, Step 783: train/loss = 0.31058427691459656, train/raw-loss = 0.2807252109050751, train/logprobs = tensor([[-0.8239, -8.7117],
        [-1.8931, -2.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985904812812805
Epoch 0, Step 784: train/loss = 0.3309769034385681, train/raw-loss = 0.30566996335983276, train/logprobs = tensor([[-0.5776, -2.4986],
        [-1.6380, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25306937098503113
Epoch 0, Step 785: train/loss = 0.35232287645339966, train/raw-loss = 0.3259769082069397, train/logprobs = tensor([[-0.6792, -3.3348],
        [-1.7383, -1.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634594440460205
Epoch 0, Step 786: train/loss = 0.24206098914146423, train/raw-loss = 0.21111762523651123, train/logprobs = tensor([[-0.9843, -5.5711],
        [-2.0677, -1.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30943363904953003
Epoch 0, Step 787: train/loss = 0.2758476734161377, train/raw-loss = 0.24961808323860168, train/logprobs = tensor([[-0.5813, -5.0247],
        [-1.9135, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2622956931591034
Epoch 0, Step 788: train/loss = 0.5436517596244812, train/raw-loss = 0.5035766363143921, train/logprobs = tensor([[-1.3097, -3.0722],
        [-3.0583, -2.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4007513225078583
Epoch 0, Step 789: train/loss = 0.16366375982761383, train/raw-loss = 0.1313873827457428, train/logprobs = tensor([[-1.6170, -5.6632],
        [-2.8677, -0.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3227638006210327
Epoch 0, Step 790: train/loss = 0.28580981492996216, train/raw-loss = 0.2594473361968994, train/logprobs = tensor([[-0.8254, -3.0868],
        [-1.9748, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26362481713294983
Epoch 0, Step 791: train/loss = 0.5730500817298889, train/raw-loss = 0.5506025552749634, train/logprobs = tensor([[-0.6973, -3.0612],
        [-1.3863, -1.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22447583079338074
Epoch 0, Step 792: train/loss = 0.3367668688297272, train/raw-loss = 0.3052448630332947, train/logprobs = tensor([[-0.7504, -4.9399],
        [-1.8998, -2.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152199685573578
Epoch 0, Step 793: train/loss = 0.36762118339538574, train/raw-loss = 0.3454292416572571, train/logprobs = tensor([[-0.6781, -7.4433],
        [-1.4703, -2.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2219190001487732
Epoch 0, Step 794: train/loss = 0.29047372937202454, train/raw-loss = 0.2632785737514496, train/logprobs = tensor([[-0.6019, -7.0015],
        [-1.8619, -1.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2719518840312958
Epoch 0, Step 795: train/loss = 0.4019968509674072, train/raw-loss = 0.37134045362472534, train/logprobs = tensor([[-0.9465, -3.1125],
        [-1.6299, -1.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065641522407532
Epoch 0, Step 796: train/loss = 0.16632387042045593, train/raw-loss = 0.13311751186847687, train/logprobs = tensor([[-1.4689, -9.5294],
        [-2.9253, -2.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320634961128235
Epoch 0, Step 797: train/loss = 0.40431082248687744, train/raw-loss = 0.3789423108100891, train/logprobs = tensor([[-0.7777, -4.3325],
        [-1.2587, -0.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253684937953949
Epoch 0, Step 798: train/loss = 0.3295443058013916, train/raw-loss = 0.2959434986114502, train/logprobs = tensor([[-0.7102, -6.9359],
        [-2.7668, -3.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3360082507133484
Epoch 0, Step 799: train/loss = 0.5362915396690369, train/raw-loss = 0.510484516620636, train/logprobs = tensor([[-0.6126, -1.7606],
        [-1.1360, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25807029008865356
Epoch 0, Step 800: train/loss = 0.5950884222984314, train/raw-loss = 0.570082426071167, train/logprobs = tensor([[-2.2553, -9.9706],
        [-1.7882, -2.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250060111284256
Epoch 0, Step 801: train/loss = 0.38774219155311584, train/raw-loss = 0.3569074869155884, train/logprobs = tensor([[-1.1021, -3.8192],
        [-2.0652, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3083467483520508
Epoch 0, Step 802: train/loss = 0.19363027811050415, train/raw-loss = 0.16210457682609558, train/logprobs = tensor([[-1.1594, -7.9524],
        [-2.6185, -2.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31525719165802
Epoch 0, Step 803: train/loss = 0.7503949403762817, train/raw-loss = 0.7233409881591797, train/logprobs = tensor([[-0.9558, -1.2633],
        [-1.1475, -1.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705393433570862
Epoch 0, Step 804: train/loss = 0.28748443722724915, train/raw-loss = 0.258859783411026, train/logprobs = tensor([[-1.1821, -5.4057],
        [-2.3268, -1.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862464487552643
Epoch 0, Step 805: train/loss = 0.4268479347229004, train/raw-loss = 0.3946518898010254, train/logprobs = tensor([[-0.8962, -4.2803],
        [-1.2725, -1.5488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219606578350067
Epoch 0, Step 806: train/loss = 0.4939511716365814, train/raw-loss = 0.46183666586875916, train/logprobs = tensor([[-1.1346, -3.7540],
        [-2.0070, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3211449980735779
Epoch 0, Step 807: train/loss = 0.2070154845714569, train/raw-loss = 0.18262074887752533, train/logprobs = tensor([[-0.7789, -6.0570],
        [-2.2422, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24394726753234863
Epoch 0, Step 808: train/loss = 0.3082773685455322, train/raw-loss = 0.2782497704029083, train/logprobs = tensor([[-1.0919, -3.9591],
        [-2.0754, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30027589201927185
Epoch 0, Step 809: train/loss = 0.903803288936615, train/raw-loss = 0.8723869919776917, train/logprobs = tensor([[-1.7597, -2.5888],
        [-1.6157, -1.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.314162939786911
Epoch 0, Step 810: train/loss = 0.27152663469314575, train/raw-loss = 0.24599164724349976, train/logprobs = tensor([[-1.3849, -6.1176],
        [-1.9866, -1.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553499937057495
Epoch 0, Step 811: train/loss = 0.28541356325149536, train/raw-loss = 0.25267472863197327, train/logprobs = tensor([[-0.9544, -3.8418],
        [-2.4011, -1.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273884057998657
Epoch 0, Step 812: train/loss = 0.3455396294593811, train/raw-loss = 0.3189176023006439, train/logprobs = tensor([[-0.7508, -3.6541],
        [-1.5873, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26622045040130615
Epoch 0, Step 813: train/loss = 0.2720251679420471, train/raw-loss = 0.2448720633983612, train/logprobs = tensor([[-0.7953, -3.4022],
        [-2.0733, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27153098583221436
Epoch 0, Step 814: train/loss = 0.23449480533599854, train/raw-loss = 0.2048967182636261, train/logprobs = tensor([[-1.2853, -7.5330],
        [-2.5524, -2.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29598090052604675
Epoch 0, Step 815: train/loss = 0.4093312919139862, train/raw-loss = 0.38194361329078674, train/logprobs = tensor([[-0.8523, -4.9557],
        [-1.6253, -1.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738765478134155
Epoch 0, Step 816: train/loss = 0.7185739874839783, train/raw-loss = 0.6901886463165283, train/logprobs = tensor([[-1.9962, -2.9385],
        [-1.4026, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838531732559204
Epoch 0, Step 817: train/loss = 0.4400331676006317, train/raw-loss = 0.4125211834907532, train/logprobs = tensor([[-1.4472, -2.7426],
        [-1.7558, -0.6789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27511972188949585
Epoch 0, Step 818: train/loss = 0.2050616294145584, train/raw-loss = 0.17462824285030365, train/logprobs = tensor([[-0.7639, -3.7916],
        [-2.3678, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043336868286133
Epoch 0, Step 819: train/loss = 0.37571999430656433, train/raw-loss = 0.3512137532234192, train/logprobs = tensor([[-1.0066, -3.2262],
        [-1.4053, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24506239593029022
Epoch 0, Step 820: train/loss = 0.2639724612236023, train/raw-loss = 0.23480567336082458, train/logprobs = tensor([[-0.9884, -5.3136],
        [-1.8967, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2916678190231323
Epoch 0, Step 821: train/loss = 0.5171573758125305, train/raw-loss = 0.48634299635887146, train/logprobs = tensor([[-0.8255, -6.0790],
        [-1.8928, -2.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30814385414123535
Epoch 0, Step 822: train/loss = 0.3651293218135834, train/raw-loss = 0.33961397409439087, train/logprobs = tensor([[-1.1477, -3.6230],
        [-1.9668, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551534175872803
Epoch 0, Step 823: train/loss = 0.16706965863704681, train/raw-loss = 0.13843996822834015, train/logprobs = tensor([[ -0.8706, -12.1426],
        [ -2.1751,  -3.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862969636917114
Epoch 0, Step 824: train/loss = 0.21106454730033875, train/raw-loss = 0.18234175443649292, train/logprobs = tensor([[-0.9621, -3.1245],
        [-2.1145, -0.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.287227988243103
Epoch 0, Step 825: train/loss = 0.40204524993896484, train/raw-loss = 0.370571494102478, train/logprobs = tensor([[-0.9939, -3.9780],
        [-1.7926, -1.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3147374391555786
Epoch 0, Step 826: train/loss = 0.47785642743110657, train/raw-loss = 0.45091044902801514, train/logprobs = tensor([[-0.7961, -2.9899],
        [-1.4471, -1.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26945960521698
Epoch 0, Step 827: train/loss = 0.3902966380119324, train/raw-loss = 0.35767632722854614, train/logprobs = tensor([[-1.5291, -3.6164],
        [-1.8555, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32620325684547424
Epoch 0, Step 828: train/loss = 0.4056449830532074, train/raw-loss = 0.3767703175544739, train/logprobs = tensor([[-0.9535, -4.9083],
        [-1.2732, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887466847896576
Epoch 0, Step 829: train/loss = 0.2107602059841156, train/raw-loss = 0.1810731589794159, train/logprobs = tensor([[-0.7685, -3.9415],
        [-2.2431, -1.2280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968704104423523
Epoch 0, Step 830: train/loss = 0.5091751217842102, train/raw-loss = 0.4805039167404175, train/logprobs = tensor([[-1.1127, -2.1849],
        [-1.5965, -1.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28671199083328247
Epoch 0, Step 831: train/loss = 0.3330497145652771, train/raw-loss = 0.3056250214576721, train/logprobs = tensor([[-0.8871, -4.7345],
        [-1.9130, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742466926574707
Epoch 0, Step 832: train/loss = 0.38534605503082275, train/raw-loss = 0.3622710108757019, train/logprobs = tensor([[-0.6604, -4.5323],
        [-1.2888, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23075023293495178
Epoch 0, Step 833: train/loss = 0.5170029997825623, train/raw-loss = 0.48671913146972656, train/logprobs = tensor([[-1.2933, -3.0147],
        [-2.0527, -1.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028385639190674
Epoch 0, Step 834: train/loss = 0.24549934267997742, train/raw-loss = 0.21891772747039795, train/logprobs = tensor([[-0.9206, -4.5025],
        [-1.9926, -1.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26581621170043945
Epoch 0, Step 835: train/loss = 0.3255678415298462, train/raw-loss = 0.29458969831466675, train/logprobs = tensor([[-0.7517, -6.6652],
        [-2.1330, -2.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30978134274482727
Epoch 0, Step 836: train/loss = 0.24234342575073242, train/raw-loss = 0.21493050456047058, train/logprobs = tensor([[-0.7598, -7.6760],
        [-2.2384, -1.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2741292417049408
Epoch 0, Step 837: train/loss = 0.2478189468383789, train/raw-loss = 0.217146098613739, train/logprobs = tensor([[-1.0145, -5.9125],
        [-2.4515, -0.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3067285418510437
Epoch 0, Step 838: train/loss = 0.30485987663269043, train/raw-loss = 0.2785768210887909, train/logprobs = tensor([[-0.4506, -3.7469],
        [-2.1758, -1.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26283037662506104
Epoch 0, Step 839: train/loss = 0.5721644163131714, train/raw-loss = 0.5470113158226013, train/logprobs = tensor([[-0.6646, -1.2211],
        [-1.2232, -1.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515312433242798
Epoch 0, Step 840: train/loss = 0.35804569721221924, train/raw-loss = 0.32612401247024536, train/logprobs = tensor([[-0.7617, -3.9588],
        [-1.9100, -1.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31921684741973877
Epoch 0, Step 841: train/loss = 0.4411337971687317, train/raw-loss = 0.40909048914909363, train/logprobs = tensor([[-1.3524, -5.1689],
        [-1.9798, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3204330801963806
Epoch 0, Step 842: train/loss = 0.30372992157936096, train/raw-loss = 0.27239614725112915, train/logprobs = tensor([[-1.0794, -3.3388],
        [-2.7231, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31333792209625244
Epoch 0, Step 843: train/loss = 0.39557981491088867, train/raw-loss = 0.3715198040008545, train/logprobs = tensor([[-0.5749, -2.2390],
        [-1.6420, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2406003475189209
Epoch 0, Step 844: train/loss = 0.3047788143157959, train/raw-loss = 0.2728695273399353, train/logprobs = tensor([[-1.1668, -4.6197],
        [-2.2710, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31909310817718506
Epoch 0, Step 845: train/loss = 0.47520655393600464, train/raw-loss = 0.4469092786312103, train/logprobs = tensor([[-1.0205, -2.4255],
        [-2.1914, -1.4703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2829723060131073
Epoch 0, Step 846: train/loss = 0.35158848762512207, train/raw-loss = 0.3230820298194885, train/logprobs = tensor([[-0.7291, -2.9177],
        [-2.2274, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28506430983543396
Epoch 0, Step 847: train/loss = 0.13527949154376984, train/raw-loss = 0.10233618319034576, train/logprobs = tensor([[-0.9953, -4.0236],
        [-3.0265, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32943302392959595
Epoch 0, Step 848: train/loss = 0.40133044123649597, train/raw-loss = 0.3718762695789337, train/logprobs = tensor([[-0.9233, -3.1254],
        [-2.6948, -0.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945418357849121
Epoch 0, Step 849: train/loss = 0.6780322194099426, train/raw-loss = 0.6473338007926941, train/logprobs = tensor([[-1.0381, -1.6478],
        [-1.2845, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3069837689399719
Epoch 0, Step 850: train/loss = 0.2891417443752289, train/raw-loss = 0.25990113615989685, train/logprobs = tensor([[-0.5769, -6.6115],
        [-2.0488, -1.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2924061417579651
Epoch 0, Step 851: train/loss = 0.33725133538246155, train/raw-loss = 0.3044920563697815, train/logprobs = tensor([[-1.0186, -5.5331],
        [-2.5438, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32759276032447815
Epoch 0, Step 852: train/loss = 0.1535470336675644, train/raw-loss = 0.1236124187707901, train/logprobs = tensor([[-1.3195, -8.7102],
        [-2.8509, -2.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29934605956077576
Epoch 0, Step 853: train/loss = 0.3248186707496643, train/raw-loss = 0.29442906379699707, train/logprobs = tensor([[-0.7422, -7.8829],
        [-1.8439, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038957715034485
Epoch 0, Step 854: train/loss = 0.4253711700439453, train/raw-loss = 0.39688989520072937, train/logprobs = tensor([[-1.0408, -4.0320],
        [-2.5689, -2.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284812867641449
Epoch 0, Step 855: train/loss = 0.5198954343795776, train/raw-loss = 0.49089911580085754, train/logprobs = tensor([[-1.0193, -3.3558],
        [-2.3014, -2.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28996309638023376
Epoch 0, Step 856: train/loss = 0.4086337685585022, train/raw-loss = 0.38684767484664917, train/logprobs = tensor([[-0.5497, -5.3658],
        [-1.4298, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21786080300807953
Epoch 0, Step 857: train/loss = 0.22639872133731842, train/raw-loss = 0.19713489711284637, train/logprobs = tensor([[-0.9801, -5.8966],
        [-2.5152, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29263836145401
Epoch 0, Step 858: train/loss = 0.5613088011741638, train/raw-loss = 0.5327540636062622, train/logprobs = tensor([[-1.5847, -6.9688],
        [-1.6452, -1.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855475842952728
Epoch 0, Step 859: train/loss = 0.33167344331741333, train/raw-loss = 0.308388352394104, train/logprobs = tensor([[-0.5082, -2.8860],
        [-1.4711, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23285074532032013
Epoch 0, Step 860: train/loss = 0.3308332562446594, train/raw-loss = 0.2998228371143341, train/logprobs = tensor([[-1.4665, -6.3256],
        [-2.3014, -2.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101041316986084
Epoch 0, Step 861: train/loss = 0.32282423973083496, train/raw-loss = 0.2915554642677307, train/logprobs = tensor([[-0.7583, -3.7789],
        [-1.5488, -1.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31268784403800964
Epoch 0, Step 862: train/loss = 0.3878210186958313, train/raw-loss = 0.35890328884124756, train/logprobs = tensor([[-0.6818, -4.0540],
        [-1.8265, -1.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28917744755744934
Epoch 0, Step 863: train/loss = 0.27129650115966797, train/raw-loss = 0.24306340515613556, train/logprobs = tensor([[-0.9718, -3.4841],
        [-2.9878, -1.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28233107924461365
Epoch 0, Step 864: train/loss = 0.29010385274887085, train/raw-loss = 0.2582753598690033, train/logprobs = tensor([[-1.4029, -3.8596],
        [-3.0487, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31828463077545166
Epoch 0, Step 865: train/loss = 0.42479783296585083, train/raw-loss = 0.39894962310791016, train/logprobs = tensor([[-0.5619, -4.5220],
        [-1.2163, -2.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25848188996315
Epoch 0, Step 866: train/loss = 0.39425772428512573, train/raw-loss = 0.36552518606185913, train/logprobs = tensor([[-1.0882, -3.1039],
        [-1.8070, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28732556104660034
Epoch 0, Step 867: train/loss = 0.1200215071439743, train/raw-loss = 0.08567468076944351, train/logprobs = tensor([[-0.9691, -6.4733],
        [-3.8175, -1.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34346818923950195
Epoch 0, Step 868: train/loss = 0.48275288939476013, train/raw-loss = 0.45811235904693604, train/logprobs = tensor([[-1.4010, -4.9330],
        [-1.2251, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24640591442584991
Epoch 0, Step 869: train/loss = 0.4110691547393799, train/raw-loss = 0.38327476382255554, train/logprobs = tensor([[-1.8804, -5.9739],
        [-2.1545, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779437303543091
Epoch 0, Step 870: train/loss = 0.2697988450527191, train/raw-loss = 0.23940148949623108, train/logprobs = tensor([[-1.1944, -2.7227],
        [-3.4811, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039737641811371
Epoch 0, Step 871: train/loss = 0.23431631922721863, train/raw-loss = 0.2021043300628662, train/logprobs = tensor([[-0.8065, -8.8866],
        [-3.1366, -2.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3221198320388794
Epoch 0, Step 872: train/loss = 0.4872414469718933, train/raw-loss = 0.4499204158782959, train/logprobs = tensor([[-1.8318, -2.9349],
        [-2.4360, -1.3631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3732098937034607
Epoch 0, Step 873: train/loss = 0.2212447226047516, train/raw-loss = 0.19420887529850006, train/logprobs = tensor([[-0.6592, -6.6845],
        [-1.8735, -1.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27035850286483765
Epoch 0, Step 874: train/loss = 0.23613592982292175, train/raw-loss = 0.20236049592494965, train/logprobs = tensor([[-0.8875, -8.5723],
        [-2.9180, -2.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3377542197704315
Epoch 0, Step 875: train/loss = 0.540940523147583, train/raw-loss = 0.5099382400512695, train/logprobs = tensor([[-0.8279, -2.6060],
        [-2.1966, -1.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100229501724243
Epoch 0, Step 876: train/loss = 0.28326699137687683, train/raw-loss = 0.25245457887649536, train/logprobs = tensor([[-1.1564, -4.3544],
        [-1.9702, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3081243634223938
Epoch 0, Step 877: train/loss = 0.19559213519096375, train/raw-loss = 0.16932925581932068, train/logprobs = tensor([[-0.7514, -7.3449],
        [-1.6002, -1.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626286447048187
Epoch 0, Step 878: train/loss = 0.45733797550201416, train/raw-loss = 0.4291638135910034, train/logprobs = tensor([[-0.9448, -3.1884],
        [-1.5873, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28174126148223877
Epoch 0, Step 879: train/loss = 0.3157479166984558, train/raw-loss = 0.2881612181663513, train/logprobs = tensor([[-0.9995, -4.2117],
        [-2.0990, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27586719393730164
Epoch 0, Step 880: train/loss = 0.49899187684059143, train/raw-loss = 0.47062161564826965, train/logprobs = tensor([[-0.8837, -2.2499],
        [-1.5961, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837029993534088
Epoch 0, Step 881: train/loss = 0.2699357271194458, train/raw-loss = 0.2415081262588501, train/logprobs = tensor([[-0.7793, -4.7178],
        [-1.8090, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842758595943451
Epoch 0, Step 882: train/loss = 0.22878271341323853, train/raw-loss = 0.194740429520607, train/logprobs = tensor([[-0.9955, -4.9971],
        [-2.1416, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34042274951934814
Epoch 0, Step 883: train/loss = 0.3199363946914673, train/raw-loss = 0.28990811109542847, train/logprobs = tensor([[-0.8912, -6.8080],
        [-2.1061, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002828359603882
Epoch 0, Step 884: train/loss = 0.7079631090164185, train/raw-loss = 0.6832410097122192, train/logprobs = tensor([[-1.5903, -5.4233],
        [-0.8603, -2.3810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2472207248210907
Epoch 0, Step 885: train/loss = 0.29166701436042786, train/raw-loss = 0.26024875044822693, train/logprobs = tensor([[-0.9776, -7.9738],
        [-2.7005, -2.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31418293714523315
Epoch 0, Step 886: train/loss = 0.2957453727722168, train/raw-loss = 0.2644806504249573, train/logprobs = tensor([[-0.8441, -3.7098],
        [-1.6458, -0.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31264740228652954
Epoch 0, Step 887: train/loss = 0.2946573495864868, train/raw-loss = 0.2644806504249573, train/logprobs = tensor([[ -1.1245, -11.3281],
        [ -2.2030,  -3.6923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3017669916152954
Epoch 0, Step 888: train/loss = 0.32562798261642456, train/raw-loss = 0.2987527847290039, train/logprobs = tensor([[-0.7430, -4.4025],
        [-1.6588, -1.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687515914440155
Epoch 0, Step 889: train/loss = 0.3021109402179718, train/raw-loss = 0.27231428027153015, train/logprobs = tensor([[-0.6666, -3.6417],
        [-1.6135, -1.0506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29796674847602844
Epoch 0, Step 890: train/loss = 0.3451648950576782, train/raw-loss = 0.3143066465854645, train/logprobs = tensor([[-1.2459, -5.0364],
        [-2.6775, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3085823655128479
Epoch 0, Step 891: train/loss = 0.3708796501159668, train/raw-loss = 0.34150221943855286, train/logprobs = tensor([[-1.2943, -4.4523],
        [-2.2494, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937740087509155
Epoch 0, Step 892: train/loss = 0.13381829857826233, train/raw-loss = 0.10548734664916992, train/logprobs = tensor([[-0.6944, -7.4220],
        [-2.2754, -1.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833095192909241
Epoch 0, Step 893: train/loss = 0.39628490805625916, train/raw-loss = 0.3645848035812378, train/logprobs = tensor([[-1.9926, -3.1280],
        [-3.2440, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3170011043548584
Epoch 0, Step 894: train/loss = 0.38900405168533325, train/raw-loss = 0.3553032875061035, train/logprobs = tensor([[-0.9018, -3.4794],
        [-2.1896, -1.0405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.337007999420166
Epoch 0, Step 895: train/loss = 0.514453649520874, train/raw-loss = 0.4812381863594055, train/logprobs = tensor([[-0.9432, -2.4289],
        [-2.5169, -1.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321548104286194
Epoch 0, Step 896: train/loss = 0.476873517036438, train/raw-loss = 0.4449596405029297, train/logprobs = tensor([[-1.5260, -2.9875],
        [-2.0947, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3191384971141815
Epoch 0, Step 897: train/loss = 0.298805296421051, train/raw-loss = 0.27572953701019287, train/logprobs = tensor([[-0.5443, -5.3410],
        [-1.4059, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23075789213180542
Epoch 0, Step 898: train/loss = 0.2779041826725006, train/raw-loss = 0.24753835797309875, train/logprobs = tensor([[-0.7630, -7.7918],
        [-2.3896, -1.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3036580979824066
Epoch 0, Step 899: train/loss = 0.34433847665786743, train/raw-loss = 0.3173704743385315, train/logprobs = tensor([[-0.8569, -4.0374],
        [-1.8885, -1.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696796655654907
Epoch 0, Step 900: train/loss = 0.21979430317878723, train/raw-loss = 0.18634745478630066, train/logprobs = tensor([[-1.1385, -5.5158],
        [-3.1342, -2.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344683349132538
Epoch 0, Step 901: train/loss = 0.48229312896728516, train/raw-loss = 0.4511580467224121, train/logprobs = tensor([[-0.7741, -3.5568],
        [-1.9001, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31135082244873047
Epoch 0, Step 902: train/loss = 0.3499422073364258, train/raw-loss = 0.3204921782016754, train/logprobs = tensor([[-0.9054, -4.6430],
        [-1.9940, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29450011253356934
Epoch 0, Step 903: train/loss = 0.6368838548660278, train/raw-loss = 0.6079834699630737, train/logprobs = tensor([[-0.7186, -1.0864],
        [-1.9591, -1.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890040874481201
Epoch 0, Step 904: train/loss = 0.43734151124954224, train/raw-loss = 0.4065972864627838, train/logprobs = tensor([[-1.0850, -2.9897],
        [-1.6785, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074426054954529
Epoch 0, Step 905: train/loss = 0.5449476838111877, train/raw-loss = 0.5146574974060059, train/logprobs = tensor([[-0.8728, -4.4030],
        [-1.5988, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3029017746448517
Epoch 0, Step 906: train/loss = 0.43787527084350586, train/raw-loss = 0.4092690348625183, train/logprobs = tensor([[-0.7442, -2.6884],
        [-1.4544, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860625982284546
Epoch 0, Step 907: train/loss = 0.47114133834838867, train/raw-loss = 0.4453546106815338, train/logprobs = tensor([[-0.6377, -2.4714],
        [-1.5590, -1.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25786688923835754
Epoch 0, Step 908: train/loss = 0.5188326835632324, train/raw-loss = 0.49460330605506897, train/logprobs = tensor([[-0.5855, -1.7682],
        [-1.1902, -1.2885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24229370057582855
Epoch 0, Step 909: train/loss = 0.41993141174316406, train/raw-loss = 0.39589035511016846, train/logprobs = tensor([[-0.8414, -3.5800],
        [-1.3200, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24041076004505157
Epoch 0, Step 910: train/loss = 0.2798040509223938, train/raw-loss = 0.24552389979362488, train/logprobs = tensor([[-0.8808, -2.8374],
        [-1.8667, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.342801570892334
Epoch 0, Step 911: train/loss = 0.32889819145202637, train/raw-loss = 0.3025621771812439, train/logprobs = tensor([[-0.8581, -4.7026],
        [-1.7946, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26336026191711426
Epoch 0, Step 912: train/loss = 0.1917010247707367, train/raw-loss = 0.16343578696250916, train/logprobs = tensor([[-1.0634, -5.7174],
        [-2.2371, -0.8235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28265243768692017
Epoch 0, Step 913: train/loss = 0.33883869647979736, train/raw-loss = 0.30445951223373413, train/logprobs = tensor([[-1.0965, -4.1219],
        [-2.8252, -2.4745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437920808792114
Epoch 0, Step 914: train/loss = 0.3332009017467499, train/raw-loss = 0.3021123707294464, train/logprobs = tensor([[-1.4116, -5.0325],
        [-2.3839, -1.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31088507175445557
Epoch 0, Step 915: train/loss = 0.33563822507858276, train/raw-loss = 0.3032643496990204, train/logprobs = tensor([[-1.2398, -3.4001],
        [-1.8885, -0.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237386643886566
Epoch 0, Step 916: train/loss = 0.15044279396533966, train/raw-loss = 0.11862770467996597, train/logprobs = tensor([[-0.7153, -6.5491],
        [-2.4781, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31815075874328613
Epoch 0, Step 917: train/loss = 0.4206494688987732, train/raw-loss = 0.3879004120826721, train/logprobs = tensor([[-0.6829, -2.7889],
        [-1.8543, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3274903893470764
Epoch 0, Step 918: train/loss = 0.344478040933609, train/raw-loss = 0.3146200180053711, train/logprobs = tensor([[-0.5548, -2.7991],
        [-1.4089, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985799312591553
Epoch 0, Step 919: train/loss = 0.6845843195915222, train/raw-loss = 0.6555812358856201, train/logprobs = tensor([[-0.6349, -0.9006],
        [-1.2378, -1.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29003146290779114
Epoch 0, Step 920: train/loss = 0.3621447682380676, train/raw-loss = 0.32926052808761597, train/logprobs = tensor([[-0.6797, -3.9618],
        [-1.9228, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288421928882599
Epoch 0, Step 921: train/loss = 0.3680461645126343, train/raw-loss = 0.34246039390563965, train/logprobs = tensor([[-1.0065, -2.6518],
        [-1.9159, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558578848838806
Epoch 0, Step 922: train/loss = 0.4985838532447815, train/raw-loss = 0.47183313965797424, train/logprobs = tensor([[-0.5637, -4.0458],
        [-1.3254, -2.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2675071656703949
Epoch 0, Step 923: train/loss = 0.5487383604049683, train/raw-loss = 0.5209561586380005, train/logprobs = tensor([[-1.0254, -3.4899],
        [-1.9474, -2.2466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27782195806503296
Epoch 0, Step 924: train/loss = 0.18679678440093994, train/raw-loss = 0.15988710522651672, train/logprobs = tensor([[-0.7239, -4.7817],
        [-1.8085, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26909688115119934
Epoch 0, Step 925: train/loss = 0.3378294110298157, train/raw-loss = 0.30889618396759033, train/logprobs = tensor([[-0.9096, -3.3479],
        [-1.6082, -1.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893325984477997
Epoch 0, Step 926: train/loss = 0.15709462761878967, train/raw-loss = 0.12600481510162354, train/logprobs = tensor([[-0.8632, -7.0194],
        [-2.2319, -1.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108980655670166
Epoch 0, Step 927: train/loss = 0.5281886458396912, train/raw-loss = 0.4985295534133911, train/logprobs = tensor([[-1.0675, -1.7905],
        [-2.1609, -1.3423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965906262397766
Epoch 0, Step 928: train/loss = 0.2882917821407318, train/raw-loss = 0.2554303705692291, train/logprobs = tensor([[-0.6926, -7.7228],
        [-2.2488, -1.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32861387729644775
Epoch 0, Step 929: train/loss = 0.4178173243999481, train/raw-loss = 0.38720279932022095, train/logprobs = tensor([[-1.2514, -6.1759],
        [-1.3807, -1.3438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061453700065613
Epoch 0, Step 930: train/loss = 0.21185943484306335, train/raw-loss = 0.1824123114347458, train/logprobs = tensor([[-0.6361, -4.5122],
        [-1.6787, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29447129368782043
Epoch 0, Step 931: train/loss = 0.27312928438186646, train/raw-loss = 0.24379952251911163, train/logprobs = tensor([[-0.9490, -7.7131],
        [-1.6533, -2.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932977080345154
Epoch 0, Step 932: train/loss = 0.47243040800094604, train/raw-loss = 0.44165197014808655, train/logprobs = tensor([[-0.8020, -2.6858],
        [-2.0706, -1.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30778467655181885
Epoch 0, Step 933: train/loss = 0.3844914436340332, train/raw-loss = 0.35292792320251465, train/logprobs = tensor([[-0.7676, -3.9180],
        [-2.2420, -2.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156351149082184
Epoch 0, Step 934: train/loss = 0.3520050644874573, train/raw-loss = 0.3254537582397461, train/logprobs = tensor([[-0.7836, -6.9475],
        [-1.6547, -2.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26551297307014465
Epoch 0, Step 935: train/loss = 0.34675100445747375, train/raw-loss = 0.3181588351726532, train/logprobs = tensor([[-0.9515, -2.1731],
        [-1.9822, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28592169284820557
Epoch 0, Step 936: train/loss = 0.1679302155971527, train/raw-loss = 0.13833963871002197, train/logprobs = tensor([[-0.7714, -5.7995],
        [-2.0108, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959060072898865
Epoch 0, Step 937: train/loss = 0.25376570224761963, train/raw-loss = 0.22647547721862793, train/logprobs = tensor([[-1.3751, -5.4968],
        [-1.8247, -0.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2729025185108185
Epoch 0, Step 938: train/loss = 0.4357970058917999, train/raw-loss = 0.41175973415374756, train/logprobs = tensor([[-0.5839, -3.1893],
        [-1.0860, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24037286639213562
Epoch 0, Step 939: train/loss = 0.29926255345344543, train/raw-loss = 0.2694854140281677, train/logprobs = tensor([[-0.6865, -4.7049],
        [-1.8038, -1.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2977714538574219
Epoch 0, Step 940: train/loss = 0.6186487078666687, train/raw-loss = 0.5895324945449829, train/logprobs = tensor([[-1.0537, -1.3864],
        [-1.4450, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2911618649959564
Epoch 0, Step 941: train/loss = 0.40395399928092957, train/raw-loss = 0.37163975834846497, train/logprobs = tensor([[-0.8207, -7.9388],
        [-1.8140, -3.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3231423497200012
Epoch 0, Step 942: train/loss = 0.5011475086212158, train/raw-loss = 0.4715684950351715, train/logprobs = tensor([[-0.6948, -3.3782],
        [-1.9393, -1.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957899570465088
Epoch 0, Step 943: train/loss = 0.2948594093322754, train/raw-loss = 0.26658597588539124, train/logprobs = tensor([[-0.6079, -7.0151],
        [-1.9479, -1.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28273460268974304
Epoch 0, Step 944: train/loss = 0.2792488932609558, train/raw-loss = 0.2514461278915405, train/logprobs = tensor([[-0.7598, -4.2183],
        [-1.9345, -0.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780275344848633
Epoch 0, Step 945: train/loss = 0.15057849884033203, train/raw-loss = 0.11646214872598648, train/logprobs = tensor([[-1.5164, -7.9299],
        [-3.1377, -1.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411634564399719
Epoch 0, Step 946: train/loss = 0.10669638216495514, train/raw-loss = 0.07868774980306625, train/logprobs = tensor([[-0.8646, -8.1903],
        [-3.2276, -1.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28008636832237244
Epoch 0, Step 947: train/loss = 0.1684221625328064, train/raw-loss = 0.14247357845306396, train/logprobs = tensor([[-0.7020, -8.8749],
        [-2.1009, -2.3353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25948578119277954
Epoch 0, Step 948: train/loss = 0.4976835250854492, train/raw-loss = 0.4694409668445587, train/logprobs = tensor([[-1.8030, -7.7987],
        [-1.4388, -1.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28242596983909607
Epoch 0, Step 949: train/loss = 0.16159749031066895, train/raw-loss = 0.13394512236118317, train/logprobs = tensor([[ -0.8780, -11.8240],
        [ -2.0478,  -3.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765236794948578
Epoch 0, Step 950: train/loss = 0.5690509676933289, train/raw-loss = 0.5426304340362549, train/logprobs = tensor([[-1.2418, -4.6895],
        [-1.1291, -2.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26420629024505615
Epoch 0, Step 951: train/loss = 0.23172840476036072, train/raw-loss = 0.20373165607452393, train/logprobs = tensor([[-0.7496, -5.2670],
        [-2.1185, -2.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27996760606765747
