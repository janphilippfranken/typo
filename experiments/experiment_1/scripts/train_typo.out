[2024-03-09 12:38:41,747][root][INFO] - beta: 0.1
[2024-03-09 12:38:41,747][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 6250
n harmless: 6250
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.'}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
25000
tokenized 25000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Epoch 0, Step 0: train/loss = 0.6357318162918091, train/raw-loss = 0.6357318162918091, train/logprobs = tensor([[-0.4308, -1.3535],
        [-0.5107, -1.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6757681369781494, train/raw-loss = 0.6757681369781494, train/logprobs = tensor([[-0.6583, -1.0265],
        [-0.6770, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6733909845352173, train/raw-loss = 0.6733909845352173, train/logprobs = tensor([[-0.5174, -0.7039],
        [-0.5662, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6216553449630737, train/raw-loss = 0.6216553449630737, train/logprobs = tensor([[-0.5512, -1.5712],
        [-0.6259, -1.3220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6579127311706543, train/raw-loss = 0.6579127311706543, train/logprobs = tensor([[-0.4046, -1.1550],
        [-0.4271, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.683114767074585, train/raw-loss = 0.683114767074585, train/logprobs = tensor([[-0.4908, -0.8480],
        [-0.5737, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6553336977958679, train/raw-loss = 0.6553336977958679, train/logprobs = tensor([[-0.6499, -0.7840],
        [-0.8093, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6633836627006531, train/raw-loss = 0.6633836627006531, train/logprobs = tensor([[-0.5876, -0.8497],
        [-0.6472, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6661855578422546, train/raw-loss = 0.6661855578422546, train/logprobs = tensor([[-0.3025, -0.9421],
        [-0.3159, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6862294673919678, train/raw-loss = 0.6862294673919678, train/logprobs = tensor([[-0.5552, -0.7072],
        [-0.6376, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6571922302246094, train/raw-loss = 0.6571922302246094, train/logprobs = tensor([[-0.4351, -0.5668],
        [-0.4920, -0.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6538093686103821, train/raw-loss = 0.6538093686103821, train/logprobs = tensor([[-0.5047, -0.8503],
        [-0.5750, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6388410329818726, train/raw-loss = 0.6388410329818726, train/logprobs = tensor([[-0.5834, -1.0723],
        [-0.7193, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.636123776435852, train/raw-loss = 0.636123776435852, train/logprobs = tensor([[-0.6079, -1.3208],
        [-0.7000, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6403026580810547, train/raw-loss = 0.6403026580810547, train/logprobs = tensor([[-0.6212, -0.9649],
        [-0.7200, -0.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6592469811439514, train/raw-loss = 0.6592469811439514, train/logprobs = tensor([[-0.5807, -0.6984],
        [-0.6892, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6758623123168945, train/raw-loss = 0.6758623123168945, train/logprobs = tensor([[-0.5074, -0.5042],
        [-0.5619, -0.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6258509159088135, train/raw-loss = 0.6258509159088135, train/logprobs = tensor([[-0.5446, -1.1194],
        [-0.6294, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.67125004529953, train/raw-loss = 0.67125004529953, train/logprobs = tensor([[-0.7139, -0.7245],
        [-0.8016, -0.7202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6720938682556152, train/raw-loss = 0.6720938682556152, train/logprobs = tensor([[-0.6830, -0.8781],
        [-0.7904, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.5842540264129639, train/raw-loss = 0.5842540264129639, train/logprobs = tensor([[-0.5470, -2.0438],
        [-0.6152, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6704121828079224, train/raw-loss = 0.6704121828079224, train/logprobs = tensor([[-0.4731, -0.6958],
        [-0.5028, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6538590788841248, train/raw-loss = 0.6538590788841248, train/logprobs = tensor([[-0.5006, -1.2025],
        [-0.5373, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.5953183174133301, train/raw-loss = 0.5953183174133301, train/logprobs = tensor([[-0.6232, -2.0455],
        [-0.7372, -1.6707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6878432631492615, train/raw-loss = 0.6878432631492615, train/logprobs = tensor([[-0.4281, -0.5477],
        [-0.4747, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6707193851470947, train/raw-loss = 0.6707193851470947, train/logprobs = tensor([[-0.6576, -1.0605],
        [-0.7231, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6479334831237793, train/raw-loss = 0.6479334831237793, train/logprobs = tensor([[-0.4684, -0.8287],
        [-0.5051, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6747323274612427, train/raw-loss = 0.6747323274612427, train/logprobs = tensor([[-0.6166, -0.6681],
        [-0.6605, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6420547962188721, train/raw-loss = 0.6420547962188721, train/logprobs = tensor([[-0.7694, -1.9529],
        [-0.9380, -1.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6168678998947144, train/raw-loss = 0.6168678998947144, train/logprobs = tensor([[-0.4452, -2.1013],
        [-0.4817, -1.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6610521078109741, train/raw-loss = 0.6610521078109741, train/logprobs = tensor([[-0.5358, -0.9149],
        [-0.5798, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6586809158325195, train/raw-loss = 0.6586809158325195, train/logprobs = tensor([[-0.6870, -1.1920],
        [-0.7340, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.664837121963501, train/raw-loss = 0.664837121963501, train/logprobs = tensor([[-0.4646, -0.9022],
        [-0.5153, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6619232892990112, train/raw-loss = 0.6619232892990112, train/logprobs = tensor([[-0.6717, -0.9461],
        [-0.7005, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.673113226890564, train/raw-loss = 0.673113226890564, train/logprobs = tensor([[-0.4912, -1.0639],
        [-0.5204, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6655296087265015, train/raw-loss = 0.6655296087265015, train/logprobs = tensor([[-0.6594, -1.1156],
        [-0.7206, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6739588975906372, train/raw-loss = 0.6739588975906372, train/logprobs = tensor([[-0.5532, -0.5788],
        [-0.5875, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6338834762573242, train/raw-loss = 0.6338834762573242, train/logprobs = tensor([[-0.5357, -1.3062],
        [-0.5921, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6518142819404602, train/raw-loss = 0.6518142819404602, train/logprobs = tensor([[-0.5693, -0.5938],
        [-0.7053, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6589335203170776, train/raw-loss = 0.6589335203170776, train/logprobs = tensor([[-0.5760, -0.5893],
        [-0.6924, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6720525026321411, train/raw-loss = 0.6720525026321411, train/logprobs = tensor([[-0.5038, -0.6410],
        [-0.5181, -0.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6714937090873718, train/raw-loss = 0.6714937090873718, train/logprobs = tensor([[-0.5809, -0.7280],
        [-0.6262, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6708586812019348, train/raw-loss = 0.6708586812019348, train/logprobs = tensor([[-0.5863, -0.7004],
        [-0.6134, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6875094771385193, train/raw-loss = 0.6875094771385193, train/logprobs = tensor([[-0.4998, -1.0725],
        [-0.5624, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5380761623382568, train/raw-loss = 0.5380761623382568, train/logprobs = tensor([[-0.4741, -2.4161],
        [-0.4990, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6509513258934021, train/raw-loss = 0.6509513258934021, train/logprobs = tensor([[-0.4149, -0.7730],
        [-0.4313, -0.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6810438632965088, train/raw-loss = 0.6810438632965088, train/logprobs = tensor([[-0.5093, -0.7886],
        [-0.5134, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6813392043113708, train/raw-loss = 0.6813392043113708, train/logprobs = tensor([[-0.4674, -0.5622],
        [-0.5299, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6694720983505249, train/raw-loss = 0.6694720983505249, train/logprobs = tensor([[-0.4809, -0.5951],
        [-0.5345, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6698030233383179, train/raw-loss = 0.6698030233383179, train/logprobs = tensor([[-0.4878, -1.2704],
        [-0.5137, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.632347822189331, train/raw-loss = 0.632347822189331, train/logprobs = tensor([[-0.5886, -0.8578],
        [-0.7197, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6996501684188843, train/raw-loss = 0.6996501684188843, train/logprobs = tensor([[-0.2713, -0.7126],
        [-0.2906, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6715490818023682, train/raw-loss = 0.6715490818023682, train/logprobs = tensor([[-0.4793, -0.7849],
        [-0.5272, -0.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6130907535552979, train/raw-loss = 0.6130907535552979, train/logprobs = tensor([[-0.3979, -2.4016],
        [-0.4313, -2.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6360349655151367, train/raw-loss = 0.6360349655151367, train/logprobs = tensor([[-0.5770, -0.9309],
        [-0.6844, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6616557836532593, train/raw-loss = 0.6616557836532593, train/logprobs = tensor([[-0.6555, -0.7382],
        [-0.7202, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6659979820251465, train/raw-loss = 0.6659979820251465, train/logprobs = tensor([[-0.5820, -0.7864],
        [-0.6325, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6489294767379761, train/raw-loss = 0.6489294767379761, train/logprobs = tensor([[-0.4988, -1.0954],
        [-0.5200, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6267923712730408, train/raw-loss = 0.6267923712730408, train/logprobs = tensor([[-2.0627, -3.6992],
        [-2.2622, -3.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6528545022010803, train/raw-loss = 0.6528545022010803, train/logprobs = tensor([[-0.5762, -0.7849],
        [-0.6352, -0.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6606899499893188, train/raw-loss = 0.6606899499893188, train/logprobs = tensor([[-0.4071, -0.6905],
        [-0.4721, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6776509881019592, train/raw-loss = 0.6776509881019592, train/logprobs = tensor([[-0.4609, -0.6000],
        [-0.4977, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6627519130706787, train/raw-loss = 0.6627519130706787, train/logprobs = tensor([[-0.4391, -0.8643],
        [-0.4521, -0.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6181536316871643, train/raw-loss = 0.6181536316871643, train/logprobs = tensor([[-0.5320, -1.4591],
        [-0.5787, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6820874214172363, train/raw-loss = 0.6814072132110596, train/logprobs = tensor([[-0.4576, -0.5742],
        [-0.4668, -0.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006801497656852007
Epoch 0, Step 65: train/loss = 0.5957750082015991, train/raw-loss = 0.5949435830116272, train/logprobs = tensor([[-0.4441, -1.6037],
        [-0.4783, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008314142934978008
Epoch 0, Step 66: train/loss = 0.6487573981285095, train/raw-loss = 0.6476504802703857, train/logprobs = tensor([[-1.1627, -1.7749],
        [-0.9963, -1.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011068661697208881
Epoch 0, Step 67: train/loss = 0.6398006677627563, train/raw-loss = 0.6388007402420044, train/logprobs = tensor([[-0.4784, -1.1684],
        [-0.4829, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009999201633036137
Epoch 0, Step 68: train/loss = 0.6472541093826294, train/raw-loss = 0.6465131044387817, train/logprobs = tensor([[-0.3706, -0.7966],
        [-0.3623, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007409712765365839
Epoch 0, Step 69: train/loss = 0.5600113272666931, train/raw-loss = 0.5591483116149902, train/logprobs = tensor([[-0.5781, -2.4763],
        [-0.5897, -1.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008630229160189629
Epoch 0, Step 70: train/loss = 0.6129515171051025, train/raw-loss = 0.6122000217437744, train/logprobs = tensor([[-0.4490, -1.2984],
        [-0.4549, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007514480035752058
Epoch 0, Step 71: train/loss = 0.6228153109550476, train/raw-loss = 0.6217036247253418, train/logprobs = tensor([[-0.5534, -0.8093],
        [-0.6372, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011116808280348778
Epoch 0, Step 72: train/loss = 0.5655845999717712, train/raw-loss = 0.5645176768302917, train/logprobs = tensor([[-0.7020, -1.6979],
        [-0.7581, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010668954811990261
Epoch 0, Step 73: train/loss = 0.6567859649658203, train/raw-loss = 0.6558020114898682, train/logprobs = tensor([[-0.4939, -0.7364],
        [-0.4656, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009839940816164017
Epoch 0, Step 74: train/loss = 0.5972151160240173, train/raw-loss = 0.5963929891586304, train/logprobs = tensor([[-0.6678, -1.4465],
        [-0.7603, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008220973424613476
Epoch 0, Step 75: train/loss = 0.5903798937797546, train/raw-loss = 0.5896713733673096, train/logprobs = tensor([[-0.4017, -2.0879],
        [-0.3987, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00708567863330245
Epoch 0, Step 76: train/loss = 0.6279892921447754, train/raw-loss = 0.627021312713623, train/logprobs = tensor([[-0.5864, -1.2565],
        [-0.5719, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009679783135652542
Epoch 0, Step 77: train/loss = 0.6367727518081665, train/raw-loss = 0.6355708837509155, train/logprobs = tensor([[-0.6665, -0.8860],
        [-0.6662, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01201922632753849
Epoch 0, Step 78: train/loss = 0.6005046367645264, train/raw-loss = 0.5996122360229492, train/logprobs = tensor([[-0.5792, -1.8067],
        [-0.6059, -1.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008924270048737526
Epoch 0, Step 79: train/loss = 0.6224303841590881, train/raw-loss = 0.6215672492980957, train/logprobs = tensor([[-0.3824, -1.2958],
        [-0.3764, -0.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008631668984889984
Epoch 0, Step 80: train/loss = 0.6107966303825378, train/raw-loss = 0.609711766242981, train/logprobs = tensor([[-0.6785, -1.3076],
        [-0.6684, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01084819994866848
Epoch 0, Step 81: train/loss = 0.6504307389259338, train/raw-loss = 0.6497045755386353, train/logprobs = tensor([[-0.4916, -0.7111],
        [-0.4925, -0.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007261984050273895
Epoch 0, Step 82: train/loss = 0.5303637981414795, train/raw-loss = 0.5297713279724121, train/logprobs = tensor([[-0.4696, -2.2179],
        [-0.4580, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005924359429627657
Epoch 0, Step 83: train/loss = 0.6208953261375427, train/raw-loss = 0.6199029684066772, train/logprobs = tensor([[-0.4720, -0.9659],
        [-0.4964, -0.6663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009923079051077366
Epoch 0, Step 84: train/loss = 0.6117369532585144, train/raw-loss = 0.610809326171875, train/logprobs = tensor([[-0.5307, -1.1778],
        [-0.6002, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009276539087295532
Epoch 0, Step 85: train/loss = 0.6350548267364502, train/raw-loss = 0.6340757012367249, train/logprobs = tensor([[-0.4991, -1.1052],
        [-0.5053, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009791427291929722
Epoch 0, Step 86: train/loss = 0.6597545146942139, train/raw-loss = 0.658560037612915, train/logprobs = tensor([[-0.6071, -1.2311],
        [-0.6108, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011945274658501148
Epoch 0, Step 87: train/loss = 0.654765248298645, train/raw-loss = 0.6538283824920654, train/logprobs = tensor([[-0.4653, -1.2461],
        [-0.4437, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009368820115923882
Epoch 0, Step 88: train/loss = 0.6554769277572632, train/raw-loss = 0.6545714139938354, train/logprobs = tensor([[-0.3897, -0.9639],
        [-0.3879, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009055373258888721
Epoch 0, Step 89: train/loss = 0.6448459029197693, train/raw-loss = 0.6440523862838745, train/logprobs = tensor([[-0.4592, -1.0687],
        [-0.4915, -0.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007935182191431522
Epoch 0, Step 90: train/loss = 0.5444152355194092, train/raw-loss = 0.5435357093811035, train/logprobs = tensor([[-0.5449, -2.8692],
        [-0.5411, -1.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008795466274023056
Epoch 0, Step 91: train/loss = 0.577958881855011, train/raw-loss = 0.5768208503723145, train/logprobs = tensor([[-0.5036, -2.3044],
        [-0.5134, -1.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011380807496607304
Epoch 0, Step 92: train/loss = 0.49848222732543945, train/raw-loss = 0.49769189953804016, train/logprobs = tensor([[-0.4789, -2.4312],
        [-0.4965, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007902741432189941
Epoch 0, Step 93: train/loss = 0.6454032063484192, train/raw-loss = 0.6444779634475708, train/logprobs = tensor([[-0.4442, -0.9605],
        [-0.4503, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009252526797354221
Epoch 0, Step 94: train/loss = 0.5942564010620117, train/raw-loss = 0.5932857990264893, train/logprobs = tensor([[-0.5568, -1.2523],
        [-0.5568, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00970593560487032
Epoch 0, Step 95: train/loss = 0.6198204159736633, train/raw-loss = 0.6188503503799438, train/logprobs = tensor([[-0.6704, -1.0657],
        [-0.7533, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009701228700578213
Epoch 0, Step 96: train/loss = 0.591162919998169, train/raw-loss = 0.5874932408332825, train/logprobs = tensor([[-0.7947, -2.7525],
        [-0.6098, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036696698516607285
Epoch 0, Step 97: train/loss = 0.5831457376480103, train/raw-loss = 0.5795599222183228, train/logprobs = tensor([[-0.7660, -1.3926],
        [-0.6932, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03585890308022499
Epoch 0, Step 98: train/loss = 0.6508283615112305, train/raw-loss = 0.6467031240463257, train/logprobs = tensor([[-0.6774, -0.9310],
        [-0.7002, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041252583265304565
Epoch 0, Step 99: train/loss = 0.6028856039047241, train/raw-loss = 0.5985443592071533, train/logprobs = tensor([[-0.7778, -1.3414],
        [-0.7664, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04341280460357666
Epoch 0, Step 100: train/loss = 0.6520776748657227, train/raw-loss = 0.647986114025116, train/logprobs = tensor([[-0.5942, -1.2595],
        [-0.5518, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04091562703251839
Epoch 0, Step 101: train/loss = 0.6104196906089783, train/raw-loss = 0.6062973737716675, train/logprobs = tensor([[-0.6680, -1.6016],
        [-0.6196, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04122394695878029
Epoch 0, Step 102: train/loss = 0.6955945491790771, train/raw-loss = 0.6901054382324219, train/logprobs = tensor([[-0.5270, -0.9669],
        [-0.5161, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054890960454940796
Epoch 0, Step 103: train/loss = 0.48515939712524414, train/raw-loss = 0.4820190370082855, train/logprobs = tensor([[-0.5755, -2.0488],
        [-0.5617, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03140341117978096
Epoch 0, Step 104: train/loss = 0.5712823271751404, train/raw-loss = 0.5675188302993774, train/logprobs = tensor([[-0.5133, -1.8410],
        [-0.4542, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03763463720679283
Epoch 0, Step 105: train/loss = 0.6220300197601318, train/raw-loss = 0.6181530356407166, train/logprobs = tensor([[-0.6213, -1.0491],
        [-0.6056, -0.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038770101964473724
Epoch 0, Step 106: train/loss = 0.4925798773765564, train/raw-loss = 0.4879246950149536, train/logprobs = tensor([[-0.8471, -2.6983],
        [-0.8961, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046551525592803955
Epoch 0, Step 107: train/loss = 0.6331770420074463, train/raw-loss = 0.6293964385986328, train/logprobs = tensor([[-0.4626, -1.0758],
        [-0.3835, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03780646249651909
Epoch 0, Step 108: train/loss = 0.6619423627853394, train/raw-loss = 0.6585388779640198, train/logprobs = tensor([[-0.4107, -1.4332],
        [-0.3797, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03403551131486893
Epoch 0, Step 109: train/loss = 0.6798118352890015, train/raw-loss = 0.6753641366958618, train/logprobs = tensor([[-0.8586, -0.9069],
        [-0.7534, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04447672888636589
Epoch 0, Step 110: train/loss = 0.6476389169692993, train/raw-loss = 0.6439502239227295, train/logprobs = tensor([[-0.5036, -1.0694],
        [-0.4640, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03688696771860123
Epoch 0, Step 111: train/loss = 0.6000962257385254, train/raw-loss = 0.5966075658798218, train/logprobs = tensor([[-0.6126, -1.4304],
        [-0.5676, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03488669916987419
Epoch 0, Step 112: train/loss = 0.589249312877655, train/raw-loss = 0.585649847984314, train/logprobs = tensor([[-0.5586, -1.5087],
        [-0.4844, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03599439188838005
Epoch 0, Step 113: train/loss = 0.5969264507293701, train/raw-loss = 0.595300555229187, train/logprobs = tensor([[-0.2409, -1.4274],
        [-0.2036, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01625881902873516
Epoch 0, Step 114: train/loss = 0.6702044010162354, train/raw-loss = 0.6666045188903809, train/logprobs = tensor([[-0.5956, -0.8859],
        [-0.5311, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03599882498383522
Epoch 0, Step 115: train/loss = 0.6106775999069214, train/raw-loss = 0.6067952513694763, train/logprobs = tensor([[-0.6834, -2.3134],
        [-0.5934, -1.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03882337361574173
Epoch 0, Step 116: train/loss = 0.6255742311477661, train/raw-loss = 0.621394693851471, train/logprobs = tensor([[-0.5442, -1.0970],
        [-0.4786, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04179506376385689
Epoch 0, Step 117: train/loss = 0.6165449023246765, train/raw-loss = 0.6127249002456665, train/logprobs = tensor([[-0.6517, -1.0471],
        [-0.6237, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03820008784532547
Epoch 0, Step 118: train/loss = 0.5360963344573975, train/raw-loss = 0.5322203636169434, train/logprobs = tensor([[-0.5888, -2.0036],
        [-0.5292, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03875971958041191
Epoch 0, Step 119: train/loss = 0.6615574359893799, train/raw-loss = 0.65898597240448, train/logprobs = tensor([[-0.4607, -0.7225],
        [-0.4376, -0.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02571459487080574
Epoch 0, Step 120: train/loss = 0.6031944751739502, train/raw-loss = 0.5990038514137268, train/logprobs = tensor([[-0.6750, -1.5621],
        [-0.6345, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041906505823135376
Epoch 0, Step 121: train/loss = 0.56661456823349, train/raw-loss = 0.5636376142501831, train/logprobs = tensor([[-0.6490, -1.7760],
        [-0.5547, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029769878834486008
Epoch 0, Step 122: train/loss = 0.6043785214424133, train/raw-loss = 0.5998951196670532, train/logprobs = tensor([[-0.6428, -1.9050],
        [-0.6137, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044834014028310776
Epoch 0, Step 123: train/loss = 0.6246132850646973, train/raw-loss = 0.6210050582885742, train/logprobs = tensor([[-0.5773, -1.2031],
        [-0.5508, -0.8483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03608163073658943
Epoch 0, Step 124: train/loss = 0.6067762970924377, train/raw-loss = 0.6039432287216187, train/logprobs = tensor([[-0.4511, -1.3401],
        [-0.4321, -0.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02833043783903122
Epoch 0, Step 125: train/loss = 0.561526894569397, train/raw-loss = 0.5576634407043457, train/logprobs = tensor([[-0.5130, -1.6792],
        [-0.4810, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038634806871414185
Epoch 0, Step 126: train/loss = 0.6222957372665405, train/raw-loss = 0.6184914112091064, train/logprobs = tensor([[-0.7268, -1.1428],
        [-0.7182, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0380430705845356
Epoch 0, Step 127: train/loss = 0.6178082227706909, train/raw-loss = 0.6135902404785156, train/logprobs = tensor([[-0.5762, -1.4279],
        [-0.5711, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04217991232872009
Epoch 0, Step 128: train/loss = 0.6837109923362732, train/raw-loss = 0.6741201281547546, train/logprobs = tensor([[-0.7310, -0.9363],
        [-0.4892, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590867906808853
Epoch 0, Step 129: train/loss = 0.5236629843711853, train/raw-loss = 0.5140695571899414, train/logprobs = tensor([[-0.5521, -3.7832],
        [-0.4947, -1.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09593458473682404
Epoch 0, Step 130: train/loss = 0.6290158629417419, train/raw-loss = 0.6211485266685486, train/logprobs = tensor([[-0.7656, -1.5200],
        [-0.5075, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867259532213211
Epoch 0, Step 131: train/loss = 0.6005948185920715, train/raw-loss = 0.5923901796340942, train/logprobs = tensor([[-0.5915, -1.2024],
        [-0.4892, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204691857099533
Epoch 0, Step 132: train/loss = 0.6760640144348145, train/raw-loss = 0.6663393378257751, train/logprobs = tensor([[-0.5940, -1.0922],
        [-0.5350, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09724743664264679
Epoch 0, Step 133: train/loss = 0.5440711975097656, train/raw-loss = 0.5360628962516785, train/logprobs = tensor([[-0.5147, -3.7285],
        [-0.4346, -2.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008325099945068
Epoch 0, Step 134: train/loss = 0.6053999662399292, train/raw-loss = 0.5959515571594238, train/logprobs = tensor([[-0.6418, -1.5266],
        [-0.5426, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09448391944169998
Epoch 0, Step 135: train/loss = 0.6645315885543823, train/raw-loss = 0.6555357575416565, train/logprobs = tensor([[-0.6659, -0.9665],
        [-0.6240, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995814621448517
Epoch 0, Step 136: train/loss = 0.7132527828216553, train/raw-loss = 0.7030572891235352, train/logprobs = tensor([[-0.7471, -1.0111],
        [-0.6734, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10195525735616684
Epoch 0, Step 137: train/loss = 0.6022766828536987, train/raw-loss = 0.5933217406272888, train/logprobs = tensor([[-0.7539, -1.7827],
        [-0.5945, -1.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895489826798439
Epoch 0, Step 138: train/loss = 0.6348962783813477, train/raw-loss = 0.6287051439285278, train/logprobs = tensor([[-0.4937, -1.3370],
        [-0.4522, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061911627650260925
Epoch 0, Step 139: train/loss = 0.5248610377311707, train/raw-loss = 0.5147934556007385, train/logprobs = tensor([[-0.6251, -2.2454],
        [-0.4977, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006762832403183
Epoch 0, Step 140: train/loss = 0.5059272646903992, train/raw-loss = 0.49837735295295715, train/logprobs = tensor([[-0.6398, -2.5728],
        [-0.5803, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754990205168724
Epoch 0, Step 141: train/loss = 0.6660427451133728, train/raw-loss = 0.6554761528968811, train/logprobs = tensor([[-0.9191, -1.2565],
        [-0.8512, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10566620528697968
Epoch 0, Step 142: train/loss = 0.4772665500640869, train/raw-loss = 0.4701312184333801, train/logprobs = tensor([[-0.4517, -2.4309],
        [-0.3867, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07135336101055145
Epoch 0, Step 143: train/loss = 0.5571330189704895, train/raw-loss = 0.5497881174087524, train/logprobs = tensor([[-0.5804, -1.9591],
        [-0.4495, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07344964146614075
Epoch 0, Step 144: train/loss = 0.5902506113052368, train/raw-loss = 0.5801821351051331, train/logprobs = tensor([[-0.8495, -3.5297],
        [-0.8233, -1.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068447887897491
Epoch 0, Step 145: train/loss = 0.6348142623901367, train/raw-loss = 0.6276957988739014, train/logprobs = tensor([[-0.6091, -1.1994],
        [-0.5215, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07118478417396545
Epoch 0, Step 146: train/loss = 0.5912037491798401, train/raw-loss = 0.5817887187004089, train/logprobs = tensor([[-0.6849, -1.3849],
        [-0.5756, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09415067732334137
Epoch 0, Step 147: train/loss = 0.5681937336921692, train/raw-loss = 0.56001877784729, train/logprobs = tensor([[-0.5551, -1.6406],
        [-0.4144, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174972236156464
Epoch 0, Step 148: train/loss = 0.5866061449050903, train/raw-loss = 0.5778346061706543, train/logprobs = tensor([[-0.6060, -1.8242],
        [-0.5061, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771514147520065
Epoch 0, Step 149: train/loss = 0.6299426555633545, train/raw-loss = 0.6198700666427612, train/logprobs = tensor([[-0.8878, -1.3324],
        [-0.6990, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10072635114192963
Epoch 0, Step 150: train/loss = 0.6525354385375977, train/raw-loss = 0.6424309015274048, train/logprobs = tensor([[-0.5991, -1.4388],
        [-0.5324, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104546695947647
Epoch 0, Step 151: train/loss = 0.6843848824501038, train/raw-loss = 0.6750178337097168, train/logprobs = tensor([[-0.8748, -0.9979],
        [-0.8188, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09367027878761292
Epoch 0, Step 152: train/loss = 0.6133463382720947, train/raw-loss = 0.6083780527114868, train/logprobs = tensor([[-0.3407, -0.9438],
        [-0.3039, -0.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049682509154081345
Epoch 0, Step 153: train/loss = 0.7126646637916565, train/raw-loss = 0.7030559182167053, train/logprobs = tensor([[-0.8890, -0.8486],
        [-0.7056, -0.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608796238899231
Epoch 0, Step 154: train/loss = 0.6276669502258301, train/raw-loss = 0.6201465129852295, train/logprobs = tensor([[-0.5525, -0.9782],
        [-0.4470, -0.5091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07520416378974915
Epoch 0, Step 155: train/loss = 0.5505111217498779, train/raw-loss = 0.5427112579345703, train/logprobs = tensor([[-0.5402, -1.9030],
        [-0.4909, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07799886912107468
Epoch 0, Step 156: train/loss = 0.516340970993042, train/raw-loss = 0.5063523650169373, train/logprobs = tensor([[-0.7365, -2.8962],
        [-0.6149, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988606721162796
Epoch 0, Step 157: train/loss = 0.7249419689178467, train/raw-loss = 0.7164520025253296, train/logprobs = tensor([[-0.6591, -0.5950],
        [-0.5549, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08490028232336044
Epoch 0, Step 158: train/loss = 0.5432486534118652, train/raw-loss = 0.5332909822463989, train/logprobs = tensor([[-0.7213, -1.9613],
        [-0.6441, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957678616046906
Epoch 0, Step 159: train/loss = 0.604211688041687, train/raw-loss = 0.595909595489502, train/logprobs = tensor([[-0.5784, -1.9322],
        [-0.5151, -1.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830216258764267
Epoch 0, Step 160: train/loss = 0.5831317901611328, train/raw-loss = 0.5729750990867615, train/logprobs = tensor([[-0.7453, -3.3856],
        [-0.5927, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10156761109828949
Epoch 0, Step 161: train/loss = 0.593526303768158, train/raw-loss = 0.5851012468338013, train/logprobs = tensor([[-0.7147, -1.2485],
        [-0.5601, -0.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08425034582614899
Epoch 0, Step 162: train/loss = 0.5029023885726929, train/raw-loss = 0.49322131276130676, train/logprobs = tensor([[-0.6099, -2.4566],
        [-0.5202, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968107059597969
Epoch 0, Step 163: train/loss = 0.586367666721344, train/raw-loss = 0.5756685733795166, train/logprobs = tensor([[-0.9277, -3.1629],
        [-0.7200, -1.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699045658111572
Epoch 0, Step 164: train/loss = 0.5256036520004272, train/raw-loss = 0.51887446641922, train/logprobs = tensor([[-0.3317, -1.9614],
        [-0.3060, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06729167699813843
Epoch 0, Step 165: train/loss = 0.5648055672645569, train/raw-loss = 0.5559733510017395, train/logprobs = tensor([[-0.6601, -3.8237],
        [-0.4751, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.088322214782238
Epoch 0, Step 166: train/loss = 0.6505887508392334, train/raw-loss = 0.6408052444458008, train/logprobs = tensor([[-0.6533, -0.9919],
        [-0.5616, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783516824245453
Epoch 0, Step 167: train/loss = 0.6476554870605469, train/raw-loss = 0.6376651525497437, train/logprobs = tensor([[-0.9080, -1.2581],
        [-0.7496, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09990333020687103
Epoch 0, Step 168: train/loss = 0.6067879796028137, train/raw-loss = 0.5957258343696594, train/logprobs = tensor([[-0.6226, -3.4236],
        [-0.5687, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106209084391594
Epoch 0, Step 169: train/loss = 0.6719480156898499, train/raw-loss = 0.6635764837265015, train/logprobs = tensor([[-0.5395, -0.6947],
        [-0.4792, -0.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371498435735703
Epoch 0, Step 170: train/loss = 0.4648626446723938, train/raw-loss = 0.4559444487094879, train/logprobs = tensor([[-0.7222, -3.4105],
        [-0.5697, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08918174356222153
Epoch 0, Step 171: train/loss = 0.5587751269340515, train/raw-loss = 0.5493434071540833, train/logprobs = tensor([[-0.6243, -3.5521],
        [-0.5272, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09431741386651993
Epoch 0, Step 172: train/loss = 0.5624178647994995, train/raw-loss = 0.5548979043960571, train/logprobs = tensor([[-0.4962, -1.8827],
        [-0.4493, -0.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751996636390686
Epoch 0, Step 173: train/loss = 0.6118946075439453, train/raw-loss = 0.6048682928085327, train/logprobs = tensor([[-0.5161, -1.1849],
        [-0.3427, -0.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07026289403438568
Epoch 0, Step 174: train/loss = 0.5691028237342834, train/raw-loss = 0.5606299638748169, train/logprobs = tensor([[-0.6110, -1.6802],
        [-0.5116, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472815155982971
Epoch 0, Step 175: train/loss = 0.5699092745780945, train/raw-loss = 0.5614065527915955, train/logprobs = tensor([[-0.5359, -1.4788],
        [-0.4731, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502689749002457
Epoch 0, Step 176: train/loss = 0.5990058779716492, train/raw-loss = 0.5898904204368591, train/logprobs = tensor([[-0.6194, -1.2043],
        [-0.4519, -0.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09115464985370636
Epoch 0, Step 177: train/loss = 0.6642980575561523, train/raw-loss = 0.6564202904701233, train/logprobs = tensor([[-0.4703, -0.7796],
        [-0.4290, -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877743244171143
Epoch 0, Step 178: train/loss = 0.5114372968673706, train/raw-loss = 0.5026142597198486, train/logprobs = tensor([[-0.7211, -1.7228],
        [-0.5826, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08822962641716003
Epoch 0, Step 179: train/loss = 0.4114222824573517, train/raw-loss = 0.4029769003391266, train/logprobs = tensor([[-0.5902, -4.8809],
        [-0.4622, -1.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445388823747635
Epoch 0, Step 180: train/loss = 0.4235262870788574, train/raw-loss = 0.41500619053840637, train/logprobs = tensor([[-0.6252, -4.6154],
        [-0.4903, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08520081639289856
Epoch 0, Step 181: train/loss = 0.5573139786720276, train/raw-loss = 0.549824595451355, train/logprobs = tensor([[-0.5046, -1.3831],
        [-0.4341, -0.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07489372789859772
Epoch 0, Step 182: train/loss = 0.7063695788383484, train/raw-loss = 0.6926571130752563, train/logprobs = tensor([[-0.8869, -2.2873],
        [-0.8754, -2.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13712498545646667
Epoch 0, Step 183: train/loss = 0.5861615538597107, train/raw-loss = 0.5764849781990051, train/logprobs = tensor([[-0.6146, -1.2582],
        [-0.6747, -0.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676559269428253
Epoch 0, Step 184: train/loss = 0.5917637348175049, train/raw-loss = 0.585432767868042, train/logprobs = tensor([[-0.3993, -1.0528],
        [-0.3911, -0.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330953538417816
Epoch 0, Step 185: train/loss = 0.5357348918914795, train/raw-loss = 0.5260408520698547, train/logprobs = tensor([[-0.8207, -3.0136],
        [-0.6905, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09694021195173264
Epoch 0, Step 186: train/loss = 0.7214650511741638, train/raw-loss = 0.7101313471794128, train/logprobs = tensor([[-0.9362, -1.1132],
        [-0.6041, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11333678662776947
Epoch 0, Step 187: train/loss = 0.5807318687438965, train/raw-loss = 0.5719548463821411, train/logprobs = tensor([[-0.6241, -1.2738],
        [-0.4418, -0.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777011930942535
Epoch 0, Step 188: train/loss = 0.577682614326477, train/raw-loss = 0.5703681707382202, train/logprobs = tensor([[-0.5799, -1.2581],
        [-0.3971, -0.4358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07314436137676239
Epoch 0, Step 189: train/loss = 0.6289218068122864, train/raw-loss = 0.6206053495407104, train/logprobs = tensor([[-0.4741, -0.9060],
        [-0.4011, -0.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08316442370414734
Epoch 0, Step 190: train/loss = 0.5401083827018738, train/raw-loss = 0.5318361520767212, train/logprobs = tensor([[-0.7564, -1.4967],
        [-0.6635, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08272227644920349
Epoch 0, Step 191: train/loss = 0.536120593547821, train/raw-loss = 0.5275093913078308, train/logprobs = tensor([[-0.6443, -2.0228],
        [-0.4961, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861116498708725
Epoch 0, Step 192: train/loss = 0.6430890560150146, train/raw-loss = 0.6302168369293213, train/logprobs = tensor([[-0.6358, -0.8824],
        [-0.5378, -0.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287221759557724
Epoch 0, Step 193: train/loss = 0.375953733921051, train/raw-loss = 0.36576735973358154, train/logprobs = tensor([[-0.6350, -4.5066],
        [-0.4190, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101863794028759
Epoch 0, Step 194: train/loss = 0.495399534702301, train/raw-loss = 0.48474329710006714, train/logprobs = tensor([[-0.7459, -2.3705],
        [-0.4738, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656240582466125
Epoch 0, Step 195: train/loss = 0.5434034466743469, train/raw-loss = 0.5305945873260498, train/logprobs = tensor([[-0.6967, -1.9299],
        [-0.4504, -0.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12808866798877716
Epoch 0, Step 196: train/loss = 0.559112012386322, train/raw-loss = 0.5480542182922363, train/logprobs = tensor([[-0.7384, -1.5772],
        [-0.5335, -0.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057741194963455
Epoch 0, Step 197: train/loss = 0.6114766597747803, train/raw-loss = 0.596592903137207, train/logprobs = tensor([[-0.9966, -3.1876],
        [-0.5807, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488378345966339
Epoch 0, Step 198: train/loss = 0.5370699763298035, train/raw-loss = 0.5237736105918884, train/logprobs = tensor([[-0.8037, -4.2054],
        [-0.5135, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13296374678611755
Epoch 0, Step 199: train/loss = 0.6141733527183533, train/raw-loss = 0.600273609161377, train/logprobs = tensor([[-1.1701, -2.0821],
        [-0.4549, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1389979124069214
Epoch 0, Step 200: train/loss = 0.5234861969947815, train/raw-loss = 0.5126494765281677, train/logprobs = tensor([[-0.6360, -2.2322],
        [-0.5324, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10836734622716904
Epoch 0, Step 201: train/loss = 0.5029345154762268, train/raw-loss = 0.49665555357933044, train/logprobs = tensor([[-0.3154, -1.6765],
        [-0.2560, -0.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278935819864273
Epoch 0, Step 202: train/loss = 0.5274627208709717, train/raw-loss = 0.5144803524017334, train/logprobs = tensor([[-0.7930, -2.1418],
        [-0.5565, -0.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12982416152954102
Epoch 0, Step 203: train/loss = 0.5612436532974243, train/raw-loss = 0.5477520227432251, train/logprobs = tensor([[-0.7189, -1.9651],
        [-0.6103, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13491618633270264
Epoch 0, Step 204: train/loss = 0.5257013440132141, train/raw-loss = 0.5165968537330627, train/logprobs = tensor([[-0.4856, -1.5548],
        [-0.4137, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09104478359222412
Epoch 0, Step 205: train/loss = 0.6187669038772583, train/raw-loss = 0.6057245135307312, train/logprobs = tensor([[-1.2601, -2.4570],
        [-0.6369, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13042429089546204
Epoch 0, Step 206: train/loss = 0.45899906754493713, train/raw-loss = 0.4474884867668152, train/logprobs = tensor([[-0.6855, -2.4938],
        [-0.5586, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1151060163974762
Epoch 0, Step 207: train/loss = 0.6326180696487427, train/raw-loss = 0.621057391166687, train/logprobs = tensor([[-0.6279, -1.0962],
        [-0.4623, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11560730636119843
Epoch 0, Step 208: train/loss = 0.603408932685852, train/raw-loss = 0.5883186459541321, train/logprobs = tensor([[-1.1960, -2.0430],
        [-0.7551, -0.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15090303122997284
Epoch 0, Step 209: train/loss = 0.5624982118606567, train/raw-loss = 0.5483160018920898, train/logprobs = tensor([[-0.7059, -1.5460],
        [-0.5807, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418224573135376
Epoch 0, Step 210: train/loss = 0.5015690326690674, train/raw-loss = 0.4911596477031708, train/logprobs = tensor([[-0.4885, -1.8212],
        [-0.3269, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10409373790025711
Epoch 0, Step 211: train/loss = 0.6004880666732788, train/raw-loss = 0.5881300568580627, train/logprobs = tensor([[-0.6201, -1.1775],
        [-0.4241, -0.3199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12357993423938751
Epoch 0, Step 212: train/loss = 0.6451186537742615, train/raw-loss = 0.6350487470626831, train/logprobs = tensor([[-1.0434, -2.0972],
        [-0.4042, -0.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10069883614778519
Epoch 0, Step 213: train/loss = 0.7080227136611938, train/raw-loss = 0.6927084922790527, train/logprobs = tensor([[-0.7664, -0.9083],
        [-0.6939, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15314257144927979
Epoch 0, Step 214: train/loss = 0.6292694211006165, train/raw-loss = 0.6189601421356201, train/logprobs = tensor([[-0.7277, -1.0578],
        [-0.5495, -0.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309294611215591
Epoch 0, Step 215: train/loss = 0.4712907075881958, train/raw-loss = 0.45415976643562317, train/logprobs = tensor([[-1.0882, -4.3040],
        [-0.9040, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17130941152572632
Epoch 0, Step 216: train/loss = 0.5136361122131348, train/raw-loss = 0.49947723746299744, train/logprobs = tensor([[-0.9617, -2.0464],
        [-0.6917, -0.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14158912003040314
Epoch 0, Step 217: train/loss = 0.6615309119224548, train/raw-loss = 0.6455205678939819, train/logprobs = tensor([[-0.8827, -1.4411],
        [-0.6528, -0.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16010282933712006
Epoch 0, Step 218: train/loss = 0.6447501182556152, train/raw-loss = 0.6277894973754883, train/logprobs = tensor([[-1.1349, -2.0624],
        [-0.8404, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.169606015086174
Epoch 0, Step 219: train/loss = 0.6089887619018555, train/raw-loss = 0.5955644249916077, train/logprobs = tensor([[-1.1968, -2.5750],
        [-0.6451, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13424304127693176
Epoch 0, Step 220: train/loss = 0.6452546119689941, train/raw-loss = 0.6330817937850952, train/logprobs = tensor([[-0.7524, -0.9478],
        [-0.5963, -0.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172854691743851
Epoch 0, Step 221: train/loss = 0.4074178636074066, train/raw-loss = 0.39603865146636963, train/logprobs = tensor([[-0.8120, -3.7562],
        [-0.5042, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11379212141036987
Epoch 0, Step 222: train/loss = 0.5697647333145142, train/raw-loss = 0.5587987899780273, train/logprobs = tensor([[-0.7296, -1.3325],
        [-0.6863, -0.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10965903848409653
Epoch 0, Step 223: train/loss = 0.48264816403388977, train/raw-loss = 0.47001227736473083, train/logprobs = tensor([[-0.8155, -3.4399],
        [-0.6455, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12635871767997742
Epoch 0, Step 224: train/loss = 0.43129315972328186, train/raw-loss = 0.4172050356864929, train/logprobs = tensor([[-0.9988, -2.9334],
        [-0.7251, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14088141918182373
Epoch 0, Step 225: train/loss = 0.5202960968017578, train/raw-loss = 0.5077852010726929, train/logprobs = tensor([[-0.5710, -1.5729],
        [-0.4687, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510885298252106
Epoch 0, Step 226: train/loss = 0.42995673418045044, train/raw-loss = 0.41919082403182983, train/logprobs = tensor([[-0.6897, -2.5563],
        [-0.5359, -0.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076589822769165
Epoch 0, Step 227: train/loss = 0.5635321140289307, train/raw-loss = 0.5490788817405701, train/logprobs = tensor([[-1.1309, -2.0265],
        [-0.7001, -0.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14453239738941193
Epoch 0, Step 228: train/loss = 0.5866689682006836, train/raw-loss = 0.5756863951683044, train/logprobs = tensor([[-0.6994, -1.8570],
        [-0.5658, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10982607305049896
Epoch 0, Step 229: train/loss = 0.7020511627197266, train/raw-loss = 0.6921464204788208, train/logprobs = tensor([[-0.4945, -0.4844],
        [-0.4100, -0.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0990469753742218
Epoch 0, Step 230: train/loss = 0.4999805986881256, train/raw-loss = 0.486939936876297, train/logprobs = tensor([[-0.7498, -2.0379],
        [-0.6472, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13040626049041748
Epoch 0, Step 231: train/loss = 0.6351048350334167, train/raw-loss = 0.6167773008346558, train/logprobs = tensor([[-1.1779, -2.3093],
        [-0.9132, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327584862709045
Epoch 0, Step 232: train/loss = 0.47562795877456665, train/raw-loss = 0.4623563885688782, train/logprobs = tensor([[-0.8304, -5.2560],
        [-0.6603, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13271546363830566
Epoch 0, Step 233: train/loss = 0.563286542892456, train/raw-loss = 0.5492681264877319, train/logprobs = tensor([[-0.5952, -1.8628],
        [-0.5329, -0.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14018452167510986
Epoch 0, Step 234: train/loss = 0.47886109352111816, train/raw-loss = 0.4659372866153717, train/logprobs = tensor([[-0.7952, -3.1061],
        [-0.6254, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292385458946228
Epoch 0, Step 235: train/loss = 0.3116760551929474, train/raw-loss = 0.30039361119270325, train/logprobs = tensor([[ -0.7631, -11.9105],
        [ -0.6308,  -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282449215650558
Epoch 0, Step 236: train/loss = 0.5661197304725647, train/raw-loss = 0.5502064228057861, train/logprobs = tensor([[-0.8643, -1.8615],
        [-0.8248, -1.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15913279354572296
Epoch 0, Step 237: train/loss = 0.5797393918037415, train/raw-loss = 0.5675582885742188, train/logprobs = tensor([[-0.6249, -2.5678],
        [-0.5640, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1218106746673584
Epoch 0, Step 238: train/loss = 0.6369510293006897, train/raw-loss = 0.6169147491455078, train/logprobs = tensor([[-1.2546, -1.6290],
        [-1.1158, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20036256313323975
Epoch 0, Step 239: train/loss = 0.4608684182167053, train/raw-loss = 0.4446761906147003, train/logprobs = tensor([[-1.1690, -3.4735],
        [-1.0348, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16192255914211273
Epoch 0, Step 240: train/loss = 0.6665845513343811, train/raw-loss = 0.6549139022827148, train/logprobs = tensor([[-0.7676, -2.3692],
        [-0.6683, -2.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11670666933059692
Epoch 0, Step 241: train/loss = 0.6744530200958252, train/raw-loss = 0.6597436666488647, train/logprobs = tensor([[-1.5927, -1.8902],
        [-1.0251, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1470930129289627
Epoch 0, Step 242: train/loss = 0.5962295532226562, train/raw-loss = 0.5833845734596252, train/logprobs = tensor([[-0.5777, -1.3045],
        [-0.3887, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12845024466514587
Epoch 0, Step 243: train/loss = 0.5163899660110474, train/raw-loss = 0.504165768623352, train/logprobs = tensor([[-0.5222, -1.7531],
        [-0.4908, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12224163115024567
Epoch 0, Step 244: train/loss = 0.5049483180046082, train/raw-loss = 0.4905036687850952, train/logprobs = tensor([[-1.0805, -3.2413],
        [-0.7519, -1.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444662630558014
Epoch 0, Step 245: train/loss = 0.5401615500450134, train/raw-loss = 0.5301690697669983, train/logprobs = tensor([[-0.4532, -1.7270],
        [-0.3644, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09992481768131256
Epoch 0, Step 246: train/loss = 0.5763614177703857, train/raw-loss = 0.5627346038818359, train/logprobs = tensor([[-1.1662, -2.5272],
        [-0.5914, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13626806437969208
Epoch 0, Step 247: train/loss = 0.4938950538635254, train/raw-loss = 0.4809558391571045, train/logprobs = tensor([[-0.6494, -2.3261],
        [-0.4277, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12939207255840302
Epoch 0, Step 248: train/loss = 0.48785561323165894, train/raw-loss = 0.47275662422180176, train/logprobs = tensor([[-0.9447, -3.0554],
        [-0.6122, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098991990089417
Epoch 0, Step 249: train/loss = 0.5568242073059082, train/raw-loss = 0.5415910482406616, train/logprobs = tensor([[-0.7753, -2.1495],
        [-0.6451, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15233242511749268
Epoch 0, Step 250: train/loss = 0.3919495642185211, train/raw-loss = 0.37982112169265747, train/logprobs = tensor([[-0.9111, -4.2588],
        [-0.6736, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212841272354126
Epoch 0, Step 251: train/loss = 0.4630568027496338, train/raw-loss = 0.4518452286720276, train/logprobs = tensor([[-0.4608, -3.1401],
        [-0.4053, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121160089969635
Epoch 0, Step 252: train/loss = 0.617993950843811, train/raw-loss = 0.6011143922805786, train/logprobs = tensor([[-0.8348, -2.3056],
        [-0.6898, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16879518330097198
Epoch 0, Step 253: train/loss = 0.6491345167160034, train/raw-loss = 0.6381218433380127, train/logprobs = tensor([[-0.8374, -0.9499],
        [-0.6316, -0.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1101270467042923
Epoch 0, Step 254: train/loss = 0.6419970989227295, train/raw-loss = 0.6277664303779602, train/logprobs = tensor([[-0.6522, -1.2810],
        [-0.6367, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14230626821517944
Epoch 0, Step 255: train/loss = 0.6317214369773865, train/raw-loss = 0.6191266775131226, train/logprobs = tensor([[-0.8337, -1.5938],
        [-0.6135, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259475201368332
Epoch 0, Step 256: train/loss = 0.5449424386024475, train/raw-loss = 0.5319716930389404, train/logprobs = tensor([[-0.9060, -2.2176],
        [-0.6279, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12970764935016632
Epoch 0, Step 257: train/loss = 0.49400320649147034, train/raw-loss = 0.4781971573829651, train/logprobs = tensor([[-1.0366, -3.2520],
        [-0.5384, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15806031227111816
Epoch 0, Step 258: train/loss = 0.5305294990539551, train/raw-loss = 0.5164843797683716, train/logprobs = tensor([[-1.1565, -3.3625],
        [-0.5101, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14045129716396332
Epoch 0, Step 259: train/loss = 0.44240421056747437, train/raw-loss = 0.427914559841156, train/logprobs = tensor([[-0.6155, -2.6901],
        [-0.4933, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14489655196666718
Epoch 0, Step 260: train/loss = 0.4504540264606476, train/raw-loss = 0.433351993560791, train/logprobs = tensor([[-0.8527, -2.8854],
        [-0.6963, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710205227136612
Epoch 0, Step 261: train/loss = 0.6013115644454956, train/raw-loss = 0.5868786573410034, train/logprobs = tensor([[-0.6311, -1.3020],
        [-0.4865, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1443292796611786
Epoch 0, Step 262: train/loss = 0.5626798868179321, train/raw-loss = 0.548439085483551, train/logprobs = tensor([[-0.7150, -1.5144],
        [-0.5543, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424080729484558
Epoch 0, Step 263: train/loss = 0.5932402610778809, train/raw-loss = 0.5760489106178284, train/logprobs = tensor([[-1.4148, -3.0286],
        [-0.7978, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719137579202652
Epoch 0, Step 264: train/loss = 0.4246392250061035, train/raw-loss = 0.4069593846797943, train/logprobs = tensor([[-1.0306, -3.1831],
        [-0.8859, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17679855227470398
Epoch 0, Step 265: train/loss = 0.5173400640487671, train/raw-loss = 0.5015147924423218, train/logprobs = tensor([[-0.6191, -1.7551],
        [-0.4777, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582522690296173
Epoch 0, Step 266: train/loss = 0.6272460222244263, train/raw-loss = 0.611162006855011, train/logprobs = tensor([[-0.8587, -1.0842],
        [-0.6922, -0.5166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16084004938602448
Epoch 0, Step 267: train/loss = 0.5024546980857849, train/raw-loss = 0.48718300461769104, train/logprobs = tensor([[-0.9182, -2.4668],
        [-0.5631, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15271708369255066
Epoch 0, Step 268: train/loss = 0.8295299410820007, train/raw-loss = 0.8123789429664612, train/logprobs = tensor([[-2.1220, -2.1007],
        [-0.9204, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1715104579925537
Epoch 0, Step 269: train/loss = 0.6253995299339294, train/raw-loss = 0.6137547492980957, train/logprobs = tensor([[-0.4558, -0.9669],
        [-0.2891, -0.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11644738912582397
Epoch 0, Step 270: train/loss = 0.7366622686386108, train/raw-loss = 0.7194313406944275, train/logprobs = tensor([[-1.7349, -2.4662],
        [-0.6761, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230963706970215
Epoch 0, Step 271: train/loss = 0.5103883147239685, train/raw-loss = 0.49168872833251953, train/logprobs = tensor([[-1.0367, -2.1933],
        [-0.7190, -0.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1869957000017166
Epoch 0, Step 272: train/loss = 0.3129638731479645, train/raw-loss = 0.30110862851142883, train/logprobs = tensor([[-0.5480, -7.0403],
        [-0.4974, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11855235695838928
Epoch 0, Step 273: train/loss = 0.5988461971282959, train/raw-loss = 0.5839259624481201, train/logprobs = tensor([[-0.7068, -1.2492],
        [-0.4650, -0.4026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14920231699943542
Epoch 0, Step 274: train/loss = 0.5094913840293884, train/raw-loss = 0.49527719616889954, train/logprobs = tensor([[-0.5803, -2.0849],
        [-0.4483, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14214210212230682
Epoch 0, Step 275: train/loss = 0.605246365070343, train/raw-loss = 0.5895785093307495, train/logprobs = tensor([[-0.7887, -1.6317],
        [-0.4515, -0.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15667909383773804
Epoch 0, Step 276: train/loss = 0.6612584590911865, train/raw-loss = 0.6482319831848145, train/logprobs = tensor([[-0.5245, -0.7824],
        [-0.4086, -0.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026519119739532
Epoch 0, Step 277: train/loss = 0.540319561958313, train/raw-loss = 0.5239461064338684, train/logprobs = tensor([[-0.8158, -2.3076],
        [-0.4233, -0.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1637342870235443
Epoch 0, Step 278: train/loss = 0.6224203705787659, train/raw-loss = 0.6062757968902588, train/logprobs = tensor([[-1.0393, -2.8254],
        [-0.6046, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16144616901874542
Epoch 0, Step 279: train/loss = 0.582959771156311, train/raw-loss = 0.5642244815826416, train/logprobs = tensor([[-1.0039, -1.6394],
        [-0.7890, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18735316395759583
Epoch 0, Step 280: train/loss = 0.6727168560028076, train/raw-loss = 0.6581026315689087, train/logprobs = tensor([[-0.6996, -0.7010],
        [-0.5121, -0.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14614269137382507
Epoch 0, Step 281: train/loss = 0.39769017696380615, train/raw-loss = 0.3795027732849121, train/logprobs = tensor([[-0.9728, -4.0529],
        [-0.8203, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18187397718429565
Epoch 0, Step 282: train/loss = 0.5819820761680603, train/raw-loss = 0.5663796663284302, train/logprobs = tensor([[-1.0193, -1.9826],
        [-0.6193, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15602388978004456
Epoch 0, Step 283: train/loss = 0.4747700095176697, train/raw-loss = 0.4574756324291229, train/logprobs = tensor([[-1.1038, -5.7988],
        [-0.8153, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17294403910636902
Epoch 0, Step 284: train/loss = 0.5304425954818726, train/raw-loss = 0.5140942931175232, train/logprobs = tensor([[-0.8597, -2.8071],
        [-0.7041, -0.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16348274052143097
Epoch 0, Step 285: train/loss = 0.36710673570632935, train/raw-loss = 0.35215288400650024, train/logprobs = tensor([[-0.7886, -4.4721],
        [-0.5647, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14953823387622833
Epoch 0, Step 286: train/loss = 0.5454204082489014, train/raw-loss = 0.5333074331283569, train/logprobs = tensor([[-0.7756, -2.2193],
        [-0.5468, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12112949043512344
Epoch 0, Step 287: train/loss = 0.6186835765838623, train/raw-loss = 0.5988689661026001, train/logprobs = tensor([[-1.0236, -1.4267],
        [-0.7414, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19814658164978027
Epoch 0, Step 288: train/loss = 0.607926607131958, train/raw-loss = 0.5919424295425415, train/logprobs = tensor([[-0.6036, -2.2169],
        [-0.4862, -0.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15984219312667847
Epoch 0, Step 289: train/loss = 0.39537009596824646, train/raw-loss = 0.3783024847507477, train/logprobs = tensor([[-0.6130, -2.3187],
        [-0.8130, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17067602276802063
Epoch 0, Step 290: train/loss = 0.5398322343826294, train/raw-loss = 0.5271670818328857, train/logprobs = tensor([[-0.6579, -1.6186],
        [-0.6209, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12665137648582458
Epoch 0, Step 291: train/loss = 0.5094804167747498, train/raw-loss = 0.49857330322265625, train/logprobs = tensor([[-0.3609, -2.1062],
        [-0.2671, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907119512557983
Epoch 0, Step 292: train/loss = 0.5216094851493835, train/raw-loss = 0.5063305497169495, train/logprobs = tensor([[-0.6340, -1.6320],
        [-0.6397, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152789905667305
Epoch 0, Step 293: train/loss = 0.5293409824371338, train/raw-loss = 0.5148464441299438, train/logprobs = tensor([[-0.6656, -1.3719],
        [-0.6907, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494530856609344
Epoch 0, Step 294: train/loss = 0.5545715689659119, train/raw-loss = 0.5349155068397522, train/logprobs = tensor([[-0.7972, -1.9982],
        [-0.7029, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1965610533952713
Epoch 0, Step 295: train/loss = 0.5089694857597351, train/raw-loss = 0.4923924207687378, train/logprobs = tensor([[-1.2499, -2.4149],
        [-1.0297, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1657705157995224
Epoch 0, Step 296: train/loss = 0.44474712014198303, train/raw-loss = 0.42892614006996155, train/logprobs = tensor([[-0.6654, -2.2672],
        [-0.7318, -0.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15821005403995514
Epoch 0, Step 297: train/loss = 0.5007994771003723, train/raw-loss = 0.4840961992740631, train/logprobs = tensor([[-0.6780, -2.1032],
        [-0.6583, -0.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16703282296657562
Epoch 0, Step 298: train/loss = 0.884831428527832, train/raw-loss = 0.8648319840431213, train/logprobs = tensor([[-1.9948, -4.6229],
        [-0.8541, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19999396800994873
Epoch 0, Step 299: train/loss = 0.488747775554657, train/raw-loss = 0.4710004925727844, train/logprobs = tensor([[-0.6183, -2.3079],
        [-0.6479, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774728000164032
Epoch 0, Step 300: train/loss = 0.5206291675567627, train/raw-loss = 0.5018616914749146, train/logprobs = tensor([[-0.7014, -2.3563],
        [-0.5969, -0.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18767490983009338
Epoch 0, Step 301: train/loss = 0.44649121165275574, train/raw-loss = 0.4271995425224304, train/logprobs = tensor([[-0.8963, -2.6716],
        [-0.7162, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1929163783788681
Epoch 0, Step 302: train/loss = 0.6117167472839355, train/raw-loss = 0.5935271978378296, train/logprobs = tensor([[-0.9085, -1.2175],
        [-0.7457, -0.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18189509212970734
Epoch 0, Step 303: train/loss = 0.4024847745895386, train/raw-loss = 0.38643860816955566, train/logprobs = tensor([[-0.6130, -3.1247],
        [-0.5873, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16046154499053955
Epoch 0, Step 304: train/loss = 0.4357488751411438, train/raw-loss = 0.41567379236221313, train/logprobs = tensor([[-0.8596, -2.6676],
        [-0.7505, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20075055956840515
Epoch 0, Step 305: train/loss = 0.4703662395477295, train/raw-loss = 0.45538702607154846, train/logprobs = tensor([[-0.5302, -2.6370],
        [-0.6006, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14979176223278046
Epoch 0, Step 306: train/loss = 0.735710084438324, train/raw-loss = 0.7137764096260071, train/logprobs = tensor([[-0.8846, -0.7942],
        [-0.7904, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2193373292684555
Epoch 0, Step 307: train/loss = 0.5553558468818665, train/raw-loss = 0.5402964949607849, train/logprobs = tensor([[-0.5510, -1.4650],
        [-0.4981, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15059372782707214
Epoch 0, Step 308: train/loss = 0.5723279714584351, train/raw-loss = 0.5533857941627502, train/logprobs = tensor([[-1.2996, -2.1415],
        [-0.8411, -0.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894218474626541
Epoch 0, Step 309: train/loss = 0.6749552488327026, train/raw-loss = 0.658014178276062, train/logprobs = tensor([[-0.7698, -1.0104],
        [-0.5558, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16941115260124207
Epoch 0, Step 310: train/loss = 0.9120182991027832, train/raw-loss = 0.895106852054596, train/logprobs = tensor([[-1.7484, -2.2309],
        [-0.5620, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16911393404006958
Epoch 0, Step 311: train/loss = 0.45366740226745605, train/raw-loss = 0.43733087182044983, train/logprobs = tensor([[-0.5980, -2.0732],
        [-0.6623, -0.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16336484253406525
Epoch 0, Step 312: train/loss = 0.7166849970817566, train/raw-loss = 0.6962294578552246, train/logprobs = tensor([[-1.1138, -1.3338],
        [-0.6667, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20455484092235565
Epoch 0, Step 313: train/loss = 0.6485000848770142, train/raw-loss = 0.6298719048500061, train/logprobs = tensor([[-1.1070, -1.8999],
        [-0.5279, -0.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18628188967704773
Epoch 0, Step 314: train/loss = 0.6154031753540039, train/raw-loss = 0.5974502563476562, train/logprobs = tensor([[-0.6252, -1.0021],
        [-0.6934, -0.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17952919006347656
Epoch 0, Step 315: train/loss = 0.5482816696166992, train/raw-loss = 0.5335276126861572, train/logprobs = tensor([[-0.8008, -1.4123],
        [-0.8390, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14754043519496918
Epoch 0, Step 316: train/loss = 0.54474276304245, train/raw-loss = 0.526904284954071, train/logprobs = tensor([[-0.5604, -2.4590],
        [-0.4909, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17838463187217712
Epoch 0, Step 317: train/loss = 0.5232524871826172, train/raw-loss = 0.5043689012527466, train/logprobs = tensor([[-0.8286, -4.3017],
        [-0.9854, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18883568048477173
Epoch 0, Step 318: train/loss = 0.4022858440876007, train/raw-loss = 0.3862934112548828, train/logprobs = tensor([[-0.4958, -2.7909],
        [-0.5570, -0.5111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15992394089698792
Epoch 0, Step 319: train/loss = 0.5362814664840698, train/raw-loss = 0.5177084803581238, train/logprobs = tensor([[-0.6352, -2.2286],
        [-0.5346, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18572978675365448
Epoch 0, Step 320: train/loss = 0.5847069621086121, train/raw-loss = 0.56279456615448, train/logprobs = tensor([[-0.9995, -1.8988],
        [-0.6783, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21912403404712677
Epoch 0, Step 321: train/loss = 0.5801003575325012, train/raw-loss = 0.560621976852417, train/logprobs = tensor([[-0.7889, -1.4317],
        [-0.8757, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19478382170200348
Epoch 0, Step 322: train/loss = 0.6623639464378357, train/raw-loss = 0.6420192122459412, train/logprobs = tensor([[-1.0148, -1.5327],
        [-0.5247, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20344717800617218
Epoch 0, Step 323: train/loss = 0.3043590784072876, train/raw-loss = 0.29073667526245117, train/logprobs = tensor([[-0.4916, -6.5919],
        [-0.5796, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13622426986694336
Epoch 0, Step 324: train/loss = 0.4719694256782532, train/raw-loss = 0.44948577880859375, train/logprobs = tensor([[-0.6916, -2.7727],
        [-0.7621, -1.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248363494873047
Epoch 0, Step 325: train/loss = 0.3325137794017792, train/raw-loss = 0.31430453062057495, train/logprobs = tensor([[-0.6798, -3.8030],
        [-0.7550, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1820923089981079
Epoch 0, Step 326: train/loss = 0.451160192489624, train/raw-loss = 0.43732476234436035, train/logprobs = tensor([[-0.4492, -2.6818],
        [-0.4811, -0.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383540779352188
Epoch 0, Step 327: train/loss = 0.4639374613761902, train/raw-loss = 0.4465741813182831, train/logprobs = tensor([[-0.6507, -2.1772],
        [-0.6093, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363283038139343
Epoch 0, Step 328: train/loss = 0.4380025565624237, train/raw-loss = 0.4161798059940338, train/logprobs = tensor([[-0.7978, -2.8250],
        [-0.8874, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21822723746299744
Epoch 0, Step 329: train/loss = 0.5692331790924072, train/raw-loss = 0.5542184114456177, train/logprobs = tensor([[-0.6171, -1.0867],
        [-0.7033, -0.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15014787018299103
Epoch 0, Step 330: train/loss = 0.45026683807373047, train/raw-loss = 0.43553197383880615, train/logprobs = tensor([[-0.5081, -1.9955],
        [-0.6174, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14734846353530884
Epoch 0, Step 331: train/loss = 0.559856116771698, train/raw-loss = 0.540117621421814, train/logprobs = tensor([[-0.7373, -1.2484],
        [-0.9905, -0.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738520681858063
Epoch 0, Step 332: train/loss = 0.5861684679985046, train/raw-loss = 0.5717328190803528, train/logprobs = tensor([[-0.6447, -2.4744],
        [-0.4831, -0.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14435629546642303
Epoch 0, Step 333: train/loss = 0.560330331325531, train/raw-loss = 0.5403046011924744, train/logprobs = tensor([[-0.6666, -1.4986],
        [-0.5585, -0.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20025748014450073
Epoch 0, Step 334: train/loss = 0.5821627974510193, train/raw-loss = 0.5613625049591064, train/logprobs = tensor([[-0.6120, -1.4288],
        [-0.5802, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20800279080867767
Epoch 0, Step 335: train/loss = 0.5077397227287292, train/raw-loss = 0.4928863048553467, train/logprobs = tensor([[-0.4496, -1.6694],
        [-0.5231, -0.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14853422343730927
Epoch 0, Step 336: train/loss = 0.5308455228805542, train/raw-loss = 0.5103653073310852, train/logprobs = tensor([[-0.6107, -1.8682],
        [-0.6007, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20480228960514069
Epoch 0, Step 337: train/loss = 0.5965541005134583, train/raw-loss = 0.5787067413330078, train/logprobs = tensor([[-0.8156, -2.2319],
        [-0.7339, -0.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17847390472888947
Epoch 0, Step 338: train/loss = 0.4281125068664551, train/raw-loss = 0.41168826818466187, train/logprobs = tensor([[-0.6506, -3.9182],
        [-0.6603, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16424229741096497
Epoch 0, Step 339: train/loss = 0.3795531690120697, train/raw-loss = 0.36442136764526367, train/logprobs = tensor([[-0.4895, -5.9375],
        [-0.5508, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513182520866394
Epoch 0, Step 340: train/loss = 0.558171272277832, train/raw-loss = 0.5416446924209595, train/logprobs = tensor([[-0.6470, -2.0066],
        [-0.6658, -0.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16526567935943604
Epoch 0, Step 341: train/loss = 0.4378970265388489, train/raw-loss = 0.4174147844314575, train/logprobs = tensor([[-0.9889, -2.6791],
        [-1.0383, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2048223465681076
Epoch 0, Step 342: train/loss = 0.4028063714504242, train/raw-loss = 0.3846762180328369, train/logprobs = tensor([[-0.6863, -3.3431],
        [-0.7707, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18130122125148773
Epoch 0, Step 343: train/loss = 0.5283395051956177, train/raw-loss = 0.514259397983551, train/logprobs = tensor([[-0.5409, -2.7097],
        [-0.5261, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408011019229889
Epoch 0, Step 344: train/loss = 0.5262132883071899, train/raw-loss = 0.5066550374031067, train/logprobs = tensor([[-0.5865, -1.6367],
        [-0.5501, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19558198750019073
Epoch 0, Step 345: train/loss = 1.2179133892059326, train/raw-loss = 1.1991500854492188, train/logprobs = tensor([[-2.1422, -1.3489],
        [-0.5360, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18763355910778046
Epoch 0, Step 346: train/loss = 0.4701610207557678, train/raw-loss = 0.4488009512424469, train/logprobs = tensor([[-0.7337, -1.8585],
        [-1.0059, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136010080575943
Epoch 0, Step 347: train/loss = 0.4566457271575928, train/raw-loss = 0.43806108832359314, train/logprobs = tensor([[-0.5900, -2.0541],
        [-0.7550, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18584641814231873
Epoch 0, Step 348: train/loss = 0.39459261298179626, train/raw-loss = 0.37701743841171265, train/logprobs = tensor([[-0.8094, -5.9596],
        [-0.8379, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17575180530548096
Epoch 0, Step 349: train/loss = 0.5297822952270508, train/raw-loss = 0.511969268321991, train/logprobs = tensor([[-0.6207, -2.6367],
        [-0.4554, -0.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17813020944595337
Epoch 0, Step 350: train/loss = 0.5089493989944458, train/raw-loss = 0.49335384368896484, train/logprobs = tensor([[-0.5464, -1.6615],
        [-0.6006, -0.4288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15595538914203644
Epoch 0, Step 351: train/loss = 0.5233961343765259, train/raw-loss = 0.4997239112854004, train/logprobs = tensor([[-0.9737, -2.2091],
        [-0.9258, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23672214150428772
Epoch 0, Step 352: train/loss = 0.6011731624603271, train/raw-loss = 0.5867312550544739, train/logprobs = tensor([[-0.4382, -1.1231],
        [-0.5055, -0.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14441856741905212
Epoch 0, Step 353: train/loss = 0.6433731913566589, train/raw-loss = 0.6283285021781921, train/logprobs = tensor([[-0.5095, -0.8282],
        [-0.4932, -0.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15044714510440826
Epoch 0, Step 354: train/loss = 0.4096832275390625, train/raw-loss = 0.3915574848651886, train/logprobs = tensor([[-0.6405, -3.1789],
        [-0.6838, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18125753104686737
Epoch 0, Step 355: train/loss = 0.5202566385269165, train/raw-loss = 0.4984819293022156, train/logprobs = tensor([[-0.8161, -1.7148],
        [-0.8390, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21774743497371674
Epoch 0, Step 356: train/loss = 0.6290183067321777, train/raw-loss = 0.6129707098007202, train/logprobs = tensor([[-0.5851, -0.7542],
        [-0.6255, -0.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16047628223896027
Epoch 0, Step 357: train/loss = 0.36606258153915405, train/raw-loss = 0.34551411867141724, train/logprobs = tensor([[-0.7593, -3.3484],
        [-1.1082, -0.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054845690727234
Epoch 0, Step 358: train/loss = 0.5358686447143555, train/raw-loss = 0.5108703374862671, train/logprobs = tensor([[-0.8397, -2.4792],
        [-0.7500, -0.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24998338520526886
Epoch 0, Step 359: train/loss = 0.5740662813186646, train/raw-loss = 0.5582273006439209, train/logprobs = tensor([[-0.4074, -0.9090],
        [-0.6164, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839026868343353
Epoch 0, Step 360: train/loss = 0.5842865109443665, train/raw-loss = 0.5652972459793091, train/logprobs = tensor([[-1.1711, -4.8276],
        [-0.8476, -0.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18989300727844238
Epoch 0, Step 361: train/loss = 0.6881961822509766, train/raw-loss = 0.6669667959213257, train/logprobs = tensor([[-0.6330, -0.6716],
        [-0.5851, -0.4957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21229350566864014
Epoch 0, Step 362: train/loss = 0.6119917035102844, train/raw-loss = 0.5891467332839966, train/logprobs = tensor([[-0.6337, -1.4106],
        [-0.5735, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22845003008842468
Epoch 0, Step 363: train/loss = 0.5127103924751282, train/raw-loss = 0.4972586929798126, train/logprobs = tensor([[-0.4472, -1.8759],
        [-0.5412, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15451720356941223
Epoch 0, Step 364: train/loss = 0.521737813949585, train/raw-loss = 0.5032833218574524, train/logprobs = tensor([[-0.6660, -2.2218],
        [-0.7454, -1.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18454506993293762
Epoch 0, Step 365: train/loss = 0.49741241335868835, train/raw-loss = 0.477072149515152, train/logprobs = tensor([[-0.4361, -1.4991],
        [-0.8773, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20340244472026825
Epoch 0, Step 366: train/loss = 0.4886840581893921, train/raw-loss = 0.4668216109275818, train/logprobs = tensor([[-0.6239, -2.1080],
        [-0.9269, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21862396597862244
Epoch 0, Step 367: train/loss = 0.3486176133155823, train/raw-loss = 0.327515184879303, train/logprobs = tensor([[-0.7164, -7.0795],
        [-1.0128, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21102404594421387
Epoch 0, Step 368: train/loss = 0.6212589144706726, train/raw-loss = 0.6040908694267273, train/logprobs = tensor([[-0.8791, -1.7578],
        [-0.6464, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17168071866035461
Epoch 0, Step 369: train/loss = 0.6757919788360596, train/raw-loss = 0.6574650406837463, train/logprobs = tensor([[-0.4618, -0.5992],
        [-0.4527, -0.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18326959013938904
Epoch 0, Step 370: train/loss = 0.6266181468963623, train/raw-loss = 0.608411431312561, train/logprobs = tensor([[-0.8056, -0.6743],
        [-0.9209, -0.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18206799030303955
Epoch 0, Step 371: train/loss = 0.37236344814300537, train/raw-loss = 0.35501667857170105, train/logprobs = tensor([[-0.5966, -2.5417],
        [-0.9200, -0.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734676957130432
Epoch 0, Step 372: train/loss = 0.579064130783081, train/raw-loss = 0.5614045262336731, train/logprobs = tensor([[-0.5551, -1.9610],
        [-0.5500, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17659631371498108
Epoch 0, Step 373: train/loss = 0.5095301866531372, train/raw-loss = 0.4883074462413788, train/logprobs = tensor([[-0.6407, -3.3619],
        [-0.7825, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122274488210678
Epoch 0, Step 374: train/loss = 0.6396536231040955, train/raw-loss = 0.6231193542480469, train/logprobs = tensor([[-0.5226, -0.8872],
        [-0.6260, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16534262895584106
Epoch 0, Step 375: train/loss = 0.5816835761070251, train/raw-loss = 0.5659645795822144, train/logprobs = tensor([[-0.4342, -1.2880],
        [-0.5495, -0.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15719036757946014
Epoch 0, Step 376: train/loss = 0.5496432185173035, train/raw-loss = 0.5310746431350708, train/logprobs = tensor([[-0.5026, -1.2658],
        [-0.7412, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18568536639213562
Epoch 0, Step 377: train/loss = 0.6078118085861206, train/raw-loss = 0.5908066630363464, train/logprobs = tensor([[-0.3774, -0.8386],
        [-0.4673, -0.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700519472360611
Epoch 0, Step 378: train/loss = 0.5480915904045105, train/raw-loss = 0.5281497240066528, train/logprobs = tensor([[-0.5844, -3.9921],
        [-0.7792, -0.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.199418842792511
Epoch 0, Step 379: train/loss = 0.600731611251831, train/raw-loss = 0.578252911567688, train/logprobs = tensor([[-0.6577, -1.5072],
        [-0.6532, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247869074344635
Epoch 0, Step 380: train/loss = 0.4912842810153961, train/raw-loss = 0.4746377766132355, train/logprobs = tensor([[-0.6538, -2.2063],
        [-0.7368, -0.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16646498441696167
Epoch 0, Step 381: train/loss = 0.568993091583252, train/raw-loss = 0.5514698028564453, train/logprobs = tensor([[-0.5855, -1.6716],
        [-0.7336, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523270845413208
Epoch 0, Step 382: train/loss = 0.4047049880027771, train/raw-loss = 0.3843715190887451, train/logprobs = tensor([[-0.6789, -3.4031],
        [-1.0442, -0.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033345252275467
Epoch 0, Step 383: train/loss = 0.6974681615829468, train/raw-loss = 0.677293062210083, train/logprobs = tensor([[-1.8409, -4.7754],
        [-1.0038, -0.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20175184309482574
Epoch 0, Step 384: train/loss = 0.5553115010261536, train/raw-loss = 0.534779965877533, train/logprobs = tensor([[-0.4960, -3.3288],
        [-0.9504, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053150236606598
Epoch 0, Step 385: train/loss = 0.5897074341773987, train/raw-loss = 0.56757652759552, train/logprobs = tensor([[-0.5833, -1.0774],
        [-0.8930, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213083654642105
Epoch 0, Step 386: train/loss = 0.5456591248512268, train/raw-loss = 0.5291228294372559, train/logprobs = tensor([[-0.4570, -1.6717],
        [-0.7217, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16536320745944977
Epoch 0, Step 387: train/loss = 0.6787109375, train/raw-loss = 0.6578466296195984, train/logprobs = tensor([[-0.4549, -0.6867],
        [-0.7038, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20864343643188477
Epoch 0, Step 388: train/loss = 0.49359187483787537, train/raw-loss = 0.47271040081977844, train/logprobs = tensor([[-0.5586, -1.6162],
        [-1.0004, -0.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20881472527980804
Epoch 0, Step 389: train/loss = 0.4918484091758728, train/raw-loss = 0.4707602858543396, train/logprobs = tensor([[-0.4443, -3.8160],
        [-0.8580, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21088071167469025
Epoch 0, Step 390: train/loss = 0.37568968534469604, train/raw-loss = 0.3564079999923706, train/logprobs = tensor([[-0.4707, -3.0678],
        [-1.0031, -0.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19281679391860962
Epoch 0, Step 391: train/loss = 0.4824228286743164, train/raw-loss = 0.46069368720054626, train/logprobs = tensor([[-0.4463, -1.6899],
        [-1.0937, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21729138493537903
Epoch 0, Step 392: train/loss = 0.5602895617485046, train/raw-loss = 0.53961181640625, train/logprobs = tensor([[-0.4712, -1.1223],
        [-0.8938, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2067774534225464
Epoch 0, Step 393: train/loss = 0.5859196782112122, train/raw-loss = 0.5661753416061401, train/logprobs = tensor([[-0.4884, -1.0277],
        [-0.9904, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19744332134723663
Epoch 0, Step 394: train/loss = 0.5467067360877991, train/raw-loss = 0.5256938338279724, train/logprobs = tensor([[-0.5593, -1.2378],
        [-0.8683, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21012896299362183
Epoch 0, Step 395: train/loss = 0.4296630024909973, train/raw-loss = 0.4084245562553406, train/logprobs = tensor([[-0.4471, -2.8354],
        [-0.9988, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21238425374031067
Epoch 0, Step 396: train/loss = 0.5649430155754089, train/raw-loss = 0.5435734987258911, train/logprobs = tensor([[-0.5198, -1.6362],
        [-0.9880, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21369493007659912
Epoch 0, Step 397: train/loss = 0.38999634981155396, train/raw-loss = 0.37266427278518677, train/logprobs = tensor([[-0.3681, -4.2461],
        [-0.8457, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17332112789154053
Epoch 0, Step 398: train/loss = 0.6795511841773987, train/raw-loss = 0.658881425857544, train/logprobs = tensor([[-0.4813, -0.7223],
        [-0.6858, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20669756829738617
Epoch 0, Step 399: train/loss = 0.5556610226631165, train/raw-loss = 0.5344468951225281, train/logprobs = tensor([[-0.6580, -1.5501],
        [-0.9483, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21214163303375244
Epoch 0, Step 400: train/loss = 0.6253105401992798, train/raw-loss = 0.6057630777359009, train/logprobs = tensor([[-0.4000, -0.7828],
        [-0.6608, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1954745501279831
Epoch 0, Step 401: train/loss = 0.5413359999656677, train/raw-loss = 0.522860586643219, train/logprobs = tensor([[-0.5593, -3.6522],
        [-0.8420, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18475434184074402
Epoch 0, Step 402: train/loss = 0.46863967180252075, train/raw-loss = 0.44502872228622437, train/logprobs = tensor([[-0.4553, -2.6261],
        [-1.1385, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23610953986644745
Epoch 0, Step 403: train/loss = 0.586959958076477, train/raw-loss = 0.5690414905548096, train/logprobs = tensor([[-0.3888, -1.7361],
        [-0.5673, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17918437719345093
Epoch 0, Step 404: train/loss = 0.537377119064331, train/raw-loss = 0.5168837308883667, train/logprobs = tensor([[-0.3785, -0.8101],
        [-0.8876, -0.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20493417978286743
Epoch 0, Step 405: train/loss = 0.45053648948669434, train/raw-loss = 0.4276658892631531, train/logprobs = tensor([[-0.6244, -1.9616],
        [-0.8984, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2287057787179947
Epoch 0, Step 406: train/loss = 0.6027386784553528, train/raw-loss = 0.5802985429763794, train/logprobs = tensor([[-0.6323, -1.2216],
        [-0.7992, -0.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22440120577812195
Epoch 0, Step 407: train/loss = 0.4524461030960083, train/raw-loss = 0.43057647347450256, train/logprobs = tensor([[-0.4805, -4.0855],
        [-0.9766, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21869617700576782
Epoch 0, Step 408: train/loss = 0.6583001613616943, train/raw-loss = 0.6409268379211426, train/logprobs = tensor([[-0.4326, -0.7236],
        [-0.7664, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737324744462967
Epoch 0, Step 409: train/loss = 0.4936026930809021, train/raw-loss = 0.47313863039016724, train/logprobs = tensor([[-0.8118, -2.0490],
        [-0.9707, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20464065670967102
Epoch 0, Step 410: train/loss = 0.42162203788757324, train/raw-loss = 0.40025854110717773, train/logprobs = tensor([[-0.7769, -3.0264],
        [-1.0356, -1.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21363483369350433
Epoch 0, Step 411: train/loss = 0.3559340834617615, train/raw-loss = 0.3297688364982605, train/logprobs = tensor([[-0.6738, -2.6592],
        [-1.2274, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616519033908844
Epoch 0, Step 412: train/loss = 0.3489271104335785, train/raw-loss = 0.32894253730773926, train/logprobs = tensor([[-0.4613, -5.0521],
        [-1.0725, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19984544813632965
Epoch 0, Step 413: train/loss = 0.6432806253433228, train/raw-loss = 0.6211099028587341, train/logprobs = tensor([[-0.5695, -0.8119],
        [-0.8175, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22170773148536682
Epoch 0, Step 414: train/loss = 0.5260024666786194, train/raw-loss = 0.5079249143600464, train/logprobs = tensor([[-0.4633, -1.7017],
        [-0.6998, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1807761788368225
Epoch 0, Step 415: train/loss = 0.4975490868091583, train/raw-loss = 0.4777509570121765, train/logprobs = tensor([[-0.4113, -1.9298],
        [-0.7982, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19798080623149872
Epoch 0, Step 416: train/loss = 0.3861056864261627, train/raw-loss = 0.3648430407047272, train/logprobs = tensor([[-0.5304, -3.5296],
        [-1.1881, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126263678073883
Epoch 0, Step 417: train/loss = 0.27043721079826355, train/raw-loss = 0.2503059506416321, train/logprobs = tensor([[-0.4980, -5.8382],
        [-0.8887, -0.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20131249725818634
Epoch 0, Step 418: train/loss = 0.5425260066986084, train/raw-loss = 0.5168147087097168, train/logprobs = tensor([[-0.6728, -1.2852],
        [-1.4949, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571132183074951
Epoch 0, Step 419: train/loss = 0.4501180946826935, train/raw-loss = 0.43192601203918457, train/logprobs = tensor([[-0.4825, -3.1011],
        [-0.7307, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18192067742347717
Epoch 0, Step 420: train/loss = 0.5084189176559448, train/raw-loss = 0.48891836404800415, train/logprobs = tensor([[-0.5034, -1.6125],
        [-0.7891, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950055956840515
Epoch 0, Step 421: train/loss = 0.552386999130249, train/raw-loss = 0.5322412252426147, train/logprobs = tensor([[-0.5624, -1.1725],
        [-1.0146, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014576941728592
Epoch 0, Step 422: train/loss = 0.5681416988372803, train/raw-loss = 0.5475289821624756, train/logprobs = tensor([[-0.4050, -1.0956],
        [-0.7228, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20612700283527374
Epoch 0, Step 423: train/loss = 0.5152565836906433, train/raw-loss = 0.49690020084381104, train/logprobs = tensor([[-0.6367, -2.1252],
        [-0.7502, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18356367945671082
Epoch 0, Step 424: train/loss = 0.608878493309021, train/raw-loss = 0.5885440111160278, train/logprobs = tensor([[-0.4439, -0.9765],
        [-0.7531, -0.8008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20334482192993164
Epoch 0, Step 425: train/loss = 0.6132164001464844, train/raw-loss = 0.589027464389801, train/logprobs = tensor([[-0.6864, -0.9604],
        [-1.0347, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2418886125087738
Epoch 0, Step 426: train/loss = 0.5487144589424133, train/raw-loss = 0.5284700989723206, train/logprobs = tensor([[-0.6575, -1.4833],
        [-0.9496, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20244306325912476
Epoch 0, Step 427: train/loss = 0.545066773891449, train/raw-loss = 0.5251635313034058, train/logprobs = tensor([[-0.6527, -1.6793],
        [-1.0711, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903206825256348
Epoch 0, Step 428: train/loss = 0.5633509159088135, train/raw-loss = 0.5454499125480652, train/logprobs = tensor([[-0.5108, -1.0292],
        [-0.7407, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790107786655426
Epoch 0, Step 429: train/loss = 0.6709315776824951, train/raw-loss = 0.648220419883728, train/logprobs = tensor([[-0.4727, -0.7928],
        [-0.8327, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22711095213890076
Epoch 0, Step 430: train/loss = 0.42455726861953735, train/raw-loss = 0.4037640690803528, train/logprobs = tensor([[-0.4247, -1.7326],
        [-1.0205, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079319804906845
Epoch 0, Step 431: train/loss = 0.6034570336341858, train/raw-loss = 0.5797873139381409, train/logprobs = tensor([[-0.5775, -1.2928],
        [-0.8197, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23669743537902832
Epoch 0, Step 432: train/loss = 0.5723745822906494, train/raw-loss = 0.5531827211380005, train/logprobs = tensor([[-0.5175, -1.0512],
        [-0.7088, -0.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19191771745681763
Epoch 0, Step 433: train/loss = 0.5727207660675049, train/raw-loss = 0.549919068813324, train/logprobs = tensor([[-0.6250, -1.5031],
        [-0.9336, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22801697254180908
Epoch 0, Step 434: train/loss = 0.6036273241043091, train/raw-loss = 0.5819914937019348, train/logprobs = tensor([[-0.7637, -1.6149],
        [-1.0392, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21635892987251282
Epoch 0, Step 435: train/loss = 0.5654489994049072, train/raw-loss = 0.5414330959320068, train/logprobs = tensor([[-0.6446, -1.1647],
        [-1.0871, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24015840888023376
Epoch 0, Step 436: train/loss = 0.4959591329097748, train/raw-loss = 0.47562700510025024, train/logprobs = tensor([[-0.4867, -1.4023],
        [-0.9965, -0.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20332126319408417
Epoch 0, Step 437: train/loss = 0.529070258140564, train/raw-loss = 0.5100085139274597, train/logprobs = tensor([[-0.5066, -3.1509],
        [-0.8076, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19061751663684845
Epoch 0, Step 438: train/loss = 0.6063045263290405, train/raw-loss = 0.5844507813453674, train/logprobs = tensor([[-0.5995, -1.2316],
        [-0.6756, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853773295879364
Epoch 0, Step 439: train/loss = 0.6364046931266785, train/raw-loss = 0.6179539561271667, train/logprobs = tensor([[-0.3534, -0.7747],
        [-0.5507, -0.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18450775742530823
Epoch 0, Step 440: train/loss = 0.4173034429550171, train/raw-loss = 0.3956833779811859, train/logprobs = tensor([[-0.4735, -2.2290],
        [-0.8338, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162005603313446
Epoch 0, Step 441: train/loss = 0.5120927095413208, train/raw-loss = 0.4943196177482605, train/logprobs = tensor([[-0.4136, -3.2773],
        [-0.5613, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17773115634918213
Epoch 0, Step 442: train/loss = 0.5556780099868774, train/raw-loss = 0.5375910401344299, train/logprobs = tensor([[-0.4426, -1.4698],
        [-0.7589, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18086957931518555
Epoch 0, Step 443: train/loss = 0.5095252394676208, train/raw-loss = 0.49229496717453003, train/logprobs = tensor([[-0.4320, -1.5650],
        [-0.8051, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230282723903656
Epoch 0, Step 444: train/loss = 0.47279849648475647, train/raw-loss = 0.4486921429634094, train/logprobs = tensor([[-0.5685, -1.7917],
        [-1.0793, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2410634160041809
Epoch 0, Step 445: train/loss = 0.5517493486404419, train/raw-loss = 0.5344620943069458, train/logprobs = tensor([[-0.5237, -1.0502],
        [-0.7222, -0.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17287223041057587
Epoch 0, Step 446: train/loss = 0.41170549392700195, train/raw-loss = 0.39011698961257935, train/logprobs = tensor([[-0.4291, -4.2111],
        [-0.8669, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158849835395813
Epoch 0, Step 447: train/loss = 0.48002320528030396, train/raw-loss = 0.45920437574386597, train/logprobs = tensor([[-0.4948, -3.6018],
        [-0.8862, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20818834006786346
Epoch 0, Step 448: train/loss = 0.47906258702278137, train/raw-loss = 0.45699331164360046, train/logprobs = tensor([[-0.4318, -1.8625],
        [-1.0204, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2206927239894867
Epoch 0, Step 449: train/loss = 0.6636762619018555, train/raw-loss = 0.644809901714325, train/logprobs = tensor([[-0.4609, -0.9369],
        [-0.6425, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886638104915619
Epoch 0, Step 450: train/loss = 0.612195611000061, train/raw-loss = 0.5904482007026672, train/logprobs = tensor([[-0.5590, -1.0845],
        [-0.7209, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21747444570064545
Epoch 0, Step 451: train/loss = 0.7181682586669922, train/raw-loss = 0.6991100311279297, train/logprobs = tensor([[-0.3637, -0.4435],
        [-0.6444, -0.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19058269262313843
Epoch 0, Step 452: train/loss = 0.46378350257873535, train/raw-loss = 0.4408758580684662, train/logprobs = tensor([[-0.8911, -1.9854],
        [-1.5933, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2290765941143036
Epoch 0, Step 453: train/loss = 0.441719651222229, train/raw-loss = 0.41719740629196167, train/logprobs = tensor([[-0.5161, -2.4481],
        [-0.9610, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24522212147712708
Epoch 0, Step 454: train/loss = 0.5750129222869873, train/raw-loss = 0.5503761768341064, train/logprobs = tensor([[-0.5254, -1.0556],
        [-1.2128, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246367946267128
Epoch 0, Step 455: train/loss = 0.4598664343357086, train/raw-loss = 0.43992769718170166, train/logprobs = tensor([[-0.4965, -1.8154],
        [-0.8573, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19938713312149048
Epoch 0, Step 456: train/loss = 0.6319053173065186, train/raw-loss = 0.6072392463684082, train/logprobs = tensor([[-0.5892, -1.0899],
        [-0.8327, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24666084349155426
Epoch 0, Step 457: train/loss = 0.5961748361587524, train/raw-loss = 0.5743736028671265, train/logprobs = tensor([[-0.4635, -0.8313],
        [-0.8108, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180129587650299
Epoch 0, Step 458: train/loss = 0.7060702443122864, train/raw-loss = 0.677570641040802, train/logprobs = tensor([[-0.4788, -0.5809],
        [-0.9069, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849966287612915
Epoch 0, Step 459: train/loss = 0.48983970284461975, train/raw-loss = 0.4737555682659149, train/logprobs = tensor([[-0.3688, -1.7514],
        [-0.6929, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16084137558937073
Epoch 0, Step 460: train/loss = 0.6303690671920776, train/raw-loss = 0.6120173335075378, train/logprobs = tensor([[-0.3621, -0.9641],
        [-0.6043, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18351732194423676
Epoch 0, Step 461: train/loss = 0.40575236082077026, train/raw-loss = 0.38276541233062744, train/logprobs = tensor([[-0.5359, -2.0561],
        [-1.4338, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22986960411071777
Epoch 0, Step 462: train/loss = 0.449040949344635, train/raw-loss = 0.4218318462371826, train/logprobs = tensor([[-0.6025, -2.0719],
        [-1.5250, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720911502838135
Epoch 0, Step 463: train/loss = 0.597702145576477, train/raw-loss = 0.5726961493492126, train/logprobs = tensor([[-0.6342, -1.0428],
        [-1.0488, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25005996227264404
Epoch 0, Step 464: train/loss = 0.3199218213558197, train/raw-loss = 0.29608917236328125, train/logprobs = tensor([[-0.5141, -3.4358],
        [-1.2033, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23832640051841736
Epoch 0, Step 465: train/loss = 0.560686469078064, train/raw-loss = 0.5404735803604126, train/logprobs = tensor([[-0.6372, -1.7817],
        [-0.7539, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021283507347107
Epoch 0, Step 466: train/loss = 0.2848394215106964, train/raw-loss = 0.26530319452285767, train/logprobs = tensor([[-0.5024, -5.3720],
        [-0.9360, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19536222517490387
Epoch 0, Step 467: train/loss = 0.5647990107536316, train/raw-loss = 0.5406509041786194, train/logprobs = tensor([[-0.5958, -1.4870],
        [-0.8560, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414804995059967
Epoch 0, Step 468: train/loss = 0.6257295608520508, train/raw-loss = 0.6034663915634155, train/logprobs = tensor([[-0.3130, -0.9010],
        [-0.6741, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22263193130493164
Epoch 0, Step 469: train/loss = 0.5712050199508667, train/raw-loss = 0.5527358651161194, train/logprobs = tensor([[-0.3397, -1.0950],
        [-0.6373, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18469128012657166
Epoch 0, Step 470: train/loss = 0.6137834191322327, train/raw-loss = 0.5945042371749878, train/logprobs = tensor([[-0.3916, -1.1625],
        [-0.7027, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1927916705608368
Epoch 0, Step 471: train/loss = 0.4778660237789154, train/raw-loss = 0.4559571146965027, train/logprobs = tensor([[-0.6137, -1.4465],
        [-1.1335, -0.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21908916532993317
Epoch 0, Step 472: train/loss = 0.5349957346916199, train/raw-loss = 0.510550856590271, train/logprobs = tensor([[-0.4302, -1.5197],
        [-0.7983, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24444913864135742
Epoch 0, Step 473: train/loss = 0.5758010745048523, train/raw-loss = 0.5555223822593689, train/logprobs = tensor([[-0.4876, -1.1059],
        [-0.8458, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20278726518154144
Epoch 0, Step 474: train/loss = 0.5865398645401001, train/raw-loss = 0.5630667805671692, train/logprobs = tensor([[-0.4173, -1.2070],
        [-0.8034, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23473113775253296
Epoch 0, Step 475: train/loss = 0.3078397214412689, train/raw-loss = 0.28775203227996826, train/logprobs = tensor([[-0.6198, -3.9579],
        [-1.1159, -0.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20087699592113495
Epoch 0, Step 476: train/loss = 0.7075250148773193, train/raw-loss = 0.6875038743019104, train/logprobs = tensor([[-0.4024, -0.4643],
        [-0.6143, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2002110481262207
Epoch 0, Step 477: train/loss = 0.5474287867546082, train/raw-loss = 0.5281498432159424, train/logprobs = tensor([[-0.6363, -3.0275],
        [-1.0231, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.192789226770401
Epoch 0, Step 478: train/loss = 0.6001648902893066, train/raw-loss = 0.5780423879623413, train/logprobs = tensor([[-0.8788, -1.9098],
        [-0.7627, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22122475504875183
Epoch 0, Step 479: train/loss = 0.4927450120449066, train/raw-loss = 0.4674730896949768, train/logprobs = tensor([[-0.5369, -1.9676],
        [-0.9655, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252718985080719
Epoch 0, Step 480: train/loss = 0.5724133253097534, train/raw-loss = 0.5467026233673096, train/logprobs = tensor([[-0.6488, -1.3790],
        [-0.8910, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571074664592743
Epoch 0, Step 481: train/loss = 0.5549925565719604, train/raw-loss = 0.5306423306465149, train/logprobs = tensor([[-0.6051, -3.4541],
        [-1.3040, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24350281059741974
Epoch 0, Step 482: train/loss = 0.6758943796157837, train/raw-loss = 0.6533750891685486, train/logprobs = tensor([[-1.3820, -1.3306],
        [-1.4223, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251928746700287
Epoch 0, Step 483: train/loss = 0.4882093667984009, train/raw-loss = 0.46425706148147583, train/logprobs = tensor([[-0.6932, -1.5596],
        [-1.3049, -0.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23952306807041168
Epoch 0, Step 484: train/loss = 0.5210654735565186, train/raw-loss = 0.5027157664299011, train/logprobs = tensor([[-0.5483, -3.2391],
        [-0.9500, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1834973394870758
Epoch 0, Step 485: train/loss = 0.6633181571960449, train/raw-loss = 0.6384239196777344, train/logprobs = tensor([[-0.8271, -1.0622],
        [-0.6965, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24894219636917114
Epoch 0, Step 486: train/loss = 0.3849393427371979, train/raw-loss = 0.36353957653045654, train/logprobs = tensor([[-0.5258, -2.6699],
        [-0.9532, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21399763226509094
Epoch 0, Step 487: train/loss = 0.49591565132141113, train/raw-loss = 0.46904075145721436, train/logprobs = tensor([[-0.3642, -1.5643],
        [-1.1759, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687488794326782
Epoch 0, Step 488: train/loss = 0.5318671464920044, train/raw-loss = 0.5085805058479309, train/logprobs = tensor([[-0.5021, -1.7752],
        [-0.9379, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23286646604537964
Epoch 0, Step 489: train/loss = 0.48919934034347534, train/raw-loss = 0.46994832158088684, train/logprobs = tensor([[-0.4891, -2.4475],
        [-0.9059, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925104409456253
Epoch 0, Step 490: train/loss = 0.5230859518051147, train/raw-loss = 0.5018482208251953, train/logprobs = tensor([[-0.6156, -1.5273],
        [-0.9088, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21237772703170776
Epoch 0, Step 491: train/loss = 0.44880276918411255, train/raw-loss = 0.42652302980422974, train/logprobs = tensor([[-0.6265, -2.0693],
        [-0.9864, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22279693186283112
Epoch 0, Step 492: train/loss = 0.33076655864715576, train/raw-loss = 0.30460938811302185, train/logprobs = tensor([[-0.6013, -3.3713],
        [-1.2184, -0.8296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615715563297272
Epoch 0, Step 493: train/loss = 0.7304291725158691, train/raw-loss = 0.703079342842102, train/logprobs = tensor([[-0.9835, -0.9417],
        [-0.9328, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27349865436553955
Epoch 0, Step 494: train/loss = 0.8505951166152954, train/raw-loss = 0.8252922296524048, train/logprobs = tensor([[-1.2674, -1.0167],
        [-0.7045, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530288100242615
Epoch 0, Step 495: train/loss = 0.5696799755096436, train/raw-loss = 0.5501534938812256, train/logprobs = tensor([[-0.5000, -1.1493],
        [-0.9346, -0.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19526460766792297
Epoch 0, Step 496: train/loss = 0.5940321683883667, train/raw-loss = 0.5733829736709595, train/logprobs = tensor([[-0.5647, -1.1918],
        [-0.7850, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20649203658103943
Epoch 0, Step 497: train/loss = 0.5024735331535339, train/raw-loss = 0.48037928342819214, train/logprobs = tensor([[-0.6158, -1.5256],
        [-1.0865, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094213962554932
Epoch 0, Step 498: train/loss = 0.4979800283908844, train/raw-loss = 0.47232237458229065, train/logprobs = tensor([[-0.4263, -3.2505],
        [-0.9829, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565769553184509
Epoch 0, Step 499: train/loss = 0.4429827332496643, train/raw-loss = 0.42172616720199585, train/logprobs = tensor([[-0.5547, -1.8722],
        [-0.8633, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21256552636623383
Epoch 0, Step 500: train/loss = 0.3903413414955139, train/raw-loss = 0.3677580654621124, train/logprobs = tensor([[-0.6317, -2.2879],
        [-1.0003, -0.5965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.225832998752594
Epoch 0, Step 501: train/loss = 0.2321181744337082, train/raw-loss = 0.20800508558750153, train/logprobs = tensor([[-0.5642, -4.0557],
        [-1.3691, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24113093316555023
Epoch 0, Step 502: train/loss = 0.41225120425224304, train/raw-loss = 0.3895934224128723, train/logprobs = tensor([[-0.7213, -2.4963],
        [-0.9824, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22657792270183563
Epoch 0, Step 503: train/loss = 0.6371981501579285, train/raw-loss = 0.6166873574256897, train/logprobs = tensor([[-0.6750, -1.8689],
        [-0.6840, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2051077038049698
Epoch 0, Step 504: train/loss = 0.5559613704681396, train/raw-loss = 0.5299871563911438, train/logprobs = tensor([[-0.7494, -1.4400],
        [-1.1909, -0.9930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25974172353744507
Epoch 0, Step 505: train/loss = 0.4799764156341553, train/raw-loss = 0.45508837699890137, train/logprobs = tensor([[-0.6137, -2.2501],
        [-0.9282, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24888066947460175
Epoch 0, Step 506: train/loss = 0.4334874451160431, train/raw-loss = 0.40711385011672974, train/logprobs = tensor([[-0.8373, -1.9686],
        [-1.7743, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26373571157455444
Epoch 0, Step 507: train/loss = 0.6223535537719727, train/raw-loss = 0.6002171039581299, train/logprobs = tensor([[-0.4435, -0.8637],
        [-0.8564, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213640809059143
Epoch 0, Step 508: train/loss = 0.5411975383758545, train/raw-loss = 0.5179194211959839, train/logprobs = tensor([[-0.6941, -1.4151],
        [-1.1609, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23278184235095978
Epoch 0, Step 509: train/loss = 0.4709930121898651, train/raw-loss = 0.45457392930984497, train/logprobs = tensor([[-0.6773, -3.7883],
        [-1.1933, -0.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641906201839447
Epoch 0, Step 510: train/loss = 0.5818774700164795, train/raw-loss = 0.5570286512374878, train/logprobs = tensor([[-0.5692, -1.3273],
        [-0.8090, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24848780035972595
Epoch 0, Step 511: train/loss = 0.33120548725128174, train/raw-loss = 0.3065400719642639, train/logprobs = tensor([[-0.5552, -3.0276],
        [-1.2614, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24665424227714539
Epoch 0, Step 512: train/loss = 0.3402565121650696, train/raw-loss = 0.31852877140045166, train/logprobs = tensor([[-0.7001, -3.3031],
        [-1.2139, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21727722883224487
Epoch 0, Step 513: train/loss = 0.516904890537262, train/raw-loss = 0.4920881986618042, train/logprobs = tensor([[-0.4380, -1.6623],
        [-0.9252, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24816681444644928
Epoch 0, Step 514: train/loss = 0.46370548009872437, train/raw-loss = 0.43910765647888184, train/logprobs = tensor([[-1.1860, -2.9649],
        [-1.0232, -0.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24597814679145813
Epoch 0, Step 515: train/loss = 0.403923898935318, train/raw-loss = 0.3804936707019806, train/logprobs = tensor([[-0.5733, -5.4068],
        [-1.1374, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343023270368576
Epoch 0, Step 516: train/loss = 0.4509972333908081, train/raw-loss = 0.42684274911880493, train/logprobs = tensor([[-0.6379, -3.8335],
        [-0.9613, -0.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24154475331306458
Epoch 0, Step 517: train/loss = 0.5191771984100342, train/raw-loss = 0.5022499561309814, train/logprobs = tensor([[-0.4405, -1.6249],
        [-0.5930, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.169272318482399
Epoch 0, Step 518: train/loss = 0.458335280418396, train/raw-loss = 0.43390047550201416, train/logprobs = tensor([[-0.7445, -4.2252],
        [-1.2048, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2443479597568512
Epoch 0, Step 519: train/loss = 0.5663519501686096, train/raw-loss = 0.5394325852394104, train/logprobs = tensor([[-0.7138, -1.6511],
        [-0.8900, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691934406757355
Epoch 0, Step 520: train/loss = 0.6806302070617676, train/raw-loss = 0.6536183953285217, train/logprobs = tensor([[-1.2704, -2.0289],
        [-0.9239, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27011778950691223
Epoch 0, Step 521: train/loss = 0.362177312374115, train/raw-loss = 0.33451521396636963, train/logprobs = tensor([[-0.8016, -2.5136],
        [-1.8256, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27662116289138794
Epoch 0, Step 522: train/loss = 0.42302972078323364, train/raw-loss = 0.399486780166626, train/logprobs = tensor([[-1.5692, -4.7305],
        [-1.6080, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23542949557304382
Epoch 0, Step 523: train/loss = 0.4740232229232788, train/raw-loss = 0.4493805766105652, train/logprobs = tensor([[-0.5725, -5.1292],
        [-0.9953, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24642643332481384
Epoch 0, Step 524: train/loss = 0.5804674029350281, train/raw-loss = 0.5563149452209473, train/logprobs = tensor([[-0.7425, -1.1662],
        [-0.9711, -0.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24152490496635437
Epoch 0, Step 525: train/loss = 0.5812162160873413, train/raw-loss = 0.5576488971710205, train/logprobs = tensor([[-0.5897, -1.7477],
        [-0.8489, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23567336797714233
Epoch 0, Step 526: train/loss = 0.5971040725708008, train/raw-loss = 0.575279712677002, train/logprobs = tensor([[-0.4610, -0.9553],
        [-0.8622, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21824370324611664
Epoch 0, Step 527: train/loss = 0.5434644222259521, train/raw-loss = 0.5181427001953125, train/logprobs = tensor([[-1.0451, -5.0412],
        [-0.9857, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25321733951568604
Epoch 0, Step 528: train/loss = 0.490101158618927, train/raw-loss = 0.4612986445426941, train/logprobs = tensor([[-0.7326, -2.0375],
        [-1.2184, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28802502155303955
Epoch 0, Step 529: train/loss = 0.4396408796310425, train/raw-loss = 0.4153584837913513, train/logprobs = tensor([[-1.0259, -3.7499],
        [-1.3150, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24282395839691162
Epoch 0, Step 530: train/loss = 0.6641239523887634, train/raw-loss = 0.6455228924751282, train/logprobs = tensor([[-0.4501, -0.9067],
        [-0.7053, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18601059913635254
Epoch 0, Step 531: train/loss = 0.6785616278648376, train/raw-loss = 0.6532557010650635, train/logprobs = tensor([[-0.6115, -1.0512],
        [-0.9252, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253059446811676
Epoch 0, Step 532: train/loss = 0.6574731469154358, train/raw-loss = 0.6319055557250977, train/logprobs = tensor([[-0.4457, -0.8174],
        [-0.9410, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556757628917694
Epoch 0, Step 533: train/loss = 0.28978413343429565, train/raw-loss = 0.2685275077819824, train/logprobs = tensor([[-0.7857, -6.2830],
        [-1.0521, -0.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21256640553474426
Epoch 0, Step 534: train/loss = 0.516747236251831, train/raw-loss = 0.49509957432746887, train/logprobs = tensor([[-0.5979, -3.5601],
        [-1.0205, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21647655963897705
Epoch 0, Step 535: train/loss = 0.5287325382232666, train/raw-loss = 0.5064365267753601, train/logprobs = tensor([[-0.4111, -1.6815],
        [-0.8715, -0.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22296017408370972
Epoch 0, Step 536: train/loss = 0.498464435338974, train/raw-loss = 0.47401946783065796, train/logprobs = tensor([[-0.4620, -2.0564],
        [-0.9900, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2444499135017395
Epoch 0, Step 537: train/loss = 0.40694624185562134, train/raw-loss = 0.3845895528793335, train/logprobs = tensor([[-0.6478, -3.4105],
        [-0.9910, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22356685996055603
Epoch 0, Step 538: train/loss = 0.5972180962562561, train/raw-loss = 0.5766195058822632, train/logprobs = tensor([[-0.9387, -2.6633],
        [-0.6225, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20598545670509338
Epoch 0, Step 539: train/loss = 0.38279128074645996, train/raw-loss = 0.35837286710739136, train/logprobs = tensor([[-0.7481, -2.9084],
        [-1.2353, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2441839873790741
Epoch 0, Step 540: train/loss = 0.37277519702911377, train/raw-loss = 0.35121220350265503, train/logprobs = tensor([[-0.6511, -4.0469],
        [-0.8880, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21562997996807098
Epoch 0, Step 541: train/loss = 0.5749343037605286, train/raw-loss = 0.5516995191574097, train/logprobs = tensor([[-0.4770, -2.0226],
        [-0.7398, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23234806954860687
Epoch 0, Step 542: train/loss = 0.4116429090499878, train/raw-loss = 0.39181482791900635, train/logprobs = tensor([[-0.7490, -3.3552],
        [-0.6605, -0.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19828054308891296
Epoch 0, Step 543: train/loss = 0.3156471252441406, train/raw-loss = 0.29578906297683716, train/logprobs = tensor([[-0.4909, -4.1019],
        [-0.9360, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858041405677795
Epoch 0, Step 544: train/loss = 0.4668044149875641, train/raw-loss = 0.4397572875022888, train/logprobs = tensor([[-0.6872, -3.9083],
        [-1.1216, -1.2140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2704709768295288
Epoch 0, Step 545: train/loss = 0.4294690787792206, train/raw-loss = 0.40500330924987793, train/logprobs = tensor([[-0.9474, -2.5680],
        [-1.3813, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446579486131668
Epoch 0, Step 546: train/loss = 0.46065688133239746, train/raw-loss = 0.4397326111793518, train/logprobs = tensor([[-0.5216, -2.4035],
        [-0.6363, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20924293994903564
Epoch 0, Step 547: train/loss = 0.600433349609375, train/raw-loss = 0.5812612175941467, train/logprobs = tensor([[-0.8583, -1.2995],
        [-0.7847, -0.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19172172248363495
Epoch 0, Step 548: train/loss = 0.379817932844162, train/raw-loss = 0.3549250662326813, train/logprobs = tensor([[-0.7317, -5.2653],
        [-0.9185, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489289939403534
Epoch 0, Step 549: train/loss = 0.42440205812454224, train/raw-loss = 0.3958960771560669, train/logprobs = tensor([[-0.6564, -3.0405],
        [-1.4508, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28505972027778625
Epoch 0, Step 550: train/loss = 0.430442214012146, train/raw-loss = 0.3970479965209961, train/logprobs = tensor([[-1.1180, -3.3093],
        [-1.6186, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33394214510917664
Epoch 0, Step 551: train/loss = 0.4844740033149719, train/raw-loss = 0.4608278274536133, train/logprobs = tensor([[-0.6172, -1.6918],
        [-0.7187, -0.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23646150529384613
Epoch 0, Step 552: train/loss = 0.5363131761550903, train/raw-loss = 0.511654794216156, train/logprobs = tensor([[-0.9900, -5.0912],
        [-0.9700, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2465832531452179
Epoch 0, Step 553: train/loss = 0.5814910531044006, train/raw-loss = 0.5581753849983215, train/logprobs = tensor([[-0.5161, -1.6464],
        [-0.7438, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2331567108631134
Epoch 0, Step 554: train/loss = 0.3355449438095093, train/raw-loss = 0.31348901987075806, train/logprobs = tensor([[-0.5020, -3.6255],
        [-1.0003, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22055885195732117
Epoch 0, Step 555: train/loss = 0.5844255089759827, train/raw-loss = 0.5616626143455505, train/logprobs = tensor([[-0.5474, -1.6968],
        [-0.7264, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22762972116470337
Epoch 0, Step 556: train/loss = 0.5381557941436768, train/raw-loss = 0.5100849866867065, train/logprobs = tensor([[-0.7421, -1.7701],
        [-0.9727, -0.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28070762753486633
Epoch 0, Step 557: train/loss = 0.48478707671165466, train/raw-loss = 0.4604499340057373, train/logprobs = tensor([[-0.6732, -1.6576],
        [-1.1754, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2433713674545288
Epoch 0, Step 558: train/loss = 0.6000211238861084, train/raw-loss = 0.5727667212486267, train/logprobs = tensor([[-0.7319, -1.7716],
        [-0.8153, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725442349910736
Epoch 0, Step 559: train/loss = 0.5026598572731018, train/raw-loss = 0.47375252842903137, train/logprobs = tensor([[-1.1143, -3.8150],
        [-0.8302, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28907331824302673
Epoch 0, Step 560: train/loss = 0.4594610035419464, train/raw-loss = 0.4305269122123718, train/logprobs = tensor([[-0.8643, -3.9792],
        [-1.0458, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28934088349342346
Epoch 0, Step 561: train/loss = 0.5282372832298279, train/raw-loss = 0.5056379437446594, train/logprobs = tensor([[-0.6241, -2.6546],
        [-0.7236, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22599387168884277
Epoch 0, Step 562: train/loss = 0.3605734407901764, train/raw-loss = 0.3292294144630432, train/logprobs = tensor([[-1.2224, -4.5724],
        [-1.4436, -0.7048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3134407103061676
Epoch 0, Step 563: train/loss = 0.5235388875007629, train/raw-loss = 0.4954231381416321, train/logprobs = tensor([[-0.7629, -3.9277],
        [-0.6918, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28115737438201904
Epoch 0, Step 564: train/loss = 0.36650246381759644, train/raw-loss = 0.34100279211997986, train/logprobs = tensor([[-0.6910, -2.9120],
        [-1.1558, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25499647855758667
Epoch 0, Step 565: train/loss = 0.5074030756950378, train/raw-loss = 0.48589274287223816, train/logprobs = tensor([[-0.7699, -3.2006],
        [-0.9112, -1.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21510344743728638
Epoch 0, Step 566: train/loss = 0.5387388467788696, train/raw-loss = 0.5122909545898438, train/logprobs = tensor([[-0.9511, -1.9020],
        [-0.9514, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644793391227722
Epoch 0, Step 567: train/loss = 0.468239963054657, train/raw-loss = 0.4378106892108917, train/logprobs = tensor([[-0.7555, -2.8690],
        [-1.3155, -1.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30429303646087646
Epoch 0, Step 568: train/loss = 0.5287320017814636, train/raw-loss = 0.5032883882522583, train/logprobs = tensor([[-0.7797, -3.3341],
        [-0.8205, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544364929199219
Epoch 0, Step 569: train/loss = 0.47953587770462036, train/raw-loss = 0.45593830943107605, train/logprobs = tensor([[-0.7266, -2.7098],
        [-0.8724, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23597534000873566
Epoch 0, Step 570: train/loss = 0.41013121604919434, train/raw-loss = 0.3844500780105591, train/logprobs = tensor([[-1.1478, -6.1966],
        [-1.1966, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568117380142212
Epoch 0, Step 571: train/loss = 0.34694114327430725, train/raw-loss = 0.3231801986694336, train/logprobs = tensor([[-1.0129, -3.9562],
        [-1.1932, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23760929703712463
Epoch 0, Step 572: train/loss = 0.2772367000579834, train/raw-loss = 0.25191712379455566, train/logprobs = tensor([[-0.6221, -5.2172],
        [-1.4137, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531958222389221
Epoch 0, Step 573: train/loss = 0.29323846101760864, train/raw-loss = 0.2688515782356262, train/logprobs = tensor([[-0.6688, -5.6287],
        [-1.1037, -0.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438688427209854
Epoch 0, Step 574: train/loss = 0.42359304428100586, train/raw-loss = 0.400623083114624, train/logprobs = tensor([[-0.7111, -3.4420],
        [-1.0384, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296992838382721
Epoch 0, Step 575: train/loss = 0.5257403254508972, train/raw-loss = 0.49813389778137207, train/logprobs = tensor([[-0.8266, -2.7328],
        [-1.4689, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27606430649757385
Epoch 0, Step 576: train/loss = 0.3933950662612915, train/raw-loss = 0.3691454827785492, train/logprobs = tensor([[-0.6199, -3.1639],
        [-0.9288, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24249544739723206
Epoch 0, Step 577: train/loss = 0.4532455801963806, train/raw-loss = 0.4263489842414856, train/logprobs = tensor([[-0.7781, -3.0195],
        [-1.1890, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689661681652069
Epoch 0, Step 578: train/loss = 0.47613945603370667, train/raw-loss = 0.4495478868484497, train/logprobs = tensor([[-0.7901, -3.0336],
        [-1.1603, -0.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26591581106185913
Epoch 0, Step 579: train/loss = 0.5168771147727966, train/raw-loss = 0.4924400746822357, train/logprobs = tensor([[-0.6630, -1.9743],
        [-0.9196, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24437016248703003
Epoch 0, Step 580: train/loss = 0.5930849313735962, train/raw-loss = 0.5612645745277405, train/logprobs = tensor([[-0.9582, -2.7012],
        [-1.2069, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31820327043533325
Epoch 0, Step 581: train/loss = 0.5797775983810425, train/raw-loss = 0.554113507270813, train/logprobs = tensor([[-0.8810, -3.1434],
        [-0.7905, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25664082169532776
Epoch 0, Step 582: train/loss = 0.4295097291469574, train/raw-loss = 0.4007931351661682, train/logprobs = tensor([[-1.0115, -4.8318],
        [-1.0667, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871658504009247
Epoch 0, Step 583: train/loss = 0.44869303703308105, train/raw-loss = 0.41779613494873047, train/logprobs = tensor([[-0.9230, -3.3465],
        [-1.2231, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3089691400527954
Epoch 0, Step 584: train/loss = 0.36182892322540283, train/raw-loss = 0.33098775148391724, train/logprobs = tensor([[-0.9375, -4.3895],
        [-1.3054, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084116578102112
Epoch 0, Step 585: train/loss = 0.3235909938812256, train/raw-loss = 0.29472118616104126, train/logprobs = tensor([[-1.0471, -8.7903],
        [-1.3782, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28869837522506714
Epoch 0, Step 586: train/loss = 0.5260094404220581, train/raw-loss = 0.501698911190033, train/logprobs = tensor([[-0.5491, -1.9600],
        [-0.7454, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24310585856437683
Epoch 0, Step 587: train/loss = 0.4310595989227295, train/raw-loss = 0.4041725993156433, train/logprobs = tensor([[-0.6914, -2.6454],
        [-0.9234, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26886996626853943
Epoch 0, Step 588: train/loss = 0.542523205280304, train/raw-loss = 0.515739381313324, train/logprobs = tensor([[-0.6883, -1.8693],
        [-0.9605, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26783859729766846
Epoch 0, Step 589: train/loss = 0.5547103881835938, train/raw-loss = 0.5257331728935242, train/logprobs = tensor([[-0.7051, -1.5624],
        [-0.9572, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897721827030182
Epoch 0, Step 590: train/loss = 0.47089120745658875, train/raw-loss = 0.44308188557624817, train/logprobs = tensor([[-1.1217, -3.2858],
        [-1.2084, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27809321880340576
Epoch 0, Step 591: train/loss = 0.3665950894355774, train/raw-loss = 0.34127670526504517, train/logprobs = tensor([[-0.7114, -4.5594],
        [-1.0442, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531834840774536
Epoch 0, Step 592: train/loss = 0.5624745488166809, train/raw-loss = 0.5367779731750488, train/logprobs = tensor([[-0.7755, -3.0616],
        [-1.0682, -0.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256965696811676
Epoch 0, Step 593: train/loss = 0.32274848222732544, train/raw-loss = 0.2907256484031677, train/logprobs = tensor([[-1.0415, -3.7514],
        [-1.5576, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32022830843925476
Epoch 0, Step 594: train/loss = 0.380062460899353, train/raw-loss = 0.3519405424594879, train/logprobs = tensor([[-0.7459, -4.0542],
        [-1.1412, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812192738056183
Epoch 0, Step 595: train/loss = 0.492794394493103, train/raw-loss = 0.4640645384788513, train/logprobs = tensor([[-1.0845, -3.4524],
        [-1.1830, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872985005378723
Epoch 0, Step 596: train/loss = 0.9229370355606079, train/raw-loss = 0.8894827365875244, train/logprobs = tensor([[-2.1479, -2.2017],
        [-1.0116, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33454254269599915
Epoch 0, Step 597: train/loss = 0.4919481873512268, train/raw-loss = 0.46291792392730713, train/logprobs = tensor([[-0.8700, -5.1503],
        [-1.2697, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29030245542526245
Epoch 0, Step 598: train/loss = 0.44111138582229614, train/raw-loss = 0.4124147295951843, train/logprobs = tensor([[-0.9391, -3.4246],
        [-1.2913, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869666814804077
Epoch 0, Step 599: train/loss = 0.3554759919643402, train/raw-loss = 0.3265970051288605, train/logprobs = tensor([[-0.7034, -5.1894],
        [-0.9937, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887900769710541
Epoch 0, Step 600: train/loss = 0.5631433725357056, train/raw-loss = 0.5333146452903748, train/logprobs = tensor([[-0.7606, -1.4428],
        [-0.9772, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982870936393738
Epoch 0, Step 601: train/loss = 0.5157038569450378, train/raw-loss = 0.4924136996269226, train/logprobs = tensor([[-0.6110, -1.8788],
        [-0.7407, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329016774892807
Epoch 0, Step 602: train/loss = 0.892522931098938, train/raw-loss = 0.8609568476676941, train/logprobs = tensor([[-2.2965, -4.2892],
        [-0.9112, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156603276729584
Epoch 0, Step 603: train/loss = 0.5062851905822754, train/raw-loss = 0.4842787981033325, train/logprobs = tensor([[-0.5668, -1.8993],
        [-0.9028, -0.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200646698474884
Epoch 0, Step 604: train/loss = 0.5649587512016296, train/raw-loss = 0.5433286428451538, train/logprobs = tensor([[-1.1321, -4.2287],
        [-1.0866, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21630090475082397
Epoch 0, Step 605: train/loss = 0.3047598600387573, train/raw-loss = 0.27484336495399475, train/logprobs = tensor([[-0.6814, -6.7129],
        [-1.1210, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991650104522705
Epoch 0, Step 606: train/loss = 0.5079417824745178, train/raw-loss = 0.48418113589286804, train/logprobs = tensor([[-1.0291, -5.0321],
        [-1.0200, -0.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2376066893339157
Epoch 0, Step 607: train/loss = 0.3441935181617737, train/raw-loss = 0.3192490339279175, train/logprobs = tensor([[-0.7118, -3.4055],
        [-1.3004, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24944457411766052
Epoch 0, Step 608: train/loss = 0.8016546964645386, train/raw-loss = 0.7649269104003906, train/logprobs = tensor([[-2.1311, -2.1152],
        [-1.2044, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36727768182754517
Epoch 0, Step 609: train/loss = 0.3946435749530792, train/raw-loss = 0.36137843132019043, train/logprobs = tensor([[-1.1435, -6.0583],
        [-1.1705, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33265137672424316
Epoch 0, Step 610: train/loss = 0.30766457319259644, train/raw-loss = 0.279489666223526, train/logprobs = tensor([[-0.8137, -4.1206],
        [-1.3158, -0.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817493677139282
Epoch 0, Step 611: train/loss = 0.3444516062736511, train/raw-loss = 0.3185112476348877, train/logprobs = tensor([[-0.8887, -5.3911],
        [-1.3990, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594035267829895
Epoch 0, Step 612: train/loss = 0.5975966453552246, train/raw-loss = 0.5637435913085938, train/logprobs = tensor([[-1.2333, -2.3241],
        [-1.3213, -1.2727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33853060007095337
Epoch 0, Step 613: train/loss = 0.4818049669265747, train/raw-loss = 0.45686620473861694, train/logprobs = tensor([[-0.9109, -7.9664],
        [-1.0280, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24938789010047913
Epoch 0, Step 614: train/loss = 0.5086648464202881, train/raw-loss = 0.47449731826782227, train/logprobs = tensor([[-1.3036, -2.6456],
        [-1.3647, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416749835014343
Epoch 0, Step 615: train/loss = 0.5449091196060181, train/raw-loss = 0.5130404829978943, train/logprobs = tensor([[-1.7916, -6.3874],
        [-1.4998, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31868618726730347
Epoch 0, Step 616: train/loss = 0.9494568109512329, train/raw-loss = 0.9154369831085205, train/logprobs = tensor([[-2.7733, -2.6448],
        [-1.1648, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34019890427589417
Epoch 0, Step 617: train/loss = 0.49839064478874207, train/raw-loss = 0.46744951605796814, train/logprobs = tensor([[-0.8954, -3.0603],
        [-1.1839, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094109892845154
Epoch 0, Step 618: train/loss = 0.6883350610733032, train/raw-loss = 0.6550898551940918, train/logprobs = tensor([[-2.3893, -4.3997],
        [-1.1421, -0.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3324517011642456
Epoch 0, Step 619: train/loss = 0.3906816840171814, train/raw-loss = 0.35664042830467224, train/logprobs = tensor([[-0.9593, -3.2611],
        [-1.7224, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404122591018677
Epoch 0, Step 620: train/loss = 0.5477331876754761, train/raw-loss = 0.5167310237884521, train/logprobs = tensor([[-0.9464, -1.8338],
        [-1.0482, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100210428237915
Epoch 0, Step 621: train/loss = 0.4118914008140564, train/raw-loss = 0.382657915353775, train/logprobs = tensor([[-0.8161, -4.0571],
        [-1.0081, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29233497381210327
Epoch 0, Step 622: train/loss = 0.48396462202072144, train/raw-loss = 0.4523851275444031, train/logprobs = tensor([[-0.7391, -2.8579],
        [-1.2283, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3157948851585388
Epoch 0, Step 623: train/loss = 0.5383383631706238, train/raw-loss = 0.5097790956497192, train/logprobs = tensor([[-0.9755, -3.4773],
        [-1.0410, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855924367904663
Epoch 0, Step 624: train/loss = 0.37438005208969116, train/raw-loss = 0.3370663523674011, train/logprobs = tensor([[-1.6048, -4.7342],
        [-1.6006, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731366991996765
Epoch 0, Step 625: train/loss = 0.39388948678970337, train/raw-loss = 0.365642786026001, train/logprobs = tensor([[-1.6360, -5.3715],
        [-1.2875, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28246721625328064
Epoch 0, Step 626: train/loss = 0.4696543216705322, train/raw-loss = 0.4442107379436493, train/logprobs = tensor([[-0.6422, -4.1750],
        [-0.8910, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25443583726882935
Epoch 0, Step 627: train/loss = 0.5193525552749634, train/raw-loss = 0.4881361126899719, train/logprobs = tensor([[-1.1125, -3.1881],
        [-1.1581, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31216394901275635
Epoch 0, Step 628: train/loss = 0.3020190894603729, train/raw-loss = 0.27755582332611084, train/logprobs = tensor([[-1.2667, -9.0710],
        [-1.3777, -1.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446327805519104
Epoch 0, Step 629: train/loss = 0.3232710063457489, train/raw-loss = 0.29400765895843506, train/logprobs = tensor([[-0.8172, -6.1082],
        [-1.5636, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29263338446617126
Epoch 0, Step 630: train/loss = 0.39505383372306824, train/raw-loss = 0.3664514422416687, train/logprobs = tensor([[-1.2698, -6.6218],
        [-1.1957, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860238254070282
Epoch 0, Step 631: train/loss = 0.6032699346542358, train/raw-loss = 0.5714927911758423, train/logprobs = tensor([[-1.6252, -3.1695],
        [-1.2359, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31777137517929077
Epoch 0, Step 632: train/loss = 0.38815778493881226, train/raw-loss = 0.3552982807159424, train/logprobs = tensor([[-1.1384, -4.8829],
        [-1.6524, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285951316356659
Epoch 0, Step 633: train/loss = 0.5910841822624207, train/raw-loss = 0.5619134902954102, train/logprobs = tensor([[-0.6721, -1.2964],
        [-1.2615, -1.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2917064130306244
Epoch 0, Step 634: train/loss = 0.7913893461227417, train/raw-loss = 0.7614233493804932, train/logprobs = tensor([[-1.7366, -1.1940],
        [-1.1703, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996603548526764
Epoch 0, Step 635: train/loss = 0.34646955132484436, train/raw-loss = 0.314883291721344, train/logprobs = tensor([[-1.0480, -3.9680],
        [-1.5888, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158627152442932
Epoch 0, Step 636: train/loss = 0.45420005917549133, train/raw-loss = 0.42502355575561523, train/logprobs = tensor([[-0.8608, -3.3504],
        [-1.1145, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2917650640010834
Epoch 0, Step 637: train/loss = 0.48226800560951233, train/raw-loss = 0.45317161083221436, train/logprobs = tensor([[-0.9110, -3.2235],
        [-0.8356, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2909643352031708
Epoch 0, Step 638: train/loss = 0.601227879524231, train/raw-loss = 0.5627903938293457, train/logprobs = tensor([[-1.7803, -2.6506],
        [-1.3774, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38437509536743164
Epoch 0, Step 639: train/loss = 0.3479987382888794, train/raw-loss = 0.3200380206108093, train/logprobs = tensor([[-0.8365, -4.7580],
        [-1.2247, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27960696816444397
Epoch 0, Step 640: train/loss = 0.4337204098701477, train/raw-loss = 0.403894305229187, train/logprobs = tensor([[-0.7705, -2.3448],
        [-1.1498, -0.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29826095700263977
Epoch 0, Step 641: train/loss = 0.5794436931610107, train/raw-loss = 0.5457944869995117, train/logprobs = tensor([[-1.3937, -5.7028],
        [-1.0950, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364923894405365
Epoch 0, Step 642: train/loss = 0.6857466101646423, train/raw-loss = 0.6531535387039185, train/logprobs = tensor([[-0.8531, -0.9047],
        [-1.0970, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32593026757240295
Epoch 0, Step 643: train/loss = 0.44639402627944946, train/raw-loss = 0.4144897758960724, train/logprobs = tensor([[-1.7394, -6.2341],
        [-1.7632, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3190425932407379
Epoch 0, Step 644: train/loss = 0.396544486284256, train/raw-loss = 0.36483556032180786, train/logprobs = tensor([[-1.2044, -6.9317],
        [-1.2065, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317088782787323
Epoch 0, Step 645: train/loss = 0.3926753103733063, train/raw-loss = 0.3620954155921936, train/logprobs = tensor([[-0.9172, -5.7067],
        [-0.9927, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30579882860183716
Epoch 0, Step 646: train/loss = 0.5018779635429382, train/raw-loss = 0.4769030809402466, train/logprobs = tensor([[-0.7614, -5.4039],
        [-0.8766, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24974840879440308
Epoch 0, Step 647: train/loss = 0.45365914702415466, train/raw-loss = 0.4089948534965515, train/logprobs = tensor([[-1.2384, -3.5008],
        [-1.3734, -1.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44664305448532104
Epoch 0, Step 648: train/loss = 0.5751920938491821, train/raw-loss = 0.546188473701477, train/logprobs = tensor([[-0.9999, -2.4503],
        [-1.1237, -0.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29003652930259705
Epoch 0, Step 649: train/loss = 0.38048073649406433, train/raw-loss = 0.34567713737487793, train/logprobs = tensor([[-1.5317, -4.6532],
        [-1.5725, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480360805988312
Epoch 0, Step 650: train/loss = 0.5995598435401917, train/raw-loss = 0.5685144066810608, train/logprobs = tensor([[-1.6566, -3.0152],
        [-0.9969, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31045472621917725
Epoch 0, Step 651: train/loss = 0.3811115622520447, train/raw-loss = 0.34094539284706116, train/logprobs = tensor([[-1.6113, -4.2278],
        [-1.5414, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40166181325912476
Epoch 0, Step 652: train/loss = 0.5423397421836853, train/raw-loss = 0.5112187266349792, train/logprobs = tensor([[-1.2287, -2.6626],
        [-1.3432, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31120988726615906
Epoch 0, Step 653: train/loss = 0.37846097350120544, train/raw-loss = 0.348816454410553, train/logprobs = tensor([[-0.8403, -6.4114],
        [-0.9305, -0.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29644539952278137
Epoch 0, Step 654: train/loss = 0.41305235028266907, train/raw-loss = 0.38460931181907654, train/logprobs = tensor([[-0.9849, -3.2515],
        [-0.9534, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2844303250312805
Epoch 0, Step 655: train/loss = 0.5134333372116089, train/raw-loss = 0.4828130900859833, train/logprobs = tensor([[-0.7366, -2.7760],
        [-1.0693, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30620276927948
Epoch 0, Step 656: train/loss = 0.38257282972335815, train/raw-loss = 0.35125285387039185, train/logprobs = tensor([[-1.1999, -5.1700],
        [-1.2485, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132000267505646
Epoch 0, Step 657: train/loss = 0.3688186705112457, train/raw-loss = 0.34343183040618896, train/logprobs = tensor([[-0.7221, -4.8163],
        [-0.9688, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25386855006217957
Epoch 0, Step 658: train/loss = 0.5874935388565063, train/raw-loss = 0.5581228137016296, train/logprobs = tensor([[-1.5603, -7.0470],
        [-0.9446, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29370757937431335
Epoch 0, Step 659: train/loss = 0.46294528245925903, train/raw-loss = 0.4331051707267761, train/logprobs = tensor([[-0.9016, -3.1756],
        [-0.9456, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29840153455734253
Epoch 0, Step 660: train/loss = 0.38690635561943054, train/raw-loss = 0.3521423637866974, train/logprobs = tensor([[-1.5485, -5.5084],
        [-2.1273, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34763985872268677
Epoch 0, Step 661: train/loss = 0.5640231966972351, train/raw-loss = 0.5297401547431946, train/logprobs = tensor([[-1.5827, -3.2523],
        [-1.3658, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428303003311157
Epoch 0, Step 662: train/loss = 0.6038739681243896, train/raw-loss = 0.5674019455909729, train/logprobs = tensor([[-2.1452, -4.2616],
        [-1.5729, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3647193908691406
Epoch 0, Step 663: train/loss = 0.2573341131210327, train/raw-loss = 0.22503693401813507, train/logprobs = tensor([[-1.0938, -6.4691],
        [-1.5467, -1.5022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229716420173645
Epoch 0, Step 664: train/loss = 0.3691347539424896, train/raw-loss = 0.3357507288455963, train/logprobs = tensor([[-0.8936, -4.3705],
        [-1.5428, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33384019136428833
Epoch 0, Step 665: train/loss = 0.5754787921905518, train/raw-loss = 0.5460191369056702, train/logprobs = tensor([[-0.6464, -2.5612],
        [-0.9304, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945965528488159
Epoch 0, Step 666: train/loss = 0.9644184112548828, train/raw-loss = 0.930385947227478, train/logprobs = tensor([[-3.1126, -3.7681],
        [-1.2017, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403244614601135
Epoch 0, Step 667: train/loss = 0.5173577070236206, train/raw-loss = 0.48235639929771423, train/logprobs = tensor([[-1.0763, -2.4941],
        [-1.6094, -1.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3500129282474518
Epoch 0, Step 668: train/loss = 0.4740105867385864, train/raw-loss = 0.4407613277435303, train/logprobs = tensor([[-1.2556, -3.7185],
        [-1.3694, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33249276876449585
Epoch 0, Step 669: train/loss = 0.4960029125213623, train/raw-loss = 0.464627742767334, train/logprobs = tensor([[-1.5839, -4.3761],
        [-1.5674, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137519061565399
Epoch 0, Step 670: train/loss = 0.4981299638748169, train/raw-loss = 0.4673781991004944, train/logprobs = tensor([[-1.0155, -1.7834],
        [-1.1929, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30751752853393555
Epoch 0, Step 671: train/loss = 0.5547870993614197, train/raw-loss = 0.5193140506744385, train/logprobs = tensor([[-1.4482, -3.1290],
        [-1.2424, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547307252883911
Epoch 0, Step 672: train/loss = 0.6757442951202393, train/raw-loss = 0.6445760130882263, train/logprobs = tensor([[-2.3215, -4.7785],
        [-1.2950, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116823434829712
Epoch 0, Step 673: train/loss = 0.6617023944854736, train/raw-loss = 0.6328048706054688, train/logprobs = tensor([[-1.2293, -3.6015],
        [-0.8833, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288975328207016
Epoch 0, Step 674: train/loss = 0.40370941162109375, train/raw-loss = 0.3674144446849823, train/logprobs = tensor([[-1.5101, -4.8351],
        [-1.1516, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629496991634369
Epoch 0, Step 675: train/loss = 0.39404186606407166, train/raw-loss = 0.35621029138565063, train/logprobs = tensor([[-1.0633, -4.4975],
        [-1.6239, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37831583619117737
Epoch 0, Step 676: train/loss = 0.6563482880592346, train/raw-loss = 0.6187268495559692, train/logprobs = tensor([[-2.6035, -4.5357],
        [-1.5759, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762147128582001
Epoch 0, Step 677: train/loss = 0.4271313548088074, train/raw-loss = 0.3937251567840576, train/logprobs = tensor([[-0.7504, -4.0885],
        [-1.2961, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33406203985214233
Epoch 0, Step 678: train/loss = 0.430363267660141, train/raw-loss = 0.3988001048564911, train/logprobs = tensor([[-0.6493, -2.6097],
        [-1.3885, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31563159823417664
Epoch 0, Step 679: train/loss = 0.6018352508544922, train/raw-loss = 0.5627157092094421, train/logprobs = tensor([[-2.9234, -8.6423],
        [-1.9046, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3911955952644348
Epoch 0, Step 680: train/loss = 0.7378966212272644, train/raw-loss = 0.6964534521102905, train/logprobs = tensor([[-1.0324, -1.1189],
        [-1.1679, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41443169116973877
Epoch 0, Step 681: train/loss = 0.5479257702827454, train/raw-loss = 0.5162774324417114, train/logprobs = tensor([[-1.3299, -3.6664],
        [-1.1303, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164828419685364
Epoch 0, Step 682: train/loss = 0.49228161573410034, train/raw-loss = 0.45882999897003174, train/logprobs = tensor([[-0.7666, -2.6332],
        [-1.1789, -0.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345164358615875
Epoch 0, Step 683: train/loss = 0.543628990650177, train/raw-loss = 0.5097155570983887, train/logprobs = tensor([[-1.2284, -2.4962],
        [-1.4567, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3391342759132385
Epoch 0, Step 684: train/loss = 0.5028514862060547, train/raw-loss = 0.4726484417915344, train/logprobs = tensor([[-1.2532, -5.1172],
        [-1.0551, -0.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30203020572662354
Epoch 0, Step 685: train/loss = 0.5302878618240356, train/raw-loss = 0.49653366208076477, train/logprobs = tensor([[-1.1336, -2.6666],
        [-1.2118, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33754175901412964
Epoch 0, Step 686: train/loss = 0.34483835101127625, train/raw-loss = 0.3189229965209961, train/logprobs = tensor([[-0.5684, -5.0581],
        [-0.8681, -0.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591536045074463
Epoch 0, Step 687: train/loss = 0.2652464509010315, train/raw-loss = 0.23690690100193024, train/logprobs = tensor([[-0.8144, -6.6871],
        [-1.0739, -0.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.283395379781723
Epoch 0, Step 688: train/loss = 0.23678214848041534, train/raw-loss = 0.20763792097568512, train/logprobs = tensor([[-0.8953, -7.6720],
        [-1.4169, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914423942565918
Epoch 0, Step 689: train/loss = 0.39946916699409485, train/raw-loss = 0.36928337812423706, train/logprobs = tensor([[-0.8678, -4.9460],
        [-1.0088, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3018577992916107
Epoch 0, Step 690: train/loss = 0.4698887765407562, train/raw-loss = 0.44197022914886475, train/logprobs = tensor([[-0.9724, -2.5200],
        [-1.3833, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27918559312820435
Epoch 0, Step 691: train/loss = 0.4664986729621887, train/raw-loss = 0.4328238070011139, train/logprobs = tensor([[-0.7438, -2.5466],
        [-1.3726, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33674880862236023
Epoch 0, Step 692: train/loss = 1.0819282531738281, train/raw-loss = 1.0400818586349487, train/logprobs = tensor([[-4.0224, -6.2873],
        [-1.3531, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41846394538879395
Epoch 0, Step 693: train/loss = 0.31083860993385315, train/raw-loss = 0.2738623023033142, train/logprobs = tensor([[-1.2525, -4.2679],
        [-1.8555, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36976325511932373
Epoch 0, Step 694: train/loss = 0.7631915807723999, train/raw-loss = 0.7277696132659912, train/logprobs = tensor([[-1.8501, -4.9805],
        [-1.3846, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35421890020370483
Epoch 0, Step 695: train/loss = 0.3287254571914673, train/raw-loss = 0.28944242000579834, train/logprobs = tensor([[-1.2340, -5.5075],
        [-1.7081, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928299844264984
Epoch 0, Step 696: train/loss = 0.48441576957702637, train/raw-loss = 0.44594064354896545, train/logprobs = tensor([[-1.0004, -3.7386],
        [-1.7100, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38475117087364197
Epoch 0, Step 697: train/loss = 0.511522114276886, train/raw-loss = 0.4794536232948303, train/logprobs = tensor([[-0.8927, -2.9948],
        [-1.0881, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3206847310066223
Epoch 0, Step 698: train/loss = 0.3331763744354248, train/raw-loss = 0.3000730276107788, train/logprobs = tensor([[-0.9022, -3.3104],
        [-1.4143, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310333788394928
Epoch 0, Step 699: train/loss = 0.681387186050415, train/raw-loss = 0.6487823128700256, train/logprobs = tensor([[-1.0546, -2.2926],
        [-0.9816, -1.1758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32604897022247314
Epoch 0, Step 700: train/loss = 0.3945268988609314, train/raw-loss = 0.3601715564727783, train/logprobs = tensor([[-1.2815, -3.1537],
        [-1.7135, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3435533940792084
Epoch 0, Step 701: train/loss = 0.6233749389648438, train/raw-loss = 0.5812221169471741, train/logprobs = tensor([[-1.6749, -3.0595],
        [-1.6054, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42152872681617737
Epoch 0, Step 702: train/loss = 0.41924989223480225, train/raw-loss = 0.39119482040405273, train/logprobs = tensor([[-0.6886, -3.2166],
        [-0.9881, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805503010749817
Epoch 0, Step 703: train/loss = 0.41238686442375183, train/raw-loss = 0.37404993176460266, train/logprobs = tensor([[-1.5396, -3.8811],
        [-1.6082, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3833693265914917
Epoch 0, Step 704: train/loss = 0.5480608344078064, train/raw-loss = 0.5128231048583984, train/logprobs = tensor([[-1.3284, -6.0473],
        [-1.5759, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523768186569214
Epoch 0, Step 705: train/loss = 0.2650398910045624, train/raw-loss = 0.22256338596343994, train/logprobs = tensor([[-1.3145, -5.7377],
        [-2.2396, -2.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247652590274811
Epoch 0, Step 706: train/loss = 0.7205023169517517, train/raw-loss = 0.6880970001220703, train/logprobs = tensor([[-2.4804, -4.2280],
        [-1.3578, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240531086921692
Epoch 0, Step 707: train/loss = 0.20837530493736267, train/raw-loss = 0.1767345666885376, train/logprobs = tensor([[-0.8075, -6.7664],
        [-1.6449, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164072632789612
Epoch 0, Step 708: train/loss = 0.5362945199012756, train/raw-loss = 0.5005335807800293, train/logprobs = tensor([[-1.0544, -3.3423],
        [-1.2062, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35760951042175293
Epoch 0, Step 709: train/loss = 0.38399988412857056, train/raw-loss = 0.34621477127075195, train/logprobs = tensor([[-1.1626, -5.2407],
        [-1.6857, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37785136699676514
Epoch 0, Step 710: train/loss = 0.45209383964538574, train/raw-loss = 0.4243805706501007, train/logprobs = tensor([[-0.6927, -4.1959],
        [-0.9875, -0.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2771328389644623
Epoch 0, Step 711: train/loss = 0.5410555005073547, train/raw-loss = 0.5076396465301514, train/logprobs = tensor([[-0.7066, -2.7023],
        [-1.0071, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341584801673889
Epoch 0, Step 712: train/loss = 0.46499961614608765, train/raw-loss = 0.4349345862865448, train/logprobs = tensor([[-1.5456, -4.1289],
        [-1.4502, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3006502091884613
Epoch 0, Step 713: train/loss = 0.4822642207145691, train/raw-loss = 0.45388346910476685, train/logprobs = tensor([[-0.6559, -3.4774],
        [-0.8028, -1.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838081121444702
Epoch 0, Step 714: train/loss = 0.5470461249351501, train/raw-loss = 0.5122499465942383, train/logprobs = tensor([[-1.2388, -2.3019],
        [-1.6729, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479614853858948
Epoch 0, Step 715: train/loss = 0.3221401572227478, train/raw-loss = 0.2839113473892212, train/logprobs = tensor([[-1.2728, -4.1857],
        [-1.8751, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38228803873062134
Epoch 0, Step 716: train/loss = 0.4248875379562378, train/raw-loss = 0.3914695084095001, train/logprobs = tensor([[-0.8884, -2.6725],
        [-1.5750, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341800570487976
Epoch 0, Step 717: train/loss = 0.33977210521698, train/raw-loss = 0.30644339323043823, train/logprobs = tensor([[-1.2024, -4.3372],
        [-1.8324, -0.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332870304584503
Epoch 0, Step 718: train/loss = 0.46335071325302124, train/raw-loss = 0.4317174553871155, train/logprobs = tensor([[-0.6869, -2.9217],
        [-1.1197, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31633302569389343
Epoch 0, Step 719: train/loss = 0.4537592828273773, train/raw-loss = 0.416215181350708, train/logprobs = tensor([[-1.3688, -3.2574],
        [-2.1779, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754414916038513
Epoch 0, Step 720: train/loss = 0.35711294412612915, train/raw-loss = 0.3225659728050232, train/logprobs = tensor([[-0.9032, -6.5765],
        [-1.2662, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34546971321105957
Epoch 0, Step 721: train/loss = 0.733167290687561, train/raw-loss = 0.6988667249679565, train/logprobs = tensor([[-2.1336, -5.0488],
        [-1.5543, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430056571960449
Epoch 0, Step 722: train/loss = 0.7661851048469543, train/raw-loss = 0.7264593243598938, train/logprobs = tensor([[-2.6198, -4.0542],
        [-1.9724, -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972577154636383
Epoch 0, Step 723: train/loss = 0.2925502359867096, train/raw-loss = 0.2563896179199219, train/logprobs = tensor([[-1.0638, -4.7214],
        [-1.3658, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3616061210632324
Epoch 0, Step 724: train/loss = 0.7245767712593079, train/raw-loss = 0.6953749060630798, train/logprobs = tensor([[-1.7716, -2.3262],
        [-1.5209, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920186519622803
Epoch 0, Step 725: train/loss = 0.4488014578819275, train/raw-loss = 0.4106314778327942, train/logprobs = tensor([[-1.1826, -2.6092],
        [-2.2841, -1.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38169991970062256
Epoch 0, Step 726: train/loss = 0.4052260220050812, train/raw-loss = 0.3732272684574127, train/logprobs = tensor([[-0.8890, -4.6294],
        [-1.2731, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31998777389526367
Epoch 0, Step 727: train/loss = 0.4947352409362793, train/raw-loss = 0.45899033546447754, train/logprobs = tensor([[-1.0731, -4.4959],
        [-1.6318, -1.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35744932293891907
Epoch 0, Step 728: train/loss = 0.5862988233566284, train/raw-loss = 0.5511300563812256, train/logprobs = tensor([[-1.4648, -7.1512],
        [-1.3298, -1.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35168707370758057
Epoch 0, Step 729: train/loss = 0.5156236886978149, train/raw-loss = 0.4801511764526367, train/logprobs = tensor([[-1.3622, -2.8689],
        [-1.8027, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547249436378479
Epoch 0, Step 730: train/loss = 0.4493049085140228, train/raw-loss = 0.41798484325408936, train/logprobs = tensor([[-1.6610, -6.1020],
        [-1.6878, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132003843784332
Epoch 0, Step 731: train/loss = 0.37873411178588867, train/raw-loss = 0.3407897353172302, train/logprobs = tensor([[-1.1935, -6.9068],
        [-1.8851, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.379443883895874
Epoch 0, Step 732: train/loss = 0.29304784536361694, train/raw-loss = 0.26144492626190186, train/logprobs = tensor([[-0.9103, -6.9892],
        [-1.3558, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31602901220321655
Epoch 0, Step 733: train/loss = 0.5581766366958618, train/raw-loss = 0.5207817554473877, train/logprobs = tensor([[-1.6720, -2.7298],
        [-1.4839, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.373948872089386
Epoch 0, Step 734: train/loss = 0.5267935991287231, train/raw-loss = 0.4973645806312561, train/logprobs = tensor([[-0.9361, -3.3856],
        [-1.2541, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942904829978943
Epoch 0, Step 735: train/loss = 0.6175094842910767, train/raw-loss = 0.5871769189834595, train/logprobs = tensor([[-0.7232, -1.0596],
        [-0.8848, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033251166343689
Epoch 0, Step 736: train/loss = 0.5605415105819702, train/raw-loss = 0.5215629935264587, train/logprobs = tensor([[-1.4502, -3.8021],
        [-1.7941, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.389785498380661
Epoch 0, Step 737: train/loss = 0.5138209462165833, train/raw-loss = 0.4749089181423187, train/logprobs = tensor([[-1.7570, -2.9941],
        [-2.0423, -1.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38912007212638855
Epoch 0, Step 738: train/loss = 0.5502767562866211, train/raw-loss = 0.5173925757408142, train/logprobs = tensor([[-0.7203, -2.9907],
        [-1.5422, -1.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288416862487793
Epoch 0, Step 739: train/loss = 0.3528984785079956, train/raw-loss = 0.3133561909198761, train/logprobs = tensor([[-1.3157, -5.0972],
        [-1.8724, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3954227566719055
Epoch 0, Step 740: train/loss = 0.6382023096084595, train/raw-loss = 0.6078734993934631, train/logprobs = tensor([[-2.3384, -7.2970],
        [-1.1812, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30328741669654846
Epoch 0, Step 741: train/loss = 0.24754691123962402, train/raw-loss = 0.21178294718265533, train/logprobs = tensor([[-0.9358, -5.6577],
        [-1.6842, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35763975977897644
Epoch 0, Step 742: train/loss = 0.42083853483200073, train/raw-loss = 0.39051923155784607, train/logprobs = tensor([[-0.8646, -4.6779],
        [-1.2328, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031931221485138
Epoch 0, Step 743: train/loss = 0.45546168088912964, train/raw-loss = 0.42115622758865356, train/logprobs = tensor([[-1.1535, -4.2831],
        [-1.1025, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430543839931488
Epoch 0, Step 744: train/loss = 0.529676616191864, train/raw-loss = 0.4888266921043396, train/logprobs = tensor([[-2.7094, -7.1272],
        [-2.1041, -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40849927067756653
Epoch 0, Step 745: train/loss = 0.34490767121315, train/raw-loss = 0.308958500623703, train/logprobs = tensor([[-0.7722, -4.3357],
        [-2.1071, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3594916760921478
Epoch 0, Step 746: train/loss = 0.26652228832244873, train/raw-loss = 0.23457160592079163, train/logprobs = tensor([[-1.0986, -6.7337],
        [-1.4464, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31950661540031433
Epoch 0, Step 747: train/loss = 0.4790263772010803, train/raw-loss = 0.44643545150756836, train/logprobs = tensor([[-1.1051, -3.0420],
        [-1.6736, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32590973377227783
Epoch 0, Step 748: train/loss = 0.2384873628616333, train/raw-loss = 0.19371649622917175, train/logprobs = tensor([[-1.7856, -8.8324],
        [-3.0792, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44770878553390503
Epoch 0, Step 749: train/loss = 0.40089452266693115, train/raw-loss = 0.36609524488449097, train/logprobs = tensor([[-0.8594, -5.1308],
        [-1.7141, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479926288127899
Epoch 0, Step 750: train/loss = 0.3176109194755554, train/raw-loss = 0.28291141986846924, train/logprobs = tensor([[-0.9119, -7.2772],
        [-1.7684, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.346995085477829
Epoch 0, Step 751: train/loss = 0.18773901462554932, train/raw-loss = 0.15288466215133667, train/logprobs = tensor([[-0.7630, -6.8800],
        [-1.9355, -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34854355454444885
Epoch 0, Step 752: train/loss = 0.6050218343734741, train/raw-loss = 0.5673537254333496, train/logprobs = tensor([[-1.4377, -2.1332],
        [-1.2400, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3766815960407257
Epoch 0, Step 753: train/loss = 0.48734137415885925, train/raw-loss = 0.447279691696167, train/logprobs = tensor([[-1.0550, -2.5698],
        [-1.9643, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4006171226501465
Epoch 0, Step 754: train/loss = 0.5186999440193176, train/raw-loss = 0.4823228120803833, train/logprobs = tensor([[-0.9262, -2.8897],
        [-1.7548, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36377212405204773
Epoch 0, Step 755: train/loss = 0.5411403179168701, train/raw-loss = 0.5017384886741638, train/logprobs = tensor([[-1.8321, -6.8438],
        [-1.9921, -1.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3940177261829376
Epoch 0, Step 756: train/loss = 0.4944238066673279, train/raw-loss = 0.45535504817962646, train/logprobs = tensor([[-1.4740, -3.8796],
        [-1.6099, -1.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3906877040863037
Epoch 0, Step 757: train/loss = 0.3409191370010376, train/raw-loss = 0.29988592863082886, train/logprobs = tensor([[-1.2239, -3.8962],
        [-2.0501, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.410332053899765
Epoch 0, Step 758: train/loss = 0.3809385895729065, train/raw-loss = 0.35172930359840393, train/logprobs = tensor([[-0.7295, -7.5040],
        [-0.8536, -1.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292092889547348
Epoch 0, Step 759: train/loss = 0.3811267614364624, train/raw-loss = 0.3452281355857849, train/logprobs = tensor([[-0.8846, -2.7016],
        [-2.1655, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35898640751838684
Epoch 0, Step 760: train/loss = 0.26475024223327637, train/raw-loss = 0.22580328583717346, train/logprobs = tensor([[-1.0222, -4.4249],
        [-2.2689, -1.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894695043563843
Epoch 0, Step 761: train/loss = 0.6610531806945801, train/raw-loss = 0.6237919926643372, train/logprobs = tensor([[-1.0960, -1.7470],
        [-1.4339, -1.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37261173129081726
Epoch 0, Step 762: train/loss = 0.3854653537273407, train/raw-loss = 0.3566906750202179, train/logprobs = tensor([[-0.8759, -2.6829],
        [-1.6887, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877466082572937
Epoch 0, Step 763: train/loss = 0.6015653014183044, train/raw-loss = 0.5659001469612122, train/logprobs = tensor([[-0.7727, -1.3468],
        [-1.2141, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3566516935825348
Epoch 0, Step 764: train/loss = 0.47099900245666504, train/raw-loss = 0.43982675671577454, train/logprobs = tensor([[-1.3644, -2.7865],
        [-1.7538, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117225468158722
Epoch 0, Step 765: train/loss = 0.5540107488632202, train/raw-loss = 0.517346978187561, train/logprobs = tensor([[-1.3686, -2.4114],
        [-1.3987, -1.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36663752794265747
Epoch 0, Step 766: train/loss = 0.401563435792923, train/raw-loss = 0.36203083395957947, train/logprobs = tensor([[-1.1197, -6.7485],
        [-1.5530, -1.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39532575011253357
Epoch 0, Step 767: train/loss = 0.30374768376350403, train/raw-loss = 0.2708699703216553, train/logprobs = tensor([[-1.0679, -7.3938],
        [-1.8537, -2.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287769556045532
Epoch 0, Step 768: train/loss = 0.49748891592025757, train/raw-loss = 0.4541105329990387, train/logprobs = tensor([[-1.6213, -2.6026],
        [-1.9065, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337836503982544
Epoch 0, Step 769: train/loss = 0.2740728259086609, train/raw-loss = 0.23446695506572723, train/logprobs = tensor([[-1.3488, -5.2061],
        [-2.3607, -1.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39605867862701416
Epoch 0, Step 770: train/loss = 0.5617900490760803, train/raw-loss = 0.5262641310691833, train/logprobs = tensor([[-0.8186, -2.0929],
        [-1.4840, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3552595376968384
Epoch 0, Step 771: train/loss = 0.3322386145591736, train/raw-loss = 0.3011968731880188, train/logprobs = tensor([[-0.9684, -3.6562],
        [-1.6388, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3104172646999359
Epoch 0, Step 772: train/loss = 0.5152856111526489, train/raw-loss = 0.47289156913757324, train/logprobs = tensor([[-1.2688, -1.6360],
        [-2.3479, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4239407479763031
Epoch 0, Step 773: train/loss = 0.35120463371276855, train/raw-loss = 0.31389161944389343, train/logprobs = tensor([[-1.1585, -4.9072],
        [-2.0714, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37313002347946167
Epoch 0, Step 774: train/loss = 0.4092969298362732, train/raw-loss = 0.37262630462646484, train/logprobs = tensor([[-0.8081, -5.5141],
        [-1.4885, -2.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3667058050632477
Epoch 0, Step 775: train/loss = 0.5671526789665222, train/raw-loss = 0.5197376608848572, train/logprobs = tensor([[-0.9794, -2.0293],
        [-2.1251, -1.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4741508960723877
Epoch 0, Step 776: train/loss = 0.6548172831535339, train/raw-loss = 0.6266389489173889, train/logprobs = tensor([[-0.6290, -1.5329],
        [-1.3670, -1.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817823588848114
Epoch 0, Step 777: train/loss = 0.4419417381286621, train/raw-loss = 0.4002169668674469, train/logprobs = tensor([[-1.3591, -2.4985],
        [-2.1833, -1.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41724735498428345
Epoch 0, Step 778: train/loss = 0.264450341463089, train/raw-loss = 0.22734567523002625, train/logprobs = tensor([[-1.1014, -6.6858],
        [-2.9192, -1.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3710465729236603
Epoch 0, Step 779: train/loss = 0.6754865646362305, train/raw-loss = 0.644684374332428, train/logprobs = tensor([[-0.6763, -0.8056],
        [-0.9497, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308021605014801
Epoch 0, Step 780: train/loss = 0.4943007826805115, train/raw-loss = 0.46724915504455566, train/logprobs = tensor([[-0.8218, -2.2558],
        [-0.9556, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705160975456238
Epoch 0, Step 781: train/loss = 0.5174753665924072, train/raw-loss = 0.4835265874862671, train/logprobs = tensor([[-1.2817, -5.7960],
        [-1.4997, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3394884765148163
Epoch 0, Step 782: train/loss = 0.3974069356918335, train/raw-loss = 0.35375913977622986, train/logprobs = tensor([[-1.7792, -7.9834],
        [-2.6555, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4364778399467468
Epoch 0, Step 783: train/loss = 0.35536906123161316, train/raw-loss = 0.3207619786262512, train/logprobs = tensor([[-0.8152, -4.4849],
        [-1.9261, -1.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34607064723968506
Epoch 0, Step 784: train/loss = 0.5093398690223694, train/raw-loss = 0.4758162498474121, train/logprobs = tensor([[-1.4805, -2.3232],
        [-1.7430, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33523643016815186
Epoch 0, Step 785: train/loss = 0.3133350908756256, train/raw-loss = 0.2754862904548645, train/logprobs = tensor([[-0.9429, -5.3198],
        [-1.7546, -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784885108470917
Epoch 0, Step 786: train/loss = 1.6041845083236694, train/raw-loss = 1.5669410228729248, train/logprobs = tensor([[-4.2398, -5.2479],
        [-2.0377, -1.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37243467569351196
Epoch 0, Step 787: train/loss = 0.4448546767234802, train/raw-loss = 0.40810626745224, train/logprobs = tensor([[-1.5408, -5.5055],
        [-1.6485, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.367483913898468
Epoch 0, Step 788: train/loss = 0.4773274064064026, train/raw-loss = 0.43843138217926025, train/logprobs = tensor([[-0.9059, -2.1765],
        [-2.3021, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3889603018760681
Epoch 0, Step 789: train/loss = 0.7915821671485901, train/raw-loss = 0.7558719515800476, train/logprobs = tensor([[-3.2433, -5.7245],
        [-1.9557, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3571012616157532
Epoch 0, Step 790: train/loss = 0.7228372693061829, train/raw-loss = 0.6857991814613342, train/logprobs = tensor([[-2.2149, -4.5824],
        [-1.4033, -0.8486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37038084864616394
Epoch 0, Step 791: train/loss = 0.364271342754364, train/raw-loss = 0.3271324634552002, train/logprobs = tensor([[-1.2124, -4.0744],
        [-2.1824, -1.6311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37138864398002625
Epoch 0, Step 792: train/loss = 1.330456018447876, train/raw-loss = 1.2966402769088745, train/logprobs = tensor([[-4.8471, -6.8584],
        [-2.0240, -1.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381568193435669
Epoch 0, Step 793: train/loss = 0.663874089717865, train/raw-loss = 0.6284872889518738, train/logprobs = tensor([[-2.4502, -3.0623],
        [-1.6309, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35386818647384644
Epoch 0, Step 794: train/loss = 0.2838740944862366, train/raw-loss = 0.24929934740066528, train/logprobs = tensor([[-0.6119, -4.3188],
        [-1.6606, -2.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.345747172832489
Epoch 0, Step 795: train/loss = 0.36858415603637695, train/raw-loss = 0.3283748924732208, train/logprobs = tensor([[-1.4413, -4.6426],
        [-2.0219, -1.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4020928740501404
Epoch 0, Step 796: train/loss = 0.2360677719116211, train/raw-loss = 0.19257153570652008, train/logprobs = tensor([[-1.2902, -5.2291],
        [-2.8762, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43496233224868774
Epoch 0, Step 797: train/loss = 0.6836287975311279, train/raw-loss = 0.6501185297966003, train/logprobs = tensor([[-1.0473, -1.5465],
        [-1.5210, -1.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351024091243744
Epoch 0, Step 798: train/loss = 0.371573269367218, train/raw-loss = 0.3314279317855835, train/logprobs = tensor([[-1.0930, -5.3316],
        [-1.9845, -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40145304799079895
Epoch 0, Step 799: train/loss = 0.42783015966415405, train/raw-loss = 0.39279651641845703, train/logprobs = tensor([[-0.9178, -4.3143],
        [-1.7027, -0.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350336492061615
Epoch 0, Step 800: train/loss = 0.4453986883163452, train/raw-loss = 0.4115726053714752, train/logprobs = tensor([[-1.1577, -5.8102],
        [-1.3557, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382607400417328
Epoch 0, Step 801: train/loss = 0.4246020019054413, train/raw-loss = 0.3894907236099243, train/logprobs = tensor([[-0.6724, -4.4801],
        [-1.9337, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3511126935482025
Epoch 0, Step 802: train/loss = 0.5756598711013794, train/raw-loss = 0.5456799268722534, train/logprobs = tensor([[-0.6940, -1.1905],
        [-1.5828, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2997998595237732
Epoch 0, Step 803: train/loss = 0.7962253093719482, train/raw-loss = 0.7625564336776733, train/logprobs = tensor([[-1.8524, -3.5333],
        [-0.8513, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33668866753578186
Epoch 0, Step 804: train/loss = 0.4883255660533905, train/raw-loss = 0.44604364037513733, train/logprobs = tensor([[-1.0282, -1.9644],
        [-2.2524, -1.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42281901836395264
Epoch 0, Step 805: train/loss = 0.47938477993011475, train/raw-loss = 0.43825626373291016, train/logprobs = tensor([[-0.9503, -2.0752],
        [-2.0916, -1.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112849533557892
Epoch 0, Step 806: train/loss = 0.41826295852661133, train/raw-loss = 0.38607388734817505, train/logprobs = tensor([[-0.7770, -2.4412],
        [-1.8466, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32189083099365234
Epoch 0, Step 807: train/loss = 0.548999011516571, train/raw-loss = 0.5172484517097473, train/logprobs = tensor([[-0.7907, -2.2893],
        [-1.3554, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175051808357239
Epoch 0, Step 808: train/loss = 0.2914416193962097, train/raw-loss = 0.2499331533908844, train/logprobs = tensor([[-1.1601, -4.4239],
        [-2.8357, -2.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4150847792625427
Epoch 0, Step 809: train/loss = 0.6514788866043091, train/raw-loss = 0.6195107698440552, train/logprobs = tensor([[-1.2263, -1.6683],
        [-1.0915, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31968122720718384
Epoch 0, Step 810: train/loss = 0.2280661165714264, train/raw-loss = 0.18946537375450134, train/logprobs = tensor([[-0.6511, -5.4363],
        [-2.6160, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3860073685646057
Epoch 0, Step 811: train/loss = 0.6501073837280273, train/raw-loss = 0.609978973865509, train/logprobs = tensor([[-1.0610, -1.2203],
        [-2.4120, -1.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.401284396648407
Epoch 0, Step 812: train/loss = 0.4364337921142578, train/raw-loss = 0.39890816807746887, train/logprobs = tensor([[-1.5750, -5.3133],
        [-1.7848, -1.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37525612115859985
Epoch 0, Step 813: train/loss = 0.2025209367275238, train/raw-loss = 0.16090449690818787, train/logprobs = tensor([[-1.4181, -9.7469],
        [-2.5383, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4161643385887146
Epoch 0, Step 814: train/loss = 0.49560725688934326, train/raw-loss = 0.4506828784942627, train/logprobs = tensor([[-1.4232, -5.2524],
        [-3.2041, -1.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44924402236938477
Epoch 0, Step 815: train/loss = 0.5948489308357239, train/raw-loss = 0.554322361946106, train/logprobs = tensor([[-0.7618, -1.4989],
        [-1.8310, -1.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4052654504776001
Epoch 0, Step 816: train/loss = 0.782632052898407, train/raw-loss = 0.7415766716003418, train/logprobs = tensor([[-2.7544, -5.5268],
        [-1.7924, -1.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105534255504608
Epoch 0, Step 817: train/loss = 0.47327467799186707, train/raw-loss = 0.434256911277771, train/logprobs = tensor([[-0.9896, -2.4484],
        [-1.7180, -1.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39017778635025024
Epoch 0, Step 818: train/loss = 0.37189847230911255, train/raw-loss = 0.33289211988449097, train/logprobs = tensor([[-1.0955, -4.2823],
        [-2.4090, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3900635838508606
Epoch 0, Step 819: train/loss = 0.40025758743286133, train/raw-loss = 0.36813870072364807, train/logprobs = tensor([[-1.1248, -3.7668],
        [-1.9623, -2.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32118892669677734
Epoch 0, Step 820: train/loss = 0.6074899435043335, train/raw-loss = 0.5683112740516663, train/logprobs = tensor([[-1.5106, -4.1739],
        [-1.9524, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917872905731201
Epoch 0, Step 821: train/loss = 0.9595246911048889, train/raw-loss = 0.9227433800697327, train/logprobs = tensor([[-2.5391, -2.3629],
        [-2.0626, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36781373620033264
Epoch 0, Step 822: train/loss = 0.823786735534668, train/raw-loss = 0.7881994843482971, train/logprobs = tensor([[-1.3183, -1.2722],
        [-1.3822, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3558729290962219
Epoch 0, Step 823: train/loss = 0.3234800100326538, train/raw-loss = 0.2929326891899109, train/logprobs = tensor([[-0.4912, -4.0820],
        [-1.6317, -1.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054729104042053
Epoch 0, Step 824: train/loss = 0.3793962597846985, train/raw-loss = 0.33713680505752563, train/logprobs = tensor([[-1.1368, -3.0150],
        [-2.1129, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4225943684577942
Epoch 0, Step 825: train/loss = 0.48390159010887146, train/raw-loss = 0.4433625340461731, train/logprobs = tensor([[-0.9981, -1.9536],
        [-1.8868, -1.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4053904414176941
Epoch 0, Step 826: train/loss = 0.5633237957954407, train/raw-loss = 0.5315320491790771, train/logprobs = tensor([[-0.7030, -3.9416],
        [-1.9320, -2.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179183900356293
Epoch 0, Step 827: train/loss = 0.49786296486854553, train/raw-loss = 0.4567590355873108, train/logprobs = tensor([[-0.7836, -3.9293],
        [-2.0680, -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4110392928123474
Epoch 0, Step 828: train/loss = 0.6645463705062866, train/raw-loss = 0.632239580154419, train/logprobs = tensor([[-1.3388, -3.0099],
        [-0.7847, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323068231344223
Epoch 0, Step 829: train/loss = 0.27351129055023193, train/raw-loss = 0.23525747656822205, train/logprobs = tensor([[-1.3501, -9.0324],
        [-2.9683, -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38253816962242126
Epoch 0, Step 830: train/loss = 0.5059323906898499, train/raw-loss = 0.4646375775337219, train/logprobs = tensor([[-1.1047, -6.6486],
        [-2.0889, -2.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4129484295845032
Epoch 0, Step 831: train/loss = 0.3119123578071594, train/raw-loss = 0.27479124069213867, train/logprobs = tensor([[-0.7899, -3.6792],
        [-2.0173, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37121137976646423
Epoch 0, Step 832: train/loss = 0.553710401058197, train/raw-loss = 0.5142436623573303, train/logprobs = tensor([[-0.9264, -5.2001],
        [-2.8169, -1.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946678936481476
Epoch 0, Step 833: train/loss = 0.6005112528800964, train/raw-loss = 0.5614812970161438, train/logprobs = tensor([[-0.9905, -2.7257],
        [-2.0899, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39029937982559204
Epoch 0, Step 834: train/loss = 0.7359801530838013, train/raw-loss = 0.6951506733894348, train/logprobs = tensor([[-3.1080, -8.2687],
        [-2.3863, -0.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4082948565483093
Epoch 0, Step 835: train/loss = 0.2661309540271759, train/raw-loss = 0.22543957829475403, train/logprobs = tensor([[-2.0714, -7.9846],
        [-2.7352, -1.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069139063358307
Epoch 0, Step 836: train/loss = 0.4224667251110077, train/raw-loss = 0.38748249411582947, train/logprobs = tensor([[-1.1360, -5.3456],
        [-2.3377, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34984225034713745
Epoch 0, Step 837: train/loss = 0.439936101436615, train/raw-loss = 0.40024814009666443, train/logprobs = tensor([[-1.3933, -4.0770],
        [-2.7020, -2.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3968791961669922
Epoch 0, Step 838: train/loss = 0.10200231522321701, train/raw-loss = 0.05270963907241821, train/logprobs = tensor([[-1.1678, -8.8438],
        [-3.7113, -2.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4929266571998596
Epoch 0, Step 839: train/loss = 0.6389440298080444, train/raw-loss = 0.603135883808136, train/logprobs = tensor([[-2.5158, -4.9753],
        [-2.5336, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580819070339203
Epoch 0, Step 840: train/loss = 0.3445644974708557, train/raw-loss = 0.3030455708503723, train/logprobs = tensor([[-1.7652, -4.8725],
        [-3.1052, -1.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41518929600715637
Epoch 0, Step 841: train/loss = 0.30683332681655884, train/raw-loss = 0.26589056849479675, train/logprobs = tensor([[-0.8103, -4.7674],
        [-2.1585, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40942782163619995
Epoch 0, Step 842: train/loss = 0.7381693124771118, train/raw-loss = 0.6974407434463501, train/logprobs = tensor([[-0.8032, -2.8503],
        [-2.2503, -2.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40728622674942017
Epoch 0, Step 843: train/loss = 0.2091478556394577, train/raw-loss = 0.17029716074466705, train/logprobs = tensor([[-1.0763, -5.7221],
        [-2.9946, -1.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885069489479065
Epoch 0, Step 844: train/loss = 0.42982232570648193, train/raw-loss = 0.39040449261665344, train/logprobs = tensor([[-0.7871, -3.1832],
        [-2.2848, -1.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39417821168899536
Epoch 0, Step 845: train/loss = 0.4802801012992859, train/raw-loss = 0.4360957145690918, train/logprobs = tensor([[-0.6745, -5.3854],
        [-2.5914, -1.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44184401631355286
Epoch 0, Step 846: train/loss = 0.19169113039970398, train/raw-loss = 0.14639145135879517, train/logprobs = tensor([[-1.5726, -7.0928],
        [-3.4235, -2.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45299679040908813
Epoch 0, Step 847: train/loss = 0.6022428870201111, train/raw-loss = 0.5600864887237549, train/logprobs = tensor([[-1.1771, -4.5553],
        [-1.8059, -3.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215635061264038
Epoch 0, Step 848: train/loss = 0.6762043833732605, train/raw-loss = 0.6301369667053223, train/logprobs = tensor([[-0.8621, -3.0860],
        [-2.7747, -2.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.460673987865448
Epoch 0, Step 849: train/loss = 0.44794169068336487, train/raw-loss = 0.40731680393218994, train/logprobs = tensor([[-0.9184, -3.3820],
        [-2.7570, -1.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4062487483024597
Epoch 0, Step 850: train/loss = 0.27411749958992004, train/raw-loss = 0.23895971477031708, train/logprobs = tensor([[-0.6451, -3.2800],
        [-2.3020, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3515777587890625
Epoch 0, Step 851: train/loss = 0.32622718811035156, train/raw-loss = 0.2881535291671753, train/logprobs = tensor([[-0.9354, -5.7365],
        [-2.0184, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807365894317627
Epoch 0, Step 852: train/loss = 0.3806320130825043, train/raw-loss = 0.3334425091743469, train/logprobs = tensor([[-1.2329, -5.5826],
        [-3.1282, -1.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47189491987228394
Epoch 0, Step 853: train/loss = 0.32236620783805847, train/raw-loss = 0.27868932485580444, train/logprobs = tensor([[-1.1720, -4.3371],
        [-2.5910, -1.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4367688000202179
Epoch 0, Step 854: train/loss = 0.31046944856643677, train/raw-loss = 0.2743987441062927, train/logprobs = tensor([[-0.6007, -5.5524],
        [-2.2219, -1.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36070695519447327
Epoch 0, Step 855: train/loss = 0.4104602336883545, train/raw-loss = 0.3731478452682495, train/logprobs = tensor([[-1.2856, -5.0541],
        [-2.2039, -1.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731237053871155
Epoch 0, Step 856: train/loss = 0.36495867371559143, train/raw-loss = 0.3200370967388153, train/logprobs = tensor([[-2.4768, -6.4881],
        [-3.7171, -2.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4492156505584717
Epoch 0, Step 857: train/loss = 0.6089577674865723, train/raw-loss = 0.5714083313941956, train/logprobs = tensor([[-1.8924, -3.0300],
        [-1.9891, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754943013191223
Epoch 0, Step 858: train/loss = 0.3191409409046173, train/raw-loss = 0.2760027348995209, train/logprobs = tensor([[-1.4552, -5.5402],
        [-2.7917, -2.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43138208985328674
Epoch 0, Step 859: train/loss = 0.32184475660324097, train/raw-loss = 0.28422489762306213, train/logprobs = tensor([[-1.1918, -7.1901],
        [-2.4133, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37619873881340027
Epoch 0, Step 860: train/loss = 0.7369469404220581, train/raw-loss = 0.686144232749939, train/logprobs = tensor([[-0.8170, -2.6810],
        [-2.7656, -2.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5080264806747437
Epoch 0, Step 861: train/loss = 0.36315497756004333, train/raw-loss = 0.31792736053466797, train/logprobs = tensor([[-1.9243, -4.6768],
        [-3.0708, -2.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522763788700104
Epoch 0, Step 862: train/loss = 0.39176541566848755, train/raw-loss = 0.34875571727752686, train/logprobs = tensor([[-1.2072, -6.6186],
        [-2.4952, -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4300967752933502
Epoch 0, Step 863: train/loss = 0.3247987627983093, train/raw-loss = 0.28102582693099976, train/logprobs = tensor([[-1.1776, -3.6528],
        [-2.9338, -2.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4377293884754181
Epoch 0, Step 864: train/loss = 0.7753061056137085, train/raw-loss = 0.7282124757766724, train/logprobs = tensor([[-0.8939, -1.1590],
        [-3.5699, -2.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47093603014945984
Epoch 0, Step 865: train/loss = 0.28742730617523193, train/raw-loss = 0.2536390721797943, train/logprobs = tensor([[-0.8161, -4.8725],
        [-2.2635, -1.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378826379776001
Epoch 0, Step 866: train/loss = 0.09082403779029846, train/raw-loss = 0.04063290357589722, train/logprobs = tensor([[-1.0951, -7.2401],
        [-4.2105, -1.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5019114017486572
Epoch 0, Step 867: train/loss = 0.631014347076416, train/raw-loss = 0.5924805998802185, train/logprobs = tensor([[-0.4808, -3.1989],
        [-1.6085, -1.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3853375315666199
Epoch 0, Step 868: train/loss = 0.5482064485549927, train/raw-loss = 0.5120567083358765, train/logprobs = tensor([[-1.4251, -3.0896],
        [-3.1545, -2.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36149701476097107
Epoch 0, Step 869: train/loss = 0.28654056787490845, train/raw-loss = 0.24817915260791779, train/logprobs = tensor([[-1.3047, -4.6128],
        [-2.6120, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836140036582947
Epoch 0, Step 870: train/loss = 0.12944823503494263, train/raw-loss = 0.07760089635848999, train/logprobs = tensor([[ -1.9223, -10.4184],
        [ -4.7164,  -2.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5184734463691711
Epoch 0, Step 871: train/loss = 0.43822166323661804, train/raw-loss = 0.3981933295726776, train/logprobs = tensor([[-1.2455, -4.4822],
        [-2.2686, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.400283545255661
Epoch 0, Step 872: train/loss = 0.8969710469245911, train/raw-loss = 0.8570330739021301, train/logprobs = tensor([[-0.9586, -4.9889],
        [-2.0089, -3.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3993801772594452
Epoch 0, Step 873: train/loss = 0.5636058449745178, train/raw-loss = 0.5105031132698059, train/logprobs = tensor([[-2.0364, -4.4382],
        [-3.1162, -1.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5310274362564087
Epoch 0, Step 874: train/loss = 0.4793332517147064, train/raw-loss = 0.4361296594142914, train/logprobs = tensor([[-1.1894, -5.2579],
        [-3.2206, -1.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43203604221343994
Epoch 0, Step 875: train/loss = 0.5196360945701599, train/raw-loss = 0.4729336202144623, train/logprobs = tensor([[-1.5650, -3.8500],
        [-2.9400, -2.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4670243263244629
Epoch 0, Step 876: train/loss = 0.47258633375167847, train/raw-loss = 0.4184345602989197, train/logprobs = tensor([[-2.3682, -4.7678],
        [-3.9974, -3.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5415179133415222
Epoch 0, Step 877: train/loss = 0.17840710282325745, train/raw-loss = 0.13456714153289795, train/logprobs = tensor([[-1.4412, -6.5481],
        [-3.6329, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4383995532989502
Epoch 0, Step 878: train/loss = 0.2737104296684265, train/raw-loss = 0.2239474356174469, train/logprobs = tensor([[-1.4872, -7.5511],
        [-3.4160, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4976297616958618
Epoch 0, Step 879: train/loss = 0.3287453353404999, train/raw-loss = 0.2773306369781494, train/logprobs = tensor([[-2.1617, -3.2664],
        [-5.1665, -2.0802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141472816467285
Epoch 0, Step 880: train/loss = 0.4923906624317169, train/raw-loss = 0.44799065589904785, train/logprobs = tensor([[-1.6959, -3.2452],
        [-2.5437, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443999707698822
Epoch 0, Step 881: train/loss = 0.3759342133998871, train/raw-loss = 0.3309621214866638, train/logprobs = tensor([[-1.0931, -5.7230],
        [-3.7036, -2.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4497207999229431
Epoch 0, Step 882: train/loss = 0.44093334674835205, train/raw-loss = 0.404899924993515, train/logprobs = tensor([[-0.9361, -5.7337],
        [-2.9462, -2.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36033427715301514
Epoch 0, Step 883: train/loss = 0.6289353370666504, train/raw-loss = 0.582334041595459, train/logprobs = tensor([[-3.5468, -9.5682],
        [-3.8946, -1.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660130739212036
Epoch 0, Step 884: train/loss = 0.6738014817237854, train/raw-loss = 0.6299797892570496, train/logprobs = tensor([[-2.1782, -4.5692],
        [-2.6623, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4382169842720032
Epoch 0, Step 885: train/loss = 0.48985975980758667, train/raw-loss = 0.4558904767036438, train/logprobs = tensor([[-0.6472, -3.9584],
        [-1.9098, -2.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396929204463959
Epoch 0, Step 886: train/loss = 0.3610300123691559, train/raw-loss = 0.322625994682312, train/logprobs = tensor([[-1.0321, -3.8014],
        [-1.5460, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840402364730835
Epoch 0, Step 887: train/loss = 0.2823343276977539, train/raw-loss = 0.241587296128273, train/logprobs = tensor([[-1.3577, -7.1719],
        [-3.1503, -1.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4074704647064209
Epoch 0, Step 888: train/loss = 0.3574869632720947, train/raw-loss = 0.311053603887558, train/logprobs = tensor([[-1.2482, -5.6208],
        [-3.6113, -2.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46433356404304504
Epoch 0, Step 889: train/loss = 0.133154958486557, train/raw-loss = 0.09502235800027847, train/logprobs = tensor([[-0.9143, -9.5552],
        [-3.2111, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3813260793685913
Epoch 0, Step 890: train/loss = 0.33522316813468933, train/raw-loss = 0.294685035943985, train/logprobs = tensor([[-1.5586, -7.4649],
        [-2.8043, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40538108348846436
Epoch 0, Step 891: train/loss = 0.5232417583465576, train/raw-loss = 0.47618064284324646, train/logprobs = tensor([[-1.5782, -4.2867],
        [-3.3795, -2.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4706113636493683
Epoch 0, Step 892: train/loss = 0.13166524469852448, train/raw-loss = 0.09612935781478882, train/logprobs = tensor([[-0.9143, -6.4533],
        [-3.2166, -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35535886883735657
Epoch 0, Step 893: train/loss = 1.1369175910949707, train/raw-loss = 1.103527545928955, train/logprobs = tensor([[-2.0353, -4.9117],
        [-0.9061, -1.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339010179042816
Epoch 0, Step 894: train/loss = 0.4003801941871643, train/raw-loss = 0.35903745889663696, train/logprobs = tensor([[-1.4687, -3.8552],
        [-2.1664, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4134274125099182
Epoch 0, Step 895: train/loss = 0.7619994878768921, train/raw-loss = 0.7159028053283691, train/logprobs = tensor([[-1.6740, -5.6179],
        [-2.3698, -2.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4609665274620056
Epoch 0, Step 896: train/loss = 0.6046361327171326, train/raw-loss = 0.5573786497116089, train/logprobs = tensor([[-0.7242, -2.0946],
        [-2.4899, -2.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4725743532180786
Epoch 0, Step 897: train/loss = 0.2540469765663147, train/raw-loss = 0.2166443020105362, train/logprobs = tensor([[-0.9927, -5.3783],
        [-2.2169, -2.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3740266263484955
Epoch 0, Step 898: train/loss = 0.5823162794113159, train/raw-loss = 0.5426809787750244, train/logprobs = tensor([[-1.0459, -3.0020],
        [-2.0585, -2.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39635366201400757
Epoch 0, Step 899: train/loss = 0.5393028259277344, train/raw-loss = 0.4937242865562439, train/logprobs = tensor([[-1.4894, -3.5041],
        [-3.6443, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4557856619358063
Epoch 0, Step 900: train/loss = 0.46630722284317017, train/raw-loss = 0.42726442217826843, train/logprobs = tensor([[-2.3010, -4.8511],
        [-2.7057, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390428364276886
Epoch 0, Step 901: train/loss = 0.40199515223503113, train/raw-loss = 0.35510721802711487, train/logprobs = tensor([[-1.4219, -2.7876],
        [-3.4064, -2.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4688792824745178
Epoch 0, Step 902: train/loss = 0.3750098943710327, train/raw-loss = 0.329922616481781, train/logprobs = tensor([[-1.4906, -5.7424],
        [-3.0078, -1.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45087265968322754
Epoch 0, Step 903: train/loss = 0.27078068256378174, train/raw-loss = 0.22809158265590668, train/logprobs = tensor([[-1.5971, -7.9362],
        [-3.5243, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42689111828804016
Epoch 0, Step 904: train/loss = 0.5467017889022827, train/raw-loss = 0.5100813508033752, train/logprobs = tensor([[-1.0401, -2.1132],
        [-2.1970, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3662045896053314
Epoch 0, Step 905: train/loss = 0.3567044734954834, train/raw-loss = 0.31613394618034363, train/logprobs = tensor([[-2.0619, -4.0790],
        [-2.9042, -1.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4057050347328186
Epoch 0, Step 906: train/loss = 0.22474868595600128, train/raw-loss = 0.18218621611595154, train/logprobs = tensor([[-1.6626, -6.6489],
        [-3.7013, -1.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4256246089935303
Epoch 0, Step 907: train/loss = 0.8505033254623413, train/raw-loss = 0.8134857416152954, train/logprobs = tensor([[-1.1672, -1.3377],
        [-1.4744, -1.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701747953891754
Epoch 0, Step 908: train/loss = 0.5848389267921448, train/raw-loss = 0.5358152389526367, train/logprobs = tensor([[-1.1393, -2.4936],
        [-3.4776, -3.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49023643136024475
Epoch 0, Step 909: train/loss = 0.508273720741272, train/raw-loss = 0.46681660413742065, train/logprobs = tensor([[-1.2117, -3.5983],
        [-2.8661, -2.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41457146406173706
Epoch 0, Step 910: train/loss = 0.4032667875289917, train/raw-loss = 0.36897510290145874, train/logprobs = tensor([[-0.9215, -1.6617],
        [-2.7538, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429167866706848
Epoch 0, Step 911: train/loss = 0.2500077486038208, train/raw-loss = 0.207225501537323, train/logprobs = tensor([[-1.7501, -5.6972],
        [-3.1377, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42782244086265564
Epoch 0, Step 912: train/loss = 0.5114479660987854, train/raw-loss = 0.471081018447876, train/logprobs = tensor([[-1.2934, -2.3578],
        [-2.2380, -2.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036695957183838
Epoch 0, Step 913: train/loss = 0.5298379063606262, train/raw-loss = 0.4826586842536926, train/logprobs = tensor([[-1.3543, -3.0454],
        [-3.3593, -2.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47179216146469116
Epoch 0, Step 914: train/loss = 0.337535560131073, train/raw-loss = 0.29847878217697144, train/logprobs = tensor([[-1.4918, -3.6061],
        [-2.9131, -2.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390567809343338
Epoch 0, Step 915: train/loss = 0.6228132843971252, train/raw-loss = 0.5708362460136414, train/logprobs = tensor([[-1.2719, -4.2030],
        [-3.9497, -2.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5197705030441284
Epoch 0, Step 916: train/loss = 0.6090393662452698, train/raw-loss = 0.5665125250816345, train/logprobs = tensor([[-0.6116, -0.7856],
        [-1.8752, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4252689480781555
Epoch 0, Step 917: train/loss = 0.5953251123428345, train/raw-loss = 0.5553632974624634, train/logprobs = tensor([[-0.7175, -2.3299],
        [-1.4714, -1.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39961862564086914
Epoch 0, Step 918: train/loss = 0.6203733682632446, train/raw-loss = 0.5820642709732056, train/logprobs = tensor([[-0.8711, -4.7016],
        [-1.8980, -3.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830910921096802
Epoch 0, Step 919: train/loss = 0.26687371730804443, train/raw-loss = 0.2174571007490158, train/logprobs = tensor([[-1.2537, -7.8576],
        [-3.9440, -2.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4941663146018982
Epoch 0, Step 920: train/loss = 0.46513065695762634, train/raw-loss = 0.42427173256874084, train/logprobs = tensor([[-0.7777, -3.8933],
        [-2.4741, -3.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40858906507492065
Epoch 0, Step 921: train/loss = 0.2834838330745697, train/raw-loss = 0.24022871255874634, train/logprobs = tensor([[-1.1199, -7.4729],
        [-2.9871, -2.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4325510263442993
Epoch 0, Step 922: train/loss = 0.9037420153617859, train/raw-loss = 0.8716470003128052, train/logprobs = tensor([[-0.5077, -2.3951],
        [-0.9656, -1.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32095083594322205
Epoch 0, Step 923: train/loss = 0.5803484320640564, train/raw-loss = 0.5404444336891174, train/logprobs = tensor([[-1.2115, -2.6643],
        [-2.3498, -2.2015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990398347377777
Epoch 0, Step 924: train/loss = 0.7070380449295044, train/raw-loss = 0.6552846431732178, train/logprobs = tensor([[-3.2712, -3.8093],
        [-3.3146, -2.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5175338983535767
Epoch 0, Step 925: train/loss = 0.623866081237793, train/raw-loss = 0.5820402503013611, train/logprobs = tensor([[-1.0224, -2.2282],
        [-2.6524, -1.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41825875639915466
Epoch 0, Step 926: train/loss = 0.40274983644485474, train/raw-loss = 0.35404732823371887, train/logprobs = tensor([[-1.1939, -4.1548],
        [-3.1586, -2.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4870252013206482
Epoch 0, Step 927: train/loss = 0.37194764614105225, train/raw-loss = 0.3243024945259094, train/logprobs = tensor([[-1.4416, -3.4975],
        [-3.2330, -2.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4764511287212372
Epoch 0, Step 928: train/loss = 0.4122936725616455, train/raw-loss = 0.37556159496307373, train/logprobs = tensor([[-1.1633, -3.3233],
        [-2.4727, -1.0294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3673211634159088
Epoch 0, Step 929: train/loss = 0.15037691593170166, train/raw-loss = 0.09797734767198563, train/logprobs = tensor([[-0.8103, -6.0967],
        [-3.8674, -2.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523995578289032
Epoch 0, Step 930: train/loss = 0.4574301540851593, train/raw-loss = 0.4168790876865387, train/logprobs = tensor([[-1.2237, -3.0250],
        [-2.6178, -1.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4055105447769165
Epoch 0, Step 931: train/loss = 0.19851553440093994, train/raw-loss = 0.14853961765766144, train/logprobs = tensor([[-1.8186, -6.7353],
        [-4.1736, -1.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4997592568397522
Epoch 0, Step 932: train/loss = 0.1331002116203308, train/raw-loss = 0.0950215756893158, train/logprobs = tensor([[-0.8115, -8.0846],
        [-2.4980, -1.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807862401008606
Epoch 0, Step 933: train/loss = 0.26153844594955444, train/raw-loss = 0.22740969061851501, train/logprobs = tensor([[-0.9529, -5.5545],
        [-2.5105, -1.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3412875235080719
Epoch 0, Step 934: train/loss = 0.3193422555923462, train/raw-loss = 0.28593429923057556, train/logprobs = tensor([[-1.1069, -8.6893],
        [-2.3104, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33407941460609436
Epoch 0, Step 935: train/loss = 0.6473448276519775, train/raw-loss = 0.6024959087371826, train/logprobs = tensor([[-2.7941, -7.0251],
        [-3.1193, -2.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44848883152008057
Epoch 0, Step 936: train/loss = 0.4863467216491699, train/raw-loss = 0.4364762306213379, train/logprobs = tensor([[-1.0741, -3.1656],
        [-2.3211, -1.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49870485067367554
Epoch 0, Step 937: train/loss = 0.23114341497421265, train/raw-loss = 0.18129798769950867, train/logprobs = tensor([[-2.2859, -5.2072],
        [-4.5097, -2.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49845433235168457
Epoch 0, Step 938: train/loss = 0.22843562066555023, train/raw-loss = 0.1893429160118103, train/logprobs = tensor([[-1.7424, -9.0695],
        [-3.0442, -2.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3909270465373993
Epoch 0, Step 939: train/loss = 0.6614667177200317, train/raw-loss = 0.6089315414428711, train/logprobs = tensor([[-2.4065, -5.9720],
        [-2.3014, -2.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5253510475158691
Epoch 0, Step 940: train/loss = 0.40538644790649414, train/raw-loss = 0.3636268377304077, train/logprobs = tensor([[-1.6421, -4.1293],
        [-2.6593, -1.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175961911678314
Epoch 0, Step 941: train/loss = 0.16617697477340698, train/raw-loss = 0.11836343258619308, train/logprobs = tensor([[-1.4933, -6.2813],
        [-3.6791, -1.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47813543677330017
Epoch 0, Step 942: train/loss = 0.45726364850997925, train/raw-loss = 0.4175387918949127, train/logprobs = tensor([[-0.9472, -3.5470],
        [-2.8468, -1.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972485661506653
Epoch 0, Step 943: train/loss = 0.2786312699317932, train/raw-loss = 0.23138143122196198, train/logprobs = tensor([[-1.4869, -5.8326],
        [-4.2450, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4724983870983124
Epoch 0, Step 944: train/loss = 0.28217947483062744, train/raw-loss = 0.23796479403972626, train/logprobs = tensor([[-1.2645, -4.1544],
        [-2.8622, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44214683771133423
Epoch 0, Step 945: train/loss = 0.23810110986232758, train/raw-loss = 0.2022295892238617, train/logprobs = tensor([[-1.5467, -7.4560],
        [-3.1456, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587152063846588
Epoch 0, Step 946: train/loss = 0.4273689389228821, train/raw-loss = 0.3779935836791992, train/logprobs = tensor([[-1.7005, -7.7248],
        [-3.2821, -2.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49375325441360474
Epoch 0, Step 947: train/loss = 0.14237600564956665, train/raw-loss = 0.09601692110300064, train/logprobs = tensor([[ -1.0957, -10.6592],
        [ -3.0919,  -2.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46359074115753174
Epoch 0, Step 948: train/loss = 0.19403541088104248, train/raw-loss = 0.1448841691017151, train/logprobs = tensor([[-0.7673, -4.5066],
        [-3.6367, -2.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4915122091770172
Epoch 0, Step 949: train/loss = 0.3597758412361145, train/raw-loss = 0.32570937275886536, train/logprobs = tensor([[-1.2471, -4.3236],
        [-2.7320, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34066420793533325
Epoch 0, Step 950: train/loss = 0.16611365973949432, train/raw-loss = 0.11471369117498398, train/logprobs = tensor([[-1.1111, -8.0243],
        [-3.8934, -2.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5139997005462646
Epoch 0, Step 951: train/loss = 0.43896228075027466, train/raw-loss = 0.3954138457775116, train/logprobs = tensor([[-2.3507, -6.3399],
        [-2.5883, -1.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4354845881462097
Epoch 0, Step 952: train/loss = 0.4244215190410614, train/raw-loss = 0.3739531636238098, train/logprobs = tensor([[-1.0518, -5.0702],
        [-4.1329, -2.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5046836137771606
Epoch 0, Step 953: train/loss = 0.9558627009391785, train/raw-loss = 0.9171735644340515, train/logprobs = tensor([[-2.5430, -4.1543],
        [-1.8213, -1.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868907392024994
Epoch 0, Step 954: train/loss = 0.45821380615234375, train/raw-loss = 0.41252079606056213, train/logprobs = tensor([[-2.1495, -5.5900],
        [-2.7641, -1.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4569300413131714
Epoch 0, Step 955: train/loss = 0.3574216663837433, train/raw-loss = 0.3060033321380615, train/logprobs = tensor([[-1.3970, -7.6598],
        [-4.1262, -3.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141830444335938
Epoch 0, Step 956: train/loss = 0.4059051275253296, train/raw-loss = 0.3553251624107361, train/logprobs = tensor([[-1.5423, -3.8969],
        [-3.8625, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5057996511459351
Epoch 0, Step 957: train/loss = 0.4150490462779999, train/raw-loss = 0.36869102716445923, train/logprobs = tensor([[-1.8245, -6.9648],
        [-2.9136, -2.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635801315307617
Epoch 0, Step 958: train/loss = 0.5184107422828674, train/raw-loss = 0.48029348254203796, train/logprobs = tensor([[-1.2253, -2.3589],
        [-2.2891, -1.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3811724781990051
Epoch 0, Step 959: train/loss = 0.44043102860450745, train/raw-loss = 0.39520543813705444, train/logprobs = tensor([[-1.9723, -4.1247],
        [-2.5785, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522557854652405
Epoch 0, Step 960: train/loss = 0.37364262342453003, train/raw-loss = 0.3218451142311096, train/logprobs = tensor([[-1.9840, -6.6375],
        [-3.4881, -3.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5179747939109802
Epoch 0, Step 961: train/loss = 0.3064855635166168, train/raw-loss = 0.2619987726211548, train/logprobs = tensor([[-1.5388, -5.4007],
        [-3.1905, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44486790895462036
Epoch 0, Step 962: train/loss = 0.14591072499752045, train/raw-loss = 0.09123016893863678, train/logprobs = tensor([[-1.5742, -6.0214],
        [-4.6472, -1.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5468055605888367
Epoch 0, Step 963: train/loss = 0.44820451736450195, train/raw-loss = 0.408454954624176, train/logprobs = tensor([[-1.8863, -6.1920],
        [-2.2947, -0.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39749544858932495
Epoch 0, Step 964: train/loss = 0.25863200426101685, train/raw-loss = 0.21112966537475586, train/logprobs = tensor([[-1.3416, -5.2710],
        [-3.7253, -2.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4750235378742218
Epoch 0, Step 965: train/loss = 0.6728357672691345, train/raw-loss = 0.6356686353683472, train/logprobs = tensor([[-1.8808, -3.5545],
        [-2.2890, -2.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3716716766357422
Epoch 0, Step 966: train/loss = 0.29059064388275146, train/raw-loss = 0.2499336302280426, train/logprobs = tensor([[-0.9567, -5.4461],
        [-2.5555, -1.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40657007694244385
Epoch 0, Step 967: train/loss = 0.6009395122528076, train/raw-loss = 0.5681199431419373, train/logprobs = tensor([[ -2.4665, -10.2596],
        [ -1.2829,  -1.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281952440738678
Epoch 0, Step 968: train/loss = 0.38355526328086853, train/raw-loss = 0.3377469778060913, train/logprobs = tensor([[-1.1713, -3.5460],
        [-3.3829, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45808255672454834
Epoch 0, Step 969: train/loss = 0.3295755386352539, train/raw-loss = 0.2777264714241028, train/logprobs = tensor([[-1.4468, -5.8452],
        [-3.2803, -2.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5184907913208008
Epoch 0, Step 970: train/loss = 0.45016688108444214, train/raw-loss = 0.3966609835624695, train/logprobs = tensor([[-1.8579, -4.0320],
        [-3.6531, -3.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5350589752197266
Epoch 0, Step 971: train/loss = 0.23843221366405487, train/raw-loss = 0.19923846423625946, train/logprobs = tensor([[-0.8265, -8.2942],
        [-2.1639, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919374942779541
Epoch 0, Step 972: train/loss = 0.9258139133453369, train/raw-loss = 0.8843153715133667, train/logprobs = tensor([[-2.6863, -2.8525],
        [-1.6493, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41498491168022156
Epoch 0, Step 973: train/loss = 0.5452033281326294, train/raw-loss = 0.49963465332984924, train/logprobs = tensor([[-3.0442, -6.6090],
        [-2.9316, -2.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45568645000457764
Epoch 0, Step 974: train/loss = 0.5365488529205322, train/raw-loss = 0.48895251750946045, train/logprobs = tensor([[-1.4835, -2.8432],
        [-3.5700, -1.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4759635925292969
Epoch 0, Step 975: train/loss = 0.35500383377075195, train/raw-loss = 0.31127262115478516, train/logprobs = tensor([[-1.1282, -7.5443],
        [-2.7336, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4373117983341217
Epoch 0, Step 976: train/loss = 0.29548180103302, train/raw-loss = 0.2509024739265442, train/logprobs = tensor([[-1.2489, -6.2872],
        [-3.5611, -1.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44579362869262695
Epoch 0, Step 977: train/loss = 0.4192107915878296, train/raw-loss = 0.3787361979484558, train/logprobs = tensor([[-2.5419, -6.2346],
        [-3.0997, -0.4745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40474554896354675
Epoch 0, Step 978: train/loss = 0.21334290504455566, train/raw-loss = 0.1708366572856903, train/logprobs = tensor([[-1.3834, -6.6099],
        [-3.3017, -1.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4250625967979431
Epoch 0, Step 979: train/loss = 0.6851348280906677, train/raw-loss = 0.649039089679718, train/logprobs = tensor([[-1.4512, -4.0055],
        [-1.7479, -2.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36095720529556274
Epoch 0, Step 980: train/loss = 0.6460240483283997, train/raw-loss = 0.5992632508277893, train/logprobs = tensor([[-3.7021, -8.9568],
        [-3.8955, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46760764718055725
Epoch 0, Step 981: train/loss = 0.3560250997543335, train/raw-loss = 0.3079324960708618, train/logprobs = tensor([[-1.3977, -5.4209],
        [-2.9026, -1.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4809262752532959
Epoch 0, Step 982: train/loss = 0.5129227638244629, train/raw-loss = 0.47396358847618103, train/logprobs = tensor([[-1.5946, -6.6915],
        [-2.7748, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38959163427352905
Epoch 0, Step 983: train/loss = 0.6063508987426758, train/raw-loss = 0.5686689615249634, train/logprobs = tensor([[-1.5420, -2.4815],
        [-1.7714, -1.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3768194019794464
Epoch 0, Step 984: train/loss = 0.71337890625, train/raw-loss = 0.6703922152519226, train/logprobs = tensor([[-2.7793, -6.8092],
        [-2.6225, -1.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4298667311668396
Epoch 0, Step 985: train/loss = 0.6507794857025146, train/raw-loss = 0.6051321029663086, train/logprobs = tensor([[-2.9120, -5.6475],
        [-4.0014, -2.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45647338032722473
Epoch 0, Step 986: train/loss = 0.32706305384635925, train/raw-loss = 0.28534135222435, train/logprobs = tensor([[-1.5241, -4.7932],
        [-2.7046, -1.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4172170162200928
Epoch 0, Step 987: train/loss = 0.3210139870643616, train/raw-loss = 0.27170509099960327, train/logprobs = tensor([[-2.1253, -6.9520],
        [-4.4045, -2.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4930889308452606
Epoch 0, Step 988: train/loss = 0.5227782726287842, train/raw-loss = 0.47791531682014465, train/logprobs = tensor([[-1.5207, -6.4655],
        [-2.7457, -1.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44862955808639526
Epoch 0, Step 989: train/loss = 0.23349080979824066, train/raw-loss = 0.19573509693145752, train/logprobs = tensor([[-1.3847, -5.2762],
        [-2.7980, -0.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3775571882724762
Epoch 0, Step 990: train/loss = 0.3810149133205414, train/raw-loss = 0.3284337520599365, train/logprobs = tensor([[-1.2356, -4.6832],
        [-4.0581, -2.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258114337921143
Epoch 0, Step 991: train/loss = 0.2569703459739685, train/raw-loss = 0.2178039401769638, train/logprobs = tensor([[-1.5962, -3.9689],
        [-3.4791, -1.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39166417717933655
Epoch 0, Step 992: train/loss = 0.4819495677947998, train/raw-loss = 0.4447716772556305, train/logprobs = tensor([[-1.7423, -2.9652],
        [-2.1358, -0.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3717787563800812
Epoch 0, Step 993: train/loss = 0.3180390000343323, train/raw-loss = 0.27577343583106995, train/logprobs = tensor([[-1.6859, -7.6601],
        [-2.8454, -2.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42265570163726807
Epoch 0, Step 994: train/loss = 0.4527226388454437, train/raw-loss = 0.4060457646846771, train/logprobs = tensor([[-1.3147, -6.3252],
        [-2.6966, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46676868200302124
Epoch 0, Step 995: train/loss = 0.38188257813453674, train/raw-loss = 0.3455047607421875, train/logprobs = tensor([[-0.9507, -8.4740],
        [-2.4361, -1.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637782335281372
Epoch 0, Step 996: train/loss = 0.5903255939483643, train/raw-loss = 0.5535792708396912, train/logprobs = tensor([[-1.1245, -1.8540],
        [-2.1604, -2.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36746343970298767
Epoch 0, Step 997: train/loss = 0.3565537631511688, train/raw-loss = 0.31223058700561523, train/logprobs = tensor([[-2.1210, -6.5860],
        [-3.4759, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4432317912578583
Epoch 0, Step 998: train/loss = 0.345878541469574, train/raw-loss = 0.30402857065200806, train/logprobs = tensor([[-1.9148, -7.6650],
        [-3.5526, -2.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4184994697570801
Epoch 0, Step 999: train/loss = 0.3392987847328186, train/raw-loss = 0.29118046164512634, train/logprobs = tensor([[-1.0651, -3.8448],
        [-2.5985, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4811832308769226
Epoch 0, Step 1000: train/loss = 0.6838861703872681, train/raw-loss = 0.636304497718811, train/logprobs = tensor([[-2.2018, -4.8614],
        [-3.4753, -2.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47581711411476135
Epoch 0, Step 1001: train/loss = 0.2840385437011719, train/raw-loss = 0.23842141032218933, train/logprobs = tensor([[-1.2972, -5.3096],
        [-3.3990, -1.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45617133378982544
Epoch 0, Step 1002: train/loss = 0.3809293806552887, train/raw-loss = 0.34592753648757935, train/logprobs = tensor([[-1.1473, -7.5440],
        [-1.9661, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35001829266548157
Epoch 0, Step 1003: train/loss = 0.5503612756729126, train/raw-loss = 0.513530433177948, train/logprobs = tensor([[-1.3871, -3.1026],
        [-1.7218, -2.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683079481124878
Epoch 0, Step 1004: train/loss = 0.5104749798774719, train/raw-loss = 0.46851831674575806, train/logprobs = tensor([[-1.7045, -6.8825],
        [-2.4209, -1.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4195666015148163
Epoch 0, Step 1005: train/loss = 0.33931130170822144, train/raw-loss = 0.3009662628173828, train/logprobs = tensor([[-1.3856, -7.3666],
        [-2.4897, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3834501802921295
Epoch 0, Step 1006: train/loss = 0.40600523352622986, train/raw-loss = 0.3514961004257202, train/logprobs = tensor([[-2.1698, -5.3610],
        [-3.9287, -2.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.545091450214386
Epoch 0, Step 1007: train/loss = 0.17255422472953796, train/raw-loss = 0.13039463758468628, train/logprobs = tensor([[ -1.9587, -11.3598],
        [ -3.6931,  -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215957820415497
Epoch 0, Step 1008: train/loss = 0.2148568332195282, train/raw-loss = 0.17131979763507843, train/logprobs = tensor([[-0.9802, -9.3576],
        [-3.4290, -1.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43537020683288574
Epoch 0, Step 1009: train/loss = 0.5116432905197144, train/raw-loss = 0.46284401416778564, train/logprobs = tensor([[-1.8757, -3.7599],
        [-2.7029, -2.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48799246549606323
Epoch 0, Step 1010: train/loss = 0.4434228241443634, train/raw-loss = 0.4015256464481354, train/logprobs = tensor([[-2.3346, -4.3317],
        [-3.3457, -1.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41897183656692505
Epoch 0, Step 1011: train/loss = 0.6557402610778809, train/raw-loss = 0.6158779263496399, train/logprobs = tensor([[-2.8267, -5.1723],
        [-2.2960, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39862382411956787
Epoch 0, Step 1012: train/loss = 0.3200201690196991, train/raw-loss = 0.28115224838256836, train/logprobs = tensor([[-1.3996, -6.3542],
        [-3.0427, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3886791169643402
Epoch 0, Step 1013: train/loss = 0.46466803550720215, train/raw-loss = 0.42249149084091187, train/logprobs = tensor([[-1.9076, -3.3724],
        [-2.4687, -1.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217653274536133
Epoch 0, Step 1014: train/loss = 0.2618653476238251, train/raw-loss = 0.21850571036338806, train/logprobs = tensor([[-1.5386, -3.8469],
        [-3.3423, -2.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335963726043701
Epoch 0, Step 1015: train/loss = 0.3626686930656433, train/raw-loss = 0.31732815504074097, train/logprobs = tensor([[-1.6905, -9.2937],
        [-3.4086, -2.3433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45340561866760254
Epoch 0, Step 1016: train/loss = 0.30723273754119873, train/raw-loss = 0.26093414425849915, train/logprobs = tensor([[-1.2866, -3.1699],
        [-3.2008, -1.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4629861116409302
Epoch 0, Step 1017: train/loss = 0.15402817726135254, train/raw-loss = 0.10293488949537277, train/logprobs = tensor([[-2.2251, -9.5514],
        [-4.7555, -2.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5109329223632812
Epoch 0, Step 1018: train/loss = 0.5454235076904297, train/raw-loss = 0.512677788734436, train/logprobs = tensor([[-1.1605, -2.3654],
        [-1.7282, -1.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3274574279785156
Epoch 0, Step 1019: train/loss = 0.3287649154663086, train/raw-loss = 0.2827647626399994, train/logprobs = tensor([[-1.2968, -4.5135],
        [-3.1054, -2.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46000126004219055
Epoch 0, Step 1020: train/loss = 0.6805660128593445, train/raw-loss = 0.6413124203681946, train/logprobs = tensor([[-1.0963, -4.1591],
        [-1.6617, -2.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3925357758998871
Epoch 0, Step 1021: train/loss = 0.15632294118404388, train/raw-loss = 0.11010769754648209, train/logprobs = tensor([[-1.6521, -6.8923],
        [-3.7379, -1.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4621526002883911
Epoch 0, Step 1022: train/loss = 0.43177491426467896, train/raw-loss = 0.38914602994918823, train/logprobs = tensor([[-1.2415, -5.3173],
        [-3.0521, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4262887239456177
Epoch 0, Step 1023: train/loss = 1.1222285032272339, train/raw-loss = 1.073667049407959, train/logprobs = tensor([[-3.2738, -7.2155],
        [-2.7244, -2.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4856158196926117
Epoch 0, Step 1024: train/loss = 0.3781929612159729, train/raw-loss = 0.3391866981983185, train/logprobs = tensor([[-1.2824, -3.1262],
        [-2.5521, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39006268978118896
Epoch 0, Step 1025: train/loss = 0.4726622402667999, train/raw-loss = 0.4363521337509155, train/logprobs = tensor([[-1.2441, -2.1621],
        [-1.9480, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36310112476348877
Epoch 0, Step 1026: train/loss = 0.4377782940864563, train/raw-loss = 0.3936818242073059, train/logprobs = tensor([[-2.3116, -6.4217],
        [-3.5851, -2.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409649968147278
Epoch 0, Step 1027: train/loss = 0.5809181928634644, train/raw-loss = 0.5396113395690918, train/logprobs = tensor([[-1.2580, -2.1175],
        [-1.8345, -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4130687117576599
Epoch 0, Step 1028: train/loss = 0.29650264978408813, train/raw-loss = 0.2591676414012909, train/logprobs = tensor([[-1.2226, -9.2992],
        [-2.8638, -2.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37335002422332764
Epoch 0, Step 1029: train/loss = 0.25428852438926697, train/raw-loss = 0.21790310740470886, train/logprobs = tensor([[-1.1721, -7.8710],
        [-2.6711, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36385416984558105
Epoch 0, Step 1030: train/loss = 0.43335971236228943, train/raw-loss = 0.39674603939056396, train/logprobs = tensor([[-1.0316, -7.2167],
        [-1.7881, -2.2642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36613672971725464
Epoch 0, Step 1031: train/loss = 0.6479659080505371, train/raw-loss = 0.603728175163269, train/logprobs = tensor([[-1.8504, -2.7882],
        [-2.0738, -1.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4423777759075165
Epoch 0, Step 1032: train/loss = 0.6367855072021484, train/raw-loss = 0.5994099974632263, train/logprobs = tensor([[-1.4463, -1.9728],
        [-1.8755, -1.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37375491857528687
Epoch 0, Step 1033: train/loss = 0.26720544695854187, train/raw-loss = 0.21714331209659576, train/logprobs = tensor([[-1.3430, -8.9240],
        [-3.3513, -1.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.500621497631073
Epoch 0, Step 1034: train/loss = 0.3815271854400635, train/raw-loss = 0.34436607360839844, train/logprobs = tensor([[-1.3399, -3.7222],
        [-2.2916, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37161093950271606
Epoch 0, Step 1035: train/loss = 0.4742923974990845, train/raw-loss = 0.42347171902656555, train/logprobs = tensor([[-1.4121, -3.5897],
        [-2.6559, -1.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.508206844329834
Epoch 0, Step 1036: train/loss = 0.19351826608181, train/raw-loss = 0.1545042246580124, train/logprobs = tensor([[-1.4316, -6.6596],
        [-2.9722, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3901404142379761
Epoch 0, Step 1037: train/loss = 0.6836353540420532, train/raw-loss = 0.6329739093780518, train/logprobs = tensor([[-0.9965, -2.2912],
        [-3.3937, -3.2173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.506614089012146
Epoch 0, Step 1038: train/loss = 0.6209374666213989, train/raw-loss = 0.5811930894851685, train/logprobs = tensor([[-1.9428, -3.1918],
        [-2.3593, -1.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3974429965019226
Epoch 0, Step 1039: train/loss = 0.615739643573761, train/raw-loss = 0.5723668932914734, train/logprobs = tensor([[-1.5304, -2.5831],
        [-2.0382, -1.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43372777104377747
Epoch 0, Step 1040: train/loss = 0.6462274789810181, train/raw-loss = 0.6084069609642029, train/logprobs = tensor([[-1.6516, -5.4887],
        [-1.7822, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782052993774414
Epoch 0, Step 1041: train/loss = 0.2678464651107788, train/raw-loss = 0.21248982846736908, train/logprobs = tensor([[-1.5769, -5.4532],
        [-3.4298, -3.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5535666346549988
Epoch 0, Step 1042: train/loss = 0.37554216384887695, train/raw-loss = 0.3341793119907379, train/logprobs = tensor([[-1.0222, -3.6992],
        [-3.1182, -1.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136282205581665
Epoch 0, Step 1043: train/loss = 0.3568147122859955, train/raw-loss = 0.3223421573638916, train/logprobs = tensor([[-0.8952, -6.0145],
        [-2.3928, -1.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34472551941871643
Epoch 0, Step 1044: train/loss = 0.9825895428657532, train/raw-loss = 0.9413782954216003, train/logprobs = tensor([[-2.9825, -3.4601],
        [-2.6252, -2.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41211265325546265
Epoch 0, Step 1045: train/loss = 0.3563675284385681, train/raw-loss = 0.3104393184185028, train/logprobs = tensor([[ -1.0153, -10.4061],
        [ -3.9974,  -2.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4592817723751068
Epoch 0, Step 1046: train/loss = 0.48141157627105713, train/raw-loss = 0.44671326875686646, train/logprobs = tensor([[-1.1573, -3.2059],
        [-1.9068, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469829559326172
Epoch 0, Step 1047: train/loss = 0.3564879894256592, train/raw-loss = 0.3072893023490906, train/logprobs = tensor([[-2.3309, -4.6325],
        [-4.2735, -1.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4919869899749756
Epoch 0, Step 1048: train/loss = 0.567009449005127, train/raw-loss = 0.5265628695487976, train/logprobs = tensor([[-1.3473, -1.9668],
        [-2.0868, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40446555614471436
Epoch 0, Step 1049: train/loss = 0.14261549711227417, train/raw-loss = 0.1039314866065979, train/logprobs = tensor([[-1.0675, -8.8638],
        [-2.8891, -2.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38684016466140747
Epoch 0, Step 1050: train/loss = 0.3835785388946533, train/raw-loss = 0.3395538032054901, train/logprobs = tensor([[-1.4350, -7.1246],
        [-2.9717, -1.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44024768471717834
Epoch 0, Step 1051: train/loss = 0.42561936378479004, train/raw-loss = 0.38436776399612427, train/logprobs = tensor([[-1.3007, -4.1000],
        [-3.8072, -1.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41251620650291443
Epoch 0, Step 1052: train/loss = 0.19526204466819763, train/raw-loss = 0.15711750090122223, train/logprobs = tensor([[-1.2265, -4.5762],
        [-3.3127, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814454972743988
Epoch 0, Step 1053: train/loss = 0.4055151641368866, train/raw-loss = 0.35498714447021484, train/logprobs = tensor([[-1.8041, -4.4144],
        [-3.4398, -2.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5052800178527832
Epoch 0, Step 1054: train/loss = 0.283432275056839, train/raw-loss = 0.2412419617176056, train/logprobs = tensor([[-1.5536, -9.0127],
        [-2.4905, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42190343141555786
Epoch 0, Step 1055: train/loss = 0.4296056926250458, train/raw-loss = 0.3993627429008484, train/logprobs = tensor([[-0.6823, -7.3473],
        [-0.8713, -1.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30242910981178284
Epoch 0, Step 1056: train/loss = 0.5799819827079773, train/raw-loss = 0.5370539426803589, train/logprobs = tensor([[-2.0986, -3.6233],
        [-2.4457, -1.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4292806386947632
Epoch 0, Step 1057: train/loss = 0.3163004517555237, train/raw-loss = 0.27552103996276855, train/logprobs = tensor([[-1.5745, -5.3395],
        [-2.6504, -1.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40779390931129456
Epoch 0, Step 1058: train/loss = 0.48607099056243896, train/raw-loss = 0.4420973062515259, train/logprobs = tensor([[-1.4177, -2.4996],
        [-3.2359, -2.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43973681330680847
Epoch 0, Step 1059: train/loss = 0.5084253549575806, train/raw-loss = 0.4656619131565094, train/logprobs = tensor([[-1.7297, -4.5140],
        [-2.2453, -2.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42763423919677734
Epoch 0, Step 1060: train/loss = 0.37918829917907715, train/raw-loss = 0.3391605615615845, train/logprobs = tensor([[ -2.1467, -10.5212],
        [ -2.5510,  -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002777934074402
Epoch 0, Step 1061: train/loss = 0.30621519684791565, train/raw-loss = 0.26221194863319397, train/logprobs = tensor([[-0.7699, -3.8028],
        [-2.8174, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4400327801704407
Epoch 0, Step 1062: train/loss = 0.2938538193702698, train/raw-loss = 0.2560676336288452, train/logprobs = tensor([[-1.3420, -4.7481],
        [-2.3770, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778616786003113
Epoch 0, Step 1063: train/loss = 0.3334253430366516, train/raw-loss = 0.2963483929634094, train/logprobs = tensor([[-1.0435, -8.9527],
        [-2.4109, -1.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37076929211616516
Epoch 0, Step 1064: train/loss = 0.12774810194969177, train/raw-loss = 0.07604089379310608, train/logprobs = tensor([[-1.2817, -9.0361],
        [-3.4613, -1.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5170721411705017
Epoch 0, Step 1065: train/loss = 0.4940633475780487, train/raw-loss = 0.4557569921016693, train/logprobs = tensor([[-1.6285, -2.9546],
        [-2.5663, -1.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38306355476379395
Epoch 0, Step 1066: train/loss = 0.3005804419517517, train/raw-loss = 0.2542237341403961, train/logprobs = tensor([[-1.5711, -6.8984],
        [-2.9556, -2.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635670781135559
Epoch 0, Step 1067: train/loss = 0.13395749032497406, train/raw-loss = 0.09881652891635895, train/logprobs = tensor([[-0.8217, -6.6376],
        [-2.4087, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514096140861511
Epoch 0, Step 1068: train/loss = 0.5749481916427612, train/raw-loss = 0.5346022248268127, train/logprobs = tensor([[-1.2735, -3.1575],
        [-2.4121, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4034595191478729
Epoch 0, Step 1069: train/loss = 0.2524680197238922, train/raw-loss = 0.21281245350837708, train/logprobs = tensor([[-1.0356, -9.0878],
        [-3.4409, -1.0080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965556025505066
Epoch 0, Step 1070: train/loss = 0.40072599053382874, train/raw-loss = 0.3623186945915222, train/logprobs = tensor([[-2.2374, -6.8567],
        [-2.4008, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840731084346771
Epoch 0, Step 1071: train/loss = 0.3276876211166382, train/raw-loss = 0.2825120985507965, train/logprobs = tensor([[-1.5129, -7.4091],
        [-3.1139, -1.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4517556428909302
Epoch 0, Step 1072: train/loss = 0.42396238446235657, train/raw-loss = 0.3912225067615509, train/logprobs = tensor([[-1.0026, -3.7334],
        [-2.3851, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32739871740341187
Epoch 0, Step 1073: train/loss = 0.7091777920722961, train/raw-loss = 0.6657232046127319, train/logprobs = tensor([[-2.8700, -6.2495],
        [-2.3277, -1.2785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4345460534095764
Epoch 0, Step 1074: train/loss = 0.9065698385238647, train/raw-loss = 0.8662244081497192, train/logprobs = tensor([[-3.8898, -6.3378],
        [-4.2028, -2.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403454452753067
Epoch 0, Step 1075: train/loss = 0.24477607011795044, train/raw-loss = 0.20205876231193542, train/logprobs = tensor([[-1.5200, -6.1512],
        [-4.1443, -3.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4271731674671173
Epoch 0, Step 1076: train/loss = 0.3914448022842407, train/raw-loss = 0.34986358880996704, train/logprobs = tensor([[-0.7819, -5.0344],
        [-2.2116, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158121347427368
Epoch 0, Step 1077: train/loss = 0.17937369644641876, train/raw-loss = 0.14503160119056702, train/logprobs = tensor([[-1.4752, -9.4171],
        [-2.7237, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34342095255851746
Epoch 0, Step 1078: train/loss = 0.3101831078529358, train/raw-loss = 0.27099210023880005, train/logprobs = tensor([[-1.4511, -9.6861],
        [-3.0883, -2.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919103443622589
Epoch 0, Step 1079: train/loss = 0.2414202243089676, train/raw-loss = 0.20594915747642517, train/logprobs = tensor([[-1.8889, -5.4046],
        [-2.9479, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35471054911613464
Epoch 0, Step 1080: train/loss = 0.49620744585990906, train/raw-loss = 0.4616810977458954, train/logprobs = tensor([[-1.2776, -5.7586],
        [-1.3103, -1.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3452635407447815
Epoch 0, Step 1081: train/loss = 0.34080439805984497, train/raw-loss = 0.3020116984844208, train/logprobs = tensor([[-1.3159, -8.9151],
        [-2.7730, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879268169403076
Epoch 0, Step 1082: train/loss = 0.41432660818099976, train/raw-loss = 0.3853290379047394, train/logprobs = tensor([[-1.4935, -7.9840],
        [-1.8256, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28997570276260376
Epoch 0, Step 1083: train/loss = 0.5093093514442444, train/raw-loss = 0.47670769691467285, train/logprobs = tensor([[-1.0953, -3.7207],
        [-1.5517, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32601654529571533
Epoch 0, Step 1084: train/loss = 0.5795119404792786, train/raw-loss = 0.5365898609161377, train/logprobs = tensor([[-0.9648, -4.0917],
        [-3.3144, -2.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42922163009643555
Epoch 0, Step 1085: train/loss = 0.1821107268333435, train/raw-loss = 0.13383238017559052, train/logprobs = tensor([[ -1.8210, -11.5067],
        [ -3.6039,  -2.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48278355598449707
Epoch 0, Step 1086: train/loss = 0.4068862497806549, train/raw-loss = 0.3692297637462616, train/logprobs = tensor([[-0.7067, -6.2895],
        [-2.3389, -2.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765648603439331
Epoch 0, Step 1087: train/loss = 0.5538936853408813, train/raw-loss = 0.5164546966552734, train/logprobs = tensor([[-1.5347, -3.5617],
        [-1.8615, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3743898868560791
Epoch 0, Step 1088: train/loss = 0.4283895492553711, train/raw-loss = 0.39341479539871216, train/logprobs = tensor([[-1.1405, -5.7902],
        [-1.6237, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497474491596222
Epoch 0, Step 1089: train/loss = 0.2979143559932709, train/raw-loss = 0.2584455609321594, train/logprobs = tensor([[-2.5528, -8.2939],
        [-3.5949, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39468806982040405
Epoch 0, Step 1090: train/loss = 1.1451517343521118, train/raw-loss = 1.106065273284912, train/logprobs = tensor([[-3.7362, -5.3313],
        [-2.0914, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908650577068329
Epoch 0, Step 1091: train/loss = 0.2097560316324234, train/raw-loss = 0.16344812512397766, train/logprobs = tensor([[-1.7365, -7.7497],
        [-3.8307, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630791246891022
Epoch 0, Step 1092: train/loss = 0.19792234897613525, train/raw-loss = 0.1555314064025879, train/logprobs = tensor([[-1.8735, -8.3065],
        [-4.0690, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42390939593315125
Epoch 0, Step 1093: train/loss = 0.37011951208114624, train/raw-loss = 0.3160902261734009, train/logprobs = tensor([[-1.6477, -6.4284],
        [-3.7886, -1.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5402928590774536
Epoch 0, Step 1094: train/loss = 0.2983781695365906, train/raw-loss = 0.2576782703399658, train/logprobs = tensor([[-1.3888, -5.0912],
        [-2.4526, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069993197917938
Epoch 0, Step 1095: train/loss = 0.3848383128643036, train/raw-loss = 0.3431338965892792, train/logprobs = tensor([[-1.9483, -3.8921],
        [-3.0873, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4170442819595337
Epoch 0, Step 1096: train/loss = 0.33390820026397705, train/raw-loss = 0.2915800213813782, train/logprobs = tensor([[-1.9755, -7.5338],
        [-3.3349, -1.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4232817590236664
Epoch 0, Step 1097: train/loss = 0.33360984921455383, train/raw-loss = 0.29519104957580566, train/logprobs = tensor([[-1.7706, -6.0904],
        [-2.9942, -1.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3841879069805145
Epoch 0, Step 1098: train/loss = 0.5172000527381897, train/raw-loss = 0.47742998600006104, train/logprobs = tensor([[-1.4973, -5.1156],
        [-2.3059, -2.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39770039916038513
Epoch 0, Step 1099: train/loss = 0.36637014150619507, train/raw-loss = 0.332008957862854, train/logprobs = tensor([[-1.4002, -6.1875],
        [-2.1944, -2.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3436119854450226
Epoch 0, Step 1100: train/loss = 0.3087121844291687, train/raw-loss = 0.2719721794128418, train/logprobs = tensor([[-1.1251, -4.9806],
        [-2.4228, -1.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36740022897720337
Epoch 0, Step 1101: train/loss = 0.3459048271179199, train/raw-loss = 0.31003716588020325, train/logprobs = tensor([[-1.6900, -6.0054],
        [-2.5177, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586764335632324
Epoch 0, Step 1102: train/loss = 0.3074943423271179, train/raw-loss = 0.2677609622478485, train/logprobs = tensor([[-1.8061, -8.1453],
        [-2.8947, -1.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3973340392112732
Epoch 0, Step 1103: train/loss = 0.5871114730834961, train/raw-loss = 0.5575408935546875, train/logprobs = tensor([[-2.3060, -4.9504],
        [-1.9087, -1.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957051694393158
Epoch 0, Step 1104: train/loss = 0.6979384422302246, train/raw-loss = 0.6572574973106384, train/logprobs = tensor([[-0.9121, -1.3728],
        [-2.0777, -2.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4068094491958618
Epoch 0, Step 1105: train/loss = 0.3323325514793396, train/raw-loss = 0.28824010491371155, train/logprobs = tensor([[-2.3650, -6.6820],
        [-3.5858, -1.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44092458486557007
Epoch 0, Step 1106: train/loss = 0.6217917203903198, train/raw-loss = 0.583503246307373, train/logprobs = tensor([[-2.2204, -4.1459],
        [-2.5659, -1.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38288456201553345
Epoch 0, Step 1107: train/loss = 0.36754804849624634, train/raw-loss = 0.3349071145057678, train/logprobs = tensor([[-1.5439, -4.9266],
        [-3.2070, -1.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3264091908931732
Epoch 0, Step 1108: train/loss = 0.357810914516449, train/raw-loss = 0.3187744915485382, train/logprobs = tensor([[-0.8866, -5.3000],
        [-3.0391, -1.8763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39036425948143005
Epoch 0, Step 1109: train/loss = 0.119905486702919, train/raw-loss = 0.0720316544175148, train/logprobs = tensor([[-1.5413, -8.2284],
        [-3.7230, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47873833775520325
Epoch 0, Step 1110: train/loss = 0.36900246143341064, train/raw-loss = 0.323798269033432, train/logprobs = tensor([[-0.9962, -2.9264],
        [-3.5629, -2.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4520418643951416
Epoch 0, Step 1111: train/loss = 0.23510527610778809, train/raw-loss = 0.1906968057155609, train/logprobs = tensor([[-1.3677, -3.5833],
        [-3.4567, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44408494234085083
Epoch 0, Step 1112: train/loss = 0.38783350586891174, train/raw-loss = 0.3482030928134918, train/logprobs = tensor([[-1.5574, -7.8401],
        [-3.0870, -1.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3963041305541992
Epoch 0, Step 1113: train/loss = 0.5188770890235901, train/raw-loss = 0.48511356115341187, train/logprobs = tensor([[-2.1606, -5.2527],
        [-1.9057, -1.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3376350700855255
Epoch 0, Step 1114: train/loss = 0.5672159194946289, train/raw-loss = 0.5287685394287109, train/logprobs = tensor([[-2.5061, -6.6529],
        [-2.4435, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844737708568573
Epoch 0, Step 1115: train/loss = 0.3888074457645416, train/raw-loss = 0.35335227847099304, train/logprobs = tensor([[-1.1694, -5.3532],
        [-2.8648, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354551762342453
Epoch 0, Step 1116: train/loss = 0.4686686396598816, train/raw-loss = 0.43313366174697876, train/logprobs = tensor([[-1.4344, -3.7563],
        [-2.2893, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35534951090812683
Epoch 0, Step 1117: train/loss = 0.7835493683815002, train/raw-loss = 0.7473505139350891, train/logprobs = tensor([[-1.5618, -1.4573],
        [-2.0411, -2.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36198896169662476
Epoch 0, Step 1118: train/loss = 0.5259307622909546, train/raw-loss = 0.49537673592567444, train/logprobs = tensor([[-2.1912, -6.4446],
        [-2.2207, -1.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055398762226105
Epoch 0, Step 1119: train/loss = 0.6072602272033691, train/raw-loss = 0.5684736967086792, train/logprobs = tensor([[-1.9425, -5.8811],
        [-1.6426, -0.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3878653049468994
Epoch 0, Step 1120: train/loss = 0.4615761637687683, train/raw-loss = 0.4282752275466919, train/logprobs = tensor([[-0.8979, -2.3979],
        [-2.4061, -1.4845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33300936222076416
Epoch 0, Step 1121: train/loss = 0.21121428906917572, train/raw-loss = 0.17650125920772552, train/logprobs = tensor([[-1.8457, -6.7760],
        [-3.0629, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3471302092075348
Epoch 0, Step 1122: train/loss = 0.5259766578674316, train/raw-loss = 0.4935745298862457, train/logprobs = tensor([[-1.0848, -2.7028],
        [-1.8848, -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240216076374054
Epoch 0, Step 1123: train/loss = 0.22467964887619019, train/raw-loss = 0.18108128011226654, train/logprobs = tensor([[ -1.3498, -10.2927],
        [ -3.3312,  -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43598365783691406
Epoch 0, Step 1124: train/loss = 0.24204757809638977, train/raw-loss = 0.2074897289276123, train/logprobs = tensor([[ -1.5972, -10.8645],
        [ -2.9323,  -1.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455786108970642
Epoch 0, Step 1125: train/loss = 0.304854154586792, train/raw-loss = 0.26773202419281006, train/logprobs = tensor([[-0.9551, -2.8956],
        [-2.5912, -1.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37122130393981934
Epoch 0, Step 1126: train/loss = 0.6116282939910889, train/raw-loss = 0.5769438743591309, train/logprobs = tensor([[-2.6855, -5.8578],
        [-2.4236, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468443751335144
Epoch 0, Step 1127: train/loss = 0.7272230982780457, train/raw-loss = 0.6971170902252197, train/logprobs = tensor([[-2.4425, -6.5889],
        [-1.8708, -1.4885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010599613189697
Epoch 0, Step 1128: train/loss = 0.4481702744960785, train/raw-loss = 0.4152016043663025, train/logprobs = tensor([[-1.2786, -2.5799],
        [-2.0079, -0.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3296862244606018
Epoch 0, Step 1129: train/loss = 0.6515628695487976, train/raw-loss = 0.6081404685974121, train/logprobs = tensor([[-1.1194, -4.6701],
        [-2.2460, -3.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43422311544418335
Epoch 0, Step 1130: train/loss = 0.47180742025375366, train/raw-loss = 0.43381357192993164, train/logprobs = tensor([[-2.1922, -4.8082],
        [-2.3912, -1.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799385726451874
Epoch 0, Step 1131: train/loss = 0.3720143437385559, train/raw-loss = 0.336455762386322, train/logprobs = tensor([[-1.4663, -7.3793],
        [-2.0210, -2.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555852770805359
Epoch 0, Step 1132: train/loss = 0.24146972596645355, train/raw-loss = 0.20194382965564728, train/logprobs = tensor([[-0.7380, -7.0018],
        [-2.0903, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39525890350341797
Epoch 0, Step 1133: train/loss = 0.4825703501701355, train/raw-loss = 0.4445776343345642, train/logprobs = tensor([[-1.2777, -3.1923],
        [-2.6477, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799270987510681
Epoch 0, Step 1134: train/loss = 0.49079379439353943, train/raw-loss = 0.4541589319705963, train/logprobs = tensor([[-1.3640, -3.5075],
        [-2.7367, -1.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3663487732410431
Epoch 0, Step 1135: train/loss = 0.27079665660858154, train/raw-loss = 0.23426249623298645, train/logprobs = tensor([[-1.0809, -7.4107],
        [-2.5036, -1.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3653414249420166
Epoch 0, Step 1136: train/loss = 0.3280108571052551, train/raw-loss = 0.28883060812950134, train/logprobs = tensor([[-1.4284, -3.7632],
        [-2.8920, -1.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918023705482483
Epoch 0, Step 1137: train/loss = 0.2666887640953064, train/raw-loss = 0.23779651522636414, train/logprobs = tensor([[-0.6562, -5.5756],
        [-1.8299, -1.4618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889225482940674
Epoch 0, Step 1138: train/loss = 0.4634193778038025, train/raw-loss = 0.4260594844818115, train/logprobs = tensor([[-1.1273, -2.5377],
        [-1.7267, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.373599112033844
Epoch 0, Step 1139: train/loss = 0.51661616563797, train/raw-loss = 0.4737183451652527, train/logprobs = tensor([[-1.5468, -5.7087],
        [-3.5667, -2.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4289780855178833
Epoch 0, Step 1140: train/loss = 0.37440285086631775, train/raw-loss = 0.3334066867828369, train/logprobs = tensor([[-1.9714, -6.0449],
        [-2.7571, -1.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4099618196487427
Epoch 0, Step 1141: train/loss = 0.4569358825683594, train/raw-loss = 0.417467325925827, train/logprobs = tensor([[-1.7660, -4.5925],
        [-2.4663, -1.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946858048439026
Epoch 0, Step 1142: train/loss = 0.41690340638160706, train/raw-loss = 0.37820208072662354, train/logprobs = tensor([[-1.7831, -3.5918],
        [-2.7308, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3870130181312561
Epoch 0, Step 1143: train/loss = 0.10381139814853668, train/raw-loss = 0.06606099754571915, train/logprobs = tensor([[-1.3591, -8.4446],
        [-3.3846, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37750399112701416
Epoch 0, Step 1144: train/loss = 0.36110079288482666, train/raw-loss = 0.3233533799648285, train/logprobs = tensor([[-1.2384, -4.7351],
        [-2.8981, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3774741590023041
Epoch 0, Step 1145: train/loss = 0.18892183899879456, train/raw-loss = 0.14718389511108398, train/logprobs = tensor([[-1.3282, -8.5977],
        [-2.7114, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4173795282840729
Epoch 0, Step 1146: train/loss = 1.061463475227356, train/raw-loss = 1.0256500244140625, train/logprobs = tensor([[-3.3090, -4.9280],
        [-1.3119, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581336438655853
Epoch 0, Step 1147: train/loss = 0.3245595693588257, train/raw-loss = 0.2874292731285095, train/logprobs = tensor([[-1.5702, -7.7374],
        [-3.5107, -1.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3713030219078064
Epoch 0, Step 1148: train/loss = 0.4178060293197632, train/raw-loss = 0.374304860830307, train/logprobs = tensor([[-1.2202, -2.5454],
        [-2.9325, -1.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43501168489456177
Epoch 0, Step 1149: train/loss = 0.27122753858566284, train/raw-loss = 0.23354700207710266, train/logprobs = tensor([[-1.4181, -5.0300],
        [-2.4562, -1.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3768054246902466
Epoch 0, Step 1150: train/loss = 0.6238809823989868, train/raw-loss = 0.5846705436706543, train/logprobs = tensor([[-3.3377, -4.5930],
        [-3.0997, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3921046555042267
Epoch 0, Step 1151: train/loss = 0.2524102032184601, train/raw-loss = 0.21694599092006683, train/logprobs = tensor([[-0.9662, -5.6641],
        [-3.0539, -2.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3546421229839325
Epoch 0, Step 1152: train/loss = 0.5993251800537109, train/raw-loss = 0.5610248446464539, train/logprobs = tensor([[-1.3530, -2.2763],
        [-1.7150, -1.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830033540725708
Epoch 0, Step 1153: train/loss = 0.14929646253585815, train/raw-loss = 0.11361666023731232, train/logprobs = tensor([[-0.9136, -6.8867],
        [-2.6417, -2.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35679805278778076
Epoch 0, Step 1154: train/loss = 0.5071196556091309, train/raw-loss = 0.47262051701545715, train/logprobs = tensor([[-1.5149, -4.9169],
        [-2.0973, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34499144554138184
Epoch 0, Step 1155: train/loss = 0.38351622223854065, train/raw-loss = 0.34685787558555603, train/logprobs = tensor([[-1.6248, -4.6327],
        [-2.8641, -1.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3665831983089447
Epoch 0, Step 1156: train/loss = 0.13996517658233643, train/raw-loss = 0.0989529937505722, train/logprobs = tensor([[-1.1054, -6.8920],
        [-3.1643, -2.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.410121887922287
Epoch 0, Step 1157: train/loss = 0.3552306294441223, train/raw-loss = 0.31544962525367737, train/logprobs = tensor([[-1.1517, -3.8520],
        [-2.9408, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39781010150909424
Epoch 0, Step 1158: train/loss = 1.0602662563323975, train/raw-loss = 1.024628758430481, train/logprobs = tensor([[-2.6243, -3.2763],
        [-2.4611, -2.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3563753366470337
Epoch 0, Step 1159: train/loss = 0.4443647563457489, train/raw-loss = 0.4061587452888489, train/logprobs = tensor([[-1.6368, -3.6073],
        [-2.4857, -2.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820599913597107
Epoch 0, Step 1160: train/loss = 0.439966082572937, train/raw-loss = 0.40541332960128784, train/logprobs = tensor([[-0.9001, -3.7897],
        [-2.0319, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455280065536499
Epoch 0, Step 1161: train/loss = 0.27062129974365234, train/raw-loss = 0.2352859377861023, train/logprobs = tensor([[-1.5876, -5.2969],
        [-3.0900, -2.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533538579940796
Epoch 0, Step 1162: train/loss = 0.5081127285957336, train/raw-loss = 0.4696118235588074, train/logprobs = tensor([[-1.4499, -2.1203],
        [-2.7601, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38500887155532837
Epoch 0, Step 1163: train/loss = 0.5380464792251587, train/raw-loss = 0.5032301545143127, train/logprobs = tensor([[-3.4199, -6.7705],
        [-3.5386, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3481634557247162
Epoch 0, Step 1164: train/loss = 0.5981118679046631, train/raw-loss = 0.5503822565078735, train/logprobs = tensor([[-1.5827, -3.8256],
        [-3.9290, -2.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4772961139678955
Epoch 0, Step 1165: train/loss = 0.3716546297073364, train/raw-loss = 0.34648334980010986, train/logprobs = tensor([[-0.9669, -4.3182],
        [-1.7416, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25171276926994324
Epoch 0, Step 1166: train/loss = 1.0026631355285645, train/raw-loss = 0.963477373123169, train/logprobs = tensor([[-3.5263, -4.4894],
        [-3.2081, -2.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918587565422058
Epoch 0, Step 1167: train/loss = 0.5378739237785339, train/raw-loss = 0.5028254985809326, train/logprobs = tensor([[-1.0731, -1.7607],
        [-2.2042, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3504842519760132
Epoch 0, Step 1168: train/loss = 0.37711101770401, train/raw-loss = 0.33041617274284363, train/logprobs = tensor([[-2.0205, -7.2390],
        [-2.4473, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4669484496116638
Epoch 0, Step 1169: train/loss = 0.3099577724933624, train/raw-loss = 0.268896222114563, train/logprobs = tensor([[-1.0949, -4.9713],
        [-2.8934, -2.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106155037879944
Epoch 0, Step 1170: train/loss = 0.11885540187358856, train/raw-loss = 0.07867167890071869, train/logprobs = tensor([[-1.2386, -8.5733],
        [-3.5621, -1.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40183722972869873
Epoch 0, Step 1171: train/loss = 0.6254271864891052, train/raw-loss = 0.5921621918678284, train/logprobs = tensor([[-2.8082, -3.1235],
        [-2.9677, -2.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3326496481895447
Epoch 0, Step 1172: train/loss = 0.3978452682495117, train/raw-loss = 0.36546966433525085, train/logprobs = tensor([[-1.7648, -5.0918],
        [-2.6847, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237561583518982
Epoch 0, Step 1173: train/loss = 0.3657495975494385, train/raw-loss = 0.32470938563346863, train/logprobs = tensor([[-1.5730, -4.9980],
        [-3.3667, -2.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4104020595550537
Epoch 0, Step 1174: train/loss = 0.2126331776380539, train/raw-loss = 0.17508681118488312, train/logprobs = tensor([[ -1.3069, -10.7245],
        [ -3.1899,  -2.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.375463604927063
Epoch 0, Step 1175: train/loss = 0.5538682341575623, train/raw-loss = 0.5234466791152954, train/logprobs = tensor([[-1.0427, -3.2240],
        [-1.3669, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30421555042266846
Epoch 0, Step 1176: train/loss = 0.3472651541233063, train/raw-loss = 0.305605947971344, train/logprobs = tensor([[-1.4396, -3.0125],
        [-3.1213, -1.2723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41659218072891235
Epoch 0, Step 1177: train/loss = 0.4613545835018158, train/raw-loss = 0.42719706892967224, train/logprobs = tensor([[-1.3675, -6.0130],
        [-1.8291, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34157538414001465
Epoch 0, Step 1178: train/loss = 0.39639437198638916, train/raw-loss = 0.36653345823287964, train/logprobs = tensor([[-1.5699, -7.3347],
        [-2.1555, -0.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2986087501049042
Epoch 0, Step 1179: train/loss = 0.39405557513237, train/raw-loss = 0.3626469671726227, train/logprobs = tensor([[-0.7690, -3.8888],
        [-2.5050, -1.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31408631801605225
Epoch 0, Step 1180: train/loss = 0.2583165466785431, train/raw-loss = 0.21915243566036224, train/logprobs = tensor([[-0.9541, -5.6728],
        [-2.5285, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3916409909725189
Epoch 0, Step 1181: train/loss = 0.27720192074775696, train/raw-loss = 0.23999065160751343, train/logprobs = tensor([[-1.2121, -7.6276],
        [-2.4295, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721126616001129
Epoch 0, Step 1182: train/loss = 0.7349550724029541, train/raw-loss = 0.6864041090011597, train/logprobs = tensor([[-1.9233, -4.4026],
        [-3.6874, -2.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48550939559936523
Epoch 0, Step 1183: train/loss = 0.33102911710739136, train/raw-loss = 0.2974807024002075, train/logprobs = tensor([[-1.3744, -5.9606],
        [-2.3598, -1.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33548426628112793
Epoch 0, Step 1184: train/loss = 0.28249889612197876, train/raw-loss = 0.2480543702840805, train/logprobs = tensor([[-1.2073, -7.2156],
        [-2.4621, -1.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34444528818130493
Epoch 0, Step 1185: train/loss = 0.8381435871124268, train/raw-loss = 0.8054829239845276, train/logprobs = tensor([[-3.2065, -6.7873],
        [-2.8803, -2.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266061246395111
Epoch 0, Step 1186: train/loss = 0.23958441615104675, train/raw-loss = 0.19710609316825867, train/logprobs = tensor([[-1.9010, -6.6103],
        [-3.0026, -1.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247831404209137
Epoch 0, Step 1187: train/loss = 0.45750176906585693, train/raw-loss = 0.4188472628593445, train/logprobs = tensor([[-1.3229, -3.3874],
        [-2.5103, -1.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3865448534488678
Epoch 0, Step 1188: train/loss = 0.2438194751739502, train/raw-loss = 0.2077130228281021, train/logprobs = tensor([[-1.4628, -4.5264],
        [-2.8271, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610644042491913
Epoch 0, Step 1189: train/loss = 0.5073074698448181, train/raw-loss = 0.4673709571361542, train/logprobs = tensor([[-2.3840, -5.0972],
        [-2.6173, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39936530590057373
Epoch 0, Step 1190: train/loss = 0.3011687695980072, train/raw-loss = 0.25971177220344543, train/logprobs = tensor([[-2.0514, -5.4661],
        [-3.8922, -2.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4145699739456177
Epoch 0, Step 1191: train/loss = 0.3198150396347046, train/raw-loss = 0.28927305340766907, train/logprobs = tensor([[-0.9693, -6.8086],
        [-1.9039, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054198920726776
Epoch 0, Step 1192: train/loss = 0.3689975440502167, train/raw-loss = 0.33749404549598694, train/logprobs = tensor([[-0.7095, -7.5414],
        [-2.6703, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31503501534461975
Epoch 0, Step 1193: train/loss = 0.3356821835041046, train/raw-loss = 0.30488619208335876, train/logprobs = tensor([[-0.7979, -3.9276],
        [-2.0307, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30796027183532715
Epoch 0, Step 1194: train/loss = 0.30065011978149414, train/raw-loss = 0.26629751920700073, train/logprobs = tensor([[-1.0625, -6.9293],
        [-2.0995, -2.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34352609515190125
Epoch 0, Step 1195: train/loss = 0.4415538012981415, train/raw-loss = 0.40621569752693176, train/logprobs = tensor([[-1.5987, -3.6370],
        [-2.5076, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533807098865509
Epoch 0, Step 1196: train/loss = 0.2672579288482666, train/raw-loss = 0.23030495643615723, train/logprobs = tensor([[-1.5520, -6.0115],
        [-3.2748, -1.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3695295751094818
Epoch 0, Step 1197: train/loss = 0.4378190040588379, train/raw-loss = 0.4034443497657776, train/logprobs = tensor([[-2.4678, -4.4625],
        [-2.5437, -1.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437469005584717
Epoch 0, Step 1198: train/loss = 0.4759230613708496, train/raw-loss = 0.4426654577255249, train/logprobs = tensor([[-1.8247, -5.8448],
        [-2.3429, -1.4242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33257609605789185
Epoch 0, Step 1199: train/loss = 0.3120845854282379, train/raw-loss = 0.2802724838256836, train/logprobs = tensor([[-0.7664, -6.2443],
        [-2.0361, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181210160255432
Epoch 0, Step 1200: train/loss = 0.500701904296875, train/raw-loss = 0.457291841506958, train/logprobs = tensor([[-1.3252, -3.1255],
        [-3.3444, -2.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43410056829452515
Epoch 0, Step 1201: train/loss = 0.6470279097557068, train/raw-loss = 0.6171796917915344, train/logprobs = tensor([[-0.9366, -2.8066],
        [-1.9702, -2.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29848238825798035
Epoch 0, Step 1202: train/loss = 0.4661068022251129, train/raw-loss = 0.43150463700294495, train/logprobs = tensor([[-2.3753, -8.8055],
        [-2.5756, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34602195024490356
Epoch 0, Step 1203: train/loss = 0.301028311252594, train/raw-loss = 0.2621423900127411, train/logprobs = tensor([[-1.3252, -5.7829],
        [-2.8582, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3888590931892395
Epoch 0, Step 1204: train/loss = 0.28520798683166504, train/raw-loss = 0.2541320025920868, train/logprobs = tensor([[-0.7552, -5.2716],
        [-1.7807, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107597827911377
Epoch 0, Step 1205: train/loss = 0.35446128249168396, train/raw-loss = 0.3130970895290375, train/logprobs = tensor([[-1.4216, -9.0414],
        [-2.3265, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41364169120788574
Epoch 0, Step 1206: train/loss = 0.5184450149536133, train/raw-loss = 0.4822152554988861, train/logprobs = tensor([[-3.0579, -8.3652],
        [-3.4780, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3622974157333374
Epoch 0, Step 1207: train/loss = 0.5070807337760925, train/raw-loss = 0.4688156843185425, train/logprobs = tensor([[-1.2697, -2.6823],
        [-2.6421, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3826504051685333
Epoch 0, Step 1208: train/loss = 0.39612874388694763, train/raw-loss = 0.3559253513813019, train/logprobs = tensor([[-2.3290, -5.5527],
        [-2.7139, -2.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4020339250564575
Epoch 0, Step 1209: train/loss = 0.3838876485824585, train/raw-loss = 0.34520891308784485, train/logprobs = tensor([[-0.7014, -5.7579],
        [-2.2813, -1.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38678741455078125
Epoch 0, Step 1210: train/loss = 0.3134390711784363, train/raw-loss = 0.2838861048221588, train/logprobs = tensor([[-1.1956, -5.5916],
        [-1.4702, -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29552972316741943
Epoch 0, Step 1211: train/loss = 0.6065312623977661, train/raw-loss = 0.5733680725097656, train/logprobs = tensor([[-1.8622, -4.1692],
        [-1.8038, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33163145184516907
Epoch 0, Step 1212: train/loss = 0.47016751766204834, train/raw-loss = 0.43238043785095215, train/logprobs = tensor([[-1.2727, -4.1609],
        [-1.8743, -1.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778707683086395
Epoch 0, Step 1213: train/loss = 0.39678430557250977, train/raw-loss = 0.3571377694606781, train/logprobs = tensor([[-1.5165, -6.2194],
        [-2.8786, -1.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39646536111831665
Epoch 0, Step 1214: train/loss = 0.5986325144767761, train/raw-loss = 0.5569709539413452, train/logprobs = tensor([[-3.0054, -5.0656],
        [-3.1898, -2.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4166158139705658
Epoch 0, Step 1215: train/loss = 0.12851203978061676, train/raw-loss = 0.0907338559627533, train/logprobs = tensor([[-1.1555, -8.3979],
        [-2.8456, -1.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37778180837631226
Epoch 0, Step 1216: train/loss = 0.12115542590618134, train/raw-loss = 0.08142629265785217, train/logprobs = tensor([[-0.8629, -6.6462],
        [-2.8836, -1.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972911834716797
Epoch 0, Step 1217: train/loss = 0.663632333278656, train/raw-loss = 0.6286174654960632, train/logprobs = tensor([[-0.9762, -1.4965],
        [-2.0158, -2.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35014885663986206
Epoch 0, Step 1218: train/loss = 0.25982484221458435, train/raw-loss = 0.22497957944869995, train/logprobs = tensor([[-0.6827, -7.0141],
        [-3.2482, -2.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484526574611664
Epoch 0, Step 1219: train/loss = 0.2983483672142029, train/raw-loss = 0.2608450651168823, train/logprobs = tensor([[-1.4870, -6.3320],
        [-2.9251, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37503281235694885
Epoch 0, Step 1220: train/loss = 0.9089358448982239, train/raw-loss = 0.8719054460525513, train/logprobs = tensor([[-3.5232, -5.9903],
        [-2.0324, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703044354915619
Epoch 0, Step 1221: train/loss = 0.39131850004196167, train/raw-loss = 0.36216574907302856, train/logprobs = tensor([[-1.5291, -5.1556],
        [-2.5494, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29152774810791016
Epoch 0, Step 1222: train/loss = 0.21412493288516998, train/raw-loss = 0.1799318790435791, train/logprobs = tensor([[-0.9549, -5.0983],
        [-2.7735, -1.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34193065762519836
Epoch 0, Step 1223: train/loss = 0.19352489709854126, train/raw-loss = 0.15838317573070526, train/logprobs = tensor([[-0.8643, -7.6348],
        [-2.3274, -2.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35141727328300476
Epoch 0, Step 1224: train/loss = 0.5719343423843384, train/raw-loss = 0.5330257415771484, train/logprobs = tensor([[-2.4814, -6.7450],
        [-2.4761, -1.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3890863358974457
Epoch 0, Step 1225: train/loss = 0.4184102416038513, train/raw-loss = 0.37568145990371704, train/logprobs = tensor([[-1.1333, -7.3046],
        [-2.2778, -2.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42728757858276367
Epoch 0, Step 1226: train/loss = 0.41618669033050537, train/raw-loss = 0.38430818915367126, train/logprobs = tensor([[-0.8051, -3.8388],
        [-1.7099, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31878507137298584
Epoch 0, Step 1227: train/loss = 0.5328565239906311, train/raw-loss = 0.49747994542121887, train/logprobs = tensor([[-1.7814, -4.7803],
        [-2.1330, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35376593470573425
Epoch 0, Step 1228: train/loss = 0.22446651756763458, train/raw-loss = 0.18774527311325073, train/logprobs = tensor([[-1.3434, -4.1391],
        [-3.0439, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672125041484833
Epoch 0, Step 1229: train/loss = 0.2809053063392639, train/raw-loss = 0.24214774370193481, train/logprobs = tensor([[-0.9977, -5.3745],
        [-2.8972, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38757556676864624
Epoch 0, Step 1230: train/loss = 0.34588178992271423, train/raw-loss = 0.3057135045528412, train/logprobs = tensor([[-1.3961, -4.2136],
        [-2.9906, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4016830027103424
Epoch 0, Step 1231: train/loss = 0.47590282559394836, train/raw-loss = 0.438111811876297, train/logprobs = tensor([[-1.1944, -4.5654],
        [-3.0230, -2.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37790995836257935
Epoch 0, Step 1232: train/loss = 0.5637133717536926, train/raw-loss = 0.5296726822853088, train/logprobs = tensor([[-2.1006, -5.9742],
        [-3.4095, -1.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404066264629364
Epoch 0, Step 1233: train/loss = 0.4008893072605133, train/raw-loss = 0.36527103185653687, train/logprobs = tensor([[-1.0589, -4.5954],
        [-2.2030, -1.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35618287324905396
Epoch 0, Step 1234: train/loss = 0.07613220810890198, train/raw-loss = 0.04150402918457985, train/logprobs = tensor([[-0.9431, -8.1413],
        [-3.4781, -0.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462817966938019
Epoch 0, Step 1235: train/loss = 0.4360317885875702, train/raw-loss = 0.4038494825363159, train/logprobs = tensor([[-0.9000, -3.4404],
        [-2.2367, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218231201171875
Epoch 0, Step 1236: train/loss = 0.2687729597091675, train/raw-loss = 0.23943597078323364, train/logprobs = tensor([[-0.8829, -5.1077],
        [-2.4558, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933697998523712
Epoch 0, Step 1237: train/loss = 0.6789809465408325, train/raw-loss = 0.6376721262931824, train/logprobs = tensor([[-1.4716, -2.6601],
        [-3.1321, -3.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41308826208114624
Epoch 0, Step 1238: train/loss = 0.1492287516593933, train/raw-loss = 0.11599939316511154, train/logprobs = tensor([[-1.6736, -4.7075],
        [-3.5102, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322935402393341
Epoch 0, Step 1239: train/loss = 0.5552760362625122, train/raw-loss = 0.5120667219161987, train/logprobs = tensor([[-1.5804, -2.9476],
        [-3.1742, -1.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4320935606956482
Epoch 0, Step 1240: train/loss = 0.680443286895752, train/raw-loss = 0.6408072710037231, train/logprobs = tensor([[-1.1946, -2.9767],
        [-2.5124, -2.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39636093378067017
Epoch 0, Step 1241: train/loss = 0.42867058515548706, train/raw-loss = 0.39036065340042114, train/logprobs = tensor([[-1.4089, -4.5312],
        [-2.4533, -2.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830992877483368
Epoch 0, Step 1242: train/loss = 0.2925598919391632, train/raw-loss = 0.2536112666130066, train/logprobs = tensor([[-1.7925, -4.0885],
        [-3.8185, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38948625326156616
Epoch 0, Step 1243: train/loss = 0.5335690975189209, train/raw-loss = 0.4956643581390381, train/logprobs = tensor([[-1.7438, -3.8721],
        [-3.2201, -2.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37904757261276245
Epoch 0, Step 1244: train/loss = 0.4297916293144226, train/raw-loss = 0.39423224329948425, train/logprobs = tensor([[-1.7869, -6.1999],
        [-3.0351, -2.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35559383034706116
Epoch 0, Step 1245: train/loss = 0.15029476583003998, train/raw-loss = 0.11139675974845886, train/logprobs = tensor([[-1.6111, -8.2243],
        [-3.5644, -1.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38898012042045593
Epoch 0, Step 1246: train/loss = 0.1591624617576599, train/raw-loss = 0.12486965954303741, train/logprobs = tensor([[ -1.6842, -10.6182],
        [ -3.3666,  -2.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34292808175086975
Epoch 0, Step 1247: train/loss = 0.21730998158454895, train/raw-loss = 0.175633504986763, train/logprobs = tensor([[-1.6355, -6.2182],
        [-3.9210, -1.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4167648255825043
Epoch 0, Step 1248: train/loss = 0.06233227252960205, train/raw-loss = 0.026347346603870392, train/logprobs = tensor([[ -1.4071, -12.7175],
        [ -4.9133,  -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598492741584778
Epoch 0, Step 1249: train/loss = 0.4083624482154846, train/raw-loss = 0.37757012248039246, train/logprobs = tensor([[-1.9251, -4.1858],
        [-2.5857, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079233169555664
Epoch 0, Step 1250: train/loss = 0.17462000250816345, train/raw-loss = 0.13222335278987885, train/logprobs = tensor([[-1.1985, -6.0658],
        [-4.0948, -2.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42396658658981323
Epoch 0, Step 1251: train/loss = 0.31608134508132935, train/raw-loss = 0.2743276059627533, train/logprobs = tensor([[-1.2920, -6.6729],
        [-3.5984, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175371825695038
Epoch 0, Step 1252: train/loss = 0.33901822566986084, train/raw-loss = 0.2985488772392273, train/logprobs = tensor([[-1.1164, -7.3968],
        [-3.5284, -1.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40469348430633545
Epoch 0, Step 1253: train/loss = 0.23219645023345947, train/raw-loss = 0.18792463839054108, train/logprobs = tensor([[-1.7833, -6.1820],
        [-3.5921, -2.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44271811842918396
Epoch 0, Step 1254: train/loss = 0.42773163318634033, train/raw-loss = 0.3875371515750885, train/logprobs = tensor([[-1.2861, -3.2540],
        [-2.9072, -2.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40194499492645264
Epoch 0, Step 1255: train/loss = 0.2557098865509033, train/raw-loss = 0.2172447144985199, train/logprobs = tensor([[-1.1496, -7.6050],
        [-2.9635, -1.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846517503261566
Epoch 0, Step 1256: train/loss = 0.2697073817253113, train/raw-loss = 0.23390540480613708, train/logprobs = tensor([[-1.2172, -7.1554],
        [-2.9647, -2.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35801979899406433
Epoch 0, Step 1257: train/loss = 0.34012937545776367, train/raw-loss = 0.3000320494174957, train/logprobs = tensor([[-1.2631, -4.0100],
        [-3.7967, -1.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40097305178642273
Epoch 0, Step 1258: train/loss = 0.3924640119075775, train/raw-loss = 0.353781521320343, train/logprobs = tensor([[-1.5665, -3.1442],
        [-3.4654, -1.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38682472705841064
Epoch 0, Step 1259: train/loss = 0.36346694827079773, train/raw-loss = 0.3299890160560608, train/logprobs = tensor([[-0.7320, -6.7563],
        [-2.1618, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33477914333343506
Epoch 0, Step 1260: train/loss = 0.30197301506996155, train/raw-loss = 0.2633901536464691, train/logprobs = tensor([[-1.3527, -5.8628],
        [-4.1764, -2.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858286738395691
Epoch 0, Step 1261: train/loss = 0.3646894693374634, train/raw-loss = 0.32678788900375366, train/logprobs = tensor([[-1.2107, -5.2249],
        [-2.9993, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3790159225463867
Epoch 0, Step 1262: train/loss = 0.3957430124282837, train/raw-loss = 0.3545985519886017, train/logprobs = tensor([[-0.9240, -8.0192],
        [-3.4213, -1.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4114447832107544
Epoch 0, Step 1263: train/loss = 0.7554014921188354, train/raw-loss = 0.7176549434661865, train/logprobs = tensor([[-1.2194, -1.5487],
        [-2.3439, -2.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37746602296829224
Epoch 0, Step 1264: train/loss = 0.59453284740448, train/raw-loss = 0.5517331957817078, train/logprobs = tensor([[-1.8280, -3.6690],
        [-3.7029, -2.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42799630761146545
Epoch 0, Step 1265: train/loss = 0.3992585241794586, train/raw-loss = 0.358172208070755, train/logprobs = tensor([[-1.1598, -5.1461],
        [-3.5604, -2.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41086333990097046
Epoch 0, Step 1266: train/loss = 0.16891148686408997, train/raw-loss = 0.13070742785930634, train/logprobs = tensor([[-1.2139, -7.2592],
        [-3.5359, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820403814315796
Epoch 0, Step 1267: train/loss = 0.34376758337020874, train/raw-loss = 0.30770984292030334, train/logprobs = tensor([[-1.2407, -5.0122],
        [-3.3862, -1.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3605772852897644
Epoch 0, Step 1268: train/loss = 0.13995502889156342, train/raw-loss = 0.10363589972257614, train/logprobs = tensor([[-1.0598, -7.1065],
        [-4.8507, -3.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3631913661956787
Epoch 0, Step 1269: train/loss = 0.16683977842330933, train/raw-loss = 0.1370771825313568, train/logprobs = tensor([[-1.5809, -6.0234],
        [-3.5869, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297625869512558
Epoch 0, Step 1270: train/loss = 0.339705228805542, train/raw-loss = 0.30012914538383484, train/logprobs = tensor([[-1.9874, -5.5446],
        [-3.3991, -2.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39576083421707153
Epoch 0, Step 1271: train/loss = 0.2631375193595886, train/raw-loss = 0.2260405719280243, train/logprobs = tensor([[-2.3148, -4.8967],
        [-3.4674, -1.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37096965312957764
Epoch 0, Step 1272: train/loss = 0.20331211388111115, train/raw-loss = 0.17029264569282532, train/logprobs = tensor([[-1.2298, -5.2544],
        [-3.1275, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3301946520805359
Epoch 0, Step 1273: train/loss = 0.5501098036766052, train/raw-loss = 0.5133280158042908, train/logprobs = tensor([[-1.3408, -3.8681],
        [-2.7100, -2.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36781826615333557
Epoch 0, Step 1274: train/loss = 0.08462882786989212, train/raw-loss = 0.05035119876265526, train/logprobs = tensor([[-1.1544, -9.8333],
        [-3.5202, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34277623891830444
Epoch 0, Step 1275: train/loss = 0.33473214507102966, train/raw-loss = 0.28948861360549927, train/logprobs = tensor([[-1.0876, -3.7623],
        [-3.1812, -1.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524350166320801
Epoch 0, Step 1276: train/loss = 0.33735695481300354, train/raw-loss = 0.2895447015762329, train/logprobs = tensor([[-1.3536, -3.5310],
        [-3.8344, -2.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47812262177467346
Epoch 0, Step 1277: train/loss = 0.668289065361023, train/raw-loss = 0.6308619976043701, train/logprobs = tensor([[-1.2089, -2.1242],
        [-3.2396, -2.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.374271035194397
Epoch 0, Step 1278: train/loss = 0.29460781812667847, train/raw-loss = 0.25959569215774536, train/logprobs = tensor([[-1.4271, -5.4636],
        [-2.6755, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3501214385032654
Epoch 0, Step 1279: train/loss = 0.4624595642089844, train/raw-loss = 0.41582825779914856, train/logprobs = tensor([[-1.2753, -3.3129],
        [-4.6717, -3.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46631309390068054
Epoch 0, Step 1280: train/loss = 0.21415990591049194, train/raw-loss = 0.16606789827346802, train/logprobs = tensor([[-2.4892, -5.0813],
        [-4.9422, -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48092007637023926
Epoch 0, Step 1281: train/loss = 0.1406715214252472, train/raw-loss = 0.10013816505670547, train/logprobs = tensor([[-1.4152, -6.8003],
        [-4.2636, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40533360838890076
Epoch 0, Step 1282: train/loss = 0.329181432723999, train/raw-loss = 0.2912079095840454, train/logprobs = tensor([[-1.9214, -4.0590],
        [-4.5246, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37973514199256897
Epoch 0, Step 1283: train/loss = 0.15718810260295868, train/raw-loss = 0.12201114743947983, train/logprobs = tensor([[-1.2230, -7.0579],
        [-2.7796, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517696261405945
Epoch 0, Step 1284: train/loss = 0.6281656622886658, train/raw-loss = 0.5898623466491699, train/logprobs = tensor([[-2.0633, -7.6785],
        [-3.4544, -1.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38303250074386597
Epoch 0, Step 1285: train/loss = 0.5457121729850769, train/raw-loss = 0.5057584047317505, train/logprobs = tensor([[-0.9685, -2.5209],
        [-3.8578, -1.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39953771233558655
Epoch 0, Step 1286: train/loss = 0.13892102241516113, train/raw-loss = 0.10702896118164062, train/logprobs = tensor([[-0.9563, -5.5626],
        [-2.9853, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31892067193984985
Epoch 0, Step 1287: train/loss = 0.33292776346206665, train/raw-loss = 0.29691505432128906, train/logprobs = tensor([[-1.3890, -5.0296],
        [-3.3904, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601270914077759
Epoch 0, Step 1288: train/loss = 0.3262140154838562, train/raw-loss = 0.28576385974884033, train/logprobs = tensor([[-1.1252, -4.3975],
        [-3.2948, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4045012593269348
Epoch 0, Step 1289: train/loss = 0.3308529853820801, train/raw-loss = 0.30167919397354126, train/logprobs = tensor([[-1.0953, -3.7354],
        [-2.3181, -1.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29173794388771057
Epoch 0, Step 1290: train/loss = 0.4428684711456299, train/raw-loss = 0.4040328860282898, train/logprobs = tensor([[-1.0944, -5.0119],
        [-3.2783, -2.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38835570216178894
Epoch 0, Step 1291: train/loss = 0.1579846739768982, train/raw-loss = 0.112598717212677, train/logprobs = tensor([[-1.5526, -5.3495],
        [-4.6128, -1.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45385944843292236
Epoch 0, Step 1292: train/loss = 0.30602753162384033, train/raw-loss = 0.26867976784706116, train/logprobs = tensor([[-1.7276, -8.2350],
        [-3.8304, -1.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37347736954689026
Epoch 0, Step 1293: train/loss = 0.47866106033325195, train/raw-loss = 0.437300443649292, train/logprobs = tensor([[-0.9169, -6.3289],
        [-3.4903, -1.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136057496070862
Epoch 0, Step 1294: train/loss = 0.15060484409332275, train/raw-loss = 0.10954645276069641, train/logprobs = tensor([[-0.8831, -7.9999],
        [-3.3451, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105837643146515
Epoch 0, Step 1295: train/loss = 0.8709011673927307, train/raw-loss = 0.8308846950531006, train/logprobs = tensor([[-1.8724, -2.2950],
        [-2.4570, -2.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4001644253730774
Epoch 0, Step 1296: train/loss = 0.514912486076355, train/raw-loss = 0.47452762722969055, train/logprobs = tensor([[-1.2432, -2.4247],
        [-3.3336, -2.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4038482904434204
Epoch 0, Step 1297: train/loss = 0.5471599102020264, train/raw-loss = 0.5005593299865723, train/logprobs = tensor([[-1.3814, -4.4070],
        [-3.8069, -2.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660053849220276
Epoch 0, Step 1298: train/loss = 0.6067995429039001, train/raw-loss = 0.5601934790611267, train/logprobs = tensor([[-1.5349, -2.6045],
        [-4.5842, -3.5690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660608172416687
Epoch 0, Step 1299: train/loss = 0.7101168036460876, train/raw-loss = 0.6695747375488281, train/logprobs = tensor([[-1.9972, -7.0825],
        [-3.5898, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4054211974143982
Epoch 0, Step 1300: train/loss = 0.34977585077285767, train/raw-loss = 0.30854809284210205, train/logprobs = tensor([[-1.4212, -5.0753],
        [-4.1618, -1.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122777283191681
Epoch 0, Step 1301: train/loss = 0.3235648274421692, train/raw-loss = 0.27835240960121155, train/logprobs = tensor([[-1.3332, -4.5898],
        [-3.3063, -1.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4521244466304779
Epoch 0, Step 1302: train/loss = 0.7986259460449219, train/raw-loss = 0.7588129043579102, train/logprobs = tensor([[-1.1799, -3.1392],
        [-3.2644, -3.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39812996983528137
Epoch 0, Step 1303: train/loss = 0.3776549994945526, train/raw-loss = 0.3411491811275482, train/logprobs = tensor([[-1.5931, -3.1989],
        [-3.5773, -1.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650577664375305
Epoch 0, Step 1304: train/loss = 0.482049822807312, train/raw-loss = 0.43949079513549805, train/logprobs = tensor([[-2.0118, -3.7013],
        [-4.0301, -1.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42559051513671875
Epoch 0, Step 1305: train/loss = 0.3355964422225952, train/raw-loss = 0.2971366047859192, train/logprobs = tensor([[-1.0015, -5.1581],
        [-2.9597, -1.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3845981955528259
Epoch 0, Step 1306: train/loss = 0.35500332713127136, train/raw-loss = 0.3093673288822174, train/logprobs = tensor([[-1.5214, -4.2279],
        [-4.6436, -2.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45635998249053955
Epoch 0, Step 1307: train/loss = 0.5526699423789978, train/raw-loss = 0.5157892107963562, train/logprobs = tensor([[-1.2298, -2.7219],
        [-3.1068, -2.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3688068091869354
Epoch 0, Step 1308: train/loss = 0.2743328809738159, train/raw-loss = 0.2426423877477646, train/logprobs = tensor([[-0.8773, -6.4559],
        [-2.8350, -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169049918651581
Epoch 0, Step 1309: train/loss = 0.5669183731079102, train/raw-loss = 0.5229008197784424, train/logprobs = tensor([[-1.5004, -3.0805],
        [-3.1656, -3.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4401755928993225
Epoch 0, Step 1310: train/loss = 0.21443095803260803, train/raw-loss = 0.1700763702392578, train/logprobs = tensor([[-1.8996, -8.9744],
        [-4.7600, -1.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443545937538147
Epoch 0, Step 1311: train/loss = 0.5769701600074768, train/raw-loss = 0.5296480059623718, train/logprobs = tensor([[-1.0442, -4.0218],
        [-3.3039, -2.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47322189807891846
Epoch 0, Step 1312: train/loss = 0.2901386618614197, train/raw-loss = 0.25495409965515137, train/logprobs = tensor([[-1.5077, -6.5341],
        [-3.4436, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3518456518650055
Epoch 0, Step 1313: train/loss = 0.1921449899673462, train/raw-loss = 0.15170849859714508, train/logprobs = tensor([[-1.6145, -6.3742],
        [-4.0265, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40436482429504395
Epoch 0, Step 1314: train/loss = 0.8396136164665222, train/raw-loss = 0.801002562046051, train/logprobs = tensor([[-1.9817, -2.9379],
        [-2.8976, -2.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3861103653907776
Epoch 0, Step 1315: train/loss = 0.5413138270378113, train/raw-loss = 0.49918168783187866, train/logprobs = tensor([[-0.8152, -2.9428],
        [-2.8361, -1.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4213215112686157
Epoch 0, Step 1316: train/loss = 0.31092244386672974, train/raw-loss = 0.2740100920200348, train/logprobs = tensor([[-1.1697, -3.7455],
        [-3.2418, -1.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691234886646271
Epoch 0, Step 1317: train/loss = 0.40554553270339966, train/raw-loss = 0.3630678653717041, train/logprobs = tensor([[-1.6809, -4.7454],
        [-3.9181, -2.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247765839099884
Epoch 0, Step 1318: train/loss = 0.3043053448200226, train/raw-loss = 0.2668222188949585, train/logprobs = tensor([[-1.6441, -5.8546],
        [-3.0828, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37483125925064087
Epoch 0, Step 1319: train/loss = 0.26069900393486023, train/raw-loss = 0.2274424284696579, train/logprobs = tensor([[-1.1845, -5.3520],
        [-2.9134, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33256590366363525
Epoch 0, Step 1320: train/loss = 0.2973681092262268, train/raw-loss = 0.25469696521759033, train/logprobs = tensor([[-1.5421, -6.2013],
        [-3.7417, -2.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4267115592956543
Epoch 0, Step 1321: train/loss = 0.3540639281272888, train/raw-loss = 0.3168032765388489, train/logprobs = tensor([[-1.2056, -2.6956],
        [-3.8517, -1.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726063370704651
Epoch 0, Step 1322: train/loss = 0.5326410531997681, train/raw-loss = 0.49166369438171387, train/logprobs = tensor([[-1.1309, -4.7240],
        [-3.2465, -2.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4097740054130554
Epoch 0, Step 1323: train/loss = 0.3319644331932068, train/raw-loss = 0.2968246340751648, train/logprobs = tensor([[-0.8554, -2.2315],
        [-4.2188, -1.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513980507850647
Epoch 0, Step 1324: train/loss = 0.20056967437267303, train/raw-loss = 0.16746577620506287, train/logprobs = tensor([[-1.6289, -9.6427],
        [-2.8525, -0.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310388922691345
Epoch 0, Step 1325: train/loss = 0.2914941906929016, train/raw-loss = 0.2462162971496582, train/logprobs = tensor([[-1.7211, -3.8638],
        [-3.5478, -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45277857780456543
Epoch 0, Step 1326: train/loss = 0.6471678018569946, train/raw-loss = 0.6114831566810608, train/logprobs = tensor([[-2.2237, -3.9030],
        [-3.0603, -2.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568466901779175
Epoch 0, Step 1327: train/loss = 0.374653697013855, train/raw-loss = 0.33196571469306946, train/logprobs = tensor([[-1.2387, -6.1872],
        [-3.0795, -2.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42687976360321045
Epoch 0, Step 1328: train/loss = 0.3163555860519409, train/raw-loss = 0.2757008671760559, train/logprobs = tensor([[-0.9624, -3.2720],
        [-3.3505, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40654730796813965
Epoch 0, Step 1329: train/loss = 0.20614533126354218, train/raw-loss = 0.17114555835723877, train/logprobs = tensor([[-1.2038, -5.2906],
        [-2.4007, -0.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34999772906303406
Epoch 0, Step 1330: train/loss = 0.21378736197948456, train/raw-loss = 0.17892244458198547, train/logprobs = tensor([[-1.3274, -7.0259],
        [-3.0407, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486490845680237
Epoch 0, Step 1331: train/loss = 0.1106942817568779, train/raw-loss = 0.06370706856250763, train/logprobs = tensor([[-1.3353, -5.1668],
        [-3.8084, -1.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46987205743789673
Epoch 0, Step 1332: train/loss = 0.3851025104522705, train/raw-loss = 0.3434021770954132, train/logprobs = tensor([[-1.4344, -3.0581],
        [-3.3393, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.417003333568573
Epoch 0, Step 1333: train/loss = 0.25687533617019653, train/raw-loss = 0.2157226800918579, train/logprobs = tensor([[-2.4501, -8.5045],
        [-4.4376, -2.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4115263819694519
Epoch 0, Step 1334: train/loss = 0.6032487750053406, train/raw-loss = 0.5686598420143127, train/logprobs = tensor([[-1.5704, -1.3075],
        [-2.6311, -1.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3458893895149231
Epoch 0, Step 1335: train/loss = 0.3160786032676697, train/raw-loss = 0.2786269187927246, train/logprobs = tensor([[-1.1000, -4.4658],
        [-3.7846, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3745168447494507
Epoch 0, Step 1336: train/loss = 0.45404040813446045, train/raw-loss = 0.4235724210739136, train/logprobs = tensor([[-0.9721, -6.7573],
        [-2.3768, -1.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30467963218688965
Epoch 0, Step 1337: train/loss = 0.3075736165046692, train/raw-loss = 0.27238693833351135, train/logprobs = tensor([[-1.1913, -8.1269],
        [-3.1145, -1.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35186702013015747
Epoch 0, Step 1338: train/loss = 0.2661703824996948, train/raw-loss = 0.22852787375450134, train/logprobs = tensor([[-1.1825, -7.5488],
        [-2.8753, -2.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37642502784729004
Epoch 0, Step 1339: train/loss = 0.31323835253715515, train/raw-loss = 0.2744799554347992, train/logprobs = tensor([[-1.3538, -4.7841],
        [-3.0186, -2.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875839114189148
Epoch 0, Step 1340: train/loss = 0.9469327926635742, train/raw-loss = 0.9086109399795532, train/logprobs = tensor([[-2.7553, -9.5800],
        [-2.2866, -2.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38321763277053833
Epoch 0, Step 1341: train/loss = 0.3203805685043335, train/raw-loss = 0.28379547595977783, train/logprobs = tensor([[-1.2961, -8.6541],
        [-3.6073, -1.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3658510446548462
Epoch 0, Step 1342: train/loss = 0.22900743782520294, train/raw-loss = 0.19291375577449799, train/logprobs = tensor([[-1.2394, -3.8841],
        [-3.1565, -1.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36093682050704956
Epoch 0, Step 1343: train/loss = 0.3530464172363281, train/raw-loss = 0.30963805317878723, train/logprobs = tensor([[-1.7296, -3.6795],
        [-3.0656, -1.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4340839385986328
Epoch 0, Step 1344: train/loss = 0.20270481705665588, train/raw-loss = 0.15670539438724518, train/logprobs = tensor([[-1.2801, -6.5182],
        [-4.0472, -3.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4599943161010742
Epoch 0, Step 1345: train/loss = 0.25386515259742737, train/raw-loss = 0.2145218849182129, train/logprobs = tensor([[-1.2000, -5.9620],
        [-3.4389, -2.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3934326767921448
Epoch 0, Step 1346: train/loss = 0.22907119989395142, train/raw-loss = 0.19244235754013062, train/logprobs = tensor([[-1.6653, -9.7662],
        [-3.2136, -1.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36628836393356323
Epoch 0, Step 1347: train/loss = 0.5633333325386047, train/raw-loss = 0.5285628437995911, train/logprobs = tensor([[-1.2067, -5.8495],
        [-2.6528, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477054238319397
Epoch 0, Step 1348: train/loss = 0.41625794768333435, train/raw-loss = 0.36862629652023315, train/logprobs = tensor([[-1.2550, -5.7115],
        [-4.0457, -2.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4763163924217224
Epoch 0, Step 1349: train/loss = 0.3541327714920044, train/raw-loss = 0.31891244649887085, train/logprobs = tensor([[-1.0105, -5.7584],
        [-3.4890, -1.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522035777568817
Epoch 0, Step 1350: train/loss = 0.28724032640457153, train/raw-loss = 0.2582307457923889, train/logprobs = tensor([[-0.9709, -5.2209],
        [-1.5399, -1.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900956869125366
Epoch 0, Step 1351: train/loss = 0.43641626834869385, train/raw-loss = 0.3943495750427246, train/logprobs = tensor([[-1.5404, -4.4724],
        [-4.4748, -2.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42066681385040283
Epoch 0, Step 1352: train/loss = 0.6188064217567444, train/raw-loss = 0.583011269569397, train/logprobs = tensor([[-1.1893, -2.1877],
        [-2.7687, -1.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579515814781189
Epoch 0, Step 1353: train/loss = 0.31193801760673523, train/raw-loss = 0.2772826552391052, train/logprobs = tensor([[-2.1542, -7.6269],
        [-2.9823, -2.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34655362367630005
Epoch 0, Step 1354: train/loss = 0.27740105986595154, train/raw-loss = 0.23734760284423828, train/logprobs = tensor([[-1.0793, -6.9452],
        [-3.6508, -2.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40053480863571167
Epoch 0, Step 1355: train/loss = 0.411141574382782, train/raw-loss = 0.3663412034511566, train/logprobs = tensor([[-1.3979, -4.8079],
        [-3.5878, -1.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4480038583278656
Epoch 0, Step 1356: train/loss = 0.6302988529205322, train/raw-loss = 0.6033037304878235, train/logprobs = tensor([[-2.6647, -9.5224],
        [-1.7808, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26995140314102173
Epoch 0, Step 1357: train/loss = 0.4824376702308655, train/raw-loss = 0.4398985803127289, train/logprobs = tensor([[-0.9966, -4.7330],
        [-3.3143, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42539095878601074
Epoch 0, Step 1358: train/loss = 0.4239186942577362, train/raw-loss = 0.37521687150001526, train/logprobs = tensor([[-1.5405, -3.9534],
        [-3.7982, -2.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4870184659957886
Epoch 0, Step 1359: train/loss = 0.26579219102859497, train/raw-loss = 0.22398976981639862, train/logprobs = tensor([[-1.8166, -6.8931],
        [-3.8490, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4180242419242859
Epoch 0, Step 1360: train/loss = 0.3553939759731293, train/raw-loss = 0.31620222330093384, train/logprobs = tensor([[-1.2462, -3.3671],
        [-3.3640, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919171690940857
Epoch 0, Step 1361: train/loss = 0.5288661122322083, train/raw-loss = 0.49059146642684937, train/logprobs = tensor([[-1.7914, -2.9669],
        [-3.1007, -2.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38274645805358887
Epoch 0, Step 1362: train/loss = 0.25429853796958923, train/raw-loss = 0.21807779371738434, train/logprobs = tensor([[-1.2235, -4.1199],
        [-3.7200, -1.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3622075319290161
Epoch 0, Step 1363: train/loss = 0.3991190493106842, train/raw-loss = 0.3559405207633972, train/logprobs = tensor([[-1.2797, -4.2706],
        [-3.5347, -2.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4317854642868042
Epoch 0, Step 1364: train/loss = 0.68672776222229, train/raw-loss = 0.6439575552940369, train/logprobs = tensor([[-2.1335, -6.2799],
        [-2.9054, -2.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42770254611968994
Epoch 0, Step 1365: train/loss = 0.8693692684173584, train/raw-loss = 0.8278365135192871, train/logprobs = tensor([[-1.3454, -1.5732],
        [-2.9661, -2.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41532814502716064
Epoch 0, Step 1366: train/loss = 0.23569294810295105, train/raw-loss = 0.20551656186580658, train/logprobs = tensor([[-1.3410, -9.8153],
        [-3.1877, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30176371335983276
Epoch 0, Step 1367: train/loss = 1.1702367067337036, train/raw-loss = 1.1165584325790405, train/logprobs = tensor([[-2.8364, -3.6537],
        [-2.5387, -2.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5367818474769592
Epoch 0, Step 1368: train/loss = 0.5006310939788818, train/raw-loss = 0.4640243351459503, train/logprobs = tensor([[-0.9209, -3.0444],
        [-2.9013, -1.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36606770753860474
Epoch 0, Step 1369: train/loss = 0.8938683271408081, train/raw-loss = 0.8523009419441223, train/logprobs = tensor([[-1.7678, -2.4611],
        [-2.4892, -2.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4156739413738251
Epoch 0, Step 1370: train/loss = 0.17584624886512756, train/raw-loss = 0.13981503248214722, train/logprobs = tensor([[-1.1268, -6.1664],
        [-3.6949, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3603120744228363
Epoch 0, Step 1371: train/loss = 0.47740277647972107, train/raw-loss = 0.4372963011264801, train/logprobs = tensor([[-2.9984, -6.8486],
        [-3.6293, -1.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010649025440216
Epoch 0, Step 1372: train/loss = 0.4273286461830139, train/raw-loss = 0.38303419947624207, train/logprobs = tensor([[-1.8108, -4.5323],
        [-3.8891, -2.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429439306259155
Epoch 0, Step 1373: train/loss = 0.5385429263114929, train/raw-loss = 0.5009918212890625, train/logprobs = tensor([[-2.4892, -7.7915],
        [-2.4081, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37551113963127136
Epoch 0, Step 1374: train/loss = 0.4341323971748352, train/raw-loss = 0.3888920545578003, train/logprobs = tensor([[-1.1748, -2.1810],
        [-3.2081, -2.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524035155773163
Epoch 0, Step 1375: train/loss = 0.3308061957359314, train/raw-loss = 0.28439971804618835, train/logprobs = tensor([[-1.4077, -4.1141],
        [-3.5065, -1.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640645980834961
Epoch 0, Step 1376: train/loss = 0.6534041166305542, train/raw-loss = 0.6182563304901123, train/logprobs = tensor([[-1.4613, -1.8014],
        [-2.4060, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514775037765503
Epoch 0, Step 1377: train/loss = 0.3249785602092743, train/raw-loss = 0.29247528314590454, train/logprobs = tensor([[-1.6707, -5.6630],
        [-3.1058, -2.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32503244280815125
Epoch 0, Step 1378: train/loss = 0.35075658559799194, train/raw-loss = 0.30902597308158875, train/logprobs = tensor([[-2.4209, -8.0210],
        [-3.7193, -1.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4173060655593872
Epoch 0, Step 1379: train/loss = 0.27174586057662964, train/raw-loss = 0.23423554003238678, train/logprobs = tensor([[-1.2209, -4.9204],
        [-3.5663, -2.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751029968261719
Epoch 0, Step 1380: train/loss = 0.29329559206962585, train/raw-loss = 0.2561880946159363, train/logprobs = tensor([[-1.7387, -3.9604],
        [-3.7683, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37107494473457336
Epoch 0, Step 1381: train/loss = 0.38610002398490906, train/raw-loss = 0.3461068272590637, train/logprobs = tensor([[-1.7945, -6.5484],
        [-3.1862, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39993196725845337
Epoch 0, Step 1382: train/loss = 0.2645893692970276, train/raw-loss = 0.22189664840698242, train/logprobs = tensor([[-1.0389, -5.8525],
        [-2.9191, -2.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42692703008651733
Epoch 0, Step 1383: train/loss = 0.4469408690929413, train/raw-loss = 0.40707045793533325, train/logprobs = tensor([[-1.2779, -2.9676],
        [-3.0424, -2.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39870402216911316
Epoch 0, Step 1384: train/loss = 0.6240615844726562, train/raw-loss = 0.5823097229003906, train/logprobs = tensor([[-1.1855, -5.0691],
        [-3.3663, -2.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41751885414123535
Epoch 0, Step 1385: train/loss = 0.21325936913490295, train/raw-loss = 0.17696188390254974, train/logprobs = tensor([[-1.3868, -6.0105],
        [-2.6907, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36297497153282166
Epoch 0, Step 1386: train/loss = 0.2818729877471924, train/raw-loss = 0.23451271653175354, train/logprobs = tensor([[-1.1452, -5.5027],
        [-3.5993, -2.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47360315918922424
Epoch 0, Step 1387: train/loss = 0.5099197030067444, train/raw-loss = 0.469936728477478, train/logprobs = tensor([[-1.5948, -3.8828],
        [-3.8869, -2.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998301327228546
Epoch 0, Step 1388: train/loss = 0.5765169262886047, train/raw-loss = 0.5289175510406494, train/logprobs = tensor([[-1.2894, -4.0341],
        [-3.5052, -2.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4759930372238159
Epoch 0, Step 1389: train/loss = 0.5913615226745605, train/raw-loss = 0.5549854040145874, train/logprobs = tensor([[-1.8856, -3.4005],
        [-2.6034, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36376163363456726
Epoch 0, Step 1390: train/loss = 0.18171805143356323, train/raw-loss = 0.14798177778720856, train/logprobs = tensor([[ -1.7528, -13.0434],
        [ -3.5122,  -1.2894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33736279606819153
Epoch 0, Step 1391: train/loss = 0.3793501555919647, train/raw-loss = 0.3432481586933136, train/logprobs = tensor([[-1.5304, -6.1266],
        [-3.6813, -2.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610196113586426
Epoch 0, Step 1392: train/loss = 0.11938512325286865, train/raw-loss = 0.07662323117256165, train/logprobs = tensor([[-1.6360, -5.2873],
        [-4.2469, -0.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42761892080307007
Epoch 0, Step 1393: train/loss = 0.4906378388404846, train/raw-loss = 0.449721097946167, train/logprobs = tensor([[-1.1437, -1.9881],
        [-2.8487, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4091675281524658
Epoch 0, Step 1394: train/loss = 0.7066062688827515, train/raw-loss = 0.6760596036911011, train/logprobs = tensor([[-2.1667, -4.1916],
        [-1.5709, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30546700954437256
Epoch 0, Step 1395: train/loss = 0.2643476128578186, train/raw-loss = 0.2276921421289444, train/logprobs = tensor([[-1.4686, -6.5769],
        [-2.6527, -2.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.366554856300354
Epoch 0, Step 1396: train/loss = 0.27840396761894226, train/raw-loss = 0.24078769981861115, train/logprobs = tensor([[-1.0064, -7.3431],
        [-3.1562, -1.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37616246938705444
Epoch 0, Step 1397: train/loss = 0.6328119039535522, train/raw-loss = 0.5972625613212585, train/logprobs = tensor([[-1.0253, -1.3365],
        [-2.0672, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35549402236938477
Epoch 0, Step 1398: train/loss = 0.28209441900253296, train/raw-loss = 0.2500566840171814, train/logprobs = tensor([[-1.6177, -3.9972],
        [-2.9508, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320377379655838
Epoch 0, Step 1399: train/loss = 0.3720815181732178, train/raw-loss = 0.33940935134887695, train/logprobs = tensor([[-1.7509, -4.3935],
        [-3.2771, -1.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267216086387634
Epoch 0, Step 1400: train/loss = 0.08806152641773224, train/raw-loss = 0.05034521594643593, train/logprobs = tensor([[-2.2852, -5.6457],
        [-5.3414, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3771631121635437
Epoch 0, Step 1401: train/loss = 0.7220726609230042, train/raw-loss = 0.6775318384170532, train/logprobs = tensor([[-1.2871, -2.2979],
        [-3.2010, -2.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44540801644325256
Epoch 0, Step 1402: train/loss = 0.27802836894989014, train/raw-loss = 0.24117720127105713, train/logprobs = tensor([[-1.2425, -8.0182],
        [-3.1153, -3.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36851179599761963
Epoch 0, Step 1403: train/loss = 0.35427749156951904, train/raw-loss = 0.31437528133392334, train/logprobs = tensor([[-1.6263, -8.9348],
        [-3.4043, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990222215652466
Epoch 0, Step 1404: train/loss = 0.42586013674736023, train/raw-loss = 0.38061267137527466, train/logprobs = tensor([[-1.4186, -4.6161],
        [-3.9352, -2.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45247435569763184
Epoch 0, Step 1405: train/loss = 0.3424089848995209, train/raw-loss = 0.30752551555633545, train/logprobs = tensor([[-1.3218, -3.7641],
        [-2.7643, -2.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488348722457886
Epoch 0, Step 1406: train/loss = 0.11683356761932373, train/raw-loss = 0.07884813845157623, train/logprobs = tensor([[-1.3146, -4.8025],
        [-4.1399, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37985432147979736
Epoch 0, Step 1407: train/loss = 0.6365412473678589, train/raw-loss = 0.5978522896766663, train/logprobs = tensor([[-1.3852, -2.1009],
        [-2.8478, -2.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868895471096039
Epoch 0, Step 1408: train/loss = 0.8961204290390015, train/raw-loss = 0.8527885675430298, train/logprobs = tensor([[-2.5566, -5.6226],
        [-2.1488, -1.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43331846594810486
Epoch 0, Step 1409: train/loss = 0.3968724012374878, train/raw-loss = 0.3634158670902252, train/logprobs = tensor([[-0.9266, -6.7296],
        [-2.0942, -1.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33456501364707947
Epoch 0, Step 1410: train/loss = 0.5363073348999023, train/raw-loss = 0.5001562833786011, train/logprobs = tensor([[-1.9586, -3.9694],
        [-2.5368, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615109920501709
Epoch 0, Step 1411: train/loss = 0.29704397916793823, train/raw-loss = 0.2652319669723511, train/logprobs = tensor([[-1.5497, -9.3505],
        [-2.6325, -1.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181201219558716
Epoch 0, Step 1412: train/loss = 0.6109733581542969, train/raw-loss = 0.5703580379486084, train/logprobs = tensor([[-1.4817, -1.9859],
        [-2.2042, -1.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061531126499176
Epoch 0, Step 1413: train/loss = 0.5222923159599304, train/raw-loss = 0.48381179571151733, train/logprobs = tensor([[-1.2152, -1.9919],
        [-2.7021, -2.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38480478525161743
Epoch 0, Step 1414: train/loss = 0.1967892348766327, train/raw-loss = 0.16225028038024902, train/logprobs = tensor([[-1.4122, -6.7663],
        [-2.8590, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34538933634757996
Epoch 0, Step 1415: train/loss = 0.5232089161872864, train/raw-loss = 0.4859367311000824, train/logprobs = tensor([[-1.5455, -3.1484],
        [-2.8382, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727218508720398
Epoch 0, Step 1416: train/loss = 0.43821561336517334, train/raw-loss = 0.39608079195022583, train/logprobs = tensor([[-2.0108, -4.3851],
        [-2.7144, -1.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42134779691696167
Epoch 0, Step 1417: train/loss = 0.15533585846424103, train/raw-loss = 0.11672279238700867, train/logprobs = tensor([[-1.3966, -5.2450],
        [-3.8994, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.386130690574646
Epoch 0, Step 1418: train/loss = 0.22944557666778564, train/raw-loss = 0.1910373717546463, train/logprobs = tensor([[-1.5067, -8.8798],
        [-3.8247, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38408195972442627
Epoch 0, Step 1419: train/loss = 0.45535188913345337, train/raw-loss = 0.41507983207702637, train/logprobs = tensor([[-1.3495, -4.0714],
        [-2.5300, -2.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40272077918052673
Epoch 0, Step 1420: train/loss = 0.25069934129714966, train/raw-loss = 0.21987584233283997, train/logprobs = tensor([[-2.3117, -7.1306],
        [-3.5870, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30823472142219543
Epoch 0, Step 1421: train/loss = 0.43407148122787476, train/raw-loss = 0.3975706100463867, train/logprobs = tensor([[-2.0250, -4.6946],
        [-2.1938, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650088310241699
Epoch 0, Step 1422: train/loss = 0.22553882002830505, train/raw-loss = 0.18834105134010315, train/logprobs = tensor([[-1.7869, -7.4650],
        [-3.0181, -1.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719777762889862
Epoch 0, Step 1423: train/loss = 1.2694101333618164, train/raw-loss = 1.2325830459594727, train/logprobs = tensor([[-4.7949, -4.9082],
        [-2.3598, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.368271142244339
Epoch 0, Step 1424: train/loss = 0.25656890869140625, train/raw-loss = 0.22100205719470978, train/logprobs = tensor([[-1.4270, -5.9208],
        [-3.4835, -0.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35566866397857666
Epoch 0, Step 1425: train/loss = 0.415274977684021, train/raw-loss = 0.3853394091129303, train/logprobs = tensor([[ -2.0520, -10.4351],
        [ -2.5524,  -1.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29935556650161743
Epoch 0, Step 1426: train/loss = 0.40649813413619995, train/raw-loss = 0.3714398145675659, train/logprobs = tensor([[-1.7475, -3.8339],
        [-2.4502, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35058310627937317
Epoch 0, Step 1427: train/loss = 0.7127483487129211, train/raw-loss = 0.666015625, train/logprobs = tensor([[-1.3611, -2.5968],
        [-3.8678, -3.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46732714772224426
Epoch 0, Step 1428: train/loss = 0.40957409143447876, train/raw-loss = 0.3595627248287201, train/logprobs = tensor([[-2.4018, -6.3075],
        [-4.2046, -2.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001135468482971
Epoch 0, Step 1429: train/loss = 0.08380812406539917, train/raw-loss = 0.04512874782085419, train/logprobs = tensor([[-1.2786, -8.2085],
        [-3.7282, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3867937922477722
Epoch 0, Step 1430: train/loss = 0.16576755046844482, train/raw-loss = 0.12777839601039886, train/logprobs = tensor([[-0.9227, -8.8525],
        [-2.7623, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3798915147781372
Epoch 0, Step 1431: train/loss = 0.44852232933044434, train/raw-loss = 0.41067779064178467, train/logprobs = tensor([[-1.7401, -5.9981],
        [-3.2542, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37844550609588623
Epoch 0, Step 1432: train/loss = 0.17407748103141785, train/raw-loss = 0.13795512914657593, train/logprobs = tensor([[-1.6724, -5.6940],
        [-3.7225, -1.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36122360825538635
Epoch 0, Step 1433: train/loss = 0.30506661534309387, train/raw-loss = 0.26512610912323, train/logprobs = tensor([[-1.2902, -4.7149],
        [-2.5405, -2.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3994048237800598
Epoch 0, Step 1434: train/loss = 0.7753094434738159, train/raw-loss = 0.7339217662811279, train/logprobs = tensor([[-1.7704, -1.9674],
        [-2.2988, -2.4056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41387686133384705
Epoch 0, Step 1435: train/loss = 0.3080287575721741, train/raw-loss = 0.273166686296463, train/logprobs = tensor([[-1.5814, -3.8145],
        [-3.0658, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486204147338867
Epoch 0, Step 1436: train/loss = 0.7775508165359497, train/raw-loss = 0.7400255799293518, train/logprobs = tensor([[-3.5524, -6.0110],
        [-3.1379, -1.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37525230646133423
Epoch 0, Step 1437: train/loss = 0.5916294455528259, train/raw-loss = 0.5551144480705261, train/logprobs = tensor([[-2.7416, -5.0943],
        [-2.4084, -0.7475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36515024304389954
Epoch 0, Step 1438: train/loss = 0.5101258754730225, train/raw-loss = 0.46795475482940674, train/logprobs = tensor([[-1.0117, -2.5471],
        [-3.0465, -2.3178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217110872268677
Epoch 0, Step 1439: train/loss = 0.14994880557060242, train/raw-loss = 0.10880807787179947, train/logprobs = tensor([[ -2.4452, -11.6178],
        [ -4.2387,  -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41140711307525635
Epoch 0, Step 1440: train/loss = 0.5641534328460693, train/raw-loss = 0.5133202075958252, train/logprobs = tensor([[-1.9531, -4.1582],
        [-4.5490, -3.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5083327293395996
Epoch 0, Step 1441: train/loss = 0.32910066843032837, train/raw-loss = 0.28600743412971497, train/logprobs = tensor([[-2.0040, -5.1869],
        [-3.9487, -1.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4309324622154236
Epoch 0, Step 1442: train/loss = 0.28225553035736084, train/raw-loss = 0.24222850799560547, train/logprobs = tensor([[-1.8339, -4.0718],
        [-4.1107, -1.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002702534198761
Epoch 0, Step 1443: train/loss = 0.18629467487335205, train/raw-loss = 0.1479516625404358, train/logprobs = tensor([[-1.8252, -5.7952],
        [-3.7477, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38343003392219543
Epoch 0, Step 1444: train/loss = 0.4793301224708557, train/raw-loss = 0.4362373352050781, train/logprobs = tensor([[-1.7408, -3.8900],
        [-3.0311, -2.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.430927574634552
Epoch 0, Step 1445: train/loss = 0.26716628670692444, train/raw-loss = 0.23240719735622406, train/logprobs = tensor([[-1.8247, -6.3572],
        [-2.7442, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34759092330932617
Epoch 0, Step 1446: train/loss = 0.13793990015983582, train/raw-loss = 0.10897478461265564, train/logprobs = tensor([[-0.9860, -8.4407],
        [-2.6048, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.289651095867157
Epoch 0, Step 1447: train/loss = 0.357566773891449, train/raw-loss = 0.3252609372138977, train/logprobs = tensor([[-1.4242, -4.2379],
        [-2.2510, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230587840080261
Epoch 0, Step 1448: train/loss = 0.45213598012924194, train/raw-loss = 0.40898531675338745, train/logprobs = tensor([[-1.8605, -7.9046],
        [-4.1033, -2.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4315069019794464
Epoch 0, Step 1449: train/loss = 0.49073928594589233, train/raw-loss = 0.44736039638519287, train/logprobs = tensor([[-0.8239, -3.4631],
        [-3.2576, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337884783744812
Epoch 0, Step 1450: train/loss = 0.5768651962280273, train/raw-loss = 0.5333774089813232, train/logprobs = tensor([[-1.2972, -2.3580],
        [-3.4764, -2.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4348781704902649
Epoch 0, Step 1451: train/loss = 0.3382773697376251, train/raw-loss = 0.307589054107666, train/logprobs = tensor([[-1.2954, -4.7891],
        [-2.6145, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30688321590423584
Epoch 0, Step 1452: train/loss = 0.5010172724723816, train/raw-loss = 0.46426695585250854, train/logprobs = tensor([[-1.4960, -3.4081],
        [-2.2318, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36750340461730957
Epoch 0, Step 1453: train/loss = 0.1698674112558365, train/raw-loss = 0.1305670589208603, train/logprobs = tensor([[-2.1454, -9.2105],
        [-4.5942, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3930036723613739
Epoch 0, Step 1454: train/loss = 0.2977719008922577, train/raw-loss = 0.26454371213912964, train/logprobs = tensor([[-1.5148, -8.6824],
        [-3.2580, -2.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322818875312805
Epoch 0, Step 1455: train/loss = 0.14764541387557983, train/raw-loss = 0.11510740220546722, train/logprobs = tensor([[-1.2966, -7.0447],
        [-3.0895, -2.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253801167011261
Epoch 0, Step 1456: train/loss = 0.13211442530155182, train/raw-loss = 0.0973266065120697, train/logprobs = tensor([[-0.8644, -7.9620],
        [-2.7644, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3478781580924988
Epoch 0, Step 1457: train/loss = 0.2650860548019409, train/raw-loss = 0.23110288381576538, train/logprobs = tensor([[-1.4371, -5.3142],
        [-2.3783, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33983153104782104
Epoch 0, Step 1458: train/loss = 0.42469948530197144, train/raw-loss = 0.395704448223114, train/logprobs = tensor([[-3.0715, -8.2184],
        [-2.8664, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28995025157928467
Epoch 0, Step 1459: train/loss = 0.3463204503059387, train/raw-loss = 0.3094787001609802, train/logprobs = tensor([[-1.3661, -4.3486],
        [-2.1260, -1.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3684171736240387
Epoch 0, Step 1460: train/loss = 0.6258714199066162, train/raw-loss = 0.5929847955703735, train/logprobs = tensor([[-2.1286, -3.8397],
        [-1.9682, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886654138565063
Epoch 0, Step 1461: train/loss = 0.35135334730148315, train/raw-loss = 0.3175821304321289, train/logprobs = tensor([[-0.7982, -4.8540],
        [-2.2325, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33771225810050964
Epoch 0, Step 1462: train/loss = 0.5444306135177612, train/raw-loss = 0.5110592842102051, train/logprobs = tensor([[-1.2924, -2.7225],
        [-2.2066, -1.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337133824825287
Epoch 0, Step 1463: train/loss = 0.26086854934692383, train/raw-loss = 0.2237268090248108, train/logprobs = tensor([[-1.5837, -6.2894],
        [-3.4218, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714175820350647
Epoch 0, Step 1464: train/loss = 0.4810160994529724, train/raw-loss = 0.44654586911201477, train/logprobs = tensor([[-2.1368, -6.2356],
        [-2.0716, -1.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447020947933197
Epoch 0, Step 1465: train/loss = 0.2166706919670105, train/raw-loss = 0.18469589948654175, train/logprobs = tensor([[ -1.4478, -11.4442],
        [ -3.7431,  -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31974780559539795
Epoch 0, Step 1466: train/loss = 0.32094839215278625, train/raw-loss = 0.28934693336486816, train/logprobs = tensor([[-2.3621, -5.6662],
        [-3.4803, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160143196582794
Epoch 0, Step 1467: train/loss = 0.8063762187957764, train/raw-loss = 0.7652626633644104, train/logprobs = tensor([[-1.3288, -2.2970],
        [-3.0942, -2.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4111357033252716
Epoch 0, Step 1468: train/loss = 0.36456507444381714, train/raw-loss = 0.3273278474807739, train/logprobs = tensor([[-1.5712, -6.1401],
        [-1.9320, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3723723888397217
Epoch 0, Step 1469: train/loss = 0.5094985961914062, train/raw-loss = 0.468843013048172, train/logprobs = tensor([[-1.8726, -4.0316],
        [-2.9902, -2.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40655604004859924
Epoch 0, Step 1470: train/loss = 0.18183103203773499, train/raw-loss = 0.1457405388355255, train/logprobs = tensor([[-1.5530, -8.3681],
        [-2.8379, -0.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609049320220947
Epoch 0, Step 1471: train/loss = 0.6110894680023193, train/raw-loss = 0.5745543241500854, train/logprobs = tensor([[-2.1438, -3.8679],
        [-2.6127, -1.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36535143852233887
Epoch 0, Step 1472: train/loss = 0.6377993822097778, train/raw-loss = 0.6001203656196594, train/logprobs = tensor([[-1.8911, -2.2565],
        [-3.1968, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37679022550582886
Epoch 0, Step 1473: train/loss = 0.35880133509635925, train/raw-loss = 0.3188644051551819, train/logprobs = tensor([[-1.9951, -9.5459],
        [-3.8295, -2.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39936941862106323
Epoch 0, Step 1474: train/loss = 0.29136598110198975, train/raw-loss = 0.25690191984176636, train/logprobs = tensor([[-1.5987, -5.2768],
        [-3.1915, -1.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3446406126022339
Epoch 0, Step 1475: train/loss = 0.3462633490562439, train/raw-loss = 0.30625832080841064, train/logprobs = tensor([[-2.4730, -4.8051],
        [-3.5477, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40005019307136536
Epoch 0, Step 1476: train/loss = 0.4428366720676422, train/raw-loss = 0.40338197350502014, train/logprobs = tensor([[-2.2189, -5.3868],
        [-3.5479, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3945470452308655
Epoch 0, Step 1477: train/loss = 0.3871423602104187, train/raw-loss = 0.3515918254852295, train/logprobs = tensor([[-0.9721, -2.0034],
        [-2.1907, -0.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555055558681488
Epoch 0, Step 1478: train/loss = 0.13770440220832825, train/raw-loss = 0.10190463066101074, train/logprobs = tensor([[-1.3966, -8.4635],
        [-2.9866, -1.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579977750778198
Epoch 0, Step 1479: train/loss = 0.4203208088874817, train/raw-loss = 0.38367190957069397, train/logprobs = tensor([[-1.4666, -3.6229],
        [-2.6796, -1.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36648881435394287
Epoch 0, Step 1480: train/loss = 0.3692868649959564, train/raw-loss = 0.3255871832370758, train/logprobs = tensor([[-1.2738, -4.1080],
        [-2.8615, -1.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4369969069957733
Epoch 0, Step 1481: train/loss = 0.2130354791879654, train/raw-loss = 0.18066143989562988, train/logprobs = tensor([[-1.1658, -6.0750],
        [-2.5048, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237404227256775
Epoch 0, Step 1482: train/loss = 0.35088807344436646, train/raw-loss = 0.3147542476654053, train/logprobs = tensor([[-1.1219, -4.8099],
        [-2.6669, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36133819818496704
Epoch 0, Step 1483: train/loss = 0.6925021409988403, train/raw-loss = 0.6601154208183289, train/logprobs = tensor([[ -3.4755, -10.3251],
        [ -2.4316,  -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3238673806190491
Epoch 0, Step 1484: train/loss = 0.5115630626678467, train/raw-loss = 0.48105525970458984, train/logprobs = tensor([[-2.7638, -7.3262],
        [-2.4010, -1.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30507761240005493
Epoch 0, Step 1485: train/loss = 0.5133039951324463, train/raw-loss = 0.4729468524456024, train/logprobs = tensor([[-1.4230, -4.2260],
        [-2.9358, -1.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40357163548469543
Epoch 0, Step 1486: train/loss = 0.2994537353515625, train/raw-loss = 0.2618609666824341, train/logprobs = tensor([[-0.9162, -3.9871],
        [-2.4848, -1.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37592804431915283
Epoch 0, Step 1487: train/loss = 0.3537316918373108, train/raw-loss = 0.31444206833839417, train/logprobs = tensor([[-2.1047, -6.1775],
        [-3.1753, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928961753845215
Epoch 0, Step 1488: train/loss = 0.17634432017803192, train/raw-loss = 0.14834006130695343, train/logprobs = tensor([[-1.3090, -8.2655],
        [-2.5775, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800426483154297
Epoch 0, Step 1489: train/loss = 0.32598093152046204, train/raw-loss = 0.2882891297340393, train/logprobs = tensor([[-1.1206, -4.2339],
        [-3.0633, -1.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37691807746887207
Epoch 0, Step 1490: train/loss = 0.4625072479248047, train/raw-loss = 0.4368038773536682, train/logprobs = tensor([[-2.3043, -4.4045],
        [-2.1328, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570335865020752
Epoch 0, Step 1491: train/loss = 0.49357783794403076, train/raw-loss = 0.46402424573898315, train/logprobs = tensor([[-2.1158, -3.8145],
        [-1.9068, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955361008644104
Epoch 0, Step 1492: train/loss = 0.28522929549217224, train/raw-loss = 0.246253103017807, train/logprobs = tensor([[-0.9827, -4.0300],
        [-2.7489, -1.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38976186513900757
Epoch 0, Step 1493: train/loss = 0.3064418137073517, train/raw-loss = 0.26823341846466064, train/logprobs = tensor([[-1.0432, -5.8516],
        [-3.0203, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820837736129761
Epoch 0, Step 1494: train/loss = 0.46325695514678955, train/raw-loss = 0.42593711614608765, train/logprobs = tensor([[-0.8775, -3.3920],
        [-2.2620, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37319859862327576
Epoch 0, Step 1495: train/loss = 1.1240040063858032, train/raw-loss = 1.0990198850631714, train/logprobs = tensor([[-3.7378, -6.4400],
        [-1.5910, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498420774936676
Epoch 0, Step 1496: train/loss = 0.07557377964258194, train/raw-loss = 0.03925979882478714, train/logprobs = tensor([[-1.3929, -9.7294],
        [-4.0628, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363139808177948
Epoch 0, Step 1497: train/loss = 0.31974130868911743, train/raw-loss = 0.28376027941703796, train/logprobs = tensor([[-1.0917, -4.1404],
        [-2.2424, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598101735115051
Epoch 0, Step 1498: train/loss = 1.0625988245010376, train/raw-loss = 1.0326764583587646, train/logprobs = tensor([[-4.4888, -9.5691],
        [-2.2418, -1.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992233633995056
Epoch 0, Step 1499: train/loss = 0.2596202790737152, train/raw-loss = 0.22459885478019714, train/logprobs = tensor([[-1.5766, -6.3373],
        [-3.1274, -1.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502143621444702
Epoch 0, Step 1500: train/loss = 0.3948426842689514, train/raw-loss = 0.3615218997001648, train/logprobs = tensor([[-0.8617, -4.3933],
        [-2.5239, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33320748805999756
Epoch 0, Step 1501: train/loss = 0.3508146107196808, train/raw-loss = 0.31173813343048096, train/logprobs = tensor([[-1.4542, -3.4468],
        [-2.5490, -1.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3907647430896759
Epoch 0, Step 1502: train/loss = 0.3398953974246979, train/raw-loss = 0.30226731300354004, train/logprobs = tensor([[-1.2625, -3.8589],
        [-3.5028, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762807548046112
Epoch 0, Step 1503: train/loss = 0.2237744927406311, train/raw-loss = 0.19424819946289062, train/logprobs = tensor([[-1.1997, -7.9279],
        [-2.1860, -1.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952631115913391
Epoch 0, Step 1504: train/loss = 0.5241512060165405, train/raw-loss = 0.4913172721862793, train/logprobs = tensor([[-1.6465, -3.3953],
        [-2.8607, -1.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283393085002899
Epoch 0, Step 1505: train/loss = 0.3586074411869049, train/raw-loss = 0.3206871449947357, train/logprobs = tensor([[-1.4372, -3.3600],
        [-3.1254, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37920308113098145
Epoch 0, Step 1506: train/loss = 0.21918991208076477, train/raw-loss = 0.18827301263809204, train/logprobs = tensor([[-1.8064, -8.5447],
        [-3.6463, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30916905403137207
Epoch 0, Step 1507: train/loss = 0.44177016615867615, train/raw-loss = 0.40749895572662354, train/logprobs = tensor([[-1.3574, -3.8623],
        [-1.9322, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427121639251709
Epoch 0, Step 1508: train/loss = 0.1959415078163147, train/raw-loss = 0.15166543424129486, train/logprobs = tensor([[-1.9120, -6.2664],
        [-4.1431, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.442760705947876
Epoch 0, Step 1509: train/loss = 0.3344518542289734, train/raw-loss = 0.30442869663238525, train/logprobs = tensor([[-2.7718, -7.5897],
        [-3.0774, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30023193359375
Epoch 0, Step 1510: train/loss = 0.39403393864631653, train/raw-loss = 0.36056801676750183, train/logprobs = tensor([[-1.6342, -5.0607],
        [-2.4438, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33465924859046936
Epoch 0, Step 1511: train/loss = 0.08686535805463791, train/raw-loss = 0.04994392767548561, train/logprobs = tensor([[-1.3612, -6.8513],
        [-3.8301, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692142963409424
Epoch 0, Step 1512: train/loss = 0.5728862285614014, train/raw-loss = 0.5345350503921509, train/logprobs = tensor([[-1.7590, -5.3354],
        [-2.9009, -1.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3835117816925049
Epoch 0, Step 1513: train/loss = 0.36713212728500366, train/raw-loss = 0.3308323621749878, train/logprobs = tensor([[-1.3063, -4.7214],
        [-3.6409, -2.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629975914955139
Epoch 0, Step 1514: train/loss = 0.4307671785354614, train/raw-loss = 0.40051233768463135, train/logprobs = tensor([[-1.5577, -4.6490],
        [-2.5755, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025483787059784
Epoch 0, Step 1515: train/loss = 0.42000389099121094, train/raw-loss = 0.37918591499328613, train/logprobs = tensor([[-1.1327, -4.5502],
        [-3.6458, -1.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40817996859550476
Epoch 0, Step 1516: train/loss = 0.5146128535270691, train/raw-loss = 0.47192370891571045, train/logprobs = tensor([[-1.2493, -2.7962],
        [-2.8417, -2.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4268915057182312
Epoch 0, Step 1517: train/loss = 0.14828059077262878, train/raw-loss = 0.11747289448976517, train/logprobs = tensor([[-1.1183, -7.8950],
        [-2.9652, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30807703733444214
Epoch 0, Step 1518: train/loss = 0.1735444962978363, train/raw-loss = 0.13857541978359222, train/logprobs = tensor([[-1.3739, -9.2004],
        [-3.2356, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34969091415405273
Epoch 0, Step 1519: train/loss = 0.31765878200531006, train/raw-loss = 0.28501179814338684, train/logprobs = tensor([[-1.6028, -4.4851],
        [-2.6461, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32647019624710083
Epoch 0, Step 1520: train/loss = 0.3771591782569885, train/raw-loss = 0.3434201180934906, train/logprobs = tensor([[-2.6049, -5.4647],
        [-3.8336, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373908996582031
Epoch 0, Step 1521: train/loss = 0.3539290726184845, train/raw-loss = 0.3195173442363739, train/logprobs = tensor([[-1.9400, -9.0938],
        [-2.5178, -2.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34411710500717163
Epoch 0, Step 1522: train/loss = 0.49431654810905457, train/raw-loss = 0.4585341215133667, train/logprobs = tensor([[-1.5120, -6.9564],
        [-2.5615, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578242361545563
Epoch 0, Step 1523: train/loss = 0.6163251399993896, train/raw-loss = 0.5794671773910522, train/logprobs = tensor([[-1.9226, -2.6052],
        [-2.7257, -2.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3685795068740845
Epoch 0, Step 1524: train/loss = 0.314608097076416, train/raw-loss = 0.2698725461959839, train/logprobs = tensor([[-1.0455, -4.2787],
        [-3.9567, -1.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.447355717420578
Epoch 0, Step 1525: train/loss = 0.24714452028274536, train/raw-loss = 0.21654455363750458, train/logprobs = tensor([[-1.1480, -4.5145],
        [-2.7323, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059995174407959
Epoch 0, Step 1526: train/loss = 0.22414588928222656, train/raw-loss = 0.1898193657398224, train/logprobs = tensor([[-1.8712, -7.1205],
        [-2.8303, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3432651162147522
Epoch 0, Step 1527: train/loss = 0.31813952326774597, train/raw-loss = 0.28172406554222107, train/logprobs = tensor([[-1.1523, -7.7903],
        [-3.7566, -1.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3641544580459595
Epoch 0, Step 1528: train/loss = 0.22871670126914978, train/raw-loss = 0.18816274404525757, train/logprobs = tensor([[-1.3768, -3.2496],
        [-3.9747, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40553969144821167
Epoch 0, Step 1529: train/loss = 0.5253862738609314, train/raw-loss = 0.48885101079940796, train/logprobs = tensor([[-1.4611, -3.0852],
        [-2.5494, -1.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36535245180130005
Epoch 0, Step 1530: train/loss = 0.28587061166763306, train/raw-loss = 0.254660427570343, train/logprobs = tensor([[ -2.0249, -10.0127],
        [ -3.1568,  -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31210193037986755
Epoch 0, Step 1531: train/loss = 0.3192490339279175, train/raw-loss = 0.28491273522377014, train/logprobs = tensor([[-1.3538, -6.2420],
        [-2.1813, -1.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433631658554077
Epoch 0, Step 1532: train/loss = 0.3468986749649048, train/raw-loss = 0.3107038140296936, train/logprobs = tensor([[-1.6527, -5.0868],
        [-3.4689, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36194828152656555
Epoch 0, Step 1533: train/loss = 0.41640007495880127, train/raw-loss = 0.3890869617462158, train/logprobs = tensor([[-1.0473, -3.1388],
        [-2.8220, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731313109397888
Epoch 0, Step 1534: train/loss = 0.2773793339729309, train/raw-loss = 0.2467997670173645, train/logprobs = tensor([[-1.3304, -7.1292],
        [-2.5352, -2.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3057957589626312
Epoch 0, Step 1535: train/loss = 0.368967205286026, train/raw-loss = 0.32865816354751587, train/logprobs = tensor([[-1.7210, -3.1759],
        [-3.5775, -2.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4030904173851013
Epoch 0, Step 1536: train/loss = 0.5933765172958374, train/raw-loss = 0.5587593913078308, train/logprobs = tensor([[-1.8347, -2.7400],
        [-2.7805, -2.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461717367172241
Epoch 0, Step 1537: train/loss = 0.6518377661705017, train/raw-loss = 0.6149522662162781, train/logprobs = tensor([[-1.2917, -2.7004],
        [-2.3081, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36885470151901245
Epoch 0, Step 1538: train/loss = 0.5835232138633728, train/raw-loss = 0.5504002571105957, train/logprobs = tensor([[-0.9904, -2.1479],
        [-1.6819, -1.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33122941851615906
Epoch 0, Step 1539: train/loss = 0.27805787324905396, train/raw-loss = 0.24575503170490265, train/logprobs = tensor([[-1.2834, -5.6210],
        [-3.2208, -1.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230281472206116
Epoch 0, Step 1540: train/loss = 0.4173661470413208, train/raw-loss = 0.3865888714790344, train/logprobs = tensor([[-0.9916, -3.4579],
        [-2.2976, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.307772696018219
Epoch 0, Step 1541: train/loss = 0.28397470712661743, train/raw-loss = 0.2541714310646057, train/logprobs = tensor([[-1.0344, -4.9059],
        [-2.7351, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29803287982940674
Epoch 0, Step 1542: train/loss = 0.131425142288208, train/raw-loss = 0.09611786156892776, train/logprobs = tensor([[-1.6460, -5.8735],
        [-3.6929, -0.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3530728220939636
Epoch 0, Step 1543: train/loss = 0.36439940333366394, train/raw-loss = 0.33087122440338135, train/logprobs = tensor([[-2.3739, -7.5872],
        [-2.8747, -1.3942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33528196811676025
Epoch 0, Step 1544: train/loss = 0.255480021238327, train/raw-loss = 0.22884753346443176, train/logprobs = tensor([[-1.7642, -5.1125],
        [-2.4751, -0.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26632511615753174
Epoch 0, Step 1545: train/loss = 0.1268579363822937, train/raw-loss = 0.09264461696147919, train/logprobs = tensor([[-1.7159, -6.7799],
        [-4.2232, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34213319420814514
Epoch 0, Step 1546: train/loss = 0.36002758145332336, train/raw-loss = 0.32237547636032104, train/logprobs = tensor([[-1.6590, -5.9139],
        [-3.8557, -1.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37652134895324707
Epoch 0, Step 1547: train/loss = 0.6940659880638123, train/raw-loss = 0.661596417427063, train/logprobs = tensor([[-2.8266, -6.2055],
        [-2.3858, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.324695885181427
Epoch 0, Step 1548: train/loss = 0.1775970757007599, train/raw-loss = 0.13921663165092468, train/logprobs = tensor([[-2.0760, -8.5032],
        [-3.7351, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38380444049835205
Epoch 0, Step 1549: train/loss = 0.5925979018211365, train/raw-loss = 0.5545007586479187, train/logprobs = tensor([[-1.5407, -2.9323],
        [-2.8665, -1.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3809716999530792
Epoch 0, Step 1550: train/loss = 0.16619496047496796, train/raw-loss = 0.12795689702033997, train/logprobs = tensor([[-1.7589, -5.2106],
        [-4.3833, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3823806047439575
Epoch 0, Step 1551: train/loss = 0.3681238889694214, train/raw-loss = 0.33583924174308777, train/logprobs = tensor([[-1.6704, -6.6168],
        [-2.2486, -1.2008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.322846382856369
Epoch 0, Step 1552: train/loss = 0.6792869567871094, train/raw-loss = 0.6494413614273071, train/logprobs = tensor([[-1.0008, -2.9962],
        [-2.2584, -2.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29845625162124634
Epoch 0, Step 1553: train/loss = 0.5191035270690918, train/raw-loss = 0.4819832742214203, train/logprobs = tensor([[-1.5047, -2.0802],
        [-2.5959, -1.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3712022602558136
Epoch 0, Step 1554: train/loss = 0.35667094588279724, train/raw-loss = 0.3157263696193695, train/logprobs = tensor([[-1.7705, -4.4836],
        [-3.7006, -1.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40944576263427734
Epoch 0, Step 1555: train/loss = 0.42594248056411743, train/raw-loss = 0.3928205668926239, train/logprobs = tensor([[-1.4626, -6.4700],
        [-2.8708, -1.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331218957901001
Epoch 0, Step 1556: train/loss = 0.162339985370636, train/raw-loss = 0.12681905925273895, train/logprobs = tensor([[-1.1471, -5.1208],
        [-2.7560, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35520923137664795
Epoch 0, Step 1557: train/loss = 0.45478129386901855, train/raw-loss = 0.4104691743850708, train/logprobs = tensor([[-1.2422, -5.2720],
        [-2.6668, -1.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4431213438510895
Epoch 0, Step 1558: train/loss = 0.1457802802324295, train/raw-loss = 0.10628130286931992, train/logprobs = tensor([[-1.9438, -8.6715],
        [-3.7315, -1.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3949897289276123
Epoch 0, Step 1559: train/loss = 0.15878383815288544, train/raw-loss = 0.1313064694404602, train/logprobs = tensor([[-1.2183, -5.6009],
        [-2.7132, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27477383613586426
Epoch 0, Step 1560: train/loss = 0.4861566126346588, train/raw-loss = 0.4545263648033142, train/logprobs = tensor([[-1.0108, -4.3939],
        [-1.9776, -1.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3163025975227356
Epoch 0, Step 1561: train/loss = 0.32019758224487305, train/raw-loss = 0.28413212299346924, train/logprobs = tensor([[ -2.1541, -11.4929],
        [ -3.4503,  -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606545329093933
Epoch 0, Step 1562: train/loss = 0.6103640794754028, train/raw-loss = 0.5719192624092102, train/logprobs = tensor([[-2.2482, -3.4896],
        [-3.7423, -1.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844483494758606
Epoch 0, Step 1563: train/loss = 0.3619803190231323, train/raw-loss = 0.3282676935195923, train/logprobs = tensor([[-1.3974, -6.2112],
        [-2.9595, -1.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33712607622146606
Epoch 0, Step 1564: train/loss = 0.3726811408996582, train/raw-loss = 0.3342318534851074, train/logprobs = tensor([[-2.2962, -5.9385],
        [-3.4525, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844930827617645
Epoch 0, Step 1565: train/loss = 0.41919833421707153, train/raw-loss = 0.38669419288635254, train/logprobs = tensor([[-1.8099, -3.7862],
        [-2.4791, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32504111528396606
Epoch 0, Step 1566: train/loss = 0.5217848420143127, train/raw-loss = 0.4781830310821533, train/logprobs = tensor([[-2.5588, -5.6029],
        [-3.3428, -2.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43601781129837036
Epoch 0, Step 1567: train/loss = 0.47732728719711304, train/raw-loss = 0.4425041675567627, train/logprobs = tensor([[-1.7796, -3.5132],
        [-2.8410, -1.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3482311964035034
Epoch 0, Step 1568: train/loss = 0.09289184957742691, train/raw-loss = 0.06333426386117935, train/logprobs = tensor([[-1.1117, -9.4183],
        [-3.7492, -1.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955758571624756
Epoch 0, Step 1569: train/loss = 0.5404961109161377, train/raw-loss = 0.5115233063697815, train/logprobs = tensor([[-0.7618, -2.0818],
        [-1.5302, -1.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28972774744033813
Epoch 0, Step 1570: train/loss = 0.5459770560264587, train/raw-loss = 0.5156396627426147, train/logprobs = tensor([[-2.0941, -5.5296],
        [-2.5050, -1.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033740818500519
Epoch 0, Step 1571: train/loss = 0.5071425437927246, train/raw-loss = 0.47384998202323914, train/logprobs = tensor([[-2.1489, -4.3718],
        [-2.8155, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33292585611343384
Epoch 0, Step 1572: train/loss = 0.5620195865631104, train/raw-loss = 0.5287256240844727, train/logprobs = tensor([[-1.2459, -1.6951],
        [-2.0361, -1.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33293965458869934
Epoch 0, Step 1573: train/loss = 0.6835182309150696, train/raw-loss = 0.6486890316009521, train/logprobs = tensor([[-3.2139, -7.5534],
        [-2.7931, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34829214215278625
Epoch 0, Step 1574: train/loss = 0.159258171916008, train/raw-loss = 0.12579424679279327, train/logprobs = tensor([[-1.2331, -6.7461],
        [-3.0666, -1.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.334639310836792
Epoch 0, Step 1575: train/loss = 0.29424741864204407, train/raw-loss = 0.2608735263347626, train/logprobs = tensor([[-1.2406, -5.5103],
        [-3.9990, -1.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33373868465423584
Epoch 0, Step 1576: train/loss = 0.5084804892539978, train/raw-loss = 0.4721035361289978, train/logprobs = tensor([[-1.2360, -2.3373],
        [-2.8010, -2.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637697398662567
Epoch 0, Step 1577: train/loss = 0.4674951136112213, train/raw-loss = 0.4263863265514374, train/logprobs = tensor([[-1.6594, -5.8779],
        [-3.9491, -2.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41108840703964233
Epoch 0, Step 1578: train/loss = 0.3362072706222534, train/raw-loss = 0.2972733974456787, train/logprobs = tensor([[-1.4497, -4.1311],
        [-3.9751, -2.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38933876156806946
Epoch 0, Step 1579: train/loss = 0.5465296506881714, train/raw-loss = 0.5121899843215942, train/logprobs = tensor([[-1.3425, -3.2456],
        [-2.1045, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34339654445648193
Epoch 0, Step 1580: train/loss = 0.26478973031044006, train/raw-loss = 0.22960443794727325, train/logprobs = tensor([[-1.6623, -9.7342],
        [-3.6465, -1.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35185280442237854
Epoch 0, Step 1581: train/loss = 0.31259143352508545, train/raw-loss = 0.27513065934181213, train/logprobs = tensor([[-1.9881, -5.3994],
        [-2.7435, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37460777163505554
Epoch 0, Step 1582: train/loss = 0.31082963943481445, train/raw-loss = 0.2824881672859192, train/logprobs = tensor([[-1.5399, -5.6696],
        [-2.4760, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28341466188430786
Epoch 0, Step 1583: train/loss = 0.08447609841823578, train/raw-loss = 0.0555572472512722, train/logprobs = tensor([[-1.0681, -8.5941],
        [-4.0315, -1.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2891885042190552
Epoch 0, Step 1584: train/loss = 0.7191462516784668, train/raw-loss = 0.6832238435745239, train/logprobs = tensor([[-1.5483, -1.8925],
        [-2.7121, -2.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592239022254944
Epoch 0, Step 1585: train/loss = 0.29439207911491394, train/raw-loss = 0.2611079812049866, train/logprobs = tensor([[-1.2821, -5.5057],
        [-3.2286, -1.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33284109830856323
Epoch 0, Step 1586: train/loss = 0.25822314620018005, train/raw-loss = 0.22511973977088928, train/logprobs = tensor([[-1.1198, -4.9811],
        [-3.7079, -2.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33103397488594055
Epoch 0, Step 1587: train/loss = 0.29814058542251587, train/raw-loss = 0.26170748472213745, train/logprobs = tensor([[-1.3818, -5.2732],
        [-2.9245, -1.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36433112621307373
Epoch 0, Step 1588: train/loss = 0.20075276494026184, train/raw-loss = 0.16419129073619843, train/logprobs = tensor([[-1.4596, -5.5370],
        [-3.1244, -1.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36561471223831177
Epoch 0, Step 1589: train/loss = 0.2508874237537384, train/raw-loss = 0.2198360115289688, train/logprobs = tensor([[ -1.5746, -10.7580],
        [ -2.8112,  -1.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31051385402679443
Epoch 0, Step 1590: train/loss = 0.15777090191841125, train/raw-loss = 0.11984989792108536, train/logprobs = tensor([[-1.5792, -7.3083],
        [-3.8273, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37921014428138733
Epoch 0, Step 1591: train/loss = 0.2712114453315735, train/raw-loss = 0.23585659265518188, train/logprobs = tensor([[-1.2458, -6.6771],
        [-3.3920, -1.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35354867577552795
Epoch 0, Step 1592: train/loss = 0.48009276390075684, train/raw-loss = 0.44850003719329834, train/logprobs = tensor([[-0.7954, -1.7197],
        [-2.4989, -1.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31592732667922974
Epoch 0, Step 1593: train/loss = 0.09929165244102478, train/raw-loss = 0.06006380170583725, train/logprobs = tensor([[-1.1723, -7.8061],
        [-4.0223, -2.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922785520553589
Epoch 0, Step 1594: train/loss = 0.6068217754364014, train/raw-loss = 0.5698989629745483, train/logprobs = tensor([[-1.5221, -3.5646],
        [-2.5453, -2.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36922797560691833
Epoch 0, Step 1595: train/loss = 0.7330936193466187, train/raw-loss = 0.6942038536071777, train/logprobs = tensor([[-2.5788, -3.1339],
        [-3.1189, -2.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38889697194099426
Epoch 0, Step 1596: train/loss = 0.44795557856559753, train/raw-loss = 0.4162350296974182, train/logprobs = tensor([[-1.4712, -4.0464],
        [-3.2547, -2.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172054886817932
Epoch 0, Step 1597: train/loss = 0.1025504395365715, train/raw-loss = 0.06841874122619629, train/logprobs = tensor([[ -1.5893, -12.6696],
        [ -3.8215,  -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34131693840026855
Epoch 0, Step 1598: train/loss = 0.44933125376701355, train/raw-loss = 0.4126375913619995, train/logprobs = tensor([[-1.9560, -8.0047],
        [-3.8314, -2.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669360876083374
Epoch 0, Step 1599: train/loss = 0.5703790783882141, train/raw-loss = 0.5304897427558899, train/logprobs = tensor([[-1.5474, -3.6162],
        [-3.6930, -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3988931179046631
Epoch 0, Step 1600: train/loss = 0.3502402603626251, train/raw-loss = 0.3164929747581482, train/logprobs = tensor([[-1.3423, -4.5125],
        [-2.9450, -2.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374728858470917
Epoch 0, Step 1601: train/loss = 0.17099148035049438, train/raw-loss = 0.1377943605184555, train/logprobs = tensor([[-1.3267, -8.4900],
        [-3.0961, -2.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33197125792503357
Epoch 0, Step 1602: train/loss = 0.2726479768753052, train/raw-loss = 0.2423439621925354, train/logprobs = tensor([[-1.8245, -4.8076],
        [-2.3167, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3030402958393097
Epoch 0, Step 1603: train/loss = 0.4991767704486847, train/raw-loss = 0.45742067694664, train/logprobs = tensor([[-1.0553, -1.9810],
        [-2.8346, -1.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41756078600883484
Epoch 0, Step 1604: train/loss = 0.3205583691596985, train/raw-loss = 0.2846442759037018, train/logprobs = tensor([[-2.3494, -8.5710],
        [-4.4878, -2.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3591407537460327
Epoch 0, Step 1605: train/loss = 0.27539852261543274, train/raw-loss = 0.2376064956188202, train/logprobs = tensor([[-0.8125, -6.6035],
        [-2.8950, -1.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37792035937309265
Epoch 0, Step 1606: train/loss = 0.09110590070486069, train/raw-loss = 0.052152324467897415, train/logprobs = tensor([[-1.8585, -7.8032],
        [-4.6634, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3895357549190521
Epoch 0, Step 1607: train/loss = 0.403246134519577, train/raw-loss = 0.3731682300567627, train/logprobs = tensor([[ -2.1649, -10.3782],
        [ -2.9388,  -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007790446281433
Epoch 0, Step 1608: train/loss = 0.38941511511802673, train/raw-loss = 0.35211604833602905, train/logprobs = tensor([[-1.6227, -7.8206],
        [-3.3963, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729904890060425
Epoch 0, Step 1609: train/loss = 0.20528359711170197, train/raw-loss = 0.17160919308662415, train/logprobs = tensor([[ -1.4594, -10.1893],
        [ -4.1829,  -0.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3367442190647125
Epoch 0, Step 1610: train/loss = 0.1344589740037918, train/raw-loss = 0.09667259454727173, train/logprobs = tensor([[-1.2033, -7.6584],
        [-2.8087, -1.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778637945652008
Epoch 0, Step 1611: train/loss = 0.4633561968803406, train/raw-loss = 0.42831623554229736, train/logprobs = tensor([[-1.8351, -3.1787],
        [-3.3863, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35040003061294556
Epoch 0, Step 1612: train/loss = 0.5380421280860901, train/raw-loss = 0.5065885782241821, train/logprobs = tensor([[-1.5894, -3.7784],
        [-1.7715, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31453531980514526
Epoch 0, Step 1613: train/loss = 0.6420617699623108, train/raw-loss = 0.6077674627304077, train/logprobs = tensor([[-1.7416, -2.4422],
        [-2.6209, -2.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34294354915618896
Epoch 0, Step 1614: train/loss = 0.39766961336135864, train/raw-loss = 0.3648337423801422, train/logprobs = tensor([[ -1.8441, -10.5570],
        [ -2.2814,  -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283587098121643
Epoch 0, Step 1615: train/loss = 0.3412235677242279, train/raw-loss = 0.311027467250824, train/logprobs = tensor([[-2.3830, -6.3404],
        [-2.7742, -1.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019610643386841
Epoch 0, Step 1616: train/loss = 0.3936716318130493, train/raw-loss = 0.35346001386642456, train/logprobs = tensor([[-2.0719, -4.7431],
        [-4.1377, -1.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4021163582801819
Epoch 0, Step 1617: train/loss = 0.525275707244873, train/raw-loss = 0.48995476961135864, train/logprobs = tensor([[-2.6390, -6.9712],
        [-2.6734, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35320907831192017
Epoch 0, Step 1618: train/loss = 0.26872771978378296, train/raw-loss = 0.2351658046245575, train/logprobs = tensor([[-1.3697, -8.2602],
        [-2.5417, -1.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356192708015442
Epoch 0, Step 1619: train/loss = 0.4869324266910553, train/raw-loss = 0.45639804005622864, train/logprobs = tensor([[-2.5006, -5.6155],
        [-3.1436, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053441047668457
Epoch 0, Step 1620: train/loss = 0.45906323194503784, train/raw-loss = 0.4271824359893799, train/logprobs = tensor([[-0.8420, -3.3447],
        [-2.0289, -1.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31880784034729004
Epoch 0, Step 1621: train/loss = 0.4130539298057556, train/raw-loss = 0.3827352225780487, train/logprobs = tensor([[-2.5782, -6.0501],
        [-2.9960, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031873106956482
Epoch 0, Step 1622: train/loss = 0.19289709627628326, train/raw-loss = 0.1511831283569336, train/logprobs = tensor([[-1.3824, -8.7017],
        [-4.3734, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41713953018188477
Epoch 0, Step 1623: train/loss = 0.39937824010849, train/raw-loss = 0.36231744289398193, train/logprobs = tensor([[-1.4173, -4.8099],
        [-2.7752, -2.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37060779333114624
Epoch 0, Step 1624: train/loss = 0.5573931932449341, train/raw-loss = 0.5202347636222839, train/logprobs = tensor([[-2.0162, -2.8110],
        [-2.8283, -2.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37158459424972534
Epoch 0, Step 1625: train/loss = 0.36483579874038696, train/raw-loss = 0.3282683491706848, train/logprobs = tensor([[-1.4311, -4.0934],
        [-2.6583, -1.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3656746745109558
Epoch 0, Step 1626: train/loss = 0.2993573546409607, train/raw-loss = 0.26506853103637695, train/logprobs = tensor([[-1.6237, -6.6797],
        [-3.5088, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34288835525512695
Epoch 0, Step 1627: train/loss = 0.44793781638145447, train/raw-loss = 0.4113476276397705, train/logprobs = tensor([[-1.5504, -3.8128],
        [-2.7528, -1.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36590200662612915
Epoch 0, Step 1628: train/loss = 0.3049026429653168, train/raw-loss = 0.2732715904712677, train/logprobs = tensor([[-1.3878, -3.4968],
        [-2.9151, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31631049513816833
Epoch 0, Step 1629: train/loss = 0.5106662511825562, train/raw-loss = 0.47627097368240356, train/logprobs = tensor([[-1.7009, -2.2625],
        [-2.2490, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34395283460617065
Epoch 0, Step 1630: train/loss = 0.15123148262500763, train/raw-loss = 0.12685877084732056, train/logprobs = tensor([[-1.7197, -7.2508],
        [-3.2879, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24372713267803192
Epoch 0, Step 1631: train/loss = 0.3238472044467926, train/raw-loss = 0.2820857763290405, train/logprobs = tensor([[-1.9153, -3.9542],
        [-3.8161, -2.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4176141023635864
Epoch 0, Step 1632: train/loss = 0.26014798879623413, train/raw-loss = 0.22607874870300293, train/logprobs = tensor([[-1.6919, -5.3841],
        [-3.4325, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.340692400932312
Epoch 0, Step 1633: train/loss = 0.27224862575531006, train/raw-loss = 0.2365424931049347, train/logprobs = tensor([[-0.7455, -3.6030],
        [-2.7387, -1.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35706111788749695
Epoch 0, Step 1634: train/loss = 1.5361082553863525, train/raw-loss = 1.5062404870986938, train/logprobs = tensor([[-6.0686, -7.3335],
        [-2.5899, -1.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2986784279346466
Epoch 0, Step 1635: train/loss = 0.3275350034236908, train/raw-loss = 0.29842302203178406, train/logprobs = tensor([[-1.6157, -8.5754],
        [-3.4529, -1.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29111984372138977
Epoch 0, Step 1636: train/loss = 0.44585496187210083, train/raw-loss = 0.4158872365951538, train/logprobs = tensor([[-1.1449, -4.4309],
        [-1.8782, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996772527694702
Epoch 0, Step 1637: train/loss = 0.4705713987350464, train/raw-loss = 0.43576928973197937, train/logprobs = tensor([[-1.1136, -4.8851],
        [-2.1121, -2.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480214774608612
Epoch 0, Step 1638: train/loss = 0.30767297744750977, train/raw-loss = 0.27712562680244446, train/logprobs = tensor([[-1.8862, -5.3062],
        [-3.2286, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054734170436859
Epoch 0, Step 1639: train/loss = 0.289691686630249, train/raw-loss = 0.25905194878578186, train/logprobs = tensor([[-1.2131, -6.0190],
        [-3.0865, -1.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306397408246994
Epoch 0, Step 1640: train/loss = 0.4938383102416992, train/raw-loss = 0.46068844199180603, train/logprobs = tensor([[-1.9481, -4.2319],
        [-3.4001, -2.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33149847388267517
Epoch 0, Step 1641: train/loss = 0.0680953785777092, train/raw-loss = 0.035901233553886414, train/logprobs = tensor([[ -1.0764, -13.2027],
        [ -3.9252,  -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219413757324219
Epoch 0, Step 1642: train/loss = 0.28764212131500244, train/raw-loss = 0.2533791661262512, train/logprobs = tensor([[-0.6835, -7.3020],
        [-2.7726, -1.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34262925386428833
Epoch 0, Step 1643: train/loss = 0.25081923604011536, train/raw-loss = 0.2169119268655777, train/logprobs = tensor([[-1.7199, -8.3122],
        [-2.9621, -1.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390733003616333
Epoch 0, Step 1644: train/loss = 0.41940048336982727, train/raw-loss = 0.3785448372364044, train/logprobs = tensor([[-1.9691, -2.9384],
        [-4.1671, -2.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40855666995048523
Epoch 0, Step 1645: train/loss = 0.4098261296749115, train/raw-loss = 0.38341471552848816, train/logprobs = tensor([[-2.5788, -4.9583],
        [-3.0181, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641139328479767
Epoch 0, Step 1646: train/loss = 0.3864148259162903, train/raw-loss = 0.3545840084552765, train/logprobs = tensor([[-2.4067, -4.0354],
        [-2.7686, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31830844283103943
Epoch 0, Step 1647: train/loss = 0.29413703083992004, train/raw-loss = 0.2606777846813202, train/logprobs = tensor([[-1.0268, -5.0499],
        [-2.7151, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345924913883209
Epoch 0, Step 1648: train/loss = 0.6161152124404907, train/raw-loss = 0.5823761224746704, train/logprobs = tensor([[-2.6738, -6.8033],
        [-2.5458, -0.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373909592628479
Epoch 0, Step 1649: train/loss = 0.5334690809249878, train/raw-loss = 0.4953245222568512, train/logprobs = tensor([[-1.6092, -3.6514],
        [-2.6187, -2.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814449906349182
Epoch 0, Step 1650: train/loss = 0.8773852586746216, train/raw-loss = 0.8468976616859436, train/logprobs = tensor([[-2.9172, -5.0564],
        [-1.8330, -1.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048757314682007
Epoch 0, Step 1651: train/loss = 0.3800674378871918, train/raw-loss = 0.34744393825531006, train/logprobs = tensor([[-2.1377, -5.4079],
        [-3.2059, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262346088886261
Epoch 0, Step 1652: train/loss = 0.2668013572692871, train/raw-loss = 0.23531433939933777, train/logprobs = tensor([[-1.4834, -3.7153],
        [-3.3152, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148704171180725
Epoch 0, Step 1653: train/loss = 0.43785086274147034, train/raw-loss = 0.4069824516773224, train/logprobs = tensor([[-1.8056, -3.2577],
        [-3.0397, -1.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086841106414795
Epoch 0, Step 1654: train/loss = 0.4013764262199402, train/raw-loss = 0.37019988894462585, train/logprobs = tensor([[-1.7062, -3.8958],
        [-1.9568, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117654323577881
Epoch 0, Step 1655: train/loss = 0.3353269398212433, train/raw-loss = 0.2984268069267273, train/logprobs = tensor([[-1.4785, -3.2756],
        [-2.7917, -1.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36900147795677185
Epoch 0, Step 1656: train/loss = 0.617244303226471, train/raw-loss = 0.5846572518348694, train/logprobs = tensor([[-2.4634, -3.1105],
        [-2.0981, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258700966835022
Epoch 0, Step 1657: train/loss = 0.31802424788475037, train/raw-loss = 0.28672006726264954, train/logprobs = tensor([[-1.9110, -4.0051],
        [-3.2134, -0.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130418658256531
Epoch 0, Step 1658: train/loss = 0.3111675977706909, train/raw-loss = 0.27649790048599243, train/logprobs = tensor([[-1.2070, -3.6065],
        [-3.4004, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3466971814632416
Epoch 0, Step 1659: train/loss = 0.14879250526428223, train/raw-loss = 0.11390463262796402, train/logprobs = tensor([[-2.1533, -5.0505],
        [-4.5880, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488786816596985
Epoch 0, Step 1660: train/loss = 0.3452022671699524, train/raw-loss = 0.3120467960834503, train/logprobs = tensor([[-1.9007, -7.0535],
        [-2.6823, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315545320510864
Epoch 0, Step 1661: train/loss = 0.22230997681617737, train/raw-loss = 0.1872880458831787, train/logprobs = tensor([[-1.3321, -4.3351],
        [-3.7778, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502193093299866
Epoch 0, Step 1662: train/loss = 0.1688804030418396, train/raw-loss = 0.13800019025802612, train/logprobs = tensor([[-1.5228, -7.6374],
        [-2.8659, -1.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088019788265228
Epoch 0, Step 1663: train/loss = 0.4767730236053467, train/raw-loss = 0.44709253311157227, train/logprobs = tensor([[-2.1135, -2.0424],
        [-2.7056, -1.2061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968047857284546
Epoch 0, Step 1664: train/loss = 0.4355783760547638, train/raw-loss = 0.4029925465583801, train/logprobs = tensor([[-1.0988, -5.1794],
        [-2.7863, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32585805654525757
Epoch 0, Step 1665: train/loss = 0.2115270495414734, train/raw-loss = 0.17300041019916534, train/logprobs = tensor([[-1.5665, -5.1760],
        [-3.9461, -2.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38526642322540283
Epoch 0, Step 1666: train/loss = 0.3504951596260071, train/raw-loss = 0.3157932162284851, train/logprobs = tensor([[-1.0612, -5.3733],
        [-3.5797, -2.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470194637775421
Epoch 0, Step 1667: train/loss = 0.5287962555885315, train/raw-loss = 0.4975399971008301, train/logprobs = tensor([[-2.9670, -4.1391],
        [-4.2545, -2.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.312562495470047
Epoch 0, Step 1668: train/loss = 0.13754504919052124, train/raw-loss = 0.10408082604408264, train/logprobs = tensor([[-0.8888, -8.7046],
        [-2.8457, -1.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346421718597412
Epoch 0, Step 1669: train/loss = 0.5278633832931519, train/raw-loss = 0.49151039123535156, train/logprobs = tensor([[-1.1822, -2.2414],
        [-2.5691, -2.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3635299503803253
Epoch 0, Step 1670: train/loss = 0.5762507319450378, train/raw-loss = 0.5464615821838379, train/logprobs = tensor([[-1.4682, -1.8987],
        [-1.7969, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297891765832901
Epoch 0, Step 1671: train/loss = 0.22120621800422668, train/raw-loss = 0.18337956070899963, train/logprobs = tensor([[-1.3104, -6.6806],
        [-3.3826, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37826696038246155
Epoch 0, Step 1672: train/loss = 0.27264052629470825, train/raw-loss = 0.23829057812690735, train/logprobs = tensor([[-1.4743, -4.0880],
        [-4.1747, -1.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434995412826538
Epoch 0, Step 1673: train/loss = 0.2850605249404907, train/raw-loss = 0.25550606846809387, train/logprobs = tensor([[-1.6205, -6.9212],
        [-3.5814, -1.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29554465413093567
Epoch 0, Step 1674: train/loss = 0.4742929935455322, train/raw-loss = 0.4430287480354309, train/logprobs = tensor([[-1.5104, -8.3781],
        [-2.6354, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126424551010132
Epoch 0, Step 1675: train/loss = 0.486034095287323, train/raw-loss = 0.4531027376651764, train/logprobs = tensor([[-1.4182, -2.8774],
        [-2.5022, -1.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293139934539795
Epoch 0, Step 1676: train/loss = 0.3435434103012085, train/raw-loss = 0.31263139843940735, train/logprobs = tensor([[-2.3798, -8.4744],
        [-2.7139, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30911993980407715
Epoch 0, Step 1677: train/loss = 0.5743386745452881, train/raw-loss = 0.5376432538032532, train/logprobs = tensor([[-1.1128, -2.9156],
        [-2.7292, -2.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669542372226715
Epoch 0, Step 1678: train/loss = 0.4963614046573639, train/raw-loss = 0.4625752866268158, train/logprobs = tensor([[-1.5678, -6.4076],
        [-4.3499, -2.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378612995147705
Epoch 0, Step 1679: train/loss = 0.47729814052581787, train/raw-loss = 0.4473935663700104, train/logprobs = tensor([[-1.5967, -5.4261],
        [-2.4088, -0.6748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2990456521511078
Epoch 0, Step 1680: train/loss = 0.6876224875450134, train/raw-loss = 0.6592874526977539, train/logprobs = tensor([[-2.5897, -4.1125],
        [-1.6140, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833501696586609
Epoch 0, Step 1681: train/loss = 0.3058069944381714, train/raw-loss = 0.2720113694667816, train/logprobs = tensor([[-1.6773, -5.3081],
        [-3.3294, -2.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33795619010925293
Epoch 0, Step 1682: train/loss = 0.26649102568626404, train/raw-loss = 0.22912272810935974, train/logprobs = tensor([[-1.9376, -3.7239],
        [-3.9560, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37368303537368774
Epoch 0, Step 1683: train/loss = 0.4539731442928314, train/raw-loss = 0.42106229066848755, train/logprobs = tensor([[-1.8251, -1.6929],
        [-3.2358, -1.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291088342666626
Epoch 0, Step 1684: train/loss = 0.23950321972370148, train/raw-loss = 0.2062159776687622, train/logprobs = tensor([[-1.1419, -6.4114],
        [-3.5299, -2.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33287227153778076
Epoch 0, Step 1685: train/loss = 0.10599159449338913, train/raw-loss = 0.07019101083278656, train/logprobs = tensor([[-1.5649, -7.8974],
        [-4.0807, -1.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580057919025421
Epoch 0, Step 1686: train/loss = 0.09223492443561554, train/raw-loss = 0.05914434790611267, train/logprobs = tensor([[-1.4642, -7.4245],
        [-3.7087, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3309057652950287
Epoch 0, Step 1687: train/loss = 0.2016257345676422, train/raw-loss = 0.16968569159507751, train/logprobs = tensor([[-0.8521, -7.6460],
        [-2.7729, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194005489349365
Epoch 0, Step 1688: train/loss = 0.22802290320396423, train/raw-loss = 0.1965314894914627, train/logprobs = tensor([[-1.2979, -6.7002],
        [-3.5187, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149142265319824
Epoch 0, Step 1689: train/loss = 0.46765071153640747, train/raw-loss = 0.4414151906967163, train/logprobs = tensor([[-2.6302, -3.5524],
        [-2.2810, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623552978038788
Epoch 0, Step 1690: train/loss = 0.6511703729629517, train/raw-loss = 0.6099252104759216, train/logprobs = tensor([[-2.0723, -6.0395],
        [-3.3941, -3.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41245192289352417
Epoch 0, Step 1691: train/loss = 0.7252579927444458, train/raw-loss = 0.6929545402526855, train/logprobs = tensor([[-2.5384, -4.3937],
        [-3.2701, -1.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230348825454712
Epoch 0, Step 1692: train/loss = 0.44865837693214417, train/raw-loss = 0.41853007674217224, train/logprobs = tensor([[-1.4666, -2.9948],
        [-2.5154, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012830317020416
Epoch 0, Step 1693: train/loss = 0.15164139866828918, train/raw-loss = 0.12321058660745621, train/logprobs = tensor([[-1.3424, -9.5687],
        [-2.9425, -1.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2843080759048462
Epoch 0, Step 1694: train/loss = 0.2520808279514313, train/raw-loss = 0.22247543931007385, train/logprobs = tensor([[-1.0759, -4.2492],
        [-2.1395, -1.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29605379700660706
Epoch 0, Step 1695: train/loss = 0.5974380970001221, train/raw-loss = 0.5668998956680298, train/logprobs = tensor([[-1.0528, -1.9466],
        [-1.7285, -1.6377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053816854953766
Epoch 0, Step 1696: train/loss = 0.36587443947792053, train/raw-loss = 0.3257853388786316, train/logprobs = tensor([[-1.1720, -5.6181],
        [-4.3874, -2.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4008907377719879
Epoch 0, Step 1697: train/loss = 0.22120946645736694, train/raw-loss = 0.1866237223148346, train/logprobs = tensor([[-1.4682, -5.4930],
        [-2.4620, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3458574116230011
Epoch 0, Step 1698: train/loss = 0.9889307618141174, train/raw-loss = 0.9516698122024536, train/logprobs = tensor([[-2.1234, -2.7334],
        [-2.4958, -3.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37260985374450684
Epoch 0, Step 1699: train/loss = 0.44000428915023804, train/raw-loss = 0.4088473916053772, train/logprobs = tensor([[-1.2613, -5.4018],
        [-1.9618, -2.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115690052509308
Epoch 0, Step 1700: train/loss = 0.5697586536407471, train/raw-loss = 0.5396339893341064, train/logprobs = tensor([[-2.0289, -2.4936],
        [-2.5999, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012467324733734
Epoch 0, Step 1701: train/loss = 0.6162226796150208, train/raw-loss = 0.5876109600067139, train/logprobs = tensor([[-2.0074, -3.4676],
        [-2.3944, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2861170172691345
Epoch 0, Step 1702: train/loss = 0.6524913311004639, train/raw-loss = 0.6191565990447998, train/logprobs = tensor([[-1.7874, -2.4006],
        [-2.1978, -1.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333480954170227
Epoch 0, Step 1703: train/loss = 0.12235143780708313, train/raw-loss = 0.08861367404460907, train/logprobs = tensor([[-2.5882, -7.0787],
        [-4.7219, -1.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33737748861312866
Epoch 0, Step 1704: train/loss = 0.6922335624694824, train/raw-loss = 0.6611011624336243, train/logprobs = tensor([[-1.9477, -3.4653],
        [-1.8769, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31132352352142334
Epoch 0, Step 1705: train/loss = 0.46755868196487427, train/raw-loss = 0.4312984049320221, train/logprobs = tensor([[-1.1496, -4.7334],
        [-2.6635, -2.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36260315775871277
Epoch 0, Step 1706: train/loss = 0.3358646333217621, train/raw-loss = 0.2921646237373352, train/logprobs = tensor([[-1.4976, -6.5668],
        [-4.0714, -2.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.437000036239624
Epoch 0, Step 1707: train/loss = 0.487022340297699, train/raw-loss = 0.456636518239975, train/logprobs = tensor([[-1.4440, -4.7035],
        [-2.2470, -2.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30385822057724
Epoch 0, Step 1708: train/loss = 0.21655410528182983, train/raw-loss = 0.1860559582710266, train/logprobs = tensor([[-1.2364, -6.4864],
        [-3.7828, -1.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30498141050338745
Epoch 0, Step 1709: train/loss = 0.35892337560653687, train/raw-loss = 0.32124951481819153, train/logprobs = tensor([[-1.8688, -4.2477],
        [-3.0451, -1.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767388164997101
Epoch 0, Step 1710: train/loss = 0.14425747096538544, train/raw-loss = 0.10672199726104736, train/logprobs = tensor([[-1.2201, -6.7745],
        [-3.6178, -1.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37535473704338074
Epoch 0, Step 1711: train/loss = 0.23713554441928864, train/raw-loss = 0.19862112402915955, train/logprobs = tensor([[-1.3301, -5.3779],
        [-3.8934, -1.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38514429330825806
Epoch 0, Step 1712: train/loss = 0.5656582117080688, train/raw-loss = 0.5364943742752075, train/logprobs = tensor([[-2.9381, -4.6199],
        [-2.9650, -2.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291637659072876
Epoch 0, Step 1713: train/loss = 0.14632630348205566, train/raw-loss = 0.11439352482557297, train/logprobs = tensor([[-1.2891, -6.3358],
        [-2.9175, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3193278908729553
Epoch 0, Step 1714: train/loss = 0.5444600582122803, train/raw-loss = 0.5127060413360596, train/logprobs = tensor([[-1.5374, -2.0928],
        [-2.9111, -1.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31754058599472046
Epoch 0, Step 1715: train/loss = 0.3625064790248871, train/raw-loss = 0.3239322304725647, train/logprobs = tensor([[-1.3243, -4.1478],
        [-3.6372, -2.2737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3857426047325134
Epoch 0, Step 1716: train/loss = 0.5186522006988525, train/raw-loss = 0.49000588059425354, train/logprobs = tensor([[-1.8822, -2.5222],
        [-2.4233, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28646302223205566
Epoch 0, Step 1717: train/loss = 0.2976328730583191, train/raw-loss = 0.26832160353660583, train/logprobs = tensor([[-1.2335, -4.6983],
        [-2.3855, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931126356124878
Epoch 0, Step 1718: train/loss = 0.4743788242340088, train/raw-loss = 0.43857231736183167, train/logprobs = tensor([[-1.7178, -4.3953],
        [-2.4259, -1.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35806509852409363
Epoch 0, Step 1719: train/loss = 0.3188946545124054, train/raw-loss = 0.2831770181655884, train/logprobs = tensor([[-1.1107, -4.6725],
        [-2.6251, -1.9364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35717642307281494
Epoch 0, Step 1720: train/loss = 0.171236053109169, train/raw-loss = 0.13794803619384766, train/logprobs = tensor([[-2.2012, -9.5728],
        [-3.9674, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3328803479671478
Epoch 0, Step 1721: train/loss = 0.17299631237983704, train/raw-loss = 0.14185981452465057, train/logprobs = tensor([[-1.2191, -6.8829],
        [-2.7342, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3113649785518646
Epoch 0, Step 1722: train/loss = 0.12400531023740768, train/raw-loss = 0.09080064296722412, train/logprobs = tensor([[-1.8951, -9.2500],
        [-4.3907, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320466876029968
Epoch 0, Step 1723: train/loss = 0.3894338607788086, train/raw-loss = 0.3604947328567505, train/logprobs = tensor([[-1.8135, -4.1350],
        [-2.0730, -1.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893911600112915
Epoch 0, Step 1724: train/loss = 0.20779669284820557, train/raw-loss = 0.17597851157188416, train/logprobs = tensor([[-1.1000, -6.4080],
        [-3.2573, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31818175315856934
Epoch 0, Step 1725: train/loss = 0.36251726746559143, train/raw-loss = 0.3214235305786133, train/logprobs = tensor([[-1.5646, -7.0326],
        [-4.3328, -2.9805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109373986721039
Epoch 0, Step 1726: train/loss = 0.5233222842216492, train/raw-loss = 0.4889953136444092, train/logprobs = tensor([[-2.6181, -7.1499],
        [-3.4963, -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34326955676078796
Epoch 0, Step 1727: train/loss = 0.4202847480773926, train/raw-loss = 0.3819596469402313, train/logprobs = tensor([[-1.7871, -4.2071],
        [-2.6262, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3832511901855469
Epoch 0, Step 1728: train/loss = 0.17052555084228516, train/raw-loss = 0.13957975804805756, train/logprobs = tensor([[-1.5878, -6.4108],
        [-3.7609, -1.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094578981399536
Epoch 0, Step 1729: train/loss = 0.3246287703514099, train/raw-loss = 0.29524457454681396, train/logprobs = tensor([[-1.1252, -4.4036],
        [-2.6870, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938419282436371
Epoch 0, Step 1730: train/loss = 0.2038668990135193, train/raw-loss = 0.17647066712379456, train/logprobs = tensor([[-1.1963, -5.1241],
        [-3.2883, -1.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27396225929260254
Epoch 0, Step 1731: train/loss = 0.2426944077014923, train/raw-loss = 0.21059605479240417, train/logprobs = tensor([[-2.4152, -7.3742],
        [-3.5698, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209836781024933
Epoch 0, Step 1732: train/loss = 0.1806057244539261, train/raw-loss = 0.1463928073644638, train/logprobs = tensor([[-1.8899, -8.0462],
        [-3.4781, -1.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421292006969452
Epoch 0, Step 1733: train/loss = 0.3430400490760803, train/raw-loss = 0.3086221218109131, train/logprobs = tensor([[-1.6513, -9.0529],
        [-2.9220, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34417927265167236
Epoch 0, Step 1734: train/loss = 0.5081691145896912, train/raw-loss = 0.4764370322227478, train/logprobs = tensor([[-2.5885, -4.7603],
        [-2.5517, -1.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3173207938671112
Epoch 0, Step 1735: train/loss = 0.4810485243797302, train/raw-loss = 0.45577311515808105, train/logprobs = tensor([[-1.8775, -3.8216],
        [-1.6849, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25275394320487976
Epoch 0, Step 1736: train/loss = 0.4518703520298004, train/raw-loss = 0.41446495056152344, train/logprobs = tensor([[-1.5445, -3.3258],
        [-3.1551, -3.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37405404448509216
Epoch 0, Step 1737: train/loss = 0.49722540378570557, train/raw-loss = 0.463228702545166, train/logprobs = tensor([[-1.9105, -6.3055],
        [-3.4464, -1.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3399668335914612
Epoch 0, Step 1738: train/loss = 0.42050859332084656, train/raw-loss = 0.3870711326599121, train/logprobs = tensor([[-2.5815, -5.0151],
        [-2.5593, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3343747556209564
Epoch 0, Step 1739: train/loss = 0.41358619928359985, train/raw-loss = 0.386425644159317, train/logprobs = tensor([[-1.4872, -2.9374],
        [-2.7168, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27160555124282837
Epoch 0, Step 1740: train/loss = 0.23388990759849548, train/raw-loss = 0.20475108921527863, train/logprobs = tensor([[-1.0674, -4.1223],
        [-3.1086, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913880944252014
Epoch 0, Step 1741: train/loss = 0.43735456466674805, train/raw-loss = 0.4123899042606354, train/logprobs = tensor([[-1.2292, -2.1956],
        [-1.9942, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2496468722820282
Epoch 0, Step 1742: train/loss = 0.5025417804718018, train/raw-loss = 0.46957576274871826, train/logprobs = tensor([[-1.4352, -4.5430],
        [-1.5984, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32966017723083496
Epoch 0, Step 1743: train/loss = 0.5903342962265015, train/raw-loss = 0.5554529428482056, train/logprobs = tensor([[-1.5071, -2.5531],
        [-2.3705, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34881332516670227
Epoch 0, Step 1744: train/loss = 0.34804487228393555, train/raw-loss = 0.31674090027809143, train/logprobs = tensor([[-1.7974, -4.7721],
        [-2.5542, -1.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31303998827934265
Epoch 0, Step 1745: train/loss = 0.2865343689918518, train/raw-loss = 0.25566214323043823, train/logprobs = tensor([[-1.7271, -2.8350],
        [-2.9811, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3087223768234253
Epoch 0, Step 1746: train/loss = 0.31801557540893555, train/raw-loss = 0.27765193581581116, train/logprobs = tensor([[-1.7278, -4.5842],
        [-3.9800, -2.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036361575126648
Epoch 0, Step 1747: train/loss = 0.41496002674102783, train/raw-loss = 0.3897833228111267, train/logprobs = tensor([[-1.6155, -7.0095],
        [-2.2946, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25176718831062317
Epoch 0, Step 1748: train/loss = 0.19477273523807526, train/raw-loss = 0.16386866569519043, train/logprobs = tensor([[-2.0945, -7.3677],
        [-3.7611, -1.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090406656265259
Epoch 0, Step 1749: train/loss = 0.27984383702278137, train/raw-loss = 0.2399168312549591, train/logprobs = tensor([[-1.3461, -5.8910],
        [-3.4417, -1.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3992702066898346
Epoch 0, Step 1750: train/loss = 0.33691805601119995, train/raw-loss = 0.3041499853134155, train/logprobs = tensor([[-1.6475, -6.3319],
        [-3.4138, -1.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276810348033905
Epoch 0, Step 1751: train/loss = 0.30721360445022583, train/raw-loss = 0.27494198083877563, train/logprobs = tensor([[-1.2592, -4.1813],
        [-2.2489, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3227163553237915
Epoch 0, Step 1752: train/loss = 0.17720521986484528, train/raw-loss = 0.14047572016716003, train/logprobs = tensor([[-1.8555, -7.8490],
        [-3.6028, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672950863838196
Epoch 0, Step 1753: train/loss = 0.2697577476501465, train/raw-loss = 0.2339550107717514, train/logprobs = tensor([[-1.1559, -5.8952],
        [-2.6440, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35802751779556274
Epoch 0, Step 1754: train/loss = 0.38812458515167236, train/raw-loss = 0.3575054705142975, train/logprobs = tensor([[-1.6689, -4.7442],
        [-2.1235, -1.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30619099736213684
Epoch 0, Step 1755: train/loss = 0.35884761810302734, train/raw-loss = 0.32251736521720886, train/logprobs = tensor([[-1.5160, -5.7122],
        [-2.6259, -2.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363302618265152
Epoch 0, Step 1756: train/loss = 0.14287371933460236, train/raw-loss = 0.1109619066119194, train/logprobs = tensor([[-1.5780, -8.7760],
        [-3.5991, -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31911811232566833
Epoch 0, Step 1757: train/loss = 0.43860840797424316, train/raw-loss = 0.4041662812232971, train/logprobs = tensor([[-1.1841, -1.7510],
        [-2.9304, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3444215953350067
Epoch 0, Step 1758: train/loss = 0.3960033059120178, train/raw-loss = 0.3696388900279999, train/logprobs = tensor([[-2.7615, -6.3671],
        [-3.3012, -1.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2636443078517914
Epoch 0, Step 1759: train/loss = 0.3859604001045227, train/raw-loss = 0.35777100920677185, train/logprobs = tensor([[-2.2991, -6.1086],
        [-2.8386, -1.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2818939685821533
Epoch 0, Step 1760: train/loss = 0.7357558608055115, train/raw-loss = 0.7008538246154785, train/logprobs = tensor([[-1.8354, -3.1027],
        [-1.6200, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490205407142639
Epoch 0, Step 1761: train/loss = 0.5210893154144287, train/raw-loss = 0.4957277774810791, train/logprobs = tensor([[-1.4382, -3.3428],
        [-1.1844, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536146938800812
Epoch 0, Step 1762: train/loss = 0.13763470947742462, train/raw-loss = 0.10876305401325226, train/logprobs = tensor([[-1.9195, -8.2756],
        [-3.7058, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28871655464172363
Epoch 0, Step 1763: train/loss = 0.26530027389526367, train/raw-loss = 0.2337270826101303, train/logprobs = tensor([[-1.0962, -6.2662],
        [-2.6617, -1.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31573182344436646
Epoch 0, Step 1764: train/loss = 0.3887917995452881, train/raw-loss = 0.3623470067977905, train/logprobs = tensor([[-1.8250, -8.0814],
        [-2.9117, -0.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26444804668426514
Epoch 0, Step 1765: train/loss = 0.32712140679359436, train/raw-loss = 0.29669660329818726, train/logprobs = tensor([[-1.1776, -3.2669],
        [-3.1729, -1.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3042480945587158
Epoch 0, Step 1766: train/loss = 0.12443385273218155, train/raw-loss = 0.09166561812162399, train/logprobs = tensor([[-1.1734, -9.0350],
        [-3.9745, -2.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276822566986084
Epoch 0, Step 1767: train/loss = 0.2412647008895874, train/raw-loss = 0.2059900462627411, train/logprobs = tensor([[-0.9703, -6.7278],
        [-3.0263, -1.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352746844291687
Epoch 0, Step 1768: train/loss = 0.31838637590408325, train/raw-loss = 0.28565797209739685, train/logprobs = tensor([[-1.2902, -6.2745],
        [-3.3447, -1.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32728368043899536
Epoch 0, Step 1769: train/loss = 0.2996828854084015, train/raw-loss = 0.26976779103279114, train/logprobs = tensor([[ -1.6820, -12.0232],
        [ -3.0711,  -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29915115237236023
Epoch 0, Step 1770: train/loss = 0.39303064346313477, train/raw-loss = 0.35927003622055054, train/logprobs = tensor([[-1.3064, -4.0502],
        [-3.0264, -1.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33760637044906616
Epoch 0, Step 1771: train/loss = 0.4513128399848938, train/raw-loss = 0.4229527711868286, train/logprobs = tensor([[-1.8030, -3.1610],
        [-2.0949, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28360071778297424
Epoch 0, Step 1772: train/loss = 0.201212078332901, train/raw-loss = 0.1701119989156723, train/logprobs = tensor([[-1.0708, -5.8689],
        [-2.9020, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31100061535835266
Epoch 0, Step 1773: train/loss = 0.6505353450775146, train/raw-loss = 0.6247583031654358, train/logprobs = tensor([[-1.6997, -2.0399],
        [-1.2618, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25777068734169006
Epoch 0, Step 1774: train/loss = 0.29714855551719666, train/raw-loss = 0.2594369053840637, train/logprobs = tensor([[-1.5848, -5.0756],
        [-4.1085, -2.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3771164119243622
Epoch 0, Step 1775: train/loss = 0.4139612019062042, train/raw-loss = 0.38134104013442993, train/logprobs = tensor([[-1.5999, -7.1078],
        [-3.9598, -3.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262014389038086
Epoch 0, Step 1776: train/loss = 0.2650698721408844, train/raw-loss = 0.23140856623649597, train/logprobs = tensor([[-1.4095, -5.1771],
        [-3.3197, -1.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33661311864852905
Epoch 0, Step 1777: train/loss = 0.37470024824142456, train/raw-loss = 0.34585651755332947, train/logprobs = tensor([[-1.3180, -5.0632],
        [-1.8975, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28843703866004944
Epoch 0, Step 1778: train/loss = 0.7464495897293091, train/raw-loss = 0.7132138609886169, train/logprobs = tensor([[-2.6764, -3.2370],
        [-2.0071, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33235687017440796
Epoch 0, Step 1779: train/loss = 0.3104232847690582, train/raw-loss = 0.28007668256759644, train/logprobs = tensor([[-1.4393, -5.9546],
        [-2.8842, -2.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034660816192627
Epoch 0, Step 1780: train/loss = 0.31277143955230713, train/raw-loss = 0.2848014235496521, train/logprobs = tensor([[-1.2773, -4.2123],
        [-2.2717, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27970030903816223
Epoch 0, Step 1781: train/loss = 0.06463140994310379, train/raw-loss = 0.03218628466129303, train/logprobs = tensor([[-1.7920, -7.4212],
        [-4.7196, -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244512379169464
Epoch 0, Step 1782: train/loss = 0.5039116144180298, train/raw-loss = 0.47975489497184753, train/logprobs = tensor([[-1.0606, -3.2174],
        [-1.5622, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24156755208969116
Epoch 0, Step 1783: train/loss = 0.28416523337364197, train/raw-loss = 0.251259446144104, train/logprobs = tensor([[-2.0882, -4.4563],
        [-3.5529, -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290577530860901
Epoch 0, Step 1784: train/loss = 0.3763669729232788, train/raw-loss = 0.3431103527545929, train/logprobs = tensor([[-0.9446, -2.9232],
        [-3.0405, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33256611227989197
Epoch 0, Step 1785: train/loss = 0.39303725957870483, train/raw-loss = 0.355224072933197, train/logprobs = tensor([[-1.2158, -3.8479],
        [-3.0564, -2.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37813133001327515
Epoch 0, Step 1786: train/loss = 0.6996201276779175, train/raw-loss = 0.6633068919181824, train/logprobs = tensor([[-2.4970, -4.8387],
        [-2.9819, -1.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36313220858573914
Epoch 0, Step 1787: train/loss = 0.12536469101905823, train/raw-loss = 0.09162859618663788, train/logprobs = tensor([[-2.1863, -7.9992],
        [-3.9245, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373609185218811
Epoch 0, Step 1788: train/loss = 0.44591936469078064, train/raw-loss = 0.41144686937332153, train/logprobs = tensor([[-1.9509, -4.8024],
        [-3.8487, -2.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447250425815582
Epoch 0, Step 1789: train/loss = 0.10968083888292313, train/raw-loss = 0.07518862187862396, train/logprobs = tensor([[-1.6059, -7.9977],
        [-3.8747, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34492215514183044
Epoch 0, Step 1790: train/loss = 0.1671905815601349, train/raw-loss = 0.14125104248523712, train/logprobs = tensor([[-1.5183, -7.0996],
        [-3.1923, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25939539074897766
Epoch 0, Step 1791: train/loss = 0.48806777596473694, train/raw-loss = 0.4528755247592926, train/logprobs = tensor([[-1.4345, -3.1731],
        [-2.3948, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3519226610660553
Epoch 0, Step 1792: train/loss = 0.3574414551258087, train/raw-loss = 0.32098859548568726, train/logprobs = tensor([[-1.5566, -6.7312],
        [-4.3665, -2.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645287752151489
Epoch 0, Step 1793: train/loss = 0.4936513304710388, train/raw-loss = 0.4703105390071869, train/logprobs = tensor([[-1.7673, -2.6244],
        [-2.2738, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23340749740600586
Epoch 0, Step 1794: train/loss = 0.2807543873786926, train/raw-loss = 0.2552415728569031, train/logprobs = tensor([[-1.2142, -8.5483],
        [-1.5425, -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25512829422950745
Epoch 0, Step 1795: train/loss = 0.4839114248752594, train/raw-loss = 0.44942507147789, train/logprobs = tensor([[-1.7085, -5.3503],
        [-3.2041, -2.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3448634445667267
Epoch 0, Step 1796: train/loss = 0.3620012700557709, train/raw-loss = 0.3291500508785248, train/logprobs = tensor([[-1.4014, -3.6333],
        [-2.6956, -1.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32851219177246094
Epoch 0, Step 1797: train/loss = 0.33343327045440674, train/raw-loss = 0.3020629584789276, train/logprobs = tensor([[-1.0427, -5.6916],
        [-2.9718, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31370288133621216
Epoch 0, Step 1798: train/loss = 0.3450177311897278, train/raw-loss = 0.3100265860557556, train/logprobs = tensor([[-2.1273, -6.8675],
        [-3.1376, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3499113917350769
Epoch 0, Step 1799: train/loss = 0.8692169785499573, train/raw-loss = 0.8404070138931274, train/logprobs = tensor([[-2.6896, -4.8723],
        [-1.4103, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28810012340545654
Epoch 0, Step 1800: train/loss = 0.2781336307525635, train/raw-loss = 0.243599072098732, train/logprobs = tensor([[-1.1658, -5.2197],
        [-2.5834, -1.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3453454375267029
Epoch 0, Step 1801: train/loss = 0.4366524815559387, train/raw-loss = 0.4057545065879822, train/logprobs = tensor([[-1.8413, -4.1772],
        [-3.1449, -2.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30897966027259827
Epoch 0, Step 1802: train/loss = 0.3187366724014282, train/raw-loss = 0.28336071968078613, train/logprobs = tensor([[-1.9227, -9.2758],
        [-3.9878, -1.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35375964641571045
