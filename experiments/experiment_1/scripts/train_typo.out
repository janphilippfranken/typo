{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-11 22:15:40,179][root][INFO] - beta: 2.0
[2024-03-11 22:15:40,179][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-2.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-2.0.json
n helpful: 2000
n harmless: 1806
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0.
3806
tokenized 3806 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-2.0-1e-6-iteration-0.
Epoch 0, Step 0: train/loss = 0.626151442527771, train/raw-loss = 0.626151442527771, train/logprobs = tensor([[-0.5320, -1.6266],
        [-0.6046, -1.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6514006853103638, train/raw-loss = 0.6514006853103638, train/logprobs = tensor([[-0.5028, -0.8636],
        [-0.5280, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6812334656715393, train/raw-loss = 0.6812334656715393, train/logprobs = tensor([[-0.4953, -0.8415],
        [-0.5338, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.5803045034408569, train/raw-loss = 0.5803045034408569, train/logprobs = tensor([[-0.5518, -2.2224],
        [-0.6612, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.62431401014328, train/raw-loss = 0.62431401014328, train/logprobs = tensor([[-0.5353, -0.9661],
        [-0.8186, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6697949171066284, train/raw-loss = 0.6697949171066284, train/logprobs = tensor([[-0.4912, -0.8927],
        [-0.5894, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6718199849128723, train/raw-loss = 0.6718199849128723, train/logprobs = tensor([[-0.5810, -0.5317],
        [-0.6328, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6043583750724792, train/raw-loss = 0.6043583750724792, train/logprobs = tensor([[-0.5441, -1.7520],
        [-0.6556, -1.4345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.5578873157501221, train/raw-loss = 0.5578873157501221, train/logprobs = tensor([[-0.5600, -2.3311],
        [-0.6450, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.643979549407959, train/raw-loss = 0.643979549407959, train/logprobs = tensor([[-0.5995, -0.9546],
        [-0.7227, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6829110980033875, train/raw-loss = 0.6829110980033875, train/logprobs = tensor([[-0.7218, -0.9243],
        [-0.7852, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6631162762641907, train/raw-loss = 0.6631162762641907, train/logprobs = tensor([[-0.6360, -0.8920],
        [-0.7353, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.4811258316040039, train/raw-loss = 0.4811258316040039, train/logprobs = tensor([[-0.6975, -2.5671],
        [-0.9054, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6171160340309143, train/raw-loss = 0.6171160340309143, train/logprobs = tensor([[-0.5521, -1.5341],
        [-0.6184, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6337964534759521, train/raw-loss = 0.6337964534759521, train/logprobs = tensor([[-0.6179, -1.0619],
        [-0.7509, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5917654037475586, train/raw-loss = 0.5917654037475586, train/logprobs = tensor([[-0.5814, -1.9856],
        [-0.6661, -1.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6909119486808777, train/raw-loss = 0.6909119486808777, train/logprobs = tensor([[-0.3845, -0.5524],
        [-0.4099, -0.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6690844893455505, train/raw-loss = 0.6690844893455505, train/logprobs = tensor([[-0.5130, -0.8290],
        [-0.5865, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6579471826553345, train/raw-loss = 0.6579471826553345, train/logprobs = tensor([[-0.4248, -1.0882],
        [-0.4624, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.621723473072052, train/raw-loss = 0.621723473072052, train/logprobs = tensor([[-0.5470, -1.4921],
        [-0.5885, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6308507919311523, train/raw-loss = 0.6308507919311523, train/logprobs = tensor([[-0.7176, -1.0544],
        [-0.8334, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6855326890945435, train/raw-loss = 0.6855326890945435, train/logprobs = tensor([[-0.4429, -0.8201],
        [-0.4723, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6773326396942139, train/raw-loss = 0.6773326396942139, train/logprobs = tensor([[-0.5269, -0.9090],
        [-0.6215, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6563409566879272, train/raw-loss = 0.6563409566879272, train/logprobs = tensor([[-0.5952, -0.8222],
        [-0.6744, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6427162885665894, train/raw-loss = 0.6427162885665894, train/logprobs = tensor([[-0.5477, -0.9513],
        [-0.6836, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6363422274589539, train/raw-loss = 0.6363422274589539, train/logprobs = tensor([[-0.5544, -0.9791],
        [-0.6497, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6998584270477295, train/raw-loss = 0.6998584270477295, train/logprobs = tensor([[-0.4371, -1.0226],
        [-0.4547, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6754298210144043, train/raw-loss = 0.6754298210144043, train/logprobs = tensor([[-0.4159, -0.7634],
        [-0.4320, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6019802093505859, train/raw-loss = 0.6019802093505859, train/logprobs = tensor([[-0.5539, -2.2298],
        [-0.6093, -1.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6605981588363647, train/raw-loss = 0.6605981588363647, train/logprobs = tensor([[-0.5695, -1.0004],
        [-0.6638, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6742237210273743, train/raw-loss = 0.6742237210273743, train/logprobs = tensor([[-0.6284, -0.7568],
        [-0.7241, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6580765247344971, train/raw-loss = 0.6580765247344971, train/logprobs = tensor([[-0.5002, -0.9803],
        [-0.5394, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6737897992134094, train/raw-loss = 0.6737897992134094, train/logprobs = tensor([[-0.5673, -1.0554],
        [-0.6395, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6480326652526855, train/raw-loss = 0.6480326652526855, train/logprobs = tensor([[-0.4636, -1.0161],
        [-0.5075, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6344242691993713, train/raw-loss = 0.6344242691993713, train/logprobs = tensor([[-0.6384, -0.9516],
        [-0.7570, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6920045018196106, train/raw-loss = 0.6920045018196106, train/logprobs = tensor([[-0.5652, -0.6577],
        [-0.5419, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6684216260910034, train/raw-loss = 0.6684216260910034, train/logprobs = tensor([[-0.5399, -0.5232],
        [-0.5776, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.5884003639221191, train/raw-loss = 0.5884003639221191, train/logprobs = tensor([[-0.5314, -1.9258],
        [-0.6220, -1.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6804813146591187, train/raw-loss = 0.6804813146591187, train/logprobs = tensor([[-0.5509, -0.5015],
        [-0.6153, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6681503653526306, train/raw-loss = 0.6681503653526306, train/logprobs = tensor([[-0.6695, -1.2182],
        [-0.7883, -1.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6451807618141174, train/raw-loss = 0.6451807618141174, train/logprobs = tensor([[-0.6167, -0.9360],
        [-0.6884, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6203322410583496, train/raw-loss = 0.6203322410583496, train/logprobs = tensor([[-0.5369, -1.5162],
        [-0.6257, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6210395693778992, train/raw-loss = 0.6210395693778992, train/logprobs = tensor([[-0.6576, -1.6781],
        [-0.7412, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6688458919525146, train/raw-loss = 0.6688458919525146, train/logprobs = tensor([[-0.5880, -0.6682],
        [-0.6841, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5931517481803894, train/raw-loss = 0.5931517481803894, train/logprobs = tensor([[-0.4521, -2.4428],
        [-0.5037, -1.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.5665391683578491, train/raw-loss = 0.5665391683578491, train/logprobs = tensor([[-0.5752, -2.2205],
        [-0.6844, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.678109884262085, train/raw-loss = 0.678109884262085, train/logprobs = tensor([[-0.8871, -0.7659],
        [-0.8938, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6390549540519714, train/raw-loss = 0.6390549540519714, train/logprobs = tensor([[-0.3988, -1.4025],
        [-0.4546, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.566025972366333, train/raw-loss = 0.566025972366333, train/logprobs = tensor([[-0.5117, -1.8578],
        [-0.5724, -1.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.5964142084121704, train/raw-loss = 0.5964142084121704, train/logprobs = tensor([[-0.5670, -1.9596],
        [-0.7400, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6416305303573608, train/raw-loss = 0.6416305303573608, train/logprobs = tensor([[-0.5193, -0.8578],
        [-0.6190, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6820334792137146, train/raw-loss = 0.6820334792137146, train/logprobs = tensor([[-0.4964, -0.9851],
        [-0.5220, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6325727701187134, train/raw-loss = 0.6325727701187134, train/logprobs = tensor([[-0.5603, -0.6316],
        [-0.7162, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6647505760192871, train/raw-loss = 0.6647505760192871, train/logprobs = tensor([[-0.6781, -1.3000],
        [-0.8537, -1.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6824195384979248, train/raw-loss = 0.6824195384979248, train/logprobs = tensor([[-0.4394, -0.8593],
        [-0.4947, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.666618287563324, train/raw-loss = 0.666618287563324, train/logprobs = tensor([[-0.5334, -0.7254],
        [-0.6013, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6506434679031372, train/raw-loss = 0.6506434679031372, train/logprobs = tensor([[-0.5674, -0.8702],
        [-0.6368, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6688615083694458, train/raw-loss = 0.6688615083694458, train/logprobs = tensor([[-0.4378, -0.9733],
        [-0.4775, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.622824490070343, train/raw-loss = 0.622824490070343, train/logprobs = tensor([[-0.5166, -1.3426],
        [-0.5917, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6586250066757202, train/raw-loss = 0.6586250066757202, train/logprobs = tensor([[-0.6401, -0.8999],
        [-0.7881, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6660503149032593, train/raw-loss = 0.6660503149032593, train/logprobs = tensor([[-0.3980, -0.7761],
        [-0.4592, -0.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6290931701660156, train/raw-loss = 0.6290931701660156, train/logprobs = tensor([[-0.5893, -1.2191],
        [-0.7058, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6267271637916565, train/raw-loss = 0.6267271637916565, train/logprobs = tensor([[-0.5463, -1.1152],
        [-0.6325, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6604589819908142, train/raw-loss = 0.6604589819908142, train/logprobs = tensor([[-0.6231, -0.6365],
        [-0.7292, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6991157531738281, train/raw-loss = 0.6785680055618286, train/logprobs = tensor([[-0.5236, -0.5339],
        [-0.5325, -0.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010273855179548264
Epoch 0, Step 65: train/loss = 0.6491732001304626, train/raw-loss = 0.6315622329711914, train/logprobs = tensor([[-0.6038, -1.0955],
        [-0.6104, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008805465884506702
Epoch 0, Step 66: train/loss = 0.5705322623252869, train/raw-loss = 0.5590013265609741, train/logprobs = tensor([[-0.5608, -1.8092],
        [-0.6194, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0057654730044305325
Epoch 0, Step 67: train/loss = 0.6564121842384338, train/raw-loss = 0.6427004933357239, train/logprobs = tensor([[-0.5268, -0.9771],
        [-0.5530, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006855834275484085
Epoch 0, Step 68: train/loss = 0.6444273591041565, train/raw-loss = 0.6343002915382385, train/logprobs = tensor([[-0.5325, -0.8679],
        [-0.5480, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005063521675765514
Epoch 0, Step 69: train/loss = 0.670269787311554, train/raw-loss = 0.6543845534324646, train/logprobs = tensor([[-0.6486, -0.9437],
        [-0.6995, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007942628115415573
Epoch 0, Step 70: train/loss = 0.6177111864089966, train/raw-loss = 0.6017553806304932, train/logprobs = tensor([[-0.5492, -1.1977],
        [-0.5511, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00797793548554182
Epoch 0, Step 71: train/loss = 0.655470609664917, train/raw-loss = 0.6365189552307129, train/logprobs = tensor([[-0.6796, -0.9444],
        [-0.7452, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00947583094239235
Epoch 0, Step 72: train/loss = 0.59347003698349, train/raw-loss = 0.5780848860740662, train/logprobs = tensor([[-0.6106, -2.4416],
        [-0.6491, -1.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007692587096244097
Epoch 0, Step 73: train/loss = 0.506322979927063, train/raw-loss = 0.4891777038574219, train/logprobs = tensor([[-0.5750, -2.5685],
        [-0.8057, -1.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008572638034820557
Epoch 0, Step 74: train/loss = 0.6490447521209717, train/raw-loss = 0.6359198093414307, train/logprobs = tensor([[-0.5559, -0.7760],
        [-0.6132, -0.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065624406561255455
Epoch 0, Step 75: train/loss = 0.6318409442901611, train/raw-loss = 0.6126776933670044, train/logprobs = tensor([[-0.6085, -1.1106],
        [-0.7068, -0.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00958161149173975
Epoch 0, Step 76: train/loss = 0.6290010213851929, train/raw-loss = 0.6177546977996826, train/logprobs = tensor([[-0.4644, -1.1645],
        [-0.4895, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005623187869787216
Epoch 0, Step 77: train/loss = 0.5966841578483582, train/raw-loss = 0.5838821530342102, train/logprobs = tensor([[-0.5274, -1.6655],
        [-0.5867, -1.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006400993559509516
Epoch 0, Step 78: train/loss = 0.6581495404243469, train/raw-loss = 0.639363169670105, train/logprobs = tensor([[-0.5064, -1.3542],
        [-0.5535, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009393176063895226
Epoch 0, Step 79: train/loss = 0.7076373100280762, train/raw-loss = 0.6915323734283447, train/logprobs = tensor([[-0.4521, -0.4442],
        [-0.4570, -0.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008052474819123745
Epoch 0, Step 80: train/loss = 0.5955491662025452, train/raw-loss = 0.5831351280212402, train/logprobs = tensor([[-0.5243, -1.1612],
        [-0.5581, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062070367857813835
Epoch 0, Step 81: train/loss = 0.6282305717468262, train/raw-loss = 0.6154731512069702, train/logprobs = tensor([[-0.5150, -1.0496],
        [-0.6209, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006378696300089359
Epoch 0, Step 82: train/loss = 0.6124851107597351, train/raw-loss = 0.5980513691902161, train/logprobs = tensor([[-0.5513, -1.4767],
        [-0.5575, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007216860540211201
Epoch 0, Step 83: train/loss = 0.5953527688980103, train/raw-loss = 0.5804933309555054, train/logprobs = tensor([[-0.4523, -1.8505],
        [-0.5113, -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007429721299558878
Epoch 0, Step 84: train/loss = 0.569369912147522, train/raw-loss = 0.5538495779037476, train/logprobs = tensor([[-0.4881, -2.5234],
        [-0.5353, -1.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00776017177850008
Epoch 0, Step 85: train/loss = 0.6750978231430054, train/raw-loss = 0.6582968235015869, train/logprobs = tensor([[-0.6270, -0.7842],
        [-0.6191, -0.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008400483056902885
Epoch 0, Step 86: train/loss = 0.577722430229187, train/raw-loss = 0.567969024181366, train/logprobs = tensor([[-0.4606, -1.7612],
        [-0.5140, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00487673282623291
Epoch 0, Step 87: train/loss = 0.5981775522232056, train/raw-loss = 0.584272027015686, train/logprobs = tensor([[-0.8867, -1.2524],
        [-1.1180, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006952750962227583
Epoch 0, Step 88: train/loss = 0.6408568620681763, train/raw-loss = 0.6227661371231079, train/logprobs = tensor([[-0.6716, -1.1132],
        [-0.7139, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009045354090631008
Epoch 0, Step 89: train/loss = 0.6391748785972595, train/raw-loss = 0.6252847909927368, train/logprobs = tensor([[-0.4716, -1.1391],
        [-0.4656, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006945040076971054
Epoch 0, Step 90: train/loss = 0.6403543949127197, train/raw-loss = 0.6262696385383606, train/logprobs = tensor([[-0.4655, -1.0025],
        [-0.4770, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007042377255856991
Epoch 0, Step 91: train/loss = 0.6104424595832825, train/raw-loss = 0.5969526767730713, train/logprobs = tensor([[-0.4929, -1.3555],
        [-0.5365, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006744918413460255
Epoch 0, Step 92: train/loss = 0.6476343870162964, train/raw-loss = 0.6290079951286316, train/logprobs = tensor([[-0.5607, -1.0638],
        [-0.6644, -0.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009313201531767845
Epoch 0, Step 93: train/loss = 0.6281774640083313, train/raw-loss = 0.6156594157218933, train/logprobs = tensor([[-0.6301, -1.0162],
        [-0.7172, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006259022280573845
Epoch 0, Step 94: train/loss = 0.659866452217102, train/raw-loss = 0.6439217329025269, train/logprobs = tensor([[-0.5245, -1.2848],
        [-0.5686, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007972372695803642
Epoch 0, Step 95: train/loss = 0.6610857248306274, train/raw-loss = 0.6478652358055115, train/logprobs = tensor([[-0.4691, -1.4888],
        [-0.4835, -1.3139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006610271520912647
Epoch 0, Step 96: train/loss = 0.7398302555084229, train/raw-loss = 0.6620941758155823, train/logprobs = tensor([[-0.5202, -0.6208],
        [-0.5489, -0.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0388680174946785
Epoch 0, Step 97: train/loss = 0.6540248394012451, train/raw-loss = 0.5611997246742249, train/logprobs = tensor([[-0.5023, -1.7535],
        [-0.5457, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046412546187639236
Epoch 0, Step 98: train/loss = 0.694899320602417, train/raw-loss = 0.6122644543647766, train/logprobs = tensor([[-0.8157, -1.1556],
        [-0.9413, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041317421942949295
Epoch 0, Step 99: train/loss = 0.7204318642616272, train/raw-loss = 0.6266990900039673, train/logprobs = tensor([[-0.6318, -0.9751],
        [-0.6373, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04686640202999115
Epoch 0, Step 100: train/loss = 0.696932315826416, train/raw-loss = 0.6355003714561462, train/logprobs = tensor([[-0.4975, -1.0148],
        [-0.5105, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03071599453687668
Epoch 0, Step 101: train/loss = 0.6900475025177002, train/raw-loss = 0.6092303395271301, train/logprobs = tensor([[-0.3985, -1.2159],
        [-0.3787, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040408577769994736
Epoch 0, Step 102: train/loss = 0.7105439305305481, train/raw-loss = 0.601067066192627, train/logprobs = tensor([[-0.6615, -1.4185],
        [-0.6638, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05473843589425087
Epoch 0, Step 103: train/loss = 0.7496739625930786, train/raw-loss = 0.6834591627120972, train/logprobs = tensor([[-0.5874, -0.6576],
        [-0.5626, -0.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03310740739107132
Epoch 0, Step 104: train/loss = 0.675966739654541, train/raw-loss = 0.6029197573661804, train/logprobs = tensor([[-0.6462, -0.9495],
        [-0.7380, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0365234911441803
Epoch 0, Step 105: train/loss = 0.6722744703292847, train/raw-loss = 0.5989608764648438, train/logprobs = tensor([[-0.6659, -1.4717],
        [-0.6273, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036656782031059265
Epoch 0, Step 106: train/loss = 0.7095482349395752, train/raw-loss = 0.6120671033859253, train/logprobs = tensor([[-0.4200, -1.3185],
        [-0.4100, -0.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048740584403276443
Epoch 0, Step 107: train/loss = 0.6591235399246216, train/raw-loss = 0.5705276727676392, train/logprobs = tensor([[-0.5905, -1.4391],
        [-0.6617, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04429794102907181
Epoch 0, Step 108: train/loss = 0.6971176862716675, train/raw-loss = 0.5850974917411804, train/logprobs = tensor([[-0.5290, -1.6458],
        [-0.5232, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056010134518146515
Epoch 0, Step 109: train/loss = 0.6719609498977661, train/raw-loss = 0.581430196762085, train/logprobs = tensor([[-0.6426, -1.3501],
        [-0.7102, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045265354216098785
Epoch 0, Step 110: train/loss = 0.7415516972541809, train/raw-loss = 0.6463612914085388, train/logprobs = tensor([[-0.5667, -1.0286],
        [-0.5926, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04759518429636955
Epoch 0, Step 111: train/loss = 0.7381461262702942, train/raw-loss = 0.665995717048645, train/logprobs = tensor([[-0.5159, -0.6220],
        [-0.5147, -0.5031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03607519716024399
Epoch 0, Step 112: train/loss = 0.6938394904136658, train/raw-loss = 0.6085137724876404, train/logprobs = tensor([[-0.5330, -1.5161],
        [-0.5397, -1.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042662862688302994
Epoch 0, Step 113: train/loss = 0.7278113961219788, train/raw-loss = 0.6201863288879395, train/logprobs = tensor([[-0.6459, -1.1555],
        [-0.6945, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053812526166439056
Epoch 0, Step 114: train/loss = 0.7195988893508911, train/raw-loss = 0.6091268062591553, train/logprobs = tensor([[-0.4842, -1.1910],
        [-0.4720, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05523601546883583
Epoch 0, Step 115: train/loss = 0.6238417029380798, train/raw-loss = 0.5235251188278198, train/logprobs = tensor([[-0.6262, -1.5677],
        [-0.7613, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05015827715396881
Epoch 0, Step 116: train/loss = 0.7515048980712891, train/raw-loss = 0.6682139039039612, train/logprobs = tensor([[-0.7207, -1.1829],
        [-0.6448, -0.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04164549708366394
Epoch 0, Step 117: train/loss = 0.7047226428985596, train/raw-loss = 0.6300265789031982, train/logprobs = tensor([[-0.5023, -0.8914],
        [-0.5578, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037348005920648575
Epoch 0, Step 118: train/loss = 0.6905498504638672, train/raw-loss = 0.5954641699790955, train/logprobs = tensor([[-0.5469, -1.1759],
        [-0.5442, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04754282534122467
Epoch 0, Step 119: train/loss = 0.6865369081497192, train/raw-loss = 0.5820329785346985, train/logprobs = tensor([[-0.5032, -1.3222],
        [-0.5398, -0.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052251990884542465
Epoch 0, Step 120: train/loss = 0.6999584436416626, train/raw-loss = 0.6162238121032715, train/logprobs = tensor([[-0.5287, -0.8768],
        [-0.5752, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04186731576919556
Epoch 0, Step 121: train/loss = 0.6975464224815369, train/raw-loss = 0.5969893932342529, train/logprobs = tensor([[-0.5100, -1.1469],
        [-0.5473, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05027851462364197
Epoch 0, Step 122: train/loss = 0.7176388502120972, train/raw-loss = 0.6433717012405396, train/logprobs = tensor([[-0.4762, -0.7469],
        [-0.4946, -0.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037133630365133286
Epoch 0, Step 123: train/loss = 0.6265645027160645, train/raw-loss = 0.5352839231491089, train/logprobs = tensor([[-0.5170, -1.9141],
        [-0.5403, -1.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04564026743173599
Epoch 0, Step 124: train/loss = 0.7273842692375183, train/raw-loss = 0.6576231718063354, train/logprobs = tensor([[-0.5809, -0.5820],
        [-0.5820, -0.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03488053381443024
Epoch 0, Step 125: train/loss = 0.701226532459259, train/raw-loss = 0.5821150541305542, train/logprobs = tensor([[-0.4936, -1.2719],
        [-0.4935, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05955573171377182
Epoch 0, Step 126: train/loss = 0.7022964954376221, train/raw-loss = 0.6291491389274597, train/logprobs = tensor([[-0.4155, -1.2389],
        [-0.4161, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036573681980371475
Epoch 0, Step 127: train/loss = 0.6467608213424683, train/raw-loss = 0.5462526082992554, train/logprobs = tensor([[-0.6675, -2.1413],
        [-0.6584, -1.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05025412514805794
Epoch 0, Step 128: train/loss = 0.5850412249565125, train/raw-loss = 0.4675830900669098, train/logprobs = tensor([[-0.5357, -2.9874],
        [-0.6543, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05872908979654312
Epoch 0, Step 129: train/loss = 0.5949193239212036, train/raw-loss = 0.49283984303474426, train/logprobs = tensor([[-0.5782, -3.2196],
        [-0.6486, -1.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051039744168519974
Epoch 0, Step 130: train/loss = 0.7204377055168152, train/raw-loss = 0.622551441192627, train/logprobs = tensor([[-0.5189, -1.0682],
        [-0.4724, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048943132162094116
Epoch 0, Step 131: train/loss = 0.6952838897705078, train/raw-loss = 0.5993229150772095, train/logprobs = tensor([[-0.4645, -0.9886],
        [-0.5186, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04798049479722977
Epoch 0, Step 132: train/loss = 0.7419435977935791, train/raw-loss = 0.6255968809127808, train/logprobs = tensor([[-0.6127, -0.9908],
        [-0.5579, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05817336589097977
Epoch 0, Step 133: train/loss = 0.686025083065033, train/raw-loss = 0.5893759727478027, train/logprobs = tensor([[-0.6036, -1.6089],
        [-0.5421, -1.0024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04832454398274422
Epoch 0, Step 134: train/loss = 0.5906037092208862, train/raw-loss = 0.46255484223365784, train/logprobs = tensor([[-0.8582, -3.1364],
        [-0.8817, -1.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0640244260430336
Epoch 0, Step 135: train/loss = 0.5333409309387207, train/raw-loss = 0.42056331038475037, train/logprobs = tensor([[-0.5451, -3.2530],
        [-0.6462, -1.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05638878047466278
Epoch 0, Step 136: train/loss = 0.6637134552001953, train/raw-loss = 0.5664889216423035, train/logprobs = tensor([[-0.4851, -1.4726],
        [-0.4760, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04861228168010712
Epoch 0, Step 137: train/loss = 0.7263615131378174, train/raw-loss = 0.630733847618103, train/logprobs = tensor([[-0.4654, -0.8667],
        [-0.5190, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04781383275985718
Epoch 0, Step 138: train/loss = 0.5508912801742554, train/raw-loss = 0.4389733076095581, train/logprobs = tensor([[-0.5946, -3.5919],
        [-0.6205, -1.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055958982557058334
Epoch 0, Step 139: train/loss = 0.712032675743103, train/raw-loss = 0.6292920112609863, train/logprobs = tensor([[-0.4865, -0.9513],
        [-0.5268, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04137033224105835
Epoch 0, Step 140: train/loss = 0.6685793995857239, train/raw-loss = 0.55971360206604, train/logprobs = tensor([[-0.5779, -1.5614],
        [-0.6630, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05443291738629341
Epoch 0, Step 141: train/loss = 0.6880724430084229, train/raw-loss = 0.5962514877319336, train/logprobs = tensor([[-0.5033, -0.9430],
        [-0.5506, -0.5295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04591047018766403
Epoch 0, Step 142: train/loss = 0.6887360215187073, train/raw-loss = 0.5723676681518555, train/logprobs = tensor([[-0.7149, -1.5310],
        [-0.7598, -1.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058184150606393814
Epoch 0, Step 143: train/loss = 0.666587233543396, train/raw-loss = 0.5697526335716248, train/logprobs = tensor([[-0.6173, -1.8121],
        [-0.6579, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04841732233762741
Epoch 0, Step 144: train/loss = 0.6156271696090698, train/raw-loss = 0.4977108836174011, train/logprobs = tensor([[-0.5821, -2.1270],
        [-0.6213, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05895812809467316
Epoch 0, Step 145: train/loss = 0.7118270397186279, train/raw-loss = 0.612230122089386, train/logprobs = tensor([[-0.4150, -1.0544],
        [-0.4055, -0.6765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04979846999049187
Epoch 0, Step 146: train/loss = 0.5278476476669312, train/raw-loss = 0.41754353046417236, train/logprobs = tensor([[-0.8188, -4.2321],
        [-0.9055, -2.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05515207350254059
Epoch 0, Step 147: train/loss = 0.6898174285888672, train/raw-loss = 0.5948907136917114, train/logprobs = tensor([[-0.4838, -0.9422],
        [-0.5347, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0474633127450943
Epoch 0, Step 148: train/loss = 0.6639131307601929, train/raw-loss = 0.5555670261383057, train/logprobs = tensor([[-0.5319, -1.3754],
        [-0.5249, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05417304486036301
Epoch 0, Step 149: train/loss = 0.6520012021064758, train/raw-loss = 0.5664122104644775, train/logprobs = tensor([[-0.5745, -1.7781],
        [-0.6099, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042794469743967056
Epoch 0, Step 150: train/loss = 0.6095725297927856, train/raw-loss = 0.5029098987579346, train/logprobs = tensor([[-0.6752, -1.7377],
        [-0.8018, -0.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05333128571510315
Epoch 0, Step 151: train/loss = 0.6806354522705078, train/raw-loss = 0.5591012239456177, train/logprobs = tensor([[-0.5134, -1.7131],
        [-0.4675, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06076711043715477
Epoch 0, Step 152: train/loss = 0.552118182182312, train/raw-loss = 0.4535793364048004, train/logprobs = tensor([[-0.6287, -3.2921],
        [-0.7356, -1.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0492694117128849
Epoch 0, Step 153: train/loss = 0.6564884185791016, train/raw-loss = 0.5341100096702576, train/logprobs = tensor([[-0.4384, -1.5614],
        [-0.4733, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061189208179712296
Epoch 0, Step 154: train/loss = 0.5774267911911011, train/raw-loss = 0.47606950998306274, train/logprobs = tensor([[-0.5931, -2.5282],
        [-0.6805, -1.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050678662955760956
Epoch 0, Step 155: train/loss = 0.6109745502471924, train/raw-loss = 0.5022151470184326, train/logprobs = tensor([[-0.8806, -2.6509],
        [-1.0384, -1.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05437972769141197
Epoch 0, Step 156: train/loss = 0.67409348487854, train/raw-loss = 0.5587529540061951, train/logprobs = tensor([[-0.5383, -1.8171],
        [-0.5447, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05767024680972099
Epoch 0, Step 157: train/loss = 0.7137612104415894, train/raw-loss = 0.6156564354896545, train/logprobs = tensor([[-0.4741, -1.0212],
        [-0.5091, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0490524061024189
Epoch 0, Step 158: train/loss = 0.6507465243339539, train/raw-loss = 0.5321148633956909, train/logprobs = tensor([[-0.4928, -1.8741],
        [-0.5016, -0.9882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059315841645002365
Epoch 0, Step 159: train/loss = 0.7516255378723145, train/raw-loss = 0.6559957265853882, train/logprobs = tensor([[-0.4501, -0.6626],
        [-0.4399, -0.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04781486839056015
Epoch 0, Step 160: train/loss = 0.703323483467102, train/raw-loss = 0.5747239589691162, train/logprobs = tensor([[-0.6882, -1.8222],
        [-0.5789, -1.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06429976224899292
Epoch 0, Step 161: train/loss = 0.596524715423584, train/raw-loss = 0.4792940318584442, train/logprobs = tensor([[-0.6543, -2.6737],
        [-0.7425, -1.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05861533060669899
Epoch 0, Step 162: train/loss = 0.6660810112953186, train/raw-loss = 0.5459725856781006, train/logprobs = tensor([[-0.6351, -1.4348],
        [-0.7277, -0.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060054223984479904
Epoch 0, Step 163: train/loss = 0.6521764397621155, train/raw-loss = 0.54566490650177, train/logprobs = tensor([[-0.6305, -1.4310],
        [-0.6484, -0.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053255751729011536
Epoch 0, Step 164: train/loss = 0.6576551198959351, train/raw-loss = 0.5406063795089722, train/logprobs = tensor([[-0.6450, -2.9295],
        [-0.6903, -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05852435156702995
Epoch 0, Step 165: train/loss = 0.7177197933197021, train/raw-loss = 0.6067205667495728, train/logprobs = tensor([[-0.5525, -1.0215],
        [-0.5848, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05549962818622589
Epoch 0, Step 166: train/loss = 0.6623197793960571, train/raw-loss = 0.5476211309432983, train/logprobs = tensor([[-0.6007, -1.5307],
        [-0.6722, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05734932795166969
Epoch 0, Step 167: train/loss = 0.624080240726471, train/raw-loss = 0.5089536905288696, train/logprobs = tensor([[-0.5143, -1.8708],
        [-0.5313, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05756324529647827
Epoch 0, Step 168: train/loss = 0.6867045164108276, train/raw-loss = 0.5740675330162048, train/logprobs = tensor([[-0.6029, -1.7998],
        [-0.5777, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056318480521440506
Epoch 0, Step 169: train/loss = 0.6524149179458618, train/raw-loss = 0.5343924760818481, train/logprobs = tensor([[-0.5827, -2.2104],
        [-0.6554, -1.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059011198580265045
Epoch 0, Step 170: train/loss = 0.6648454070091248, train/raw-loss = 0.5467771887779236, train/logprobs = tensor([[-0.5454, -1.6863],
        [-0.6237, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05903412774205208
Epoch 0, Step 171: train/loss = 0.6793964505195618, train/raw-loss = 0.5573365688323975, train/logprobs = tensor([[-0.6212, -1.3666],
        [-0.6509, -0.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06102994829416275
Epoch 0, Step 172: train/loss = 0.6251289248466492, train/raw-loss = 0.5020944476127625, train/logprobs = tensor([[-0.7904, -1.7304],
        [-0.9097, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061517223715782166
Epoch 0, Step 173: train/loss = 0.5982335209846497, train/raw-loss = 0.46180352568626404, train/logprobs = tensor([[-0.4770, -2.1161],
        [-0.5403, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821498274803162
Epoch 0, Step 174: train/loss = 0.7268390655517578, train/raw-loss = 0.6215397119522095, train/logprobs = tensor([[-0.5713, -1.0013],
        [-0.6155, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052649691700935364
Epoch 0, Step 175: train/loss = 0.6825302839279175, train/raw-loss = 0.549376904964447, train/logprobs = tensor([[-1.1369, -3.3136],
        [-1.0357, -2.1203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06657668203115463
Epoch 0, Step 176: train/loss = 0.630017876625061, train/raw-loss = 0.5202192068099976, train/logprobs = tensor([[-0.6097, -2.3764],
        [-0.6678, -1.2806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054899364709854126
Epoch 0, Step 177: train/loss = 0.6477174758911133, train/raw-loss = 0.5299911499023438, train/logprobs = tensor([[-0.6065, -1.8049],
        [-0.6689, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058863185346126556
Epoch 0, Step 178: train/loss = 0.6835649013519287, train/raw-loss = 0.5545835494995117, train/logprobs = tensor([[-0.7740, -1.5965],
        [-0.8934, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644906684756279
Epoch 0, Step 179: train/loss = 0.7451623678207397, train/raw-loss = 0.6411023139953613, train/logprobs = tensor([[-0.5631, -0.8025],
        [-0.5945, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052030012011528015
Epoch 0, Step 180: train/loss = 0.676142156124115, train/raw-loss = 0.5557640790939331, train/logprobs = tensor([[-0.6628, -1.9374],
        [-0.6206, -1.1868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06018904596567154
Epoch 0, Step 181: train/loss = 0.728736937046051, train/raw-loss = 0.5962731838226318, train/logprobs = tensor([[-0.3169, -1.0778],
        [-0.3141, -0.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.066231869161129
Epoch 0, Step 182: train/loss = 0.7140728831291199, train/raw-loss = 0.5814000368118286, train/logprobs = tensor([[-0.5470, -1.2189],
        [-0.5611, -0.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06633642315864563
Epoch 0, Step 183: train/loss = 0.6661046743392944, train/raw-loss = 0.5222705602645874, train/logprobs = tensor([[-0.5712, -2.0222],
        [-0.5935, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07191704213619232
Epoch 0, Step 184: train/loss = 0.6590405702590942, train/raw-loss = 0.542250394821167, train/logprobs = tensor([[-0.4610, -1.5920],
        [-0.4668, -0.7761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05839510262012482
Epoch 0, Step 185: train/loss = 0.7287036776542664, train/raw-loss = 0.5956971645355225, train/logprobs = tensor([[-0.4617, -1.1700],
        [-0.4598, -0.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06650323420763016
Epoch 0, Step 186: train/loss = 0.7279817461967468, train/raw-loss = 0.6285380721092224, train/logprobs = tensor([[-0.6787, -0.8917],
        [-0.6518, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04972182586789131
Epoch 0, Step 187: train/loss = 0.7429264783859253, train/raw-loss = 0.6206572651863098, train/logprobs = tensor([[-0.5572, -1.1016],
        [-0.5475, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06113462895154953
Epoch 0, Step 188: train/loss = 0.6982988119125366, train/raw-loss = 0.5501377582550049, train/logprobs = tensor([[-0.4961, -1.6021],
        [-0.5299, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07408054172992706
Epoch 0, Step 189: train/loss = 0.7283538579940796, train/raw-loss = 0.5916652679443359, train/logprobs = tensor([[-0.8821, -1.4794],
        [-0.8943, -1.0219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06834428012371063
Epoch 0, Step 190: train/loss = 0.7005383968353271, train/raw-loss = 0.5757753849029541, train/logprobs = tensor([[-0.5647, -1.3202],
        [-0.5719, -0.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06238151341676712
Epoch 0, Step 191: train/loss = 0.6875853538513184, train/raw-loss = 0.5439810752868652, train/logprobs = tensor([[-0.6222, -2.2971],
        [-0.6569, -1.3495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07180215418338776
Epoch 0, Step 192: train/loss = 0.6957389116287231, train/raw-loss = 0.6089785695075989, train/logprobs = tensor([[-0.4299, -0.9956],
        [-0.4135, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043380193412303925
Epoch 0, Step 193: train/loss = 0.7402077913284302, train/raw-loss = 0.652908205986023, train/logprobs = tensor([[-0.5368, -0.7200],
        [-0.5371, -0.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04364979639649391
Epoch 0, Step 194: train/loss = 0.6189290881156921, train/raw-loss = 0.5124713182449341, train/logprobs = tensor([[-0.5582, -2.0167],
        [-0.5540, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053228914737701416
Epoch 0, Step 195: train/loss = 0.705614447593689, train/raw-loss = 0.6092536449432373, train/logprobs = tensor([[-0.6499, -1.0491],
        [-0.5745, -0.5445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04818040132522583
Epoch 0, Step 196: train/loss = 0.5944929718971252, train/raw-loss = 0.4915434718132019, train/logprobs = tensor([[-0.6277, -1.8731],
        [-0.6307, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05147472396492958
Epoch 0, Step 197: train/loss = 0.6326394081115723, train/raw-loss = 0.5304350256919861, train/logprobs = tensor([[-0.5204, -2.0635],
        [-0.5028, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05110219120979309
Epoch 0, Step 198: train/loss = 0.6881959438323975, train/raw-loss = 0.5900782346725464, train/logprobs = tensor([[-0.5311, -1.2300],
        [-0.4684, -0.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04905882477760315
Epoch 0, Step 199: train/loss = 0.5811848640441895, train/raw-loss = 0.47564101219177246, train/logprobs = tensor([[-0.6249, -3.1060],
        [-0.6386, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0527719147503376
Epoch 0, Step 200: train/loss = 0.6509147882461548, train/raw-loss = 0.5630196332931519, train/logprobs = tensor([[-0.5593, -1.2796],
        [-0.5948, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04394758492708206
Epoch 0, Step 201: train/loss = 0.6155799627304077, train/raw-loss = 0.5141224265098572, train/logprobs = tensor([[-0.5964, -1.6213],
        [-0.5882, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05072876811027527
Epoch 0, Step 202: train/loss = 0.7372618913650513, train/raw-loss = 0.6611919403076172, train/logprobs = tensor([[-0.4412, -0.5948],
        [-0.4216, -0.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03803498297929764
Epoch 0, Step 203: train/loss = 0.6589623689651489, train/raw-loss = 0.5506222248077393, train/logprobs = tensor([[-0.7229, -1.6027],
        [-0.7215, -0.8733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05417006462812424
Epoch 0, Step 204: train/loss = 0.7410516738891602, train/raw-loss = 0.6486570835113525, train/logprobs = tensor([[-0.6702, -0.8019],
        [-0.6442, -0.5460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0461973212659359
Epoch 0, Step 205: train/loss = 0.6998111605644226, train/raw-loss = 0.5884610414505005, train/logprobs = tensor([[-0.6029, -1.3537],
        [-0.5725, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05567505955696106
Epoch 0, Step 206: train/loss = 0.6022902727127075, train/raw-loss = 0.5074353218078613, train/logprobs = tensor([[-0.5222, -1.6974],
        [-0.6572, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04742748290300369
Epoch 0, Step 207: train/loss = 0.7116175889968872, train/raw-loss = 0.6129674911499023, train/logprobs = tensor([[-0.4673, -1.1563],
        [-0.4566, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04932504892349243
Epoch 0, Step 208: train/loss = 0.6868325471878052, train/raw-loss = 0.5782615542411804, train/logprobs = tensor([[-0.7190, -1.3996],
        [-0.6596, -0.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054285503923892975
Epoch 0, Step 209: train/loss = 0.6469315886497498, train/raw-loss = 0.5473437905311584, train/logprobs = tensor([[-0.4987, -1.5090],
        [-0.4434, -0.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04979390278458595
Epoch 0, Step 210: train/loss = 0.5667101144790649, train/raw-loss = 0.4635102450847626, train/logprobs = tensor([[-0.7030, -2.2279],
        [-0.8146, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051599934697151184
Epoch 0, Step 211: train/loss = 0.6501527428627014, train/raw-loss = 0.5655201077461243, train/logprobs = tensor([[-0.4849, -3.1042],
        [-0.5124, -1.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04231629520654678
Epoch 0, Step 212: train/loss = 0.5777221322059631, train/raw-loss = 0.47557660937309265, train/logprobs = tensor([[-0.6827, -3.7748],
        [-0.7489, -1.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05107276141643524
Epoch 0, Step 213: train/loss = 0.6990328431129456, train/raw-loss = 0.6025106906890869, train/logprobs = tensor([[-0.6332, -1.1121],
        [-0.6645, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048261091113090515
Epoch 0, Step 214: train/loss = 0.7199088931083679, train/raw-loss = 0.6125493049621582, train/logprobs = tensor([[-0.7885, -1.0605],
        [-0.8351, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053679805248975754
Epoch 0, Step 215: train/loss = 0.6271854639053345, train/raw-loss = 0.5125635862350464, train/logprobs = tensor([[-0.7601, -1.6502],
        [-0.8180, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05731094628572464
Epoch 0, Step 216: train/loss = 0.5827624201774597, train/raw-loss = 0.48650896549224854, train/logprobs = tensor([[-0.4711, -2.4068],
        [-0.4546, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0481267087161541
Epoch 0, Step 217: train/loss = 0.7090573906898499, train/raw-loss = 0.6092187166213989, train/logprobs = tensor([[-0.5007, -0.8311],
        [-0.5517, -0.5097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04991934075951576
Epoch 0, Step 218: train/loss = 0.5923293232917786, train/raw-loss = 0.4874720275402069, train/logprobs = tensor([[-0.5276, -1.8281],
        [-0.5544, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05242864415049553
Epoch 0, Step 219: train/loss = 0.608191728591919, train/raw-loss = 0.49414002895355225, train/logprobs = tensor([[-0.6979, -2.2518],
        [-0.6786, -1.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05702586844563484
Epoch 0, Step 220: train/loss = 0.7651727199554443, train/raw-loss = 0.6763178110122681, train/logprobs = tensor([[-0.5603, -0.6789],
        [-0.5273, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04442746564745903
Epoch 0, Step 221: train/loss = 0.6763006448745728, train/raw-loss = 0.5822650790214539, train/logprobs = tensor([[-0.6724, -1.2485],
        [-0.7197, -0.7581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047017768025398254
Epoch 0, Step 222: train/loss = 0.6499536633491516, train/raw-loss = 0.5622873902320862, train/logprobs = tensor([[-0.4677, -4.0685],
        [-0.4364, -2.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04383314028382301
Epoch 0, Step 223: train/loss = 0.5633471608161926, train/raw-loss = 0.45655882358551025, train/logprobs = tensor([[-0.7152, -5.4208],
        [-0.6381, -2.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05339416489005089
Epoch 0, Step 224: train/loss = 0.7659107446670532, train/raw-loss = 0.6470757722854614, train/logprobs = tensor([[-0.7340, -0.9891],
        [-0.5693, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05941750109195709
Epoch 0, Step 225: train/loss = 0.7170037627220154, train/raw-loss = 0.612485945224762, train/logprobs = tensor([[-0.5715, -0.9326],
        [-0.5860, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0522589311003685
Epoch 0, Step 226: train/loss = 0.6422507762908936, train/raw-loss = 0.543493926525116, train/logprobs = tensor([[-0.7100, -1.5559],
        [-0.7910, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04937843233346939
Epoch 0, Step 227: train/loss = 0.5480928421020508, train/raw-loss = 0.4317236542701721, train/logprobs = tensor([[-0.7920, -3.0700],
        [-0.6972, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058184586465358734
Epoch 0, Step 228: train/loss = 0.6342692971229553, train/raw-loss = 0.5067426562309265, train/logprobs = tensor([[-0.5767, -1.6720],
        [-0.8177, -0.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0637633204460144
Epoch 0, Step 229: train/loss = 0.5343307852745056, train/raw-loss = 0.4180629849433899, train/logprobs = tensor([[-0.6628, -2.3346],
        [-0.8736, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058133892714977264
Epoch 0, Step 230: train/loss = 0.7123592495918274, train/raw-loss = 0.6064364910125732, train/logprobs = tensor([[-0.8260, -1.3512],
        [-0.7025, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05296138674020767
Epoch 0, Step 231: train/loss = 0.7334295511245728, train/raw-loss = 0.6316608190536499, train/logprobs = tensor([[-0.6738, -0.8058],
        [-0.7150, -0.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05088435113430023
Epoch 0, Step 232: train/loss = 0.6601616740226746, train/raw-loss = 0.5357385873794556, train/logprobs = tensor([[-0.6097, -1.4995],
        [-0.6230, -0.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06221158057451248
Epoch 0, Step 233: train/loss = 0.6330849528312683, train/raw-loss = 0.5232030153274536, train/logprobs = tensor([[-0.7322, -2.1892],
        [-0.7427, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05494098365306854
Epoch 0, Step 234: train/loss = 0.5675151348114014, train/raw-loss = 0.4468463063240051, train/logprobs = tensor([[-0.6734, -2.9885],
        [-0.7375, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06033441796898842
Epoch 0, Step 235: train/loss = 0.651497483253479, train/raw-loss = 0.5346764326095581, train/logprobs = tensor([[-0.5063, -1.9028],
        [-0.5269, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05841049551963806
Epoch 0, Step 236: train/loss = 0.6484339237213135, train/raw-loss = 0.5306442975997925, train/logprobs = tensor([[-0.6023, -1.4314],
        [-0.6640, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05889482796192169
Epoch 0, Step 237: train/loss = 0.774926483631134, train/raw-loss = 0.6556851863861084, train/logprobs = tensor([[-0.8084, -0.6006],
        [-0.8527, -0.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05962061136960983
Epoch 0, Step 238: train/loss = 0.6208391785621643, train/raw-loss = 0.5087295770645142, train/logprobs = tensor([[-0.5331, -1.6409],
        [-0.6379, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05605481564998627
Epoch 0, Step 239: train/loss = 0.6868696808815002, train/raw-loss = 0.583125114440918, train/logprobs = tensor([[-0.4931, -1.1569],
        [-0.5330, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051872290670871735
Epoch 0, Step 240: train/loss = 0.7380157113075256, train/raw-loss = 0.6302660703659058, train/logprobs = tensor([[-0.6187, -0.9111],
        [-0.5637, -0.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05387484282255173
Epoch 0, Step 241: train/loss = 0.5259684324264526, train/raw-loss = 0.4061807692050934, train/logprobs = tensor([[-0.5431, -2.4665],
        [-0.6762, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05989382416009903
Epoch 0, Step 242: train/loss = 0.6228816509246826, train/raw-loss = 0.5138319730758667, train/logprobs = tensor([[-0.6666, -1.6319],
        [-0.7023, -0.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05452484264969826
Epoch 0, Step 243: train/loss = 0.594085693359375, train/raw-loss = 0.48443007469177246, train/logprobs = tensor([[-0.6895, -3.5925],
        [-0.7224, -1.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05482780560851097
Epoch 0, Step 244: train/loss = 0.7112533450126648, train/raw-loss = 0.6121204495429993, train/logprobs = tensor([[-0.5558, -1.0015],
        [-0.5849, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04956646263599396
Epoch 0, Step 245: train/loss = 0.7472047209739685, train/raw-loss = 0.643562376499176, train/logprobs = tensor([[-0.6682, -1.1442],
        [-0.6298, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05182117596268654
Epoch 0, Step 246: train/loss = 0.751593828201294, train/raw-loss = 0.6491358280181885, train/logprobs = tensor([[-0.6979, -0.9891],
        [-0.6195, -0.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05122899264097214
Epoch 0, Step 247: train/loss = 0.545710027217865, train/raw-loss = 0.4201478064060211, train/logprobs = tensor([[-0.4741, -3.0591],
        [-0.5152, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278112530708313
Epoch 0, Step 248: train/loss = 0.602203905582428, train/raw-loss = 0.5081311464309692, train/logprobs = tensor([[-0.5650, -3.4475],
        [-0.5686, -1.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04703640192747116
Epoch 0, Step 249: train/loss = 0.6165797114372253, train/raw-loss = 0.5002970099449158, train/logprobs = tensor([[-0.5628, -3.0492],
        [-0.5568, -1.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058141373097896576
Epoch 0, Step 250: train/loss = 0.6789138317108154, train/raw-loss = 0.5692527294158936, train/logprobs = tensor([[-0.6825, -1.6111],
        [-0.6139, -0.8442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05483053997159004
Epoch 0, Step 251: train/loss = 0.7136832475662231, train/raw-loss = 0.6068857312202454, train/logprobs = tensor([[-0.6202, -0.9471],
        [-0.6799, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05339876189827919
Epoch 0, Step 252: train/loss = 0.619995653629303, train/raw-loss = 0.4991481304168701, train/logprobs = tensor([[-0.7098, -2.2249],
        [-0.7697, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06042373925447464
Epoch 0, Step 253: train/loss = 0.6559805870056152, train/raw-loss = 0.5523622035980225, train/logprobs = tensor([[-0.4135, -1.3812],
        [-0.4107, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05180917680263519
Epoch 0, Step 254: train/loss = 0.6053289175033569, train/raw-loss = 0.511436939239502, train/logprobs = tensor([[-0.8449, -1.8691],
        [-0.8850, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046946022659540176
Epoch 0, Step 255: train/loss = 0.7319822311401367, train/raw-loss = 0.6281039714813232, train/logprobs = tensor([[-0.4545, -0.7485],
        [-0.4774, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05193918198347092
Epoch 0, Step 256: train/loss = 0.6765019297599792, train/raw-loss = 0.5854415893554688, train/logprobs = tensor([[-0.6197, -1.2391],
        [-0.5992, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045530181378126144
Epoch 0, Step 257: train/loss = 0.6914164423942566, train/raw-loss = 0.5862692594528198, train/logprobs = tensor([[-0.9600, -1.6608],
        [-0.8661, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05257362872362137
Epoch 0, Step 258: train/loss = 0.6681939959526062, train/raw-loss = 0.5732198357582092, train/logprobs = tensor([[-0.8649, -1.5974],
        [-0.8592, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04748707264661789
Epoch 0, Step 259: train/loss = 0.5646963715553284, train/raw-loss = 0.4703862965106964, train/logprobs = tensor([[-0.5640, -1.8141],
        [-0.6139, -0.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047155044972896576
Epoch 0, Step 260: train/loss = 0.5717313289642334, train/raw-loss = 0.4756940007209778, train/logprobs = tensor([[-0.6116, -2.2369],
        [-0.7140, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04801866412162781
Epoch 0, Step 261: train/loss = 0.6779219508171082, train/raw-loss = 0.559112012386322, train/logprobs = tensor([[-0.5982, -1.6387],
        [-0.5248, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059404950588941574
Epoch 0, Step 262: train/loss = 0.5850905179977417, train/raw-loss = 0.49237045645713806, train/logprobs = tensor([[-0.4577, -1.5480],
        [-0.5594, -0.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04636004567146301
Epoch 0, Step 263: train/loss = 0.6216410398483276, train/raw-loss = 0.5167750716209412, train/logprobs = tensor([[-0.6865, -1.6300],
        [-0.7000, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052432991564273834
Epoch 0, Step 264: train/loss = 0.6492859125137329, train/raw-loss = 0.5562776923179626, train/logprobs = tensor([[-0.6672, -0.8819],
        [-0.8096, -0.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04650411009788513
Epoch 0, Step 265: train/loss = 0.6375691294670105, train/raw-loss = 0.5452551245689392, train/logprobs = tensor([[-0.5913, -4.8356],
        [-0.7135, -1.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04615697264671326
Epoch 0, Step 266: train/loss = 0.5759979486465454, train/raw-loss = 0.4714551568031311, train/logprobs = tensor([[-0.8711, -2.1993],
        [-0.9119, -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05227141082286835
Epoch 0, Step 267: train/loss = 0.5993776917457581, train/raw-loss = 0.49252113699913025, train/logprobs = tensor([[-0.5891, -2.0842],
        [-0.6430, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053428277373313904
Epoch 0, Step 268: train/loss = 0.6190642714500427, train/raw-loss = 0.5222732424736023, train/logprobs = tensor([[-0.4874, -1.2739],
        [-0.5847, -0.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048395536839962006
Epoch 0, Step 269: train/loss = 0.6510516405105591, train/raw-loss = 0.5352384448051453, train/logprobs = tensor([[-0.6654, -3.0351],
        [-0.5475, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057906586676836014
Epoch 0, Step 270: train/loss = 0.6321640014648438, train/raw-loss = 0.53302001953125, train/logprobs = tensor([[-0.6120, -2.8242],
        [-0.6435, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04957197979092598
Epoch 0, Step 271: train/loss = 0.7279923558235168, train/raw-loss = 0.6150058507919312, train/logprobs = tensor([[-0.5078, -1.0112],
        [-0.4620, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056493259966373444
Epoch 0, Step 272: train/loss = 0.54055255651474, train/raw-loss = 0.4278537631034851, train/logprobs = tensor([[-0.8413, -1.9928],
        [-1.0403, -0.7052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056349415332078934
Epoch 0, Step 273: train/loss = 0.45873337984085083, train/raw-loss = 0.34812599420547485, train/logprobs = tensor([[-0.6158, -6.1341],
        [-0.7666, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05530370771884918
Epoch 0, Step 274: train/loss = 0.5783520936965942, train/raw-loss = 0.47105902433395386, train/logprobs = tensor([[-0.8240, -3.5124],
        [-0.8081, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053646527230739594
Epoch 0, Step 275: train/loss = 0.5680038928985596, train/raw-loss = 0.4657551944255829, train/logprobs = tensor([[-0.6491, -2.0705],
        [-0.7858, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05112435296177864
Epoch 0, Step 276: train/loss = 0.7262516021728516, train/raw-loss = 0.6289582252502441, train/logprobs = tensor([[-1.0879, -1.7953],
        [-0.6906, -0.6232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04864664748311043
Epoch 0, Step 277: train/loss = 0.6183830499649048, train/raw-loss = 0.519974946975708, train/logprobs = tensor([[-1.0998, -2.8337],
        [-0.9429, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049204081296920776
Epoch 0, Step 278: train/loss = 0.5569208860397339, train/raw-loss = 0.4633168578147888, train/logprobs = tensor([[-0.5367, -2.3785],
        [-0.5718, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046802010387182236
Epoch 0, Step 279: train/loss = 0.6011977195739746, train/raw-loss = 0.4928004741668701, train/logprobs = tensor([[-0.6674, -2.5172],
        [-0.6784, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054198600351810455
Epoch 0, Step 280: train/loss = 0.5882185697555542, train/raw-loss = 0.4817398488521576, train/logprobs = tensor([[-0.5013, -2.0503],
        [-0.5551, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05323934927582741
Epoch 0, Step 281: train/loss = 0.6386688351631165, train/raw-loss = 0.538072943687439, train/logprobs = tensor([[-0.8634, -3.7858],
        [-0.7219, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05029793828725815
Epoch 0, Step 282: train/loss = 0.6282318830490112, train/raw-loss = 0.5451285243034363, train/logprobs = tensor([[-0.7579, -2.0659],
        [-0.7398, -1.2391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04155167192220688
Epoch 0, Step 283: train/loss = 0.7090146541595459, train/raw-loss = 0.6154099702835083, train/logprobs = tensor([[-0.5048, -1.0871],
        [-0.5165, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046802371740341187
Epoch 0, Step 284: train/loss = 0.6773136854171753, train/raw-loss = 0.5740430355072021, train/logprobs = tensor([[-0.5443, -0.9649],
        [-0.6160, -0.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05163531005382538
Epoch 0, Step 285: train/loss = 0.5728142261505127, train/raw-loss = 0.4611559212207794, train/logprobs = tensor([[-0.6785, -2.4204],
        [-0.9066, -0.9168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05582915246486664
Epoch 0, Step 286: train/loss = 0.7378449440002441, train/raw-loss = 0.6454503536224365, train/logprobs = tensor([[-0.5117, -0.8761],
        [-0.5291, -0.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046197302639484406
Epoch 0, Step 287: train/loss = 0.6144235730171204, train/raw-loss = 0.505367636680603, train/logprobs = tensor([[-0.5792, -2.0889],
        [-0.5533, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05452795699238777
Epoch 0, Step 288: train/loss = 0.5733844041824341, train/raw-loss = 0.47232717275619507, train/logprobs = tensor([[-0.6833, -3.9134],
        [-0.6262, -1.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05052861571311951
Epoch 0, Step 289: train/loss = 0.708181619644165, train/raw-loss = 0.6267805099487305, train/logprobs = tensor([[-0.5302, -0.8764],
        [-0.4561, -0.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04070058837532997
Epoch 0, Step 290: train/loss = 0.5657013654708862, train/raw-loss = 0.46338391304016113, train/logprobs = tensor([[-0.5383, -2.1649],
        [-0.5890, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051158756017684937
Epoch 0, Step 291: train/loss = 0.5581989884376526, train/raw-loss = 0.4423498809337616, train/logprobs = tensor([[-0.8680, -2.7763],
        [-0.8877, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05792457237839699
Epoch 0, Step 292: train/loss = 0.6218073964118958, train/raw-loss = 0.5294612050056458, train/logprobs = tensor([[-0.4625, -1.2493],
        [-0.5425, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0461731031537056
Epoch 0, Step 293: train/loss = 0.5632030963897705, train/raw-loss = 0.4666162133216858, train/logprobs = tensor([[-0.6818, -3.3285],
        [-0.8333, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04829343408346176
Epoch 0, Step 294: train/loss = 0.6043941378593445, train/raw-loss = 0.49242568016052246, train/logprobs = tensor([[-0.6054, -1.5499],
        [-0.7376, -0.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05598422884941101
Epoch 0, Step 295: train/loss = 0.6108711957931519, train/raw-loss = 0.5165838599205017, train/logprobs = tensor([[-0.5400, -1.4908],
        [-0.7059, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04714364558458328
Epoch 0, Step 296: train/loss = 0.5947427749633789, train/raw-loss = 0.5069079399108887, train/logprobs = tensor([[-0.4823, -3.6807],
        [-0.5680, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04391741007566452
Epoch 0, Step 297: train/loss = 0.6950118541717529, train/raw-loss = 0.6122879385948181, train/logprobs = tensor([[-0.4895, -0.9945],
        [-0.4603, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04136195033788681
Epoch 0, Step 298: train/loss = 0.6798415184020996, train/raw-loss = 0.6023808717727661, train/logprobs = tensor([[-0.4387, -1.1164],
        [-0.4239, -0.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03873036801815033
Epoch 0, Step 299: train/loss = 0.6339757442474365, train/raw-loss = 0.5404399633407593, train/logprobs = tensor([[-0.5793, -1.9547],
        [-0.7184, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04676789045333862
Epoch 0, Step 300: train/loss = 0.6092183589935303, train/raw-loss = 0.5076470375061035, train/logprobs = tensor([[-0.8386, -1.9099],
        [-0.7871, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05078566074371338
Epoch 0, Step 301: train/loss = 0.6156255006790161, train/raw-loss = 0.5234463214874268, train/logprobs = tensor([[-0.5402, -1.3534],
        [-0.6118, -0.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04608956724405289
Epoch 0, Step 302: train/loss = 0.6249845027923584, train/raw-loss = 0.5086508393287659, train/logprobs = tensor([[-0.8408, -2.2818],
        [-0.7506, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058166831731796265
Epoch 0, Step 303: train/loss = 0.6501979827880859, train/raw-loss = 0.5625144839286804, train/logprobs = tensor([[-0.6124, -1.1872],
        [-0.5838, -0.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043841760605573654
Epoch 0, Step 304: train/loss = 0.720628023147583, train/raw-loss = 0.6252597570419312, train/logprobs = tensor([[-0.7095, -0.9436],
        [-0.7824, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047684136778116226
Epoch 0, Step 305: train/loss = 0.5643672943115234, train/raw-loss = 0.4678233861923218, train/logprobs = tensor([[-0.5647, -3.3664],
        [-0.5446, -1.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04827195405960083
Epoch 0, Step 306: train/loss = 0.6112469434738159, train/raw-loss = 0.5069680213928223, train/logprobs = tensor([[-0.5498, -1.6902],
        [-0.5634, -0.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05213946849107742
Epoch 0, Step 307: train/loss = 0.6909550428390503, train/raw-loss = 0.6028679609298706, train/logprobs = tensor([[-0.5818, -0.7649],
        [-0.6423, -0.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04404355213046074
Epoch 0, Step 308: train/loss = 0.5908361077308655, train/raw-loss = 0.4908285140991211, train/logprobs = tensor([[-0.7265, -1.6487],
        [-0.7412, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05000380426645279
Epoch 0, Step 309: train/loss = 0.5866994857788086, train/raw-loss = 0.493619441986084, train/logprobs = tensor([[-0.5470, -1.8049],
        [-0.5670, -0.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04654000699520111
Epoch 0, Step 310: train/loss = 0.6234225630760193, train/raw-loss = 0.5298866629600525, train/logprobs = tensor([[-0.6192, -1.4026],
        [-0.5873, -0.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046767935156822205
Epoch 0, Step 311: train/loss = 0.7198529839515686, train/raw-loss = 0.6280621290206909, train/logprobs = tensor([[-0.6382, -0.9394],
        [-0.5269, -0.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04589543119072914
Epoch 0, Step 312: train/loss = 0.6969858407974243, train/raw-loss = 0.6006791591644287, train/logprobs = tensor([[-0.9288, -1.4232],
        [-0.9055, -0.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0481533482670784
Epoch 0, Step 313: train/loss = 0.5254062414169312, train/raw-loss = 0.4223693013191223, train/logprobs = tensor([[-0.5682, -4.2251],
        [-0.5828, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051518481224775314
Epoch 0, Step 314: train/loss = 0.541641354560852, train/raw-loss = 0.44140464067459106, train/logprobs = tensor([[-0.5327, -3.2957],
        [-0.5380, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05011835694313049
Epoch 0, Step 315: train/loss = 0.5382350087165833, train/raw-loss = 0.439194917678833, train/logprobs = tensor([[-0.6582, -2.2759],
        [-0.7601, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04952005296945572
Epoch 0, Step 316: train/loss = 0.7362970113754272, train/raw-loss = 0.6655391454696655, train/logprobs = tensor([[-0.4907, -0.5195],
        [-0.4677, -0.3808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035378970205783844
Epoch 0, Step 317: train/loss = 0.5641177296638489, train/raw-loss = 0.46166110038757324, train/logprobs = tensor([[-0.5481, -3.9288],
        [-0.5888, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05122832953929901
Epoch 0, Step 318: train/loss = 0.6472052335739136, train/raw-loss = 0.5530113577842712, train/logprobs = tensor([[-0.5242, -1.1993],
        [-0.5663, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04709693789482117
Epoch 0, Step 319: train/loss = 0.6030067801475525, train/raw-loss = 0.5050060749053955, train/logprobs = tensor([[-0.7856, -2.2311],
        [-0.6843, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0490003377199173
Epoch 0, Step 320: train/loss = 0.5760203003883362, train/raw-loss = 0.471879243850708, train/logprobs = tensor([[-0.5438, -3.6130],
        [-0.5532, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05207052454352379
Epoch 0, Step 321: train/loss = 0.5968353748321533, train/raw-loss = 0.49961817264556885, train/logprobs = tensor([[-0.5835, -1.4998],
        [-0.6479, -0.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048608630895614624
Epoch 0, Step 322: train/loss = 0.5861735939979553, train/raw-loss = 0.49395573139190674, train/logprobs = tensor([[-1.0598, -3.8761],
        [-0.9065, -1.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04610893502831459
Epoch 0, Step 323: train/loss = 0.5082993507385254, train/raw-loss = 0.4107363224029541, train/logprobs = tensor([[-0.6059, -4.5685],
        [-0.6579, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04878152534365654
Epoch 0, Step 324: train/loss = 0.596035361289978, train/raw-loss = 0.5013225078582764, train/logprobs = tensor([[-0.4729, -1.7581],
        [-0.5124, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04735641926527023
Epoch 0, Step 325: train/loss = 0.5287485718727112, train/raw-loss = 0.4121488034725189, train/logprobs = tensor([[-0.5962, -2.9510],
        [-0.6253, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058299873024225235
Epoch 0, Step 326: train/loss = 0.5880141854286194, train/raw-loss = 0.4922417402267456, train/logprobs = tensor([[-0.5111, -1.5482],
        [-0.5475, -0.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04788622260093689
Epoch 0, Step 327: train/loss = 0.5332241058349609, train/raw-loss = 0.4171639084815979, train/logprobs = tensor([[-0.7569, -3.0018],
        [-0.7843, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05803009122610092
Epoch 0, Step 328: train/loss = 0.6658201813697815, train/raw-loss = 0.5759013891220093, train/logprobs = tensor([[-0.6089, -2.0519],
        [-0.5243, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04495937377214432
Epoch 0, Step 329: train/loss = 0.6774177551269531, train/raw-loss = 0.5728526711463928, train/logprobs = tensor([[-0.7864, -1.4628],
        [-0.6895, -0.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05228254571557045
Epoch 0, Step 330: train/loss = 0.5617937445640564, train/raw-loss = 0.4703887403011322, train/logprobs = tensor([[-0.5585, -2.2055],
        [-0.5843, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0457024946808815
Epoch 0, Step 331: train/loss = 0.5026295781135559, train/raw-loss = 0.3902483582496643, train/logprobs = tensor([[-0.7209, -3.8116],
        [-0.7327, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056190602481365204
Epoch 0, Step 332: train/loss = 0.6229597926139832, train/raw-loss = 0.5335759520530701, train/logprobs = tensor([[-0.4744, -1.3919],
        [-0.4727, -0.5886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044691916555166245
Epoch 0, Step 333: train/loss = 0.5824026465415955, train/raw-loss = 0.4908326268196106, train/logprobs = tensor([[-0.5437, -1.8369],
        [-0.6344, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04578498750925064
Epoch 0, Step 334: train/loss = 0.5658859610557556, train/raw-loss = 0.46244683861732483, train/logprobs = tensor([[-0.5928, -2.3746],
        [-0.6880, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05171956121921539
Epoch 0, Step 335: train/loss = 0.5193119645118713, train/raw-loss = 0.4102795720100403, train/logprobs = tensor([[-0.7248, -3.6705],
        [-0.8297, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054516181349754333
Epoch 0, Step 336: train/loss = 0.7194622159004211, train/raw-loss = 0.6311075687408447, train/logprobs = tensor([[-0.7475, -0.8790],
        [-0.6916, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044177379459142685
Epoch 0, Step 337: train/loss = 0.6567339301109314, train/raw-loss = 0.5727133750915527, train/logprobs = tensor([[-0.4379, -1.3401],
        [-0.4957, -0.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042010288685560226
Epoch 0, Step 338: train/loss = 0.5862751603126526, train/raw-loss = 0.47794175148010254, train/logprobs = tensor([[-0.5414, -1.8501],
        [-0.6226, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05416668951511383
Epoch 0, Step 339: train/loss = 0.6733421683311462, train/raw-loss = 0.5929223895072937, train/logprobs = tensor([[-0.5736, -1.2106],
        [-0.5143, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04020990431308746
Epoch 0, Step 340: train/loss = 0.6475586295127869, train/raw-loss = 0.5470219254493713, train/logprobs = tensor([[-0.5132, -1.2180],
        [-0.5669, -0.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05026836693286896
Epoch 0, Step 341: train/loss = 0.5660022497177124, train/raw-loss = 0.4721679389476776, train/logprobs = tensor([[-0.7190, -3.8800],
        [-0.6605, -1.2451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0469171479344368
Epoch 0, Step 342: train/loss = 0.7173400521278381, train/raw-loss = 0.6550571918487549, train/logprobs = tensor([[-0.4830, -0.4221],
        [-0.5157, -0.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03114140033721924
Epoch 0, Step 343: train/loss = 0.602698802947998, train/raw-loss = 0.5076916217803955, train/logprobs = tensor([[-0.5503, -3.0029],
        [-0.5784, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04750360548496246
Epoch 0, Step 344: train/loss = 0.6075100898742676, train/raw-loss = 0.5022480487823486, train/logprobs = tensor([[-0.7063, -1.2598],
        [-0.9436, -0.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052631013095378876
Epoch 0, Step 345: train/loss = 0.6957078576087952, train/raw-loss = 0.5992697477340698, train/logprobs = tensor([[-0.8658, -1.0833],
        [-0.7099, -0.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04821907728910446
Epoch 0, Step 346: train/loss = 0.638590931892395, train/raw-loss = 0.551516592502594, train/logprobs = tensor([[-0.4768, -1.0620],
        [-0.5707, -0.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04353715106844902
Epoch 0, Step 347: train/loss = 0.5329816341400146, train/raw-loss = 0.4190354347229004, train/logprobs = tensor([[-0.6906, -2.3575],
        [-0.8657, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05697311460971832
Epoch 0, Step 348: train/loss = 0.539435863494873, train/raw-loss = 0.4280279278755188, train/logprobs = tensor([[-0.6038, -2.6741],
        [-0.5193, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05570400133728981
Epoch 0, Step 349: train/loss = 0.48551541566848755, train/raw-loss = 0.37717151641845703, train/logprobs = tensor([[-0.8816, -3.5568],
        [-0.8227, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05417197197675705
Epoch 0, Step 350: train/loss = 0.6276156902313232, train/raw-loss = 0.5453532934188843, train/logprobs = tensor([[-0.4978, -1.2017],
        [-0.5712, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041131239384412766
Epoch 0, Step 351: train/loss = 0.6777151226997375, train/raw-loss = 0.5821957588195801, train/logprobs = tensor([[-0.5538, -1.0324],
        [-0.5411, -0.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047759704291820526
Epoch 0, Step 352: train/loss = 0.5216164588928223, train/raw-loss = 0.431601345539093, train/logprobs = tensor([[-0.7872, -2.2339],
        [-0.8795, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04500756040215492
Epoch 0, Step 353: train/loss = 0.5783116817474365, train/raw-loss = 0.4943530261516571, train/logprobs = tensor([[-0.5449, -1.6920],
        [-0.6192, -0.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04197929427027702
Epoch 0, Step 354: train/loss = 0.6189196109771729, train/raw-loss = 0.5357506275177002, train/logprobs = tensor([[-0.7405, -2.3500],
        [-0.7014, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04158450663089752
Epoch 0, Step 355: train/loss = 0.5912267565727234, train/raw-loss = 0.5042529106140137, train/logprobs = tensor([[-0.7704, -2.4101],
        [-0.4865, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04348688945174217
Epoch 0, Step 356: train/loss = 0.47973114252090454, train/raw-loss = 0.3806692957878113, train/logprobs = tensor([[-0.6743, -5.1484],
        [-0.7055, -1.2146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04953090846538544
Epoch 0, Step 357: train/loss = 0.5363881587982178, train/raw-loss = 0.4417378008365631, train/logprobs = tensor([[-0.5823, -2.3815],
        [-0.6601, -0.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04732517898082733
Epoch 0, Step 358: train/loss = 0.6518290042877197, train/raw-loss = 0.5766150951385498, train/logprobs = tensor([[-0.4712, -1.3958],
        [-0.4617, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037606991827487946
Epoch 0, Step 359: train/loss = 0.5899907350540161, train/raw-loss = 0.5040955543518066, train/logprobs = tensor([[-0.6469, -1.9394],
        [-0.6230, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04294760525226593
Epoch 0, Step 360: train/loss = 0.5142868757247925, train/raw-loss = 0.4317391812801361, train/logprobs = tensor([[-0.5103, -3.9856],
        [-0.5035, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041273850947618484
Epoch 0, Step 361: train/loss = 0.6239436864852905, train/raw-loss = 0.5470466613769531, train/logprobs = tensor([[-0.5364, -1.3726],
        [-0.5618, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038448527455329895
Epoch 0, Step 362: train/loss = 0.5515425801277161, train/raw-loss = 0.452824205160141, train/logprobs = tensor([[-0.7453, -1.9791],
        [-0.9052, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04935920238494873
Epoch 0, Step 363: train/loss = 0.5950354933738708, train/raw-loss = 0.516649067401886, train/logprobs = tensor([[-0.5214, -1.5467],
        [-0.6360, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03919322416186333
Epoch 0, Step 364: train/loss = 0.7186747789382935, train/raw-loss = 0.6311015486717224, train/logprobs = tensor([[-0.6710, -0.6815],
        [-0.7761, -0.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04378662630915642
Epoch 0, Step 365: train/loss = 0.6242207288742065, train/raw-loss = 0.5293465852737427, train/logprobs = tensor([[-0.8370, -1.5374],
        [-0.8749, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04743707552552223
Epoch 0, Step 366: train/loss = 0.697076141834259, train/raw-loss = 0.6258634924888611, train/logprobs = tensor([[-0.5898, -0.9911],
        [-0.5279, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03560633957386017
Epoch 0, Step 367: train/loss = 0.5753992795944214, train/raw-loss = 0.4757367968559265, train/logprobs = tensor([[-0.9300, -2.3656],
        [-0.9271, -0.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04983123019337654
Epoch 0, Step 368: train/loss = 0.6996723413467407, train/raw-loss = 0.6121580600738525, train/logprobs = tensor([[-0.9879, -1.0218],
        [-0.8961, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043757177889347076
Epoch 0, Step 369: train/loss = 0.5196564197540283, train/raw-loss = 0.42884233593940735, train/logprobs = tensor([[-0.4572, -2.1146],
        [-0.4861, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04540703073143959
Epoch 0, Step 370: train/loss = 0.6412680149078369, train/raw-loss = 0.5589306354522705, train/logprobs = tensor([[-0.4808, -0.8976],
        [-0.6440, -0.4589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04116867855191231
Epoch 0, Step 371: train/loss = 0.6791836619377136, train/raw-loss = 0.6049976348876953, train/logprobs = tensor([[-0.4113, -0.7863],
        [-0.4235, -0.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03709302097558975
Epoch 0, Step 372: train/loss = 0.6736924648284912, train/raw-loss = 0.5640832185745239, train/logprobs = tensor([[-1.0450, -2.3147],
        [-0.6340, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05480465292930603
Epoch 0, Step 373: train/loss = 0.5427961945533752, train/raw-loss = 0.4558550715446472, train/logprobs = tensor([[-0.6228, -2.9746],
        [-0.6903, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04347055405378342
Epoch 0, Step 374: train/loss = 0.5343769192695618, train/raw-loss = 0.45079222321510315, train/logprobs = tensor([[-0.5103, -2.3328],
        [-0.5284, -0.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041792336851358414
Epoch 0, Step 375: train/loss = 0.604981005191803, train/raw-loss = 0.5216776132583618, train/logprobs = tensor([[-0.6167, -1.3278],
        [-0.6135, -0.4016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04165172576904297
Epoch 0, Step 376: train/loss = 0.5260676741600037, train/raw-loss = 0.4411739110946655, train/logprobs = tensor([[-0.4004, -2.3396],
        [-0.4382, -0.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042446862906217575
Epoch 0, Step 377: train/loss = 0.5889344811439514, train/raw-loss = 0.4966965913772583, train/logprobs = tensor([[-0.6670, -1.5122],
        [-0.6979, -0.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04611894115805626
Epoch 0, Step 378: train/loss = 0.5062130689620972, train/raw-loss = 0.41518068313598633, train/logprobs = tensor([[-0.4870, -2.6997],
        [-0.5239, -0.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04551620036363602
Epoch 0, Step 379: train/loss = 0.5298976302146912, train/raw-loss = 0.4497191309928894, train/logprobs = tensor([[-0.5421, -2.1372],
        [-0.5793, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04008924961090088
Epoch 0, Step 380: train/loss = 0.6370977759361267, train/raw-loss = 0.5580915808677673, train/logprobs = tensor([[-0.6685, -1.6258],
        [-0.6236, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039503104984760284
Epoch 0, Step 381: train/loss = 0.6971193552017212, train/raw-loss = 0.6157764196395874, train/logprobs = tensor([[-0.6293, -0.9261],
        [-0.4670, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0406714603304863
Epoch 0, Step 382: train/loss = 0.5178056955337524, train/raw-loss = 0.4169231653213501, train/logprobs = tensor([[-0.5828, -2.5528],
        [-0.6870, -0.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05044127255678177
Epoch 0, Step 383: train/loss = 0.5768216848373413, train/raw-loss = 0.5066185593605042, train/logprobs = tensor([[-0.4136, -2.1154],
        [-0.4176, -0.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03510155901312828
Epoch 0, Step 384: train/loss = 0.5930139422416687, train/raw-loss = 0.5081186890602112, train/logprobs = tensor([[-0.4423, -1.5727],
        [-0.4835, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04244761914014816
Epoch 0, Step 385: train/loss = 0.5901018977165222, train/raw-loss = 0.5039291977882385, train/logprobs = tensor([[-0.5550, -1.5521],
        [-0.6679, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043086349964141846
Epoch 0, Step 386: train/loss = 0.5705734491348267, train/raw-loss = 0.4774518311023712, train/logprobs = tensor([[-0.5756, -2.0799],
        [-0.5961, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046560801565647125
Epoch 0, Step 387: train/loss = 0.4898824691772461, train/raw-loss = 0.4163440465927124, train/logprobs = tensor([[-0.5799, -4.4916],
        [-0.5626, -0.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03676921874284744
Epoch 0, Step 388: train/loss = 0.6166039109230042, train/raw-loss = 0.547423243522644, train/logprobs = tensor([[-0.3981, -1.7381],
        [-0.3657, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03459032624959946
Epoch 0, Step 389: train/loss = 0.44067707657814026, train/raw-loss = 0.34192878007888794, train/logprobs = tensor([[-0.6548, -3.4577],
        [-0.6985, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04937414079904556
Epoch 0, Step 390: train/loss = 0.610884428024292, train/raw-loss = 0.5359538197517395, train/logprobs = tensor([[-0.6522, -3.8181],
        [-0.6029, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03746531158685684
Epoch 0, Step 391: train/loss = 0.5626385807991028, train/raw-loss = 0.47591355443000793, train/logprobs = tensor([[-0.6491, -2.4336],
        [-0.7648, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04336251690983772
Epoch 0, Step 392: train/loss = 0.753511905670166, train/raw-loss = 0.671772837638855, train/logprobs = tensor([[-1.1507, -1.3333],
        [-0.7239, -0.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04086950421333313
Epoch 0, Step 393: train/loss = 0.5992583632469177, train/raw-loss = 0.5283032655715942, train/logprobs = tensor([[-0.4882, -1.3824],
        [-0.4336, -0.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035477567464113235
Epoch 0, Step 394: train/loss = 0.5377483367919922, train/raw-loss = 0.44239023327827454, train/logprobs = tensor([[-0.7948, -2.8700],
        [-0.6310, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04767903313040733
Epoch 0, Step 395: train/loss = 0.43462803959846497, train/raw-loss = 0.34116125106811523, train/logprobs = tensor([[-0.7384, -6.6936],
        [-0.9322, -1.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04673337563872337
Epoch 0, Step 396: train/loss = 0.6372535228729248, train/raw-loss = 0.5679413676261902, train/logprobs = tensor([[-0.4588, -0.9805],
        [-0.5201, -0.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465604409575462
Epoch 0, Step 397: train/loss = 0.5093479156494141, train/raw-loss = 0.43051138520240784, train/logprobs = tensor([[-0.4811, -3.6512],
        [-0.4568, -0.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039418257772922516
Epoch 0, Step 398: train/loss = 0.7051005959510803, train/raw-loss = 0.6418557167053223, train/logprobs = tensor([[-0.7136, -0.6385],
        [-0.6287, -0.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03162246197462082
Epoch 0, Step 399: train/loss = 0.4879381060600281, train/raw-loss = 0.39896535873413086, train/logprobs = tensor([[-0.6127, -4.7806],
        [-0.7318, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04448636621236801
Epoch 0, Step 400: train/loss = 0.4805229902267456, train/raw-loss = 0.3694876432418823, train/logprobs = tensor([[-0.9665, -3.4668],
        [-0.8906, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055517662316560745
Epoch 0, Step 401: train/loss = 0.5337339639663696, train/raw-loss = 0.4419897794723511, train/logprobs = tensor([[-0.6401, -2.4913],
        [-0.8519, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04587211087346077
Epoch 0, Step 402: train/loss = 0.48405349254608154, train/raw-loss = 0.3853418231010437, train/logprobs = tensor([[-0.7042, -3.2444],
        [-0.8995, -0.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04935581609606743
Epoch 0, Step 403: train/loss = 0.4415696859359741, train/raw-loss = 0.3374974727630615, train/logprobs = tensor([[-1.0176, -5.9482],
        [-0.9187, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0520360991358757
Epoch 0, Step 404: train/loss = 0.5236276388168335, train/raw-loss = 0.4467155337333679, train/logprobs = tensor([[-1.9496, -6.6518],
        [-1.6438, -2.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038456059992313385
Epoch 0, Step 405: train/loss = 0.6846869587898254, train/raw-loss = 0.5977586507797241, train/logprobs = tensor([[-0.7000, -0.8783],
        [-0.6435, -0.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043464161455631256
Epoch 0, Step 406: train/loss = 0.5288428068161011, train/raw-loss = 0.42873793840408325, train/logprobs = tensor([[-0.7727, -2.5543],
        [-0.8153, -0.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05005240440368652
Epoch 0, Step 407: train/loss = 0.5671127438545227, train/raw-loss = 0.4898863136768341, train/logprobs = tensor([[-0.3348, -1.9067],
        [-0.3887, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038613211363554
Epoch 0, Step 408: train/loss = 0.45851439237594604, train/raw-loss = 0.3747228980064392, train/logprobs = tensor([[-0.4903, -3.0632],
        [-0.5376, -0.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04189576581120491
Epoch 0, Step 409: train/loss = 0.5295944809913635, train/raw-loss = 0.45549657940864563, train/logprobs = tensor([[-0.5387, -1.7646],
        [-0.6583, -0.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03704894334077835
Epoch 0, Step 410: train/loss = 0.592643678188324, train/raw-loss = 0.5091437697410583, train/logprobs = tensor([[-0.5171, -1.7460],
        [-0.4957, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04174993559718132
Epoch 0, Step 411: train/loss = 0.6337969303131104, train/raw-loss = 0.5618047714233398, train/logprobs = tensor([[-0.5210, -1.3082],
        [-0.4873, -0.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035996079444885254
Epoch 0, Step 412: train/loss = 0.5551090836524963, train/raw-loss = 0.4564491808414459, train/logprobs = tensor([[-0.9601, -2.0746],
        [-0.9910, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0493299663066864
Epoch 0, Step 413: train/loss = 0.5469436049461365, train/raw-loss = 0.458878755569458, train/logprobs = tensor([[-0.7136, -1.7267],
        [-0.8914, -0.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04403242468833923
Epoch 0, Step 414: train/loss = 0.5358848571777344, train/raw-loss = 0.4451124668121338, train/logprobs = tensor([[-0.7950, -4.2487],
        [-1.0008, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04538621008396149
Epoch 0, Step 415: train/loss = 0.5774795413017273, train/raw-loss = 0.4931870996952057, train/logprobs = tensor([[-0.7743, -2.1024],
        [-0.7669, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042146213352680206
Epoch 0, Step 416: train/loss = 0.42739999294281006, train/raw-loss = 0.3383955955505371, train/logprobs = tensor([[-0.6669, -6.5104],
        [-0.8116, -1.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04450218006968498
Epoch 0, Step 417: train/loss = 0.648074746131897, train/raw-loss = 0.5747867822647095, train/logprobs = tensor([[-0.3913, -1.3464],
        [-0.3210, -0.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664400428533554
Epoch 0, Step 418: train/loss = 0.5666260123252869, train/raw-loss = 0.4699414372444153, train/logprobs = tensor([[-0.5141, -2.7719],
        [-0.4809, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04834231361746788
Epoch 0, Step 419: train/loss = 0.4699614644050598, train/raw-loss = 0.3800947070121765, train/logprobs = tensor([[-0.5140, -3.3993],
        [-0.5652, -0.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04493338614702225
Epoch 0, Step 420: train/loss = 0.5534379482269287, train/raw-loss = 0.4559524357318878, train/logprobs = tensor([[-0.7514, -2.2906],
        [-0.8209, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048742763698101044
Epoch 0, Step 421: train/loss = 0.6359071135520935, train/raw-loss = 0.5445778369903564, train/logprobs = tensor([[-0.6020, -1.4118],
        [-0.5522, -0.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04566463083028793
Epoch 0, Step 422: train/loss = 0.6221792101860046, train/raw-loss = 0.5283141136169434, train/logprobs = tensor([[-0.7452, -1.8023],
        [-0.7031, -0.4138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04693255200982094
Epoch 0, Step 423: train/loss = 0.5555187463760376, train/raw-loss = 0.4734189510345459, train/logprobs = tensor([[-0.6204, -4.4180],
        [-0.5338, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04104989022016525
Epoch 0, Step 424: train/loss = 0.5211880803108215, train/raw-loss = 0.41708609461784363, train/logprobs = tensor([[-0.8483, -3.0005],
        [-0.8631, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05205100029706955
Epoch 0, Step 425: train/loss = 0.5832428336143494, train/raw-loss = 0.4967171847820282, train/logprobs = tensor([[-0.5653, -1.4055],
        [-0.6033, -0.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043262846767902374
Epoch 0, Step 426: train/loss = 0.5214729905128479, train/raw-loss = 0.4306798577308655, train/logprobs = tensor([[-0.6701, -2.8389],
        [-0.5854, -0.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045396558940410614
Epoch 0, Step 427: train/loss = 0.5992802381515503, train/raw-loss = 0.5227984189987183, train/logprobs = tensor([[-0.6533, -1.6486],
        [-0.5856, -0.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038240909576416016
Epoch 0, Step 428: train/loss = 0.5615144371986389, train/raw-loss = 0.46610671281814575, train/logprobs = tensor([[-0.3445, -1.9567],
        [-0.3451, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04770384728908539
Epoch 0, Step 429: train/loss = 0.6226205229759216, train/raw-loss = 0.5055270791053772, train/logprobs = tensor([[-0.7712, -1.7107],
        [-0.6924, -0.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058546699583530426
Epoch 0, Step 430: train/loss = 0.5443486571311951, train/raw-loss = 0.46217218041419983, train/logprobs = tensor([[-0.6920, -3.9438],
        [-0.7700, -0.6727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041088223457336426
Epoch 0, Step 431: train/loss = 0.7064287066459656, train/raw-loss = 0.6148108839988708, train/logprobs = tensor([[-0.8907, -1.3671],
        [-0.5309, -0.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04580891132354736
Epoch 0, Step 432: train/loss = 0.6250379681587219, train/raw-loss = 0.5440800189971924, train/logprobs = tensor([[-0.6651, -1.4124],
        [-0.6483, -0.4974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04047895967960358
Epoch 0, Step 433: train/loss = 0.7819885611534119, train/raw-loss = 0.7002824544906616, train/logprobs = tensor([[-0.9200, -0.8493],
        [-0.5462, -0.3938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04085308313369751
Epoch 0, Step 434: train/loss = 0.6602755188941956, train/raw-loss = 0.5653940439224243, train/logprobs = tensor([[-0.8535, -1.7622],
        [-0.5341, -0.5111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04744075611233711
Epoch 0, Step 435: train/loss = 0.6145364046096802, train/raw-loss = 0.5168382525444031, train/logprobs = tensor([[-0.4804, -1.4023],
        [-0.4883, -0.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04884907230734825
Epoch 0, Step 436: train/loss = 0.5586254596710205, train/raw-loss = 0.46966633200645447, train/logprobs = tensor([[-0.5054, -1.6840],
        [-0.7945, -0.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04447957128286362
Epoch 0, Step 437: train/loss = 0.3842998147010803, train/raw-loss = 0.29389411211013794, train/logprobs = tensor([[-0.5710, -5.8540],
        [-0.7187, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04520285874605179
Epoch 0, Step 438: train/loss = 0.5737842321395874, train/raw-loss = 0.4944015145301819, train/logprobs = tensor([[-0.5002, -1.5745],
        [-0.5231, -0.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03969134762883186
Epoch 0, Step 439: train/loss = 0.566055417060852, train/raw-loss = 0.4792666435241699, train/logprobs = tensor([[-0.5826, -1.4890],
        [-0.6364, -0.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04339439794421196
Epoch 0, Step 440: train/loss = 0.5325814485549927, train/raw-loss = 0.43355152010917664, train/logprobs = tensor([[-0.6084, -4.5843],
        [-0.7018, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04951496794819832
Epoch 0, Step 441: train/loss = 0.6302338242530823, train/raw-loss = 0.5478817224502563, train/logprobs = tensor([[-0.4765, -1.1263],
        [-0.5071, -0.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04117603227496147
Epoch 0, Step 442: train/loss = 0.6847329139709473, train/raw-loss = 0.6216850280761719, train/logprobs = tensor([[-0.5056, -1.0725],
        [-0.3818, -0.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03152395039796829
Epoch 0, Step 443: train/loss = 0.5617042779922485, train/raw-loss = 0.48409658670425415, train/logprobs = tensor([[-0.4562, -2.6231],
        [-0.4989, -0.4864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038803830742836
Epoch 0, Step 444: train/loss = 0.5996620059013367, train/raw-loss = 0.5174481868743896, train/logprobs = tensor([[-0.5609, -2.5853],
        [-0.4286, -0.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0411069355905056
Epoch 0, Step 445: train/loss = 0.6405553221702576, train/raw-loss = 0.5729621052742004, train/logprobs = tensor([[-0.3749, -1.1621],
        [-0.3546, -0.4739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033796608448028564
Epoch 0, Step 446: train/loss = 0.6146237254142761, train/raw-loss = 0.5123167037963867, train/logprobs = tensor([[-0.7005, -1.4268],
        [-0.6370, -0.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051153507083654404
Epoch 0, Step 447: train/loss = 0.465681254863739, train/raw-loss = 0.3660334348678589, train/logprobs = tensor([[-0.6535, -2.9482],
        [-0.6403, -0.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04982392489910126
Epoch 0, Step 448: train/loss = 0.5665624737739563, train/raw-loss = 0.4821135997772217, train/logprobs = tensor([[-1.0134, -2.5590],
        [-0.7948, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04222442954778671
Epoch 0, Step 449: train/loss = 0.5302615165710449, train/raw-loss = 0.42468494176864624, train/logprobs = tensor([[-0.5842, -2.2577],
        [-0.6552, -0.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05278827250003815
Epoch 0, Step 450: train/loss = 0.5413414239883423, train/raw-loss = 0.4442715644836426, train/logprobs = tensor([[-0.4850, -3.2434],
        [-0.4823, -0.6720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04853493347764015
Epoch 0, Step 451: train/loss = 0.5372280478477478, train/raw-loss = 0.4372889995574951, train/logprobs = tensor([[-0.5488, -2.0622],
        [-0.5492, -0.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049969520419836044
Epoch 0, Step 452: train/loss = 0.48757511377334595, train/raw-loss = 0.3776671290397644, train/logprobs = tensor([[-0.6476, -4.8835],
        [-0.7237, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05495399609208107
Epoch 0, Step 453: train/loss = 0.643841028213501, train/raw-loss = 0.5529628396034241, train/logprobs = tensor([[-0.5937, -1.5620],
        [-0.4464, -0.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04543912410736084
Epoch 0, Step 454: train/loss = 0.5953673720359802, train/raw-loss = 0.4884923994541168, train/logprobs = tensor([[-0.8759, -3.9584],
        [-0.6729, -0.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05343747138977051
Epoch 0, Step 455: train/loss = 0.6146225929260254, train/raw-loss = 0.5109087824821472, train/logprobs = tensor([[-0.6878, -1.7507],
        [-0.5490, -0.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051856882870197296
Epoch 0, Step 456: train/loss = 0.5564661026000977, train/raw-loss = 0.4618137776851654, train/logprobs = tensor([[-0.4967, -4.2401],
        [-0.5574, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047326166182756424
Epoch 0, Step 457: train/loss = 0.5675584673881531, train/raw-loss = 0.4670412540435791, train/logprobs = tensor([[-0.5157, -1.9081],
        [-0.5913, -0.5846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05025861784815788
Epoch 0, Step 458: train/loss = 0.5943228006362915, train/raw-loss = 0.4997967481613159, train/logprobs = tensor([[-0.9092, -2.9200],
        [-0.6017, -0.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04726306349039078
Epoch 0, Step 459: train/loss = 0.4711485803127289, train/raw-loss = 0.36014890670776367, train/logprobs = tensor([[-0.6932, -3.0664],
        [-0.7344, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0554998517036438
Epoch 0, Step 460: train/loss = 0.5454148054122925, train/raw-loss = 0.43688639998435974, train/logprobs = tensor([[-0.5063, -2.0937],
        [-0.5995, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05426417291164398
Epoch 0, Step 461: train/loss = 0.5560020208358765, train/raw-loss = 0.4717091917991638, train/logprobs = tensor([[-0.3454, -2.1449],
        [-0.3263, -0.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042146433144807816
Epoch 0, Step 462: train/loss = 0.5971684455871582, train/raw-loss = 0.5090614557266235, train/logprobs = tensor([[-0.7553, -2.0185],
        [-0.5208, -0.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044053494930267334
Epoch 0, Step 463: train/loss = 0.6088036894798279, train/raw-loss = 0.5243438482284546, train/logprobs = tensor([[-0.4573, -1.3448],
        [-0.3807, -0.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042229924350976944
Epoch 0, Step 464: train/loss = 0.8201920986175537, train/raw-loss = 0.7188678979873657, train/logprobs = tensor([[-1.4275, -2.0135],
        [-0.5751, -0.6410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05066211149096489
Epoch 0, Step 465: train/loss = 0.6022701263427734, train/raw-loss = 0.49675440788269043, train/logprobs = tensor([[-0.6210, -1.8733],
        [-0.5726, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0527578741312027
Epoch 0, Step 466: train/loss = 0.5381218194961548, train/raw-loss = 0.4206233620643616, train/logprobs = tensor([[-0.7482, -2.8915],
        [-0.6117, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0587492361664772
Epoch 0, Step 467: train/loss = 0.5305697917938232, train/raw-loss = 0.42382073402404785, train/logprobs = tensor([[-0.6133, -2.4660],
        [-0.8122, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053374528884887695
Epoch 0, Step 468: train/loss = 0.5834717750549316, train/raw-loss = 0.49206459522247314, train/logprobs = tensor([[-0.5057, -1.6190],
        [-0.5027, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04570356756448746
Epoch 0, Step 469: train/loss = 0.574355959892273, train/raw-loss = 0.48440322279930115, train/logprobs = tensor([[-0.5465, -1.4371],
        [-0.6032, -0.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04497634246945381
Epoch 0, Step 470: train/loss = 0.7165144681930542, train/raw-loss = 0.6088159084320068, train/logprobs = tensor([[-0.6101, -1.0145],
        [-0.4827, -0.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05384927988052368
Epoch 0, Step 471: train/loss = 0.5594338178634644, train/raw-loss = 0.41904425621032715, train/logprobs = tensor([[-0.7516, -2.4381],
        [-0.7264, -0.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.070194773375988
Epoch 0, Step 472: train/loss = 0.6849507093429565, train/raw-loss = 0.602277398109436, train/logprobs = tensor([[-0.5585, -0.6715],
        [-0.6154, -0.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04133664816617966
Epoch 0, Step 473: train/loss = 0.5425509214401245, train/raw-loss = 0.44662168622016907, train/logprobs = tensor([[-0.5173, -1.9795],
        [-0.5005, -0.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047964610159397125
Epoch 0, Step 474: train/loss = 0.599263072013855, train/raw-loss = 0.5107886791229248, train/logprobs = tensor([[-0.5617, -1.7570],
        [-0.4276, -0.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044237177819013596
Epoch 0, Step 475: train/loss = 0.4755498170852661, train/raw-loss = 0.36562418937683105, train/logprobs = tensor([[-0.6059, -3.1277],
        [-0.6487, -0.6447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054962798953056335
Epoch 0, Step 476: train/loss = 0.6471028923988342, train/raw-loss = 0.5499870181083679, train/logprobs = tensor([[-0.8705, -1.2941],
        [-0.9002, -0.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855794832110405
Epoch 0, Step 477: train/loss = 0.4486337900161743, train/raw-loss = 0.3404204249382019, train/logprobs = tensor([[-0.5653, -4.0174],
        [-0.5956, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05410667508840561
Epoch 0, Step 478: train/loss = 0.5285434722900391, train/raw-loss = 0.42351946234703064, train/logprobs = tensor([[-0.6567, -4.4188],
        [-0.8197, -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05251198634505272
Epoch 0, Step 479: train/loss = 0.5137848258018494, train/raw-loss = 0.3848203718662262, train/logprobs = tensor([[-0.7589, -2.8533],
        [-0.7919, -0.5011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448222696781158
Epoch 0, Step 480: train/loss = 0.6072204113006592, train/raw-loss = 0.5119785070419312, train/logprobs = tensor([[-0.4960, -1.8594],
        [-0.5087, -0.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04762091860175133
Epoch 0, Step 481: train/loss = 0.6272161602973938, train/raw-loss = 0.5243194103240967, train/logprobs = tensor([[-0.6670, -1.7156],
        [-0.6457, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05144839361310005
Epoch 0, Step 482: train/loss = 0.630821943283081, train/raw-loss = 0.5378252863883972, train/logprobs = tensor([[-0.5239, -2.4724],
        [-0.3931, -0.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04649834334850311
Epoch 0, Step 483: train/loss = 0.46851909160614014, train/raw-loss = 0.35590189695358276, train/logprobs = tensor([[-0.5707, -2.7925],
        [-0.6349, -0.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056308597326278687
Epoch 0, Step 484: train/loss = 0.4863641858100891, train/raw-loss = 0.3913249969482422, train/logprobs = tensor([[-0.5610, -3.2584],
        [-0.5388, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04751959815621376
Epoch 0, Step 485: train/loss = 0.5002921223640442, train/raw-loss = 0.3958297073841095, train/logprobs = tensor([[-0.8379, -2.8778],
        [-0.9017, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05223119631409645
Epoch 0, Step 486: train/loss = 0.5144844055175781, train/raw-loss = 0.4018764793872833, train/logprobs = tensor([[-0.5989, -3.0890],
        [-0.7020, -0.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0563039667904377
Epoch 0, Step 487: train/loss = 0.666610598564148, train/raw-loss = 0.5757299661636353, train/logprobs = tensor([[-0.6586, -1.2530],
        [-0.5029, -0.4619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045440301299095154
Epoch 0, Step 488: train/loss = 0.6689908504486084, train/raw-loss = 0.560893177986145, train/logprobs = tensor([[-1.0876, -3.6033],
        [-0.8938, -0.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054048843681812286
Epoch 0, Step 489: train/loss = 0.549429178237915, train/raw-loss = 0.44305115938186646, train/logprobs = tensor([[-0.6539, -1.7391],
        [-0.7945, -0.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05318900942802429
Epoch 0, Step 490: train/loss = 0.48225703835487366, train/raw-loss = 0.3669668436050415, train/logprobs = tensor([[-0.6473, -3.7011],
        [-0.7603, -0.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05764508619904518
Epoch 0, Step 491: train/loss = 0.7145788669586182, train/raw-loss = 0.6287845373153687, train/logprobs = tensor([[-0.6089, -0.7935],
        [-0.5278, -0.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04289714992046356
Epoch 0, Step 492: train/loss = 0.7353152632713318, train/raw-loss = 0.6265975832939148, train/logprobs = tensor([[-1.2529, -2.7110],
        [-0.7355, -0.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054358839988708496
Epoch 0, Step 493: train/loss = 0.4882969260215759, train/raw-loss = 0.3668500781059265, train/logprobs = tensor([[-0.6577, -5.0175],
        [-0.8155, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0607234425842762
Epoch 0, Step 494: train/loss = 0.6355267763137817, train/raw-loss = 0.5074669718742371, train/logprobs = tensor([[-0.6029, -1.8290],
        [-0.5221, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06402993202209473
Epoch 0, Step 495: train/loss = 0.5847421288490295, train/raw-loss = 0.4880843162536621, train/logprobs = tensor([[-0.4751, -1.4691],
        [-0.4909, -0.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04832889139652252
Epoch 0, Step 496: train/loss = 0.5305064916610718, train/raw-loss = 0.42867380380630493, train/logprobs = tensor([[-0.5539, -2.5094],
        [-0.6266, -0.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050916362553834915
Epoch 0, Step 497: train/loss = 0.5831269025802612, train/raw-loss = 0.47599947452545166, train/logprobs = tensor([[-0.5590, -1.5312],
        [-0.6408, -0.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05356369912624359
Epoch 0, Step 498: train/loss = 0.5727562308311462, train/raw-loss = 0.4681117832660675, train/logprobs = tensor([[-0.5647, -2.9826],
        [-0.5180, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052322208881378174
Epoch 0, Step 499: train/loss = 0.5891326665878296, train/raw-loss = 0.4788881242275238, train/logprobs = tensor([[-0.7757, -2.0280],
        [-0.6943, -0.6095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055122293531894684
Epoch 0, Step 500: train/loss = 0.6794873476028442, train/raw-loss = 0.5791910886764526, train/logprobs = tensor([[-0.5996, -1.2674],
        [-0.5262, -0.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0501481257379055
Epoch 0, Step 501: train/loss = 0.6436363458633423, train/raw-loss = 0.5340362191200256, train/logprobs = tensor([[-0.9157, -1.6105],
        [-0.8999, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054800085723400116
Epoch 0, Step 502: train/loss = 0.47509312629699707, train/raw-loss = 0.3731585741043091, train/logprobs = tensor([[-0.5674, -3.3982],
        [-0.6334, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05096729099750519
Epoch 0, Step 503: train/loss = 0.7189417481422424, train/raw-loss = 0.6150617599487305, train/logprobs = tensor([[-0.7256, -1.1675],
        [-0.5006, -0.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051939982920885086
Epoch 0, Step 504: train/loss = 0.6781139373779297, train/raw-loss = 0.5770363807678223, train/logprobs = tensor([[-0.9346, -1.4811],
        [-0.7175, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0505388081073761
Epoch 0, Step 505: train/loss = 0.5267878174781799, train/raw-loss = 0.4227967858314514, train/logprobs = tensor([[-0.5600, -2.5645],
        [-0.5384, -0.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05199551209807396
Epoch 0, Step 506: train/loss = 0.7199408411979675, train/raw-loss = 0.6411452293395996, train/logprobs = tensor([[-0.5321, -0.6481],
        [-0.4448, -0.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03939782455563545
Epoch 0, Step 507: train/loss = 0.6159764528274536, train/raw-loss = 0.5226601362228394, train/logprobs = tensor([[-0.7939, -1.7760],
        [-0.6970, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04665816202759743
Epoch 0, Step 508: train/loss = 0.6131353974342346, train/raw-loss = 0.5122830867767334, train/logprobs = tensor([[-0.8291, -2.8727],
        [-0.6474, -0.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0504261776804924
Epoch 0, Step 509: train/loss = 0.719468355178833, train/raw-loss = 0.6465312838554382, train/logprobs = tensor([[-0.9165, -1.1304],
        [-0.6016, -0.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03646855056285858
Epoch 0, Step 510: train/loss = 0.5078549385070801, train/raw-loss = 0.39545533061027527, train/logprobs = tensor([[-0.7654, -4.5428],
        [-0.7571, -0.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056199811398983
Epoch 0, Step 511: train/loss = 0.6117760539054871, train/raw-loss = 0.5048685073852539, train/logprobs = tensor([[-0.4654, -3.1792],
        [-0.4522, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05345374718308449
Epoch 0, Step 512: train/loss = 0.7529271841049194, train/raw-loss = 0.6445565223693848, train/logprobs = tensor([[-1.2932, -2.8839],
        [-0.6566, -0.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054185330867767334
Epoch 0, Step 513: train/loss = 0.4992061257362366, train/raw-loss = 0.3988631069660187, train/logprobs = tensor([[-0.5926, -3.4931],
        [-0.5507, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050171516835689545
Epoch 0, Step 514: train/loss = 0.5810130834579468, train/raw-loss = 0.47818025946617126, train/logprobs = tensor([[-0.5790, -2.3017],
        [-0.7471, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05141641944646835
Epoch 0, Step 515: train/loss = 0.6085692644119263, train/raw-loss = 0.5205379128456116, train/logprobs = tensor([[-0.5444, -1.6079],
        [-0.5853, -0.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04401567578315735
Epoch 0, Step 516: train/loss = 0.6675503253936768, train/raw-loss = 0.5665555000305176, train/logprobs = tensor([[-0.4957, -1.0817],
        [-0.4952, -0.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05049740523099899
Epoch 0, Step 517: train/loss = 0.7061827778816223, train/raw-loss = 0.6065592765808105, train/logprobs = tensor([[-1.2888, -2.4882],
        [-0.6378, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04981173947453499
Epoch 0, Step 518: train/loss = 0.5713867545127869, train/raw-loss = 0.4885982871055603, train/logprobs = tensor([[-0.4532, -2.1657],
        [-0.4511, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04139424115419388
Epoch 0, Step 519: train/loss = 0.5214714407920837, train/raw-loss = 0.41191786527633667, train/logprobs = tensor([[-0.8435, -5.4974],
        [-0.7529, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05477680638432503
Epoch 0, Step 520: train/loss = 0.5559000372886658, train/raw-loss = 0.4601874351501465, train/logprobs = tensor([[-0.5215, -3.4412],
        [-0.5150, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04785628616809845
Epoch 0, Step 521: train/loss = 0.4380594789981842, train/raw-loss = 0.33200570940971375, train/logprobs = tensor([[-0.5437, -3.2254],
        [-0.5896, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053026892244815826
Epoch 0, Step 522: train/loss = 0.6185076832771301, train/raw-loss = 0.5297729969024658, train/logprobs = tensor([[-0.4884, -1.2618],
        [-0.5479, -0.4076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044367339462041855
Epoch 0, Step 523: train/loss = 0.5521385669708252, train/raw-loss = 0.44590824842453003, train/logprobs = tensor([[-0.6567, -1.6727],
        [-0.8517, -0.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053115129470825195
Epoch 0, Step 524: train/loss = 0.5031917095184326, train/raw-loss = 0.39172643423080444, train/logprobs = tensor([[-0.6599, -3.3650],
        [-0.6151, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05573264881968498
Epoch 0, Step 525: train/loss = 0.5184288024902344, train/raw-loss = 0.40962743759155273, train/logprobs = tensor([[-0.6506, -2.8977],
        [-0.5615, -0.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054400697350502014
Epoch 0, Step 526: train/loss = 0.6473313570022583, train/raw-loss = 0.5517078638076782, train/logprobs = tensor([[-0.5908, -1.3931],
        [-0.4748, -0.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047811780124902725
Epoch 0, Step 527: train/loss = 0.6110859513282776, train/raw-loss = 0.5261249542236328, train/logprobs = tensor([[-0.4797, -1.5775],
        [-0.4993, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04248050972819328
Epoch 0, Step 528: train/loss = 0.5488032698631287, train/raw-loss = 0.4682231545448303, train/logprobs = tensor([[-0.5187, -3.5549],
        [-0.5684, -0.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04029005393385887
Epoch 0, Step 529: train/loss = 0.5448043346405029, train/raw-loss = 0.4331066608428955, train/logprobs = tensor([[-0.8378, -2.0822],
        [-0.7618, -0.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05584882199764252
Epoch 0, Step 530: train/loss = 0.5916533470153809, train/raw-loss = 0.4926537275314331, train/logprobs = tensor([[-0.5753, -1.7009],
        [-0.6292, -0.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049499835819005966
Epoch 0, Step 531: train/loss = 0.5525921583175659, train/raw-loss = 0.45729395747184753, train/logprobs = tensor([[-0.5256, -2.9644],
        [-0.5742, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0476490780711174
Epoch 0, Step 532: train/loss = 0.5229811668395996, train/raw-loss = 0.4308370351791382, train/logprobs = tensor([[-0.4323, -2.1256],
        [-0.4071, -0.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04607207700610161
Epoch 0, Step 533: train/loss = 0.6363033056259155, train/raw-loss = 0.536501944065094, train/logprobs = tensor([[-0.7172, -1.2905],
        [-0.7683, -0.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04990068078041077
Epoch 0, Step 534: train/loss = 0.4552151560783386, train/raw-loss = 0.3494425415992737, train/logprobs = tensor([[-0.6005, -3.7616],
        [-0.6053, -0.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052886296063661575
Epoch 0, Step 535: train/loss = 0.518180787563324, train/raw-loss = 0.401716023683548, train/logprobs = tensor([[-0.8898, -3.6479],
        [-0.7011, -0.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823236331343651
Epoch 0, Step 536: train/loss = 0.4828589856624603, train/raw-loss = 0.37093693017959595, train/logprobs = tensor([[-0.7887, -8.3427],
        [-0.5254, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05596102774143219
Epoch 0, Step 537: train/loss = 0.5656545162200928, train/raw-loss = 0.46787354350090027, train/logprobs = tensor([[-0.7992, -1.7641],
        [-0.8182, -0.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04889048635959625
Epoch 0, Step 538: train/loss = 0.6445647478103638, train/raw-loss = 0.5473887920379639, train/logprobs = tensor([[-0.7582, -1.5598],
        [-0.6728, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04858798533678055
Epoch 0, Step 539: train/loss = 0.7627898454666138, train/raw-loss = 0.6587362289428711, train/logprobs = tensor([[-1.0446, -1.5669],
        [-0.4371, -0.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05202680826187134
Epoch 0, Step 540: train/loss = 0.6677237749099731, train/raw-loss = 0.5855342149734497, train/logprobs = tensor([[-0.6269, -1.2225],
        [-0.4790, -0.5090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04109477996826172
Epoch 0, Step 541: train/loss = 0.5624089241027832, train/raw-loss = 0.4621153175830841, train/logprobs = tensor([[-0.7011, -1.8707],
        [-0.7676, -0.4185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050146788358688354
Epoch 0, Step 542: train/loss = 0.5162045955657959, train/raw-loss = 0.4186123013496399, train/logprobs = tensor([[-0.5651, -3.4716],
        [-0.6646, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04879612475633621
Epoch 0, Step 543: train/loss = 0.6632802486419678, train/raw-loss = 0.5833423733711243, train/logprobs = tensor([[-0.4387, -0.9973],
        [-0.4092, -0.3862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03996892645955086
Epoch 0, Step 544: train/loss = 0.6197430491447449, train/raw-loss = 0.5282147526741028, train/logprobs = tensor([[-0.7384, -1.3035],
        [-0.6778, -0.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045764148235321045
Epoch 0, Step 545: train/loss = 0.44297870993614197, train/raw-loss = 0.34086596965789795, train/logprobs = tensor([[-0.9587, -6.2191],
        [-1.0151, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051056377589702606
Epoch 0, Step 546: train/loss = 0.525529682636261, train/raw-loss = 0.42750415205955505, train/logprobs = tensor([[-0.5982, -2.7120],
        [-0.7460, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04901275783777237
Epoch 0, Step 547: train/loss = 0.7745526432991028, train/raw-loss = 0.6814355254173279, train/logprobs = tensor([[-2.5075, -6.9733],
        [-1.4086, -1.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04655854403972626
Epoch 0, Step 548: train/loss = 0.6724608540534973, train/raw-loss = 0.5902842283248901, train/logprobs = tensor([[-0.6898, -1.2347],
        [-0.5645, -0.5542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041088324040174484
Epoch 0, Step 549: train/loss = 0.5724117755889893, train/raw-loss = 0.4761492609977722, train/logprobs = tensor([[-0.5333, -1.5276],
        [-0.5837, -0.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04813127964735031
Epoch 0, Step 550: train/loss = 0.5524178743362427, train/raw-loss = 0.4699898362159729, train/logprobs = tensor([[-0.5992, -1.7961],
        [-0.5908, -0.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041214004158973694
Epoch 0, Step 551: train/loss = 0.7452042698860168, train/raw-loss = 0.6358562707901001, train/logprobs = tensor([[-1.1312, -1.6155],
        [-0.6208, -0.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05467399209737778
Epoch 0, Step 552: train/loss = 0.5306922197341919, train/raw-loss = 0.44623154401779175, train/logprobs = tensor([[-0.6571, -2.1644],
        [-0.6669, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04223033785820007
Epoch 0, Step 553: train/loss = 0.7368172407150269, train/raw-loss = 0.6670417785644531, train/logprobs = tensor([[-0.3967, -0.2628],
        [-0.3999, -0.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03488771989941597
Epoch 0, Step 554: train/loss = 0.5729534029960632, train/raw-loss = 0.4803885817527771, train/logprobs = tensor([[-0.7500, -2.0508],
        [-0.6799, -0.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04628243297338486
Epoch 0, Step 555: train/loss = 0.4574875831604004, train/raw-loss = 0.3654688596725464, train/logprobs = tensor([[-0.4074, -2.7693],
        [-0.4917, -0.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046009361743927
Epoch 0, Step 556: train/loss = 0.6011704206466675, train/raw-loss = 0.5124270915985107, train/logprobs = tensor([[-0.5348, -1.5254],
        [-0.5840, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044371675699949265
Epoch 0, Step 557: train/loss = 0.6435470581054688, train/raw-loss = 0.5797326564788818, train/logprobs = tensor([[-0.3713, -1.0689],
        [-0.4135, -0.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03190722316503525
Epoch 0, Step 558: train/loss = 0.696702778339386, train/raw-loss = 0.626166582107544, train/logprobs = tensor([[-0.5773, -0.7917],
        [-0.4794, -0.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035268090665340424
Epoch 0, Step 559: train/loss = 0.4707483649253845, train/raw-loss = 0.36513596773147583, train/logprobs = tensor([[-0.8484, -2.8729],
        [-1.0689, -0.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052806224673986435
Epoch 0, Step 560: train/loss = 0.5977095365524292, train/raw-loss = 0.5161644220352173, train/logprobs = tensor([[-0.6004, -1.5012],
        [-0.6149, -0.4539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040772587060928345
Epoch 0, Step 561: train/loss = 0.6424946784973145, train/raw-loss = 0.5660989880561829, train/logprobs = tensor([[-0.7088, -1.3644],
        [-0.5224, -0.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03819785639643669
Epoch 0, Step 562: train/loss = 0.4699985682964325, train/raw-loss = 0.35531723499298096, train/logprobs = tensor([[-0.6347, -3.2483],
        [-0.6573, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05734067037701607
Epoch 0, Step 563: train/loss = 0.5932439565658569, train/raw-loss = 0.5105320811271667, train/logprobs = tensor([[-0.5336, -1.3123],
        [-0.6029, -0.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04135594516992569
Epoch 0, Step 564: train/loss = 0.44173359870910645, train/raw-loss = 0.3337857723236084, train/logprobs = tensor([[-0.9502, -6.0991],
        [-0.8952, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05397391691803932
Epoch 0, Step 565: train/loss = 0.5129432082176208, train/raw-loss = 0.4269498288631439, train/logprobs = tensor([[-0.6795, -2.0697],
        [-0.8225, -0.5873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042996685951948166
Epoch 0, Step 566: train/loss = 0.5556961894035339, train/raw-loss = 0.46329206228256226, train/logprobs = tensor([[-0.9010, -4.6438],
        [-0.8564, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04620207101106644
Epoch 0, Step 567: train/loss = 0.5996761322021484, train/raw-loss = 0.5216948986053467, train/logprobs = tensor([[-0.4888, -2.1899],
        [-0.3850, -0.6252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038990575820207596
Epoch 0, Step 568: train/loss = 0.49637123942375183, train/raw-loss = 0.4014809727668762, train/logprobs = tensor([[-0.8136, -5.6420],
        [-0.8285, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04744512587785721
Epoch 0, Step 569: train/loss = 0.6366385221481323, train/raw-loss = 0.5542421340942383, train/logprobs = tensor([[-0.6493, -1.4262],
        [-0.5498, -0.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041198186576366425
Epoch 0, Step 570: train/loss = 0.558858335018158, train/raw-loss = 0.4727134108543396, train/logprobs = tensor([[-0.3893, -3.3833],
        [-0.3360, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043072450906038284
Epoch 0, Step 571: train/loss = 0.6427962183952332, train/raw-loss = 0.5506413578987122, train/logprobs = tensor([[-1.1960, -2.4726],
        [-0.8344, -0.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046077437698841095
Epoch 0, Step 572: train/loss = 0.6423869132995605, train/raw-loss = 0.5518183708190918, train/logprobs = tensor([[-0.5536, -1.1401],
        [-0.5272, -0.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04528428241610527
Epoch 0, Step 573: train/loss = 0.5296475291252136, train/raw-loss = 0.4325878620147705, train/logprobs = tensor([[-0.6614, -2.5138],
        [-0.8141, -0.4679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048529841005802155
Epoch 0, Step 574: train/loss = 0.5666176080703735, train/raw-loss = 0.4860571622848511, train/logprobs = tensor([[-0.9118, -2.5875],
        [-0.9769, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040280237793922424
Epoch 0, Step 575: train/loss = 0.5134731531143188, train/raw-loss = 0.4269159436225891, train/logprobs = tensor([[-0.5953, -4.0193],
        [-0.5278, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04327859356999397
Epoch 0, Step 576: train/loss = 0.4726867377758026, train/raw-loss = 0.3839096426963806, train/logprobs = tensor([[-0.5388, -5.3203],
        [-0.6682, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0443885512650013
Epoch 0, Step 577: train/loss = 0.5533079504966736, train/raw-loss = 0.4653974175453186, train/logprobs = tensor([[-0.7157, -1.9862],
        [-0.7621, -0.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043955247849226
Epoch 0, Step 578: train/loss = 0.5202717185020447, train/raw-loss = 0.4395214915275574, train/logprobs = tensor([[-0.7002, -1.8491],
        [-0.8915, -0.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04037511721253395
Epoch 0, Step 579: train/loss = 0.5041170716285706, train/raw-loss = 0.41662317514419556, train/logprobs = tensor([[-0.5166, -2.2986],
        [-0.6065, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04374697059392929
Epoch 0, Step 580: train/loss = 0.6578072309494019, train/raw-loss = 0.5655834674835205, train/logprobs = tensor([[-0.8021, -2.2357],
        [-0.5544, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04611189663410187
Epoch 0, Step 581: train/loss = 0.6777466535568237, train/raw-loss = 0.5988670587539673, train/logprobs = tensor([[-0.6726, -1.5810],
        [-0.5090, -0.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03943980485200882
Epoch 0, Step 582: train/loss = 0.4381462037563324, train/raw-loss = 0.35914990305900574, train/logprobs = tensor([[-0.8345, -5.3518],
        [-0.8832, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03949815779924393
Epoch 0, Step 583: train/loss = 0.6078115701675415, train/raw-loss = 0.5381252765655518, train/logprobs = tensor([[-0.4916, -1.4841],
        [-0.4454, -0.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03484316170215607
Epoch 0, Step 584: train/loss = 0.5879197716712952, train/raw-loss = 0.5000488758087158, train/logprobs = tensor([[-0.4657, -1.6972],
        [-0.5051, -0.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04393545538187027
Epoch 0, Step 585: train/loss = 0.6194148659706116, train/raw-loss = 0.5251315832138062, train/logprobs = tensor([[-0.7025, -1.7302],
        [-0.6074, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04714164137840271
Epoch 0, Step 586: train/loss = 0.49299460649490356, train/raw-loss = 0.4120063781738281, train/logprobs = tensor([[-0.6027, -3.1079],
        [-0.6375, -0.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04049409553408623
Epoch 0, Step 587: train/loss = 0.523966908454895, train/raw-loss = 0.44971156120300293, train/logprobs = tensor([[-0.4284, -1.6979],
        [-0.5079, -0.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03712769225239754
Epoch 0, Step 588: train/loss = 0.5605790615081787, train/raw-loss = 0.4884997606277466, train/logprobs = tensor([[-0.5852, -4.2109],
        [-0.6830, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03603963553905487
Epoch 0, Step 589: train/loss = 0.4432394504547119, train/raw-loss = 0.3384134769439697, train/logprobs = tensor([[-0.7524, -5.0108],
        [-0.8439, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0524129755795002
Epoch 0, Step 590: train/loss = 0.6171256303787231, train/raw-loss = 0.5236630439758301, train/logprobs = tensor([[-0.8002, -1.7488],
        [-0.7032, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04673128202557564
Epoch 0, Step 591: train/loss = 0.7108374834060669, train/raw-loss = 0.6374901533126831, train/logprobs = tensor([[-0.5049, -0.7438],
        [-0.4880, -0.4866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03667367249727249
Epoch 0, Step 592: train/loss = 0.6558946371078491, train/raw-loss = 0.5786885023117065, train/logprobs = tensor([[-1.4439, -2.2543],
        [-1.0038, -0.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03860308974981308
Epoch 0, Step 593: train/loss = 0.6217883229255676, train/raw-loss = 0.5531670451164246, train/logprobs = tensor([[-0.4012, -1.1414],
        [-0.4099, -0.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03431062400341034
Epoch 0, Step 594: train/loss = 0.524183452129364, train/raw-loss = 0.45044243335723877, train/logprobs = tensor([[-0.6139, -6.2420],
        [-0.6931, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03687051311135292
Epoch 0, Step 595: train/loss = 0.5343738794326782, train/raw-loss = 0.44102030992507935, train/logprobs = tensor([[-0.6994, -2.1167],
        [-0.8771, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04667679965496063
Epoch 0, Step 596: train/loss = 0.5864413380622864, train/raw-loss = 0.5015511512756348, train/logprobs = tensor([[-0.6287, -1.4074],
        [-0.7063, -0.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04244507476687431
Epoch 0, Step 597: train/loss = 0.42539921402931213, train/raw-loss = 0.3324452340602875, train/logprobs = tensor([[-0.7315, -3.1755],
        [-0.9302, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046476997435092926
Epoch 0, Step 598: train/loss = 0.5817365050315857, train/raw-loss = 0.5003712177276611, train/logprobs = tensor([[-0.4488, -1.9885],
        [-0.4641, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04068264737725258
Epoch 0, Step 599: train/loss = 0.573749303817749, train/raw-loss = 0.48864567279815674, train/logprobs = tensor([[-0.5204, -1.7884],
        [-0.6323, -0.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042551830410957336
Epoch 0, Step 600: train/loss = 0.5352868437767029, train/raw-loss = 0.44406136870384216, train/logprobs = tensor([[-0.7061, -2.1151],
        [-0.7930, -0.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04561273753643036
Epoch 0, Step 601: train/loss = 0.6599491238594055, train/raw-loss = 0.5648525953292847, train/logprobs = tensor([[-0.7677, -1.2052],
        [-0.7419, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04754825681447983
Epoch 0, Step 602: train/loss = 0.46868470311164856, train/raw-loss = 0.3876398801803589, train/logprobs = tensor([[-0.5560, -2.4464],
        [-0.6283, -0.4870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04052241891622543
Epoch 0, Step 603: train/loss = 0.6111047267913818, train/raw-loss = 0.5342516899108887, train/logprobs = tensor([[-0.7005, -1.0033],
        [-0.8599, -0.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038426514714956284
Epoch 0, Step 604: train/loss = 0.5331470966339111, train/raw-loss = 0.43981099128723145, train/logprobs = tensor([[-0.5595, -2.4325],
        [-0.5425, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04666806384921074
Epoch 0, Step 605: train/loss = 0.5510903596878052, train/raw-loss = 0.46173280477523804, train/logprobs = tensor([[-0.5677, -1.8873],
        [-0.6167, -0.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04467877745628357
Epoch 0, Step 606: train/loss = 0.6608027815818787, train/raw-loss = 0.5882710814476013, train/logprobs = tensor([[-0.6443, -1.0173],
        [-0.5647, -0.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03626586124300957
Epoch 0, Step 607: train/loss = 0.44055408239364624, train/raw-loss = 0.35750508308410645, train/logprobs = tensor([[-0.4414, -4.0234],
        [-0.4939, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0415244922041893
Epoch 0, Step 608: train/loss = 0.9435837268829346, train/raw-loss = 0.8679571747779846, train/logprobs = tensor([[-1.8325, -2.1161],
        [-0.5535, -0.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037813249975442886
Epoch 0, Step 609: train/loss = 0.49130091071128845, train/raw-loss = 0.39963212609291077, train/logprobs = tensor([[-0.6200, -4.1483],
        [-0.7282, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04583439603447914
Epoch 0, Step 610: train/loss = 0.5251062512397766, train/raw-loss = 0.42937177419662476, train/logprobs = tensor([[-0.7262, -3.1398],
        [-0.6914, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047867223620414734
Epoch 0, Step 611: train/loss = 0.5532448291778564, train/raw-loss = 0.4654184877872467, train/logprobs = tensor([[-0.6441, -2.0092],
        [-0.6774, -0.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04391317814588547
Epoch 0, Step 612: train/loss = 0.6905456781387329, train/raw-loss = 0.6332837343215942, train/logprobs = tensor([[-0.5280, -0.6733],
        [-0.5092, -0.3938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028630971908569336
Epoch 0, Step 613: train/loss = 0.4576806426048279, train/raw-loss = 0.36853519082069397, train/logprobs = tensor([[-0.6148, -3.7948],
        [-0.7982, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04457271844148636
Epoch 0, Step 614: train/loss = 0.6269826292991638, train/raw-loss = 0.5583796501159668, train/logprobs = tensor([[-0.6183, -1.0314],
        [-0.7696, -0.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034301478415727615
Epoch 0, Step 615: train/loss = 0.5616668462753296, train/raw-loss = 0.48686835169792175, train/logprobs = tensor([[-0.3132, -2.1284],
        [-0.3862, -0.5157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037399254739284515
Epoch 0, Step 616: train/loss = 0.5640310049057007, train/raw-loss = 0.47806310653686523, train/logprobs = tensor([[-0.8898, -2.4462],
        [-0.7690, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04298395663499832
Epoch 0, Step 617: train/loss = 0.5882626175880432, train/raw-loss = 0.5086877346038818, train/logprobs = tensor([[-0.8147, -1.8547],
        [-0.7505, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03978746011853218
Epoch 0, Step 618: train/loss = 0.416898250579834, train/raw-loss = 0.33347851037979126, train/logprobs = tensor([[-0.5370, -2.8255],
        [-0.6984, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041709866374731064
Epoch 0, Step 619: train/loss = 0.6404088735580444, train/raw-loss = 0.5607019662857056, train/logprobs = tensor([[-0.5335, -1.0393],
        [-0.5207, -0.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03985344246029854
Epoch 0, Step 620: train/loss = 0.6024171113967896, train/raw-loss = 0.5308419466018677, train/logprobs = tensor([[-0.6693, -2.5751],
        [-0.5059, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03578758239746094
Epoch 0, Step 621: train/loss = 0.6412341594696045, train/raw-loss = 0.5609655976295471, train/logprobs = tensor([[-0.8337, -1.0272],
        [-0.8713, -0.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04013429582118988
Epoch 0, Step 622: train/loss = 0.5866754055023193, train/raw-loss = 0.5188986659049988, train/logprobs = tensor([[-0.6319, -1.8691],
        [-0.5279, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03388838842511177
Epoch 0, Step 623: train/loss = 0.4806247055530548, train/raw-loss = 0.39665547013282776, train/logprobs = tensor([[-0.4618, -3.7527],
        [-0.4941, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041984621435403824
Epoch 0, Step 624: train/loss = 0.7346103191375732, train/raw-loss = 0.6695683598518372, train/logprobs = tensor([[-0.6947, -0.8158],
        [-0.4691, -0.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03252096846699715
Epoch 0, Step 625: train/loss = 0.6584922671318054, train/raw-loss = 0.5854386687278748, train/logprobs = tensor([[-0.6673, -1.2115],
        [-0.6746, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036526795476675034
Epoch 0, Step 626: train/loss = 0.6863604187965393, train/raw-loss = 0.5987741947174072, train/logprobs = tensor([[-1.2267, -2.2369],
        [-0.6928, -0.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04379313066601753
Epoch 0, Step 627: train/loss = 0.51231849193573, train/raw-loss = 0.41916531324386597, train/logprobs = tensor([[-0.6963, -3.2208],
        [-0.6893, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657658189535141
Epoch 0, Step 628: train/loss = 0.5518190860748291, train/raw-loss = 0.46714913845062256, train/logprobs = tensor([[-0.6857, -2.0024],
        [-0.7277, -0.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04233495891094208
Epoch 0, Step 629: train/loss = 0.649047315120697, train/raw-loss = 0.5771559476852417, train/logprobs = tensor([[-0.4576, -1.5692],
        [-0.4075, -0.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035945698618888855
Epoch 0, Step 630: train/loss = 0.5939310789108276, train/raw-loss = 0.5234165191650391, train/logprobs = tensor([[-0.5111, -1.9568],
        [-0.5436, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03525729849934578
Epoch 0, Step 631: train/loss = 0.4731053113937378, train/raw-loss = 0.38005781173706055, train/logprobs = tensor([[-0.7209, -3.1653],
        [-0.9191, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04652374982833862
Epoch 0, Step 632: train/loss = 0.5575665831565857, train/raw-loss = 0.46488285064697266, train/logprobs = tensor([[-0.6793, -4.2352],
        [-0.9480, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04634186252951622
Epoch 0, Step 633: train/loss = 0.5404714345932007, train/raw-loss = 0.4631890654563904, train/logprobs = tensor([[-0.6548, -1.9554],
        [-0.7712, -0.6447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03864118456840515
Epoch 0, Step 634: train/loss = 0.6419941186904907, train/raw-loss = 0.5714260935783386, train/logprobs = tensor([[-0.5001, -1.8831],
        [-0.5009, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03528401255607605
Epoch 0, Step 635: train/loss = 0.6019162535667419, train/raw-loss = 0.5317865610122681, train/logprobs = tensor([[-0.5676, -1.5423],
        [-0.4662, -0.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03506484627723694
Epoch 0, Step 636: train/loss = 0.672675371170044, train/raw-loss = 0.6067495942115784, train/logprobs = tensor([[-2.5157, -5.1890],
        [-1.6467, -2.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03296290710568428
Epoch 0, Step 637: train/loss = 0.55741286277771, train/raw-loss = 0.4831344783306122, train/logprobs = tensor([[-0.5123, -1.5443],
        [-0.6185, -0.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03713921830058098
Epoch 0, Step 638: train/loss = 0.7282047867774963, train/raw-loss = 0.6594024896621704, train/logprobs = tensor([[-0.7573, -0.7141],
        [-0.6835, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034401148557662964
Epoch 0, Step 639: train/loss = 0.5779238939285278, train/raw-loss = 0.46896499395370483, train/logprobs = tensor([[-0.7573, -1.7414],
        [-0.9068, -0.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05447947233915329
Epoch 0, Step 640: train/loss = 0.4876159429550171, train/raw-loss = 0.41770485043525696, train/logprobs = tensor([[-0.5056, -2.2634],
        [-0.5681, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034955546259880066
Epoch 0, Step 641: train/loss = 0.46260425448417664, train/raw-loss = 0.37713780999183655, train/logprobs = tensor([[-0.4819, -3.3150],
        [-0.5167, -0.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04273323342204094
Epoch 0, Step 642: train/loss = 0.6079827547073364, train/raw-loss = 0.5432259440422058, train/logprobs = tensor([[-0.4337, -1.6872],
        [-0.4645, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03237838298082352
Epoch 0, Step 643: train/loss = 0.5825576782226562, train/raw-loss = 0.5022475123405457, train/logprobs = tensor([[-0.7452, -1.5899],
        [-0.7361, -0.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040155090391635895
Epoch 0, Step 644: train/loss = 0.516349196434021, train/raw-loss = 0.43557101488113403, train/logprobs = tensor([[-0.7417, -2.3503],
        [-0.8389, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040389079600572586
Epoch 0, Step 645: train/loss = 0.4346170723438263, train/raw-loss = 0.3538726270198822, train/logprobs = tensor([[-0.5773, -5.7939],
        [-0.6590, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04037223011255264
Epoch 0, Step 646: train/loss = 0.5656271576881409, train/raw-loss = 0.48382073640823364, train/logprobs = tensor([[-0.5525, -1.5495],
        [-0.6855, -0.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040903206914663315
Epoch 0, Step 647: train/loss = 0.5587971806526184, train/raw-loss = 0.46888917684555054, train/logprobs = tensor([[-0.6319, -1.7986],
        [-0.7543, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04495400935411453
Epoch 0, Step 648: train/loss = 0.5746790766716003, train/raw-loss = 0.4997950792312622, train/logprobs = tensor([[-0.5560, -1.7238],
        [-0.5872, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03744199872016907
Epoch 0, Step 649: train/loss = 0.47115358710289, train/raw-loss = 0.3816659152507782, train/logprobs = tensor([[-0.6326, -2.4063],
        [-0.8694, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04474383220076561
Epoch 0, Step 650: train/loss = 0.5506338477134705, train/raw-loss = 0.47806453704833984, train/logprobs = tensor([[-0.5592, -1.8004],
        [-0.6658, -0.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0362846665084362
Epoch 0, Step 651: train/loss = 0.561321496963501, train/raw-loss = 0.5018144845962524, train/logprobs = tensor([[-0.4670, -2.5623],
        [-0.5220, -0.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02975350245833397
Epoch 0, Step 652: train/loss = 0.45890045166015625, train/raw-loss = 0.37126949429512024, train/logprobs = tensor([[-0.4436, -3.2837],
        [-0.5477, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0438154898583889
Epoch 0, Step 653: train/loss = 0.46057185530662537, train/raw-loss = 0.3886070251464844, train/logprobs = tensor([[-0.4582, -3.0016],
        [-0.5119, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0359824076294899
Epoch 0, Step 654: train/loss = 0.5971276760101318, train/raw-loss = 0.519676923751831, train/logprobs = tensor([[-0.5937, -1.8161],
        [-0.4747, -0.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038725346326828
Epoch 0, Step 655: train/loss = 0.528080940246582, train/raw-loss = 0.45020315051078796, train/logprobs = tensor([[-0.8143, -4.7776],
        [-0.8598, -1.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893890976905823
Epoch 0, Step 656: train/loss = 0.6337892413139343, train/raw-loss = 0.5660547018051147, train/logprobs = tensor([[-0.7474, -1.8103],
        [-0.6162, -0.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386726230382919
Epoch 0, Step 657: train/loss = 0.6021043062210083, train/raw-loss = 0.5155166387557983, train/logprobs = tensor([[-0.6910, -2.1000],
        [-0.6900, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04329385235905647
Epoch 0, Step 658: train/loss = 0.5966711044311523, train/raw-loss = 0.5162172913551331, train/logprobs = tensor([[-0.5706, -2.5543],
        [-0.6191, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04022692143917084
Epoch 0, Step 659: train/loss = 0.5894099473953247, train/raw-loss = 0.523321807384491, train/logprobs = tensor([[-0.7697, -3.3354],
        [-0.4529, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03304407745599747
Epoch 0, Step 660: train/loss = 0.6138071417808533, train/raw-loss = 0.5394285917282104, train/logprobs = tensor([[-0.8671, -2.2809],
        [-0.7730, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03718927130103111
Epoch 0, Step 661: train/loss = 0.49427419900894165, train/raw-loss = 0.42665183544158936, train/logprobs = tensor([[-0.6147, -5.4031],
        [-0.5160, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033811189234256744
Epoch 0, Step 662: train/loss = 0.5317241549491882, train/raw-loss = 0.46569550037384033, train/logprobs = tensor([[-0.6428, -3.7524],
        [-0.8496, -0.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03301432728767395
Epoch 0, Step 663: train/loss = 0.513985812664032, train/raw-loss = 0.4184380769729614, train/logprobs = tensor([[-0.5391, -3.1580],
        [-0.5845, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04777384549379349
Epoch 0, Step 664: train/loss = 0.6841386556625366, train/raw-loss = 0.6101654767990112, train/logprobs = tensor([[-1.4349, -3.4783],
        [-0.7296, -0.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036986589431762695
Epoch 0, Step 665: train/loss = 0.573398768901825, train/raw-loss = 0.4910975992679596, train/logprobs = tensor([[-0.6784, -1.8335],
        [-0.7073, -0.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04115057364106178
Epoch 0, Step 666: train/loss = 0.643113911151886, train/raw-loss = 0.5549591779708862, train/logprobs = tensor([[-0.9903, -2.8893],
        [-0.5371, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04407733678817749
Epoch 0, Step 667: train/loss = 0.6053380370140076, train/raw-loss = 0.528593897819519, train/logprobs = tensor([[-0.4971, -1.2666],
        [-0.6008, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03837207332253456
Epoch 0, Step 668: train/loss = 0.6702374219894409, train/raw-loss = 0.5808662176132202, train/logprobs = tensor([[-0.9737, -1.8985],
        [-0.5979, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04468560591340065
Epoch 0, Step 669: train/loss = 0.6611117124557495, train/raw-loss = 0.5830051898956299, train/logprobs = tensor([[-0.6096, -0.9218],
        [-0.6384, -0.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039053287357091904
Epoch 0, Step 670: train/loss = 0.5230293273925781, train/raw-loss = 0.44515490531921387, train/logprobs = tensor([[-0.6058, -4.3753],
        [-0.6570, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893718868494034
Epoch 0, Step 671: train/loss = 0.5794652104377747, train/raw-loss = 0.5096679925918579, train/logprobs = tensor([[-0.4794, -1.7023],
        [-0.5414, -0.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03489862382411957
Epoch 0, Step 672: train/loss = 0.515378475189209, train/raw-loss = 0.43743911385536194, train/logprobs = tensor([[-0.6337, -5.0407],
        [-0.7303, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038969654589891434
Epoch 0, Step 673: train/loss = 0.5811374187469482, train/raw-loss = 0.5040098428726196, train/logprobs = tensor([[-0.5542, -2.4866],
        [-0.5751, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0385638102889061
Epoch 0, Step 674: train/loss = 0.46462851762771606, train/raw-loss = 0.3831760883331299, train/logprobs = tensor([[-0.8554, -2.3018],
        [-1.2090, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040726207196712494
Epoch 0, Step 675: train/loss = 0.6385021209716797, train/raw-loss = 0.5734273791313171, train/logprobs = tensor([[-0.5682, -1.2458],
        [-0.5609, -0.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032537393271923065
Epoch 0, Step 676: train/loss = 0.5389930009841919, train/raw-loss = 0.47329849004745483, train/logprobs = tensor([[-0.5606, -2.6183],
        [-0.6200, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03284725174307823
Epoch 0, Step 677: train/loss = 0.6164773106575012, train/raw-loss = 0.5583008527755737, train/logprobs = tensor([[-0.3760, -1.2026],
        [-0.4763, -0.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02908821403980255
Epoch 0, Step 678: train/loss = 0.43683546781539917, train/raw-loss = 0.3510863184928894, train/logprobs = tensor([[-0.5914, -3.5290],
        [-0.8149, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04287457838654518
Epoch 0, Step 679: train/loss = 0.5972270369529724, train/raw-loss = 0.5123746991157532, train/logprobs = tensor([[-0.9483, -1.9620],
        [-0.6484, -0.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04242616519331932
Epoch 0, Step 680: train/loss = 0.5490819215774536, train/raw-loss = 0.4700733721256256, train/logprobs = tensor([[-0.5313, -1.8924],
        [-0.5428, -0.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0395042821764946
Epoch 0, Step 681: train/loss = 0.5526144504547119, train/raw-loss = 0.4716354012489319, train/logprobs = tensor([[-0.7973, -5.0158],
        [-0.6450, -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04048949107527733
Epoch 0, Step 682: train/loss = 0.5308120250701904, train/raw-loss = 0.4309491515159607, train/logprobs = tensor([[-0.8072, -5.1027],
        [-0.8896, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049931421875953674
Epoch 0, Step 683: train/loss = 0.49604806303977966, train/raw-loss = 0.400726318359375, train/logprobs = tensor([[-0.5326, -3.9437],
        [-0.6211, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04766086861491203
Epoch 0, Step 684: train/loss = 0.5088521242141724, train/raw-loss = 0.4263121485710144, train/logprobs = tensor([[-0.4953, -3.5222],
        [-0.3809, -0.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041269998997449875
Epoch 0, Step 685: train/loss = 0.6809254288673401, train/raw-loss = 0.6027728319168091, train/logprobs = tensor([[-1.0368, -1.4319],
        [-0.7403, -0.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03907627612352371
Epoch 0, Step 686: train/loss = 0.6082554459571838, train/raw-loss = 0.5359867811203003, train/logprobs = tensor([[-0.5324, -1.4579],
        [-0.6268, -0.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03613435477018356
Epoch 0, Step 687: train/loss = 0.5178516507148743, train/raw-loss = 0.44294875860214233, train/logprobs = tensor([[-0.8583, -4.1545],
        [-0.6949, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037451453506946564
Epoch 0, Step 688: train/loss = 0.5921353101730347, train/raw-loss = 0.5116704702377319, train/logprobs = tensor([[-0.5661, -1.3799],
        [-0.6740, -0.4795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040232427418231964
Epoch 0, Step 689: train/loss = 0.6243771314620972, train/raw-loss = 0.545208215713501, train/logprobs = tensor([[-0.6037, -1.4040],
        [-0.5438, -0.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0395844392478466
Epoch 0, Step 690: train/loss = 0.5106182098388672, train/raw-loss = 0.41362202167510986, train/logprobs = tensor([[-0.7370, -1.9215],
        [-0.8408, -0.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04849807918071747
Epoch 0, Step 691: train/loss = 0.6683216691017151, train/raw-loss = 0.5870941877365112, train/logprobs = tensor([[-0.5900, -1.1336],
        [-0.5768, -0.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040613751858472824
Epoch 0, Step 692: train/loss = 0.5327243804931641, train/raw-loss = 0.4574412405490875, train/logprobs = tensor([[-0.5620, -2.3846],
        [-0.5501, -0.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03764156252145767
Epoch 0, Step 693: train/loss = 0.4727543294429779, train/raw-loss = 0.39282500743865967, train/logprobs = tensor([[-0.4548, -3.4247],
        [-0.5589, -0.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03996466472744942
Epoch 0, Step 694: train/loss = 0.5716385841369629, train/raw-loss = 0.4971710443496704, train/logprobs = tensor([[-0.6008, -1.8003],
        [-0.6085, -0.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037233784794807434
Epoch 0, Step 695: train/loss = 0.621286928653717, train/raw-loss = 0.572356104850769, train/logprobs = tensor([[-0.4873, -2.1391],
        [-0.4942, -0.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024465400725603104
Epoch 0, Step 696: train/loss = 0.5675254464149475, train/raw-loss = 0.4877638816833496, train/logprobs = tensor([[-0.7271, -2.3878],
        [-0.7893, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03988078236579895
Epoch 0, Step 697: train/loss = 0.5900875329971313, train/raw-loss = 0.5204747319221497, train/logprobs = tensor([[-0.5288, -1.7941],
        [-0.5294, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03480641916394234
Epoch 0, Step 698: train/loss = 0.5385292172431946, train/raw-loss = 0.4604704976081848, train/logprobs = tensor([[-0.7324, -3.3394],
        [-0.7406, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03902936354279518
Epoch 0, Step 699: train/loss = 0.5178217887878418, train/raw-loss = 0.4393159747123718, train/logprobs = tensor([[-0.7256, -2.0165],
        [-0.8194, -0.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925289213657379
Epoch 0, Step 700: train/loss = 0.538136899471283, train/raw-loss = 0.4651515483856201, train/logprobs = tensor([[-0.7550, -3.8556],
        [-0.6120, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036492664366960526
Epoch 0, Step 701: train/loss = 0.5806143283843994, train/raw-loss = 0.4818722903728485, train/logprobs = tensor([[-1.3284, -2.9559],
        [-0.8428, -0.6630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04937101900577545
Epoch 0, Step 702: train/loss = 0.5381128787994385, train/raw-loss = 0.43964022397994995, train/logprobs = tensor([[-0.6681, -2.9620],
        [-0.7839, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049236319959163666
Epoch 0, Step 703: train/loss = 0.5738646984100342, train/raw-loss = 0.5071734189987183, train/logprobs = tensor([[-0.5623, -1.8441],
        [-0.5503, -0.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03334563970565796
Epoch 0, Step 704: train/loss = 0.4594016671180725, train/raw-loss = 0.37432223558425903, train/logprobs = tensor([[-0.5888, -5.3897],
        [-0.6270, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04253970831632614
Epoch 0, Step 705: train/loss = 0.4392666220664978, train/raw-loss = 0.35270997881889343, train/logprobs = tensor([[-0.7306, -3.2254],
        [-0.9285, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04327833279967308
Epoch 0, Step 706: train/loss = 0.45752960443496704, train/raw-loss = 0.36522912979125977, train/logprobs = tensor([[-0.8668, -3.4218],
        [-1.0552, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04615021497011185
Epoch 0, Step 707: train/loss = 0.4692397713661194, train/raw-loss = 0.38672301173210144, train/logprobs = tensor([[-0.6287, -3.1387],
        [-0.6606, -0.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04125839099287987
Epoch 0, Step 708: train/loss = 0.4467453360557556, train/raw-loss = 0.3630857765674591, train/logprobs = tensor([[-0.6719, -3.3667],
        [-0.9630, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04182978719472885
Epoch 0, Step 709: train/loss = 0.6707777380943298, train/raw-loss = 0.6037266254425049, train/logprobs = tensor([[-0.9652, -1.9047],
        [-0.8692, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033525533974170685
Epoch 0, Step 710: train/loss = 0.6131373643875122, train/raw-loss = 0.546307384967804, train/logprobs = tensor([[-0.3314, -1.3730],
        [-0.3637, -0.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033414971083402634
Epoch 0, Step 711: train/loss = 0.5617378354072571, train/raw-loss = 0.48514726758003235, train/logprobs = tensor([[-0.6012, -2.0429],
        [-0.5683, -0.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03829527646303177
Epoch 0, Step 712: train/loss = 0.679847240447998, train/raw-loss = 0.6026848554611206, train/logprobs = tensor([[-0.5011, -0.9177],
        [-0.4920, -0.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03858121111989021
Epoch 0, Step 713: train/loss = 0.6170576810836792, train/raw-loss = 0.542464554309845, train/logprobs = tensor([[-0.6354, -1.7064],
        [-0.5121, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03729655593633652
Epoch 0, Step 714: train/loss = 0.7863020300865173, train/raw-loss = 0.7122433185577393, train/logprobs = tensor([[-1.3223, -1.7954],
        [-0.5517, -0.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03702933341264725
Epoch 0, Step 715: train/loss = 0.6189016103744507, train/raw-loss = 0.5524202585220337, train/logprobs = tensor([[-0.4268, -1.2003],
        [-0.4957, -0.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033240675926208496
Epoch 0, Step 716: train/loss = 0.4955002963542938, train/raw-loss = 0.41697463393211365, train/logprobs = tensor([[-0.5854, -2.3069],
        [-0.7329, -0.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03926282376050949
Epoch 0, Step 717: train/loss = 0.568065345287323, train/raw-loss = 0.47809693217277527, train/logprobs = tensor([[-0.8261, -3.9617],
        [-0.7390, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04498419538140297
Epoch 0, Step 718: train/loss = 0.5678356289863586, train/raw-loss = 0.5079058408737183, train/logprobs = tensor([[-0.5732, -1.3925],
        [-0.6180, -0.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029964903369545937
Epoch 0, Step 719: train/loss = 0.47241348028182983, train/raw-loss = 0.38671940565109253, train/logprobs = tensor([[-0.7486, -3.9480],
        [-0.5817, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04284703731536865
Epoch 0, Step 720: train/loss = 0.5654239058494568, train/raw-loss = 0.49188971519470215, train/logprobs = tensor([[-0.5265, -1.7617],
        [-0.5238, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03676708787679672
Epoch 0, Step 721: train/loss = 0.6296550631523132, train/raw-loss = 0.5706255435943604, train/logprobs = tensor([[-0.5243, -1.1620],
        [-0.5177, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029514767229557037
Epoch 0, Step 722: train/loss = 0.5104686617851257, train/raw-loss = 0.41837623715400696, train/logprobs = tensor([[-0.6223, -3.3365],
        [-0.6575, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04604622349143028
Epoch 0, Step 723: train/loss = 0.4830119013786316, train/raw-loss = 0.4058327078819275, train/logprobs = tensor([[-0.8626, -3.2178],
        [-0.9271, -0.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03858957439661026
Epoch 0, Step 724: train/loss = 0.5651549100875854, train/raw-loss = 0.48790714144706726, train/logprobs = tensor([[-0.6102, -2.0340],
        [-0.6611, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0386238768696785
Epoch 0, Step 725: train/loss = 0.5183717012405396, train/raw-loss = 0.4404325783252716, train/logprobs = tensor([[-0.5815, -2.3069],
        [-0.7422, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038969557732343674
Epoch 0, Step 726: train/loss = 0.4905155897140503, train/raw-loss = 0.4174402356147766, train/logprobs = tensor([[-0.4289, -2.7326],
        [-0.4615, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03653767704963684
Epoch 0, Step 727: train/loss = 0.6491902470588684, train/raw-loss = 0.5854360461235046, train/logprobs = tensor([[-0.4330, -0.9037],
        [-0.4680, -0.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03187709301710129
Epoch 0, Step 728: train/loss = 0.540507972240448, train/raw-loss = 0.46369993686676025, train/logprobs = tensor([[-0.6471, -2.1864],
        [-0.6417, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03840402141213417
Epoch 0, Step 729: train/loss = 0.5097275376319885, train/raw-loss = 0.4231429398059845, train/logprobs = tensor([[-0.6456, -2.1746],
        [-0.7300, -0.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04329230636358261
Epoch 0, Step 730: train/loss = 0.6480448246002197, train/raw-loss = 0.5653698444366455, train/logprobs = tensor([[-0.8457, -1.4179],
        [-0.7358, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041337475180625916
Epoch 0, Step 731: train/loss = 0.4732615649700165, train/raw-loss = 0.3900580108165741, train/logprobs = tensor([[-0.7108, -5.9877],
        [-0.6945, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04160177707672119
Epoch 0, Step 732: train/loss = 0.5558007955551147, train/raw-loss = 0.4894963204860687, train/logprobs = tensor([[-0.4286, -2.2534],
        [-0.4844, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033152252435684204
Epoch 0, Step 733: train/loss = 0.5424607396125793, train/raw-loss = 0.4719008803367615, train/logprobs = tensor([[-0.4467, -2.7430],
        [-0.5547, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035279929637908936
Epoch 0, Step 734: train/loss = 0.6231642365455627, train/raw-loss = 0.5621501207351685, train/logprobs = tensor([[-0.4841, -1.2759],
        [-0.4522, -0.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030507031828165054
Epoch 0, Step 735: train/loss = 0.532151997089386, train/raw-loss = 0.45361214876174927, train/logprobs = tensor([[-0.6534, -2.7567],
        [-0.8265, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03926992788910866
Epoch 0, Step 736: train/loss = 0.4979552924633026, train/raw-loss = 0.4264463782310486, train/logprobs = tensor([[-0.7134, -3.0540],
        [-0.6310, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03575444221496582
Epoch 0, Step 737: train/loss = 0.5898655652999878, train/raw-loss = 0.530992865562439, train/logprobs = tensor([[-0.6248, -2.2843],
        [-0.4232, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02943633310496807
Epoch 0, Step 738: train/loss = 0.6229450702667236, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6827, -1.2919],
        [-0.6070, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299696743488312
Epoch 0, Step 739: train/loss = 0.597826361656189, train/raw-loss = 0.5267279744148254, train/logprobs = tensor([[-0.5046, -2.3081],
        [-0.5397, -0.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03554919362068176
Epoch 0, Step 740: train/loss = 0.7057613730430603, train/raw-loss = 0.6403412818908691, train/logprobs = tensor([[-0.6062, -0.8280],
        [-0.5012, -0.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03271007537841797
Epoch 0, Step 741: train/loss = 0.6523922681808472, train/raw-loss = 0.5861722826957703, train/logprobs = tensor([[-0.6134, -0.9993],
        [-0.5884, -0.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03310999646782875
Epoch 0, Step 742: train/loss = 0.5557481050491333, train/raw-loss = 0.4874480962753296, train/logprobs = tensor([[-0.4394, -2.0756],
        [-0.4214, -0.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03414998576045036
Epoch 0, Step 743: train/loss = 0.5074850916862488, train/raw-loss = 0.4228277802467346, train/logprobs = tensor([[-0.6502, -2.5531],
        [-0.7248, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232865571975708
Epoch 0, Step 744: train/loss = 0.6205111742019653, train/raw-loss = 0.5425757169723511, train/logprobs = tensor([[-0.6231, -1.1080],
        [-0.8499, -0.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038967736065387726
Epoch 0, Step 745: train/loss = 0.4564642906188965, train/raw-loss = 0.38268032670021057, train/logprobs = tensor([[-0.5564, -3.0082],
        [-0.6149, -0.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036891985684633255
Epoch 0, Step 746: train/loss = 0.483981728553772, train/raw-loss = 0.41316694021224976, train/logprobs = tensor([[-0.5258, -2.2513],
        [-0.5865, -0.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03540739789605141
Epoch 0, Step 747: train/loss = 0.6071099638938904, train/raw-loss = 0.5372346639633179, train/logprobs = tensor([[-0.7658, -1.5328],
        [-0.6243, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03493765741586685
Epoch 0, Step 748: train/loss = 0.4511226713657379, train/raw-loss = 0.36775651574134827, train/logprobs = tensor([[-0.9002, -6.5433],
        [-0.9909, -1.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041683077812194824
Epoch 0, Step 749: train/loss = 0.5295235514640808, train/raw-loss = 0.4342087507247925, train/logprobs = tensor([[-0.7069, -2.5468],
        [-0.7613, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04765741154551506
Epoch 0, Step 750: train/loss = 0.583854079246521, train/raw-loss = 0.504550576210022, train/logprobs = tensor([[-1.1636, -4.1095],
        [-0.8599, -1.3036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03965176269412041
Epoch 0, Step 751: train/loss = 0.5354657173156738, train/raw-loss = 0.4507918059825897, train/logprobs = tensor([[-0.7085, -1.7673],
        [-0.8372, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042336974292993546
Epoch 0, Step 752: train/loss = 0.5334185361862183, train/raw-loss = 0.47172674536705017, train/logprobs = tensor([[-0.4081, -1.8389],
        [-0.4477, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030845891684293747
Epoch 0, Step 753: train/loss = 0.5981431007385254, train/raw-loss = 0.521966814994812, train/logprobs = tensor([[-1.2394, -3.6491],
        [-0.7291, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03808816149830818
Epoch 0, Step 754: train/loss = 0.5193754434585571, train/raw-loss = 0.44744062423706055, train/logprobs = tensor([[-0.6634, -3.4748],
        [-0.7413, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0359673909842968
Epoch 0, Step 755: train/loss = 0.5197181701660156, train/raw-loss = 0.43798428773880005, train/logprobs = tensor([[-0.7728, -2.2863],
        [-0.7749, -0.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040866918861866
Epoch 0, Step 756: train/loss = 0.5982059836387634, train/raw-loss = 0.5232226252555847, train/logprobs = tensor([[-0.6621, -1.7517],
        [-0.6898, -0.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03749168664216995
Epoch 0, Step 757: train/loss = 0.6205336451530457, train/raw-loss = 0.5500857830047607, train/logprobs = tensor([[-0.7120, -1.2668],
        [-0.7076, -0.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035223908722400665
Epoch 0, Step 758: train/loss = 0.6792544722557068, train/raw-loss = 0.6105534434318542, train/logprobs = tensor([[-1.0155, -1.2169],
        [-0.8949, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034350503236055374
Epoch 0, Step 759: train/loss = 0.4672356843948364, train/raw-loss = 0.3930966854095459, train/logprobs = tensor([[-0.6605, -5.0525],
        [-0.8585, -1.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037069518119096756
Epoch 0, Step 760: train/loss = 0.6079197525978088, train/raw-loss = 0.5388492941856384, train/logprobs = tensor([[-0.6766, -1.3983],
        [-0.6839, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03453522548079491
Epoch 0, Step 761: train/loss = 0.4616655707359314, train/raw-loss = 0.3804776966571808, train/logprobs = tensor([[-0.5322, -2.8632],
        [-0.7529, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04059392958879471
Epoch 0, Step 762: train/loss = 0.6717473268508911, train/raw-loss = 0.6048405766487122, train/logprobs = tensor([[-0.6080, -0.9825],
        [-0.5558, -0.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033453378826379776
Epoch 0, Step 763: train/loss = 0.4203052222728729, train/raw-loss = 0.34467390179634094, train/logprobs = tensor([[-0.4155, -3.9239],
        [-0.4700, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03781565651297569
Epoch 0, Step 764: train/loss = 0.5626082420349121, train/raw-loss = 0.4924466609954834, train/logprobs = tensor([[-0.6401, -2.9832],
        [-0.6506, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03508080169558525
Epoch 0, Step 765: train/loss = 0.4681137800216675, train/raw-loss = 0.38055768609046936, train/logprobs = tensor([[-0.7138, -3.2616],
        [-0.8000, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043778058141469955
Epoch 0, Step 766: train/loss = 0.7197803854942322, train/raw-loss = 0.6530473232269287, train/logprobs = tensor([[-0.5258, -0.7429],
        [-0.4755, -0.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03336654603481293
Epoch 0, Step 767: train/loss = 0.4789492189884186, train/raw-loss = 0.40543150901794434, train/logprobs = tensor([[-0.7592, -7.9500],
        [-0.6649, -1.5020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03675886243581772
Epoch 0, Step 768: train/loss = 0.6112191081047058, train/raw-loss = 0.5340856909751892, train/logprobs = tensor([[-0.6990, -2.7668],
        [-0.6856, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0385667085647583
Epoch 0, Step 769: train/loss = 0.5570599436759949, train/raw-loss = 0.48467132449150085, train/logprobs = tensor([[-1.0063, -2.8956],
        [-0.7798, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036194317042827606
Epoch 0, Step 770: train/loss = 0.6018462777137756, train/raw-loss = 0.5327444076538086, train/logprobs = tensor([[-0.7007, -1.5031],
        [-0.6578, -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034550949931144714
Epoch 0, Step 771: train/loss = 0.7073870301246643, train/raw-loss = 0.6390281915664673, train/logprobs = tensor([[-1.0548, -1.0981],
        [-0.8284, -0.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034179411828517914
Epoch 0, Step 772: train/loss = 0.5284505486488342, train/raw-loss = 0.46412771940231323, train/logprobs = tensor([[-0.4023, -4.8819],
        [-0.5067, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032161422073841095
Epoch 0, Step 773: train/loss = 0.6477426886558533, train/raw-loss = 0.5680876970291138, train/logprobs = tensor([[-1.6602, -4.7450],
        [-1.1002, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039827488362789154
Epoch 0, Step 774: train/loss = 0.5471059083938599, train/raw-loss = 0.47177064418792725, train/logprobs = tensor([[-0.5432, -1.9213],
        [-0.5537, -0.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03766763210296631
Epoch 0, Step 775: train/loss = 0.4753420650959015, train/raw-loss = 0.3900270164012909, train/logprobs = tensor([[-0.6802, -3.5015],
        [-0.7824, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042657520622015
Epoch 0, Step 776: train/loss = 0.6339372992515564, train/raw-loss = 0.5672338604927063, train/logprobs = tensor([[-0.7988, -1.4927],
        [-0.7180, -0.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03335171937942505
Epoch 0, Step 777: train/loss = 0.46710658073425293, train/raw-loss = 0.3979610502719879, train/logprobs = tensor([[-0.5312, -3.5100],
        [-0.5114, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0345727764070034
Epoch 0, Step 778: train/loss = 0.674963116645813, train/raw-loss = 0.6082395315170288, train/logprobs = tensor([[-0.8146, -1.2008],
        [-0.6165, -0.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03336179256439209
Epoch 0, Step 779: train/loss = 0.6222094893455505, train/raw-loss = 0.5543222427368164, train/logprobs = tensor([[-0.5769, -1.1352],
        [-0.6326, -0.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03394360840320587
Epoch 0, Step 780: train/loss = 0.5141014456748962, train/raw-loss = 0.43833601474761963, train/logprobs = tensor([[-0.7273, -2.4443],
        [-0.8607, -0.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03788269683718681
Epoch 0, Step 781: train/loss = 0.4750407338142395, train/raw-loss = 0.4088660478591919, train/logprobs = tensor([[-0.5916, -3.8030],
        [-0.5844, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033087339252233505
Epoch 0, Step 782: train/loss = 0.5500568747520447, train/raw-loss = 0.4821076989173889, train/logprobs = tensor([[-0.4551, -2.5955],
        [-0.5559, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03397459164261818
Epoch 0, Step 783: train/loss = 0.44756507873535156, train/raw-loss = 0.3691551983356476, train/logprobs = tensor([[-0.5918, -5.6465],
        [-0.6129, -1.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039204925298690796
Epoch 0, Step 784: train/loss = 0.5493391156196594, train/raw-loss = 0.4816740155220032, train/logprobs = tensor([[-0.4738, -1.5018],
        [-0.6665, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03383255749940872
Epoch 0, Step 785: train/loss = 0.5473684072494507, train/raw-loss = 0.4906007945537567, train/logprobs = tensor([[-0.5125, -1.9274],
        [-0.5287, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028383823111653328
Epoch 0, Step 786: train/loss = 0.4493677020072937, train/raw-loss = 0.363116979598999, train/logprobs = tensor([[-0.5758, -2.8736],
        [-0.6791, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04312534257769585
Epoch 0, Step 787: train/loss = 0.4781426787376404, train/raw-loss = 0.4157191216945648, train/logprobs = tensor([[-0.4624, -3.0440],
        [-0.6066, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031211761757731438
Epoch 0, Step 788: train/loss = 0.6102849245071411, train/raw-loss = 0.521308958530426, train/logprobs = tensor([[-0.8899, -2.0390],
        [-0.9334, -0.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04448797553777695
Epoch 0, Step 789: train/loss = 0.4261164665222168, train/raw-loss = 0.3277519941329956, train/logprobs = tensor([[-0.8501, -3.1296],
        [-0.9994, -0.8187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04918220639228821
Epoch 0, Step 790: train/loss = 0.5236201882362366, train/raw-loss = 0.4666615128517151, train/logprobs = tensor([[-0.5962, -1.8809],
        [-0.5875, -0.5858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028479326516389847
Epoch 0, Step 791: train/loss = 0.613541841506958, train/raw-loss = 0.5553186535835266, train/logprobs = tensor([[-0.4790, -2.2824],
        [-0.5300, -0.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029111597687005997
Epoch 0, Step 792: train/loss = 0.4815397262573242, train/raw-loss = 0.40007293224334717, train/logprobs = tensor([[-0.5237, -2.6574],
        [-0.6474, -0.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04073340445756912
Epoch 0, Step 793: train/loss = 0.515261173248291, train/raw-loss = 0.45023882389068604, train/logprobs = tensor([[-0.4966, -4.0242],
        [-0.6438, -0.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03251117467880249
Epoch 0, Step 794: train/loss = 0.43823322653770447, train/raw-loss = 0.36975306272506714, train/logprobs = tensor([[-0.5100, -3.8322],
        [-0.6310, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03424008563160896
Epoch 0, Step 795: train/loss = 0.5859053134918213, train/raw-loss = 0.5091773271560669, train/logprobs = tensor([[-0.5755, -1.3602],
        [-0.6912, -0.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836396709084511
Epoch 0, Step 796: train/loss = 0.4236214756965637, train/raw-loss = 0.32146963477134705, train/logprobs = tensor([[-0.8716, -6.3190],
        [-0.9307, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05107593163847923
Epoch 0, Step 797: train/loss = 0.5352360010147095, train/raw-loss = 0.4734114408493042, train/logprobs = tensor([[-0.6809, -2.6800],
        [-0.5686, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030912280082702637
Epoch 0, Step 798: train/loss = 0.517734706401825, train/raw-loss = 0.4435797929763794, train/logprobs = tensor([[-0.6150, -4.9377],
        [-0.8005, -1.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03707744553685188
Epoch 0, Step 799: train/loss = 0.6506668925285339, train/raw-loss = 0.5915399789810181, train/logprobs = tensor([[-0.4437, -1.0762],
        [-0.4346, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029563458636403084
Epoch 0, Step 800: train/loss = 0.5248783230781555, train/raw-loss = 0.4535634517669678, train/logprobs = tensor([[-1.1979, -6.5264],
        [-0.8942, -1.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03565743938088417
Epoch 0, Step 801: train/loss = 0.5752713680267334, train/raw-loss = 0.4960062503814697, train/logprobs = tensor([[-0.8022, -1.9087],
        [-0.7763, -0.5448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03963257744908333
Epoch 0, Step 802: train/loss = 0.47783011198043823, train/raw-loss = 0.38338083028793335, train/logprobs = tensor([[-0.7697, -5.5549],
        [-0.8698, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047224633395671844
Epoch 0, Step 803: train/loss = 0.7308980226516724, train/raw-loss = 0.6717694401741028, train/logprobs = tensor([[-0.6359, -0.7607],
        [-0.5310, -0.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02956429496407509
Epoch 0, Step 804: train/loss = 0.5349205732345581, train/raw-loss = 0.46597224473953247, train/logprobs = tensor([[-0.6616, -2.7875],
        [-0.7010, -1.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034474194049835205
Epoch 0, Step 805: train/loss = 0.5838399529457092, train/raw-loss = 0.5143189430236816, train/logprobs = tensor([[-0.5800, -1.9385],
        [-0.4702, -0.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034760482609272
Epoch 0, Step 806: train/loss = 0.5969012975692749, train/raw-loss = 0.5200086236000061, train/logprobs = tensor([[-0.7888, -1.7452],
        [-0.7323, -0.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038446344435214996
Epoch 0, Step 807: train/loss = 0.4641267657279968, train/raw-loss = 0.39902257919311523, train/logprobs = tensor([[-0.5762, -3.2554],
        [-0.6623, -0.6880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03255211189389229
Epoch 0, Step 808: train/loss = 0.5529553294181824, train/raw-loss = 0.48614439368247986, train/logprobs = tensor([[-0.6605, -1.9782],
        [-0.6660, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033405475318431854
Epoch 0, Step 809: train/loss = 0.7225741744041443, train/raw-loss = 0.6498183012008667, train/logprobs = tensor([[-0.9554, -1.2967],
        [-0.6518, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0363779217004776
Epoch 0, Step 810: train/loss = 0.4728512763977051, train/raw-loss = 0.39377152919769287, train/logprobs = tensor([[-0.9951, -3.7607],
        [-0.8888, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039539873600006104
Epoch 0, Step 811: train/loss = 0.5554025173187256, train/raw-loss = 0.48108622431755066, train/logprobs = tensor([[-0.6750, -1.9752],
        [-0.7116, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037158139050006866
Epoch 0, Step 812: train/loss = 0.5438326001167297, train/raw-loss = 0.4745984673500061, train/logprobs = tensor([[-0.5639, -2.0242],
        [-0.5274, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03461705893278122
Epoch 0, Step 813: train/loss = 0.5060508251190186, train/raw-loss = 0.4379221498966217, train/logprobs = tensor([[-0.5590, -2.0714],
        [-0.6064, -0.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03406430408358574
Epoch 0, Step 814: train/loss = 0.5035232305526733, train/raw-loss = 0.42868316173553467, train/logprobs = tensor([[-0.7644, -5.1016],
        [-0.7387, -1.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03742004185914993
Epoch 0, Step 815: train/loss = 0.5084420442581177, train/raw-loss = 0.44750043749809265, train/logprobs = tensor([[-0.5488, -3.7735],
        [-0.5187, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030470816418528557
Epoch 0, Step 816: train/loss = 0.6887897253036499, train/raw-loss = 0.6198713779449463, train/logprobs = tensor([[-1.1229, -1.6725],
        [-0.7204, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03445917367935181
Epoch 0, Step 817: train/loss = 0.6668645739555359, train/raw-loss = 0.6015305519104004, train/logprobs = tensor([[-0.8842, -1.2997],
        [-0.6370, -0.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032667018473148346
Epoch 0, Step 818: train/loss = 0.5003191828727722, train/raw-loss = 0.43371817469596863, train/logprobs = tensor([[-0.5378, -1.9749],
        [-0.6339, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03330051526427269
Epoch 0, Step 819: train/loss = 0.5563147664070129, train/raw-loss = 0.4899364411830902, train/logprobs = tensor([[-0.5650, -1.7011],
        [-0.5716, -0.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033189162611961365
Epoch 0, Step 820: train/loss = 0.5076890587806702, train/raw-loss = 0.43344277143478394, train/logprobs = tensor([[-0.6621, -2.8078],
        [-0.7631, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037123143672943115
Epoch 0, Step 821: train/loss = 0.5823670625686646, train/raw-loss = 0.5250470638275146, train/logprobs = tensor([[-0.5279, -4.3633],
        [-0.5480, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02866000309586525
Epoch 0, Step 822: train/loss = 0.5570940971374512, train/raw-loss = 0.48616859316825867, train/logprobs = tensor([[-0.7149, -1.9511],
        [-0.7250, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035462770611047745
Epoch 0, Step 823: train/loss = 0.3875124454498291, train/raw-loss = 0.3143988251686096, train/logprobs = tensor([[-0.5363, -8.8611],
        [-0.6884, -1.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03655678778886795
Epoch 0, Step 824: train/loss = 0.5179046392440796, train/raw-loss = 0.4436640739440918, train/logprobs = tensor([[-0.5978, -1.5776],
        [-0.7087, -0.4202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0371202677488327
Epoch 0, Step 825: train/loss = 0.5691196322441101, train/raw-loss = 0.49512699246406555, train/logprobs = tensor([[-0.6777, -2.1857],
        [-0.6783, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03699631616473198
Epoch 0, Step 826: train/loss = 0.5703810453414917, train/raw-loss = 0.5077905058860779, train/logprobs = tensor([[-0.4506, -1.5697],
        [-0.5002, -0.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03129526227712631
Epoch 0, Step 827: train/loss = 0.5994825959205627, train/raw-loss = 0.5050497055053711, train/logprobs = tensor([[-0.8020, -1.6878],
        [-0.6630, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047216445207595825
