[2024-03-09 12:38:41,747][root][INFO] - beta: 0.1
[2024-03-09 12:38:41,747][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 6250
n harmless: 6250
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.'}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
25000
tokenized 25000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-1.
Epoch 0, Step 0: train/loss = 0.6357318162918091, train/raw-loss = 0.6357318162918091, train/logprobs = tensor([[-0.4308, -1.3535],
        [-0.5107, -1.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6757681369781494, train/raw-loss = 0.6757681369781494, train/logprobs = tensor([[-0.6583, -1.0265],
        [-0.6770, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6733909845352173, train/raw-loss = 0.6733909845352173, train/logprobs = tensor([[-0.5174, -0.7039],
        [-0.5662, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6216553449630737, train/raw-loss = 0.6216553449630737, train/logprobs = tensor([[-0.5512, -1.5712],
        [-0.6259, -1.3220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6579127311706543, train/raw-loss = 0.6579127311706543, train/logprobs = tensor([[-0.4046, -1.1550],
        [-0.4271, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.683114767074585, train/raw-loss = 0.683114767074585, train/logprobs = tensor([[-0.4908, -0.8480],
        [-0.5737, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6553336977958679, train/raw-loss = 0.6553336977958679, train/logprobs = tensor([[-0.6499, -0.7840],
        [-0.8093, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6633836627006531, train/raw-loss = 0.6633836627006531, train/logprobs = tensor([[-0.5876, -0.8497],
        [-0.6472, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6661855578422546, train/raw-loss = 0.6661855578422546, train/logprobs = tensor([[-0.3025, -0.9421],
        [-0.3159, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6862294673919678, train/raw-loss = 0.6862294673919678, train/logprobs = tensor([[-0.5552, -0.7072],
        [-0.6376, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6571922302246094, train/raw-loss = 0.6571922302246094, train/logprobs = tensor([[-0.4351, -0.5668],
        [-0.4920, -0.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6538093686103821, train/raw-loss = 0.6538093686103821, train/logprobs = tensor([[-0.5047, -0.8503],
        [-0.5750, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6388410329818726, train/raw-loss = 0.6388410329818726, train/logprobs = tensor([[-0.5834, -1.0723],
        [-0.7193, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.636123776435852, train/raw-loss = 0.636123776435852, train/logprobs = tensor([[-0.6079, -1.3208],
        [-0.7000, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6403026580810547, train/raw-loss = 0.6403026580810547, train/logprobs = tensor([[-0.6212, -0.9649],
        [-0.7200, -0.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6592469811439514, train/raw-loss = 0.6592469811439514, train/logprobs = tensor([[-0.5807, -0.6984],
        [-0.6892, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6758623123168945, train/raw-loss = 0.6758623123168945, train/logprobs = tensor([[-0.5074, -0.5042],
        [-0.5619, -0.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6258509159088135, train/raw-loss = 0.6258509159088135, train/logprobs = tensor([[-0.5446, -1.1194],
        [-0.6294, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.67125004529953, train/raw-loss = 0.67125004529953, train/logprobs = tensor([[-0.7139, -0.7245],
        [-0.8016, -0.7202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6720938682556152, train/raw-loss = 0.6720938682556152, train/logprobs = tensor([[-0.6830, -0.8781],
        [-0.7904, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.5842540264129639, train/raw-loss = 0.5842540264129639, train/logprobs = tensor([[-0.5470, -2.0438],
        [-0.6152, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6704121828079224, train/raw-loss = 0.6704121828079224, train/logprobs = tensor([[-0.4731, -0.6958],
        [-0.5028, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6538590788841248, train/raw-loss = 0.6538590788841248, train/logprobs = tensor([[-0.5006, -1.2025],
        [-0.5373, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.5953183174133301, train/raw-loss = 0.5953183174133301, train/logprobs = tensor([[-0.6232, -2.0455],
        [-0.7372, -1.6707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6878432631492615, train/raw-loss = 0.6878432631492615, train/logprobs = tensor([[-0.4281, -0.5477],
        [-0.4747, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6707193851470947, train/raw-loss = 0.6707193851470947, train/logprobs = tensor([[-0.6576, -1.0605],
        [-0.7231, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6479334831237793, train/raw-loss = 0.6479334831237793, train/logprobs = tensor([[-0.4684, -0.8287],
        [-0.5051, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6747323274612427, train/raw-loss = 0.6747323274612427, train/logprobs = tensor([[-0.6166, -0.6681],
        [-0.6605, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6420547962188721, train/raw-loss = 0.6420547962188721, train/logprobs = tensor([[-0.7694, -1.9529],
        [-0.9380, -1.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6168678998947144, train/raw-loss = 0.6168678998947144, train/logprobs = tensor([[-0.4452, -2.1013],
        [-0.4817, -1.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6610521078109741, train/raw-loss = 0.6610521078109741, train/logprobs = tensor([[-0.5358, -0.9149],
        [-0.5798, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6586809158325195, train/raw-loss = 0.6586809158325195, train/logprobs = tensor([[-0.6870, -1.1920],
        [-0.7340, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.664837121963501, train/raw-loss = 0.664837121963501, train/logprobs = tensor([[-0.4646, -0.9022],
        [-0.5153, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6619232892990112, train/raw-loss = 0.6619232892990112, train/logprobs = tensor([[-0.6717, -0.9461],
        [-0.7005, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.673113226890564, train/raw-loss = 0.673113226890564, train/logprobs = tensor([[-0.4912, -1.0639],
        [-0.5204, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6655296087265015, train/raw-loss = 0.6655296087265015, train/logprobs = tensor([[-0.6594, -1.1156],
        [-0.7206, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6739588975906372, train/raw-loss = 0.6739588975906372, train/logprobs = tensor([[-0.5532, -0.5788],
        [-0.5875, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6338834762573242, train/raw-loss = 0.6338834762573242, train/logprobs = tensor([[-0.5357, -1.3062],
        [-0.5921, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6518142819404602, train/raw-loss = 0.6518142819404602, train/logprobs = tensor([[-0.5693, -0.5938],
        [-0.7053, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6589335203170776, train/raw-loss = 0.6589335203170776, train/logprobs = tensor([[-0.5760, -0.5893],
        [-0.6924, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6720525026321411, train/raw-loss = 0.6720525026321411, train/logprobs = tensor([[-0.5038, -0.6410],
        [-0.5181, -0.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6714937090873718, train/raw-loss = 0.6714937090873718, train/logprobs = tensor([[-0.5809, -0.7280],
        [-0.6262, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6708586812019348, train/raw-loss = 0.6708586812019348, train/logprobs = tensor([[-0.5863, -0.7004],
        [-0.6134, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6875094771385193, train/raw-loss = 0.6875094771385193, train/logprobs = tensor([[-0.4998, -1.0725],
        [-0.5624, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5380761623382568, train/raw-loss = 0.5380761623382568, train/logprobs = tensor([[-0.4741, -2.4161],
        [-0.4990, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6509513258934021, train/raw-loss = 0.6509513258934021, train/logprobs = tensor([[-0.4149, -0.7730],
        [-0.4313, -0.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6810438632965088, train/raw-loss = 0.6810438632965088, train/logprobs = tensor([[-0.5093, -0.7886],
        [-0.5134, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6813392043113708, train/raw-loss = 0.6813392043113708, train/logprobs = tensor([[-0.4674, -0.5622],
        [-0.5299, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6694720983505249, train/raw-loss = 0.6694720983505249, train/logprobs = tensor([[-0.4809, -0.5951],
        [-0.5345, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6698030233383179, train/raw-loss = 0.6698030233383179, train/logprobs = tensor([[-0.4878, -1.2704],
        [-0.5137, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.632347822189331, train/raw-loss = 0.632347822189331, train/logprobs = tensor([[-0.5886, -0.8578],
        [-0.7197, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6996501684188843, train/raw-loss = 0.6996501684188843, train/logprobs = tensor([[-0.2713, -0.7126],
        [-0.2906, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6715490818023682, train/raw-loss = 0.6715490818023682, train/logprobs = tensor([[-0.4793, -0.7849],
        [-0.5272, -0.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6130907535552979, train/raw-loss = 0.6130907535552979, train/logprobs = tensor([[-0.3979, -2.4016],
        [-0.4313, -2.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6360349655151367, train/raw-loss = 0.6360349655151367, train/logprobs = tensor([[-0.5770, -0.9309],
        [-0.6844, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6616557836532593, train/raw-loss = 0.6616557836532593, train/logprobs = tensor([[-0.6555, -0.7382],
        [-0.7202, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6659979820251465, train/raw-loss = 0.6659979820251465, train/logprobs = tensor([[-0.5820, -0.7864],
        [-0.6325, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6489294767379761, train/raw-loss = 0.6489294767379761, train/logprobs = tensor([[-0.4988, -1.0954],
        [-0.5200, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6267923712730408, train/raw-loss = 0.6267923712730408, train/logprobs = tensor([[-2.0627, -3.6992],
        [-2.2622, -3.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6528545022010803, train/raw-loss = 0.6528545022010803, train/logprobs = tensor([[-0.5762, -0.7849],
        [-0.6352, -0.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6606899499893188, train/raw-loss = 0.6606899499893188, train/logprobs = tensor([[-0.4071, -0.6905],
        [-0.4721, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6776509881019592, train/raw-loss = 0.6776509881019592, train/logprobs = tensor([[-0.4609, -0.6000],
        [-0.4977, -0.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6627519130706787, train/raw-loss = 0.6627519130706787, train/logprobs = tensor([[-0.4391, -0.8643],
        [-0.4521, -0.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6181536316871643, train/raw-loss = 0.6181536316871643, train/logprobs = tensor([[-0.5320, -1.4591],
        [-0.5787, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6820874214172363, train/raw-loss = 0.6814072132110596, train/logprobs = tensor([[-0.4576, -0.5742],
        [-0.4668, -0.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006801497656852007
Epoch 0, Step 65: train/loss = 0.5957750082015991, train/raw-loss = 0.5949435830116272, train/logprobs = tensor([[-0.4441, -1.6037],
        [-0.4783, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008314142934978008
Epoch 0, Step 66: train/loss = 0.6487573981285095, train/raw-loss = 0.6476504802703857, train/logprobs = tensor([[-1.1627, -1.7749],
        [-0.9963, -1.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011068661697208881
Epoch 0, Step 67: train/loss = 0.6398006677627563, train/raw-loss = 0.6388007402420044, train/logprobs = tensor([[-0.4784, -1.1684],
        [-0.4829, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009999201633036137
Epoch 0, Step 68: train/loss = 0.6472541093826294, train/raw-loss = 0.6465131044387817, train/logprobs = tensor([[-0.3706, -0.7966],
        [-0.3623, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007409712765365839
Epoch 0, Step 69: train/loss = 0.5600113272666931, train/raw-loss = 0.5591483116149902, train/logprobs = tensor([[-0.5781, -2.4763],
        [-0.5897, -1.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008630229160189629
Epoch 0, Step 70: train/loss = 0.6129515171051025, train/raw-loss = 0.6122000217437744, train/logprobs = tensor([[-0.4490, -1.2984],
        [-0.4549, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007514480035752058
Epoch 0, Step 71: train/loss = 0.6228153109550476, train/raw-loss = 0.6217036247253418, train/logprobs = tensor([[-0.5534, -0.8093],
        [-0.6372, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011116808280348778
Epoch 0, Step 72: train/loss = 0.5655845999717712, train/raw-loss = 0.5645176768302917, train/logprobs = tensor([[-0.7020, -1.6979],
        [-0.7581, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010668954811990261
Epoch 0, Step 73: train/loss = 0.6567859649658203, train/raw-loss = 0.6558020114898682, train/logprobs = tensor([[-0.4939, -0.7364],
        [-0.4656, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009839940816164017
Epoch 0, Step 74: train/loss = 0.5972151160240173, train/raw-loss = 0.5963929891586304, train/logprobs = tensor([[-0.6678, -1.4465],
        [-0.7603, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008220973424613476
Epoch 0, Step 75: train/loss = 0.5903798937797546, train/raw-loss = 0.5896713733673096, train/logprobs = tensor([[-0.4017, -2.0879],
        [-0.3987, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00708567863330245
Epoch 0, Step 76: train/loss = 0.6279892921447754, train/raw-loss = 0.627021312713623, train/logprobs = tensor([[-0.5864, -1.2565],
        [-0.5719, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009679783135652542
Epoch 0, Step 77: train/loss = 0.6367727518081665, train/raw-loss = 0.6355708837509155, train/logprobs = tensor([[-0.6665, -0.8860],
        [-0.6662, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01201922632753849
Epoch 0, Step 78: train/loss = 0.6005046367645264, train/raw-loss = 0.5996122360229492, train/logprobs = tensor([[-0.5792, -1.8067],
        [-0.6059, -1.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008924270048737526
Epoch 0, Step 79: train/loss = 0.6224303841590881, train/raw-loss = 0.6215672492980957, train/logprobs = tensor([[-0.3824, -1.2958],
        [-0.3764, -0.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008631668984889984
Epoch 0, Step 80: train/loss = 0.6107966303825378, train/raw-loss = 0.609711766242981, train/logprobs = tensor([[-0.6785, -1.3076],
        [-0.6684, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01084819994866848
Epoch 0, Step 81: train/loss = 0.6504307389259338, train/raw-loss = 0.6497045755386353, train/logprobs = tensor([[-0.4916, -0.7111],
        [-0.4925, -0.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007261984050273895
Epoch 0, Step 82: train/loss = 0.5303637981414795, train/raw-loss = 0.5297713279724121, train/logprobs = tensor([[-0.4696, -2.2179],
        [-0.4580, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005924359429627657
Epoch 0, Step 83: train/loss = 0.6208953261375427, train/raw-loss = 0.6199029684066772, train/logprobs = tensor([[-0.4720, -0.9659],
        [-0.4964, -0.6663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009923079051077366
Epoch 0, Step 84: train/loss = 0.6117369532585144, train/raw-loss = 0.610809326171875, train/logprobs = tensor([[-0.5307, -1.1778],
        [-0.6002, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009276539087295532
Epoch 0, Step 85: train/loss = 0.6350548267364502, train/raw-loss = 0.6340757012367249, train/logprobs = tensor([[-0.4991, -1.1052],
        [-0.5053, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009791427291929722
Epoch 0, Step 86: train/loss = 0.6597545146942139, train/raw-loss = 0.658560037612915, train/logprobs = tensor([[-0.6071, -1.2311],
        [-0.6108, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011945274658501148
Epoch 0, Step 87: train/loss = 0.654765248298645, train/raw-loss = 0.6538283824920654, train/logprobs = tensor([[-0.4653, -1.2461],
        [-0.4437, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009368820115923882
Epoch 0, Step 88: train/loss = 0.6554769277572632, train/raw-loss = 0.6545714139938354, train/logprobs = tensor([[-0.3897, -0.9639],
        [-0.3879, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009055373258888721
Epoch 0, Step 89: train/loss = 0.6448459029197693, train/raw-loss = 0.6440523862838745, train/logprobs = tensor([[-0.4592, -1.0687],
        [-0.4915, -0.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007935182191431522
Epoch 0, Step 90: train/loss = 0.5444152355194092, train/raw-loss = 0.5435357093811035, train/logprobs = tensor([[-0.5449, -2.8692],
        [-0.5411, -1.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008795466274023056
Epoch 0, Step 91: train/loss = 0.577958881855011, train/raw-loss = 0.5768208503723145, train/logprobs = tensor([[-0.5036, -2.3044],
        [-0.5134, -1.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011380807496607304
Epoch 0, Step 92: train/loss = 0.49848222732543945, train/raw-loss = 0.49769189953804016, train/logprobs = tensor([[-0.4789, -2.4312],
        [-0.4965, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007902741432189941
Epoch 0, Step 93: train/loss = 0.6454032063484192, train/raw-loss = 0.6444779634475708, train/logprobs = tensor([[-0.4442, -0.9605],
        [-0.4503, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009252526797354221
Epoch 0, Step 94: train/loss = 0.5942564010620117, train/raw-loss = 0.5932857990264893, train/logprobs = tensor([[-0.5568, -1.2523],
        [-0.5568, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00970593560487032
Epoch 0, Step 95: train/loss = 0.6198204159736633, train/raw-loss = 0.6188503503799438, train/logprobs = tensor([[-0.6704, -1.0657],
        [-0.7533, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009701228700578213
Epoch 0, Step 96: train/loss = 0.591162919998169, train/raw-loss = 0.5874932408332825, train/logprobs = tensor([[-0.7947, -2.7525],
        [-0.6098, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036696698516607285
Epoch 0, Step 97: train/loss = 0.5831457376480103, train/raw-loss = 0.5795599222183228, train/logprobs = tensor([[-0.7660, -1.3926],
        [-0.6932, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03585890308022499
Epoch 0, Step 98: train/loss = 0.6508283615112305, train/raw-loss = 0.6467031240463257, train/logprobs = tensor([[-0.6774, -0.9310],
        [-0.7002, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041252583265304565
Epoch 0, Step 99: train/loss = 0.6028856039047241, train/raw-loss = 0.5985443592071533, train/logprobs = tensor([[-0.7778, -1.3414],
        [-0.7664, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04341280460357666
Epoch 0, Step 100: train/loss = 0.6520776748657227, train/raw-loss = 0.647986114025116, train/logprobs = tensor([[-0.5942, -1.2595],
        [-0.5518, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04091562703251839
Epoch 0, Step 101: train/loss = 0.6104196906089783, train/raw-loss = 0.6062973737716675, train/logprobs = tensor([[-0.6680, -1.6016],
        [-0.6196, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04122394695878029
Epoch 0, Step 102: train/loss = 0.6955945491790771, train/raw-loss = 0.6901054382324219, train/logprobs = tensor([[-0.5270, -0.9669],
        [-0.5161, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054890960454940796
Epoch 0, Step 103: train/loss = 0.48515939712524414, train/raw-loss = 0.4820190370082855, train/logprobs = tensor([[-0.5755, -2.0488],
        [-0.5617, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03140341117978096
Epoch 0, Step 104: train/loss = 0.5712823271751404, train/raw-loss = 0.5675188302993774, train/logprobs = tensor([[-0.5133, -1.8410],
        [-0.4542, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03763463720679283
Epoch 0, Step 105: train/loss = 0.6220300197601318, train/raw-loss = 0.6181530356407166, train/logprobs = tensor([[-0.6213, -1.0491],
        [-0.6056, -0.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038770101964473724
Epoch 0, Step 106: train/loss = 0.4925798773765564, train/raw-loss = 0.4879246950149536, train/logprobs = tensor([[-0.8471, -2.6983],
        [-0.8961, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046551525592803955
Epoch 0, Step 107: train/loss = 0.6331770420074463, train/raw-loss = 0.6293964385986328, train/logprobs = tensor([[-0.4626, -1.0758],
        [-0.3835, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03780646249651909
Epoch 0, Step 108: train/loss = 0.6619423627853394, train/raw-loss = 0.6585388779640198, train/logprobs = tensor([[-0.4107, -1.4332],
        [-0.3797, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03403551131486893
Epoch 0, Step 109: train/loss = 0.6798118352890015, train/raw-loss = 0.6753641366958618, train/logprobs = tensor([[-0.8586, -0.9069],
        [-0.7534, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04447672888636589
Epoch 0, Step 110: train/loss = 0.6476389169692993, train/raw-loss = 0.6439502239227295, train/logprobs = tensor([[-0.5036, -1.0694],
        [-0.4640, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03688696771860123
Epoch 0, Step 111: train/loss = 0.6000962257385254, train/raw-loss = 0.5966075658798218, train/logprobs = tensor([[-0.6126, -1.4304],
        [-0.5676, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03488669916987419
Epoch 0, Step 112: train/loss = 0.589249312877655, train/raw-loss = 0.585649847984314, train/logprobs = tensor([[-0.5586, -1.5087],
        [-0.4844, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03599439188838005
Epoch 0, Step 113: train/loss = 0.5969264507293701, train/raw-loss = 0.595300555229187, train/logprobs = tensor([[-0.2409, -1.4274],
        [-0.2036, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01625881902873516
Epoch 0, Step 114: train/loss = 0.6702044010162354, train/raw-loss = 0.6666045188903809, train/logprobs = tensor([[-0.5956, -0.8859],
        [-0.5311, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03599882498383522
Epoch 0, Step 115: train/loss = 0.6106775999069214, train/raw-loss = 0.6067952513694763, train/logprobs = tensor([[-0.6834, -2.3134],
        [-0.5934, -1.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03882337361574173
Epoch 0, Step 116: train/loss = 0.6255742311477661, train/raw-loss = 0.621394693851471, train/logprobs = tensor([[-0.5442, -1.0970],
        [-0.4786, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04179506376385689
Epoch 0, Step 117: train/loss = 0.6165449023246765, train/raw-loss = 0.6127249002456665, train/logprobs = tensor([[-0.6517, -1.0471],
        [-0.6237, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03820008784532547
Epoch 0, Step 118: train/loss = 0.5360963344573975, train/raw-loss = 0.5322203636169434, train/logprobs = tensor([[-0.5888, -2.0036],
        [-0.5292, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03875971958041191
Epoch 0, Step 119: train/loss = 0.6615574359893799, train/raw-loss = 0.65898597240448, train/logprobs = tensor([[-0.4607, -0.7225],
        [-0.4376, -0.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02571459487080574
Epoch 0, Step 120: train/loss = 0.6031944751739502, train/raw-loss = 0.5990038514137268, train/logprobs = tensor([[-0.6750, -1.5621],
        [-0.6345, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041906505823135376
Epoch 0, Step 121: train/loss = 0.56661456823349, train/raw-loss = 0.5636376142501831, train/logprobs = tensor([[-0.6490, -1.7760],
        [-0.5547, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029769878834486008
Epoch 0, Step 122: train/loss = 0.6043785214424133, train/raw-loss = 0.5998951196670532, train/logprobs = tensor([[-0.6428, -1.9050],
        [-0.6137, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044834014028310776
Epoch 0, Step 123: train/loss = 0.6246132850646973, train/raw-loss = 0.6210050582885742, train/logprobs = tensor([[-0.5773, -1.2031],
        [-0.5508, -0.8483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03608163073658943
Epoch 0, Step 124: train/loss = 0.6067762970924377, train/raw-loss = 0.6039432287216187, train/logprobs = tensor([[-0.4511, -1.3401],
        [-0.4321, -0.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02833043783903122
Epoch 0, Step 125: train/loss = 0.561526894569397, train/raw-loss = 0.5576634407043457, train/logprobs = tensor([[-0.5130, -1.6792],
        [-0.4810, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038634806871414185
Epoch 0, Step 126: train/loss = 0.6222957372665405, train/raw-loss = 0.6184914112091064, train/logprobs = tensor([[-0.7268, -1.1428],
        [-0.7182, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0380430705845356
Epoch 0, Step 127: train/loss = 0.6178082227706909, train/raw-loss = 0.6135902404785156, train/logprobs = tensor([[-0.5762, -1.4279],
        [-0.5711, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04217991232872009
Epoch 0, Step 128: train/loss = 0.6837109923362732, train/raw-loss = 0.6741201281547546, train/logprobs = tensor([[-0.7310, -0.9363],
        [-0.4892, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590867906808853
Epoch 0, Step 129: train/loss = 0.5236629843711853, train/raw-loss = 0.5140695571899414, train/logprobs = tensor([[-0.5521, -3.7832],
        [-0.4947, -1.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09593458473682404
Epoch 0, Step 130: train/loss = 0.6290158629417419, train/raw-loss = 0.6211485266685486, train/logprobs = tensor([[-0.7656, -1.5200],
        [-0.5075, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867259532213211
Epoch 0, Step 131: train/loss = 0.6005948185920715, train/raw-loss = 0.5923901796340942, train/logprobs = tensor([[-0.5915, -1.2024],
        [-0.4892, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204691857099533
Epoch 0, Step 132: train/loss = 0.6760640144348145, train/raw-loss = 0.6663393378257751, train/logprobs = tensor([[-0.5940, -1.0922],
        [-0.5350, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09724743664264679
Epoch 0, Step 133: train/loss = 0.5440711975097656, train/raw-loss = 0.5360628962516785, train/logprobs = tensor([[-0.5147, -3.7285],
        [-0.4346, -2.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008325099945068
Epoch 0, Step 134: train/loss = 0.6053999662399292, train/raw-loss = 0.5959515571594238, train/logprobs = tensor([[-0.6418, -1.5266],
        [-0.5426, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09448391944169998
Epoch 0, Step 135: train/loss = 0.6645315885543823, train/raw-loss = 0.6555357575416565, train/logprobs = tensor([[-0.6659, -0.9665],
        [-0.6240, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995814621448517
Epoch 0, Step 136: train/loss = 0.7132527828216553, train/raw-loss = 0.7030572891235352, train/logprobs = tensor([[-0.7471, -1.0111],
        [-0.6734, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10195525735616684
Epoch 0, Step 137: train/loss = 0.6022766828536987, train/raw-loss = 0.5933217406272888, train/logprobs = tensor([[-0.7539, -1.7827],
        [-0.5945, -1.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895489826798439
Epoch 0, Step 138: train/loss = 0.6348962783813477, train/raw-loss = 0.6287051439285278, train/logprobs = tensor([[-0.4937, -1.3370],
        [-0.4522, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061911627650260925
Epoch 0, Step 139: train/loss = 0.5248610377311707, train/raw-loss = 0.5147934556007385, train/logprobs = tensor([[-0.6251, -2.2454],
        [-0.4977, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006762832403183
Epoch 0, Step 140: train/loss = 0.5059272646903992, train/raw-loss = 0.49837735295295715, train/logprobs = tensor([[-0.6398, -2.5728],
        [-0.5803, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754990205168724
Epoch 0, Step 141: train/loss = 0.6660427451133728, train/raw-loss = 0.6554761528968811, train/logprobs = tensor([[-0.9191, -1.2565],
        [-0.8512, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10566620528697968
Epoch 0, Step 142: train/loss = 0.4772665500640869, train/raw-loss = 0.4701312184333801, train/logprobs = tensor([[-0.4517, -2.4309],
        [-0.3867, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07135336101055145
Epoch 0, Step 143: train/loss = 0.5571330189704895, train/raw-loss = 0.5497881174087524, train/logprobs = tensor([[-0.5804, -1.9591],
        [-0.4495, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07344964146614075
Epoch 0, Step 144: train/loss = 0.5902506113052368, train/raw-loss = 0.5801821351051331, train/logprobs = tensor([[-0.8495, -3.5297],
        [-0.8233, -1.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068447887897491
Epoch 0, Step 145: train/loss = 0.6348142623901367, train/raw-loss = 0.6276957988739014, train/logprobs = tensor([[-0.6091, -1.1994],
        [-0.5215, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07118478417396545
Epoch 0, Step 146: train/loss = 0.5912037491798401, train/raw-loss = 0.5817887187004089, train/logprobs = tensor([[-0.6849, -1.3849],
        [-0.5756, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09415067732334137
Epoch 0, Step 147: train/loss = 0.5681937336921692, train/raw-loss = 0.56001877784729, train/logprobs = tensor([[-0.5551, -1.6406],
        [-0.4144, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174972236156464
Epoch 0, Step 148: train/loss = 0.5866061449050903, train/raw-loss = 0.5778346061706543, train/logprobs = tensor([[-0.6060, -1.8242],
        [-0.5061, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771514147520065
Epoch 0, Step 149: train/loss = 0.6299426555633545, train/raw-loss = 0.6198700666427612, train/logprobs = tensor([[-0.8878, -1.3324],
        [-0.6990, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10072635114192963
Epoch 0, Step 150: train/loss = 0.6525354385375977, train/raw-loss = 0.6424309015274048, train/logprobs = tensor([[-0.5991, -1.4388],
        [-0.5324, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104546695947647
Epoch 0, Step 151: train/loss = 0.6843848824501038, train/raw-loss = 0.6750178337097168, train/logprobs = tensor([[-0.8748, -0.9979],
        [-0.8188, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09367027878761292
Epoch 0, Step 152: train/loss = 0.6133463382720947, train/raw-loss = 0.6083780527114868, train/logprobs = tensor([[-0.3407, -0.9438],
        [-0.3039, -0.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049682509154081345
Epoch 0, Step 153: train/loss = 0.7126646637916565, train/raw-loss = 0.7030559182167053, train/logprobs = tensor([[-0.8890, -0.8486],
        [-0.7056, -0.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608796238899231
Epoch 0, Step 154: train/loss = 0.6276669502258301, train/raw-loss = 0.6201465129852295, train/logprobs = tensor([[-0.5525, -0.9782],
        [-0.4470, -0.5091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07520416378974915
Epoch 0, Step 155: train/loss = 0.5505111217498779, train/raw-loss = 0.5427112579345703, train/logprobs = tensor([[-0.5402, -1.9030],
        [-0.4909, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07799886912107468
Epoch 0, Step 156: train/loss = 0.516340970993042, train/raw-loss = 0.5063523650169373, train/logprobs = tensor([[-0.7365, -2.8962],
        [-0.6149, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988606721162796
Epoch 0, Step 157: train/loss = 0.7249419689178467, train/raw-loss = 0.7164520025253296, train/logprobs = tensor([[-0.6591, -0.5950],
        [-0.5549, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08490028232336044
Epoch 0, Step 158: train/loss = 0.5432486534118652, train/raw-loss = 0.5332909822463989, train/logprobs = tensor([[-0.7213, -1.9613],
        [-0.6441, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957678616046906
Epoch 0, Step 159: train/loss = 0.604211688041687, train/raw-loss = 0.595909595489502, train/logprobs = tensor([[-0.5784, -1.9322],
        [-0.5151, -1.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830216258764267
Epoch 0, Step 160: train/loss = 0.5831317901611328, train/raw-loss = 0.5729750990867615, train/logprobs = tensor([[-0.7453, -3.3856],
        [-0.5927, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10156761109828949
Epoch 0, Step 161: train/loss = 0.593526303768158, train/raw-loss = 0.5851012468338013, train/logprobs = tensor([[-0.7147, -1.2485],
        [-0.5601, -0.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08425034582614899
Epoch 0, Step 162: train/loss = 0.5029023885726929, train/raw-loss = 0.49322131276130676, train/logprobs = tensor([[-0.6099, -2.4566],
        [-0.5202, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968107059597969
Epoch 0, Step 163: train/loss = 0.586367666721344, train/raw-loss = 0.5756685733795166, train/logprobs = tensor([[-0.9277, -3.1629],
        [-0.7200, -1.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699045658111572
Epoch 0, Step 164: train/loss = 0.5256036520004272, train/raw-loss = 0.51887446641922, train/logprobs = tensor([[-0.3317, -1.9614],
        [-0.3060, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06729167699813843
Epoch 0, Step 165: train/loss = 0.5648055672645569, train/raw-loss = 0.5559733510017395, train/logprobs = tensor([[-0.6601, -3.8237],
        [-0.4751, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.088322214782238
Epoch 0, Step 166: train/loss = 0.6505887508392334, train/raw-loss = 0.6408052444458008, train/logprobs = tensor([[-0.6533, -0.9919],
        [-0.5616, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783516824245453
Epoch 0, Step 167: train/loss = 0.6476554870605469, train/raw-loss = 0.6376651525497437, train/logprobs = tensor([[-0.9080, -1.2581],
        [-0.7496, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09990333020687103
Epoch 0, Step 168: train/loss = 0.6067879796028137, train/raw-loss = 0.5957258343696594, train/logprobs = tensor([[-0.6226, -3.4236],
        [-0.5687, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106209084391594
Epoch 0, Step 169: train/loss = 0.6719480156898499, train/raw-loss = 0.6635764837265015, train/logprobs = tensor([[-0.5395, -0.6947],
        [-0.4792, -0.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371498435735703
Epoch 0, Step 170: train/loss = 0.4648626446723938, train/raw-loss = 0.4559444487094879, train/logprobs = tensor([[-0.7222, -3.4105],
        [-0.5697, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08918174356222153
Epoch 0, Step 171: train/loss = 0.5587751269340515, train/raw-loss = 0.5493434071540833, train/logprobs = tensor([[-0.6243, -3.5521],
        [-0.5272, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09431741386651993
Epoch 0, Step 172: train/loss = 0.5624178647994995, train/raw-loss = 0.5548979043960571, train/logprobs = tensor([[-0.4962, -1.8827],
        [-0.4493, -0.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751996636390686
Epoch 0, Step 173: train/loss = 0.6118946075439453, train/raw-loss = 0.6048682928085327, train/logprobs = tensor([[-0.5161, -1.1849],
        [-0.3427, -0.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07026289403438568
Epoch 0, Step 174: train/loss = 0.5691028237342834, train/raw-loss = 0.5606299638748169, train/logprobs = tensor([[-0.6110, -1.6802],
        [-0.5116, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472815155982971
Epoch 0, Step 175: train/loss = 0.5699092745780945, train/raw-loss = 0.5614065527915955, train/logprobs = tensor([[-0.5359, -1.4788],
        [-0.4731, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502689749002457
Epoch 0, Step 176: train/loss = 0.5990058779716492, train/raw-loss = 0.5898904204368591, train/logprobs = tensor([[-0.6194, -1.2043],
        [-0.4519, -0.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09115464985370636
Epoch 0, Step 177: train/loss = 0.6642980575561523, train/raw-loss = 0.6564202904701233, train/logprobs = tensor([[-0.4703, -0.7796],
        [-0.4290, -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877743244171143
Epoch 0, Step 178: train/loss = 0.5114372968673706, train/raw-loss = 0.5026142597198486, train/logprobs = tensor([[-0.7211, -1.7228],
        [-0.5826, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08822962641716003
Epoch 0, Step 179: train/loss = 0.4114222824573517, train/raw-loss = 0.4029769003391266, train/logprobs = tensor([[-0.5902, -4.8809],
        [-0.4622, -1.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445388823747635
Epoch 0, Step 180: train/loss = 0.4235262870788574, train/raw-loss = 0.41500619053840637, train/logprobs = tensor([[-0.6252, -4.6154],
        [-0.4903, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08520081639289856
Epoch 0, Step 181: train/loss = 0.5573139786720276, train/raw-loss = 0.549824595451355, train/logprobs = tensor([[-0.5046, -1.3831],
        [-0.4341, -0.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07489372789859772
Epoch 0, Step 182: train/loss = 0.7063695788383484, train/raw-loss = 0.6926571130752563, train/logprobs = tensor([[-0.8869, -2.2873],
        [-0.8754, -2.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13712498545646667
Epoch 0, Step 183: train/loss = 0.5861615538597107, train/raw-loss = 0.5764849781990051, train/logprobs = tensor([[-0.6146, -1.2582],
        [-0.6747, -0.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676559269428253
Epoch 0, Step 184: train/loss = 0.5917637348175049, train/raw-loss = 0.585432767868042, train/logprobs = tensor([[-0.3993, -1.0528],
        [-0.3911, -0.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330953538417816
Epoch 0, Step 185: train/loss = 0.5357348918914795, train/raw-loss = 0.5260408520698547, train/logprobs = tensor([[-0.8207, -3.0136],
        [-0.6905, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09694021195173264
Epoch 0, Step 186: train/loss = 0.7214650511741638, train/raw-loss = 0.7101313471794128, train/logprobs = tensor([[-0.9362, -1.1132],
        [-0.6041, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11333678662776947
Epoch 0, Step 187: train/loss = 0.5807318687438965, train/raw-loss = 0.5719548463821411, train/logprobs = tensor([[-0.6241, -1.2738],
        [-0.4418, -0.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777011930942535
Epoch 0, Step 188: train/loss = 0.577682614326477, train/raw-loss = 0.5703681707382202, train/logprobs = tensor([[-0.5799, -1.2581],
        [-0.3971, -0.4358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07314436137676239
Epoch 0, Step 189: train/loss = 0.6289218068122864, train/raw-loss = 0.6206053495407104, train/logprobs = tensor([[-0.4741, -0.9060],
        [-0.4011, -0.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08316442370414734
Epoch 0, Step 190: train/loss = 0.5401083827018738, train/raw-loss = 0.5318361520767212, train/logprobs = tensor([[-0.7564, -1.4967],
        [-0.6635, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08272227644920349
Epoch 0, Step 191: train/loss = 0.536120593547821, train/raw-loss = 0.5275093913078308, train/logprobs = tensor([[-0.6443, -2.0228],
        [-0.4961, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861116498708725
Epoch 0, Step 192: train/loss = 0.6430890560150146, train/raw-loss = 0.6302168369293213, train/logprobs = tensor([[-0.6358, -0.8824],
        [-0.5378, -0.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1287221759557724
Epoch 0, Step 193: train/loss = 0.375953733921051, train/raw-loss = 0.36576735973358154, train/logprobs = tensor([[-0.6350, -4.5066],
        [-0.4190, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101863794028759
Epoch 0, Step 194: train/loss = 0.495399534702301, train/raw-loss = 0.48474329710006714, train/logprobs = tensor([[-0.7459, -2.3705],
        [-0.4738, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656240582466125
Epoch 0, Step 195: train/loss = 0.5434034466743469, train/raw-loss = 0.5305945873260498, train/logprobs = tensor([[-0.6967, -1.9299],
        [-0.4504, -0.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12808866798877716
Epoch 0, Step 196: train/loss = 0.559112012386322, train/raw-loss = 0.5480542182922363, train/logprobs = tensor([[-0.7384, -1.5772],
        [-0.5335, -0.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057741194963455
Epoch 0, Step 197: train/loss = 0.6114766597747803, train/raw-loss = 0.596592903137207, train/logprobs = tensor([[-0.9966, -3.1876],
        [-0.5807, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488378345966339
Epoch 0, Step 198: train/loss = 0.5370699763298035, train/raw-loss = 0.5237736105918884, train/logprobs = tensor([[-0.8037, -4.2054],
        [-0.5135, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13296374678611755
Epoch 0, Step 199: train/loss = 0.6141733527183533, train/raw-loss = 0.600273609161377, train/logprobs = tensor([[-1.1701, -2.0821],
        [-0.4549, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1389979124069214
Epoch 0, Step 200: train/loss = 0.5234861969947815, train/raw-loss = 0.5126494765281677, train/logprobs = tensor([[-0.6360, -2.2322],
        [-0.5324, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10836734622716904
Epoch 0, Step 201: train/loss = 0.5029345154762268, train/raw-loss = 0.49665555357933044, train/logprobs = tensor([[-0.3154, -1.6765],
        [-0.2560, -0.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278935819864273
Epoch 0, Step 202: train/loss = 0.5274627208709717, train/raw-loss = 0.5144803524017334, train/logprobs = tensor([[-0.7930, -2.1418],
        [-0.5565, -0.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12982416152954102
Epoch 0, Step 203: train/loss = 0.5612436532974243, train/raw-loss = 0.5477520227432251, train/logprobs = tensor([[-0.7189, -1.9651],
        [-0.6103, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13491618633270264
Epoch 0, Step 204: train/loss = 0.5257013440132141, train/raw-loss = 0.5165968537330627, train/logprobs = tensor([[-0.4856, -1.5548],
        [-0.4137, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09104478359222412
Epoch 0, Step 205: train/loss = 0.6187669038772583, train/raw-loss = 0.6057245135307312, train/logprobs = tensor([[-1.2601, -2.4570],
        [-0.6369, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13042429089546204
Epoch 0, Step 206: train/loss = 0.45899906754493713, train/raw-loss = 0.4474884867668152, train/logprobs = tensor([[-0.6855, -2.4938],
        [-0.5586, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1151060163974762
Epoch 0, Step 207: train/loss = 0.6326180696487427, train/raw-loss = 0.621057391166687, train/logprobs = tensor([[-0.6279, -1.0962],
        [-0.4623, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11560730636119843
Epoch 0, Step 208: train/loss = 0.603408932685852, train/raw-loss = 0.5883186459541321, train/logprobs = tensor([[-1.1960, -2.0430],
        [-0.7551, -0.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15090303122997284
Epoch 0, Step 209: train/loss = 0.5624982118606567, train/raw-loss = 0.5483160018920898, train/logprobs = tensor([[-0.7059, -1.5460],
        [-0.5807, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418224573135376
Epoch 0, Step 210: train/loss = 0.5015690326690674, train/raw-loss = 0.4911596477031708, train/logprobs = tensor([[-0.4885, -1.8212],
        [-0.3269, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10409373790025711
Epoch 0, Step 211: train/loss = 0.6004880666732788, train/raw-loss = 0.5881300568580627, train/logprobs = tensor([[-0.6201, -1.1775],
        [-0.4241, -0.3199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12357993423938751
Epoch 0, Step 212: train/loss = 0.6451186537742615, train/raw-loss = 0.6350487470626831, train/logprobs = tensor([[-1.0434, -2.0972],
        [-0.4042, -0.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10069883614778519
Epoch 0, Step 213: train/loss = 0.7080227136611938, train/raw-loss = 0.6927084922790527, train/logprobs = tensor([[-0.7664, -0.9083],
        [-0.6939, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15314257144927979
Epoch 0, Step 214: train/loss = 0.6292694211006165, train/raw-loss = 0.6189601421356201, train/logprobs = tensor([[-0.7277, -1.0578],
        [-0.5495, -0.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309294611215591
Epoch 0, Step 215: train/loss = 0.4712907075881958, train/raw-loss = 0.45415976643562317, train/logprobs = tensor([[-1.0882, -4.3040],
        [-0.9040, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17130941152572632
Epoch 0, Step 216: train/loss = 0.5136361122131348, train/raw-loss = 0.49947723746299744, train/logprobs = tensor([[-0.9617, -2.0464],
        [-0.6917, -0.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14158912003040314
Epoch 0, Step 217: train/loss = 0.6615309119224548, train/raw-loss = 0.6455205678939819, train/logprobs = tensor([[-0.8827, -1.4411],
        [-0.6528, -0.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16010282933712006
Epoch 0, Step 218: train/loss = 0.6447501182556152, train/raw-loss = 0.6277894973754883, train/logprobs = tensor([[-1.1349, -2.0624],
        [-0.8404, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.169606015086174
Epoch 0, Step 219: train/loss = 0.6089887619018555, train/raw-loss = 0.5955644249916077, train/logprobs = tensor([[-1.1968, -2.5750],
        [-0.6451, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13424304127693176
Epoch 0, Step 220: train/loss = 0.6452546119689941, train/raw-loss = 0.6330817937850952, train/logprobs = tensor([[-0.7524, -0.9478],
        [-0.5963, -0.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172854691743851
Epoch 0, Step 221: train/loss = 0.4074178636074066, train/raw-loss = 0.39603865146636963, train/logprobs = tensor([[-0.8120, -3.7562],
        [-0.5042, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11379212141036987
Epoch 0, Step 222: train/loss = 0.5697647333145142, train/raw-loss = 0.5587987899780273, train/logprobs = tensor([[-0.7296, -1.3325],
        [-0.6863, -0.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10965903848409653
Epoch 0, Step 223: train/loss = 0.48264816403388977, train/raw-loss = 0.47001227736473083, train/logprobs = tensor([[-0.8155, -3.4399],
        [-0.6455, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12635871767997742
Epoch 0, Step 224: train/loss = 0.43129315972328186, train/raw-loss = 0.4172050356864929, train/logprobs = tensor([[-0.9988, -2.9334],
        [-0.7251, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14088141918182373
Epoch 0, Step 225: train/loss = 0.5202960968017578, train/raw-loss = 0.5077852010726929, train/logprobs = tensor([[-0.5710, -1.5729],
        [-0.4687, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510885298252106
Epoch 0, Step 226: train/loss = 0.42995673418045044, train/raw-loss = 0.41919082403182983, train/logprobs = tensor([[-0.6897, -2.5563],
        [-0.5359, -0.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076589822769165
Epoch 0, Step 227: train/loss = 0.5635321140289307, train/raw-loss = 0.5490788817405701, train/logprobs = tensor([[-1.1309, -2.0265],
        [-0.7001, -0.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14453239738941193
Epoch 0, Step 228: train/loss = 0.5866689682006836, train/raw-loss = 0.5756863951683044, train/logprobs = tensor([[-0.6994, -1.8570],
        [-0.5658, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10982607305049896
Epoch 0, Step 229: train/loss = 0.7020511627197266, train/raw-loss = 0.6921464204788208, train/logprobs = tensor([[-0.4945, -0.4844],
        [-0.4100, -0.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0990469753742218
Epoch 0, Step 230: train/loss = 0.4999805986881256, train/raw-loss = 0.486939936876297, train/logprobs = tensor([[-0.7498, -2.0379],
        [-0.6472, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13040626049041748
Epoch 0, Step 231: train/loss = 0.6351048350334167, train/raw-loss = 0.6167773008346558, train/logprobs = tensor([[-1.1779, -2.3093],
        [-0.9132, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327584862709045
Epoch 0, Step 232: train/loss = 0.47562795877456665, train/raw-loss = 0.4623563885688782, train/logprobs = tensor([[-0.8304, -5.2560],
        [-0.6603, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13271546363830566
Epoch 0, Step 233: train/loss = 0.563286542892456, train/raw-loss = 0.5492681264877319, train/logprobs = tensor([[-0.5952, -1.8628],
        [-0.5329, -0.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14018452167510986
Epoch 0, Step 234: train/loss = 0.47886109352111816, train/raw-loss = 0.4659372866153717, train/logprobs = tensor([[-0.7952, -3.1061],
        [-0.6254, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292385458946228
Epoch 0, Step 235: train/loss = 0.3116760551929474, train/raw-loss = 0.30039361119270325, train/logprobs = tensor([[ -0.7631, -11.9105],
        [ -0.6308,  -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282449215650558
Epoch 0, Step 236: train/loss = 0.5661197304725647, train/raw-loss = 0.5502064228057861, train/logprobs = tensor([[-0.8643, -1.8615],
        [-0.8248, -1.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15913279354572296
Epoch 0, Step 237: train/loss = 0.5797393918037415, train/raw-loss = 0.5675582885742188, train/logprobs = tensor([[-0.6249, -2.5678],
        [-0.5640, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1218106746673584
Epoch 0, Step 238: train/loss = 0.6369510293006897, train/raw-loss = 0.6169147491455078, train/logprobs = tensor([[-1.2546, -1.6290],
        [-1.1158, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20036256313323975
Epoch 0, Step 239: train/loss = 0.4608684182167053, train/raw-loss = 0.4446761906147003, train/logprobs = tensor([[-1.1690, -3.4735],
        [-1.0348, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16192255914211273
Epoch 0, Step 240: train/loss = 0.6665845513343811, train/raw-loss = 0.6549139022827148, train/logprobs = tensor([[-0.7676, -2.3692],
        [-0.6683, -2.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11670666933059692
Epoch 0, Step 241: train/loss = 0.6744530200958252, train/raw-loss = 0.6597436666488647, train/logprobs = tensor([[-1.5927, -1.8902],
        [-1.0251, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1470930129289627
Epoch 0, Step 242: train/loss = 0.5962295532226562, train/raw-loss = 0.5833845734596252, train/logprobs = tensor([[-0.5777, -1.3045],
        [-0.3887, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12845024466514587
Epoch 0, Step 243: train/loss = 0.5163899660110474, train/raw-loss = 0.504165768623352, train/logprobs = tensor([[-0.5222, -1.7531],
        [-0.4908, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12224163115024567
Epoch 0, Step 244: train/loss = 0.5049483180046082, train/raw-loss = 0.4905036687850952, train/logprobs = tensor([[-1.0805, -3.2413],
        [-0.7519, -1.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444662630558014
Epoch 0, Step 245: train/loss = 0.5401615500450134, train/raw-loss = 0.5301690697669983, train/logprobs = tensor([[-0.4532, -1.7270],
        [-0.3644, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09992481768131256
Epoch 0, Step 246: train/loss = 0.5763614177703857, train/raw-loss = 0.5627346038818359, train/logprobs = tensor([[-1.1662, -2.5272],
        [-0.5914, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13626806437969208
Epoch 0, Step 247: train/loss = 0.4938950538635254, train/raw-loss = 0.4809558391571045, train/logprobs = tensor([[-0.6494, -2.3261],
        [-0.4277, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12939207255840302
Epoch 0, Step 248: train/loss = 0.48785561323165894, train/raw-loss = 0.47275662422180176, train/logprobs = tensor([[-0.9447, -3.0554],
        [-0.6122, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098991990089417
Epoch 0, Step 249: train/loss = 0.5568242073059082, train/raw-loss = 0.5415910482406616, train/logprobs = tensor([[-0.7753, -2.1495],
        [-0.6451, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15233242511749268
Epoch 0, Step 250: train/loss = 0.3919495642185211, train/raw-loss = 0.37982112169265747, train/logprobs = tensor([[-0.9111, -4.2588],
        [-0.6736, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1212841272354126
Epoch 0, Step 251: train/loss = 0.4630568027496338, train/raw-loss = 0.4518452286720276, train/logprobs = tensor([[-0.4608, -3.1401],
        [-0.4053, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121160089969635
Epoch 0, Step 252: train/loss = 0.617993950843811, train/raw-loss = 0.6011143922805786, train/logprobs = tensor([[-0.8348, -2.3056],
        [-0.6898, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16879518330097198
Epoch 0, Step 253: train/loss = 0.6491345167160034, train/raw-loss = 0.6381218433380127, train/logprobs = tensor([[-0.8374, -0.9499],
        [-0.6316, -0.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1101270467042923
Epoch 0, Step 254: train/loss = 0.6419970989227295, train/raw-loss = 0.6277664303779602, train/logprobs = tensor([[-0.6522, -1.2810],
        [-0.6367, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14230626821517944
Epoch 0, Step 255: train/loss = 0.6317214369773865, train/raw-loss = 0.6191266775131226, train/logprobs = tensor([[-0.8337, -1.5938],
        [-0.6135, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259475201368332
Epoch 0, Step 256: train/loss = 0.5449424386024475, train/raw-loss = 0.5319716930389404, train/logprobs = tensor([[-0.9060, -2.2176],
        [-0.6279, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12970764935016632
Epoch 0, Step 257: train/loss = 0.49400320649147034, train/raw-loss = 0.4781971573829651, train/logprobs = tensor([[-1.0366, -3.2520],
        [-0.5384, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15806031227111816
Epoch 0, Step 258: train/loss = 0.5305294990539551, train/raw-loss = 0.5164843797683716, train/logprobs = tensor([[-1.1565, -3.3625],
        [-0.5101, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14045129716396332
Epoch 0, Step 259: train/loss = 0.44240421056747437, train/raw-loss = 0.427914559841156, train/logprobs = tensor([[-0.6155, -2.6901],
        [-0.4933, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14489655196666718
Epoch 0, Step 260: train/loss = 0.4504540264606476, train/raw-loss = 0.433351993560791, train/logprobs = tensor([[-0.8527, -2.8854],
        [-0.6963, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710205227136612
Epoch 0, Step 261: train/loss = 0.6013115644454956, train/raw-loss = 0.5868786573410034, train/logprobs = tensor([[-0.6311, -1.3020],
        [-0.4865, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1443292796611786
Epoch 0, Step 262: train/loss = 0.5626798868179321, train/raw-loss = 0.548439085483551, train/logprobs = tensor([[-0.7150, -1.5144],
        [-0.5543, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424080729484558
Epoch 0, Step 263: train/loss = 0.5932402610778809, train/raw-loss = 0.5760489106178284, train/logprobs = tensor([[-1.4148, -3.0286],
        [-0.7978, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719137579202652
Epoch 0, Step 264: train/loss = 0.4246392250061035, train/raw-loss = 0.4069593846797943, train/logprobs = tensor([[-1.0306, -3.1831],
        [-0.8859, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17679855227470398
Epoch 0, Step 265: train/loss = 0.5173400640487671, train/raw-loss = 0.5015147924423218, train/logprobs = tensor([[-0.6191, -1.7551],
        [-0.4777, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582522690296173
Epoch 0, Step 266: train/loss = 0.6272460222244263, train/raw-loss = 0.611162006855011, train/logprobs = tensor([[-0.8587, -1.0842],
        [-0.6922, -0.5166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16084004938602448
Epoch 0, Step 267: train/loss = 0.5024546980857849, train/raw-loss = 0.48718300461769104, train/logprobs = tensor([[-0.9182, -2.4668],
        [-0.5631, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15271708369255066
Epoch 0, Step 268: train/loss = 0.8295299410820007, train/raw-loss = 0.8123789429664612, train/logprobs = tensor([[-2.1220, -2.1007],
        [-0.9204, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1715104579925537
Epoch 0, Step 269: train/loss = 0.6253995299339294, train/raw-loss = 0.6137547492980957, train/logprobs = tensor([[-0.4558, -0.9669],
        [-0.2891, -0.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11644738912582397
Epoch 0, Step 270: train/loss = 0.7366622686386108, train/raw-loss = 0.7194313406944275, train/logprobs = tensor([[-1.7349, -2.4662],
        [-0.6761, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230963706970215
Epoch 0, Step 271: train/loss = 0.5103883147239685, train/raw-loss = 0.49168872833251953, train/logprobs = tensor([[-1.0367, -2.1933],
        [-0.7190, -0.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1869957000017166
Epoch 0, Step 272: train/loss = 0.3129638731479645, train/raw-loss = 0.30110862851142883, train/logprobs = tensor([[-0.5480, -7.0403],
        [-0.4974, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11855235695838928
Epoch 0, Step 273: train/loss = 0.5988461971282959, train/raw-loss = 0.5839259624481201, train/logprobs = tensor([[-0.7068, -1.2492],
        [-0.4650, -0.4026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14920231699943542
Epoch 0, Step 274: train/loss = 0.5094913840293884, train/raw-loss = 0.49527719616889954, train/logprobs = tensor([[-0.5803, -2.0849],
        [-0.4483, -0.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14214210212230682
Epoch 0, Step 275: train/loss = 0.605246365070343, train/raw-loss = 0.5895785093307495, train/logprobs = tensor([[-0.7887, -1.6317],
        [-0.4515, -0.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15667909383773804
Epoch 0, Step 276: train/loss = 0.6612584590911865, train/raw-loss = 0.6482319831848145, train/logprobs = tensor([[-0.5245, -0.7824],
        [-0.4086, -0.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13026519119739532
Epoch 0, Step 277: train/loss = 0.540319561958313, train/raw-loss = 0.5239461064338684, train/logprobs = tensor([[-0.8158, -2.3076],
        [-0.4233, -0.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1637342870235443
Epoch 0, Step 278: train/loss = 0.6224203705787659, train/raw-loss = 0.6062757968902588, train/logprobs = tensor([[-1.0393, -2.8254],
        [-0.6046, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16144616901874542
Epoch 0, Step 279: train/loss = 0.582959771156311, train/raw-loss = 0.5642244815826416, train/logprobs = tensor([[-1.0039, -1.6394],
        [-0.7890, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18735316395759583
Epoch 0, Step 280: train/loss = 0.6727168560028076, train/raw-loss = 0.6581026315689087, train/logprobs = tensor([[-0.6996, -0.7010],
        [-0.5121, -0.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14614269137382507
Epoch 0, Step 281: train/loss = 0.39769017696380615, train/raw-loss = 0.3795027732849121, train/logprobs = tensor([[-0.9728, -4.0529],
        [-0.8203, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18187397718429565
Epoch 0, Step 282: train/loss = 0.5819820761680603, train/raw-loss = 0.5663796663284302, train/logprobs = tensor([[-1.0193, -1.9826],
        [-0.6193, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15602388978004456
Epoch 0, Step 283: train/loss = 0.4747700095176697, train/raw-loss = 0.4574756324291229, train/logprobs = tensor([[-1.1038, -5.7988],
        [-0.8153, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17294403910636902
Epoch 0, Step 284: train/loss = 0.5304425954818726, train/raw-loss = 0.5140942931175232, train/logprobs = tensor([[-0.8597, -2.8071],
        [-0.7041, -0.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16348274052143097
Epoch 0, Step 285: train/loss = 0.36710673570632935, train/raw-loss = 0.35215288400650024, train/logprobs = tensor([[-0.7886, -4.4721],
        [-0.5647, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14953823387622833
Epoch 0, Step 286: train/loss = 0.5454204082489014, train/raw-loss = 0.5333074331283569, train/logprobs = tensor([[-0.7756, -2.2193],
        [-0.5468, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12112949043512344
Epoch 0, Step 287: train/loss = 0.6186835765838623, train/raw-loss = 0.5988689661026001, train/logprobs = tensor([[-1.0236, -1.4267],
        [-0.7414, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19814658164978027
Epoch 0, Step 288: train/loss = 0.607926607131958, train/raw-loss = 0.5919424295425415, train/logprobs = tensor([[-0.6036, -2.2169],
        [-0.4862, -0.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15984219312667847
Epoch 0, Step 289: train/loss = 0.39537009596824646, train/raw-loss = 0.3783024847507477, train/logprobs = tensor([[-0.6130, -2.3187],
        [-0.8130, -0.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17067602276802063
Epoch 0, Step 290: train/loss = 0.5398322343826294, train/raw-loss = 0.5271670818328857, train/logprobs = tensor([[-0.6579, -1.6186],
        [-0.6209, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12665137648582458
Epoch 0, Step 291: train/loss = 0.5094804167747498, train/raw-loss = 0.49857330322265625, train/logprobs = tensor([[-0.3609, -2.1062],
        [-0.2671, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907119512557983
Epoch 0, Step 292: train/loss = 0.5216094851493835, train/raw-loss = 0.5063305497169495, train/logprobs = tensor([[-0.6340, -1.6320],
        [-0.6397, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152789905667305
Epoch 0, Step 293: train/loss = 0.5293409824371338, train/raw-loss = 0.5148464441299438, train/logprobs = tensor([[-0.6656, -1.3719],
        [-0.6907, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494530856609344
Epoch 0, Step 294: train/loss = 0.5545715689659119, train/raw-loss = 0.5349155068397522, train/logprobs = tensor([[-0.7972, -1.9982],
        [-0.7029, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1965610533952713
Epoch 0, Step 295: train/loss = 0.5089694857597351, train/raw-loss = 0.4923924207687378, train/logprobs = tensor([[-1.2499, -2.4149],
        [-1.0297, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1657705157995224
Epoch 0, Step 296: train/loss = 0.44474712014198303, train/raw-loss = 0.42892614006996155, train/logprobs = tensor([[-0.6654, -2.2672],
        [-0.7318, -0.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15821005403995514
Epoch 0, Step 297: train/loss = 0.5007994771003723, train/raw-loss = 0.4840961992740631, train/logprobs = tensor([[-0.6780, -2.1032],
        [-0.6583, -0.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16703282296657562
Epoch 0, Step 298: train/loss = 0.884831428527832, train/raw-loss = 0.8648319840431213, train/logprobs = tensor([[-1.9948, -4.6229],
        [-0.8541, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19999396800994873
Epoch 0, Step 299: train/loss = 0.488747775554657, train/raw-loss = 0.4710004925727844, train/logprobs = tensor([[-0.6183, -2.3079],
        [-0.6479, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774728000164032
Epoch 0, Step 300: train/loss = 0.5206291675567627, train/raw-loss = 0.5018616914749146, train/logprobs = tensor([[-0.7014, -2.3563],
        [-0.5969, -0.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18767490983009338
Epoch 0, Step 301: train/loss = 0.44649121165275574, train/raw-loss = 0.4271995425224304, train/logprobs = tensor([[-0.8963, -2.6716],
        [-0.7162, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1929163783788681
Epoch 0, Step 302: train/loss = 0.6117167472839355, train/raw-loss = 0.5935271978378296, train/logprobs = tensor([[-0.9085, -1.2175],
        [-0.7457, -0.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18189509212970734
Epoch 0, Step 303: train/loss = 0.4024847745895386, train/raw-loss = 0.38643860816955566, train/logprobs = tensor([[-0.6130, -3.1247],
        [-0.5873, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16046154499053955
Epoch 0, Step 304: train/loss = 0.4357488751411438, train/raw-loss = 0.41567379236221313, train/logprobs = tensor([[-0.8596, -2.6676],
        [-0.7505, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20075055956840515
Epoch 0, Step 305: train/loss = 0.4703662395477295, train/raw-loss = 0.45538702607154846, train/logprobs = tensor([[-0.5302, -2.6370],
        [-0.6006, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14979176223278046
Epoch 0, Step 306: train/loss = 0.735710084438324, train/raw-loss = 0.7137764096260071, train/logprobs = tensor([[-0.8846, -0.7942],
        [-0.7904, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2193373292684555
Epoch 0, Step 307: train/loss = 0.5553558468818665, train/raw-loss = 0.5402964949607849, train/logprobs = tensor([[-0.5510, -1.4650],
        [-0.4981, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15059372782707214
Epoch 0, Step 308: train/loss = 0.5723279714584351, train/raw-loss = 0.5533857941627502, train/logprobs = tensor([[-1.2996, -2.1415],
        [-0.8411, -0.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894218474626541
Epoch 0, Step 309: train/loss = 0.6749552488327026, train/raw-loss = 0.658014178276062, train/logprobs = tensor([[-0.7698, -1.0104],
        [-0.5558, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16941115260124207
Epoch 0, Step 310: train/loss = 0.9120182991027832, train/raw-loss = 0.895106852054596, train/logprobs = tensor([[-1.7484, -2.2309],
        [-0.5620, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16911393404006958
Epoch 0, Step 311: train/loss = 0.45366740226745605, train/raw-loss = 0.43733087182044983, train/logprobs = tensor([[-0.5980, -2.0732],
        [-0.6623, -0.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16336484253406525
Epoch 0, Step 312: train/loss = 0.7166849970817566, train/raw-loss = 0.6962294578552246, train/logprobs = tensor([[-1.1138, -1.3338],
        [-0.6667, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20455484092235565
Epoch 0, Step 313: train/loss = 0.6485000848770142, train/raw-loss = 0.6298719048500061, train/logprobs = tensor([[-1.1070, -1.8999],
        [-0.5279, -0.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18628188967704773
Epoch 0, Step 314: train/loss = 0.6154031753540039, train/raw-loss = 0.5974502563476562, train/logprobs = tensor([[-0.6252, -1.0021],
        [-0.6934, -0.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17952919006347656
Epoch 0, Step 315: train/loss = 0.5482816696166992, train/raw-loss = 0.5335276126861572, train/logprobs = tensor([[-0.8008, -1.4123],
        [-0.8390, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14754043519496918
Epoch 0, Step 316: train/loss = 0.54474276304245, train/raw-loss = 0.526904284954071, train/logprobs = tensor([[-0.5604, -2.4590],
        [-0.4909, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17838463187217712
Epoch 0, Step 317: train/loss = 0.5232524871826172, train/raw-loss = 0.5043689012527466, train/logprobs = tensor([[-0.8286, -4.3017],
        [-0.9854, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18883568048477173
Epoch 0, Step 318: train/loss = 0.4022858440876007, train/raw-loss = 0.3862934112548828, train/logprobs = tensor([[-0.4958, -2.7909],
        [-0.5570, -0.5111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15992394089698792
Epoch 0, Step 319: train/loss = 0.5362814664840698, train/raw-loss = 0.5177084803581238, train/logprobs = tensor([[-0.6352, -2.2286],
        [-0.5346, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18572978675365448
Epoch 0, Step 320: train/loss = 0.5847069621086121, train/raw-loss = 0.56279456615448, train/logprobs = tensor([[-0.9995, -1.8988],
        [-0.6783, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21912403404712677
Epoch 0, Step 321: train/loss = 0.5801003575325012, train/raw-loss = 0.560621976852417, train/logprobs = tensor([[-0.7889, -1.4317],
        [-0.8757, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19478382170200348
Epoch 0, Step 322: train/loss = 0.6623639464378357, train/raw-loss = 0.6420192122459412, train/logprobs = tensor([[-1.0148, -1.5327],
        [-0.5247, -0.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20344717800617218
Epoch 0, Step 323: train/loss = 0.3043590784072876, train/raw-loss = 0.29073667526245117, train/logprobs = tensor([[-0.4916, -6.5919],
        [-0.5796, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13622426986694336
Epoch 0, Step 324: train/loss = 0.4719694256782532, train/raw-loss = 0.44948577880859375, train/logprobs = tensor([[-0.6916, -2.7727],
        [-0.7621, -1.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248363494873047
Epoch 0, Step 325: train/loss = 0.3325137794017792, train/raw-loss = 0.31430453062057495, train/logprobs = tensor([[-0.6798, -3.8030],
        [-0.7550, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1820923089981079
Epoch 0, Step 326: train/loss = 0.451160192489624, train/raw-loss = 0.43732476234436035, train/logprobs = tensor([[-0.4492, -2.6818],
        [-0.4811, -0.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383540779352188
Epoch 0, Step 327: train/loss = 0.4639374613761902, train/raw-loss = 0.4465741813182831, train/logprobs = tensor([[-0.6507, -2.1772],
        [-0.6093, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363283038139343
Epoch 0, Step 328: train/loss = 0.4380025565624237, train/raw-loss = 0.4161798059940338, train/logprobs = tensor([[-0.7978, -2.8250],
        [-0.8874, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21822723746299744
Epoch 0, Step 329: train/loss = 0.5692331790924072, train/raw-loss = 0.5542184114456177, train/logprobs = tensor([[-0.6171, -1.0867],
        [-0.7033, -0.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15014787018299103
Epoch 0, Step 330: train/loss = 0.45026683807373047, train/raw-loss = 0.43553197383880615, train/logprobs = tensor([[-0.5081, -1.9955],
        [-0.6174, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14734846353530884
Epoch 0, Step 331: train/loss = 0.559856116771698, train/raw-loss = 0.540117621421814, train/logprobs = tensor([[-0.7373, -1.2484],
        [-0.9905, -0.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738520681858063
Epoch 0, Step 332: train/loss = 0.5861684679985046, train/raw-loss = 0.5717328190803528, train/logprobs = tensor([[-0.6447, -2.4744],
        [-0.4831, -0.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14435629546642303
Epoch 0, Step 333: train/loss = 0.560330331325531, train/raw-loss = 0.5403046011924744, train/logprobs = tensor([[-0.6666, -1.4986],
        [-0.5585, -0.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20025748014450073
Epoch 0, Step 334: train/loss = 0.5821627974510193, train/raw-loss = 0.5613625049591064, train/logprobs = tensor([[-0.6120, -1.4288],
        [-0.5802, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20800279080867767
Epoch 0, Step 335: train/loss = 0.5077397227287292, train/raw-loss = 0.4928863048553467, train/logprobs = tensor([[-0.4496, -1.6694],
        [-0.5231, -0.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14853422343730927
Epoch 0, Step 336: train/loss = 0.5308455228805542, train/raw-loss = 0.5103653073310852, train/logprobs = tensor([[-0.6107, -1.8682],
        [-0.6007, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20480228960514069
Epoch 0, Step 337: train/loss = 0.5965541005134583, train/raw-loss = 0.5787067413330078, train/logprobs = tensor([[-0.8156, -2.2319],
        [-0.7339, -0.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17847390472888947
Epoch 0, Step 338: train/loss = 0.4281125068664551, train/raw-loss = 0.41168826818466187, train/logprobs = tensor([[-0.6506, -3.9182],
        [-0.6603, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16424229741096497
Epoch 0, Step 339: train/loss = 0.3795531690120697, train/raw-loss = 0.36442136764526367, train/logprobs = tensor([[-0.4895, -5.9375],
        [-0.5508, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513182520866394
Epoch 0, Step 340: train/loss = 0.558171272277832, train/raw-loss = 0.5416446924209595, train/logprobs = tensor([[-0.6470, -2.0066],
        [-0.6658, -0.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16526567935943604
Epoch 0, Step 341: train/loss = 0.4378970265388489, train/raw-loss = 0.4174147844314575, train/logprobs = tensor([[-0.9889, -2.6791],
        [-1.0383, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2048223465681076
Epoch 0, Step 342: train/loss = 0.4028063714504242, train/raw-loss = 0.3846762180328369, train/logprobs = tensor([[-0.6863, -3.3431],
        [-0.7707, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18130122125148773
Epoch 0, Step 343: train/loss = 0.5283395051956177, train/raw-loss = 0.514259397983551, train/logprobs = tensor([[-0.5409, -2.7097],
        [-0.5261, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408011019229889
Epoch 0, Step 344: train/loss = 0.5262132883071899, train/raw-loss = 0.5066550374031067, train/logprobs = tensor([[-0.5865, -1.6367],
        [-0.5501, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19558198750019073
Epoch 0, Step 345: train/loss = 1.2179133892059326, train/raw-loss = 1.1991500854492188, train/logprobs = tensor([[-2.1422, -1.3489],
        [-0.5360, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18763355910778046
Epoch 0, Step 346: train/loss = 0.4701610207557678, train/raw-loss = 0.4488009512424469, train/logprobs = tensor([[-0.7337, -1.8585],
        [-1.0059, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136010080575943
Epoch 0, Step 347: train/loss = 0.4566457271575928, train/raw-loss = 0.43806108832359314, train/logprobs = tensor([[-0.5900, -2.0541],
        [-0.7550, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18584641814231873
Epoch 0, Step 348: train/loss = 0.39459261298179626, train/raw-loss = 0.37701743841171265, train/logprobs = tensor([[-0.8094, -5.9596],
        [-0.8379, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17575180530548096
Epoch 0, Step 349: train/loss = 0.5297822952270508, train/raw-loss = 0.511969268321991, train/logprobs = tensor([[-0.6207, -2.6367],
        [-0.4554, -0.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17813020944595337
Epoch 0, Step 350: train/loss = 0.5089493989944458, train/raw-loss = 0.49335384368896484, train/logprobs = tensor([[-0.5464, -1.6615],
        [-0.6006, -0.4288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15595538914203644
Epoch 0, Step 351: train/loss = 0.5233961343765259, train/raw-loss = 0.4997239112854004, train/logprobs = tensor([[-0.9737, -2.2091],
        [-0.9258, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23672214150428772
Epoch 0, Step 352: train/loss = 0.6011731624603271, train/raw-loss = 0.5867312550544739, train/logprobs = tensor([[-0.4382, -1.1231],
        [-0.5055, -0.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14441856741905212
Epoch 0, Step 353: train/loss = 0.6433731913566589, train/raw-loss = 0.6283285021781921, train/logprobs = tensor([[-0.5095, -0.8282],
        [-0.4932, -0.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15044714510440826
Epoch 0, Step 354: train/loss = 0.4096832275390625, train/raw-loss = 0.3915574848651886, train/logprobs = tensor([[-0.6405, -3.1789],
        [-0.6838, -0.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18125753104686737
Epoch 0, Step 355: train/loss = 0.5202566385269165, train/raw-loss = 0.4984819293022156, train/logprobs = tensor([[-0.8161, -1.7148],
        [-0.8390, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21774743497371674
Epoch 0, Step 356: train/loss = 0.6290183067321777, train/raw-loss = 0.6129707098007202, train/logprobs = tensor([[-0.5851, -0.7542],
        [-0.6255, -0.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16047628223896027
Epoch 0, Step 357: train/loss = 0.36606258153915405, train/raw-loss = 0.34551411867141724, train/logprobs = tensor([[-0.7593, -3.3484],
        [-1.1082, -0.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054845690727234
Epoch 0, Step 358: train/loss = 0.5358686447143555, train/raw-loss = 0.5108703374862671, train/logprobs = tensor([[-0.8397, -2.4792],
        [-0.7500, -0.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24998338520526886
Epoch 0, Step 359: train/loss = 0.5740662813186646, train/raw-loss = 0.5582273006439209, train/logprobs = tensor([[-0.4074, -0.9090],
        [-0.6164, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839026868343353
Epoch 0, Step 360: train/loss = 0.5842865109443665, train/raw-loss = 0.5652972459793091, train/logprobs = tensor([[-1.1711, -4.8276],
        [-0.8476, -0.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18989300727844238
Epoch 0, Step 361: train/loss = 0.6881961822509766, train/raw-loss = 0.6669667959213257, train/logprobs = tensor([[-0.6330, -0.6716],
        [-0.5851, -0.4957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21229350566864014
Epoch 0, Step 362: train/loss = 0.6119917035102844, train/raw-loss = 0.5891467332839966, train/logprobs = tensor([[-0.6337, -1.4106],
        [-0.5735, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22845003008842468
Epoch 0, Step 363: train/loss = 0.5127103924751282, train/raw-loss = 0.4972586929798126, train/logprobs = tensor([[-0.4472, -1.8759],
        [-0.5412, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15451720356941223
Epoch 0, Step 364: train/loss = 0.521737813949585, train/raw-loss = 0.5032833218574524, train/logprobs = tensor([[-0.6660, -2.2218],
        [-0.7454, -1.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18454506993293762
Epoch 0, Step 365: train/loss = 0.49741241335868835, train/raw-loss = 0.477072149515152, train/logprobs = tensor([[-0.4361, -1.4991],
        [-0.8773, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20340244472026825
Epoch 0, Step 366: train/loss = 0.4886840581893921, train/raw-loss = 0.4668216109275818, train/logprobs = tensor([[-0.6239, -2.1080],
        [-0.9269, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21862396597862244
Epoch 0, Step 367: train/loss = 0.3486176133155823, train/raw-loss = 0.327515184879303, train/logprobs = tensor([[-0.7164, -7.0795],
        [-1.0128, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21102404594421387
Epoch 0, Step 368: train/loss = 0.6212589144706726, train/raw-loss = 0.6040908694267273, train/logprobs = tensor([[-0.8791, -1.7578],
        [-0.6464, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17168071866035461
Epoch 0, Step 369: train/loss = 0.6757919788360596, train/raw-loss = 0.6574650406837463, train/logprobs = tensor([[-0.4618, -0.5992],
        [-0.4527, -0.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18326959013938904
Epoch 0, Step 370: train/loss = 0.6266181468963623, train/raw-loss = 0.608411431312561, train/logprobs = tensor([[-0.8056, -0.6743],
        [-0.9209, -0.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18206799030303955
Epoch 0, Step 371: train/loss = 0.37236344814300537, train/raw-loss = 0.35501667857170105, train/logprobs = tensor([[-0.5966, -2.5417],
        [-0.9200, -0.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734676957130432
Epoch 0, Step 372: train/loss = 0.579064130783081, train/raw-loss = 0.5614045262336731, train/logprobs = tensor([[-0.5551, -1.9610],
        [-0.5500, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17659631371498108
Epoch 0, Step 373: train/loss = 0.5095301866531372, train/raw-loss = 0.4883074462413788, train/logprobs = tensor([[-0.6407, -3.3619],
        [-0.7825, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122274488210678
Epoch 0, Step 374: train/loss = 0.6396536231040955, train/raw-loss = 0.6231193542480469, train/logprobs = tensor([[-0.5226, -0.8872],
        [-0.6260, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16534262895584106
Epoch 0, Step 375: train/loss = 0.5816835761070251, train/raw-loss = 0.5659645795822144, train/logprobs = tensor([[-0.4342, -1.2880],
        [-0.5495, -0.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15719036757946014
Epoch 0, Step 376: train/loss = 0.5496432185173035, train/raw-loss = 0.5310746431350708, train/logprobs = tensor([[-0.5026, -1.2658],
        [-0.7412, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18568536639213562
Epoch 0, Step 377: train/loss = 0.6078118085861206, train/raw-loss = 0.5908066630363464, train/logprobs = tensor([[-0.3774, -0.8386],
        [-0.4673, -0.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700519472360611
Epoch 0, Step 378: train/loss = 0.5480915904045105, train/raw-loss = 0.5281497240066528, train/logprobs = tensor([[-0.5844, -3.9921],
        [-0.7792, -0.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.199418842792511
Epoch 0, Step 379: train/loss = 0.600731611251831, train/raw-loss = 0.578252911567688, train/logprobs = tensor([[-0.6577, -1.5072],
        [-0.6532, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247869074344635
Epoch 0, Step 380: train/loss = 0.4912842810153961, train/raw-loss = 0.4746377766132355, train/logprobs = tensor([[-0.6538, -2.2063],
        [-0.7368, -0.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16646498441696167
Epoch 0, Step 381: train/loss = 0.568993091583252, train/raw-loss = 0.5514698028564453, train/logprobs = tensor([[-0.5855, -1.6716],
        [-0.7336, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523270845413208
Epoch 0, Step 382: train/loss = 0.4047049880027771, train/raw-loss = 0.3843715190887451, train/logprobs = tensor([[-0.6789, -3.4031],
        [-1.0442, -0.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033345252275467
Epoch 0, Step 383: train/loss = 0.6974681615829468, train/raw-loss = 0.677293062210083, train/logprobs = tensor([[-1.8409, -4.7754],
        [-1.0038, -0.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20175184309482574
Epoch 0, Step 384: train/loss = 0.5553115010261536, train/raw-loss = 0.534779965877533, train/logprobs = tensor([[-0.4960, -3.3288],
        [-0.9504, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053150236606598
Epoch 0, Step 385: train/loss = 0.5897074341773987, train/raw-loss = 0.56757652759552, train/logprobs = tensor([[-0.5833, -1.0774],
        [-0.8930, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213083654642105
Epoch 0, Step 386: train/loss = 0.5456591248512268, train/raw-loss = 0.5291228294372559, train/logprobs = tensor([[-0.4570, -1.6717],
        [-0.7217, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16536320745944977
Epoch 0, Step 387: train/loss = 0.6787109375, train/raw-loss = 0.6578466296195984, train/logprobs = tensor([[-0.4549, -0.6867],
        [-0.7038, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20864343643188477
Epoch 0, Step 388: train/loss = 0.49359187483787537, train/raw-loss = 0.47271040081977844, train/logprobs = tensor([[-0.5586, -1.6162],
        [-1.0004, -0.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20881472527980804
Epoch 0, Step 389: train/loss = 0.4918484091758728, train/raw-loss = 0.4707602858543396, train/logprobs = tensor([[-0.4443, -3.8160],
        [-0.8580, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21088071167469025
Epoch 0, Step 390: train/loss = 0.37568968534469604, train/raw-loss = 0.3564079999923706, train/logprobs = tensor([[-0.4707, -3.0678],
        [-1.0031, -0.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19281679391860962
Epoch 0, Step 391: train/loss = 0.4824228286743164, train/raw-loss = 0.46069368720054626, train/logprobs = tensor([[-0.4463, -1.6899],
        [-1.0937, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21729138493537903
Epoch 0, Step 392: train/loss = 0.5602895617485046, train/raw-loss = 0.53961181640625, train/logprobs = tensor([[-0.4712, -1.1223],
        [-0.8938, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2067774534225464
Epoch 0, Step 393: train/loss = 0.5859196782112122, train/raw-loss = 0.5661753416061401, train/logprobs = tensor([[-0.4884, -1.0277],
        [-0.9904, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19744332134723663
Epoch 0, Step 394: train/loss = 0.5467067360877991, train/raw-loss = 0.5256938338279724, train/logprobs = tensor([[-0.5593, -1.2378],
        [-0.8683, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21012896299362183
Epoch 0, Step 395: train/loss = 0.4296630024909973, train/raw-loss = 0.4084245562553406, train/logprobs = tensor([[-0.4471, -2.8354],
        [-0.9988, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21238425374031067
Epoch 0, Step 396: train/loss = 0.5649430155754089, train/raw-loss = 0.5435734987258911, train/logprobs = tensor([[-0.5198, -1.6362],
        [-0.9880, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21369493007659912
Epoch 0, Step 397: train/loss = 0.38999634981155396, train/raw-loss = 0.37266427278518677, train/logprobs = tensor([[-0.3681, -4.2461],
        [-0.8457, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17332112789154053
Epoch 0, Step 398: train/loss = 0.6795511841773987, train/raw-loss = 0.658881425857544, train/logprobs = tensor([[-0.4813, -0.7223],
        [-0.6858, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20669756829738617
Epoch 0, Step 399: train/loss = 0.5556610226631165, train/raw-loss = 0.5344468951225281, train/logprobs = tensor([[-0.6580, -1.5501],
        [-0.9483, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21214163303375244
Epoch 0, Step 400: train/loss = 0.6253105401992798, train/raw-loss = 0.6057630777359009, train/logprobs = tensor([[-0.4000, -0.7828],
        [-0.6608, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1954745501279831
Epoch 0, Step 401: train/loss = 0.5413359999656677, train/raw-loss = 0.522860586643219, train/logprobs = tensor([[-0.5593, -3.6522],
        [-0.8420, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18475434184074402
Epoch 0, Step 402: train/loss = 0.46863967180252075, train/raw-loss = 0.44502872228622437, train/logprobs = tensor([[-0.4553, -2.6261],
        [-1.1385, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23610953986644745
Epoch 0, Step 403: train/loss = 0.586959958076477, train/raw-loss = 0.5690414905548096, train/logprobs = tensor([[-0.3888, -1.7361],
        [-0.5673, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17918437719345093
Epoch 0, Step 404: train/loss = 0.537377119064331, train/raw-loss = 0.5168837308883667, train/logprobs = tensor([[-0.3785, -0.8101],
        [-0.8876, -0.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20493417978286743
Epoch 0, Step 405: train/loss = 0.45053648948669434, train/raw-loss = 0.4276658892631531, train/logprobs = tensor([[-0.6244, -1.9616],
        [-0.8984, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2287057787179947
Epoch 0, Step 406: train/loss = 0.6027386784553528, train/raw-loss = 0.5802985429763794, train/logprobs = tensor([[-0.6323, -1.2216],
        [-0.7992, -0.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22440120577812195
Epoch 0, Step 407: train/loss = 0.4524461030960083, train/raw-loss = 0.43057647347450256, train/logprobs = tensor([[-0.4805, -4.0855],
        [-0.9766, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21869617700576782
Epoch 0, Step 408: train/loss = 0.6583001613616943, train/raw-loss = 0.6409268379211426, train/logprobs = tensor([[-0.4326, -0.7236],
        [-0.7664, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737324744462967
Epoch 0, Step 409: train/loss = 0.4936026930809021, train/raw-loss = 0.47313863039016724, train/logprobs = tensor([[-0.8118, -2.0490],
        [-0.9707, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20464065670967102
Epoch 0, Step 410: train/loss = 0.42162203788757324, train/raw-loss = 0.40025854110717773, train/logprobs = tensor([[-0.7769, -3.0264],
        [-1.0356, -1.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21363483369350433
Epoch 0, Step 411: train/loss = 0.3559340834617615, train/raw-loss = 0.3297688364982605, train/logprobs = tensor([[-0.6738, -2.6592],
        [-1.2274, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616519033908844
Epoch 0, Step 412: train/loss = 0.3489271104335785, train/raw-loss = 0.32894253730773926, train/logprobs = tensor([[-0.4613, -5.0521],
        [-1.0725, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19984544813632965
Epoch 0, Step 413: train/loss = 0.6432806253433228, train/raw-loss = 0.6211099028587341, train/logprobs = tensor([[-0.5695, -0.8119],
        [-0.8175, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22170773148536682
Epoch 0, Step 414: train/loss = 0.5260024666786194, train/raw-loss = 0.5079249143600464, train/logprobs = tensor([[-0.4633, -1.7017],
        [-0.6998, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1807761788368225
Epoch 0, Step 415: train/loss = 0.4975490868091583, train/raw-loss = 0.4777509570121765, train/logprobs = tensor([[-0.4113, -1.9298],
        [-0.7982, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19798080623149872
Epoch 0, Step 416: train/loss = 0.3861056864261627, train/raw-loss = 0.3648430407047272, train/logprobs = tensor([[-0.5304, -3.5296],
        [-1.1881, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126263678073883
Epoch 0, Step 417: train/loss = 0.27043721079826355, train/raw-loss = 0.2503059506416321, train/logprobs = tensor([[-0.4980, -5.8382],
        [-0.8887, -0.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20131249725818634
Epoch 0, Step 418: train/loss = 0.5425260066986084, train/raw-loss = 0.5168147087097168, train/logprobs = tensor([[-0.6728, -1.2852],
        [-1.4949, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571132183074951
Epoch 0, Step 419: train/loss = 0.4501180946826935, train/raw-loss = 0.43192601203918457, train/logprobs = tensor([[-0.4825, -3.1011],
        [-0.7307, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18192067742347717
Epoch 0, Step 420: train/loss = 0.5084189176559448, train/raw-loss = 0.48891836404800415, train/logprobs = tensor([[-0.5034, -1.6125],
        [-0.7891, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950055956840515
Epoch 0, Step 421: train/loss = 0.552386999130249, train/raw-loss = 0.5322412252426147, train/logprobs = tensor([[-0.5624, -1.1725],
        [-1.0146, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014576941728592
Epoch 0, Step 422: train/loss = 0.5681416988372803, train/raw-loss = 0.5475289821624756, train/logprobs = tensor([[-0.4050, -1.0956],
        [-0.7228, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20612700283527374
Epoch 0, Step 423: train/loss = 0.5152565836906433, train/raw-loss = 0.49690020084381104, train/logprobs = tensor([[-0.6367, -2.1252],
        [-0.7502, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18356367945671082
Epoch 0, Step 424: train/loss = 0.608878493309021, train/raw-loss = 0.5885440111160278, train/logprobs = tensor([[-0.4439, -0.9765],
        [-0.7531, -0.8008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20334482192993164
Epoch 0, Step 425: train/loss = 0.6132164001464844, train/raw-loss = 0.589027464389801, train/logprobs = tensor([[-0.6864, -0.9604],
        [-1.0347, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2418886125087738
Epoch 0, Step 426: train/loss = 0.5487144589424133, train/raw-loss = 0.5284700989723206, train/logprobs = tensor([[-0.6575, -1.4833],
        [-0.9496, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20244306325912476
Epoch 0, Step 427: train/loss = 0.545066773891449, train/raw-loss = 0.5251635313034058, train/logprobs = tensor([[-0.6527, -1.6793],
        [-1.0711, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903206825256348
Epoch 0, Step 428: train/loss = 0.5633509159088135, train/raw-loss = 0.5454499125480652, train/logprobs = tensor([[-0.5108, -1.0292],
        [-0.7407, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790107786655426
Epoch 0, Step 429: train/loss = 0.6709315776824951, train/raw-loss = 0.648220419883728, train/logprobs = tensor([[-0.4727, -0.7928],
        [-0.8327, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22711095213890076
Epoch 0, Step 430: train/loss = 0.42455726861953735, train/raw-loss = 0.4037640690803528, train/logprobs = tensor([[-0.4247, -1.7326],
        [-1.0205, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079319804906845
Epoch 0, Step 431: train/loss = 0.6034570336341858, train/raw-loss = 0.5797873139381409, train/logprobs = tensor([[-0.5775, -1.2928],
        [-0.8197, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23669743537902832
Epoch 0, Step 432: train/loss = 0.5723745822906494, train/raw-loss = 0.5531827211380005, train/logprobs = tensor([[-0.5175, -1.0512],
        [-0.7088, -0.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19191771745681763
Epoch 0, Step 433: train/loss = 0.5727207660675049, train/raw-loss = 0.549919068813324, train/logprobs = tensor([[-0.6250, -1.5031],
        [-0.9336, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22801697254180908
Epoch 0, Step 434: train/loss = 0.6036273241043091, train/raw-loss = 0.5819914937019348, train/logprobs = tensor([[-0.7637, -1.6149],
        [-1.0392, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21635892987251282
Epoch 0, Step 435: train/loss = 0.5654489994049072, train/raw-loss = 0.5414330959320068, train/logprobs = tensor([[-0.6446, -1.1647],
        [-1.0871, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24015840888023376
Epoch 0, Step 436: train/loss = 0.4959591329097748, train/raw-loss = 0.47562700510025024, train/logprobs = tensor([[-0.4867, -1.4023],
        [-0.9965, -0.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20332126319408417
Epoch 0, Step 437: train/loss = 0.529070258140564, train/raw-loss = 0.5100085139274597, train/logprobs = tensor([[-0.5066, -3.1509],
        [-0.8076, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19061751663684845
Epoch 0, Step 438: train/loss = 0.6063045263290405, train/raw-loss = 0.5844507813453674, train/logprobs = tensor([[-0.5995, -1.2316],
        [-0.6756, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853773295879364
Epoch 0, Step 439: train/loss = 0.6364046931266785, train/raw-loss = 0.6179539561271667, train/logprobs = tensor([[-0.3534, -0.7747],
        [-0.5507, -0.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18450775742530823
Epoch 0, Step 440: train/loss = 0.4173034429550171, train/raw-loss = 0.3956833779811859, train/logprobs = tensor([[-0.4735, -2.2290],
        [-0.8338, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162005603313446
Epoch 0, Step 441: train/loss = 0.5120927095413208, train/raw-loss = 0.4943196177482605, train/logprobs = tensor([[-0.4136, -3.2773],
        [-0.5613, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17773115634918213
Epoch 0, Step 442: train/loss = 0.5556780099868774, train/raw-loss = 0.5375910401344299, train/logprobs = tensor([[-0.4426, -1.4698],
        [-0.7589, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18086957931518555
Epoch 0, Step 443: train/loss = 0.5095252394676208, train/raw-loss = 0.49229496717453003, train/logprobs = tensor([[-0.4320, -1.5650],
        [-0.8051, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230282723903656
Epoch 0, Step 444: train/loss = 0.47279849648475647, train/raw-loss = 0.4486921429634094, train/logprobs = tensor([[-0.5685, -1.7917],
        [-1.0793, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2410634160041809
Epoch 0, Step 445: train/loss = 0.5517493486404419, train/raw-loss = 0.5344620943069458, train/logprobs = tensor([[-0.5237, -1.0502],
        [-0.7222, -0.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17287223041057587
Epoch 0, Step 446: train/loss = 0.41170549392700195, train/raw-loss = 0.39011698961257935, train/logprobs = tensor([[-0.4291, -4.2111],
        [-0.8669, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158849835395813
Epoch 0, Step 447: train/loss = 0.48002320528030396, train/raw-loss = 0.45920437574386597, train/logprobs = tensor([[-0.4948, -3.6018],
        [-0.8862, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20818834006786346
Epoch 0, Step 448: train/loss = 0.47906258702278137, train/raw-loss = 0.45699331164360046, train/logprobs = tensor([[-0.4318, -1.8625],
        [-1.0204, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2206927239894867
Epoch 0, Step 449: train/loss = 0.6636762619018555, train/raw-loss = 0.644809901714325, train/logprobs = tensor([[-0.4609, -0.9369],
        [-0.6425, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886638104915619
Epoch 0, Step 450: train/loss = 0.612195611000061, train/raw-loss = 0.5904482007026672, train/logprobs = tensor([[-0.5590, -1.0845],
        [-0.7209, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21747444570064545
Epoch 0, Step 451: train/loss = 0.7181682586669922, train/raw-loss = 0.6991100311279297, train/logprobs = tensor([[-0.3637, -0.4435],
        [-0.6444, -0.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19058269262313843
Epoch 0, Step 452: train/loss = 0.46378350257873535, train/raw-loss = 0.4408758580684662, train/logprobs = tensor([[-0.8911, -1.9854],
        [-1.5933, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2290765941143036
Epoch 0, Step 453: train/loss = 0.441719651222229, train/raw-loss = 0.41719740629196167, train/logprobs = tensor([[-0.5161, -2.4481],
        [-0.9610, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24522212147712708
Epoch 0, Step 454: train/loss = 0.5750129222869873, train/raw-loss = 0.5503761768341064, train/logprobs = tensor([[-0.5254, -1.0556],
        [-1.2128, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246367946267128
Epoch 0, Step 455: train/loss = 0.4598664343357086, train/raw-loss = 0.43992769718170166, train/logprobs = tensor([[-0.4965, -1.8154],
        [-0.8573, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19938713312149048
Epoch 0, Step 456: train/loss = 0.6319053173065186, train/raw-loss = 0.6072392463684082, train/logprobs = tensor([[-0.5892, -1.0899],
        [-0.8327, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24666084349155426
Epoch 0, Step 457: train/loss = 0.5961748361587524, train/raw-loss = 0.5743736028671265, train/logprobs = tensor([[-0.4635, -0.8313],
        [-0.8108, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180129587650299
Epoch 0, Step 458: train/loss = 0.7060702443122864, train/raw-loss = 0.677570641040802, train/logprobs = tensor([[-0.4788, -0.5809],
        [-0.9069, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849966287612915
Epoch 0, Step 459: train/loss = 0.48983970284461975, train/raw-loss = 0.4737555682659149, train/logprobs = tensor([[-0.3688, -1.7514],
        [-0.6929, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16084137558937073
Epoch 0, Step 460: train/loss = 0.6303690671920776, train/raw-loss = 0.6120173335075378, train/logprobs = tensor([[-0.3621, -0.9641],
        [-0.6043, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18351732194423676
Epoch 0, Step 461: train/loss = 0.40575236082077026, train/raw-loss = 0.38276541233062744, train/logprobs = tensor([[-0.5359, -2.0561],
        [-1.4338, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22986960411071777
Epoch 0, Step 462: train/loss = 0.449040949344635, train/raw-loss = 0.4218318462371826, train/logprobs = tensor([[-0.6025, -2.0719],
        [-1.5250, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720911502838135
Epoch 0, Step 463: train/loss = 0.597702145576477, train/raw-loss = 0.5726961493492126, train/logprobs = tensor([[-0.6342, -1.0428],
        [-1.0488, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25005996227264404
Epoch 0, Step 464: train/loss = 0.3199218213558197, train/raw-loss = 0.29608917236328125, train/logprobs = tensor([[-0.5141, -3.4358],
        [-1.2033, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23832640051841736
Epoch 0, Step 465: train/loss = 0.560686469078064, train/raw-loss = 0.5404735803604126, train/logprobs = tensor([[-0.6372, -1.7817],
        [-0.7539, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021283507347107
Epoch 0, Step 466: train/loss = 0.2848394215106964, train/raw-loss = 0.26530319452285767, train/logprobs = tensor([[-0.5024, -5.3720],
        [-0.9360, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19536222517490387
Epoch 0, Step 467: train/loss = 0.5647990107536316, train/raw-loss = 0.5406509041786194, train/logprobs = tensor([[-0.5958, -1.4870],
        [-0.8560, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414804995059967
Epoch 0, Step 468: train/loss = 0.6257295608520508, train/raw-loss = 0.6034663915634155, train/logprobs = tensor([[-0.3130, -0.9010],
        [-0.6741, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22263193130493164
Epoch 0, Step 469: train/loss = 0.5712050199508667, train/raw-loss = 0.5527358651161194, train/logprobs = tensor([[-0.3397, -1.0950],
        [-0.6373, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18469128012657166
Epoch 0, Step 470: train/loss = 0.6137834191322327, train/raw-loss = 0.5945042371749878, train/logprobs = tensor([[-0.3916, -1.1625],
        [-0.7027, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1927916705608368
Epoch 0, Step 471: train/loss = 0.4778660237789154, train/raw-loss = 0.4559571146965027, train/logprobs = tensor([[-0.6137, -1.4465],
        [-1.1335, -0.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21908916532993317
Epoch 0, Step 472: train/loss = 0.5349957346916199, train/raw-loss = 0.510550856590271, train/logprobs = tensor([[-0.4302, -1.5197],
        [-0.7983, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24444913864135742
Epoch 0, Step 473: train/loss = 0.5758010745048523, train/raw-loss = 0.5555223822593689, train/logprobs = tensor([[-0.4876, -1.1059],
        [-0.8458, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20278726518154144
Epoch 0, Step 474: train/loss = 0.5865398645401001, train/raw-loss = 0.5630667805671692, train/logprobs = tensor([[-0.4173, -1.2070],
        [-0.8034, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23473113775253296
Epoch 0, Step 475: train/loss = 0.3078397214412689, train/raw-loss = 0.28775203227996826, train/logprobs = tensor([[-0.6198, -3.9579],
        [-1.1159, -0.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20087699592113495
Epoch 0, Step 476: train/loss = 0.7075250148773193, train/raw-loss = 0.6875038743019104, train/logprobs = tensor([[-0.4024, -0.4643],
        [-0.6143, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2002110481262207
Epoch 0, Step 477: train/loss = 0.5474287867546082, train/raw-loss = 0.5281498432159424, train/logprobs = tensor([[-0.6363, -3.0275],
        [-1.0231, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.192789226770401
Epoch 0, Step 478: train/loss = 0.6001648902893066, train/raw-loss = 0.5780423879623413, train/logprobs = tensor([[-0.8788, -1.9098],
        [-0.7627, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22122475504875183
Epoch 0, Step 479: train/loss = 0.4927450120449066, train/raw-loss = 0.4674730896949768, train/logprobs = tensor([[-0.5369, -1.9676],
        [-0.9655, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252718985080719
Epoch 0, Step 480: train/loss = 0.5724133253097534, train/raw-loss = 0.5467026233673096, train/logprobs = tensor([[-0.6488, -1.3790],
        [-0.8910, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571074664592743
Epoch 0, Step 481: train/loss = 0.5549925565719604, train/raw-loss = 0.5306423306465149, train/logprobs = tensor([[-0.6051, -3.4541],
        [-1.3040, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24350281059741974
Epoch 0, Step 482: train/loss = 0.6758943796157837, train/raw-loss = 0.6533750891685486, train/logprobs = tensor([[-1.3820, -1.3306],
        [-1.4223, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251928746700287
Epoch 0, Step 483: train/loss = 0.4882093667984009, train/raw-loss = 0.46425706148147583, train/logprobs = tensor([[-0.6932, -1.5596],
        [-1.3049, -0.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23952306807041168
Epoch 0, Step 484: train/loss = 0.5210654735565186, train/raw-loss = 0.5027157664299011, train/logprobs = tensor([[-0.5483, -3.2391],
        [-0.9500, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1834973394870758
Epoch 0, Step 485: train/loss = 0.6633181571960449, train/raw-loss = 0.6384239196777344, train/logprobs = tensor([[-0.8271, -1.0622],
        [-0.6965, -0.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24894219636917114
Epoch 0, Step 486: train/loss = 0.3849393427371979, train/raw-loss = 0.36353957653045654, train/logprobs = tensor([[-0.5258, -2.6699],
        [-0.9532, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21399763226509094
Epoch 0, Step 487: train/loss = 0.49591565132141113, train/raw-loss = 0.46904075145721436, train/logprobs = tensor([[-0.3642, -1.5643],
        [-1.1759, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687488794326782
Epoch 0, Step 488: train/loss = 0.5318671464920044, train/raw-loss = 0.5085805058479309, train/logprobs = tensor([[-0.5021, -1.7752],
        [-0.9379, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23286646604537964
Epoch 0, Step 489: train/loss = 0.48919934034347534, train/raw-loss = 0.46994832158088684, train/logprobs = tensor([[-0.4891, -2.4475],
        [-0.9059, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1925104409456253
Epoch 0, Step 490: train/loss = 0.5230859518051147, train/raw-loss = 0.5018482208251953, train/logprobs = tensor([[-0.6156, -1.5273],
        [-0.9088, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21237772703170776
Epoch 0, Step 491: train/loss = 0.44880276918411255, train/raw-loss = 0.42652302980422974, train/logprobs = tensor([[-0.6265, -2.0693],
        [-0.9864, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22279693186283112
Epoch 0, Step 492: train/loss = 0.33076655864715576, train/raw-loss = 0.30460938811302185, train/logprobs = tensor([[-0.6013, -3.3713],
        [-1.2184, -0.8296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615715563297272
Epoch 0, Step 493: train/loss = 0.7304291725158691, train/raw-loss = 0.703079342842102, train/logprobs = tensor([[-0.9835, -0.9417],
        [-0.9328, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27349865436553955
Epoch 0, Step 494: train/loss = 0.8505951166152954, train/raw-loss = 0.8252922296524048, train/logprobs = tensor([[-1.2674, -1.0167],
        [-0.7045, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530288100242615
Epoch 0, Step 495: train/loss = 0.5696799755096436, train/raw-loss = 0.5501534938812256, train/logprobs = tensor([[-0.5000, -1.1493],
        [-0.9346, -0.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19526460766792297
Epoch 0, Step 496: train/loss = 0.5940321683883667, train/raw-loss = 0.5733829736709595, train/logprobs = tensor([[-0.5647, -1.1918],
        [-0.7850, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20649203658103943
Epoch 0, Step 497: train/loss = 0.5024735331535339, train/raw-loss = 0.48037928342819214, train/logprobs = tensor([[-0.6158, -1.5256],
        [-1.0865, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094213962554932
Epoch 0, Step 498: train/loss = 0.4979800283908844, train/raw-loss = 0.47232237458229065, train/logprobs = tensor([[-0.4263, -3.2505],
        [-0.9829, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565769553184509
Epoch 0, Step 499: train/loss = 0.4429827332496643, train/raw-loss = 0.42172616720199585, train/logprobs = tensor([[-0.5547, -1.8722],
        [-0.8633, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21256552636623383
Epoch 0, Step 500: train/loss = 0.3903413414955139, train/raw-loss = 0.3677580654621124, train/logprobs = tensor([[-0.6317, -2.2879],
        [-1.0003, -0.5965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.225832998752594
Epoch 0, Step 501: train/loss = 0.2321181744337082, train/raw-loss = 0.20800508558750153, train/logprobs = tensor([[-0.5642, -4.0557],
        [-1.3691, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24113093316555023
Epoch 0, Step 502: train/loss = 0.41225120425224304, train/raw-loss = 0.3895934224128723, train/logprobs = tensor([[-0.7213, -2.4963],
        [-0.9824, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22657792270183563
Epoch 0, Step 503: train/loss = 0.6371981501579285, train/raw-loss = 0.6166873574256897, train/logprobs = tensor([[-0.6750, -1.8689],
        [-0.6840, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2051077038049698
Epoch 0, Step 504: train/loss = 0.5559613704681396, train/raw-loss = 0.5299871563911438, train/logprobs = tensor([[-0.7494, -1.4400],
        [-1.1909, -0.9930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25974172353744507
Epoch 0, Step 505: train/loss = 0.4799764156341553, train/raw-loss = 0.45508837699890137, train/logprobs = tensor([[-0.6137, -2.2501],
        [-0.9282, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24888066947460175
Epoch 0, Step 506: train/loss = 0.4334874451160431, train/raw-loss = 0.40711385011672974, train/logprobs = tensor([[-0.8373, -1.9686],
        [-1.7743, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26373571157455444
Epoch 0, Step 507: train/loss = 0.6223535537719727, train/raw-loss = 0.6002171039581299, train/logprobs = tensor([[-0.4435, -0.8637],
        [-0.8564, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213640809059143
Epoch 0, Step 508: train/loss = 0.5411975383758545, train/raw-loss = 0.5179194211959839, train/logprobs = tensor([[-0.6941, -1.4151],
        [-1.1609, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23278184235095978
Epoch 0, Step 509: train/loss = 0.4709930121898651, train/raw-loss = 0.45457392930984497, train/logprobs = tensor([[-0.6773, -3.7883],
        [-1.1933, -0.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641906201839447
Epoch 0, Step 510: train/loss = 0.5818774700164795, train/raw-loss = 0.5570286512374878, train/logprobs = tensor([[-0.5692, -1.3273],
        [-0.8090, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24848780035972595
Epoch 0, Step 511: train/loss = 0.33120548725128174, train/raw-loss = 0.3065400719642639, train/logprobs = tensor([[-0.5552, -3.0276],
        [-1.2614, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24665424227714539
Epoch 0, Step 512: train/loss = 0.3402565121650696, train/raw-loss = 0.31852877140045166, train/logprobs = tensor([[-0.7001, -3.3031],
        [-1.2139, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21727722883224487
Epoch 0, Step 513: train/loss = 0.516904890537262, train/raw-loss = 0.4920881986618042, train/logprobs = tensor([[-0.4380, -1.6623],
        [-0.9252, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24816681444644928
Epoch 0, Step 514: train/loss = 0.46370548009872437, train/raw-loss = 0.43910765647888184, train/logprobs = tensor([[-1.1860, -2.9649],
        [-1.0232, -0.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24597814679145813
Epoch 0, Step 515: train/loss = 0.403923898935318, train/raw-loss = 0.3804936707019806, train/logprobs = tensor([[-0.5733, -5.4068],
        [-1.1374, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343023270368576
Epoch 0, Step 516: train/loss = 0.4509972333908081, train/raw-loss = 0.42684274911880493, train/logprobs = tensor([[-0.6379, -3.8335],
        [-0.9613, -0.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24154475331306458
Epoch 0, Step 517: train/loss = 0.5191771984100342, train/raw-loss = 0.5022499561309814, train/logprobs = tensor([[-0.4405, -1.6249],
        [-0.5930, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.169272318482399
Epoch 0, Step 518: train/loss = 0.458335280418396, train/raw-loss = 0.43390047550201416, train/logprobs = tensor([[-0.7445, -4.2252],
        [-1.2048, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2443479597568512
Epoch 0, Step 519: train/loss = 0.5663519501686096, train/raw-loss = 0.5394325852394104, train/logprobs = tensor([[-0.7138, -1.6511],
        [-0.8900, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691934406757355
Epoch 0, Step 520: train/loss = 0.6806302070617676, train/raw-loss = 0.6536183953285217, train/logprobs = tensor([[-1.2704, -2.0289],
        [-0.9239, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27011778950691223
Epoch 0, Step 521: train/loss = 0.362177312374115, train/raw-loss = 0.33451521396636963, train/logprobs = tensor([[-0.8016, -2.5136],
        [-1.8256, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27662116289138794
Epoch 0, Step 522: train/loss = 0.42302972078323364, train/raw-loss = 0.399486780166626, train/logprobs = tensor([[-1.5692, -4.7305],
        [-1.6080, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23542949557304382
Epoch 0, Step 523: train/loss = 0.4740232229232788, train/raw-loss = 0.4493805766105652, train/logprobs = tensor([[-0.5725, -5.1292],
        [-0.9953, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24642643332481384
Epoch 0, Step 524: train/loss = 0.5804674029350281, train/raw-loss = 0.5563149452209473, train/logprobs = tensor([[-0.7425, -1.1662],
        [-0.9711, -0.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24152490496635437
Epoch 0, Step 525: train/loss = 0.5812162160873413, train/raw-loss = 0.5576488971710205, train/logprobs = tensor([[-0.5897, -1.7477],
        [-0.8489, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23567336797714233
Epoch 0, Step 526: train/loss = 0.5971040725708008, train/raw-loss = 0.575279712677002, train/logprobs = tensor([[-0.4610, -0.9553],
        [-0.8622, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21824370324611664
Epoch 0, Step 527: train/loss = 0.5434644222259521, train/raw-loss = 0.5181427001953125, train/logprobs = tensor([[-1.0451, -5.0412],
        [-0.9857, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25321733951568604
Epoch 0, Step 528: train/loss = 0.490101158618927, train/raw-loss = 0.4612986445426941, train/logprobs = tensor([[-0.7326, -2.0375],
        [-1.2184, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28802502155303955
Epoch 0, Step 529: train/loss = 0.4396408796310425, train/raw-loss = 0.4153584837913513, train/logprobs = tensor([[-1.0259, -3.7499],
        [-1.3150, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24282395839691162
Epoch 0, Step 530: train/loss = 0.6641239523887634, train/raw-loss = 0.6455228924751282, train/logprobs = tensor([[-0.4501, -0.9067],
        [-0.7053, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18601059913635254
Epoch 0, Step 531: train/loss = 0.6785616278648376, train/raw-loss = 0.6532557010650635, train/logprobs = tensor([[-0.6115, -1.0512],
        [-0.9252, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253059446811676
Epoch 0, Step 532: train/loss = 0.6574731469154358, train/raw-loss = 0.6319055557250977, train/logprobs = tensor([[-0.4457, -0.8174],
        [-0.9410, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556757628917694
Epoch 0, Step 533: train/loss = 0.28978413343429565, train/raw-loss = 0.2685275077819824, train/logprobs = tensor([[-0.7857, -6.2830],
        [-1.0521, -0.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21256640553474426
Epoch 0, Step 534: train/loss = 0.516747236251831, train/raw-loss = 0.49509957432746887, train/logprobs = tensor([[-0.5979, -3.5601],
        [-1.0205, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21647655963897705
Epoch 0, Step 535: train/loss = 0.5287325382232666, train/raw-loss = 0.5064365267753601, train/logprobs = tensor([[-0.4111, -1.6815],
        [-0.8715, -0.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22296017408370972
Epoch 0, Step 536: train/loss = 0.498464435338974, train/raw-loss = 0.47401946783065796, train/logprobs = tensor([[-0.4620, -2.0564],
        [-0.9900, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2444499135017395
Epoch 0, Step 537: train/loss = 0.40694624185562134, train/raw-loss = 0.3845895528793335, train/logprobs = tensor([[-0.6478, -3.4105],
        [-0.9910, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22356685996055603
Epoch 0, Step 538: train/loss = 0.5972180962562561, train/raw-loss = 0.5766195058822632, train/logprobs = tensor([[-0.9387, -2.6633],
        [-0.6225, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20598545670509338
Epoch 0, Step 539: train/loss = 0.38279128074645996, train/raw-loss = 0.35837286710739136, train/logprobs = tensor([[-0.7481, -2.9084],
        [-1.2353, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2441839873790741
Epoch 0, Step 540: train/loss = 0.37277519702911377, train/raw-loss = 0.35121220350265503, train/logprobs = tensor([[-0.6511, -4.0469],
        [-0.8880, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21562997996807098
Epoch 0, Step 541: train/loss = 0.5749343037605286, train/raw-loss = 0.5516995191574097, train/logprobs = tensor([[-0.4770, -2.0226],
        [-0.7398, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23234806954860687
Epoch 0, Step 542: train/loss = 0.4116429090499878, train/raw-loss = 0.39181482791900635, train/logprobs = tensor([[-0.7490, -3.3552],
        [-0.6605, -0.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19828054308891296
Epoch 0, Step 543: train/loss = 0.3156471252441406, train/raw-loss = 0.29578906297683716, train/logprobs = tensor([[-0.4909, -4.1019],
        [-0.9360, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858041405677795
Epoch 0, Step 544: train/loss = 0.4668044149875641, train/raw-loss = 0.4397572875022888, train/logprobs = tensor([[-0.6872, -3.9083],
        [-1.1216, -1.2140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2704709768295288
Epoch 0, Step 545: train/loss = 0.4294690787792206, train/raw-loss = 0.40500330924987793, train/logprobs = tensor([[-0.9474, -2.5680],
        [-1.3813, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446579486131668
Epoch 0, Step 546: train/loss = 0.46065688133239746, train/raw-loss = 0.4397326111793518, train/logprobs = tensor([[-0.5216, -2.4035],
        [-0.6363, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20924293994903564
Epoch 0, Step 547: train/loss = 0.600433349609375, train/raw-loss = 0.5812612175941467, train/logprobs = tensor([[-0.8583, -1.2995],
        [-0.7847, -0.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19172172248363495
Epoch 0, Step 548: train/loss = 0.379817932844162, train/raw-loss = 0.3549250662326813, train/logprobs = tensor([[-0.7317, -5.2653],
        [-0.9185, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489289939403534
Epoch 0, Step 549: train/loss = 0.42440205812454224, train/raw-loss = 0.3958960771560669, train/logprobs = tensor([[-0.6564, -3.0405],
        [-1.4508, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28505972027778625
Epoch 0, Step 550: train/loss = 0.430442214012146, train/raw-loss = 0.3970479965209961, train/logprobs = tensor([[-1.1180, -3.3093],
        [-1.6186, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33394214510917664
Epoch 0, Step 551: train/loss = 0.4844740033149719, train/raw-loss = 0.4608278274536133, train/logprobs = tensor([[-0.6172, -1.6918],
        [-0.7187, -0.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23646150529384613
Epoch 0, Step 552: train/loss = 0.5363131761550903, train/raw-loss = 0.511654794216156, train/logprobs = tensor([[-0.9900, -5.0912],
        [-0.9700, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2465832531452179
Epoch 0, Step 553: train/loss = 0.5814910531044006, train/raw-loss = 0.5581753849983215, train/logprobs = tensor([[-0.5161, -1.6464],
        [-0.7438, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2331567108631134
Epoch 0, Step 554: train/loss = 0.3355449438095093, train/raw-loss = 0.31348901987075806, train/logprobs = tensor([[-0.5020, -3.6255],
        [-1.0003, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22055885195732117
Epoch 0, Step 555: train/loss = 0.5844255089759827, train/raw-loss = 0.5616626143455505, train/logprobs = tensor([[-0.5474, -1.6968],
        [-0.7264, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22762972116470337
Epoch 0, Step 556: train/loss = 0.5381557941436768, train/raw-loss = 0.5100849866867065, train/logprobs = tensor([[-0.7421, -1.7701],
        [-0.9727, -0.9886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28070762753486633
Epoch 0, Step 557: train/loss = 0.48478707671165466, train/raw-loss = 0.4604499340057373, train/logprobs = tensor([[-0.6732, -1.6576],
        [-1.1754, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2433713674545288
Epoch 0, Step 558: train/loss = 0.6000211238861084, train/raw-loss = 0.5727667212486267, train/logprobs = tensor([[-0.7319, -1.7716],
        [-0.8153, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725442349910736
Epoch 0, Step 559: train/loss = 0.5026598572731018, train/raw-loss = 0.47375252842903137, train/logprobs = tensor([[-1.1143, -3.8150],
        [-0.8302, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28907331824302673
Epoch 0, Step 560: train/loss = 0.4594610035419464, train/raw-loss = 0.4305269122123718, train/logprobs = tensor([[-0.8643, -3.9792],
        [-1.0458, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28934088349342346
Epoch 0, Step 561: train/loss = 0.5282372832298279, train/raw-loss = 0.5056379437446594, train/logprobs = tensor([[-0.6241, -2.6546],
        [-0.7236, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22599387168884277
Epoch 0, Step 562: train/loss = 0.3605734407901764, train/raw-loss = 0.3292294144630432, train/logprobs = tensor([[-1.2224, -4.5724],
        [-1.4436, -0.7048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3134407103061676
Epoch 0, Step 563: train/loss = 0.5235388875007629, train/raw-loss = 0.4954231381416321, train/logprobs = tensor([[-0.7629, -3.9277],
        [-0.6918, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28115737438201904
Epoch 0, Step 564: train/loss = 0.36650246381759644, train/raw-loss = 0.34100279211997986, train/logprobs = tensor([[-0.6910, -2.9120],
        [-1.1558, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25499647855758667
Epoch 0, Step 565: train/loss = 0.5074030756950378, train/raw-loss = 0.48589274287223816, train/logprobs = tensor([[-0.7699, -3.2006],
        [-0.9112, -1.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21510344743728638
Epoch 0, Step 566: train/loss = 0.5387388467788696, train/raw-loss = 0.5122909545898438, train/logprobs = tensor([[-0.9511, -1.9020],
        [-0.9514, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644793391227722
Epoch 0, Step 567: train/loss = 0.468239963054657, train/raw-loss = 0.4378106892108917, train/logprobs = tensor([[-0.7555, -2.8690],
        [-1.3155, -1.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30429303646087646
Epoch 0, Step 568: train/loss = 0.5287320017814636, train/raw-loss = 0.5032883882522583, train/logprobs = tensor([[-0.7797, -3.3341],
        [-0.8205, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544364929199219
Epoch 0, Step 569: train/loss = 0.47953587770462036, train/raw-loss = 0.45593830943107605, train/logprobs = tensor([[-0.7266, -2.7098],
        [-0.8724, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23597534000873566
Epoch 0, Step 570: train/loss = 0.41013121604919434, train/raw-loss = 0.3844500780105591, train/logprobs = tensor([[-1.1478, -6.1966],
        [-1.1966, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568117380142212
Epoch 0, Step 571: train/loss = 0.34694114327430725, train/raw-loss = 0.3231801986694336, train/logprobs = tensor([[-1.0129, -3.9562],
        [-1.1932, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23760929703712463
Epoch 0, Step 572: train/loss = 0.2772367000579834, train/raw-loss = 0.25191712379455566, train/logprobs = tensor([[-0.6221, -5.2172],
        [-1.4137, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531958222389221
Epoch 0, Step 573: train/loss = 0.29323846101760864, train/raw-loss = 0.2688515782356262, train/logprobs = tensor([[-0.6688, -5.6287],
        [-1.1037, -0.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438688427209854
Epoch 0, Step 574: train/loss = 0.42359304428100586, train/raw-loss = 0.400623083114624, train/logprobs = tensor([[-0.7111, -3.4420],
        [-1.0384, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296992838382721
Epoch 0, Step 575: train/loss = 0.5257403254508972, train/raw-loss = 0.49813389778137207, train/logprobs = tensor([[-0.8266, -2.7328],
        [-1.4689, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27606430649757385
Epoch 0, Step 576: train/loss = 0.3933950662612915, train/raw-loss = 0.3691454827785492, train/logprobs = tensor([[-0.6199, -3.1639],
        [-0.9288, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24249544739723206
Epoch 0, Step 577: train/loss = 0.4532455801963806, train/raw-loss = 0.4263489842414856, train/logprobs = tensor([[-0.7781, -3.0195],
        [-1.1890, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689661681652069
Epoch 0, Step 578: train/loss = 0.47613945603370667, train/raw-loss = 0.4495478868484497, train/logprobs = tensor([[-0.7901, -3.0336],
        [-1.1603, -0.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26591581106185913
Epoch 0, Step 579: train/loss = 0.5168771147727966, train/raw-loss = 0.4924400746822357, train/logprobs = tensor([[-0.6630, -1.9743],
        [-0.9196, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24437016248703003
Epoch 0, Step 580: train/loss = 0.5930849313735962, train/raw-loss = 0.5612645745277405, train/logprobs = tensor([[-0.9582, -2.7012],
        [-1.2069, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31820327043533325
Epoch 0, Step 581: train/loss = 0.5797775983810425, train/raw-loss = 0.554113507270813, train/logprobs = tensor([[-0.8810, -3.1434],
        [-0.7905, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25664082169532776
Epoch 0, Step 582: train/loss = 0.4295097291469574, train/raw-loss = 0.4007931351661682, train/logprobs = tensor([[-1.0115, -4.8318],
        [-1.0667, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871658504009247
Epoch 0, Step 583: train/loss = 0.44869303703308105, train/raw-loss = 0.41779613494873047, train/logprobs = tensor([[-0.9230, -3.3465],
        [-1.2231, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3089691400527954
Epoch 0, Step 584: train/loss = 0.36182892322540283, train/raw-loss = 0.33098775148391724, train/logprobs = tensor([[-0.9375, -4.3895],
        [-1.3054, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084116578102112
Epoch 0, Step 585: train/loss = 0.3235909938812256, train/raw-loss = 0.29472118616104126, train/logprobs = tensor([[-1.0471, -8.7903],
        [-1.3782, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28869837522506714
Epoch 0, Step 586: train/loss = 0.5260094404220581, train/raw-loss = 0.501698911190033, train/logprobs = tensor([[-0.5491, -1.9600],
        [-0.7454, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24310585856437683
Epoch 0, Step 587: train/loss = 0.4310595989227295, train/raw-loss = 0.4041725993156433, train/logprobs = tensor([[-0.6914, -2.6454],
        [-0.9234, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26886996626853943
Epoch 0, Step 588: train/loss = 0.542523205280304, train/raw-loss = 0.515739381313324, train/logprobs = tensor([[-0.6883, -1.8693],
        [-0.9605, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26783859729766846
Epoch 0, Step 589: train/loss = 0.5547103881835938, train/raw-loss = 0.5257331728935242, train/logprobs = tensor([[-0.7051, -1.5624],
        [-0.9572, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897721827030182
Epoch 0, Step 590: train/loss = 0.47089120745658875, train/raw-loss = 0.44308188557624817, train/logprobs = tensor([[-1.1217, -3.2858],
        [-1.2084, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27809321880340576
Epoch 0, Step 591: train/loss = 0.3665950894355774, train/raw-loss = 0.34127670526504517, train/logprobs = tensor([[-0.7114, -4.5594],
        [-1.0442, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531834840774536
Epoch 0, Step 592: train/loss = 0.5624745488166809, train/raw-loss = 0.5367779731750488, train/logprobs = tensor([[-0.7755, -3.0616],
        [-1.0682, -0.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256965696811676
Epoch 0, Step 593: train/loss = 0.32274848222732544, train/raw-loss = 0.2907256484031677, train/logprobs = tensor([[-1.0415, -3.7514],
        [-1.5576, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32022830843925476
Epoch 0, Step 594: train/loss = 0.380062460899353, train/raw-loss = 0.3519405424594879, train/logprobs = tensor([[-0.7459, -4.0542],
        [-1.1412, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812192738056183
Epoch 0, Step 595: train/loss = 0.492794394493103, train/raw-loss = 0.4640645384788513, train/logprobs = tensor([[-1.0845, -3.4524],
        [-1.1830, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872985005378723
Epoch 0, Step 596: train/loss = 0.9229370355606079, train/raw-loss = 0.8894827365875244, train/logprobs = tensor([[-2.1479, -2.2017],
        [-1.0116, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33454254269599915
Epoch 0, Step 597: train/loss = 0.4919481873512268, train/raw-loss = 0.46291792392730713, train/logprobs = tensor([[-0.8700, -5.1503],
        [-1.2697, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29030245542526245
Epoch 0, Step 598: train/loss = 0.44111138582229614, train/raw-loss = 0.4124147295951843, train/logprobs = tensor([[-0.9391, -3.4246],
        [-1.2913, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869666814804077
Epoch 0, Step 599: train/loss = 0.3554759919643402, train/raw-loss = 0.3265970051288605, train/logprobs = tensor([[-0.7034, -5.1894],
        [-0.9937, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887900769710541
Epoch 0, Step 600: train/loss = 0.5631433725357056, train/raw-loss = 0.5333146452903748, train/logprobs = tensor([[-0.7606, -1.4428],
        [-0.9772, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982870936393738
Epoch 0, Step 601: train/loss = 0.5157038569450378, train/raw-loss = 0.4924136996269226, train/logprobs = tensor([[-0.6110, -1.8788],
        [-0.7407, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329016774892807
Epoch 0, Step 602: train/loss = 0.892522931098938, train/raw-loss = 0.8609568476676941, train/logprobs = tensor([[-2.2965, -4.2892],
        [-0.9112, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156603276729584
Epoch 0, Step 603: train/loss = 0.5062851905822754, train/raw-loss = 0.4842787981033325, train/logprobs = tensor([[-0.5668, -1.8993],
        [-0.9028, -0.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200646698474884
Epoch 0, Step 604: train/loss = 0.5649587512016296, train/raw-loss = 0.5433286428451538, train/logprobs = tensor([[-1.1321, -4.2287],
        [-1.0866, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21630090475082397
Epoch 0, Step 605: train/loss = 0.3047598600387573, train/raw-loss = 0.27484336495399475, train/logprobs = tensor([[-0.6814, -6.7129],
        [-1.1210, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991650104522705
Epoch 0, Step 606: train/loss = 0.5079417824745178, train/raw-loss = 0.48418113589286804, train/logprobs = tensor([[-1.0291, -5.0321],
        [-1.0200, -0.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2376066893339157
Epoch 0, Step 607: train/loss = 0.3441935181617737, train/raw-loss = 0.3192490339279175, train/logprobs = tensor([[-0.7118, -3.4055],
        [-1.3004, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24944457411766052
Epoch 0, Step 608: train/loss = 0.8016546964645386, train/raw-loss = 0.7649269104003906, train/logprobs = tensor([[-2.1311, -2.1152],
        [-1.2044, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36727768182754517
Epoch 0, Step 609: train/loss = 0.3946435749530792, train/raw-loss = 0.36137843132019043, train/logprobs = tensor([[-1.1435, -6.0583],
        [-1.1705, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33265137672424316
Epoch 0, Step 610: train/loss = 0.30766457319259644, train/raw-loss = 0.279489666223526, train/logprobs = tensor([[-0.8137, -4.1206],
        [-1.3158, -0.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817493677139282
Epoch 0, Step 611: train/loss = 0.3444516062736511, train/raw-loss = 0.3185112476348877, train/logprobs = tensor([[-0.8887, -5.3911],
        [-1.3990, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594035267829895
Epoch 0, Step 612: train/loss = 0.5975966453552246, train/raw-loss = 0.5637435913085938, train/logprobs = tensor([[-1.2333, -2.3241],
        [-1.3213, -1.2727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33853060007095337
Epoch 0, Step 613: train/loss = 0.4818049669265747, train/raw-loss = 0.45686620473861694, train/logprobs = tensor([[-0.9109, -7.9664],
        [-1.0280, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24938789010047913
Epoch 0, Step 614: train/loss = 0.5086648464202881, train/raw-loss = 0.47449731826782227, train/logprobs = tensor([[-1.3036, -2.6456],
        [-1.3647, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416749835014343
Epoch 0, Step 615: train/loss = 0.5449091196060181, train/raw-loss = 0.5130404829978943, train/logprobs = tensor([[-1.7916, -6.3874],
        [-1.4998, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31868618726730347
Epoch 0, Step 616: train/loss = 0.9494568109512329, train/raw-loss = 0.9154369831085205, train/logprobs = tensor([[-2.7733, -2.6448],
        [-1.1648, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34019890427589417
Epoch 0, Step 617: train/loss = 0.49839064478874207, train/raw-loss = 0.46744951605796814, train/logprobs = tensor([[-0.8954, -3.0603],
        [-1.1839, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094109892845154
Epoch 0, Step 618: train/loss = 0.6883350610733032, train/raw-loss = 0.6550898551940918, train/logprobs = tensor([[-2.3893, -4.3997],
        [-1.1421, -0.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3324517011642456
Epoch 0, Step 619: train/loss = 0.3906816840171814, train/raw-loss = 0.35664042830467224, train/logprobs = tensor([[-0.9593, -3.2611],
        [-1.7224, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404122591018677
Epoch 0, Step 620: train/loss = 0.5477331876754761, train/raw-loss = 0.5167310237884521, train/logprobs = tensor([[-0.9464, -1.8338],
        [-1.0482, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100210428237915
Epoch 0, Step 621: train/loss = 0.4118914008140564, train/raw-loss = 0.382657915353775, train/logprobs = tensor([[-0.8161, -4.0571],
        [-1.0081, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29233497381210327
Epoch 0, Step 622: train/loss = 0.48396462202072144, train/raw-loss = 0.4523851275444031, train/logprobs = tensor([[-0.7391, -2.8579],
        [-1.2283, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3157948851585388
Epoch 0, Step 623: train/loss = 0.5383383631706238, train/raw-loss = 0.5097790956497192, train/logprobs = tensor([[-0.9755, -3.4773],
        [-1.0410, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855924367904663
Epoch 0, Step 624: train/loss = 0.37438005208969116, train/raw-loss = 0.3370663523674011, train/logprobs = tensor([[-1.6048, -4.7342],
        [-1.6006, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731366991996765
Epoch 0, Step 625: train/loss = 0.39388948678970337, train/raw-loss = 0.365642786026001, train/logprobs = tensor([[-1.6360, -5.3715],
        [-1.2875, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28246721625328064
Epoch 0, Step 626: train/loss = 0.4696543216705322, train/raw-loss = 0.4442107379436493, train/logprobs = tensor([[-0.6422, -4.1750],
        [-0.8910, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25443583726882935
Epoch 0, Step 627: train/loss = 0.5193525552749634, train/raw-loss = 0.4881361126899719, train/logprobs = tensor([[-1.1125, -3.1881],
        [-1.1581, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31216394901275635
Epoch 0, Step 628: train/loss = 0.3020190894603729, train/raw-loss = 0.27755582332611084, train/logprobs = tensor([[-1.2667, -9.0710],
        [-1.3777, -1.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446327805519104
Epoch 0, Step 629: train/loss = 0.3232710063457489, train/raw-loss = 0.29400765895843506, train/logprobs = tensor([[-0.8172, -6.1082],
        [-1.5636, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29263338446617126
Epoch 0, Step 630: train/loss = 0.39505383372306824, train/raw-loss = 0.3664514422416687, train/logprobs = tensor([[-1.2698, -6.6218],
        [-1.1957, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860238254070282
Epoch 0, Step 631: train/loss = 0.6032699346542358, train/raw-loss = 0.5714927911758423, train/logprobs = tensor([[-1.6252, -3.1695],
        [-1.2359, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31777137517929077
Epoch 0, Step 632: train/loss = 0.38815778493881226, train/raw-loss = 0.3552982807159424, train/logprobs = tensor([[-1.1384, -4.8829],
        [-1.6524, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285951316356659
Epoch 0, Step 633: train/loss = 0.5910841822624207, train/raw-loss = 0.5619134902954102, train/logprobs = tensor([[-0.6721, -1.2964],
        [-1.2615, -1.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2917064130306244
Epoch 0, Step 634: train/loss = 0.7913893461227417, train/raw-loss = 0.7614233493804932, train/logprobs = tensor([[-1.7366, -1.1940],
        [-1.1703, -0.6946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996603548526764
Epoch 0, Step 635: train/loss = 0.34646955132484436, train/raw-loss = 0.314883291721344, train/logprobs = tensor([[-1.0480, -3.9680],
        [-1.5888, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158627152442932
Epoch 0, Step 636: train/loss = 0.45420005917549133, train/raw-loss = 0.42502355575561523, train/logprobs = tensor([[-0.8608, -3.3504],
        [-1.1145, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2917650640010834
Epoch 0, Step 637: train/loss = 0.48226800560951233, train/raw-loss = 0.45317161083221436, train/logprobs = tensor([[-0.9110, -3.2235],
        [-0.8356, -0.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2909643352031708
Epoch 0, Step 638: train/loss = 0.601227879524231, train/raw-loss = 0.5627903938293457, train/logprobs = tensor([[-1.7803, -2.6506],
        [-1.3774, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38437509536743164
Epoch 0, Step 639: train/loss = 0.3479987382888794, train/raw-loss = 0.3200380206108093, train/logprobs = tensor([[-0.8365, -4.7580],
        [-1.2247, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27960696816444397
Epoch 0, Step 640: train/loss = 0.4337204098701477, train/raw-loss = 0.403894305229187, train/logprobs = tensor([[-0.7705, -2.3448],
        [-1.1498, -0.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29826095700263977
Epoch 0, Step 641: train/loss = 0.5794436931610107, train/raw-loss = 0.5457944869995117, train/logprobs = tensor([[-1.3937, -5.7028],
        [-1.0950, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364923894405365
Epoch 0, Step 642: train/loss = 0.6857466101646423, train/raw-loss = 0.6531535387039185, train/logprobs = tensor([[-0.8531, -0.9047],
        [-1.0970, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32593026757240295
Epoch 0, Step 643: train/loss = 0.44639402627944946, train/raw-loss = 0.4144897758960724, train/logprobs = tensor([[-1.7394, -6.2341],
        [-1.7632, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3190425932407379
Epoch 0, Step 644: train/loss = 0.396544486284256, train/raw-loss = 0.36483556032180786, train/logprobs = tensor([[-1.2044, -6.9317],
        [-1.2065, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317088782787323
Epoch 0, Step 645: train/loss = 0.3926753103733063, train/raw-loss = 0.3620954155921936, train/logprobs = tensor([[-0.9172, -5.7067],
        [-0.9927, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30579882860183716
Epoch 0, Step 646: train/loss = 0.5018779635429382, train/raw-loss = 0.4769030809402466, train/logprobs = tensor([[-0.7614, -5.4039],
        [-0.8766, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24974840879440308
Epoch 0, Step 647: train/loss = 0.45365914702415466, train/raw-loss = 0.4089948534965515, train/logprobs = tensor([[-1.2384, -3.5008],
        [-1.3734, -1.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44664305448532104
Epoch 0, Step 648: train/loss = 0.5751920938491821, train/raw-loss = 0.546188473701477, train/logprobs = tensor([[-0.9999, -2.4503],
        [-1.1237, -0.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29003652930259705
Epoch 0, Step 649: train/loss = 0.38048073649406433, train/raw-loss = 0.34567713737487793, train/logprobs = tensor([[-1.5317, -4.6532],
        [-1.5725, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480360805988312
Epoch 0, Step 650: train/loss = 0.5995598435401917, train/raw-loss = 0.5685144066810608, train/logprobs = tensor([[-1.6566, -3.0152],
        [-0.9969, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31045472621917725
Epoch 0, Step 651: train/loss = 0.3811115622520447, train/raw-loss = 0.34094539284706116, train/logprobs = tensor([[-1.6113, -4.2278],
        [-1.5414, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40166181325912476
Epoch 0, Step 652: train/loss = 0.5423397421836853, train/raw-loss = 0.5112187266349792, train/logprobs = tensor([[-1.2287, -2.6626],
        [-1.3432, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31120988726615906
Epoch 0, Step 653: train/loss = 0.37846097350120544, train/raw-loss = 0.348816454410553, train/logprobs = tensor([[-0.8403, -6.4114],
        [-0.9305, -0.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29644539952278137
Epoch 0, Step 654: train/loss = 0.41305235028266907, train/raw-loss = 0.38460931181907654, train/logprobs = tensor([[-0.9849, -3.2515],
        [-0.9534, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2844303250312805
Epoch 0, Step 655: train/loss = 0.5134333372116089, train/raw-loss = 0.4828130900859833, train/logprobs = tensor([[-0.7366, -2.7760],
        [-1.0693, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30620276927948
Epoch 0, Step 656: train/loss = 0.38257282972335815, train/raw-loss = 0.35125285387039185, train/logprobs = tensor([[-1.1999, -5.1700],
        [-1.2485, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132000267505646
Epoch 0, Step 657: train/loss = 0.3688186705112457, train/raw-loss = 0.34343183040618896, train/logprobs = tensor([[-0.7221, -4.8163],
        [-0.9688, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25386855006217957
Epoch 0, Step 658: train/loss = 0.5874935388565063, train/raw-loss = 0.5581228137016296, train/logprobs = tensor([[-1.5603, -7.0470],
        [-0.9446, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29370757937431335
Epoch 0, Step 659: train/loss = 0.46294528245925903, train/raw-loss = 0.4331051707267761, train/logprobs = tensor([[-0.9016, -3.1756],
        [-0.9456, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29840153455734253
Epoch 0, Step 660: train/loss = 0.38690635561943054, train/raw-loss = 0.3521423637866974, train/logprobs = tensor([[-1.5485, -5.5084],
        [-2.1273, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34763985872268677
Epoch 0, Step 661: train/loss = 0.5640231966972351, train/raw-loss = 0.5297401547431946, train/logprobs = tensor([[-1.5827, -3.2523],
        [-1.3658, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428303003311157
Epoch 0, Step 662: train/loss = 0.6038739681243896, train/raw-loss = 0.5674019455909729, train/logprobs = tensor([[-2.1452, -4.2616],
        [-1.5729, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3647193908691406
Epoch 0, Step 663: train/loss = 0.2573341131210327, train/raw-loss = 0.22503693401813507, train/logprobs = tensor([[-1.0938, -6.4691],
        [-1.5467, -1.5022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229716420173645
Epoch 0, Step 664: train/loss = 0.3691347539424896, train/raw-loss = 0.3357507288455963, train/logprobs = tensor([[-0.8936, -4.3705],
        [-1.5428, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33384019136428833
Epoch 0, Step 665: train/loss = 0.5754787921905518, train/raw-loss = 0.5460191369056702, train/logprobs = tensor([[-0.6464, -2.5612],
        [-0.9304, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945965528488159
Epoch 0, Step 666: train/loss = 0.9644184112548828, train/raw-loss = 0.930385947227478, train/logprobs = tensor([[-3.1126, -3.7681],
        [-1.2017, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403244614601135
Epoch 0, Step 667: train/loss = 0.5173577070236206, train/raw-loss = 0.48235639929771423, train/logprobs = tensor([[-1.0763, -2.4941],
        [-1.6094, -1.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3500129282474518
Epoch 0, Step 668: train/loss = 0.4740105867385864, train/raw-loss = 0.4407613277435303, train/logprobs = tensor([[-1.2556, -3.7185],
        [-1.3694, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33249276876449585
Epoch 0, Step 669: train/loss = 0.4960029125213623, train/raw-loss = 0.464627742767334, train/logprobs = tensor([[-1.5839, -4.3761],
        [-1.5674, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137519061565399
Epoch 0, Step 670: train/loss = 0.4981299638748169, train/raw-loss = 0.4673781991004944, train/logprobs = tensor([[-1.0155, -1.7834],
        [-1.1929, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30751752853393555
Epoch 0, Step 671: train/loss = 0.5547870993614197, train/raw-loss = 0.5193140506744385, train/logprobs = tensor([[-1.4482, -3.1290],
        [-1.2424, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547307252883911
Epoch 0, Step 672: train/loss = 0.6757442951202393, train/raw-loss = 0.6445760130882263, train/logprobs = tensor([[-2.3215, -4.7785],
        [-1.2950, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116823434829712
Epoch 0, Step 673: train/loss = 0.6617023944854736, train/raw-loss = 0.6328048706054688, train/logprobs = tensor([[-1.2293, -3.6015],
        [-0.8833, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288975328207016
Epoch 0, Step 674: train/loss = 0.40370941162109375, train/raw-loss = 0.3674144446849823, train/logprobs = tensor([[-1.5101, -4.8351],
        [-1.1516, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629496991634369
Epoch 0, Step 675: train/loss = 0.39404186606407166, train/raw-loss = 0.35621029138565063, train/logprobs = tensor([[-1.0633, -4.4975],
        [-1.6239, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37831583619117737
Epoch 0, Step 676: train/loss = 0.6563482880592346, train/raw-loss = 0.6187268495559692, train/logprobs = tensor([[-2.6035, -4.5357],
        [-1.5759, -0.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762147128582001
Epoch 0, Step 677: train/loss = 0.4271313548088074, train/raw-loss = 0.3937251567840576, train/logprobs = tensor([[-0.7504, -4.0885],
        [-1.2961, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33406203985214233
Epoch 0, Step 678: train/loss = 0.430363267660141, train/raw-loss = 0.3988001048564911, train/logprobs = tensor([[-0.6493, -2.6097],
        [-1.3885, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31563159823417664
Epoch 0, Step 679: train/loss = 0.6018352508544922, train/raw-loss = 0.5627157092094421, train/logprobs = tensor([[-2.9234, -8.6423],
        [-1.9046, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3911955952644348
Epoch 0, Step 680: train/loss = 0.7378966212272644, train/raw-loss = 0.6964534521102905, train/logprobs = tensor([[-1.0324, -1.1189],
        [-1.1679, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41443169116973877
Epoch 0, Step 681: train/loss = 0.5479257702827454, train/raw-loss = 0.5162774324417114, train/logprobs = tensor([[-1.3299, -3.6664],
        [-1.1303, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164828419685364
Epoch 0, Step 682: train/loss = 0.49228161573410034, train/raw-loss = 0.45882999897003174, train/logprobs = tensor([[-0.7666, -2.6332],
        [-1.1789, -0.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345164358615875
Epoch 0, Step 683: train/loss = 0.543628990650177, train/raw-loss = 0.5097155570983887, train/logprobs = tensor([[-1.2284, -2.4962],
        [-1.4567, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3391342759132385
Epoch 0, Step 684: train/loss = 0.5028514862060547, train/raw-loss = 0.4726484417915344, train/logprobs = tensor([[-1.2532, -5.1172],
        [-1.0551, -0.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30203020572662354
Epoch 0, Step 685: train/loss = 0.5302878618240356, train/raw-loss = 0.49653366208076477, train/logprobs = tensor([[-1.1336, -2.6666],
        [-1.2118, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33754175901412964
Epoch 0, Step 686: train/loss = 0.34483835101127625, train/raw-loss = 0.3189229965209961, train/logprobs = tensor([[-0.5684, -5.0581],
        [-0.8681, -0.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591536045074463
Epoch 0, Step 687: train/loss = 0.2652464509010315, train/raw-loss = 0.23690690100193024, train/logprobs = tensor([[-0.8144, -6.6871],
        [-1.0739, -0.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.283395379781723
Epoch 0, Step 688: train/loss = 0.23678214848041534, train/raw-loss = 0.20763792097568512, train/logprobs = tensor([[-0.8953, -7.6720],
        [-1.4169, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914423942565918
Epoch 0, Step 689: train/loss = 0.39946916699409485, train/raw-loss = 0.36928337812423706, train/logprobs = tensor([[-0.8678, -4.9460],
        [-1.0088, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3018577992916107
Epoch 0, Step 690: train/loss = 0.4698887765407562, train/raw-loss = 0.44197022914886475, train/logprobs = tensor([[-0.9724, -2.5200],
        [-1.3833, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27918559312820435
Epoch 0, Step 691: train/loss = 0.4664986729621887, train/raw-loss = 0.4328238070011139, train/logprobs = tensor([[-0.7438, -2.5466],
        [-1.3726, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33674880862236023
Epoch 0, Step 692: train/loss = 1.0819282531738281, train/raw-loss = 1.0400818586349487, train/logprobs = tensor([[-4.0224, -6.2873],
        [-1.3531, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41846394538879395
Epoch 0, Step 693: train/loss = 0.31083860993385315, train/raw-loss = 0.2738623023033142, train/logprobs = tensor([[-1.2525, -4.2679],
        [-1.8555, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36976325511932373
Epoch 0, Step 694: train/loss = 0.7631915807723999, train/raw-loss = 0.7277696132659912, train/logprobs = tensor([[-1.8501, -4.9805],
        [-1.3846, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35421890020370483
Epoch 0, Step 695: train/loss = 0.3287254571914673, train/raw-loss = 0.28944242000579834, train/logprobs = tensor([[-1.2340, -5.5075],
        [-1.7081, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928299844264984
Epoch 0, Step 696: train/loss = 0.48441576957702637, train/raw-loss = 0.44594064354896545, train/logprobs = tensor([[-1.0004, -3.7386],
        [-1.7100, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38475117087364197
Epoch 0, Step 697: train/loss = 0.511522114276886, train/raw-loss = 0.4794536232948303, train/logprobs = tensor([[-0.8927, -2.9948],
        [-1.0881, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3206847310066223
Epoch 0, Step 698: train/loss = 0.3331763744354248, train/raw-loss = 0.3000730276107788, train/logprobs = tensor([[-0.9022, -3.3104],
        [-1.4143, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310333788394928
Epoch 0, Step 699: train/loss = 0.681387186050415, train/raw-loss = 0.6487823128700256, train/logprobs = tensor([[-1.0546, -2.2926],
        [-0.9816, -1.1758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32604897022247314
Epoch 0, Step 700: train/loss = 0.3945268988609314, train/raw-loss = 0.3601715564727783, train/logprobs = tensor([[-1.2815, -3.1537],
        [-1.7135, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3435533940792084
Epoch 0, Step 701: train/loss = 0.6233749389648438, train/raw-loss = 0.5812221169471741, train/logprobs = tensor([[-1.6749, -3.0595],
        [-1.6054, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42152872681617737
Epoch 0, Step 702: train/loss = 0.41924989223480225, train/raw-loss = 0.39119482040405273, train/logprobs = tensor([[-0.6886, -3.2166],
        [-0.9881, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805503010749817
Epoch 0, Step 703: train/loss = 0.41238686442375183, train/raw-loss = 0.37404993176460266, train/logprobs = tensor([[-1.5396, -3.8811],
        [-1.6082, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3833693265914917
Epoch 0, Step 704: train/loss = 0.5480608344078064, train/raw-loss = 0.5128231048583984, train/logprobs = tensor([[-1.3284, -6.0473],
        [-1.5759, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523768186569214
Epoch 0, Step 705: train/loss = 0.2650398910045624, train/raw-loss = 0.22256338596343994, train/logprobs = tensor([[-1.3145, -5.7377],
        [-2.2396, -2.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247652590274811
Epoch 0, Step 706: train/loss = 0.7205023169517517, train/raw-loss = 0.6880970001220703, train/logprobs = tensor([[-2.4804, -4.2280],
        [-1.3578, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240531086921692
Epoch 0, Step 707: train/loss = 0.20837530493736267, train/raw-loss = 0.1767345666885376, train/logprobs = tensor([[-0.8075, -6.7664],
        [-1.6449, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164072632789612
Epoch 0, Step 708: train/loss = 0.5362945199012756, train/raw-loss = 0.5005335807800293, train/logprobs = tensor([[-1.0544, -3.3423],
        [-1.2062, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35760951042175293
Epoch 0, Step 709: train/loss = 0.38399988412857056, train/raw-loss = 0.34621477127075195, train/logprobs = tensor([[-1.1626, -5.2407],
        [-1.6857, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37785136699676514
Epoch 0, Step 710: train/loss = 0.45209383964538574, train/raw-loss = 0.4243805706501007, train/logprobs = tensor([[-0.6927, -4.1959],
        [-0.9875, -0.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2771328389644623
Epoch 0, Step 711: train/loss = 0.5410555005073547, train/raw-loss = 0.5076396465301514, train/logprobs = tensor([[-0.7066, -2.7023],
        [-1.0071, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341584801673889
Epoch 0, Step 712: train/loss = 0.46499961614608765, train/raw-loss = 0.4349345862865448, train/logprobs = tensor([[-1.5456, -4.1289],
        [-1.4502, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3006502091884613
Epoch 0, Step 713: train/loss = 0.4822642207145691, train/raw-loss = 0.45388346910476685, train/logprobs = tensor([[-0.6559, -3.4774],
        [-0.8028, -1.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838081121444702
Epoch 0, Step 714: train/loss = 0.5470461249351501, train/raw-loss = 0.5122499465942383, train/logprobs = tensor([[-1.2388, -2.3019],
        [-1.6729, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479614853858948
Epoch 0, Step 715: train/loss = 0.3221401572227478, train/raw-loss = 0.2839113473892212, train/logprobs = tensor([[-1.2728, -4.1857],
        [-1.8751, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38228803873062134
Epoch 0, Step 716: train/loss = 0.4248875379562378, train/raw-loss = 0.3914695084095001, train/logprobs = tensor([[-0.8884, -2.6725],
        [-1.5750, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341800570487976
Epoch 0, Step 717: train/loss = 0.33977210521698, train/raw-loss = 0.30644339323043823, train/logprobs = tensor([[-1.2024, -4.3372],
        [-1.8324, -0.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332870304584503
Epoch 0, Step 718: train/loss = 0.46335071325302124, train/raw-loss = 0.4317174553871155, train/logprobs = tensor([[-0.6869, -2.9217],
        [-1.1197, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31633302569389343
Epoch 0, Step 719: train/loss = 0.4537592828273773, train/raw-loss = 0.416215181350708, train/logprobs = tensor([[-1.3688, -3.2574],
        [-2.1779, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754414916038513
Epoch 0, Step 720: train/loss = 0.35711294412612915, train/raw-loss = 0.3225659728050232, train/logprobs = tensor([[-0.9032, -6.5765],
        [-1.2662, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34546971321105957
Epoch 0, Step 721: train/loss = 0.733167290687561, train/raw-loss = 0.6988667249679565, train/logprobs = tensor([[-2.1336, -5.0488],
        [-1.5543, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430056571960449
Epoch 0, Step 722: train/loss = 0.7661851048469543, train/raw-loss = 0.7264593243598938, train/logprobs = tensor([[-2.6198, -4.0542],
        [-1.9724, -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972577154636383
Epoch 0, Step 723: train/loss = 0.2925502359867096, train/raw-loss = 0.2563896179199219, train/logprobs = tensor([[-1.0638, -4.7214],
        [-1.3658, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3616061210632324
Epoch 0, Step 724: train/loss = 0.7245767712593079, train/raw-loss = 0.6953749060630798, train/logprobs = tensor([[-1.7716, -2.3262],
        [-1.5209, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920186519622803
Epoch 0, Step 725: train/loss = 0.4488014578819275, train/raw-loss = 0.4106314778327942, train/logprobs = tensor([[-1.1826, -2.6092],
        [-2.2841, -1.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38169991970062256
Epoch 0, Step 726: train/loss = 0.4052260220050812, train/raw-loss = 0.3732272684574127, train/logprobs = tensor([[-0.8890, -4.6294],
        [-1.2731, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31998777389526367
Epoch 0, Step 727: train/loss = 0.4947352409362793, train/raw-loss = 0.45899033546447754, train/logprobs = tensor([[-1.0731, -4.4959],
        [-1.6318, -1.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35744932293891907
Epoch 0, Step 728: train/loss = 0.5862988233566284, train/raw-loss = 0.5511300563812256, train/logprobs = tensor([[-1.4648, -7.1512],
        [-1.3298, -1.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35168707370758057
Epoch 0, Step 729: train/loss = 0.5156236886978149, train/raw-loss = 0.4801511764526367, train/logprobs = tensor([[-1.3622, -2.8689],
        [-1.8027, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547249436378479
Epoch 0, Step 730: train/loss = 0.4493049085140228, train/raw-loss = 0.41798484325408936, train/logprobs = tensor([[-1.6610, -6.1020],
        [-1.6878, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132003843784332
Epoch 0, Step 731: train/loss = 0.37873411178588867, train/raw-loss = 0.3407897353172302, train/logprobs = tensor([[-1.1935, -6.9068],
        [-1.8851, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.379443883895874
Epoch 0, Step 732: train/loss = 0.29304784536361694, train/raw-loss = 0.26144492626190186, train/logprobs = tensor([[-0.9103, -6.9892],
        [-1.3558, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31602901220321655
Epoch 0, Step 733: train/loss = 0.5581766366958618, train/raw-loss = 0.5207817554473877, train/logprobs = tensor([[-1.6720, -2.7298],
        [-1.4839, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.373948872089386
Epoch 0, Step 734: train/loss = 0.5267935991287231, train/raw-loss = 0.4973645806312561, train/logprobs = tensor([[-0.9361, -3.3856],
        [-1.2541, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942904829978943
Epoch 0, Step 735: train/loss = 0.6175094842910767, train/raw-loss = 0.5871769189834595, train/logprobs = tensor([[-0.7232, -1.0596],
        [-0.8848, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033251166343689
Epoch 0, Step 736: train/loss = 0.5605415105819702, train/raw-loss = 0.5215629935264587, train/logprobs = tensor([[-1.4502, -3.8021],
        [-1.7941, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.389785498380661
Epoch 0, Step 737: train/loss = 0.5138209462165833, train/raw-loss = 0.4749089181423187, train/logprobs = tensor([[-1.7570, -2.9941],
        [-2.0423, -1.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38912007212638855
Epoch 0, Step 738: train/loss = 0.5502767562866211, train/raw-loss = 0.5173925757408142, train/logprobs = tensor([[-0.7203, -2.9907],
        [-1.5422, -1.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288416862487793
Epoch 0, Step 739: train/loss = 0.3528984785079956, train/raw-loss = 0.3133561909198761, train/logprobs = tensor([[-1.3157, -5.0972],
        [-1.8724, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3954227566719055
Epoch 0, Step 740: train/loss = 0.6382023096084595, train/raw-loss = 0.6078734993934631, train/logprobs = tensor([[-2.3384, -7.2970],
        [-1.1812, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30328741669654846
Epoch 0, Step 741: train/loss = 0.24754691123962402, train/raw-loss = 0.21178294718265533, train/logprobs = tensor([[-0.9358, -5.6577],
        [-1.6842, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35763975977897644
Epoch 0, Step 742: train/loss = 0.42083853483200073, train/raw-loss = 0.39051923155784607, train/logprobs = tensor([[-0.8646, -4.6779],
        [-1.2328, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031931221485138
Epoch 0, Step 743: train/loss = 0.45546168088912964, train/raw-loss = 0.42115622758865356, train/logprobs = tensor([[-1.1535, -4.2831],
        [-1.1025, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430543839931488
Epoch 0, Step 744: train/loss = 0.529676616191864, train/raw-loss = 0.4888266921043396, train/logprobs = tensor([[-2.7094, -7.1272],
        [-2.1041, -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40849927067756653
Epoch 0, Step 745: train/loss = 0.34490767121315, train/raw-loss = 0.308958500623703, train/logprobs = tensor([[-0.7722, -4.3357],
        [-2.1071, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3594916760921478
Epoch 0, Step 746: train/loss = 0.26652228832244873, train/raw-loss = 0.23457160592079163, train/logprobs = tensor([[-1.0986, -6.7337],
        [-1.4464, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31950661540031433
Epoch 0, Step 747: train/loss = 0.4790263772010803, train/raw-loss = 0.44643545150756836, train/logprobs = tensor([[-1.1051, -3.0420],
        [-1.6736, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32590973377227783
Epoch 0, Step 748: train/loss = 0.2384873628616333, train/raw-loss = 0.19371649622917175, train/logprobs = tensor([[-1.7856, -8.8324],
        [-3.0792, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44770878553390503
Epoch 0, Step 749: train/loss = 0.40089452266693115, train/raw-loss = 0.36609524488449097, train/logprobs = tensor([[-0.8594, -5.1308],
        [-1.7141, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479926288127899
Epoch 0, Step 750: train/loss = 0.3176109194755554, train/raw-loss = 0.28291141986846924, train/logprobs = tensor([[-0.9119, -7.2772],
        [-1.7684, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.346995085477829
Epoch 0, Step 751: train/loss = 0.18773901462554932, train/raw-loss = 0.15288466215133667, train/logprobs = tensor([[-0.7630, -6.8800],
        [-1.9355, -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34854355454444885
Epoch 0, Step 752: train/loss = 0.6050218343734741, train/raw-loss = 0.5673537254333496, train/logprobs = tensor([[-1.4377, -2.1332],
        [-1.2400, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3766815960407257
Epoch 0, Step 753: train/loss = 0.48734137415885925, train/raw-loss = 0.447279691696167, train/logprobs = tensor([[-1.0550, -2.5698],
        [-1.9643, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4006171226501465
Epoch 0, Step 754: train/loss = 0.5186999440193176, train/raw-loss = 0.4823228120803833, train/logprobs = tensor([[-0.9262, -2.8897],
        [-1.7548, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36377212405204773
Epoch 0, Step 755: train/loss = 0.5411403179168701, train/raw-loss = 0.5017384886741638, train/logprobs = tensor([[-1.8321, -6.8438],
        [-1.9921, -1.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3940177261829376
Epoch 0, Step 756: train/loss = 0.4944238066673279, train/raw-loss = 0.45535504817962646, train/logprobs = tensor([[-1.4740, -3.8796],
        [-1.6099, -1.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3906877040863037
Epoch 0, Step 757: train/loss = 0.3409191370010376, train/raw-loss = 0.29988592863082886, train/logprobs = tensor([[-1.2239, -3.8962],
        [-2.0501, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.410332053899765
Epoch 0, Step 758: train/loss = 0.3809385895729065, train/raw-loss = 0.35172930359840393, train/logprobs = tensor([[-0.7295, -7.5040],
        [-0.8536, -1.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292092889547348
Epoch 0, Step 759: train/loss = 0.3811267614364624, train/raw-loss = 0.3452281355857849, train/logprobs = tensor([[-0.8846, -2.7016],
        [-2.1655, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35898640751838684
Epoch 0, Step 760: train/loss = 0.26475024223327637, train/raw-loss = 0.22580328583717346, train/logprobs = tensor([[-1.0222, -4.4249],
        [-2.2689, -1.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894695043563843
Epoch 0, Step 761: train/loss = 0.6610531806945801, train/raw-loss = 0.6237919926643372, train/logprobs = tensor([[-1.0960, -1.7470],
        [-1.4339, -1.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37261173129081726
Epoch 0, Step 762: train/loss = 0.3854653537273407, train/raw-loss = 0.3566906750202179, train/logprobs = tensor([[-0.8759, -2.6829],
        [-1.6887, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877466082572937
Epoch 0, Step 763: train/loss = 0.6015653014183044, train/raw-loss = 0.5659001469612122, train/logprobs = tensor([[-0.7727, -1.3468],
        [-1.2141, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3566516935825348
Epoch 0, Step 764: train/loss = 0.47099900245666504, train/raw-loss = 0.43982675671577454, train/logprobs = tensor([[-1.3644, -2.7865],
        [-1.7538, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117225468158722
Epoch 0, Step 765: train/loss = 0.5540107488632202, train/raw-loss = 0.517346978187561, train/logprobs = tensor([[-1.3686, -2.4114],
        [-1.3987, -1.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36663752794265747
Epoch 0, Step 766: train/loss = 0.401563435792923, train/raw-loss = 0.36203083395957947, train/logprobs = tensor([[-1.1197, -6.7485],
        [-1.5530, -1.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39532575011253357
Epoch 0, Step 767: train/loss = 0.30374768376350403, train/raw-loss = 0.2708699703216553, train/logprobs = tensor([[-1.0679, -7.3938],
        [-1.8537, -2.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287769556045532
Epoch 0, Step 768: train/loss = 0.49748891592025757, train/raw-loss = 0.4541105329990387, train/logprobs = tensor([[-1.6213, -2.6026],
        [-1.9065, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337836503982544
Epoch 0, Step 769: train/loss = 0.2740728259086609, train/raw-loss = 0.23446695506572723, train/logprobs = tensor([[-1.3488, -5.2061],
        [-2.3607, -1.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39605867862701416
Epoch 0, Step 770: train/loss = 0.5617900490760803, train/raw-loss = 0.5262641310691833, train/logprobs = tensor([[-0.8186, -2.0929],
        [-1.4840, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3552595376968384
Epoch 0, Step 771: train/loss = 0.3322386145591736, train/raw-loss = 0.3011968731880188, train/logprobs = tensor([[-0.9684, -3.6562],
        [-1.6388, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3104172646999359
Epoch 0, Step 772: train/loss = 0.5152856111526489, train/raw-loss = 0.47289156913757324, train/logprobs = tensor([[-1.2688, -1.6360],
        [-2.3479, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4239407479763031
Epoch 0, Step 773: train/loss = 0.35120463371276855, train/raw-loss = 0.31389161944389343, train/logprobs = tensor([[-1.1585, -4.9072],
        [-2.0714, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37313002347946167
Epoch 0, Step 774: train/loss = 0.4092969298362732, train/raw-loss = 0.37262630462646484, train/logprobs = tensor([[-0.8081, -5.5141],
        [-1.4885, -2.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3667058050632477
Epoch 0, Step 775: train/loss = 0.5671526789665222, train/raw-loss = 0.5197376608848572, train/logprobs = tensor([[-0.9794, -2.0293],
        [-2.1251, -1.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4741508960723877
Epoch 0, Step 776: train/loss = 0.6548172831535339, train/raw-loss = 0.6266389489173889, train/logprobs = tensor([[-0.6290, -1.5329],
        [-1.3670, -1.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817823588848114
Epoch 0, Step 777: train/loss = 0.4419417381286621, train/raw-loss = 0.4002169668674469, train/logprobs = tensor([[-1.3591, -2.4985],
        [-2.1833, -1.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41724735498428345
Epoch 0, Step 778: train/loss = 0.264450341463089, train/raw-loss = 0.22734567523002625, train/logprobs = tensor([[-1.1014, -6.6858],
        [-2.9192, -1.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3710465729236603
Epoch 0, Step 779: train/loss = 0.6754865646362305, train/raw-loss = 0.644684374332428, train/logprobs = tensor([[-0.6763, -0.8056],
        [-0.9497, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308021605014801
Epoch 0, Step 780: train/loss = 0.4943007826805115, train/raw-loss = 0.46724915504455566, train/logprobs = tensor([[-0.8218, -2.2558],
        [-0.9556, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705160975456238
Epoch 0, Step 781: train/loss = 0.5174753665924072, train/raw-loss = 0.4835265874862671, train/logprobs = tensor([[-1.2817, -5.7960],
        [-1.4997, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3394884765148163
Epoch 0, Step 782: train/loss = 0.3974069356918335, train/raw-loss = 0.35375913977622986, train/logprobs = tensor([[-1.7792, -7.9834],
        [-2.6555, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4364778399467468
Epoch 0, Step 783: train/loss = 0.35536906123161316, train/raw-loss = 0.3207619786262512, train/logprobs = tensor([[-0.8152, -4.4849],
        [-1.9261, -1.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34607064723968506
Epoch 0, Step 784: train/loss = 0.5093398690223694, train/raw-loss = 0.4758162498474121, train/logprobs = tensor([[-1.4805, -2.3232],
        [-1.7430, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33523643016815186
Epoch 0, Step 785: train/loss = 0.3133350908756256, train/raw-loss = 0.2754862904548645, train/logprobs = tensor([[-0.9429, -5.3198],
        [-1.7546, -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784885108470917
Epoch 0, Step 786: train/loss = 1.6041845083236694, train/raw-loss = 1.5669410228729248, train/logprobs = tensor([[-4.2398, -5.2479],
        [-2.0377, -1.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37243467569351196
Epoch 0, Step 787: train/loss = 0.4448546767234802, train/raw-loss = 0.40810626745224, train/logprobs = tensor([[-1.5408, -5.5055],
        [-1.6485, -0.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.367483913898468
Epoch 0, Step 788: train/loss = 0.4773274064064026, train/raw-loss = 0.43843138217926025, train/logprobs = tensor([[-0.9059, -2.1765],
        [-2.3021, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3889603018760681
Epoch 0, Step 789: train/loss = 0.7915821671485901, train/raw-loss = 0.7558719515800476, train/logprobs = tensor([[-3.2433, -5.7245],
        [-1.9557, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3571012616157532
Epoch 0, Step 790: train/loss = 0.7228372693061829, train/raw-loss = 0.6857991814613342, train/logprobs = tensor([[-2.2149, -4.5824],
        [-1.4033, -0.8486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37038084864616394
Epoch 0, Step 791: train/loss = 0.364271342754364, train/raw-loss = 0.3271324634552002, train/logprobs = tensor([[-1.2124, -4.0744],
        [-2.1824, -1.6311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37138864398002625
Epoch 0, Step 792: train/loss = 1.330456018447876, train/raw-loss = 1.2966402769088745, train/logprobs = tensor([[-4.8471, -6.8584],
        [-2.0240, -1.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381568193435669
Epoch 0, Step 793: train/loss = 0.663874089717865, train/raw-loss = 0.6284872889518738, train/logprobs = tensor([[-2.4502, -3.0623],
        [-1.6309, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35386818647384644
Epoch 0, Step 794: train/loss = 0.2838740944862366, train/raw-loss = 0.24929934740066528, train/logprobs = tensor([[-0.6119, -4.3188],
        [-1.6606, -2.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.345747172832489
Epoch 0, Step 795: train/loss = 0.36858415603637695, train/raw-loss = 0.3283748924732208, train/logprobs = tensor([[-1.4413, -4.6426],
        [-2.0219, -1.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4020928740501404
Epoch 0, Step 796: train/loss = 0.2360677719116211, train/raw-loss = 0.19257153570652008, train/logprobs = tensor([[-1.2902, -5.2291],
        [-2.8762, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43496233224868774
Epoch 0, Step 797: train/loss = 0.6836287975311279, train/raw-loss = 0.6501185297966003, train/logprobs = tensor([[-1.0473, -1.5465],
        [-1.5210, -1.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351024091243744
Epoch 0, Step 798: train/loss = 0.371573269367218, train/raw-loss = 0.3314279317855835, train/logprobs = tensor([[-1.0930, -5.3316],
        [-1.9845, -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40145304799079895
Epoch 0, Step 799: train/loss = 0.42783015966415405, train/raw-loss = 0.39279651641845703, train/logprobs = tensor([[-0.9178, -4.3143],
        [-1.7027, -0.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350336492061615
Epoch 0, Step 800: train/loss = 0.4453986883163452, train/raw-loss = 0.4115726053714752, train/logprobs = tensor([[-1.1577, -5.8102],
        [-1.3557, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382607400417328
Epoch 0, Step 801: train/loss = 0.4246020019054413, train/raw-loss = 0.3894907236099243, train/logprobs = tensor([[-0.6724, -4.4801],
        [-1.9337, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3511126935482025
Epoch 0, Step 802: train/loss = 0.5756598711013794, train/raw-loss = 0.5456799268722534, train/logprobs = tensor([[-0.6940, -1.1905],
        [-1.5828, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2997998595237732
Epoch 0, Step 803: train/loss = 0.7962253093719482, train/raw-loss = 0.7625564336776733, train/logprobs = tensor([[-1.8524, -3.5333],
        [-0.8513, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33668866753578186
Epoch 0, Step 804: train/loss = 0.4883255660533905, train/raw-loss = 0.44604364037513733, train/logprobs = tensor([[-1.0282, -1.9644],
        [-2.2524, -1.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42281901836395264
Epoch 0, Step 805: train/loss = 0.47938477993011475, train/raw-loss = 0.43825626373291016, train/logprobs = tensor([[-0.9503, -2.0752],
        [-2.0916, -1.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112849533557892
Epoch 0, Step 806: train/loss = 0.41826295852661133, train/raw-loss = 0.38607388734817505, train/logprobs = tensor([[-0.7770, -2.4412],
        [-1.8466, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32189083099365234
Epoch 0, Step 807: train/loss = 0.548999011516571, train/raw-loss = 0.5172484517097473, train/logprobs = tensor([[-0.7907, -2.2893],
        [-1.3554, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175051808357239
Epoch 0, Step 808: train/loss = 0.2914416193962097, train/raw-loss = 0.2499331533908844, train/logprobs = tensor([[-1.1601, -4.4239],
        [-2.8357, -2.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4150847792625427
Epoch 0, Step 809: train/loss = 0.6514788866043091, train/raw-loss = 0.6195107698440552, train/logprobs = tensor([[-1.2263, -1.6683],
        [-1.0915, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31968122720718384
Epoch 0, Step 810: train/loss = 0.2280661165714264, train/raw-loss = 0.18946537375450134, train/logprobs = tensor([[-0.6511, -5.4363],
        [-2.6160, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3860073685646057
Epoch 0, Step 811: train/loss = 0.6501073837280273, train/raw-loss = 0.609978973865509, train/logprobs = tensor([[-1.0610, -1.2203],
        [-2.4120, -1.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.401284396648407
Epoch 0, Step 812: train/loss = 0.4364337921142578, train/raw-loss = 0.39890816807746887, train/logprobs = tensor([[-1.5750, -5.3133],
        [-1.7848, -1.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37525612115859985
Epoch 0, Step 813: train/loss = 0.2025209367275238, train/raw-loss = 0.16090449690818787, train/logprobs = tensor([[-1.4181, -9.7469],
        [-2.5383, -0.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4161643385887146
Epoch 0, Step 814: train/loss = 0.49560725688934326, train/raw-loss = 0.4506828784942627, train/logprobs = tensor([[-1.4232, -5.2524],
        [-3.2041, -1.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44924402236938477
Epoch 0, Step 815: train/loss = 0.5948489308357239, train/raw-loss = 0.554322361946106, train/logprobs = tensor([[-0.7618, -1.4989],
        [-1.8310, -1.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4052654504776001
Epoch 0, Step 816: train/loss = 0.782632052898407, train/raw-loss = 0.7415766716003418, train/logprobs = tensor([[-2.7544, -5.5268],
        [-1.7924, -1.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105534255504608
Epoch 0, Step 817: train/loss = 0.47327467799186707, train/raw-loss = 0.434256911277771, train/logprobs = tensor([[-0.9896, -2.4484],
        [-1.7180, -1.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39017778635025024
Epoch 0, Step 818: train/loss = 0.37189847230911255, train/raw-loss = 0.33289211988449097, train/logprobs = tensor([[-1.0955, -4.2823],
        [-2.4090, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3900635838508606
Epoch 0, Step 819: train/loss = 0.40025758743286133, train/raw-loss = 0.36813870072364807, train/logprobs = tensor([[-1.1248, -3.7668],
        [-1.9623, -2.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32118892669677734
Epoch 0, Step 820: train/loss = 0.6074899435043335, train/raw-loss = 0.5683112740516663, train/logprobs = tensor([[-1.5106, -4.1739],
        [-1.9524, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917872905731201
Epoch 0, Step 821: train/loss = 0.9595246911048889, train/raw-loss = 0.9227433800697327, train/logprobs = tensor([[-2.5391, -2.3629],
        [-2.0626, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36781373620033264
Epoch 0, Step 822: train/loss = 0.823786735534668, train/raw-loss = 0.7881994843482971, train/logprobs = tensor([[-1.3183, -1.2722],
        [-1.3822, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3558729290962219
Epoch 0, Step 823: train/loss = 0.3234800100326538, train/raw-loss = 0.2929326891899109, train/logprobs = tensor([[-0.4912, -4.0820],
        [-1.6317, -1.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054729104042053
Epoch 0, Step 824: train/loss = 0.3793962597846985, train/raw-loss = 0.33713680505752563, train/logprobs = tensor([[-1.1368, -3.0150],
        [-2.1129, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4225943684577942
Epoch 0, Step 825: train/loss = 0.48390159010887146, train/raw-loss = 0.4433625340461731, train/logprobs = tensor([[-0.9981, -1.9536],
        [-1.8868, -1.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4053904414176941
Epoch 0, Step 826: train/loss = 0.5633237957954407, train/raw-loss = 0.5315320491790771, train/logprobs = tensor([[-0.7030, -3.9416],
        [-1.9320, -2.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179183900356293
Epoch 0, Step 827: train/loss = 0.49786296486854553, train/raw-loss = 0.4567590355873108, train/logprobs = tensor([[-0.7836, -3.9293],
        [-2.0680, -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4110392928123474
Epoch 0, Step 828: train/loss = 0.6645463705062866, train/raw-loss = 0.632239580154419, train/logprobs = tensor([[-1.3388, -3.0099],
        [-0.7847, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323068231344223
Epoch 0, Step 829: train/loss = 0.27351129055023193, train/raw-loss = 0.23525747656822205, train/logprobs = tensor([[-1.3501, -9.0324],
        [-2.9683, -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38253816962242126
Epoch 0, Step 830: train/loss = 0.5059323906898499, train/raw-loss = 0.4646375775337219, train/logprobs = tensor([[-1.1047, -6.6486],
        [-2.0889, -2.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4129484295845032
Epoch 0, Step 831: train/loss = 0.3119123578071594, train/raw-loss = 0.27479124069213867, train/logprobs = tensor([[-0.7899, -3.6792],
        [-2.0173, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37121137976646423
Epoch 0, Step 832: train/loss = 0.553710401058197, train/raw-loss = 0.5142436623573303, train/logprobs = tensor([[-0.9264, -5.2001],
        [-2.8169, -1.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946678936481476
Epoch 0, Step 833: train/loss = 0.6005112528800964, train/raw-loss = 0.5614812970161438, train/logprobs = tensor([[-0.9905, -2.7257],
        [-2.0899, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39029937982559204
Epoch 0, Step 834: train/loss = 0.7359801530838013, train/raw-loss = 0.6951506733894348, train/logprobs = tensor([[-3.1080, -8.2687],
        [-2.3863, -0.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4082948565483093
Epoch 0, Step 835: train/loss = 0.2661309540271759, train/raw-loss = 0.22543957829475403, train/logprobs = tensor([[-2.0714, -7.9846],
        [-2.7352, -1.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069139063358307
Epoch 0, Step 836: train/loss = 0.4224667251110077, train/raw-loss = 0.38748249411582947, train/logprobs = tensor([[-1.1360, -5.3456],
        [-2.3377, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34984225034713745
Epoch 0, Step 837: train/loss = 0.439936101436615, train/raw-loss = 0.40024814009666443, train/logprobs = tensor([[-1.3933, -4.0770],
        [-2.7020, -2.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3968791961669922
Epoch 0, Step 838: train/loss = 0.10200231522321701, train/raw-loss = 0.05270963907241821, train/logprobs = tensor([[-1.1678, -8.8438],
        [-3.7113, -2.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4929266571998596
Epoch 0, Step 839: train/loss = 0.6389440298080444, train/raw-loss = 0.603135883808136, train/logprobs = tensor([[-2.5158, -4.9753],
        [-2.5336, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580819070339203
Epoch 0, Step 840: train/loss = 0.3445644974708557, train/raw-loss = 0.3030455708503723, train/logprobs = tensor([[-1.7652, -4.8725],
        [-3.1052, -1.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41518929600715637
Epoch 0, Step 841: train/loss = 0.30683332681655884, train/raw-loss = 0.26589056849479675, train/logprobs = tensor([[-0.8103, -4.7674],
        [-2.1585, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40942782163619995
Epoch 0, Step 842: train/loss = 0.7381693124771118, train/raw-loss = 0.6974407434463501, train/logprobs = tensor([[-0.8032, -2.8503],
        [-2.2503, -2.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40728622674942017
Epoch 0, Step 843: train/loss = 0.2091478556394577, train/raw-loss = 0.17029716074466705, train/logprobs = tensor([[-1.0763, -5.7221],
        [-2.9946, -1.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885069489479065
Epoch 0, Step 844: train/loss = 0.42982232570648193, train/raw-loss = 0.39040449261665344, train/logprobs = tensor([[-0.7871, -3.1832],
        [-2.2848, -1.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39417821168899536
Epoch 0, Step 845: train/loss = 0.4802801012992859, train/raw-loss = 0.4360957145690918, train/logprobs = tensor([[-0.6745, -5.3854],
        [-2.5914, -1.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44184401631355286
Epoch 0, Step 846: train/loss = 0.19169113039970398, train/raw-loss = 0.14639145135879517, train/logprobs = tensor([[-1.5726, -7.0928],
        [-3.4235, -2.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45299679040908813
Epoch 0, Step 847: train/loss = 0.6022428870201111, train/raw-loss = 0.5600864887237549, train/logprobs = tensor([[-1.1771, -4.5553],
        [-1.8059, -3.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215635061264038
Epoch 0, Step 848: train/loss = 0.6762043833732605, train/raw-loss = 0.6301369667053223, train/logprobs = tensor([[-0.8621, -3.0860],
        [-2.7747, -2.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.460673987865448
Epoch 0, Step 849: train/loss = 0.44794169068336487, train/raw-loss = 0.40731680393218994, train/logprobs = tensor([[-0.9184, -3.3820],
        [-2.7570, -1.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4062487483024597
Epoch 0, Step 850: train/loss = 0.27411749958992004, train/raw-loss = 0.23895971477031708, train/logprobs = tensor([[-0.6451, -3.2800],
        [-2.3020, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3515777587890625
Epoch 0, Step 851: train/loss = 0.32622718811035156, train/raw-loss = 0.2881535291671753, train/logprobs = tensor([[-0.9354, -5.7365],
        [-2.0184, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807365894317627
Epoch 0, Step 852: train/loss = 0.3806320130825043, train/raw-loss = 0.3334425091743469, train/logprobs = tensor([[-1.2329, -5.5826],
        [-3.1282, -1.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47189491987228394
Epoch 0, Step 853: train/loss = 0.32236620783805847, train/raw-loss = 0.27868932485580444, train/logprobs = tensor([[-1.1720, -4.3371],
        [-2.5910, -1.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4367688000202179
Epoch 0, Step 854: train/loss = 0.31046944856643677, train/raw-loss = 0.2743987441062927, train/logprobs = tensor([[-0.6007, -5.5524],
        [-2.2219, -1.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36070695519447327
Epoch 0, Step 855: train/loss = 0.4104602336883545, train/raw-loss = 0.3731478452682495, train/logprobs = tensor([[-1.2856, -5.0541],
        [-2.2039, -1.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731237053871155
Epoch 0, Step 856: train/loss = 0.36495867371559143, train/raw-loss = 0.3200370967388153, train/logprobs = tensor([[-2.4768, -6.4881],
        [-3.7171, -2.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4492156505584717
Epoch 0, Step 857: train/loss = 0.6089577674865723, train/raw-loss = 0.5714083313941956, train/logprobs = tensor([[-1.8924, -3.0300],
        [-1.9891, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754943013191223
Epoch 0, Step 858: train/loss = 0.3191409409046173, train/raw-loss = 0.2760027348995209, train/logprobs = tensor([[-1.4552, -5.5402],
        [-2.7917, -2.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43138208985328674
Epoch 0, Step 859: train/loss = 0.32184475660324097, train/raw-loss = 0.28422489762306213, train/logprobs = tensor([[-1.1918, -7.1901],
        [-2.4133, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37619873881340027
Epoch 0, Step 860: train/loss = 0.7369469404220581, train/raw-loss = 0.686144232749939, train/logprobs = tensor([[-0.8170, -2.6810],
        [-2.7656, -2.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5080264806747437
Epoch 0, Step 861: train/loss = 0.36315497756004333, train/raw-loss = 0.31792736053466797, train/logprobs = tensor([[-1.9243, -4.6768],
        [-3.0708, -2.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522763788700104
Epoch 0, Step 862: train/loss = 0.39176541566848755, train/raw-loss = 0.34875571727752686, train/logprobs = tensor([[-1.2072, -6.6186],
        [-2.4952, -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4300967752933502
Epoch 0, Step 863: train/loss = 0.3247987627983093, train/raw-loss = 0.28102582693099976, train/logprobs = tensor([[-1.1776, -3.6528],
        [-2.9338, -2.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4377293884754181
Epoch 0, Step 864: train/loss = 0.7753061056137085, train/raw-loss = 0.7282124757766724, train/logprobs = tensor([[-0.8939, -1.1590],
        [-3.5699, -2.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47093603014945984
Epoch 0, Step 865: train/loss = 0.28742730617523193, train/raw-loss = 0.2536390721797943, train/logprobs = tensor([[-0.8161, -4.8725],
        [-2.2635, -1.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378826379776001
Epoch 0, Step 866: train/loss = 0.09082403779029846, train/raw-loss = 0.04063290357589722, train/logprobs = tensor([[-1.0951, -7.2401],
        [-4.2105, -1.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5019114017486572
Epoch 0, Step 867: train/loss = 0.631014347076416, train/raw-loss = 0.5924805998802185, train/logprobs = tensor([[-0.4808, -3.1989],
        [-1.6085, -1.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3853375315666199
Epoch 0, Step 868: train/loss = 0.5482064485549927, train/raw-loss = 0.5120567083358765, train/logprobs = tensor([[-1.4251, -3.0896],
        [-3.1545, -2.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36149701476097107
Epoch 0, Step 869: train/loss = 0.28654056787490845, train/raw-loss = 0.24817915260791779, train/logprobs = tensor([[-1.3047, -4.6128],
        [-2.6120, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836140036582947
Epoch 0, Step 870: train/loss = 0.12944823503494263, train/raw-loss = 0.07760089635848999, train/logprobs = tensor([[ -1.9223, -10.4184],
        [ -4.7164,  -2.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5184734463691711
Epoch 0, Step 871: train/loss = 0.43822166323661804, train/raw-loss = 0.3981933295726776, train/logprobs = tensor([[-1.2455, -4.4822],
        [-2.2686, -1.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.400283545255661
Epoch 0, Step 872: train/loss = 0.8969710469245911, train/raw-loss = 0.8570330739021301, train/logprobs = tensor([[-0.9586, -4.9889],
        [-2.0089, -3.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3993801772594452
Epoch 0, Step 873: train/loss = 0.5636058449745178, train/raw-loss = 0.5105031132698059, train/logprobs = tensor([[-2.0364, -4.4382],
        [-3.1162, -1.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5310274362564087
Epoch 0, Step 874: train/loss = 0.4793332517147064, train/raw-loss = 0.4361296594142914, train/logprobs = tensor([[-1.1894, -5.2579],
        [-3.2206, -1.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43203604221343994
Epoch 0, Step 875: train/loss = 0.5196360945701599, train/raw-loss = 0.4729336202144623, train/logprobs = tensor([[-1.5650, -3.8500],
        [-2.9400, -2.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4670243263244629
Epoch 0, Step 876: train/loss = 0.47258633375167847, train/raw-loss = 0.4184345602989197, train/logprobs = tensor([[-2.3682, -4.7678],
        [-3.9974, -3.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5415179133415222
Epoch 0, Step 877: train/loss = 0.17840710282325745, train/raw-loss = 0.13456714153289795, train/logprobs = tensor([[-1.4412, -6.5481],
        [-3.6329, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4383995532989502
Epoch 0, Step 878: train/loss = 0.2737104296684265, train/raw-loss = 0.2239474356174469, train/logprobs = tensor([[-1.4872, -7.5511],
        [-3.4160, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4976297616958618
Epoch 0, Step 879: train/loss = 0.3287453353404999, train/raw-loss = 0.2773306369781494, train/logprobs = tensor([[-2.1617, -3.2664],
        [-5.1665, -2.0802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141472816467285
Epoch 0, Step 880: train/loss = 0.4923906624317169, train/raw-loss = 0.44799065589904785, train/logprobs = tensor([[-1.6959, -3.2452],
        [-2.5437, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443999707698822
Epoch 0, Step 881: train/loss = 0.3759342133998871, train/raw-loss = 0.3309621214866638, train/logprobs = tensor([[-1.0931, -5.7230],
        [-3.7036, -2.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4497207999229431
Epoch 0, Step 882: train/loss = 0.44093334674835205, train/raw-loss = 0.404899924993515, train/logprobs = tensor([[-0.9361, -5.7337],
        [-2.9462, -2.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36033427715301514
Epoch 0, Step 883: train/loss = 0.6289353370666504, train/raw-loss = 0.582334041595459, train/logprobs = tensor([[-3.5468, -9.5682],
        [-3.8946, -1.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660130739212036
Epoch 0, Step 884: train/loss = 0.6738014817237854, train/raw-loss = 0.6299797892570496, train/logprobs = tensor([[-2.1782, -4.5692],
        [-2.6623, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4382169842720032
Epoch 0, Step 885: train/loss = 0.48985975980758667, train/raw-loss = 0.4558904767036438, train/logprobs = tensor([[-0.6472, -3.9584],
        [-1.9098, -2.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396929204463959
Epoch 0, Step 886: train/loss = 0.3610300123691559, train/raw-loss = 0.322625994682312, train/logprobs = tensor([[-1.0321, -3.8014],
        [-1.5460, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840402364730835
Epoch 0, Step 887: train/loss = 0.2823343276977539, train/raw-loss = 0.241587296128273, train/logprobs = tensor([[-1.3577, -7.1719],
        [-3.1503, -1.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4074704647064209
Epoch 0, Step 888: train/loss = 0.3574869632720947, train/raw-loss = 0.311053603887558, train/logprobs = tensor([[-1.2482, -5.6208],
        [-3.6113, -2.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46433356404304504
Epoch 0, Step 889: train/loss = 0.133154958486557, train/raw-loss = 0.09502235800027847, train/logprobs = tensor([[-0.9143, -9.5552],
        [-3.2111, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3813260793685913
Epoch 0, Step 890: train/loss = 0.33522316813468933, train/raw-loss = 0.294685035943985, train/logprobs = tensor([[-1.5586, -7.4649],
        [-2.8043, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40538108348846436
Epoch 0, Step 891: train/loss = 0.5232417583465576, train/raw-loss = 0.47618064284324646, train/logprobs = tensor([[-1.5782, -4.2867],
        [-3.3795, -2.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4706113636493683
Epoch 0, Step 892: train/loss = 0.13166524469852448, train/raw-loss = 0.09612935781478882, train/logprobs = tensor([[-0.9143, -6.4533],
        [-3.2166, -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35535886883735657
Epoch 0, Step 893: train/loss = 1.1369175910949707, train/raw-loss = 1.103527545928955, train/logprobs = tensor([[-2.0353, -4.9117],
        [-0.9061, -1.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339010179042816
Epoch 0, Step 894: train/loss = 0.4003801941871643, train/raw-loss = 0.35903745889663696, train/logprobs = tensor([[-1.4687, -3.8552],
        [-2.1664, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4134274125099182
Epoch 0, Step 895: train/loss = 0.7619994878768921, train/raw-loss = 0.7159028053283691, train/logprobs = tensor([[-1.6740, -5.6179],
        [-2.3698, -2.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4609665274620056
Epoch 0, Step 896: train/loss = 0.6046361327171326, train/raw-loss = 0.5573786497116089, train/logprobs = tensor([[-0.7242, -2.0946],
        [-2.4899, -2.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4725743532180786
Epoch 0, Step 897: train/loss = 0.2540469765663147, train/raw-loss = 0.2166443020105362, train/logprobs = tensor([[-0.9927, -5.3783],
        [-2.2169, -2.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3740266263484955
Epoch 0, Step 898: train/loss = 0.5823162794113159, train/raw-loss = 0.5426809787750244, train/logprobs = tensor([[-1.0459, -3.0020],
        [-2.0585, -2.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39635366201400757
Epoch 0, Step 899: train/loss = 0.5393028259277344, train/raw-loss = 0.4937242865562439, train/logprobs = tensor([[-1.4894, -3.5041],
        [-3.6443, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4557856619358063
Epoch 0, Step 900: train/loss = 0.46630722284317017, train/raw-loss = 0.42726442217826843, train/logprobs = tensor([[-2.3010, -4.8511],
        [-2.7057, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390428364276886
Epoch 0, Step 901: train/loss = 0.40199515223503113, train/raw-loss = 0.35510721802711487, train/logprobs = tensor([[-1.4219, -2.7876],
        [-3.4064, -2.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4688792824745178
Epoch 0, Step 902: train/loss = 0.3750098943710327, train/raw-loss = 0.329922616481781, train/logprobs = tensor([[-1.4906, -5.7424],
        [-3.0078, -1.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45087265968322754
Epoch 0, Step 903: train/loss = 0.27078068256378174, train/raw-loss = 0.22809158265590668, train/logprobs = tensor([[-1.5971, -7.9362],
        [-3.5243, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42689111828804016
Epoch 0, Step 904: train/loss = 0.5467017889022827, train/raw-loss = 0.5100813508033752, train/logprobs = tensor([[-1.0401, -2.1132],
        [-2.1970, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3662045896053314
Epoch 0, Step 905: train/loss = 0.3567044734954834, train/raw-loss = 0.31613394618034363, train/logprobs = tensor([[-2.0619, -4.0790],
        [-2.9042, -1.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4057050347328186
Epoch 0, Step 906: train/loss = 0.22474868595600128, train/raw-loss = 0.18218621611595154, train/logprobs = tensor([[-1.6626, -6.6489],
        [-3.7013, -1.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4256246089935303
Epoch 0, Step 907: train/loss = 0.8505033254623413, train/raw-loss = 0.8134857416152954, train/logprobs = tensor([[-1.1672, -1.3377],
        [-1.4744, -1.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701747953891754
Epoch 0, Step 908: train/loss = 0.5848389267921448, train/raw-loss = 0.5358152389526367, train/logprobs = tensor([[-1.1393, -2.4936],
        [-3.4776, -3.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49023643136024475
Epoch 0, Step 909: train/loss = 0.508273720741272, train/raw-loss = 0.46681660413742065, train/logprobs = tensor([[-1.2117, -3.5983],
        [-2.8661, -2.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41457146406173706
Epoch 0, Step 910: train/loss = 0.4032667875289917, train/raw-loss = 0.36897510290145874, train/logprobs = tensor([[-0.9215, -1.6617],
        [-2.7538, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429167866706848
Epoch 0, Step 911: train/loss = 0.2500077486038208, train/raw-loss = 0.207225501537323, train/logprobs = tensor([[-1.7501, -5.6972],
        [-3.1377, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42782244086265564
Epoch 0, Step 912: train/loss = 0.5114479660987854, train/raw-loss = 0.471081018447876, train/logprobs = tensor([[-1.2934, -2.3578],
        [-2.2380, -2.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036695957183838
Epoch 0, Step 913: train/loss = 0.5298379063606262, train/raw-loss = 0.4826586842536926, train/logprobs = tensor([[-1.3543, -3.0454],
        [-3.3593, -2.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47179216146469116
Epoch 0, Step 914: train/loss = 0.337535560131073, train/raw-loss = 0.29847878217697144, train/logprobs = tensor([[-1.4918, -3.6061],
        [-2.9131, -2.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390567809343338
Epoch 0, Step 915: train/loss = 0.6228132843971252, train/raw-loss = 0.5708362460136414, train/logprobs = tensor([[-1.2719, -4.2030],
        [-3.9497, -2.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5197705030441284
Epoch 0, Step 916: train/loss = 0.6090393662452698, train/raw-loss = 0.5665125250816345, train/logprobs = tensor([[-0.6116, -0.7856],
        [-1.8752, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4252689480781555
Epoch 0, Step 917: train/loss = 0.5953251123428345, train/raw-loss = 0.5553632974624634, train/logprobs = tensor([[-0.7175, -2.3299],
        [-1.4714, -1.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39961862564086914
Epoch 0, Step 918: train/loss = 0.6203733682632446, train/raw-loss = 0.5820642709732056, train/logprobs = tensor([[-0.8711, -4.7016],
        [-1.8980, -3.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830910921096802
Epoch 0, Step 919: train/loss = 0.26687371730804443, train/raw-loss = 0.2174571007490158, train/logprobs = tensor([[-1.2537, -7.8576],
        [-3.9440, -2.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4941663146018982
Epoch 0, Step 920: train/loss = 0.46513065695762634, train/raw-loss = 0.42427173256874084, train/logprobs = tensor([[-0.7777, -3.8933],
        [-2.4741, -3.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40858906507492065
Epoch 0, Step 921: train/loss = 0.2834838330745697, train/raw-loss = 0.24022871255874634, train/logprobs = tensor([[-1.1199, -7.4729],
        [-2.9871, -2.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4325510263442993
Epoch 0, Step 922: train/loss = 0.9037420153617859, train/raw-loss = 0.8716470003128052, train/logprobs = tensor([[-0.5077, -2.3951],
        [-0.9656, -1.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32095083594322205
Epoch 0, Step 923: train/loss = 0.5803484320640564, train/raw-loss = 0.5404444336891174, train/logprobs = tensor([[-1.2115, -2.6643],
        [-2.3498, -2.2015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990398347377777
Epoch 0, Step 924: train/loss = 0.7070380449295044, train/raw-loss = 0.6552846431732178, train/logprobs = tensor([[-3.2712, -3.8093],
        [-3.3146, -2.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5175338983535767
Epoch 0, Step 925: train/loss = 0.623866081237793, train/raw-loss = 0.5820402503013611, train/logprobs = tensor([[-1.0224, -2.2282],
        [-2.6524, -1.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41825875639915466
Epoch 0, Step 926: train/loss = 0.40274983644485474, train/raw-loss = 0.35404732823371887, train/logprobs = tensor([[-1.1939, -4.1548],
        [-3.1586, -2.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4870252013206482
Epoch 0, Step 927: train/loss = 0.37194764614105225, train/raw-loss = 0.3243024945259094, train/logprobs = tensor([[-1.4416, -3.4975],
        [-3.2330, -2.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4764511287212372
Epoch 0, Step 928: train/loss = 0.4122936725616455, train/raw-loss = 0.37556159496307373, train/logprobs = tensor([[-1.1633, -3.3233],
        [-2.4727, -1.0294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3673211634159088
Epoch 0, Step 929: train/loss = 0.15037691593170166, train/raw-loss = 0.09797734767198563, train/logprobs = tensor([[-0.8103, -6.0967],
        [-3.8674, -2.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523995578289032
Epoch 0, Step 930: train/loss = 0.4574301540851593, train/raw-loss = 0.4168790876865387, train/logprobs = tensor([[-1.2237, -3.0250],
        [-2.6178, -1.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4055105447769165
Epoch 0, Step 931: train/loss = 0.19851553440093994, train/raw-loss = 0.14853961765766144, train/logprobs = tensor([[-1.8186, -6.7353],
        [-4.1736, -1.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4997592568397522
Epoch 0, Step 932: train/loss = 0.1331002116203308, train/raw-loss = 0.0950215756893158, train/logprobs = tensor([[-0.8115, -8.0846],
        [-2.4980, -1.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807862401008606
Epoch 0, Step 933: train/loss = 0.26153844594955444, train/raw-loss = 0.22740969061851501, train/logprobs = tensor([[-0.9529, -5.5545],
        [-2.5105, -1.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3412875235080719
Epoch 0, Step 934: train/loss = 0.3193422555923462, train/raw-loss = 0.28593429923057556, train/logprobs = tensor([[-1.1069, -8.6893],
        [-2.3104, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33407941460609436
Epoch 0, Step 935: train/loss = 0.6473448276519775, train/raw-loss = 0.6024959087371826, train/logprobs = tensor([[-2.7941, -7.0251],
        [-3.1193, -2.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44848883152008057
Epoch 0, Step 936: train/loss = 0.4863467216491699, train/raw-loss = 0.4364762306213379, train/logprobs = tensor([[-1.0741, -3.1656],
        [-2.3211, -1.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49870485067367554
Epoch 0, Step 937: train/loss = 0.23114341497421265, train/raw-loss = 0.18129798769950867, train/logprobs = tensor([[-2.2859, -5.2072],
        [-4.5097, -2.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49845433235168457
Epoch 0, Step 938: train/loss = 0.22843562066555023, train/raw-loss = 0.1893429160118103, train/logprobs = tensor([[-1.7424, -9.0695],
        [-3.0442, -2.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3909270465373993
Epoch 0, Step 939: train/loss = 0.6614667177200317, train/raw-loss = 0.6089315414428711, train/logprobs = tensor([[-2.4065, -5.9720],
        [-2.3014, -2.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5253510475158691
Epoch 0, Step 940: train/loss = 0.40538644790649414, train/raw-loss = 0.3636268377304077, train/logprobs = tensor([[-1.6421, -4.1293],
        [-2.6593, -1.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175961911678314
Epoch 0, Step 941: train/loss = 0.16617697477340698, train/raw-loss = 0.11836343258619308, train/logprobs = tensor([[-1.4933, -6.2813],
        [-3.6791, -1.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47813543677330017
Epoch 0, Step 942: train/loss = 0.45726364850997925, train/raw-loss = 0.4175387918949127, train/logprobs = tensor([[-0.9472, -3.5470],
        [-2.8468, -1.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972485661506653
Epoch 0, Step 943: train/loss = 0.2786312699317932, train/raw-loss = 0.23138143122196198, train/logprobs = tensor([[-1.4869, -5.8326],
        [-4.2450, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4724983870983124
Epoch 0, Step 944: train/loss = 0.28217947483062744, train/raw-loss = 0.23796479403972626, train/logprobs = tensor([[-1.2645, -4.1544],
        [-2.8622, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44214683771133423
Epoch 0, Step 945: train/loss = 0.23810110986232758, train/raw-loss = 0.2022295892238617, train/logprobs = tensor([[-1.5467, -7.4560],
        [-3.1456, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587152063846588
Epoch 0, Step 946: train/loss = 0.4273689389228821, train/raw-loss = 0.3779935836791992, train/logprobs = tensor([[-1.7005, -7.7248],
        [-3.2821, -2.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49375325441360474
Epoch 0, Step 947: train/loss = 0.14237600564956665, train/raw-loss = 0.09601692110300064, train/logprobs = tensor([[ -1.0957, -10.6592],
        [ -3.0919,  -2.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46359074115753174
Epoch 0, Step 948: train/loss = 0.19403541088104248, train/raw-loss = 0.1448841691017151, train/logprobs = tensor([[-0.7673, -4.5066],
        [-3.6367, -2.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4915122091770172
Epoch 0, Step 949: train/loss = 0.3597758412361145, train/raw-loss = 0.32570937275886536, train/logprobs = tensor([[-1.2471, -4.3236],
        [-2.7320, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34066420793533325
Epoch 0, Step 950: train/loss = 0.16611365973949432, train/raw-loss = 0.11471369117498398, train/logprobs = tensor([[-1.1111, -8.0243],
        [-3.8934, -2.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5139997005462646
Epoch 0, Step 951: train/loss = 0.43896228075027466, train/raw-loss = 0.3954138457775116, train/logprobs = tensor([[-2.3507, -6.3399],
        [-2.5883, -1.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4354845881462097
Epoch 0, Step 952: train/loss = 0.4244215190410614, train/raw-loss = 0.3739531636238098, train/logprobs = tensor([[-1.0518, -5.0702],
        [-4.1329, -2.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5046836137771606
Epoch 0, Step 953: train/loss = 0.9558627009391785, train/raw-loss = 0.9171735644340515, train/logprobs = tensor([[-2.5430, -4.1543],
        [-1.8213, -1.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868907392024994
Epoch 0, Step 954: train/loss = 0.45821380615234375, train/raw-loss = 0.41252079606056213, train/logprobs = tensor([[-2.1495, -5.5900],
        [-2.7641, -1.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4569300413131714
Epoch 0, Step 955: train/loss = 0.3574216663837433, train/raw-loss = 0.3060033321380615, train/logprobs = tensor([[-1.3970, -7.6598],
        [-4.1262, -3.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141830444335938
Epoch 0, Step 956: train/loss = 0.4059051275253296, train/raw-loss = 0.3553251624107361, train/logprobs = tensor([[-1.5423, -3.8969],
        [-3.8625, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5057996511459351
Epoch 0, Step 957: train/loss = 0.4150490462779999, train/raw-loss = 0.36869102716445923, train/logprobs = tensor([[-1.8245, -6.9648],
        [-2.9136, -2.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635801315307617
Epoch 0, Step 958: train/loss = 0.5184107422828674, train/raw-loss = 0.48029348254203796, train/logprobs = tensor([[-1.2253, -2.3589],
        [-2.2891, -1.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3811724781990051
Epoch 0, Step 959: train/loss = 0.44043102860450745, train/raw-loss = 0.39520543813705444, train/logprobs = tensor([[-1.9723, -4.1247],
        [-2.5785, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522557854652405
Epoch 0, Step 960: train/loss = 0.37364262342453003, train/raw-loss = 0.3218451142311096, train/logprobs = tensor([[-1.9840, -6.6375],
        [-3.4881, -3.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5179747939109802
Epoch 0, Step 961: train/loss = 0.3064855635166168, train/raw-loss = 0.2619987726211548, train/logprobs = tensor([[-1.5388, -5.4007],
        [-3.1905, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44486790895462036
Epoch 0, Step 962: train/loss = 0.14591072499752045, train/raw-loss = 0.09123016893863678, train/logprobs = tensor([[-1.5742, -6.0214],
        [-4.6472, -1.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5468055605888367
Epoch 0, Step 963: train/loss = 0.44820451736450195, train/raw-loss = 0.408454954624176, train/logprobs = tensor([[-1.8863, -6.1920],
        [-2.2947, -0.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39749544858932495
Epoch 0, Step 964: train/loss = 0.25863200426101685, train/raw-loss = 0.21112966537475586, train/logprobs = tensor([[-1.3416, -5.2710],
        [-3.7253, -2.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4750235378742218
Epoch 0, Step 965: train/loss = 0.6728357672691345, train/raw-loss = 0.6356686353683472, train/logprobs = tensor([[-1.8808, -3.5545],
        [-2.2890, -2.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3716716766357422
Epoch 0, Step 966: train/loss = 0.29059064388275146, train/raw-loss = 0.2499336302280426, train/logprobs = tensor([[-0.9567, -5.4461],
        [-2.5555, -1.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40657007694244385
Epoch 0, Step 967: train/loss = 0.6009395122528076, train/raw-loss = 0.5681199431419373, train/logprobs = tensor([[ -2.4665, -10.2596],
        [ -1.2829,  -1.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281952440738678
Epoch 0, Step 968: train/loss = 0.38355526328086853, train/raw-loss = 0.3377469778060913, train/logprobs = tensor([[-1.1713, -3.5460],
        [-3.3829, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45808255672454834
Epoch 0, Step 969: train/loss = 0.3295755386352539, train/raw-loss = 0.2777264714241028, train/logprobs = tensor([[-1.4468, -5.8452],
        [-3.2803, -2.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5184907913208008
Epoch 0, Step 970: train/loss = 0.45016688108444214, train/raw-loss = 0.3966609835624695, train/logprobs = tensor([[-1.8579, -4.0320],
        [-3.6531, -3.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5350589752197266
Epoch 0, Step 971: train/loss = 0.23843221366405487, train/raw-loss = 0.19923846423625946, train/logprobs = tensor([[-0.8265, -8.2942],
        [-2.1639, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919374942779541
Epoch 0, Step 972: train/loss = 0.9258139133453369, train/raw-loss = 0.8843153715133667, train/logprobs = tensor([[-2.6863, -2.8525],
        [-1.6493, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41498491168022156
Epoch 0, Step 973: train/loss = 0.5452033281326294, train/raw-loss = 0.49963465332984924, train/logprobs = tensor([[-3.0442, -6.6090],
        [-2.9316, -2.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45568645000457764
Epoch 0, Step 974: train/loss = 0.5365488529205322, train/raw-loss = 0.48895251750946045, train/logprobs = tensor([[-1.4835, -2.8432],
        [-3.5700, -1.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4759635925292969
Epoch 0, Step 975: train/loss = 0.35500383377075195, train/raw-loss = 0.31127262115478516, train/logprobs = tensor([[-1.1282, -7.5443],
        [-2.7336, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4373117983341217
Epoch 0, Step 976: train/loss = 0.29548180103302, train/raw-loss = 0.2509024739265442, train/logprobs = tensor([[-1.2489, -6.2872],
        [-3.5611, -1.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44579362869262695
Epoch 0, Step 977: train/loss = 0.4192107915878296, train/raw-loss = 0.3787361979484558, train/logprobs = tensor([[-2.5419, -6.2346],
        [-3.0997, -0.4745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40474554896354675
Epoch 0, Step 978: train/loss = 0.21334290504455566, train/raw-loss = 0.1708366572856903, train/logprobs = tensor([[-1.3834, -6.6099],
        [-3.3017, -1.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4250625967979431
Epoch 0, Step 979: train/loss = 0.6851348280906677, train/raw-loss = 0.649039089679718, train/logprobs = tensor([[-1.4512, -4.0055],
        [-1.7479, -2.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36095720529556274
Epoch 0, Step 980: train/loss = 0.6460240483283997, train/raw-loss = 0.5992632508277893, train/logprobs = tensor([[-3.7021, -8.9568],
        [-3.8955, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46760764718055725
Epoch 0, Step 981: train/loss = 0.3560250997543335, train/raw-loss = 0.3079324960708618, train/logprobs = tensor([[-1.3977, -5.4209],
        [-2.9026, -1.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4809262752532959
Epoch 0, Step 982: train/loss = 0.5129227638244629, train/raw-loss = 0.47396358847618103, train/logprobs = tensor([[-1.5946, -6.6915],
        [-2.7748, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38959163427352905
Epoch 0, Step 983: train/loss = 0.6063508987426758, train/raw-loss = 0.5686689615249634, train/logprobs = tensor([[-1.5420, -2.4815],
        [-1.7714, -1.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3768194019794464
Epoch 0, Step 984: train/loss = 0.71337890625, train/raw-loss = 0.6703922152519226, train/logprobs = tensor([[-2.7793, -6.8092],
        [-2.6225, -1.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4298667311668396
Epoch 0, Step 985: train/loss = 0.6507794857025146, train/raw-loss = 0.6051321029663086, train/logprobs = tensor([[-2.9120, -5.6475],
        [-4.0014, -2.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45647338032722473
Epoch 0, Step 986: train/loss = 0.32706305384635925, train/raw-loss = 0.28534135222435, train/logprobs = tensor([[-1.5241, -4.7932],
        [-2.7046, -1.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4172170162200928
Epoch 0, Step 987: train/loss = 0.3210139870643616, train/raw-loss = 0.27170509099960327, train/logprobs = tensor([[-2.1253, -6.9520],
        [-4.4045, -2.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4930889308452606
Epoch 0, Step 988: train/loss = 0.5227782726287842, train/raw-loss = 0.47791531682014465, train/logprobs = tensor([[-1.5207, -6.4655],
        [-2.7457, -1.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44862955808639526
Epoch 0, Step 989: train/loss = 0.23349080979824066, train/raw-loss = 0.19573509693145752, train/logprobs = tensor([[-1.3847, -5.2762],
        [-2.7980, -0.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3775571882724762
Epoch 0, Step 990: train/loss = 0.3810149133205414, train/raw-loss = 0.3284337520599365, train/logprobs = tensor([[-1.2356, -4.6832],
        [-4.0581, -2.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258114337921143
Epoch 0, Step 991: train/loss = 0.2569703459739685, train/raw-loss = 0.2178039401769638, train/logprobs = tensor([[-1.5962, -3.9689],
        [-3.4791, -1.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39166417717933655
Epoch 0, Step 992: train/loss = 0.4819495677947998, train/raw-loss = 0.4447716772556305, train/logprobs = tensor([[-1.7423, -2.9652],
        [-2.1358, -0.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3717787563800812
Epoch 0, Step 993: train/loss = 0.3180390000343323, train/raw-loss = 0.27577343583106995, train/logprobs = tensor([[-1.6859, -7.6601],
        [-2.8454, -2.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42265570163726807
Epoch 0, Step 994: train/loss = 0.4527226388454437, train/raw-loss = 0.4060457646846771, train/logprobs = tensor([[-1.3147, -6.3252],
        [-2.6966, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46676868200302124
Epoch 0, Step 995: train/loss = 0.38188257813453674, train/raw-loss = 0.3455047607421875, train/logprobs = tensor([[-0.9507, -8.4740],
        [-2.4361, -1.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637782335281372
Epoch 0, Step 996: train/loss = 0.5903255939483643, train/raw-loss = 0.5535792708396912, train/logprobs = tensor([[-1.1245, -1.8540],
        [-2.1604, -2.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36746343970298767
Epoch 0, Step 997: train/loss = 0.3565537631511688, train/raw-loss = 0.31223058700561523, train/logprobs = tensor([[-2.1210, -6.5860],
        [-3.4759, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4432317912578583
Epoch 0, Step 998: train/loss = 0.345878541469574, train/raw-loss = 0.30402857065200806, train/logprobs = tensor([[-1.9148, -7.6650],
        [-3.5526, -2.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4184994697570801
Epoch 0, Step 999: train/loss = 0.3392987847328186, train/raw-loss = 0.29118046164512634, train/logprobs = tensor([[-1.0651, -3.8448],
        [-2.5985, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4811832308769226
Epoch 0, Step 1000: train/loss = 0.6838861703872681, train/raw-loss = 0.636304497718811, train/logprobs = tensor([[-2.2018, -4.8614],
        [-3.4753, -2.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47581711411476135
Epoch 0, Step 1001: train/loss = 0.2840385437011719, train/raw-loss = 0.23842141032218933, train/logprobs = tensor([[-1.2972, -5.3096],
        [-3.3990, -1.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45617133378982544
Epoch 0, Step 1002: train/loss = 0.3809293806552887, train/raw-loss = 0.34592753648757935, train/logprobs = tensor([[-1.1473, -7.5440],
        [-1.9661, -1.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35001829266548157
Epoch 0, Step 1003: train/loss = 0.5503612756729126, train/raw-loss = 0.513530433177948, train/logprobs = tensor([[-1.3871, -3.1026],
        [-1.7218, -2.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683079481124878
Epoch 0, Step 1004: train/loss = 0.5104749798774719, train/raw-loss = 0.46851831674575806, train/logprobs = tensor([[-1.7045, -6.8825],
        [-2.4209, -1.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4195666015148163
Epoch 0, Step 1005: train/loss = 0.33931130170822144, train/raw-loss = 0.3009662628173828, train/logprobs = tensor([[-1.3856, -7.3666],
        [-2.4897, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3834501802921295
Epoch 0, Step 1006: train/loss = 0.40600523352622986, train/raw-loss = 0.3514961004257202, train/logprobs = tensor([[-2.1698, -5.3610],
        [-3.9287, -2.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.545091450214386
Epoch 0, Step 1007: train/loss = 0.17255422472953796, train/raw-loss = 0.13039463758468628, train/logprobs = tensor([[ -1.9587, -11.3598],
        [ -3.6931,  -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215957820415497
Epoch 0, Step 1008: train/loss = 0.2148568332195282, train/raw-loss = 0.17131979763507843, train/logprobs = tensor([[-0.9802, -9.3576],
        [-3.4290, -1.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43537020683288574
Epoch 0, Step 1009: train/loss = 0.5116432905197144, train/raw-loss = 0.46284401416778564, train/logprobs = tensor([[-1.8757, -3.7599],
        [-2.7029, -2.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48799246549606323
Epoch 0, Step 1010: train/loss = 0.4434228241443634, train/raw-loss = 0.4015256464481354, train/logprobs = tensor([[-2.3346, -4.3317],
        [-3.3457, -1.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41897183656692505
Epoch 0, Step 1011: train/loss = 0.6557402610778809, train/raw-loss = 0.6158779263496399, train/logprobs = tensor([[-2.8267, -5.1723],
        [-2.2960, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39862382411956787
Epoch 0, Step 1012: train/loss = 0.3200201690196991, train/raw-loss = 0.28115224838256836, train/logprobs = tensor([[-1.3996, -6.3542],
        [-3.0427, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3886791169643402
Epoch 0, Step 1013: train/loss = 0.46466803550720215, train/raw-loss = 0.42249149084091187, train/logprobs = tensor([[-1.9076, -3.3724],
        [-2.4687, -1.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217653274536133
Epoch 0, Step 1014: train/loss = 0.2618653476238251, train/raw-loss = 0.21850571036338806, train/logprobs = tensor([[-1.5386, -3.8469],
        [-3.3423, -2.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335963726043701
Epoch 0, Step 1015: train/loss = 0.3626686930656433, train/raw-loss = 0.31732815504074097, train/logprobs = tensor([[-1.6905, -9.2937],
        [-3.4086, -2.3433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45340561866760254
Epoch 0, Step 1016: train/loss = 0.30723273754119873, train/raw-loss = 0.26093414425849915, train/logprobs = tensor([[-1.2866, -3.1699],
        [-3.2008, -1.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4629861116409302
Epoch 0, Step 1017: train/loss = 0.15402817726135254, train/raw-loss = 0.10293488949537277, train/logprobs = tensor([[-2.2251, -9.5514],
        [-4.7555, -2.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5109329223632812
Epoch 0, Step 1018: train/loss = 0.5454235076904297, train/raw-loss = 0.512677788734436, train/logprobs = tensor([[-1.1605, -2.3654],
        [-1.7282, -1.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3274574279785156
Epoch 0, Step 1019: train/loss = 0.3287649154663086, train/raw-loss = 0.2827647626399994, train/logprobs = tensor([[-1.2968, -4.5135],
        [-3.1054, -2.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46000126004219055
Epoch 0, Step 1020: train/loss = 0.6805660128593445, train/raw-loss = 0.6413124203681946, train/logprobs = tensor([[-1.0963, -4.1591],
        [-1.6617, -2.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3925357758998871
Epoch 0, Step 1021: train/loss = 0.15632294118404388, train/raw-loss = 0.11010769754648209, train/logprobs = tensor([[-1.6521, -6.8923],
        [-3.7379, -1.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4621526002883911
Epoch 0, Step 1022: train/loss = 0.43177491426467896, train/raw-loss = 0.38914602994918823, train/logprobs = tensor([[-1.2415, -5.3173],
        [-3.0521, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4262887239456177
Epoch 0, Step 1023: train/loss = 1.1222285032272339, train/raw-loss = 1.073667049407959, train/logprobs = tensor([[-3.2738, -7.2155],
        [-2.7244, -2.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4856158196926117
Epoch 0, Step 1024: train/loss = 0.3781929612159729, train/raw-loss = 0.3391866981983185, train/logprobs = tensor([[-1.2824, -3.1262],
        [-2.5521, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39006268978118896
Epoch 0, Step 1025: train/loss = 0.4726622402667999, train/raw-loss = 0.4363521337509155, train/logprobs = tensor([[-1.2441, -2.1621],
        [-1.9480, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36310112476348877
Epoch 0, Step 1026: train/loss = 0.4377782940864563, train/raw-loss = 0.3936818242073059, train/logprobs = tensor([[-2.3116, -6.4217],
        [-3.5851, -2.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409649968147278
Epoch 0, Step 1027: train/loss = 0.5809181928634644, train/raw-loss = 0.5396113395690918, train/logprobs = tensor([[-1.2580, -2.1175],
        [-1.8345, -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4130687117576599
Epoch 0, Step 1028: train/loss = 0.29650264978408813, train/raw-loss = 0.2591676414012909, train/logprobs = tensor([[-1.2226, -9.2992],
        [-2.8638, -2.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37335002422332764
Epoch 0, Step 1029: train/loss = 0.25428852438926697, train/raw-loss = 0.21790310740470886, train/logprobs = tensor([[-1.1721, -7.8710],
        [-2.6711, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36385416984558105
Epoch 0, Step 1030: train/loss = 0.43335971236228943, train/raw-loss = 0.39674603939056396, train/logprobs = tensor([[-1.0316, -7.2167],
        [-1.7881, -2.2642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36613672971725464
Epoch 0, Step 1031: train/loss = 0.6479659080505371, train/raw-loss = 0.603728175163269, train/logprobs = tensor([[-1.8504, -2.7882],
        [-2.0738, -1.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4423777759075165
Epoch 0, Step 1032: train/loss = 0.6367855072021484, train/raw-loss = 0.5994099974632263, train/logprobs = tensor([[-1.4463, -1.9728],
        [-1.8755, -1.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37375491857528687
Epoch 0, Step 1033: train/loss = 0.26720544695854187, train/raw-loss = 0.21714331209659576, train/logprobs = tensor([[-1.3430, -8.9240],
        [-3.3513, -1.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.500621497631073
Epoch 0, Step 1034: train/loss = 0.3815271854400635, train/raw-loss = 0.34436607360839844, train/logprobs = tensor([[-1.3399, -3.7222],
        [-2.2916, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37161093950271606
Epoch 0, Step 1035: train/loss = 0.4742923974990845, train/raw-loss = 0.42347171902656555, train/logprobs = tensor([[-1.4121, -3.5897],
        [-2.6559, -1.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.508206844329834
Epoch 0, Step 1036: train/loss = 0.19351826608181, train/raw-loss = 0.1545042246580124, train/logprobs = tensor([[-1.4316, -6.6596],
        [-2.9722, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3901404142379761
Epoch 0, Step 1037: train/loss = 0.6836353540420532, train/raw-loss = 0.6329739093780518, train/logprobs = tensor([[-0.9965, -2.2912],
        [-3.3937, -3.2173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.506614089012146
Epoch 0, Step 1038: train/loss = 0.6209374666213989, train/raw-loss = 0.5811930894851685, train/logprobs = tensor([[-1.9428, -3.1918],
        [-2.3593, -1.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3974429965019226
Epoch 0, Step 1039: train/loss = 0.615739643573761, train/raw-loss = 0.5723668932914734, train/logprobs = tensor([[-1.5304, -2.5831],
        [-2.0382, -1.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43372777104377747
Epoch 0, Step 1040: train/loss = 0.6462274789810181, train/raw-loss = 0.6084069609642029, train/logprobs = tensor([[-1.6516, -5.4887],
        [-1.7822, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782052993774414
Epoch 0, Step 1041: train/loss = 0.2678464651107788, train/raw-loss = 0.21248982846736908, train/logprobs = tensor([[-1.5769, -5.4532],
        [-3.4298, -3.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5535666346549988
Epoch 0, Step 1042: train/loss = 0.37554216384887695, train/raw-loss = 0.3341793119907379, train/logprobs = tensor([[-1.0222, -3.6992],
        [-3.1182, -1.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136282205581665
Epoch 0, Step 1043: train/loss = 0.3568147122859955, train/raw-loss = 0.3223421573638916, train/logprobs = tensor([[-0.8952, -6.0145],
        [-2.3928, -1.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34472551941871643
Epoch 0, Step 1044: train/loss = 0.9825895428657532, train/raw-loss = 0.9413782954216003, train/logprobs = tensor([[-2.9825, -3.4601],
        [-2.6252, -2.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41211265325546265
Epoch 0, Step 1045: train/loss = 0.3563675284385681, train/raw-loss = 0.3104393184185028, train/logprobs = tensor([[ -1.0153, -10.4061],
        [ -3.9974,  -2.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4592817723751068
Epoch 0, Step 1046: train/loss = 0.48141157627105713, train/raw-loss = 0.44671326875686646, train/logprobs = tensor([[-1.1573, -3.2059],
        [-1.9068, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469829559326172
Epoch 0, Step 1047: train/loss = 0.3564879894256592, train/raw-loss = 0.3072893023490906, train/logprobs = tensor([[-2.3309, -4.6325],
        [-4.2735, -1.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4919869899749756
Epoch 0, Step 1048: train/loss = 0.567009449005127, train/raw-loss = 0.5265628695487976, train/logprobs = tensor([[-1.3473, -1.9668],
        [-2.0868, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40446555614471436
Epoch 0, Step 1049: train/loss = 0.14261549711227417, train/raw-loss = 0.1039314866065979, train/logprobs = tensor([[-1.0675, -8.8638],
        [-2.8891, -2.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38684016466140747
Epoch 0, Step 1050: train/loss = 0.3835785388946533, train/raw-loss = 0.3395538032054901, train/logprobs = tensor([[-1.4350, -7.1246],
        [-2.9717, -1.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44024768471717834
Epoch 0, Step 1051: train/loss = 0.42561936378479004, train/raw-loss = 0.38436776399612427, train/logprobs = tensor([[-1.3007, -4.1000],
        [-3.8072, -1.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41251620650291443
Epoch 0, Step 1052: train/loss = 0.19526204466819763, train/raw-loss = 0.15711750090122223, train/logprobs = tensor([[-1.2265, -4.5762],
        [-3.3127, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814454972743988
Epoch 0, Step 1053: train/loss = 0.4055151641368866, train/raw-loss = 0.35498714447021484, train/logprobs = tensor([[-1.8041, -4.4144],
        [-3.4398, -2.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5052800178527832
Epoch 0, Step 1054: train/loss = 0.283432275056839, train/raw-loss = 0.2412419617176056, train/logprobs = tensor([[-1.5536, -9.0127],
        [-2.4905, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42190343141555786
Epoch 0, Step 1055: train/loss = 0.4296056926250458, train/raw-loss = 0.3993627429008484, train/logprobs = tensor([[-0.6823, -7.3473],
        [-0.8713, -1.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30242910981178284
Epoch 0, Step 1056: train/loss = 0.5799819827079773, train/raw-loss = 0.5370539426803589, train/logprobs = tensor([[-2.0986, -3.6233],
        [-2.4457, -1.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4292806386947632
Epoch 0, Step 1057: train/loss = 0.3163004517555237, train/raw-loss = 0.27552103996276855, train/logprobs = tensor([[-1.5745, -5.3395],
        [-2.6504, -1.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40779390931129456
Epoch 0, Step 1058: train/loss = 0.48607099056243896, train/raw-loss = 0.4420973062515259, train/logprobs = tensor([[-1.4177, -2.4996],
        [-3.2359, -2.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43973681330680847
Epoch 0, Step 1059: train/loss = 0.5084253549575806, train/raw-loss = 0.4656619131565094, train/logprobs = tensor([[-1.7297, -4.5140],
        [-2.2453, -2.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42763423919677734
Epoch 0, Step 1060: train/loss = 0.37918829917907715, train/raw-loss = 0.3391605615615845, train/logprobs = tensor([[ -2.1467, -10.5212],
        [ -2.5510,  -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002777934074402
Epoch 0, Step 1061: train/loss = 0.30621519684791565, train/raw-loss = 0.26221194863319397, train/logprobs = tensor([[-0.7699, -3.8028],
        [-2.8174, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4400327801704407
Epoch 0, Step 1062: train/loss = 0.2938538193702698, train/raw-loss = 0.2560676336288452, train/logprobs = tensor([[-1.3420, -4.7481],
        [-2.3770, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778616786003113
Epoch 0, Step 1063: train/loss = 0.3334253430366516, train/raw-loss = 0.2963483929634094, train/logprobs = tensor([[-1.0435, -8.9527],
        [-2.4109, -1.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37076929211616516
Epoch 0, Step 1064: train/loss = 0.12774810194969177, train/raw-loss = 0.07604089379310608, train/logprobs = tensor([[-1.2817, -9.0361],
        [-3.4613, -1.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5170721411705017
Epoch 0, Step 1065: train/loss = 0.4940633475780487, train/raw-loss = 0.4557569921016693, train/logprobs = tensor([[-1.6285, -2.9546],
        [-2.5663, -1.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38306355476379395
Epoch 0, Step 1066: train/loss = 0.3005804419517517, train/raw-loss = 0.2542237341403961, train/logprobs = tensor([[-1.5711, -6.8984],
        [-2.9556, -2.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635670781135559
Epoch 0, Step 1067: train/loss = 0.13395749032497406, train/raw-loss = 0.09881652891635895, train/logprobs = tensor([[-0.8217, -6.6376],
        [-2.4087, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514096140861511
Epoch 0, Step 1068: train/loss = 0.5749481916427612, train/raw-loss = 0.5346022248268127, train/logprobs = tensor([[-1.2735, -3.1575],
        [-2.4121, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4034595191478729
Epoch 0, Step 1069: train/loss = 0.2524680197238922, train/raw-loss = 0.21281245350837708, train/logprobs = tensor([[-1.0356, -9.0878],
        [-3.4409, -1.0080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965556025505066
Epoch 0, Step 1070: train/loss = 0.40072599053382874, train/raw-loss = 0.3623186945915222, train/logprobs = tensor([[-2.2374, -6.8567],
        [-2.4008, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840731084346771
Epoch 0, Step 1071: train/loss = 0.3276876211166382, train/raw-loss = 0.2825120985507965, train/logprobs = tensor([[-1.5129, -7.4091],
        [-3.1139, -1.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4517556428909302
Epoch 0, Step 1072: train/loss = 0.42396238446235657, train/raw-loss = 0.3912225067615509, train/logprobs = tensor([[-1.0026, -3.7334],
        [-2.3851, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32739871740341187
Epoch 0, Step 1073: train/loss = 0.7091777920722961, train/raw-loss = 0.6657232046127319, train/logprobs = tensor([[-2.8700, -6.2495],
        [-2.3277, -1.2785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4345460534095764
Epoch 0, Step 1074: train/loss = 0.9065698385238647, train/raw-loss = 0.8662244081497192, train/logprobs = tensor([[-3.8898, -6.3378],
        [-4.2028, -2.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403454452753067
Epoch 0, Step 1075: train/loss = 0.24477607011795044, train/raw-loss = 0.20205876231193542, train/logprobs = tensor([[-1.5200, -6.1512],
        [-4.1443, -3.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4271731674671173
Epoch 0, Step 1076: train/loss = 0.3914448022842407, train/raw-loss = 0.34986358880996704, train/logprobs = tensor([[-0.7819, -5.0344],
        [-2.2116, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158121347427368
Epoch 0, Step 1077: train/loss = 0.17937369644641876, train/raw-loss = 0.14503160119056702, train/logprobs = tensor([[-1.4752, -9.4171],
        [-2.7237, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34342095255851746
Epoch 0, Step 1078: train/loss = 0.3101831078529358, train/raw-loss = 0.27099210023880005, train/logprobs = tensor([[-1.4511, -9.6861],
        [-3.0883, -2.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919103443622589
Epoch 0, Step 1079: train/loss = 0.2414202243089676, train/raw-loss = 0.20594915747642517, train/logprobs = tensor([[-1.8889, -5.4046],
        [-2.9479, -1.0089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35471054911613464
Epoch 0, Step 1080: train/loss = 0.49620744585990906, train/raw-loss = 0.4616810977458954, train/logprobs = tensor([[-1.2776, -5.7586],
        [-1.3103, -1.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3452635407447815
Epoch 0, Step 1081: train/loss = 0.34080439805984497, train/raw-loss = 0.3020116984844208, train/logprobs = tensor([[-1.3159, -8.9151],
        [-2.7730, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879268169403076
Epoch 0, Step 1082: train/loss = 0.41432660818099976, train/raw-loss = 0.3853290379047394, train/logprobs = tensor([[-1.4935, -7.9840],
        [-1.8256, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28997570276260376
Epoch 0, Step 1083: train/loss = 0.5093093514442444, train/raw-loss = 0.47670769691467285, train/logprobs = tensor([[-1.0953, -3.7207],
        [-1.5517, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32601654529571533
Epoch 0, Step 1084: train/loss = 0.5795119404792786, train/raw-loss = 0.5365898609161377, train/logprobs = tensor([[-0.9648, -4.0917],
        [-3.3144, -2.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42922163009643555
Epoch 0, Step 1085: train/loss = 0.1821107268333435, train/raw-loss = 0.13383238017559052, train/logprobs = tensor([[ -1.8210, -11.5067],
        [ -3.6039,  -2.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48278355598449707
Epoch 0, Step 1086: train/loss = 0.4068862497806549, train/raw-loss = 0.3692297637462616, train/logprobs = tensor([[-0.7067, -6.2895],
        [-2.3389, -2.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765648603439331
Epoch 0, Step 1087: train/loss = 0.5538936853408813, train/raw-loss = 0.5164546966552734, train/logprobs = tensor([[-1.5347, -3.5617],
        [-1.8615, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3743898868560791
Epoch 0, Step 1088: train/loss = 0.4283895492553711, train/raw-loss = 0.39341479539871216, train/logprobs = tensor([[-1.1405, -5.7902],
        [-1.6237, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497474491596222
Epoch 0, Step 1089: train/loss = 0.2979143559932709, train/raw-loss = 0.2584455609321594, train/logprobs = tensor([[-2.5528, -8.2939],
        [-3.5949, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39468806982040405
Epoch 0, Step 1090: train/loss = 1.1451517343521118, train/raw-loss = 1.106065273284912, train/logprobs = tensor([[-3.7362, -5.3313],
        [-2.0914, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908650577068329
Epoch 0, Step 1091: train/loss = 0.2097560316324234, train/raw-loss = 0.16344812512397766, train/logprobs = tensor([[-1.7365, -7.7497],
        [-3.8307, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630791246891022
Epoch 0, Step 1092: train/loss = 0.19792234897613525, train/raw-loss = 0.1555314064025879, train/logprobs = tensor([[-1.8735, -8.3065],
        [-4.0690, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42390939593315125
Epoch 0, Step 1093: train/loss = 0.37011951208114624, train/raw-loss = 0.3160902261734009, train/logprobs = tensor([[-1.6477, -6.4284],
        [-3.7886, -1.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5402928590774536
Epoch 0, Step 1094: train/loss = 0.2983781695365906, train/raw-loss = 0.2576782703399658, train/logprobs = tensor([[-1.3888, -5.0912],
        [-2.4526, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069993197917938
Epoch 0, Step 1095: train/loss = 0.3848383128643036, train/raw-loss = 0.3431338965892792, train/logprobs = tensor([[-1.9483, -3.8921],
        [-3.0873, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4170442819595337
Epoch 0, Step 1096: train/loss = 0.33390820026397705, train/raw-loss = 0.2915800213813782, train/logprobs = tensor([[-1.9755, -7.5338],
        [-3.3349, -1.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4232817590236664
Epoch 0, Step 1097: train/loss = 0.33360984921455383, train/raw-loss = 0.29519104957580566, train/logprobs = tensor([[-1.7706, -6.0904],
        [-2.9942, -1.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3841879069805145
Epoch 0, Step 1098: train/loss = 0.5172000527381897, train/raw-loss = 0.47742998600006104, train/logprobs = tensor([[-1.4973, -5.1156],
        [-2.3059, -2.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39770039916038513
Epoch 0, Step 1099: train/loss = 0.36637014150619507, train/raw-loss = 0.332008957862854, train/logprobs = tensor([[-1.4002, -6.1875],
        [-2.1944, -2.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3436119854450226
Epoch 0, Step 1100: train/loss = 0.3087121844291687, train/raw-loss = 0.2719721794128418, train/logprobs = tensor([[-1.1251, -4.9806],
        [-2.4228, -1.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36740022897720337
Epoch 0, Step 1101: train/loss = 0.3459048271179199, train/raw-loss = 0.31003716588020325, train/logprobs = tensor([[-1.6900, -6.0054],
        [-2.5177, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586764335632324
Epoch 0, Step 1102: train/loss = 0.3074943423271179, train/raw-loss = 0.2677609622478485, train/logprobs = tensor([[-1.8061, -8.1453],
        [-2.8947, -1.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3973340392112732
Epoch 0, Step 1103: train/loss = 0.5871114730834961, train/raw-loss = 0.5575408935546875, train/logprobs = tensor([[-2.3060, -4.9504],
        [-1.9087, -1.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957051694393158
Epoch 0, Step 1104: train/loss = 0.6979384422302246, train/raw-loss = 0.6572574973106384, train/logprobs = tensor([[-0.9121, -1.3728],
        [-2.0777, -2.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4068094491958618
Epoch 0, Step 1105: train/loss = 0.3323325514793396, train/raw-loss = 0.28824010491371155, train/logprobs = tensor([[-2.3650, -6.6820],
        [-3.5858, -1.4389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44092458486557007
Epoch 0, Step 1106: train/loss = 0.6217917203903198, train/raw-loss = 0.583503246307373, train/logprobs = tensor([[-2.2204, -4.1459],
        [-2.5659, -1.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38288456201553345
Epoch 0, Step 1107: train/loss = 0.36754804849624634, train/raw-loss = 0.3349071145057678, train/logprobs = tensor([[-1.5439, -4.9266],
        [-3.2070, -1.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3264091908931732
Epoch 0, Step 1108: train/loss = 0.357810914516449, train/raw-loss = 0.3187744915485382, train/logprobs = tensor([[-0.8866, -5.3000],
        [-3.0391, -1.8763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39036425948143005
Epoch 0, Step 1109: train/loss = 0.119905486702919, train/raw-loss = 0.0720316544175148, train/logprobs = tensor([[-1.5413, -8.2284],
        [-3.7230, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47873833775520325
Epoch 0, Step 1110: train/loss = 0.36900246143341064, train/raw-loss = 0.323798269033432, train/logprobs = tensor([[-0.9962, -2.9264],
        [-3.5629, -2.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4520418643951416
Epoch 0, Step 1111: train/loss = 0.23510527610778809, train/raw-loss = 0.1906968057155609, train/logprobs = tensor([[-1.3677, -3.5833],
        [-3.4567, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44408494234085083
Epoch 0, Step 1112: train/loss = 0.38783350586891174, train/raw-loss = 0.3482030928134918, train/logprobs = tensor([[-1.5574, -7.8401],
        [-3.0870, -1.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3963041305541992
Epoch 0, Step 1113: train/loss = 0.5188770890235901, train/raw-loss = 0.48511356115341187, train/logprobs = tensor([[-2.1606, -5.2527],
        [-1.9057, -1.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3376350700855255
Epoch 0, Step 1114: train/loss = 0.5672159194946289, train/raw-loss = 0.5287685394287109, train/logprobs = tensor([[-2.5061, -6.6529],
        [-2.4435, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844737708568573
Epoch 0, Step 1115: train/loss = 0.3888074457645416, train/raw-loss = 0.35335227847099304, train/logprobs = tensor([[-1.1694, -5.3532],
        [-2.8648, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354551762342453
Epoch 0, Step 1116: train/loss = 0.4686686396598816, train/raw-loss = 0.43313366174697876, train/logprobs = tensor([[-1.4344, -3.7563],
        [-2.2893, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35534951090812683
Epoch 0, Step 1117: train/loss = 0.7835493683815002, train/raw-loss = 0.7473505139350891, train/logprobs = tensor([[-1.5618, -1.4573],
        [-2.0411, -2.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36198896169662476
Epoch 0, Step 1118: train/loss = 0.5259307622909546, train/raw-loss = 0.49537673592567444, train/logprobs = tensor([[-2.1912, -6.4446],
        [-2.2207, -1.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055398762226105
Epoch 0, Step 1119: train/loss = 0.6072602272033691, train/raw-loss = 0.5684736967086792, train/logprobs = tensor([[-1.9425, -5.8811],
        [-1.6426, -0.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3878653049468994
Epoch 0, Step 1120: train/loss = 0.4615761637687683, train/raw-loss = 0.4282752275466919, train/logprobs = tensor([[-0.8979, -2.3979],
        [-2.4061, -1.4845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33300936222076416
Epoch 0, Step 1121: train/loss = 0.21121428906917572, train/raw-loss = 0.17650125920772552, train/logprobs = tensor([[-1.8457, -6.7760],
        [-3.0629, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3471302092075348
Epoch 0, Step 1122: train/loss = 0.5259766578674316, train/raw-loss = 0.4935745298862457, train/logprobs = tensor([[-1.0848, -2.7028],
        [-1.8848, -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240216076374054
Epoch 0, Step 1123: train/loss = 0.22467964887619019, train/raw-loss = 0.18108128011226654, train/logprobs = tensor([[ -1.3498, -10.2927],
        [ -3.3312,  -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43598365783691406
Epoch 0, Step 1124: train/loss = 0.24204757809638977, train/raw-loss = 0.2074897289276123, train/logprobs = tensor([[ -1.5972, -10.8645],
        [ -2.9323,  -1.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455786108970642
Epoch 0, Step 1125: train/loss = 0.304854154586792, train/raw-loss = 0.26773202419281006, train/logprobs = tensor([[-0.9551, -2.8956],
        [-2.5912, -1.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37122130393981934
Epoch 0, Step 1126: train/loss = 0.6116282939910889, train/raw-loss = 0.5769438743591309, train/logprobs = tensor([[-2.6855, -5.8578],
        [-2.4236, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468443751335144
Epoch 0, Step 1127: train/loss = 0.7272230982780457, train/raw-loss = 0.6971170902252197, train/logprobs = tensor([[-2.4425, -6.5889],
        [-1.8708, -1.4885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010599613189697
Epoch 0, Step 1128: train/loss = 0.4481702744960785, train/raw-loss = 0.4152016043663025, train/logprobs = tensor([[-1.2786, -2.5799],
        [-2.0079, -0.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3296862244606018
Epoch 0, Step 1129: train/loss = 0.6515628695487976, train/raw-loss = 0.6081404685974121, train/logprobs = tensor([[-1.1194, -4.6701],
        [-2.2460, -3.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43422311544418335
Epoch 0, Step 1130: train/loss = 0.47180742025375366, train/raw-loss = 0.43381357192993164, train/logprobs = tensor([[-2.1922, -4.8082],
        [-2.3912, -1.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799385726451874
Epoch 0, Step 1131: train/loss = 0.3720143437385559, train/raw-loss = 0.336455762386322, train/logprobs = tensor([[-1.4663, -7.3793],
        [-2.0210, -2.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555852770805359
Epoch 0, Step 1132: train/loss = 0.24146972596645355, train/raw-loss = 0.20194382965564728, train/logprobs = tensor([[-0.7380, -7.0018],
        [-2.0903, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39525890350341797
Epoch 0, Step 1133: train/loss = 0.4825703501701355, train/raw-loss = 0.4445776343345642, train/logprobs = tensor([[-1.2777, -3.1923],
        [-2.6477, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799270987510681
Epoch 0, Step 1134: train/loss = 0.49079379439353943, train/raw-loss = 0.4541589319705963, train/logprobs = tensor([[-1.3640, -3.5075],
        [-2.7367, -1.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3663487732410431
Epoch 0, Step 1135: train/loss = 0.27079665660858154, train/raw-loss = 0.23426249623298645, train/logprobs = tensor([[-1.0809, -7.4107],
        [-2.5036, -1.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3653414249420166
Epoch 0, Step 1136: train/loss = 0.3280108571052551, train/raw-loss = 0.28883060812950134, train/logprobs = tensor([[-1.4284, -3.7632],
        [-2.8920, -1.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918023705482483
Epoch 0, Step 1137: train/loss = 0.2666887640953064, train/raw-loss = 0.23779651522636414, train/logprobs = tensor([[-0.6562, -5.5756],
        [-1.8299, -1.4618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889225482940674
Epoch 0, Step 1138: train/loss = 0.4634193778038025, train/raw-loss = 0.4260594844818115, train/logprobs = tensor([[-1.1273, -2.5377],
        [-1.7267, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.373599112033844
Epoch 0, Step 1139: train/loss = 0.51661616563797, train/raw-loss = 0.4737183451652527, train/logprobs = tensor([[-1.5468, -5.7087],
        [-3.5667, -2.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4289780855178833
Epoch 0, Step 1140: train/loss = 0.37440285086631775, train/raw-loss = 0.3334066867828369, train/logprobs = tensor([[-1.9714, -6.0449],
        [-2.7571, -1.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4099618196487427
Epoch 0, Step 1141: train/loss = 0.4569358825683594, train/raw-loss = 0.417467325925827, train/logprobs = tensor([[-1.7660, -4.5925],
        [-2.4663, -1.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946858048439026
Epoch 0, Step 1142: train/loss = 0.41690340638160706, train/raw-loss = 0.37820208072662354, train/logprobs = tensor([[-1.7831, -3.5918],
        [-2.7308, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3870130181312561
Epoch 0, Step 1143: train/loss = 0.10381139814853668, train/raw-loss = 0.06606099754571915, train/logprobs = tensor([[-1.3591, -8.4446],
        [-3.3846, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37750399112701416
Epoch 0, Step 1144: train/loss = 0.36110079288482666, train/raw-loss = 0.3233533799648285, train/logprobs = tensor([[-1.2384, -4.7351],
        [-2.8981, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3774741590023041
Epoch 0, Step 1145: train/loss = 0.18892183899879456, train/raw-loss = 0.14718389511108398, train/logprobs = tensor([[-1.3282, -8.5977],
        [-2.7114, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4173795282840729
Epoch 0, Step 1146: train/loss = 1.061463475227356, train/raw-loss = 1.0256500244140625, train/logprobs = tensor([[-3.3090, -4.9280],
        [-1.3119, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581336438655853
Epoch 0, Step 1147: train/loss = 0.3245595693588257, train/raw-loss = 0.2874292731285095, train/logprobs = tensor([[-1.5702, -7.7374],
        [-3.5107, -1.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3713030219078064
Epoch 0, Step 1148: train/loss = 0.4178060293197632, train/raw-loss = 0.374304860830307, train/logprobs = tensor([[-1.2202, -2.5454],
        [-2.9325, -1.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43501168489456177
Epoch 0, Step 1149: train/loss = 0.27122753858566284, train/raw-loss = 0.23354700207710266, train/logprobs = tensor([[-1.4181, -5.0300],
        [-2.4562, -1.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3768054246902466
Epoch 0, Step 1150: train/loss = 0.6238809823989868, train/raw-loss = 0.5846705436706543, train/logprobs = tensor([[-3.3377, -4.5930],
        [-3.0997, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3921046555042267
Epoch 0, Step 1151: train/loss = 0.2524102032184601, train/raw-loss = 0.21694599092006683, train/logprobs = tensor([[-0.9662, -5.6641],
        [-3.0539, -2.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3546421229839325
Epoch 0, Step 1152: train/loss = 0.5993251800537109, train/raw-loss = 0.5610248446464539, train/logprobs = tensor([[-1.3530, -2.2763],
        [-1.7150, -1.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830033540725708
Epoch 0, Step 1153: train/loss = 0.14929646253585815, train/raw-loss = 0.11361666023731232, train/logprobs = tensor([[-0.9136, -6.8867],
        [-2.6417, -2.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35679805278778076
Epoch 0, Step 1154: train/loss = 0.5071196556091309, train/raw-loss = 0.47262051701545715, train/logprobs = tensor([[-1.5149, -4.9169],
        [-2.0973, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34499144554138184
Epoch 0, Step 1155: train/loss = 0.38351622223854065, train/raw-loss = 0.34685787558555603, train/logprobs = tensor([[-1.6248, -4.6327],
        [-2.8641, -1.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3665831983089447
Epoch 0, Step 1156: train/loss = 0.13996517658233643, train/raw-loss = 0.0989529937505722, train/logprobs = tensor([[-1.1054, -6.8920],
        [-3.1643, -2.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.410121887922287
Epoch 0, Step 1157: train/loss = 0.3552306294441223, train/raw-loss = 0.31544962525367737, train/logprobs = tensor([[-1.1517, -3.8520],
        [-2.9408, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39781010150909424
Epoch 0, Step 1158: train/loss = 1.0602662563323975, train/raw-loss = 1.024628758430481, train/logprobs = tensor([[-2.6243, -3.2763],
        [-2.4611, -2.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3563753366470337
Epoch 0, Step 1159: train/loss = 0.4443647563457489, train/raw-loss = 0.4061587452888489, train/logprobs = tensor([[-1.6368, -3.6073],
        [-2.4857, -2.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820599913597107
Epoch 0, Step 1160: train/loss = 0.439966082572937, train/raw-loss = 0.40541332960128784, train/logprobs = tensor([[-0.9001, -3.7897],
        [-2.0319, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455280065536499
Epoch 0, Step 1161: train/loss = 0.27062129974365234, train/raw-loss = 0.2352859377861023, train/logprobs = tensor([[-1.5876, -5.2969],
        [-3.0900, -2.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533538579940796
Epoch 0, Step 1162: train/loss = 0.5081127285957336, train/raw-loss = 0.4696118235588074, train/logprobs = tensor([[-1.4499, -2.1203],
        [-2.7601, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38500887155532837
Epoch 0, Step 1163: train/loss = 0.5380464792251587, train/raw-loss = 0.5032301545143127, train/logprobs = tensor([[-3.4199, -6.7705],
        [-3.5386, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3481634557247162
Epoch 0, Step 1164: train/loss = 0.5981118679046631, train/raw-loss = 0.5503822565078735, train/logprobs = tensor([[-1.5827, -3.8256],
        [-3.9290, -2.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4772961139678955
Epoch 0, Step 1165: train/loss = 0.3716546297073364, train/raw-loss = 0.34648334980010986, train/logprobs = tensor([[-0.9669, -4.3182],
        [-1.7416, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25171276926994324
Epoch 0, Step 1166: train/loss = 1.0026631355285645, train/raw-loss = 0.963477373123169, train/logprobs = tensor([[-3.5263, -4.4894],
        [-3.2081, -2.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918587565422058
Epoch 0, Step 1167: train/loss = 0.5378739237785339, train/raw-loss = 0.5028254985809326, train/logprobs = tensor([[-1.0731, -1.7607],
        [-2.2042, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3504842519760132
Epoch 0, Step 1168: train/loss = 0.37711101770401, train/raw-loss = 0.33041617274284363, train/logprobs = tensor([[-2.0205, -7.2390],
        [-2.4473, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4669484496116638
Epoch 0, Step 1169: train/loss = 0.3099577724933624, train/raw-loss = 0.268896222114563, train/logprobs = tensor([[-1.0949, -4.9713],
        [-2.8934, -2.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106155037879944
Epoch 0, Step 1170: train/loss = 0.11885540187358856, train/raw-loss = 0.07867167890071869, train/logprobs = tensor([[-1.2386, -8.5733],
        [-3.5621, -1.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40183722972869873
Epoch 0, Step 1171: train/loss = 0.6254271864891052, train/raw-loss = 0.5921621918678284, train/logprobs = tensor([[-2.8082, -3.1235],
        [-2.9677, -2.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3326496481895447
Epoch 0, Step 1172: train/loss = 0.3978452682495117, train/raw-loss = 0.36546966433525085, train/logprobs = tensor([[-1.7648, -5.0918],
        [-2.6847, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237561583518982
Epoch 0, Step 1173: train/loss = 0.3657495975494385, train/raw-loss = 0.32470938563346863, train/logprobs = tensor([[-1.5730, -4.9980],
        [-3.3667, -2.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4104020595550537
Epoch 0, Step 1174: train/loss = 0.2126331776380539, train/raw-loss = 0.17508681118488312, train/logprobs = tensor([[ -1.3069, -10.7245],
        [ -3.1899,  -2.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.375463604927063
Epoch 0, Step 1175: train/loss = 0.5538682341575623, train/raw-loss = 0.5234466791152954, train/logprobs = tensor([[-1.0427, -3.2240],
        [-1.3669, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30421555042266846
Epoch 0, Step 1176: train/loss = 0.3472651541233063, train/raw-loss = 0.305605947971344, train/logprobs = tensor([[-1.4396, -3.0125],
        [-3.1213, -1.2723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41659218072891235
Epoch 0, Step 1177: train/loss = 0.4613545835018158, train/raw-loss = 0.42719706892967224, train/logprobs = tensor([[-1.3675, -6.0130],
        [-1.8291, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34157538414001465
Epoch 0, Step 1178: train/loss = 0.39639437198638916, train/raw-loss = 0.36653345823287964, train/logprobs = tensor([[-1.5699, -7.3347],
        [-2.1555, -0.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2986087501049042
Epoch 0, Step 1179: train/loss = 0.39405557513237, train/raw-loss = 0.3626469671726227, train/logprobs = tensor([[-0.7690, -3.8888],
        [-2.5050, -1.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31408631801605225
Epoch 0, Step 1180: train/loss = 0.2583165466785431, train/raw-loss = 0.21915243566036224, train/logprobs = tensor([[-0.9541, -5.6728],
        [-2.5285, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3916409909725189
Epoch 0, Step 1181: train/loss = 0.27720192074775696, train/raw-loss = 0.23999065160751343, train/logprobs = tensor([[-1.2121, -7.6276],
        [-2.4295, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721126616001129
Epoch 0, Step 1182: train/loss = 0.7349550724029541, train/raw-loss = 0.6864041090011597, train/logprobs = tensor([[-1.9233, -4.4026],
        [-3.6874, -2.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48550939559936523
Epoch 0, Step 1183: train/loss = 0.33102911710739136, train/raw-loss = 0.2974807024002075, train/logprobs = tensor([[-1.3744, -5.9606],
        [-2.3598, -1.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33548426628112793
Epoch 0, Step 1184: train/loss = 0.28249889612197876, train/raw-loss = 0.2480543702840805, train/logprobs = tensor([[-1.2073, -7.2156],
        [-2.4621, -1.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34444528818130493
Epoch 0, Step 1185: train/loss = 0.8381435871124268, train/raw-loss = 0.8054829239845276, train/logprobs = tensor([[-3.2065, -6.7873],
        [-2.8803, -2.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266061246395111
Epoch 0, Step 1186: train/loss = 0.23958441615104675, train/raw-loss = 0.19710609316825867, train/logprobs = tensor([[-1.9010, -6.6103],
        [-3.0026, -1.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247831404209137
Epoch 0, Step 1187: train/loss = 0.45750176906585693, train/raw-loss = 0.4188472628593445, train/logprobs = tensor([[-1.3229, -3.3874],
        [-2.5103, -1.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3865448534488678
Epoch 0, Step 1188: train/loss = 0.2438194751739502, train/raw-loss = 0.2077130228281021, train/logprobs = tensor([[-1.4628, -4.5264],
        [-2.8271, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610644042491913
Epoch 0, Step 1189: train/loss = 0.5073074698448181, train/raw-loss = 0.4673709571361542, train/logprobs = tensor([[-2.3840, -5.0972],
        [-2.6173, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39936530590057373
Epoch 0, Step 1190: train/loss = 0.3011687695980072, train/raw-loss = 0.25971177220344543, train/logprobs = tensor([[-2.0514, -5.4661],
        [-3.8922, -2.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4145699739456177
Epoch 0, Step 1191: train/loss = 0.3198150396347046, train/raw-loss = 0.28927305340766907, train/logprobs = tensor([[-0.9693, -6.8086],
        [-1.9039, -0.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054198920726776
Epoch 0, Step 1192: train/loss = 0.3689975440502167, train/raw-loss = 0.33749404549598694, train/logprobs = tensor([[-0.7095, -7.5414],
        [-2.6703, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31503501534461975
Epoch 0, Step 1193: train/loss = 0.3356821835041046, train/raw-loss = 0.30488619208335876, train/logprobs = tensor([[-0.7979, -3.9276],
        [-2.0307, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30796027183532715
Epoch 0, Step 1194: train/loss = 0.30065011978149414, train/raw-loss = 0.26629751920700073, train/logprobs = tensor([[-1.0625, -6.9293],
        [-2.0995, -2.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34352609515190125
Epoch 0, Step 1195: train/loss = 0.4415538012981415, train/raw-loss = 0.40621569752693176, train/logprobs = tensor([[-1.5987, -3.6370],
        [-2.5076, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533807098865509
Epoch 0, Step 1196: train/loss = 0.2672579288482666, train/raw-loss = 0.23030495643615723, train/logprobs = tensor([[-1.5520, -6.0115],
        [-3.2748, -1.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3695295751094818
Epoch 0, Step 1197: train/loss = 0.4378190040588379, train/raw-loss = 0.4034443497657776, train/logprobs = tensor([[-2.4678, -4.4625],
        [-2.5437, -1.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437469005584717
Epoch 0, Step 1198: train/loss = 0.4759230613708496, train/raw-loss = 0.4426654577255249, train/logprobs = tensor([[-1.8247, -5.8448],
        [-2.3429, -1.4242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33257609605789185
Epoch 0, Step 1199: train/loss = 0.3120845854282379, train/raw-loss = 0.2802724838256836, train/logprobs = tensor([[-0.7664, -6.2443],
        [-2.0361, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181210160255432
Epoch 0, Step 1200: train/loss = 0.500701904296875, train/raw-loss = 0.457291841506958, train/logprobs = tensor([[-1.3252, -3.1255],
        [-3.3444, -2.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43410056829452515
Epoch 0, Step 1201: train/loss = 0.6470279097557068, train/raw-loss = 0.6171796917915344, train/logprobs = tensor([[-0.9366, -2.8066],
        [-1.9702, -2.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29848238825798035
Epoch 0, Step 1202: train/loss = 0.4661068022251129, train/raw-loss = 0.43150463700294495, train/logprobs = tensor([[-2.3753, -8.8055],
        [-2.5756, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34602195024490356
Epoch 0, Step 1203: train/loss = 0.301028311252594, train/raw-loss = 0.2621423900127411, train/logprobs = tensor([[-1.3252, -5.7829],
        [-2.8582, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3888590931892395
Epoch 0, Step 1204: train/loss = 0.28520798683166504, train/raw-loss = 0.2541320025920868, train/logprobs = tensor([[-0.7552, -5.2716],
        [-1.7807, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107597827911377
Epoch 0, Step 1205: train/loss = 0.35446128249168396, train/raw-loss = 0.3130970895290375, train/logprobs = tensor([[-1.4216, -9.0414],
        [-2.3265, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41364169120788574
Epoch 0, Step 1206: train/loss = 0.5184450149536133, train/raw-loss = 0.4822152554988861, train/logprobs = tensor([[-3.0579, -8.3652],
        [-3.4780, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3622974157333374
Epoch 0, Step 1207: train/loss = 0.5070807337760925, train/raw-loss = 0.4688156843185425, train/logprobs = tensor([[-1.2697, -2.6823],
        [-2.6421, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3826504051685333
Epoch 0, Step 1208: train/loss = 0.39612874388694763, train/raw-loss = 0.3559253513813019, train/logprobs = tensor([[-2.3290, -5.5527],
        [-2.7139, -2.0273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4020339250564575
Epoch 0, Step 1209: train/loss = 0.3838876485824585, train/raw-loss = 0.34520891308784485, train/logprobs = tensor([[-0.7014, -5.7579],
        [-2.2813, -1.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38678741455078125
Epoch 0, Step 1210: train/loss = 0.3134390711784363, train/raw-loss = 0.2838861048221588, train/logprobs = tensor([[-1.1956, -5.5916],
        [-1.4702, -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29552972316741943
Epoch 0, Step 1211: train/loss = 0.6065312623977661, train/raw-loss = 0.5733680725097656, train/logprobs = tensor([[-1.8622, -4.1692],
        [-1.8038, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33163145184516907
Epoch 0, Step 1212: train/loss = 0.47016751766204834, train/raw-loss = 0.43238043785095215, train/logprobs = tensor([[-1.2727, -4.1609],
        [-1.8743, -1.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778707683086395
Epoch 0, Step 1213: train/loss = 0.39678430557250977, train/raw-loss = 0.3571377694606781, train/logprobs = tensor([[-1.5165, -6.2194],
        [-2.8786, -1.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39646536111831665
Epoch 0, Step 1214: train/loss = 0.5986325144767761, train/raw-loss = 0.5569709539413452, train/logprobs = tensor([[-3.0054, -5.0656],
        [-3.1898, -2.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4166158139705658
Epoch 0, Step 1215: train/loss = 0.12851203978061676, train/raw-loss = 0.0907338559627533, train/logprobs = tensor([[-1.1555, -8.3979],
        [-2.8456, -1.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37778180837631226
Epoch 0, Step 1216: train/loss = 0.12115542590618134, train/raw-loss = 0.08142629265785217, train/logprobs = tensor([[-0.8629, -6.6462],
        [-2.8836, -1.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972911834716797
Epoch 0, Step 1217: train/loss = 0.663632333278656, train/raw-loss = 0.6286174654960632, train/logprobs = tensor([[-0.9762, -1.4965],
        [-2.0158, -2.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35014885663986206
Epoch 0, Step 1218: train/loss = 0.25982484221458435, train/raw-loss = 0.22497957944869995, train/logprobs = tensor([[-0.6827, -7.0141],
        [-3.2482, -2.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484526574611664
Epoch 0, Step 1219: train/loss = 0.2983483672142029, train/raw-loss = 0.2608450651168823, train/logprobs = tensor([[-1.4870, -6.3320],
        [-2.9251, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37503281235694885
Epoch 0, Step 1220: train/loss = 0.9089358448982239, train/raw-loss = 0.8719054460525513, train/logprobs = tensor([[-3.5232, -5.9903],
        [-2.0324, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703044354915619
Epoch 0, Step 1221: train/loss = 0.39131850004196167, train/raw-loss = 0.36216574907302856, train/logprobs = tensor([[-1.5291, -5.1556],
        [-2.5494, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29152774810791016
Epoch 0, Step 1222: train/loss = 0.21412493288516998, train/raw-loss = 0.1799318790435791, train/logprobs = tensor([[-0.9549, -5.0983],
        [-2.7735, -1.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34193065762519836
Epoch 0, Step 1223: train/loss = 0.19352489709854126, train/raw-loss = 0.15838317573070526, train/logprobs = tensor([[-0.8643, -7.6348],
        [-2.3274, -2.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35141727328300476
Epoch 0, Step 1224: train/loss = 0.5719343423843384, train/raw-loss = 0.5330257415771484, train/logprobs = tensor([[-2.4814, -6.7450],
        [-2.4761, -1.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3890863358974457
Epoch 0, Step 1225: train/loss = 0.4184102416038513, train/raw-loss = 0.37568145990371704, train/logprobs = tensor([[-1.1333, -7.3046],
        [-2.2778, -2.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42728757858276367
Epoch 0, Step 1226: train/loss = 0.41618669033050537, train/raw-loss = 0.38430818915367126, train/logprobs = tensor([[-0.8051, -3.8388],
        [-1.7099, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31878507137298584
Epoch 0, Step 1227: train/loss = 0.5328565239906311, train/raw-loss = 0.49747994542121887, train/logprobs = tensor([[-1.7814, -4.7803],
        [-2.1330, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35376593470573425
Epoch 0, Step 1228: train/loss = 0.22446651756763458, train/raw-loss = 0.18774527311325073, train/logprobs = tensor([[-1.3434, -4.1391],
        [-3.0439, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672125041484833
Epoch 0, Step 1229: train/loss = 0.2809053063392639, train/raw-loss = 0.24214774370193481, train/logprobs = tensor([[-0.9977, -5.3745],
        [-2.8972, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38757556676864624
Epoch 0, Step 1230: train/loss = 0.34588178992271423, train/raw-loss = 0.3057135045528412, train/logprobs = tensor([[-1.3961, -4.2136],
        [-2.9906, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4016830027103424
Epoch 0, Step 1231: train/loss = 0.47590282559394836, train/raw-loss = 0.438111811876297, train/logprobs = tensor([[-1.1944, -4.5654],
        [-3.0230, -2.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37790995836257935
Epoch 0, Step 1232: train/loss = 0.5637133717536926, train/raw-loss = 0.5296726822853088, train/logprobs = tensor([[-2.1006, -5.9742],
        [-3.4095, -1.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404066264629364
Epoch 0, Step 1233: train/loss = 0.4008893072605133, train/raw-loss = 0.36527103185653687, train/logprobs = tensor([[-1.0589, -4.5954],
        [-2.2030, -1.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35618287324905396
Epoch 0, Step 1234: train/loss = 0.07613220810890198, train/raw-loss = 0.04150402918457985, train/logprobs = tensor([[-0.9431, -8.1413],
        [-3.4781, -0.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462817966938019
Epoch 0, Step 1235: train/loss = 0.4360317885875702, train/raw-loss = 0.4038494825363159, train/logprobs = tensor([[-0.9000, -3.4404],
        [-2.2367, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218231201171875
Epoch 0, Step 1236: train/loss = 0.2687729597091675, train/raw-loss = 0.23943597078323364, train/logprobs = tensor([[-0.8829, -5.1077],
        [-2.4558, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933697998523712
Epoch 0, Step 1237: train/loss = 0.6789809465408325, train/raw-loss = 0.6376721262931824, train/logprobs = tensor([[-1.4716, -2.6601],
        [-3.1321, -3.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41308826208114624
Epoch 0, Step 1238: train/loss = 0.1492287516593933, train/raw-loss = 0.11599939316511154, train/logprobs = tensor([[-1.6736, -4.7075],
        [-3.5102, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322935402393341
Epoch 0, Step 1239: train/loss = 0.5552760362625122, train/raw-loss = 0.5120667219161987, train/logprobs = tensor([[-1.5804, -2.9476],
        [-3.1742, -1.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4320935606956482
Epoch 0, Step 1240: train/loss = 0.680443286895752, train/raw-loss = 0.6408072710037231, train/logprobs = tensor([[-1.1946, -2.9767],
        [-2.5124, -2.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39636093378067017
Epoch 0, Step 1241: train/loss = 0.42867058515548706, train/raw-loss = 0.39036065340042114, train/logprobs = tensor([[-1.4089, -4.5312],
        [-2.4533, -2.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830992877483368
Epoch 0, Step 1242: train/loss = 0.2925598919391632, train/raw-loss = 0.2536112666130066, train/logprobs = tensor([[-1.7925, -4.0885],
        [-3.8185, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38948625326156616
Epoch 0, Step 1243: train/loss = 0.5335690975189209, train/raw-loss = 0.4956643581390381, train/logprobs = tensor([[-1.7438, -3.8721],
        [-3.2201, -2.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37904757261276245
Epoch 0, Step 1244: train/loss = 0.4297916293144226, train/raw-loss = 0.39423224329948425, train/logprobs = tensor([[-1.7869, -6.1999],
        [-3.0351, -2.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35559383034706116
Epoch 0, Step 1245: train/loss = 0.15029476583003998, train/raw-loss = 0.11139675974845886, train/logprobs = tensor([[-1.6111, -8.2243],
        [-3.5644, -1.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38898012042045593
Epoch 0, Step 1246: train/loss = 0.1591624617576599, train/raw-loss = 0.12486965954303741, train/logprobs = tensor([[ -1.6842, -10.6182],
        [ -3.3666,  -2.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34292808175086975
Epoch 0, Step 1247: train/loss = 0.21730998158454895, train/raw-loss = 0.175633504986763, train/logprobs = tensor([[-1.6355, -6.2182],
        [-3.9210, -1.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4167648255825043
Epoch 0, Step 1248: train/loss = 0.06233227252960205, train/raw-loss = 0.026347346603870392, train/logprobs = tensor([[ -1.4071, -12.7175],
        [ -4.9133,  -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598492741584778
Epoch 0, Step 1249: train/loss = 0.4083624482154846, train/raw-loss = 0.37757012248039246, train/logprobs = tensor([[-1.9251, -4.1858],
        [-2.5857, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079233169555664
Epoch 0, Step 1250: train/loss = 0.17462000250816345, train/raw-loss = 0.13222335278987885, train/logprobs = tensor([[-1.1985, -6.0658],
        [-4.0948, -2.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42396658658981323
Epoch 0, Step 1251: train/loss = 0.31608134508132935, train/raw-loss = 0.2743276059627533, train/logprobs = tensor([[-1.2920, -6.6729],
        [-3.5984, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175371825695038
Epoch 0, Step 1252: train/loss = 0.33901822566986084, train/raw-loss = 0.2985488772392273, train/logprobs = tensor([[-1.1164, -7.3968],
        [-3.5284, -1.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40469348430633545
Epoch 0, Step 1253: train/loss = 0.23219645023345947, train/raw-loss = 0.18792463839054108, train/logprobs = tensor([[-1.7833, -6.1820],
        [-3.5921, -2.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44271811842918396
Epoch 0, Step 1254: train/loss = 0.42773163318634033, train/raw-loss = 0.3875371515750885, train/logprobs = tensor([[-1.2861, -3.2540],
        [-2.9072, -2.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40194499492645264
Epoch 0, Step 1255: train/loss = 0.2557098865509033, train/raw-loss = 0.2172447144985199, train/logprobs = tensor([[-1.1496, -7.6050],
        [-2.9635, -1.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846517503261566
Epoch 0, Step 1256: train/loss = 0.2697073817253113, train/raw-loss = 0.23390540480613708, train/logprobs = tensor([[-1.2172, -7.1554],
        [-2.9647, -2.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35801979899406433
Epoch 0, Step 1257: train/loss = 0.34012937545776367, train/raw-loss = 0.3000320494174957, train/logprobs = tensor([[-1.2631, -4.0100],
        [-3.7967, -1.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40097305178642273
Epoch 0, Step 1258: train/loss = 0.3924640119075775, train/raw-loss = 0.353781521320343, train/logprobs = tensor([[-1.5665, -3.1442],
        [-3.4654, -1.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38682472705841064
Epoch 0, Step 1259: train/loss = 0.36346694827079773, train/raw-loss = 0.3299890160560608, train/logprobs = tensor([[-0.7320, -6.7563],
        [-2.1618, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33477914333343506
Epoch 0, Step 1260: train/loss = 0.30197301506996155, train/raw-loss = 0.2633901536464691, train/logprobs = tensor([[-1.3527, -5.8628],
        [-4.1764, -2.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858286738395691
Epoch 0, Step 1261: train/loss = 0.3646894693374634, train/raw-loss = 0.32678788900375366, train/logprobs = tensor([[-1.2107, -5.2249],
        [-2.9993, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3790159225463867
Epoch 0, Step 1262: train/loss = 0.3957430124282837, train/raw-loss = 0.3545985519886017, train/logprobs = tensor([[-0.9240, -8.0192],
        [-3.4213, -1.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4114447832107544
Epoch 0, Step 1263: train/loss = 0.7554014921188354, train/raw-loss = 0.7176549434661865, train/logprobs = tensor([[-1.2194, -1.5487],
        [-2.3439, -2.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37746602296829224
Epoch 0, Step 1264: train/loss = 0.59453284740448, train/raw-loss = 0.5517331957817078, train/logprobs = tensor([[-1.8280, -3.6690],
        [-3.7029, -2.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42799630761146545
Epoch 0, Step 1265: train/loss = 0.3992585241794586, train/raw-loss = 0.358172208070755, train/logprobs = tensor([[-1.1598, -5.1461],
        [-3.5604, -2.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41086333990097046
Epoch 0, Step 1266: train/loss = 0.16891148686408997, train/raw-loss = 0.13070742785930634, train/logprobs = tensor([[-1.2139, -7.2592],
        [-3.5359, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820403814315796
Epoch 0, Step 1267: train/loss = 0.34376758337020874, train/raw-loss = 0.30770984292030334, train/logprobs = tensor([[-1.2407, -5.0122],
        [-3.3862, -1.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3605772852897644
Epoch 0, Step 1268: train/loss = 0.13995502889156342, train/raw-loss = 0.10363589972257614, train/logprobs = tensor([[-1.0598, -7.1065],
        [-4.8507, -3.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3631913661956787
Epoch 0, Step 1269: train/loss = 0.16683977842330933, train/raw-loss = 0.1370771825313568, train/logprobs = tensor([[-1.5809, -6.0234],
        [-3.5869, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297625869512558
Epoch 0, Step 1270: train/loss = 0.339705228805542, train/raw-loss = 0.30012914538383484, train/logprobs = tensor([[-1.9874, -5.5446],
        [-3.3991, -2.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39576083421707153
Epoch 0, Step 1271: train/loss = 0.2631375193595886, train/raw-loss = 0.2260405719280243, train/logprobs = tensor([[-2.3148, -4.8967],
        [-3.4674, -1.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37096965312957764
Epoch 0, Step 1272: train/loss = 0.20331211388111115, train/raw-loss = 0.17029264569282532, train/logprobs = tensor([[-1.2298, -5.2544],
        [-3.1275, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3301946520805359
Epoch 0, Step 1273: train/loss = 0.5501098036766052, train/raw-loss = 0.5133280158042908, train/logprobs = tensor([[-1.3408, -3.8681],
        [-2.7100, -2.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36781826615333557
Epoch 0, Step 1274: train/loss = 0.08462882786989212, train/raw-loss = 0.05035119876265526, train/logprobs = tensor([[-1.1544, -9.8333],
        [-3.5202, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34277623891830444
Epoch 0, Step 1275: train/loss = 0.33473214507102966, train/raw-loss = 0.28948861360549927, train/logprobs = tensor([[-1.0876, -3.7623],
        [-3.1812, -1.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524350166320801
Epoch 0, Step 1276: train/loss = 0.33735695481300354, train/raw-loss = 0.2895447015762329, train/logprobs = tensor([[-1.3536, -3.5310],
        [-3.8344, -2.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47812262177467346
Epoch 0, Step 1277: train/loss = 0.668289065361023, train/raw-loss = 0.6308619976043701, train/logprobs = tensor([[-1.2089, -2.1242],
        [-3.2396, -2.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.374271035194397
Epoch 0, Step 1278: train/loss = 0.29460781812667847, train/raw-loss = 0.25959569215774536, train/logprobs = tensor([[-1.4271, -5.4636],
        [-2.6755, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3501214385032654
Epoch 0, Step 1279: train/loss = 0.4624595642089844, train/raw-loss = 0.41582825779914856, train/logprobs = tensor([[-1.2753, -3.3129],
        [-4.6717, -3.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46631309390068054
Epoch 0, Step 1280: train/loss = 0.21415990591049194, train/raw-loss = 0.16606789827346802, train/logprobs = tensor([[-2.4892, -5.0813],
        [-4.9422, -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48092007637023926
Epoch 0, Step 1281: train/loss = 0.1406715214252472, train/raw-loss = 0.10013816505670547, train/logprobs = tensor([[-1.4152, -6.8003],
        [-4.2636, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40533360838890076
Epoch 0, Step 1282: train/loss = 0.329181432723999, train/raw-loss = 0.2912079095840454, train/logprobs = tensor([[-1.9214, -4.0590],
        [-4.5246, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37973514199256897
Epoch 0, Step 1283: train/loss = 0.15718810260295868, train/raw-loss = 0.12201114743947983, train/logprobs = tensor([[-1.2230, -7.0579],
        [-2.7796, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517696261405945
Epoch 0, Step 1284: train/loss = 0.6281656622886658, train/raw-loss = 0.5898623466491699, train/logprobs = tensor([[-2.0633, -7.6785],
        [-3.4544, -1.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38303250074386597
Epoch 0, Step 1285: train/loss = 0.5457121729850769, train/raw-loss = 0.5057584047317505, train/logprobs = tensor([[-0.9685, -2.5209],
        [-3.8578, -1.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39953771233558655
Epoch 0, Step 1286: train/loss = 0.13892102241516113, train/raw-loss = 0.10702896118164062, train/logprobs = tensor([[-0.9563, -5.5626],
        [-2.9853, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31892067193984985
Epoch 0, Step 1287: train/loss = 0.33292776346206665, train/raw-loss = 0.29691505432128906, train/logprobs = tensor([[-1.3890, -5.0296],
        [-3.3904, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601270914077759
Epoch 0, Step 1288: train/loss = 0.3262140154838562, train/raw-loss = 0.28576385974884033, train/logprobs = tensor([[-1.1252, -4.3975],
        [-3.2948, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4045012593269348
Epoch 0, Step 1289: train/loss = 0.3308529853820801, train/raw-loss = 0.30167919397354126, train/logprobs = tensor([[-1.0953, -3.7354],
        [-2.3181, -1.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29173794388771057
Epoch 0, Step 1290: train/loss = 0.4428684711456299, train/raw-loss = 0.4040328860282898, train/logprobs = tensor([[-1.0944, -5.0119],
        [-3.2783, -2.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38835570216178894
Epoch 0, Step 1291: train/loss = 0.1579846739768982, train/raw-loss = 0.112598717212677, train/logprobs = tensor([[-1.5526, -5.3495],
        [-4.6128, -1.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45385944843292236
Epoch 0, Step 1292: train/loss = 0.30602753162384033, train/raw-loss = 0.26867976784706116, train/logprobs = tensor([[-1.7276, -8.2350],
        [-3.8304, -1.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37347736954689026
Epoch 0, Step 1293: train/loss = 0.47866106033325195, train/raw-loss = 0.437300443649292, train/logprobs = tensor([[-0.9169, -6.3289],
        [-3.4903, -1.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136057496070862
Epoch 0, Step 1294: train/loss = 0.15060484409332275, train/raw-loss = 0.10954645276069641, train/logprobs = tensor([[-0.8831, -7.9999],
        [-3.3451, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105837643146515
Epoch 0, Step 1295: train/loss = 0.8709011673927307, train/raw-loss = 0.8308846950531006, train/logprobs = tensor([[-1.8724, -2.2950],
        [-2.4570, -2.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4001644253730774
Epoch 0, Step 1296: train/loss = 0.514912486076355, train/raw-loss = 0.47452762722969055, train/logprobs = tensor([[-1.2432, -2.4247],
        [-3.3336, -2.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4038482904434204
Epoch 0, Step 1297: train/loss = 0.5471599102020264, train/raw-loss = 0.5005593299865723, train/logprobs = tensor([[-1.3814, -4.4070],
        [-3.8069, -2.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660053849220276
Epoch 0, Step 1298: train/loss = 0.6067995429039001, train/raw-loss = 0.5601934790611267, train/logprobs = tensor([[-1.5349, -2.6045],
        [-4.5842, -3.5690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660608172416687
Epoch 0, Step 1299: train/loss = 0.7101168036460876, train/raw-loss = 0.6695747375488281, train/logprobs = tensor([[-1.9972, -7.0825],
        [-3.5898, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4054211974143982
Epoch 0, Step 1300: train/loss = 0.34977585077285767, train/raw-loss = 0.30854809284210205, train/logprobs = tensor([[-1.4212, -5.0753],
        [-4.1618, -1.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122777283191681
Epoch 0, Step 1301: train/loss = 0.3235648274421692, train/raw-loss = 0.27835240960121155, train/logprobs = tensor([[-1.3332, -4.5898],
        [-3.3063, -1.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4521244466304779
Epoch 0, Step 1302: train/loss = 0.7986259460449219, train/raw-loss = 0.7588129043579102, train/logprobs = tensor([[-1.1799, -3.1392],
        [-3.2644, -3.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39812996983528137
Epoch 0, Step 1303: train/loss = 0.3776549994945526, train/raw-loss = 0.3411491811275482, train/logprobs = tensor([[-1.5931, -3.1989],
        [-3.5773, -1.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650577664375305
Epoch 0, Step 1304: train/loss = 0.482049822807312, train/raw-loss = 0.43949079513549805, train/logprobs = tensor([[-2.0118, -3.7013],
        [-4.0301, -1.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42559051513671875
Epoch 0, Step 1305: train/loss = 0.3355964422225952, train/raw-loss = 0.2971366047859192, train/logprobs = tensor([[-1.0015, -5.1581],
        [-2.9597, -1.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3845981955528259
Epoch 0, Step 1306: train/loss = 0.35500332713127136, train/raw-loss = 0.3093673288822174, train/logprobs = tensor([[-1.5214, -4.2279],
        [-4.6436, -2.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45635998249053955
Epoch 0, Step 1307: train/loss = 0.5526699423789978, train/raw-loss = 0.5157892107963562, train/logprobs = tensor([[-1.2298, -2.7219],
        [-3.1068, -2.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3688068091869354
Epoch 0, Step 1308: train/loss = 0.2743328809738159, train/raw-loss = 0.2426423877477646, train/logprobs = tensor([[-0.8773, -6.4559],
        [-2.8350, -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169049918651581
Epoch 0, Step 1309: train/loss = 0.5669183731079102, train/raw-loss = 0.5229008197784424, train/logprobs = tensor([[-1.5004, -3.0805],
        [-3.1656, -3.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4401755928993225
Epoch 0, Step 1310: train/loss = 0.21443095803260803, train/raw-loss = 0.1700763702392578, train/logprobs = tensor([[-1.8996, -8.9744],
        [-4.7600, -1.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443545937538147
Epoch 0, Step 1311: train/loss = 0.5769701600074768, train/raw-loss = 0.5296480059623718, train/logprobs = tensor([[-1.0442, -4.0218],
        [-3.3039, -2.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47322189807891846
Epoch 0, Step 1312: train/loss = 0.2901386618614197, train/raw-loss = 0.25495409965515137, train/logprobs = tensor([[-1.5077, -6.5341],
        [-3.4436, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3518456518650055
Epoch 0, Step 1313: train/loss = 0.1921449899673462, train/raw-loss = 0.15170849859714508, train/logprobs = tensor([[-1.6145, -6.3742],
        [-4.0265, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40436482429504395
Epoch 0, Step 1314: train/loss = 0.8396136164665222, train/raw-loss = 0.801002562046051, train/logprobs = tensor([[-1.9817, -2.9379],
        [-2.8976, -2.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3861103653907776
Epoch 0, Step 1315: train/loss = 0.5413138270378113, train/raw-loss = 0.49918168783187866, train/logprobs = tensor([[-0.8152, -2.9428],
        [-2.8361, -1.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4213215112686157
Epoch 0, Step 1316: train/loss = 0.31092244386672974, train/raw-loss = 0.2740100920200348, train/logprobs = tensor([[-1.1697, -3.7455],
        [-3.2418, -1.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691234886646271
Epoch 0, Step 1317: train/loss = 0.40554553270339966, train/raw-loss = 0.3630678653717041, train/logprobs = tensor([[-1.6809, -4.7454],
        [-3.9181, -2.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247765839099884
Epoch 0, Step 1318: train/loss = 0.3043053448200226, train/raw-loss = 0.2668222188949585, train/logprobs = tensor([[-1.6441, -5.8546],
        [-3.0828, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37483125925064087
Epoch 0, Step 1319: train/loss = 0.26069900393486023, train/raw-loss = 0.2274424284696579, train/logprobs = tensor([[-1.1845, -5.3520],
        [-2.9134, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33256590366363525
Epoch 0, Step 1320: train/loss = 0.2973681092262268, train/raw-loss = 0.25469696521759033, train/logprobs = tensor([[-1.5421, -6.2013],
        [-3.7417, -2.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4267115592956543
Epoch 0, Step 1321: train/loss = 0.3540639281272888, train/raw-loss = 0.3168032765388489, train/logprobs = tensor([[-1.2056, -2.6956],
        [-3.8517, -1.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726063370704651
Epoch 0, Step 1322: train/loss = 0.5326410531997681, train/raw-loss = 0.49166369438171387, train/logprobs = tensor([[-1.1309, -4.7240],
        [-3.2465, -2.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4097740054130554
Epoch 0, Step 1323: train/loss = 0.3319644331932068, train/raw-loss = 0.2968246340751648, train/logprobs = tensor([[-0.8554, -2.2315],
        [-4.2188, -1.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513980507850647
Epoch 0, Step 1324: train/loss = 0.20056967437267303, train/raw-loss = 0.16746577620506287, train/logprobs = tensor([[-1.6289, -9.6427],
        [-2.8525, -0.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310388922691345
Epoch 0, Step 1325: train/loss = 0.2914941906929016, train/raw-loss = 0.2462162971496582, train/logprobs = tensor([[-1.7211, -3.8638],
        [-3.5478, -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45277857780456543
Epoch 0, Step 1326: train/loss = 0.6471678018569946, train/raw-loss = 0.6114831566810608, train/logprobs = tensor([[-2.2237, -3.9030],
        [-3.0603, -2.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568466901779175
Epoch 0, Step 1327: train/loss = 0.374653697013855, train/raw-loss = 0.33196571469306946, train/logprobs = tensor([[-1.2387, -6.1872],
        [-3.0795, -2.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42687976360321045
Epoch 0, Step 1328: train/loss = 0.3163555860519409, train/raw-loss = 0.2757008671760559, train/logprobs = tensor([[-0.9624, -3.2720],
        [-3.3505, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40654730796813965
Epoch 0, Step 1329: train/loss = 0.20614533126354218, train/raw-loss = 0.17114555835723877, train/logprobs = tensor([[-1.2038, -5.2906],
        [-2.4007, -0.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34999772906303406
Epoch 0, Step 1330: train/loss = 0.21378736197948456, train/raw-loss = 0.17892244458198547, train/logprobs = tensor([[-1.3274, -7.0259],
        [-3.0407, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486490845680237
Epoch 0, Step 1331: train/loss = 0.1106942817568779, train/raw-loss = 0.06370706856250763, train/logprobs = tensor([[-1.3353, -5.1668],
        [-3.8084, -1.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46987205743789673
Epoch 0, Step 1332: train/loss = 0.3851025104522705, train/raw-loss = 0.3434021770954132, train/logprobs = tensor([[-1.4344, -3.0581],
        [-3.3393, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.417003333568573
Epoch 0, Step 1333: train/loss = 0.25687533617019653, train/raw-loss = 0.2157226800918579, train/logprobs = tensor([[-2.4501, -8.5045],
        [-4.4376, -2.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4115263819694519
Epoch 0, Step 1334: train/loss = 0.6032487750053406, train/raw-loss = 0.5686598420143127, train/logprobs = tensor([[-1.5704, -1.3075],
        [-2.6311, -1.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3458893895149231
Epoch 0, Step 1335: train/loss = 0.3160786032676697, train/raw-loss = 0.2786269187927246, train/logprobs = tensor([[-1.1000, -4.4658],
        [-3.7846, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3745168447494507
Epoch 0, Step 1336: train/loss = 0.45404040813446045, train/raw-loss = 0.4235724210739136, train/logprobs = tensor([[-0.9721, -6.7573],
        [-2.3768, -1.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30467963218688965
Epoch 0, Step 1337: train/loss = 0.3075736165046692, train/raw-loss = 0.27238693833351135, train/logprobs = tensor([[-1.1913, -8.1269],
        [-3.1145, -1.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35186702013015747
Epoch 0, Step 1338: train/loss = 0.2661703824996948, train/raw-loss = 0.22852787375450134, train/logprobs = tensor([[-1.1825, -7.5488],
        [-2.8753, -2.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37642502784729004
Epoch 0, Step 1339: train/loss = 0.31323835253715515, train/raw-loss = 0.2744799554347992, train/logprobs = tensor([[-1.3538, -4.7841],
        [-3.0186, -2.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875839114189148
Epoch 0, Step 1340: train/loss = 0.9469327926635742, train/raw-loss = 0.9086109399795532, train/logprobs = tensor([[-2.7553, -9.5800],
        [-2.2866, -2.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38321763277053833
Epoch 0, Step 1341: train/loss = 0.3203805685043335, train/raw-loss = 0.28379547595977783, train/logprobs = tensor([[-1.2961, -8.6541],
        [-3.6073, -1.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3658510446548462
Epoch 0, Step 1342: train/loss = 0.22900743782520294, train/raw-loss = 0.19291375577449799, train/logprobs = tensor([[-1.2394, -3.8841],
        [-3.1565, -1.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36093682050704956
Epoch 0, Step 1343: train/loss = 0.3530464172363281, train/raw-loss = 0.30963805317878723, train/logprobs = tensor([[-1.7296, -3.6795],
        [-3.0656, -1.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4340839385986328
Epoch 0, Step 1344: train/loss = 0.20270481705665588, train/raw-loss = 0.15670539438724518, train/logprobs = tensor([[-1.2801, -6.5182],
        [-4.0472, -3.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4599943161010742
Epoch 0, Step 1345: train/loss = 0.25386515259742737, train/raw-loss = 0.2145218849182129, train/logprobs = tensor([[-1.2000, -5.9620],
        [-3.4389, -2.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3934326767921448
Epoch 0, Step 1346: train/loss = 0.22907119989395142, train/raw-loss = 0.19244235754013062, train/logprobs = tensor([[-1.6653, -9.7662],
        [-3.2136, -1.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36628836393356323
Epoch 0, Step 1347: train/loss = 0.5633333325386047, train/raw-loss = 0.5285628437995911, train/logprobs = tensor([[-1.2067, -5.8495],
        [-2.6528, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477054238319397
Epoch 0, Step 1348: train/loss = 0.41625794768333435, train/raw-loss = 0.36862629652023315, train/logprobs = tensor([[-1.2550, -5.7115],
        [-4.0457, -2.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4763163924217224
Epoch 0, Step 1349: train/loss = 0.3541327714920044, train/raw-loss = 0.31891244649887085, train/logprobs = tensor([[-1.0105, -5.7584],
        [-3.4890, -1.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522035777568817
Epoch 0, Step 1350: train/loss = 0.28724032640457153, train/raw-loss = 0.2582307457923889, train/logprobs = tensor([[-0.9709, -5.2209],
        [-1.5399, -1.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900956869125366
Epoch 0, Step 1351: train/loss = 0.43641626834869385, train/raw-loss = 0.3943495750427246, train/logprobs = tensor([[-1.5404, -4.4724],
        [-4.4748, -2.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42066681385040283
Epoch 0, Step 1352: train/loss = 0.6188064217567444, train/raw-loss = 0.583011269569397, train/logprobs = tensor([[-1.1893, -2.1877],
        [-2.7687, -1.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579515814781189
Epoch 0, Step 1353: train/loss = 0.31193801760673523, train/raw-loss = 0.2772826552391052, train/logprobs = tensor([[-2.1542, -7.6269],
        [-2.9823, -2.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34655362367630005
Epoch 0, Step 1354: train/loss = 0.27740105986595154, train/raw-loss = 0.23734760284423828, train/logprobs = tensor([[-1.0793, -6.9452],
        [-3.6508, -2.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40053480863571167
Epoch 0, Step 1355: train/loss = 0.411141574382782, train/raw-loss = 0.3663412034511566, train/logprobs = tensor([[-1.3979, -4.8079],
        [-3.5878, -1.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4480038583278656
Epoch 0, Step 1356: train/loss = 0.6302988529205322, train/raw-loss = 0.6033037304878235, train/logprobs = tensor([[-2.6647, -9.5224],
        [-1.7808, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26995140314102173
Epoch 0, Step 1357: train/loss = 0.4824376702308655, train/raw-loss = 0.4398985803127289, train/logprobs = tensor([[-0.9966, -4.7330],
        [-3.3143, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42539095878601074
Epoch 0, Step 1358: train/loss = 0.4239186942577362, train/raw-loss = 0.37521687150001526, train/logprobs = tensor([[-1.5405, -3.9534],
        [-3.7982, -2.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4870184659957886
Epoch 0, Step 1359: train/loss = 0.26579219102859497, train/raw-loss = 0.22398976981639862, train/logprobs = tensor([[-1.8166, -6.8931],
        [-3.8490, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4180242419242859
Epoch 0, Step 1360: train/loss = 0.3553939759731293, train/raw-loss = 0.31620222330093384, train/logprobs = tensor([[-1.2462, -3.3671],
        [-3.3640, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919171690940857
Epoch 0, Step 1361: train/loss = 0.5288661122322083, train/raw-loss = 0.49059146642684937, train/logprobs = tensor([[-1.7914, -2.9669],
        [-3.1007, -2.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38274645805358887
Epoch 0, Step 1362: train/loss = 0.25429853796958923, train/raw-loss = 0.21807779371738434, train/logprobs = tensor([[-1.2235, -4.1199],
        [-3.7200, -1.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3622075319290161
Epoch 0, Step 1363: train/loss = 0.3991190493106842, train/raw-loss = 0.3559405207633972, train/logprobs = tensor([[-1.2797, -4.2706],
        [-3.5347, -2.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4317854642868042
Epoch 0, Step 1364: train/loss = 0.68672776222229, train/raw-loss = 0.6439575552940369, train/logprobs = tensor([[-2.1335, -6.2799],
        [-2.9054, -2.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42770254611968994
Epoch 0, Step 1365: train/loss = 0.8693692684173584, train/raw-loss = 0.8278365135192871, train/logprobs = tensor([[-1.3454, -1.5732],
        [-2.9661, -2.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41532814502716064
Epoch 0, Step 1366: train/loss = 0.23569294810295105, train/raw-loss = 0.20551656186580658, train/logprobs = tensor([[-1.3410, -9.8153],
        [-3.1877, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30176371335983276
Epoch 0, Step 1367: train/loss = 1.1702367067337036, train/raw-loss = 1.1165584325790405, train/logprobs = tensor([[-2.8364, -3.6537],
        [-2.5387, -2.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5367818474769592
Epoch 0, Step 1368: train/loss = 0.5006310939788818, train/raw-loss = 0.4640243351459503, train/logprobs = tensor([[-0.9209, -3.0444],
        [-2.9013, -1.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36606770753860474
Epoch 0, Step 1369: train/loss = 0.8938683271408081, train/raw-loss = 0.8523009419441223, train/logprobs = tensor([[-1.7678, -2.4611],
        [-2.4892, -2.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4156739413738251
Epoch 0, Step 1370: train/loss = 0.17584624886512756, train/raw-loss = 0.13981503248214722, train/logprobs = tensor([[-1.1268, -6.1664],
        [-3.6949, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3603120744228363
Epoch 0, Step 1371: train/loss = 0.47740277647972107, train/raw-loss = 0.4372963011264801, train/logprobs = tensor([[-2.9984, -6.8486],
        [-3.6293, -1.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010649025440216
Epoch 0, Step 1372: train/loss = 0.4273286461830139, train/raw-loss = 0.38303419947624207, train/logprobs = tensor([[-1.8108, -4.5323],
        [-3.8891, -2.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429439306259155
Epoch 0, Step 1373: train/loss = 0.5385429263114929, train/raw-loss = 0.5009918212890625, train/logprobs = tensor([[-2.4892, -7.7915],
        [-2.4081, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37551113963127136
Epoch 0, Step 1374: train/loss = 0.4341323971748352, train/raw-loss = 0.3888920545578003, train/logprobs = tensor([[-1.1748, -2.1810],
        [-3.2081, -2.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524035155773163
Epoch 0, Step 1375: train/loss = 0.3308061957359314, train/raw-loss = 0.28439971804618835, train/logprobs = tensor([[-1.4077, -4.1141],
        [-3.5065, -1.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640645980834961
Epoch 0, Step 1376: train/loss = 0.6534041166305542, train/raw-loss = 0.6182563304901123, train/logprobs = tensor([[-1.4613, -1.8014],
        [-2.4060, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514775037765503
Epoch 0, Step 1377: train/loss = 0.3249785602092743, train/raw-loss = 0.29247528314590454, train/logprobs = tensor([[-1.6707, -5.6630],
        [-3.1058, -2.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32503244280815125
Epoch 0, Step 1378: train/loss = 0.35075658559799194, train/raw-loss = 0.30902597308158875, train/logprobs = tensor([[-2.4209, -8.0210],
        [-3.7193, -1.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4173060655593872
Epoch 0, Step 1379: train/loss = 0.27174586057662964, train/raw-loss = 0.23423554003238678, train/logprobs = tensor([[-1.2209, -4.9204],
        [-3.5663, -2.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751029968261719
Epoch 0, Step 1380: train/loss = 0.29329559206962585, train/raw-loss = 0.2561880946159363, train/logprobs = tensor([[-1.7387, -3.9604],
        [-3.7683, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37107494473457336
Epoch 0, Step 1381: train/loss = 0.38610002398490906, train/raw-loss = 0.3461068272590637, train/logprobs = tensor([[-1.7945, -6.5484],
        [-3.1862, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39993196725845337
Epoch 0, Step 1382: train/loss = 0.2645893692970276, train/raw-loss = 0.22189664840698242, train/logprobs = tensor([[-1.0389, -5.8525],
        [-2.9191, -2.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42692703008651733
Epoch 0, Step 1383: train/loss = 0.4469408690929413, train/raw-loss = 0.40707045793533325, train/logprobs = tensor([[-1.2779, -2.9676],
        [-3.0424, -2.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39870402216911316
Epoch 0, Step 1384: train/loss = 0.6240615844726562, train/raw-loss = 0.5823097229003906, train/logprobs = tensor([[-1.1855, -5.0691],
        [-3.3663, -2.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41751885414123535
Epoch 0, Step 1385: train/loss = 0.21325936913490295, train/raw-loss = 0.17696188390254974, train/logprobs = tensor([[-1.3868, -6.0105],
        [-2.6907, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36297497153282166
Epoch 0, Step 1386: train/loss = 0.2818729877471924, train/raw-loss = 0.23451271653175354, train/logprobs = tensor([[-1.1452, -5.5027],
        [-3.5993, -2.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47360315918922424
Epoch 0, Step 1387: train/loss = 0.5099197030067444, train/raw-loss = 0.469936728477478, train/logprobs = tensor([[-1.5948, -3.8828],
        [-3.8869, -2.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998301327228546
Epoch 0, Step 1388: train/loss = 0.5765169262886047, train/raw-loss = 0.5289175510406494, train/logprobs = tensor([[-1.2894, -4.0341],
        [-3.5052, -2.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4759930372238159
Epoch 0, Step 1389: train/loss = 0.5913615226745605, train/raw-loss = 0.5549854040145874, train/logprobs = tensor([[-1.8856, -3.4005],
        [-2.6034, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36376163363456726
Epoch 0, Step 1390: train/loss = 0.18171805143356323, train/raw-loss = 0.14798177778720856, train/logprobs = tensor([[ -1.7528, -13.0434],
        [ -3.5122,  -1.2894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33736279606819153
Epoch 0, Step 1391: train/loss = 0.3793501555919647, train/raw-loss = 0.3432481586933136, train/logprobs = tensor([[-1.5304, -6.1266],
        [-3.6813, -2.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610196113586426
Epoch 0, Step 1392: train/loss = 0.11938512325286865, train/raw-loss = 0.07662323117256165, train/logprobs = tensor([[-1.6360, -5.2873],
        [-4.2469, -0.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42761892080307007
Epoch 0, Step 1393: train/loss = 0.4906378388404846, train/raw-loss = 0.449721097946167, train/logprobs = tensor([[-1.1437, -1.9881],
        [-2.8487, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4091675281524658
Epoch 0, Step 1394: train/loss = 0.7066062688827515, train/raw-loss = 0.6760596036911011, train/logprobs = tensor([[-2.1667, -4.1916],
        [-1.5709, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30546700954437256
Epoch 0, Step 1395: train/loss = 0.2643476128578186, train/raw-loss = 0.2276921421289444, train/logprobs = tensor([[-1.4686, -6.5769],
        [-2.6527, -2.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.366554856300354
Epoch 0, Step 1396: train/loss = 0.27840396761894226, train/raw-loss = 0.24078769981861115, train/logprobs = tensor([[-1.0064, -7.3431],
        [-3.1562, -1.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37616246938705444
Epoch 0, Step 1397: train/loss = 0.6328119039535522, train/raw-loss = 0.5972625613212585, train/logprobs = tensor([[-1.0253, -1.3365],
        [-2.0672, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35549402236938477
Epoch 0, Step 1398: train/loss = 0.28209441900253296, train/raw-loss = 0.2500566840171814, train/logprobs = tensor([[-1.6177, -3.9972],
        [-2.9508, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320377379655838
Epoch 0, Step 1399: train/loss = 0.3720815181732178, train/raw-loss = 0.33940935134887695, train/logprobs = tensor([[-1.7509, -4.3935],
        [-3.2771, -1.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267216086387634
Epoch 0, Step 1400: train/loss = 0.08806152641773224, train/raw-loss = 0.05034521594643593, train/logprobs = tensor([[-2.2852, -5.6457],
        [-5.3414, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3771631121635437
Epoch 0, Step 1401: train/loss = 0.7220726609230042, train/raw-loss = 0.6775318384170532, train/logprobs = tensor([[-1.2871, -2.2979],
        [-3.2010, -2.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44540801644325256
Epoch 0, Step 1402: train/loss = 0.27802836894989014, train/raw-loss = 0.24117720127105713, train/logprobs = tensor([[-1.2425, -8.0182],
        [-3.1153, -3.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36851179599761963
Epoch 0, Step 1403: train/loss = 0.35427749156951904, train/raw-loss = 0.31437528133392334, train/logprobs = tensor([[-1.6263, -8.9348],
        [-3.4043, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990222215652466
Epoch 0, Step 1404: train/loss = 0.42586013674736023, train/raw-loss = 0.38061267137527466, train/logprobs = tensor([[-1.4186, -4.6161],
        [-3.9352, -2.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45247435569763184
Epoch 0, Step 1405: train/loss = 0.3424089848995209, train/raw-loss = 0.30752551555633545, train/logprobs = tensor([[-1.3218, -3.7641],
        [-2.7643, -2.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488348722457886
Epoch 0, Step 1406: train/loss = 0.11683356761932373, train/raw-loss = 0.07884813845157623, train/logprobs = tensor([[-1.3146, -4.8025],
        [-4.1399, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37985432147979736
Epoch 0, Step 1407: train/loss = 0.6365412473678589, train/raw-loss = 0.5978522896766663, train/logprobs = tensor([[-1.3852, -2.1009],
        [-2.8478, -2.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868895471096039
Epoch 0, Step 1408: train/loss = 0.8961204290390015, train/raw-loss = 0.8527885675430298, train/logprobs = tensor([[-2.5566, -5.6226],
        [-2.1488, -1.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43331846594810486
Epoch 0, Step 1409: train/loss = 0.3968724012374878, train/raw-loss = 0.3634158670902252, train/logprobs = tensor([[-0.9266, -6.7296],
        [-2.0942, -1.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33456501364707947
Epoch 0, Step 1410: train/loss = 0.5363073348999023, train/raw-loss = 0.5001562833786011, train/logprobs = tensor([[-1.9586, -3.9694],
        [-2.5368, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615109920501709
Epoch 0, Step 1411: train/loss = 0.29704397916793823, train/raw-loss = 0.2652319669723511, train/logprobs = tensor([[-1.5497, -9.3505],
        [-2.6325, -1.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181201219558716
Epoch 0, Step 1412: train/loss = 0.6109733581542969, train/raw-loss = 0.5703580379486084, train/logprobs = tensor([[-1.4817, -1.9859],
        [-2.2042, -1.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061531126499176
Epoch 0, Step 1413: train/loss = 0.5222923159599304, train/raw-loss = 0.48381179571151733, train/logprobs = tensor([[-1.2152, -1.9919],
        [-2.7021, -2.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38480478525161743
Epoch 0, Step 1414: train/loss = 0.1967892348766327, train/raw-loss = 0.16225028038024902, train/logprobs = tensor([[-1.4122, -6.7663],
        [-2.8590, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34538933634757996
Epoch 0, Step 1415: train/loss = 0.5232089161872864, train/raw-loss = 0.4859367311000824, train/logprobs = tensor([[-1.5455, -3.1484],
        [-2.8382, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727218508720398
Epoch 0, Step 1416: train/loss = 0.43821561336517334, train/raw-loss = 0.39608079195022583, train/logprobs = tensor([[-2.0108, -4.3851],
        [-2.7144, -1.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42134779691696167
Epoch 0, Step 1417: train/loss = 0.15533585846424103, train/raw-loss = 0.11672279238700867, train/logprobs = tensor([[-1.3966, -5.2450],
        [-3.8994, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.386130690574646
Epoch 0, Step 1418: train/loss = 0.22944557666778564, train/raw-loss = 0.1910373717546463, train/logprobs = tensor([[-1.5067, -8.8798],
        [-3.8247, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38408195972442627
Epoch 0, Step 1419: train/loss = 0.45535188913345337, train/raw-loss = 0.41507983207702637, train/logprobs = tensor([[-1.3495, -4.0714],
        [-2.5300, -2.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40272077918052673
Epoch 0, Step 1420: train/loss = 0.25069934129714966, train/raw-loss = 0.21987584233283997, train/logprobs = tensor([[-2.3117, -7.1306],
        [-3.5870, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30823472142219543
Epoch 0, Step 1421: train/loss = 0.43407148122787476, train/raw-loss = 0.3975706100463867, train/logprobs = tensor([[-2.0250, -4.6946],
        [-2.1938, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650088310241699
Epoch 0, Step 1422: train/loss = 0.22553882002830505, train/raw-loss = 0.18834105134010315, train/logprobs = tensor([[-1.7869, -7.4650],
        [-3.0181, -1.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719777762889862
Epoch 0, Step 1423: train/loss = 1.2694101333618164, train/raw-loss = 1.2325830459594727, train/logprobs = tensor([[-4.7949, -4.9082],
        [-2.3598, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.368271142244339
Epoch 0, Step 1424: train/loss = 0.25656890869140625, train/raw-loss = 0.22100205719470978, train/logprobs = tensor([[-1.4270, -5.9208],
        [-3.4835, -0.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35566866397857666
Epoch 0, Step 1425: train/loss = 0.415274977684021, train/raw-loss = 0.3853394091129303, train/logprobs = tensor([[ -2.0520, -10.4351],
        [ -2.5524,  -1.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29935556650161743
Epoch 0, Step 1426: train/loss = 0.40649813413619995, train/raw-loss = 0.3714398145675659, train/logprobs = tensor([[-1.7475, -3.8339],
        [-2.4502, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35058310627937317
Epoch 0, Step 1427: train/loss = 0.7127483487129211, train/raw-loss = 0.666015625, train/logprobs = tensor([[-1.3611, -2.5968],
        [-3.8678, -3.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46732714772224426
Epoch 0, Step 1428: train/loss = 0.40957409143447876, train/raw-loss = 0.3595627248287201, train/logprobs = tensor([[-2.4018, -6.3075],
        [-4.2046, -2.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001135468482971
Epoch 0, Step 1429: train/loss = 0.08380812406539917, train/raw-loss = 0.04512874782085419, train/logprobs = tensor([[-1.2786, -8.2085],
        [-3.7282, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3867937922477722
Epoch 0, Step 1430: train/loss = 0.16576755046844482, train/raw-loss = 0.12777839601039886, train/logprobs = tensor([[-0.9227, -8.8525],
        [-2.7623, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3798915147781372
Epoch 0, Step 1431: train/loss = 0.44852232933044434, train/raw-loss = 0.41067779064178467, train/logprobs = tensor([[-1.7401, -5.9981],
        [-3.2542, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37844550609588623
Epoch 0, Step 1432: train/loss = 0.17407748103141785, train/raw-loss = 0.13795512914657593, train/logprobs = tensor([[-1.6724, -5.6940],
        [-3.7225, -1.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36122360825538635
Epoch 0, Step 1433: train/loss = 0.30506661534309387, train/raw-loss = 0.26512610912323, train/logprobs = tensor([[-1.2902, -4.7149],
        [-2.5405, -2.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3994048237800598
Epoch 0, Step 1434: train/loss = 0.7753094434738159, train/raw-loss = 0.7339217662811279, train/logprobs = tensor([[-1.7704, -1.9674],
        [-2.2988, -2.4056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41387686133384705
Epoch 0, Step 1435: train/loss = 0.3080287575721741, train/raw-loss = 0.273166686296463, train/logprobs = tensor([[-1.5814, -3.8145],
        [-3.0658, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486204147338867
Epoch 0, Step 1436: train/loss = 0.7775508165359497, train/raw-loss = 0.7400255799293518, train/logprobs = tensor([[-3.5524, -6.0110],
        [-3.1379, -1.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37525230646133423
Epoch 0, Step 1437: train/loss = 0.5916294455528259, train/raw-loss = 0.5551144480705261, train/logprobs = tensor([[-2.7416, -5.0943],
        [-2.4084, -0.7475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36515024304389954
Epoch 0, Step 1438: train/loss = 0.5101258754730225, train/raw-loss = 0.46795475482940674, train/logprobs = tensor([[-1.0117, -2.5471],
        [-3.0465, -2.3178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217110872268677
Epoch 0, Step 1439: train/loss = 0.14994880557060242, train/raw-loss = 0.10880807787179947, train/logprobs = tensor([[ -2.4452, -11.6178],
        [ -4.2387,  -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41140711307525635
Epoch 0, Step 1440: train/loss = 0.5641534328460693, train/raw-loss = 0.5133202075958252, train/logprobs = tensor([[-1.9531, -4.1582],
        [-4.5490, -3.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5083327293395996
Epoch 0, Step 1441: train/loss = 0.32910066843032837, train/raw-loss = 0.28600743412971497, train/logprobs = tensor([[-2.0040, -5.1869],
        [-3.9487, -1.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4309324622154236
Epoch 0, Step 1442: train/loss = 0.28225553035736084, train/raw-loss = 0.24222850799560547, train/logprobs = tensor([[-1.8339, -4.0718],
        [-4.1107, -1.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002702534198761
Epoch 0, Step 1443: train/loss = 0.18629467487335205, train/raw-loss = 0.1479516625404358, train/logprobs = tensor([[-1.8252, -5.7952],
        [-3.7477, -1.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38343003392219543
Epoch 0, Step 1444: train/loss = 0.4793301224708557, train/raw-loss = 0.4362373352050781, train/logprobs = tensor([[-1.7408, -3.8900],
        [-3.0311, -2.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.430927574634552
Epoch 0, Step 1445: train/loss = 0.26716628670692444, train/raw-loss = 0.23240719735622406, train/logprobs = tensor([[-1.8247, -6.3572],
        [-2.7442, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34759092330932617
Epoch 0, Step 1446: train/loss = 0.13793990015983582, train/raw-loss = 0.10897478461265564, train/logprobs = tensor([[-0.9860, -8.4407],
        [-2.6048, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.289651095867157
Epoch 0, Step 1447: train/loss = 0.357566773891449, train/raw-loss = 0.3252609372138977, train/logprobs = tensor([[-1.4242, -4.2379],
        [-2.2510, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230587840080261
Epoch 0, Step 1448: train/loss = 0.45213598012924194, train/raw-loss = 0.40898531675338745, train/logprobs = tensor([[-1.8605, -7.9046],
        [-4.1033, -2.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4315069019794464
Epoch 0, Step 1449: train/loss = 0.49073928594589233, train/raw-loss = 0.44736039638519287, train/logprobs = tensor([[-0.8239, -3.4631],
        [-3.2576, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337884783744812
Epoch 0, Step 1450: train/loss = 0.5768651962280273, train/raw-loss = 0.5333774089813232, train/logprobs = tensor([[-1.2972, -2.3580],
        [-3.4764, -2.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4348781704902649
Epoch 0, Step 1451: train/loss = 0.3382773697376251, train/raw-loss = 0.307589054107666, train/logprobs = tensor([[-1.2954, -4.7891],
        [-2.6145, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30688321590423584
Epoch 0, Step 1452: train/loss = 0.5010172724723816, train/raw-loss = 0.46426695585250854, train/logprobs = tensor([[-1.4960, -3.4081],
        [-2.2318, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36750340461730957
Epoch 0, Step 1453: train/loss = 0.1698674112558365, train/raw-loss = 0.1305670589208603, train/logprobs = tensor([[-2.1454, -9.2105],
        [-4.5942, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3930036723613739
Epoch 0, Step 1454: train/loss = 0.2977719008922577, train/raw-loss = 0.26454371213912964, train/logprobs = tensor([[-1.5148, -8.6824],
        [-3.2580, -2.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322818875312805
Epoch 0, Step 1455: train/loss = 0.14764541387557983, train/raw-loss = 0.11510740220546722, train/logprobs = tensor([[-1.2966, -7.0447],
        [-3.0895, -2.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253801167011261
Epoch 0, Step 1456: train/loss = 0.13211442530155182, train/raw-loss = 0.0973266065120697, train/logprobs = tensor([[-0.8644, -7.9620],
        [-2.7644, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3478781580924988
Epoch 0, Step 1457: train/loss = 0.2650860548019409, train/raw-loss = 0.23110288381576538, train/logprobs = tensor([[-1.4371, -5.3142],
        [-2.3783, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33983153104782104
Epoch 0, Step 1458: train/loss = 0.42469948530197144, train/raw-loss = 0.395704448223114, train/logprobs = tensor([[-3.0715, -8.2184],
        [-2.8664, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28995025157928467
Epoch 0, Step 1459: train/loss = 0.3463204503059387, train/raw-loss = 0.3094787001609802, train/logprobs = tensor([[-1.3661, -4.3486],
        [-2.1260, -1.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3684171736240387
Epoch 0, Step 1460: train/loss = 0.6258714199066162, train/raw-loss = 0.5929847955703735, train/logprobs = tensor([[-2.1286, -3.8397],
        [-1.9682, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886654138565063
Epoch 0, Step 1461: train/loss = 0.35135334730148315, train/raw-loss = 0.3175821304321289, train/logprobs = tensor([[-0.7982, -4.8540],
        [-2.2325, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33771225810050964
Epoch 0, Step 1462: train/loss = 0.5444306135177612, train/raw-loss = 0.5110592842102051, train/logprobs = tensor([[-1.2924, -2.7225],
        [-2.2066, -1.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337133824825287
Epoch 0, Step 1463: train/loss = 0.26086854934692383, train/raw-loss = 0.2237268090248108, train/logprobs = tensor([[-1.5837, -6.2894],
        [-3.4218, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714175820350647
Epoch 0, Step 1464: train/loss = 0.4810160994529724, train/raw-loss = 0.44654586911201477, train/logprobs = tensor([[-2.1368, -6.2356],
        [-2.0716, -1.4401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447020947933197
Epoch 0, Step 1465: train/loss = 0.2166706919670105, train/raw-loss = 0.18469589948654175, train/logprobs = tensor([[ -1.4478, -11.4442],
        [ -3.7431,  -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31974780559539795
Epoch 0, Step 1466: train/loss = 0.32094839215278625, train/raw-loss = 0.28934693336486816, train/logprobs = tensor([[-2.3621, -5.6662],
        [-3.4803, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160143196582794
Epoch 0, Step 1467: train/loss = 0.8063762187957764, train/raw-loss = 0.7652626633644104, train/logprobs = tensor([[-1.3288, -2.2970],
        [-3.0942, -2.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4111357033252716
Epoch 0, Step 1468: train/loss = 0.36456507444381714, train/raw-loss = 0.3273278474807739, train/logprobs = tensor([[-1.5712, -6.1401],
        [-1.9320, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3723723888397217
Epoch 0, Step 1469: train/loss = 0.5094985961914062, train/raw-loss = 0.468843013048172, train/logprobs = tensor([[-1.8726, -4.0316],
        [-2.9902, -2.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40655604004859924
Epoch 0, Step 1470: train/loss = 0.18183103203773499, train/raw-loss = 0.1457405388355255, train/logprobs = tensor([[-1.5530, -8.3681],
        [-2.8379, -0.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609049320220947
Epoch 0, Step 1471: train/loss = 0.6110894680023193, train/raw-loss = 0.5745543241500854, train/logprobs = tensor([[-2.1438, -3.8679],
        [-2.6127, -1.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36535143852233887
Epoch 0, Step 1472: train/loss = 0.6377993822097778, train/raw-loss = 0.6001203656196594, train/logprobs = tensor([[-1.8911, -2.2565],
        [-3.1968, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37679022550582886
Epoch 0, Step 1473: train/loss = 0.35880133509635925, train/raw-loss = 0.3188644051551819, train/logprobs = tensor([[-1.9951, -9.5459],
        [-3.8295, -2.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39936941862106323
Epoch 0, Step 1474: train/loss = 0.29136598110198975, train/raw-loss = 0.25690191984176636, train/logprobs = tensor([[-1.5987, -5.2768],
        [-3.1915, -1.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3446406126022339
Epoch 0, Step 1475: train/loss = 0.3462633490562439, train/raw-loss = 0.30625832080841064, train/logprobs = tensor([[-2.4730, -4.8051],
        [-3.5477, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40005019307136536
Epoch 0, Step 1476: train/loss = 0.4428366720676422, train/raw-loss = 0.40338197350502014, train/logprobs = tensor([[-2.2189, -5.3868],
        [-3.5479, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3945470452308655
Epoch 0, Step 1477: train/loss = 0.3871423602104187, train/raw-loss = 0.3515918254852295, train/logprobs = tensor([[-0.9721, -2.0034],
        [-2.1907, -0.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555055558681488
Epoch 0, Step 1478: train/loss = 0.13770440220832825, train/raw-loss = 0.10190463066101074, train/logprobs = tensor([[-1.3966, -8.4635],
        [-2.9866, -1.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579977750778198
Epoch 0, Step 1479: train/loss = 0.4203208088874817, train/raw-loss = 0.38367190957069397, train/logprobs = tensor([[-1.4666, -3.6229],
        [-2.6796, -1.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36648881435394287
Epoch 0, Step 1480: train/loss = 0.3692868649959564, train/raw-loss = 0.3255871832370758, train/logprobs = tensor([[-1.2738, -4.1080],
        [-2.8615, -1.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4369969069957733
Epoch 0, Step 1481: train/loss = 0.2130354791879654, train/raw-loss = 0.18066143989562988, train/logprobs = tensor([[-1.1658, -6.0750],
        [-2.5048, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237404227256775
Epoch 0, Step 1482: train/loss = 0.35088807344436646, train/raw-loss = 0.3147542476654053, train/logprobs = tensor([[-1.1219, -4.8099],
        [-2.6669, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36133819818496704
Epoch 0, Step 1483: train/loss = 0.6925021409988403, train/raw-loss = 0.6601154208183289, train/logprobs = tensor([[ -3.4755, -10.3251],
        [ -2.4316,  -0.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3238673806190491
Epoch 0, Step 1484: train/loss = 0.5115630626678467, train/raw-loss = 0.48105525970458984, train/logprobs = tensor([[-2.7638, -7.3262],
        [-2.4010, -1.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30507761240005493
Epoch 0, Step 1485: train/loss = 0.5133039951324463, train/raw-loss = 0.4729468524456024, train/logprobs = tensor([[-1.4230, -4.2260],
        [-2.9358, -1.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40357163548469543
Epoch 0, Step 1486: train/loss = 0.2994537353515625, train/raw-loss = 0.2618609666824341, train/logprobs = tensor([[-0.9162, -3.9871],
        [-2.4848, -1.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37592804431915283
Epoch 0, Step 1487: train/loss = 0.3537316918373108, train/raw-loss = 0.31444206833839417, train/logprobs = tensor([[-2.1047, -6.1775],
        [-3.1753, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928961753845215
Epoch 0, Step 1488: train/loss = 0.17634432017803192, train/raw-loss = 0.14834006130695343, train/logprobs = tensor([[-1.3090, -8.2655],
        [-2.5775, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800426483154297
Epoch 0, Step 1489: train/loss = 0.32598093152046204, train/raw-loss = 0.2882891297340393, train/logprobs = tensor([[-1.1206, -4.2339],
        [-3.0633, -1.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37691807746887207
Epoch 0, Step 1490: train/loss = 0.4625072479248047, train/raw-loss = 0.4368038773536682, train/logprobs = tensor([[-2.3043, -4.4045],
        [-2.1328, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570335865020752
Epoch 0, Step 1491: train/loss = 0.49357783794403076, train/raw-loss = 0.46402424573898315, train/logprobs = tensor([[-2.1158, -3.8145],
        [-1.9068, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955361008644104
Epoch 0, Step 1492: train/loss = 0.28522929549217224, train/raw-loss = 0.246253103017807, train/logprobs = tensor([[-0.9827, -4.0300],
        [-2.7489, -1.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38976186513900757
Epoch 0, Step 1493: train/loss = 0.3064418137073517, train/raw-loss = 0.26823341846466064, train/logprobs = tensor([[-1.0432, -5.8516],
        [-3.0203, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820837736129761
Epoch 0, Step 1494: train/loss = 0.46325695514678955, train/raw-loss = 0.42593711614608765, train/logprobs = tensor([[-0.8775, -3.3920],
        [-2.2620, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37319859862327576
Epoch 0, Step 1495: train/loss = 1.1240040063858032, train/raw-loss = 1.0990198850631714, train/logprobs = tensor([[-3.7378, -6.4400],
        [-1.5910, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498420774936676
Epoch 0, Step 1496: train/loss = 0.07557377964258194, train/raw-loss = 0.03925979882478714, train/logprobs = tensor([[-1.3929, -9.7294],
        [-4.0628, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363139808177948
Epoch 0, Step 1497: train/loss = 0.31974130868911743, train/raw-loss = 0.28376027941703796, train/logprobs = tensor([[-1.0917, -4.1404],
        [-2.2424, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598101735115051
Epoch 0, Step 1498: train/loss = 1.0625988245010376, train/raw-loss = 1.0326764583587646, train/logprobs = tensor([[-4.4888, -9.5691],
        [-2.2418, -1.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992233633995056
Epoch 0, Step 1499: train/loss = 0.2596202790737152, train/raw-loss = 0.22459885478019714, train/logprobs = tensor([[-1.5766, -6.3373],
        [-3.1274, -1.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502143621444702
Epoch 0, Step 1500: train/loss = 0.3948426842689514, train/raw-loss = 0.3615218997001648, train/logprobs = tensor([[-0.8617, -4.3933],
        [-2.5239, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33320748805999756
Epoch 0, Step 1501: train/loss = 0.3508146107196808, train/raw-loss = 0.31173813343048096, train/logprobs = tensor([[-1.4542, -3.4468],
        [-2.5490, -1.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3907647430896759
Epoch 0, Step 1502: train/loss = 0.3398953974246979, train/raw-loss = 0.30226731300354004, train/logprobs = tensor([[-1.2625, -3.8589],
        [-3.5028, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762807548046112
Epoch 0, Step 1503: train/loss = 0.2237744927406311, train/raw-loss = 0.19424819946289062, train/logprobs = tensor([[-1.1997, -7.9279],
        [-2.1860, -1.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952631115913391
Epoch 0, Step 1504: train/loss = 0.5241512060165405, train/raw-loss = 0.4913172721862793, train/logprobs = tensor([[-1.6465, -3.3953],
        [-2.8607, -1.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283393085002899
Epoch 0, Step 1505: train/loss = 0.3586074411869049, train/raw-loss = 0.3206871449947357, train/logprobs = tensor([[-1.4372, -3.3600],
        [-3.1254, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37920308113098145
Epoch 0, Step 1506: train/loss = 0.21918991208076477, train/raw-loss = 0.18827301263809204, train/logprobs = tensor([[-1.8064, -8.5447],
        [-3.6463, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30916905403137207
Epoch 0, Step 1507: train/loss = 0.44177016615867615, train/raw-loss = 0.40749895572662354, train/logprobs = tensor([[-1.3574, -3.8623],
        [-1.9322, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427121639251709
Epoch 0, Step 1508: train/loss = 0.1959415078163147, train/raw-loss = 0.15166543424129486, train/logprobs = tensor([[-1.9120, -6.2664],
        [-4.1431, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.442760705947876
Epoch 0, Step 1509: train/loss = 0.3344518542289734, train/raw-loss = 0.30442869663238525, train/logprobs = tensor([[-2.7718, -7.5897],
        [-3.0774, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30023193359375
Epoch 0, Step 1510: train/loss = 0.39403393864631653, train/raw-loss = 0.36056801676750183, train/logprobs = tensor([[-1.6342, -5.0607],
        [-2.4438, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33465924859046936
Epoch 0, Step 1511: train/loss = 0.08686535805463791, train/raw-loss = 0.04994392767548561, train/logprobs = tensor([[-1.3612, -6.8513],
        [-3.8301, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692142963409424
Epoch 0, Step 1512: train/loss = 0.5728862285614014, train/raw-loss = 0.5345350503921509, train/logprobs = tensor([[-1.7590, -5.3354],
        [-2.9009, -1.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3835117816925049
Epoch 0, Step 1513: train/loss = 0.36713212728500366, train/raw-loss = 0.3308323621749878, train/logprobs = tensor([[-1.3063, -4.7214],
        [-3.6409, -2.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629975914955139
Epoch 0, Step 1514: train/loss = 0.4307671785354614, train/raw-loss = 0.40051233768463135, train/logprobs = tensor([[-1.5577, -4.6490],
        [-2.5755, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025483787059784
Epoch 0, Step 1515: train/loss = 0.42000389099121094, train/raw-loss = 0.37918591499328613, train/logprobs = tensor([[-1.1327, -4.5502],
        [-3.6458, -1.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40817996859550476
Epoch 0, Step 1516: train/loss = 0.5146128535270691, train/raw-loss = 0.47192370891571045, train/logprobs = tensor([[-1.2493, -2.7962],
        [-2.8417, -2.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4268915057182312
Epoch 0, Step 1517: train/loss = 0.14828059077262878, train/raw-loss = 0.11747289448976517, train/logprobs = tensor([[-1.1183, -7.8950],
        [-2.9652, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30807703733444214
Epoch 0, Step 1518: train/loss = 0.1735444962978363, train/raw-loss = 0.13857541978359222, train/logprobs = tensor([[-1.3739, -9.2004],
        [-3.2356, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34969091415405273
Epoch 0, Step 1519: train/loss = 0.31765878200531006, train/raw-loss = 0.28501179814338684, train/logprobs = tensor([[-1.6028, -4.4851],
        [-2.6461, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32647019624710083
Epoch 0, Step 1520: train/loss = 0.3771591782569885, train/raw-loss = 0.3434201180934906, train/logprobs = tensor([[-2.6049, -5.4647],
        [-3.8336, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373908996582031
Epoch 0, Step 1521: train/loss = 0.3539290726184845, train/raw-loss = 0.3195173442363739, train/logprobs = tensor([[-1.9400, -9.0938],
        [-2.5178, -2.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34411710500717163
Epoch 0, Step 1522: train/loss = 0.49431654810905457, train/raw-loss = 0.4585341215133667, train/logprobs = tensor([[-1.5120, -6.9564],
        [-2.5615, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578242361545563
Epoch 0, Step 1523: train/loss = 0.6163251399993896, train/raw-loss = 0.5794671773910522, train/logprobs = tensor([[-1.9226, -2.6052],
        [-2.7257, -2.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3685795068740845
Epoch 0, Step 1524: train/loss = 0.314608097076416, train/raw-loss = 0.2698725461959839, train/logprobs = tensor([[-1.0455, -4.2787],
        [-3.9567, -1.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.447355717420578
Epoch 0, Step 1525: train/loss = 0.24714452028274536, train/raw-loss = 0.21654455363750458, train/logprobs = tensor([[-1.1480, -4.5145],
        [-2.7323, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059995174407959
Epoch 0, Step 1526: train/loss = 0.22414588928222656, train/raw-loss = 0.1898193657398224, train/logprobs = tensor([[-1.8712, -7.1205],
        [-2.8303, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3432651162147522
Epoch 0, Step 1527: train/loss = 0.31813952326774597, train/raw-loss = 0.28172406554222107, train/logprobs = tensor([[-1.1523, -7.7903],
        [-3.7566, -1.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3641544580459595
Epoch 0, Step 1528: train/loss = 0.22871670126914978, train/raw-loss = 0.18816274404525757, train/logprobs = tensor([[-1.3768, -3.2496],
        [-3.9747, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40553969144821167
Epoch 0, Step 1529: train/loss = 0.5253862738609314, train/raw-loss = 0.48885101079940796, train/logprobs = tensor([[-1.4611, -3.0852],
        [-2.5494, -1.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36535245180130005
Epoch 0, Step 1530: train/loss = 0.28587061166763306, train/raw-loss = 0.254660427570343, train/logprobs = tensor([[ -2.0249, -10.0127],
        [ -3.1568,  -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31210193037986755
Epoch 0, Step 1531: train/loss = 0.3192490339279175, train/raw-loss = 0.28491273522377014, train/logprobs = tensor([[-1.3538, -6.2420],
        [-2.1813, -1.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433631658554077
Epoch 0, Step 1532: train/loss = 0.3468986749649048, train/raw-loss = 0.3107038140296936, train/logprobs = tensor([[-1.6527, -5.0868],
        [-3.4689, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36194828152656555
Epoch 0, Step 1533: train/loss = 0.41640007495880127, train/raw-loss = 0.3890869617462158, train/logprobs = tensor([[-1.0473, -3.1388],
        [-2.8220, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731313109397888
Epoch 0, Step 1534: train/loss = 0.2773793339729309, train/raw-loss = 0.2467997670173645, train/logprobs = tensor([[-1.3304, -7.1292],
        [-2.5352, -2.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3057957589626312
Epoch 0, Step 1535: train/loss = 0.368967205286026, train/raw-loss = 0.32865816354751587, train/logprobs = tensor([[-1.7210, -3.1759],
        [-3.5775, -2.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4030904173851013
Epoch 0, Step 1536: train/loss = 0.5933765172958374, train/raw-loss = 0.5587593913078308, train/logprobs = tensor([[-1.8347, -2.7400],
        [-2.7805, -2.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461717367172241
Epoch 0, Step 1537: train/loss = 0.6518377661705017, train/raw-loss = 0.6149522662162781, train/logprobs = tensor([[-1.2917, -2.7004],
        [-2.3081, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36885470151901245
Epoch 0, Step 1538: train/loss = 0.5835232138633728, train/raw-loss = 0.5504002571105957, train/logprobs = tensor([[-0.9904, -2.1479],
        [-1.6819, -1.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33122941851615906
Epoch 0, Step 1539: train/loss = 0.27805787324905396, train/raw-loss = 0.24575503170490265, train/logprobs = tensor([[-1.2834, -5.6210],
        [-3.2208, -1.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230281472206116
Epoch 0, Step 1540: train/loss = 0.4173661470413208, train/raw-loss = 0.3865888714790344, train/logprobs = tensor([[-0.9916, -3.4579],
        [-2.2976, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.307772696018219
Epoch 0, Step 1541: train/loss = 0.28397470712661743, train/raw-loss = 0.2541714310646057, train/logprobs = tensor([[-1.0344, -4.9059],
        [-2.7351, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29803287982940674
Epoch 0, Step 1542: train/loss = 0.131425142288208, train/raw-loss = 0.09611786156892776, train/logprobs = tensor([[-1.6460, -5.8735],
        [-3.6929, -0.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3530728220939636
Epoch 0, Step 1543: train/loss = 0.36439940333366394, train/raw-loss = 0.33087122440338135, train/logprobs = tensor([[-2.3739, -7.5872],
        [-2.8747, -1.3942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33528196811676025
Epoch 0, Step 1544: train/loss = 0.255480021238327, train/raw-loss = 0.22884753346443176, train/logprobs = tensor([[-1.7642, -5.1125],
        [-2.4751, -0.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26632511615753174
Epoch 0, Step 1545: train/loss = 0.1268579363822937, train/raw-loss = 0.09264461696147919, train/logprobs = tensor([[-1.7159, -6.7799],
        [-4.2232, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34213319420814514
Epoch 0, Step 1546: train/loss = 0.36002758145332336, train/raw-loss = 0.32237547636032104, train/logprobs = tensor([[-1.6590, -5.9139],
        [-3.8557, -1.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37652134895324707
Epoch 0, Step 1547: train/loss = 0.6940659880638123, train/raw-loss = 0.661596417427063, train/logprobs = tensor([[-2.8266, -6.2055],
        [-2.3858, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.324695885181427
Epoch 0, Step 1548: train/loss = 0.1775970757007599, train/raw-loss = 0.13921663165092468, train/logprobs = tensor([[-2.0760, -8.5032],
        [-3.7351, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38380444049835205
Epoch 0, Step 1549: train/loss = 0.5925979018211365, train/raw-loss = 0.5545007586479187, train/logprobs = tensor([[-1.5407, -2.9323],
        [-2.8665, -1.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3809716999530792
Epoch 0, Step 1550: train/loss = 0.16619496047496796, train/raw-loss = 0.12795689702033997, train/logprobs = tensor([[-1.7589, -5.2106],
        [-4.3833, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3823806047439575
Epoch 0, Step 1551: train/loss = 0.3681238889694214, train/raw-loss = 0.33583924174308777, train/logprobs = tensor([[-1.6704, -6.6168],
        [-2.2486, -1.2008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.322846382856369
Epoch 0, Step 1552: train/loss = 0.6792869567871094, train/raw-loss = 0.6494413614273071, train/logprobs = tensor([[-1.0008, -2.9962],
        [-2.2584, -2.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29845625162124634
Epoch 0, Step 1553: train/loss = 0.5191035270690918, train/raw-loss = 0.4819832742214203, train/logprobs = tensor([[-1.5047, -2.0802],
        [-2.5959, -1.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3712022602558136
Epoch 0, Step 1554: train/loss = 0.35667094588279724, train/raw-loss = 0.3157263696193695, train/logprobs = tensor([[-1.7705, -4.4836],
        [-3.7006, -1.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40944576263427734
Epoch 0, Step 1555: train/loss = 0.42594248056411743, train/raw-loss = 0.3928205668926239, train/logprobs = tensor([[-1.4626, -6.4700],
        [-2.8708, -1.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331218957901001
Epoch 0, Step 1556: train/loss = 0.162339985370636, train/raw-loss = 0.12681905925273895, train/logprobs = tensor([[-1.1471, -5.1208],
        [-2.7560, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35520923137664795
Epoch 0, Step 1557: train/loss = 0.45478129386901855, train/raw-loss = 0.4104691743850708, train/logprobs = tensor([[-1.2422, -5.2720],
        [-2.6668, -1.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4431213438510895
Epoch 0, Step 1558: train/loss = 0.1457802802324295, train/raw-loss = 0.10628130286931992, train/logprobs = tensor([[-1.9438, -8.6715],
        [-3.7315, -1.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3949897289276123
Epoch 0, Step 1559: train/loss = 0.15878383815288544, train/raw-loss = 0.1313064694404602, train/logprobs = tensor([[-1.2183, -5.6009],
        [-2.7132, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27477383613586426
Epoch 0, Step 1560: train/loss = 0.4861566126346588, train/raw-loss = 0.4545263648033142, train/logprobs = tensor([[-1.0108, -4.3939],
        [-1.9776, -1.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3163025975227356
Epoch 0, Step 1561: train/loss = 0.32019758224487305, train/raw-loss = 0.28413212299346924, train/logprobs = tensor([[ -2.1541, -11.4929],
        [ -3.4503,  -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606545329093933
Epoch 0, Step 1562: train/loss = 0.6103640794754028, train/raw-loss = 0.5719192624092102, train/logprobs = tensor([[-2.2482, -3.4896],
        [-3.7423, -1.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844483494758606
Epoch 0, Step 1563: train/loss = 0.3619803190231323, train/raw-loss = 0.3282676935195923, train/logprobs = tensor([[-1.3974, -6.2112],
        [-2.9595, -1.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33712607622146606
Epoch 0, Step 1564: train/loss = 0.3726811408996582, train/raw-loss = 0.3342318534851074, train/logprobs = tensor([[-2.2962, -5.9385],
        [-3.4525, -0.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3844930827617645
Epoch 0, Step 1565: train/loss = 0.41919833421707153, train/raw-loss = 0.38669419288635254, train/logprobs = tensor([[-1.8099, -3.7862],
        [-2.4791, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32504111528396606
Epoch 0, Step 1566: train/loss = 0.5217848420143127, train/raw-loss = 0.4781830310821533, train/logprobs = tensor([[-2.5588, -5.6029],
        [-3.3428, -2.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43601781129837036
Epoch 0, Step 1567: train/loss = 0.47732728719711304, train/raw-loss = 0.4425041675567627, train/logprobs = tensor([[-1.7796, -3.5132],
        [-2.8410, -1.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3482311964035034
Epoch 0, Step 1568: train/loss = 0.09289184957742691, train/raw-loss = 0.06333426386117935, train/logprobs = tensor([[-1.1117, -9.4183],
        [-3.7492, -1.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955758571624756
Epoch 0, Step 1569: train/loss = 0.5404961109161377, train/raw-loss = 0.5115233063697815, train/logprobs = tensor([[-0.7618, -2.0818],
        [-1.5302, -1.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28972774744033813
Epoch 0, Step 1570: train/loss = 0.5459770560264587, train/raw-loss = 0.5156396627426147, train/logprobs = tensor([[-2.0941, -5.5296],
        [-2.5050, -1.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033740818500519
Epoch 0, Step 1571: train/loss = 0.5071425437927246, train/raw-loss = 0.47384998202323914, train/logprobs = tensor([[-2.1489, -4.3718],
        [-2.8155, -1.1675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33292585611343384
Epoch 0, Step 1572: train/loss = 0.5620195865631104, train/raw-loss = 0.5287256240844727, train/logprobs = tensor([[-1.2459, -1.6951],
        [-2.0361, -1.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33293965458869934
Epoch 0, Step 1573: train/loss = 0.6835182309150696, train/raw-loss = 0.6486890316009521, train/logprobs = tensor([[-3.2139, -7.5534],
        [-2.7931, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34829214215278625
Epoch 0, Step 1574: train/loss = 0.159258171916008, train/raw-loss = 0.12579424679279327, train/logprobs = tensor([[-1.2331, -6.7461],
        [-3.0666, -1.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.334639310836792
Epoch 0, Step 1575: train/loss = 0.29424741864204407, train/raw-loss = 0.2608735263347626, train/logprobs = tensor([[-1.2406, -5.5103],
        [-3.9990, -1.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33373868465423584
Epoch 0, Step 1576: train/loss = 0.5084804892539978, train/raw-loss = 0.4721035361289978, train/logprobs = tensor([[-1.2360, -2.3373],
        [-2.8010, -2.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637697398662567
Epoch 0, Step 1577: train/loss = 0.4674951136112213, train/raw-loss = 0.4263863265514374, train/logprobs = tensor([[-1.6594, -5.8779],
        [-3.9491, -2.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41108840703964233
Epoch 0, Step 1578: train/loss = 0.3362072706222534, train/raw-loss = 0.2972733974456787, train/logprobs = tensor([[-1.4497, -4.1311],
        [-3.9751, -2.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38933876156806946
Epoch 0, Step 1579: train/loss = 0.5465296506881714, train/raw-loss = 0.5121899843215942, train/logprobs = tensor([[-1.3425, -3.2456],
        [-2.1045, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34339654445648193
Epoch 0, Step 1580: train/loss = 0.26478973031044006, train/raw-loss = 0.22960443794727325, train/logprobs = tensor([[-1.6623, -9.7342],
        [-3.6465, -1.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35185280442237854
Epoch 0, Step 1581: train/loss = 0.31259143352508545, train/raw-loss = 0.27513065934181213, train/logprobs = tensor([[-1.9881, -5.3994],
        [-2.7435, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37460777163505554
Epoch 0, Step 1582: train/loss = 0.31082963943481445, train/raw-loss = 0.2824881672859192, train/logprobs = tensor([[-1.5399, -5.6696],
        [-2.4760, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28341466188430786
Epoch 0, Step 1583: train/loss = 0.08447609841823578, train/raw-loss = 0.0555572472512722, train/logprobs = tensor([[-1.0681, -8.5941],
        [-4.0315, -1.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2891885042190552
Epoch 0, Step 1584: train/loss = 0.7191462516784668, train/raw-loss = 0.6832238435745239, train/logprobs = tensor([[-1.5483, -1.8925],
        [-2.7121, -2.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592239022254944
Epoch 0, Step 1585: train/loss = 0.29439207911491394, train/raw-loss = 0.2611079812049866, train/logprobs = tensor([[-1.2821, -5.5057],
        [-3.2286, -1.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33284109830856323
Epoch 0, Step 1586: train/loss = 0.25822314620018005, train/raw-loss = 0.22511973977088928, train/logprobs = tensor([[-1.1198, -4.9811],
        [-3.7079, -2.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33103397488594055
Epoch 0, Step 1587: train/loss = 0.29814058542251587, train/raw-loss = 0.26170748472213745, train/logprobs = tensor([[-1.3818, -5.2732],
        [-2.9245, -1.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36433112621307373
Epoch 0, Step 1588: train/loss = 0.20075276494026184, train/raw-loss = 0.16419129073619843, train/logprobs = tensor([[-1.4596, -5.5370],
        [-3.1244, -1.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36561471223831177
Epoch 0, Step 1589: train/loss = 0.2508874237537384, train/raw-loss = 0.2198360115289688, train/logprobs = tensor([[ -1.5746, -10.7580],
        [ -2.8112,  -1.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31051385402679443
Epoch 0, Step 1590: train/loss = 0.15777090191841125, train/raw-loss = 0.11984989792108536, train/logprobs = tensor([[-1.5792, -7.3083],
        [-3.8273, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37921014428138733
Epoch 0, Step 1591: train/loss = 0.2712114453315735, train/raw-loss = 0.23585659265518188, train/logprobs = tensor([[-1.2458, -6.6771],
        [-3.3920, -1.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35354867577552795
Epoch 0, Step 1592: train/loss = 0.48009276390075684, train/raw-loss = 0.44850003719329834, train/logprobs = tensor([[-0.7954, -1.7197],
        [-2.4989, -1.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31592732667922974
Epoch 0, Step 1593: train/loss = 0.09929165244102478, train/raw-loss = 0.06006380170583725, train/logprobs = tensor([[-1.1723, -7.8061],
        [-4.0223, -2.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922785520553589
Epoch 0, Step 1594: train/loss = 0.6068217754364014, train/raw-loss = 0.5698989629745483, train/logprobs = tensor([[-1.5221, -3.5646],
        [-2.5453, -2.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36922797560691833
Epoch 0, Step 1595: train/loss = 0.7330936193466187, train/raw-loss = 0.6942038536071777, train/logprobs = tensor([[-2.5788, -3.1339],
        [-3.1189, -2.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38889697194099426
Epoch 0, Step 1596: train/loss = 0.44795557856559753, train/raw-loss = 0.4162350296974182, train/logprobs = tensor([[-1.4712, -4.0464],
        [-3.2547, -2.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172054886817932
Epoch 0, Step 1597: train/loss = 0.1025504395365715, train/raw-loss = 0.06841874122619629, train/logprobs = tensor([[ -1.5893, -12.6696],
        [ -3.8215,  -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34131693840026855
Epoch 0, Step 1598: train/loss = 0.44933125376701355, train/raw-loss = 0.4126375913619995, train/logprobs = tensor([[-1.9560, -8.0047],
        [-3.8314, -2.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669360876083374
Epoch 0, Step 1599: train/loss = 0.5703790783882141, train/raw-loss = 0.5304897427558899, train/logprobs = tensor([[-1.5474, -3.6162],
        [-3.6930, -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3988931179046631
Epoch 0, Step 1600: train/loss = 0.3502402603626251, train/raw-loss = 0.3164929747581482, train/logprobs = tensor([[-1.3423, -4.5125],
        [-2.9450, -2.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374728858470917
Epoch 0, Step 1601: train/loss = 0.17099148035049438, train/raw-loss = 0.1377943605184555, train/logprobs = tensor([[-1.3267, -8.4900],
        [-3.0961, -2.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33197125792503357
Epoch 0, Step 1602: train/loss = 0.2726479768753052, train/raw-loss = 0.2423439621925354, train/logprobs = tensor([[-1.8245, -4.8076],
        [-2.3167, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3030402958393097
Epoch 0, Step 1603: train/loss = 0.4991767704486847, train/raw-loss = 0.45742067694664, train/logprobs = tensor([[-1.0553, -1.9810],
        [-2.8346, -1.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41756078600883484
Epoch 0, Step 1604: train/loss = 0.3205583691596985, train/raw-loss = 0.2846442759037018, train/logprobs = tensor([[-2.3494, -8.5710],
        [-4.4878, -2.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3591407537460327
Epoch 0, Step 1605: train/loss = 0.27539852261543274, train/raw-loss = 0.2376064956188202, train/logprobs = tensor([[-0.8125, -6.6035],
        [-2.8950, -1.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37792035937309265
Epoch 0, Step 1606: train/loss = 0.09110590070486069, train/raw-loss = 0.052152324467897415, train/logprobs = tensor([[-1.8585, -7.8032],
        [-4.6634, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3895357549190521
Epoch 0, Step 1607: train/loss = 0.403246134519577, train/raw-loss = 0.3731682300567627, train/logprobs = tensor([[ -2.1649, -10.3782],
        [ -2.9388,  -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007790446281433
Epoch 0, Step 1608: train/loss = 0.38941511511802673, train/raw-loss = 0.35211604833602905, train/logprobs = tensor([[-1.6227, -7.8206],
        [-3.3963, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729904890060425
Epoch 0, Step 1609: train/loss = 0.20528359711170197, train/raw-loss = 0.17160919308662415, train/logprobs = tensor([[ -1.4594, -10.1893],
        [ -4.1829,  -0.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3367442190647125
Epoch 0, Step 1610: train/loss = 0.1344589740037918, train/raw-loss = 0.09667259454727173, train/logprobs = tensor([[-1.2033, -7.6584],
        [-2.8087, -1.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778637945652008
Epoch 0, Step 1611: train/loss = 0.4633561968803406, train/raw-loss = 0.42831623554229736, train/logprobs = tensor([[-1.8351, -3.1787],
        [-3.3863, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35040003061294556
Epoch 0, Step 1612: train/loss = 0.5380421280860901, train/raw-loss = 0.5065885782241821, train/logprobs = tensor([[-1.5894, -3.7784],
        [-1.7715, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31453531980514526
Epoch 0, Step 1613: train/loss = 0.6420617699623108, train/raw-loss = 0.6077674627304077, train/logprobs = tensor([[-1.7416, -2.4422],
        [-2.6209, -2.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34294354915618896
Epoch 0, Step 1614: train/loss = 0.39766961336135864, train/raw-loss = 0.3648337423801422, train/logprobs = tensor([[ -1.8441, -10.5570],
        [ -2.2814,  -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283587098121643
Epoch 0, Step 1615: train/loss = 0.3412235677242279, train/raw-loss = 0.311027467250824, train/logprobs = tensor([[-2.3830, -6.3404],
        [-2.7742, -1.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019610643386841
Epoch 0, Step 1616: train/loss = 0.3936716318130493, train/raw-loss = 0.35346001386642456, train/logprobs = tensor([[-2.0719, -4.7431],
        [-4.1377, -1.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4021163582801819
Epoch 0, Step 1617: train/loss = 0.525275707244873, train/raw-loss = 0.48995476961135864, train/logprobs = tensor([[-2.6390, -6.9712],
        [-2.6734, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35320907831192017
Epoch 0, Step 1618: train/loss = 0.26872771978378296, train/raw-loss = 0.2351658046245575, train/logprobs = tensor([[-1.3697, -8.2602],
        [-2.5417, -1.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356192708015442
Epoch 0, Step 1619: train/loss = 0.4869324266910553, train/raw-loss = 0.45639804005622864, train/logprobs = tensor([[-2.5006, -5.6155],
        [-3.1436, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053441047668457
Epoch 0, Step 1620: train/loss = 0.45906323194503784, train/raw-loss = 0.4271824359893799, train/logprobs = tensor([[-0.8420, -3.3447],
        [-2.0289, -1.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31880784034729004
Epoch 0, Step 1621: train/loss = 0.4130539298057556, train/raw-loss = 0.3827352225780487, train/logprobs = tensor([[-2.5782, -6.0501],
        [-2.9960, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031873106956482
Epoch 0, Step 1622: train/loss = 0.19289709627628326, train/raw-loss = 0.1511831283569336, train/logprobs = tensor([[-1.3824, -8.7017],
        [-4.3734, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41713953018188477
Epoch 0, Step 1623: train/loss = 0.39937824010849, train/raw-loss = 0.36231744289398193, train/logprobs = tensor([[-1.4173, -4.8099],
        [-2.7752, -2.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37060779333114624
Epoch 0, Step 1624: train/loss = 0.5573931932449341, train/raw-loss = 0.5202347636222839, train/logprobs = tensor([[-2.0162, -2.8110],
        [-2.8283, -2.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37158459424972534
Epoch 0, Step 1625: train/loss = 0.36483579874038696, train/raw-loss = 0.3282683491706848, train/logprobs = tensor([[-1.4311, -4.0934],
        [-2.6583, -1.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3656746745109558
Epoch 0, Step 1626: train/loss = 0.2993573546409607, train/raw-loss = 0.26506853103637695, train/logprobs = tensor([[-1.6237, -6.6797],
        [-3.5088, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34288835525512695
Epoch 0, Step 1627: train/loss = 0.44793781638145447, train/raw-loss = 0.4113476276397705, train/logprobs = tensor([[-1.5504, -3.8128],
        [-2.7528, -1.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36590200662612915
Epoch 0, Step 1628: train/loss = 0.3049026429653168, train/raw-loss = 0.2732715904712677, train/logprobs = tensor([[-1.3878, -3.4968],
        [-2.9151, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31631049513816833
Epoch 0, Step 1629: train/loss = 0.5106662511825562, train/raw-loss = 0.47627097368240356, train/logprobs = tensor([[-1.7009, -2.2625],
        [-2.2490, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34395283460617065
Epoch 0, Step 1630: train/loss = 0.15123148262500763, train/raw-loss = 0.12685877084732056, train/logprobs = tensor([[-1.7197, -7.2508],
        [-3.2879, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24372713267803192
Epoch 0, Step 1631: train/loss = 0.3238472044467926, train/raw-loss = 0.2820857763290405, train/logprobs = tensor([[-1.9153, -3.9542],
        [-3.8161, -2.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4176141023635864
Epoch 0, Step 1632: train/loss = 0.26014798879623413, train/raw-loss = 0.22607874870300293, train/logprobs = tensor([[-1.6919, -5.3841],
        [-3.4325, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.340692400932312
Epoch 0, Step 1633: train/loss = 0.27224862575531006, train/raw-loss = 0.2365424931049347, train/logprobs = tensor([[-0.7455, -3.6030],
        [-2.7387, -1.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35706111788749695
Epoch 0, Step 1634: train/loss = 1.5361082553863525, train/raw-loss = 1.5062404870986938, train/logprobs = tensor([[-6.0686, -7.3335],
        [-2.5899, -1.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2986784279346466
Epoch 0, Step 1635: train/loss = 0.3275350034236908, train/raw-loss = 0.29842302203178406, train/logprobs = tensor([[-1.6157, -8.5754],
        [-3.4529, -1.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29111984372138977
Epoch 0, Step 1636: train/loss = 0.44585496187210083, train/raw-loss = 0.4158872365951538, train/logprobs = tensor([[-1.1449, -4.4309],
        [-1.8782, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996772527694702
Epoch 0, Step 1637: train/loss = 0.4705713987350464, train/raw-loss = 0.43576928973197937, train/logprobs = tensor([[-1.1136, -4.8851],
        [-2.1121, -2.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480214774608612
Epoch 0, Step 1638: train/loss = 0.30767297744750977, train/raw-loss = 0.27712562680244446, train/logprobs = tensor([[-1.8862, -5.3062],
        [-3.2286, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054734170436859
Epoch 0, Step 1639: train/loss = 0.289691686630249, train/raw-loss = 0.25905194878578186, train/logprobs = tensor([[-1.2131, -6.0190],
        [-3.0865, -1.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306397408246994
Epoch 0, Step 1640: train/loss = 0.4938383102416992, train/raw-loss = 0.46068844199180603, train/logprobs = tensor([[-1.9481, -4.2319],
        [-3.4001, -2.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33149847388267517
Epoch 0, Step 1641: train/loss = 0.0680953785777092, train/raw-loss = 0.035901233553886414, train/logprobs = tensor([[ -1.0764, -13.2027],
        [ -3.9252,  -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219413757324219
Epoch 0, Step 1642: train/loss = 0.28764212131500244, train/raw-loss = 0.2533791661262512, train/logprobs = tensor([[-0.6835, -7.3020],
        [-2.7726, -1.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34262925386428833
Epoch 0, Step 1643: train/loss = 0.25081923604011536, train/raw-loss = 0.2169119268655777, train/logprobs = tensor([[-1.7199, -8.3122],
        [-2.9621, -1.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390733003616333
Epoch 0, Step 1644: train/loss = 0.41940048336982727, train/raw-loss = 0.3785448372364044, train/logprobs = tensor([[-1.9691, -2.9384],
        [-4.1671, -2.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40855666995048523
Epoch 0, Step 1645: train/loss = 0.4098261296749115, train/raw-loss = 0.38341471552848816, train/logprobs = tensor([[-2.5788, -4.9583],
        [-3.0181, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641139328479767
Epoch 0, Step 1646: train/loss = 0.3864148259162903, train/raw-loss = 0.3545840084552765, train/logprobs = tensor([[-2.4067, -4.0354],
        [-2.7686, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31830844283103943
Epoch 0, Step 1647: train/loss = 0.29413703083992004, train/raw-loss = 0.2606777846813202, train/logprobs = tensor([[-1.0268, -5.0499],
        [-2.7151, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345924913883209
Epoch 0, Step 1648: train/loss = 0.6161152124404907, train/raw-loss = 0.5823761224746704, train/logprobs = tensor([[-2.6738, -6.8033],
        [-2.5458, -0.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373909592628479
Epoch 0, Step 1649: train/loss = 0.5334690809249878, train/raw-loss = 0.4953245222568512, train/logprobs = tensor([[-1.6092, -3.6514],
        [-2.6187, -2.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814449906349182
Epoch 0, Step 1650: train/loss = 0.8773852586746216, train/raw-loss = 0.8468976616859436, train/logprobs = tensor([[-2.9172, -5.0564],
        [-1.8330, -1.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048757314682007
Epoch 0, Step 1651: train/loss = 0.3800674378871918, train/raw-loss = 0.34744393825531006, train/logprobs = tensor([[-2.1377, -5.4079],
        [-3.2059, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262346088886261
Epoch 0, Step 1652: train/loss = 0.2668013572692871, train/raw-loss = 0.23531433939933777, train/logprobs = tensor([[-1.4834, -3.7153],
        [-3.3152, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148704171180725
Epoch 0, Step 1653: train/loss = 0.43785086274147034, train/raw-loss = 0.4069824516773224, train/logprobs = tensor([[-1.8056, -3.2577],
        [-3.0397, -1.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086841106414795
Epoch 0, Step 1654: train/loss = 0.4013764262199402, train/raw-loss = 0.37019988894462585, train/logprobs = tensor([[-1.7062, -3.8958],
        [-1.9568, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117654323577881
Epoch 0, Step 1655: train/loss = 0.3353269398212433, train/raw-loss = 0.2984268069267273, train/logprobs = tensor([[-1.4785, -3.2756],
        [-2.7917, -1.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36900147795677185
Epoch 0, Step 1656: train/loss = 0.617244303226471, train/raw-loss = 0.5846572518348694, train/logprobs = tensor([[-2.4634, -3.1105],
        [-2.0981, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258700966835022
Epoch 0, Step 1657: train/loss = 0.31802424788475037, train/raw-loss = 0.28672006726264954, train/logprobs = tensor([[-1.9110, -4.0051],
        [-3.2134, -0.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130418658256531
Epoch 0, Step 1658: train/loss = 0.3111675977706909, train/raw-loss = 0.27649790048599243, train/logprobs = tensor([[-1.2070, -3.6065],
        [-3.4004, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3466971814632416
Epoch 0, Step 1659: train/loss = 0.14879250526428223, train/raw-loss = 0.11390463262796402, train/logprobs = tensor([[-2.1533, -5.0505],
        [-4.5880, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488786816596985
Epoch 0, Step 1660: train/loss = 0.3452022671699524, train/raw-loss = 0.3120467960834503, train/logprobs = tensor([[-1.9007, -7.0535],
        [-2.6823, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315545320510864
Epoch 0, Step 1661: train/loss = 0.22230997681617737, train/raw-loss = 0.1872880458831787, train/logprobs = tensor([[-1.3321, -4.3351],
        [-3.7778, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502193093299866
Epoch 0, Step 1662: train/loss = 0.1688804030418396, train/raw-loss = 0.13800019025802612, train/logprobs = tensor([[-1.5228, -7.6374],
        [-2.8659, -1.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088019788265228
Epoch 0, Step 1663: train/loss = 0.4767730236053467, train/raw-loss = 0.44709253311157227, train/logprobs = tensor([[-2.1135, -2.0424],
        [-2.7056, -1.2061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968047857284546
Epoch 0, Step 1664: train/loss = 0.4355783760547638, train/raw-loss = 0.4029925465583801, train/logprobs = tensor([[-1.0988, -5.1794],
        [-2.7863, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32585805654525757
Epoch 0, Step 1665: train/loss = 0.2115270495414734, train/raw-loss = 0.17300041019916534, train/logprobs = tensor([[-1.5665, -5.1760],
        [-3.9461, -2.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38526642322540283
Epoch 0, Step 1666: train/loss = 0.3504951596260071, train/raw-loss = 0.3157932162284851, train/logprobs = tensor([[-1.0612, -5.3733],
        [-3.5797, -2.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470194637775421
Epoch 0, Step 1667: train/loss = 0.5287962555885315, train/raw-loss = 0.4975399971008301, train/logprobs = tensor([[-2.9670, -4.1391],
        [-4.2545, -2.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.312562495470047
Epoch 0, Step 1668: train/loss = 0.13754504919052124, train/raw-loss = 0.10408082604408264, train/logprobs = tensor([[-0.8888, -8.7046],
        [-2.8457, -1.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346421718597412
Epoch 0, Step 1669: train/loss = 0.5278633832931519, train/raw-loss = 0.49151039123535156, train/logprobs = tensor([[-1.1822, -2.2414],
        [-2.5691, -2.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3635299503803253
Epoch 0, Step 1670: train/loss = 0.5762507319450378, train/raw-loss = 0.5464615821838379, train/logprobs = tensor([[-1.4682, -1.8987],
        [-1.7969, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297891765832901
Epoch 0, Step 1671: train/loss = 0.22120621800422668, train/raw-loss = 0.18337956070899963, train/logprobs = tensor([[-1.3104, -6.6806],
        [-3.3826, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37826696038246155
Epoch 0, Step 1672: train/loss = 0.27264052629470825, train/raw-loss = 0.23829057812690735, train/logprobs = tensor([[-1.4743, -4.0880],
        [-4.1747, -1.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434995412826538
Epoch 0, Step 1673: train/loss = 0.2850605249404907, train/raw-loss = 0.25550606846809387, train/logprobs = tensor([[-1.6205, -6.9212],
        [-3.5814, -1.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29554465413093567
Epoch 0, Step 1674: train/loss = 0.4742929935455322, train/raw-loss = 0.4430287480354309, train/logprobs = tensor([[-1.5104, -8.3781],
        [-2.6354, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126424551010132
Epoch 0, Step 1675: train/loss = 0.486034095287323, train/raw-loss = 0.4531027376651764, train/logprobs = tensor([[-1.4182, -2.8774],
        [-2.5022, -1.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293139934539795
Epoch 0, Step 1676: train/loss = 0.3435434103012085, train/raw-loss = 0.31263139843940735, train/logprobs = tensor([[-2.3798, -8.4744],
        [-2.7139, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30911993980407715
Epoch 0, Step 1677: train/loss = 0.5743386745452881, train/raw-loss = 0.5376432538032532, train/logprobs = tensor([[-1.1128, -2.9156],
        [-2.7292, -2.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669542372226715
Epoch 0, Step 1678: train/loss = 0.4963614046573639, train/raw-loss = 0.4625752866268158, train/logprobs = tensor([[-1.5678, -6.4076],
        [-4.3499, -2.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378612995147705
Epoch 0, Step 1679: train/loss = 0.47729814052581787, train/raw-loss = 0.4473935663700104, train/logprobs = tensor([[-1.5967, -5.4261],
        [-2.4088, -0.6748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2990456521511078
Epoch 0, Step 1680: train/loss = 0.6876224875450134, train/raw-loss = 0.6592874526977539, train/logprobs = tensor([[-2.5897, -4.1125],
        [-1.6140, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833501696586609
Epoch 0, Step 1681: train/loss = 0.3058069944381714, train/raw-loss = 0.2720113694667816, train/logprobs = tensor([[-1.6773, -5.3081],
        [-3.3294, -2.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33795619010925293
Epoch 0, Step 1682: train/loss = 0.26649102568626404, train/raw-loss = 0.22912272810935974, train/logprobs = tensor([[-1.9376, -3.7239],
        [-3.9560, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37368303537368774
Epoch 0, Step 1683: train/loss = 0.4539731442928314, train/raw-loss = 0.42106229066848755, train/logprobs = tensor([[-1.8251, -1.6929],
        [-3.2358, -1.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291088342666626
Epoch 0, Step 1684: train/loss = 0.23950321972370148, train/raw-loss = 0.2062159776687622, train/logprobs = tensor([[-1.1419, -6.4114],
        [-3.5299, -2.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33287227153778076
Epoch 0, Step 1685: train/loss = 0.10599159449338913, train/raw-loss = 0.07019101083278656, train/logprobs = tensor([[-1.5649, -7.8974],
        [-4.0807, -1.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580057919025421
Epoch 0, Step 1686: train/loss = 0.09223492443561554, train/raw-loss = 0.05914434790611267, train/logprobs = tensor([[-1.4642, -7.4245],
        [-3.7087, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3309057652950287
Epoch 0, Step 1687: train/loss = 0.2016257345676422, train/raw-loss = 0.16968569159507751, train/logprobs = tensor([[-0.8521, -7.6460],
        [-2.7729, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194005489349365
Epoch 0, Step 1688: train/loss = 0.22802290320396423, train/raw-loss = 0.1965314894914627, train/logprobs = tensor([[-1.2979, -6.7002],
        [-3.5187, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149142265319824
Epoch 0, Step 1689: train/loss = 0.46765071153640747, train/raw-loss = 0.4414151906967163, train/logprobs = tensor([[-2.6302, -3.5524],
        [-2.2810, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623552978038788
Epoch 0, Step 1690: train/loss = 0.6511703729629517, train/raw-loss = 0.6099252104759216, train/logprobs = tensor([[-2.0723, -6.0395],
        [-3.3941, -3.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41245192289352417
Epoch 0, Step 1691: train/loss = 0.7252579927444458, train/raw-loss = 0.6929545402526855, train/logprobs = tensor([[-2.5384, -4.3937],
        [-3.2701, -1.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230348825454712
Epoch 0, Step 1692: train/loss = 0.44865837693214417, train/raw-loss = 0.41853007674217224, train/logprobs = tensor([[-1.4666, -2.9948],
        [-2.5154, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012830317020416
Epoch 0, Step 1693: train/loss = 0.15164139866828918, train/raw-loss = 0.12321058660745621, train/logprobs = tensor([[-1.3424, -9.5687],
        [-2.9425, -1.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2843080759048462
Epoch 0, Step 1694: train/loss = 0.2520808279514313, train/raw-loss = 0.22247543931007385, train/logprobs = tensor([[-1.0759, -4.2492],
        [-2.1395, -1.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29605379700660706
Epoch 0, Step 1695: train/loss = 0.5974380970001221, train/raw-loss = 0.5668998956680298, train/logprobs = tensor([[-1.0528, -1.9466],
        [-1.7285, -1.6377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053816854953766
Epoch 0, Step 1696: train/loss = 0.36587443947792053, train/raw-loss = 0.3257853388786316, train/logprobs = tensor([[-1.1720, -5.6181],
        [-4.3874, -2.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4008907377719879
Epoch 0, Step 1697: train/loss = 0.22120946645736694, train/raw-loss = 0.1866237223148346, train/logprobs = tensor([[-1.4682, -5.4930],
        [-2.4620, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3458574116230011
Epoch 0, Step 1698: train/loss = 0.9889307618141174, train/raw-loss = 0.9516698122024536, train/logprobs = tensor([[-2.1234, -2.7334],
        [-2.4958, -3.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37260985374450684
Epoch 0, Step 1699: train/loss = 0.44000428915023804, train/raw-loss = 0.4088473916053772, train/logprobs = tensor([[-1.2613, -5.4018],
        [-1.9618, -2.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115690052509308
Epoch 0, Step 1700: train/loss = 0.5697586536407471, train/raw-loss = 0.5396339893341064, train/logprobs = tensor([[-2.0289, -2.4936],
        [-2.5999, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012467324733734
Epoch 0, Step 1701: train/loss = 0.6162226796150208, train/raw-loss = 0.5876109600067139, train/logprobs = tensor([[-2.0074, -3.4676],
        [-2.3944, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2861170172691345
Epoch 0, Step 1702: train/loss = 0.6524913311004639, train/raw-loss = 0.6191565990447998, train/logprobs = tensor([[-1.7874, -2.4006],
        [-2.1978, -1.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333480954170227
Epoch 0, Step 1703: train/loss = 0.12235143780708313, train/raw-loss = 0.08861367404460907, train/logprobs = tensor([[-2.5882, -7.0787],
        [-4.7219, -1.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33737748861312866
Epoch 0, Step 1704: train/loss = 0.6922335624694824, train/raw-loss = 0.6611011624336243, train/logprobs = tensor([[-1.9477, -3.4653],
        [-1.8769, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31132352352142334
Epoch 0, Step 1705: train/loss = 0.46755868196487427, train/raw-loss = 0.4312984049320221, train/logprobs = tensor([[-1.1496, -4.7334],
        [-2.6635, -2.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36260315775871277
Epoch 0, Step 1706: train/loss = 0.3358646333217621, train/raw-loss = 0.2921646237373352, train/logprobs = tensor([[-1.4976, -6.5668],
        [-4.0714, -2.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.437000036239624
Epoch 0, Step 1707: train/loss = 0.487022340297699, train/raw-loss = 0.456636518239975, train/logprobs = tensor([[-1.4440, -4.7035],
        [-2.2470, -2.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30385822057724
Epoch 0, Step 1708: train/loss = 0.21655410528182983, train/raw-loss = 0.1860559582710266, train/logprobs = tensor([[-1.2364, -6.4864],
        [-3.7828, -1.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30498141050338745
Epoch 0, Step 1709: train/loss = 0.35892337560653687, train/raw-loss = 0.32124951481819153, train/logprobs = tensor([[-1.8688, -4.2477],
        [-3.0451, -1.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767388164997101
Epoch 0, Step 1710: train/loss = 0.14425747096538544, train/raw-loss = 0.10672199726104736, train/logprobs = tensor([[-1.2201, -6.7745],
        [-3.6178, -1.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37535473704338074
Epoch 0, Step 1711: train/loss = 0.23713554441928864, train/raw-loss = 0.19862112402915955, train/logprobs = tensor([[-1.3301, -5.3779],
        [-3.8934, -1.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38514429330825806
Epoch 0, Step 1712: train/loss = 0.5656582117080688, train/raw-loss = 0.5364943742752075, train/logprobs = tensor([[-2.9381, -4.6199],
        [-2.9650, -2.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291637659072876
Epoch 0, Step 1713: train/loss = 0.14632630348205566, train/raw-loss = 0.11439352482557297, train/logprobs = tensor([[-1.2891, -6.3358],
        [-2.9175, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3193278908729553
Epoch 0, Step 1714: train/loss = 0.5444600582122803, train/raw-loss = 0.5127060413360596, train/logprobs = tensor([[-1.5374, -2.0928],
        [-2.9111, -1.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31754058599472046
Epoch 0, Step 1715: train/loss = 0.3625064790248871, train/raw-loss = 0.3239322304725647, train/logprobs = tensor([[-1.3243, -4.1478],
        [-3.6372, -2.2737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3857426047325134
Epoch 0, Step 1716: train/loss = 0.5186522006988525, train/raw-loss = 0.49000588059425354, train/logprobs = tensor([[-1.8822, -2.5222],
        [-2.4233, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28646302223205566
Epoch 0, Step 1717: train/loss = 0.2976328730583191, train/raw-loss = 0.26832160353660583, train/logprobs = tensor([[-1.2335, -4.6983],
        [-2.3855, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931126356124878
Epoch 0, Step 1718: train/loss = 0.4743788242340088, train/raw-loss = 0.43857231736183167, train/logprobs = tensor([[-1.7178, -4.3953],
        [-2.4259, -1.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35806509852409363
Epoch 0, Step 1719: train/loss = 0.3188946545124054, train/raw-loss = 0.2831770181655884, train/logprobs = tensor([[-1.1107, -4.6725],
        [-2.6251, -1.9364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35717642307281494
Epoch 0, Step 1720: train/loss = 0.171236053109169, train/raw-loss = 0.13794803619384766, train/logprobs = tensor([[-2.2012, -9.5728],
        [-3.9674, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3328803479671478
Epoch 0, Step 1721: train/loss = 0.17299631237983704, train/raw-loss = 0.14185981452465057, train/logprobs = tensor([[-1.2191, -6.8829],
        [-2.7342, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3113649785518646
Epoch 0, Step 1722: train/loss = 0.12400531023740768, train/raw-loss = 0.09080064296722412, train/logprobs = tensor([[-1.8951, -9.2500],
        [-4.3907, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320466876029968
Epoch 0, Step 1723: train/loss = 0.3894338607788086, train/raw-loss = 0.3604947328567505, train/logprobs = tensor([[-1.8135, -4.1350],
        [-2.0730, -1.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893911600112915
Epoch 0, Step 1724: train/loss = 0.20779669284820557, train/raw-loss = 0.17597851157188416, train/logprobs = tensor([[-1.1000, -6.4080],
        [-3.2573, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31818175315856934
Epoch 0, Step 1725: train/loss = 0.36251726746559143, train/raw-loss = 0.3214235305786133, train/logprobs = tensor([[-1.5646, -7.0326],
        [-4.3328, -2.9805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109373986721039
Epoch 0, Step 1726: train/loss = 0.5233222842216492, train/raw-loss = 0.4889953136444092, train/logprobs = tensor([[-2.6181, -7.1499],
        [-3.4963, -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34326955676078796
Epoch 0, Step 1727: train/loss = 0.4202847480773926, train/raw-loss = 0.3819596469402313, train/logprobs = tensor([[-1.7871, -4.2071],
        [-2.6262, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3832511901855469
Epoch 0, Step 1728: train/loss = 0.17052555084228516, train/raw-loss = 0.13957975804805756, train/logprobs = tensor([[-1.5878, -6.4108],
        [-3.7609, -1.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094578981399536
Epoch 0, Step 1729: train/loss = 0.3246287703514099, train/raw-loss = 0.29524457454681396, train/logprobs = tensor([[-1.1252, -4.4036],
        [-2.6870, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938419282436371
Epoch 0, Step 1730: train/loss = 0.2038668990135193, train/raw-loss = 0.17647066712379456, train/logprobs = tensor([[-1.1963, -5.1241],
        [-3.2883, -1.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27396225929260254
Epoch 0, Step 1731: train/loss = 0.2426944077014923, train/raw-loss = 0.21059605479240417, train/logprobs = tensor([[-2.4152, -7.3742],
        [-3.5698, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209836781024933
Epoch 0, Step 1732: train/loss = 0.1806057244539261, train/raw-loss = 0.1463928073644638, train/logprobs = tensor([[-1.8899, -8.0462],
        [-3.4781, -1.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421292006969452
Epoch 0, Step 1733: train/loss = 0.3430400490760803, train/raw-loss = 0.3086221218109131, train/logprobs = tensor([[-1.6513, -9.0529],
        [-2.9220, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34417927265167236
Epoch 0, Step 1734: train/loss = 0.5081691145896912, train/raw-loss = 0.4764370322227478, train/logprobs = tensor([[-2.5885, -4.7603],
        [-2.5517, -1.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3173207938671112
Epoch 0, Step 1735: train/loss = 0.4810485243797302, train/raw-loss = 0.45577311515808105, train/logprobs = tensor([[-1.8775, -3.8216],
        [-1.6849, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25275394320487976
Epoch 0, Step 1736: train/loss = 0.4518703520298004, train/raw-loss = 0.41446495056152344, train/logprobs = tensor([[-1.5445, -3.3258],
        [-3.1551, -3.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37405404448509216
Epoch 0, Step 1737: train/loss = 0.49722540378570557, train/raw-loss = 0.463228702545166, train/logprobs = tensor([[-1.9105, -6.3055],
        [-3.4464, -1.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3399668335914612
Epoch 0, Step 1738: train/loss = 0.42050859332084656, train/raw-loss = 0.3870711326599121, train/logprobs = tensor([[-2.5815, -5.0151],
        [-2.5593, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3343747556209564
Epoch 0, Step 1739: train/loss = 0.41358619928359985, train/raw-loss = 0.386425644159317, train/logprobs = tensor([[-1.4872, -2.9374],
        [-2.7168, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27160555124282837
Epoch 0, Step 1740: train/loss = 0.23388990759849548, train/raw-loss = 0.20475108921527863, train/logprobs = tensor([[-1.0674, -4.1223],
        [-3.1086, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913880944252014
Epoch 0, Step 1741: train/loss = 0.43735456466674805, train/raw-loss = 0.4123899042606354, train/logprobs = tensor([[-1.2292, -2.1956],
        [-1.9942, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2496468722820282
Epoch 0, Step 1742: train/loss = 0.5025417804718018, train/raw-loss = 0.46957576274871826, train/logprobs = tensor([[-1.4352, -4.5430],
        [-1.5984, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32966017723083496
Epoch 0, Step 1743: train/loss = 0.5903342962265015, train/raw-loss = 0.5554529428482056, train/logprobs = tensor([[-1.5071, -2.5531],
        [-2.3705, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34881332516670227
Epoch 0, Step 1744: train/loss = 0.34804487228393555, train/raw-loss = 0.31674090027809143, train/logprobs = tensor([[-1.7974, -4.7721],
        [-2.5542, -1.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31303998827934265
Epoch 0, Step 1745: train/loss = 0.2865343689918518, train/raw-loss = 0.25566214323043823, train/logprobs = tensor([[-1.7271, -2.8350],
        [-2.9811, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3087223768234253
Epoch 0, Step 1746: train/loss = 0.31801557540893555, train/raw-loss = 0.27765193581581116, train/logprobs = tensor([[-1.7278, -4.5842],
        [-3.9800, -2.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036361575126648
Epoch 0, Step 1747: train/loss = 0.41496002674102783, train/raw-loss = 0.3897833228111267, train/logprobs = tensor([[-1.6155, -7.0095],
        [-2.2946, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25176718831062317
Epoch 0, Step 1748: train/loss = 0.19477273523807526, train/raw-loss = 0.16386866569519043, train/logprobs = tensor([[-2.0945, -7.3677],
        [-3.7611, -1.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090406656265259
Epoch 0, Step 1749: train/loss = 0.27984383702278137, train/raw-loss = 0.2399168312549591, train/logprobs = tensor([[-1.3461, -5.8910],
        [-3.4417, -1.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3992702066898346
Epoch 0, Step 1750: train/loss = 0.33691805601119995, train/raw-loss = 0.3041499853134155, train/logprobs = tensor([[-1.6475, -6.3319],
        [-3.4138, -1.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276810348033905
Epoch 0, Step 1751: train/loss = 0.30721360445022583, train/raw-loss = 0.27494198083877563, train/logprobs = tensor([[-1.2592, -4.1813],
        [-2.2489, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3227163553237915
Epoch 0, Step 1752: train/loss = 0.17720521986484528, train/raw-loss = 0.14047572016716003, train/logprobs = tensor([[-1.8555, -7.8490],
        [-3.6028, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672950863838196
Epoch 0, Step 1753: train/loss = 0.2697577476501465, train/raw-loss = 0.2339550107717514, train/logprobs = tensor([[-1.1559, -5.8952],
        [-2.6440, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35802751779556274
Epoch 0, Step 1754: train/loss = 0.38812458515167236, train/raw-loss = 0.3575054705142975, train/logprobs = tensor([[-1.6689, -4.7442],
        [-2.1235, -1.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30619099736213684
Epoch 0, Step 1755: train/loss = 0.35884761810302734, train/raw-loss = 0.32251736521720886, train/logprobs = tensor([[-1.5160, -5.7122],
        [-2.6259, -2.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.363302618265152
Epoch 0, Step 1756: train/loss = 0.14287371933460236, train/raw-loss = 0.1109619066119194, train/logprobs = tensor([[-1.5780, -8.7760],
        [-3.5991, -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31911811232566833
Epoch 0, Step 1757: train/loss = 0.43860840797424316, train/raw-loss = 0.4041662812232971, train/logprobs = tensor([[-1.1841, -1.7510],
        [-2.9304, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3444215953350067
Epoch 0, Step 1758: train/loss = 0.3960033059120178, train/raw-loss = 0.3696388900279999, train/logprobs = tensor([[-2.7615, -6.3671],
        [-3.3012, -1.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2636443078517914
Epoch 0, Step 1759: train/loss = 0.3859604001045227, train/raw-loss = 0.35777100920677185, train/logprobs = tensor([[-2.2991, -6.1086],
        [-2.8386, -1.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2818939685821533
Epoch 0, Step 1760: train/loss = 0.7357558608055115, train/raw-loss = 0.7008538246154785, train/logprobs = tensor([[-1.8354, -3.1027],
        [-1.6200, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490205407142639
Epoch 0, Step 1761: train/loss = 0.5210893154144287, train/raw-loss = 0.4957277774810791, train/logprobs = tensor([[-1.4382, -3.3428],
        [-1.1844, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536146938800812
Epoch 0, Step 1762: train/loss = 0.13763470947742462, train/raw-loss = 0.10876305401325226, train/logprobs = tensor([[-1.9195, -8.2756],
        [-3.7058, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28871655464172363
Epoch 0, Step 1763: train/loss = 0.26530027389526367, train/raw-loss = 0.2337270826101303, train/logprobs = tensor([[-1.0962, -6.2662],
        [-2.6617, -1.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31573182344436646
Epoch 0, Step 1764: train/loss = 0.3887917995452881, train/raw-loss = 0.3623470067977905, train/logprobs = tensor([[-1.8250, -8.0814],
        [-2.9117, -0.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26444804668426514
Epoch 0, Step 1765: train/loss = 0.32712140679359436, train/raw-loss = 0.29669660329818726, train/logprobs = tensor([[-1.1776, -3.2669],
        [-3.1729, -1.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3042480945587158
Epoch 0, Step 1766: train/loss = 0.12443385273218155, train/raw-loss = 0.09166561812162399, train/logprobs = tensor([[-1.1734, -9.0350],
        [-3.9745, -2.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276822566986084
Epoch 0, Step 1767: train/loss = 0.2412647008895874, train/raw-loss = 0.2059900462627411, train/logprobs = tensor([[-0.9703, -6.7278],
        [-3.0263, -1.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352746844291687
Epoch 0, Step 1768: train/loss = 0.31838637590408325, train/raw-loss = 0.28565797209739685, train/logprobs = tensor([[-1.2902, -6.2745],
        [-3.3447, -1.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32728368043899536
Epoch 0, Step 1769: train/loss = 0.2996828854084015, train/raw-loss = 0.26976779103279114, train/logprobs = tensor([[ -1.6820, -12.0232],
        [ -3.0711,  -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29915115237236023
Epoch 0, Step 1770: train/loss = 0.39303064346313477, train/raw-loss = 0.35927003622055054, train/logprobs = tensor([[-1.3064, -4.0502],
        [-3.0264, -1.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33760637044906616
Epoch 0, Step 1771: train/loss = 0.4513128399848938, train/raw-loss = 0.4229527711868286, train/logprobs = tensor([[-1.8030, -3.1610],
        [-2.0949, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28360071778297424
Epoch 0, Step 1772: train/loss = 0.201212078332901, train/raw-loss = 0.1701119989156723, train/logprobs = tensor([[-1.0708, -5.8689],
        [-2.9020, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31100061535835266
Epoch 0, Step 1773: train/loss = 0.6505353450775146, train/raw-loss = 0.6247583031654358, train/logprobs = tensor([[-1.6997, -2.0399],
        [-1.2618, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25777068734169006
Epoch 0, Step 1774: train/loss = 0.29714855551719666, train/raw-loss = 0.2594369053840637, train/logprobs = tensor([[-1.5848, -5.0756],
        [-4.1085, -2.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3771164119243622
Epoch 0, Step 1775: train/loss = 0.4139612019062042, train/raw-loss = 0.38134104013442993, train/logprobs = tensor([[-1.5999, -7.1078],
        [-3.9598, -3.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262014389038086
Epoch 0, Step 1776: train/loss = 0.2650698721408844, train/raw-loss = 0.23140856623649597, train/logprobs = tensor([[-1.4095, -5.1771],
        [-3.3197, -1.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33661311864852905
Epoch 0, Step 1777: train/loss = 0.37470024824142456, train/raw-loss = 0.34585651755332947, train/logprobs = tensor([[-1.3180, -5.0632],
        [-1.8975, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28843703866004944
Epoch 0, Step 1778: train/loss = 0.7464495897293091, train/raw-loss = 0.7132138609886169, train/logprobs = tensor([[-2.6764, -3.2370],
        [-2.0071, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33235687017440796
Epoch 0, Step 1779: train/loss = 0.3104232847690582, train/raw-loss = 0.28007668256759644, train/logprobs = tensor([[-1.4393, -5.9546],
        [-2.8842, -2.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034660816192627
Epoch 0, Step 1780: train/loss = 0.31277143955230713, train/raw-loss = 0.2848014235496521, train/logprobs = tensor([[-1.2773, -4.2123],
        [-2.2717, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27970030903816223
Epoch 0, Step 1781: train/loss = 0.06463140994310379, train/raw-loss = 0.03218628466129303, train/logprobs = tensor([[-1.7920, -7.4212],
        [-4.7196, -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244512379169464
Epoch 0, Step 1782: train/loss = 0.5039116144180298, train/raw-loss = 0.47975489497184753, train/logprobs = tensor([[-1.0606, -3.2174],
        [-1.5622, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24156755208969116
Epoch 0, Step 1783: train/loss = 0.28416523337364197, train/raw-loss = 0.251259446144104, train/logprobs = tensor([[-2.0882, -4.4563],
        [-3.5529, -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290577530860901
Epoch 0, Step 1784: train/loss = 0.3763669729232788, train/raw-loss = 0.3431103527545929, train/logprobs = tensor([[-0.9446, -2.9232],
        [-3.0405, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33256611227989197
Epoch 0, Step 1785: train/loss = 0.39303725957870483, train/raw-loss = 0.355224072933197, train/logprobs = tensor([[-1.2158, -3.8479],
        [-3.0564, -2.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37813133001327515
Epoch 0, Step 1786: train/loss = 0.6996201276779175, train/raw-loss = 0.6633068919181824, train/logprobs = tensor([[-2.4970, -4.8387],
        [-2.9819, -1.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36313220858573914
Epoch 0, Step 1787: train/loss = 0.12536469101905823, train/raw-loss = 0.09162859618663788, train/logprobs = tensor([[-2.1863, -7.9992],
        [-3.9245, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373609185218811
Epoch 0, Step 1788: train/loss = 0.44591936469078064, train/raw-loss = 0.41144686937332153, train/logprobs = tensor([[-1.9509, -4.8024],
        [-3.8487, -2.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447250425815582
Epoch 0, Step 1789: train/loss = 0.10968083888292313, train/raw-loss = 0.07518862187862396, train/logprobs = tensor([[-1.6059, -7.9977],
        [-3.8747, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34492215514183044
Epoch 0, Step 1790: train/loss = 0.1671905815601349, train/raw-loss = 0.14125104248523712, train/logprobs = tensor([[-1.5183, -7.0996],
        [-3.1923, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25939539074897766
Epoch 0, Step 1791: train/loss = 0.48806777596473694, train/raw-loss = 0.4528755247592926, train/logprobs = tensor([[-1.4345, -3.1731],
        [-2.3948, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3519226610660553
Epoch 0, Step 1792: train/loss = 0.3574414551258087, train/raw-loss = 0.32098859548568726, train/logprobs = tensor([[-1.5566, -6.7312],
        [-4.3665, -2.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645287752151489
Epoch 0, Step 1793: train/loss = 0.4936513304710388, train/raw-loss = 0.4703105390071869, train/logprobs = tensor([[-1.7673, -2.6244],
        [-2.2738, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23340749740600586
Epoch 0, Step 1794: train/loss = 0.2807543873786926, train/raw-loss = 0.2552415728569031, train/logprobs = tensor([[-1.2142, -8.5483],
        [-1.5425, -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25512829422950745
Epoch 0, Step 1795: train/loss = 0.4839114248752594, train/raw-loss = 0.44942507147789, train/logprobs = tensor([[-1.7085, -5.3503],
        [-3.2041, -2.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3448634445667267
Epoch 0, Step 1796: train/loss = 0.3620012700557709, train/raw-loss = 0.3291500508785248, train/logprobs = tensor([[-1.4014, -3.6333],
        [-2.6956, -1.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32851219177246094
Epoch 0, Step 1797: train/loss = 0.33343327045440674, train/raw-loss = 0.3020629584789276, train/logprobs = tensor([[-1.0427, -5.6916],
        [-2.9718, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31370288133621216
Epoch 0, Step 1798: train/loss = 0.3450177311897278, train/raw-loss = 0.3100265860557556, train/logprobs = tensor([[-2.1273, -6.8675],
        [-3.1376, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3499113917350769
Epoch 0, Step 1799: train/loss = 0.8692169785499573, train/raw-loss = 0.8404070138931274, train/logprobs = tensor([[-2.6896, -4.8723],
        [-1.4103, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28810012340545654
Epoch 0, Step 1800: train/loss = 0.2781336307525635, train/raw-loss = 0.243599072098732, train/logprobs = tensor([[-1.1658, -5.2197],
        [-2.5834, -1.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3453454375267029
Epoch 0, Step 1801: train/loss = 0.4366524815559387, train/raw-loss = 0.4057545065879822, train/logprobs = tensor([[-1.8413, -4.1772],
        [-3.1449, -2.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30897966027259827
Epoch 0, Step 1802: train/loss = 0.3187366724014282, train/raw-loss = 0.28336071968078613, train/logprobs = tensor([[-1.9227, -9.2758],
        [-3.9878, -1.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35375964641571045
Epoch 0, Step 1803: train/loss = 0.38438984751701355, train/raw-loss = 0.3531988859176636, train/logprobs = tensor([[-1.6934, -6.4169],
        [-3.0851, -1.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119097352027893
Epoch 0, Step 1804: train/loss = 0.26771649718284607, train/raw-loss = 0.23712104558944702, train/logprobs = tensor([[-1.0140, -3.6227],
        [-2.2427, -1.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059544861316681
Epoch 0, Step 1805: train/loss = 0.36306026577949524, train/raw-loss = 0.3318517804145813, train/logprobs = tensor([[-1.2626, -9.0678],
        [-2.7552, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31208470463752747
Epoch 0, Step 1806: train/loss = 0.5208089351654053, train/raw-loss = 0.4813411235809326, train/logprobs = tensor([[-1.4888, -4.7140],
        [-3.4874, -3.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946784734725952
Epoch 0, Step 1807: train/loss = 0.211761936545372, train/raw-loss = 0.17705337703227997, train/logprobs = tensor([[-1.4322, -5.4441],
        [-3.5063, -1.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34708553552627563
Epoch 0, Step 1808: train/loss = 0.19957713782787323, train/raw-loss = 0.17293260991573334, train/logprobs = tensor([[-1.9610, -9.4080],
        [-3.2912, -1.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664453089237213
Epoch 0, Step 1809: train/loss = 0.2738156318664551, train/raw-loss = 0.23916415870189667, train/logprobs = tensor([[ -1.6612, -11.9466],
        [ -2.9642,  -2.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34651488065719604
Epoch 0, Step 1810: train/loss = 0.40760183334350586, train/raw-loss = 0.377482533454895, train/logprobs = tensor([[-1.1850, -2.6686],
        [-3.2375, -1.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011927902698517
Epoch 0, Step 1811: train/loss = 0.22812247276306152, train/raw-loss = 0.19872097671031952, train/logprobs = tensor([[-1.2323, -7.5302],
        [-2.8267, -1.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2940150499343872
Epoch 0, Step 1812: train/loss = 0.5455490946769714, train/raw-loss = 0.5188895463943481, train/logprobs = tensor([[-0.6993, -3.0915],
        [-1.6264, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26659560203552246
Epoch 0, Step 1813: train/loss = 0.39583539962768555, train/raw-loss = 0.36235669255256653, train/logprobs = tensor([[-1.8543, -3.8421],
        [-3.1759, -1.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33478739857673645
Epoch 0, Step 1814: train/loss = 0.2871648073196411, train/raw-loss = 0.2566539943218231, train/logprobs = tensor([[-1.4108, -4.5530],
        [-3.3633, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30510812997817993
Epoch 0, Step 1815: train/loss = 0.13894931972026825, train/raw-loss = 0.11022473126649857, train/logprobs = tensor([[-1.2793, -6.8452],
        [-3.0767, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872459292411804
Epoch 0, Step 1816: train/loss = 0.6725685000419617, train/raw-loss = 0.6390584707260132, train/logprobs = tensor([[-1.4592, -1.7374],
        [-2.1423, -1.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351006507873535
Epoch 0, Step 1817: train/loss = 0.22469162940979004, train/raw-loss = 0.1922174096107483, train/logprobs = tensor([[-1.6332, -7.0627],
        [-4.4696, -1.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32474225759506226
Epoch 0, Step 1818: train/loss = 0.33648064732551575, train/raw-loss = 0.3084033131599426, train/logprobs = tensor([[-1.4496, -4.3861],
        [-2.0112, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807731032371521
Epoch 0, Step 1819: train/loss = 0.40687912702560425, train/raw-loss = 0.3834097385406494, train/logprobs = tensor([[-0.6667, -5.0707],
        [-3.0580, -1.2945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23469389975070953
Epoch 0, Step 1820: train/loss = 0.44257473945617676, train/raw-loss = 0.41384589672088623, train/logprobs = tensor([[-1.3751, -6.0973],
        [-1.9735, -0.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28728848695755005
Epoch 0, Step 1821: train/loss = 0.354625403881073, train/raw-loss = 0.3224618434906006, train/logprobs = tensor([[-1.2623, -5.6978],
        [-2.3898, -2.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3216356039047241
Epoch 0, Step 1822: train/loss = 0.6526628732681274, train/raw-loss = 0.6169756650924683, train/logprobs = tensor([[-2.0372, -3.3040],
        [-3.5953, -2.6095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568717837333679
Epoch 0, Step 1823: train/loss = 0.3162863254547119, train/raw-loss = 0.2828857898712158, train/logprobs = tensor([[-1.9253, -3.2475],
        [-3.8771, -1.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3340054154396057
Epoch 0, Step 1824: train/loss = 0.4852057099342346, train/raw-loss = 0.4577380120754242, train/logprobs = tensor([[-1.3201, -2.7905],
        [-1.6654, -1.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746768891811371
Epoch 0, Step 1825: train/loss = 0.07701794058084488, train/raw-loss = 0.04389842972159386, train/logprobs = tensor([[ -1.7560, -10.1850],
        [ -4.7050,  -1.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33119505643844604
Epoch 0, Step 1826: train/loss = 0.45919549465179443, train/raw-loss = 0.42441993951797485, train/logprobs = tensor([[-1.7718, -3.0548],
        [-2.6642, -2.3281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34775590896606445
Epoch 0, Step 1827: train/loss = 0.5881933569908142, train/raw-loss = 0.561009407043457, train/logprobs = tensor([[-1.5922, -3.9565],
        [-2.2109, -1.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2718396782875061
Epoch 0, Step 1828: train/loss = 0.09962929785251617, train/raw-loss = 0.06730002164840698, train/logprobs = tensor([[-1.1288, -6.1005],
        [-3.5639, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32329267263412476
Epoch 0, Step 1829: train/loss = 0.3396573066711426, train/raw-loss = 0.3093021512031555, train/logprobs = tensor([[-1.0159, -5.3548],
        [-3.5345, -1.4372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035517632961273
Epoch 0, Step 1830: train/loss = 0.5227592587471008, train/raw-loss = 0.47977668046951294, train/logprobs = tensor([[-1.2313, -2.6875],
        [-3.3956, -2.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42982596158981323
Epoch 0, Step 1831: train/loss = 0.24998188018798828, train/raw-loss = 0.22209328413009644, train/logprobs = tensor([[-0.8256, -5.5999],
        [-2.5001, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27888572216033936
Epoch 0, Step 1832: train/loss = 0.434883177280426, train/raw-loss = 0.40826836228370667, train/logprobs = tensor([[-2.4225, -6.8710],
        [-2.7630, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661481201648712
Epoch 0, Step 1833: train/loss = 0.0632682740688324, train/raw-loss = 0.034213948994874954, train/logprobs = tensor([[-1.7674, -8.7516],
        [-4.7889, -1.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29054325819015503
Epoch 0, Step 1834: train/loss = 0.3874509036540985, train/raw-loss = 0.3489491641521454, train/logprobs = tensor([[-1.2998, -4.4022],
        [-3.5044, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850175440311432
Epoch 0, Step 1835: train/loss = 0.39161139726638794, train/raw-loss = 0.3613250255584717, train/logprobs = tensor([[-0.9750, -3.1269],
        [-3.3548, -1.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028638958930969
Epoch 0, Step 1836: train/loss = 0.3421701490879059, train/raw-loss = 0.30116966366767883, train/logprobs = tensor([[-1.0360, -2.6569],
        [-3.7667, -2.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4100049138069153
Epoch 0, Step 1837: train/loss = 0.1514061987400055, train/raw-loss = 0.12643282115459442, train/logprobs = tensor([[-1.1683, -5.0718],
        [-3.0430, -1.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24973373115062714
Epoch 0, Step 1838: train/loss = 0.35935652256011963, train/raw-loss = 0.3311458230018616, train/logprobs = tensor([[-1.6330, -5.5818],
        [-2.5778, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28210726380348206
Epoch 0, Step 1839: train/loss = 0.3658679127693176, train/raw-loss = 0.3293628692626953, train/logprobs = tensor([[-1.2891, -3.4456],
        [-2.9060, -2.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36505064368247986
Epoch 0, Step 1840: train/loss = 0.25826096534729004, train/raw-loss = 0.21811819076538086, train/logprobs = tensor([[-1.4338, -5.4071],
        [-4.6443, -2.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4014279842376709
Epoch 0, Step 1841: train/loss = 0.3553768992424011, train/raw-loss = 0.31970787048339844, train/logprobs = tensor([[-1.0246, -4.5690],
        [-3.3343, -2.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35669034719467163
Epoch 0, Step 1842: train/loss = 0.12586133182048798, train/raw-loss = 0.09173887968063354, train/logprobs = tensor([[-1.6181, -7.5675],
        [-4.3136, -1.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34122446179389954
Epoch 0, Step 1843: train/loss = 0.6045360565185547, train/raw-loss = 0.5782018303871155, train/logprobs = tensor([[-3.0085, -6.8991],
        [-2.3097, -1.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633419632911682
Epoch 0, Step 1844: train/loss = 0.23220570385456085, train/raw-loss = 0.18954630196094513, train/logprobs = tensor([[-1.4362, -6.5243],
        [-4.2665, -1.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4265938997268677
Epoch 0, Step 1845: train/loss = 0.05989079922437668, train/raw-loss = 0.02659589797258377, train/logprobs = tensor([[-1.6362, -8.6519],
        [-4.6935, -1.3389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33294904232025146
Epoch 0, Step 1846: train/loss = 0.3414270281791687, train/raw-loss = 0.308430552482605, train/logprobs = tensor([[-1.8312, -3.9853],
        [-3.1456, -1.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3299645781517029
Epoch 0, Step 1847: train/loss = 0.6280189752578735, train/raw-loss = 0.5955065488815308, train/logprobs = tensor([[-2.2362, -4.1764],
        [-2.5308, -1.4337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251250386238098
Epoch 0, Step 1848: train/loss = 0.5099889636039734, train/raw-loss = 0.4818830192089081, train/logprobs = tensor([[-2.2952, -5.7787],
        [-2.4110, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28105926513671875
Epoch 0, Step 1849: train/loss = 0.6202145218849182, train/raw-loss = 0.5869823098182678, train/logprobs = tensor([[-1.5799, -2.0348],
        [-2.4358, -1.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33232226967811584
Epoch 0, Step 1850: train/loss = 0.5343086123466492, train/raw-loss = 0.5042276978492737, train/logprobs = tensor([[-1.2052, -2.7733],
        [-1.8863, -1.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30080926418304443
Epoch 0, Step 1851: train/loss = 0.597389817237854, train/raw-loss = 0.560580313205719, train/logprobs = tensor([[-1.1120, -2.9060],
        [-3.9015, -2.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680950701236725
Epoch 0, Step 1852: train/loss = 0.37734484672546387, train/raw-loss = 0.3378443121910095, train/logprobs = tensor([[-1.3594, -4.1332],
        [-2.9550, -2.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3950052261352539
Epoch 0, Step 1853: train/loss = 0.6447387933731079, train/raw-loss = 0.6122422218322754, train/logprobs = tensor([[-1.2467, -1.9256],
        [-2.6864, -1.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249659538269043
Epoch 0, Step 1854: train/loss = 0.6962523460388184, train/raw-loss = 0.6698160171508789, train/logprobs = tensor([[-2.5844, -3.7266],
        [-1.8857, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643636465072632
Epoch 0, Step 1855: train/loss = 0.34733709692955017, train/raw-loss = 0.3177349269390106, train/logprobs = tensor([[-1.6987, -5.8260],
        [-2.4476, -2.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29602158069610596
Epoch 0, Step 1856: train/loss = 0.4576311707496643, train/raw-loss = 0.42096665501594543, train/logprobs = tensor([[-1.1044, -4.4833],
        [-2.4781, -2.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3666451871395111
Epoch 0, Step 1857: train/loss = 0.3297104835510254, train/raw-loss = 0.29208672046661377, train/logprobs = tensor([[-1.3950, -4.0965],
        [-3.9145, -2.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762377202510834
Epoch 0, Step 1858: train/loss = 0.40213871002197266, train/raw-loss = 0.3651479482650757, train/logprobs = tensor([[-0.9885, -4.4061],
        [-3.0133, -2.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36990734934806824
Epoch 0, Step 1859: train/loss = 0.3199780583381653, train/raw-loss = 0.2903338670730591, train/logprobs = tensor([[-1.1049, -3.8237],
        [-2.5310, -2.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964420020580292
Epoch 0, Step 1860: train/loss = 0.46928325295448303, train/raw-loss = 0.4336860775947571, train/logprobs = tensor([[-1.2892, -2.6464],
        [-3.5161, -2.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35597217082977295
Epoch 0, Step 1861: train/loss = 0.3676052391529083, train/raw-loss = 0.3353898525238037, train/logprobs = tensor([[-1.2871, -2.9977],
        [-2.9871, -1.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32215380668640137
Epoch 0, Step 1862: train/loss = 0.2507638931274414, train/raw-loss = 0.22297415137290955, train/logprobs = tensor([[-1.0088, -6.5149],
        [-1.9811, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27789708971977234
Epoch 0, Step 1863: train/loss = 0.20076437294483185, train/raw-loss = 0.1626897007226944, train/logprobs = tensor([[-1.0914, -8.8632],
        [-4.7016, -2.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807467222213745
Epoch 0, Step 1864: train/loss = 0.520105242729187, train/raw-loss = 0.48713117837905884, train/logprobs = tensor([[-1.4215, -2.5397],
        [-2.7205, -1.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32974016666412354
Epoch 0, Step 1865: train/loss = 0.3752697706222534, train/raw-loss = 0.3417806625366211, train/logprobs = tensor([[-0.8224, -2.3488],
        [-3.5839, -2.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348912000656128
Epoch 0, Step 1866: train/loss = 0.4184223413467407, train/raw-loss = 0.38457852602005005, train/logprobs = tensor([[-1.7610, -4.1892],
        [-3.4291, -1.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3384379744529724
Epoch 0, Step 1867: train/loss = 0.16523396968841553, train/raw-loss = 0.1324579119682312, train/logprobs = tensor([[-1.9451, -3.7601],
        [-4.4394, -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32776039838790894
Epoch 0, Step 1868: train/loss = 0.5712505578994751, train/raw-loss = 0.5344313383102417, train/logprobs = tensor([[-0.8194, -2.9620],
        [-2.8867, -1.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3681918680667877
Epoch 0, Step 1869: train/loss = 0.29585498571395874, train/raw-loss = 0.2617438733577728, train/logprobs = tensor([[-1.1554, -4.4211],
        [-3.6959, -1.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411112129688263
Epoch 0, Step 1870: train/loss = 0.2539272904396057, train/raw-loss = 0.22496969997882843, train/logprobs = tensor([[-1.3282, -5.7578],
        [-2.7842, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895760238170624
Epoch 0, Step 1871: train/loss = 0.19072015583515167, train/raw-loss = 0.15612564980983734, train/logprobs = tensor([[-1.7668, -8.3831],
        [-3.7457, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34594497084617615
Epoch 0, Step 1872: train/loss = 0.4070061445236206, train/raw-loss = 0.37721532583236694, train/logprobs = tensor([[-1.0533, -5.4040],
        [-3.4312, -1.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979082465171814
Epoch 0, Step 1873: train/loss = 0.3146792948246002, train/raw-loss = 0.277044415473938, train/logprobs = tensor([[-1.6280, -4.3702],
        [-3.6311, -2.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37634867429733276
Epoch 0, Step 1874: train/loss = 0.26205095648765564, train/raw-loss = 0.23256318271160126, train/logprobs = tensor([[-0.8692, -4.1906],
        [-2.3560, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.294877827167511
Epoch 0, Step 1875: train/loss = 0.7258643507957458, train/raw-loss = 0.6888658404350281, train/logprobs = tensor([[-2.6590, -5.1500],
        [-2.6824, -2.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36998450756073
Epoch 0, Step 1876: train/loss = 0.4104209244251251, train/raw-loss = 0.374309241771698, train/logprobs = tensor([[-0.9850, -2.8331],
        [-2.4707, -2.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3611167371273041
Epoch 0, Step 1877: train/loss = 0.43420377373695374, train/raw-loss = 0.40300822257995605, train/logprobs = tensor([[-1.0252, -2.7232],
        [-3.3091, -2.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119553327560425
Epoch 0, Step 1878: train/loss = 0.24792930483818054, train/raw-loss = 0.21993499994277954, train/logprobs = tensor([[-0.9358, -3.6192],
        [-3.2368, -1.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2799430191516876
Epoch 0, Step 1879: train/loss = 0.4543726146221161, train/raw-loss = 0.42157894372940063, train/logprobs = tensor([[-1.4618, -2.8846],
        [-2.6804, -2.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3279366195201874
Epoch 0, Step 1880: train/loss = 0.4926859736442566, train/raw-loss = 0.45687198638916016, train/logprobs = tensor([[-1.0877, -3.3209],
        [-3.7428, -2.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581399917602539
Epoch 0, Step 1881: train/loss = 0.6324993371963501, train/raw-loss = 0.607683002948761, train/logprobs = tensor([[-2.1231, -3.1431],
        [-1.9063, -1.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2481633424758911
Epoch 0, Step 1882: train/loss = 0.29864317178726196, train/raw-loss = 0.26709991693496704, train/logprobs = tensor([[-1.2982, -4.9435],
        [-4.0395, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3154323101043701
Epoch 0, Step 1883: train/loss = 0.19003596901893616, train/raw-loss = 0.15487149357795715, train/logprobs = tensor([[-1.9573, -6.1202],
        [-4.4692, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35164451599121094
Epoch 0, Step 1884: train/loss = 0.13828390836715698, train/raw-loss = 0.10275184363126755, train/logprobs = tensor([[-1.2456, -5.8277],
        [-2.8749, -1.1158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35532060265541077
Epoch 0, Step 1885: train/loss = 0.23288129270076752, train/raw-loss = 0.20054349303245544, train/logprobs = tensor([[-1.2435, -8.5953],
        [-3.7703, -2.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3233780860900879
Epoch 0, Step 1886: train/loss = 0.31698060035705566, train/raw-loss = 0.2883661985397339, train/logprobs = tensor([[-1.9823, -3.4778],
        [-2.9999, -1.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2861437499523163
Epoch 0, Step 1887: train/loss = 0.568686306476593, train/raw-loss = 0.545039176940918, train/logprobs = tensor([[-1.5043, -2.9884],
        [-1.8460, -1.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23647165298461914
Epoch 0, Step 1888: train/loss = 0.11184325069189072, train/raw-loss = 0.07949085533618927, train/logprobs = tensor([[-1.7986, -5.9595],
        [-5.1677, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32352393865585327
Epoch 0, Step 1889: train/loss = 0.208834707736969, train/raw-loss = 0.1795330047607422, train/logprobs = tensor([[-1.4860, -5.3776],
        [-4.4582, -1.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29301702976226807
Epoch 0, Step 1890: train/loss = 0.30709415674209595, train/raw-loss = 0.2789210379123688, train/logprobs = tensor([[-1.5612, -3.1192],
        [-3.2021, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817310690879822
Epoch 0, Step 1891: train/loss = 0.3529874086380005, train/raw-loss = 0.3147463798522949, train/logprobs = tensor([[-1.6383, -4.2377],
        [-4.6990, -2.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3824102282524109
Epoch 0, Step 1892: train/loss = 0.49722564220428467, train/raw-loss = 0.46528956294059753, train/logprobs = tensor([[-1.3333, -3.4646],
        [-2.3705, -2.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3193608522415161
Epoch 0, Step 1893: train/loss = 0.2990243136882782, train/raw-loss = 0.27021288871765137, train/logprobs = tensor([[-1.5253, -3.2687],
        [-2.8658, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881142795085907
Epoch 0, Step 1894: train/loss = 0.08584336936473846, train/raw-loss = 0.054496943950653076, train/logprobs = tensor([[-1.5037, -8.6476],
        [-4.2247, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3134641647338867
Epoch 0, Step 1895: train/loss = 0.2509117126464844, train/raw-loss = 0.21700340509414673, train/logprobs = tensor([[-1.5578, -4.9778],
        [-3.7240, -1.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390832543373108
Epoch 0, Step 1896: train/loss = 0.2516084909439087, train/raw-loss = 0.2230948805809021, train/logprobs = tensor([[-1.1997, -4.8313],
        [-2.9474, -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28513601422309875
Epoch 0, Step 1897: train/loss = 0.4875223934650421, train/raw-loss = 0.44822999835014343, train/logprobs = tensor([[-1.1973, -3.3199],
        [-3.5470, -2.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3929239809513092
Epoch 0, Step 1898: train/loss = 0.610037088394165, train/raw-loss = 0.575967013835907, train/logprobs = tensor([[-1.6872, -2.7557],
        [-3.0094, -1.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34070056676864624
Epoch 0, Step 1899: train/loss = 0.3484189510345459, train/raw-loss = 0.312066912651062, train/logprobs = tensor([[-1.2958, -6.6550],
        [-4.5876, -4.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3635205030441284
Epoch 0, Step 1900: train/loss = 0.34327447414398193, train/raw-loss = 0.3167940378189087, train/logprobs = tensor([[-1.3807, -5.2853],
        [-2.4843, -0.9349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26480430364608765
Epoch 0, Step 1901: train/loss = 0.5326663851737976, train/raw-loss = 0.5076141357421875, train/logprobs = tensor([[-1.1160, -3.7891],
        [-1.5971, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25052255392074585
Epoch 0, Step 1902: train/loss = 0.6105259656906128, train/raw-loss = 0.5813000798225403, train/logprobs = tensor([[-1.4190, -3.0230],
        [-2.6529, -2.1300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2922586500644684
Epoch 0, Step 1903: train/loss = 0.46569573879241943, train/raw-loss = 0.4350361227989197, train/logprobs = tensor([[-0.9903, -2.2787],
        [-2.4054, -1.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30659589171409607
Epoch 0, Step 1904: train/loss = 0.24077066779136658, train/raw-loss = 0.21204309165477753, train/logprobs = tensor([[-1.8449, -5.7253],
        [-4.2944, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872757017612457
Epoch 0, Step 1905: train/loss = 0.3256593942642212, train/raw-loss = 0.30097395181655884, train/logprobs = tensor([[-1.8942, -6.6689],
        [-2.6658, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24685430526733398
Epoch 0, Step 1906: train/loss = 0.29734766483306885, train/raw-loss = 0.26736053824424744, train/logprobs = tensor([[-1.1284, -3.8031],
        [-3.1319, -1.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998712360858917
Epoch 0, Step 1907: train/loss = 0.19028449058532715, train/raw-loss = 0.1574307680130005, train/logprobs = tensor([[-1.0286, -8.0237],
        [-4.0030, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285371959209442
Epoch 0, Step 1908: train/loss = 0.6097856163978577, train/raw-loss = 0.5721768736839294, train/logprobs = tensor([[-1.3686, -3.5070],
        [-3.9544, -2.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37608766555786133
Epoch 0, Step 1909: train/loss = 0.29262787103652954, train/raw-loss = 0.2622130513191223, train/logprobs = tensor([[-0.8568, -4.2962],
        [-3.2703, -2.3059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041483163833618
Epoch 0, Step 1910: train/loss = 0.5292287468910217, train/raw-loss = 0.5024464130401611, train/logprobs = tensor([[-1.3437, -2.8554],
        [-1.5216, -1.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26782310009002686
Epoch 0, Step 1911: train/loss = 0.2289089560508728, train/raw-loss = 0.1969672590494156, train/logprobs = tensor([[-1.7939, -5.2633],
        [-5.0126, -1.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319416880607605
Epoch 0, Step 1912: train/loss = 0.38942649960517883, train/raw-loss = 0.3608262836933136, train/logprobs = tensor([[-1.0555, -6.0382],
        [-2.2774, -1.7581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286001980304718
Epoch 0, Step 1913: train/loss = 0.29659005999565125, train/raw-loss = 0.2597348690032959, train/logprobs = tensor([[-1.4416, -5.6454],
        [-2.9873, -2.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3685520589351654
Epoch 0, Step 1914: train/loss = 0.7603433132171631, train/raw-loss = 0.7326153516769409, train/logprobs = tensor([[-1.9178, -2.3891],
        [-1.7728, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772790193557739
Epoch 0, Step 1915: train/loss = 0.12675097584724426, train/raw-loss = 0.09390807896852493, train/logprobs = tensor([[-1.8188, -6.7871],
        [-4.0931, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32842904329299927
Epoch 0, Step 1916: train/loss = 0.2987769544124603, train/raw-loss = 0.2664232552051544, train/logprobs = tensor([[-2.0131, -6.6938],
        [-3.3814, -1.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235369324684143
Epoch 0, Step 1917: train/loss = 0.5685715675354004, train/raw-loss = 0.5407034754753113, train/logprobs = tensor([[-1.2295, -3.0458],
        [-2.1362, -1.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27868133783340454
Epoch 0, Step 1918: train/loss = 0.18903586268424988, train/raw-loss = 0.16424399614334106, train/logprobs = tensor([[-2.0634, -5.4293],
        [-4.0990, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24791865050792694
Epoch 0, Step 1919: train/loss = 0.5178606510162354, train/raw-loss = 0.4876607656478882, train/logprobs = tensor([[-0.9629, -4.5664],
        [-2.9021, -3.2526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30199873447418213
Epoch 0, Step 1920: train/loss = 0.26155734062194824, train/raw-loss = 0.22996941208839417, train/logprobs = tensor([[-2.1127, -8.0413],
        [-3.7102, -1.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31587931513786316
Epoch 0, Step 1921: train/loss = 0.39251071214675903, train/raw-loss = 0.36063629388809204, train/logprobs = tensor([[-1.3092, -3.3224],
        [-2.9627, -1.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31874406337738037
Epoch 0, Step 1922: train/loss = 0.30099472403526306, train/raw-loss = 0.27477872371673584, train/logprobs = tensor([[-1.7624, -3.7125],
        [-2.8420, -1.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621597945690155
Epoch 0, Step 1923: train/loss = 0.6439452767372131, train/raw-loss = 0.6075000166893005, train/logprobs = tensor([[-1.8056, -2.2285],
        [-3.6477, -2.7615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3644527494907379
Epoch 0, Step 1924: train/loss = 0.44050705432891846, train/raw-loss = 0.4118477702140808, train/logprobs = tensor([[-1.2640, -3.6995],
        [-1.7071, -1.0753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865931987762451
Epoch 0, Step 1925: train/loss = 0.15573322772979736, train/raw-loss = 0.1277070939540863, train/logprobs = tensor([[-1.4766, -6.9563],
        [-4.0023, -1.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802613377571106
Epoch 0, Step 1926: train/loss = 0.34204667806625366, train/raw-loss = 0.3084210753440857, train/logprobs = tensor([[-1.8481, -5.1803],
        [-3.0313, -1.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362559974193573
Epoch 0, Step 1927: train/loss = 0.5140852928161621, train/raw-loss = 0.47808653116226196, train/logprobs = tensor([[-1.4935, -2.9857],
        [-2.7235, -1.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3599870800971985
Epoch 0, Step 1928: train/loss = 0.26266539096832275, train/raw-loss = 0.23146279156208038, train/logprobs = tensor([[-1.5357, -7.0930],
        [-3.3825, -0.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31202614307403564
Epoch 0, Step 1929: train/loss = 0.4650523066520691, train/raw-loss = 0.4398418068885803, train/logprobs = tensor([[-1.6175, -3.0334],
        [-1.9561, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25210505723953247
Epoch 0, Step 1930: train/loss = 0.29928991198539734, train/raw-loss = 0.26710423827171326, train/logprobs = tensor([[-1.4037, -3.1222],
        [-2.3760, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218567967414856
Epoch 0, Step 1931: train/loss = 0.37726396322250366, train/raw-loss = 0.3506828546524048, train/logprobs = tensor([[-1.4988, -6.6010],
        [-2.9481, -1.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658115029335022
Epoch 0, Step 1932: train/loss = 0.3724479079246521, train/raw-loss = 0.34765005111694336, train/logprobs = tensor([[-1.7661, -3.7368],
        [-2.7144, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24797894060611725
Epoch 0, Step 1933: train/loss = 0.3911026120185852, train/raw-loss = 0.3605603575706482, train/logprobs = tensor([[-1.2575, -3.5547],
        [-2.2229, -1.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054225444793701
Epoch 0, Step 1934: train/loss = 0.36572468280792236, train/raw-loss = 0.3357645869255066, train/logprobs = tensor([[-1.1033, -4.7385],
        [-3.1991, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996012270450592
Epoch 0, Step 1935: train/loss = 0.3812485337257385, train/raw-loss = 0.35402804613113403, train/logprobs = tensor([[-1.8898, -5.0744],
        [-3.3880, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722049355506897
Epoch 0, Step 1936: train/loss = 0.13789436221122742, train/raw-loss = 0.11060316860675812, train/logprobs = tensor([[-1.7189, -3.8292],
        [-3.7554, -0.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27291202545166016
Epoch 0, Step 1937: train/loss = 0.2514348328113556, train/raw-loss = 0.21918891370296478, train/logprobs = tensor([[-1.8069, -4.4659],
        [-3.1089, -1.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224591612815857
Epoch 0, Step 1938: train/loss = 0.3103620409965515, train/raw-loss = 0.28241270780563354, train/logprobs = tensor([[-1.2287, -6.2768],
        [-2.2761, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2794932425022125
Epoch 0, Step 1939: train/loss = 0.24649208784103394, train/raw-loss = 0.2166174054145813, train/logprobs = tensor([[-1.6108, -5.7646],
        [-2.7139, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29874664545059204
Epoch 0, Step 1940: train/loss = 0.2652183175086975, train/raw-loss = 0.23335596919059753, train/logprobs = tensor([[-1.2524, -7.3564],
        [-4.1318, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186236619949341
Epoch 0, Step 1941: train/loss = 0.16231654584407806, train/raw-loss = 0.13200582563877106, train/logprobs = tensor([[-1.1716, -7.6657],
        [-2.9683, -1.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30310720205307007
Epoch 0, Step 1942: train/loss = 0.5296831727027893, train/raw-loss = 0.5000715255737305, train/logprobs = tensor([[-3.1282, -6.6247],
        [-3.1379, -2.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961159944534302
Epoch 0, Step 1943: train/loss = 0.3408135175704956, train/raw-loss = 0.31820809841156006, train/logprobs = tensor([[-2.1038, -5.7741],
        [-2.0046, -1.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22605416178703308
Epoch 0, Step 1944: train/loss = 0.5126354694366455, train/raw-loss = 0.47853735089302063, train/logprobs = tensor([[-1.1371, -3.0338],
        [-4.1563, -2.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3409813642501831
Epoch 0, Step 1945: train/loss = 0.18367041647434235, train/raw-loss = 0.15487128496170044, train/logprobs = tensor([[-0.9367, -7.6804],
        [-2.9711, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879912257194519
Epoch 0, Step 1946: train/loss = 0.410042941570282, train/raw-loss = 0.38042980432510376, train/logprobs = tensor([[-2.0060, -4.5687],
        [-3.0165, -0.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961311936378479
Epoch 0, Step 1947: train/loss = 0.4073740243911743, train/raw-loss = 0.3774009048938751, train/logprobs = tensor([[-1.2809, -2.5574],
        [-2.3302, -1.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29973113536834717
Epoch 0, Step 1948: train/loss = 0.34975162148475647, train/raw-loss = 0.3185173273086548, train/logprobs = tensor([[-1.4268, -3.7743],
        [-3.9590, -1.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31234338879585266
Epoch 0, Step 1949: train/loss = 0.30736392736434937, train/raw-loss = 0.2784773111343384, train/logprobs = tensor([[-1.3687, -3.9252],
        [-2.7889, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2888660728931427
Epoch 0, Step 1950: train/loss = 0.4187438488006592, train/raw-loss = 0.39100268483161926, train/logprobs = tensor([[-1.4591, -2.9874],
        [-2.7716, -1.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27741172909736633
Epoch 0, Step 1951: train/loss = 0.2685734033584595, train/raw-loss = 0.2365323305130005, train/logprobs = tensor([[-1.1999, -6.9147],
        [-3.0958, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32041066884994507
Epoch 0, Step 1952: train/loss = 0.36556246876716614, train/raw-loss = 0.3326072692871094, train/logprobs = tensor([[-1.6351, -3.5266],
        [-2.4470, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295518755912781
Epoch 0, Step 1953: train/loss = 0.1287376582622528, train/raw-loss = 0.10076899081468582, train/logprobs = tensor([[-1.8304, -5.6998],
        [-3.9414, -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27968671917915344
Epoch 0, Step 1954: train/loss = 0.4911723732948303, train/raw-loss = 0.46494415402412415, train/logprobs = tensor([[-1.2002, -2.8341],
        [-2.1040, -1.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26228222250938416
Epoch 0, Step 1955: train/loss = 0.4917615056037903, train/raw-loss = 0.4661920666694641, train/logprobs = tensor([[-1.6991, -6.0394],
        [-2.0599, -1.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25569432973861694
Epoch 0, Step 1956: train/loss = 0.10690341144800186, train/raw-loss = 0.07716953754425049, train/logprobs = tensor([[-1.2597, -6.6029],
        [-3.2899, -1.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29733869433403015
Epoch 0, Step 1957: train/loss = 0.3010145425796509, train/raw-loss = 0.2652263641357422, train/logprobs = tensor([[-0.9847, -4.0858],
        [-2.6290, -2.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35788166522979736
Epoch 0, Step 1958: train/loss = 0.3301483988761902, train/raw-loss = 0.28964221477508545, train/logprobs = tensor([[-1.2343, -3.9336],
        [-4.2720, -2.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050619602203369
Epoch 0, Step 1959: train/loss = 0.2518707513809204, train/raw-loss = 0.21385815739631653, train/logprobs = tensor([[-1.2438, -9.8105],
        [-4.5126, -2.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38012605905532837
Epoch 0, Step 1960: train/loss = 0.8096755743026733, train/raw-loss = 0.7772971987724304, train/logprobs = tensor([[-3.2091, -3.3069],
        [-3.2141, -1.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323784202337265
Epoch 0, Step 1961: train/loss = 0.2152455896139145, train/raw-loss = 0.18734562397003174, train/logprobs = tensor([[-0.9885, -7.0959],
        [-1.7498, -1.4571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789997160434723
Epoch 0, Step 1962: train/loss = 0.24058985710144043, train/raw-loss = 0.21210229396820068, train/logprobs = tensor([[-1.1862, -5.7853],
        [-3.1593, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28487566113471985
Epoch 0, Step 1963: train/loss = 0.28993502259254456, train/raw-loss = 0.25551092624664307, train/logprobs = tensor([[-1.6471, -4.2672],
        [-3.9323, -1.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3442409634590149
Epoch 0, Step 1964: train/loss = 0.24569129943847656, train/raw-loss = 0.2207009494304657, train/logprobs = tensor([[-1.1929, -8.2554],
        [-2.1182, -1.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2499033808708191
Epoch 0, Step 1965: train/loss = 0.3058737814426422, train/raw-loss = 0.2692955732345581, train/logprobs = tensor([[-1.7487, -5.7012],
        [-3.1825, -2.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36578190326690674
Epoch 0, Step 1966: train/loss = 0.3799210488796234, train/raw-loss = 0.3495418429374695, train/logprobs = tensor([[-1.9113, -4.5359],
        [-2.4018, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30379223823547363
Epoch 0, Step 1967: train/loss = 0.5585376024246216, train/raw-loss = 0.5281761884689331, train/logprobs = tensor([[-1.2584, -4.3378],
        [-2.5212, -2.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30361407995224
Epoch 0, Step 1968: train/loss = 0.35209694504737854, train/raw-loss = 0.3176531195640564, train/logprobs = tensor([[-1.2627, -2.7362],
        [-3.0353, -1.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34443819522857666
Epoch 0, Step 1969: train/loss = 0.2659420371055603, train/raw-loss = 0.2364572435617447, train/logprobs = tensor([[-1.1479, -4.1029],
        [-2.5175, -1.2811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2948480546474457
Epoch 0, Step 1970: train/loss = 0.43924838304519653, train/raw-loss = 0.412687212228775, train/logprobs = tensor([[-1.6720, -5.5941],
        [-1.8111, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26561152935028076
Epoch 0, Step 1971: train/loss = 0.18470141291618347, train/raw-loss = 0.15089717507362366, train/logprobs = tensor([[-1.9712, -7.1791],
        [-3.5141, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380425274372101
Epoch 0, Step 1972: train/loss = 0.40448451042175293, train/raw-loss = 0.38059186935424805, train/logprobs = tensor([[-0.9948, -2.8651],
        [-1.8052, -1.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23892608284950256
Epoch 0, Step 1973: train/loss = 0.4821242094039917, train/raw-loss = 0.45680081844329834, train/logprobs = tensor([[-1.8008, -2.5787],
        [-2.4816, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532343864440918
Epoch 0, Step 1974: train/loss = 0.4840938448905945, train/raw-loss = 0.45507699251174927, train/logprobs = tensor([[-1.2315, -2.8342],
        [-2.3968, -1.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29016849398612976
Epoch 0, Step 1975: train/loss = 0.3007518947124481, train/raw-loss = 0.27389973402023315, train/logprobs = tensor([[-1.8462, -3.8424],
        [-3.8902, -1.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268521785736084
Epoch 0, Step 1976: train/loss = 0.29976868629455566, train/raw-loss = 0.27676957845687866, train/logprobs = tensor([[-1.6888, -3.9482],
        [-2.4714, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22999118268489838
Epoch 0, Step 1977: train/loss = 0.48312169313430786, train/raw-loss = 0.44912683963775635, train/logprobs = tensor([[-1.3042, -3.0886],
        [-2.5569, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3399485945701599
Epoch 0, Step 1978: train/loss = 0.31485646963119507, train/raw-loss = 0.2874557673931122, train/logprobs = tensor([[-1.0692, -4.9965],
        [-2.8601, -1.1158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27400702238082886
Epoch 0, Step 1979: train/loss = 0.12004590034484863, train/raw-loss = 0.08727818727493286, train/logprobs = tensor([[-1.1095, -7.2443],
        [-3.1425, -1.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276771605014801
Epoch 0, Step 1980: train/loss = 0.0792299211025238, train/raw-loss = 0.04288802295923233, train/logprobs = tensor([[ -2.0227, -10.7302],
        [ -4.6936,  -1.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634189963340759
Epoch 0, Step 1981: train/loss = 0.32343894243240356, train/raw-loss = 0.297671914100647, train/logprobs = tensor([[-1.0921, -2.4675],
        [-2.4970, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25767025351524353
Epoch 0, Step 1982: train/loss = 0.3197759687900543, train/raw-loss = 0.29285693168640137, train/logprobs = tensor([[-2.1118, -4.0802],
        [-2.8008, -1.1567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691904902458191
Epoch 0, Step 1983: train/loss = 0.45311349630355835, train/raw-loss = 0.41653987765312195, train/logprobs = tensor([[-1.5607, -6.8756],
        [-3.5996, -1.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657362461090088
Epoch 0, Step 1984: train/loss = 0.7830801010131836, train/raw-loss = 0.7589735984802246, train/logprobs = tensor([[-2.3771, -2.4112],
        [-1.3234, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24106444418430328
Epoch 0, Step 1985: train/loss = 0.19551101326942444, train/raw-loss = 0.16219070553779602, train/logprobs = tensor([[ -1.6588, -10.6716],
        [ -3.3003,  -1.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332030177116394
Epoch 0, Step 1986: train/loss = 0.2616927921772003, train/raw-loss = 0.23090413212776184, train/logprobs = tensor([[-1.7100, -6.8417],
        [-3.1246, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30788660049438477
Epoch 0, Step 1987: train/loss = 0.4092042148113251, train/raw-loss = 0.3814753293991089, train/logprobs = tensor([[-1.6686, -4.5735],
        [-2.5612, -1.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27728888392448425
Epoch 0, Step 1988: train/loss = 0.22858786582946777, train/raw-loss = 0.20048931241035461, train/logprobs = tensor([[-1.5830, -4.4162],
        [-2.9303, -0.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28098544478416443
Epoch 0, Step 1989: train/loss = 0.46008989214897156, train/raw-loss = 0.4326208531856537, train/logprobs = tensor([[-1.2347, -4.0246],
        [-2.7158, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.274690181016922
Epoch 0, Step 1990: train/loss = 0.7579373121261597, train/raw-loss = 0.7343534231185913, train/logprobs = tensor([[-2.1833, -2.6099],
        [-1.3197, -0.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23583857715129852
Epoch 0, Step 1991: train/loss = 0.15890857577323914, train/raw-loss = 0.13244302570819855, train/logprobs = tensor([[-1.1456, -6.8821],
        [-2.3151, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26465553045272827
Epoch 0, Step 1992: train/loss = 0.11279914528131485, train/raw-loss = 0.07802634686231613, train/logprobs = tensor([[-1.5223, -6.8696],
        [-4.2479, -1.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477279245853424
Epoch 0, Step 1993: train/loss = 0.21339797973632812, train/raw-loss = 0.18502472341060638, train/logprobs = tensor([[-1.0866, -8.1477],
        [-2.6257, -0.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837325632572174
Epoch 0, Step 1994: train/loss = 0.5376490950584412, train/raw-loss = 0.5133891105651855, train/logprobs = tensor([[-0.7825, -3.1153],
        [-1.2034, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.242599755525589
Epoch 0, Step 1995: train/loss = 0.2818055748939514, train/raw-loss = 0.25150489807128906, train/logprobs = tensor([[-1.7245, -2.8143],
        [-3.4989, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30300694704055786
Epoch 0, Step 1996: train/loss = 0.16364729404449463, train/raw-loss = 0.13611094653606415, train/logprobs = tensor([[-1.1644, -7.7136],
        [-2.8740, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2753634750843048
Epoch 0, Step 1997: train/loss = 0.2776336669921875, train/raw-loss = 0.24631765484809875, train/logprobs = tensor([[-1.2675, -5.9835],
        [-3.1951, -2.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31316009163856506
Epoch 0, Step 1998: train/loss = 0.2845098078250885, train/raw-loss = 0.2568487226963043, train/logprobs = tensor([[-1.5115, -4.4990],
        [-2.5170, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27661073207855225
Epoch 0, Step 1999: train/loss = 0.1757301539182663, train/raw-loss = 0.14761239290237427, train/logprobs = tensor([[ -2.3017, -11.9946],
        [ -3.5392,  -1.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28117743134498596
Epoch 0, Step 2000: train/loss = 0.680109441280365, train/raw-loss = 0.6458930969238281, train/logprobs = tensor([[-1.8358, -1.7430],
        [-2.0329, -1.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34216320514678955
Epoch 0, Step 2001: train/loss = 0.10824721306562424, train/raw-loss = 0.08031253516674042, train/logprobs = tensor([[-1.2557, -4.5356],
        [-3.2108, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2793467938899994
Epoch 0, Step 2002: train/loss = 0.2662164270877838, train/raw-loss = 0.23555970191955566, train/logprobs = tensor([[-1.4888, -4.9364],
        [-2.8570, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30656734108924866
Epoch 0, Step 2003: train/loss = 0.39916670322418213, train/raw-loss = 0.36544281244277954, train/logprobs = tensor([[-1.3416, -3.3231],
        [-3.1853, -2.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372388184070587
Epoch 0, Step 2004: train/loss = 0.34073126316070557, train/raw-loss = 0.31421902775764465, train/logprobs = tensor([[-1.6990, -5.5457],
        [-2.1286, -1.2093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26512256264686584
Epoch 0, Step 2005: train/loss = 0.29263681173324585, train/raw-loss = 0.2636050581932068, train/logprobs = tensor([[-1.3010, -5.0605],
        [-3.0470, -2.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29031744599342346
Epoch 0, Step 2006: train/loss = 0.9460064172744751, train/raw-loss = 0.9227885603904724, train/logprobs = tensor([[-3.5447, -4.9476],
        [-2.1863, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23217783868312836
Epoch 0, Step 2007: train/loss = 0.34408825635910034, train/raw-loss = 0.3146686255931854, train/logprobs = tensor([[-1.2840, -4.0310],
        [-2.6181, -1.2371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29419589042663574
Epoch 0, Step 2008: train/loss = 0.34211939573287964, train/raw-loss = 0.3186279535293579, train/logprobs = tensor([[-2.0407, -7.5126],
        [-2.9639, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23491430282592773
Epoch 0, Step 2009: train/loss = 0.3983924686908722, train/raw-loss = 0.3639126121997833, train/logprobs = tensor([[-1.5935, -4.7816],
        [-2.7613, -1.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34479859471321106
Epoch 0, Step 2010: train/loss = 0.35231661796569824, train/raw-loss = 0.33200642466545105, train/logprobs = tensor([[-1.0797, -5.3059],
        [-1.5385, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20310178399085999
Epoch 0, Step 2011: train/loss = 0.6216309666633606, train/raw-loss = 0.5929455757141113, train/logprobs = tensor([[-1.7327, -2.8102],
        [-1.5902, -1.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868539094924927
Epoch 0, Step 2012: train/loss = 0.5750492811203003, train/raw-loss = 0.5448014736175537, train/logprobs = tensor([[-1.4948, -2.1959],
        [-1.8916, -1.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30247819423675537
Epoch 0, Step 2013: train/loss = 0.27550601959228516, train/raw-loss = 0.24715682864189148, train/logprobs = tensor([[-1.3218, -3.7245],
        [-3.3564, -1.3211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28349199891090393
Epoch 0, Step 2014: train/loss = 0.21583999693393707, train/raw-loss = 0.18693402409553528, train/logprobs = tensor([[-1.3222, -4.0772],
        [-3.2442, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890596091747284
Epoch 0, Step 2015: train/loss = 0.3038936257362366, train/raw-loss = 0.2728496491909027, train/logprobs = tensor([[-1.5738, -4.3437],
        [-3.1130, -1.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3104393482208252
Epoch 0, Step 2016: train/loss = 0.28679728507995605, train/raw-loss = 0.2582160532474518, train/logprobs = tensor([[-1.3969, -3.9030],
        [-3.4855, -1.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2858123183250427
Epoch 0, Step 2017: train/loss = 0.2330356240272522, train/raw-loss = 0.20412322878837585, train/logprobs = tensor([[-1.2449, -6.7757],
        [-3.5326, -1.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28912392258644104
Epoch 0, Step 2018: train/loss = 0.3026996850967407, train/raw-loss = 0.28142455220222473, train/logprobs = tensor([[-1.5286, -5.1792],
        [-2.3556, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21275125443935394
Epoch 0, Step 2019: train/loss = 0.23357824981212616, train/raw-loss = 0.20485934615135193, train/logprobs = tensor([[-0.9837, -6.3111],
        [-2.5393, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871887981891632
Epoch 0, Step 2020: train/loss = 0.6433022618293762, train/raw-loss = 0.6162443161010742, train/logprobs = tensor([[-1.8031, -2.2701],
        [-1.5355, -1.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705799341201782
Epoch 0, Step 2021: train/loss = 0.3071528673171997, train/raw-loss = 0.28475263714790344, train/logprobs = tensor([[-1.4399, -3.6454],
        [-2.4647, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2240023910999298
Epoch 0, Step 2022: train/loss = 0.5475583672523499, train/raw-loss = 0.5240918397903442, train/logprobs = tensor([[-1.4147, -2.1085],
        [-1.2609, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2346649467945099
Epoch 0, Step 2023: train/loss = 0.5863363742828369, train/raw-loss = 0.5613192915916443, train/logprobs = tensor([[-1.7420, -1.9592],
        [-2.6984, -1.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2501712739467621
Epoch 0, Step 2024: train/loss = 0.4220791757106781, train/raw-loss = 0.3896062970161438, train/logprobs = tensor([[-2.0821, -3.8053],
        [-2.7783, -1.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3247285485267639
Epoch 0, Step 2025: train/loss = 0.7895927429199219, train/raw-loss = 0.7596392631530762, train/logprobs = tensor([[-2.2477, -3.1770],
        [-1.7913, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2995354235172272
Epoch 0, Step 2026: train/loss = 0.17909856140613556, train/raw-loss = 0.14613154530525208, train/logprobs = tensor([[-2.4294, -6.5477],
        [-4.3052, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.329670250415802
Epoch 0, Step 2027: train/loss = 0.2585166096687317, train/raw-loss = 0.23164008557796478, train/logprobs = tensor([[-1.2772, -7.0692],
        [-3.1233, -1.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687652111053467
Epoch 0, Step 2028: train/loss = 0.3602117896080017, train/raw-loss = 0.33013102412223816, train/logprobs = tensor([[-1.0762, -3.7333],
        [-2.1871, -1.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30080747604370117
Epoch 0, Step 2029: train/loss = 0.2591092884540558, train/raw-loss = 0.23195703327655792, train/logprobs = tensor([[-1.2925, -5.1659],
        [-2.9223, -1.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715224623680115
Epoch 0, Step 2030: train/loss = 0.6444472074508667, train/raw-loss = 0.6155408620834351, train/logprobs = tensor([[-3.0285, -9.5744],
        [-2.8457, -1.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890634536743164
Epoch 0, Step 2031: train/loss = 0.4303582012653351, train/raw-loss = 0.39692413806915283, train/logprobs = tensor([[-1.4258, -3.6398],
        [-2.8973, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33434027433395386
Epoch 0, Step 2032: train/loss = 0.6711670756340027, train/raw-loss = 0.6375619173049927, train/logprobs = tensor([[-1.6257, -6.2650],
        [-3.3063, -2.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3360512852668762
Epoch 0, Step 2033: train/loss = 0.24598519504070282, train/raw-loss = 0.2141592800617218, train/logprobs = tensor([[-1.6043, -8.1665],
        [-3.5348, -1.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318259060382843
Epoch 0, Step 2034: train/loss = 0.17005465924739838, train/raw-loss = 0.14128634333610535, train/logprobs = tensor([[-1.5228, -5.6566],
        [-3.0252, -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876830995082855
Epoch 0, Step 2035: train/loss = 0.4679664969444275, train/raw-loss = 0.4382658004760742, train/logprobs = tensor([[-2.1217, -7.0982],
        [-2.4420, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2970069646835327
Epoch 0, Step 2036: train/loss = 0.5027501583099365, train/raw-loss = 0.4771667718887329, train/logprobs = tensor([[-1.7399, -3.3760],
        [-2.3659, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25583335757255554
Epoch 0, Step 2037: train/loss = 0.22459493577480316, train/raw-loss = 0.19449391961097717, train/logprobs = tensor([[-1.9901, -6.8716],
        [-3.2766, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010101616382599
Epoch 0, Step 2038: train/loss = 0.44423794746398926, train/raw-loss = 0.41480228304862976, train/logprobs = tensor([[-1.0838, -3.8392],
        [-2.0236, -1.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943568825721741
Epoch 0, Step 2039: train/loss = 0.3571019470691681, train/raw-loss = 0.3308889865875244, train/logprobs = tensor([[-1.0031, -4.7164],
        [-2.0166, -1.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26212966442108154
Epoch 0, Step 2040: train/loss = 0.39882177114486694, train/raw-loss = 0.3742341697216034, train/logprobs = tensor([[-1.3496, -5.2056],
        [-2.0257, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24587632715702057
Epoch 0, Step 2041: train/loss = 0.38472455739974976, train/raw-loss = 0.3559148907661438, train/logprobs = tensor([[-0.9998, -3.7809],
        [-1.8307, -1.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28809648752212524
Epoch 0, Step 2042: train/loss = 0.2641652524471283, train/raw-loss = 0.2337309718132019, train/logprobs = tensor([[-1.0720, -4.1830],
        [-3.0384, -1.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043426275253296
Epoch 0, Step 2043: train/loss = 0.660467267036438, train/raw-loss = 0.6346012353897095, train/logprobs = tensor([[-2.2278, -5.9096],
        [-2.1957, -1.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25866061449050903
Epoch 0, Step 2044: train/loss = 0.36220481991767883, train/raw-loss = 0.3381686508655548, train/logprobs = tensor([[-1.1132, -3.5986],
        [-1.5234, -0.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24036182463169098
Epoch 0, Step 2045: train/loss = 0.4154016077518463, train/raw-loss = 0.3891938030719757, train/logprobs = tensor([[-0.4535, -4.7646],
        [-2.1292, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2620784044265747
Epoch 0, Step 2046: train/loss = 0.46986815333366394, train/raw-loss = 0.43983981013298035, train/logprobs = tensor([[-1.9060, -4.9927],
        [-2.4676, -1.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002833425998688
Epoch 0, Step 2047: train/loss = 0.40477168560028076, train/raw-loss = 0.3766694664955139, train/logprobs = tensor([[-1.8249, -6.9443],
        [-2.8528, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2810225486755371
Epoch 0, Step 2048: train/loss = 0.3488139510154724, train/raw-loss = 0.320016086101532, train/logprobs = tensor([[-1.9614, -3.9450],
        [-3.0954, -1.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879788875579834
Epoch 0, Step 2049: train/loss = 0.2645708918571472, train/raw-loss = 0.23679473996162415, train/logprobs = tensor([[-1.4716, -7.5227],
        [-2.1112, -1.4508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2777614891529083
Epoch 0, Step 2050: train/loss = 0.30902835726737976, train/raw-loss = 0.2814275920391083, train/logprobs = tensor([[-1.0679, -3.4678],
        [-2.6803, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27600786089897156
Epoch 0, Step 2051: train/loss = 0.39389297366142273, train/raw-loss = 0.35940274596214294, train/logprobs = tensor([[-1.3062, -3.9421],
        [-3.1580, -1.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3449021875858307
Epoch 0, Step 2052: train/loss = 0.45384687185287476, train/raw-loss = 0.426041841506958, train/logprobs = tensor([[-1.2301, -3.2214],
        [-3.1392, -2.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27805015444755554
Epoch 0, Step 2053: train/loss = 0.14330457150936127, train/raw-loss = 0.1169077605009079, train/logprobs = tensor([[-1.0790, -6.6307],
        [-2.7867, -1.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639681100845337
Epoch 0, Step 2054: train/loss = 0.2972589433193207, train/raw-loss = 0.269583135843277, train/logprobs = tensor([[-1.3613, -6.4734],
        [-2.7537, -1.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767583131790161
Epoch 0, Step 2055: train/loss = 0.10421757400035858, train/raw-loss = 0.07329010218381882, train/logprobs = tensor([[-1.5215, -7.4747],
        [-4.1567, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30927467346191406
Epoch 0, Step 2056: train/loss = 0.38944143056869507, train/raw-loss = 0.36562737822532654, train/logprobs = tensor([[-1.5757, -5.1802],
        [-2.8908, -0.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23814043402671814
Epoch 0, Step 2057: train/loss = 0.3302842676639557, train/raw-loss = 0.3028677999973297, train/logprobs = tensor([[-1.0703, -3.0561],
        [-2.1758, -0.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27416449785232544
Epoch 0, Step 2058: train/loss = 0.3817107081413269, train/raw-loss = 0.35205867886543274, train/logprobs = tensor([[-1.3425, -2.8451],
        [-2.5018, -1.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29652050137519836
Epoch 0, Step 2059: train/loss = 0.35118725895881653, train/raw-loss = 0.3226577639579773, train/logprobs = tensor([[-1.1053, -6.6603],
        [-2.0575, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28529518842697144
Epoch 0, Step 2060: train/loss = 0.2354297637939453, train/raw-loss = 0.2068050652742386, train/logprobs = tensor([[-1.2485, -5.7345],
        [-3.2300, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862471342086792
Epoch 0, Step 2061: train/loss = 0.20572695136070251, train/raw-loss = 0.17335869371891022, train/logprobs = tensor([[-1.7367, -4.8971],
        [-3.5831, -1.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236824870109558
Epoch 0, Step 2062: train/loss = 0.6153321266174316, train/raw-loss = 0.5889772176742554, train/logprobs = tensor([[-1.8463, -5.2700],
        [-2.2081, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2635487914085388
Epoch 0, Step 2063: train/loss = 0.250071257352829, train/raw-loss = 0.2272130250930786, train/logprobs = tensor([[-0.8756, -5.4901],
        [-2.6105, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22858236730098724
Epoch 0, Step 2064: train/loss = 0.4030377268791199, train/raw-loss = 0.3680781424045563, train/logprobs = tensor([[-1.0513, -3.5036],
        [-3.0945, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.349595844745636
Epoch 0, Step 2065: train/loss = 0.2250969409942627, train/raw-loss = 0.2017630934715271, train/logprobs = tensor([[-1.3449, -4.3084],
        [-2.2974, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23333841562271118
Epoch 0, Step 2066: train/loss = 0.5566978454589844, train/raw-loss = 0.5275731086730957, train/logprobs = tensor([[-0.7828, -2.0900],
        [-1.5172, -1.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29124772548675537
Epoch 0, Step 2067: train/loss = 0.4642532467842102, train/raw-loss = 0.43345871567726135, train/logprobs = tensor([[-1.8612, -4.0351],
        [-4.3433, -2.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079454302787781
Epoch 0, Step 2068: train/loss = 0.32568109035491943, train/raw-loss = 0.2936219274997711, train/logprobs = tensor([[-1.5519, -4.4696],
        [-3.3185, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32059168815612793
Epoch 0, Step 2069: train/loss = 0.46455949544906616, train/raw-loss = 0.4414185881614685, train/logprobs = tensor([[-1.6571, -4.2770],
        [-1.8448, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23140892386436462
Epoch 0, Step 2070: train/loss = 0.6096869111061096, train/raw-loss = 0.5792814493179321, train/logprobs = tensor([[-1.0832, -4.0406],
        [-1.9672, -2.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040549159049988
Epoch 0, Step 2071: train/loss = 0.2001214176416397, train/raw-loss = 0.17246472835540771, train/logprobs = tensor([[-1.7423, -7.4618],
        [-2.7017, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.276566743850708
Epoch 0, Step 2072: train/loss = 0.296398788690567, train/raw-loss = 0.26882195472717285, train/logprobs = tensor([[-1.7602, -5.1145],
        [-3.2136, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27576854825019836
Epoch 0, Step 2073: train/loss = 0.2573941946029663, train/raw-loss = 0.22570189833641052, train/logprobs = tensor([[-1.3200, -4.4459],
        [-2.9283, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169228434562683
Epoch 0, Step 2074: train/loss = 0.3397643566131592, train/raw-loss = 0.31573277711868286, train/logprobs = tensor([[-1.3590, -6.3718],
        [-2.8225, -0.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24031603336334229
Epoch 0, Step 2075: train/loss = 0.16766425967216492, train/raw-loss = 0.14134109020233154, train/logprobs = tensor([[-1.2157, -4.9997],
        [-3.0549, -0.9125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26323172450065613
Epoch 0, Step 2076: train/loss = 0.24139362573623657, train/raw-loss = 0.21252760291099548, train/logprobs = tensor([[-1.2480, -3.3620],
        [-2.8322, -1.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28866004943847656
Epoch 0, Step 2077: train/loss = 0.25742146372795105, train/raw-loss = 0.22139599919319153, train/logprobs = tensor([[-0.9060, -3.5042],
        [-2.6903, -2.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602544665336609
Epoch 0, Step 2078: train/loss = 0.3097577393054962, train/raw-loss = 0.283436119556427, train/logprobs = tensor([[-0.7655, -4.5957],
        [-2.0382, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26321619749069214
Epoch 0, Step 2079: train/loss = 0.3383554220199585, train/raw-loss = 0.3132135272026062, train/logprobs = tensor([[-0.9409, -5.6299],
        [-2.2602, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514191269874573
Epoch 0, Step 2080: train/loss = 0.4814377725124359, train/raw-loss = 0.45665866136550903, train/logprobs = tensor([[-1.2018, -4.0099],
        [-2.0655, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24779127538204193
Epoch 0, Step 2081: train/loss = 0.3696080148220062, train/raw-loss = 0.3449289798736572, train/logprobs = tensor([[-1.6772, -4.6853],
        [-2.2910, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24679045379161835
Epoch 0, Step 2082: train/loss = 0.5715198516845703, train/raw-loss = 0.5438125133514404, train/logprobs = tensor([[-1.7274, -3.5329],
        [-1.6378, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770736515522003
Epoch 0, Step 2083: train/loss = 0.31313180923461914, train/raw-loss = 0.2845245897769928, train/logprobs = tensor([[-1.5726, -2.9103],
        [-2.8215, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860722541809082
Epoch 0, Step 2084: train/loss = 0.3216237425804138, train/raw-loss = 0.28813743591308594, train/logprobs = tensor([[-1.3388, -2.0735],
        [-4.0073, -0.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33486315608024597
Epoch 0, Step 2085: train/loss = 0.3857596218585968, train/raw-loss = 0.3499756455421448, train/logprobs = tensor([[-1.5342, -5.6896],
        [-3.5073, -1.8886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.357839971780777
Epoch 0, Step 2086: train/loss = 0.3508889079093933, train/raw-loss = 0.32788214087486267, train/logprobs = tensor([[-0.8866, -3.6133],
        [-1.2531, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23006759583950043
Epoch 0, Step 2087: train/loss = 0.34618517756462097, train/raw-loss = 0.314455509185791, train/logprobs = tensor([[-1.6375, -5.0406],
        [-2.8880, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172970414161682
Epoch 0, Step 2088: train/loss = 0.5699278712272644, train/raw-loss = 0.5430083274841309, train/logprobs = tensor([[-2.7781, -3.0126],
        [-2.7481, -1.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691950798034668
Epoch 0, Step 2089: train/loss = 0.495197594165802, train/raw-loss = 0.47140759229660034, train/logprobs = tensor([[-1.7976, -3.6441],
        [-2.0460, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23789992928504944
Epoch 0, Step 2090: train/loss = 0.14258119463920593, train/raw-loss = 0.1152903214097023, train/logprobs = tensor([[-0.9135, -9.5267],
        [-3.1703, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2729087173938751
Epoch 0, Step 2091: train/loss = 0.4320760667324066, train/raw-loss = 0.4060210883617401, train/logprobs = tensor([[-1.3852, -6.4853],
        [-2.0983, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26054996252059937
Epoch 0, Step 2092: train/loss = 0.3742516338825226, train/raw-loss = 0.3453536033630371, train/logprobs = tensor([[-1.8400, -3.8252],
        [-2.4363, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28897982835769653
Epoch 0, Step 2093: train/loss = 0.3740828335285187, train/raw-loss = 0.34724414348602295, train/logprobs = tensor([[-1.2245, -3.6214],
        [-2.1281, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26838672161102295
Epoch 0, Step 2094: train/loss = 0.45776450634002686, train/raw-loss = 0.433258980512619, train/logprobs = tensor([[-2.4335, -3.9342],
        [-2.6677, -1.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24505501985549927
Epoch 0, Step 2095: train/loss = 0.40586960315704346, train/raw-loss = 0.3719172477722168, train/logprobs = tensor([[-1.5610, -8.5610],
        [-3.3583, -1.7281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3395237326622009
Epoch 0, Step 2096: train/loss = 0.5883120894432068, train/raw-loss = 0.5569666028022766, train/logprobs = tensor([[-0.8876, -2.7362],
        [-2.6074, -2.3804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31345516443252563
Epoch 0, Step 2097: train/loss = 0.26175564527511597, train/raw-loss = 0.2313876450061798, train/logprobs = tensor([[-0.9263, -3.8481],
        [-2.6770, -1.4522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30367982387542725
Epoch 0, Step 2098: train/loss = 0.4162587523460388, train/raw-loss = 0.38870903849601746, train/logprobs = tensor([[-1.5492, -3.9436],
        [-2.7630, -1.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2754973769187927
Epoch 0, Step 2099: train/loss = 0.263477623462677, train/raw-loss = 0.23157063126564026, train/logprobs = tensor([[-1.3142, -4.6052],
        [-3.8962, -1.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3190697431564331
Epoch 0, Step 2100: train/loss = 0.44464099407196045, train/raw-loss = 0.421073853969574, train/logprobs = tensor([[-1.2946, -2.7011],
        [-2.3358, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2356717437505722
Epoch 0, Step 2101: train/loss = 0.44653066992759705, train/raw-loss = 0.4199528694152832, train/logprobs = tensor([[-0.9017, -4.2461],
        [-2.8385, -2.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657778561115265
Epoch 0, Step 2102: train/loss = 0.33582019805908203, train/raw-loss = 0.2995094656944275, train/logprobs = tensor([[-1.6928, -5.8848],
        [-3.5898, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36310723423957825
Epoch 0, Step 2103: train/loss = 0.5795927047729492, train/raw-loss = 0.5456719398498535, train/logprobs = tensor([[-1.3726, -3.2779],
        [-4.0794, -2.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392079174518585
Epoch 0, Step 2104: train/loss = 0.38410279154777527, train/raw-loss = 0.35295870900154114, train/logprobs = tensor([[-1.6033, -6.0964],
        [-2.9107, -1.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3114407956600189
Epoch 0, Step 2105: train/loss = 0.10852954536676407, train/raw-loss = 0.08182643353939056, train/logprobs = tensor([[-1.0614, -7.4458],
        [-3.1990, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2670310437679291
Epoch 0, Step 2106: train/loss = 0.5374115109443665, train/raw-loss = 0.5111592411994934, train/logprobs = tensor([[-1.0951, -1.5067],
        [-1.8700, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2625230848789215
Epoch 0, Step 2107: train/loss = 0.2851611077785492, train/raw-loss = 0.2530575096607208, train/logprobs = tensor([[-1.1280, -3.8731],
        [-3.0237, -1.3776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32103607058525085
Epoch 0, Step 2108: train/loss = 0.1364891082048416, train/raw-loss = 0.10932936519384384, train/logprobs = tensor([[-1.7133, -7.1048],
        [-3.7622, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715975046157837
Epoch 0, Step 2109: train/loss = 0.20534245669841766, train/raw-loss = 0.1719779521226883, train/logprobs = tensor([[-1.3134, -2.7126],
        [-4.6882, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3336448669433594
Epoch 0, Step 2110: train/loss = 0.11513540893793106, train/raw-loss = 0.0811116173863411, train/logprobs = tensor([[-1.6179, -7.6968],
        [-4.5999, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34023794531822205
Epoch 0, Step 2111: train/loss = 0.38383275270462036, train/raw-loss = 0.362035870552063, train/logprobs = tensor([[-0.9567, -4.8268],
        [-2.1291, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2179689258337021
Epoch 0, Step 2112: train/loss = 0.45631831884384155, train/raw-loss = 0.42985859513282776, train/logprobs = tensor([[-2.3075, -2.9860],
        [-3.3961, -1.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26459720730781555
Epoch 0, Step 2113: train/loss = 0.06817746162414551, train/raw-loss = 0.038060516119003296, train/logprobs = tensor([[-1.2169, -5.8984],
        [-4.1036, -1.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30116942524909973
Epoch 0, Step 2114: train/loss = 0.10276268422603607, train/raw-loss = 0.07523760199546814, train/logprobs = tensor([[-1.6955, -6.5055],
        [-3.9758, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27525070309638977
Epoch 0, Step 2115: train/loss = 0.5156364440917969, train/raw-loss = 0.49051564931869507, train/logprobs = tensor([[-0.9393, -3.9524],
        [-2.5240, -1.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25120797753334045
Epoch 0, Step 2116: train/loss = 0.24928273260593414, train/raw-loss = 0.21784594655036926, train/logprobs = tensor([[-1.4015, -9.1440],
        [-3.4718, -0.8526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31436777114868164
Epoch 0, Step 2117: train/loss = 0.2841334939002991, train/raw-loss = 0.26252809166908264, train/logprobs = tensor([[-1.0532, -5.7376],
        [-2.5759, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21605415642261505
Epoch 0, Step 2118: train/loss = 0.44526973366737366, train/raw-loss = 0.41974449157714844, train/logprobs = tensor([[-1.6035, -7.1539],
        [-2.1319, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25525254011154175
Epoch 0, Step 2119: train/loss = 0.34573549032211304, train/raw-loss = 0.31066977977752686, train/logprobs = tensor([[-1.5013, -7.7142],
        [-3.8500, -1.3572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3506568372249603
Epoch 0, Step 2120: train/loss = 0.0897606909275055, train/raw-loss = 0.05700014904141426, train/logprobs = tensor([[-1.1752, -4.7756],
        [-3.7403, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32760539650917053
Epoch 0, Step 2121: train/loss = 0.44161999225616455, train/raw-loss = 0.41139116883277893, train/logprobs = tensor([[-1.5499, -5.6835],
        [-2.3996, -1.2306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022882640361786
Epoch 0, Step 2122: train/loss = 0.3921205401420593, train/raw-loss = 0.36791813373565674, train/logprobs = tensor([[-1.5243, -3.5830],
        [-2.4949, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2420240342617035
Epoch 0, Step 2123: train/loss = 0.6236473321914673, train/raw-loss = 0.6011451482772827, train/logprobs = tensor([[-1.5657, -4.7001],
        [-2.0915, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2250218391418457
Epoch 0, Step 2124: train/loss = 0.15820762515068054, train/raw-loss = 0.12425083667039871, train/logprobs = tensor([[-1.4669, -8.8202],
        [-3.7652, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33956775069236755
Epoch 0, Step 2125: train/loss = 0.2713772654533386, train/raw-loss = 0.23885011672973633, train/logprobs = tensor([[-1.6548, -4.5402],
        [-4.2299, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32527148723602295
Epoch 0, Step 2126: train/loss = 0.24053242802619934, train/raw-loss = 0.20620225369930267, train/logprobs = tensor([[-1.0598, -6.1445],
        [-3.2576, -0.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433016836643219
Epoch 0, Step 2127: train/loss = 0.2264201045036316, train/raw-loss = 0.19997809827327728, train/logprobs = tensor([[-0.8346, -5.1799],
        [-2.3050, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644200325012207
Epoch 0, Step 2128: train/loss = 0.34339702129364014, train/raw-loss = 0.3134576380252838, train/logprobs = tensor([[-1.3563, -3.2228],
        [-2.7745, -1.5506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29939407110214233
Epoch 0, Step 2129: train/loss = 0.4939843714237213, train/raw-loss = 0.46515098214149475, train/logprobs = tensor([[-0.8424, -3.3556],
        [-1.6688, -1.6272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28833404183387756
Epoch 0, Step 2130: train/loss = 0.34082910418510437, train/raw-loss = 0.30507251620292664, train/logprobs = tensor([[-1.2398, -4.8515],
        [-3.3800, -2.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3575657606124878
Epoch 0, Step 2131: train/loss = 0.558790385723114, train/raw-loss = 0.5368000864982605, train/logprobs = tensor([[-1.0845, -2.8032],
        [-1.3381, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21990317106246948
Epoch 0, Step 2132: train/loss = 0.4943498373031616, train/raw-loss = 0.46554094552993774, train/logprobs = tensor([[-0.9868, -2.1661],
        [-2.1780, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28808897733688354
Epoch 0, Step 2133: train/loss = 0.1928405612707138, train/raw-loss = 0.16711144149303436, train/logprobs = tensor([[-1.6867, -6.2676],
        [-3.1808, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25729119777679443
Epoch 0, Step 2134: train/loss = 0.249312624335289, train/raw-loss = 0.22126607596874237, train/logprobs = tensor([[-1.4765, -6.8330],
        [-3.8921, -1.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280465692281723
Epoch 0, Step 2135: train/loss = 0.5279477834701538, train/raw-loss = 0.4981173574924469, train/logprobs = tensor([[-1.2566, -2.4350],
        [-2.8932, -1.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983039319515228
Epoch 0, Step 2136: train/loss = 0.3587663173675537, train/raw-loss = 0.3342481851577759, train/logprobs = tensor([[-0.8694, -4.9749],
        [-2.0200, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24518144130706787
Epoch 0, Step 2137: train/loss = 0.680420994758606, train/raw-loss = 0.6442815661430359, train/logprobs = tensor([[-1.9638, -3.2766],
        [-3.0068, -2.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.361394464969635
Epoch 0, Step 2138: train/loss = 0.3720291554927826, train/raw-loss = 0.3408188819885254, train/logprobs = tensor([[-1.1920, -3.7422],
        [-3.8032, -1.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121030330657959
Epoch 0, Step 2139: train/loss = 0.29668471217155457, train/raw-loss = 0.26881247758865356, train/logprobs = tensor([[-0.9134, -5.6098],
        [-2.0449, -1.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787221670150757
Epoch 0, Step 2140: train/loss = 0.14719712734222412, train/raw-loss = 0.1192760020494461, train/logprobs = tensor([[ -0.9331, -10.5869],
        [ -3.1237,  -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27921128273010254
Epoch 0, Step 2141: train/loss = 0.5383410453796387, train/raw-loss = 0.5065414309501648, train/logprobs = tensor([[-1.0941, -3.1570],
        [-2.0359, -1.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31799596548080444
Epoch 0, Step 2142: train/loss = 0.570764422416687, train/raw-loss = 0.544846773147583, train/logprobs = tensor([[-1.6407, -4.6619],
        [-1.8516, -3.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591765820980072
Epoch 0, Step 2143: train/loss = 0.1656319946050644, train/raw-loss = 0.13470077514648438, train/logprobs = tensor([[-1.2013, -4.6027],
        [-4.2122, -1.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30931201577186584
Epoch 0, Step 2144: train/loss = 0.4198998510837555, train/raw-loss = 0.392911434173584, train/logprobs = tensor([[-0.8945, -2.7565],
        [-2.0303, -1.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26988399028778076
Epoch 0, Step 2145: train/loss = 0.18217861652374268, train/raw-loss = 0.15904997289180756, train/logprobs = tensor([[-1.0921, -5.3525],
        [-2.3864, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312864363193512
Epoch 0, Step 2146: train/loss = 0.1246696263551712, train/raw-loss = 0.0946151614189148, train/logprobs = tensor([[-1.1144, -7.0722],
        [-3.0577, -1.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005445897579193
Epoch 0, Step 2147: train/loss = 0.10306444764137268, train/raw-loss = 0.07106403261423111, train/logprobs = tensor([[-0.8851, -7.9992],
        [-2.8333, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200041651725769
Epoch 0, Step 2148: train/loss = 0.3644862174987793, train/raw-loss = 0.33971545100212097, train/logprobs = tensor([[-1.3049, -3.1329],
        [-2.4344, -1.2630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24770782887935638
Epoch 0, Step 2149: train/loss = 0.34821435809135437, train/raw-loss = 0.3096632957458496, train/logprobs = tensor([[-1.6679, -3.5054],
        [-3.9213, -2.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3855108320713043
Epoch 0, Step 2150: train/loss = 0.35427576303482056, train/raw-loss = 0.32622045278549194, train/logprobs = tensor([[-1.0257, -4.1320],
        [-3.3319, -1.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805532217025757
Epoch 0, Step 2151: train/loss = 0.320117712020874, train/raw-loss = 0.28736087679862976, train/logprobs = tensor([[-1.6243, -4.4227],
        [-4.2174, -1.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32756829261779785
Epoch 0, Step 2152: train/loss = 0.1338232308626175, train/raw-loss = 0.10164344310760498, train/logprobs = tensor([[-0.9667, -4.4638],
        [-3.3215, -1.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217978775501251
Epoch 0, Step 2153: train/loss = 0.3596079349517822, train/raw-loss = 0.3280080556869507, train/logprobs = tensor([[-1.5688, -2.7195],
        [-3.0206, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31599873304367065
Epoch 0, Step 2154: train/loss = 0.10909217596054077, train/raw-loss = 0.07660076767206192, train/logprobs = tensor([[-1.1046, -5.3260],
        [-3.8815, -1.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32491421699523926
Epoch 0, Step 2155: train/loss = 0.6399853229522705, train/raw-loss = 0.6078869104385376, train/logprobs = tensor([[-1.7258, -3.0277],
        [-1.9871, -2.3637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209838271141052
Epoch 0, Step 2156: train/loss = 0.2862527370452881, train/raw-loss = 0.2557826638221741, train/logprobs = tensor([[-1.3750, -4.0811],
        [-3.3920, -1.5326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3047008514404297
Epoch 0, Step 2157: train/loss = 0.427985817193985, train/raw-loss = 0.4032374322414398, train/logprobs = tensor([[-1.1620, -4.8941],
        [-1.5921, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24748414754867554
Epoch 0, Step 2158: train/loss = 0.3051682710647583, train/raw-loss = 0.2858421504497528, train/logprobs = tensor([[-1.6412, -5.4560],
        [-2.3452, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19326122105121613
Epoch 0, Step 2159: train/loss = 0.3236981928348541, train/raw-loss = 0.2951802611351013, train/logprobs = tensor([[-1.1206, -6.1438],
        [-3.0003, -2.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28517934679985046
Epoch 0, Step 2160: train/loss = 0.27543848752975464, train/raw-loss = 0.2467789649963379, train/logprobs = tensor([[-1.2278, -7.6384],
        [-3.3553, -1.3005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865951657295227
Epoch 0, Step 2161: train/loss = 0.3036092519760132, train/raw-loss = 0.274006724357605, train/logprobs = tensor([[-1.8044, -4.8166],
        [-3.1587, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960253953933716
Epoch 0, Step 2162: train/loss = 0.695566713809967, train/raw-loss = 0.6550320386886597, train/logprobs = tensor([[-1.1705, -2.5082],
        [-2.4095, -2.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40534693002700806
Epoch 0, Step 2163: train/loss = 0.3336898684501648, train/raw-loss = 0.30473658442497253, train/logprobs = tensor([[-1.1472, -2.8420],
        [-2.5907, -0.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28953275084495544
Epoch 0, Step 2164: train/loss = 0.4869675040245056, train/raw-loss = 0.4648597538471222, train/logprobs = tensor([[-1.4392, -2.9539],
        [-1.6190, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2210775464773178
Epoch 0, Step 2165: train/loss = 0.27571901679039, train/raw-loss = 0.24627800285816193, train/logprobs = tensor([[-1.6043, -5.7765],
        [-3.3427, -1.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2944103479385376
Epoch 0, Step 2166: train/loss = 0.24323660135269165, train/raw-loss = 0.22076444327831268, train/logprobs = tensor([[-0.8153, -4.3420],
        [-2.5441, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22472161054611206
Epoch 0, Step 2167: train/loss = 0.5050740242004395, train/raw-loss = 0.47989851236343384, train/logprobs = tensor([[-1.0669, -1.6604],
        [-2.0024, -1.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25175514817237854
Epoch 0, Step 2168: train/loss = 0.3859110176563263, train/raw-loss = 0.3558909296989441, train/logprobs = tensor([[-1.1754, -3.8297],
        [-2.9669, -1.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002009093761444
Epoch 0, Step 2169: train/loss = 0.4603874087333679, train/raw-loss = 0.4373813569545746, train/logprobs = tensor([[-1.2934, -3.1149],
        [-2.3822, -0.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23006024956703186
Epoch 0, Step 2170: train/loss = 0.19486266374588013, train/raw-loss = 0.1673755645751953, train/logprobs = tensor([[-1.7624, -4.8261],
        [-3.4005, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27487102150917053
Epoch 0, Step 2171: train/loss = 0.9001778364181519, train/raw-loss = 0.8779271245002747, train/logprobs = tensor([[-1.8994, -1.9060],
        [-1.3108, -1.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22250670194625854
Epoch 0, Step 2172: train/loss = 0.2551184594631195, train/raw-loss = 0.2286742776632309, train/logprobs = tensor([[-1.0643, -8.2296],
        [-1.9603, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26444166898727417
Epoch 0, Step 2173: train/loss = 0.3964662551879883, train/raw-loss = 0.368669331073761, train/logprobs = tensor([[-1.1898, -4.8159],
        [-2.9956, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779688835144043
Epoch 0, Step 2174: train/loss = 0.4119904935359955, train/raw-loss = 0.3798416554927826, train/logprobs = tensor([[-1.6715, -2.9692],
        [-3.4524, -2.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32148852944374084
Epoch 0, Step 2175: train/loss = 0.3560253977775574, train/raw-loss = 0.3291582465171814, train/logprobs = tensor([[-1.2472, -3.4213],
        [-2.5918, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2686713933944702
Epoch 0, Step 2176: train/loss = 0.5907068252563477, train/raw-loss = 0.5625298023223877, train/logprobs = tensor([[-1.3367, -1.6058],
        [-2.3193, -1.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817702293395996
Epoch 0, Step 2177: train/loss = 0.17419959604740143, train/raw-loss = 0.14604361355304718, train/logprobs = tensor([[-1.1692, -4.9755],
        [-3.5305, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2815597355365753
Epoch 0, Step 2178: train/loss = 0.6021325588226318, train/raw-loss = 0.5797666311264038, train/logprobs = tensor([[-1.4924, -2.2509],
        [-1.8115, -1.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22365915775299072
Epoch 0, Step 2179: train/loss = 0.5679632425308228, train/raw-loss = 0.5445782542228699, train/logprobs = tensor([[-1.4911, -3.2382],
        [-1.9152, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23384974896907806
Epoch 0, Step 2180: train/loss = 0.5191234350204468, train/raw-loss = 0.4866141676902771, train/logprobs = tensor([[-0.8312, -2.9283],
        [-3.4365, -2.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32509279251098633
Epoch 0, Step 2181: train/loss = 0.32126298546791077, train/raw-loss = 0.2947750687599182, train/logprobs = tensor([[-1.1625, -6.4519],
        [-2.5062, -1.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.264879435300827
Epoch 0, Step 2182: train/loss = 0.29173702001571655, train/raw-loss = 0.2689327597618103, train/logprobs = tensor([[-1.6375, -2.9258],
        [-3.9915, -0.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22804270684719086
Epoch 0, Step 2183: train/loss = 0.579051673412323, train/raw-loss = 0.554875373840332, train/logprobs = tensor([[-1.0817, -2.0755],
        [-2.6980, -1.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417634129524231
Epoch 0, Step 2184: train/loss = 0.4475390911102295, train/raw-loss = 0.4211970567703247, train/logprobs = tensor([[-1.3623, -2.2257],
        [-3.1163, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26342058181762695
Epoch 0, Step 2185: train/loss = 0.28934627771377563, train/raw-loss = 0.2641998529434204, train/logprobs = tensor([[-1.8682, -4.9033],
        [-3.2344, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514640688896179
Epoch 0, Step 2186: train/loss = 0.4854099154472351, train/raw-loss = 0.45837393403053284, train/logprobs = tensor([[-1.0346, -3.3538],
        [-3.0177, -2.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703597843647003
Epoch 0, Step 2187: train/loss = 0.29742348194122314, train/raw-loss = 0.2615198493003845, train/logprobs = tensor([[-1.1451, -3.5390],
        [-3.3790, -2.6408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35903632640838623
Epoch 0, Step 2188: train/loss = 0.42440640926361084, train/raw-loss = 0.3946387767791748, train/logprobs = tensor([[-1.4665, -5.2227],
        [-2.1679, -1.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297676146030426
Epoch 0, Step 2189: train/loss = 0.25473564863204956, train/raw-loss = 0.2181040197610855, train/logprobs = tensor([[-1.4041, -5.6235],
        [-4.9429, -2.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36631616950035095
Epoch 0, Step 2190: train/loss = 0.3913249373435974, train/raw-loss = 0.3570888936519623, train/logprobs = tensor([[-1.5467, -5.1706],
        [-3.8856, -1.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3423606753349304
Epoch 0, Step 2191: train/loss = 0.19644023478031158, train/raw-loss = 0.16936077177524567, train/logprobs = tensor([[-1.2488, -8.2561],
        [-3.3257, -2.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707945704460144
Epoch 0, Step 2192: train/loss = 0.3533722758293152, train/raw-loss = 0.32649311423301697, train/logprobs = tensor([[-1.3071, -2.9781],
        [-3.4322, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687918245792389
Epoch 0, Step 2193: train/loss = 0.10898641496896744, train/raw-loss = 0.07414129376411438, train/logprobs = tensor([[-1.4212, -9.5196],
        [-3.8122, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484512269496918
Epoch 0, Step 2194: train/loss = 0.5126202702522278, train/raw-loss = 0.48795172572135925, train/logprobs = tensor([[-1.1354, -4.3258],
        [-1.6095, -1.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24668550491333008
Epoch 0, Step 2195: train/loss = 0.1712954044342041, train/raw-loss = 0.14329108595848083, train/logprobs = tensor([[-1.8111, -8.9894],
        [-3.8242, -1.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800430953502655
Epoch 0, Step 2196: train/loss = 0.4954395592212677, train/raw-loss = 0.4684678614139557, train/logprobs = tensor([[-1.8350, -5.8835],
        [-1.7111, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697169780731201
Epoch 0, Step 2197: train/loss = 0.31140637397766113, train/raw-loss = 0.28551772236824036, train/logprobs = tensor([[-1.3004, -4.6128],
        [-2.6332, -2.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2588866353034973
Epoch 0, Step 2198: train/loss = 0.2897566556930542, train/raw-loss = 0.26258862018585205, train/logprobs = tensor([[-1.5810, -3.7828],
        [-3.1581, -2.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716805934906006
Epoch 0, Step 2199: train/loss = 0.2483820617198944, train/raw-loss = 0.22255542874336243, train/logprobs = tensor([[-1.6074, -7.6349],
        [-2.5770, -2.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2582661509513855
Epoch 0, Step 2200: train/loss = 0.08198750764131546, train/raw-loss = 0.051508210599422455, train/logprobs = tensor([[-1.2088, -9.0737],
        [-3.6389, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30479303002357483
Epoch 0, Step 2201: train/loss = 0.47165846824645996, train/raw-loss = 0.4412553906440735, train/logprobs = tensor([[-2.7712, -5.1526],
        [-3.2058, -1.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040309548377991
Epoch 0, Step 2202: train/loss = 0.48597782850265503, train/raw-loss = 0.4588255286216736, train/logprobs = tensor([[-1.5509, -2.6679],
        [-2.7148, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27152299880981445
Epoch 0, Step 2203: train/loss = 0.1824764460325241, train/raw-loss = 0.15134690701961517, train/logprobs = tensor([[-0.7792, -9.5276],
        [-3.3713, -1.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31129544973373413
Epoch 0, Step 2204: train/loss = 0.362699419260025, train/raw-loss = 0.3362561762332916, train/logprobs = tensor([[-1.1354, -5.4104],
        [-2.4918, -1.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26443248987197876
Epoch 0, Step 2205: train/loss = 0.10288035869598389, train/raw-loss = 0.07574605941772461, train/logprobs = tensor([[-1.0553, -7.6152],
        [-3.2944, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713429927825928
Epoch 0, Step 2206: train/loss = 0.44170165061950684, train/raw-loss = 0.41764888167381287, train/logprobs = tensor([[-1.1268, -2.3769],
        [-1.8105, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24052786827087402
Epoch 0, Step 2207: train/loss = 0.2584327459335327, train/raw-loss = 0.225192129611969, train/logprobs = tensor([[-1.4290, -7.6762],
        [-3.6319, -2.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33240634202957153
Epoch 0, Step 2208: train/loss = 0.37608131766319275, train/raw-loss = 0.34763702750205994, train/logprobs = tensor([[-0.9958, -4.3626],
        [-1.7810, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2844432294368744
Epoch 0, Step 2209: train/loss = 0.24287176132202148, train/raw-loss = 0.21426209807395935, train/logprobs = tensor([[-0.8035, -2.7849],
        [-3.2008, -1.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286096453666687
Epoch 0, Step 2210: train/loss = 0.2871522903442383, train/raw-loss = 0.2557131350040436, train/logprobs = tensor([[-1.1079, -5.9455],
        [-3.8673, -2.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31439173221588135
Epoch 0, Step 2211: train/loss = 0.3815324008464813, train/raw-loss = 0.354644238948822, train/logprobs = tensor([[-1.3206, -3.1273],
        [-2.7840, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26888179779052734
Epoch 0, Step 2212: train/loss = 0.11793461441993713, train/raw-loss = 0.08449552953243256, train/logprobs = tensor([[-1.7443, -6.2242],
        [-4.4093, -1.6379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33439087867736816
Epoch 0, Step 2213: train/loss = 0.5905154943466187, train/raw-loss = 0.5623533725738525, train/logprobs = tensor([[-1.8248, -4.6073],
        [-1.8358, -1.3536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28162139654159546
Epoch 0, Step 2214: train/loss = 0.3656708598136902, train/raw-loss = 0.33365198969841003, train/logprobs = tensor([[-1.4960, -3.4665],
        [-2.9849, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201884925365448
Epoch 0, Step 2215: train/loss = 0.4493170380592346, train/raw-loss = 0.4194454848766327, train/logprobs = tensor([[-1.6022, -1.9728],
        [-3.4539, -1.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29871535301208496
Epoch 0, Step 2216: train/loss = 0.33249109983444214, train/raw-loss = 0.3058493435382843, train/logprobs = tensor([[-0.9727, -4.5062],
        [-2.0119, -1.6232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664177417755127
Epoch 0, Step 2217: train/loss = 0.6013100743293762, train/raw-loss = 0.5705016255378723, train/logprobs = tensor([[-2.5491, -2.7153],
        [-2.7578, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080838918685913
Epoch 0, Step 2218: train/loss = 0.3482600450515747, train/raw-loss = 0.3192857801914215, train/logprobs = tensor([[-0.6803, -5.2572],
        [-2.8363, -1.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28974246978759766
Epoch 0, Step 2219: train/loss = 0.38249364495277405, train/raw-loss = 0.3578389883041382, train/logprobs = tensor([[-1.1814, -6.2273],
        [-2.0653, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24654652178287506
Epoch 0, Step 2220: train/loss = 0.1546911746263504, train/raw-loss = 0.13462847471237183, train/logprobs = tensor([[-1.1513, -7.2903],
        [-2.3530, -0.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20062685012817383
Epoch 0, Step 2221: train/loss = 0.5938166975975037, train/raw-loss = 0.5631608963012695, train/logprobs = tensor([[-1.6395, -2.9009],
        [-2.9079, -2.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065582811832428
Epoch 0, Step 2222: train/loss = 0.5040034055709839, train/raw-loss = 0.47553157806396484, train/logprobs = tensor([[-1.5654, -2.7209],
        [-2.6547, -2.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28471839427948
Epoch 0, Step 2223: train/loss = 0.39118891954421997, train/raw-loss = 0.36021527647972107, train/logprobs = tensor([[-1.5452, -3.6579],
        [-3.9558, -1.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30973657965660095
Epoch 0, Step 2224: train/loss = 0.44561681151390076, train/raw-loss = 0.42122966051101685, train/logprobs = tensor([[-1.1074, -4.5128],
        [-1.5936, -1.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438717931509018
Epoch 0, Step 2225: train/loss = 0.2882620096206665, train/raw-loss = 0.25461670756340027, train/logprobs = tensor([[-1.2941, -2.9703],
        [-3.0436, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364529013633728
Epoch 0, Step 2226: train/loss = 0.32827338576316833, train/raw-loss = 0.30392372608184814, train/logprobs = tensor([[-0.7275, -7.1756],
        [-1.7609, -1.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24349644780158997
Epoch 0, Step 2227: train/loss = 0.5464470982551575, train/raw-loss = 0.5194945335388184, train/logprobs = tensor([[-1.1634, -2.4497],
        [-1.9078, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2695257067680359
Epoch 0, Step 2228: train/loss = 0.4350719749927521, train/raw-loss = 0.40616375207901, train/logprobs = tensor([[-1.0512, -2.4266],
        [-2.3351, -1.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890823185443878
Epoch 0, Step 2229: train/loss = 0.29146966338157654, train/raw-loss = 0.26095569133758545, train/logprobs = tensor([[-1.2239, -6.8796],
        [-3.5277, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30513960123062134
Epoch 0, Step 2230: train/loss = 0.4336175322532654, train/raw-loss = 0.40373238921165466, train/logprobs = tensor([[-1.0628, -4.7740],
        [-2.4056, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2988516092300415
Epoch 0, Step 2231: train/loss = 0.5714888572692871, train/raw-loss = 0.5477193593978882, train/logprobs = tensor([[-1.3019, -1.7956],
        [-1.7883, -1.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23769482970237732
Epoch 0, Step 2232: train/loss = 0.3485605716705322, train/raw-loss = 0.3219279646873474, train/logprobs = tensor([[-1.9804, -3.6759],
        [-3.0610, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663264274597168
Epoch 0, Step 2233: train/loss = 0.359130322933197, train/raw-loss = 0.3343382477760315, train/logprobs = tensor([[-1.4021, -4.2548],
        [-2.9166, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24792057275772095
Epoch 0, Step 2234: train/loss = 0.6007705926895142, train/raw-loss = 0.5778228044509888, train/logprobs = tensor([[-1.4056, -1.5973],
        [-1.6109, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22947782278060913
Epoch 0, Step 2235: train/loss = 0.3863598108291626, train/raw-loss = 0.36431774497032166, train/logprobs = tensor([[-1.3005, -3.7564],
        [-2.3977, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2204209268093109
Epoch 0, Step 2236: train/loss = 0.23387107253074646, train/raw-loss = 0.20814645290374756, train/logprobs = tensor([[-1.8590, -5.2362],
        [-3.0761, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25724631547927856
Epoch 0, Step 2237: train/loss = 0.25556695461273193, train/raw-loss = 0.22727453708648682, train/logprobs = tensor([[-1.0844, -3.3855],
        [-3.4760, -1.2611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2829241156578064
Epoch 0, Step 2238: train/loss = 0.2369481921195984, train/raw-loss = 0.21132415533065796, train/logprobs = tensor([[-0.7706, -6.3865],
        [-3.3554, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25624048709869385
Epoch 0, Step 2239: train/loss = 0.3411545157432556, train/raw-loss = 0.3166220784187317, train/logprobs = tensor([[-1.2224, -7.3851],
        [-2.8990, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2453242987394333
Epoch 0, Step 2240: train/loss = 0.23310528695583344, train/raw-loss = 0.20317688584327698, train/logprobs = tensor([[-1.0177, -6.6733],
        [-3.8384, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992840111255646
Epoch 0, Step 2241: train/loss = 0.32620561122894287, train/raw-loss = 0.293317586183548, train/logprobs = tensor([[-1.3870, -5.5925],
        [-3.4068, -1.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32888057827949524
Epoch 0, Step 2242: train/loss = 0.6295007467269897, train/raw-loss = 0.6025880575180054, train/logprobs = tensor([[-1.4809, -1.6327],
        [-2.0433, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691270112991333
Epoch 0, Step 2243: train/loss = 0.3089219927787781, train/raw-loss = 0.27567219734191895, train/logprobs = tensor([[-1.0606, -2.3304],
        [-3.2277, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33249804377555847
Epoch 0, Step 2244: train/loss = 0.2839440107345581, train/raw-loss = 0.26026976108551025, train/logprobs = tensor([[-1.4253, -4.9616],
        [-2.6878, -1.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23674240708351135
Epoch 0, Step 2245: train/loss = 0.4816213846206665, train/raw-loss = 0.45376056432724, train/logprobs = tensor([[-1.7352, -7.0737],
        [-2.5080, -1.3355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2786080241203308
Epoch 0, Step 2246: train/loss = 0.6553900241851807, train/raw-loss = 0.6241196990013123, train/logprobs = tensor([[-1.6254, -2.5056],
        [-2.2096, -1.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31270337104797363
Epoch 0, Step 2247: train/loss = 0.3880392014980316, train/raw-loss = 0.3558434545993805, train/logprobs = tensor([[-0.8860, -3.1221],
        [-3.3176, -1.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219572901725769
Epoch 0, Step 2248: train/loss = 0.21662870049476624, train/raw-loss = 0.18989962339401245, train/logprobs = tensor([[-1.0680, -7.3799],
        [-2.8849, -1.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2672906816005707
Epoch 0, Step 2249: train/loss = 0.636524498462677, train/raw-loss = 0.6036720275878906, train/logprobs = tensor([[-1.1921, -2.0416],
        [-1.8688, -2.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32852429151535034
Epoch 0, Step 2250: train/loss = 0.42071038484573364, train/raw-loss = 0.38854143023490906, train/logprobs = tensor([[-1.0606, -4.0750],
        [-2.7681, -1.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3216894865036011
Epoch 0, Step 2251: train/loss = 0.28681817650794983, train/raw-loss = 0.2569003999233246, train/logprobs = tensor([[-0.9022, -7.2759],
        [-3.6473, -2.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991778254508972
Epoch 0, Step 2252: train/loss = 0.4809875190258026, train/raw-loss = 0.44827502965927124, train/logprobs = tensor([[-1.3107, -3.9864],
        [-3.6216, -2.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3271251618862152
Epoch 0, Step 2253: train/loss = 0.5921159386634827, train/raw-loss = 0.5602961778640747, train/logprobs = tensor([[-1.7889, -2.4823],
        [-3.7944, -2.2548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31819722056388855
Epoch 0, Step 2254: train/loss = 0.4999781847000122, train/raw-loss = 0.4674593508243561, train/logprobs = tensor([[-0.8521, -2.2981],
        [-3.1468, -1.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32518845796585083
Epoch 0, Step 2255: train/loss = 0.19094520807266235, train/raw-loss = 0.16108928620815277, train/logprobs = tensor([[-1.9216, -5.7388],
        [-5.0149, -1.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985594868659973
Epoch 0, Step 2256: train/loss = 0.31881117820739746, train/raw-loss = 0.2958616614341736, train/logprobs = tensor([[-1.5281, -2.7119],
        [-2.7748, -0.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22949539124965668
Epoch 0, Step 2257: train/loss = 0.5871109962463379, train/raw-loss = 0.5611709356307983, train/logprobs = tensor([[-1.5501, -2.9531],
        [-1.4640, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25940072536468506
Epoch 0, Step 2258: train/loss = 0.436015784740448, train/raw-loss = 0.4072394371032715, train/logprobs = tensor([[-1.1031, -2.4887],
        [-3.6782, -2.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28776344656944275
Epoch 0, Step 2259: train/loss = 0.2455524057149887, train/raw-loss = 0.2162875086069107, train/logprobs = tensor([[-0.7727, -6.6088],
        [-3.1990, -1.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2926488518714905
Epoch 0, Step 2260: train/loss = 0.15831178426742554, train/raw-loss = 0.12854927778244019, train/logprobs = tensor([[-1.1623, -5.4388],
        [-4.4384, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29762494564056396
Epoch 0, Step 2261: train/loss = 0.32884860038757324, train/raw-loss = 0.30252593755722046, train/logprobs = tensor([[-1.4910, -5.6395],
        [-2.6805, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632264196872711
Epoch 0, Step 2262: train/loss = 0.07528963685035706, train/raw-loss = 0.04091542959213257, train/logprobs = tensor([[-1.1414, -7.9227],
        [-4.7492, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437420427799225
Epoch 0, Step 2263: train/loss = 0.25927236676216125, train/raw-loss = 0.23286819458007812, train/logprobs = tensor([[-1.7112, -3.5704],
        [-2.7807, -0.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.264041930437088
Epoch 0, Step 2264: train/loss = 0.6400652527809143, train/raw-loss = 0.6067550182342529, train/logprobs = tensor([[-1.1976, -1.6050],
        [-2.5072, -2.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331022262573242
Epoch 0, Step 2265: train/loss = 0.22893887758255005, train/raw-loss = 0.19859446585178375, train/logprobs = tensor([[-1.5240, -6.7530],
        [-3.6302, -1.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034440577030182
Epoch 0, Step 2266: train/loss = 0.4261850118637085, train/raw-loss = 0.3895978033542633, train/logprobs = tensor([[-1.2701, -4.9818],
        [-4.2111, -3.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3658723831176758
Epoch 0, Step 2267: train/loss = 0.23954463005065918, train/raw-loss = 0.2044120728969574, train/logprobs = tensor([[-1.8298, -3.7612],
        [-4.8663, -1.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513258099555969
Epoch 0, Step 2268: train/loss = 0.537850558757782, train/raw-loss = 0.5048167705535889, train/logprobs = tensor([[-1.4213, -5.1218],
        [-3.3408, -2.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3303374648094177
Epoch 0, Step 2269: train/loss = 0.22384469211101532, train/raw-loss = 0.1895357370376587, train/logprobs = tensor([[-0.8927, -5.2905],
        [-3.6311, -2.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430895507335663
Epoch 0, Step 2270: train/loss = 0.44786345958709717, train/raw-loss = 0.4226926565170288, train/logprobs = tensor([[-2.6051, -7.7452],
        [-2.5059, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.251708060503006
Epoch 0, Step 2271: train/loss = 0.8000909090042114, train/raw-loss = 0.7657457590103149, train/logprobs = tensor([[-1.7847, -1.6827],
        [-2.3528, -2.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434518873691559
Epoch 0, Step 2272: train/loss = 0.15019913017749786, train/raw-loss = 0.12115918099880219, train/logprobs = tensor([[-1.2426, -5.9984],
        [-3.4174, -1.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29039955139160156
Epoch 0, Step 2273: train/loss = 0.37712904810905457, train/raw-loss = 0.3377891182899475, train/logprobs = tensor([[-1.2262, -4.9862],
        [-3.6254, -2.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39339959621429443
Epoch 0, Step 2274: train/loss = 0.4881952106952667, train/raw-loss = 0.4508323669433594, train/logprobs = tensor([[-0.9857, -3.4856],
        [-3.3267, -2.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37362831830978394
Epoch 0, Step 2275: train/loss = 0.36183881759643555, train/raw-loss = 0.33361148834228516, train/logprobs = tensor([[-1.8558, -3.2178],
        [-2.4854, -1.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822730839252472
Epoch 0, Step 2276: train/loss = 0.6154861450195312, train/raw-loss = 0.5904291272163391, train/logprobs = tensor([[-1.5666, -3.5503],
        [-1.7566, -2.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25056999921798706
Epoch 0, Step 2277: train/loss = 0.11042466759681702, train/raw-loss = 0.08266521245241165, train/logprobs = tensor([[-1.2733, -7.5704],
        [-3.2568, -1.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775944769382477
Epoch 0, Step 2278: train/loss = 0.16448435187339783, train/raw-loss = 0.1399918794631958, train/logprobs = tensor([[-1.1296, -5.3788],
        [-2.7594, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24492481350898743
Epoch 0, Step 2279: train/loss = 0.46077466011047363, train/raw-loss = 0.4363027811050415, train/logprobs = tensor([[-1.6379, -3.6957],
        [-1.9246, -1.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24471864104270935
Epoch 0, Step 2280: train/loss = 0.39595475792884827, train/raw-loss = 0.36033567786216736, train/logprobs = tensor([[-1.3403, -3.3654],
        [-2.9327, -1.2198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35619068145751953
Epoch 0, Step 2281: train/loss = 0.22021251916885376, train/raw-loss = 0.1904211789369583, train/logprobs = tensor([[-1.6056, -3.1022],
        [-3.2351, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297913521528244
Epoch 0, Step 2282: train/loss = 0.38951560854911804, train/raw-loss = 0.3495732545852661, train/logprobs = tensor([[-0.9300, -8.5088],
        [-3.4380, -2.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3994237184524536
Epoch 0, Step 2283: train/loss = 0.3683726489543915, train/raw-loss = 0.33699774742126465, train/logprobs = tensor([[-2.3269, -3.3807],
        [-2.6550, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31374895572662354
Epoch 0, Step 2284: train/loss = 0.11911950260400772, train/raw-loss = 0.09045204520225525, train/logprobs = tensor([[ -1.4956, -13.2343],
        [ -4.1127,  -2.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866746187210083
Epoch 0, Step 2285: train/loss = 0.585972011089325, train/raw-loss = 0.5503531694412231, train/logprobs = tensor([[-2.0428, -4.7534],
        [-3.0749, -2.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3561890125274658
Epoch 0, Step 2286: train/loss = 0.31767404079437256, train/raw-loss = 0.2926807999610901, train/logprobs = tensor([[-1.1548, -4.3420],
        [-3.2965, -1.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24993225932121277
Epoch 0, Step 2287: train/loss = 0.26756641268730164, train/raw-loss = 0.23426544666290283, train/logprobs = tensor([[-1.2463, -3.8532],
        [-3.5340, -1.3374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330095708370209
Epoch 0, Step 2288: train/loss = 0.455211341381073, train/raw-loss = 0.42622941732406616, train/logprobs = tensor([[-1.8635, -3.9558],
        [-3.2435, -1.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2898189425468445
Epoch 0, Step 2289: train/loss = 0.23149347305297852, train/raw-loss = 0.2001955658197403, train/logprobs = tensor([[-1.1326, -5.6725],
        [-3.6063, -2.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.312979131937027
Epoch 0, Step 2290: train/loss = 0.3158375024795532, train/raw-loss = 0.2864384651184082, train/logprobs = tensor([[-1.8115, -9.6111],
        [-3.4213, -2.3805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2939903438091278
Epoch 0, Step 2291: train/loss = 0.4794328510761261, train/raw-loss = 0.454184889793396, train/logprobs = tensor([[-1.9360, -4.8451],
        [-2.7113, -1.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25247955322265625
Epoch 0, Step 2292: train/loss = 0.5648396015167236, train/raw-loss = 0.5389494299888611, train/logprobs = tensor([[-1.5675, -2.3223],
        [-1.6570, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25890159606933594
Epoch 0, Step 2293: train/loss = 0.23844948410987854, train/raw-loss = 0.20602384209632874, train/logprobs = tensor([[-1.6726, -5.2243],
        [-3.3635, -1.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32425668835639954
Epoch 0, Step 2294: train/loss = 0.5201216340065002, train/raw-loss = 0.49464261531829834, train/logprobs = tensor([[-1.7038, -3.0978],
        [-2.3588, -1.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547903060913086
Epoch 0, Step 2295: train/loss = 0.11103888601064682, train/raw-loss = 0.08657491952180862, train/logprobs = tensor([[-1.7779, -5.6809],
        [-4.8847, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24463969469070435
Epoch 0, Step 2296: train/loss = 0.3875754475593567, train/raw-loss = 0.3614180088043213, train/logprobs = tensor([[-3.1385, -4.8370],
        [-4.4695, -2.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26157432794570923
Epoch 0, Step 2297: train/loss = 0.3599964380264282, train/raw-loss = 0.33360788226127625, train/logprobs = tensor([[-1.4201, -5.4444],
        [-2.0874, -1.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638857662677765
Epoch 0, Step 2298: train/loss = 0.45799270272254944, train/raw-loss = 0.43174999952316284, train/logprobs = tensor([[-1.4127, -2.9912],
        [-3.5866, -1.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2624269127845764
Epoch 0, Step 2299: train/loss = 0.1696482002735138, train/raw-loss = 0.1444578617811203, train/logprobs = tensor([[-1.2541, -4.8236],
        [-3.7161, -0.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25190335512161255
Epoch 0, Step 2300: train/loss = 0.34743067622184753, train/raw-loss = 0.3231581449508667, train/logprobs = tensor([[-0.9579, -3.6816],
        [-2.2438, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427254468202591
Epoch 0, Step 2301: train/loss = 0.37229520082473755, train/raw-loss = 0.3454054892063141, train/logprobs = tensor([[-1.7128, -5.6037],
        [-2.6219, -0.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688966691493988
Epoch 0, Step 2302: train/loss = 0.2750067710876465, train/raw-loss = 0.2457137256860733, train/logprobs = tensor([[ -2.5307, -13.7768],
        [ -4.8179,  -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29293033480644226
Epoch 0, Step 2303: train/loss = 0.3257767856121063, train/raw-loss = 0.28923118114471436, train/logprobs = tensor([[-0.8636, -5.0819],
        [-3.4017, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36545616388320923
Epoch 0, Step 2304: train/loss = 0.2923767864704132, train/raw-loss = 0.26816079020500183, train/logprobs = tensor([[-1.1822, -6.4623],
        [-3.1357, -2.2122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24215981364250183
Epoch 0, Step 2305: train/loss = 0.4681755602359772, train/raw-loss = 0.43687301874160767, train/logprobs = tensor([[-1.1804, -2.0177],
        [-2.3779, -1.2521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31302541494369507
Epoch 0, Step 2306: train/loss = 0.1684899926185608, train/raw-loss = 0.14255264401435852, train/logprobs = tensor([[-1.1042, -8.8539],
        [-4.0983, -1.3687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2593735158443451
Epoch 0, Step 2307: train/loss = 0.2050609439611435, train/raw-loss = 0.17832975089550018, train/logprobs = tensor([[-1.8784, -3.7776],
        [-4.7373, -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673117518424988
Epoch 0, Step 2308: train/loss = 0.4450175166130066, train/raw-loss = 0.4120410680770874, train/logprobs = tensor([[-1.2175, -2.6443],
        [-2.9146, -2.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32976391911506653
Epoch 0, Step 2309: train/loss = 0.1740233451128006, train/raw-loss = 0.14167866110801697, train/logprobs = tensor([[ -1.4376, -11.8492],
        [ -4.5757,  -0.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3234468996524811
Epoch 0, Step 2310: train/loss = 0.20854315161705017, train/raw-loss = 0.18080748617649078, train/logprobs = tensor([[-1.2704, -7.1732],
        [-4.2474, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27735665440559387
Epoch 0, Step 2311: train/loss = 0.2660880386829376, train/raw-loss = 0.2332019954919815, train/logprobs = tensor([[-1.3517, -4.7005],
        [-3.5625, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886019349098206
Epoch 0, Step 2312: train/loss = 0.30403438210487366, train/raw-loss = 0.2750629186630249, train/logprobs = tensor([[ -1.3021, -10.8966],
        [ -3.4856,  -1.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897147536277771
Epoch 0, Step 2313: train/loss = 0.13646432757377625, train/raw-loss = 0.10129313170909882, train/logprobs = tensor([[-1.3590, -5.6450],
        [-3.8864, -1.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35171204805374146
Epoch 0, Step 2314: train/loss = 0.39164698123931885, train/raw-loss = 0.3519977927207947, train/logprobs = tensor([[-1.6085, -3.5869],
        [-4.3710, -2.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39649146795272827
Epoch 0, Step 2315: train/loss = 0.1844806671142578, train/raw-loss = 0.15478883683681488, train/logprobs = tensor([[-1.3077, -4.3539],
        [-3.6076, -0.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2969183921813965
Epoch 0, Step 2316: train/loss = 0.4077393710613251, train/raw-loss = 0.37910282611846924, train/logprobs = tensor([[-1.4197, -4.4380],
        [-2.8734, -1.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28636592626571655
Epoch 0, Step 2317: train/loss = 0.2495463341474533, train/raw-loss = 0.21917332708835602, train/logprobs = tensor([[-1.5951, -6.8160],
        [-3.2852, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30373018980026245
Epoch 0, Step 2318: train/loss = 0.14408479630947113, train/raw-loss = 0.11396895349025726, train/logprobs = tensor([[-1.3735, -7.7483],
        [-3.7152, -2.3894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011583387851715
Epoch 0, Step 2319: train/loss = 0.14997489750385284, train/raw-loss = 0.12102506309747696, train/logprobs = tensor([[-1.1826, -4.3842],
        [-3.6878, -0.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28949838876724243
Epoch 0, Step 2320: train/loss = 0.1757187843322754, train/raw-loss = 0.14357733726501465, train/logprobs = tensor([[-1.4484, -6.4835],
        [-3.8631, -0.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3214145600795746
Epoch 0, Step 2321: train/loss = 0.3996465802192688, train/raw-loss = 0.3703470826148987, train/logprobs = tensor([[-1.8527, -4.8850],
        [-2.5010, -1.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929950952529907
Epoch 0, Step 2322: train/loss = 0.6051473617553711, train/raw-loss = 0.5826166868209839, train/logprobs = tensor([[-1.2839, -1.2811],
        [-1.6179, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22530697286128998
Epoch 0, Step 2323: train/loss = 0.1496216058731079, train/raw-loss = 0.12547369301319122, train/logprobs = tensor([[-1.2519, -4.9230],
        [-3.0526, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24147915840148926
Epoch 0, Step 2324: train/loss = 0.21478037536144257, train/raw-loss = 0.18463043868541718, train/logprobs = tensor([[-1.0418, -5.8444],
        [-3.7119, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30149924755096436
Epoch 0, Step 2325: train/loss = 0.3902384042739868, train/raw-loss = 0.35976216197013855, train/logprobs = tensor([[-1.2442, -6.3998],
        [-3.0657, -1.4664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3047623932361603
Epoch 0, Step 2326: train/loss = 0.40905651450157166, train/raw-loss = 0.3805372714996338, train/logprobs = tensor([[-1.3196, -4.9269],
        [-2.6297, -2.3643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28519248962402344
Epoch 0, Step 2327: train/loss = 0.32504451274871826, train/raw-loss = 0.3019976317882538, train/logprobs = tensor([[-0.9970, -3.5871],
        [-2.5807, -0.8228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23046892881393433
Epoch 0, Step 2328: train/loss = 0.41644424200057983, train/raw-loss = 0.38976946473121643, train/logprobs = tensor([[-1.0326, -2.3235],
        [-2.4846, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2667478024959564
Epoch 0, Step 2329: train/loss = 0.33547455072402954, train/raw-loss = 0.30679070949554443, train/logprobs = tensor([[-1.8262, -5.8763],
        [-2.8216, -1.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28683847188949585
Epoch 0, Step 2330: train/loss = 0.22584249079227448, train/raw-loss = 0.2028656303882599, train/logprobs = tensor([[-1.5961, -4.5754],
        [-2.9879, -1.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22976861894130707
Epoch 0, Step 2331: train/loss = 0.357669860124588, train/raw-loss = 0.3284187912940979, train/logprobs = tensor([[-0.9195, -8.5313],
        [-2.8705, -2.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29251062870025635
Epoch 0, Step 2332: train/loss = 0.1066526398062706, train/raw-loss = 0.07834944128990173, train/logprobs = tensor([[-1.8587, -6.0953],
        [-4.5245, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28303200006484985
Epoch 0, Step 2333: train/loss = 0.23002907633781433, train/raw-loss = 0.20078429579734802, train/logprobs = tensor([[-1.3683, -4.5658],
        [-3.5246, -1.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2924477756023407
Epoch 0, Step 2334: train/loss = 0.28330910205841064, train/raw-loss = 0.2572086453437805, train/logprobs = tensor([[-1.9266, -5.1351],
        [-3.0302, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26100438833236694
Epoch 0, Step 2335: train/loss = 0.5634514093399048, train/raw-loss = 0.527489185333252, train/logprobs = tensor([[-1.8728, -5.6187],
        [-3.4765, -2.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3596216142177582
Epoch 0, Step 2336: train/loss = 0.5345976948738098, train/raw-loss = 0.5021092295646667, train/logprobs = tensor([[-1.9642, -4.5255],
        [-2.5818, -1.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32488489151000977
Epoch 0, Step 2337: train/loss = 0.19883513450622559, train/raw-loss = 0.16553880274295807, train/logprobs = tensor([[-1.4784, -8.4650],
        [-3.8126, -2.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33296334743499756
Epoch 0, Step 2338: train/loss = 0.4047917425632477, train/raw-loss = 0.3760603070259094, train/logprobs = tensor([[-1.1536, -3.1076],
        [-2.2111, -2.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873145341873169
Epoch 0, Step 2339: train/loss = 0.7890424728393555, train/raw-loss = 0.7589016556739807, train/logprobs = tensor([[-1.5929, -1.3371],
        [-1.8429, -1.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3014090657234192
Epoch 0, Step 2340: train/loss = 0.340813547372818, train/raw-loss = 0.31161803007125854, train/logprobs = tensor([[-1.7800, -5.2052],
        [-3.9215, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29195526242256165
Epoch 0, Step 2341: train/loss = 0.4077969193458557, train/raw-loss = 0.38264715671539307, train/logprobs = tensor([[-1.5047, -2.3715],
        [-2.5849, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514975965023041
Epoch 0, Step 2342: train/loss = 0.12879575788974762, train/raw-loss = 0.10465718805789948, train/logprobs = tensor([[-1.3049, -5.7270],
        [-3.1435, -1.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24138563871383667
Epoch 0, Step 2343: train/loss = 0.5111402273178101, train/raw-loss = 0.4808266758918762, train/logprobs = tensor([[-1.5370, -3.3183],
        [-2.6664, -2.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30313578248023987
Epoch 0, Step 2344: train/loss = 0.6846085786819458, train/raw-loss = 0.6592556238174438, train/logprobs = tensor([[-1.4394, -1.7541],
        [-2.3212, -1.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25352975726127625
Epoch 0, Step 2345: train/loss = 0.3439212441444397, train/raw-loss = 0.30987200140953064, train/logprobs = tensor([[-0.9425, -3.5087],
        [-3.5653, -1.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34049245715141296
Epoch 0, Step 2346: train/loss = 0.2752229869365692, train/raw-loss = 0.2518308460712433, train/logprobs = tensor([[-1.2251, -4.9655],
        [-2.7109, -1.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23392120003700256
Epoch 0, Step 2347: train/loss = 0.2862613797187805, train/raw-loss = 0.2593134641647339, train/logprobs = tensor([[-1.1965, -3.2061],
        [-2.2583, -1.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26947909593582153
Epoch 0, Step 2348: train/loss = 0.4273969531059265, train/raw-loss = 0.4024078845977783, train/logprobs = tensor([[-1.0972, -3.0284],
        [-2.8685, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498905509710312
Epoch 0, Step 2349: train/loss = 0.44682812690734863, train/raw-loss = 0.41809532046318054, train/logprobs = tensor([[-1.7662, -3.3070],
        [-3.1122, -1.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873281240463257
Epoch 0, Step 2350: train/loss = 0.618724524974823, train/raw-loss = 0.5814650058746338, train/logprobs = tensor([[-1.2859, -1.7261],
        [-4.0927, -2.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3725947141647339
Epoch 0, Step 2351: train/loss = 0.48716485500335693, train/raw-loss = 0.4638513922691345, train/logprobs = tensor([[-2.6801, -8.1365],
        [-2.7222, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23313438892364502
Epoch 0, Step 2352: train/loss = 0.4947757124900818, train/raw-loss = 0.46326568722724915, train/logprobs = tensor([[-1.2985, -3.1228],
        [-2.0769, -2.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31509989500045776
Epoch 0, Step 2353: train/loss = 0.36067718267440796, train/raw-loss = 0.33885860443115234, train/logprobs = tensor([[-1.7456, -6.6250],
        [-3.1990, -1.0009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.218185693025589
Epoch 0, Step 2354: train/loss = 0.3786900043487549, train/raw-loss = 0.35145121812820435, train/logprobs = tensor([[-1.5496, -5.8540],
        [-1.9739, -1.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723877429962158
Epoch 0, Step 2355: train/loss = 0.3595472276210785, train/raw-loss = 0.3304751515388489, train/logprobs = tensor([[-1.5528, -3.9888],
        [-2.4599, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29072049260139465
Epoch 0, Step 2356: train/loss = 0.4849938154220581, train/raw-loss = 0.46231192350387573, train/logprobs = tensor([[-1.4322, -4.8126],
        [-2.0795, -1.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22681866586208344
Epoch 0, Step 2357: train/loss = 0.4015693664550781, train/raw-loss = 0.37047165632247925, train/logprobs = tensor([[-2.5372, -7.4155],
        [-4.2647, -1.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31097733974456787
Epoch 0, Step 2358: train/loss = 0.21796008944511414, train/raw-loss = 0.18654820322990417, train/logprobs = tensor([[-1.7026, -5.5093],
        [-3.1217, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31411898136138916
Epoch 0, Step 2359: train/loss = 0.08524151146411896, train/raw-loss = 0.05358169972896576, train/logprobs = tensor([[-1.4077, -5.1642],
        [-4.0248, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31659817695617676
Epoch 0, Step 2360: train/loss = 0.6618091464042664, train/raw-loss = 0.6196195483207703, train/logprobs = tensor([[-1.2819, -3.9766],
        [-3.5860, -2.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218965768814087
Epoch 0, Step 2361: train/loss = 0.42572495341300964, train/raw-loss = 0.39510712027549744, train/logprobs = tensor([[ -3.4683, -11.2201],
        [ -5.5278,  -2.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30617859959602356
Epoch 0, Step 2362: train/loss = 0.1846284568309784, train/raw-loss = 0.1546284556388855, train/logprobs = tensor([[-1.5309, -3.5452],
        [-3.6065, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30000001192092896
Epoch 0, Step 2363: train/loss = 0.4489993453025818, train/raw-loss = 0.41631877422332764, train/logprobs = tensor([[-1.1378, -4.1110],
        [-3.8770, -2.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32680556178092957
Epoch 0, Step 2364: train/loss = 0.7318890690803528, train/raw-loss = 0.6994670629501343, train/logprobs = tensor([[-1.3250, -1.9258],
        [-3.0138, -2.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3242204785346985
Epoch 0, Step 2365: train/loss = 0.22673329710960388, train/raw-loss = 0.1959570348262787, train/logprobs = tensor([[-0.9338, -6.1588],
        [-2.8476, -1.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30776262283325195
Epoch 0, Step 2366: train/loss = 0.16439184546470642, train/raw-loss = 0.13643111288547516, train/logprobs = tensor([[-1.4657, -5.9020],
        [-4.6541, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27960723638534546
Epoch 0, Step 2367: train/loss = 0.2762856185436249, train/raw-loss = 0.2492748200893402, train/logprobs = tensor([[-0.6868, -4.2796],
        [-2.0245, -1.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701079249382019
Epoch 0, Step 2368: train/loss = 0.24333110451698303, train/raw-loss = 0.21482497453689575, train/logprobs = tensor([[-0.8776, -5.5705],
        [-2.3789, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2850612699985504
Epoch 0, Step 2369: train/loss = 0.5566745400428772, train/raw-loss = 0.5244205594062805, train/logprobs = tensor([[-1.4992, -3.5552],
        [-2.4424, -1.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225397765636444
Epoch 0, Step 2370: train/loss = 0.3608285188674927, train/raw-loss = 0.3344373106956482, train/logprobs = tensor([[-1.5347, -4.1287],
        [-2.5702, -1.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639119327068329
Epoch 0, Step 2371: train/loss = 0.5131102204322815, train/raw-loss = 0.4779738783836365, train/logprobs = tensor([[-1.6054, -2.4667],
        [-2.3892, -1.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513633906841278
Epoch 0, Step 2372: train/loss = 0.6552911996841431, train/raw-loss = 0.6231057643890381, train/logprobs = tensor([[-1.9221, -2.4533],
        [-2.1228, -2.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32185429334640503
Epoch 0, Step 2373: train/loss = 0.46784815192222595, train/raw-loss = 0.4425303041934967, train/logprobs = tensor([[-0.7747, -4.0456],
        [-2.2298, -1.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25317832827568054
Epoch 0, Step 2374: train/loss = 0.1252378225326538, train/raw-loss = 0.09567417204380035, train/logprobs = tensor([[-1.3898, -7.4732],
        [-4.0935, -1.3026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29563644528388977
Epoch 0, Step 2375: train/loss = 0.23015205562114716, train/raw-loss = 0.20149192214012146, train/logprobs = tensor([[-1.8651, -6.2803],
        [-3.0820, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866014838218689
Epoch 0, Step 2376: train/loss = 0.3994216322898865, train/raw-loss = 0.3721398115158081, train/logprobs = tensor([[-1.4246, -3.2740],
        [-2.2877, -1.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272817999124527
Epoch 0, Step 2377: train/loss = 0.3832576870918274, train/raw-loss = 0.35286933183670044, train/logprobs = tensor([[-1.2676, -3.3013],
        [-2.4626, -1.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30388370156288147
Epoch 0, Step 2378: train/loss = 0.21654167771339417, train/raw-loss = 0.18800869584083557, train/logprobs = tensor([[-1.8029, -5.7400],
        [-4.1973, -2.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2853296995162964
Epoch 0, Step 2379: train/loss = 0.44267725944519043, train/raw-loss = 0.4131832420825958, train/logprobs = tensor([[-2.5072, -7.6162],
        [-3.1065, -2.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29494011402130127
Epoch 0, Step 2380: train/loss = 0.5671435594558716, train/raw-loss = 0.5314444899559021, train/logprobs = tensor([[-1.8481, -3.9195],
        [-3.0567, -2.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3569910228252411
Epoch 0, Step 2381: train/loss = 0.41521772742271423, train/raw-loss = 0.3896026611328125, train/logprobs = tensor([[-0.9533, -3.8261],
        [-2.4750, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25615060329437256
Epoch 0, Step 2382: train/loss = 0.34982866048812866, train/raw-loss = 0.32826849818229675, train/logprobs = tensor([[-1.2039, -2.7545],
        [-2.1288, -0.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21560168266296387
Epoch 0, Step 2383: train/loss = 0.4659331142902374, train/raw-loss = 0.4359778165817261, train/logprobs = tensor([[-1.1336, -3.8663],
        [-2.3231, -1.5873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2995533347129822
Epoch 0, Step 2384: train/loss = 0.2790422737598419, train/raw-loss = 0.24490918219089508, train/logprobs = tensor([[-1.3321, -6.2274],
        [-3.4649, -1.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3413310647010803
Epoch 0, Step 2385: train/loss = 0.4280102849006653, train/raw-loss = 0.39445433020591736, train/logprobs = tensor([[-1.4349, -3.5588],
        [-2.3424, -1.4417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3355596363544464
Epoch 0, Step 2386: train/loss = 0.6858722567558289, train/raw-loss = 0.665952742099762, train/logprobs = tensor([[-2.8857, -7.5780],
        [-2.0246, -1.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19919496774673462
Epoch 0, Step 2387: train/loss = 0.45462894439697266, train/raw-loss = 0.4297460913658142, train/logprobs = tensor([[-1.4567, -3.7031],
        [-2.2969, -1.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24882817268371582
Epoch 0, Step 2388: train/loss = 0.5093680620193481, train/raw-loss = 0.4819190502166748, train/logprobs = tensor([[-2.7013, -6.2157],
        [-2.5465, -1.0465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2744900584220886
Epoch 0, Step 2389: train/loss = 0.3065918982028961, train/raw-loss = 0.27160966396331787, train/logprobs = tensor([[-1.2742, -6.4582],
        [-3.2717, -2.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34982240200042725
Epoch 0, Step 2390: train/loss = 0.5943459868431091, train/raw-loss = 0.5625191330909729, train/logprobs = tensor([[-1.2226, -1.5659],
        [-1.7222, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31826871633529663
Epoch 0, Step 2391: train/loss = 0.4845077395439148, train/raw-loss = 0.4511174261569977, train/logprobs = tensor([[-1.3091, -2.4510],
        [-2.9243, -1.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339027166366577
Epoch 0, Step 2392: train/loss = 0.8222419023513794, train/raw-loss = 0.7868331074714661, train/logprobs = tensor([[-2.3825, -3.1872],
        [-1.8430, -1.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354088693857193
Epoch 0, Step 2393: train/loss = 0.44751763343811035, train/raw-loss = 0.41772791743278503, train/logprobs = tensor([[-1.9093, -4.3403],
        [-3.0778, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978971600532532
Epoch 0, Step 2394: train/loss = 0.27837711572647095, train/raw-loss = 0.25088173151016235, train/logprobs = tensor([[-1.3611, -4.1759],
        [-2.3882, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749541103839874
Epoch 0, Step 2395: train/loss = 0.286702424287796, train/raw-loss = 0.26166245341300964, train/logprobs = tensor([[-1.2304, -3.6177],
        [-2.4064, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25039979815483093
Epoch 0, Step 2396: train/loss = 0.6914279460906982, train/raw-loss = 0.6692866683006287, train/logprobs = tensor([[-2.9223, -9.2477],
        [-2.1814, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22141219675540924
Epoch 0, Step 2397: train/loss = 0.40055227279663086, train/raw-loss = 0.37364885210990906, train/logprobs = tensor([[-1.4717, -4.6755],
        [-2.6952, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26903384923934937
Epoch 0, Step 2398: train/loss = 0.34725385904312134, train/raw-loss = 0.31913498044013977, train/logprobs = tensor([[-2.2303, -8.1749],
        [-2.4566, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811889946460724
Epoch 0, Step 2399: train/loss = 0.14211705327033997, train/raw-loss = 0.1118859127163887, train/logprobs = tensor([[-1.4611, -6.8791],
        [-3.0905, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30231136083602905
Epoch 0, Step 2400: train/loss = 0.5709705948829651, train/raw-loss = 0.5427052974700928, train/logprobs = tensor([[-1.2658, -1.5558],
        [-1.6801, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2826530933380127
Epoch 0, Step 2401: train/loss = 0.33803534507751465, train/raw-loss = 0.31079965829849243, train/logprobs = tensor([[-1.0978, -5.5779],
        [-2.4969, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27235642075538635
Epoch 0, Step 2402: train/loss = 0.6119790077209473, train/raw-loss = 0.5751452445983887, train/logprobs = tensor([[-1.6860, -2.5866],
        [-3.0563, -2.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36833786964416504
Epoch 0, Step 2403: train/loss = 0.37074267864227295, train/raw-loss = 0.3384924530982971, train/logprobs = tensor([[-2.1245, -4.4143],
        [-3.0158, -1.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32250240445137024
Epoch 0, Step 2404: train/loss = 0.3950299620628357, train/raw-loss = 0.3697074055671692, train/logprobs = tensor([[-1.1068, -2.7385],
        [-2.5684, -1.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25322550535202026
Epoch 0, Step 2405: train/loss = 0.2985244691371918, train/raw-loss = 0.2694196105003357, train/logprobs = tensor([[-1.2453, -6.1164],
        [-3.2258, -1.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29104864597320557
Epoch 0, Step 2406: train/loss = 0.381632924079895, train/raw-loss = 0.3519509434700012, train/logprobs = tensor([[-1.3444, -7.1979],
        [-1.7015, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29681986570358276
Epoch 0, Step 2407: train/loss = 0.4739915430545807, train/raw-loss = 0.4477294683456421, train/logprobs = tensor([[-0.7737, -2.0342],
        [-2.4422, -1.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262620747089386
Epoch 0, Step 2408: train/loss = 0.3777812719345093, train/raw-loss = 0.3505929708480835, train/logprobs = tensor([[-1.8175, -4.6339],
        [-2.5568, -2.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2718830406665802
Epoch 0, Step 2409: train/loss = 0.382270872592926, train/raw-loss = 0.3556087613105774, train/logprobs = tensor([[-2.3214, -2.8765],
        [-3.0577, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2666209936141968
Epoch 0, Step 2410: train/loss = 0.5082288980484009, train/raw-loss = 0.4812655746936798, train/logprobs = tensor([[-1.5139, -2.6266],
        [-2.5190, -1.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696332037448883
Epoch 0, Step 2411: train/loss = 0.2974548637866974, train/raw-loss = 0.2689986824989319, train/logprobs = tensor([[-2.5097, -7.3759],
        [-3.2635, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845616638660431
Epoch 0, Step 2412: train/loss = 0.2946566045284271, train/raw-loss = 0.2678242623806, train/logprobs = tensor([[-2.0377, -6.8027],
        [-2.7161, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26832324266433716
Epoch 0, Step 2413: train/loss = 0.4616212546825409, train/raw-loss = 0.44202494621276855, train/logprobs = tensor([[-1.4530, -4.3976],
        [-1.4476, -1.3311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19596336781978607
Epoch 0, Step 2414: train/loss = 0.3606048822402954, train/raw-loss = 0.33654913306236267, train/logprobs = tensor([[-1.9572, -2.7535],
        [-2.7180, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24055755138397217
Epoch 0, Step 2415: train/loss = 0.22354362905025482, train/raw-loss = 0.1958942413330078, train/logprobs = tensor([[-1.5396, -5.0824],
        [-3.3486, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2764941155910492
Epoch 0, Step 2416: train/loss = 0.28338754177093506, train/raw-loss = 0.2570542097091675, train/logprobs = tensor([[-1.2901, -9.5609],
        [-3.3610, -2.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26333341002464294
Epoch 0, Step 2417: train/loss = 0.3476022481918335, train/raw-loss = 0.3176719844341278, train/logprobs = tensor([[-1.6449, -2.5924],
        [-3.0090, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2993023097515106
Epoch 0, Step 2418: train/loss = 0.39921218156814575, train/raw-loss = 0.3703100085258484, train/logprobs = tensor([[-0.9947, -3.0528],
        [-2.3823, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890220284461975
Epoch 0, Step 2419: train/loss = 0.48478466272354126, train/raw-loss = 0.46214228868484497, train/logprobs = tensor([[-1.0801, -4.3742],
        [-1.8329, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22642356157302856
Epoch 0, Step 2420: train/loss = 0.3801508843898773, train/raw-loss = 0.35006383061408997, train/logprobs = tensor([[-1.9639, -4.4257],
        [-2.8347, -1.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30087053775787354
Epoch 0, Step 2421: train/loss = 0.3634195029735565, train/raw-loss = 0.32965803146362305, train/logprobs = tensor([[-1.9121, -5.9870],
        [-2.8859, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33761492371559143
Epoch 0, Step 2422: train/loss = 0.40496402978897095, train/raw-loss = 0.36957019567489624, train/logprobs = tensor([[-1.6353, -8.4041],
        [-2.7072, -1.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35393834114074707
Epoch 0, Step 2423: train/loss = 0.3130643367767334, train/raw-loss = 0.28392961621284485, train/logprobs = tensor([[-1.3899, -5.6936],
        [-2.1527, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29134711623191833
Epoch 0, Step 2424: train/loss = 0.20195454359054565, train/raw-loss = 0.16773180663585663, train/logprobs = tensor([[-1.7953, -5.1079],
        [-3.0532, -1.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34222716093063354
Epoch 0, Step 2425: train/loss = 0.5332908034324646, train/raw-loss = 0.5036574602127075, train/logprobs = tensor([[-1.7591, -5.0786],
        [-1.8817, -1.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2963329255580902
Epoch 0, Step 2426: train/loss = 0.33417823910713196, train/raw-loss = 0.3004721999168396, train/logprobs = tensor([[-2.2835, -9.5186],
        [-3.3214, -1.0195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3370603621006012
Epoch 0, Step 2427: train/loss = 0.32046326994895935, train/raw-loss = 0.30012136697769165, train/logprobs = tensor([[-1.6368, -7.5106],
        [-2.4340, -0.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20341913402080536
Epoch 0, Step 2428: train/loss = 0.6547659039497375, train/raw-loss = 0.620688796043396, train/logprobs = tensor([[-1.7548, -3.7055],
        [-3.0028, -2.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3407710790634155
Epoch 0, Step 2429: train/loss = 0.27340030670166016, train/raw-loss = 0.24536429345607758, train/logprobs = tensor([[-1.2581, -7.4727],
        [-2.2231, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28036025166511536
Epoch 0, Step 2430: train/loss = 0.17465727031230927, train/raw-loss = 0.14412268996238708, train/logprobs = tensor([[-1.2485, -5.0997],
        [-4.1168, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305345743894577
Epoch 0, Step 2431: train/loss = 0.15358386933803558, train/raw-loss = 0.11992065608501434, train/logprobs = tensor([[-1.5530, -9.7711],
        [-3.8034, -3.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3366321921348572
Epoch 0, Step 2432: train/loss = 0.6619622707366943, train/raw-loss = 0.6291521787643433, train/logprobs = tensor([[-1.8396, -2.5557],
        [-2.6954, -2.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32810041308403015
Epoch 0, Step 2433: train/loss = 0.25876379013061523, train/raw-loss = 0.23231355845928192, train/logprobs = tensor([[-1.8327, -4.7878],
        [-3.2833, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2645024359226227
Epoch 0, Step 2434: train/loss = 0.2603815197944641, train/raw-loss = 0.23325133323669434, train/logprobs = tensor([[-1.4577, -3.2967],
        [-2.9054, -1.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713019847869873
Epoch 0, Step 2435: train/loss = 0.36017724871635437, train/raw-loss = 0.3297940492630005, train/logprobs = tensor([[-0.8630, -2.6059],
        [-2.7977, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038320541381836
Epoch 0, Step 2436: train/loss = 0.4857028126716614, train/raw-loss = 0.4499054253101349, train/logprobs = tensor([[-1.1417, -2.7129],
        [-2.9363, -2.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.357973575592041
Epoch 0, Step 2437: train/loss = 0.4899902045726776, train/raw-loss = 0.45416924357414246, train/logprobs = tensor([[-1.4358, -3.7064],
        [-3.3091, -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358210027217865
Epoch 0, Step 2438: train/loss = 0.3305800259113312, train/raw-loss = 0.3072131276130676, train/logprobs = tensor([[-1.3844, -3.4290],
        [-2.7641, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23366907238960266
Epoch 0, Step 2439: train/loss = 0.11326181888580322, train/raw-loss = 0.08716310560703278, train/logprobs = tensor([[-1.1033, -5.4273],
        [-3.4334, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26098716259002686
Epoch 0, Step 2440: train/loss = 0.23515741527080536, train/raw-loss = 0.20728322863578796, train/logprobs = tensor([[-1.4184, -5.5027],
        [-2.8483, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787419259548187
Epoch 0, Step 2441: train/loss = 0.3778967559337616, train/raw-loss = 0.34525230526924133, train/logprobs = tensor([[-1.3689, -4.8646],
        [-4.4864, -2.1582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32644420862197876
Epoch 0, Step 2442: train/loss = 0.2869963049888611, train/raw-loss = 0.25661247968673706, train/logprobs = tensor([[-2.2152, -7.7877],
        [-3.8921, -1.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30383801460266113
Epoch 0, Step 2443: train/loss = 0.3843597173690796, train/raw-loss = 0.36248987913131714, train/logprobs = tensor([[-1.8161, -5.6471],
        [-1.9261, -1.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21869824826717377
Epoch 0, Step 2444: train/loss = 0.506594717502594, train/raw-loss = 0.475344717502594, train/logprobs = tensor([[-1.9798, -4.2594],
        [-3.5149, -2.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125
Epoch 0, Step 2445: train/loss = 0.30918359756469727, train/raw-loss = 0.27441465854644775, train/logprobs = tensor([[-1.6329, -4.3644],
        [-3.6195, -1.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3476894497871399
Epoch 0, Step 2446: train/loss = 0.4494132399559021, train/raw-loss = 0.4169682264328003, train/logprobs = tensor([[-2.0850, -4.2216],
        [-3.0167, -1.4127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32444971799850464
Epoch 0, Step 2447: train/loss = 0.13478079438209534, train/raw-loss = 0.10690167546272278, train/logprobs = tensor([[-1.5763, -6.7405],
        [-3.6905, -1.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787911891937256
Epoch 0, Step 2448: train/loss = 0.1646035760641098, train/raw-loss = 0.12955079972743988, train/logprobs = tensor([[-2.0479, -7.1858],
        [-4.6570, -1.6236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35052767395973206
Epoch 0, Step 2449: train/loss = 0.4946575164794922, train/raw-loss = 0.4612831771373749, train/logprobs = tensor([[-1.5147, -8.2007],
        [-2.7390, -2.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33374321460723877
Epoch 0, Step 2450: train/loss = 0.6707248091697693, train/raw-loss = 0.6392775774002075, train/logprobs = tensor([[-1.7306, -1.8439],
        [-2.3097, -1.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31447261571884155
Epoch 0, Step 2451: train/loss = 0.44557392597198486, train/raw-loss = 0.41080331802368164, train/logprobs = tensor([[-2.4099, -7.1557],
        [-3.7709, -3.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477053642272949
Epoch 0, Step 2452: train/loss = 0.34336066246032715, train/raw-loss = 0.31931352615356445, train/logprobs = tensor([[-1.3131, -6.9453],
        [-2.7896, -1.3500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24047154188156128
Epoch 0, Step 2453: train/loss = 0.29018187522888184, train/raw-loss = 0.2588335871696472, train/logprobs = tensor([[-1.4231, -5.9193],
        [-2.6600, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31348276138305664
Epoch 0, Step 2454: train/loss = 0.20630811154842377, train/raw-loss = 0.17394663393497467, train/logprobs = tensor([[-2.3273, -7.8223],
        [-3.1522, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236147463321686
Epoch 0, Step 2455: train/loss = 0.48934128880500793, train/raw-loss = 0.46146029233932495, train/logprobs = tensor([[-1.1026, -1.9693],
        [-2.1722, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27880987524986267
Epoch 0, Step 2456: train/loss = 0.40894874930381775, train/raw-loss = 0.38077080249786377, train/logprobs = tensor([[-0.9674, -4.6214],
        [-1.9360, -1.4684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28177952766418457
Epoch 0, Step 2457: train/loss = 0.6046725511550903, train/raw-loss = 0.5639922618865967, train/logprobs = tensor([[-1.3120, -3.3405],
        [-3.3549, -2.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4068026840686798
Epoch 0, Step 2458: train/loss = 0.3466488718986511, train/raw-loss = 0.321933776140213, train/logprobs = tensor([[-2.0870, -2.5846],
        [-4.3260, -1.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24715110659599304
Epoch 0, Step 2459: train/loss = 0.5432190895080566, train/raw-loss = 0.515022873878479, train/logprobs = tensor([[-1.3788, -3.7426],
        [-1.7041, -0.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819620370864868
Epoch 0, Step 2460: train/loss = 0.4432147443294525, train/raw-loss = 0.40923449397087097, train/logprobs = tensor([[-1.2942, -3.2282],
        [-2.6555, -1.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33980223536491394
Epoch 0, Step 2461: train/loss = 0.29987281560897827, train/raw-loss = 0.2713391184806824, train/logprobs = tensor([[-1.5241, -4.8920],
        [-2.8332, -2.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28533709049224854
Epoch 0, Step 2462: train/loss = 0.5006971955299377, train/raw-loss = 0.47326281666755676, train/logprobs = tensor([[-2.6054, -5.1300],
        [-2.9002, -1.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743438184261322
Epoch 0, Step 2463: train/loss = 0.36315351724624634, train/raw-loss = 0.3360787034034729, train/logprobs = tensor([[-1.8537, -4.7644],
        [-2.8951, -2.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707481384277344
Epoch 0, Step 2464: train/loss = 0.22109776735305786, train/raw-loss = 0.188232421875, train/logprobs = tensor([[-1.5358, -4.9597],
        [-4.3663, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3286535143852234
Epoch 0, Step 2465: train/loss = 0.38881343603134155, train/raw-loss = 0.3598877191543579, train/logprobs = tensor([[-1.7834, -3.9161],
        [-2.7227, -1.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892570495605469
Epoch 0, Step 2466: train/loss = 0.3230694532394409, train/raw-loss = 0.29431700706481934, train/logprobs = tensor([[-1.5844, -7.1256],
        [-2.6420, -2.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28752419352531433
Epoch 0, Step 2467: train/loss = 0.33737412095069885, train/raw-loss = 0.308904767036438, train/logprobs = tensor([[-1.8998, -5.9143],
        [-2.6996, -0.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846941351890564
Epoch 0, Step 2468: train/loss = 0.4698088765144348, train/raw-loss = 0.44162213802337646, train/logprobs = tensor([[-1.1051, -2.0156],
        [-1.9981, -1.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2818671762943268
Epoch 0, Step 2469: train/loss = 0.48483628034591675, train/raw-loss = 0.4586333930492401, train/logprobs = tensor([[-1.4850, -3.7204],
        [-1.9639, -1.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26202914118766785
Epoch 0, Step 2470: train/loss = 0.3043208718299866, train/raw-loss = 0.2750462293624878, train/logprobs = tensor([[-1.6644, -5.5191],
        [-2.8783, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29274678230285645
Epoch 0, Step 2471: train/loss = 0.7231770753860474, train/raw-loss = 0.6912798285484314, train/logprobs = tensor([[-2.1236, -3.0152],
        [-1.9665, -1.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3189723491668701
Epoch 0, Step 2472: train/loss = 0.19225361943244934, train/raw-loss = 0.15978668630123138, train/logprobs = tensor([[-2.2328, -5.9749],
        [-4.3107, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32466942071914673
Epoch 0, Step 2473: train/loss = 0.5004507303237915, train/raw-loss = 0.46377044916152954, train/logprobs = tensor([[-1.7172, -4.3310],
        [-3.8226, -2.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36680328845977783
Epoch 0, Step 2474: train/loss = 0.0963517278432846, train/raw-loss = 0.06515926867723465, train/logprobs = tensor([[ -1.1048, -10.6696],
        [ -3.4891,  -1.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119244873523712
Epoch 0, Step 2475: train/loss = 0.3587786853313446, train/raw-loss = 0.3332505226135254, train/logprobs = tensor([[-1.6767, -3.4408],
        [-2.5473, -1.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25528138875961304
Epoch 0, Step 2476: train/loss = 0.44871586561203003, train/raw-loss = 0.4197675585746765, train/logprobs = tensor([[-1.5380, -5.5302],
        [-2.7745, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894834280014038
Epoch 0, Step 2477: train/loss = 0.46671199798583984, train/raw-loss = 0.44126418232917786, train/logprobs = tensor([[-1.8763, -9.4475],
        [-2.9229, -1.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254478394985199
Epoch 0, Step 2478: train/loss = 0.27642500400543213, train/raw-loss = 0.25408661365509033, train/logprobs = tensor([[-1.5239, -4.4316],
        [-2.4012, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22338411211967468
Epoch 0, Step 2479: train/loss = 0.3994666039943695, train/raw-loss = 0.3629416823387146, train/logprobs = tensor([[-2.0758, -3.2262],
        [-4.0834, -1.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3652491271495819
Epoch 0, Step 2480: train/loss = 0.43910232186317444, train/raw-loss = 0.4088740944862366, train/logprobs = tensor([[-1.2266, -2.2575],
        [-2.3959, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022822439670563
Epoch 0, Step 2481: train/loss = 0.286416232585907, train/raw-loss = 0.2500970959663391, train/logprobs = tensor([[-2.0695, -8.0114],
        [-3.8876, -2.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36319151520729065
Epoch 0, Step 2482: train/loss = 0.20291364192962646, train/raw-loss = 0.1826564222574234, train/logprobs = tensor([[-0.9265, -6.6011],
        [-1.7305, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2025723159313202
Epoch 0, Step 2483: train/loss = 0.646443247795105, train/raw-loss = 0.613741934299469, train/logprobs = tensor([[-2.0424, -3.0440],
        [-2.5766, -2.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3270135521888733
Epoch 0, Step 2484: train/loss = 0.23515217006206512, train/raw-loss = 0.21197918057441711, train/logprobs = tensor([[-1.3863, -6.1478],
        [-2.1306, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23172976076602936
Epoch 0, Step 2485: train/loss = 0.1831781417131424, train/raw-loss = 0.15403464436531067, train/logprobs = tensor([[-1.6416, -7.3234],
        [-3.7197, -1.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914348840713501
Epoch 0, Step 2486: train/loss = 0.3211754858493805, train/raw-loss = 0.2873879671096802, train/logprobs = tensor([[-1.6629, -4.4507],
        [-2.4750, -1.3756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378754258155823
Epoch 0, Step 2487: train/loss = 0.37860962748527527, train/raw-loss = 0.3528381884098053, train/logprobs = tensor([[-1.9498, -4.0869],
        [-2.3996, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25771450996398926
Epoch 0, Step 2488: train/loss = 0.2627900242805481, train/raw-loss = 0.23688478767871857, train/logprobs = tensor([[-1.2005, -6.5450],
        [-2.4302, -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25905248522758484
Epoch 0, Step 2489: train/loss = 0.21473070979118347, train/raw-loss = 0.18501105904579163, train/logprobs = tensor([[-1.9037, -4.5436],
        [-4.3119, -0.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29719650745391846
Epoch 0, Step 2490: train/loss = 0.6823276281356812, train/raw-loss = 0.652678370475769, train/logprobs = tensor([[-2.1345, -3.1218],
        [-1.9586, -2.2927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29649317264556885
Epoch 0, Step 2491: train/loss = 0.3106692135334015, train/raw-loss = 0.2747109830379486, train/logprobs = tensor([[-1.4941, -7.3882],
        [-1.9941, -2.2216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35958248376846313
Epoch 0, Step 2492: train/loss = 0.13207010924816132, train/raw-loss = 0.1060856282711029, train/logprobs = tensor([[-1.9306, -5.7961],
        [-4.3116, -1.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598448395729065
Epoch 0, Step 2493: train/loss = 0.3621308505535126, train/raw-loss = 0.32641884684562683, train/logprobs = tensor([[-2.1211, -7.6148],
        [-3.9383, -2.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35712018609046936
Epoch 0, Step 2494: train/loss = 0.3520570993423462, train/raw-loss = 0.3231881260871887, train/logprobs = tensor([[-1.2853, -3.7996],
        [-2.3570, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886897325515747
Epoch 0, Step 2495: train/loss = 0.3845064640045166, train/raw-loss = 0.35934340953826904, train/logprobs = tensor([[-2.8597, -6.2472],
        [-3.3866, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516305446624756
Epoch 0, Step 2496: train/loss = 0.21612471342086792, train/raw-loss = 0.18033641576766968, train/logprobs = tensor([[-1.9291, -7.6961],
        [-4.4176, -1.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578830063343048
Epoch 0, Step 2497: train/loss = 0.19888094067573547, train/raw-loss = 0.16743236780166626, train/logprobs = tensor([[-1.2468, -4.8586],
        [-3.1807, -1.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31448543071746826
Epoch 0, Step 2498: train/loss = 0.16231662034988403, train/raw-loss = 0.13346239924430847, train/logprobs = tensor([[-1.5408, -5.8179],
        [-3.1902, -0.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28854215145111084
Epoch 0, Step 2499: train/loss = 0.11101293563842773, train/raw-loss = 0.08424320071935654, train/logprobs = tensor([[-2.3097, -8.7007],
        [-4.4625, -2.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267697274684906
Epoch 0, Step 2500: train/loss = 0.3435642719268799, train/raw-loss = 0.31430432200431824, train/logprobs = tensor([[-1.9529, -6.7193],
        [-3.0540, -1.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925994098186493
Epoch 0, Step 2501: train/loss = 0.6089901924133301, train/raw-loss = 0.581066906452179, train/logprobs = tensor([[-1.2921, -2.2513],
        [-3.3084, -2.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27923309803009033
Epoch 0, Step 2502: train/loss = 0.2647559642791748, train/raw-loss = 0.23390217125415802, train/logprobs = tensor([[-2.2918, -8.5261],
        [-3.1530, -2.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3085377812385559
Epoch 0, Step 2503: train/loss = 0.4115186929702759, train/raw-loss = 0.3804626166820526, train/logprobs = tensor([[-1.3245, -7.7895],
        [-4.0359, -2.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3105606436729431
Epoch 0, Step 2504: train/loss = 0.43764030933380127, train/raw-loss = 0.40409842133522034, train/logprobs = tensor([[-1.5299, -4.4827],
        [-2.3569, -1.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33541905879974365
Epoch 0, Step 2505: train/loss = 0.6369991898536682, train/raw-loss = 0.6061479449272156, train/logprobs = tensor([[-0.8761, -4.8002],
        [-2.5908, -2.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30851244926452637
Epoch 0, Step 2506: train/loss = 0.14007587730884552, train/raw-loss = 0.11017630994319916, train/logprobs = tensor([[-0.9277, -9.3904],
        [-2.9429, -1.2608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.298995703458786
Epoch 0, Step 2507: train/loss = 0.315751850605011, train/raw-loss = 0.2861611247062683, train/logprobs = tensor([[-1.4299, -4.4406],
        [-3.9995, -2.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.295907199382782
Epoch 0, Step 2508: train/loss = 0.2842521071434021, train/raw-loss = 0.24762330949306488, train/logprobs = tensor([[-1.9069, -5.7969],
        [-3.6249, -1.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36628803610801697
Epoch 0, Step 2509: train/loss = 0.13877785205841064, train/raw-loss = 0.1064305454492569, train/logprobs = tensor([[-1.7834, -8.7744],
        [-3.5539, -2.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3234730362892151
Epoch 0, Step 2510: train/loss = 0.5740328431129456, train/raw-loss = 0.546032190322876, train/logprobs = tensor([[-1.5243, -2.1091],
        [-1.6353, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800061106681824
Epoch 0, Step 2511: train/loss = 0.37987956404685974, train/raw-loss = 0.3572371006011963, train/logprobs = tensor([[-0.9682, -3.6979],
        [-2.8869, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22642448544502258
Epoch 0, Step 2512: train/loss = 0.2531783878803253, train/raw-loss = 0.22234225273132324, train/logprobs = tensor([[-1.5618, -3.6928],
        [-2.9782, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3083614408969879
Epoch 0, Step 2513: train/loss = 0.5560342073440552, train/raw-loss = 0.5230939388275146, train/logprobs = tensor([[-1.6469, -2.5923],
        [-2.8697, -1.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32940298318862915
Epoch 0, Step 2514: train/loss = 0.2864137589931488, train/raw-loss = 0.24645733833312988, train/logprobs = tensor([[-2.1924, -4.6706],
        [-4.3931, -2.7997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.399564266204834
Epoch 0, Step 2515: train/loss = 0.4818175733089447, train/raw-loss = 0.45078426599502563, train/logprobs = tensor([[-1.5724, -4.3888],
        [-4.4118, -1.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31033286452293396
Epoch 0, Step 2516: train/loss = 0.508358895778656, train/raw-loss = 0.47930067777633667, train/logprobs = tensor([[-2.0410, -4.7266],
        [-2.2517, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2905827760696411
Epoch 0, Step 2517: train/loss = 0.3432280421257019, train/raw-loss = 0.31005239486694336, train/logprobs = tensor([[-1.7648, -4.5069],
        [-2.6618, -1.1104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3317562937736511
Epoch 0, Step 2518: train/loss = 0.41527503728866577, train/raw-loss = 0.38239768147468567, train/logprobs = tensor([[-1.0646, -4.6066],
        [-3.3540, -1.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287734389305115
Epoch 0, Step 2519: train/loss = 0.42883047461509705, train/raw-loss = 0.39575421810150146, train/logprobs = tensor([[-1.6356, -6.5808],
        [-3.4358, -2.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3307626247406006
Epoch 0, Step 2520: train/loss = 0.6264568567276001, train/raw-loss = 0.5901269912719727, train/logprobs = tensor([[-2.0348, -2.5919],
        [-2.1232, -1.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36329901218414307
Epoch 0, Step 2521: train/loss = 0.2568357586860657, train/raw-loss = 0.22555632889270782, train/logprobs = tensor([[-1.8730, -4.5361],
        [-4.1402, -1.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31279417872428894
Epoch 0, Step 2522: train/loss = 0.5173066854476929, train/raw-loss = 0.4802134335041046, train/logprobs = tensor([[-1.8190, -4.3100],
        [-4.0436, -2.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37093260884284973
Epoch 0, Step 2523: train/loss = 0.3888837695121765, train/raw-loss = 0.3655439615249634, train/logprobs = tensor([[-1.6026, -8.2526],
        [-1.9212, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23339830338954926
Epoch 0, Step 2524: train/loss = 0.5302873253822327, train/raw-loss = 0.5021698474884033, train/logprobs = tensor([[-1.7294, -4.4406],
        [-2.2686, -1.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28117436170578003
Epoch 0, Step 2525: train/loss = 0.34356367588043213, train/raw-loss = 0.3152412176132202, train/logprobs = tensor([[-1.9576, -6.1871],
        [-3.7274, -1.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28322434425354004
Epoch 0, Step 2526: train/loss = 0.34169068932533264, train/raw-loss = 0.3120984733104706, train/logprobs = tensor([[-1.7844, -6.7649],
        [-2.9994, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29592207074165344
Epoch 0, Step 2527: train/loss = 0.4215090572834015, train/raw-loss = 0.3898855447769165, train/logprobs = tensor([[-1.8909, -4.6600],
        [-3.8385, -1.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3162350356578827
Epoch 0, Step 2528: train/loss = 0.2756079435348511, train/raw-loss = 0.24114921689033508, train/logprobs = tensor([[-1.5325, -7.8651],
        [-3.3198, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3445873260498047
Epoch 0, Step 2529: train/loss = 0.43884605169296265, train/raw-loss = 0.40667062997817993, train/logprobs = tensor([[-1.0755, -4.3931],
        [-2.7298, -2.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32175442576408386
Epoch 0, Step 2530: train/loss = 0.2138904333114624, train/raw-loss = 0.17846378684043884, train/logprobs = tensor([[-1.6711, -6.3321],
        [-4.2940, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35426634550094604
Epoch 0, Step 2531: train/loss = 0.35911884903907776, train/raw-loss = 0.3272518813610077, train/logprobs = tensor([[-1.9962, -4.5651],
        [-2.6144, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186699151992798
Epoch 0, Step 2532: train/loss = 0.10098879784345627, train/raw-loss = 0.06943850219249725, train/logprobs = tensor([[ -1.7147, -13.3469],
        [ -4.7319,  -1.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31550294160842896
Epoch 0, Step 2533: train/loss = 0.62074875831604, train/raw-loss = 0.5856614112854004, train/logprobs = tensor([[-1.3068, -3.4408],
        [-2.8067, -2.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350873738527298
Epoch 0, Step 2534: train/loss = 0.3262954652309418, train/raw-loss = 0.2874225080013275, train/logprobs = tensor([[-2.1543, -6.2770],
        [-3.9388, -1.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38872966170310974
Epoch 0, Step 2535: train/loss = 0.4424503445625305, train/raw-loss = 0.41734766960144043, train/logprobs = tensor([[-2.0781, -5.0539],
        [-2.2856, -1.1785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510262727737427
Epoch 0, Step 2536: train/loss = 0.11998619139194489, train/raw-loss = 0.09208545088768005, train/logprobs = tensor([[-2.0645, -6.9006],
        [-3.9790, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27900734543800354
Epoch 0, Step 2537: train/loss = 0.22265851497650146, train/raw-loss = 0.19205065071582794, train/logprobs = tensor([[-1.3738, -4.7438],
        [-3.0295, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30607861280441284
Epoch 0, Step 2538: train/loss = 0.33973753452301025, train/raw-loss = 0.3087348937988281, train/logprobs = tensor([[-2.0269, -9.6168],
        [-2.8292, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100264370441437
Epoch 0, Step 2539: train/loss = 0.882361888885498, train/raw-loss = 0.8578593730926514, train/logprobs = tensor([[-3.1710, -4.6233],
        [-1.9109, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2450248897075653
Epoch 0, Step 2540: train/loss = 0.30608296394348145, train/raw-loss = 0.2758578658103943, train/logprobs = tensor([[-1.0692, -4.8914],
        [-2.0475, -1.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30225110054016113
Epoch 0, Step 2541: train/loss = 0.09965404868125916, train/raw-loss = 0.06985823065042496, train/logprobs = tensor([[-1.9575, -6.2995],
        [-4.3229, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297958105802536
Epoch 0, Step 2542: train/loss = 0.49788618087768555, train/raw-loss = 0.4664436876773834, train/logprobs = tensor([[-1.8150, -3.9043],
        [-3.8699, -2.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3144247531890869
Epoch 0, Step 2543: train/loss = 0.3363175690174103, train/raw-loss = 0.30417120456695557, train/logprobs = tensor([[-2.0770, -6.7818],
        [-3.1056, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3214636445045471
Epoch 0, Step 2544: train/loss = 0.3186158537864685, train/raw-loss = 0.27962782979011536, train/logprobs = tensor([[-3.0231, -3.7958],
        [-4.2935, -2.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38988015055656433
Epoch 0, Step 2545: train/loss = 0.3513525426387787, train/raw-loss = 0.31820735335350037, train/logprobs = tensor([[-1.4720, -5.7991],
        [-3.0290, -1.2702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314517140388489
Epoch 0, Step 2546: train/loss = 0.40922749042510986, train/raw-loss = 0.37519311904907227, train/logprobs = tensor([[-2.1781, -8.3393],
        [-2.7692, -2.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403436541557312
Epoch 0, Step 2547: train/loss = 0.6939489245414734, train/raw-loss = 0.6570552587509155, train/logprobs = tensor([[-1.6883, -4.9531],
        [-3.1753, -2.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3689367473125458
Epoch 0, Step 2548: train/loss = 0.45473670959472656, train/raw-loss = 0.4163348078727722, train/logprobs = tensor([[-1.6796, -3.1176],
        [-3.1970, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38401907682418823
Epoch 0, Step 2549: train/loss = 0.5204897522926331, train/raw-loss = 0.4852471947669983, train/logprobs = tensor([[-1.5905, -2.2697],
        [-2.3719, -1.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3524259328842163
Epoch 0, Step 2550: train/loss = 0.5787768363952637, train/raw-loss = 0.5470703840255737, train/logprobs = tensor([[-2.6874, -8.2191],
        [-2.6647, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3170645833015442
Epoch 0, Step 2551: train/loss = 0.452501118183136, train/raw-loss = 0.42384880781173706, train/logprobs = tensor([[-1.4429, -2.2288],
        [-2.7722, -1.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28652307391166687
Epoch 0, Step 2552: train/loss = 0.4156613349914551, train/raw-loss = 0.38656070828437805, train/logprobs = tensor([[ -2.3476, -10.8931],
        [ -3.2577,  -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29100650548934937
Epoch 0, Step 2553: train/loss = 0.21124163269996643, train/raw-loss = 0.1697205901145935, train/logprobs = tensor([[-2.2593, -8.4376],
        [-4.4255, -2.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.415210485458374
Epoch 0, Step 2554: train/loss = 0.42920777201652527, train/raw-loss = 0.3964233994483948, train/logprobs = tensor([[-2.8532, -4.3156],
        [-3.7813, -1.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32784372568130493
Epoch 0, Step 2555: train/loss = 0.16081227362155914, train/raw-loss = 0.12524493038654327, train/logprobs = tensor([[-1.8339, -5.0832],
        [-5.0321, -1.9149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556734621524811
Epoch 0, Step 2556: train/loss = 0.4069427251815796, train/raw-loss = 0.36897921562194824, train/logprobs = tensor([[-3.3239, -5.8107],
        [-4.4887, -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3796353042125702
Epoch 0, Step 2557: train/loss = 0.5169823169708252, train/raw-loss = 0.49164772033691406, train/logprobs = tensor([[-1.4969, -4.8608],
        [-1.8692, -1.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533460259437561
Epoch 0, Step 2558: train/loss = 0.25611260533332825, train/raw-loss = 0.22662025690078735, train/logprobs = tensor([[-1.1238, -4.5421],
        [-2.9583, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29492348432540894
Epoch 0, Step 2559: train/loss = 0.19057489931583405, train/raw-loss = 0.15386317670345306, train/logprobs = tensor([[ -1.3696, -10.0640],
        [ -3.7796,  -2.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36711710691452026
Epoch 0, Step 2560: train/loss = 0.4333774447441101, train/raw-loss = 0.393265962600708, train/logprobs = tensor([[-2.0712, -5.8361],
        [-2.9996, -1.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4011145830154419
Epoch 0, Step 2561: train/loss = 0.5155007839202881, train/raw-loss = 0.48290014266967773, train/logprobs = tensor([[-1.9681, -4.9694],
        [-2.2204, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3260062634944916
Epoch 0, Step 2562: train/loss = 0.2113771140575409, train/raw-loss = 0.1779348999261856, train/logprobs = tensor([[-2.8526, -6.9269],
        [-3.9686, -1.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33442223072052
Epoch 0, Step 2563: train/loss = 0.12995530664920807, train/raw-loss = 0.08871696144342422, train/logprobs = tensor([[-1.6727, -6.1871],
        [-5.6429, -1.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41238337755203247
Epoch 0, Step 2564: train/loss = 0.3161914646625519, train/raw-loss = 0.2863285541534424, train/logprobs = tensor([[-2.5886, -6.8673],
        [-3.3838, -2.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29862916469573975
Epoch 0, Step 2565: train/loss = 0.487801730632782, train/raw-loss = 0.45277243852615356, train/logprobs = tensor([[-2.6413, -6.2629],
        [-3.7285, -2.6247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502925634384155
Epoch 0, Step 2566: train/loss = 0.5831100344657898, train/raw-loss = 0.5509373545646667, train/logprobs = tensor([[-1.6797, -2.2250],
        [-2.3536, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32172727584838867
Epoch 0, Step 2567: train/loss = 0.3299849033355713, train/raw-loss = 0.2971065938472748, train/logprobs = tensor([[-1.4604, -4.2556],
        [-3.1080, -1.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287830352783203
Epoch 0, Step 2568: train/loss = 0.7076734900474548, train/raw-loss = 0.6740323305130005, train/logprobs = tensor([[-1.3464, -3.0527],
        [-3.2147, -2.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33641159534454346
Epoch 0, Step 2569: train/loss = 0.3559531569480896, train/raw-loss = 0.31813812255859375, train/logprobs = tensor([[-1.9201, -5.0495],
        [-3.4912, -1.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37815046310424805
Epoch 0, Step 2570: train/loss = 0.7497587203979492, train/raw-loss = 0.7197304964065552, train/logprobs = tensor([[-1.6050, -1.7891],
        [-1.9713, -1.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002825975418091
Epoch 0, Step 2571: train/loss = 0.31604933738708496, train/raw-loss = 0.2856016159057617, train/logprobs = tensor([[-1.4614, -3.4419],
        [-3.5321, -2.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304476797580719
Epoch 0, Step 2572: train/loss = 0.32380908727645874, train/raw-loss = 0.2924850583076477, train/logprobs = tensor([[-2.5380, -6.1681],
        [-4.0544, -2.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313240110874176
Epoch 0, Step 2573: train/loss = 0.5047633051872253, train/raw-loss = 0.4778510630130768, train/logprobs = tensor([[-3.0186, -7.4031],
        [-2.5211, -2.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691223621368408
Epoch 0, Step 2574: train/loss = 0.16334334015846252, train/raw-loss = 0.13241994380950928, train/logprobs = tensor([[-1.5999, -8.6123],
        [-3.2735, -1.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30923399329185486
Epoch 0, Step 2575: train/loss = 0.4471774101257324, train/raw-loss = 0.41243815422058105, train/logprobs = tensor([[-1.3121, -4.0615],
        [-5.3098, -2.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473924994468689
Epoch 0, Step 2576: train/loss = 0.26224377751350403, train/raw-loss = 0.22618111968040466, train/logprobs = tensor([[-1.8566, -5.2543],
        [-4.4706, -2.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606266975402832
Epoch 0, Step 2577: train/loss = 0.5659672021865845, train/raw-loss = 0.5308293104171753, train/logprobs = tensor([[-1.2239, -2.2992],
        [-2.8396, -2.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513789176940918
Epoch 0, Step 2578: train/loss = 0.28294771909713745, train/raw-loss = 0.2583933174610138, train/logprobs = tensor([[-1.6214, -4.6960],
        [-3.8101, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2455439418554306
Epoch 0, Step 2579: train/loss = 0.35880953073501587, train/raw-loss = 0.3306920528411865, train/logprobs = tensor([[-2.0073, -6.5036],
        [-3.6165, -2.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811751067638397
Epoch 0, Step 2580: train/loss = 0.14929169416427612, train/raw-loss = 0.11126908659934998, train/logprobs = tensor([[-2.5129, -8.3005],
        [-4.2368, -1.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3802260160446167
Epoch 0, Step 2581: train/loss = 0.48007169365882874, train/raw-loss = 0.45021605491638184, train/logprobs = tensor([[-2.7473, -4.2309],
        [-4.0128, -2.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985564172267914
Epoch 0, Step 2582: train/loss = 0.1684114933013916, train/raw-loss = 0.13911789655685425, train/logprobs = tensor([[-1.6422, -9.4629],
        [-4.2598, -2.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929359972476959
Epoch 0, Step 2583: train/loss = 0.1564854383468628, train/raw-loss = 0.12131660431623459, train/logprobs = tensor([[-1.6380, -6.5962],
        [-4.6568, -1.3384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35168835520744324
Epoch 0, Step 2584: train/loss = 0.24531415104866028, train/raw-loss = 0.20639443397521973, train/logprobs = tensor([[-2.3701, -4.8361],
        [-5.5695, -2.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891969919204712
Epoch 0, Step 2585: train/loss = 0.5114225149154663, train/raw-loss = 0.4768138527870178, train/logprobs = tensor([[-1.9264, -5.4403],
        [-4.3413, -3.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3460862636566162
Epoch 0, Step 2586: train/loss = 0.38480401039123535, train/raw-loss = 0.35342657566070557, train/logprobs = tensor([[-1.2570, -4.5594],
        [-2.6986, -1.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313774049282074
Epoch 0, Step 2587: train/loss = 0.47022855281829834, train/raw-loss = 0.44295191764831543, train/logprobs = tensor([[-0.8647, -3.2283],
        [-1.7803, -1.5806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27276650071144104
Epoch 0, Step 2588: train/loss = 0.31342029571533203, train/raw-loss = 0.28296715021133423, train/logprobs = tensor([[-2.1879, -4.7980],
        [-3.6435, -2.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3045314848423004
Epoch 0, Step 2589: train/loss = 0.2757917642593384, train/raw-loss = 0.2447803020477295, train/logprobs = tensor([[-2.1466, -7.3591],
        [-3.8970, -2.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31011444330215454
Epoch 0, Step 2590: train/loss = 0.41128474473953247, train/raw-loss = 0.37940558791160583, train/logprobs = tensor([[-3.2355, -6.2959],
        [-4.1469, -2.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31879132986068726
Epoch 0, Step 2591: train/loss = 0.2300594449043274, train/raw-loss = 0.19474564492702484, train/logprobs = tensor([[-1.9210, -8.5511],
        [-4.0939, -2.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35313788056373596
Epoch 0, Step 2592: train/loss = 0.2509167492389679, train/raw-loss = 0.2177347093820572, train/logprobs = tensor([[-1.3704, -6.6835],
        [-3.8195, -1.8862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3318204879760742
Epoch 0, Step 2593: train/loss = 0.3197976350784302, train/raw-loss = 0.2762216627597809, train/logprobs = tensor([[-1.4692, -5.3841],
        [-4.1653, -2.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4357597827911377
Epoch 0, Step 2594: train/loss = 0.14627839624881744, train/raw-loss = 0.11212238669395447, train/logprobs = tensor([[-2.1581, -7.5400],
        [-4.7604, -2.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341560035943985
Epoch 0, Step 2595: train/loss = 0.5149173140525818, train/raw-loss = 0.4888859689235687, train/logprobs = tensor([[-1.3028, -2.3343],
        [-3.4045, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26031365990638733
Epoch 0, Step 2596: train/loss = 0.35841232538223267, train/raw-loss = 0.32795560359954834, train/logprobs = tensor([[-1.4909, -8.7431],
        [-2.8924, -1.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30456724762916565
Epoch 0, Step 2597: train/loss = 0.08987780660390854, train/raw-loss = 0.0602400004863739, train/logprobs = tensor([[-1.2482, -7.2341],
        [-4.1521, -1.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2963780164718628
Epoch 0, Step 2598: train/loss = 0.34483882784843445, train/raw-loss = 0.31480351090431213, train/logprobs = tensor([[-1.7919, -3.5691],
        [-4.9941, -2.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30035293102264404
Epoch 0, Step 2599: train/loss = 0.316220223903656, train/raw-loss = 0.2850062847137451, train/logprobs = tensor([[-2.3421, -4.5215],
        [-3.8309, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121393322944641
Epoch 0, Step 2600: train/loss = 0.18589989840984344, train/raw-loss = 0.14854489266872406, train/logprobs = tensor([[-1.4810, -4.9163],
        [-4.1205, -1.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37355005741119385
Epoch 0, Step 2601: train/loss = 0.4054471552371979, train/raw-loss = 0.3706638216972351, train/logprobs = tensor([[-1.4902, -6.3573],
        [-3.2622, -1.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34783339500427246
Epoch 0, Step 2602: train/loss = 0.35908591747283936, train/raw-loss = 0.32259055972099304, train/logprobs = tensor([[-1.4553, -6.6268],
        [-4.5532, -2.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3649536371231079
Epoch 0, Step 2603: train/loss = 0.2481965571641922, train/raw-loss = 0.21513856947422028, train/logprobs = tensor([[-2.5305, -6.9332],
        [-4.4077, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330579936504364
Epoch 0, Step 2604: train/loss = 0.35463961958885193, train/raw-loss = 0.3229735195636749, train/logprobs = tensor([[-2.0660, -6.1138],
        [-3.9857, -1.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31666120886802673
Epoch 0, Step 2605: train/loss = 0.32380449771881104, train/raw-loss = 0.2922132611274719, train/logprobs = tensor([[-2.2037, -5.0890],
        [-3.8314, -1.3644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31591254472732544
Epoch 0, Step 2606: train/loss = 0.32466021180152893, train/raw-loss = 0.2999442517757416, train/logprobs = tensor([[-1.3517, -1.8860],
        [-3.2719, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24715955555438995
Epoch 0, Step 2607: train/loss = 0.3699576258659363, train/raw-loss = 0.32968470454216003, train/logprobs = tensor([[-1.5199, -5.8472],
        [-3.2063, -2.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40272894501686096
Epoch 0, Step 2608: train/loss = 0.18521584570407867, train/raw-loss = 0.15239287912845612, train/logprobs = tensor([[-2.2401, -7.0812],
        [-5.5398, -1.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3282295763492584
Epoch 0, Step 2609: train/loss = 0.3716212213039398, train/raw-loss = 0.334177166223526, train/logprobs = tensor([[-2.2236, -3.4109],
        [-3.8963, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3744403123855591
Epoch 0, Step 2610: train/loss = 0.4121907353401184, train/raw-loss = 0.3732934296131134, train/logprobs = tensor([[-2.0969, -6.9290],
        [-4.0467, -2.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3889731764793396
Epoch 0, Step 2611: train/loss = 0.2494065761566162, train/raw-loss = 0.2162105143070221, train/logprobs = tensor([[-2.5774, -7.9050],
        [-4.0093, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319607079029083
Epoch 0, Step 2612: train/loss = 0.595649003982544, train/raw-loss = 0.567634642124176, train/logprobs = tensor([[-1.7792, -2.5845],
        [-2.3682, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28014302253723145
Epoch 0, Step 2613: train/loss = 0.16591733694076538, train/raw-loss = 0.13104523718357086, train/logprobs = tensor([[-1.3421, -6.5676],
        [-3.6543, -1.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34872105717658997
Epoch 0, Step 2614: train/loss = 0.21011444926261902, train/raw-loss = 0.18002349138259888, train/logprobs = tensor([[-2.3539, -7.7929],
        [-3.4233, -1.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3009095788002014
Epoch 0, Step 2615: train/loss = 0.11938539892435074, train/raw-loss = 0.07984220236539841, train/logprobs = tensor([[-1.6021, -6.2099],
        [-4.9731, -1.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39543184638023376
Epoch 0, Step 2616: train/loss = 0.28362879157066345, train/raw-loss = 0.24984131753444672, train/logprobs = tensor([[-1.5635, -9.4684],
        [-5.1951, -1.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33787500858306885
Epoch 0, Step 2617: train/loss = 0.6699106097221375, train/raw-loss = 0.6306944489479065, train/logprobs = tensor([[-1.6979, -2.8304],
        [-4.4475, -3.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3921615481376648
Epoch 0, Step 2618: train/loss = 0.22728222608566284, train/raw-loss = 0.19738586246967316, train/logprobs = tensor([[-2.0935, -7.9631],
        [-4.1404, -1.4351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989636957645416
Epoch 0, Step 2619: train/loss = 0.6912285089492798, train/raw-loss = 0.658825695514679, train/logprobs = tensor([[-2.2532, -2.3016],
        [-3.2026, -2.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32402822375297546
Epoch 0, Step 2620: train/loss = 0.22981148958206177, train/raw-loss = 0.20348194241523743, train/logprobs = tensor([[-1.9151, -5.6577],
        [-2.8059, -2.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632952928543091
Epoch 0, Step 2621: train/loss = 0.5333260297775269, train/raw-loss = 0.4895082712173462, train/logprobs = tensor([[-2.1794, -5.0783],
        [-4.6917, -2.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43817752599716187
Epoch 0, Step 2622: train/loss = 0.49802619218826294, train/raw-loss = 0.47803229093551636, train/logprobs = tensor([[-1.3216, -2.7510],
        [-2.2050, -1.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19993892312049866
