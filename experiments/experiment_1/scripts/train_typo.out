{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}

{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-11 18:26:21,552][root][INFO] - beta: 3.0
[2024-03-11 18:26:21,553][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/helpful-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-3.0.json
n helpful: 2000
n harmless: 1806
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
data/sweep/helpful-iteration-0-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-0-lr-1e-6-beta-3.0.json
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0.
3806
tokenized 3806 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-0.
Epoch 0, Step 0: train/loss = 0.626151442527771, train/raw-loss = 0.626151442527771, train/logprobs = tensor([[-0.5320, -1.6266],
        [-0.6046, -1.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6514006853103638, train/raw-loss = 0.6514006853103638, train/logprobs = tensor([[-0.5028, -0.8636],
        [-0.5280, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6812334656715393, train/raw-loss = 0.6812334656715393, train/logprobs = tensor([[-0.4953, -0.8415],
        [-0.5338, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.5803045034408569, train/raw-loss = 0.5803045034408569, train/logprobs = tensor([[-0.5518, -2.2224],
        [-0.6612, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.62431401014328, train/raw-loss = 0.62431401014328, train/logprobs = tensor([[-0.5353, -0.9661],
        [-0.8186, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6697949171066284, train/raw-loss = 0.6697949171066284, train/logprobs = tensor([[-0.4912, -0.8927],
        [-0.5894, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6718199849128723, train/raw-loss = 0.6718199849128723, train/logprobs = tensor([[-0.5810, -0.5317],
        [-0.6328, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6043583750724792, train/raw-loss = 0.6043583750724792, train/logprobs = tensor([[-0.5441, -1.7520],
        [-0.6556, -1.4345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.5578873157501221, train/raw-loss = 0.5578873157501221, train/logprobs = tensor([[-0.5600, -2.3311],
        [-0.6450, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.643979549407959, train/raw-loss = 0.643979549407959, train/logprobs = tensor([[-0.5995, -0.9546],
        [-0.7227, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6829110980033875, train/raw-loss = 0.6829110980033875, train/logprobs = tensor([[-0.7218, -0.9243],
        [-0.7852, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6631162762641907, train/raw-loss = 0.6631162762641907, train/logprobs = tensor([[-0.6360, -0.8920],
        [-0.7353, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.4811258316040039, train/raw-loss = 0.4811258316040039, train/logprobs = tensor([[-0.6975, -2.5671],
        [-0.9054, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6171160340309143, train/raw-loss = 0.6171160340309143, train/logprobs = tensor([[-0.5521, -1.5341],
        [-0.6184, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6337964534759521, train/raw-loss = 0.6337964534759521, train/logprobs = tensor([[-0.6179, -1.0619],
        [-0.7509, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5917654037475586, train/raw-loss = 0.5917654037475586, train/logprobs = tensor([[-0.5814, -1.9856],
        [-0.6661, -1.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6909119486808777, train/raw-loss = 0.6909119486808777, train/logprobs = tensor([[-0.3845, -0.5524],
        [-0.4099, -0.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6690844893455505, train/raw-loss = 0.6690844893455505, train/logprobs = tensor([[-0.5130, -0.8290],
        [-0.5865, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6579471826553345, train/raw-loss = 0.6579471826553345, train/logprobs = tensor([[-0.4248, -1.0882],
        [-0.4624, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.621723473072052, train/raw-loss = 0.621723473072052, train/logprobs = tensor([[-0.5470, -1.4921],
        [-0.5885, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6308507919311523, train/raw-loss = 0.6308507919311523, train/logprobs = tensor([[-0.7176, -1.0544],
        [-0.8334, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6855326890945435, train/raw-loss = 0.6855326890945435, train/logprobs = tensor([[-0.4429, -0.8201],
        [-0.4723, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6773326396942139, train/raw-loss = 0.6773326396942139, train/logprobs = tensor([[-0.5269, -0.9090],
        [-0.6215, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6563409566879272, train/raw-loss = 0.6563409566879272, train/logprobs = tensor([[-0.5952, -0.8222],
        [-0.6744, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6427162885665894, train/raw-loss = 0.6427162885665894, train/logprobs = tensor([[-0.5477, -0.9513],
        [-0.6836, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6363422274589539, train/raw-loss = 0.6363422274589539, train/logprobs = tensor([[-0.5544, -0.9791],
        [-0.6497, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6998584270477295, train/raw-loss = 0.6998584270477295, train/logprobs = tensor([[-0.4371, -1.0226],
        [-0.4547, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6754298210144043, train/raw-loss = 0.6754298210144043, train/logprobs = tensor([[-0.4159, -0.7634],
        [-0.4320, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6019802093505859, train/raw-loss = 0.6019802093505859, train/logprobs = tensor([[-0.5539, -2.2298],
        [-0.6093, -1.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6605981588363647, train/raw-loss = 0.6605981588363647, train/logprobs = tensor([[-0.5695, -1.0004],
        [-0.6638, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6742237210273743, train/raw-loss = 0.6742237210273743, train/logprobs = tensor([[-0.6284, -0.7568],
        [-0.7241, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6580765247344971, train/raw-loss = 0.6580765247344971, train/logprobs = tensor([[-0.5002, -0.9803],
        [-0.5394, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6737897992134094, train/raw-loss = 0.6737897992134094, train/logprobs = tensor([[-0.5673, -1.0554],
        [-0.6395, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6480326652526855, train/raw-loss = 0.6480326652526855, train/logprobs = tensor([[-0.4636, -1.0161],
        [-0.5075, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6344242691993713, train/raw-loss = 0.6344242691993713, train/logprobs = tensor([[-0.6384, -0.9516],
        [-0.7570, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6920045018196106, train/raw-loss = 0.6920045018196106, train/logprobs = tensor([[-0.5652, -0.6577],
        [-0.5419, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6684216260910034, train/raw-loss = 0.6684216260910034, train/logprobs = tensor([[-0.5399, -0.5232],
        [-0.5776, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.5884003639221191, train/raw-loss = 0.5884003639221191, train/logprobs = tensor([[-0.5314, -1.9258],
        [-0.6220, -1.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6804813146591187, train/raw-loss = 0.6804813146591187, train/logprobs = tensor([[-0.5509, -0.5015],
        [-0.6153, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6681503653526306, train/raw-loss = 0.6681503653526306, train/logprobs = tensor([[-0.6695, -1.2182],
        [-0.7883, -1.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6451807618141174, train/raw-loss = 0.6451807618141174, train/logprobs = tensor([[-0.6167, -0.9360],
        [-0.6884, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6203322410583496, train/raw-loss = 0.6203322410583496, train/logprobs = tensor([[-0.5369, -1.5162],
        [-0.6257, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6210395693778992, train/raw-loss = 0.6210395693778992, train/logprobs = tensor([[-0.6576, -1.6781],
        [-0.7412, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6688458919525146, train/raw-loss = 0.6688458919525146, train/logprobs = tensor([[-0.5880, -0.6682],
        [-0.6841, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5931517481803894, train/raw-loss = 0.5931517481803894, train/logprobs = tensor([[-0.4521, -2.4428],
        [-0.5037, -1.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.5665391683578491, train/raw-loss = 0.5665391683578491, train/logprobs = tensor([[-0.5752, -2.2205],
        [-0.6844, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.678109884262085, train/raw-loss = 0.678109884262085, train/logprobs = tensor([[-0.8871, -0.7659],
        [-0.8938, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6390549540519714, train/raw-loss = 0.6390549540519714, train/logprobs = tensor([[-0.3988, -1.4025],
        [-0.4546, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.566025972366333, train/raw-loss = 0.566025972366333, train/logprobs = tensor([[-0.5117, -1.8578],
        [-0.5724, -1.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.5964142084121704, train/raw-loss = 0.5964142084121704, train/logprobs = tensor([[-0.5670, -1.9596],
        [-0.7400, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6416305303573608, train/raw-loss = 0.6416305303573608, train/logprobs = tensor([[-0.5193, -0.8578],
        [-0.6190, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6820334792137146, train/raw-loss = 0.6820334792137146, train/logprobs = tensor([[-0.4964, -0.9851],
        [-0.5220, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6325727701187134, train/raw-loss = 0.6325727701187134, train/logprobs = tensor([[-0.5603, -0.6316],
        [-0.7162, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6647505760192871, train/raw-loss = 0.6647505760192871, train/logprobs = tensor([[-0.6781, -1.3000],
        [-0.8537, -1.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6824195384979248, train/raw-loss = 0.6824195384979248, train/logprobs = tensor([[-0.4394, -0.8593],
        [-0.4947, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.666618287563324, train/raw-loss = 0.666618287563324, train/logprobs = tensor([[-0.5334, -0.7254],
        [-0.6013, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6506434679031372, train/raw-loss = 0.6506434679031372, train/logprobs = tensor([[-0.5674, -0.8702],
        [-0.6368, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6688615083694458, train/raw-loss = 0.6688615083694458, train/logprobs = tensor([[-0.4378, -0.9733],
        [-0.4775, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.622824490070343, train/raw-loss = 0.622824490070343, train/logprobs = tensor([[-0.5166, -1.3426],
        [-0.5917, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6586250066757202, train/raw-loss = 0.6586250066757202, train/logprobs = tensor([[-0.6401, -0.8999],
        [-0.7881, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6660503149032593, train/raw-loss = 0.6660503149032593, train/logprobs = tensor([[-0.3980, -0.7761],
        [-0.4592, -0.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6290931701660156, train/raw-loss = 0.6290931701660156, train/logprobs = tensor([[-0.5893, -1.2191],
        [-0.7058, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6267271637916565, train/raw-loss = 0.6267271637916565, train/logprobs = tensor([[-0.5463, -1.1152],
        [-0.6325, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6604589819908142, train/raw-loss = 0.6604589819908142, train/logprobs = tensor([[-0.6231, -0.6365],
        [-0.7292, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.7110318541526794, train/raw-loss = 0.6800627708435059, train/logprobs = tensor([[-0.5233, -0.5305],
        [-0.5326, -0.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01032303273677826
Epoch 0, Step 65: train/loss = 0.6574929356575012, train/raw-loss = 0.6311585903167725, train/logprobs = tensor([[-0.6064, -1.0974],
        [-0.6125, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008778104558587074
Epoch 0, Step 66: train/loss = 0.5757361054420471, train/raw-loss = 0.5583166480064392, train/logprobs = tensor([[-0.5609, -1.8179],
        [-0.6197, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005806482397019863
Epoch 0, Step 67: train/loss = 0.6626477241516113, train/raw-loss = 0.6419579982757568, train/logprobs = tensor([[-0.5258, -0.9789],
        [-0.5539, -0.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006896602921187878
Epoch 0, Step 68: train/loss = 0.649722158908844, train/raw-loss = 0.6346821784973145, train/logprobs = tensor([[-0.5336, -0.8669],
        [-0.5484, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005013325251638889
Epoch 0, Step 69: train/loss = 0.678464412689209, train/raw-loss = 0.6546218395233154, train/logprobs = tensor([[-0.6491, -0.9426],
        [-0.6978, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007947513833642006
Epoch 0, Step 70: train/loss = 0.626885175704956, train/raw-loss = 0.6028339862823486, train/logprobs = tensor([[-0.5508, -1.1935],
        [-0.5518, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008017072454094887
Epoch 0, Step 71: train/loss = 0.6661605834960938, train/raw-loss = 0.6374726295471191, train/logprobs = tensor([[-0.6801, -0.9424],
        [-0.7438, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009562656283378601
Epoch 0, Step 72: train/loss = 0.6024878025054932, train/raw-loss = 0.5794126391410828, train/logprobs = tensor([[-0.6100, -2.4297],
        [-0.6477, -1.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0076917135156691074
Epoch 0, Step 73: train/loss = 0.5160166025161743, train/raw-loss = 0.4904126524925232, train/logprobs = tensor([[-0.5758, -2.5635],
        [-0.8048, -1.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008534655906260014
Epoch 0, Step 74: train/loss = 0.6557018756866455, train/raw-loss = 0.6356936097145081, train/logprobs = tensor([[-0.5543, -0.7773],
        [-0.6117, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006669407710433006
Epoch 0, Step 75: train/loss = 0.6425806879997253, train/raw-loss = 0.6136256456375122, train/logprobs = tensor([[-0.6072, -1.1083],
        [-0.7037, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009651696309447289
Epoch 0, Step 76: train/loss = 0.635007381439209, train/raw-loss = 0.6181272864341736, train/logprobs = tensor([[-0.4639, -1.1628],
        [-0.4890, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005626685451716185
Epoch 0, Step 77: train/loss = 0.6046153903007507, train/raw-loss = 0.5855298638343811, train/logprobs = tensor([[-0.5275, -1.6591],
        [-0.5864, -1.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00636184960603714
Epoch 0, Step 78: train/loss = 0.6665066480636597, train/raw-loss = 0.6382544040679932, train/logprobs = tensor([[-0.5065, -1.3565],
        [-0.5540, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009417426772415638
Epoch 0, Step 79: train/loss = 0.7165806889533997, train/raw-loss = 0.6922347545623779, train/logprobs = tensor([[-0.4507, -0.4412],
        [-0.4562, -0.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008115301840007305
Epoch 0, Step 80: train/loss = 0.6017584204673767, train/raw-loss = 0.582927405834198, train/logprobs = tensor([[-0.5229, -1.1590],
        [-0.5575, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006277010310441256
Epoch 0, Step 81: train/loss = 0.6343128681182861, train/raw-loss = 0.6152956485748291, train/logprobs = tensor([[-0.5139, -1.0488],
        [-0.6210, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006339075975120068
Epoch 0, Step 82: train/loss = 0.6193898320198059, train/raw-loss = 0.5975033044815063, train/logprobs = tensor([[-0.5507, -1.4772],
        [-0.5571, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007295522373169661
Epoch 0, Step 83: train/loss = 0.6036520600318909, train/raw-loss = 0.5812263488769531, train/logprobs = tensor([[-0.4538, -1.8449],
        [-0.5105, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007475221995264292
Epoch 0, Step 84: train/loss = 0.5777297019958496, train/raw-loss = 0.5543230772018433, train/logprobs = tensor([[-0.4869, -2.5271],
        [-0.5348, -1.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007802196312695742
Epoch 0, Step 85: train/loss = 0.6843744516372681, train/raw-loss = 0.6588877439498901, train/logprobs = tensor([[-0.6274, -0.7842],
        [-0.6175, -0.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008495569229125977
Epoch 0, Step 86: train/loss = 0.5819429755210876, train/raw-loss = 0.5672699809074402, train/logprobs = tensor([[-0.4615, -1.7620],
        [-0.5152, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004890989977866411
Epoch 0, Step 87: train/loss = 0.604536771774292, train/raw-loss = 0.5834903120994568, train/logprobs = tensor([[-0.8823, -1.2539],
        [-1.1155, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007015489973127842
Epoch 0, Step 88: train/loss = 0.6504135131835938, train/raw-loss = 0.6233641505241394, train/logprobs = tensor([[-0.6733, -1.1119],
        [-0.7140, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009016474708914757
Epoch 0, Step 89: train/loss = 0.6462708711624146, train/raw-loss = 0.625259280204773, train/logprobs = tensor([[-0.4719, -1.1443],
        [-0.4650, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007003873586654663
Epoch 0, Step 90: train/loss = 0.6472773551940918, train/raw-loss = 0.6261333227157593, train/logprobs = tensor([[-0.4664, -1.0006],
        [-0.4780, -0.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007047994993627071
Epoch 0, Step 91: train/loss = 0.6149460673332214, train/raw-loss = 0.5946846604347229, train/logprobs = tensor([[-0.4928, -1.3614],
        [-0.5373, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006753811612725258
Epoch 0, Step 92: train/loss = 0.657824695110321, train/raw-loss = 0.6295430064201355, train/logprobs = tensor([[-0.5624, -1.0634],
        [-0.6649, -0.8999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009427240118384361
Epoch 0, Step 93: train/loss = 0.6340069770812988, train/raw-loss = 0.6149962544441223, train/logprobs = tensor([[-0.6286, -1.0187],
        [-0.7157, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006336910650134087
Epoch 0, Step 94: train/loss = 0.667773425579071, train/raw-loss = 0.6435310244560242, train/logprobs = tensor([[-0.5263, -1.2880],
        [-0.5658, -1.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008080813102424145
Epoch 0, Step 95: train/loss = 0.6683406829833984, train/raw-loss = 0.6484586000442505, train/logprobs = tensor([[-0.4685, -1.4872],
        [-0.4826, -1.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006627341732382774
Epoch 0, Step 96: train/loss = 0.7826266884803772, train/raw-loss = 0.6622186303138733, train/logprobs = tensor([[-0.5179, -0.6182],
        [-0.5486, -0.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04013600945472717
Epoch 0, Step 97: train/loss = 0.7156482934951782, train/raw-loss = 0.5649669766426086, train/logprobs = tensor([[-0.5020, -1.7325],
        [-0.5476, -1.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050227127969264984
Epoch 0, Step 98: train/loss = 0.7389266490936279, train/raw-loss = 0.6126006841659546, train/logprobs = tensor([[-0.8147, -1.1506],
        [-0.9458, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04210865870118141
Epoch 0, Step 99: train/loss = 0.7884588241577148, train/raw-loss = 0.6274846792221069, train/logprobs = tensor([[-0.6298, -0.9691],
        [-0.6375, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05365804582834244
Epoch 0, Step 100: train/loss = 0.7321329116821289, train/raw-loss = 0.6348503828048706, train/logprobs = tensor([[-0.4956, -1.0100],
        [-0.5140, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03242753446102142
Epoch 0, Step 101: train/loss = 0.7439650297164917, train/raw-loss = 0.6124564409255981, train/logprobs = tensor([[-0.3984, -1.2017],
        [-0.3793, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04383617267012596
Epoch 0, Step 102: train/loss = 0.7805773019790649, train/raw-loss = 0.6015989780426025, train/logprobs = tensor([[-0.6594, -1.4141],
        [-0.6645, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0596594512462616
Epoch 0, Step 103: train/loss = 0.7798997163772583, train/raw-loss = 0.6829233169555664, train/logprobs = tensor([[-0.5841, -0.6542],
        [-0.5636, -0.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03232545778155327
Epoch 0, Step 104: train/loss = 0.7199286222457886, train/raw-loss = 0.604744553565979, train/logprobs = tensor([[-0.6443, -0.9415],
        [-0.7372, -0.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03839466720819473
Epoch 0, Step 105: train/loss = 0.7076810598373413, train/raw-loss = 0.601412832736969, train/logprobs = tensor([[-0.6643, -1.4589],
        [-0.6277, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03542275354266167
Epoch 0, Step 106: train/loss = 0.7697780132293701, train/raw-loss = 0.6128696799278259, train/logprobs = tensor([[-0.4191, -1.3131],
        [-0.4097, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05230279266834259
Epoch 0, Step 107: train/loss = 0.7171906232833862, train/raw-loss = 0.5718866586685181, train/logprobs = tensor([[-0.5908, -1.4322],
        [-0.6639, -0.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04843465983867645
Epoch 0, Step 108: train/loss = 0.7792809009552002, train/raw-loss = 0.587282121181488, train/logprobs = tensor([[-0.5285, -1.6356],
        [-0.5232, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06399957835674286
Epoch 0, Step 109: train/loss = 0.7325598001480103, train/raw-loss = 0.5849661827087402, train/logprobs = tensor([[-0.6390, -1.3318],
        [-0.7109, -0.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04919789731502533
Epoch 0, Step 110: train/loss = 0.8043798208236694, train/raw-loss = 0.6472432613372803, train/logprobs = tensor([[-0.5670, -1.0208],
        [-0.5979, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05237883701920509
Epoch 0, Step 111: train/loss = 0.7781431674957275, train/raw-loss = 0.6669695377349854, train/logprobs = tensor([[-0.5140, -0.6186],
        [-0.5129, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03705785796046257
Epoch 0, Step 112: train/loss = 0.7506709098815918, train/raw-loss = 0.611538290977478, train/logprobs = tensor([[-0.5321, -1.4998],
        [-0.5394, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0463775172829628
Epoch 0, Step 113: train/loss = 0.8002100586891174, train/raw-loss = 0.6237045526504517, train/logprobs = tensor([[-0.6438, -1.1365],
        [-0.6959, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05883517861366272
Epoch 0, Step 114: train/loss = 0.795376181602478, train/raw-loss = 0.6116040945053101, train/logprobs = tensor([[-0.4844, -1.1812],
        [-0.4757, -0.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06125735491514206
Epoch 0, Step 115: train/loss = 0.6875703930854797, train/raw-loss = 0.5252504348754883, train/logprobs = tensor([[-0.6248, -1.5499],
        [-0.7634, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054106637835502625
Epoch 0, Step 116: train/loss = 0.798965573310852, train/raw-loss = 0.669675350189209, train/logprobs = tensor([[-0.7199, -1.1782],
        [-0.6452, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04309672489762306
Epoch 0, Step 117: train/loss = 0.7462227940559387, train/raw-loss = 0.6312350034713745, train/logprobs = tensor([[-0.5024, -0.8879],
        [-0.5610, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03832924738526344
Epoch 0, Step 118: train/loss = 0.754704475402832, train/raw-loss = 0.5987391471862793, train/logprobs = tensor([[-0.5441, -1.1665],
        [-0.5433, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05198846012353897
Epoch 0, Step 119: train/loss = 0.7593368291854858, train/raw-loss = 0.5842932462692261, train/logprobs = tensor([[-0.5016, -1.3064],
        [-0.5400, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05834786221385002
Epoch 0, Step 120: train/loss = 0.7553583383560181, train/raw-loss = 0.6173087954521179, train/logprobs = tensor([[-0.5261, -0.8698],
        [-0.5744, -0.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046016499400138855
Epoch 0, Step 121: train/loss = 0.7666593790054321, train/raw-loss = 0.599319577217102, train/logprobs = tensor([[-0.5071, -1.1364],
        [-0.5471, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05577995255589485
Epoch 0, Step 122: train/loss = 0.7641226053237915, train/raw-loss = 0.645165205001831, train/logprobs = tensor([[-0.4764, -0.7394],
        [-0.4944, -0.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03965247422456741
Epoch 0, Step 123: train/loss = 0.6844472885131836, train/raw-loss = 0.5394428372383118, train/logprobs = tensor([[-0.5166, -1.8928],
        [-0.5393, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048334814608097076
Epoch 0, Step 124: train/loss = 0.7706514000892639, train/raw-loss = 0.6577410697937012, train/logprobs = tensor([[-0.5771, -0.5773],
        [-0.5842, -0.4370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03763677924871445
Epoch 0, Step 125: train/loss = 0.787009596824646, train/raw-loss = 0.5859892964363098, train/logprobs = tensor([[-0.4926, -1.2552],
        [-0.4952, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06700676679611206
Epoch 0, Step 126: train/loss = 0.7516379356384277, train/raw-loss = 0.6307637691497803, train/logprobs = tensor([[-0.4155, -1.2331],
        [-0.4185, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04029139131307602
Epoch 0, Step 127: train/loss = 0.7136747241020203, train/raw-loss = 0.5493077039718628, train/logprobs = tensor([[-0.6644, -2.1204],
        [-0.6580, -1.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05478903278708458
Epoch 0, Step 128: train/loss = 0.639541506767273, train/raw-loss = 0.47322922945022583, train/logprobs = tensor([[-0.5303, -2.9306],
        [-0.6586, -1.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05543741583824158
Epoch 0, Step 129: train/loss = 0.6337670087814331, train/raw-loss = 0.4952496886253357, train/logprobs = tensor([[-0.5784, -3.1495],
        [-0.6597, -1.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046172432601451874
Epoch 0, Step 130: train/loss = 0.7697264552116394, train/raw-loss = 0.6223664879798889, train/logprobs = tensor([[-0.5141, -1.0443],
        [-0.4787, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049120012670755386
Epoch 0, Step 131: train/loss = 0.7295060157775879, train/raw-loss = 0.6019567251205444, train/logprobs = tensor([[-0.4638, -0.9664],
        [-0.5270, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042516425251960754
Epoch 0, Step 132: train/loss = 0.7999993562698364, train/raw-loss = 0.6277002096176147, train/logprobs = tensor([[-0.6062, -0.9759],
        [-0.5630, -0.6380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057433050125837326
Epoch 0, Step 133: train/loss = 0.7307569980621338, train/raw-loss = 0.5919424295425415, train/logprobs = tensor([[-0.5964, -1.5675],
        [-0.5454, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046271536499261856
Epoch 0, Step 134: train/loss = 0.6403697729110718, train/raw-loss = 0.46840739250183105, train/logprobs = tensor([[-0.8500, -3.0841],
        [-0.8925, -1.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05732078477740288
Epoch 0, Step 135: train/loss = 0.5890577435493469, train/raw-loss = 0.4223152697086334, train/logprobs = tensor([[-0.5444, -3.2083],
        [-0.6532, -1.4060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05558082461357117
Epoch 0, Step 136: train/loss = 0.708534836769104, train/raw-loss = 0.5720800757408142, train/logprobs = tensor([[-0.4811, -1.4440],
        [-0.4782, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04548491910099983
Epoch 0, Step 137: train/loss = 0.7739916443824768, train/raw-loss = 0.6356585025787354, train/logprobs = tensor([[-0.4597, -0.8417],
        [-0.5250, -0.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046111054718494415
Epoch 0, Step 138: train/loss = 0.6061038970947266, train/raw-loss = 0.44529375433921814, train/logprobs = tensor([[-0.5904, -3.5088],
        [-0.6238, -1.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0536033920943737
Epoch 0, Step 139: train/loss = 0.7472055554389954, train/raw-loss = 0.6355714797973633, train/logprobs = tensor([[-0.4820, -0.9278],
        [-0.5315, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0372113473713398
Epoch 0, Step 140: train/loss = 0.7024025917053223, train/raw-loss = 0.5608500242233276, train/logprobs = tensor([[-0.5786, -1.5439],
        [-0.6736, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04718419536948204
Epoch 0, Step 141: train/loss = 0.7313975095748901, train/raw-loss = 0.5983237624168396, train/logprobs = tensor([[-0.5017, -0.9223],
        [-0.5564, -0.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044357918202877045
Epoch 0, Step 142: train/loss = 0.7400087118148804, train/raw-loss = 0.5780034065246582, train/logprobs = tensor([[-0.7112, -1.4992],
        [-0.7766, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05400177091360092
Epoch 0, Step 143: train/loss = 0.7103055715560913, train/raw-loss = 0.5720946788787842, train/logprobs = tensor([[-0.6123, -1.7729],
        [-0.6694, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046070292592048645
Epoch 0, Step 144: train/loss = 0.6824718713760376, train/raw-loss = 0.5043587684631348, train/logprobs = tensor([[-0.5793, -2.0736],
        [-0.6221, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05937104672193527
Epoch 0, Step 145: train/loss = 0.7529445290565491, train/raw-loss = 0.6168220043182373, train/logprobs = tensor([[-0.4114, -1.0337],
        [-0.4071, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04537418857216835
Epoch 0, Step 146: train/loss = 0.5716971158981323, train/raw-loss = 0.42273133993148804, train/logprobs = tensor([[-0.8206, -4.1317],
        [-0.9114, -2.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0496552437543869
Epoch 0, Step 147: train/loss = 0.7350063920021057, train/raw-loss = 0.5987325310707092, train/logprobs = tensor([[-0.4813, -0.9212],
        [-0.5427, -0.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04542461037635803
Epoch 0, Step 148: train/loss = 0.7193077206611633, train/raw-loss = 0.5636584758758545, train/logprobs = tensor([[-0.5264, -1.3379],
        [-0.5291, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05188307538628578
Epoch 0, Step 149: train/loss = 0.699063777923584, train/raw-loss = 0.5690754055976868, train/logprobs = tensor([[-0.5738, -1.7527],
        [-0.6170, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04332946240901947
Epoch 0, Step 150: train/loss = 0.6595334410667419, train/raw-loss = 0.5108755826950073, train/logprobs = tensor([[-0.6744, -1.6870],
        [-0.8078, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04955262690782547
Epoch 0, Step 151: train/loss = 0.7444311380386353, train/raw-loss = 0.5662783980369568, train/logprobs = tensor([[-0.5085, -1.6667],
        [-0.4749, -1.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059384241700172424
Epoch 0, Step 152: train/loss = 0.588010847568512, train/raw-loss = 0.4555087089538574, train/logprobs = tensor([[-0.6271, -3.2243],
        [-0.7421, -1.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04416738077998161
Epoch 0, Step 153: train/loss = 0.719658613204956, train/raw-loss = 0.5427225828170776, train/logprobs = tensor([[-0.4369, -1.5173],
        [-0.4777, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05897866189479828
Epoch 0, Step 154: train/loss = 0.6265031695365906, train/raw-loss = 0.48515552282333374, train/logprobs = tensor([[-0.5923, -2.4683],
        [-0.6852, -1.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04711588844656944
Epoch 0, Step 155: train/loss = 0.6652997136116028, train/raw-loss = 0.5083574056625366, train/logprobs = tensor([[-0.8756, -2.6034],
        [-1.0440, -1.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05231409892439842
Epoch 0, Step 156: train/loss = 0.7350367307662964, train/raw-loss = 0.5600149035453796, train/logprobs = tensor([[-0.5347, -1.7883],
        [-0.5518, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05834060162305832
Epoch 0, Step 157: train/loss = 0.7574945688247681, train/raw-loss = 0.6205003261566162, train/logprobs = tensor([[-0.4756, -0.9939],
        [-0.5133, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045664746314287186
Epoch 0, Step 158: train/loss = 0.7224817276000977, train/raw-loss = 0.5357429385185242, train/logprobs = tensor([[-0.4881, -1.8344],
        [-0.5101, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06224627047777176
Epoch 0, Step 159: train/loss = 0.797575831413269, train/raw-loss = 0.657861053943634, train/logprobs = tensor([[-0.4470, -0.6500],
        [-0.4399, -0.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657160863280296
Epoch 0, Step 160: train/loss = 0.7765237092971802, train/raw-loss = 0.5814341902732849, train/logprobs = tensor([[-0.6786, -1.7793],
        [-0.5894, -1.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06502985209226608
Epoch 0, Step 161: train/loss = 0.6616839170455933, train/raw-loss = 0.48757070302963257, train/logprobs = tensor([[-0.6471, -2.5996],
        [-0.7477, -1.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05803775414824486
Epoch 0, Step 162: train/loss = 0.7299138903617859, train/raw-loss = 0.5509561896324158, train/logprobs = tensor([[-0.6236, -1.4062],
        [-0.7387, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05965256690979004
Epoch 0, Step 163: train/loss = 0.7158595323562622, train/raw-loss = 0.5519261360168457, train/logprobs = tensor([[-0.6268, -1.3911],
        [-0.6575, -0.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05464445799589157
Epoch 0, Step 164: train/loss = 0.7080667018890381, train/raw-loss = 0.5410641431808472, train/logprobs = tensor([[-0.6398, -2.8517],
        [-0.6976, -1.4880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055667489767074585
Epoch 0, Step 165: train/loss = 0.7751359939575195, train/raw-loss = 0.6133621335029602, train/logprobs = tensor([[-0.5501, -0.9876],
        [-0.5868, -0.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05392461270093918
Epoch 0, Step 166: train/loss = 0.7270172834396362, train/raw-loss = 0.5534667372703552, train/logprobs = tensor([[-0.6006, -1.5000],
        [-0.6758, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0578501895070076
Epoch 0, Step 167: train/loss = 0.6879309415817261, train/raw-loss = 0.5139791369438171, train/logprobs = tensor([[-0.5121, -1.8316],
        [-0.5341, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05798391252756119
Epoch 0, Step 168: train/loss = 0.7494857311248779, train/raw-loss = 0.5760809183120728, train/logprobs = tensor([[-0.5973, -1.7670],
        [-0.5869, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057801589369773865
Epoch 0, Step 169: train/loss = 0.7193297147750854, train/raw-loss = 0.5430346727371216, train/logprobs = tensor([[-0.5755, -2.1459],
        [-0.6598, -1.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05876501649618149
Epoch 0, Step 170: train/loss = 0.7255669832229614, train/raw-loss = 0.5508871078491211, train/logprobs = tensor([[-0.5422, -1.6340],
        [-0.6238, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05822661891579628
Epoch 0, Step 171: train/loss = 0.7479952573776245, train/raw-loss = 0.5620995759963989, train/logprobs = tensor([[-0.6179, -1.3266],
        [-0.6601, -0.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061965212225914
Epoch 0, Step 172: train/loss = 0.6863970756530762, train/raw-loss = 0.5089455246925354, train/logprobs = tensor([[-0.7846, -1.6821],
        [-0.9196, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05915053188800812
Epoch 0, Step 173: train/loss = 0.6789427995681763, train/raw-loss = 0.46674275398254395, train/logprobs = tensor([[-0.4771, -2.0431],
        [-0.5519, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07073334604501724
Epoch 0, Step 174: train/loss = 0.7771197557449341, train/raw-loss = 0.6274830102920532, train/logprobs = tensor([[-0.5714, -0.9771],
        [-0.6171, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04987892508506775
Epoch 0, Step 175: train/loss = 0.7523871660232544, train/raw-loss = 0.5503343343734741, train/logprobs = tensor([[-1.1188, -3.2395],
        [-1.0424, -2.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06735094636678696
Epoch 0, Step 176: train/loss = 0.6894581913948059, train/raw-loss = 0.525291383266449, train/logprobs = tensor([[-0.6046, -2.3033],
        [-0.6765, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05472224950790405
Epoch 0, Step 177: train/loss = 0.7076336145401001, train/raw-loss = 0.5352264046669006, train/logprobs = tensor([[-0.5967, -1.7515],
        [-0.6758, -1.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05746907368302345
Epoch 0, Step 178: train/loss = 0.7535278797149658, train/raw-loss = 0.5637381672859192, train/logprobs = tensor([[-0.7711, -1.5636],
        [-0.9018, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06326323747634888
Epoch 0, Step 179: train/loss = 0.7889142632484436, train/raw-loss = 0.6460993885993958, train/logprobs = tensor([[-0.5619, -0.7848],
        [-0.5976, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04760495573282242
Epoch 0, Step 180: train/loss = 0.7302585244178772, train/raw-loss = 0.5597414970397949, train/logprobs = tensor([[-0.6522, -1.8813],
        [-0.6276, -1.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05683900788426399
Epoch 0, Step 181: train/loss = 0.8225363492965698, train/raw-loss = 0.605033814907074, train/logprobs = tensor([[-0.3158, -1.0317],
        [-0.3141, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07250085473060608
Epoch 0, Step 182: train/loss = 0.7965526580810547, train/raw-loss = 0.5857318043708801, train/logprobs = tensor([[-0.5454, -1.1904],
        [-0.5667, -0.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07027361541986465
Epoch 0, Step 183: train/loss = 0.7480615377426147, train/raw-loss = 0.5288262367248535, train/logprobs = tensor([[-0.5656, -1.9742],
        [-0.5985, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07307843863964081
Epoch 0, Step 184: train/loss = 0.7273206114768982, train/raw-loss = 0.5481746196746826, train/logprobs = tensor([[-0.4588, -1.5451],
        [-0.4698, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05971531569957733
Epoch 0, Step 185: train/loss = 0.8065294623374939, train/raw-loss = 0.6009600162506104, train/logprobs = tensor([[-0.4600, -1.1439],
        [-0.4700, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06852315366268158
Epoch 0, Step 186: train/loss = 0.7686015963554382, train/raw-loss = 0.6310348510742188, train/logprobs = tensor([[-0.6688, -0.8734],
        [-0.6521, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0458555743098259
Epoch 0, Step 187: train/loss = 0.8114521503448486, train/raw-loss = 0.626492977142334, train/logprobs = tensor([[-0.5548, -1.0758],
        [-0.5506, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06165304780006409
Epoch 0, Step 188: train/loss = 0.7874113321304321, train/raw-loss = 0.5571749210357666, train/logprobs = tensor([[-0.4945, -1.5509],
        [-0.5318, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07674546539783478
Epoch 0, Step 189: train/loss = 0.792216420173645, train/raw-loss = 0.5988121628761292, train/logprobs = tensor([[-0.8688, -1.4389],
        [-0.8870, -1.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06446808576583862
Epoch 0, Step 190: train/loss = 0.7688004374504089, train/raw-loss = 0.5794899463653564, train/logprobs = tensor([[-0.5611, -1.2840],
        [-0.5746, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06310349702835083
Epoch 0, Step 191: train/loss = 0.7644583582878113, train/raw-loss = 0.5493463277816772, train/logprobs = tensor([[-0.6181, -2.2345],
        [-0.6628, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07170400768518448
Epoch 0, Step 192: train/loss = 0.7665923833847046, train/raw-loss = 0.6175384521484375, train/logprobs = tensor([[-0.4274, -0.9537],
        [-0.4162, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04968464747071266
Epoch 0, Step 193: train/loss = 0.7794956564903259, train/raw-loss = 0.6557079553604126, train/logprobs = tensor([[-0.5341, -0.7006],
        [-0.5428, -0.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04126256704330444
Epoch 0, Step 194: train/loss = 0.6856496334075928, train/raw-loss = 0.5247472524642944, train/logprobs = tensor([[-0.5542, -1.9409],
        [-0.5564, -1.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053634148091077805
Epoch 0, Step 195: train/loss = 0.7665010690689087, train/raw-loss = 0.6120505332946777, train/logprobs = tensor([[-0.6321, -1.0128],
        [-0.5798, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051483530551195145
Epoch 0, Step 196: train/loss = 0.6593514084815979, train/raw-loss = 0.49989011883735657, train/logprobs = tensor([[-0.6109, -1.8038],
        [-0.6337, -0.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053153783082962036
Epoch 0, Step 197: train/loss = 0.70774245262146, train/raw-loss = 0.5395336747169495, train/logprobs = tensor([[-0.5188, -1.9837],
        [-0.5088, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05606959015130997
Epoch 0, Step 198: train/loss = 0.7369540929794312, train/raw-loss = 0.5967062711715698, train/logprobs = tensor([[-0.5228, -1.1964],
        [-0.4682, -0.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0467492938041687
Epoch 0, Step 199: train/loss = 0.6327527761459351, train/raw-loss = 0.4828875660896301, train/logprobs = tensor([[-0.6172, -2.9597],
        [-0.6417, -1.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04995507746934891
Epoch 0, Step 200: train/loss = 0.7007973790168762, train/raw-loss = 0.570595383644104, train/logprobs = tensor([[-0.5551, -1.2287],
        [-0.5925, -0.6524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04340066760778427
Epoch 0, Step 201: train/loss = 0.6919697523117065, train/raw-loss = 0.5265851020812988, train/logprobs = tensor([[-0.5909, -1.5538],
        [-0.5982, -0.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05512819439172745
Epoch 0, Step 202: train/loss = 0.7824599146842957, train/raw-loss = 0.66446852684021, train/logprobs = tensor([[-0.4371, -0.5782],
        [-0.4249, -0.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039330482482910156
Epoch 0, Step 203: train/loss = 0.7161937952041626, train/raw-loss = 0.559630274772644, train/logprobs = tensor([[-0.7153, -1.5502],
        [-0.7249, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05218783766031265
Epoch 0, Step 204: train/loss = 0.7850977778434753, train/raw-loss = 0.6527510285377502, train/logprobs = tensor([[-0.6627, -0.7793],
        [-0.6486, -0.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0441155768930912
Epoch 0, Step 205: train/loss = 0.7766810655593872, train/raw-loss = 0.5993236899375916, train/logprobs = tensor([[-0.5953, -1.3048],
        [-0.5704, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059119127690792084
Epoch 0, Step 206: train/loss = 0.6743378043174744, train/raw-loss = 0.5208716988563538, train/logprobs = tensor([[-0.5239, -1.6310],
        [-0.6575, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05115535482764244
Epoch 0, Step 207: train/loss = 0.7777000665664673, train/raw-loss = 0.6222492456436157, train/logprobs = tensor([[-0.4633, -1.1129],
        [-0.4564, -0.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05181692913174629
Epoch 0, Step 208: train/loss = 0.7369245290756226, train/raw-loss = 0.5877723693847656, train/logprobs = tensor([[-0.7050, -1.3252],
        [-0.6572, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04971740022301674
Epoch 0, Step 209: train/loss = 0.7062408924102783, train/raw-loss = 0.5491505265235901, train/logprobs = tensor([[-0.4909, -1.4788],
        [-0.4443, -0.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05236344784498215
Epoch 0, Step 210: train/loss = 0.6326051950454712, train/raw-loss = 0.47618919610977173, train/logprobs = tensor([[-0.6960, -2.1183],
        [-0.8212, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05213867127895355
Epoch 0, Step 211: train/loss = 0.6917943954467773, train/raw-loss = 0.5672604441642761, train/logprobs = tensor([[-0.4823, -3.0000],
        [-0.5129, -1.1906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041511327028274536
Epoch 0, Step 212: train/loss = 0.6350950002670288, train/raw-loss = 0.48180192708969116, train/logprobs = tensor([[-0.6728, -3.5710],
        [-0.7590, -1.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05109768360853195
Epoch 0, Step 213: train/loss = 0.7560887336730957, train/raw-loss = 0.6107410788536072, train/logprobs = tensor([[-0.6234, -1.0679],
        [-0.6826, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04844922572374344
Epoch 0, Step 214: train/loss = 0.7607101798057556, train/raw-loss = 0.6161027550697327, train/logprobs = tensor([[-0.7761, -1.0247],
        [-0.8344, -0.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04820249229669571
Epoch 0, Step 215: train/loss = 0.6862416863441467, train/raw-loss = 0.5202269554138184, train/logprobs = tensor([[-0.7503, -1.5949],
        [-0.8255, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05533823370933533
Epoch 0, Step 216: train/loss = 0.6443418860435486, train/raw-loss = 0.49137192964553833, train/logprobs = tensor([[-0.4673, -2.3134],
        [-0.4575, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05099000036716461
Epoch 0, Step 217: train/loss = 0.7583978772163391, train/raw-loss = 0.6153069138526917, train/logprobs = tensor([[-0.4894, -0.7930],
        [-0.5529, -0.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04769700765609741
Epoch 0, Step 218: train/loss = 0.6656361818313599, train/raw-loss = 0.49926498532295227, train/logprobs = tensor([[-0.5193, -1.7536],
        [-0.5606, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05545707046985626
Epoch 0, Step 219: train/loss = 0.6641762852668762, train/raw-loss = 0.505504310131073, train/logprobs = tensor([[-0.6799, -2.1615],
        [-0.6810, -1.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05289066582918167
Epoch 0, Step 220: train/loss = 0.7897832989692688, train/raw-loss = 0.6774157881736755, train/logprobs = tensor([[-0.5550, -0.6656],
        [-0.5290, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03745584934949875
Epoch 0, Step 221: train/loss = 0.7317770719528198, train/raw-loss = 0.5913380980491638, train/logprobs = tensor([[-0.6590, -1.2099],
        [-0.7192, -0.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04681301862001419
Epoch 0, Step 222: train/loss = 0.6919007301330566, train/raw-loss = 0.5628072023391724, train/logprobs = tensor([[-0.4599, -3.9268],
        [-0.4384, -2.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04303116723895073
Epoch 0, Step 223: train/loss = 0.6245383024215698, train/raw-loss = 0.45796698331832886, train/logprobs = tensor([[-0.7044, -5.1556],
        [-0.6439, -2.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05552377551794052
Epoch 0, Step 224: train/loss = 0.8036532402038574, train/raw-loss = 0.6499518156051636, train/logprobs = tensor([[-0.7265, -0.9653],
        [-0.5698, -0.5858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05123380571603775
Epoch 0, Step 225: train/loss = 0.7580955624580383, train/raw-loss = 0.6208338737487793, train/logprobs = tensor([[-0.5697, -0.9006],
        [-0.5877, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04575391113758087
Epoch 0, Step 226: train/loss = 0.6904168128967285, train/raw-loss = 0.5550581216812134, train/logprobs = tensor([[-0.7051, -1.5099],
        [-0.7969, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04511956498026848
Epoch 0, Step 227: train/loss = 0.5970786809921265, train/raw-loss = 0.43979424238204956, train/logprobs = tensor([[-0.7874, -2.9548],
        [-0.7069, -1.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05242813006043434
Epoch 0, Step 228: train/loss = 0.6875206232070923, train/raw-loss = 0.5166781544685364, train/logprobs = tensor([[-0.5744, -1.6127],
        [-0.8165, -0.8325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056947484612464905
Epoch 0, Step 229: train/loss = 0.5860755443572998, train/raw-loss = 0.42985621094703674, train/logprobs = tensor([[-0.6666, -2.2362],
        [-0.8770, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052073098719120026
Epoch 0, Step 230: train/loss = 0.7549102306365967, train/raw-loss = 0.6128917336463928, train/logprobs = tensor([[-0.8111, -1.2951],
        [-0.7086, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047339510172605515
Epoch 0, Step 231: train/loss = 0.7729696035385132, train/raw-loss = 0.6390347480773926, train/logprobs = tensor([[-0.6684, -0.7764],
        [-0.7165, -0.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044644951820373535
Epoch 0, Step 232: train/loss = 0.7063997983932495, train/raw-loss = 0.5466364622116089, train/logprobs = tensor([[-0.6036, -1.4420],
        [-0.6248, -0.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05325443670153618
Epoch 0, Step 233: train/loss = 0.6792376041412354, train/raw-loss = 0.5296193361282349, train/logprobs = tensor([[-0.7109, -2.0956],
        [-0.7490, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049872759729623795
Epoch 0, Step 234: train/loss = 0.6235696077346802, train/raw-loss = 0.4559068977832794, train/logprobs = tensor([[-0.6632, -2.8578],
        [-0.7329, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05588756129145622
Epoch 0, Step 235: train/loss = 0.7036378383636475, train/raw-loss = 0.5485436916351318, train/logprobs = tensor([[-0.5027, -1.8040],
        [-0.5277, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051698025315999985
Epoch 0, Step 236: train/loss = 0.6989160776138306, train/raw-loss = 0.543251633644104, train/logprobs = tensor([[-0.6043, -1.3675],
        [-0.6635, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051888130605220795
Epoch 0, Step 237: train/loss = 0.8092746734619141, train/raw-loss = 0.6570110321044922, train/logprobs = tensor([[-0.8015, -0.5891],
        [-0.8500, -0.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050754547119140625
Epoch 0, Step 238: train/loss = 0.6666072607040405, train/raw-loss = 0.5215275287628174, train/logprobs = tensor([[-0.5362, -1.5710],
        [-0.6394, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04835992306470871
Epoch 0, Step 239: train/loss = 0.7268412113189697, train/raw-loss = 0.5898945927619934, train/logprobs = tensor([[-0.4903, -1.1037],
        [-0.5308, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045648861676454544
Epoch 0, Step 240: train/loss = 0.7787968516349792, train/raw-loss = 0.6367873549461365, train/logprobs = tensor([[-0.6094, -0.8668],
        [-0.5670, -0.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047336507588624954
Epoch 0, Step 241: train/loss = 0.5895484685897827, train/raw-loss = 0.4239760637283325, train/logprobs = tensor([[-0.5419, -2.3520],
        [-0.6744, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0551907904446125
Epoch 0, Step 242: train/loss = 0.6764224767684937, train/raw-loss = 0.5276435017585754, train/logprobs = tensor([[-0.6626, -1.5643],
        [-0.6961, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049592986702919006
Epoch 0, Step 243: train/loss = 0.6372250914573669, train/raw-loss = 0.4927648603916168, train/logprobs = tensor([[-0.6758, -3.4694],
        [-0.7273, -1.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04815341532230377
Epoch 0, Step 244: train/loss = 0.7437534928321838, train/raw-loss = 0.6180203557014465, train/logprobs = tensor([[-0.5548, -0.9830],
        [-0.5862, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041911035776138306
Epoch 0, Step 245: train/loss = 0.7859704494476318, train/raw-loss = 0.6502220034599304, train/logprobs = tensor([[-0.6568, -1.1147],
        [-0.6279, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04524947702884674
Epoch 0, Step 246: train/loss = 0.7885209918022156, train/raw-loss = 0.6569647789001465, train/logprobs = tensor([[-0.6885, -0.9520],
        [-0.6195, -0.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043852075934410095
Epoch 0, Step 247: train/loss = 0.5939337015151978, train/raw-loss = 0.4307863414287567, train/logprobs = tensor([[-0.4779, -2.8785],
        [-0.5258, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054382454603910446
Epoch 0, Step 248: train/loss = 0.6405154466629028, train/raw-loss = 0.5135759115219116, train/logprobs = tensor([[-0.5608, -3.3299],
        [-0.5687, -1.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04231316223740578
Epoch 0, Step 249: train/loss = 0.6636199951171875, train/raw-loss = 0.5084566473960876, train/logprobs = tensor([[-0.5570, -2.9290],
        [-0.5522, -1.2942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05172111466526985
Epoch 0, Step 250: train/loss = 0.7171001434326172, train/raw-loss = 0.5758941769599915, train/logprobs = tensor([[-0.6731, -1.5519],
        [-0.6146, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04706866666674614
Epoch 0, Step 251: train/loss = 0.7454527616500854, train/raw-loss = 0.6116957068443298, train/logprobs = tensor([[-0.6177, -0.9260],
        [-0.6810, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044585686177015305
Epoch 0, Step 252: train/loss = 0.6640341281890869, train/raw-loss = 0.5071702003479004, train/logprobs = tensor([[-0.6967, -2.1051],
        [-0.7780, -0.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0522879883646965
Epoch 0, Step 253: train/loss = 0.7063291072845459, train/raw-loss = 0.5702031254768372, train/logprobs = tensor([[-0.4090, -1.2985],
        [-0.4108, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04537532851099968
Epoch 0, Step 254: train/loss = 0.6412354111671448, train/raw-loss = 0.5198159217834473, train/logprobs = tensor([[-0.8318, -1.7920],
        [-0.8766, -0.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040473174303770065
Epoch 0, Step 255: train/loss = 0.7717857956886292, train/raw-loss = 0.6366151571273804, train/logprobs = tensor([[-0.4509, -0.7057],
        [-0.4745, -0.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04505687206983566
Epoch 0, Step 256: train/loss = 0.7021439671516418, train/raw-loss = 0.5912421345710754, train/logprobs = tensor([[-0.6181, -1.2042],
        [-0.5980, -0.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03696727752685547
Epoch 0, Step 257: train/loss = 0.7317018508911133, train/raw-loss = 0.5932015180587769, train/logprobs = tensor([[-0.9367, -1.5873],
        [-0.8939, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04616677016019821
Epoch 0, Step 258: train/loss = 0.7000003457069397, train/raw-loss = 0.579586386680603, train/logprobs = tensor([[-0.8618, -1.5415],
        [-0.8601, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04013797640800476
Epoch 0, Step 259: train/loss = 0.6104545593261719, train/raw-loss = 0.484872043132782, train/logprobs = tensor([[-0.5619, -1.7198],
        [-0.6180, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04186083748936653
Epoch 0, Step 260: train/loss = 0.6112588047981262, train/raw-loss = 0.48657453060150146, train/logprobs = tensor([[-0.6175, -2.1327],
        [-0.7121, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041561417281627655
Epoch 0, Step 261: train/loss = 0.7209528684616089, train/raw-loss = 0.5678209066390991, train/logprobs = tensor([[-0.5945, -1.5817],
        [-0.5210, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05104399472475052
Epoch 0, Step 262: train/loss = 0.6237984895706177, train/raw-loss = 0.5064131021499634, train/logprobs = tensor([[-0.4605, -1.4732],
        [-0.5530, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03912845626473427
Epoch 0, Step 263: train/loss = 0.6597254276275635, train/raw-loss = 0.5264462828636169, train/logprobs = tensor([[-0.6810, -1.5769],
        [-0.6995, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044426366686820984
Epoch 0, Step 264: train/loss = 0.6839093565940857, train/raw-loss = 0.5663944482803345, train/logprobs = tensor([[-0.6665, -0.8478],
        [-0.7917, -0.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03917162865400314
Epoch 0, Step 265: train/loss = 0.6668844819068909, train/raw-loss = 0.5482212901115417, train/logprobs = tensor([[-0.5922, -4.7988],
        [-0.7000, -1.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03955438360571861
Epoch 0, Step 266: train/loss = 0.6131536960601807, train/raw-loss = 0.4806877374649048, train/logprobs = tensor([[-0.8687, -2.1272],
        [-0.9159, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044155303388834
Epoch 0, Step 267: train/loss = 0.6415277123451233, train/raw-loss = 0.5005139112472534, train/logprobs = tensor([[-0.5856, -1.9757],
        [-0.6327, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04700459539890289
Epoch 0, Step 268: train/loss = 0.659428596496582, train/raw-loss = 0.5364163517951965, train/logprobs = tensor([[-0.4880, -1.1805],
        [-0.5718, -0.4298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04100407287478447
Epoch 0, Step 269: train/loss = 0.6875583529472351, train/raw-loss = 0.5379939675331116, train/logprobs = tensor([[-0.6520, -2.9141],
        [-0.5405, -0.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04985479637980461
Epoch 0, Step 270: train/loss = 0.6712349057197571, train/raw-loss = 0.5388895869255066, train/logprobs = tensor([[-0.6089, -2.7104],
        [-0.6416, -1.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044115111231803894
Epoch 0, Step 271: train/loss = 0.7753853797912598, train/raw-loss = 0.6200003623962402, train/logprobs = tensor([[-0.5023, -0.9888],
        [-0.4656, -0.5943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05179502069950104
Epoch 0, Step 272: train/loss = 0.5933179259300232, train/raw-loss = 0.4470253586769104, train/logprobs = tensor([[-0.8336, -1.8787],
        [-1.0270, -0.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0487641878426075
Epoch 0, Step 273: train/loss = 0.5038513541221619, train/raw-loss = 0.35630708932876587, train/logprobs = tensor([[-0.6126, -5.9245],
        [-0.7542, -1.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04918140172958374
Epoch 0, Step 274: train/loss = 0.618858814239502, train/raw-loss = 0.47933459281921387, train/logprobs = tensor([[-0.8173, -3.4041],
        [-0.7978, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04650808870792389
Epoch 0, Step 275: train/loss = 0.6119083762168884, train/raw-loss = 0.4785056710243225, train/logprobs = tensor([[-0.6504, -1.9964],
        [-0.7759, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044467560946941376
Epoch 0, Step 276: train/loss = 0.7509847283363342, train/raw-loss = 0.6185063123703003, train/logprobs = tensor([[-1.0291, -1.7017],
        [-0.7010, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044159483164548874
Epoch 0, Step 277: train/loss = 0.6519207954406738, train/raw-loss = 0.5267224311828613, train/logprobs = tensor([[-1.0939, -2.7623],
        [-0.9552, -1.3374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0417327955365181
Epoch 0, Step 278: train/loss = 0.5970703363418579, train/raw-loss = 0.47419390082359314, train/logprobs = tensor([[-0.5390, -2.2885],
        [-0.5681, -0.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040958795696496964
Epoch 0, Step 279: train/loss = 0.6393427848815918, train/raw-loss = 0.49866387248039246, train/logprobs = tensor([[-0.6630, -2.4541],
        [-0.6690, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04689296334981918
Epoch 0, Step 280: train/loss = 0.6335523724555969, train/raw-loss = 0.4929187595844269, train/logprobs = tensor([[-0.5064, -1.9833],
        [-0.5556, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04687786474823952
Epoch 0, Step 281: train/loss = 0.6751222014427185, train/raw-loss = 0.5437780618667603, train/logprobs = tensor([[-0.8495, -3.6833],
        [-0.7245, -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04378140717744827
Epoch 0, Step 282: train/loss = 0.6658433079719543, train/raw-loss = 0.5571076273918152, train/logprobs = tensor([[-0.7530, -2.0226],
        [-0.7378, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036245230585336685
Epoch 0, Step 283: train/loss = 0.7512214183807373, train/raw-loss = 0.6275014281272888, train/logprobs = tensor([[-0.5012, -1.0538],
        [-0.5166, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04123999923467636
Epoch 0, Step 284: train/loss = 0.7158417701721191, train/raw-loss = 0.5811754465103149, train/logprobs = tensor([[-0.5391, -0.9406],
        [-0.6052, -0.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04488877207040787
Epoch 0, Step 285: train/loss = 0.624609649181366, train/raw-loss = 0.47868770360946655, train/logprobs = tensor([[-0.6817, -2.2679],
        [-0.8957, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0486406572163105
Epoch 0, Step 286: train/loss = 0.7783917188644409, train/raw-loss = 0.6556987762451172, train/logprobs = tensor([[-0.5120, -0.8657],
        [-0.5304, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04089764878153801
Epoch 0, Step 287: train/loss = 0.6591111421585083, train/raw-loss = 0.5158349871635437, train/logprobs = tensor([[-0.5786, -1.9765],
        [-0.5519, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047758713364601135
Epoch 0, Step 288: train/loss = 0.6026687622070312, train/raw-loss = 0.48082059621810913, train/logprobs = tensor([[-0.6787, -3.8299],
        [-0.6199, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040616054087877274
Epoch 0, Step 289: train/loss = 0.7316200733184814, train/raw-loss = 0.6297721862792969, train/logprobs = tensor([[-0.5231, -0.8517],
        [-0.4633, -0.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03394930809736252
Epoch 0, Step 290: train/loss = 0.6056906580924988, train/raw-loss = 0.4799636900424957, train/logprobs = tensor([[-0.5314, -2.0560],
        [-0.5770, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04190899431705475
Epoch 0, Step 291: train/loss = 0.6005856990814209, train/raw-loss = 0.45494651794433594, train/logprobs = tensor([[-0.8569, -2.6439],
        [-0.8822, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048546381294727325
Epoch 0, Step 292: train/loss = 0.6614696979522705, train/raw-loss = 0.5442265868186951, train/logprobs = tensor([[-0.4667, -1.1952],
        [-0.5377, -0.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03908102959394455
Epoch 0, Step 293: train/loss = 0.5976923704147339, train/raw-loss = 0.47634321451187134, train/logprobs = tensor([[-0.6834, -3.2846],
        [-0.8150, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04044971242547035
Epoch 0, Step 294: train/loss = 0.6469852924346924, train/raw-loss = 0.5097954273223877, train/logprobs = tensor([[-0.6014, -1.4745],
        [-0.7213, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045729950070381165
Epoch 0, Step 295: train/loss = 0.6436625123023987, train/raw-loss = 0.5256903171539307, train/logprobs = tensor([[-0.5368, -1.4380],
        [-0.6949, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039324063807725906
Epoch 0, Step 296: train/loss = 0.6248321533203125, train/raw-loss = 0.5140523314476013, train/logprobs = tensor([[-0.4888, -3.5678],
        [-0.5598, -1.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03692661225795746
Epoch 0, Step 297: train/loss = 0.7189629673957825, train/raw-loss = 0.6185265183448792, train/logprobs = tensor([[-0.4905, -0.9746],
        [-0.4575, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033478815108537674
Epoch 0, Step 298: train/loss = 0.7020650506019592, train/raw-loss = 0.6099758744239807, train/logprobs = tensor([[-0.4401, -1.0606],
        [-0.4225, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030696388334035873
Epoch 0, Step 299: train/loss = 0.6610493659973145, train/raw-loss = 0.5453406572341919, train/logprobs = tensor([[-0.5792, -1.8587],
        [-0.7032, -0.7135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03856956958770752
Epoch 0, Step 300: train/loss = 0.642336368560791, train/raw-loss = 0.518643319606781, train/logprobs = tensor([[-0.8202, -1.8303],
        [-0.7681, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041231006383895874
Epoch 0, Step 301: train/loss = 0.6491992473602295, train/raw-loss = 0.5386808514595032, train/logprobs = tensor([[-0.5436, -1.2925],
        [-0.5984, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036839455366134644
Epoch 0, Step 302: train/loss = 0.6732538938522339, train/raw-loss = 0.520111083984375, train/logprobs = tensor([[-0.8262, -2.1077],
        [-0.7540, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05104758217930794
Epoch 0, Step 303: train/loss = 0.6776313781738281, train/raw-loss = 0.570411205291748, train/logprobs = tensor([[-0.6096, -1.1540],
        [-0.5773, -0.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03574005141854286
Epoch 0, Step 304: train/loss = 0.7556989192962646, train/raw-loss = 0.6318742036819458, train/logprobs = tensor([[-0.7142, -0.9358],
        [-0.7736, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04127492383122444
Epoch 0, Step 305: train/loss = 0.6133550405502319, train/raw-loss = 0.4901672899723053, train/logprobs = tensor([[-0.5626, -3.2911],
        [-0.5337, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04106259346008301
Epoch 0, Step 306: train/loss = 0.6539515852928162, train/raw-loss = 0.5224306583404541, train/logprobs = tensor([[-0.5405, -1.5866],
        [-0.5548, -0.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043840330094099045
Epoch 0, Step 307: train/loss = 0.7219170331954956, train/raw-loss = 0.611054003238678, train/logprobs = tensor([[-0.5816, -0.7467],
        [-0.6314, -0.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03695434331893921
Epoch 0, Step 308: train/loss = 0.6307095289230347, train/raw-loss = 0.505657434463501, train/logprobs = tensor([[-0.7295, -1.5791],
        [-0.7301, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041684024035930634
Epoch 0, Step 309: train/loss = 0.6274967193603516, train/raw-loss = 0.5126823782920837, train/logprobs = tensor([[-0.5431, -1.6528],
        [-0.5646, -0.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03827143460512161
Epoch 0, Step 310: train/loss = 0.6607012152671814, train/raw-loss = 0.5451075434684753, train/logprobs = tensor([[-0.6200, -1.3459],
        [-0.5875, -0.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038531236350536346
Epoch 0, Step 311: train/loss = 0.7477902173995972, train/raw-loss = 0.6326909065246582, train/logprobs = tensor([[-0.6334, -0.9204],
        [-0.5264, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836642950773239
Epoch 0, Step 312: train/loss = 0.7435472011566162, train/raw-loss = 0.6073190569877625, train/logprobs = tensor([[-0.9175, -1.3771],
        [-0.9789, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045409366488456726
Epoch 0, Step 313: train/loss = 0.5627301931381226, train/raw-loss = 0.43336957693099976, train/logprobs = tensor([[-0.5677, -4.0920],
        [-0.5790, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04312020540237427
Epoch 0, Step 314: train/loss = 0.5793026685714722, train/raw-loss = 0.4513901472091675, train/logprobs = tensor([[-0.5341, -3.1141],
        [-0.5275, -1.1558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04263749718666077
Epoch 0, Step 315: train/loss = 0.5792533159255981, train/raw-loss = 0.45407071709632874, train/logprobs = tensor([[-0.6531, -2.1822],
        [-0.7447, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041727542877197266
Epoch 0, Step 316: train/loss = 0.7595169544219971, train/raw-loss = 0.6680158376693726, train/logprobs = tensor([[-0.4968, -0.5181],
        [-0.4731, -0.3894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030500374734401703
Epoch 0, Step 317: train/loss = 0.5986066460609436, train/raw-loss = 0.4725799560546875, train/logprobs = tensor([[-0.5571, -3.8242],
        [-0.5799, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042008884251117706
Epoch 0, Step 318: train/loss = 0.6736019849777222, train/raw-loss = 0.5631285309791565, train/logprobs = tensor([[-0.5297, -1.1546],
        [-0.5601, -0.5397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03682447969913483
Epoch 0, Step 319: train/loss = 0.6501049399375916, train/raw-loss = 0.525412917137146, train/logprobs = tensor([[-0.7836, -2.1383],
        [-0.7106, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041564010083675385
Epoch 0, Step 320: train/loss = 0.6086228489875793, train/raw-loss = 0.48522746562957764, train/logprobs = tensor([[-0.5460, -3.5208],
        [-0.5432, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04113180562853813
Epoch 0, Step 321: train/loss = 0.6328122019767761, train/raw-loss = 0.5182436108589172, train/logprobs = tensor([[-0.5773, -1.4209],
        [-0.6313, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038189537823200226
Epoch 0, Step 322: train/loss = 0.6103603839874268, train/raw-loss = 0.5013810396194458, train/logprobs = tensor([[-1.0409, -3.7736],
        [-0.9008, -1.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03632644563913345
Epoch 0, Step 323: train/loss = 0.5365968346595764, train/raw-loss = 0.4185110330581665, train/logprobs = tensor([[-0.6129, -4.3960],
        [-0.6543, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03936193510890007
Epoch 0, Step 324: train/loss = 0.6292495727539062, train/raw-loss = 0.5162388682365417, train/logprobs = tensor([[-0.4722, -1.6704],
        [-0.5064, -0.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037670236080884933
Epoch 0, Step 325: train/loss = 0.5647020936012268, train/raw-loss = 0.42992764711380005, train/logprobs = tensor([[-0.5922, -2.7735],
        [-0.6190, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04492482170462608
Epoch 0, Step 326: train/loss = 0.6248277425765991, train/raw-loss = 0.511692464351654, train/logprobs = tensor([[-0.5155, -1.4557],
        [-0.5469, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03771176189184189
Epoch 0, Step 327: train/loss = 0.568778395652771, train/raw-loss = 0.43093574047088623, train/logprobs = tensor([[-0.7408, -2.8287],
        [-0.7661, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04594755172729492
Epoch 0, Step 328: train/loss = 0.6800770163536072, train/raw-loss = 0.5771681666374207, train/logprobs = tensor([[-0.5929, -1.8812],
        [-0.5238, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0343029648065567
Epoch 0, Step 329: train/loss = 0.7127066850662231, train/raw-loss = 0.5848594307899475, train/logprobs = tensor([[-0.7599, -1.3573],
        [-0.6811, -0.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04261574521660805
Epoch 0, Step 330: train/loss = 0.6005241274833679, train/raw-loss = 0.49080485105514526, train/logprobs = tensor([[-0.5643, -2.0731],
        [-0.5859, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03657309710979462
Epoch 0, Step 331: train/loss = 0.5310985445976257, train/raw-loss = 0.3985539376735687, train/logprobs = tensor([[-0.7074, -3.5686],
        [-0.7231, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04418153688311577
Epoch 0, Step 332: train/loss = 0.6583907604217529, train/raw-loss = 0.5485546588897705, train/logprobs = tensor([[-0.4775, -1.3255],
        [-0.4712, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036612026393413544
Epoch 0, Step 333: train/loss = 0.6174269914627075, train/raw-loss = 0.5083968639373779, train/logprobs = tensor([[-0.5569, -1.7515],
        [-0.6212, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03634337708353996
Epoch 0, Step 334: train/loss = 0.6018982529640198, train/raw-loss = 0.4791308641433716, train/logprobs = tensor([[-0.5884, -2.2713],
        [-0.6753, -1.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04092244803905487
Epoch 0, Step 335: train/loss = 0.5540247559547424, train/raw-loss = 0.41844382882118225, train/logprobs = tensor([[-0.7124, -3.4238],
        [-0.8269, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04519364982843399
Epoch 0, Step 336: train/loss = 0.741162896156311, train/raw-loss = 0.640157163143158, train/logprobs = tensor([[-0.7504, -0.8577],
        [-0.6877, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033668600022792816
Epoch 0, Step 337: train/loss = 0.6813552975654602, train/raw-loss = 0.5842467546463013, train/logprobs = tensor([[-0.4478, -1.2589],
        [-0.4924, -0.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032369501888751984
Epoch 0, Step 338: train/loss = 0.626020073890686, train/raw-loss = 0.4966949224472046, train/logprobs = tensor([[-0.5434, -1.7387],
        [-0.6091, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04310837760567665
Epoch 0, Step 339: train/loss = 0.6939182281494141, train/raw-loss = 0.6025494337081909, train/logprobs = tensor([[-0.5808, -1.1775],
        [-0.5138, -0.6695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030456246808171272
Epoch 0, Step 340: train/loss = 0.6864792108535767, train/raw-loss = 0.561866819858551, train/logprobs = tensor([[-0.5166, -1.1536],
        [-0.5538, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04153748229146004
Epoch 0, Step 341: train/loss = 0.5950469374656677, train/raw-loss = 0.48295214772224426, train/logprobs = tensor([[-0.6973, -3.7233],
        [-0.6512, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03736494109034538
Epoch 0, Step 342: train/loss = 0.7354357242584229, train/raw-loss = 0.6603022813796997, train/logprobs = tensor([[-0.4875, -0.4127],
        [-0.5088, -0.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02504446730017662
Epoch 0, Step 343: train/loss = 0.629448652267456, train/raw-loss = 0.5177026987075806, train/logprobs = tensor([[-0.5503, -2.8130],
        [-0.5732, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03724865987896919
Epoch 0, Step 344: train/loss = 0.6357586979866028, train/raw-loss = 0.5146564841270447, train/logprobs = tensor([[-0.6961, -1.2127],
        [-0.9307, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040367402136325836
Epoch 0, Step 345: train/loss = 0.7235013842582703, train/raw-loss = 0.6094963550567627, train/logprobs = tensor([[-0.8389, -1.0113],
        [-0.7079, -0.4672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03800167888402939
Epoch 0, Step 346: train/loss = 0.6704572439193726, train/raw-loss = 0.5662804245948792, train/logprobs = tensor([[-0.4776, -1.0047],
        [-0.5598, -0.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034725580364465714
Epoch 0, Step 347: train/loss = 0.5870344638824463, train/raw-loss = 0.44683992862701416, train/logprobs = tensor([[-0.6830, -2.1761],
        [-0.8472, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04673150181770325
Epoch 0, Step 348: train/loss = 0.5823596715927124, train/raw-loss = 0.45022475719451904, train/logprobs = tensor([[-0.5910, -2.4674],
        [-0.5124, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04404497519135475
Epoch 0, Step 349: train/loss = 0.5154979825019836, train/raw-loss = 0.3871053159236908, train/logprobs = tensor([[-0.8650, -3.3491],
        [-0.8204, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04279756918549538
Epoch 0, Step 350: train/loss = 0.6574171781539917, train/raw-loss = 0.5608669519424438, train/logprobs = tensor([[-0.5031, -1.1253],
        [-0.5661, -0.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03218340873718262
Epoch 0, Step 351: train/loss = 0.7061749696731567, train/raw-loss = 0.5960977077484131, train/logprobs = tensor([[-0.5509, -0.9814],
        [-0.5252, -0.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03669242560863495
Epoch 0, Step 352: train/loss = 0.5613608956336975, train/raw-loss = 0.45810186862945557, train/logprobs = tensor([[-0.7644, -2.0595],
        [-0.8565, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03441968932747841
Epoch 0, Step 353: train/loss = 0.6112666130065918, train/raw-loss = 0.5085405707359314, train/logprobs = tensor([[-0.5506, -1.5509],
        [-0.6160, -0.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03424200415611267
Epoch 0, Step 354: train/loss = 0.6505509614944458, train/raw-loss = 0.5487817525863647, train/logprobs = tensor([[-0.7250, -2.1375],
        [-0.6989, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03392306715250015
Epoch 0, Step 355: train/loss = 0.6175830364227295, train/raw-loss = 0.5149729251861572, train/logprobs = tensor([[-0.7438, -2.1940],
        [-0.5006, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03420335799455643
Epoch 0, Step 356: train/loss = 0.5124608278274536, train/raw-loss = 0.3940289616584778, train/logprobs = tensor([[-0.6682, -4.9053],
        [-0.6968, -1.3558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03947726637125015
Epoch 0, Step 357: train/loss = 0.5773172378540039, train/raw-loss = 0.46433812379837036, train/logprobs = tensor([[-0.5959, -2.1311],
        [-0.6570, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03765970468521118
Epoch 0, Step 358: train/loss = 0.6765523552894592, train/raw-loss = 0.5832849740982056, train/logprobs = tensor([[-0.4732, -1.3200],
        [-0.4604, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031089147552847862
Epoch 0, Step 359: train/loss = 0.6171107888221741, train/raw-loss = 0.5152430534362793, train/logprobs = tensor([[-0.6277, -1.8173],
        [-0.6235, -0.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03395591676235199
Epoch 0, Step 360: train/loss = 0.5472276210784912, train/raw-loss = 0.45152878761291504, train/logprobs = tensor([[-0.5106, -3.7715],
        [-0.5022, -1.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0318995863199234
Epoch 0, Step 361: train/loss = 0.6519678235054016, train/raw-loss = 0.5638121366500854, train/logprobs = tensor([[-0.5349, -1.2910],
        [-0.5488, -0.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029385210946202278
Epoch 0, Step 362: train/loss = 0.586748480796814, train/raw-loss = 0.47483766078948975, train/logprobs = tensor([[-0.7422, -1.8389],
        [-0.8970, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03730358928442001
Epoch 0, Step 363: train/loss = 0.6344946622848511, train/raw-loss = 0.5334621071815491, train/logprobs = tensor([[-0.5410, -1.4808],
        [-0.6388, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033677518367767334
Epoch 0, Step 364: train/loss = 0.7768532037734985, train/raw-loss = 0.6368399858474731, train/logprobs = tensor([[-0.7048, -0.7056],
        [-0.7854, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04667108505964279
Epoch 0, Step 365: train/loss = 0.64992755651474, train/raw-loss = 0.541080892086029, train/logprobs = tensor([[-0.8106, -1.4628],
        [-0.8628, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628220781683922
Epoch 0, Step 366: train/loss = 0.7214661836624146, train/raw-loss = 0.639080286026001, train/logprobs = tensor([[-0.5847, -0.9322],
        [-0.5304, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027461983263492584
Epoch 0, Step 367: train/loss = 0.6174992918968201, train/raw-loss = 0.48612546920776367, train/logprobs = tensor([[-0.9155, -2.2178],
        [-0.9279, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0437912791967392
Epoch 0, Step 368: train/loss = 0.7172839641571045, train/raw-loss = 0.6141411066055298, train/logprobs = tensor([[-0.9563, -0.9586],
        [-0.8956, -0.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03438093513250351
Epoch 0, Step 369: train/loss = 0.5626737475395203, train/raw-loss = 0.455732524394989, train/logprobs = tensor([[-0.4617, -1.9206],
        [-0.4819, -0.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03564707189798355
Epoch 0, Step 370: train/loss = 0.6690075397491455, train/raw-loss = 0.571569561958313, train/logprobs = tensor([[-0.4842, -0.8571],
        [-0.6387, -0.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03247934207320213
Epoch 0, Step 371: train/loss = 0.714658260345459, train/raw-loss = 0.6176728010177612, train/logprobs = tensor([[-0.4139, -0.7458],
        [-0.4218, -0.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03232848271727562
Epoch 0, Step 372: train/loss = 0.6972454190254211, train/raw-loss = 0.5724056959152222, train/logprobs = tensor([[-1.0039, -2.1618],
        [-0.6449, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04161325469613075
Epoch 0, Step 373: train/loss = 0.5706804990768433, train/raw-loss = 0.47076401114463806, train/logprobs = tensor([[-0.6196, -2.8217],
        [-0.6785, -0.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033305492252111435
Epoch 0, Step 374: train/loss = 0.5668464303016663, train/raw-loss = 0.46670204401016235, train/logprobs = tensor([[-0.5037, -2.1876],
        [-0.5111, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03338145837187767
Epoch 0, Step 375: train/loss = 0.6402015686035156, train/raw-loss = 0.5407360792160034, train/logprobs = tensor([[-0.6093, -1.2149],
        [-0.6073, -0.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03315515071153641
Epoch 0, Step 376: train/loss = 0.5670790672302246, train/raw-loss = 0.4608021378517151, train/logprobs = tensor([[-0.4058, -2.1682],
        [-0.4335, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035425640642642975
Epoch 0, Step 377: train/loss = 0.6279622316360474, train/raw-loss = 0.5177139043807983, train/logprobs = tensor([[-0.6631, -1.4024],
        [-0.6993, -0.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0367494635283947
Epoch 0, Step 378: train/loss = 0.5404959917068481, train/raw-loss = 0.4339521527290344, train/logprobs = tensor([[-0.4905, -2.4811],
        [-0.5206, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03551463037729263
Epoch 0, Step 379: train/loss = 0.5593076944351196, train/raw-loss = 0.46547603607177734, train/logprobs = tensor([[-0.5408, -1.9904],
        [-0.5783, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03127722442150116
Epoch 0, Step 380: train/loss = 0.6593154668807983, train/raw-loss = 0.5664867758750916, train/logprobs = tensor([[-0.6667, -1.5458],
        [-0.6193, -0.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030942916870117188
Epoch 0, Step 381: train/loss = 0.7238476872444153, train/raw-loss = 0.6214047074317932, train/logprobs = tensor([[-0.5901, -0.8525],
        [-0.4782, -0.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034147679805755615
Epoch 0, Step 382: train/loss = 0.5583019256591797, train/raw-loss = 0.43475574254989624, train/logprobs = tensor([[-0.5758, -2.3486],
        [-0.6741, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041182056069374084
Epoch 0, Step 383: train/loss = 0.6089891791343689, train/raw-loss = 0.5231073498725891, train/logprobs = tensor([[-0.4158, -1.9015],
        [-0.4136, -0.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028627263382077217
Epoch 0, Step 384: train/loss = 0.6444160342216492, train/raw-loss = 0.5326351523399353, train/logprobs = tensor([[-0.4404, -1.4343],
        [-0.4817, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037260305136442184
Epoch 0, Step 385: train/loss = 0.6256183385848999, train/raw-loss = 0.5194265842437744, train/logprobs = tensor([[-0.5547, -1.4462],
        [-0.6579, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0353972353041172
Epoch 0, Step 386: train/loss = 0.6148031949996948, train/raw-loss = 0.4989292025566101, train/logprobs = tensor([[-0.5734, -1.8336],
        [-0.5850, -0.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038624659180641174
Epoch 0, Step 387: train/loss = 0.5232653617858887, train/raw-loss = 0.4319419860839844, train/logprobs = tensor([[-0.5844, -4.1833],
        [-0.5655, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030441109091043472
Epoch 0, Step 388: train/loss = 0.6483669877052307, train/raw-loss = 0.5612483024597168, train/logprobs = tensor([[-0.3941, -1.5077],
        [-0.3731, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029039571061730385
Epoch 0, Step 389: train/loss = 0.47745785117149353, train/raw-loss = 0.3618392050266266, train/logprobs = tensor([[-0.6453, -3.1127],
        [-0.7000, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038539543747901917
Epoch 0, Step 390: train/loss = 0.6323933005332947, train/raw-loss = 0.5404123067855835, train/logprobs = tensor([[-0.6398, -3.6567],
        [-0.6019, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03066030889749527
Epoch 0, Step 391: train/loss = 0.5940330624580383, train/raw-loss = 0.4918043315410614, train/logprobs = tensor([[-0.6483, -2.1681],
        [-0.7686, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0340762585401535
Epoch 0, Step 392: train/loss = 0.7699025869369507, train/raw-loss = 0.6682664155960083, train/logprobs = tensor([[-1.1086, -1.1907],
        [-0.7626, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03387869894504547
Epoch 0, Step 393: train/loss = 0.6329435110092163, train/raw-loss = 0.548457145690918, train/logprobs = tensor([[-0.4708, -1.2600],
        [-0.4349, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028162110596895218
Epoch 0, Step 394: train/loss = 0.5690821409225464, train/raw-loss = 0.45211395621299744, train/logprobs = tensor([[-0.7385, -2.5495],
        [-0.6294, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038989391177892685
Epoch 0, Step 395: train/loss = 0.4714086055755615, train/raw-loss = 0.35995954275131226, train/logprobs = tensor([[-0.7275, -6.3428],
        [-0.9229, -1.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037149690091609955
Epoch 0, Step 396: train/loss = 0.6651463508605957, train/raw-loss = 0.5827783346176147, train/logprobs = tensor([[-0.4624, -0.8904],
        [-0.5164, -0.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027456015348434448
Epoch 0, Step 397: train/loss = 0.5442432761192322, train/raw-loss = 0.4486536979675293, train/logprobs = tensor([[-0.4750, -3.2718],
        [-0.4612, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03186320513486862
Epoch 0, Step 398: train/loss = 0.7213644981384277, train/raw-loss = 0.6456272602081299, train/logprobs = tensor([[-0.6982, -0.6062],
        [-0.6383, -0.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025245744735002518
Epoch 0, Step 399: train/loss = 0.5299522280693054, train/raw-loss = 0.4171963334083557, train/logprobs = tensor([[-0.6186, -4.3997],
        [-0.7311, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0375852957367897
Epoch 0, Step 400: train/loss = 0.5226261019706726, train/raw-loss = 0.3883906602859497, train/logprobs = tensor([[-0.9333, -3.0784],
        [-0.8912, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04474513605237007
Epoch 0, Step 401: train/loss = 0.5732403993606567, train/raw-loss = 0.4556102454662323, train/logprobs = tensor([[-0.6160, -2.2362],
        [-0.8455, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03921004384756088
Epoch 0, Step 402: train/loss = 0.5229816436767578, train/raw-loss = 0.40078994631767273, train/logprobs = tensor([[-0.7011, -3.0004],
        [-0.8880, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04073058068752289
Epoch 0, Step 403: train/loss = 0.4776875972747803, train/raw-loss = 0.3528919219970703, train/logprobs = tensor([[-0.9809, -5.5471],
        [-0.9110, -1.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04159856215119362
Epoch 0, Step 404: train/loss = 0.5494565963745117, train/raw-loss = 0.451798677444458, train/logprobs = tensor([[-1.9715, -6.3438],
        [-1.7186, -2.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03255263715982437
Epoch 0, Step 405: train/loss = 0.7147915959358215, train/raw-loss = 0.6090744733810425, train/logprobs = tensor([[-0.6764, -0.8135],
        [-0.6491, -0.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035239048302173615
Epoch 0, Step 406: train/loss = 0.5754097104072571, train/raw-loss = 0.45103710889816284, train/logprobs = tensor([[-0.7522, -2.2320],
        [-0.8107, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041457533836364746
Epoch 0, Step 407: train/loss = 0.6070311665534973, train/raw-loss = 0.5087476968765259, train/logprobs = tensor([[-0.3406, -1.7595],
        [-0.3853, -0.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032761141657829285
Epoch 0, Step 408: train/loss = 0.5066768527030945, train/raw-loss = 0.39598947763442993, train/logprobs = tensor([[-0.4887, -2.7916],
        [-0.5353, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03689579293131828
Epoch 0, Step 409: train/loss = 0.5656490325927734, train/raw-loss = 0.4757031500339508, train/logprobs = tensor([[-0.5291, -1.5861],
        [-0.6546, -0.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029981959611177444
Epoch 0, Step 410: train/loss = 0.6443604230880737, train/raw-loss = 0.539669930934906, train/logprobs = tensor([[-0.5083, -1.5445],
        [-0.4976, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034896839410066605
Epoch 0, Step 411: train/loss = 0.6636995077133179, train/raw-loss = 0.5803794860839844, train/logprobs = tensor([[-0.5188, -1.1640],
        [-0.4909, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027773350477218628
Epoch 0, Step 412: train/loss = 0.5903493165969849, train/raw-loss = 0.47590774297714233, train/logprobs = tensor([[-0.9233, -1.8805],
        [-0.9865, -0.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03814717009663582
Epoch 0, Step 413: train/loss = 0.5898329615592957, train/raw-loss = 0.48451370000839233, train/logprobs = tensor([[-0.7031, -1.5707],
        [-0.8893, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03510643169283867
Epoch 0, Step 414: train/loss = 0.5677804946899414, train/raw-loss = 0.4602958559989929, train/logprobs = tensor([[-0.7979, -3.9844],
        [-0.9978, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03582821786403656
Epoch 0, Step 415: train/loss = 0.6148107647895813, train/raw-loss = 0.5134161710739136, train/logprobs = tensor([[-0.7453, -1.9108],
        [-0.7534, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033798202872276306
Epoch 0, Step 416: train/loss = 0.471088171005249, train/raw-loss = 0.3620065748691559, train/logprobs = tensor([[-0.6628, -5.9345],
        [-0.8110, -2.1010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03636053204536438
Epoch 0, Step 417: train/loss = 0.6732833385467529, train/raw-loss = 0.587716817855835, train/logprobs = tensor([[-0.3895, -1.1885],
        [-0.3238, -0.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028522180393338203
Epoch 0, Step 418: train/loss = 0.6039249300956726, train/raw-loss = 0.48976343870162964, train/logprobs = tensor([[-0.5150, -2.3873],
        [-0.4837, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03805382549762726
Epoch 0, Step 419: train/loss = 0.5126546025276184, train/raw-loss = 0.40514427423477173, train/logprobs = tensor([[-0.5256, -3.0398],
        [-0.5566, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035836778581142426
Epoch 0, Step 420: train/loss = 0.5866694450378418, train/raw-loss = 0.47481951117515564, train/logprobs = tensor([[-0.7158, -2.0088],
        [-0.8130, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03728330880403519
Epoch 0, Step 421: train/loss = 0.6639738082885742, train/raw-loss = 0.5602517127990723, train/logprobs = tensor([[-0.5993, -1.3033],
        [-0.5612, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03457405045628548
Epoch 0, Step 422: train/loss = 0.6488761305809021, train/raw-loss = 0.5374649167060852, train/logprobs = tensor([[-0.7208, -1.6124],
        [-0.6927, -0.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03713706135749817
Epoch 0, Step 423: train/loss = 0.5846083164215088, train/raw-loss = 0.48863208293914795, train/logprobs = tensor([[-0.6101, -4.1077],
        [-0.5231, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03199208155274391
Epoch 0, Step 424: train/loss = 0.5548748970031738, train/raw-loss = 0.4351329505443573, train/logprobs = tensor([[-0.8271, -2.7788],
        [-0.8549, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03991398587822914
Epoch 0, Step 425: train/loss = 0.622399091720581, train/raw-loss = 0.5226178169250488, train/logprobs = tensor([[-0.5704, -1.2872],
        [-0.6028, -0.5206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03326043486595154
Epoch 0, Step 426: train/loss = 0.55220627784729, train/raw-loss = 0.444358229637146, train/logprobs = tensor([[-0.6539, -2.6267],
        [-0.5802, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03594934940338135
Epoch 0, Step 427: train/loss = 0.6239190101623535, train/raw-loss = 0.5407236218452454, train/logprobs = tensor([[-0.6461, -1.4873],
        [-0.5796, -0.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027731820940971375
Epoch 0, Step 428: train/loss = 0.6110882759094238, train/raw-loss = 0.4998326003551483, train/logprobs = tensor([[-0.3450, -1.7341],
        [-0.3441, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03708522766828537
Epoch 0, Step 429: train/loss = 0.659386396408081, train/raw-loss = 0.5283257365226746, train/logprobs = tensor([[-0.7438, -1.5456],
        [-0.6860, -0.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0436868816614151
Epoch 0, Step 430: train/loss = 0.5666040778160095, train/raw-loss = 0.471445769071579, train/logprobs = tensor([[-0.6830, -3.6897],
        [-0.7674, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03171943128108978
Epoch 0, Step 431: train/loss = 0.725062370300293, train/raw-loss = 0.6217995285987854, train/logprobs = tensor([[-0.8361, -1.2334],
        [-0.5407, -0.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03442094847559929
Epoch 0, Step 432: train/loss = 0.6499195694923401, train/raw-loss = 0.5593070387840271, train/logprobs = tensor([[-0.6620, -1.2710],
        [-0.6543, -0.5210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03020418807864189
Epoch 0, Step 433: train/loss = 0.7856457829475403, train/raw-loss = 0.6924854516983032, train/logprobs = tensor([[-0.8613, -0.8128],
        [-0.5455, -0.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031053442507982254
Epoch 0, Step 434: train/loss = 0.6848386526107788, train/raw-loss = 0.5761419534683228, train/logprobs = tensor([[-0.8042, -1.5528],
        [-0.5353, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03623223304748535
Epoch 0, Step 435: train/loss = 0.6603988409042358, train/raw-loss = 0.538486659526825, train/logprobs = tensor([[-0.4819, -1.2698],
        [-0.4950, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04063739627599716
Epoch 0, Step 436: train/loss = 0.5928800106048584, train/raw-loss = 0.4855044484138489, train/logprobs = tensor([[-0.4957, -1.5014],
        [-0.7841, -0.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03579186648130417
Epoch 0, Step 437: train/loss = 0.42511793971061707, train/raw-loss = 0.3125993609428406, train/logprobs = tensor([[-0.5738, -5.4566],
        [-0.7115, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03750619292259216
Epoch 0, Step 438: train/loss = 0.6051241159439087, train/raw-loss = 0.5151951909065247, train/logprobs = tensor([[-0.4992, -1.4315],
        [-0.5151, -0.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02997630462050438
Epoch 0, Step 439: train/loss = 0.6017633676528931, train/raw-loss = 0.500889778137207, train/logprobs = tensor([[-0.5835, -1.3630],
        [-0.6317, -0.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03362451121211052
Epoch 0, Step 440: train/loss = 0.5722336769104004, train/raw-loss = 0.4443627893924713, train/logprobs = tensor([[-0.5976, -4.3058],
        [-0.6995, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042623624205589294
Epoch 0, Step 441: train/loss = 0.6626465320587158, train/raw-loss = 0.5670039653778076, train/logprobs = tensor([[-0.4848, -1.0484],
        [-0.5019, -0.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03188086301088333
Epoch 0, Step 442: train/loss = 0.7018128037452698, train/raw-loss = 0.6294395327568054, train/logprobs = tensor([[-0.4950, -1.0653],
        [-0.3714, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024124421179294586
Epoch 0, Step 443: train/loss = 0.5854800343513489, train/raw-loss = 0.4952681064605713, train/logprobs = tensor([[-0.4619, -2.3650],
        [-0.4998, -0.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030070645734667778
Epoch 0, Step 444: train/loss = 0.6188022494316101, train/raw-loss = 0.5236709117889404, train/logprobs = tensor([[-0.5367, -2.2798],
        [-0.4286, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0317104309797287
Epoch 0, Step 445: train/loss = 0.6672219038009644, train/raw-loss = 0.5838951468467712, train/logprobs = tensor([[-0.3787, -1.1049],
        [-0.3558, -0.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02777557261288166
Epoch 0, Step 446: train/loss = 0.6502744555473328, train/raw-loss = 0.534187912940979, train/logprobs = tensor([[-0.6729, -1.2883],
        [-0.6283, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038695499300956726
Epoch 0, Step 447: train/loss = 0.5071999430656433, train/raw-loss = 0.39040565490722656, train/logprobs = tensor([[-0.6318, -2.6091],
        [-0.6348, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893143683671951
Epoch 0, Step 448: train/loss = 0.5938396453857422, train/raw-loss = 0.4987231194972992, train/logprobs = tensor([[-0.9854, -2.3378],
        [-0.7744, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031705498695373535
Epoch 0, Step 449: train/loss = 0.5664193630218506, train/raw-loss = 0.4473397731781006, train/logprobs = tensor([[-0.5833, -2.0177],
        [-0.6393, -0.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0396931990981102
Epoch 0, Step 450: train/loss = 0.5776425004005432, train/raw-loss = 0.46659475564956665, train/logprobs = tensor([[-0.4939, -2.9102],
        [-0.4690, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03701591491699219
Epoch 0, Step 451: train/loss = 0.5784233808517456, train/raw-loss = 0.4655768871307373, train/logprobs = tensor([[-0.5493, -1.7984],
        [-0.5505, -0.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03761550784111023
Epoch 0, Step 452: train/loss = 0.5288048982620239, train/raw-loss = 0.4003744125366211, train/logprobs = tensor([[-0.6395, -4.4698],
        [-0.7014, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04281017184257507
Epoch 0, Step 453: train/loss = 0.6670086979866028, train/raw-loss = 0.5680098533630371, train/logprobs = tensor([[-0.5727, -1.3749],
        [-0.4337, -0.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299960866570473
Epoch 0, Step 454: train/loss = 0.6131445169448853, train/raw-loss = 0.49539119005203247, train/logprobs = tensor([[-0.8217, -3.5288],
        [-0.6654, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925110772252083
Epoch 0, Step 455: train/loss = 0.6444821357727051, train/raw-loss = 0.5284852385520935, train/logprobs = tensor([[-0.6645, -1.5921],
        [-0.5462, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038665637373924255
Epoch 0, Step 456: train/loss = 0.5898232460021973, train/raw-loss = 0.47964945435523987, train/logprobs = tensor([[-0.5010, -3.9290],
        [-0.5506, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03672460466623306
Epoch 0, Step 457: train/loss = 0.6061423420906067, train/raw-loss = 0.48884662985801697, train/logprobs = tensor([[-0.5337, -1.7470],
        [-0.5891, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03909856453537941
Epoch 0, Step 458: train/loss = 0.6153994798660278, train/raw-loss = 0.5085562467575073, train/logprobs = tensor([[-0.8559, -2.5407],
        [-0.5958, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03561440110206604
Epoch 0, Step 459: train/loss = 0.5112540125846863, train/raw-loss = 0.38861358165740967, train/logprobs = tensor([[-0.6823, -2.7621],
        [-0.7078, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04088014364242554
Epoch 0, Step 460: train/loss = 0.5938559770584106, train/raw-loss = 0.47043830156326294, train/logprobs = tensor([[-0.5124, -1.8215],
        [-0.5809, -0.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04113922640681267
Epoch 0, Step 461: train/loss = 0.59209144115448, train/raw-loss = 0.4890022277832031, train/logprobs = tensor([[-0.3463, -1.8505],
        [-0.3286, -0.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03436307609081268
Epoch 0, Step 462: train/loss = 0.6235538721084595, train/raw-loss = 0.5223640203475952, train/logprobs = tensor([[-0.7152, -1.8109],
        [-0.5204, -0.5325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03372994437813759
Epoch 0, Step 463: train/loss = 0.6408980488777161, train/raw-loss = 0.5428368449211121, train/logprobs = tensor([[-0.4524, -1.2357],
        [-0.3720, -0.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032687071710824966
Epoch 0, Step 464: train/loss = 0.8348104357719421, train/raw-loss = 0.7136363387107849, train/logprobs = tensor([[-1.3343, -1.8383],
        [-0.5720, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04039134830236435
Epoch 0, Step 465: train/loss = 0.6403285264968872, train/raw-loss = 0.5233744382858276, train/logprobs = tensor([[-0.6092, -1.6442],
        [-0.5677, -0.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03898468241095543
Epoch 0, Step 466: train/loss = 0.5777920484542847, train/raw-loss = 0.44182994961738586, train/logprobs = tensor([[-0.7170, -2.5690],
        [-0.6013, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045320697128772736
Epoch 0, Step 467: train/loss = 0.5695942640304565, train/raw-loss = 0.4462921619415283, train/logprobs = tensor([[-0.6196, -2.2051],
        [-0.7854, -0.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04110070317983627
Epoch 0, Step 468: train/loss = 0.6218326091766357, train/raw-loss = 0.5157725811004639, train/logprobs = tensor([[-0.4980, -1.4437],
        [-0.4886, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03535333275794983
Epoch 0, Step 469: train/loss = 0.6153228282928467, train/raw-loss = 0.5164704918861389, train/logprobs = tensor([[-0.5595, -1.2569],
        [-0.5940, -0.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03295077010989189
Epoch 0, Step 470: train/loss = 0.7381213307380676, train/raw-loss = 0.6200549006462097, train/logprobs = tensor([[-0.5886, -0.9258],
        [-0.4852, -0.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03935548663139343
Epoch 0, Step 471: train/loss = 0.6037174463272095, train/raw-loss = 0.4412279427051544, train/logprobs = tensor([[-0.7290, -2.1705],
        [-0.7007, -0.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05416317284107208
Epoch 0, Step 472: train/loss = 0.7052146196365356, train/raw-loss = 0.6153694987297058, train/logprobs = tensor([[-0.5687, -0.6409],
        [-0.6007, -0.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029948364943265915
Epoch 0, Step 473: train/loss = 0.5795856714248657, train/raw-loss = 0.47006890177726746, train/logprobs = tensor([[-0.5162, -1.8233],
        [-0.4906, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036505576223134995
Epoch 0, Step 474: train/loss = 0.625140905380249, train/raw-loss = 0.5239838361740112, train/logprobs = tensor([[-0.5640, -1.6750],
        [-0.4235, -0.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03371904790401459
Epoch 0, Step 475: train/loss = 0.5185607075691223, train/raw-loss = 0.39376360177993774, train/logprobs = tensor([[-0.6249, -2.7848],
        [-0.6410, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04159903526306152
Epoch 0, Step 476: train/loss = 0.681896448135376, train/raw-loss = 0.5700749158859253, train/logprobs = tensor([[-0.8478, -1.1879],
        [-0.8665, -0.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0372738391160965
Epoch 0, Step 477: train/loss = 0.4909786880016327, train/raw-loss = 0.36373817920684814, train/logprobs = tensor([[-0.5662, -3.5323],
        [-0.5833, -0.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042413514107465744
Epoch 0, Step 478: train/loss = 0.5591740012168884, train/raw-loss = 0.44066524505615234, train/logprobs = tensor([[-0.6603, -4.1131],
        [-0.8007, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03950292244553566
Epoch 0, Step 479: train/loss = 0.5508785247802734, train/raw-loss = 0.4032336473464966, train/logprobs = tensor([[-0.7375, -2.4836],
        [-0.7667, -0.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04921495169401169
Epoch 0, Step 480: train/loss = 0.6356139183044434, train/raw-loss = 0.527478039264679, train/logprobs = tensor([[-0.5005, -1.7211],
        [-0.5024, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03604528307914734
Epoch 0, Step 481: train/loss = 0.655906081199646, train/raw-loss = 0.5391834378242493, train/logprobs = tensor([[-0.6776, -1.5860],
        [-0.6376, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038907550275325775
Epoch 0, Step 482: train/loss = 0.647750735282898, train/raw-loss = 0.5436941981315613, train/logprobs = tensor([[-0.5242, -2.2267],
        [-0.3930, -0.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03468551114201546
Epoch 0, Step 483: train/loss = 0.5159231424331665, train/raw-loss = 0.38732385635375977, train/logprobs = tensor([[-0.5746, -2.4409],
        [-0.6047, -0.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04286644607782364
Epoch 0, Step 484: train/loss = 0.5144460201263428, train/raw-loss = 0.4045175015926361, train/logprobs = tensor([[-0.5481, -2.9735],
        [-0.5114, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664283826947212
Epoch 0, Step 485: train/loss = 0.5358996391296387, train/raw-loss = 0.4175640344619751, train/logprobs = tensor([[-0.8295, -2.5745],
        [-0.8843, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039445213973522186
Epoch 0, Step 486: train/loss = 0.5460463762283325, train/raw-loss = 0.4201838970184326, train/logprobs = tensor([[-0.5859, -2.7066],
        [-0.6757, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041954156011343
Epoch 0, Step 487: train/loss = 0.6864972114562988, train/raw-loss = 0.5905163884162903, train/logprobs = tensor([[-0.6378, -1.1429],
        [-0.4843, -0.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031993597745895386
Epoch 0, Step 488: train/loss = 0.6827411651611328, train/raw-loss = 0.5655732154846191, train/logprobs = tensor([[-1.0253, -3.2747],
        [-0.8784, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03905600681900978
Epoch 0, Step 489: train/loss = 0.5899993181228638, train/raw-loss = 0.46933484077453613, train/logprobs = tensor([[-0.6602, -1.5749],
        [-0.7577, -0.4176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04022149741649628
Epoch 0, Step 490: train/loss = 0.5114912986755371, train/raw-loss = 0.3810080885887146, train/logprobs = tensor([[-0.6607, -3.3873],
        [-0.7492, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043494414538145065
Epoch 0, Step 491: train/loss = 0.7317942380905151, train/raw-loss = 0.6390822529792786, train/logprobs = tensor([[-0.6221, -0.7644],
        [-0.5281, -0.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030903995037078857
Epoch 0, Step 492: train/loss = 0.7327684164047241, train/raw-loss = 0.6129444241523743, train/logprobs = tensor([[-1.1597, -2.4490],
        [-0.7288, -0.9835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03994134068489075
Epoch 0, Step 493: train/loss = 0.5280089378356934, train/raw-loss = 0.39033615589141846, train/logprobs = tensor([[-0.6548, -4.5703],
        [-0.7924, -0.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045890942215919495
Epoch 0, Step 494: train/loss = 0.6759647130966187, train/raw-loss = 0.5296865701675415, train/logprobs = tensor([[-0.5891, -1.6676],
        [-0.5116, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04875938221812248
Epoch 0, Step 495: train/loss = 0.6105306148529053, train/raw-loss = 0.5020595192909241, train/logprobs = tensor([[-0.4683, -1.3612],
        [-0.4858, -0.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03615700826048851
Epoch 0, Step 496: train/loss = 0.5654371976852417, train/raw-loss = 0.4503067433834076, train/logprobs = tensor([[-0.5700, -2.1995],
        [-0.6116, -0.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0383768193423748
Epoch 0, Step 497: train/loss = 0.6062476634979248, train/raw-loss = 0.49172013998031616, train/logprobs = tensor([[-0.5638, -1.4546],
        [-0.6205, -0.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038175854831933975
Epoch 0, Step 498: train/loss = 0.6049917340278625, train/raw-loss = 0.48341500759124756, train/logprobs = tensor([[-0.5512, -2.6273],
        [-0.5030, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04052558168768883
Epoch 0, Step 499: train/loss = 0.6191694140434265, train/raw-loss = 0.503973126411438, train/logprobs = tensor([[-0.7647, -1.7664],
        [-0.6824, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03839876875281334
Epoch 0, Step 500: train/loss = 0.7001179456710815, train/raw-loss = 0.590276300907135, train/logprobs = tensor([[-0.5886, -1.1772],
        [-0.5146, -0.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036613889038562775
Epoch 0, Step 501: train/loss = 0.6717102527618408, train/raw-loss = 0.5520873665809631, train/logprobs = tensor([[-0.8872, -1.4615],
        [-0.8694, -0.7447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039874300360679626
Epoch 0, Step 502: train/loss = 0.5037384033203125, train/raw-loss = 0.3921678960323334, train/logprobs = tensor([[-0.5688, -3.0437],
        [-0.6173, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03719018027186394
Epoch 0, Step 503: train/loss = 0.7412062883377075, train/raw-loss = 0.6298688650131226, train/logprobs = tensor([[-0.7030, -1.0714],
        [-0.4956, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037112489342689514
Epoch 0, Step 504: train/loss = 0.6903741359710693, train/raw-loss = 0.5824861526489258, train/logprobs = tensor([[-0.8856, -1.3603],
        [-0.7083, -0.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03596264123916626
Epoch 0, Step 505: train/loss = 0.5657790303230286, train/raw-loss = 0.4496544897556305, train/logprobs = tensor([[-0.5556, -2.2208],
        [-0.5281, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038708172738552094
Epoch 0, Step 506: train/loss = 0.740173876285553, train/raw-loss = 0.651980996131897, train/logprobs = tensor([[-0.5357, -0.6099],
        [-0.4418, -0.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029397619888186455
Epoch 0, Step 507: train/loss = 0.6444506645202637, train/raw-loss = 0.5393067598342896, train/logprobs = tensor([[-0.7682, -1.6399],
        [-0.6727, -0.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035047974437475204
Epoch 0, Step 508: train/loss = 0.6364443302154541, train/raw-loss = 0.5251150131225586, train/logprobs = tensor([[-0.7921, -2.5163],
        [-0.6377, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03710976243019104
Epoch 0, Step 509: train/loss = 0.732949435710907, train/raw-loss = 0.6540025472640991, train/logprobs = tensor([[-0.8803, -1.0562],
        [-0.6033, -0.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026315616443753242
Epoch 0, Step 510: train/loss = 0.5446290969848633, train/raw-loss = 0.4167220890522003, train/logprobs = tensor([[-0.7472, -4.2143],
        [-0.7237, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042635656893253326
Epoch 0, Step 511: train/loss = 0.6408531069755554, train/raw-loss = 0.5212479829788208, train/logprobs = tensor([[-0.4659, -2.8395],
        [-0.4455, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03986835852265358
Epoch 0, Step 512: train/loss = 0.7509718537330627, train/raw-loss = 0.6307622194290161, train/logprobs = tensor([[-1.1825, -2.4212],
        [-0.6377, -0.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04006987810134888
Epoch 0, Step 513: train/loss = 0.5245131254196167, train/raw-loss = 0.4150851368904114, train/logprobs = tensor([[-0.5879, -3.0864],
        [-0.5492, -0.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03647598624229431
Epoch 0, Step 514: train/loss = 0.6183618903160095, train/raw-loss = 0.5055869817733765, train/logprobs = tensor([[-0.5946, -1.9785],
        [-0.7200, -0.5738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03759164735674858
Epoch 0, Step 515: train/loss = 0.6383392810821533, train/raw-loss = 0.540169358253479, train/logprobs = tensor([[-0.5465, -1.4156],
        [-0.5942, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03272329643368721
Epoch 0, Step 516: train/loss = 0.6819738149642944, train/raw-loss = 0.578559160232544, train/logprobs = tensor([[-0.5067, -1.0389],
        [-0.4781, -0.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03447156026959419
Epoch 0, Step 517: train/loss = 0.7111086249351501, train/raw-loss = 0.6062214374542236, train/logprobs = tensor([[-1.1888, -2.1825],
        [-0.6186, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03496239334344864
Epoch 0, Step 518: train/loss = 0.592110812664032, train/raw-loss = 0.5034937858581543, train/logprobs = tensor([[-0.4639, -1.9347],
        [-0.4442, -0.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029539011418819427
Epoch 0, Step 519: train/loss = 0.5461663007736206, train/raw-loss = 0.4295271933078766, train/logprobs = tensor([[-0.8073, -5.0436],
        [-0.7320, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038879696279764175
Epoch 0, Step 520: train/loss = 0.5773448944091797, train/raw-loss = 0.47492924332618713, train/logprobs = tensor([[-0.5209, -3.0985],
        [-0.4993, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034138552844524384
Epoch 0, Step 521: train/loss = 0.47247278690338135, train/raw-loss = 0.3525654375553131, train/logprobs = tensor([[-0.5448, -2.9569],
        [-0.5785, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03996913135051727
Epoch 0, Step 522: train/loss = 0.652104377746582, train/raw-loss = 0.5593058466911316, train/logprobs = tensor([[-0.5068, -1.0918],
        [-0.5330, -0.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030932854861021042
Epoch 0, Step 523: train/loss = 0.5878967642784119, train/raw-loss = 0.4780454933643341, train/logprobs = tensor([[-0.6669, -1.4531],
        [-0.8211, -0.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03661710023880005
Epoch 0, Step 524: train/loss = 0.5352823138237, train/raw-loss = 0.41156214475631714, train/logprobs = tensor([[-0.6613, -2.9654],
        [-0.6019, -0.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04124007001519203
Epoch 0, Step 525: train/loss = 0.5552775859832764, train/raw-loss = 0.4351770579814911, train/logprobs = tensor([[-0.6433, -2.4908],
        [-0.5582, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0400334931910038
Epoch 0, Step 526: train/loss = 0.6774671077728271, train/raw-loss = 0.575864315032959, train/logprobs = tensor([[-0.5841, -1.2434],
        [-0.4644, -0.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386758640408516
Epoch 0, Step 527: train/loss = 0.6340285539627075, train/raw-loss = 0.5417596101760864, train/logprobs = tensor([[-0.4962, -1.4493],
        [-0.5052, -0.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030756300315260887
Epoch 0, Step 528: train/loss = 0.5635257959365845, train/raw-loss = 0.4796362817287445, train/logprobs = tensor([[-0.5270, -3.2009],
        [-0.5607, -0.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02796318009495735
Epoch 0, Step 529: train/loss = 0.5865441560745239, train/raw-loss = 0.46321552991867065, train/logprobs = tensor([[-0.8263, -1.8374],
        [-0.7388, -0.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041109539568424225
Epoch 0, Step 530: train/loss = 0.619445264339447, train/raw-loss = 0.5127147436141968, train/logprobs = tensor([[-0.5820, -1.5324],
        [-0.6215, -0.5618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03557682782411575
Epoch 0, Step 531: train/loss = 0.5806398391723633, train/raw-loss = 0.4782053828239441, train/logprobs = tensor([[-0.5348, -2.6015],
        [-0.5695, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03414482623338699
Epoch 0, Step 532: train/loss = 0.5604393482208252, train/raw-loss = 0.4521932005882263, train/logprobs = tensor([[-0.4289, -1.9073],
        [-0.3916, -0.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03608205169439316
Epoch 0, Step 533: train/loss = 0.6616926193237305, train/raw-loss = 0.5563338994979858, train/logprobs = tensor([[-0.7253, -1.1656],
        [-0.7451, -0.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03511958569288254
Epoch 0, Step 534: train/loss = 0.4873422682285309, train/raw-loss = 0.3704105317592621, train/logprobs = tensor([[-0.6021, -3.3694],
        [-0.5848, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0389772467315197
Epoch 0, Step 535: train/loss = 0.5495316982269287, train/raw-loss = 0.4224085807800293, train/logprobs = tensor([[-0.8655, -3.2506],
        [-0.6776, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042374372482299805
Epoch 0, Step 536: train/loss = 0.5098987817764282, train/raw-loss = 0.3885260820388794, train/logprobs = tensor([[-0.7762, -7.6369],
        [-0.5077, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04045756161212921
Epoch 0, Step 537: train/loss = 0.5974433422088623, train/raw-loss = 0.49301621317863464, train/logprobs = tensor([[-0.7982, -1.5753],
        [-0.7805, -0.4359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03480903059244156
Epoch 0, Step 538: train/loss = 0.6722305417060852, train/raw-loss = 0.5645276308059692, train/logprobs = tensor([[-0.7375, -1.4057],
        [-0.6472, -0.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03590095788240433
Epoch 0, Step 539: train/loss = 0.7699187994003296, train/raw-loss = 0.6558084487915039, train/logprobs = tensor([[-0.9437, -1.3741],
        [-0.4473, -0.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038036786019802094
Epoch 0, Step 540: train/loss = 0.6854656934738159, train/raw-loss = 0.5992178916931152, train/logprobs = tensor([[-0.6119, -1.1177],
        [-0.4737, -0.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028749261051416397
Epoch 0, Step 541: train/loss = 0.6001284122467041, train/raw-loss = 0.49002355337142944, train/logprobs = tensor([[-0.7038, -1.6471],
        [-0.7404, -0.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03670162335038185
Epoch 0, Step 542: train/loss = 0.5470795631408691, train/raw-loss = 0.43379074335098267, train/logprobs = tensor([[-0.5802, -3.1244],
        [-0.6419, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03776293992996216
Epoch 0, Step 543: train/loss = 0.6807777285575867, train/raw-loss = 0.5944085717201233, train/logprobs = tensor([[-0.4473, -0.9412],
        [-0.4021, -0.3855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028789732605218887
Epoch 0, Step 544: train/loss = 0.6461358070373535, train/raw-loss = 0.5524603128433228, train/logprobs = tensor([[-0.7395, -1.1874],
        [-0.6588, -0.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031225157901644707
Epoch 0, Step 545: train/loss = 0.45891231298446655, train/raw-loss = 0.35526615381240845, train/logprobs = tensor([[-0.9364, -5.6535],
        [-0.9773, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034548722207546234
Epoch 0, Step 546: train/loss = 0.5611485242843628, train/raw-loss = 0.45307520031929016, train/logprobs = tensor([[-0.6121, -2.3623],
        [-0.7093, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03602444380521774
Epoch 0, Step 547: train/loss = 0.7306760549545288, train/raw-loss = 0.635301411151886, train/logprobs = tensor([[-2.2464, -6.3263],
        [-1.3458, -1.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031791530549526215
Epoch 0, Step 548: train/loss = 0.6864646077156067, train/raw-loss = 0.6019550561904907, train/logprobs = tensor([[-0.6817, -1.1550],
        [-0.5514, -0.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028169861063361168
Epoch 0, Step 549: train/loss = 0.6049456596374512, train/raw-loss = 0.5037245154380798, train/logprobs = tensor([[-0.5280, -1.3419],
        [-0.5585, -0.3804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03374038636684418
Epoch 0, Step 550: train/loss = 0.5774905681610107, train/raw-loss = 0.49264436960220337, train/logprobs = tensor([[-0.5871, -1.6236],
        [-0.5784, -0.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028282079845666885
Epoch 0, Step 551: train/loss = 0.7371934652328491, train/raw-loss = 0.6264114379882812, train/logprobs = tensor([[-1.0287, -1.4326],
        [-0.6177, -0.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036927349865436554
Epoch 0, Step 552: train/loss = 0.5627158284187317, train/raw-loss = 0.47240281105041504, train/logprobs = tensor([[-0.6818, -1.9632],
        [-0.6571, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030104350298643112
Epoch 0, Step 553: train/loss = 0.7472740411758423, train/raw-loss = 0.6730411648750305, train/logprobs = tensor([[-0.4016, -0.2504],
        [-0.3954, -0.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02474428527057171
Epoch 0, Step 554: train/loss = 0.5917370319366455, train/raw-loss = 0.4985913932323456, train/logprobs = tensor([[-0.7432, -1.8237],
        [-0.6629, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03104856237769127
Epoch 0, Step 555: train/loss = 0.48404043912887573, train/raw-loss = 0.39157238602638245, train/logprobs = tensor([[-0.4179, -2.4703],
        [-0.4852, -0.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030822673812508583
Epoch 0, Step 556: train/loss = 0.6233606338500977, train/raw-loss = 0.5331431031227112, train/logprobs = tensor([[-0.5468, -1.4123],
        [-0.5708, -0.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030072519555687904
Epoch 0, Step 557: train/loss = 0.6583055257797241, train/raw-loss = 0.5918265581130981, train/logprobs = tensor([[-0.3778, -0.9573],
        [-0.4040, -0.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022159641608595848
Epoch 0, Step 558: train/loss = 0.7125998139381409, train/raw-loss = 0.6391373872756958, train/logprobs = tensor([[-0.5884, -0.7617],
        [-0.4731, -0.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02448747307062149
Epoch 0, Step 559: train/loss = 0.5001206398010254, train/raw-loss = 0.39008915424346924, train/logprobs = tensor([[-0.8358, -2.5143],
        [-1.0251, -0.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03667713701725006
Epoch 0, Step 560: train/loss = 0.6213915348052979, train/raw-loss = 0.5398486256599426, train/logprobs = tensor([[-0.6153, -1.3461],
        [-0.5981, -0.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027180960401892662
Epoch 0, Step 561: train/loss = 0.6595907211303711, train/raw-loss = 0.5814992785453796, train/logprobs = tensor([[-0.6978, -1.2573],
        [-0.5255, -0.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026030488312244415
Epoch 0, Step 562: train/loss = 0.5089552402496338, train/raw-loss = 0.3911866545677185, train/logprobs = tensor([[-0.6262, -2.8227],
        [-0.6346, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925619274377823
Epoch 0, Step 563: train/loss = 0.6235300898551941, train/raw-loss = 0.537319004535675, train/logprobs = tensor([[-0.5436, -1.1487],
        [-0.5739, -0.3433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028737036511301994
Epoch 0, Step 564: train/loss = 0.4592636227607727, train/raw-loss = 0.3511367738246918, train/logprobs = tensor([[-0.9135, -5.5248],
        [-0.8830, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03604227304458618
Epoch 0, Step 565: train/loss = 0.5482929348945618, train/raw-loss = 0.46097901463508606, train/logprobs = tensor([[-0.6908, -1.8194],
        [-0.7871, -0.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02910464257001877
Epoch 0, Step 566: train/loss = 0.566399097442627, train/raw-loss = 0.4731096625328064, train/logprobs = tensor([[-0.8854, -4.3237],
        [-0.8419, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031096458435058594
Epoch 0, Step 567: train/loss = 0.6166552305221558, train/raw-loss = 0.5335408449172974, train/logprobs = tensor([[-0.4865, -1.9771],
        [-0.3901, -0.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027704816311597824
Epoch 0, Step 568: train/loss = 0.5157995820045471, train/raw-loss = 0.41548681259155273, train/logprobs = tensor([[-0.8215, -5.3417],
        [-0.8103, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03343760967254639
Epoch 0, Step 569: train/loss = 0.6579515337944031, train/raw-loss = 0.5694684982299805, train/logprobs = tensor([[-0.6514, -1.2984],
        [-0.5396, -0.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029494360089302063
Epoch 0, Step 570: train/loss = 0.5806977152824402, train/raw-loss = 0.49284422397613525, train/logprobs = tensor([[-0.3798, -2.9907],
        [-0.3324, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029284492135047913
Epoch 0, Step 571: train/loss = 0.6447061896324158, train/raw-loss = 0.5520773530006409, train/logprobs = tensor([[-1.1462, -2.1611],
        [-0.8238, -0.6182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0308762826025486
Epoch 0, Step 572: train/loss = 0.6719338893890381, train/raw-loss = 0.5752482414245605, train/logprobs = tensor([[-0.5530, -1.0290],
        [-0.5078, -0.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03222857043147087
Epoch 0, Step 573: train/loss = 0.5509043335914612, train/raw-loss = 0.45120418071746826, train/logprobs = tensor([[-0.6559, -2.2211],
        [-0.7791, -0.4823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033233389258384705
Epoch 0, Step 574: train/loss = 0.5862855315208435, train/raw-loss = 0.5000386238098145, train/logprobs = tensor([[-0.9238, -2.3944],
        [-0.9714, -0.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02874898351728916
Epoch 0, Step 575: train/loss = 0.5311473608016968, train/raw-loss = 0.4417942762374878, train/logprobs = tensor([[-0.5930, -3.4404],
        [-0.5127, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02978435903787613
Epoch 0, Step 576: train/loss = 0.49474865198135376, train/raw-loss = 0.4017446041107178, train/logprobs = tensor([[-0.5537, -4.9199],
        [-0.6475, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031001366674900055
Epoch 0, Step 577: train/loss = 0.570960283279419, train/raw-loss = 0.4813457131385803, train/logprobs = tensor([[-0.7127, -1.8542],
        [-0.7522, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029871532693505287
Epoch 0, Step 578: train/loss = 0.5488146543502808, train/raw-loss = 0.4680158495903015, train/logprobs = tensor([[-0.7205, -1.6865],
        [-0.8592, -0.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02693292871117592
Epoch 0, Step 579: train/loss = 0.5418004989624023, train/raw-loss = 0.45219892263412476, train/logprobs = tensor([[-0.5282, -2.0212],
        [-0.5907, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02986718900501728
Epoch 0, Step 580: train/loss = 0.6599845886230469, train/raw-loss = 0.5707411766052246, train/logprobs = tensor([[-0.7567, -1.9358],
        [-0.5532, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029747791588306427
Epoch 0, Step 581: train/loss = 0.6789470911026001, train/raw-loss = 0.6062848567962646, train/logprobs = tensor([[-0.6726, -1.4015],
        [-0.5278, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02422075718641281
Epoch 0, Step 582: train/loss = 0.46677571535110474, train/raw-loss = 0.3858735263347626, train/logprobs = tensor([[-0.8220, -4.7925],
        [-0.8713, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02696739137172699
Epoch 0, Step 583: train/loss = 0.6341174244880676, train/raw-loss = 0.563111424446106, train/logprobs = tensor([[-0.4971, -1.3074],
        [-0.4422, -0.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0236686822026968
Epoch 0, Step 584: train/loss = 0.6087744235992432, train/raw-loss = 0.5187124609947205, train/logprobs = tensor([[-0.4777, -1.5191],
        [-0.4996, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03002067282795906
Epoch 0, Step 585: train/loss = 0.6423131227493286, train/raw-loss = 0.5439942479133606, train/logprobs = tensor([[-0.6879, -1.5654],
        [-0.5929, -0.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03277295082807541
Epoch 0, Step 586: train/loss = 0.5166738629341125, train/raw-loss = 0.43172985315322876, train/logprobs = tensor([[-0.6151, -2.7813],
        [-0.6175, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028314655646681786
Epoch 0, Step 587: train/loss = 0.5593547821044922, train/raw-loss = 0.48613157868385315, train/logprobs = tensor([[-0.4425, -1.4744],
        [-0.4945, -0.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024407733231782913
Epoch 0, Step 588: train/loss = 0.5796599388122559, train/raw-loss = 0.505242645740509, train/logprobs = tensor([[-0.5922, -4.0092],
        [-0.6686, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02480578050017357
Epoch 0, Step 589: train/loss = 0.4719323515892029, train/raw-loss = 0.3609863817691803, train/logprobs = tensor([[-0.7394, -4.3445],
        [-0.8245, -1.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03698199242353439
Epoch 0, Step 590: train/loss = 0.6393275260925293, train/raw-loss = 0.5475205779075623, train/logprobs = tensor([[-0.7941, -1.5571],
        [-0.6843, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030602313578128815
Epoch 0, Step 591: train/loss = 0.7202377319335938, train/raw-loss = 0.6477401256561279, train/logprobs = tensor([[-0.5256, -0.7244],
        [-0.4946, -0.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024165861308574677
Epoch 0, Step 592: train/loss = 0.6624070405960083, train/raw-loss = 0.5831419229507446, train/logprobs = tensor([[-1.4236, -2.1564],
        [-1.0161, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0264216810464859
Epoch 0, Step 593: train/loss = 0.6442960500717163, train/raw-loss = 0.5731155872344971, train/logprobs = tensor([[-0.4107, -1.0312],
        [-0.4036, -0.3779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023726820945739746
Epoch 0, Step 594: train/loss = 0.5367730855941772, train/raw-loss = 0.45742177963256836, train/logprobs = tensor([[-0.6150, -5.7619],
        [-0.6701, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026450417935848236
Epoch 0, Step 595: train/loss = 0.5708967447280884, train/raw-loss = 0.47410494089126587, train/logprobs = tensor([[-0.7010, -1.9080],
        [-0.8375, -0.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032263945788145065
Epoch 0, Step 596: train/loss = 0.6057284474372864, train/raw-loss = 0.5191920399665833, train/logprobs = tensor([[-0.6249, -1.3061],
        [-0.6955, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028845470398664474
Epoch 0, Step 597: train/loss = 0.4654175341129303, train/raw-loss = 0.36905625462532043, train/logprobs = tensor([[-0.7518, -2.8276],
        [-0.8919, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03212043270468712
Epoch 0, Step 598: train/loss = 0.6090856194496155, train/raw-loss = 0.5232864022254944, train/logprobs = tensor([[-0.4687, -1.7919],
        [-0.4604, -0.6395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028599731624126434
Epoch 0, Step 599: train/loss = 0.5973938703536987, train/raw-loss = 0.5098105669021606, train/logprobs = tensor([[-0.5216, -1.6204],
        [-0.6106, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029194429516792297
Epoch 0, Step 600: train/loss = 0.570939302444458, train/raw-loss = 0.47753459215164185, train/logprobs = tensor([[-0.6869, -1.8331],
        [-0.7468, -0.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031134914606809616
Epoch 0, Step 601: train/loss = 0.6829780340194702, train/raw-loss = 0.5859569311141968, train/logprobs = tensor([[-0.7634, -1.0927],
        [-0.7451, -0.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032340362668037415
Epoch 0, Step 602: train/loss = 0.49231165647506714, train/raw-loss = 0.4080136716365814, train/logprobs = tensor([[-0.5585, -2.2647],
        [-0.6123, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028099320828914642
Epoch 0, Step 603: train/loss = 0.6381731629371643, train/raw-loss = 0.5583910346031189, train/logprobs = tensor([[-0.7212, -0.9241],
        [-0.8448, -0.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026594044640660286
Epoch 0, Step 604: train/loss = 0.5623785257339478, train/raw-loss = 0.46491265296936035, train/logprobs = tensor([[-0.5556, -2.1650],
        [-0.5354, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032488636672496796
Epoch 0, Step 605: train/loss = 0.581935703754425, train/raw-loss = 0.4912377893924713, train/logprobs = tensor([[-0.5818, -1.6629],
        [-0.6043, -0.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030232641845941544
Epoch 0, Step 606: train/loss = 0.6667351722717285, train/raw-loss = 0.5933964848518372, train/logprobs = tensor([[-0.6112, -0.9611],
        [-0.5569, -0.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02444623038172722
Epoch 0, Step 607: train/loss = 0.4700954258441925, train/raw-loss = 0.3822285830974579, train/logprobs = tensor([[-0.4460, -3.4605],
        [-0.4728, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029288947582244873
Epoch 0, Step 608: train/loss = 0.8910163044929504, train/raw-loss = 0.814154863357544, train/logprobs = tensor([[-1.5931, -1.8416],
        [-0.5740, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025620516389608383
Epoch 0, Step 609: train/loss = 0.5174862742424011, train/raw-loss = 0.41777193546295166, train/logprobs = tensor([[-0.6132, -3.7735],
        [-0.6941, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03323811665177345
Epoch 0, Step 610: train/loss = 0.54655522108078, train/raw-loss = 0.44829580187797546, train/logprobs = tensor([[-0.6965, -2.7626],
        [-0.6784, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03275313228368759
Epoch 0, Step 611: train/loss = 0.585151731967926, train/raw-loss = 0.4908376932144165, train/logprobs = tensor([[-0.6606, -1.7768],
        [-0.6584, -0.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03143801912665367
Epoch 0, Step 612: train/loss = 0.7031353712081909, train/raw-loss = 0.647524893283844, train/logprobs = tensor([[-0.5509, -0.6500],
        [-0.5117, -0.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018536824733018875
Epoch 0, Step 613: train/loss = 0.48102763295173645, train/raw-loss = 0.38958221673965454, train/logprobs = tensor([[-0.6203, -3.3668],
        [-0.7515, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030481800436973572
Epoch 0, Step 614: train/loss = 0.6439401507377625, train/raw-loss = 0.5769829750061035, train/logprobs = tensor([[-0.6306, -0.9497],
        [-0.7453, -0.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022319050505757332
Epoch 0, Step 615: train/loss = 0.5856163501739502, train/raw-loss = 0.5044595003128052, train/logprobs = tensor([[-0.3248, -1.8855],
        [-0.3704, -0.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027052275836467743
Epoch 0, Step 616: train/loss = 0.5910282135009766, train/raw-loss = 0.5051907300949097, train/logprobs = tensor([[-0.8743, -2.2424],
        [-0.7465, -0.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028612520545721054
Epoch 0, Step 617: train/loss = 0.6161054968833923, train/raw-loss = 0.5340920090675354, train/logprobs = tensor([[-0.8035, -1.6880],
        [-0.7166, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027337826788425446
Epoch 0, Step 618: train/loss = 0.4646807909011841, train/raw-loss = 0.37766993045806885, train/logprobs = tensor([[-0.5501, -2.4793],
        [-0.6642, -0.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029003622010350227
Epoch 0, Step 619: train/loss = 0.6632623672485352, train/raw-loss = 0.5866292715072632, train/logprobs = tensor([[-0.5317, -0.8879],
        [-0.5088, -0.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025544360280036926
Epoch 0, Step 620: train/loss = 0.6204667091369629, train/raw-loss = 0.5446407198905945, train/logprobs = tensor([[-0.6495, -2.3435],
        [-0.4886, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025275344029068947
Epoch 0, Step 621: train/loss = 0.654916524887085, train/raw-loss = 0.5731424689292908, train/logprobs = tensor([[-0.8140, -0.9608],
        [-0.8572, -0.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02725803479552269
Epoch 0, Step 622: train/loss = 0.6109309196472168, train/raw-loss = 0.5402738451957703, train/logprobs = tensor([[-0.6067, -1.6401],
        [-0.5098, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023552345111966133
Epoch 0, Step 623: train/loss = 0.5101935863494873, train/raw-loss = 0.4225819706916809, train/logprobs = tensor([[-0.4592, -3.3276],
        [-0.4739, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029203884303569794
Epoch 0, Step 624: train/loss = 0.7407218217849731, train/raw-loss = 0.6745765805244446, train/logprobs = tensor([[-0.6896, -0.7978],
        [-0.4797, -0.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022048430517315865
Epoch 0, Step 625: train/loss = 0.6824023723602295, train/raw-loss = 0.6085241436958313, train/logprobs = tensor([[-0.6730, -1.1346],
        [-0.6663, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024626074358820915
Epoch 0, Step 626: train/loss = 0.6846628785133362, train/raw-loss = 0.5955220460891724, train/logprobs = tensor([[-1.1430, -1.9998],
        [-0.6927, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02971363253891468
Epoch 0, Step 627: train/loss = 0.5293429493904114, train/raw-loss = 0.4386840760707855, train/logprobs = tensor([[-0.7112, -2.9561],
        [-0.6936, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03021961823105812
Epoch 0, Step 628: train/loss = 0.5776070356369019, train/raw-loss = 0.4922950267791748, train/logprobs = tensor([[-0.6833, -1.8681],
        [-0.6845, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02843734808266163
Epoch 0, Step 629: train/loss = 0.6599326729774475, train/raw-loss = 0.5871466398239136, train/logprobs = tensor([[-0.4610, -1.3897],
        [-0.4108, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024261999875307083
Epoch 0, Step 630: train/loss = 0.611422061920166, train/raw-loss = 0.5358121991157532, train/logprobs = tensor([[-0.5274, -1.8201],
        [-0.5307, -0.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025203267112374306
Epoch 0, Step 631: train/loss = 0.5007358193397522, train/raw-loss = 0.4060191214084625, train/logprobs = tensor([[-0.7323, -2.7931],
        [-0.8651, -0.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03157223016023636
Epoch 0, Step 632: train/loss = 0.5744450092315674, train/raw-loss = 0.4824817180633545, train/logprobs = tensor([[-0.6979, -3.9880],
        [-0.9108, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030654426664114
Epoch 0, Step 633: train/loss = 0.5707770586013794, train/raw-loss = 0.4926700294017792, train/logprobs = tensor([[-0.6506, -1.7844],
        [-0.7233, -0.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026035688817501068
Epoch 0, Step 634: train/loss = 0.6520807147026062, train/raw-loss = 0.5791445374488831, train/logprobs = tensor([[-0.5049, -1.7815],
        [-0.4858, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024312060326337814
Epoch 0, Step 635: train/loss = 0.6269012689590454, train/raw-loss = 0.5542296767234802, train/logprobs = tensor([[-0.5761, -1.4202],
        [-0.4703, -0.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024223841726779938
Epoch 0, Step 636: train/loss = 0.6691075563430786, train/raw-loss = 0.6000473499298096, train/logprobs = tensor([[-2.5261, -4.8491],
        [-1.7567, -2.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023020058870315552
Epoch 0, Step 637: train/loss = 0.5827254056930542, train/raw-loss = 0.5091545581817627, train/logprobs = tensor([[-0.5241, -1.3732],
        [-0.5945, -0.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024523619562387466
Epoch 0, Step 638: train/loss = 0.7297914028167725, train/raw-loss = 0.6683139801025391, train/logprobs = tensor([[-0.7576, -0.6998],
        [-0.6711, -0.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020492462441325188
Epoch 0, Step 639: train/loss = 0.6088271737098694, train/raw-loss = 0.5002765655517578, train/logprobs = tensor([[-0.7632, -1.5297],
        [-0.8499, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036183543503284454
Epoch 0, Step 640: train/loss = 0.536348819732666, train/raw-loss = 0.4631554186344147, train/logprobs = tensor([[-0.5273, -1.9933],
        [-0.5576, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024397796019911766
Epoch 0, Step 641: train/loss = 0.5001879930496216, train/raw-loss = 0.4136434495449066, train/logprobs = tensor([[-0.4979, -2.9211],
        [-0.5026, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0288481917232275
Epoch 0, Step 642: train/loss = 0.6259613037109375, train/raw-loss = 0.5623544454574585, train/logprobs = tensor([[-0.4493, -1.5560],
        [-0.4638, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021202294155955315
Epoch 0, Step 643: train/loss = 0.61698317527771, train/raw-loss = 0.5347156524658203, train/logprobs = tensor([[-0.7286, -1.4111],
        [-0.7167, -0.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027422508224844933
Epoch 0, Step 644: train/loss = 0.5574848055839539, train/raw-loss = 0.4744167625904083, train/logprobs = tensor([[-0.7552, -2.0545],
        [-0.8056, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027689337730407715
Epoch 0, Step 645: train/loss = 0.4667949676513672, train/raw-loss = 0.3854143023490906, train/logprobs = tensor([[-0.5862, -5.2319],
        [-0.6284, -1.2850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02712687849998474
Epoch 0, Step 646: train/loss = 0.5924526453018188, train/raw-loss = 0.5108997821807861, train/logprobs = tensor([[-0.5657, -1.3700],
        [-0.6486, -0.4319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027184294536709785
Epoch 0, Step 647: train/loss = 0.5991888642311096, train/raw-loss = 0.51123046875, train/logprobs = tensor([[-0.6432, -1.6195],
        [-0.7218, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029319478198885918
Epoch 0, Step 648: train/loss = 0.6001144051551819, train/raw-loss = 0.5264239311218262, train/logprobs = tensor([[-0.5633, -1.5412],
        [-0.5739, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024563487619161606
Epoch 0, Step 649: train/loss = 0.5207375288009644, train/raw-loss = 0.42872855067253113, train/logprobs = tensor([[-0.6301, -2.0908],
        [-0.8050, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030669664964079857
Epoch 0, Step 650: train/loss = 0.5685760378837585, train/raw-loss = 0.49929943680763245, train/logprobs = tensor([[-0.5630, -1.6343],
        [-0.6440, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023092206567525864
Epoch 0, Step 651: train/loss = 0.5779999494552612, train/raw-loss = 0.5141570568084717, train/logprobs = tensor([[-0.4855, -2.2780],
        [-0.5375, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021280935034155846
Epoch 0, Step 652: train/loss = 0.4954439103603363, train/raw-loss = 0.4062567353248596, train/logprobs = tensor([[-0.4600, -2.8464],
        [-0.5267, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02972906082868576
Epoch 0, Step 653: train/loss = 0.4869348406791687, train/raw-loss = 0.4142534136772156, train/logprobs = tensor([[-0.4745, -2.6675],
        [-0.4919, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02422715723514557
Epoch 0, Step 654: train/loss = 0.6164827346801758, train/raw-loss = 0.5399198532104492, train/logprobs = tensor([[-0.5636, -1.5812],
        [-0.4786, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02552095055580139
Epoch 0, Step 655: train/loss = 0.528662383556366, train/raw-loss = 0.451610803604126, train/logprobs = tensor([[-0.7921, -4.5657],
        [-0.8198, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02568385936319828
Epoch 0, Step 656: train/loss = 0.6337848901748657, train/raw-loss = 0.5660520792007446, train/logprobs = tensor([[-0.7234, -1.6631],
        [-0.6320, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02257760614156723
Epoch 0, Step 657: train/loss = 0.6181455850601196, train/raw-loss = 0.5312055349349976, train/logprobs = tensor([[-0.6785, -1.9249],
        [-0.6844, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028980009257793427
Epoch 0, Step 658: train/loss = 0.6092149019241333, train/raw-loss = 0.5321354866027832, train/logprobs = tensor([[-0.5821, -2.3024],
        [-0.5962, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025693116709589958
Epoch 0, Step 659: train/loss = 0.5993091464042664, train/raw-loss = 0.5317137241363525, train/logprobs = tensor([[-0.7572, -2.9195],
        [-0.4737, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022531811147928238
Epoch 0, Step 660: train/loss = 0.6165460348129272, train/raw-loss = 0.5437692999839783, train/logprobs = tensor([[-0.8206, -2.0940],
        [-0.7706, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024258926510810852
Epoch 0, Step 661: train/loss = 0.5259416103363037, train/raw-loss = 0.453832745552063, train/logprobs = tensor([[-0.6051, -4.8653],
        [-0.4965, -1.2245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024036288261413574
Epoch 0, Step 662: train/loss = 0.5534451007843018, train/raw-loss = 0.48062020540237427, train/logprobs = tensor([[-0.6346, -3.3440],
        [-0.8187, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024274948984384537
Epoch 0, Step 663: train/loss = 0.5424095392227173, train/raw-loss = 0.4447128176689148, train/logprobs = tensor([[-0.5408, -2.8383],
        [-0.5559, -0.6656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03256558999419212
Epoch 0, Step 664: train/loss = 0.6865568161010742, train/raw-loss = 0.6062710285186768, train/logprobs = tensor([[-1.3617, -3.0681],
        [-0.7274, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02676193043589592
Epoch 0, Step 665: train/loss = 0.5996466875076294, train/raw-loss = 0.514665961265564, train/logprobs = tensor([[-0.6805, -1.6483],
        [-0.6784, -0.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028326891362667084
Epoch 0, Step 666: train/loss = 0.6384902000427246, train/raw-loss = 0.5469906330108643, train/logprobs = tensor([[-0.9011, -2.4869],
        [-0.5366, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030499858781695366
Epoch 0, Step 667: train/loss = 0.6337089538574219, train/raw-loss = 0.5540621280670166, train/logprobs = tensor([[-0.4986, -1.1484],
        [-0.5711, -0.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026548950001597404
Epoch 0, Step 668: train/loss = 0.6714701056480408, train/raw-loss = 0.5842089056968689, train/logprobs = tensor([[-0.8917, -1.7203],
        [-0.5886, -0.7752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029087064787745476
Epoch 0, Step 669: train/loss = 0.6685584783554077, train/raw-loss = 0.5962756276130676, train/logprobs = tensor([[-0.6111, -0.8854],
        [-0.6239, -0.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02409428358078003
Epoch 0, Step 670: train/loss = 0.5422985553741455, train/raw-loss = 0.4592030644416809, train/logprobs = tensor([[-0.6238, -3.8914],
        [-0.6417, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02769847773015499
Epoch 0, Step 671: train/loss = 0.610862672328949, train/raw-loss = 0.5360857844352722, train/logprobs = tensor([[-0.4955, -1.4974],
        [-0.5316, -0.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02492561936378479
Epoch 0, Step 672: train/loss = 0.5341624021530151, train/raw-loss = 0.45417988300323486, train/logprobs = tensor([[-0.6238, -4.6722],
        [-0.6933, -1.3140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026660826057195663
Epoch 0, Step 673: train/loss = 0.603413462638855, train/raw-loss = 0.5178399682044983, train/logprobs = tensor([[-0.5689, -2.2854],
        [-0.5712, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028524503111839294
Epoch 0, Step 674: train/loss = 0.508169412612915, train/raw-loss = 0.42417824268341064, train/logprobs = tensor([[-0.8992, -2.0608],
        [-1.1611, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027997054159641266
Epoch 0, Step 675: train/loss = 0.662492036819458, train/raw-loss = 0.5953450202941895, train/logprobs = tensor([[-0.5884, -1.0812],
        [-0.5552, -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022382330149412155
Epoch 0, Step 676: train/loss = 0.5674070119857788, train/raw-loss = 0.4886314868927002, train/logprobs = tensor([[-0.5666, -2.3383],
        [-0.6155, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026258496567606926
Epoch 0, Step 677: train/loss = 0.6374443173408508, train/raw-loss = 0.5758266448974609, train/logprobs = tensor([[-0.3970, -1.0704],
        [-0.4669, -0.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020539212971925735
Epoch 0, Step 678: train/loss = 0.475212037563324, train/raw-loss = 0.38750702142715454, train/logprobs = tensor([[-0.6041, -3.0940],
        [-0.7845, -0.9243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029235005378723145
Epoch 0, Step 679: train/loss = 0.6241654753684998, train/raw-loss = 0.5354147553443909, train/logprobs = tensor([[-0.9447, -1.8040],
        [-0.6445, -0.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029583575204014778
Epoch 0, Step 680: train/loss = 0.5852672457695007, train/raw-loss = 0.49943050742149353, train/logprobs = tensor([[-0.5354, -1.7052],
        [-0.5218, -0.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02861224114894867
Epoch 0, Step 681: train/loss = 0.5745577216148376, train/raw-loss = 0.49032828211784363, train/logprobs = tensor([[-0.7541, -4.5305],
        [-0.6323, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02807646617293358
Epoch 0, Step 682: train/loss = 0.5584484338760376, train/raw-loss = 0.45555904507637024, train/logprobs = tensor([[-0.7997, -4.7559],
        [-0.8381, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03429645672440529
Epoch 0, Step 683: train/loss = 0.530742883682251, train/raw-loss = 0.4312519431114197, train/logprobs = tensor([[-0.5480, -3.4238],
        [-0.5858, -1.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033163659274578094
Epoch 0, Step 684: train/loss = 0.5366895198822021, train/raw-loss = 0.4429251551628113, train/logprobs = tensor([[-0.4754, -3.0735],
        [-0.3612, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03125477954745293
Epoch 0, Step 685: train/loss = 0.6951759457588196, train/raw-loss = 0.6165974736213684, train/logprobs = tensor([[-0.9873, -1.2750],
        [-0.7413, -0.5959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02619282715022564
Epoch 0, Step 686: train/loss = 0.6265463829040527, train/raw-loss = 0.5592429041862488, train/logprobs = tensor([[-0.5449, -1.3235],
        [-0.5891, -0.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022434499114751816
Epoch 0, Step 687: train/loss = 0.5417921543121338, train/raw-loss = 0.4579445719718933, train/logprobs = tensor([[-0.8326, -3.6646],
        [-0.6923, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02794918604195118
Epoch 0, Step 688: train/loss = 0.6219761371612549, train/raw-loss = 0.5410280227661133, train/logprobs = tensor([[-0.5784, -1.2494],
        [-0.6436, -0.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026982685551047325
Epoch 0, Step 689: train/loss = 0.6484544277191162, train/raw-loss = 0.5673950910568237, train/logprobs = tensor([[-0.5953, -1.2685],
        [-0.5293, -0.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027019768953323364
Epoch 0, Step 690: train/loss = 0.55051589012146, train/raw-loss = 0.4530492424964905, train/logprobs = tensor([[-0.7340, -1.6825],
        [-0.7975, -0.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032488882541656494
Epoch 0, Step 691: train/loss = 0.6908568143844604, train/raw-loss = 0.6045130491256714, train/logprobs = tensor([[-0.5932, -1.0685],
        [-0.5596, -0.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028781244531273842
Epoch 0, Step 692: train/loss = 0.5611982345581055, train/raw-loss = 0.48188120126724243, train/logprobs = tensor([[-0.5801, -2.1176],
        [-0.5373, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026439014822244644
Epoch 0, Step 693: train/loss = 0.49907782673835754, train/raw-loss = 0.4152361750602722, train/logprobs = tensor([[-0.4590, -2.9295],
        [-0.5307, -0.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02794724330306053
Epoch 0, Step 694: train/loss = 0.6004745960235596, train/raw-loss = 0.5179147720336914, train/logprobs = tensor([[-0.6164, -1.6251],
        [-0.6031, -0.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027519937604665756
Epoch 0, Step 695: train/loss = 0.6270471811294556, train/raw-loss = 0.5795024037361145, train/logprobs = tensor([[-0.5056, -1.9320],
        [-0.4915, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015848258510231972
Epoch 0, Step 696: train/loss = 0.5817312598228455, train/raw-loss = 0.5038313269615173, train/logprobs = tensor([[-0.7138, -2.1340],
        [-0.7687, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02596663311123848
Epoch 0, Step 697: train/loss = 0.6101343631744385, train/raw-loss = 0.5373343825340271, train/logprobs = tensor([[-0.5271, -1.5642],
        [-0.5287, -0.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02426666021347046
Epoch 0, Step 698: train/loss = 0.5600647926330566, train/raw-loss = 0.4799330234527588, train/logprobs = tensor([[-0.7267, -3.0299],
        [-0.6965, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02671060711145401
Epoch 0, Step 699: train/loss = 0.5527891516685486, train/raw-loss = 0.4730125963687897, train/logprobs = tensor([[-0.7381, -1.8085],
        [-0.8024, -0.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026592176407575607
Epoch 0, Step 700: train/loss = 0.5517839193344116, train/raw-loss = 0.47542473673820496, train/logprobs = tensor([[-0.7471, -3.3657],
        [-0.6145, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02545306645333767
Epoch 0, Step 701: train/loss = 0.5908530354499817, train/raw-loss = 0.4892668128013611, train/logprobs = tensor([[-1.2401, -2.6556],
        [-0.8757, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386209160089493
Epoch 0, Step 702: train/loss = 0.5603070855140686, train/raw-loss = 0.4586567282676697, train/logprobs = tensor([[-0.6782, -2.6332],
        [-0.7288, -0.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03388345241546631
Epoch 0, Step 703: train/loss = 0.6011568903923035, train/raw-loss = 0.5290787220001221, train/logprobs = tensor([[-0.5655, -1.6503],
        [-0.5581, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024026062339544296
Epoch 0, Step 704: train/loss = 0.5069307088851929, train/raw-loss = 0.41050103306770325, train/logprobs = tensor([[-0.6003, -4.9438],
        [-0.5992, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032143235206604004
Epoch 0, Step 705: train/loss = 0.4665549695491791, train/raw-loss = 0.3799900412559509, train/logprobs = tensor([[-0.7323, -2.8303],
        [-0.8759, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02885497361421585
Epoch 0, Step 706: train/loss = 0.4839404821395874, train/raw-loss = 0.3892405331134796, train/logprobs = tensor([[-0.8518, -2.9412],
        [-1.0127, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03156665712594986
Epoch 0, Step 707: train/loss = 0.5036172270774841, train/raw-loss = 0.4174335300922394, train/logprobs = tensor([[-0.6240, -2.7074],
        [-0.6377, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028727896511554718
Epoch 0, Step 708: train/loss = 0.4859533905982971, train/raw-loss = 0.3943774104118347, train/logprobs = tensor([[-0.6857, -2.9219],
        [-0.8943, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03052532486617565
Epoch 0, Step 709: train/loss = 0.6677446961402893, train/raw-loss = 0.5881778001785278, train/logprobs = tensor([[-0.9382, -1.8016],
        [-0.8923, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02652229741215706
Epoch 0, Step 710: train/loss = 0.6476778388023376, train/raw-loss = 0.5686895251274109, train/logprobs = tensor([[-0.3430, -1.2644],
        [-0.3479, -0.5907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026329440996050835
Epoch 0, Step 711: train/loss = 0.592068612575531, train/raw-loss = 0.5098345279693604, train/logprobs = tensor([[-0.5850, -1.7614],
        [-0.5480, -0.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02741137146949768
Epoch 0, Step 712: train/loss = 0.7033683061599731, train/raw-loss = 0.6195886731147766, train/logprobs = tensor([[-0.4948, -0.8124],
        [-0.4808, -0.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027926534414291382
Epoch 0, Step 713: train/loss = 0.6428595185279846, train/raw-loss = 0.5650753974914551, train/logprobs = tensor([[-0.6262, -1.5216],
        [-0.5079, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025928040966391563
Epoch 0, Step 714: train/loss = 0.7631078958511353, train/raw-loss = 0.6840581893920898, train/logprobs = tensor([[-1.1534, -1.5094],
        [-0.5850, -0.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026349905878305435
Epoch 0, Step 715: train/loss = 0.6407777070999146, train/raw-loss = 0.572557270526886, train/logprobs = tensor([[-0.4469, -1.0980],
        [-0.4774, -0.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022740140557289124
Epoch 0, Step 716: train/loss = 0.5298866033554077, train/raw-loss = 0.4476960599422455, train/logprobs = tensor([[-0.6073, -2.0747],
        [-0.7145, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027396857738494873
Epoch 0, Step 717: train/loss = 0.5963278412818909, train/raw-loss = 0.5015233159065247, train/logprobs = tensor([[-0.8042, -3.5800],
        [-0.7044, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031601499766111374
Epoch 0, Step 718: train/loss = 0.6069899201393127, train/raw-loss = 0.5441616773605347, train/logprobs = tensor([[-0.5879, -1.2507],
        [-0.5859, -0.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02094276063144207
Epoch 0, Step 719: train/loss = 0.4963500201702118, train/raw-loss = 0.41151654720306396, train/logprobs = tensor([[-0.7317, -3.5100],
        [-0.5752, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028277814388275146
Epoch 0, Step 720: train/loss = 0.5979906320571899, train/raw-loss = 0.5205003619194031, train/logprobs = tensor([[-0.5286, -1.5987],
        [-0.5210, -0.6841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025830108672380447
Epoch 0, Step 721: train/loss = 0.6564854383468628, train/raw-loss = 0.5930529236793518, train/logprobs = tensor([[-0.5415, -1.0936],
        [-0.5085, -0.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02114415541291237
Epoch 0, Step 722: train/loss = 0.5380377173423767, train/raw-loss = 0.44190776348114014, train/logprobs = tensor([[-0.6067, -2.9333],
        [-0.6379, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03204331547021866
Epoch 0, Step 723: train/loss = 0.5131023526191711, train/raw-loss = 0.43196916580200195, train/logprobs = tensor([[-0.8671, -2.8288],
        [-0.8898, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027044394984841347
Epoch 0, Step 724: train/loss = 0.583541989326477, train/raw-loss = 0.505122184753418, train/logprobs = tensor([[-0.5966, -1.8566],
        [-0.6492, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026139937341213226
Epoch 0, Step 725: train/loss = 0.5687467455863953, train/raw-loss = 0.47456932067871094, train/logprobs = tensor([[-0.5966, -2.0431],
        [-0.6986, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03139247000217438
Epoch 0, Step 726: train/loss = 0.5307456851005554, train/raw-loss = 0.4513663649559021, train/logprobs = tensor([[-0.4360, -2.2445],
        [-0.4535, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026459772139787674
Epoch 0, Step 727: train/loss = 0.6701707243919373, train/raw-loss = 0.6048479080200195, train/logprobs = tensor([[-0.4290, -0.8135],
        [-0.4404, -0.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0217742882668972
Epoch 0, Step 728: train/loss = 0.5740712285041809, train/raw-loss = 0.48996156454086304, train/logprobs = tensor([[-0.6369, -1.9363],
        [-0.6139, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02803656831383705
Epoch 0, Step 729: train/loss = 0.5553874373435974, train/raw-loss = 0.4682123363018036, train/logprobs = tensor([[-0.6453, -1.8448],
        [-0.6848, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029058370739221573
Epoch 0, Step 730: train/loss = 0.6881412863731384, train/raw-loss = 0.6001471281051636, train/logprobs = tensor([[-0.8702, -1.2550],
        [-0.7094, -0.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029331376776099205
Epoch 0, Step 731: train/loss = 0.48996853828430176, train/raw-loss = 0.39801284670829773, train/logprobs = tensor([[-0.6946, -5.3326],
        [-0.6681, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03065188229084015
Epoch 0, Step 732: train/loss = 0.5808823704719543, train/raw-loss = 0.5116186141967773, train/logprobs = tensor([[-0.4468, -1.9524],
        [-0.4712, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023087922483682632
Epoch 0, Step 733: train/loss = 0.5687746405601501, train/raw-loss = 0.4946558177471161, train/logprobs = tensor([[-0.4560, -2.4861],
        [-0.5226, -0.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024706270545721054
Epoch 0, Step 734: train/loss = 0.6520141959190369, train/raw-loss = 0.5838277339935303, train/logprobs = tensor([[-0.4953, -1.1661],
        [-0.4514, -0.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022728819400072098
Epoch 0, Step 735: train/loss = 0.5581186413764954, train/raw-loss = 0.4720615744590759, train/logprobs = tensor([[-0.6499, -2.3558],
        [-0.7939, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02868569642305374
Epoch 0, Step 736: train/loss = 0.5293407440185547, train/raw-loss = 0.4499890208244324, train/logprobs = tensor([[-0.6952, -2.6688],
        [-0.6044, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026450572535395622
Epoch 0, Step 737: train/loss = 0.6010111570358276, train/raw-loss = 0.5375248193740845, train/logprobs = tensor([[-0.6145, -2.1701],
        [-0.4372, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021162105724215508
Epoch 0, Step 738: train/loss = 0.6517459154129028, train/raw-loss = 0.5800906419754028, train/logprobs = tensor([[-0.6826, -1.1864],
        [-0.5950, -0.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023885101079940796
Epoch 0, Step 739: train/loss = 0.6262965202331543, train/raw-loss = 0.5387908220291138, train/logprobs = tensor([[-0.5123, -2.0183],
        [-0.5217, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02916857972741127
Epoch 0, Step 740: train/loss = 0.7152299880981445, train/raw-loss = 0.6501308679580688, train/logprobs = tensor([[-0.5923, -0.7663],
        [-0.4955, -0.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02169971540570259
Epoch 0, Step 741: train/loss = 0.6692240238189697, train/raw-loss = 0.5987931489944458, train/logprobs = tensor([[-0.5919, -0.9157],
        [-0.5793, -0.4497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02347695268690586
Epoch 0, Step 742: train/loss = 0.5806980133056641, train/raw-loss = 0.5065685510635376, train/logprobs = tensor([[-0.4407, -1.8171],
        [-0.4121, -0.4932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024709854274988174
Epoch 0, Step 743: train/loss = 0.543483316898346, train/raw-loss = 0.45688706636428833, train/logprobs = tensor([[-0.6403, -2.1891],
        [-0.6703, -0.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028865430504083633
Epoch 0, Step 744: train/loss = 0.6531177759170532, train/raw-loss = 0.5674242973327637, train/logprobs = tensor([[-0.6231, -1.0323],
        [-0.8202, -0.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028564490377902985
Epoch 0, Step 745: train/loss = 0.49524810910224915, train/raw-loss = 0.4164654612541199, train/logprobs = tensor([[-0.5723, -2.6001],
        [-0.5844, -0.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026260893791913986
Epoch 0, Step 746: train/loss = 0.5208312273025513, train/raw-loss = 0.44533586502075195, train/logprobs = tensor([[-0.5273, -2.0036],
        [-0.5588, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025165118277072906
Epoch 0, Step 747: train/loss = 0.6382606625556946, train/raw-loss = 0.561414897441864, train/logprobs = tensor([[-0.7746, -1.4150],
        [-0.6352, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02561526745557785
Epoch 0, Step 748: train/loss = 0.4684898257255554, train/raw-loss = 0.3833111822605133, train/logprobs = tensor([[-0.8856, -6.0796],
        [-0.9377, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028392888605594635
Epoch 0, Step 749: train/loss = 0.5613619685173035, train/raw-loss = 0.4647900462150574, train/logprobs = tensor([[-0.7109, -2.2766],
        [-0.7315, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03219064325094223
Epoch 0, Step 750: train/loss = 0.5966366529464722, train/raw-loss = 0.5112234950065613, train/logprobs = tensor([[-1.0850, -3.6193],
        [-0.8364, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028471045196056366
Epoch 0, Step 751: train/loss = 0.5773201584815979, train/raw-loss = 0.4946502447128296, train/logprobs = tensor([[-0.7194, -1.5115],
        [-0.7992, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0275566466152668
Epoch 0, Step 752: train/loss = 0.5836924314498901, train/raw-loss = 0.5147498250007629, train/logprobs = tensor([[-0.4174, -1.5671],
        [-0.4326, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022980865091085434
Epoch 0, Step 753: train/loss = 0.5960168838500977, train/raw-loss = 0.51964271068573, train/logprobs = tensor([[-1.1599, -3.3184],
        [-0.7303, -1.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02545805834233761
Epoch 0, Step 754: train/loss = 0.5541965961456299, train/raw-loss = 0.4775262475013733, train/logprobs = tensor([[-0.6848, -3.1772],
        [-0.7211, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025556787848472595
Epoch 0, Step 755: train/loss = 0.5747833251953125, train/raw-loss = 0.48797810077667236, train/logprobs = tensor([[-0.7576, -1.9721],
        [-0.7380, -0.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028935076668858528
Epoch 0, Step 756: train/loss = 0.6167129874229431, train/raw-loss = 0.5382256507873535, train/logprobs = tensor([[-0.6569, -1.5416],
        [-0.6544, -0.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026162458583712578
Epoch 0, Step 757: train/loss = 0.6420509815216064, train/raw-loss = 0.5696778297424316, train/logprobs = tensor([[-0.6814, -1.0899],
        [-0.6786, -0.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024124369025230408
Epoch 0, Step 758: train/loss = 0.6996992826461792, train/raw-loss = 0.6282856464385986, train/logprobs = tensor([[-0.9983, -1.1255],
        [-0.8894, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02380455657839775
Epoch 0, Step 759: train/loss = 0.5036198496818542, train/raw-loss = 0.42637017369270325, train/logprobs = tensor([[-0.6659, -4.6514],
        [-0.7945, -1.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025749891996383667
Epoch 0, Step 760: train/loss = 0.6342427730560303, train/raw-loss = 0.5640712380409241, train/logprobs = tensor([[-0.6572, -1.2515],
        [-0.6616, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02339048869907856
Epoch 0, Step 761: train/loss = 0.4918920695781708, train/raw-loss = 0.4079762101173401, train/logprobs = tensor([[-0.5329, -2.5092],
        [-0.7222, -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027971962466835976
Epoch 0, Step 762: train/loss = 0.6881207227706909, train/raw-loss = 0.6232389211654663, train/logprobs = tensor([[-0.6011, -0.9035],
        [-0.5270, -0.4925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021627243608236313
Epoch 0, Step 763: train/loss = 0.47097450494766235, train/raw-loss = 0.38485094904899597, train/logprobs = tensor([[-0.4223, -3.4453],
        [-0.4436, -1.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028707852587103844
Epoch 0, Step 764: train/loss = 0.5898759365081787, train/raw-loss = 0.5162458419799805, train/logprobs = tensor([[-0.6327, -2.7282],
        [-0.6190, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024543356150388718
Epoch 0, Step 765: train/loss = 0.5050341486930847, train/raw-loss = 0.41455596685409546, train/logprobs = tensor([[-0.7190, -2.8526],
        [-0.7809, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030159398913383484
Epoch 0, Step 766: train/loss = 0.7325944900512695, train/raw-loss = 0.6635487079620361, train/logprobs = tensor([[-0.5414, -0.7277],
        [-0.4885, -0.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02301526442170143
Epoch 0, Step 767: train/loss = 0.49970701336860657, train/raw-loss = 0.42307132482528687, train/logprobs = tensor([[-0.7135, -7.5912],
        [-0.6645, -1.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025545228272676468
Epoch 0, Step 768: train/loss = 0.6200007200241089, train/raw-loss = 0.5441182851791382, train/logprobs = tensor([[-0.6756, -2.5433],
        [-0.6507, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025294136255979538
Epoch 0, Step 769: train/loss = 0.5798386931419373, train/raw-loss = 0.5044662356376648, train/logprobs = tensor([[-0.9763, -2.5946],
        [-0.7420, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025124160572886467
Epoch 0, Step 770: train/loss = 0.6261330842971802, train/raw-loss = 0.552299976348877, train/logprobs = tensor([[-0.6709, -1.3599],
        [-0.6240, -0.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02461105026304722
Epoch 0, Step 771: train/loss = 0.7166305780410767, train/raw-loss = 0.6478750705718994, train/logprobs = tensor([[-1.0302, -1.0222],
        [-0.8305, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02291851118206978
Epoch 0, Step 772: train/loss = 0.55848628282547, train/raw-loss = 0.48746803402900696, train/logprobs = tensor([[-0.4260, -4.4465],
        [-0.4814, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023672737181186676
Epoch 0, Step 773: train/loss = 0.6326310634613037, train/raw-loss = 0.552837073802948, train/logprobs = tensor([[-1.5170, -4.2518],
        [-1.0768, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026597972959280014
Epoch 0, Step 774: train/loss = 0.5876643061637878, train/raw-loss = 0.505158543586731, train/logprobs = tensor([[-0.5495, -1.6992],
        [-0.5254, -0.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027501916512846947
Epoch 0, Step 775: train/loss = 0.49919354915618896, train/raw-loss = 0.4147873818874359, train/logprobs = tensor([[-0.6718, -3.2810],
        [-0.7357, -1.2840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028135385364294052
Epoch 0, Step 776: train/loss = 0.6505730748176575, train/raw-loss = 0.5863399505615234, train/logprobs = tensor([[-0.7888, -1.3189],
        [-0.6726, -0.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021411053836345673
Epoch 0, Step 777: train/loss = 0.498721182346344, train/raw-loss = 0.4264456033706665, train/logprobs = tensor([[-0.5392, -3.0101],
        [-0.5106, -0.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02409186214208603
Epoch 0, Step 778: train/loss = 0.6897051930427551, train/raw-loss = 0.6242075562477112, train/logprobs = tensor([[-0.8008, -1.0967],
        [-0.6239, -0.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021832548081874847
Epoch 0, Step 779: train/loss = 0.6472138166427612, train/raw-loss = 0.5815029144287109, train/logprobs = tensor([[-0.5958, -1.0362],
        [-0.6114, -0.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021903619170188904
Epoch 0, Step 780: train/loss = 0.5444176197052002, train/raw-loss = 0.46654272079467773, train/logprobs = tensor([[-0.7475, -2.1928],
        [-0.8156, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02595829777419567
Epoch 0, Step 781: train/loss = 0.5109870433807373, train/raw-loss = 0.44161128997802734, train/logprobs = tensor([[-0.5849, -3.2762],
        [-0.5664, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023125261068344116
Epoch 0, Step 782: train/loss = 0.5748886466026306, train/raw-loss = 0.501723051071167, train/logprobs = tensor([[-0.4811, -2.2283],
        [-0.5245, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024388529360294342
Epoch 0, Step 783: train/loss = 0.4678805470466614, train/raw-loss = 0.3856947422027588, train/logprobs = tensor([[-0.6027, -5.0621],
        [-0.5856, -1.3476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02739527076482773
Epoch 0, Step 784: train/loss = 0.5867226123809814, train/raw-loss = 0.5166823863983154, train/logprobs = tensor([[-0.4953, -1.3656],
        [-0.6228, -0.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02334674261510372
Epoch 0, Step 785: train/loss = 0.5712946057319641, train/raw-loss = 0.5148778557777405, train/logprobs = tensor([[-0.5181, -1.7212],
        [-0.5060, -0.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01880558207631111
Epoch 0, Step 786: train/loss = 0.49430984258651733, train/raw-loss = 0.4108455181121826, train/logprobs = tensor([[-0.5893, -2.4690],
        [-0.6384, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027821436524391174
Epoch 0, Step 787: train/loss = 0.4993230104446411, train/raw-loss = 0.4365149438381195, train/logprobs = tensor([[-0.4817, -2.7855],
        [-0.5596, -0.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020936015993356705
Epoch 0, Step 788: train/loss = 0.6277561187744141, train/raw-loss = 0.5398877859115601, train/logprobs = tensor([[-0.8814, -1.8868],
        [-0.8831, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029289450496435165
Epoch 0, Step 789: train/loss = 0.46418920159339905, train/raw-loss = 0.36667758226394653, train/logprobs = tensor([[-0.8440, -2.7321],
        [-0.9462, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0325038842856884
Epoch 0, Step 790: train/loss = 0.5692057013511658, train/raw-loss = 0.5058563947677612, train/logprobs = tensor([[-0.5940, -1.6528],
        [-0.5822, -0.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021116454154253006
Epoch 0, Step 791: train/loss = 0.6341984868049622, train/raw-loss = 0.5635935068130493, train/logprobs = tensor([[-0.4722, -2.0691],
        [-0.4980, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02353498712182045
Epoch 0, Step 792: train/loss = 0.5216699242591858, train/raw-loss = 0.4397813081741333, train/logprobs = tensor([[-0.5376, -2.2818],
        [-0.6114, -0.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027296192944049835
Epoch 0, Step 793: train/loss = 0.5258116722106934, train/raw-loss = 0.45867303013801575, train/logprobs = tensor([[-0.5017, -3.6412],
        [-0.6094, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02237955667078495
Epoch 0, Step 794: train/loss = 0.46294623613357544, train/raw-loss = 0.39257508516311646, train/logprobs = tensor([[-0.5198, -3.3197],
        [-0.5891, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02345704846084118
Epoch 0, Step 795: train/loss = 0.6307622790336609, train/raw-loss = 0.5554370880126953, train/logprobs = tensor([[-0.5920, -1.1697],
        [-0.6447, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025108415633440018
Epoch 0, Step 796: train/loss = 0.4552991986274719, train/raw-loss = 0.34808897972106934, train/logprobs = tensor([[-0.8621, -5.7530],
        [-0.8859, -1.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035736728459596634
Epoch 0, Step 797: train/loss = 0.5534328818321228, train/raw-loss = 0.48815834522247314, train/logprobs = tensor([[-0.6892, -2.5134],
        [-0.5796, -0.8261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021758168935775757
Epoch 0, Step 798: train/loss = 0.5291776657104492, train/raw-loss = 0.4532374143600464, train/logprobs = tensor([[-0.6333, -4.5756],
        [-0.7510, -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025313429534435272
Epoch 0, Step 799: train/loss = 0.6708076596260071, train/raw-loss = 0.6097458600997925, train/logprobs = tensor([[-0.4540, -0.9927],
        [-0.4321, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020353946834802628
Epoch 0, Step 800: train/loss = 0.5126975774765015, train/raw-loss = 0.43883782625198364, train/logprobs = tensor([[-1.1088, -5.9907],
        [-0.8793, -1.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024619905278086662
Epoch 0, Step 801: train/loss = 0.6076642870903015, train/raw-loss = 0.5290725231170654, train/logprobs = tensor([[-0.8184, -1.6655],
        [-0.7410, -0.5780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026197245344519615
Epoch 0, Step 802: train/loss = 0.51600182056427, train/raw-loss = 0.420390784740448, train/logprobs = tensor([[-0.7559, -5.0366],
        [-0.7863, -1.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031870342791080475
Epoch 0, Step 803: train/loss = 0.7396553754806519, train/raw-loss = 0.6787246465682983, train/logprobs = tensor([[-0.6381, -0.7516],
        [-0.5291, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020310241729021072
Epoch 0, Step 804: train/loss = 0.562441885471344, train/raw-loss = 0.49343425035476685, train/logprobs = tensor([[-0.6556, -2.5589],
        [-0.6848, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02300255186855793
Epoch 0, Step 805: train/loss = 0.6073678731918335, train/raw-loss = 0.5402790307998657, train/logprobs = tensor([[-0.5686, -1.6687],
        [-0.4648, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022362926974892616
Epoch 0, Step 806: train/loss = 0.6124781966209412, train/raw-loss = 0.541887640953064, train/logprobs = tensor([[-0.7798, -1.5827],
        [-0.7158, -0.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023530198261141777
Epoch 0, Step 807: train/loss = 0.4889332354068756, train/raw-loss = 0.42294496297836304, train/logprobs = tensor([[-0.5748, -2.7979],
        [-0.6291, -0.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021996088325977325
Epoch 0, Step 808: train/loss = 0.5758852958679199, train/raw-loss = 0.5091297626495361, train/logprobs = tensor([[-0.6565, -1.7978],
        [-0.6342, -0.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02225186675786972
Epoch 0, Step 809: train/loss = 0.7409865856170654, train/raw-loss = 0.6677310466766357, train/logprobs = tensor([[-0.9596, -1.1663],
        [-0.6638, -0.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024418514221906662
Epoch 0, Step 810: train/loss = 0.5012346506118774, train/raw-loss = 0.42199909687042236, train/logprobs = tensor([[-0.9602, -3.3881],
        [-0.8717, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026411855593323708
Epoch 0, Step 811: train/loss = 0.5872441530227661, train/raw-loss = 0.5163927674293518, train/logprobs = tensor([[-0.6834, -1.7489],
        [-0.6946, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023617137223482132
Epoch 0, Step 812: train/loss = 0.577367901802063, train/raw-loss = 0.5063804388046265, train/logprobs = tensor([[-0.5541, -1.8031],
        [-0.5161, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023662470281124115
Epoch 0, Step 813: train/loss = 0.544671893119812, train/raw-loss = 0.4769013822078705, train/logprobs = tensor([[-0.5663, -1.8486],
        [-0.5720, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022590171545743942
Epoch 0, Step 814: train/loss = 0.5236210823059082, train/raw-loss = 0.45122280716896057, train/logprobs = tensor([[-0.7352, -4.6492],
        [-0.6909, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02413277141749859
Epoch 0, Step 815: train/loss = 0.5265650749206543, train/raw-loss = 0.4608229994773865, train/logprobs = tensor([[-0.5603, -3.4658],
        [-0.5169, -1.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021914035081863403
Epoch 0, Step 816: train/loss = 0.6933152675628662, train/raw-loss = 0.628124475479126, train/logprobs = tensor([[-1.0878, -1.5271],
        [-0.7210, -0.6192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02173025906085968
Epoch 0, Step 817: train/loss = 0.6808655858039856, train/raw-loss = 0.6117793321609497, train/logprobs = tensor([[-0.8271, -1.1542],
        [-0.6280, -0.4929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023028751835227013
Epoch 0, Step 818: train/loss = 0.541922926902771, train/raw-loss = 0.47448351979255676, train/logprobs = tensor([[-0.5553, -1.7461],
        [-0.5937, -0.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022479798644781113
Epoch 0, Step 819: train/loss = 0.5870409607887268, train/raw-loss = 0.5183643698692322, train/logprobs = tensor([[-0.5504, -1.5312],
        [-0.5419, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022892195731401443
Epoch 0, Step 820: train/loss = 0.5402482748031616, train/raw-loss = 0.46669578552246094, train/logprobs = tensor([[-0.6815, -2.3521],
        [-0.7140, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02451750636100769
Epoch 0, Step 821: train/loss = 0.5967239141464233, train/raw-loss = 0.5392613410949707, train/logprobs = tensor([[-0.5339, -4.0498],
        [-0.5313, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01915418542921543
Epoch 0, Step 822: train/loss = 0.5843397378921509, train/raw-loss = 0.5165814757347107, train/logprobs = tensor([[-0.7056, -1.6732],
        [-0.6754, -0.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02258608117699623
Epoch 0, Step 823: train/loss = 0.4194386601448059, train/raw-loss = 0.34493333101272583, train/logprobs = tensor([[-0.5507, -8.1774],
        [-0.6491, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024835117161273956
Epoch 0, Step 824: train/loss = 0.5594300031661987, train/raw-loss = 0.48717769980430603, train/logprobs = tensor([[-0.5943, -1.3636],
        [-0.6584, -0.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024084093049168587
Epoch 0, Step 825: train/loss = 0.5882269144058228, train/raw-loss = 0.5165573358535767, train/logprobs = tensor([[-0.6729, -1.9606],
        [-0.6527, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023889875039458275
Epoch 0, Step 826: train/loss = 0.5937838554382324, train/raw-loss = 0.5353005528450012, train/logprobs = tensor([[-0.4532, -1.3909],
        [-0.4746, -0.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01949443854391575
Epoch 0, Step 827: train/loss = 0.6226261258125305, train/raw-loss = 0.5312231183052063, train/logprobs = tensor([[-0.7629, -1.4977],
        [-0.6514, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030467670410871506
Epoch 0, Step 828: train/loss = 0.577863335609436, train/raw-loss = 0.5099694728851318, train/logprobs = tensor([[-0.6491, -2.3872],
        [-0.5698, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022631289437413216
Epoch 0, Step 829: train/loss = 0.5371744632720947, train/raw-loss = 0.46590378880500793, train/logprobs = tensor([[-0.6076, -1.8226],
        [-0.6999, -0.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02375689521431923
Epoch 0, Step 830: train/loss = 0.6690137386322021, train/raw-loss = 0.6009984016418457, train/logprobs = tensor([[-0.6021, -0.9935],
        [-0.5738, -0.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022671770304441452
Epoch 0, Step 831: train/loss = 0.5418306589126587, train/raw-loss = 0.4659157395362854, train/logprobs = tensor([[-0.6180, -2.7217],
        [-0.6527, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025304967537522316
Epoch 0, Step 832: train/loss = 0.5351622104644775, train/raw-loss = 0.47518131136894226, train/logprobs = tensor([[-0.3779, -2.7299],
        [-0.3984, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019993631169199944
Epoch 0, Step 833: train/loss = 0.6621016263961792, train/raw-loss = 0.6005271673202515, train/logprobs = tensor([[-0.7257, -1.2925],
        [-0.6552, -0.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020524822175502777
Epoch 0, Step 834: train/loss = 0.5203933715820312, train/raw-loss = 0.45700761675834656, train/logprobs = tensor([[-0.7608, -2.3922],
        [-0.7653, -0.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02112858183681965
Epoch 0, Step 835: train/loss = 0.5807349681854248, train/raw-loss = 0.501151442527771, train/logprobs = tensor([[-0.5676, -4.2167],
        [-0.6430, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026527831330895424
Epoch 0, Step 836: train/loss = 0.473658949136734, train/raw-loss = 0.4048181176185608, train/logprobs = tensor([[-0.5800, -4.2646],
        [-0.5939, -1.0295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02294693887233734
Epoch 0, Step 837: train/loss = 0.4779660701751709, train/raw-loss = 0.39732155203819275, train/logprobs = tensor([[-0.6263, -2.5971],
        [-0.6791, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026881510391831398
Epoch 0, Step 838: train/loss = 0.5071130394935608, train/raw-loss = 0.44246143102645874, train/logprobs = tensor([[-0.4377, -1.7347],
        [-0.5738, -0.5957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02155052125453949
Epoch 0, Step 839: train/loss = 0.6911674737930298, train/raw-loss = 0.6411353945732117, train/logprobs = tensor([[-0.5617, -0.6407],
        [-0.5495, -0.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016677359119057655
Epoch 0, Step 840: train/loss = 0.5812429189682007, train/raw-loss = 0.5162122845649719, train/logprobs = tensor([[-0.4432, -1.8225],
        [-0.4748, -0.6812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02167687378823757
Epoch 0, Step 841: train/loss = 0.5894383192062378, train/raw-loss = 0.5213728547096252, train/logprobs = tensor([[-0.7012, -2.6365],
        [-0.6775, -0.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022688470780849457
Epoch 0, Step 842: train/loss = 0.5708571076393127, train/raw-loss = 0.5020116567611694, train/logprobs = tensor([[-0.6872, -1.5141],
        [-0.7643, -0.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022948462516069412
Epoch 0, Step 843: train/loss = 0.6292945146560669, train/raw-loss = 0.583329975605011, train/logprobs = tensor([[-0.4807, -1.1339],
        [-0.4286, -0.5040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015321508049964905
Epoch 0, Step 844: train/loss = 0.5897223353385925, train/raw-loss = 0.5200968384742737, train/logprobs = tensor([[-0.7139, -2.3434],
        [-0.5961, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0232085008174181
Epoch 0, Step 845: train/loss = 0.6309819221496582, train/raw-loss = 0.5600820779800415, train/logprobs = tensor([[-0.6420, -1.1970],
        [-0.7149, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023633282631635666
Epoch 0, Step 846: train/loss = 0.5902376174926758, train/raw-loss = 0.5227940678596497, train/logprobs = tensor([[-0.6251, -1.2669],
        [-0.7865, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02248118259012699
Epoch 0, Step 847: train/loss = 0.5214335918426514, train/raw-loss = 0.4434433579444885, train/logprobs = tensor([[-0.6803, -1.7768],
        [-0.8203, -0.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025996733456850052
Epoch 0, Step 848: train/loss = 0.6067783832550049, train/raw-loss = 0.5368335843086243, train/logprobs = tensor([[-0.5413, -1.5883],
        [-0.6097, -0.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0233149453997612
Epoch 0, Step 849: train/loss = 0.7203106880187988, train/raw-loss = 0.6576635241508484, train/logprobs = tensor([[-0.5476, -0.6691],
        [-0.4985, -0.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02088238298892975
Epoch 0, Step 850: train/loss = 0.46093690395355225, train/raw-loss = 0.3944209814071655, train/logprobs = tensor([[-0.4405, -3.1344],
        [-0.5006, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02217196486890316
Epoch 0, Step 851: train/loss = 0.5736609697341919, train/raw-loss = 0.504782497882843, train/logprobs = tensor([[-0.7174, -1.9272],
        [-0.7448, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02295948565006256
Epoch 0, Step 852: train/loss = 0.4740303158760071, train/raw-loss = 0.40684273838996887, train/logprobs = tensor([[-0.8481, -4.8338],
        [-0.8559, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02239585854113102
Epoch 0, Step 853: train/loss = 0.45493993163108826, train/raw-loss = 0.380953311920166, train/logprobs = tensor([[-0.5251, -4.0512],
        [-0.5468, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024662204086780548
Epoch 0, Step 854: train/loss = 0.5800948143005371, train/raw-loss = 0.5232232809066772, train/logprobs = tensor([[-0.8271, -2.7286],
        [-0.7887, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01895718276500702
Epoch 0, Step 855: train/loss = 0.6273646354675293, train/raw-loss = 0.5699820518493652, train/logprobs = tensor([[-0.7453, -2.1250],
        [-0.6873, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019127529114484787
Epoch 0, Step 856: train/loss = 0.5322006940841675, train/raw-loss = 0.4784199595451355, train/logprobs = tensor([[-0.3924, -2.4398],
        [-0.4583, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017926905304193497
Epoch 0, Step 857: train/loss = 0.4879004657268524, train/raw-loss = 0.425205796957016, train/logprobs = tensor([[-0.6553, -3.0117],
        [-0.6695, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020898224785923958
Epoch 0, Step 858: train/loss = 0.5935148596763611, train/raw-loss = 0.5266547203063965, train/logprobs = tensor([[-0.9409, -4.2765],
        [-0.7042, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02228671684861183
Epoch 0, Step 859: train/loss = 0.5845580697059631, train/raw-loss = 0.5326331853866577, train/logprobs = tensor([[-0.4140, -1.3422],
        [-0.4431, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01730828732252121
Epoch 0, Step 860: train/loss = 0.5225528478622437, train/raw-loss = 0.45015743374824524, train/logprobs = tensor([[-0.6494, -2.7418],
        [-0.6993, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024131810292601585
Epoch 0, Step 861: train/loss = 0.5697052478790283, train/raw-loss = 0.49467191100120544, train/logprobs = tensor([[-0.5079, -1.6617],
        [-0.5506, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025011122226715088
Epoch 0, Step 862: train/loss = 0.5725334882736206, train/raw-loss = 0.5035444498062134, train/logprobs = tensor([[-0.4858, -1.8278],
        [-0.4956, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022996343672275543
Epoch 0, Step 863: train/loss = 0.5714171528816223, train/raw-loss = 0.4922381639480591, train/logprobs = tensor([[-0.7398, -1.4010],
        [-1.0615, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026392988860607147
Epoch 0, Step 864: train/loss = 0.5454546809196472, train/raw-loss = 0.4656578302383423, train/logprobs = tensor([[-0.7440, -1.8899],
        [-0.8654, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026598958298563957
Epoch 0, Step 865: train/loss = 0.5748313069343567, train/raw-loss = 0.5150682330131531, train/logprobs = tensor([[-0.4174, -2.3900],
        [-0.4227, -0.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019921015948057175
Epoch 0, Step 866: train/loss = 0.6094301342964172, train/raw-loss = 0.5409132838249207, train/logprobs = tensor([[-0.5429, -1.3491],
        [-0.4810, -0.4821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022838952019810677
Epoch 0, Step 867: train/loss = 0.4568290710449219, train/raw-loss = 0.3835230767726898, train/logprobs = tensor([[-0.6910, -3.1443],
        [-0.8555, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02443532831966877
Epoch 0, Step 868: train/loss = 0.5984449982643127, train/raw-loss = 0.5308905839920044, train/logprobs = tensor([[-0.8319, -2.0797],
        [-0.5224, -0.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02251812443137169
Epoch 0, Step 869: train/loss = 0.595894992351532, train/raw-loss = 0.5239208340644836, train/logprobs = tensor([[-1.2404, -2.6930],
        [-0.8522, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023991378024220467
Epoch 0, Step 870: train/loss = 0.5387038588523865, train/raw-loss = 0.4667667746543884, train/logprobs = tensor([[-0.7966, -1.2536],
        [-1.0772, -0.3569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023979023098945618
Epoch 0, Step 871: train/loss = 0.44654381275177, train/raw-loss = 0.3724139332771301, train/logprobs = tensor([[-0.6436, -5.1392],
        [-0.7733, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024709969758987427
Epoch 0, Step 872: train/loss = 0.6630986928939819, train/raw-loss = 0.5795142650604248, train/logprobs = tensor([[-0.7759, -1.1839],
        [-0.7546, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027861468493938446
Epoch 0, Step 873: train/loss = 0.506376326084137, train/raw-loss = 0.43939122557640076, train/logprobs = tensor([[-0.4905, -2.9729],
        [-0.5647, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022328369319438934
Epoch 0, Step 874: train/loss = 0.4433611035346985, train/raw-loss = 0.3761233389377594, train/logprobs = tensor([[-0.6091, -5.1708],
        [-0.8409, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022412586957216263
Epoch 0, Step 875: train/loss = 0.6233977675437927, train/raw-loss = 0.557558000087738, train/logprobs = tensor([[-0.5179, -1.4896],
        [-0.5961, -0.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021946623921394348
Epoch 0, Step 876: train/loss = 0.5531079769134521, train/raw-loss = 0.484664648771286, train/logprobs = tensor([[-0.6853, -2.0196],
        [-0.6732, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022814445197582245
Epoch 0, Step 877: train/loss = 0.4444289207458496, train/raw-loss = 0.3723881244659424, train/logprobs = tensor([[-0.5663, -2.9327],
        [-0.6208, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024013593792915344
Epoch 0, Step 878: train/loss = 0.6241240501403809, train/raw-loss = 0.5597689151763916, train/logprobs = tensor([[-0.5333, -1.5487],
        [-0.5558, -0.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021451730281114578
Epoch 0, Step 879: train/loss = 0.5149118900299072, train/raw-loss = 0.4502643644809723, train/logprobs = tensor([[-0.8072, -2.6347],
        [-0.7034, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02154916152358055
Epoch 0, Step 880: train/loss = 0.6381840705871582, train/raw-loss = 0.5859222412109375, train/logprobs = tensor([[-0.6020, -1.0680],
        [-0.6042, -0.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017420601099729538
Epoch 0, Step 881: train/loss = 0.5419402122497559, train/raw-loss = 0.47585052251815796, train/logprobs = tensor([[-0.5475, -1.7736],
        [-0.5908, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02202988602221012
Epoch 0, Step 882: train/loss = 0.5475411415100098, train/raw-loss = 0.4693700075149536, train/logprobs = tensor([[-0.6546, -1.8880],
        [-0.6356, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026057053357362747
Epoch 0, Step 883: train/loss = 0.4779696464538574, train/raw-loss = 0.3953080177307129, train/logprobs = tensor([[-0.5656, -3.3762],
        [-0.6488, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027553874999284744
Epoch 0, Step 884: train/loss = 0.5681499242782593, train/raw-loss = 0.503291666507721, train/logprobs = tensor([[-0.9071, -3.2664],
        [-0.5237, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02161942794919014
Epoch 0, Step 885: train/loss = 0.4892374873161316, train/raw-loss = 0.41985899209976196, train/logprobs = tensor([[-0.7282, -3.7965],
        [-0.7864, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02312617003917694
Epoch 0, Step 886: train/loss = 0.6221114993095398, train/raw-loss = 0.5461623668670654, train/logprobs = tensor([[-0.5545, -1.2677],
        [-0.5503, -0.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025316379964351654
Epoch 0, Step 887: train/loss = 0.5149103999137878, train/raw-loss = 0.43709221482276917, train/logprobs = tensor([[-0.7239, -7.6730],
        [-0.6366, -1.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025939399376511574
Epoch 0, Step 888: train/loss = 0.5220986604690552, train/raw-loss = 0.4646090865135193, train/logprobs = tensor([[-0.4633, -1.9482],
        [-0.5252, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019163191318511963
Epoch 0, Step 889: train/loss = 0.5526912212371826, train/raw-loss = 0.4839305877685547, train/logprobs = tensor([[-0.5370, -1.8243],
        [-0.5728, -0.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022920209914445877
Epoch 0, Step 890: train/loss = 0.5291874408721924, train/raw-loss = 0.4524557590484619, train/logprobs = tensor([[-0.7343, -2.0381],
        [-0.7829, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02557721734046936
