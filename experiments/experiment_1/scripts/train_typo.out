[2024-03-09 21:06:15,322][root][INFO] - beta: 0.1
[2024-03-09 21:06:15,322][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-iteration-1
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 6250
n harmless: 6250
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can purchase a set at most sporting goods stores or online.\n\nOnce you have your set, find a flat, open area to play. The game is played by tossing horseshoes at a stake, trying to get them as close to the stake as possible. The player with the closest horseshoe to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies to learn from experienced players.\n\nRemember to have fun and enjoy the challenge of this classic game!", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Sure, I can teach you how to play horseshoes.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, dick, pussy, cunt, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, pr', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: What are some cuss words in english?\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k\n- B*tch\n- D*ck\n- A**hole\n- S**t\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- C**t\n- F**k', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, dick, pussy, cunt, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, pr'}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-iteration-1.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-iteration-1.
25000
tokenized 25000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-iteration-1.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-0.1-iteration-1.
Epoch 0, Step 0: train/loss = 0.5327303409576416, train/raw-loss = 0.5327303409576416, train/logprobs = tensor([[-0.8071, -2.9355],
        [-1.0319, -2.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6757681369781494, train/raw-loss = 0.6757681369781494, train/logprobs = tensor([[-0.6583, -1.0265],
        [-0.6770, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6687531471252441, train/raw-loss = 0.6687531471252441, train/logprobs = tensor([[-0.4941, -0.6953],
        [-0.5460, -0.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6216553449630737, train/raw-loss = 0.6216553449630737, train/logprobs = tensor([[-0.5512, -1.5712],
        [-0.6259, -1.3220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6579127311706543, train/raw-loss = 0.6579127311706543, train/logprobs = tensor([[-0.4046, -1.1550],
        [-0.4271, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.683114767074585, train/raw-loss = 0.683114767074585, train/logprobs = tensor([[-0.4908, -0.8480],
        [-0.5737, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6553336977958679, train/raw-loss = 0.6553336977958679, train/logprobs = tensor([[-0.6499, -0.7840],
        [-0.8093, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6633836627006531, train/raw-loss = 0.6633836627006531, train/logprobs = tensor([[-0.5876, -0.8497],
        [-0.6472, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6661855578422546, train/raw-loss = 0.6661855578422546, train/logprobs = tensor([[-0.3025, -0.9421],
        [-0.3159, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.5489578247070312, train/raw-loss = 0.5489578247070312, train/logprobs = tensor([[-0.8824, -2.8940],
        [-1.1310, -2.3592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6677992343902588, train/raw-loss = 0.6677992343902588, train/logprobs = tensor([[-0.4517, -0.3421],
        [-0.5168, -0.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6236667633056641, train/raw-loss = 0.6236667633056641, train/logprobs = tensor([[-0.5432, -1.0997],
        [-0.6253, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6509023904800415, train/raw-loss = 0.6509023904800415, train/logprobs = tensor([[-0.4976, -1.1860],
        [-0.5380, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6323549151420593, train/raw-loss = 0.6323549151420593, train/logprobs = tensor([[-0.6377, -1.3750],
        [-0.7252, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.5607563257217407, train/raw-loss = 0.5607563257217407, train/logprobs = tensor([[-0.6111, -2.0697],
        [-0.6871, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6592469811439514, train/raw-loss = 0.6592469811439514, train/logprobs = tensor([[-0.5807, -0.6984],
        [-0.6892, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6709405183792114, train/raw-loss = 0.6709405183792114, train/logprobs = tensor([[-0.5892, -0.7261],
        [-0.6759, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6233722567558289, train/raw-loss = 0.6233722567558289, train/logprobs = tensor([[-0.5897, -1.1129],
        [-0.6872, -0.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6895330548286438, train/raw-loss = 0.6895330548286438, train/logprobs = tensor([[-0.5934, -0.5665],
        [-0.6163, -0.5746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6720938682556152, train/raw-loss = 0.6720938682556152, train/logprobs = tensor([[-0.6830, -0.8781],
        [-0.7904, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6378501653671265, train/raw-loss = 0.6378501653671265, train/logprobs = tensor([[-0.4698, -1.1357],
        [-0.5262, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6693183779716492, train/raw-loss = 0.6693183779716492, train/logprobs = tensor([[-0.5805, -1.1611],
        [-0.6451, -1.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6538590788841248, train/raw-loss = 0.6538590788841248, train/logprobs = tensor([[-0.5006, -1.2025],
        [-0.5373, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6639240980148315, train/raw-loss = 0.6639240980148315, train/logprobs = tensor([[-0.5435, -0.7506],
        [-0.6170, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6878432631492615, train/raw-loss = 0.6878432631492615, train/logprobs = tensor([[-0.4281, -0.5477],
        [-0.4747, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6308262348175049, train/raw-loss = 0.6308262348175049, train/logprobs = tensor([[-0.6691, -1.2088],
        [-0.7548, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6479334831237793, train/raw-loss = 0.6479334831237793, train/logprobs = tensor([[-0.4684, -0.8287],
        [-0.5051, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6747323274612427, train/raw-loss = 0.6747323274612427, train/logprobs = tensor([[-0.6166, -0.6681],
        [-0.6605, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6420373916625977, train/raw-loss = 0.6420373916625977, train/logprobs = tensor([[-0.5899, -1.3341],
        [-0.7096, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6611607074737549, train/raw-loss = 0.6611607074737549, train/logprobs = tensor([[-0.4098, -0.9505],
        [-0.4431, -0.8512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6610521078109741, train/raw-loss = 0.6610521078109741, train/logprobs = tensor([[-0.5358, -0.9149],
        [-0.5798, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6506096124649048, train/raw-loss = 0.6506096124649048, train/logprobs = tensor([[-0.7854, -1.1514],
        [-0.9133, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.660994291305542, train/raw-loss = 0.660994291305542, train/logprobs = tensor([[-0.4702, -0.8304],
        [-0.5487, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6619232892990112, train/raw-loss = 0.6619232892990112, train/logprobs = tensor([[-0.6717, -0.9461],
        [-0.7005, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.673113226890564, train/raw-loss = 0.673113226890564, train/logprobs = tensor([[-0.4912, -1.0639],
        [-0.5204, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6580444574356079, train/raw-loss = 0.6580444574356079, train/logprobs = tensor([[-0.6095, -1.0459],
        [-0.6646, -0.9563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6668177843093872, train/raw-loss = 0.6668177843093872, train/logprobs = tensor([[-0.5206, -0.8773],
        [-0.5453, -0.7910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6535869240760803, train/raw-loss = 0.6535869240760803, train/logprobs = tensor([[-0.8591, -1.1098],
        [-1.0230, -1.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6462055444717407, train/raw-loss = 0.6462055444717407, train/logprobs = tensor([[-0.6383, -0.8831],
        [-0.7650, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6589335203170776, train/raw-loss = 0.6589335203170776, train/logprobs = tensor([[-0.5760, -0.5893],
        [-0.6924, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6720525026321411, train/raw-loss = 0.6720525026321411, train/logprobs = tensor([[-0.5038, -0.6410],
        [-0.5181, -0.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6642957925796509, train/raw-loss = 0.6642957925796509, train/logprobs = tensor([[-0.5741, -0.8131],
        [-0.6032, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6708586812019348, train/raw-loss = 0.6708586812019348, train/logprobs = tensor([[-0.5863, -0.7004],
        [-0.6134, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6479618549346924, train/raw-loss = 0.6479618549346924, train/logprobs = tensor([[-0.5509, -0.9771],
        [-0.6408, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6111243963241577, train/raw-loss = 0.6111243963241577, train/logprobs = tensor([[-0.4314, -2.0323],
        [-0.4620, -1.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.5839340090751648, train/raw-loss = 0.5839340090751648, train/logprobs = tensor([[-0.4996, -2.0368],
        [-0.5312, -1.5492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6810438632965088, train/raw-loss = 0.6810438632965088, train/logprobs = tensor([[-0.5093, -0.7886],
        [-0.5134, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6813392043113708, train/raw-loss = 0.6813392043113708, train/logprobs = tensor([[-0.4674, -0.5622],
        [-0.5299, -0.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6392419338226318, train/raw-loss = 0.6392419338226318, train/logprobs = tensor([[-0.4316, -1.1637],
        [-0.4364, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6217007040977478, train/raw-loss = 0.6217007040977478, train/logprobs = tensor([[-0.5927, -0.9797],
        [-0.7141, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6564667224884033, train/raw-loss = 0.6564667224884033, train/logprobs = tensor([[-0.5338, -0.9557],
        [-0.6302, -0.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6534794569015503, train/raw-loss = 0.6534794569015503, train/logprobs = tensor([[-0.3225, -0.8862],
        [-0.3480, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6724396347999573, train/raw-loss = 0.6724396347999573, train/logprobs = tensor([[-0.4785, -0.7144],
        [-0.5102, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.5419564247131348, train/raw-loss = 0.5419564247131348, train/logprobs = tensor([[-0.6331, -2.3349],
        [-0.8375, -1.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6360349655151367, train/raw-loss = 0.6360349655151367, train/logprobs = tensor([[-0.5770, -0.9309],
        [-0.6844, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6616557836532593, train/raw-loss = 0.6616557836532593, train/logprobs = tensor([[-0.6555, -0.7382],
        [-0.7202, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.5522400140762329, train/raw-loss = 0.5522400140762329, train/logprobs = tensor([[-0.6200, -2.1499],
        [-0.6792, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6215718388557434, train/raw-loss = 0.6215718388557434, train/logprobs = tensor([[-0.6115, -1.2422],
        [-0.7445, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6267923712730408, train/raw-loss = 0.6267923712730408, train/logprobs = tensor([[-2.0627, -3.6992],
        [-2.2622, -3.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6431835889816284, train/raw-loss = 0.6431835889816284, train/logprobs = tensor([[-0.4745, -1.0747],
        [-0.5317, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6350677013397217, train/raw-loss = 0.6350677013397217, train/logprobs = tensor([[-0.4349, -0.9633],
        [-0.5089, -0.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6650807857513428, train/raw-loss = 0.6650807857513428, train/logprobs = tensor([[-0.4906, -0.6698],
        [-0.5216, -0.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6418758034706116, train/raw-loss = 0.6418758034706116, train/logprobs = tensor([[-0.5821, -0.8942],
        [-0.6461, -0.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6507992148399353, train/raw-loss = 0.6507992148399353, train/logprobs = tensor([[-0.5641, -1.2237],
        [-0.5906, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6681196093559265, train/raw-loss = 0.6675485372543335, train/logprobs = tensor([[-0.5420, -0.8286],
        [-0.5483, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005711024161428213
Epoch 0, Step 65: train/loss = 0.6192637085914612, train/raw-loss = 0.6187270879745483, train/logprobs = tensor([[-0.5153, -1.1256],
        [-0.5864, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053663309663534164
Epoch 0, Step 66: train/loss = 0.649095892906189, train/raw-loss = 0.6484413146972656, train/logprobs = tensor([[-1.0936, -1.6826],
        [-1.0331, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065462626516819
Epoch 0, Step 67: train/loss = 0.6496197581291199, train/raw-loss = 0.6490083336830139, train/logprobs = tensor([[-0.4787, -1.1267],
        [-0.4902, -0.9354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006114516407251358
Epoch 0, Step 68: train/loss = 0.6374996900558472, train/raw-loss = 0.6368952989578247, train/logprobs = tensor([[-0.6183, -1.1384],
        [-0.6442, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006043500732630491
Epoch 0, Step 69: train/loss = 0.5743396282196045, train/raw-loss = 0.573681116104126, train/logprobs = tensor([[-0.6789, -2.5122],
        [-0.6979, -1.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006585101597011089
Epoch 0, Step 70: train/loss = 0.624591588973999, train/raw-loss = 0.6241769790649414, train/logprobs = tensor([[-0.4150, -1.1795],
        [-0.4248, -0.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041466704569756985
Epoch 0, Step 71: train/loss = 0.6173800230026245, train/raw-loss = 0.6166374683380127, train/logprobs = tensor([[-0.5554, -0.8012],
        [-0.6482, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007425352465361357
Epoch 0, Step 72: train/loss = 0.5634737610816956, train/raw-loss = 0.5627415180206299, train/logprobs = tensor([[-0.7084, -1.6878],
        [-0.7753, -1.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007322492077946663
Epoch 0, Step 73: train/loss = 0.6264778971672058, train/raw-loss = 0.6257616877555847, train/logprobs = tensor([[-0.6165, -0.9866],
        [-0.6193, -0.6923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007162133231759071
Epoch 0, Step 74: train/loss = 0.6056659817695618, train/raw-loss = 0.6050955057144165, train/logprobs = tensor([[-0.6392, -1.5832],
        [-0.7182, -1.2790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0057052490301430225
Epoch 0, Step 75: train/loss = 0.5669417977333069, train/raw-loss = 0.5664553642272949, train/logprobs = tensor([[-0.4641, -2.3858],
        [-0.5004, -1.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004864190239459276
Epoch 0, Step 76: train/loss = 0.6268332004547119, train/raw-loss = 0.626160740852356, train/logprobs = tensor([[-0.5929, -1.2425],
        [-0.5840, -0.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067239124327898026
Epoch 0, Step 77: train/loss = 0.6576608419418335, train/raw-loss = 0.6569725871086121, train/logprobs = tensor([[-0.6383, -0.5341],
        [-0.6833, -0.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006882099434733391
Epoch 0, Step 78: train/loss = 0.5691693425178528, train/raw-loss = 0.5684618353843689, train/logprobs = tensor([[-0.7153, -1.8546],
        [-0.8591, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007075268775224686
Epoch 0, Step 79: train/loss = 0.5814144611358643, train/raw-loss = 0.5808092355728149, train/logprobs = tensor([[-0.4701, -1.6826],
        [-0.4864, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006052213720977306
Epoch 0, Step 80: train/loss = 0.5803847312927246, train/raw-loss = 0.5796070098876953, train/logprobs = tensor([[-0.6192, -1.5659],
        [-0.6574, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00777701148763299
Epoch 0, Step 81: train/loss = 0.6465416550636292, train/raw-loss = 0.6460283994674683, train/logprobs = tensor([[-0.4710, -0.8363],
        [-0.4787, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005132986698299646
Epoch 0, Step 82: train/loss = 0.4591882824897766, train/raw-loss = 0.4586532711982727, train/logprobs = tensor([[-0.7326, -4.1522],
        [-0.6837, -2.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005350124556571245
Epoch 0, Step 83: train/loss = 0.660110354423523, train/raw-loss = 0.6595802307128906, train/logprobs = tensor([[-0.5219, -0.8532],
        [-0.5393, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005301540717482567
Epoch 0, Step 84: train/loss = 0.6219527721405029, train/raw-loss = 0.6213552355766296, train/logprobs = tensor([[-0.6176, -1.0983],
        [-0.7150, -0.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059751239605247974
Epoch 0, Step 85: train/loss = 0.6322171092033386, train/raw-loss = 0.6315711140632629, train/logprobs = tensor([[-0.5021, -1.1066],
        [-0.5122, -0.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006459539756178856
Epoch 0, Step 86: train/loss = 0.6606176495552063, train/raw-loss = 0.659890353679657, train/logprobs = tensor([[-0.6117, -1.2222],
        [-0.6237, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007272533141076565
Epoch 0, Step 87: train/loss = 0.6553056240081787, train/raw-loss = 0.6546878814697266, train/logprobs = tensor([[-0.4668, -1.2300],
        [-0.4498, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006176955997943878
Epoch 0, Step 88: train/loss = 0.6756659746170044, train/raw-loss = 0.6750484108924866, train/logprobs = tensor([[-0.4617, -0.6654],
        [-0.4615, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006175956688821316
Epoch 0, Step 89: train/loss = 0.6351636052131653, train/raw-loss = 0.6346545815467834, train/logprobs = tensor([[-0.4672, -1.3462],
        [-0.5172, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005090832710266113
Epoch 0, Step 90: train/loss = 0.5474445223808289, train/raw-loss = 0.5468519330024719, train/logprobs = tensor([[-0.5397, -2.8176],
        [-0.5535, -1.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005925863049924374
Epoch 0, Step 91: train/loss = 0.6625271439552307, train/raw-loss = 0.6616767048835754, train/logprobs = tensor([[-0.6407, -0.6617],
        [-0.6669, -0.5572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008504501543939114
Epoch 0, Step 92: train/loss = 0.5569328665733337, train/raw-loss = 0.5564582347869873, train/logprobs = tensor([[-0.4237, -1.8910],
        [-0.4554, -1.2757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004746392369270325
Epoch 0, Step 93: train/loss = 0.6666682958602905, train/raw-loss = 0.6661128997802734, train/logprobs = tensor([[-0.4368, -0.6473],
        [-0.4577, -0.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005553853698074818
Epoch 0, Step 94: train/loss = 0.5136376619338989, train/raw-loss = 0.5130132436752319, train/logprobs = tensor([[-0.5585, -2.9917],
        [-0.5675, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062441229820251465
Epoch 0, Step 95: train/loss = 0.6275263428688049, train/raw-loss = 0.6268977522850037, train/logprobs = tensor([[-0.6813, -1.0266],
        [-0.7764, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062850890681147575
Epoch 0, Step 96: train/loss = 0.5702747106552124, train/raw-loss = 0.5670446157455444, train/logprobs = tensor([[-0.6576, -1.6405],
        [-0.5994, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03230154886841774
Epoch 0, Step 97: train/loss = 0.5151299238204956, train/raw-loss = 0.5126535892486572, train/logprobs = tensor([[-0.5344, -2.1165],
        [-0.5195, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024762969464063644
Epoch 0, Step 98: train/loss = 0.6144933104515076, train/raw-loss = 0.6113353967666626, train/logprobs = tensor([[-0.6073, -1.3917],
        [-0.5836, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03157868981361389
Epoch 0, Step 99: train/loss = 0.49946141242980957, train/raw-loss = 0.4961508810520172, train/logprobs = tensor([[-0.8313, -3.4686],
        [-0.8482, -1.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03310537338256836
Epoch 0, Step 100: train/loss = 0.6453911662101746, train/raw-loss = 0.6419705748558044, train/logprobs = tensor([[-0.6128, -1.2673],
        [-0.5585, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03420591726899147
Epoch 0, Step 101: train/loss = 0.5919613838195801, train/raw-loss = 0.5885724425315857, train/logprobs = tensor([[-0.6601, -1.6996],
        [-0.6382, -1.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033889397978782654
Epoch 0, Step 102: train/loss = 0.6924934983253479, train/raw-loss = 0.6881140470504761, train/logprobs = tensor([[-0.5200, -0.9503],
        [-0.5113, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043794166296720505
Epoch 0, Step 103: train/loss = 0.47977662086486816, train/raw-loss = 0.4772987961769104, train/logprobs = tensor([[-0.5823, -2.1836],
        [-0.5577, -0.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02477853372693062
Epoch 0, Step 104: train/loss = 0.5497795343399048, train/raw-loss = 0.5474215745925903, train/logprobs = tensor([[-0.4792, -1.9162],
        [-0.4399, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02357935905456543
Epoch 0, Step 105: train/loss = 0.5487516522407532, train/raw-loss = 0.545802116394043, train/logprobs = tensor([[-0.6876, -4.1713],
        [-0.6813, -2.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02949550934135914
Epoch 0, Step 106: train/loss = 0.513144850730896, train/raw-loss = 0.5093012452125549, train/logprobs = tensor([[-0.9780, -2.3439],
        [-1.0683, -1.4604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03843560814857483
Epoch 0, Step 107: train/loss = 0.4743987023830414, train/raw-loss = 0.4718676805496216, train/logprobs = tensor([[-0.5886, -3.4351],
        [-0.6132, -1.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02531060390174389
Epoch 0, Step 108: train/loss = 0.6168578863143921, train/raw-loss = 0.6137946248054504, train/logprobs = tensor([[-0.4795, -1.5862],
        [-0.5000, -1.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03063237853348255
Epoch 0, Step 109: train/loss = 0.675152599811554, train/raw-loss = 0.6717291474342346, train/logprobs = tensor([[-0.8603, -0.9102],
        [-0.7763, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03423410654067993
Epoch 0, Step 110: train/loss = 0.6576142907142639, train/raw-loss = 0.6545535326004028, train/logprobs = tensor([[-0.4773, -1.0380],
        [-0.4435, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03060816042125225
Epoch 0, Step 111: train/loss = 0.5918605923652649, train/raw-loss = 0.5888258218765259, train/logprobs = tensor([[-0.6290, -1.4912],
        [-0.5721, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030347680673003197
Epoch 0, Step 112: train/loss = 0.6819297075271606, train/raw-loss = 0.6786998510360718, train/logprobs = tensor([[-0.6467, -0.8614],
        [-0.5331, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03229901194572449
Epoch 0, Step 113: train/loss = 0.5166553258895874, train/raw-loss = 0.5152437686920166, train/logprobs = tensor([[-0.2727, -2.1221],
        [-0.2732, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014115937054157257
Epoch 0, Step 114: train/loss = 0.572425365447998, train/raw-loss = 0.5698260068893433, train/logprobs = tensor([[-0.5466, -1.3744],
        [-0.5530, -0.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025993643328547478
Epoch 0, Step 115: train/loss = 0.6004611253738403, train/raw-loss = 0.5974164605140686, train/logprobs = tensor([[-0.6817, -2.2546],
        [-0.6154, -1.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030446689575910568
Epoch 0, Step 116: train/loss = 0.6199980974197388, train/raw-loss = 0.6166470646858215, train/logprobs = tensor([[-0.5477, -1.0882],
        [-0.4802, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03351013362407684
Epoch 0, Step 117: train/loss = 0.5523026585578918, train/raw-loss = 0.5485966205596924, train/logprobs = tensor([[-1.0781, -2.2777],
        [-1.0900, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037060271948575974
Epoch 0, Step 118: train/loss = 0.5819876790046692, train/raw-loss = 0.5785350799560547, train/logprobs = tensor([[-0.6688, -1.5467],
        [-0.6638, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034525614231824875
Epoch 0, Step 119: train/loss = 0.6275593638420105, train/raw-loss = 0.6250337362289429, train/logprobs = tensor([[-0.5763, -0.9802],
        [-0.6007, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025256536900997162
Epoch 0, Step 120: train/loss = 0.5978289842605591, train/raw-loss = 0.5943322777748108, train/logprobs = tensor([[-0.6851, -1.5314],
        [-0.6428, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03496696054935455
Epoch 0, Step 121: train/loss = 0.5875691771507263, train/raw-loss = 0.584846019744873, train/logprobs = tensor([[-0.8227, -1.4759],
        [-0.7183, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027231717482209206
Epoch 0, Step 122: train/loss = 0.5375506281852722, train/raw-loss = 0.5341115593910217, train/logprobs = tensor([[-0.6686, -2.7047],
        [-0.6350, -1.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03439078480005264
Epoch 0, Step 123: train/loss = 0.6093571186065674, train/raw-loss = 0.6058135628700256, train/logprobs = tensor([[-0.8005, -1.5707],
        [-0.7671, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035435862839221954
Epoch 0, Step 124: train/loss = 0.5906094312667847, train/raw-loss = 0.5878205299377441, train/logprobs = tensor([[-0.6925, -1.7112],
        [-0.6120, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02788899466395378
Epoch 0, Step 125: train/loss = 0.6078841090202332, train/raw-loss = 0.6048252582550049, train/logprobs = tensor([[-0.6639, -1.2436],
        [-0.6212, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030589010566473007
Epoch 0, Step 126: train/loss = 0.5809854865074158, train/raw-loss = 0.5779286026954651, train/logprobs = tensor([[-0.7197, -2.6256],
        [-0.7214, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03056882694363594
Epoch 0, Step 127: train/loss = 0.6061902642250061, train/raw-loss = 0.6028037071228027, train/logprobs = tensor([[-0.5960, -1.5332],
        [-0.5996, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033865686506032944
Epoch 0, Step 128: train/loss = 0.6743769645690918, train/raw-loss = 0.6663011908531189, train/logprobs = tensor([[-0.7344, -0.9288],
        [-0.4793, -0.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08075787872076035
Epoch 0, Step 129: train/loss = 0.5908480882644653, train/raw-loss = 0.584002673625946, train/logprobs = tensor([[-0.5710, -2.6563],
        [-0.5275, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06845404952764511
Epoch 0, Step 130: train/loss = 0.6219969987869263, train/raw-loss = 0.6155518889427185, train/logprobs = tensor([[-0.7589, -1.4978],
        [-0.5212, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06445059180259705
Epoch 0, Step 131: train/loss = 0.5460744500160217, train/raw-loss = 0.5392533540725708, train/logprobs = tensor([[-0.7031, -2.2080],
        [-0.6102, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821086257696152
Epoch 0, Step 132: train/loss = 0.6709387302398682, train/raw-loss = 0.6627180576324463, train/logprobs = tensor([[-0.5900, -1.0533],
        [-0.5300, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08220651745796204
Epoch 0, Step 133: train/loss = 0.535642147064209, train/raw-loss = 0.5291968584060669, train/logprobs = tensor([[-0.5142, -3.6501],
        [-0.4443, -1.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06445310264825821
Epoch 0, Step 134: train/loss = 0.5875100493431091, train/raw-loss = 0.5801613330841064, train/logprobs = tensor([[-0.5466, -5.2053],
        [-0.5227, -2.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07348755747079849
Epoch 0, Step 135: train/loss = 0.6570518016815186, train/raw-loss = 0.6496105790138245, train/logprobs = tensor([[-0.6735, -0.9739],
        [-0.6044, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441165298223495
Epoch 0, Step 136: train/loss = 0.706547200679779, train/raw-loss = 0.6981958150863647, train/logprobs = tensor([[-0.7480, -1.0315],
        [-0.6844, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08351442217826843
Epoch 0, Step 137: train/loss = 0.5928937196731567, train/raw-loss = 0.5853179097175598, train/logprobs = tensor([[-0.7353, -1.7287],
        [-0.5371, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075757697224617
Epoch 0, Step 138: train/loss = 0.5795695185661316, train/raw-loss = 0.5735263228416443, train/logprobs = tensor([[-0.5780, -1.7414],
        [-0.5224, -1.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06043176352977753
Epoch 0, Step 139: train/loss = 0.5304247736930847, train/raw-loss = 0.5220654010772705, train/logprobs = tensor([[-0.6302, -1.8860],
        [-0.5150, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08359315991401672
Epoch 0, Step 140: train/loss = 0.5145924091339111, train/raw-loss = 0.5088133811950684, train/logprobs = tensor([[-0.6888, -1.7953],
        [-0.6815, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05779017135500908
Epoch 0, Step 141: train/loss = 0.6553338766098022, train/raw-loss = 0.6466185450553894, train/logprobs = tensor([[-0.9044, -1.2319],
        [-0.8097, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08715317398309708
Epoch 0, Step 142: train/loss = 0.4726821482181549, train/raw-loss = 0.46727973222732544, train/logprobs = tensor([[-0.4494, -2.2922],
        [-0.3970, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054024599492549896
Epoch 0, Step 143: train/loss = 0.552142322063446, train/raw-loss = 0.5460814833641052, train/logprobs = tensor([[-0.5355, -1.8526],
        [-0.4341, -0.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06060852110385895
Epoch 0, Step 144: train/loss = 0.6406774520874023, train/raw-loss = 0.6315079927444458, train/logprobs = tensor([[-0.8590, -1.2850],
        [-0.8011, -0.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09169471263885498
Epoch 0, Step 145: train/loss = 0.553547739982605, train/raw-loss = 0.5472266674041748, train/logprobs = tensor([[-0.7845, -2.1011],
        [-0.6239, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06321106106042862
Epoch 0, Step 146: train/loss = 0.4882524311542511, train/raw-loss = 0.4811415672302246, train/logprobs = tensor([[-0.7672, -4.3205],
        [-0.5659, -1.5945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07110875844955444
Epoch 0, Step 147: train/loss = 0.6060996055603027, train/raw-loss = 0.6005944609642029, train/logprobs = tensor([[-0.4907, -1.0069],
        [-0.4035, -0.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05505160242319107
Epoch 0, Step 148: train/loss = 0.5553081631660461, train/raw-loss = 0.5485290288925171, train/logprobs = tensor([[-0.6149, -1.7712],
        [-0.5098, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06779180467128754
Epoch 0, Step 149: train/loss = 0.6053974032402039, train/raw-loss = 0.5974477529525757, train/logprobs = tensor([[-0.8856, -1.3277],
        [-0.7812, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07949651777744293
Epoch 0, Step 150: train/loss = 0.5626289248466492, train/raw-loss = 0.5550845265388489, train/logprobs = tensor([[-0.5462, -1.8420],
        [-0.5343, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07544386386871338
Epoch 0, Step 151: train/loss = 0.6855932474136353, train/raw-loss = 0.6775551438331604, train/logprobs = tensor([[-0.9070, -1.0222],
        [-0.8435, -0.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08038091659545898
Epoch 0, Step 152: train/loss = 0.5749149322509766, train/raw-loss = 0.5704959630966187, train/logprobs = tensor([[-0.4701, -1.2341],
        [-0.4123, -0.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044189728796482086
Epoch 0, Step 153: train/loss = 0.7267976999282837, train/raw-loss = 0.7176201939582825, train/logprobs = tensor([[-1.1764, -1.1356],
        [-0.7753, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177540242671967
Epoch 0, Step 154: train/loss = 0.5323694944381714, train/raw-loss = 0.5258026719093323, train/logprobs = tensor([[-0.6984, -3.4128],
        [-0.5897, -1.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0656682625412941
Epoch 0, Step 155: train/loss = 0.5270452499389648, train/raw-loss = 0.5197020769119263, train/logprobs = tensor([[-0.7040, -2.0227],
        [-0.5844, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07343223690986633
Epoch 0, Step 156: train/loss = 0.5024636387825012, train/raw-loss = 0.4938431978225708, train/logprobs = tensor([[-0.8462, -3.1783],
        [-0.6923, -1.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08620448410511017
Epoch 0, Step 157: train/loss = 0.7251558303833008, train/raw-loss = 0.7181822657585144, train/logprobs = tensor([[-0.6550, -0.5859],
        [-0.5415, -0.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06973585486412048
Epoch 0, Step 158: train/loss = 0.48231926560401917, train/raw-loss = 0.4736386239528656, train/logprobs = tensor([[-0.9862, -2.3630],
        [-0.8717, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08680613338947296
Epoch 0, Step 159: train/loss = 0.5735487937927246, train/raw-loss = 0.5670411586761475, train/logprobs = tensor([[-0.5675, -1.5106],
        [-0.5200, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.065076544880867
Epoch 0, Step 160: train/loss = 0.43652236461639404, train/raw-loss = 0.42831382155418396, train/logprobs = tensor([[-0.7763, -5.3651],
        [-0.5881, -1.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820852667093277
Epoch 0, Step 161: train/loss = 0.591899037361145, train/raw-loss = 0.5847153663635254, train/logprobs = tensor([[-0.7541, -1.2906],
        [-0.5785, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07183685153722763
Epoch 0, Step 162: train/loss = 0.4973528981208801, train/raw-loss = 0.4895869195461273, train/logprobs = tensor([[-0.6079, -2.3322],
        [-0.5550, -1.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0776602253317833
Epoch 0, Step 163: train/loss = 0.5892772674560547, train/raw-loss = 0.57984459400177, train/logprobs = tensor([[-0.9510, -3.7900],
        [-0.7140, -1.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09432698786258698
Epoch 0, Step 164: train/loss = 0.5561630129814148, train/raw-loss = 0.5491605997085571, train/logprobs = tensor([[-0.6191, -1.6209],
        [-0.5419, -0.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07002362608909607
Epoch 0, Step 165: train/loss = 0.4616801142692566, train/raw-loss = 0.454873263835907, train/logprobs = tensor([[-0.5666, -4.7908],
        [-0.4999, -1.2709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06806868314743042
Epoch 0, Step 166: train/loss = 0.5584039688110352, train/raw-loss = 0.5492367744445801, train/logprobs = tensor([[-0.8541, -2.2442],
        [-0.6595, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916713997721672
Epoch 0, Step 167: train/loss = 0.6302831172943115, train/raw-loss = 0.6222238540649414, train/logprobs = tensor([[-0.9503, -1.3113],
        [-0.8314, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08059224486351013
Epoch 0, Step 168: train/loss = 0.6068096160888672, train/raw-loss = 0.5970474481582642, train/logprobs = tensor([[-0.6297, -2.1045],
        [-0.6070, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09762270748615265
Epoch 0, Step 169: train/loss = 0.6520161628723145, train/raw-loss = 0.6437737941741943, train/logprobs = tensor([[-0.6607, -0.8924],
        [-0.5774, -0.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08242343366146088
Epoch 0, Step 170: train/loss = 0.4760405421257019, train/raw-loss = 0.46876925230026245, train/logprobs = tensor([[-0.7041, -3.7338],
        [-0.6806, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.072712741792202
Epoch 0, Step 171: train/loss = 0.5108842849731445, train/raw-loss = 0.5033077001571655, train/logprobs = tensor([[-0.6249, -2.0488],
        [-0.6171, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07576607167720795
Epoch 0, Step 172: train/loss = 0.5610634684562683, train/raw-loss = 0.5547981858253479, train/logprobs = tensor([[-0.5103, -1.8374],
        [-0.4764, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06265252828598022
Epoch 0, Step 173: train/loss = 0.5726405382156372, train/raw-loss = 0.5671639442443848, train/logprobs = tensor([[-0.5756, -1.3824],
        [-0.4608, -0.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054765380918979645
Epoch 0, Step 174: train/loss = 0.5648506879806519, train/raw-loss = 0.5578370690345764, train/logprobs = tensor([[-0.6212, -1.6798],
        [-0.5575, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0701361894607544
Epoch 0, Step 175: train/loss = 0.5011223554611206, train/raw-loss = 0.49352720379829407, train/logprobs = tensor([[-0.5573, -2.2747],
        [-0.4753, -0.9897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07595144212245941
Epoch 0, Step 176: train/loss = 0.5427632331848145, train/raw-loss = 0.5343098044395447, train/logprobs = tensor([[-0.7129, -1.9902],
        [-0.6574, -0.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08453422039747238
Epoch 0, Step 177: train/loss = 0.6561673283576965, train/raw-loss = 0.6492599844932556, train/logprobs = tensor([[-0.4993, -0.8227],
        [-0.4446, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0690731406211853
Epoch 0, Step 178: train/loss = 0.510783314704895, train/raw-loss = 0.5033962726593018, train/logprobs = tensor([[-0.7342, -1.7067],
        [-0.6140, -0.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0738707035779953
Epoch 0, Step 179: train/loss = 0.45819273591041565, train/raw-loss = 0.45156556367874146, train/logprobs = tensor([[-0.6951, -3.9126],
        [-0.6084, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06627162545919418
Epoch 0, Step 180: train/loss = 0.40739649534225464, train/raw-loss = 0.4001680016517639, train/logprobs = tensor([[-0.6828, -4.6108],
        [-0.5865, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0722850114107132
Epoch 0, Step 181: train/loss = 0.6014464497566223, train/raw-loss = 0.5944865345954895, train/logprobs = tensor([[-0.5254, -1.0719],
        [-0.4309, -0.3830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06959955394268036
Epoch 0, Step 182: train/loss = 0.7062824964523315, train/raw-loss = 0.6948627233505249, train/logprobs = tensor([[-0.9066, -2.3727],
        [-0.9104, -2.3825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11419748514890671
Epoch 0, Step 183: train/loss = 0.63840252161026, train/raw-loss = 0.6315925121307373, train/logprobs = tensor([[-0.6176, -0.8353],
        [-0.7091, -0.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06809983402490616
Epoch 0, Step 184: train/loss = 0.6037888526916504, train/raw-loss = 0.5985068082809448, train/logprobs = tensor([[-0.4114, -1.0377],
        [-0.4041, -0.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052820947021245956
Epoch 0, Step 185: train/loss = 0.47885262966156006, train/raw-loss = 0.46971356868743896, train/logprobs = tensor([[-0.9586, -4.7516],
        [-0.7398, -1.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09139043837785721
Epoch 0, Step 186: train/loss = 0.7030959129333496, train/raw-loss = 0.6935573816299438, train/logprobs = tensor([[-0.9001, -1.0655],
        [-0.6603, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09538518637418747
Epoch 0, Step 187: train/loss = 0.4593616724014282, train/raw-loss = 0.4524441361427307, train/logprobs = tensor([[-0.7241, -4.5293],
        [-0.5885, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06917575001716614
Epoch 0, Step 188: train/loss = 0.38858723640441895, train/raw-loss = 0.38140904903411865, train/logprobs = tensor([[-0.9472, -5.5898],
        [-0.7069, -1.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07178183645009995
Epoch 0, Step 189: train/loss = 0.5326268672943115, train/raw-loss = 0.5236952304840088, train/logprobs = tensor([[-0.9924, -1.8173],
        [-0.8578, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931677788496017
Epoch 0, Step 190: train/loss = 0.5240652561187744, train/raw-loss = 0.5171631574630737, train/logprobs = tensor([[-0.7604, -1.5437],
        [-0.7066, -0.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06902145594358444
Epoch 0, Step 191: train/loss = 0.47556519508361816, train/raw-loss = 0.468053936958313, train/logprobs = tensor([[-0.7148, -4.3976],
        [-0.5979, -1.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07511242479085922
Epoch 0, Step 192: train/loss = 0.6438664197921753, train/raw-loss = 0.633226215839386, train/logprobs = tensor([[-0.5923, -0.8235],
        [-0.5352, -0.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10640181601047516
Epoch 0, Step 193: train/loss = 0.48069655895233154, train/raw-loss = 0.47275689244270325, train/logprobs = tensor([[-0.5487, -2.7202],
        [-0.4353, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07939647138118744
Epoch 0, Step 194: train/loss = 0.5307019948959351, train/raw-loss = 0.5218398571014404, train/logprobs = tensor([[-0.7128, -2.0509],
        [-0.5256, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08862056583166122
Epoch 0, Step 195: train/loss = 0.5264122486114502, train/raw-loss = 0.5142237544059753, train/logprobs = tensor([[-0.7474, -2.6492],
        [-0.6123, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12188492715358734
Epoch 0, Step 196: train/loss = 0.5275415778160095, train/raw-loss = 0.5182269215583801, train/logprobs = tensor([[-0.6634, -2.5260],
        [-0.6617, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09314651042222977
Epoch 0, Step 197: train/loss = 0.5437817573547363, train/raw-loss = 0.5316426753997803, train/logprobs = tensor([[-0.9182, -4.4526],
        [-0.6324, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12139090150594711
Epoch 0, Step 198: train/loss = 0.5901442170143127, train/raw-loss = 0.5778564810752869, train/logprobs = tensor([[-1.2227, -3.8985],
        [-0.7573, -1.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12287718057632446
Epoch 0, Step 199: train/loss = 0.6191697716712952, train/raw-loss = 0.6066556572914124, train/logprobs = tensor([[-1.4491, -2.4694],
        [-0.5960, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12514185905456543
Epoch 0, Step 200: train/loss = 0.4763929545879364, train/raw-loss = 0.46419063210487366, train/logprobs = tensor([[-0.8221, -5.0573],
        [-0.7402, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12202279269695282
Epoch 0, Step 201: train/loss = 0.47594308853149414, train/raw-loss = 0.4656178951263428, train/logprobs = tensor([[-0.8305, -2.8573],
        [-0.7536, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10325194895267487
Epoch 0, Step 202: train/loss = 0.551366925239563, train/raw-loss = 0.5409243702888489, train/logprobs = tensor([[-0.8493, -1.8289],
        [-0.7428, -0.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10442529618740082
Epoch 0, Step 203: train/loss = 0.5544845461845398, train/raw-loss = 0.5420434474945068, train/logprobs = tensor([[-0.7155, -2.0260],
        [-0.6914, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12441138923168182
Epoch 0, Step 204: train/loss = 0.4626976251602173, train/raw-loss = 0.45425137877464294, train/logprobs = tensor([[-0.5166, -4.5412],
        [-0.4881, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08446257561445236
Epoch 0, Step 205: train/loss = 0.5153156518936157, train/raw-loss = 0.5052530169487, train/logprobs = tensor([[-0.8624, -2.1451],
        [-0.7466, -0.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006268635392189
Epoch 0, Step 206: train/loss = 0.4407084286212921, train/raw-loss = 0.4297866225242615, train/logprobs = tensor([[-0.7082, -2.8374],
        [-0.6123, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.109218068420887
Epoch 0, Step 207: train/loss = 0.5018963813781738, train/raw-loss = 0.4903990626335144, train/logprobs = tensor([[-0.7529, -2.6549],
        [-0.6410, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11497309803962708
Epoch 0, Step 208: train/loss = 0.5696523785591125, train/raw-loss = 0.5567173957824707, train/logprobs = tensor([[-1.1623, -2.1693],
        [-0.8620, -0.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12935000658035278
Epoch 0, Step 209: train/loss = 0.5460549592971802, train/raw-loss = 0.5333949327468872, train/logprobs = tensor([[-1.1220, -2.2034],
        [-0.8648, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12660054862499237
Epoch 0, Step 210: train/loss = 0.48778700828552246, train/raw-loss = 0.47733497619628906, train/logprobs = tensor([[-0.6158, -2.8227],
        [-0.6171, -0.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10451999306678772
Epoch 0, Step 211: train/loss = 0.5396462082862854, train/raw-loss = 0.52840256690979, train/logprobs = tensor([[-0.6197, -2.3605],
        [-0.5357, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124359667301178
Epoch 0, Step 212: train/loss = 0.6030312776565552, train/raw-loss = 0.5940728187561035, train/logprobs = tensor([[-0.9627, -2.0709],
        [-0.4974, -0.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958512544631958
Epoch 0, Step 213: train/loss = 0.7059855461120605, train/raw-loss = 0.693728506565094, train/logprobs = tensor([[-0.7052, -0.8526],
        [-0.6566, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12257105112075806
Epoch 0, Step 214: train/loss = 0.624539852142334, train/raw-loss = 0.6157404780387878, train/logprobs = tensor([[-0.7159, -1.0423],
        [-0.5873, -0.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799406886100769
Epoch 0, Step 215: train/loss = 0.4775557518005371, train/raw-loss = 0.46255195140838623, train/logprobs = tensor([[-1.3118, -3.3132],
        [-1.2371, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15003818273544312
Epoch 0, Step 216: train/loss = 0.5121136903762817, train/raw-loss = 0.49943041801452637, train/logprobs = tensor([[-0.9329, -1.9731],
        [-0.7645, -0.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1268325001001358
Epoch 0, Step 217: train/loss = 0.6560724377632141, train/raw-loss = 0.6425480246543884, train/logprobs = tensor([[-0.9338, -1.4873],
        [-0.7124, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1352432817220688
Epoch 0, Step 218: train/loss = 0.6312271356582642, train/raw-loss = 0.6166289448738098, train/logprobs = tensor([[-1.0932, -1.9119],
        [-0.8852, -1.2000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14598223567008972
Epoch 0, Step 219: train/loss = 0.5792267322540283, train/raw-loss = 0.5676715970039368, train/logprobs = tensor([[-1.2010, -2.4972],
        [-0.8322, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11555148661136627
Epoch 0, Step 220: train/loss = 0.6058748960494995, train/raw-loss = 0.5941766500473022, train/logprobs = tensor([[-0.7981, -1.3098],
        [-0.7231, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11698241531848907
Epoch 0, Step 221: train/loss = 0.3892304599285126, train/raw-loss = 0.3793284595012665, train/logprobs = tensor([[-0.7041, -3.3768],
        [-0.6368, -1.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09902039915323257
Epoch 0, Step 222: train/loss = 0.5584889650344849, train/raw-loss = 0.548658013343811, train/logprobs = tensor([[-0.7861, -1.4917],
        [-0.7154, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09830951690673828
Epoch 0, Step 223: train/loss = 0.47770291566848755, train/raw-loss = 0.46656984090805054, train/logprobs = tensor([[-0.7904, -3.1642],
        [-0.6824, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11133074760437012
Epoch 0, Step 224: train/loss = 0.4151635468006134, train/raw-loss = 0.40093880891799927, train/logprobs = tensor([[-0.9672, -3.0093],
        [-0.8143, -0.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14224757254123688
Epoch 0, Step 225: train/loss = 0.5097408294677734, train/raw-loss = 0.49854761362075806, train/logprobs = tensor([[-0.4934, -2.3301],
        [-0.5607, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11193161457777023
Epoch 0, Step 226: train/loss = 0.3855777382850647, train/raw-loss = 0.3728911578655243, train/logprobs = tensor([[-0.7864, -6.3539],
        [-0.7224, -1.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12686587870121002
Epoch 0, Step 227: train/loss = 0.5301111340522766, train/raw-loss = 0.5155741572380066, train/logprobs = tensor([[-0.9842, -1.8492],
        [-1.0051, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14536935091018677
Epoch 0, Step 228: train/loss = 0.5838035941123962, train/raw-loss = 0.5726907253265381, train/logprobs = tensor([[-0.6923, -1.7819],
        [-0.6202, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111282929778099
Epoch 0, Step 229: train/loss = 0.6414669752120972, train/raw-loss = 0.6294786930084229, train/logprobs = tensor([[-0.6834, -0.8207],
        [-0.6651, -0.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11988306045532227
Epoch 0, Step 230: train/loss = 0.5324955582618713, train/raw-loss = 0.519849419593811, train/logprobs = tensor([[-0.7844, -2.0083],
        [-0.7034, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12646086513996124
Epoch 0, Step 231: train/loss = 0.6108565330505371, train/raw-loss = 0.5947271585464478, train/logprobs = tensor([[-0.9828, -1.9624],
        [-0.7954, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612936556339264
Epoch 0, Step 232: train/loss = 0.45649683475494385, train/raw-loss = 0.4435049891471863, train/logprobs = tensor([[-0.8088, -5.3505],
        [-0.7621, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12991847097873688
Epoch 0, Step 233: train/loss = 0.6336632966995239, train/raw-loss = 0.6204240918159485, train/logprobs = tensor([[-0.5930, -0.9802],
        [-0.5989, -0.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13239127397537231
Epoch 0, Step 234: train/loss = 0.4937746524810791, train/raw-loss = 0.4780924320220947, train/logprobs = tensor([[-1.0025, -3.7499],
        [-0.8204, -2.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15682178735733032
Epoch 0, Step 235: train/loss = 0.29758358001708984, train/raw-loss = 0.28355228900909424, train/logprobs = tensor([[-0.8870, -9.9069],
        [-0.9060, -1.0956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14031286537647247
Epoch 0, Step 236: train/loss = 0.5260696411132812, train/raw-loss = 0.5093017816543579, train/logprobs = tensor([[-1.0089, -2.3230],
        [-0.9293, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16767889261245728
Epoch 0, Step 237: train/loss = 0.5839231610298157, train/raw-loss = 0.5726306438446045, train/logprobs = tensor([[-0.6303, -2.7340],
        [-0.5589, -1.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11292558163404465
Epoch 0, Step 238: train/loss = 0.5866431593894958, train/raw-loss = 0.567205548286438, train/logprobs = tensor([[-1.3272, -2.5125],
        [-1.2784, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943754404783249
Epoch 0, Step 239: train/loss = 0.4495544135570526, train/raw-loss = 0.4340589940547943, train/logprobs = tensor([[-1.0866, -3.3056],
        [-0.9825, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15495437383651733
Epoch 0, Step 240: train/loss = 0.6197880506515503, train/raw-loss = 0.6087033748626709, train/logprobs = tensor([[-0.7323, -2.2992],
        [-0.7307, -1.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11084678024053574
Epoch 0, Step 241: train/loss = 0.6123482584953308, train/raw-loss = 0.5976386666297913, train/logprobs = tensor([[-1.6290, -2.3969],
        [-1.1434, -1.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14709539711475372
Epoch 0, Step 242: train/loss = 0.5515689849853516, train/raw-loss = 0.5387442111968994, train/logprobs = tensor([[-0.6023, -1.5659],
        [-0.5488, -0.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12824787199497223
Epoch 0, Step 243: train/loss = 0.5007764101028442, train/raw-loss = 0.48709362745285034, train/logprobs = tensor([[-0.6789, -1.9735],
        [-0.7223, -0.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368277370929718
Epoch 0, Step 244: train/loss = 0.49371337890625, train/raw-loss = 0.4792536199092865, train/logprobs = tensor([[-0.9772, -3.1595],
        [-0.7955, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14459748566150665
Epoch 0, Step 245: train/loss = 0.45250797271728516, train/raw-loss = 0.43982821702957153, train/logprobs = tensor([[-0.6001, -5.2557],
        [-0.6428, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1267973929643631
Epoch 0, Step 246: train/loss = 0.4485204815864563, train/raw-loss = 0.43057864904403687, train/logprobs = tensor([[-0.8921, -2.9015],
        [-0.8933, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17941835522651672
Epoch 0, Step 247: train/loss = 0.42894303798675537, train/raw-loss = 0.4180329442024231, train/logprobs = tensor([[-0.5123, -7.2021],
        [-0.4627, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10910123586654663
Epoch 0, Step 248: train/loss = 0.4588935971260071, train/raw-loss = 0.4460310935974121, train/logprobs = tensor([[-0.8161, -3.9994],
        [-0.5256, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12862536311149597
Epoch 0, Step 249: train/loss = 0.5401850938796997, train/raw-loss = 0.527033805847168, train/logprobs = tensor([[-0.7194, -2.0909],
        [-0.6799, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13151271641254425
Epoch 0, Step 250: train/loss = 0.3579750657081604, train/raw-loss = 0.3428720533847809, train/logprobs = tensor([[-1.2059, -4.9136],
        [-1.1054, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1510300487279892
Epoch 0, Step 251: train/loss = 0.4630812406539917, train/raw-loss = 0.45111769437789917, train/logprobs = tensor([[-0.4603, -3.2408],
        [-0.4776, -1.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1196351870894432
Epoch 0, Step 252: train/loss = 0.6076174974441528, train/raw-loss = 0.5926017761230469, train/logprobs = tensor([[-0.8276, -2.2651],
        [-0.7361, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15015658736228943
Epoch 0, Step 253: train/loss = 0.6036471128463745, train/raw-loss = 0.5907267928123474, train/logprobs = tensor([[-0.9922, -1.4426],
        [-0.7762, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12920309603214264
Epoch 0, Step 254: train/loss = 0.6372279524803162, train/raw-loss = 0.6241402626037598, train/logprobs = tensor([[-0.6321, -1.2995],
        [-0.6536, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13087712228298187
Epoch 0, Step 255: train/loss = 0.5036363005638123, train/raw-loss = 0.49064552783966064, train/logprobs = tensor([[-0.7195, -2.9216],
        [-0.7476, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299077272415161
Epoch 0, Step 256: train/loss = 0.5392359495162964, train/raw-loss = 0.5261012315750122, train/logprobs = tensor([[-0.8864, -2.1163],
        [-0.7792, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13134732842445374
Epoch 0, Step 257: train/loss = 0.5486903190612793, train/raw-loss = 0.5298988223075867, train/logprobs = tensor([[-1.5884, -3.9217],
        [-0.7974, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18791474401950836
Epoch 0, Step 258: train/loss = 0.633703351020813, train/raw-loss = 0.6158170700073242, train/logprobs = tensor([[-1.5608, -3.2883],
        [-0.7708, -0.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17886321246623993
Epoch 0, Step 259: train/loss = 0.4768070578575134, train/raw-loss = 0.46412795782089233, train/logprobs = tensor([[-0.5230, -2.2451],
        [-0.5050, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12679104506969452
Epoch 0, Step 260: train/loss = 0.3602570593357086, train/raw-loss = 0.3438015580177307, train/logprobs = tensor([[-1.1161, -5.4557],
        [-1.3895, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16455529630184174
Epoch 0, Step 261: train/loss = 0.617507815361023, train/raw-loss = 0.6027065515518188, train/logprobs = tensor([[-0.6252, -1.3678],
        [-0.5362, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14801177382469177
Epoch 0, Step 262: train/loss = 0.4826030731201172, train/raw-loss = 0.4678896367549896, train/logprobs = tensor([[-0.7903, -3.2815],
        [-0.7890, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14713479578495026
Epoch 0, Step 263: train/loss = 0.5854614973068237, train/raw-loss = 0.5677989721298218, train/logprobs = tensor([[-1.4839, -5.6212],
        [-0.9899, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1766250729560852
Epoch 0, Step 264: train/loss = 0.40858107805252075, train/raw-loss = 0.3906152844429016, train/logprobs = tensor([[-1.0091, -2.4269],
        [-1.0381, -0.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17965781688690186
Epoch 0, Step 265: train/loss = 0.49741238355636597, train/raw-loss = 0.4805331230163574, train/logprobs = tensor([[-0.9034, -5.5865],
        [-0.7216, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16879266500473022
Epoch 0, Step 266: train/loss = 0.594221830368042, train/raw-loss = 0.57900071144104, train/logprobs = tensor([[-0.7897, -1.0710],
        [-0.8234, -0.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15221144258975983
Epoch 0, Step 267: train/loss = 0.5262141227722168, train/raw-loss = 0.5097994804382324, train/logprobs = tensor([[-0.9043, -3.0689],
        [-0.6658, -0.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16414670646190643
Epoch 0, Step 268: train/loss = 0.5447907447814941, train/raw-loss = 0.5258862972259521, train/logprobs = tensor([[-1.1307, -2.9984],
        [-0.9899, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18904495239257812
Epoch 0, Step 269: train/loss = 0.6541630029678345, train/raw-loss = 0.6433293223381042, train/logprobs = tensor([[-0.4900, -0.9035],
        [-0.3553, -0.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10833688080310822
Epoch 0, Step 270: train/loss = 0.6735019683837891, train/raw-loss = 0.6571350693702698, train/logprobs = tensor([[-1.6405, -2.7902],
        [-0.7761, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16366861760616302
Epoch 0, Step 271: train/loss = 0.52320396900177, train/raw-loss = 0.5081146955490112, train/logprobs = tensor([[-0.7775, -1.7986],
        [-0.6841, -0.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508927196264267
Epoch 0, Step 272: train/loss = 0.35601598024368286, train/raw-loss = 0.342810720205307, train/logprobs = tensor([[-0.6131, -4.5282],
        [-0.7691, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13205263018608093
Epoch 0, Step 273: train/loss = 0.6118230819702148, train/raw-loss = 0.5985875129699707, train/logprobs = tensor([[-0.6193, -1.2254],
        [-0.4819, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13235613703727722
Epoch 0, Step 274: train/loss = 0.4628227949142456, train/raw-loss = 0.4459729790687561, train/logprobs = tensor([[-0.8194, -2.2375],
        [-0.8009, -0.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16849800944328308
Epoch 0, Step 275: train/loss = 0.5995007753372192, train/raw-loss = 0.5849405527114868, train/logprobs = tensor([[-0.7365, -1.5778],
        [-0.4992, -0.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456030011177063
Epoch 0, Step 276: train/loss = 0.5276972055435181, train/raw-loss = 0.5143887996673584, train/logprobs = tensor([[-0.7487, -4.1856],
        [-0.6035, -1.2677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13308390974998474
Epoch 0, Step 277: train/loss = 0.5372732877731323, train/raw-loss = 0.5215786695480347, train/logprobs = tensor([[-0.8361, -2.2683],
        [-0.4745, -0.3854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15694621205329895
Epoch 0, Step 278: train/loss = 0.6012760996818542, train/raw-loss = 0.5868943333625793, train/logprobs = tensor([[-0.9642, -2.9668],
        [-0.6787, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14381767809391022
Epoch 0, Step 279: train/loss = 0.5050641894340515, train/raw-loss = 0.4865236282348633, train/logprobs = tensor([[-1.1171, -2.5064],
        [-1.0242, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18540573120117188
Epoch 0, Step 280: train/loss = 0.6785158514976501, train/raw-loss = 0.6642808318138123, train/logprobs = tensor([[-0.6905, -0.6668],
        [-0.5729, -0.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14235012233257294
Epoch 0, Step 281: train/loss = 0.41520214080810547, train/raw-loss = 0.3984692096710205, train/logprobs = tensor([[-0.9668, -4.0377],
        [-0.9373, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16732949018478394
Epoch 0, Step 282: train/loss = 0.5894712209701538, train/raw-loss = 0.5735447406768799, train/logprobs = tensor([[-0.9602, -1.9148],
        [-0.7832, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15926483273506165
Epoch 0, Step 283: train/loss = 0.42739057540893555, train/raw-loss = 0.41057175397872925, train/logprobs = tensor([[-0.8499, -2.9873],
        [-0.8477, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16818802058696747
Epoch 0, Step 284: train/loss = 0.45804694294929504, train/raw-loss = 0.440221905708313, train/logprobs = tensor([[-0.9128, -3.3015],
        [-0.8446, -0.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178250253200531
Epoch 0, Step 285: train/loss = 0.3434494137763977, train/raw-loss = 0.3262639045715332, train/logprobs = tensor([[-0.7621, -3.5830],
        [-0.9093, -0.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17185507714748383
Epoch 0, Step 286: train/loss = 0.5596282482147217, train/raw-loss = 0.546288788318634, train/logprobs = tensor([[-0.8362, -1.9030],
        [-0.7428, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13339507579803467
Epoch 0, Step 287: train/loss = 0.6331213712692261, train/raw-loss = 0.6145060062408447, train/logprobs = tensor([[-1.0375, -1.5062],
        [-0.7911, -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18615294992923737
Epoch 0, Step 288: train/loss = 0.6055293083190918, train/raw-loss = 0.5878617167472839, train/logprobs = tensor([[-0.9219, -1.6351],
        [-0.8689, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17667576670646667
Epoch 0, Step 289: train/loss = 0.39119479060173035, train/raw-loss = 0.37703198194503784, train/logprobs = tensor([[-0.6301, -2.6637],
        [-0.7652, -0.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14162756502628326
Epoch 0, Step 290: train/loss = 0.5899692177772522, train/raw-loss = 0.5766459703445435, train/logprobs = tensor([[-0.7870, -1.1865],
        [-0.7686, -0.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332324743270874
Epoch 0, Step 291: train/loss = 0.49576425552368164, train/raw-loss = 0.48136603832244873, train/logprobs = tensor([[-0.7380, -4.1118],
        [-0.5566, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14398221671581268
Epoch 0, Step 292: train/loss = 0.47202402353286743, train/raw-loss = 0.45398592948913574, train/logprobs = tensor([[-1.1026, -4.0003],
        [-0.9005, -1.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1803809255361557
Epoch 0, Step 293: train/loss = 0.5057163238525391, train/raw-loss = 0.4916574954986572, train/logprobs = tensor([[-0.7743, -1.6478],
        [-0.8104, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14058817923069
Epoch 0, Step 294: train/loss = 0.520702600479126, train/raw-loss = 0.5043076276779175, train/logprobs = tensor([[-0.7692, -2.0653],
        [-0.8549, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16395001113414764
Epoch 0, Step 295: train/loss = 0.5166641473770142, train/raw-loss = 0.4996934235095978, train/logprobs = tensor([[-1.4981, -3.2750],
        [-1.0781, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16970720887184143
Epoch 0, Step 296: train/loss = 0.39971065521240234, train/raw-loss = 0.3836040496826172, train/logprobs = tensor([[-0.9815, -2.8727],
        [-1.0043, -0.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16106651723384857
Epoch 0, Step 297: train/loss = 0.5064791440963745, train/raw-loss = 0.491402268409729, train/logprobs = tensor([[-0.6797, -2.2239],
        [-0.7525, -0.6689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15076909959316254
Epoch 0, Step 298: train/loss = 1.1422312259674072, train/raw-loss = 1.1240841150283813, train/logprobs = tensor([[-2.6646, -2.2635],
        [-0.9913, -0.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1814705729484558
Epoch 0, Step 299: train/loss = 0.4100281000137329, train/raw-loss = 0.39524605870246887, train/logprobs = tensor([[-0.6203, -3.5174],
        [-0.6551, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1478199064731598
Epoch 0, Step 300: train/loss = 0.6521706581115723, train/raw-loss = 0.6341204643249512, train/logprobs = tensor([[-1.5484, -4.6851],
        [-0.6527, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1805020123720169
Epoch 0, Step 301: train/loss = 0.45710548758506775, train/raw-loss = 0.43912917375564575, train/logprobs = tensor([[-1.0333, -6.1090],
        [-0.9306, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1797633320093155
Epoch 0, Step 302: train/loss = 0.49034059047698975, train/raw-loss = 0.47394904494285583, train/logprobs = tensor([[-1.0648, -2.1151],
        [-0.9633, -0.2614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16391576826572418
Epoch 0, Step 303: train/loss = 0.44078731536865234, train/raw-loss = 0.4240509867668152, train/logprobs = tensor([[-0.7602, -3.0220],
        [-0.5852, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1673632115125656
Epoch 0, Step 304: train/loss = 0.4897913932800293, train/raw-loss = 0.4691905379295349, train/logprobs = tensor([[-1.0618, -2.5905],
        [-0.9783, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20600861310958862
Epoch 0, Step 305: train/loss = 0.4312199652194977, train/raw-loss = 0.41475626826286316, train/logprobs = tensor([[-0.6974, -3.3634],
        [-0.8488, -0.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16463688015937805
Epoch 0, Step 306: train/loss = 0.7369670867919922, train/raw-loss = 0.718187689781189, train/logprobs = tensor([[-1.1697, -1.1742],
        [-0.8968, -0.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1877938210964203
Epoch 0, Step 307: train/loss = 0.5282580852508545, train/raw-loss = 0.512572705745697, train/logprobs = tensor([[-0.7451, -1.8533],
        [-0.7137, -0.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15685361623764038
Epoch 0, Step 308: train/loss = 0.45538657903671265, train/raw-loss = 0.4415968358516693, train/logprobs = tensor([[-0.8519, -3.3552],
        [-0.7848, -0.4743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13789768517017365
Epoch 0, Step 309: train/loss = 0.5504785776138306, train/raw-loss = 0.5359014272689819, train/logprobs = tensor([[-0.6750, -2.8258],
        [-0.6753, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14577187597751617
Epoch 0, Step 310: train/loss = 1.1205034255981445, train/raw-loss = 1.1047720909118652, train/logprobs = tensor([[-2.4447, -2.8186],
        [-0.6577, -0.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15731285512447357
Epoch 0, Step 311: train/loss = 0.46379685401916504, train/raw-loss = 0.4467683434486389, train/logprobs = tensor([[-0.9094, -2.3946],
        [-0.8260, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17028506100177765
Epoch 0, Step 312: train/loss = 0.6777626872062683, train/raw-loss = 0.6572328805923462, train/logprobs = tensor([[-1.6919, -3.5885],
        [-0.8280, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20529866218566895
Epoch 0, Step 313: train/loss = 0.44046324491500854, train/raw-loss = 0.4262816905975342, train/logprobs = tensor([[-0.7877, -5.6663],
        [-0.5754, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14181531965732574
Epoch 0, Step 314: train/loss = 0.53733891248703, train/raw-loss = 0.5199602246284485, train/logprobs = tensor([[-0.9427, -1.7735],
        [-0.9293, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737866997718811
Epoch 0, Step 315: train/loss = 0.4245920777320862, train/raw-loss = 0.4073490500450134, train/logprobs = tensor([[-1.0541, -4.0311],
        [-1.3751, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17243050038814545
Epoch 0, Step 316: train/loss = 0.4639841914176941, train/raw-loss = 0.4463624358177185, train/logprobs = tensor([[-0.8380, -7.0359],
        [-1.0084, -1.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17621761560440063
Epoch 0, Step 317: train/loss = 0.5917442440986633, train/raw-loss = 0.5750546455383301, train/logprobs = tensor([[-1.0205, -4.2706],
        [-0.9295, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16689592599868774
Epoch 0, Step 318: train/loss = 0.3977518677711487, train/raw-loss = 0.38191768527030945, train/logprobs = tensor([[-1.0543, -3.7865],
        [-0.8784, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15834195911884308
Epoch 0, Step 319: train/loss = 0.5463220477104187, train/raw-loss = 0.5288465619087219, train/logprobs = tensor([[-0.7200, -1.9418],
        [-0.6043, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17475493252277374
Epoch 0, Step 320: train/loss = 0.5663295984268188, train/raw-loss = 0.5473120808601379, train/logprobs = tensor([[-1.1843, -2.5535],
        [-0.7126, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19017454981803894
Epoch 0, Step 321: train/loss = 0.615178108215332, train/raw-loss = 0.598972499370575, train/logprobs = tensor([[-0.8449, -1.4179],
        [-0.7934, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16205649077892303
Epoch 0, Step 322: train/loss = 0.705024778842926, train/raw-loss = 0.6875571012496948, train/logprobs = tensor([[-1.2853, -1.8293],
        [-0.5812, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174676775932312
Epoch 0, Step 323: train/loss = 0.3022518455982208, train/raw-loss = 0.289747953414917, train/logprobs = tensor([[-0.5674, -8.2168],
        [-0.6123, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12503880262374878
Epoch 0, Step 324: train/loss = 0.43798720836639404, train/raw-loss = 0.41762879490852356, train/logprobs = tensor([[-0.8542, -3.7026],
        [-0.8350, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20358407497406006
Epoch 0, Step 325: train/loss = 0.2974312901496887, train/raw-loss = 0.27974048256874084, train/logprobs = tensor([[-0.7883, -6.2419],
        [-0.8647, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17690812051296234
Epoch 0, Step 326: train/loss = 0.4083920121192932, train/raw-loss = 0.39501452445983887, train/logprobs = tensor([[-0.6567, -3.9766],
        [-0.6187, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13377486169338226
Epoch 0, Step 327: train/loss = 0.34674060344696045, train/raw-loss = 0.3287205398082733, train/logprobs = tensor([[-0.7366, -4.8670],
        [-0.8666, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802002191543579
Epoch 0, Step 328: train/loss = 0.41749048233032227, train/raw-loss = 0.3969446122646332, train/logprobs = tensor([[-1.2277, -6.6184],
        [-1.2645, -1.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20545907318592072
Epoch 0, Step 329: train/loss = 0.5209738612174988, train/raw-loss = 0.5062354803085327, train/logprobs = tensor([[-0.9008, -2.4074],
        [-0.8959, -0.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14738386869430542
Epoch 0, Step 330: train/loss = 0.4779248833656311, train/raw-loss = 0.46439793705940247, train/logprobs = tensor([[-0.5063, -2.0118],
        [-0.5756, -0.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1352691650390625
Epoch 0, Step 331: train/loss = 0.47177034616470337, train/raw-loss = 0.4514235556125641, train/logprobs = tensor([[-1.7214, -2.9328],
        [-1.4828, -0.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034677267074585
Epoch 0, Step 332: train/loss = 0.5962309241294861, train/raw-loss = 0.5832411646842957, train/logprobs = tensor([[-0.7851, -3.3213],
        [-0.5438, -0.5802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1298978328704834
Epoch 0, Step 333: train/loss = 0.5537620186805725, train/raw-loss = 0.5378000736236572, train/logprobs = tensor([[-0.7306, -1.6359],
        [-0.5807, -0.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1596188247203827
Epoch 0, Step 334: train/loss = 0.5551849603652954, train/raw-loss = 0.5366754531860352, train/logprobs = tensor([[-0.7080, -1.8936],
        [-0.6495, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1850944459438324
Epoch 0, Step 335: train/loss = 0.3695667088031769, train/raw-loss = 0.35463064908981323, train/logprobs = tensor([[-0.5865, -7.3140],
        [-0.8237, -1.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14936065673828125
Epoch 0, Step 336: train/loss = 0.4919804334640503, train/raw-loss = 0.4751163423061371, train/logprobs = tensor([[-0.6865, -5.9569],
        [-0.7105, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1686408668756485
Epoch 0, Step 337: train/loss = 0.40864840149879456, train/raw-loss = 0.38949352502822876, train/logprobs = tensor([[-1.1477, -4.2302],
        [-1.2244, -0.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915484368801117
Epoch 0, Step 338: train/loss = 0.40550535917282104, train/raw-loss = 0.3931436538696289, train/logprobs = tensor([[-0.6595, -6.4947],
        [-0.5618, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12361685931682587
Epoch 0, Step 339: train/loss = 0.3856503367424011, train/raw-loss = 0.37068215012550354, train/logprobs = tensor([[-0.6775, -5.1325],
        [-0.8178, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968201518058777
Epoch 0, Step 340: train/loss = 0.5431137681007385, train/raw-loss = 0.5265603065490723, train/logprobs = tensor([[-0.8293, -1.4091],
        [-0.9019, -0.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1655348837375641
Epoch 0, Step 341: train/loss = 0.42125147581100464, train/raw-loss = 0.4036015570163727, train/logprobs = tensor([[-1.0290, -6.9077],
        [-0.9339, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17649908363819122
Epoch 0, Step 342: train/loss = 0.4311966300010681, train/raw-loss = 0.4138253927230835, train/logprobs = tensor([[-0.7515, -4.2261],
        [-0.8542, -1.2007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17371220886707306
Epoch 0, Step 343: train/loss = 0.453772634267807, train/raw-loss = 0.4391879141330719, train/logprobs = tensor([[-0.6963, -3.8164],
        [-0.6444, -0.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14584678411483765
Epoch 0, Step 344: train/loss = 0.5006141066551208, train/raw-loss = 0.48380690813064575, train/logprobs = tensor([[-0.6395, -2.1839],
        [-0.5579, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16807186603546143
Epoch 0, Step 345: train/loss = 1.2328723669052124, train/raw-loss = 1.215551733970642, train/logprobs = tensor([[-2.3320, -1.5784],
        [-0.5999, -0.6249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17320600152015686
Epoch 0, Step 346: train/loss = 0.44050973653793335, train/raw-loss = 0.4215936064720154, train/logprobs = tensor([[-0.9819, -2.6230],
        [-1.0020, -0.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1891615241765976
Epoch 0, Step 347: train/loss = 0.3656482994556427, train/raw-loss = 0.3451193571090698, train/logprobs = tensor([[-1.1014, -3.9601],
        [-1.2394, -0.6435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052893340587616
Epoch 0, Step 348: train/loss = 0.3482879400253296, train/raw-loss = 0.3327321708202362, train/logprobs = tensor([[-0.7388, -5.8498],
        [-0.8231, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15555761754512787
Epoch 0, Step 349: train/loss = 0.4350129961967468, train/raw-loss = 0.4171275198459625, train/logprobs = tensor([[-0.9505, -4.1103],
        [-0.7649, -0.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17885500192642212
Epoch 0, Step 350: train/loss = 0.39514416456222534, train/raw-loss = 0.3811348080635071, train/logprobs = tensor([[-0.5748, -4.6503],
        [-0.6160, -0.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14009350538253784
Epoch 0, Step 351: train/loss = 0.44261276721954346, train/raw-loss = 0.42381492257118225, train/logprobs = tensor([[-0.8912, -5.8942],
        [-1.0457, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187978595495224
Epoch 0, Step 352: train/loss = 0.6001057624816895, train/raw-loss = 0.5873889327049255, train/logprobs = tensor([[-0.4942, -1.3754],
        [-0.5004, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12716861069202423
Epoch 0, Step 353: train/loss = 0.512992262840271, train/raw-loss = 0.4964226484298706, train/logprobs = tensor([[-0.7009, -5.7560],
        [-0.8530, -1.0036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16569623351097107
Epoch 0, Step 354: train/loss = 0.3968544602394104, train/raw-loss = 0.3777261972427368, train/logprobs = tensor([[-0.9473, -3.9749],
        [-0.9991, -0.5907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19128209352493286
Epoch 0, Step 355: train/loss = 0.38021379709243774, train/raw-loss = 0.360834002494812, train/logprobs = tensor([[-1.0438, -7.1872],
        [-0.9622, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.193797767162323
Epoch 0, Step 356: train/loss = 0.5505964756011963, train/raw-loss = 0.5362653732299805, train/logprobs = tensor([[-0.5975, -1.6416],
        [-0.5500, -0.5426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14331062138080597
Epoch 0, Step 357: train/loss = 0.35605502128601074, train/raw-loss = 0.3381906747817993, train/logprobs = tensor([[-0.9532, -4.2633],
        [-1.2323, -0.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1786431074142456
Epoch 0, Step 358: train/loss = 0.5779500007629395, train/raw-loss = 0.5562759637832642, train/logprobs = tensor([[-1.2436, -3.4211],
        [-0.7438, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21674075722694397
Epoch 0, Step 359: train/loss = 0.5599092245101929, train/raw-loss = 0.5441644191741943, train/logprobs = tensor([[-0.6247, -1.2240],
        [-0.7820, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15744833648204803
Epoch 0, Step 360: train/loss = 0.6187503337860107, train/raw-loss = 0.6022049784660339, train/logprobs = tensor([[-1.5505, -6.4336],
        [-0.9123, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16545337438583374
Epoch 0, Step 361: train/loss = 0.7078806757926941, train/raw-loss = 0.6888902187347412, train/logprobs = tensor([[-0.9001, -0.8992],
        [-0.6025, -0.5091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18990381062030792
Epoch 0, Step 362: train/loss = 0.5959731340408325, train/raw-loss = 0.5765882730484009, train/logprobs = tensor([[-0.7423, -1.8215],
        [-0.5387, -0.6190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19384926557540894
Epoch 0, Step 363: train/loss = 0.4968077540397644, train/raw-loss = 0.48041319847106934, train/logprobs = tensor([[-0.7005, -1.6905],
        [-1.0476, -0.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16394586861133575
Epoch 0, Step 364: train/loss = 0.44791504740715027, train/raw-loss = 0.43208086490631104, train/logprobs = tensor([[-0.6552, -4.2260],
        [-0.7780, -1.2619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15834157168865204
Epoch 0, Step 365: train/loss = 0.38670316338539124, train/raw-loss = 0.3667057752609253, train/logprobs = tensor([[-0.7282, -2.9063],
        [-1.0508, -0.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19997364282608032
Epoch 0, Step 366: train/loss = 0.4643460214138031, train/raw-loss = 0.4449242353439331, train/logprobs = tensor([[-0.9089, -2.9683],
        [-0.9826, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19421759247779846
Epoch 0, Step 367: train/loss = 0.3545096516609192, train/raw-loss = 0.33283019065856934, train/logprobs = tensor([[-0.8542, -3.3883],
        [-1.2224, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21679437160491943
Epoch 0, Step 368: train/loss = 0.7401095628738403, train/raw-loss = 0.7248256206512451, train/logprobs = tensor([[-1.3125, -2.1218],
        [-0.6290, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15283948183059692
Epoch 0, Step 369: train/loss = 0.5836226344108582, train/raw-loss = 0.5676348209381104, train/logprobs = tensor([[-0.7605, -1.8748],
        [-0.6787, -0.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15987807512283325
Epoch 0, Step 370: train/loss = 0.6566874980926514, train/raw-loss = 0.6409302949905396, train/logprobs = tensor([[-0.9957, -0.7751],
        [-0.8930, -0.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1575719118118286
Epoch 0, Step 371: train/loss = 0.3545447587966919, train/raw-loss = 0.33768898248672485, train/logprobs = tensor([[-0.6462, -3.0208],
        [-1.0307, -0.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16855773329734802
Epoch 0, Step 372: train/loss = 0.4800666570663452, train/raw-loss = 0.46305209398269653, train/logprobs = tensor([[-0.8139, -7.1530],
        [-0.7486, -1.3751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17014598846435547
Epoch 0, Step 373: train/loss = 0.5085588693618774, train/raw-loss = 0.48954296112060547, train/logprobs = tensor([[-0.7473, -2.5387],
        [-0.7755, -1.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19015896320343018
Epoch 0, Step 374: train/loss = 0.541519045829773, train/raw-loss = 0.5283867716789246, train/logprobs = tensor([[-0.4713, -7.8123],
        [-0.6748, -1.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1313227266073227
Epoch 0, Step 375: train/loss = 0.5688952207565308, train/raw-loss = 0.5557383894920349, train/logprobs = tensor([[-0.5401, -1.4228],
        [-0.5178, -0.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13156794011592865
Epoch 0, Step 376: train/loss = 0.5482223629951477, train/raw-loss = 0.5301934480667114, train/logprobs = tensor([[-0.6029, -1.4373],
        [-0.8844, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802898645401001
Epoch 0, Step 377: train/loss = 0.58231520652771, train/raw-loss = 0.5667359828948975, train/logprobs = tensor([[-0.5001, -1.1587],
        [-0.5026, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15579193830490112
Epoch 0, Step 378: train/loss = 0.5767685174942017, train/raw-loss = 0.554999053478241, train/logprobs = tensor([[-0.9398, -1.2293],
        [-1.1582, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21769441664218903
Epoch 0, Step 379: train/loss = 0.5232411623001099, train/raw-loss = 0.5018395185470581, train/logprobs = tensor([[-0.8754, -2.4559],
        [-0.7481, -0.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21401718258857727
Epoch 0, Step 380: train/loss = 0.36160722374916077, train/raw-loss = 0.3440440595149994, train/logprobs = tensor([[-0.8700, -4.0039],
        [-0.9870, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17563152313232422
Epoch 0, Step 381: train/loss = 0.4643018841743469, train/raw-loss = 0.44694557785987854, train/logprobs = tensor([[-0.7115, -3.7210],
        [-0.9197, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735628992319107
Epoch 0, Step 382: train/loss = 0.24461449682712555, train/raw-loss = 0.22515791654586792, train/logprobs = tensor([[-0.9284, -5.3873],
        [-1.4587, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19456574320793152
Epoch 0, Step 383: train/loss = 0.9432786107063293, train/raw-loss = 0.924857497215271, train/logprobs = tensor([[-2.9566, -5.5330],
        [-0.9895, -0.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18421071767807007
Epoch 0, Step 384: train/loss = 0.5401380658149719, train/raw-loss = 0.5187793970108032, train/logprobs = tensor([[-0.5399, -1.1407],
        [-1.0708, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21358686685562134
Epoch 0, Step 385: train/loss = 0.5055978298187256, train/raw-loss = 0.4861004948616028, train/logprobs = tensor([[-0.6789, -5.4127],
        [-0.8078, -1.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19497300684452057
Epoch 0, Step 386: train/loss = 0.41451162099838257, train/raw-loss = 0.39442184567451477, train/logprobs = tensor([[-0.4804, -2.6995],
        [-0.9445, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20089776813983917
Epoch 0, Step 387: train/loss = 0.6898553967475891, train/raw-loss = 0.6696127653121948, train/logprobs = tensor([[-0.5172, -0.7773],
        [-0.6793, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20242595672607422
Epoch 0, Step 388: train/loss = 0.48025694489479065, train/raw-loss = 0.4595959186553955, train/logprobs = tensor([[-0.7593, -2.2556],
        [-0.9800, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20661018788814545
Epoch 0, Step 389: train/loss = 0.49025553464889526, train/raw-loss = 0.47034430503845215, train/logprobs = tensor([[-0.6601, -5.0336],
        [-0.8533, -0.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19911199808120728
Epoch 0, Step 390: train/loss = 0.33663421869277954, train/raw-loss = 0.3171047568321228, train/logprobs = tensor([[-0.5307, -3.6763],
        [-1.0663, -0.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19529445469379425
Epoch 0, Step 391: train/loss = 0.47046396136283875, train/raw-loss = 0.44467195868492126, train/logprobs = tensor([[-1.3941, -3.2469],
        [-1.4228, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579200267791748
Epoch 0, Step 392: train/loss = 0.6085244417190552, train/raw-loss = 0.5850825905799866, train/logprobs = tensor([[-0.9506, -1.5666],
        [-0.9979, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23441869020462036
Epoch 0, Step 393: train/loss = 0.4675721526145935, train/raw-loss = 0.4485306143760681, train/logprobs = tensor([[-0.6719, -2.3932],
        [-0.9542, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1904154121875763
Epoch 0, Step 394: train/loss = 0.47404253482818604, train/raw-loss = 0.45284080505371094, train/logprobs = tensor([[-0.7040, -3.7787],
        [-1.2869, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21201740205287933
Epoch 0, Step 395: train/loss = 0.32208436727523804, train/raw-loss = 0.30024397373199463, train/logprobs = tensor([[-0.5953, -3.4711],
        [-1.2931, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21840403974056244
Epoch 0, Step 396: train/loss = 0.505260705947876, train/raw-loss = 0.48322367668151855, train/logprobs = tensor([[-0.8480, -2.5072],
        [-1.0155, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22037000954151154
Epoch 0, Step 397: train/loss = 0.32316726446151733, train/raw-loss = 0.3003087341785431, train/logprobs = tensor([[-0.5869, -3.6764],
        [-1.3566, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285856157541275
Epoch 0, Step 398: train/loss = 0.6831041574478149, train/raw-loss = 0.6631609201431274, train/logprobs = tensor([[-0.5823, -0.8509],
        [-0.6484, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19943226873874664
Epoch 0, Step 399: train/loss = 0.5102107524871826, train/raw-loss = 0.48842406272888184, train/logprobs = tensor([[-0.7804, -1.9876],
        [-1.0072, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21786701679229736
Epoch 0, Step 400: train/loss = 0.6047559380531311, train/raw-loss = 0.5849409103393555, train/logprobs = tensor([[-0.5008, -1.0688],
        [-0.6672, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19815011322498322
Epoch 0, Step 401: train/loss = 0.5267876386642456, train/raw-loss = 0.5088548064231873, train/logprobs = tensor([[-0.5732, -4.6486],
        [-0.8410, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17932862043380737
Epoch 0, Step 402: train/loss = 0.46240341663360596, train/raw-loss = 0.43783655762672424, train/logprobs = tensor([[-0.6846, -2.0930],
        [-1.2364, -0.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456681728363037
Epoch 0, Step 403: train/loss = 0.5735407471656799, train/raw-loss = 0.5562044978141785, train/logprobs = tensor([[-0.4593, -1.9096],
        [-0.5792, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17336256802082062
Epoch 0, Step 404: train/loss = 0.3319355845451355, train/raw-loss = 0.3103640377521515, train/logprobs = tensor([[-0.5617, -3.1974],
        [-1.3616, -0.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21571539342403412
Epoch 0, Step 405: train/loss = 0.42755040526390076, train/raw-loss = 0.4057775139808655, train/logprobs = tensor([[-0.7504, -2.8497],
        [-0.8822, -0.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2177286595106125
Epoch 0, Step 406: train/loss = 0.6218554973602295, train/raw-loss = 0.5990481376647949, train/logprobs = tensor([[-0.6706, -1.3954],
        [-0.8612, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22807353734970093
Epoch 0, Step 407: train/loss = 0.4629193842411041, train/raw-loss = 0.44027572870254517, train/logprobs = tensor([[-0.5380, -5.5402],
        [-1.0042, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22643662989139557
Epoch 0, Step 408: train/loss = 0.5579805374145508, train/raw-loss = 0.5379421710968018, train/logprobs = tensor([[-0.6141, -1.1665],
        [-1.0105, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20038406550884247
Epoch 0, Step 409: train/loss = 0.5622165203094482, train/raw-loss = 0.5416601896286011, train/logprobs = tensor([[-1.4469, -3.3592],
        [-1.0400, -1.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20556345582008362
Epoch 0, Step 410: train/loss = 0.41553547978401184, train/raw-loss = 0.3940768837928772, train/logprobs = tensor([[-1.0195, -4.4254],
        [-1.0455, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21458591520786285
Epoch 0, Step 411: train/loss = 0.36020994186401367, train/raw-loss = 0.33583489060401917, train/logprobs = tensor([[-0.9522, -2.8554],
        [-1.2516, -0.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24375049769878387
Epoch 0, Step 412: train/loss = 0.39108169078826904, train/raw-loss = 0.37069010734558105, train/logprobs = tensor([[-0.6681, -3.5051],
        [-1.0871, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2039162665605545
Epoch 0, Step 413: train/loss = 0.49180716276168823, train/raw-loss = 0.4668882489204407, train/logprobs = tensor([[-0.6227, -1.6248],
        [-1.1215, -0.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24918922781944275
Epoch 0, Step 414: train/loss = 0.42813295125961304, train/raw-loss = 0.40787962079048157, train/logprobs = tensor([[-0.5686, -4.7814],
        [-0.9412, -1.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20253342390060425
Epoch 0, Step 415: train/loss = 0.44503504037857056, train/raw-loss = 0.42336833477020264, train/logprobs = tensor([[-0.4913, -2.1196],
        [-1.0868, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21666693687438965
Epoch 0, Step 416: train/loss = 0.37699800729751587, train/raw-loss = 0.3546193242073059, train/logprobs = tensor([[-0.6071, -4.3439],
        [-1.0747, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2237868309020996
Epoch 0, Step 417: train/loss = 0.33903637528419495, train/raw-loss = 0.3122881352901459, train/logprobs = tensor([[-0.8527, -4.1821],
        [-1.2127, -1.2765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2674826681613922
Epoch 0, Step 418: train/loss = 0.504335880279541, train/raw-loss = 0.4764776825904846, train/logprobs = tensor([[-1.0611, -2.0779],
        [-1.5683, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785826325416565
Epoch 0, Step 419: train/loss = 0.4424753785133362, train/raw-loss = 0.4251282513141632, train/logprobs = tensor([[-0.5329, -3.9108],
        [-0.7390, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347115278244019
Epoch 0, Step 420: train/loss = 0.5161306858062744, train/raw-loss = 0.49175989627838135, train/logprobs = tensor([[-0.4968, -1.4342],
        [-1.3554, -1.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24370744824409485
Epoch 0, Step 421: train/loss = 0.47846120595932007, train/raw-loss = 0.45760273933410645, train/logprobs = tensor([[-0.7753, -3.0867],
        [-1.3293, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20858457684516907
Epoch 0, Step 422: train/loss = 0.49658089876174927, train/raw-loss = 0.4752907454967499, train/logprobs = tensor([[-0.5280, -4.4928],
        [-0.9038, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21290144324302673
Epoch 0, Step 423: train/loss = 0.5290163159370422, train/raw-loss = 0.5126731395721436, train/logprobs = tensor([[-0.7294, -1.3320],
        [-1.1449, -0.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16343198716640472
Epoch 0, Step 424: train/loss = 0.8875778913497925, train/raw-loss = 0.8649969100952148, train/logprobs = tensor([[-2.1395, -2.8345],
        [-0.8359, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22580993175506592
Epoch 0, Step 425: train/loss = 0.6149185299873352, train/raw-loss = 0.5896488428115845, train/logprobs = tensor([[-1.0746, -2.2890],
        [-1.0353, -0.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526969611644745
Epoch 0, Step 426: train/loss = 0.5414583683013916, train/raw-loss = 0.5161179900169373, train/logprobs = tensor([[-0.4748, -1.5436],
        [-1.1395, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534034252166748
Epoch 0, Step 427: train/loss = 0.42899948358535767, train/raw-loss = 0.40407922863960266, train/logprobs = tensor([[-0.7470, -3.0837],
        [-1.4217, -0.9359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24920253455638885
Epoch 0, Step 428: train/loss = 0.5568717122077942, train/raw-loss = 0.5377386212348938, train/logprobs = tensor([[-0.4990, -1.1110],
        [-0.8346, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19133082032203674
Epoch 0, Step 429: train/loss = 0.45351293683052063, train/raw-loss = 0.4264894723892212, train/logprobs = tensor([[-0.7649, -3.0559],
        [-1.1676, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27023452520370483
Epoch 0, Step 430: train/loss = 0.3099353015422821, train/raw-loss = 0.2906932234764099, train/logprobs = tensor([[-0.6182, -6.4072],
        [-0.9788, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19242100417613983
Epoch 0, Step 431: train/loss = 0.43919748067855835, train/raw-loss = 0.41423892974853516, train/logprobs = tensor([[-0.4967, -2.3956],
        [-1.2014, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495855987071991
Epoch 0, Step 432: train/loss = 0.5588506460189819, train/raw-loss = 0.5388846397399902, train/logprobs = tensor([[-0.5615, -1.2008],
        [-0.7644, -0.3851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996595859527588
Epoch 0, Step 433: train/loss = 0.6604892611503601, train/raw-loss = 0.636650800704956, train/logprobs = tensor([[-0.7491, -0.8542],
        [-0.9578, -0.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23838461935520172
Epoch 0, Step 434: train/loss = 0.5460537075996399, train/raw-loss = 0.520131528377533, train/logprobs = tensor([[-1.4530, -3.9212],
        [-1.4037, -1.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25922176241874695
Epoch 0, Step 435: train/loss = 0.5625861287117004, train/raw-loss = 0.5397331714630127, train/logprobs = tensor([[-0.7140, -1.2803],
        [-1.1410, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22852973639965057
Epoch 0, Step 436: train/loss = 0.454603374004364, train/raw-loss = 0.4332650303840637, train/logprobs = tensor([[-0.4866, -2.0998],
        [-1.0389, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21338334679603577
Epoch 0, Step 437: train/loss = 0.6178812980651855, train/raw-loss = 0.5993645787239075, train/logprobs = tensor([[-0.6058, -1.0159],
        [-0.9752, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18516668677330017
Epoch 0, Step 438: train/loss = 0.4820280075073242, train/raw-loss = 0.45910823345184326, train/logprobs = tensor([[-0.6699, -1.6485],
        [-1.0112, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22919772565364838
Epoch 0, Step 439: train/loss = 0.5791138410568237, train/raw-loss = 0.558371901512146, train/logprobs = tensor([[-0.4560, -1.5301],
        [-0.7222, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20741914212703705
Epoch 0, Step 440: train/loss = 0.2353733777999878, train/raw-loss = 0.2103804647922516, train/logprobs = tensor([[-0.8161, -8.6483],
        [-1.5406, -1.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2499290406703949
Epoch 0, Step 441: train/loss = 0.38250046968460083, train/raw-loss = 0.3629125654697418, train/logprobs = tensor([[-0.4812, -4.9811],
        [-0.7608, -1.3521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19587892293930054
Epoch 0, Step 442: train/loss = 0.48346829414367676, train/raw-loss = 0.4647361636161804, train/logprobs = tensor([[-0.6433, -3.0611],
        [-0.9130, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18732136487960815
Epoch 0, Step 443: train/loss = 0.5123167037963867, train/raw-loss = 0.49449554085731506, train/logprobs = tensor([[-0.7034, -5.0125],
        [-0.8335, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17821136116981506
Epoch 0, Step 444: train/loss = 0.38393694162368774, train/raw-loss = 0.3627339005470276, train/logprobs = tensor([[-0.5722, -3.1122],
        [-0.9470, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21203036606311798
Epoch 0, Step 445: train/loss = 0.5691176652908325, train/raw-loss = 0.5528011322021484, train/logprobs = tensor([[-0.6453, -1.1924],
        [-0.6705, -0.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16316525638103485
Epoch 0, Step 446: train/loss = 0.26516515016555786, train/raw-loss = 0.24100983142852783, train/logprobs = tensor([[-0.7022, -4.4980],
        [-1.1524, -0.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24155300855636597
Epoch 0, Step 447: train/loss = 0.456478089094162, train/raw-loss = 0.43509814143180847, train/logprobs = tensor([[-0.4893, -3.4608],
        [-1.0445, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2137995958328247
Epoch 0, Step 448: train/loss = 0.5375396609306335, train/raw-loss = 0.514200747013092, train/logprobs = tensor([[-0.5919, -1.7551],
        [-1.1032, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333892285823822
Epoch 0, Step 449: train/loss = 0.48022982478141785, train/raw-loss = 0.45794492959976196, train/logprobs = tensor([[-0.8879, -6.0004],
        [-0.9242, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22284892201423645
Epoch 0, Step 450: train/loss = 0.5101295709609985, train/raw-loss = 0.49039599299430847, train/logprobs = tensor([[-0.5922, -2.1766],
        [-0.5585, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19733580946922302
Epoch 0, Step 451: train/loss = 0.7282912731170654, train/raw-loss = 0.708453357219696, train/logprobs = tensor([[-0.4945, -0.4330],
        [-0.5959, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1983790546655655
Epoch 0, Step 452: train/loss = 0.41876786947250366, train/raw-loss = 0.3942418098449707, train/logprobs = tensor([[-1.3165, -2.9902],
        [-1.6521, -1.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24526023864746094
Epoch 0, Step 453: train/loss = 0.393178254365921, train/raw-loss = 0.3671492338180542, train/logprobs = tensor([[-0.5488, -2.8601],
        [-1.1390, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26029008626937866
Epoch 0, Step 454: train/loss = 0.6120822429656982, train/raw-loss = 0.5850547552108765, train/logprobs = tensor([[-0.6237, -1.0771],
        [-1.1904, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2702752351760864
Epoch 0, Step 455: train/loss = 0.44829440116882324, train/raw-loss = 0.42900723218917847, train/logprobs = tensor([[-0.5569, -2.5060],
        [-0.8205, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1928711235523224
Epoch 0, Step 456: train/loss = 0.4164183437824249, train/raw-loss = 0.3904132843017578, train/logprobs = tensor([[-0.6997, -3.1794],
        [-0.9976, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26005107164382935
Epoch 0, Step 457: train/loss = 0.5805463790893555, train/raw-loss = 0.5577351450920105, train/logprobs = tensor([[-0.5889, -1.2400],
        [-0.8470, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2281120866537094
Epoch 0, Step 458: train/loss = 0.656825602054596, train/raw-loss = 0.6317954659461975, train/logprobs = tensor([[-0.5729, -0.4490],
        [-0.9114, -0.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2503012716770172
Epoch 0, Step 459: train/loss = 0.38834041357040405, train/raw-loss = 0.3699953258037567, train/logprobs = tensor([[-0.5709, -5.5735],
        [-1.2709, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18345078825950623
Epoch 0, Step 460: train/loss = 0.45279714465141296, train/raw-loss = 0.429195374250412, train/logprobs = tensor([[-0.9720, -4.1434],
        [-1.2625, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23601771891117096
Epoch 0, Step 461: train/loss = 0.3313444256782532, train/raw-loss = 0.30083486437797546, train/logprobs = tensor([[-0.8346, -3.4139],
        [-1.9343, -1.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305095374584198
Epoch 0, Step 462: train/loss = 0.3586268126964569, train/raw-loss = 0.33393365144729614, train/logprobs = tensor([[-0.6929, -3.8332],
        [-1.5983, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24693186581134796
Epoch 0, Step 463: train/loss = 0.5090973973274231, train/raw-loss = 0.482990562915802, train/logprobs = tensor([[-0.7059, -1.5946],
        [-1.1095, -0.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610683739185333
Epoch 0, Step 464: train/loss = 0.27059853076934814, train/raw-loss = 0.24639931321144104, train/logprobs = tensor([[-0.5436, -3.5435],
        [-1.2760, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24199211597442627
Epoch 0, Step 465: train/loss = 0.7944536805152893, train/raw-loss = 0.7725017070770264, train/logprobs = tensor([[-1.9145, -3.5267],
        [-0.6835, -0.8042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21951927244663239
Epoch 0, Step 466: train/loss = 0.2414092719554901, train/raw-loss = 0.21963565051555634, train/logprobs = tensor([[-0.7279, -5.4255],
        [-1.5006, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21773606538772583
Epoch 0, Step 467: train/loss = 0.5350840091705322, train/raw-loss = 0.5095575451850891, train/logprobs = tensor([[-0.9026, -1.9372],
        [-1.0454, -0.7822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25526463985443115
Epoch 0, Step 468: train/loss = 0.5965075492858887, train/raw-loss = 0.5742237567901611, train/logprobs = tensor([[-0.4408, -1.3055],
        [-0.6592, -0.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22283786535263062
Epoch 0, Step 469: train/loss = 0.5064330101013184, train/raw-loss = 0.4885098934173584, train/logprobs = tensor([[-0.4378, -1.2772],
        [-0.8033, -0.2582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17923088371753693
Epoch 0, Step 470: train/loss = 0.446370005607605, train/raw-loss = 0.4268855154514313, train/logprobs = tensor([[-0.4729, -6.3534],
        [-0.8812, -1.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1948450207710266
Epoch 0, Step 471: train/loss = 0.4450972080230713, train/raw-loss = 0.4243859648704529, train/logprobs = tensor([[-0.6926, -1.9440],
        [-1.1340, -0.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20711266994476318
Epoch 0, Step 472: train/loss = 0.4698382019996643, train/raw-loss = 0.44505205750465393, train/logprobs = tensor([[-0.4859, -3.5750],
        [-0.9609, -0.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24786138534545898
Epoch 0, Step 473: train/loss = 0.37592366337776184, train/raw-loss = 0.35101333260536194, train/logprobs = tensor([[-0.6521, -5.4401],
        [-1.2572, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24910347163677216
Epoch 0, Step 474: train/loss = 0.5555357336997986, train/raw-loss = 0.5324296951293945, train/logprobs = tensor([[-0.4311, -1.5360],
        [-0.8412, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2310604304075241
Epoch 0, Step 475: train/loss = 0.26555585861206055, train/raw-loss = 0.24272151291370392, train/logprobs = tensor([[-0.7623, -5.4333],
        [-1.2367, -0.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22834347188472748
Epoch 0, Step 476: train/loss = 0.5761402249336243, train/raw-loss = 0.5527468919754028, train/logprobs = tensor([[-0.4203, -1.4722],
        [-0.8384, -0.7904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23393326997756958
Epoch 0, Step 477: train/loss = 0.5846971869468689, train/raw-loss = 0.5620256662368774, train/logprobs = tensor([[-1.5153, -4.6628],
        [-1.5196, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22671642899513245
Epoch 0, Step 478: train/loss = 0.5803937911987305, train/raw-loss = 0.5582655668258667, train/logprobs = tensor([[-1.3172, -3.1666],
        [-0.7658, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22128143906593323
Epoch 0, Step 479: train/loss = 0.48074647784233093, train/raw-loss = 0.4539814293384552, train/logprobs = tensor([[-0.5823, -1.9592],
        [-1.0359, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676507830619812
Epoch 0, Step 480: train/loss = 0.4980843663215637, train/raw-loss = 0.4700680375099182, train/logprobs = tensor([[-0.8232, -2.6167],
        [-0.9531, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28016364574432373
Epoch 0, Step 481: train/loss = 0.6088133454322815, train/raw-loss = 0.5820805430412292, train/logprobs = tensor([[-1.0255, -2.0327],
        [-1.1236, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673278748989105
Epoch 0, Step 482: train/loss = 0.4939771592617035, train/raw-loss = 0.4683552384376526, train/logprobs = tensor([[-0.8085, -1.7671],
        [-1.4502, -0.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562192380428314
Epoch 0, Step 483: train/loss = 0.2987854778766632, train/raw-loss = 0.27103766798973083, train/logprobs = tensor([[-1.1027, -3.2992],
        [-1.7631, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27747827768325806
Epoch 0, Step 484: train/loss = 0.5675542950630188, train/raw-loss = 0.5481191277503967, train/logprobs = tensor([[-1.4437, -6.7025],
        [-1.1219, -0.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19435179233551025
Epoch 0, Step 485: train/loss = 0.7473167181015015, train/raw-loss = 0.7192394137382507, train/logprobs = tensor([[-1.4461, -1.7921],
        [-0.7897, -0.7092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807730436325073
Epoch 0, Step 486: train/loss = 0.3127938210964203, train/raw-loss = 0.2905259430408478, train/logprobs = tensor([[-0.6490, -3.0622],
        [-0.9595, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22267860174179077
Epoch 0, Step 487: train/loss = 0.4874206483364105, train/raw-loss = 0.45685380697250366, train/logprobs = tensor([[-0.7613, -2.1398],
        [-1.2111, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056681156158447
Epoch 0, Step 488: train/loss = 0.5048704743385315, train/raw-loss = 0.4761212468147278, train/logprobs = tensor([[-1.2165, -4.6012],
        [-1.2821, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2874923646450043
Epoch 0, Step 489: train/loss = 0.5357694625854492, train/raw-loss = 0.5177798867225647, train/logprobs = tensor([[-0.6008, -2.0363],
        [-0.6901, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17989587783813477
Epoch 0, Step 490: train/loss = 0.48134806752204895, train/raw-loss = 0.4562946557998657, train/logprobs = tensor([[-1.0443, -2.2952],
        [-1.1491, -0.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25053396821022034
Epoch 0, Step 491: train/loss = 0.40941932797431946, train/raw-loss = 0.38027483224868774, train/logprobs = tensor([[-1.0598, -2.7359],
        [-1.5082, -0.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29144471883773804
Epoch 0, Step 492: train/loss = 0.3704165518283844, train/raw-loss = 0.34506431221961975, train/logprobs = tensor([[-0.6913, -3.2888],
        [-1.0464, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25352251529693604
Epoch 0, Step 493: train/loss = 0.8869312405586243, train/raw-loss = 0.8543124198913574, train/logprobs = tensor([[-2.2746, -2.5147],
        [-0.8684, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32618802785873413
Epoch 0, Step 494: train/loss = 0.8582969307899475, train/raw-loss = 0.8297210931777954, train/logprobs = tensor([[-1.8943, -2.5636],
        [-0.7015, -0.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.285758376121521
Epoch 0, Step 495: train/loss = 0.4502735137939453, train/raw-loss = 0.4275646209716797, train/logprobs = tensor([[-0.7982, -4.6285],
        [-1.1521, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.227089062333107
Epoch 0, Step 496: train/loss = 0.5759220719337463, train/raw-loss = 0.5513795614242554, train/logprobs = tensor([[-0.7250, -1.6834],
        [-0.8574, -0.7530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24542465806007385
Epoch 0, Step 497: train/loss = 0.5104550123214722, train/raw-loss = 0.48477762937545776, train/logprobs = tensor([[-0.8883, -1.7518],
        [-1.1531, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567737102508545
Epoch 0, Step 498: train/loss = 0.523248553276062, train/raw-loss = 0.49427276849746704, train/logprobs = tensor([[-0.5688, -1.3804],
        [-1.0483, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897578477859497
Epoch 0, Step 499: train/loss = 0.30665162205696106, train/raw-loss = 0.2818923890590668, train/logprobs = tensor([[-0.7257, -3.3079],
        [-1.1172, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24759221076965332
Epoch 0, Step 500: train/loss = 0.3289012014865875, train/raw-loss = 0.30169886350631714, train/logprobs = tensor([[-1.0244, -3.6100],
        [-1.3522, -0.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720235586166382
Epoch 0, Step 501: train/loss = 0.2092636078596115, train/raw-loss = 0.18171221017837524, train/logprobs = tensor([[-0.7969, -4.9240],
        [-1.6306, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27551397681236267
Epoch 0, Step 502: train/loss = 0.3832961916923523, train/raw-loss = 0.36036497354507446, train/logprobs = tensor([[-0.8756, -2.9927],
        [-1.0433, -0.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22931203246116638
Epoch 0, Step 503: train/loss = 0.7570186257362366, train/raw-loss = 0.7325464487075806, train/logprobs = tensor([[-0.8214, -1.2881],
        [-0.6768, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.244722381234169
Epoch 0, Step 504: train/loss = 0.3877875506877899, train/raw-loss = 0.36356493830680847, train/logprobs = tensor([[-0.8720, -3.6782],
        [-1.2403, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24222585558891296
Epoch 0, Step 505: train/loss = 0.46500903367996216, train/raw-loss = 0.43936407566070557, train/logprobs = tensor([[-0.8535, -3.9095],
        [-0.9354, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25644925236701965
Epoch 0, Step 506: train/loss = 0.48976027965545654, train/raw-loss = 0.4608508050441742, train/logprobs = tensor([[-1.5542, -2.6834],
        [-1.8500, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890947759151459
Epoch 0, Step 507: train/loss = 0.5929728150367737, train/raw-loss = 0.5694102048873901, train/logprobs = tensor([[-0.5282, -1.2679],
        [-0.7647, -0.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2356262058019638
Epoch 0, Step 508: train/loss = 0.4598028361797333, train/raw-loss = 0.43015679717063904, train/logprobs = tensor([[-1.3668, -2.3658],
        [-1.5816, -0.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29646027088165283
Epoch 0, Step 509: train/loss = 0.4531322717666626, train/raw-loss = 0.435144305229187, train/logprobs = tensor([[-0.7808, -1.6624],
        [-1.1795, -0.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1798797994852066
Epoch 0, Step 510: train/loss = 0.591618001461029, train/raw-loss = 0.5682373046875, train/logprobs = tensor([[-0.6947, -4.9125],
        [-0.7675, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23380698263645172
Epoch 0, Step 511: train/loss = 0.24761326611042023, train/raw-loss = 0.21998116374015808, train/logprobs = tensor([[-0.7356, -4.4051],
        [-1.3998, -1.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2763209342956543
Epoch 0, Step 512: train/loss = 0.32562190294265747, train/raw-loss = 0.3034188747406006, train/logprobs = tensor([[-0.7112, -4.3545],
        [-1.2305, -0.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22203071415424347
Epoch 0, Step 513: train/loss = 0.42183566093444824, train/raw-loss = 0.39546385407447815, train/logprobs = tensor([[-0.8014, -6.4985],
        [-1.0797, -0.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26371797919273376
Epoch 0, Step 514: train/loss = 0.576072096824646, train/raw-loss = 0.5450131893157959, train/logprobs = tensor([[-1.7569, -3.1894],
        [-1.2592, -0.6630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.310589075088501
Epoch 0, Step 515: train/loss = 0.31021732091903687, train/raw-loss = 0.2811306118965149, train/logprobs = tensor([[-0.7452, -3.5117],
        [-1.4631, -1.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2908666431903839
Epoch 0, Step 516: train/loss = 0.46215885877609253, train/raw-loss = 0.43702828884124756, train/logprobs = tensor([[-0.8039, -3.1268],
        [-0.9071, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25130578875541687
Epoch 0, Step 517: train/loss = 0.38685405254364014, train/raw-loss = 0.3636103868484497, train/logprobs = tensor([[-0.6391, -3.6362],
        [-0.9984, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23243656754493713
Epoch 0, Step 518: train/loss = 0.34462863206863403, train/raw-loss = 0.3142927885055542, train/logprobs = tensor([[-0.8673, -5.7968],
        [-1.4846, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30335837602615356
Epoch 0, Step 519: train/loss = 0.5298534035682678, train/raw-loss = 0.5011852979660034, train/logprobs = tensor([[-0.8975, -2.4731],
        [-0.8490, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28668057918548584
Epoch 0, Step 520: train/loss = 0.6546115279197693, train/raw-loss = 0.6260650157928467, train/logprobs = tensor([[-1.4959, -2.6289],
        [-0.9512, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28546518087387085
Epoch 0, Step 521: train/loss = 0.35740727186203003, train/raw-loss = 0.32574930787086487, train/logprobs = tensor([[-1.3197, -3.8507],
        [-1.9586, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3165796995162964
Epoch 0, Step 522: train/loss = 0.804391622543335, train/raw-loss = 0.7777608633041382, train/logprobs = tensor([[-2.8871, -5.4823],
        [-1.5160, -0.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663073241710663
Epoch 0, Step 523: train/loss = 0.5069572925567627, train/raw-loss = 0.4797453284263611, train/logprobs = tensor([[-0.7662, -2.9150],
        [-0.9401, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2721198797225952
Epoch 0, Step 524: train/loss = 0.5750032067298889, train/raw-loss = 0.5477795004844666, train/logprobs = tensor([[-1.0272, -1.6594],
        [-1.0121, -0.5421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722368836402893
Epoch 0, Step 525: train/loss = 0.48225268721580505, train/raw-loss = 0.45635291934013367, train/logprobs = tensor([[-0.5394, -2.6867],
        [-0.9233, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589977979660034
Epoch 0, Step 526: train/loss = 0.29549628496170044, train/raw-loss = 0.27405303716659546, train/logprobs = tensor([[-0.5745, -7.7725],
        [-0.9010, -1.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2144322246313095
Epoch 0, Step 527: train/loss = 0.5504716038703918, train/raw-loss = 0.5252575874328613, train/logprobs = tensor([[-1.4356, -5.7620],
        [-1.1936, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2521395683288574
Epoch 0, Step 528: train/loss = 0.38877737522125244, train/raw-loss = 0.3575422763824463, train/logprobs = tensor([[-0.7000, -3.4826],
        [-1.3169, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3123511075973511
Epoch 0, Step 529: train/loss = 0.4370635747909546, train/raw-loss = 0.4089551270008087, train/logprobs = tensor([[-1.8119, -5.9374],
        [-1.5432, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28108450770378113
Epoch 0, Step 530: train/loss = 0.5139418840408325, train/raw-loss = 0.4896429777145386, train/logprobs = tensor([[-0.7048, -2.9486],
        [-1.1227, -0.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2429891675710678
Epoch 0, Step 531: train/loss = 0.613024115562439, train/raw-loss = 0.5848316550254822, train/logprobs = tensor([[-1.1530, -3.7984],
        [-0.9622, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819250226020813
Epoch 0, Step 532: train/loss = 0.5882642865180969, train/raw-loss = 0.5607061386108398, train/logprobs = tensor([[-0.6876, -1.5133],
        [-0.7945, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2755812704563141
Epoch 0, Step 533: train/loss = 0.5231786966323853, train/raw-loss = 0.4982944130897522, train/logprobs = tensor([[ -2.2175, -10.4439],
        [ -1.6021,  -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24884280562400818
Epoch 0, Step 534: train/loss = 0.32163912057876587, train/raw-loss = 0.2937099039554596, train/logprobs = tensor([[-1.0099, -6.5233],
        [-1.5235, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792920172214508
Epoch 0, Step 535: train/loss = 0.5200454592704773, train/raw-loss = 0.49625441431999207, train/logprobs = tensor([[-0.5198, -2.2211],
        [-0.9367, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23791024088859558
Epoch 0, Step 536: train/loss = 0.5097688436508179, train/raw-loss = 0.4835411310195923, train/logprobs = tensor([[-0.7514, -4.0755],
        [-1.0188, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26227760314941406
Epoch 0, Step 537: train/loss = 0.3092491924762726, train/raw-loss = 0.2796756327152252, train/logprobs = tensor([[-0.8925, -5.3897],
        [-1.5061, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957359552383423
Epoch 0, Step 538: train/loss = 0.7736026048660278, train/raw-loss = 0.7473526000976562, train/logprobs = tensor([[-2.2837, -4.1023],
        [-1.0520, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26250025629997253
Epoch 0, Step 539: train/loss = 0.45568767189979553, train/raw-loss = 0.4292870759963989, train/logprobs = tensor([[-0.9093, -2.4107],
        [-1.2038, -0.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26400601863861084
Epoch 0, Step 540: train/loss = 0.3604843020439148, train/raw-loss = 0.3366899788379669, train/logprobs = tensor([[-0.9282, -8.7431],
        [-1.0510, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23794332146644592
Epoch 0, Step 541: train/loss = 0.5183330178260803, train/raw-loss = 0.497065007686615, train/logprobs = tensor([[-0.3854, -2.2408],
        [-0.6463, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21268004179000854
Epoch 0, Step 542: train/loss = 0.598075807094574, train/raw-loss = 0.5731501579284668, train/logprobs = tensor([[-1.7847, -3.5223],
        [-0.9222, -0.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492566555738449
Epoch 0, Step 543: train/loss = 0.44450798630714417, train/raw-loss = 0.4192759692668915, train/logprobs = tensor([[-0.8286, -3.6175],
        [-0.9948, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523201107978821
Epoch 0, Step 544: train/loss = 0.5201258063316345, train/raw-loss = 0.48945656418800354, train/logprobs = tensor([[-0.9236, -1.8105],
        [-1.1605, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066923916339874
Epoch 0, Step 545: train/loss = 0.3886209726333618, train/raw-loss = 0.3527326285839081, train/logprobs = tensor([[-1.5054, -3.4436],
        [-1.8062, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588833212852478
Epoch 0, Step 546: train/loss = 0.34796714782714844, train/raw-loss = 0.31789112091064453, train/logprobs = tensor([[-0.8311, -4.1250],
        [-1.4927, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30076026916503906
Epoch 0, Step 547: train/loss = 0.49751734733581543, train/raw-loss = 0.472698450088501, train/logprobs = tensor([[-1.1651, -6.2003],
        [-1.1724, -1.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24818888306617737
Epoch 0, Step 548: train/loss = 0.43521174788475037, train/raw-loss = 0.4072088897228241, train/logprobs = tensor([[-1.4248, -5.1287],
        [-1.2985, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28002870082855225
Epoch 0, Step 549: train/loss = 0.48612892627716064, train/raw-loss = 0.4576369524002075, train/logprobs = tensor([[-1.0709, -2.8470],
        [-1.1305, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849194407463074
Epoch 0, Step 550: train/loss = 0.4336831271648407, train/raw-loss = 0.40054041147232056, train/logprobs = tensor([[-1.2666, -4.6374],
        [-1.5367, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314269781112671
Epoch 0, Step 551: train/loss = 0.30229175090789795, train/raw-loss = 0.2740841209888458, train/logprobs = tensor([[-0.8586, -5.5518],
        [-1.0398, -0.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2820765972137451
Epoch 0, Step 552: train/loss = 0.40061625838279724, train/raw-loss = 0.37274307012557983, train/logprobs = tensor([[-1.0075, -6.2511],
        [-1.2811, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787315845489502
Epoch 0, Step 553: train/loss = 0.5622152090072632, train/raw-loss = 0.538776695728302, train/logprobs = tensor([[-0.5725, -2.2046],
        [-0.7614, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23438537120819092
Epoch 0, Step 554: train/loss = 0.3552402853965759, train/raw-loss = 0.33109021186828613, train/logprobs = tensor([[-0.8295, -9.5862],
        [-1.1656, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24150092899799347
Epoch 0, Step 555: train/loss = 0.5136396884918213, train/raw-loss = 0.4901602864265442, train/logprobs = tensor([[-0.9170, -8.8885],
        [-0.9857, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23479324579238892
Epoch 0, Step 556: train/loss = 0.5168970823287964, train/raw-loss = 0.4874000549316406, train/logprobs = tensor([[-0.8559, -2.0992],
        [-0.9955, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2949698865413666
Epoch 0, Step 557: train/loss = 0.48586565256118774, train/raw-loss = 0.45835113525390625, train/logprobs = tensor([[-0.8700, -2.2674],
        [-1.1638, -0.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27514520287513733
Epoch 0, Step 558: train/loss = 0.6179340481758118, train/raw-loss = 0.5861988067626953, train/logprobs = tensor([[-1.0052, -2.3647],
        [-0.9364, -0.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3173525631427765
Epoch 0, Step 559: train/loss = 0.568977952003479, train/raw-loss = 0.5414371490478516, train/logprobs = tensor([[-0.9831, -3.1709],
        [-0.7981, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27540814876556396
Epoch 0, Step 560: train/loss = 0.45842379331588745, train/raw-loss = 0.42978858947753906, train/logprobs = tensor([[-0.8181, -4.8715],
        [-1.0400, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28635191917419434
Epoch 0, Step 561: train/loss = 0.5271570086479187, train/raw-loss = 0.5027539134025574, train/logprobs = tensor([[-0.7184, -2.9485],
        [-0.7624, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24403086304664612
Epoch 0, Step 562: train/loss = 0.3844543695449829, train/raw-loss = 0.35239487886428833, train/logprobs = tensor([[-1.5939, -5.4998],
        [-1.5505, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320594847202301
Epoch 0, Step 563: train/loss = 0.5363168120384216, train/raw-loss = 0.5064700245857239, train/logprobs = tensor([[-0.9192, -4.9067],
        [-0.6798, -0.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29846835136413574
Epoch 0, Step 564: train/loss = 0.37469035387039185, train/raw-loss = 0.34704431891441345, train/logprobs = tensor([[-0.8843, -3.7591],
        [-1.2052, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27646028995513916
Epoch 0, Step 565: train/loss = 0.34680312871932983, train/raw-loss = 0.3172648549079895, train/logprobs = tensor([[-0.8643, -6.8443],
        [-1.3130, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29538270831108093
Epoch 0, Step 566: train/loss = 0.565850019454956, train/raw-loss = 0.5333871841430664, train/logprobs = tensor([[-1.7212, -3.3785],
        [-1.1725, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3246276378631592
Epoch 0, Step 567: train/loss = 0.524518609046936, train/raw-loss = 0.4909077286720276, train/logprobs = tensor([[-0.9083, -2.3225],
        [-1.3959, -1.0539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3361085057258606
Epoch 0, Step 568: train/loss = 0.5554157495498657, train/raw-loss = 0.5250144004821777, train/logprobs = tensor([[-0.9344, -3.5303],
        [-0.7914, -0.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30401378870010376
Epoch 0, Step 569: train/loss = 0.44889676570892334, train/raw-loss = 0.4238651990890503, train/logprobs = tensor([[-1.0326, -2.5384],
        [-1.4843, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25031566619873047
Epoch 0, Step 570: train/loss = 0.4149424135684967, train/raw-loss = 0.38613855838775635, train/logprobs = tensor([[-1.3676, -6.9678],
        [-1.5465, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288038432598114
Epoch 0, Step 571: train/loss = 0.504612922668457, train/raw-loss = 0.47921472787857056, train/logprobs = tensor([[-1.4320, -3.2399],
        [-1.3413, -0.5417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2539815306663513
Epoch 0, Step 572: train/loss = 0.20752280950546265, train/raw-loss = 0.17873679101467133, train/logprobs = tensor([[-0.6821, -6.7266],
        [-1.4864, -1.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28786012530326843
Epoch 0, Step 573: train/loss = 0.2917235493659973, train/raw-loss = 0.26193350553512573, train/logprobs = tensor([[-0.9631, -4.5408],
        [-1.4156, -0.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979002296924591
Epoch 0, Step 574: train/loss = 0.4267931580543518, train/raw-loss = 0.39854931831359863, train/logprobs = tensor([[-1.0037, -4.7306],
        [-1.1314, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28243836760520935
Epoch 0, Step 575: train/loss = 0.4638538658618927, train/raw-loss = 0.43552327156066895, train/logprobs = tensor([[-0.9148, -6.2681],
        [-0.9633, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28330618143081665
Epoch 0, Step 576: train/loss = 0.38913559913635254, train/raw-loss = 0.3597954213619232, train/logprobs = tensor([[-0.8958, -5.1945],
        [-1.1649, -1.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2934015393257141
Epoch 0, Step 577: train/loss = 0.4405052065849304, train/raw-loss = 0.41074350476264954, train/logprobs = tensor([[-0.8574, -3.2387],
        [-1.3318, -1.0453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976170778274536
Epoch 0, Step 578: train/loss = 0.49558940529823303, train/raw-loss = 0.4669108986854553, train/logprobs = tensor([[-1.2618, -3.9155],
        [-1.2383, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2867847681045532
Epoch 0, Step 579: train/loss = 0.22347202897071838, train/raw-loss = 0.1952805519104004, train/logprobs = tensor([[-0.7557, -5.9846],
        [-1.3501, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28191471099853516
Epoch 0, Step 580: train/loss = 0.619257926940918, train/raw-loss = 0.5850929021835327, train/logprobs = tensor([[-1.2471, -3.3061],
        [-1.1532, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34164977073669434
Epoch 0, Step 581: train/loss = 0.5334111452102661, train/raw-loss = 0.5050336122512817, train/logprobs = tensor([[-0.9881, -3.8051],
        [-0.8341, -0.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837753891944885
Epoch 0, Step 582: train/loss = 0.46512866020202637, train/raw-loss = 0.4315618872642517, train/logprobs = tensor([[-1.4695, -5.1114],
        [-1.4334, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33566778898239136
Epoch 0, Step 583: train/loss = 0.4807846248149872, train/raw-loss = 0.44907331466674805, train/logprobs = tensor([[-1.4292, -6.9149],
        [-1.3361, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31711331009864807
Epoch 0, Step 584: train/loss = 0.369207501411438, train/raw-loss = 0.33490705490112305, train/logprobs = tensor([[-1.2472, -5.8548],
        [-1.3867, -0.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430044949054718
Epoch 0, Step 585: train/loss = 0.4875113368034363, train/raw-loss = 0.45310261845588684, train/logprobs = tensor([[-0.9818, -3.7093],
        [-1.2761, -1.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3440873622894287
Epoch 0, Step 586: train/loss = 0.5762048363685608, train/raw-loss = 0.5492547750473022, train/logprobs = tensor([[-0.7946, -2.2096],
        [-0.8051, -0.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2695007026195526
Epoch 0, Step 587: train/loss = 0.4091469645500183, train/raw-loss = 0.38070064783096313, train/logprobs = tensor([[-1.1506, -3.5465],
        [-1.1186, -0.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28446298837661743
Epoch 0, Step 588: train/loss = 0.5232906937599182, train/raw-loss = 0.49623772501945496, train/logprobs = tensor([[-0.6406, -1.8284],
        [-0.9969, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27053001523017883
Epoch 0, Step 589: train/loss = 0.47677671909332275, train/raw-loss = 0.44763076305389404, train/logprobs = tensor([[-0.7129, -3.3161],
        [-1.3701, -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29145973920822144
Epoch 0, Step 590: train/loss = 0.5436335206031799, train/raw-loss = 0.5125202536582947, train/logprobs = tensor([[-1.5133, -4.9239],
        [-1.2488, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3111325800418854
Epoch 0, Step 591: train/loss = 0.37879520654678345, train/raw-loss = 0.35218197107315063, train/logprobs = tensor([[-0.8561, -6.6379],
        [-1.0796, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661324441432953
Epoch 0, Step 592: train/loss = 0.4972150921821594, train/raw-loss = 0.4684111475944519, train/logprobs = tensor([[-1.0955, -3.7007],
        [-1.4580, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2880401015281677
Epoch 0, Step 593: train/loss = 0.4519508481025696, train/raw-loss = 0.4203990399837494, train/logprobs = tensor([[-1.7058, -4.2421],
        [-1.5887, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3155181109905243
Epoch 0, Step 594: train/loss = 0.3446483612060547, train/raw-loss = 0.3159902095794678, train/logprobs = tensor([[-0.7493, -4.6509],
        [-1.1947, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28658154606819153
Epoch 0, Step 595: train/loss = 0.4971863925457001, train/raw-loss = 0.4664417505264282, train/logprobs = tensor([[-1.2200, -3.4186],
        [-1.3617, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30744609236717224
Epoch 0, Step 596: train/loss = 0.9057599306106567, train/raw-loss = 0.8749213218688965, train/logprobs = tensor([[-2.1757, -2.2240],
        [-1.0712, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30838558077812195
Epoch 0, Step 597: train/loss = 0.4782823920249939, train/raw-loss = 0.4444621801376343, train/logprobs = tensor([[-0.9184, -1.9814],
        [-1.4303, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382025361061096
Epoch 0, Step 598: train/loss = 0.46318483352661133, train/raw-loss = 0.43346649408340454, train/logprobs = tensor([[-1.1046, -3.7738],
        [-1.3534, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29718318581581116
Epoch 0, Step 599: train/loss = 0.33734023571014404, train/raw-loss = 0.3065623641014099, train/logprobs = tensor([[-0.6831, -5.9598],
        [-1.1384, -0.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077787458896637
Epoch 0, Step 600: train/loss = 0.4463133215904236, train/raw-loss = 0.41840076446533203, train/logprobs = tensor([[-0.7775, -3.8924],
        [-1.4778, -0.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27912572026252747
Epoch 0, Step 601: train/loss = 0.5116293430328369, train/raw-loss = 0.48743319511413574, train/logprobs = tensor([[-0.6823, -2.0219],
        [-0.7364, -0.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24196182191371918
Epoch 0, Step 602: train/loss = 1.0290206670761108, train/raw-loss = 0.9982980489730835, train/logprobs = tensor([[-2.6592, -5.1081],
        [-1.1237, -1.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3072258234024048
Epoch 0, Step 603: train/loss = 0.5370920300483704, train/raw-loss = 0.5158873796463013, train/logprobs = tensor([[-0.4966, -1.5383],
        [-0.7174, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21204641461372375
Epoch 0, Step 604: train/loss = 0.7669058442115784, train/raw-loss = 0.743047833442688, train/logprobs = tensor([[-2.5509, -4.0965],
        [-1.3212, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23857945203781128
Epoch 0, Step 605: train/loss = 0.28551438450813293, train/raw-loss = 0.25448501110076904, train/logprobs = tensor([[-0.8629, -7.6222],
        [-1.1515, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31029361486434937
Epoch 0, Step 606: train/loss = 0.5682982206344604, train/raw-loss = 0.5407875776290894, train/logprobs = tensor([[-1.3240, -6.0345],
        [-1.0321, -0.7044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27510619163513184
Epoch 0, Step 607: train/loss = 0.38121357560157776, train/raw-loss = 0.3533293306827545, train/logprobs = tensor([[-1.4558, -8.1583],
        [-1.8008, -1.4008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27884259819984436
Epoch 0, Step 608: train/loss = 0.8689819574356079, train/raw-loss = 0.8361328840255737, train/logprobs = tensor([[-2.3307, -2.4215],
        [-0.9958, -0.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3284916281700134
Epoch 0, Step 609: train/loss = 0.39587661623954773, train/raw-loss = 0.36336416006088257, train/logprobs = tensor([[-0.9906, -6.4961],
        [-1.1796, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32512444257736206
Epoch 0, Step 610: train/loss = 0.20222902297973633, train/raw-loss = 0.1709035336971283, train/logprobs = tensor([[-0.8322, -6.4868],
        [-1.6120, -0.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132550120353699
Epoch 0, Step 611: train/loss = 0.2718001902103424, train/raw-loss = 0.24033497273921967, train/logprobs = tensor([[-0.9543, -6.6855],
        [-1.5332, -1.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31465205550193787
Epoch 0, Step 612: train/loss = 0.46374770998954773, train/raw-loss = 0.4286465644836426, train/logprobs = tensor([[-1.1395, -6.2175],
        [-1.5323, -1.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35101133584976196
Epoch 0, Step 613: train/loss = 0.4437973201274872, train/raw-loss = 0.41758406162261963, train/logprobs = tensor([[-0.8210, -3.2692],
        [-1.2395, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26213258504867554
Epoch 0, Step 614: train/loss = 0.5082228779792786, train/raw-loss = 0.47221383452415466, train/logprobs = tensor([[-1.1442, -2.4620],
        [-1.4225, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3600907325744629
Epoch 0, Step 615: train/loss = 0.5755346417427063, train/raw-loss = 0.5444881916046143, train/logprobs = tensor([[-1.7735, -7.0645],
        [-1.4534, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3104635179042816
Epoch 0, Step 616: train/loss = 0.8753896951675415, train/raw-loss = 0.8425045609474182, train/logprobs = tensor([[-2.9247, -3.1626],
        [-1.3171, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32885098457336426
Epoch 0, Step 617: train/loss = 0.5083023309707642, train/raw-loss = 0.47862958908081055, train/logprobs = tensor([[-0.9203, -2.9347],
        [-1.1200, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967272102832794
Epoch 0, Step 618: train/loss = 0.6352704763412476, train/raw-loss = 0.5995638370513916, train/logprobs = tensor([[-2.2381, -4.2829],
        [-1.3831, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35706615447998047
Epoch 0, Step 619: train/loss = 0.31759926676750183, train/raw-loss = 0.2891978919506073, train/logprobs = tensor([[-1.3276, -5.4575],
        [-1.9236, -0.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840138077735901
Epoch 0, Step 620: train/loss = 0.5051469206809998, train/raw-loss = 0.4737308621406555, train/logprobs = tensor([[-0.6931, -4.2884],
        [-1.4101, -0.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141600489616394
Epoch 0, Step 621: train/loss = 0.3948122262954712, train/raw-loss = 0.36516904830932617, train/logprobs = tensor([[-0.7259, -4.3947],
        [-0.9809, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964319884777069
Epoch 0, Step 622: train/loss = 0.4049918055534363, train/raw-loss = 0.37340426445007324, train/logprobs = tensor([[-0.6715, -3.6980],
        [-1.3886, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31587547063827515
Epoch 0, Step 623: train/loss = 0.47411268949508667, train/raw-loss = 0.4421093165874481, train/logprobs = tensor([[-1.1095, -5.7101],
        [-1.4631, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200342059135437
Epoch 0, Step 624: train/loss = 0.30241164565086365, train/raw-loss = 0.2674027979373932, train/logprobs = tensor([[-1.5255, -6.0897],
        [-1.8666, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3500884771347046
Epoch 0, Step 625: train/loss = 0.2786675691604614, train/raw-loss = 0.24888676404953003, train/logprobs = tensor([[-1.3122, -6.4783],
        [-1.7198, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29780811071395874
Epoch 0, Step 626: train/loss = 0.4611365795135498, train/raw-loss = 0.4364137649536133, train/logprobs = tensor([[-0.7224, -6.3070],
        [-0.9991, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24722795188426971
Epoch 0, Step 627: train/loss = 0.4836890399456024, train/raw-loss = 0.45144715905189514, train/logprobs = tensor([[-0.8302, -3.3397],
        [-1.3062, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32241880893707275
Epoch 0, Step 628: train/loss = 0.32727497816085815, train/raw-loss = 0.2941402792930603, train/logprobs = tensor([[-1.2589, -9.6374],
        [-1.8823, -1.3601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33134663105010986
Epoch 0, Step 629: train/loss = 0.4537404477596283, train/raw-loss = 0.4232814311981201, train/logprobs = tensor([[-1.6200, -4.7058],
        [-1.5249, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30459001660346985
Epoch 0, Step 630: train/loss = 0.3951694965362549, train/raw-loss = 0.3632914423942566, train/logprobs = tensor([[-1.2353, -4.6850],
        [-1.5338, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318780779838562
Epoch 0, Step 631: train/loss = 0.49214839935302734, train/raw-loss = 0.4627113938331604, train/logprobs = tensor([[-1.5728, -5.4165],
        [-1.2741, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29437023401260376
Epoch 0, Step 632: train/loss = 0.32861918210983276, train/raw-loss = 0.29405689239501953, train/logprobs = tensor([[-1.3179, -5.3189],
        [-1.7861, -0.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3456227481365204
Epoch 0, Step 633: train/loss = 0.5927947759628296, train/raw-loss = 0.5624059438705444, train/logprobs = tensor([[-0.9676, -1.4992],
        [-1.2741, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303888201713562
Epoch 0, Step 634: train/loss = 0.8008383512496948, train/raw-loss = 0.771094799041748, train/logprobs = tensor([[-1.5594, -1.0274],
        [-1.1654, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29743602871894836
Epoch 0, Step 635: train/loss = 0.3158244490623474, train/raw-loss = 0.2847023010253906, train/logprobs = tensor([[-0.8425, -3.9810],
        [-1.5680, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31122148036956787
Epoch 0, Step 636: train/loss = 0.4141058027744293, train/raw-loss = 0.3841099441051483, train/logprobs = tensor([[-1.0527, -3.5809],
        [-1.6692, -0.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29995861649513245
Epoch 0, Step 637: train/loss = 0.4121379852294922, train/raw-loss = 0.38429808616638184, train/logprobs = tensor([[-0.5927, -3.2283],
        [-0.9654, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27839893102645874
Epoch 0, Step 638: train/loss = 0.5746361613273621, train/raw-loss = 0.5358187556266785, train/logprobs = tensor([[-1.5056, -2.4305],
        [-1.4571, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3881740868091583
Epoch 0, Step 639: train/loss = 0.35656848549842834, train/raw-loss = 0.3272450566291809, train/logprobs = tensor([[-0.8139, -4.0428],
        [-1.5340, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932339608669281
Epoch 0, Step 640: train/loss = 0.3486784100532532, train/raw-loss = 0.3191136121749878, train/logprobs = tensor([[-0.6054, -4.0430],
        [-1.4633, -0.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956475615501404
Epoch 0, Step 641: train/loss = 0.5292201638221741, train/raw-loss = 0.4986596703529358, train/logprobs = tensor([[-1.2565, -6.0349],
        [-1.1495, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056052625179291
Epoch 0, Step 642: train/loss = 0.5708626508712769, train/raw-loss = 0.5409246683120728, train/logprobs = tensor([[-0.5464, -4.3693],
        [-1.0714, -0.9984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2993798851966858
Epoch 0, Step 643: train/loss = 0.29509878158569336, train/raw-loss = 0.26124221086502075, train/logprobs = tensor([[ -1.3694, -11.0603],
        [ -2.2421,  -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3385655879974365
Epoch 0, Step 644: train/loss = 0.4130023717880249, train/raw-loss = 0.38233932852745056, train/logprobs = tensor([[-1.0367, -5.4055],
        [-1.0569, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066302537918091
Epoch 0, Step 645: train/loss = 0.3065231442451477, train/raw-loss = 0.2728186547756195, train/logprobs = tensor([[-0.7422, -5.0161],
        [-1.6428, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33704495429992676
Epoch 0, Step 646: train/loss = 0.5146530866622925, train/raw-loss = 0.48445427417755127, train/logprobs = tensor([[-1.2225, -3.0234],
        [-1.3841, -0.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30198800563812256
Epoch 0, Step 647: train/loss = 0.4594089984893799, train/raw-loss = 0.4232713282108307, train/logprobs = tensor([[-0.8917, -2.7971],
        [-1.3540, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3613767623901367
Epoch 0, Step 648: train/loss = 0.48932522535324097, train/raw-loss = 0.45957404375076294, train/logprobs = tensor([[-1.0133, -2.9543],
        [-1.2890, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29751184582710266
Epoch 0, Step 649: train/loss = 0.3734068274497986, train/raw-loss = 0.341899573802948, train/logprobs = tensor([[-1.2479, -3.6148],
        [-1.4101, -0.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31507250666618347
Epoch 0, Step 650: train/loss = 0.4763772785663605, train/raw-loss = 0.4451047480106354, train/logprobs = tensor([[-0.8538, -4.0254],
        [-1.2216, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31272509694099426
Epoch 0, Step 651: train/loss = 0.3704524338245392, train/raw-loss = 0.3339494466781616, train/logprobs = tensor([[-1.3179, -3.6518],
        [-1.4778, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3650296628475189
Epoch 0, Step 652: train/loss = 0.5396469235420227, train/raw-loss = 0.5087530016899109, train/logprobs = tensor([[-0.8837, -1.7506],
        [-1.3086, -1.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3089391589164734
Epoch 0, Step 653: train/loss = 0.3987833857536316, train/raw-loss = 0.3710578680038452, train/logprobs = tensor([[-0.8155, -7.0378],
        [-0.8900, -1.3965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772552967071533
Epoch 0, Step 654: train/loss = 0.43861281871795654, train/raw-loss = 0.4109022915363312, train/logprobs = tensor([[-1.2443, -3.2179],
        [-1.1869, -0.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27710533142089844
Epoch 0, Step 655: train/loss = 0.6422942280769348, train/raw-loss = 0.6094629168510437, train/logprobs = tensor([[-0.7885, -1.0148],
        [-1.0568, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32831335067749023
Epoch 0, Step 656: train/loss = 0.3457716405391693, train/raw-loss = 0.31309327483177185, train/logprobs = tensor([[-1.3224, -5.9842],
        [-1.7853, -0.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267836272716522
Epoch 0, Step 657: train/loss = 0.3225939869880676, train/raw-loss = 0.2915942370891571, train/logprobs = tensor([[-0.8176, -5.4169],
        [-1.3694, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30999764800071716
Epoch 0, Step 658: train/loss = 0.597798228263855, train/raw-loss = 0.5710361003875732, train/logprobs = tensor([[-1.4665, -7.5936],
        [-0.8803, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26762086153030396
Epoch 0, Step 659: train/loss = 0.45141470432281494, train/raw-loss = 0.4269898235797882, train/logprobs = tensor([[-0.6996, -2.9239],
        [-0.8768, -0.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24424895644187927
Epoch 0, Step 660: train/loss = 0.30713027715682983, train/raw-loss = 0.27859216928482056, train/logprobs = tensor([[-0.5693, -5.1136],
        [-1.3058, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2853810787200928
Epoch 0, Step 661: train/loss = 0.5003043413162231, train/raw-loss = 0.47058331966400146, train/logprobs = tensor([[-1.0686, -2.9364],
        [-1.3849, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2972101867198944
Epoch 0, Step 662: train/loss = 0.41216447949409485, train/raw-loss = 0.3766166567802429, train/logprobs = tensor([[-1.5242, -6.3560],
        [-1.8467, -0.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3554783761501312
Epoch 0, Step 663: train/loss = 0.2752203047275543, train/raw-loss = 0.24419713020324707, train/logprobs = tensor([[-0.9509, -4.6192],
        [-1.4449, -1.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3102319836616516
Epoch 0, Step 664: train/loss = 0.3793947696685791, train/raw-loss = 0.3487568199634552, train/logprobs = tensor([[-0.6689, -3.8069],
        [-1.4682, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30637913942337036
Epoch 0, Step 665: train/loss = 0.5834327936172485, train/raw-loss = 0.5572164058685303, train/logprobs = tensor([[-0.5231, -2.2789],
        [-0.9439, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621634602546692
Epoch 0, Step 666: train/loss = 0.9314324855804443, train/raw-loss = 0.898577868938446, train/logprobs = tensor([[-2.6138, -3.1829],
        [-1.0390, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285461664199829
Epoch 0, Step 667: train/loss = 0.5282219052314758, train/raw-loss = 0.4939708411693573, train/logprobs = tensor([[-0.8679, -2.9301],
        [-1.7602, -1.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425106704235077
Epoch 0, Step 668: train/loss = 0.1741533875465393, train/raw-loss = 0.13264383375644684, train/logprobs = tensor([[-0.9885, -7.6493],
        [-2.1732, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41509556770324707
Epoch 0, Step 669: train/loss = 0.24748489260673523, train/raw-loss = 0.20760506391525269, train/logprobs = tensor([[-1.6979, -7.5517],
        [-2.8800, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39879828691482544
Epoch 0, Step 670: train/loss = 0.41530847549438477, train/raw-loss = 0.3840091824531555, train/logprobs = tensor([[-0.9354, -5.2502],
        [-1.8018, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31299278140068054
Epoch 0, Step 671: train/loss = 0.4512840509414673, train/raw-loss = 0.4195330739021301, train/logprobs = tensor([[-1.7631, -4.8172],
        [-1.4841, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31750988960266113
Epoch 0, Step 672: train/loss = 0.5819494128227234, train/raw-loss = 0.5531322956085205, train/logprobs = tensor([[-1.5774, -3.6906],
        [-1.1305, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881712019443512
Epoch 0, Step 673: train/loss = 0.6274219155311584, train/raw-loss = 0.6018682718276978, train/logprobs = tensor([[-0.7561, -2.9766],
        [-0.8880, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555357813835144
Epoch 0, Step 674: train/loss = 0.4375098943710327, train/raw-loss = 0.4037764072418213, train/logprobs = tensor([[-0.9950, -3.4035],
        [-1.1857, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373347520828247
Epoch 0, Step 675: train/loss = 0.4100682735443115, train/raw-loss = 0.37182947993278503, train/logprobs = tensor([[-0.6555, -3.8859],
        [-1.5760, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38238805532455444
Epoch 0, Step 676: train/loss = 0.47388285398483276, train/raw-loss = 0.43828272819519043, train/logprobs = tensor([[-1.7081, -5.4320],
        [-1.6480, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560016453266144
Epoch 0, Step 677: train/loss = 0.5642061829566956, train/raw-loss = 0.5333127975463867, train/logprobs = tensor([[-1.1601, -5.1218],
        [-1.1774, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3089335560798645
Epoch 0, Step 678: train/loss = 0.4587632119655609, train/raw-loss = 0.4305228888988495, train/logprobs = tensor([[-0.6757, -3.5636],
        [-1.1640, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2824033796787262
Epoch 0, Step 679: train/loss = 0.32201525568962097, train/raw-loss = 0.2868574261665344, train/logprobs = tensor([[-1.3157, -6.0254],
        [-1.9563, -0.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35157811641693115
Epoch 0, Step 680: train/loss = 0.7580950260162354, train/raw-loss = 0.7242282032966614, train/logprobs = tensor([[-0.6474, -0.8490],
        [-1.0643, -1.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3386681377887726
Epoch 0, Step 681: train/loss = 0.49673259258270264, train/raw-loss = 0.47058534622192383, train/logprobs = tensor([[-0.8302, -2.6212],
        [-1.0366, -0.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26147279143333435
Epoch 0, Step 682: train/loss = 0.561491847038269, train/raw-loss = 0.5350703597068787, train/logprobs = tensor([[-0.4409, -0.7241],
        [-1.0630, -0.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642148733139038
Epoch 0, Step 683: train/loss = 0.5721225738525391, train/raw-loss = 0.544820249080658, train/logprobs = tensor([[-0.8542, -1.8237],
        [-1.2130, -0.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730235457420349
Epoch 0, Step 684: train/loss = 0.43526649475097656, train/raw-loss = 0.40497535467147827, train/logprobs = tensor([[-0.9390, -4.4101],
        [-1.2957, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30291175842285156
Epoch 0, Step 685: train/loss = 0.4925277829170227, train/raw-loss = 0.4624939560890198, train/logprobs = tensor([[-0.6611, -2.1707],
        [-1.1164, -0.9687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30033811926841736
Epoch 0, Step 686: train/loss = 0.2925964295864105, train/raw-loss = 0.2610662877559662, train/logprobs = tensor([[-1.2752, -4.6974],
        [-2.1820, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3153015375137329
Epoch 0, Step 687: train/loss = 0.20020323991775513, train/raw-loss = 0.16809800267219543, train/logprobs = tensor([[-0.4925, -6.3190],
        [-1.4067, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210521936416626
Epoch 0, Step 688: train/loss = 0.3236857056617737, train/raw-loss = 0.29637449979782104, train/logprobs = tensor([[-1.1582, -8.5915],
        [-1.1689, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731119394302368
Epoch 0, Step 689: train/loss = 0.4024094343185425, train/raw-loss = 0.3755084276199341, train/logprobs = tensor([[-0.5682, -3.5343],
        [-0.9303, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26901060342788696
Epoch 0, Step 690: train/loss = 0.46237608790397644, train/raw-loss = 0.4349525570869446, train/logprobs = tensor([[-0.3617, -2.0430],
        [-1.2418, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742353677749634
Epoch 0, Step 691: train/loss = 0.40840739011764526, train/raw-loss = 0.3775070011615753, train/logprobs = tensor([[-0.7322, -3.2672],
        [-1.5080, -0.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30900394916534424
Epoch 0, Step 692: train/loss = 0.7854183912277222, train/raw-loss = 0.746945858001709, train/logprobs = tensor([[-2.8582, -7.1985],
        [-1.6075, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3847252428531647
Epoch 0, Step 693: train/loss = 0.3396993577480316, train/raw-loss = 0.3036194145679474, train/logprobs = tensor([[-0.8379, -3.5069],
        [-1.5967, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3607993721961975
Epoch 0, Step 694: train/loss = 0.761336088180542, train/raw-loss = 0.7284283638000488, train/logprobs = tensor([[-1.4206, -4.0060],
        [-1.3757, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32907772064208984
Epoch 0, Step 695: train/loss = 0.31464099884033203, train/raw-loss = 0.2784959673881531, train/logprobs = tensor([[-0.5418, -3.5696],
        [-1.5494, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3614504337310791
Epoch 0, Step 696: train/loss = 0.4925788938999176, train/raw-loss = 0.4561708867549896, train/logprobs = tensor([[-0.7132, -2.9013],
        [-1.6746, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364080011844635
Epoch 0, Step 697: train/loss = 0.3502117991447449, train/raw-loss = 0.31967389583587646, train/logprobs = tensor([[-0.5701, -4.4661],
        [-1.1145, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305378794670105
Epoch 0, Step 698: train/loss = 0.3861910402774811, train/raw-loss = 0.35327211022377014, train/logprobs = tensor([[-0.4958, -2.3948],
        [-1.3541, -1.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291894197463989
Epoch 0, Step 699: train/loss = 0.6340450644493103, train/raw-loss = 0.6066448092460632, train/logprobs = tensor([[-0.6837, -1.7507],
        [-0.7991, -0.9535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740021347999573
Epoch 0, Step 700: train/loss = 0.3793680667877197, train/raw-loss = 0.346414178609848, train/logprobs = tensor([[-0.5987, -3.1058],
        [-1.5875, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295390009880066
Epoch 0, Step 701: train/loss = 0.5812038779258728, train/raw-loss = 0.5432102680206299, train/logprobs = tensor([[-1.0774, -2.4829],
        [-1.3033, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799355924129486
Epoch 0, Step 702: train/loss = 0.36328065395355225, train/raw-loss = 0.3287116289138794, train/logprobs = tensor([[-1.4472, -6.7302],
        [-1.8691, -1.0874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34569019079208374
Epoch 0, Step 703: train/loss = 0.36551374197006226, train/raw-loss = 0.3321289122104645, train/logprobs = tensor([[-1.4453, -5.6337],
        [-2.0044, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3338482975959778
Epoch 0, Step 704: train/loss = 0.2756991982460022, train/raw-loss = 0.24242790043354034, train/logprobs = tensor([[-0.5405, -5.2127],
        [-1.9600, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.332712858915329
Epoch 0, Step 705: train/loss = 0.29848599433898926, train/raw-loss = 0.2595382034778595, train/logprobs = tensor([[-0.9300, -4.2533],
        [-1.9332, -1.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894779682159424
Epoch 0, Step 706: train/loss = 0.6290248036384583, train/raw-loss = 0.5994652509689331, train/logprobs = tensor([[-1.9116, -3.9765],
        [-1.0917, -0.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29559528827667236
Epoch 0, Step 707: train/loss = 0.21464116871356964, train/raw-loss = 0.1810992807149887, train/logprobs = tensor([[-0.6317, -9.1740],
        [-1.8256, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33541882038116455
Epoch 0, Step 708: train/loss = 0.5210885405540466, train/raw-loss = 0.48574143648147583, train/logprobs = tensor([[-0.7376, -3.0914],
        [-1.2134, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35347113013267517
Epoch 0, Step 709: train/loss = 0.40992581844329834, train/raw-loss = 0.3768373131752014, train/logprobs = tensor([[-0.7935, -4.5954],
        [-1.4166, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3308848738670349
Epoch 0, Step 710: train/loss = 0.29549649357795715, train/raw-loss = 0.26258373260498047, train/logprobs = tensor([[-0.5219, -4.4056],
        [-1.6764, -0.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32912784814834595
Epoch 0, Step 711: train/loss = 0.5379893779754639, train/raw-loss = 0.5028064250946045, train/logprobs = tensor([[-0.4784, -2.6797],
        [-1.2592, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351829469203949
Epoch 0, Step 712: train/loss = 0.43077555298805237, train/raw-loss = 0.40109699964523315, train/logprobs = tensor([[-1.0773, -3.5277],
        [-1.3841, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29678580164909363
Epoch 0, Step 713: train/loss = 0.4212871491909027, train/raw-loss = 0.3920990526676178, train/logprobs = tensor([[-0.4398, -3.7445],
        [-0.9961, -1.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29188141226768494
Epoch 0, Step 714: train/loss = 0.44733139872550964, train/raw-loss = 0.4220990836620331, train/logprobs = tensor([[-0.9488, -2.1239],
        [-1.5256, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252323180437088
Epoch 0, Step 715: train/loss = 0.3706364631652832, train/raw-loss = 0.3371354937553406, train/logprobs = tensor([[-0.7475, -3.0813],
        [-1.5596, -0.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33500975370407104
Epoch 0, Step 716: train/loss = 0.5389270186424255, train/raw-loss = 0.5053807497024536, train/logprobs = tensor([[-0.5777, -1.6177],
        [-1.4175, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33546268939971924
Epoch 0, Step 717: train/loss = 0.3485966622829437, train/raw-loss = 0.3163086771965027, train/logprobs = tensor([[-0.8068, -2.9886],
        [-1.6954, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32287999987602234
Epoch 0, Step 718: train/loss = 0.44465693831443787, train/raw-loss = 0.4163280725479126, train/logprobs = tensor([[-0.4774, -3.6149],
        [-1.1357, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832888066768646
Epoch 0, Step 719: train/loss = 0.4590642750263214, train/raw-loss = 0.42388468980789185, train/logprobs = tensor([[-0.5660, -2.8611],
        [-1.8714, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517962098121643
Epoch 0, Step 720: train/loss = 0.3922368884086609, train/raw-loss = 0.36354368925094604, train/logprobs = tensor([[-0.5442, -6.0116],
        [-1.0410, -0.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869317829608917
Epoch 0, Step 721: train/loss = 0.2616842985153198, train/raw-loss = 0.23132438957691193, train/logprobs = tensor([[ -0.7761, -11.1709],
        [ -2.1314,  -2.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035992383956909
Epoch 0, Step 722: train/loss = 1.4045177698135376, train/raw-loss = 1.369563341140747, train/logprobs = tensor([[-5.0078, -4.9779],
        [-1.8369, -1.3140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34954360127449036
Epoch 0, Step 723: train/loss = 0.2508854269981384, train/raw-loss = 0.21678191423416138, train/logprobs = tensor([[-0.7098, -4.7435],
        [-1.4910, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3410353660583496
Epoch 0, Step 724: train/loss = 0.9127756953239441, train/raw-loss = 0.8824106454849243, train/logprobs = tensor([[-1.2867, -1.1366],
        [-1.2831, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3036503493785858
Epoch 0, Step 725: train/loss = 0.46824145317077637, train/raw-loss = 0.4330716133117676, train/logprobs = tensor([[-0.5382, -5.3818],
        [-2.0138, -1.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351698637008667
Epoch 0, Step 726: train/loss = 0.3272029757499695, train/raw-loss = 0.2987963557243347, train/logprobs = tensor([[-0.5482, -6.4634],
        [-1.3342, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284065842628479
Epoch 0, Step 727: train/loss = 0.4652363955974579, train/raw-loss = 0.42515823245048523, train/logprobs = tensor([[-0.7536, -2.7963],
        [-2.0594, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4007818102836609
Epoch 0, Step 728: train/loss = 0.44163256883621216, train/raw-loss = 0.4091159999370575, train/logprobs = tensor([[-0.9353, -6.0773],
        [-1.6140, -1.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251657783985138
Epoch 0, Step 729: train/loss = 0.4372304677963257, train/raw-loss = 0.4003860354423523, train/logprobs = tensor([[-0.6892, -3.4711],
        [-1.7438, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36844414472579956
Epoch 0, Step 730: train/loss = 0.36962881684303284, train/raw-loss = 0.3365132808685303, train/logprobs = tensor([[-1.3350, -5.3864],
        [-1.8810, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3311552405357361
Epoch 0, Step 731: train/loss = 0.37828874588012695, train/raw-loss = 0.34380459785461426, train/logprobs = tensor([[-0.5987, -7.1323],
        [-1.6515, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34484177827835083
Epoch 0, Step 732: train/loss = 0.45201823115348816, train/raw-loss = 0.4224966764450073, train/logprobs = tensor([[-0.7622, -2.7365],
        [-1.0648, -0.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952156662940979
Epoch 0, Step 733: train/loss = 0.5202603936195374, train/raw-loss = 0.4862128496170044, train/logprobs = tensor([[-0.9224, -1.6402],
        [-1.4143, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34047573804855347
Epoch 0, Step 734: train/loss = 0.6103653907775879, train/raw-loss = 0.5850178599357605, train/logprobs = tensor([[-0.5461, -0.8416],
        [-0.9796, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534756660461426
Epoch 0, Step 735: train/loss = 0.6635926365852356, train/raw-loss = 0.6414456367492676, train/logprobs = tensor([[-0.4375, -0.6423],
        [-0.7224, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22146984934806824
Epoch 0, Step 736: train/loss = 0.4490169882774353, train/raw-loss = 0.41644564270973206, train/logprobs = tensor([[-0.8958, -4.9419],
        [-1.6622, -0.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3257136344909668
Epoch 0, Step 737: train/loss = 0.5144160985946655, train/raw-loss = 0.48056530952453613, train/logprobs = tensor([[-0.8986, -1.5951],
        [-1.6171, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33850809931755066
Epoch 0, Step 738: train/loss = 0.532221794128418, train/raw-loss = 0.5007879734039307, train/logprobs = tensor([[-0.4434, -2.4052],
        [-1.2604, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31433865427970886
Epoch 0, Step 739: train/loss = 0.25784242153167725, train/raw-loss = 0.2188795506954193, train/logprobs = tensor([[-0.7870, -3.6567],
        [-2.0010, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3896285891532898
Epoch 0, Step 740: train/loss = 0.4392162561416626, train/raw-loss = 0.4141891598701477, train/logprobs = tensor([[-0.6288, -2.8170],
        [-0.8376, -0.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502710819244385
Epoch 0, Step 741: train/loss = 0.36211615800857544, train/raw-loss = 0.3297192454338074, train/logprobs = tensor([[-0.5538, -2.2592],
        [-1.6672, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3239690363407135
Epoch 0, Step 742: train/loss = 0.4437785744667053, train/raw-loss = 0.4154054820537567, train/logprobs = tensor([[-1.1417, -2.9603],
        [-1.5080, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837306559085846
Epoch 0, Step 743: train/loss = 0.44573861360549927, train/raw-loss = 0.4164326786994934, train/logprobs = tensor([[-0.7046, -3.7125],
        [-0.8831, -0.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2930592894554138
Epoch 0, Step 744: train/loss = 0.29167163372039795, train/raw-loss = 0.25371792912483215, train/logprobs = tensor([[-0.9153, -5.2056],
        [-1.8463, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37953710556030273
Epoch 0, Step 745: train/loss = 0.2636788487434387, train/raw-loss = 0.23021090030670166, train/logprobs = tensor([[-0.5842, -7.1121],
        [-1.9130, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346795439720154
Epoch 0, Step 746: train/loss = 0.34728333353996277, train/raw-loss = 0.32130032777786255, train/logprobs = tensor([[-0.5240, -5.6779],
        [-0.9122, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25983014702796936
Epoch 0, Step 747: train/loss = 0.4919940233230591, train/raw-loss = 0.4636189341545105, train/logprobs = tensor([[-0.6959, -2.5137],
        [-1.4319, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28375089168548584
Epoch 0, Step 748: train/loss = 0.24914619326591492, train/raw-loss = 0.210868239402771, train/logprobs = tensor([[-1.0145, -8.7666],
        [-2.2370, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.382779598236084
Epoch 0, Step 749: train/loss = 0.42362457513809204, train/raw-loss = 0.3922119736671448, train/logprobs = tensor([[-0.5923, -6.7749],
        [-1.2797, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141261041164398
Epoch 0, Step 750: train/loss = 0.45353102684020996, train/raw-loss = 0.42630821466445923, train/logprobs = tensor([[-1.2837, -6.3543],
        [-1.3460, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27222806215286255
Epoch 0, Step 751: train/loss = 0.21353501081466675, train/raw-loss = 0.1809244453907013, train/logprobs = tensor([[-0.5992, -5.4505],
        [-1.6618, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.326105535030365
Epoch 0, Step 752: train/loss = 0.5200561285018921, train/raw-loss = 0.4858436584472656, train/logprobs = tensor([[-0.7046, -5.9941],
        [-1.2292, -1.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421240448951721
Epoch 0, Step 753: train/loss = 0.5738915205001831, train/raw-loss = 0.538602352142334, train/logprobs = tensor([[-0.9599, -2.2504],
        [-1.8473, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528915047645569
Epoch 0, Step 754: train/loss = 0.5185484886169434, train/raw-loss = 0.4895865023136139, train/logprobs = tensor([[-0.5706, -2.3440],
        [-1.2204, -0.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896200120449066
Epoch 0, Step 755: train/loss = 0.3455662131309509, train/raw-loss = 0.3117624819278717, train/logprobs = tensor([[-1.0360, -6.5964],
        [-1.7096, -1.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380371332168579
Epoch 0, Step 756: train/loss = 0.40173155069351196, train/raw-loss = 0.37224081158638, train/logprobs = tensor([[-0.9592, -5.1521],
        [-1.2463, -0.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2949073612689972
Epoch 0, Step 757: train/loss = 0.3932081460952759, train/raw-loss = 0.35743004083633423, train/logprobs = tensor([[-0.8008, -3.4604],
        [-1.5756, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3577808737754822
Epoch 0, Step 758: train/loss = 0.3874366283416748, train/raw-loss = 0.3644677996635437, train/logprobs = tensor([[-0.5142, -5.2815],
        [-0.6002, -1.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296885997056961
Epoch 0, Step 759: train/loss = 0.3252238631248474, train/raw-loss = 0.28846269845962524, train/logprobs = tensor([[-0.7360, -6.8415],
        [-2.0464, -1.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36761170625686646
Epoch 0, Step 760: train/loss = 0.31352290511131287, train/raw-loss = 0.2782708406448364, train/logprobs = tensor([[-0.5220, -3.7640],
        [-1.6440, -1.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525208532810211
Epoch 0, Step 761: train/loss = 0.6090336441993713, train/raw-loss = 0.5744980573654175, train/logprobs = tensor([[-0.6864, -1.5164],
        [-1.2440, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34535616636276245
Epoch 0, Step 762: train/loss = 0.3174673914909363, train/raw-loss = 0.28974267840385437, train/logprobs = tensor([[-0.9536, -4.5413],
        [-1.5755, -0.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772471308708191
Epoch 0, Step 763: train/loss = 0.6444804072380066, train/raw-loss = 0.6142420768737793, train/logprobs = tensor([[-0.4799, -0.8110],
        [-0.9851, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30238351225852966
Epoch 0, Step 764: train/loss = 0.5215886235237122, train/raw-loss = 0.49851226806640625, train/logprobs = tensor([[-0.9513, -1.9459],
        [-1.1572, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076410591602325
Epoch 0, Step 765: train/loss = 0.5513995885848999, train/raw-loss = 0.5182478427886963, train/logprobs = tensor([[-0.8816, -1.6042],
        [-1.2316, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33151715993881226
Epoch 0, Step 766: train/loss = 0.3296898901462555, train/raw-loss = 0.2968467175960541, train/logprobs = tensor([[-0.6904, -4.0896],
        [-1.4715, -0.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3284318447113037
Epoch 0, Step 767: train/loss = 0.41922447085380554, train/raw-loss = 0.3920682668685913, train/logprobs = tensor([[-0.7935, -4.5818],
        [-1.2837, -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27156198024749756
Epoch 0, Step 768: train/loss = 0.5390974283218384, train/raw-loss = 0.502691388130188, train/logprobs = tensor([[-0.9744, -1.6306],
        [-1.3439, -0.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36406010389328003
Epoch 0, Step 769: train/loss = 0.21752281486988068, train/raw-loss = 0.18748655915260315, train/logprobs = tensor([[-0.5915, -8.0320],
        [-2.1375, -1.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003625273704529
Epoch 0, Step 770: train/loss = 0.5303429365158081, train/raw-loss = 0.4963005483150482, train/logprobs = tensor([[-0.6497, -2.2724],
        [-1.4442, -0.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404238820075989
Epoch 0, Step 771: train/loss = 0.32616114616394043, train/raw-loss = 0.2986028790473938, train/logprobs = tensor([[-0.6119, -3.1545],
        [-1.3855, -0.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27558255195617676
Epoch 0, Step 772: train/loss = 0.5431327223777771, train/raw-loss = 0.5059666633605957, train/logprobs = tensor([[-1.0338, -2.2721],
        [-1.8739, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3716607093811035
Epoch 0, Step 773: train/loss = 0.3282514810562134, train/raw-loss = 0.2933565378189087, train/logprobs = tensor([[-0.8767, -4.3564],
        [-1.7642, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.348949670791626
Epoch 0, Step 774: train/loss = 0.5688309073448181, train/raw-loss = 0.5384113788604736, train/logprobs = tensor([[-0.8030, -1.9574],
        [-0.9515, -1.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041953444480896
Epoch 0, Step 775: train/loss = 0.5993004441261292, train/raw-loss = 0.5556750893592834, train/logprobs = tensor([[-0.7183, -1.3494],
        [-1.5661, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4362539052963257
Epoch 0, Step 776: train/loss = 0.604631245136261, train/raw-loss = 0.5786104202270508, train/logprobs = tensor([[-0.4548, -1.2148],
        [-0.9667, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602083683013916
Epoch 0, Step 777: train/loss = 0.5087937712669373, train/raw-loss = 0.47862178087234497, train/logprobs = tensor([[-0.7370, -2.1598],
        [-1.0401, -0.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30171999335289
Epoch 0, Step 778: train/loss = 0.27389413118362427, train/raw-loss = 0.23941323161125183, train/logprobs = tensor([[-0.8015, -5.9379],
        [-2.0442, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34480926394462585
Epoch 0, Step 779: train/loss = 0.6899074912071228, train/raw-loss = 0.663764238357544, train/logprobs = tensor([[-0.4581, -0.4874],
        [-0.7967, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614324688911438
Epoch 0, Step 780: train/loss = 0.5836912393569946, train/raw-loss = 0.5538613796234131, train/logprobs = tensor([[-0.7962, -1.4457],
        [-0.9355, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982986271381378
Epoch 0, Step 781: train/loss = 0.4795517921447754, train/raw-loss = 0.4512503743171692, train/logprobs = tensor([[-0.8567, -5.7806],
        [-1.1095, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2830142378807068
Epoch 0, Step 782: train/loss = 0.4011807143688202, train/raw-loss = 0.36200642585754395, train/logprobs = tensor([[-1.1634, -8.3576],
        [-2.0663, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917425870895386
Epoch 0, Step 783: train/loss = 0.4395368993282318, train/raw-loss = 0.4045635759830475, train/logprobs = tensor([[-0.8090, -2.9458],
        [-1.6137, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34973299503326416
Epoch 0, Step 784: train/loss = 0.551446259021759, train/raw-loss = 0.5175193548202515, train/logprobs = tensor([[-1.1997, -1.5312],
        [-1.5374, -0.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33926934003829956
Epoch 0, Step 785: train/loss = 0.38364654779434204, train/raw-loss = 0.3493376672267914, train/logprobs = tensor([[-0.7294, -4.1151],
        [-1.2856, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34308910369873047
Epoch 0, Step 786: train/loss = 0.983559250831604, train/raw-loss = 0.9474542737007141, train/logprobs = tensor([[-3.0581, -6.7697],
        [-1.7866, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36104896664619446
Epoch 0, Step 787: train/loss = 0.6075270771980286, train/raw-loss = 0.5776863098144531, train/logprobs = tensor([[-1.7765, -4.5960],
        [-1.0049, -0.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29840701818466187
Epoch 0, Step 788: train/loss = 0.4241969585418701, train/raw-loss = 0.39189964532852173, train/logprobs = tensor([[-0.7586, -2.4377],
        [-1.3651, -0.8288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229731619358063
Epoch 0, Step 789: train/loss = 0.49307727813720703, train/raw-loss = 0.46071094274520874, train/logprobs = tensor([[-0.6226, -3.5182],
        [-1.1991, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32366323471069336
Epoch 0, Step 790: train/loss = 0.31056129932403564, train/raw-loss = 0.27730223536491394, train/logprobs = tensor([[-0.6308, -7.0492],
        [-1.5345, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33259066939353943
Epoch 0, Step 791: train/loss = 0.38704538345336914, train/raw-loss = 0.3569405674934387, train/logprobs = tensor([[-0.7119, -5.1111],
        [-1.2170, -1.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010481595993042
Epoch 0, Step 792: train/loss = 0.3353934586048126, train/raw-loss = 0.3085666298866272, train/logprobs = tensor([[-0.6221, -8.0416],
        [-1.1685, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26826825737953186
Epoch 0, Step 793: train/loss = 0.5838618278503418, train/raw-loss = 0.5508809089660645, train/logprobs = tensor([[-1.9508, -7.1338],
        [-1.5692, -1.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3298095166683197
Epoch 0, Step 794: train/loss = 0.2457261085510254, train/raw-loss = 0.2100394368171692, train/logprobs = tensor([[-0.5277, -9.1674],
        [-1.5344, -1.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568665385246277
Epoch 0, Step 795: train/loss = 0.41267475485801697, train/raw-loss = 0.3771094083786011, train/logprobs = tensor([[-0.9002, -3.8747],
        [-1.6878, -1.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556533753871918
Epoch 0, Step 796: train/loss = 0.1731497049331665, train/raw-loss = 0.13428345322608948, train/logprobs = tensor([[-0.9052, -5.0574],
        [-2.3000, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38866233825683594
Epoch 0, Step 797: train/loss = 0.6720797419548035, train/raw-loss = 0.6425945162773132, train/logprobs = tensor([[-0.7814, -1.1556],
        [-0.9568, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29485246539115906
Epoch 0, Step 798: train/loss = 0.3936944007873535, train/raw-loss = 0.3606320321559906, train/logprobs = tensor([[-0.6759, -4.3465],
        [-1.3877, -0.8274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306240141391754
Epoch 0, Step 799: train/loss = 0.33218687772750854, train/raw-loss = 0.2998840808868408, train/logprobs = tensor([[-0.7728, -3.1761],
        [-1.8220, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230280578136444
Epoch 0, Step 800: train/loss = 0.3221837878227234, train/raw-loss = 0.29165124893188477, train/logprobs = tensor([[-0.8700, -7.6448],
        [-1.4902, -1.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30532509088516235
Epoch 0, Step 801: train/loss = 0.42838945984840393, train/raw-loss = 0.39988529682159424, train/logprobs = tensor([[-0.5458, -3.2302],
        [-1.5433, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2850414514541626
Epoch 0, Step 802: train/loss = 0.4740210771560669, train/raw-loss = 0.4483335614204407, train/logprobs = tensor([[-0.7981, -2.9943],
        [-1.2670, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568753957748413
Epoch 0, Step 803: train/loss = 0.887067973613739, train/raw-loss = 0.8582092523574829, train/logprobs = tensor([[-2.2916, -2.9500],
        [-0.7020, -0.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2885875105857849
Epoch 0, Step 804: train/loss = 0.5307080745697021, train/raw-loss = 0.49911922216415405, train/logprobs = tensor([[-0.7051, -0.9300],
        [-1.4951, -0.6248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158881664276123
Epoch 0, Step 805: train/loss = 0.4590277373790741, train/raw-loss = 0.42627018690109253, train/logprobs = tensor([[-0.7554, -2.5599],
        [-1.4947, -1.0956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32757529616355896
Epoch 0, Step 806: train/loss = 0.4317666292190552, train/raw-loss = 0.4019666910171509, train/logprobs = tensor([[-0.5477, -2.1351],
        [-1.3912, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29799917340278625
Epoch 0, Step 807: train/loss = 0.550571084022522, train/raw-loss = 0.5242263078689575, train/logprobs = tensor([[-0.5452, -2.0695],
        [-0.8746, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.263448029756546
Epoch 0, Step 808: train/loss = 0.3775133788585663, train/raw-loss = 0.3443928062915802, train/logprobs = tensor([[-0.7016, -2.9793],
        [-1.7817, -1.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33120542764663696
Epoch 0, Step 809: train/loss = 0.6929482221603394, train/raw-loss = 0.6648252010345459, train/logprobs = tensor([[-0.9754, -1.3823],
        [-0.5092, -0.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28123152256011963
Epoch 0, Step 810: train/loss = 0.28556543588638306, train/raw-loss = 0.25171443819999695, train/logprobs = tensor([[-0.5474, -4.9379],
        [-1.6047, -1.3273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3385097086429596
Epoch 0, Step 811: train/loss = 0.6718514561653137, train/raw-loss = 0.6374903917312622, train/logprobs = tensor([[-0.7426, -0.8872],
        [-1.2922, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34361061453819275
Epoch 0, Step 812: train/loss = 0.46030092239379883, train/raw-loss = 0.430076003074646, train/logprobs = tensor([[-0.9667, -3.7976],
        [-1.1291, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022492527961731
Epoch 0, Step 813: train/loss = 0.26512274146080017, train/raw-loss = 0.23074744641780853, train/logprobs = tensor([[-1.0146, -7.8715],
        [-1.5570, -0.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34375303983688354
Epoch 0, Step 814: train/loss = 0.4724594056606293, train/raw-loss = 0.43901941180229187, train/logprobs = tensor([[-1.0077, -5.8466],
        [-1.8573, -1.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344002366065979
Epoch 0, Step 815: train/loss = 0.4653031826019287, train/raw-loss = 0.4340376853942871, train/logprobs = tensor([[-0.6574, -2.8918],
        [-1.3675, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126550614833832
Epoch 0, Step 816: train/loss = 0.5669825077056885, train/raw-loss = 0.5311118960380554, train/logprobs = tensor([[-1.6855, -9.0330],
        [-1.9296, -2.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587058186531067
Epoch 0, Step 817: train/loss = 0.49981701374053955, train/raw-loss = 0.4642772376537323, train/logprobs = tensor([[-0.6809, -3.1456],
        [-1.2878, -1.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35539770126342773
Epoch 0, Step 818: train/loss = 0.31088879704475403, train/raw-loss = 0.27641746401786804, train/logprobs = tensor([[-0.8512, -4.1964],
        [-1.8443, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447135388851166
Epoch 0, Step 819: train/loss = 0.35715755820274353, train/raw-loss = 0.32894662022590637, train/logprobs = tensor([[-0.7423, -4.8989],
        [-1.2581, -1.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2821092903614044
Epoch 0, Step 820: train/loss = 0.4387235641479492, train/raw-loss = 0.4071371853351593, train/logprobs = tensor([[-1.2788, -6.3913],
        [-1.4909, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31586354970932007
Epoch 0, Step 821: train/loss = 0.6645318865776062, train/raw-loss = 0.6351149082183838, train/logprobs = tensor([[-1.4845, -4.7965],
        [-1.0804, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2941696345806122
Epoch 0, Step 822: train/loss = 0.7488247156143188, train/raw-loss = 0.7171846032142639, train/logprobs = tensor([[-0.6269, -0.6789],
        [-0.9737, -0.9919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31640174984931946
Epoch 0, Step 823: train/loss = 0.35974743962287903, train/raw-loss = 0.3311285376548767, train/logprobs = tensor([[-0.3866, -3.1712],
        [-1.0383, -1.1594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2861890196800232
Epoch 0, Step 824: train/loss = 0.37962761521339417, train/raw-loss = 0.3450554609298706, train/logprobs = tensor([[-0.9141, -4.6016],
        [-1.5264, -0.5883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457212448120117
Epoch 0, Step 825: train/loss = 0.40195274353027344, train/raw-loss = 0.3657363951206207, train/logprobs = tensor([[-0.6648, -4.0558],
        [-1.3575, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3621637523174286
Epoch 0, Step 826: train/loss = 0.5758920907974243, train/raw-loss = 0.5478659868240356, train/logprobs = tensor([[-0.7086, -3.1788],
        [-1.1862, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802611291408539
Epoch 0, Step 827: train/loss = 0.47887086868286133, train/raw-loss = 0.44580522179603577, train/logprobs = tensor([[-0.6146, -2.9570],
        [-1.1129, -0.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306562900543213
Epoch 0, Step 828: train/loss = 0.6279820203781128, train/raw-loss = 0.6023597717285156, train/logprobs = tensor([[-1.0589, -2.4251],
        [-0.5241, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562222480773926
Epoch 0, Step 829: train/loss = 0.1670796126127243, train/raw-loss = 0.13261450827121735, train/logprobs = tensor([[ -0.8579, -11.0692],
        [ -2.0217,  -2.2915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34465110301971436
Epoch 0, Step 830: train/loss = 0.47542059421539307, train/raw-loss = 0.44064104557037354, train/logprobs = tensor([[-0.6809, -4.8031],
        [-1.4982, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477957844734192
Epoch 0, Step 831: train/loss = 0.30174773931503296, train/raw-loss = 0.27084100246429443, train/logprobs = tensor([[-1.0753, -4.0343],
        [-2.0761, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090671896934509
Epoch 0, Step 832: train/loss = 0.4957517087459564, train/raw-loss = 0.46673092246055603, train/logprobs = tensor([[-0.6215, -5.5190],
        [-1.0408, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29020801186561584
Epoch 0, Step 833: train/loss = 0.5438467264175415, train/raw-loss = 0.5103282928466797, train/logprobs = tensor([[-0.6624, -3.3999],
        [-1.3932, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351847231388092
Epoch 0, Step 834: train/loss = 0.6349034905433655, train/raw-loss = 0.6029608845710754, train/logprobs = tensor([[-2.0455, -7.2703],
        [-1.5620, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194260597229004
Epoch 0, Step 835: train/loss = 0.1989055871963501, train/raw-loss = 0.16346977651119232, train/logprobs = tensor([[-0.8362, -5.2854],
        [-1.9634, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35435813665390015
Epoch 0, Step 836: train/loss = 0.4006885290145874, train/raw-loss = 0.36956584453582764, train/logprobs = tensor([[-0.9726, -9.0116],
        [-1.7019, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3112269639968872
Epoch 0, Step 837: train/loss = 0.4680449962615967, train/raw-loss = 0.4389243423938751, train/logprobs = tensor([[-0.8347, -2.6886],
        [-1.5648, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2912062704563141
Epoch 0, Step 838: train/loss = 0.3205946385860443, train/raw-loss = 0.2881549298763275, train/logprobs = tensor([[-0.8058, -5.4455],
        [-1.5014, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3243969678878784
Epoch 0, Step 839: train/loss = 0.5093716382980347, train/raw-loss = 0.4828431010246277, train/logprobs = tensor([[-1.1808, -6.1998],
        [-1.3104, -0.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652856707572937
Epoch 0, Step 840: train/loss = 0.5087153911590576, train/raw-loss = 0.48165082931518555, train/logprobs = tensor([[-1.3086, -2.3355],
        [-1.5318, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27064523100852966
Epoch 0, Step 841: train/loss = 0.24547448754310608, train/raw-loss = 0.2099369466304779, train/logprobs = tensor([[-0.6682, -6.9524],
        [-1.8874, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553754687309265
Epoch 0, Step 842: train/loss = 0.44004571437835693, train/raw-loss = 0.4080469608306885, train/logprobs = tensor([[-1.1918, -9.6058],
        [-1.6970, -1.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31998738646507263
Epoch 0, Step 843: train/loss = 0.26580196619033813, train/raw-loss = 0.23580065369606018, train/logprobs = tensor([[-0.7569, -5.3229],
        [-1.6267, -0.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30001330375671387
Epoch 0, Step 844: train/loss = 0.4251684546470642, train/raw-loss = 0.3926658034324646, train/logprobs = tensor([[-0.5808, -3.0638],
        [-1.2541, -0.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32502639293670654
Epoch 0, Step 845: train/loss = 0.4292052090167999, train/raw-loss = 0.3942183554172516, train/logprobs = tensor([[-0.4305, -5.8616],
        [-1.3137, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3498683571815491
Epoch 0, Step 846: train/loss = 0.405436635017395, train/raw-loss = 0.3687264919281006, train/logprobs = tensor([[-1.9307, -4.0322],
        [-2.3421, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3671015501022339
Epoch 0, Step 847: train/loss = 0.4235229790210724, train/raw-loss = 0.3941909670829773, train/logprobs = tensor([[-0.7566, -6.1012],
        [-0.8851, -2.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29332029819488525
Epoch 0, Step 848: train/loss = 0.4732775092124939, train/raw-loss = 0.43103110790252686, train/logprobs = tensor([[-0.7292, -2.1995],
        [-2.2019, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4224642217159271
Epoch 0, Step 849: train/loss = 0.3617081642150879, train/raw-loss = 0.3333975672721863, train/logprobs = tensor([[-0.5471, -3.5400],
        [-1.1803, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831060290336609
Epoch 0, Step 850: train/loss = 0.3878011703491211, train/raw-loss = 0.35367465019226074, train/logprobs = tensor([[-0.6279, -2.3647],
        [-1.7572, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341265469789505
Epoch 0, Step 851: train/loss = 0.3792499005794525, train/raw-loss = 0.34640222787857056, train/logprobs = tensor([[-0.6153, -5.6727],
        [-1.1659, -0.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3284763693809509
Epoch 0, Step 852: train/loss = 0.38249272108078003, train/raw-loss = 0.339348167181015, train/logprobs = tensor([[-0.8267, -4.2740],
        [-2.2419, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43144556879997253
Epoch 0, Step 853: train/loss = 0.3206811249256134, train/raw-loss = 0.29076093435287476, train/logprobs = tensor([[-0.7209, -9.5675],
        [-1.7375, -1.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992020845413208
Epoch 0, Step 854: train/loss = 0.38372161984443665, train/raw-loss = 0.3514319360256195, train/logprobs = tensor([[-0.7051, -4.7510],
        [-1.3543, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32289689779281616
Epoch 0, Step 855: train/loss = 0.41558265686035156, train/raw-loss = 0.3816775977611542, train/logprobs = tensor([[-0.9795, -4.8995],
        [-1.3283, -1.3396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33905044198036194
Epoch 0, Step 856: train/loss = 0.28862103819847107, train/raw-loss = 0.2517666220664978, train/logprobs = tensor([[ -1.0714, -10.2232],
        [ -2.3413,  -2.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36854422092437744
Epoch 0, Step 857: train/loss = 0.48851272463798523, train/raw-loss = 0.4572027921676636, train/logprobs = tensor([[-0.8313, -3.0440],
        [-1.1857, -0.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130996525287628
Epoch 0, Step 858: train/loss = 0.24921977519989014, train/raw-loss = 0.21381908655166626, train/logprobs = tensor([[-1.0285, -9.3193],
        [-1.8900, -2.0443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35400691628456116
Epoch 0, Step 859: train/loss = 0.2710600793361664, train/raw-loss = 0.23839658498764038, train/logprobs = tensor([[-0.5749, -9.7786],
        [-1.6147, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32663488388061523
Epoch 0, Step 860: train/loss = 0.5986924767494202, train/raw-loss = 0.5631346106529236, train/logprobs = tensor([[-0.7126, -1.1767],
        [-1.3519, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35557883977890015
Epoch 0, Step 861: train/loss = 0.3985682725906372, train/raw-loss = 0.3658718764781952, train/logprobs = tensor([[-1.2318, -3.2964],
        [-1.7980, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32696396112442017
Epoch 0, Step 862: train/loss = 0.34565049409866333, train/raw-loss = 0.31014949083328247, train/logprobs = tensor([[-1.0597, -9.4688],
        [-1.9179, -1.7312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35500985383987427
Epoch 0, Step 863: train/loss = 0.32940319180488586, train/raw-loss = 0.293178915977478, train/logprobs = tensor([[-0.8784, -7.1714],
        [-2.1743, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36224302649497986
Epoch 0, Step 864: train/loss = 0.42815226316452026, train/raw-loss = 0.3907927870750427, train/logprobs = tensor([[-0.9092, -5.1829],
        [-1.4941, -1.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735945522785187
Epoch 0, Step 865: train/loss = 0.30461907386779785, train/raw-loss = 0.27099862694740295, train/logprobs = tensor([[-0.6328, -5.6824],
        [-1.3920, -0.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33620429039001465
Epoch 0, Step 866: train/loss = 0.17481805384159088, train/raw-loss = 0.12986038625240326, train/logprobs = tensor([[-1.4261, -7.9270],
        [-2.6735, -0.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4495767652988434
Epoch 0, Step 867: train/loss = 0.42688941955566406, train/raw-loss = 0.3970913589000702, train/logprobs = tensor([[-0.5884, -4.8052],
        [-1.1853, -1.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979808449745178
Epoch 0, Step 868: train/loss = 0.4582946300506592, train/raw-loss = 0.42674005031585693, train/logprobs = tensor([[-1.1310, -3.7164],
        [-1.2297, -0.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3155454397201538
Epoch 0, Step 869: train/loss = 0.26144564151763916, train/raw-loss = 0.2191927433013916, train/logprobs = tensor([[-1.1307, -7.7635],
        [-2.1882, -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42252886295318604
Epoch 0, Step 870: train/loss = 0.1978623867034912, train/raw-loss = 0.15943236649036407, train/logprobs = tensor([[-1.0130, -9.2274],
        [-2.3949, -2.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38430023193359375
Epoch 0, Step 871: train/loss = 0.44639748334884644, train/raw-loss = 0.4172963798046112, train/logprobs = tensor([[-0.7062, -3.1786],
        [-0.9540, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2910108268260956
Epoch 0, Step 872: train/loss = 0.4760838449001312, train/raw-loss = 0.44442102313041687, train/logprobs = tensor([[-0.8636, -3.7838],
        [-0.9482, -1.3922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31662851572036743
Epoch 0, Step 873: train/loss = 0.6358509063720703, train/raw-loss = 0.5932732224464417, train/logprobs = tensor([[-2.1434, -5.4907],
        [-1.8948, -1.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42577677965164185
Epoch 0, Step 874: train/loss = 0.1747879981994629, train/raw-loss = 0.1366180032491684, train/logprobs = tensor([[-0.9357, -5.5154],
        [-2.4138, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3816998302936554
Epoch 0, Step 875: train/loss = 0.44031980633735657, train/raw-loss = 0.403278648853302, train/logprobs = tensor([[-1.0560, -3.2797],
        [-1.2626, -0.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3704114854335785
Epoch 0, Step 876: train/loss = 0.42890483140945435, train/raw-loss = 0.38721275329589844, train/logprobs = tensor([[-1.9656, -4.5822],
        [-2.6246, -1.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41692084074020386
Epoch 0, Step 877: train/loss = 0.2740858495235443, train/raw-loss = 0.24230413138866425, train/logprobs = tensor([[-0.7136, -7.4915],
        [-1.6874, -0.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31781715154647827
Epoch 0, Step 878: train/loss = 0.32052963972091675, train/raw-loss = 0.27736517786979675, train/logprobs = tensor([[-1.0999, -6.1462],
        [-1.7921, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4316445589065552
Epoch 0, Step 879: train/loss = 0.3356553316116333, train/raw-loss = 0.29922956228256226, train/logprobs = tensor([[-1.3194, -2.7735],
        [-2.7157, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3642578721046448
Epoch 0, Step 880: train/loss = 0.5489919185638428, train/raw-loss = 0.5124669075012207, train/logprobs = tensor([[-1.1142, -2.1395],
        [-1.2316, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36525049805641174
Epoch 0, Step 881: train/loss = 0.3557285666465759, train/raw-loss = 0.32446950674057007, train/logprobs = tensor([[-0.8526, -5.2040],
        [-1.3916, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125908076763153
Epoch 0, Step 882: train/loss = 0.32154449820518494, train/raw-loss = 0.2909017503261566, train/logprobs = tensor([[-0.5683, -5.2018],
        [-1.3847, -0.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064275085926056
Epoch 0, Step 883: train/loss = 0.3612797260284424, train/raw-loss = 0.3230612576007843, train/logprobs = tensor([[-1.2057, -6.2906],
        [-1.7848, -1.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3821844756603241
Epoch 0, Step 884: train/loss = 0.28764063119888306, train/raw-loss = 0.24953633546829224, train/logprobs = tensor([[-0.7997, -5.6500],
        [-2.1411, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38104283809661865
Epoch 0, Step 885: train/loss = 0.4054459035396576, train/raw-loss = 0.37120479345321655, train/logprobs = tensor([[-0.7228, -3.6497],
        [-1.7746, -0.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34241098165512085
Epoch 0, Step 886: train/loss = 0.4534383714199066, train/raw-loss = 0.4245585799217224, train/logprobs = tensor([[-0.7692, -2.8963],
        [-1.0226, -0.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887977957725525
Epoch 0, Step 887: train/loss = 0.21535345911979675, train/raw-loss = 0.181623175740242, train/logprobs = tensor([[-1.1101, -8.3525],
        [-2.2314, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373029828071594
Epoch 0, Step 888: train/loss = 0.4513615369796753, train/raw-loss = 0.41502660512924194, train/logprobs = tensor([[-0.7789, -2.0936],
        [-1.6163, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3633497953414917
Epoch 0, Step 889: train/loss = 0.2030072957277298, train/raw-loss = 0.17169266939163208, train/logprobs = tensor([[-0.6725, -8.6397],
        [-1.6028, -0.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3131462335586548
Epoch 0, Step 890: train/loss = 0.3902089595794678, train/raw-loss = 0.35684382915496826, train/logprobs = tensor([[-1.4380, -8.9212],
        [-2.1173, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3336511254310608
Epoch 0, Step 891: train/loss = 0.4263620674610138, train/raw-loss = 0.3913402259349823, train/logprobs = tensor([[-1.1123, -4.0737],
        [-1.5430, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502184748649597
Epoch 0, Step 892: train/loss = 0.15722939372062683, train/raw-loss = 0.1241716742515564, train/logprobs = tensor([[-0.6249, -5.4417],
        [-2.1363, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33057722449302673
Epoch 0, Step 893: train/loss = 0.475211501121521, train/raw-loss = 0.4468521177768707, train/logprobs = tensor([[-0.5760, -4.8607],
        [-0.8392, -1.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2835937738418579
Epoch 0, Step 894: train/loss = 0.48604869842529297, train/raw-loss = 0.45655250549316406, train/logprobs = tensor([[-1.1198, -4.8229],
        [-1.4095, -0.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29496192932128906
Epoch 0, Step 895: train/loss = 0.6018638610839844, train/raw-loss = 0.5721652507781982, train/logprobs = tensor([[-0.9518, -5.7011],
        [-0.9949, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29698628187179565
Epoch 0, Step 896: train/loss = 0.6259331107139587, train/raw-loss = 0.5888711810112, train/logprobs = tensor([[-0.6864, -1.5166],
        [-1.0118, -1.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37061941623687744
Epoch 0, Step 897: train/loss = 0.2996077835559845, train/raw-loss = 0.27073878049850464, train/logprobs = tensor([[-0.6604, -4.6917],
        [-1.1126, -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886897623538971
Epoch 0, Step 898: train/loss = 0.5451316833496094, train/raw-loss = 0.5192691087722778, train/logprobs = tensor([[-0.7553, -2.3158],
        [-0.6509, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25862622261047363
Epoch 0, Step 899: train/loss = 0.2980886995792389, train/raw-loss = 0.2600472569465637, train/logprobs = tensor([[ -0.8514, -10.2672],
        [ -2.1783,  -1.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38041436672210693
Epoch 0, Step 900: train/loss = 0.3815329968929291, train/raw-loss = 0.3468027710914612, train/logprobs = tensor([[-0.9350, -4.6895],
        [-1.5777, -1.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473023772239685
Epoch 0, Step 901: train/loss = 0.4981122314929962, train/raw-loss = 0.46017640829086304, train/logprobs = tensor([[-0.9490, -1.7636],
        [-1.7506, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37935835123062134
Epoch 0, Step 902: train/loss = 0.3781823217868805, train/raw-loss = 0.34362098574638367, train/logprobs = tensor([[-0.9595, -7.2876],
        [-1.4741, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34561336040496826
Epoch 0, Step 903: train/loss = 0.3830651342868805, train/raw-loss = 0.3485736548900604, train/logprobs = tensor([[-0.5691, -5.2718],
        [-1.5347, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34491458535194397
Epoch 0, Step 904: train/loss = 0.569306492805481, train/raw-loss = 0.542742133140564, train/logprobs = tensor([[-0.6565, -3.9413],
        [-0.6965, -0.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2656432092189789
Epoch 0, Step 905: train/loss = 0.438965380191803, train/raw-loss = 0.40514200925827026, train/logprobs = tensor([[-1.3055, -3.2011],
        [-1.4487, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33823350071907043
Epoch 0, Step 906: train/loss = 0.2397891730070114, train/raw-loss = 0.20260965824127197, train/logprobs = tensor([[ -1.4018, -10.0886],
        [ -2.9852,  -1.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37179532647132874
Epoch 0, Step 907: train/loss = 0.7208606600761414, train/raw-loss = 0.6954227685928345, train/logprobs = tensor([[-0.6913, -0.8615],
        [-0.7730, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543793022632599
Epoch 0, Step 908: train/loss = 0.4704318940639496, train/raw-loss = 0.4265143871307373, train/logprobs = tensor([[-0.7407, -3.8317],
        [-2.2690, -1.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4391750693321228
Epoch 0, Step 909: train/loss = 0.569992184638977, train/raw-loss = 0.536169707775116, train/logprobs = tensor([[-0.9163, -2.5310],
        [-1.1502, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382248282432556
Epoch 0, Step 910: train/loss = 0.4424320459365845, train/raw-loss = 0.41740936040878296, train/logprobs = tensor([[-0.6943, -2.3752],
        [-1.5393, -0.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502264380455017
Epoch 0, Step 911: train/loss = 0.2715452015399933, train/raw-loss = 0.23313641548156738, train/logprobs = tensor([[-0.8515, -3.6594],
        [-2.2710, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840878903865814
Epoch 0, Step 912: train/loss = 0.3996589183807373, train/raw-loss = 0.36346498131752014, train/logprobs = tensor([[-1.1221, -6.3188],
        [-1.8645, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36193907260894775
Epoch 0, Step 913: train/loss = 0.5444005727767944, train/raw-loss = 0.5059946775436401, train/logprobs = tensor([[-1.2979, -2.8328],
        [-1.5296, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38405901193618774
Epoch 0, Step 914: train/loss = 0.4348698854446411, train/raw-loss = 0.40056172013282776, train/logprobs = tensor([[-0.9632, -2.0971],
        [-1.4972, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.343081533908844
Epoch 0, Step 915: train/loss = 0.4524095356464386, train/raw-loss = 0.4035395383834839, train/logprobs = tensor([[-0.8480, -4.9766],
        [-2.6761, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48870009183883667
Epoch 0, Step 916: train/loss = 0.5144187211990356, train/raw-loss = 0.47968539595603943, train/logprobs = tensor([[-0.6336, -4.9073],
        [-1.7224, -1.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34733352065086365
Epoch 0, Step 917: train/loss = 0.4647214412689209, train/raw-loss = 0.4325825572013855, train/logprobs = tensor([[-1.1186, -4.4369],
        [-1.7285, -0.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32138925790786743
Epoch 0, Step 918: train/loss = 0.5060093402862549, train/raw-loss = 0.4742250442504883, train/logprobs = tensor([[-0.6631, -3.8674],
        [-0.9902, -1.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317842572927475
Epoch 0, Step 919: train/loss = 0.5353798270225525, train/raw-loss = 0.49618446826934814, train/logprobs = tensor([[-1.4862, -6.4219],
        [-1.6826, -1.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919537663459778
Epoch 0, Step 920: train/loss = 0.4059869050979614, train/raw-loss = 0.37821486592292786, train/logprobs = tensor([[-0.5421, -3.1944],
        [-0.9688, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27772054076194763
Epoch 0, Step 921: train/loss = 0.432495653629303, train/raw-loss = 0.3986322581768036, train/logprobs = tensor([[-0.5717, -4.6270],
        [-1.1645, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3386339545249939
Epoch 0, Step 922: train/loss = 0.6984351277351379, train/raw-loss = 0.6742030382156372, train/logprobs = tensor([[-0.3920, -3.3510],
        [-0.4870, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24232111871242523
Epoch 0, Step 923: train/loss = 0.5758647918701172, train/raw-loss = 0.5413964986801147, train/logprobs = tensor([[-0.9011, -1.8795],
        [-1.1953, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3446829319000244
Epoch 0, Step 924: train/loss = 0.4854012131690979, train/raw-loss = 0.4490280747413635, train/logprobs = tensor([[-1.4994, -3.0890],
        [-1.5665, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637310862541199
Epoch 0, Step 925: train/loss = 0.6583539247512817, train/raw-loss = 0.6232720613479614, train/logprobs = tensor([[-0.8327, -1.6099],
        [-1.1102, -1.3492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3508186936378479
Epoch 0, Step 926: train/loss = 0.5085955858230591, train/raw-loss = 0.46978285908699036, train/logprobs = tensor([[-0.8789, -2.9517],
        [-1.5073, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3881267309188843
Epoch 0, Step 927: train/loss = 0.4460855722427368, train/raw-loss = 0.4086996912956238, train/logprobs = tensor([[-1.2444, -2.8983],
        [-1.6155, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3738594055175781
Epoch 0, Step 928: train/loss = 0.43961042165756226, train/raw-loss = 0.4110870957374573, train/logprobs = tensor([[-0.6986, -3.0185],
        [-1.2101, -0.3523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28523313999176025
Epoch 0, Step 929: train/loss = 0.21157458424568176, train/raw-loss = 0.16638998687267303, train/logprobs = tensor([[-0.5409, -5.2280],
        [-1.9685, -1.3741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4518459141254425
Epoch 0, Step 930: train/loss = 0.33728551864624023, train/raw-loss = 0.3010268211364746, train/logprobs = tensor([[-1.0342, -4.5367],
        [-2.3802, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36258700489997864
Epoch 0, Step 931: train/loss = 0.22883594036102295, train/raw-loss = 0.18798017501831055, train/logprobs = tensor([[-1.2631, -6.6519],
        [-2.3358, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4085575342178345
Epoch 0, Step 932: train/loss = 0.16660991311073303, train/raw-loss = 0.13237181305885315, train/logprobs = tensor([[-0.8467, -8.1458],
        [-2.4153, -1.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34238094091415405
Epoch 0, Step 933: train/loss = 0.38258856534957886, train/raw-loss = 0.3502010703086853, train/logprobs = tensor([[-0.6305, -4.4168],
        [-1.2151, -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32387518882751465
Epoch 0, Step 934: train/loss = 0.31246477365493774, train/raw-loss = 0.27880042791366577, train/logprobs = tensor([[-0.6017, -5.7884],
        [-1.4283, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3366434574127197
Epoch 0, Step 935: train/loss = 0.49903231859207153, train/raw-loss = 0.46461182832717896, train/logprobs = tensor([[-1.8942, -5.2401],
        [-2.3780, -1.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344204843044281
Epoch 0, Step 936: train/loss = 0.5215028524398804, train/raw-loss = 0.48410260677337646, train/logprobs = tensor([[-0.7198, -1.6624],
        [-1.1311, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3740028142929077
Epoch 0, Step 937: train/loss = 0.19667723774909973, train/raw-loss = 0.15614791214466095, train/logprobs = tensor([[-1.1009, -7.9058],
        [-2.3010, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40529316663742065
Epoch 0, Step 938: train/loss = 0.3379301428794861, train/raw-loss = 0.29831641912460327, train/logprobs = tensor([[-0.8580, -5.1813],
        [-1.6622, -1.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3961372375488281
Epoch 0, Step 939: train/loss = 0.5990393161773682, train/raw-loss = 0.5598119497299194, train/logprobs = tensor([[-1.5527, -4.3986],
        [-1.2202, -1.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922732174396515
Epoch 0, Step 940: train/loss = 0.5056562423706055, train/raw-loss = 0.47543853521347046, train/logprobs = tensor([[-0.9746, -2.6755],
        [-0.9560, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021768033504486
Epoch 0, Step 941: train/loss = 0.28757745027542114, train/raw-loss = 0.24327966570854187, train/logprobs = tensor([[-0.6914, -7.0328],
        [-2.1560, -1.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429776966571808
Epoch 0, Step 942: train/loss = 0.47527140378952026, train/raw-loss = 0.44319045543670654, train/logprobs = tensor([[-1.1953, -6.8407],
        [-2.0608, -1.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32080966234207153
Epoch 0, Step 943: train/loss = 0.4540421962738037, train/raw-loss = 0.4090295433998108, train/logprobs = tensor([[-0.7647, -3.6085],
        [-2.7015, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4501263499259949
Epoch 0, Step 944: train/loss = 0.3132161498069763, train/raw-loss = 0.2815607786178589, train/logprobs = tensor([[-0.7513, -7.3268],
        [-1.9152, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31655362248420715
Epoch 0, Step 945: train/loss = 0.22964707016944885, train/raw-loss = 0.18569985032081604, train/logprobs = tensor([[-1.0197, -7.3462],
        [-2.7563, -1.4382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43947213888168335
Epoch 0, Step 946: train/loss = 0.40941518545150757, train/raw-loss = 0.37206196784973145, train/logprobs = tensor([[-1.0065, -6.3154],
        [-1.6827, -1.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735317885875702
Epoch 0, Step 947: train/loss = 0.3171912431716919, train/raw-loss = 0.2799975872039795, train/logprobs = tensor([[-0.7627, -5.2667],
        [-1.7002, -1.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719366788864136
Epoch 0, Step 948: train/loss = 0.31350043416023254, train/raw-loss = 0.27487415075302124, train/logprobs = tensor([[-0.7565, -5.2485],
        [-2.0740, -1.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3862629532814026
Epoch 0, Step 949: train/loss = 0.42847809195518494, train/raw-loss = 0.4019218385219574, train/logprobs = tensor([[-1.2279, -4.8897],
        [-1.5317, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655627727508545
Epoch 0, Step 950: train/loss = 0.21117812395095825, train/raw-loss = 0.1663537621498108, train/logprobs = tensor([[-0.6314, -5.3927],
        [-2.3885, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44824352860450745
Epoch 0, Step 951: train/loss = 0.3543189764022827, train/raw-loss = 0.31817683577537537, train/logprobs = tensor([[-1.5283, -6.2213],
        [-1.6534, -1.8149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3614214360713959
Epoch 0, Step 952: train/loss = 0.44006258249282837, train/raw-loss = 0.3958252966403961, train/logprobs = tensor([[-0.7487, -4.2299],
        [-2.2022, -1.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44237256050109863
Epoch 0, Step 953: train/loss = 0.9140989780426025, train/raw-loss = 0.8821439743041992, train/logprobs = tensor([[-1.8240, -2.8505],
        [-0.9789, -1.1780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319550096988678
Epoch 0, Step 954: train/loss = 0.4307629466056824, train/raw-loss = 0.39054083824157715, train/logprobs = tensor([[-1.5304, -4.5559],
        [-2.1515, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4022206664085388
Epoch 0, Step 955: train/loss = 0.3097628653049469, train/raw-loss = 0.2598533630371094, train/logprobs = tensor([[-1.1335, -6.8978],
        [-2.6084, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49909523129463196
Epoch 0, Step 956: train/loss = 0.4384554326534271, train/raw-loss = 0.4001818001270294, train/logprobs = tensor([[-1.0900, -2.6443],
        [-1.9983, -0.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3827362060546875
Epoch 0, Step 957: train/loss = 0.509025514125824, train/raw-loss = 0.47351470589637756, train/logprobs = tensor([[-1.2595, -6.2585],
        [-1.2995, -1.2498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35510799288749695
Epoch 0, Step 958: train/loss = 0.36293673515319824, train/raw-loss = 0.3304187059402466, train/logprobs = tensor([[-0.8020, -5.2377],
        [-2.2264, -0.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251802325248718
Epoch 0, Step 959: train/loss = 0.451839417219162, train/raw-loss = 0.4164711833000183, train/logprobs = tensor([[-0.7995, -5.2615],
        [-1.4062, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536824882030487
Epoch 0, Step 960: train/loss = 0.2652656137943268, train/raw-loss = 0.22563445568084717, train/logprobs = tensor([[-1.6046, -8.8649],
        [-2.3596, -2.1371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39631155133247375
Epoch 0, Step 961: train/loss = 0.38001275062561035, train/raw-loss = 0.34464430809020996, train/logprobs = tensor([[-0.9321, -3.1555],
        [-1.8749, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536844253540039
Epoch 0, Step 962: train/loss = 0.182744562625885, train/raw-loss = 0.14008529484272003, train/logprobs = tensor([[-0.9721, -8.3746],
        [-2.8727, -1.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42659252882003784
Epoch 0, Step 963: train/loss = 0.4595726728439331, train/raw-loss = 0.42872804403305054, train/logprobs = tensor([[-1.1562, -4.5374],
        [-1.1915, -0.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084460496902466
Epoch 0, Step 964: train/loss = 0.20851574838161469, train/raw-loss = 0.16225777566432953, train/logprobs = tensor([[-0.7944, -5.2268],
        [-2.3991, -1.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46257972717285156
Epoch 0, Step 965: train/loss = 0.48980793356895447, train/raw-loss = 0.46215200424194336, train/logprobs = tensor([[-1.2435, -3.7606],
        [-1.4553, -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765595018863678
Epoch 0, Step 966: train/loss = 0.42077338695526123, train/raw-loss = 0.3851125240325928, train/logprobs = tensor([[-1.0356, -5.1898],
        [-1.1912, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35660845041275024
Epoch 0, Step 967: train/loss = 0.42821013927459717, train/raw-loss = 0.39412856101989746, train/logprobs = tensor([[-1.6957, -9.5814],
        [-1.5008, -2.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3408159613609314
Epoch 0, Step 968: train/loss = 0.48121213912963867, train/raw-loss = 0.43699488043785095, train/logprobs = tensor([[-1.0223, -3.0988],
        [-1.9847, -1.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44217249751091003
Epoch 0, Step 969: train/loss = 0.29918092489242554, train/raw-loss = 0.2573269307613373, train/logprobs = tensor([[-0.4806, -4.9310],
        [-1.8490, -1.1429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4185400903224945
Epoch 0, Step 970: train/loss = 0.41721445322036743, train/raw-loss = 0.3717314600944519, train/logprobs = tensor([[-0.9670, -2.8051],
        [-2.0982, -1.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45483022928237915
Epoch 0, Step 971: train/loss = 0.30358269810676575, train/raw-loss = 0.27080515027046204, train/logprobs = tensor([[-0.4819, -7.2953],
        [-1.1943, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3277750611305237
Epoch 0, Step 972: train/loss = 0.722244143486023, train/raw-loss = 0.6935521364212036, train/logprobs = tensor([[-1.3149, -1.4413],
        [-0.7257, -0.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869199514389038
Epoch 0, Step 973: train/loss = 0.5533758401870728, train/raw-loss = 0.5163618326187134, train/logprobs = tensor([[-1.8460, -4.3466],
        [-1.3280, -1.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701399564743042
Epoch 0, Step 974: train/loss = 0.5417513251304626, train/raw-loss = 0.5047338008880615, train/logprobs = tensor([[-1.0245, -1.7048],
        [-1.8279, -1.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701753318309784
Epoch 0, Step 975: train/loss = 0.4077683985233307, train/raw-loss = 0.3721497058868408, train/logprobs = tensor([[-0.7696, -5.8433],
        [-1.6934, -1.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35618701577186584
Epoch 0, Step 976: train/loss = 0.3004510998725891, train/raw-loss = 0.26237913966178894, train/logprobs = tensor([[-0.8536, -5.0984],
        [-2.0961, -0.8999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807196021080017
Epoch 0, Step 977: train/loss = 0.3702244162559509, train/raw-loss = 0.3372616171836853, train/logprobs = tensor([[-1.1694, -3.6090],
        [-2.0875, -0.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32962778210639954
Epoch 0, Step 978: train/loss = 0.24573099613189697, train/raw-loss = 0.2085372507572174, train/logprobs = tensor([[-0.7101, -5.8899],
        [-1.9382, -1.0515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719373345375061
Epoch 0, Step 979: train/loss = 0.34247034788131714, train/raw-loss = 0.3182844817638397, train/logprobs = tensor([[-0.3685, -8.9858],
        [-0.7504, -1.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24185888469219208
Epoch 0, Step 980: train/loss = 0.36826804280281067, train/raw-loss = 0.32828161120414734, train/logprobs = tensor([[-2.4625, -9.4967],
        [-2.6400, -1.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998644948005676
Epoch 0, Step 981: train/loss = 0.13062994182109833, train/raw-loss = 0.08111371845006943, train/logprobs = tensor([[ -1.0730, -14.1387],
        [ -2.9780,  -0.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49516215920448303
Epoch 0, Step 982: train/loss = 0.4236023426055908, train/raw-loss = 0.3852898180484772, train/logprobs = tensor([[ -2.0891, -10.0831],
        [ -2.0659,  -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38312506675720215
Epoch 0, Step 983: train/loss = 0.49849164485931396, train/raw-loss = 0.4641772508621216, train/logprobs = tensor([[-1.1466, -2.8829],
        [-1.3183, -1.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431440591812134
Epoch 0, Step 984: train/loss = 0.5863843560218811, train/raw-loss = 0.548446536064148, train/logprobs = tensor([[-2.0719, -3.7419],
        [-2.1295, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37937790155410767
Epoch 0, Step 985: train/loss = 0.6046926379203796, train/raw-loss = 0.5688914060592651, train/logprobs = tensor([[-2.0207, -9.3484],
        [-1.4866, -1.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580123484134674
Epoch 0, Step 986: train/loss = 0.6560525298118591, train/raw-loss = 0.6240867972373962, train/logprobs = tensor([[-1.2321, -2.2004],
        [-0.9738, -1.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31965696811676025
Epoch 0, Step 987: train/loss = 0.3152077794075012, train/raw-loss = 0.27418380975723267, train/logprobs = tensor([[-1.3434, -4.7466],
        [-2.5864, -1.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41023963689804077
Epoch 0, Step 988: train/loss = 0.5228663682937622, train/raw-loss = 0.4808519184589386, train/logprobs = tensor([[-0.9907, -3.1122],
        [-1.8724, -2.3086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42014387249946594
Epoch 0, Step 989: train/loss = 0.15496206283569336, train/raw-loss = 0.11646272242069244, train/logprobs = tensor([[-0.9635, -6.4985],
        [-2.7962, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3849933445453644
Epoch 0, Step 990: train/loss = 0.43219250440597534, train/raw-loss = 0.39232003688812256, train/logprobs = tensor([[-0.8348, -3.1840],
        [-1.7788, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.398724228143692
Epoch 0, Step 991: train/loss = 0.3741893768310547, train/raw-loss = 0.3387552499771118, train/logprobs = tensor([[-1.1527, -3.1901],
        [-1.9735, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3543408215045929
Epoch 0, Step 992: train/loss = 0.2883714437484741, train/raw-loss = 0.249376118183136, train/logprobs = tensor([[-0.7921, -2.8932],
        [-2.3529, -0.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38995352387428284
Epoch 0, Step 993: train/loss = 0.3100557029247284, train/raw-loss = 0.27325743436813354, train/logprobs = tensor([[-0.8887, -6.9137],
        [-1.8637, -1.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36798256635665894
Epoch 0, Step 994: train/loss = 0.4656791388988495, train/raw-loss = 0.4306607246398926, train/logprobs = tensor([[-0.8222, -4.6477],
        [-1.4152, -0.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35018423199653625
Epoch 0, Step 995: train/loss = 0.25475138425827026, train/raw-loss = 0.21872985363006592, train/logprobs = tensor([[-0.6793, -9.1326],
        [-2.3392, -1.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602154850959778
Epoch 0, Step 996: train/loss = 0.2924901843070984, train/raw-loss = 0.25757360458374023, train/logprobs = tensor([[-1.4710, -7.0759],
        [-2.4881, -1.2785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34916555881500244
Epoch 0, Step 997: train/loss = 0.1968582570552826, train/raw-loss = 0.15208208560943604, train/logprobs = tensor([[ -0.7500, -12.9043],
        [ -2.6700,  -1.7282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44776177406311035
Epoch 0, Step 998: train/loss = 0.36395299434661865, train/raw-loss = 0.33090245723724365, train/logprobs = tensor([[-0.9460, -6.3548],
        [-2.0277, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33050537109375
Epoch 0, Step 999: train/loss = 0.24486857652664185, train/raw-loss = 0.1992882788181305, train/logprobs = tensor([[-0.8748, -6.2598],
        [-2.1683, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4558030962944031
Epoch 0, Step 1000: train/loss = 0.4561268389225006, train/raw-loss = 0.42344629764556885, train/logprobs = tensor([[-1.0578, -5.7556],
        [-1.3915, -1.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32680583000183105
Epoch 0, Step 1001: train/loss = 0.3830454349517822, train/raw-loss = 0.3419889509677887, train/logprobs = tensor([[-0.7635, -3.9444],
        [-1.8851, -1.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105646312236786
Epoch 0, Step 1002: train/loss = 0.403272807598114, train/raw-loss = 0.36939793825149536, train/logprobs = tensor([[-0.7429, -7.1093],
        [-1.1443, -1.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33874866366386414
Epoch 0, Step 1003: train/loss = 0.5518662929534912, train/raw-loss = 0.5242906808853149, train/logprobs = tensor([[-0.8744, -2.4861],
        [-0.8108, -1.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757555842399597
Epoch 0, Step 1004: train/loss = 0.5204023122787476, train/raw-loss = 0.4860706925392151, train/logprobs = tensor([[-1.1134, -6.6857],
        [-1.1877, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34331631660461426
Epoch 0, Step 1005: train/loss = 0.3071262538433075, train/raw-loss = 0.27517464756965637, train/logprobs = tensor([[ -0.9304, -10.3905],
        [ -1.8184,  -1.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319516122341156
Epoch 0, Step 1006: train/loss = 0.4246167540550232, train/raw-loss = 0.3822292983531952, train/logprobs = tensor([[-1.4934, -4.2013],
        [-2.2054, -1.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4238741993904114
Epoch 0, Step 1007: train/loss = 0.12390235811471939, train/raw-loss = 0.08237966150045395, train/logprobs = tensor([[-0.7554, -8.8218],
        [-2.7028, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4152269959449768
Epoch 0, Step 1008: train/loss = 0.26417529582977295, train/raw-loss = 0.2240849882364273, train/logprobs = tensor([[-1.1037, -9.0683],
        [-1.9490, -1.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40090298652648926
Epoch 0, Step 1009: train/loss = 0.5439322590827942, train/raw-loss = 0.5052141547203064, train/logprobs = tensor([[-1.2940, -2.6884],
        [-1.6630, -2.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38718080520629883
Epoch 0, Step 1010: train/loss = 0.428166925907135, train/raw-loss = 0.3973243236541748, train/logprobs = tensor([[-1.6781, -5.5368],
        [-1.8822, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084264397621155
Epoch 0, Step 1011: train/loss = 0.6014565229415894, train/raw-loss = 0.5705390572547913, train/logprobs = tensor([[-2.0038, -3.6609],
        [-1.2734, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30917423963546753
Epoch 0, Step 1012: train/loss = 0.4539148807525635, train/raw-loss = 0.42747175693511963, train/logprobs = tensor([[-0.5795, -2.5932],
        [-0.9620, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644316554069519
Epoch 0, Step 1013: train/loss = 0.4186744689941406, train/raw-loss = 0.3791148066520691, train/logprobs = tensor([[-1.5417, -4.4518],
        [-2.1775, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3955969512462616
Epoch 0, Step 1014: train/loss = 0.24904972314834595, train/raw-loss = 0.20609596371650696, train/logprobs = tensor([[-1.0082, -7.9075],
        [-2.2134, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4295376241207123
Epoch 0, Step 1015: train/loss = 0.46575674414634705, train/raw-loss = 0.4244219660758972, train/logprobs = tensor([[-1.0456, -9.2031],
        [-1.7543, -2.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41334766149520874
Epoch 0, Step 1016: train/loss = 0.3298531174659729, train/raw-loss = 0.288448303937912, train/logprobs = tensor([[-0.8644, -3.1251],
        [-2.0163, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41404807567596436
Epoch 0, Step 1017: train/loss = 0.23169666528701782, train/raw-loss = 0.18988162279129028, train/logprobs = tensor([[-1.2763, -3.5025],
        [-2.6286, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41815051436424255
Epoch 0, Step 1018: train/loss = 0.3344489336013794, train/raw-loss = 0.29765135049819946, train/logprobs = tensor([[-0.8500, -6.1581],
        [-1.7736, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36797547340393066
Epoch 0, Step 1019: train/loss = 0.3146379888057709, train/raw-loss = 0.2667950689792633, train/logprobs = tensor([[-0.8606, -6.1597],
        [-2.4951, -1.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4784289598464966
Epoch 0, Step 1020: train/loss = 0.64390629529953, train/raw-loss = 0.6139034032821655, train/logprobs = tensor([[-0.7272, -2.7361],
        [-0.8533, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3000289797782898
Epoch 0, Step 1021: train/loss = 0.46965938806533813, train/raw-loss = 0.4264201521873474, train/logprobs = tensor([[-1.0302, -3.3398],
        [-2.3000, -1.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4323921203613281
Epoch 0, Step 1022: train/loss = 0.4302555322647095, train/raw-loss = 0.3994974195957184, train/logprobs = tensor([[-0.6608, -2.5565],
        [-1.6103, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30758070945739746
Epoch 0, Step 1023: train/loss = 0.9064101576805115, train/raw-loss = 0.8727300763130188, train/logprobs = tensor([[-3.5870, -8.9781],
        [-1.9372, -0.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33680015802383423
Epoch 0, Step 1024: train/loss = 0.43149280548095703, train/raw-loss = 0.3918397128582001, train/logprobs = tensor([[-0.7210, -2.1325],
        [-1.8444, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39653119444847107
Epoch 0, Step 1025: train/loss = 0.564954400062561, train/raw-loss = 0.5381861925125122, train/logprobs = tensor([[-0.6984, -1.3650],
        [-0.8072, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676820755004883
Epoch 0, Step 1026: train/loss = 0.5231577157974243, train/raw-loss = 0.4809393286705017, train/logprobs = tensor([[-2.0081, -2.7382],
        [-2.5540, -1.7375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4221836030483246
Epoch 0, Step 1027: train/loss = 0.651231050491333, train/raw-loss = 0.6120618581771851, train/logprobs = tensor([[-0.6538, -1.2719],
        [-1.2226, -1.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3916919231414795
Epoch 0, Step 1028: train/loss = 0.16448980569839478, train/raw-loss = 0.12490784376859665, train/logprobs = tensor([[-1.0626, -9.0179],
        [-2.5641, -1.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.395819753408432
Epoch 0, Step 1029: train/loss = 0.4656762182712555, train/raw-loss = 0.42334067821502686, train/logprobs = tensor([[ -1.9211, -11.2871],
        [ -2.4565,  -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42335525155067444
Epoch 0, Step 1030: train/loss = 0.5374928712844849, train/raw-loss = 0.5091729164123535, train/logprobs = tensor([[-0.6306, -5.9288],
        [-0.7555, -1.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831993103027344
Epoch 0, Step 1031: train/loss = 0.6790362596511841, train/raw-loss = 0.6400004625320435, train/logprobs = tensor([[-1.2317, -1.6553],
        [-1.2339, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39035719633102417
Epoch 0, Step 1032: train/loss = 0.5092551708221436, train/raw-loss = 0.47136613726615906, train/logprobs = tensor([[-0.7921, -4.9522],
        [-1.8208, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3788903057575226
Epoch 0, Step 1033: train/loss = 0.3057524561882019, train/raw-loss = 0.26136040687561035, train/logprobs = tensor([[-0.6598, -6.9265],
        [-2.2092, -1.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4439205229282379
Epoch 0, Step 1034: train/loss = 0.49845874309539795, train/raw-loss = 0.4710583984851837, train/logprobs = tensor([[-0.7390, -2.8476],
        [-0.8494, -1.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27400386333465576
Epoch 0, Step 1035: train/loss = 0.3571782112121582, train/raw-loss = 0.31183478236198425, train/logprobs = tensor([[-0.7403, -4.7206],
        [-2.3981, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4534341096878052
Epoch 0, Step 1036: train/loss = 0.19863279163837433, train/raw-loss = 0.1595202535390854, train/logprobs = tensor([[-0.8819, -5.1227],
        [-2.9923, -0.5560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39112526178359985
Epoch 0, Step 1037: train/loss = 0.653618574142456, train/raw-loss = 0.6062147617340088, train/logprobs = tensor([[-0.6484, -1.8769],
        [-1.9661, -2.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.474038302898407
Epoch 0, Step 1038: train/loss = 0.7188587188720703, train/raw-loss = 0.6747980713844299, train/logprobs = tensor([[-0.8021, -4.8771],
        [-2.5562, -2.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44060561060905457
Epoch 0, Step 1039: train/loss = 0.5796078443527222, train/raw-loss = 0.5447201132774353, train/logprobs = tensor([[-0.7419, -1.3394],
        [-1.3310, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34887734055519104
Epoch 0, Step 1040: train/loss = 0.4509197473526001, train/raw-loss = 0.41989055275917053, train/logprobs = tensor([[-0.4686, -4.7647],
        [-0.9361, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3102920651435852
Epoch 0, Step 1041: train/loss = 0.41659343242645264, train/raw-loss = 0.3651738166809082, train/logprobs = tensor([[-1.0148, -3.7087],
        [-2.1930, -2.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141960978507996
Epoch 0, Step 1042: train/loss = 0.514873206615448, train/raw-loss = 0.4755178689956665, train/logprobs = tensor([[-1.3155, -3.5200],
        [-1.7714, -0.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39355331659317017
Epoch 0, Step 1043: train/loss = 0.40279948711395264, train/raw-loss = 0.36858052015304565, train/logprobs = tensor([[-0.6914, -5.2926],
        [-1.4790, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421899974346161
Epoch 0, Step 1044: train/loss = 1.0443825721740723, train/raw-loss = 1.0125126838684082, train/logprobs = tensor([[-2.4298, -2.4992],
        [-1.0783, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186999559402466
Epoch 0, Step 1045: train/loss = 0.28503167629241943, train/raw-loss = 0.24733616411685944, train/logprobs = tensor([[ -0.8237, -11.7728],
        [ -2.4752,  -2.4875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3769550025463104
Epoch 0, Step 1046: train/loss = 0.5418188571929932, train/raw-loss = 0.5099586248397827, train/logprobs = tensor([[-0.7296, -1.8661],
        [-1.0309, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31860220432281494
Epoch 0, Step 1047: train/loss = 0.41145414113998413, train/raw-loss = 0.3676662743091583, train/logprobs = tensor([[-1.0723, -3.7495],
        [-2.6179, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4378783106803894
Epoch 0, Step 1048: train/loss = 0.6433265805244446, train/raw-loss = 0.6102516055107117, train/logprobs = tensor([[-0.6264, -1.1370],
        [-1.2910, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33074989914894104
Epoch 0, Step 1049: train/loss = 0.25711822509765625, train/raw-loss = 0.21581873297691345, train/logprobs = tensor([[-1.7970, -5.9686],
        [-2.4200, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4129948616027832
Epoch 0, Step 1050: train/loss = 0.25087398290634155, train/raw-loss = 0.2087666243314743, train/logprobs = tensor([[-0.6150, -8.2358],
        [-2.4983, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42107367515563965
Epoch 0, Step 1051: train/loss = 0.3464847207069397, train/raw-loss = 0.31153732538223267, train/logprobs = tensor([[-1.1773, -5.0918],
        [-2.1028, -1.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3494739532470703
Epoch 0, Step 1052: train/loss = 0.22309912741184235, train/raw-loss = 0.1875278204679489, train/logprobs = tensor([[-0.7214, -4.9905],
        [-2.4366, -0.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35571298003196716
Epoch 0, Step 1053: train/loss = 0.46590352058410645, train/raw-loss = 0.41958945989608765, train/logprobs = tensor([[-1.2354, -4.6791],
        [-2.2307, -1.3847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4631405770778656
Epoch 0, Step 1054: train/loss = 0.2605404853820801, train/raw-loss = 0.2248833328485489, train/logprobs = tensor([[-0.7157, -6.4010],
        [-1.5906, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3565714359283447
Epoch 0, Step 1055: train/loss = 0.43847471475601196, train/raw-loss = 0.41386693716049194, train/logprobs = tensor([[-0.4893, -5.1117],
        [-0.6786, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24607785046100616
Epoch 0, Step 1056: train/loss = 0.40454545617103577, train/raw-loss = 0.3657022714614868, train/logprobs = tensor([[-1.2012, -3.9884],
        [-1.7598, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3884318470954895
Epoch 0, Step 1057: train/loss = 0.4358391761779785, train/raw-loss = 0.3930082321166992, train/logprobs = tensor([[-0.8953, -3.7668],
        [-1.9323, -1.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4283095598220825
Epoch 0, Step 1058: train/loss = 0.5151294469833374, train/raw-loss = 0.4766199588775635, train/logprobs = tensor([[-1.4098, -3.4463],
        [-2.2024, -2.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850950598716736
Epoch 0, Step 1059: train/loss = 0.4323628544807434, train/raw-loss = 0.3906100392341614, train/logprobs = tensor([[-1.0736, -3.9746],
        [-2.4797, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41752851009368896
Epoch 0, Step 1060: train/loss = 0.2989393472671509, train/raw-loss = 0.2568322718143463, train/logprobs = tensor([[-1.3016, -4.3664],
        [-2.7734, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42107054591178894
Epoch 0, Step 1061: train/loss = 0.30047518014907837, train/raw-loss = 0.25592970848083496, train/logprobs = tensor([[-0.6125, -6.4942],
        [-2.0080, -1.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4454543888568878
Epoch 0, Step 1062: train/loss = 0.42322468757629395, train/raw-loss = 0.3960861265659332, train/logprobs = tensor([[-0.6580, -2.2602],
        [-0.9742, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713859975337982
Epoch 0, Step 1063: train/loss = 0.3329603374004364, train/raw-loss = 0.30008119344711304, train/logprobs = tensor([[-0.7131, -6.0125],
        [-1.9255, -1.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32879167795181274
Epoch 0, Step 1064: train/loss = 0.23127232491970062, train/raw-loss = 0.18363164365291595, train/logprobs = tensor([[-0.5978, -8.5042],
        [-2.0292, -1.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47640669345855713
Epoch 0, Step 1065: train/loss = 0.5840805768966675, train/raw-loss = 0.5462726354598999, train/logprobs = tensor([[-1.2743, -4.2806],
        [-1.6042, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378079891204834
Epoch 0, Step 1066: train/loss = 0.30632147192955017, train/raw-loss = 0.26029443740844727, train/logprobs = tensor([[-0.7425, -6.4704],
        [-2.1170, -1.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4602702856063843
Epoch 0, Step 1067: train/loss = 0.09887057542800903, train/raw-loss = 0.05338648334145546, train/logprobs = tensor([[-0.7085, -8.6661],
        [-3.6826, -1.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45484086871147156
Epoch 0, Step 1068: train/loss = 0.33539122343063354, train/raw-loss = 0.28977933526039124, train/logprobs = tensor([[-0.8621, -8.5712],
        [-2.9265, -2.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45611879229545593
Epoch 0, Step 1069: train/loss = 0.23915010690689087, train/raw-loss = 0.19745081663131714, train/logprobs = tensor([[-0.7844, -4.5221],
        [-3.1581, -0.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4169928729534149
Epoch 0, Step 1070: train/loss = 0.38459086418151855, train/raw-loss = 0.3454928994178772, train/logprobs = tensor([[-1.3942, -6.0797],
        [-2.1519, -1.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3909795880317688
Epoch 0, Step 1071: train/loss = 0.35279446840286255, train/raw-loss = 0.31309303641319275, train/logprobs = tensor([[-0.9168, -6.4143],
        [-1.8772, -1.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3970143496990204
Epoch 0, Step 1072: train/loss = 0.4657007157802582, train/raw-loss = 0.43774038553237915, train/logprobs = tensor([[-1.0811, -3.1244],
        [-1.2565, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27960360050201416
Epoch 0, Step 1073: train/loss = 0.5491087436676025, train/raw-loss = 0.5096440315246582, train/logprobs = tensor([[-1.9697, -4.4787],
        [-1.9651, -1.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3946472108364105
Epoch 0, Step 1074: train/loss = 0.4786401391029358, train/raw-loss = 0.4279583990573883, train/logprobs = tensor([[-2.2366, -3.8437],
        [-4.3272, -2.2417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5068172216415405
Epoch 0, Step 1075: train/loss = 0.4429566264152527, train/raw-loss = 0.39234378933906555, train/logprobs = tensor([[-0.6504, -4.3324],
        [-2.6148, -2.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5061285495758057
Epoch 0, Step 1076: train/loss = 0.42157965898513794, train/raw-loss = 0.38487881422042847, train/logprobs = tensor([[-0.4591, -3.9921],
        [-1.3293, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3670082986354828
Epoch 0, Step 1077: train/loss = 0.25926125049591064, train/raw-loss = 0.22170019149780273, train/logprobs = tensor([[-1.3906, -4.7712],
        [-2.3036, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3756105303764343
Epoch 0, Step 1078: train/loss = 0.37596118450164795, train/raw-loss = 0.3361605405807495, train/logprobs = tensor([[-0.6290, -5.4141],
        [-1.7130, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980061709880829
Epoch 0, Step 1079: train/loss = 0.3775325417518616, train/raw-loss = 0.33840641379356384, train/logprobs = tensor([[-1.5059, -5.5783],
        [-2.5592, -1.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39126119017601013
Epoch 0, Step 1080: train/loss = 0.4909875988960266, train/raw-loss = 0.4584854543209076, train/logprobs = tensor([[-1.1666, -4.0664],
        [-1.5644, -1.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32502099871635437
Epoch 0, Step 1081: train/loss = 0.2932876944541931, train/raw-loss = 0.256552129983902, train/logprobs = tensor([[ -0.9327, -11.3184],
        [ -2.3456,  -2.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.367355614900589
Epoch 0, Step 1082: train/loss = 0.34435200691223145, train/raw-loss = 0.3128884732723236, train/logprobs = tensor([[-0.8747, -6.9531],
        [-1.5054, -1.3594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3146354556083679
Epoch 0, Step 1083: train/loss = 0.5205404758453369, train/raw-loss = 0.49594131112098694, train/logprobs = tensor([[-0.7378, -2.6438],
        [-0.7578, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24599146842956543
Epoch 0, Step 1084: train/loss = 0.6488561034202576, train/raw-loss = 0.608826220035553, train/logprobs = tensor([[-0.7319, -1.4837],
        [-2.2207, -2.1501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40029895305633545
Epoch 0, Step 1085: train/loss = 0.237113356590271, train/raw-loss = 0.1967981606721878, train/logprobs = tensor([[-1.7274, -9.6567],
        [-2.9751, -1.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40315189957618713
Epoch 0, Step 1086: train/loss = 0.37341248989105225, train/raw-loss = 0.3333881199359894, train/logprobs = tensor([[-0.6686, -5.4799],
        [-2.1149, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002436101436615
Epoch 0, Step 1087: train/loss = 0.5315685868263245, train/raw-loss = 0.4987618625164032, train/logprobs = tensor([[-0.8449, -2.3040],
        [-1.2979, -0.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.328066885471344
Epoch 0, Step 1088: train/loss = 0.4642995595932007, train/raw-loss = 0.42997056245803833, train/logprobs = tensor([[-0.6241, -4.5922],
        [-1.3151, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34328973293304443
Epoch 0, Step 1089: train/loss = 0.1223503053188324, train/raw-loss = 0.0781608521938324, train/logprobs = tensor([[-1.2652, -5.9971],
        [-3.7972, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4418945610523224
Epoch 0, Step 1090: train/loss = 0.8674455285072327, train/raw-loss = 0.8233125805854797, train/logprobs = tensor([[ -3.4955, -10.6862],
        [ -3.0167,  -1.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44132933020591736
Epoch 0, Step 1091: train/loss = 0.26303786039352417, train/raw-loss = 0.2137719988822937, train/logprobs = tensor([[-1.3288, -4.2530],
        [-3.0259, -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49265891313552856
Epoch 0, Step 1092: train/loss = 0.38793960213661194, train/raw-loss = 0.351693719625473, train/logprobs = tensor([[-0.9828, -5.3778],
        [-2.3171, -1.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36245909333229065
Epoch 0, Step 1093: train/loss = 0.2973904013633728, train/raw-loss = 0.25577664375305176, train/logprobs = tensor([[-1.4073, -6.4054],
        [-2.6994, -1.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4161375164985657
Epoch 0, Step 1094: train/loss = 0.5096614360809326, train/raw-loss = 0.47549140453338623, train/logprobs = tensor([[-0.7247, -1.6834],
        [-1.5047, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416999578475952
Epoch 0, Step 1095: train/loss = 0.546134352684021, train/raw-loss = 0.508764922618866, train/logprobs = tensor([[-0.8214, -1.3213],
        [-2.3936, -1.3427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3736945688724518
Epoch 0, Step 1096: train/loss = 0.350186288356781, train/raw-loss = 0.31778010725975037, train/logprobs = tensor([[-1.0703, -8.0559],
        [-2.0192, -1.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240618407726288
Epoch 0, Step 1097: train/loss = 0.5204914212226868, train/raw-loss = 0.46809104084968567, train/logprobs = tensor([[-0.8086, -4.2722],
        [-2.5676, -1.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5240037441253662
Epoch 0, Step 1098: train/loss = 0.410847008228302, train/raw-loss = 0.37912166118621826, train/logprobs = tensor([[-0.8030, -4.8742],
        [-1.4769, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3172535300254822
Epoch 0, Step 1099: train/loss = 0.3526993989944458, train/raw-loss = 0.31208136677742004, train/logprobs = tensor([[-1.1176, -5.0918],
        [-2.0825, -2.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.406180202960968
Epoch 0, Step 1100: train/loss = 0.28913649916648865, train/raw-loss = 0.2520693838596344, train/logprobs = tensor([[-0.7351, -4.2188],
        [-2.2700, -1.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37067121267318726
Epoch 0, Step 1101: train/loss = 0.29992273449897766, train/raw-loss = 0.26385605335235596, train/logprobs = tensor([[-0.8255, -7.3558],
        [-1.8422, -1.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36066675186157227
Epoch 0, Step 1102: train/loss = 0.2838857173919678, train/raw-loss = 0.24211382865905762, train/logprobs = tensor([[-0.7362, -4.8548],
        [-2.4476, -1.4457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.417718768119812
Epoch 0, Step 1103: train/loss = 0.5292381644248962, train/raw-loss = 0.49581047892570496, train/logprobs = tensor([[-1.4721, -3.4101],
        [-1.5139, -1.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33427679538726807
Epoch 0, Step 1104: train/loss = 0.7783164978027344, train/raw-loss = 0.7367551326751709, train/logprobs = tensor([[-0.5860, -0.7351],
        [-1.2684, -1.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41561347246170044
Epoch 0, Step 1105: train/loss = 0.27743393182754517, train/raw-loss = 0.2306954562664032, train/logprobs = tensor([[-1.2555, -4.4549],
        [-3.2297, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46738481521606445
Epoch 0, Step 1106: train/loss = 0.5668877959251404, train/raw-loss = 0.5251410603523254, train/logprobs = tensor([[-1.1536, -3.1976],
        [-1.8409, -1.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41746750473976135
Epoch 0, Step 1107: train/loss = 0.44389891624450684, train/raw-loss = 0.41158434748649597, train/logprobs = tensor([[-0.8346, -5.3414],
        [-2.4148, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32314544916152954
Epoch 0, Step 1108: train/loss = 0.433044970035553, train/raw-loss = 0.38450074195861816, train/logprobs = tensor([[-0.7530, -6.3852],
        [-3.5708, -2.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48544251918792725
Epoch 0, Step 1109: train/loss = 0.34015515446662903, train/raw-loss = 0.27781298756599426, train/logprobs = tensor([[-1.1256, -4.1435],
        [-3.4661, -1.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6234214305877686
Epoch 0, Step 1110: train/loss = 0.542557418346405, train/raw-loss = 0.4957766532897949, train/logprobs = tensor([[-0.7402, -1.4105],
        [-3.1168, -1.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678083062171936
Epoch 0, Step 1111: train/loss = 0.41012877225875854, train/raw-loss = 0.3600785732269287, train/logprobs = tensor([[-0.9243, -5.6069],
        [-2.6845, -1.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5005017518997192
Epoch 0, Step 1112: train/loss = 0.32470983266830444, train/raw-loss = 0.27983182668685913, train/logprobs = tensor([[-0.8345, -6.8174],
        [-2.4054, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4487796425819397
Epoch 0, Step 1113: train/loss = 0.5835980772972107, train/raw-loss = 0.5491924285888672, train/logprobs = tensor([[-1.6117, -4.2904],
        [-1.1205, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34405583143234253
Epoch 0, Step 1114: train/loss = 0.6003885269165039, train/raw-loss = 0.571357250213623, train/logprobs = tensor([[-1.2545, -2.8487],
        [-1.1400, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29031288623809814
Epoch 0, Step 1115: train/loss = 0.2422313392162323, train/raw-loss = 0.20026247203350067, train/logprobs = tensor([[-0.7830, -5.8245],
        [-2.8717, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4196886122226715
Epoch 0, Step 1116: train/loss = 0.4843568205833435, train/raw-loss = 0.45530498027801514, train/logprobs = tensor([[-0.9265, -2.4117],
        [-2.0153, -0.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2905184030532837
Epoch 0, Step 1117: train/loss = 0.7370033860206604, train/raw-loss = 0.7120963335037231, train/logprobs = tensor([[-0.7902, -0.7723],
        [-0.4100, -0.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24907052516937256
Epoch 0, Step 1118: train/loss = 0.6047816276550293, train/raw-loss = 0.5754696130752563, train/logprobs = tensor([[-0.8334, -3.8275],
        [-1.7484, -1.4568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29311996698379517
Epoch 0, Step 1119: train/loss = 0.5152624845504761, train/raw-loss = 0.4869008958339691, train/logprobs = tensor([[-1.1547, -3.4442],
        [-1.0403, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2836162745952606
Epoch 0, Step 1120: train/loss = 0.6074668765068054, train/raw-loss = 0.5664442181587219, train/logprobs = tensor([[-0.5675, -1.6982],
        [-1.9019, -1.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4102269411087036
Epoch 0, Step 1121: train/loss = 0.310617059469223, train/raw-loss = 0.25693029165267944, train/logprobs = tensor([[-0.5775, -5.2416],
        [-2.8207, -1.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5368674993515015
Epoch 0, Step 1122: train/loss = 0.38945701718330383, train/raw-loss = 0.346350759267807, train/logprobs = tensor([[-1.1625, -3.8560],
        [-3.4187, -1.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43106284737586975
Epoch 0, Step 1123: train/loss = 0.3133513927459717, train/raw-loss = 0.2660260498523712, train/logprobs = tensor([[-0.8395, -3.8235],
        [-2.9310, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47325342893600464
Epoch 0, Step 1124: train/loss = 0.4356924295425415, train/raw-loss = 0.39544713497161865, train/logprobs = tensor([[-1.2885, -6.8928],
        [-2.3874, -1.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40245285630226135
Epoch 0, Step 1125: train/loss = 0.5693411231040955, train/raw-loss = 0.5228431820869446, train/logprobs = tensor([[-0.6613, -1.5979],
        [-2.0490, -1.8237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4649796187877655
Epoch 0, Step 1126: train/loss = 0.6016629934310913, train/raw-loss = 0.5644610524177551, train/logprobs = tensor([[-2.8233, -7.3519],
        [-2.7372, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37201955914497375
Epoch 0, Step 1127: train/loss = 0.5558512806892395, train/raw-loss = 0.5233295559883118, train/logprobs = tensor([[-1.3928, -4.2385],
        [-1.6424, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3252173066139221
Epoch 0, Step 1128: train/loss = 0.49608898162841797, train/raw-loss = 0.4600332975387573, train/logprobs = tensor([[-1.1878, -5.0120],
        [-2.6568, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3605566620826721
Epoch 0, Step 1129: train/loss = 0.33433839678764343, train/raw-loss = 0.29733988642692566, train/logprobs = tensor([[-0.7637, -4.5826],
        [-1.3678, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36998507380485535
Epoch 0, Step 1130: train/loss = 0.5109750628471375, train/raw-loss = 0.46542656421661377, train/logprobs = tensor([[-1.5046, -4.1479],
        [-2.6226, -1.2620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45548492670059204
Epoch 0, Step 1131: train/loss = 0.39183664321899414, train/raw-loss = 0.3586333394050598, train/logprobs = tensor([[-0.8047, -5.0839],
        [-1.3740, -1.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33203330636024475
Epoch 0, Step 1132: train/loss = 0.26836416125297546, train/raw-loss = 0.2247616946697235, train/logprobs = tensor([[-0.6566, -7.6614],
        [-2.1759, -2.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43602463603019714
Epoch 0, Step 1133: train/loss = 0.5723985433578491, train/raw-loss = 0.5301011800765991, train/logprobs = tensor([[-0.7634, -1.9426],
        [-2.4038, -1.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42297282814979553
Epoch 0, Step 1134: train/loss = 0.38922879099845886, train/raw-loss = 0.3505208194255829, train/logprobs = tensor([[-0.9477, -2.8963],
        [-2.8631, -1.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38708001375198364
Epoch 0, Step 1135: train/loss = 0.47138968110084534, train/raw-loss = 0.42812156677246094, train/logprobs = tensor([[-0.7338, -4.4053],
        [-1.8313, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4326810836791992
Epoch 0, Step 1136: train/loss = 0.3446234166622162, train/raw-loss = 0.30542898178100586, train/logprobs = tensor([[-0.8101, -7.0299],
        [-2.5685, -2.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919442594051361
Epoch 0, Step 1137: train/loss = 0.451063334941864, train/raw-loss = 0.40646594762802124, train/logprobs = tensor([[-0.6177, -2.8486],
        [-2.5460, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44597387313842773
Epoch 0, Step 1138: train/loss = 0.5691196918487549, train/raw-loss = 0.5354034900665283, train/logprobs = tensor([[-0.5660, -1.2224],
        [-1.4089, -0.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3371623456478119
Epoch 0, Step 1139: train/loss = 0.31887292861938477, train/raw-loss = 0.27422887086868286, train/logprobs = tensor([[-1.0569, -4.4829],
        [-2.7602, -1.4202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44644057750701904
Epoch 0, Step 1140: train/loss = 0.11710982024669647, train/raw-loss = 0.06933701783418655, train/logprobs = tensor([[-1.0549, -5.5334],
        [-3.4613, -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.477728009223938
Epoch 0, Step 1141: train/loss = 0.36332958936691284, train/raw-loss = 0.3235339820384979, train/logprobs = tensor([[-1.0516, -5.8924],
        [-3.0428, -1.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39795616269111633
Epoch 0, Step 1142: train/loss = 0.3843849003314972, train/raw-loss = 0.34374508261680603, train/logprobs = tensor([[-1.0803, -3.3440],
        [-2.4176, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4063979983329773
Epoch 0, Step 1143: train/loss = 0.1609579622745514, train/raw-loss = 0.117071233689785, train/logprobs = tensor([[-0.7203, -5.8413],
        [-2.7133, -1.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43886736035346985
Epoch 0, Step 1144: train/loss = 0.6803410649299622, train/raw-loss = 0.6366409063339233, train/logprobs = tensor([[-0.7782, -3.2885],
        [-2.7897, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43700167536735535
Epoch 0, Step 1145: train/loss = 0.15704292058944702, train/raw-loss = 0.10792648792266846, train/logprobs = tensor([[-0.6690, -6.5272],
        [-2.6599, -2.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4911641776561737
Epoch 0, Step 1146: train/loss = 0.7565779089927673, train/raw-loss = 0.7150892615318298, train/logprobs = tensor([[-1.8295, -2.6715],
        [-1.8136, -1.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41488659381866455
Epoch 0, Step 1147: train/loss = 0.4548743665218353, train/raw-loss = 0.4157874882221222, train/logprobs = tensor([[-1.0944, -6.5374],
        [-3.1683, -2.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908686339855194
Epoch 0, Step 1148: train/loss = 0.4902207851409912, train/raw-loss = 0.4343676269054413, train/logprobs = tensor([[-0.7477, -3.3089],
        [-3.2087, -2.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5585314035415649
Epoch 0, Step 1149: train/loss = 0.3267463147640228, train/raw-loss = 0.2866065204143524, train/logprobs = tensor([[-0.9437, -2.9589],
        [-2.0447, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40139779448509216
Epoch 0, Step 1150: train/loss = 0.5638381838798523, train/raw-loss = 0.5159330368041992, train/logprobs = tensor([[-1.8477, -4.0319],
        [-2.8476, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47905153036117554
Epoch 0, Step 1151: train/loss = 0.2962901294231415, train/raw-loss = 0.24920904636383057, train/logprobs = tensor([[-0.5980, -6.9412],
        [-2.3589, -2.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4708110988140106
Epoch 0, Step 1152: train/loss = 0.5762725472450256, train/raw-loss = 0.537448525428772, train/logprobs = tensor([[-0.9364, -1.6256],
        [-1.5298, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38824033737182617
Epoch 0, Step 1153: train/loss = 0.13712400197982788, train/raw-loss = 0.09060303121805191, train/logprobs = tensor([[ -0.7638, -14.6958],
        [ -3.2972,  -2.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4652097225189209
Epoch 0, Step 1154: train/loss = 0.48519429564476013, train/raw-loss = 0.4494404196739197, train/logprobs = tensor([[-1.0781, -3.6640],
        [-1.9984, -1.3354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3575388789176941
Epoch 0, Step 1155: train/loss = 0.42275410890579224, train/raw-loss = 0.38832196593284607, train/logprobs = tensor([[-0.9354, -2.6828],
        [-2.1818, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34432166814804077
Epoch 0, Step 1156: train/loss = 0.4367581307888031, train/raw-loss = 0.3875243365764618, train/logprobs = tensor([[-1.1495, -3.2194],
        [-3.1794, -2.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4923379719257355
Epoch 0, Step 1157: train/loss = 0.4077184498310089, train/raw-loss = 0.35963043570518494, train/logprobs = tensor([[-0.7540, -2.5727],
        [-2.3731, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48088014125823975
Epoch 0, Step 1158: train/loss = 0.7214663624763489, train/raw-loss = 0.6759381294250488, train/logprobs = tensor([[-1.7489, -3.4569],
        [-3.2838, -1.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45528221130371094
Epoch 0, Step 1159: train/loss = 0.7534700632095337, train/raw-loss = 0.7125331163406372, train/logprobs = tensor([[-1.0610, -1.6731],
        [-1.9912, -2.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40936946868896484
Epoch 0, Step 1160: train/loss = 0.38486549258232117, train/raw-loss = 0.3505188226699829, train/logprobs = tensor([[-1.7461, -6.6190],
        [-2.7466, -1.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34346675872802734
Epoch 0, Step 1161: train/loss = 0.286883145570755, train/raw-loss = 0.25318223237991333, train/logprobs = tensor([[-1.2140, -6.0845],
        [-3.0974, -1.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33700910210609436
Epoch 0, Step 1162: train/loss = 0.7119753360748291, train/raw-loss = 0.6643100380897522, train/logprobs = tensor([[-0.9064, -1.1269],
        [-2.4585, -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4766525626182556
Epoch 0, Step 1163: train/loss = 0.345378577709198, train/raw-loss = 0.301768958568573, train/logprobs = tensor([[-1.9926, -5.2367],
        [-4.1675, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43609654903411865
Epoch 0, Step 1164: train/loss = 0.6928739547729492, train/raw-loss = 0.6351882219314575, train/logprobs = tensor([[-0.8831, -2.6363],
        [-3.3230, -2.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.57685786485672
Epoch 0, Step 1165: train/loss = 0.3696277439594269, train/raw-loss = 0.34364500641822815, train/logprobs = tensor([[-1.0359, -3.9062],
        [-1.7960, -0.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598273754119873
Epoch 0, Step 1166: train/loss = 0.7447500228881836, train/raw-loss = 0.6913391351699829, train/logprobs = tensor([[-0.8198, -2.0493],
        [-3.3522, -3.2269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5341094136238098
Epoch 0, Step 1167: train/loss = 0.6203080415725708, train/raw-loss = 0.5837696194648743, train/logprobs = tensor([[-0.6942, -1.0269],
        [-1.5382, -1.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36538398265838623
Epoch 0, Step 1168: train/loss = 0.2687326669692993, train/raw-loss = 0.21998783946037292, train/logprobs = tensor([[-1.1358, -4.4064],
        [-2.1503, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4874482750892639
Epoch 0, Step 1169: train/loss = 0.501702070236206, train/raw-loss = 0.4539148807525635, train/logprobs = tensor([[-0.6861, -2.6876],
        [-2.3672, -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4778721332550049
Epoch 0, Step 1170: train/loss = 0.3171935975551605, train/raw-loss = 0.2678104639053345, train/logprobs = tensor([[-0.8369, -4.6210],
        [-3.0551, -1.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4938313364982605
Epoch 0, Step 1171: train/loss = 0.5182287693023682, train/raw-loss = 0.4847121238708496, train/logprobs = tensor([[-0.8655, -2.4471],
        [-1.7800, -1.3510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351665735244751
Epoch 0, Step 1172: train/loss = 0.4343869686126709, train/raw-loss = 0.39934948086738586, train/logprobs = tensor([[-0.9544, -3.3947],
        [-1.9919, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350374698638916
Epoch 0, Step 1173: train/loss = 0.37187594175338745, train/raw-loss = 0.32074761390686035, train/logprobs = tensor([[-1.6897, -8.6413],
        [-4.7305, -2.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5112830996513367
Epoch 0, Step 1174: train/loss = 0.37747129797935486, train/raw-loss = 0.33676624298095703, train/logprobs = tensor([[-0.6763, -6.5090],
        [-2.0489, -2.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40705007314682007
Epoch 0, Step 1175: train/loss = 0.42897486686706543, train/raw-loss = 0.39191484451293945, train/logprobs = tensor([[-1.0194, -2.8608],
        [-1.8661, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37060028314590454
Epoch 0, Step 1176: train/loss = 0.4231850802898407, train/raw-loss = 0.3795255124568939, train/logprobs = tensor([[-0.8081, -1.9854],
        [-2.5646, -1.3007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.436595618724823
Epoch 0, Step 1177: train/loss = 0.5200163722038269, train/raw-loss = 0.4862207770347595, train/logprobs = tensor([[-0.9154, -4.0540],
        [-1.5339, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33795660734176636
Epoch 0, Step 1178: train/loss = 0.3837621808052063, train/raw-loss = 0.35032084584236145, train/logprobs = tensor([[-0.8661, -5.7944],
        [-2.1576, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344130218029022
Epoch 0, Step 1179: train/loss = 0.3780418932437897, train/raw-loss = 0.3360808789730072, train/logprobs = tensor([[-0.4468, -2.8529],
        [-2.0060, -1.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41961050033569336
Epoch 0, Step 1180: train/loss = 0.1700519174337387, train/raw-loss = 0.12388047575950623, train/logprobs = tensor([[-0.9097, -4.3175],
        [-2.6723, -1.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46171438694000244
Epoch 0, Step 1181: train/loss = 0.33675435185432434, train/raw-loss = 0.29388099908828735, train/logprobs = tensor([[-0.7375, -5.4725],
        [-2.0227, -2.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42873355746269226
Epoch 0, Step 1182: train/loss = 0.6514350175857544, train/raw-loss = 0.6065789461135864, train/logprobs = tensor([[-1.0337, -2.2282],
        [-2.6424, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44856101274490356
Epoch 0, Step 1183: train/loss = 0.32738569378852844, train/raw-loss = 0.28695085644721985, train/logprobs = tensor([[-1.0316, -7.4030],
        [-2.9400, -1.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40434813499450684
Epoch 0, Step 1184: train/loss = 0.1905623972415924, train/raw-loss = 0.15446200966835022, train/logprobs = tensor([[-0.8305, -7.9236],
        [-1.7748, -1.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36100396513938904
Epoch 0, Step 1185: train/loss = 0.41591864824295044, train/raw-loss = 0.37984466552734375, train/logprobs = tensor([[-0.7884, -5.1170],
        [-2.1099, -1.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3607397973537445
Epoch 0, Step 1186: train/loss = 0.16809317469596863, train/raw-loss = 0.12286993116140366, train/logprobs = tensor([[-0.7445, -6.7156],
        [-2.3408, -1.1916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45223239064216614
Epoch 0, Step 1187: train/loss = 0.46581488847732544, train/raw-loss = 0.4279881715774536, train/logprobs = tensor([[-0.8111, -1.7826],
        [-2.0570, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782670497894287
Epoch 0, Step 1188: train/loss = 0.29066210985183716, train/raw-loss = 0.23599441349506378, train/logprobs = tensor([[-0.9645, -8.6800],
        [-3.1494, -1.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5466768741607666
Epoch 0, Step 1189: train/loss = 0.5117519497871399, train/raw-loss = 0.46849241852760315, train/logprobs = tensor([[-1.3528, -2.7387],
        [-2.7842, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43259525299072266
Epoch 0, Step 1190: train/loss = 0.39935439825057983, train/raw-loss = 0.3574630320072174, train/logprobs = tensor([[-1.2123, -3.1586],
        [-3.1946, -1.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4189136028289795
Epoch 0, Step 1191: train/loss = 0.27491524815559387, train/raw-loss = 0.24171754717826843, train/logprobs = tensor([[-0.6239, -5.5382],
        [-2.0400, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33197689056396484
Epoch 0, Step 1192: train/loss = 0.4588586688041687, train/raw-loss = 0.4219370186328888, train/logprobs = tensor([[-1.8191, -3.3037],
        [-3.0709, -2.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692164719104767
Epoch 0, Step 1193: train/loss = 0.33227598667144775, train/raw-loss = 0.29123955965042114, train/logprobs = tensor([[-0.9619, -3.7987],
        [-2.4646, -2.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4103640913963318
Epoch 0, Step 1194: train/loss = 0.40976524353027344, train/raw-loss = 0.3731907606124878, train/logprobs = tensor([[-0.6826, -5.5181],
        [-1.6285, -2.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657444715499878
Epoch 0, Step 1195: train/loss = 0.33481526374816895, train/raw-loss = 0.2877616584300995, train/logprobs = tensor([[-1.1214, -4.2076],
        [-3.2188, -1.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4705355763435364
Epoch 0, Step 1196: train/loss = 0.3414152264595032, train/raw-loss = 0.2867516279220581, train/logprobs = tensor([[-1.1506, -4.8086],
        [-2.7087, -1.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5466362833976746
Epoch 0, Step 1197: train/loss = 0.2568220794200897, train/raw-loss = 0.22247818112373352, train/logprobs = tensor([[-1.3707, -3.2042],
        [-3.1275, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434390425682068
Epoch 0, Step 1198: train/loss = 0.3334504961967468, train/raw-loss = 0.3008350133895874, train/logprobs = tensor([[-1.2646, -3.9791],
        [-3.2462, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3261546790599823
Epoch 0, Step 1199: train/loss = 0.49023765325546265, train/raw-loss = 0.4540819525718689, train/logprobs = tensor([[-0.7647, -7.3167],
        [-2.2092, -2.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615569770336151
Epoch 0, Step 1200: train/loss = 0.5881876945495605, train/raw-loss = 0.5394225120544434, train/logprobs = tensor([[-0.9527, -2.0931],
        [-2.3502, -2.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4876514971256256
Epoch 0, Step 1201: train/loss = 0.6555546522140503, train/raw-loss = 0.6151925921440125, train/logprobs = tensor([[-0.7629, -1.4817],
        [-1.8856, -1.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40362095832824707
Epoch 0, Step 1202: train/loss = 0.5277497172355652, train/raw-loss = 0.4987691640853882, train/logprobs = tensor([[-1.9740, -7.4564],
        [-1.5069, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28980523347854614
Epoch 0, Step 1203: train/loss = 0.39813029766082764, train/raw-loss = 0.3520260155200958, train/logprobs = tensor([[-0.8321, -4.7904],
        [-2.4016, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4610426425933838
Epoch 0, Step 1204: train/loss = 0.3187650144100189, train/raw-loss = 0.2789496183395386, train/logprobs = tensor([[-0.5757, -4.6472],
        [-1.5260, -1.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3981539309024811
Epoch 0, Step 1205: train/loss = 0.4574006497859955, train/raw-loss = 0.3997219204902649, train/logprobs = tensor([[-0.6895, -2.3407],
        [-2.4402, -1.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5767874121665955
Epoch 0, Step 1206: train/loss = 0.46018797159194946, train/raw-loss = 0.4217257499694824, train/logprobs = tensor([[-2.5900, -7.3440],
        [-3.2958, -1.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38462263345718384
Epoch 0, Step 1207: train/loss = 0.5571848154067993, train/raw-loss = 0.5084770917892456, train/logprobs = tensor([[-0.8228, -1.6664],
        [-2.2019, -1.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48707711696624756
Epoch 0, Step 1208: train/loss = 0.3375282883644104, train/raw-loss = 0.29758405685424805, train/logprobs = tensor([[-1.0914, -3.2774],
        [-2.3318, -1.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3994421660900116
Epoch 0, Step 1209: train/loss = 0.23889049887657166, train/raw-loss = 0.18506081402301788, train/logprobs = tensor([[-1.0548, -3.9746],
        [-3.5610, -1.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5382970571517944
Epoch 0, Step 1210: train/loss = 0.37470948696136475, train/raw-loss = 0.3470748960971832, train/logprobs = tensor([[-0.5241, -3.2296],
        [-1.1996, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2763459086418152
Epoch 0, Step 1211: train/loss = 0.3802449703216553, train/raw-loss = 0.3413380980491638, train/logprobs = tensor([[-0.7873, -6.2106],
        [-2.5713, -1.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3890685439109802
Epoch 0, Step 1212: train/loss = 0.4236227869987488, train/raw-loss = 0.37702882289886475, train/logprobs = tensor([[-0.7858, -3.5922],
        [-2.3016, -1.3842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46593958139419556
Epoch 0, Step 1213: train/loss = 0.30312541127204895, train/raw-loss = 0.2585434913635254, train/logprobs = tensor([[-1.2869, -7.0079],
        [-3.9897, -1.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4458191692829132
Epoch 0, Step 1214: train/loss = 0.4009714722633362, train/raw-loss = 0.35855573415756226, train/logprobs = tensor([[-1.2913, -3.3959],
        [-2.7459, -1.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4241575002670288
Epoch 0, Step 1215: train/loss = 0.2648265063762665, train/raw-loss = 0.22969847917556763, train/logprobs = tensor([[-0.6966, -4.5589],
        [-1.9241, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3512801229953766
Epoch 0, Step 1216: train/loss = 0.2168252170085907, train/raw-loss = 0.1701621115207672, train/logprobs = tensor([[-0.7009, -4.9231],
        [-2.6083, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46663111448287964
Epoch 0, Step 1217: train/loss = 0.7153282761573792, train/raw-loss = 0.6781269907951355, train/logprobs = tensor([[-0.6890, -0.9801],
        [-1.6521, -1.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37201231718063354
Epoch 0, Step 1218: train/loss = 0.20831318199634552, train/raw-loss = 0.17066946625709534, train/logprobs = tensor([[-1.8742, -7.2354],
        [-3.4882, -0.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3764370083808899
Epoch 0, Step 1219: train/loss = 0.29459261894226074, train/raw-loss = 0.2549588680267334, train/logprobs = tensor([[-1.1439, -4.7515],
        [-2.2244, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3963375687599182
Epoch 0, Step 1220: train/loss = 0.2741301953792572, train/raw-loss = 0.2328794151544571, train/logprobs = tensor([[-1.1075, -7.3498],
        [-2.5041, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41250792145729065
Epoch 0, Step 1221: train/loss = 0.3733161687850952, train/raw-loss = 0.32702502608299255, train/logprobs = tensor([[-1.5592, -3.2998],
        [-2.9135, -1.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46291136741638184
Epoch 0, Step 1222: train/loss = 0.2673555016517639, train/raw-loss = 0.23239395022392273, train/logprobs = tensor([[-0.8847, -7.3214],
        [-2.3362, -1.3019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496156632900238
Epoch 0, Step 1223: train/loss = 0.3730691075325012, train/raw-loss = 0.3168066143989563, train/logprobs = tensor([[-1.1961, -5.5072],
        [-3.0760, -2.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5626249313354492
Epoch 0, Step 1224: train/loss = 0.5944280624389648, train/raw-loss = 0.5482136011123657, train/logprobs = tensor([[-2.3980, -7.5616],
        [-2.3605, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46214428544044495
Epoch 0, Step 1225: train/loss = 0.4940090775489807, train/raw-loss = 0.44584909081459045, train/logprobs = tensor([[-0.9512, -2.0250],
        [-2.6784, -1.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4815998673439026
Epoch 0, Step 1226: train/loss = 0.45849114656448364, train/raw-loss = 0.4251407980918884, train/logprobs = tensor([[-0.5873, -3.4554],
        [-1.2795, -1.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33350351452827454
Epoch 0, Step 1227: train/loss = 0.3678191006183624, train/raw-loss = 0.3242729604244232, train/logprobs = tensor([[-0.9686, -4.9009],
        [-2.0598, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4354613721370697
Epoch 0, Step 1228: train/loss = 0.2934342324733734, train/raw-loss = 0.25442421436309814, train/logprobs = tensor([[-0.9356, -2.9743],
        [-2.3196, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39010030031204224
Epoch 0, Step 1229: train/loss = 0.26617759466171265, train/raw-loss = 0.22703225910663605, train/logprobs = tensor([[-0.8026, -4.8446],
        [-2.7960, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39145326614379883
Epoch 0, Step 1230: train/loss = 0.383464515209198, train/raw-loss = 0.33879992365837097, train/logprobs = tensor([[-0.7745, -5.0865],
        [-2.3096, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4466463327407837
Epoch 0, Step 1231: train/loss = 0.4759579598903656, train/raw-loss = 0.43557479977607727, train/logprobs = tensor([[-0.8890, -3.1270],
        [-2.1279, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4038318395614624
Epoch 0, Step 1232: train/loss = 0.3836595118045807, train/raw-loss = 0.3427687883377075, train/logprobs = tensor([[-1.1292, -6.3676],
        [-2.9833, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4089071750640869
Epoch 0, Step 1233: train/loss = 0.48785579204559326, train/raw-loss = 0.4502745270729065, train/logprobs = tensor([[-1.0018, -2.1273],
        [-2.1259, -1.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3758127987384796
Epoch 0, Step 1234: train/loss = 0.12519881129264832, train/raw-loss = 0.08077619969844818, train/logprobs = tensor([[-0.7227, -6.1751],
        [-2.5601, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44422611594200134
Epoch 0, Step 1235: train/loss = 0.32325005531311035, train/raw-loss = 0.2852238416671753, train/logprobs = tensor([[-0.8394, -5.9642],
        [-2.8781, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38026243448257446
Epoch 0, Step 1236: train/loss = 0.3380454480648041, train/raw-loss = 0.29755085706710815, train/logprobs = tensor([[-1.0554, -3.3111],
        [-3.1946, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049459397792816
Epoch 0, Step 1237: train/loss = 0.5957565903663635, train/raw-loss = 0.5373345017433167, train/logprobs = tensor([[-1.1514, -7.2720],
        [-4.0458, -3.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5842210054397583
Epoch 0, Step 1238: train/loss = 0.18046942353248596, train/raw-loss = 0.1339598447084427, train/logprobs = tensor([[-1.3585, -5.4343],
        [-3.1566, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4650956988334656
Epoch 0, Step 1239: train/loss = 0.5817334055900574, train/raw-loss = 0.5318202972412109, train/logprobs = tensor([[-0.8694, -1.7753],
        [-2.2947, -1.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4991319179534912
Epoch 0, Step 1240: train/loss = 0.6792069673538208, train/raw-loss = 0.640445351600647, train/logprobs = tensor([[-0.9276, -2.1995],
        [-1.7406, -2.0493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3876165747642517
Epoch 0, Step 1241: train/loss = 0.4864659905433655, train/raw-loss = 0.4438621401786804, train/logprobs = tensor([[-1.0270, -2.5545],
        [-2.1881, -1.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4260387420654297
Epoch 0, Step 1242: train/loss = 0.49038615822792053, train/raw-loss = 0.45253437757492065, train/logprobs = tensor([[-0.8550, -2.0111],
        [-3.3346, -1.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3785174489021301
Epoch 0, Step 1243: train/loss = 0.5934737920761108, train/raw-loss = 0.5519371628761292, train/logprobs = tensor([[-1.0435, -2.5309],
        [-2.2956, -2.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4153664708137512
Epoch 0, Step 1244: train/loss = 0.39098644256591797, train/raw-loss = 0.35060733556747437, train/logprobs = tensor([[-1.2080, -4.7767],
        [-2.6802, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4037911295890808
Epoch 0, Step 1245: train/loss = 0.11847572028636932, train/raw-loss = 0.06523118913173676, train/logprobs = tensor([[-1.1535, -7.8872],
        [-3.3025, -1.8601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5324453711509705
Epoch 0, Step 1246: train/loss = 0.15763284265995026, train/raw-loss = 0.1207275316119194, train/logprobs = tensor([[ -0.7505, -10.1561],
        [ -2.0403,  -2.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36905309557914734
Epoch 0, Step 1247: train/loss = 0.2351248562335968, train/raw-loss = 0.1843581646680832, train/logprobs = tensor([[-1.1206, -4.7130],
        [-3.8477, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.507667064666748
Epoch 0, Step 1248: train/loss = 0.09971427172422409, train/raw-loss = 0.057584162801504135, train/logprobs = tensor([[-1.1389, -9.5933],
        [-3.4142, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42130112648010254
Epoch 0, Step 1249: train/loss = 0.32984355092048645, train/raw-loss = 0.28490331768989563, train/logprobs = tensor([[-0.9466, -2.8240],
        [-2.4074, -1.2571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4494026005268097
Epoch 0, Step 1250: train/loss = 0.25762489438056946, train/raw-loss = 0.2091870903968811, train/logprobs = tensor([[-0.9301, -4.6038],
        [-2.7337, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48437783122062683
Epoch 0, Step 1251: train/loss = 0.34610453248023987, train/raw-loss = 0.2996179759502411, train/logprobs = tensor([[-0.8798, -6.3621],
        [-2.4258, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46486538648605347
Epoch 0, Step 1252: train/loss = 0.38033294677734375, train/raw-loss = 0.3369714021682739, train/logprobs = tensor([[-0.8054, -6.6153],
        [-2.2514, -1.5426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4336150288581848
Epoch 0, Step 1253: train/loss = 0.30667153000831604, train/raw-loss = 0.2617011070251465, train/logprobs = tensor([[-1.6628, -4.8415],
        [-2.6399, -1.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44970375299453735
Epoch 0, Step 1254: train/loss = 0.27374207973480225, train/raw-loss = 0.2315790355205536, train/logprobs = tensor([[-0.9175, -4.8756],
        [-3.6635, -1.7128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4216301441192627
Epoch 0, Step 1255: train/loss = 0.3022569715976715, train/raw-loss = 0.2561357617378235, train/logprobs = tensor([[-1.2594, -5.0573],
        [-2.6187, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4612120985984802
Epoch 0, Step 1256: train/loss = 0.5049303770065308, train/raw-loss = 0.46310845017433167, train/logprobs = tensor([[-1.0532, -1.4924],
        [-2.8632, -1.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41821983456611633
Epoch 0, Step 1257: train/loss = 0.31927427649497986, train/raw-loss = 0.2779397964477539, train/logprobs = tensor([[-0.9019, -4.6366],
        [-2.8281, -1.2991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4133448898792267
Epoch 0, Step 1258: train/loss = 0.3402089774608612, train/raw-loss = 0.29797548055648804, train/logprobs = tensor([[-1.0025, -4.1493],
        [-2.5641, -1.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4223354160785675
Epoch 0, Step 1259: train/loss = 0.4273217022418976, train/raw-loss = 0.38930758833885193, train/logprobs = tensor([[-0.9421, -3.6058],
        [-2.1880, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3801407516002655
Epoch 0, Step 1260: train/loss = 0.29020196199417114, train/raw-loss = 0.24208541214466095, train/logprobs = tensor([[-1.3986, -5.3742],
        [-3.7684, -1.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48116567730903625
Epoch 0, Step 1261: train/loss = 0.4295872747898102, train/raw-loss = 0.3860708475112915, train/logprobs = tensor([[-1.0702, -4.3660],
        [-2.3058, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43516433238983154
Epoch 0, Step 1262: train/loss = 0.4573080539703369, train/raw-loss = 0.40782928466796875, train/logprobs = tensor([[-0.7299, -4.2964],
        [-2.4374, -1.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4947880804538727
Epoch 0, Step 1263: train/loss = 0.5899900794029236, train/raw-loss = 0.5481370091438293, train/logprobs = tensor([[-0.7404, -2.8684],
        [-2.4241, -1.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4185298681259155
Epoch 0, Step 1264: train/loss = 0.5583488941192627, train/raw-loss = 0.5194835662841797, train/logprobs = tensor([[-1.1935, -2.5807],
        [-2.1973, -1.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38865312933921814
Epoch 0, Step 1265: train/loss = 0.46397459506988525, train/raw-loss = 0.4159252941608429, train/logprobs = tensor([[-0.9904, -2.7213],
        [-3.0582, -2.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48049306869506836
Epoch 0, Step 1266: train/loss = 0.30181169509887695, train/raw-loss = 0.2616128623485565, train/logprobs = tensor([[-0.9548, -6.7968],
        [-2.5301, -1.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40198808908462524
Epoch 0, Step 1267: train/loss = 0.23894569277763367, train/raw-loss = 0.2001500129699707, train/logprobs = tensor([[-1.1009, -6.3651],
        [-3.2227, -1.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879566788673401
Epoch 0, Step 1268: train/loss = 0.3002164661884308, train/raw-loss = 0.26616305112838745, train/logprobs = tensor([[-1.4661, -4.8305],
        [-2.6859, -1.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3405342102050781
Epoch 0, Step 1269: train/loss = 0.17240217328071594, train/raw-loss = 0.1331407129764557, train/logprobs = tensor([[ -1.0883, -10.3208],
        [ -2.9610,  -2.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3926146626472473
Epoch 0, Step 1270: train/loss = 0.4259374141693115, train/raw-loss = 0.38326123356819153, train/logprobs = tensor([[-1.3820, -6.8289],
        [-2.6516, -1.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4267618656158447
Epoch 0, Step 1271: train/loss = 0.4733789563179016, train/raw-loss = 0.43689435720443726, train/logprobs = tensor([[-2.0946, -3.9862],
        [-2.0711, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36484619975090027
Epoch 0, Step 1272: train/loss = 0.44756609201431274, train/raw-loss = 0.41256409883499146, train/logprobs = tensor([[-0.9894, -3.1701],
        [-1.9465, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3500201106071472
Epoch 0, Step 1273: train/loss = 0.5525214672088623, train/raw-loss = 0.5138505101203918, train/logprobs = tensor([[-0.7548, -2.3772],
        [-1.7087, -1.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3867095112800598
Epoch 0, Step 1274: train/loss = 0.12437573820352554, train/raw-loss = 0.08269187062978745, train/logprobs = tensor([[ -0.9453, -10.0684],
        [ -3.1033,  -2.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41683870553970337
Epoch 0, Step 1275: train/loss = 0.359308123588562, train/raw-loss = 0.31231534481048584, train/logprobs = tensor([[-0.7908, -2.8575],
        [-2.0384, -1.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46992745995521545
Epoch 0, Step 1276: train/loss = 0.4258993864059448, train/raw-loss = 0.37239351868629456, train/logprobs = tensor([[-1.0695, -4.0334],
        [-2.6474, -1.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5350587368011475
Epoch 0, Step 1277: train/loss = 0.5694405436515808, train/raw-loss = 0.5240036249160767, train/logprobs = tensor([[-1.3120, -4.3361],
        [-2.8476, -2.3700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4543690085411072
Epoch 0, Step 1278: train/loss = 0.24785061180591583, train/raw-loss = 0.20984041690826416, train/logprobs = tensor([[-1.0364, -9.2441],
        [-2.7309, -1.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38010191917419434
Epoch 0, Step 1279: train/loss = 0.5454391241073608, train/raw-loss = 0.49634963274002075, train/logprobs = tensor([[-1.1536, -2.6967],
        [-3.2551, -2.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49089568853378296
Epoch 0, Step 1280: train/loss = 0.22436916828155518, train/raw-loss = 0.17173327505588531, train/logprobs = tensor([[-1.4268, -4.7511],
        [-3.9120, -1.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5263590216636658
Epoch 0, Step 1281: train/loss = 0.22746138274669647, train/raw-loss = 0.18351323902606964, train/logprobs = tensor([[-1.0071, -5.2247],
        [-2.7593, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43948134779930115
Epoch 0, Step 1282: train/loss = 0.4781559109687805, train/raw-loss = 0.4377817213535309, train/logprobs = tensor([[-1.2372, -3.4417],
        [-3.4510, -1.0866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4037419557571411
Epoch 0, Step 1283: train/loss = 0.21612094342708588, train/raw-loss = 0.1721142828464508, train/logprobs = tensor([[-1.0361, -5.6725],
        [-2.4482, -0.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44006672501564026
Epoch 0, Step 1284: train/loss = 0.4482598900794983, train/raw-loss = 0.4112512171268463, train/logprobs = tensor([[-1.6995, -6.2348],
        [-2.5085, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37008699774742126
Epoch 0, Step 1285: train/loss = 0.6033458709716797, train/raw-loss = 0.5664991140365601, train/logprobs = tensor([[-0.4926, -1.5423],
        [-2.7989, -1.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36846745014190674
Epoch 0, Step 1286: train/loss = 0.16033749282360077, train/raw-loss = 0.11715748906135559, train/logprobs = tensor([[-0.8181, -8.3296],
        [-2.7661, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43179988861083984
Epoch 0, Step 1287: train/loss = 0.39962267875671387, train/raw-loss = 0.3664599657058716, train/logprobs = tensor([[-1.0330, -3.1688],
        [-2.2189, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331626832485199
Epoch 0, Step 1288: train/loss = 0.24975748360157013, train/raw-loss = 0.20482388138771057, train/logprobs = tensor([[-1.0216, -5.3998],
        [-2.6694, -1.1909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44933608174324036
Epoch 0, Step 1289: train/loss = 0.30578887462615967, train/raw-loss = 0.26661041378974915, train/logprobs = tensor([[-1.3032, -7.3645],
        [-2.5808, -1.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917846083641052
Epoch 0, Step 1290: train/loss = 0.41002723574638367, train/raw-loss = 0.3693617582321167, train/logprobs = tensor([[-0.8674, -3.2484],
        [-2.2273, -1.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40665510296821594
Epoch 0, Step 1291: train/loss = 0.3128581643104553, train/raw-loss = 0.26383280754089355, train/logprobs = tensor([[-1.0026, -4.1236],
        [-3.1714, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4902537167072296
Epoch 0, Step 1292: train/loss = 0.24157822132110596, train/raw-loss = 0.20531433820724487, train/logprobs = tensor([[-1.4423, -8.6819],
        [-2.9268, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3626387119293213
Epoch 0, Step 1293: train/loss = 0.4464913010597229, train/raw-loss = 0.403797447681427, train/logprobs = tensor([[-0.7627, -6.4981],
        [-2.0599, -1.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42693808674812317
Epoch 0, Step 1294: train/loss = 0.1723015457391739, train/raw-loss = 0.12847645580768585, train/logprobs = tensor([[-0.9010, -7.6347],
        [-3.0241, -1.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.438250869512558
Epoch 0, Step 1295: train/loss = 0.849065899848938, train/raw-loss = 0.8056964874267578, train/logprobs = tensor([[-1.4006, -1.5459],
        [-1.6721, -1.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43369361758232117
Epoch 0, Step 1296: train/loss = 0.43118754029273987, train/raw-loss = 0.39239656925201416, train/logprobs = tensor([[-1.7434, -3.6881],
        [-3.0404, -1.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879097104072571
Epoch 0, Step 1297: train/loss = 0.4719949960708618, train/raw-loss = 0.4310450553894043, train/logprobs = tensor([[-0.7553, -3.8468],
        [-2.3611, -1.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40949928760528564
Epoch 0, Step 1298: train/loss = 0.5145500302314758, train/raw-loss = 0.4675101935863495, train/logprobs = tensor([[-0.9517, -2.2709],
        [-2.5464, -1.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47039809823036194
Epoch 0, Step 1299: train/loss = 0.46108245849609375, train/raw-loss = 0.4188140034675598, train/logprobs = tensor([[-1.0481, -6.8079],
        [-2.8039, -1.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4226844906806946
Epoch 0, Step 1300: train/loss = 0.36991554498672485, train/raw-loss = 0.32644909620285034, train/logprobs = tensor([[-0.9703, -3.3444],
        [-2.8500, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43466413021087646
Epoch 0, Step 1301: train/loss = 0.3373785614967346, train/raw-loss = 0.29457443952560425, train/logprobs = tensor([[-0.8210, -3.5379],
        [-2.2357, -1.2670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4280409812927246
Epoch 0, Step 1302: train/loss = 0.617841362953186, train/raw-loss = 0.5783514976501465, train/logprobs = tensor([[-0.9180, -1.9576],
        [-2.0488, -2.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3948984742164612
Epoch 0, Step 1303: train/loss = 0.42641255259513855, train/raw-loss = 0.3843238353729248, train/logprobs = tensor([[-0.9892, -6.3647],
        [-2.0360, -1.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4208870232105255
Epoch 0, Step 1304: train/loss = 0.43042853474617004, train/raw-loss = 0.38869374990463257, train/logprobs = tensor([[-1.8439, -3.2954],
        [-3.5838, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41734808683395386
Epoch 0, Step 1305: train/loss = 0.35618093609809875, train/raw-loss = 0.3158247768878937, train/logprobs = tensor([[-0.9744, -4.3394],
        [-2.1472, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40356189012527466
Epoch 0, Step 1306: train/loss = 0.48629122972488403, train/raw-loss = 0.4413420557975769, train/logprobs = tensor([[-0.9115, -2.3030],
        [-2.9761, -1.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.449491947889328
Epoch 0, Step 1307: train/loss = 0.5203309059143066, train/raw-loss = 0.4874480366706848, train/logprobs = tensor([[-0.6565, -3.6402],
        [-1.4633, -1.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32882797718048096
Epoch 0, Step 1308: train/loss = 0.4390380382537842, train/raw-loss = 0.4043753743171692, train/logprobs = tensor([[-0.7677, -1.5676],
        [-1.8532, -0.5694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34662672877311707
Epoch 0, Step 1309: train/loss = 0.44922226667404175, train/raw-loss = 0.4072459936141968, train/logprobs = tensor([[-0.8172, -2.8432],
        [-2.4395, -1.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41976243257522583
Epoch 0, Step 1310: train/loss = 0.2341754287481308, train/raw-loss = 0.18721485137939453, train/logprobs = tensor([[-1.0805, -9.6089],
        [-3.3204, -1.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4696057438850403
Epoch 0, Step 1311: train/loss = 0.5131601691246033, train/raw-loss = 0.47004610300064087, train/logprobs = tensor([[-0.6869, -2.7494],
        [-2.0267, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4311409592628479
Epoch 0, Step 1312: train/loss = 0.30103227496147156, train/raw-loss = 0.26049208641052246, train/logprobs = tensor([[-1.1757, -4.8231],
        [-2.5031, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4054018259048462
Epoch 0, Step 1313: train/loss = 0.30692413449287415, train/raw-loss = 0.2672773599624634, train/logprobs = tensor([[-1.0766, -5.2000],
        [-2.3533, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3964675962924957
Epoch 0, Step 1314: train/loss = 0.6716852188110352, train/raw-loss = 0.6351065635681152, train/logprobs = tensor([[-1.3051, -2.9916],
        [-1.9427, -1.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36578649282455444
Epoch 0, Step 1315: train/loss = 0.3453502655029297, train/raw-loss = 0.30484047532081604, train/logprobs = tensor([[-0.8240, -4.3102],
        [-2.0542, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40509772300720215
Epoch 0, Step 1316: train/loss = 0.4386465549468994, train/raw-loss = 0.40194976329803467, train/logprobs = tensor([[-1.0703, -3.8833],
        [-1.7778, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669675588607788
Epoch 0, Step 1317: train/loss = 0.4544990658760071, train/raw-loss = 0.41484639048576355, train/logprobs = tensor([[-1.1856, -3.1745],
        [-2.2977, -1.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965267837047577
Epoch 0, Step 1318: train/loss = 0.26046863198280334, train/raw-loss = 0.21574078500270844, train/logprobs = tensor([[-0.8903, -8.0478],
        [-2.5174, -0.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44727829098701477
Epoch 0, Step 1319: train/loss = 0.2584766149520874, train/raw-loss = 0.21769292652606964, train/logprobs = tensor([[-0.8965, -5.6826],
        [-2.7911, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40783706307411194
Epoch 0, Step 1320: train/loss = 0.3179054260253906, train/raw-loss = 0.2785928249359131, train/logprobs = tensor([[-0.9043, -4.2306],
        [-2.3277, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931259214878082
Epoch 0, Step 1321: train/loss = 0.41833555698394775, train/raw-loss = 0.3793841004371643, train/logprobs = tensor([[-0.9523, -1.8293],
        [-2.2635, -1.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38951414823532104
Epoch 0, Step 1322: train/loss = 0.5009552836418152, train/raw-loss = 0.46216535568237305, train/logprobs = tensor([[-0.7989, -3.2693],
        [-1.9193, -1.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3878997564315796
Epoch 0, Step 1323: train/loss = 0.46748650074005127, train/raw-loss = 0.4343947768211365, train/logprobs = tensor([[-0.9238, -1.3586],
        [-2.3035, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33091720938682556
Epoch 0, Step 1324: train/loss = 0.175442174077034, train/raw-loss = 0.14002619683742523, train/logprobs = tensor([[ -1.0206, -12.7686],
        [ -2.3520,  -1.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35415971279144287
Epoch 0, Step 1325: train/loss = 0.4093487858772278, train/raw-loss = 0.36395424604415894, train/logprobs = tensor([[-1.0240, -2.2011],
        [-2.1715, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45394501090049744
Epoch 0, Step 1326: train/loss = 0.38487493991851807, train/raw-loss = 0.3549329936504364, train/logprobs = tensor([[-1.8492, -4.3988],
        [-2.0865, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994195818901062
Epoch 0, Step 1327: train/loss = 0.4494004249572754, train/raw-loss = 0.4116055965423584, train/logprobs = tensor([[-0.8934, -5.7221],
        [-1.5547, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37794816493988037
Epoch 0, Step 1328: train/loss = 0.2972976267337799, train/raw-loss = 0.2572798728942871, train/logprobs = tensor([[-0.9812, -4.6465],
        [-2.1449, -1.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4001776874065399
Epoch 0, Step 1329: train/loss = 0.40855535864830017, train/raw-loss = 0.3707275390625, train/logprobs = tensor([[-1.0511, -3.5539],
        [-1.6904, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782781958580017
Epoch 0, Step 1330: train/loss = 0.36274683475494385, train/raw-loss = 0.3275447487831116, train/logprobs = tensor([[-0.8723, -3.9237],
        [-1.8761, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3520210087299347
Epoch 0, Step 1331: train/loss = 0.2693099081516266, train/raw-loss = 0.22289212048053741, train/logprobs = tensor([[-1.1013, -3.6349],
        [-2.0925, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46417781710624695
Epoch 0, Step 1332: train/loss = 0.41910144686698914, train/raw-loss = 0.38105762004852295, train/logprobs = tensor([[-1.3526, -1.9529],
        [-2.2144, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3804379999637604
Epoch 0, Step 1333: train/loss = 0.36411768198013306, train/raw-loss = 0.32724329829216003, train/logprobs = tensor([[-2.0462, -6.3439],
        [-2.8196, -1.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3687438368797302
Epoch 0, Step 1334: train/loss = 0.6032021045684814, train/raw-loss = 0.573262095451355, train/logprobs = tensor([[-0.9224, -0.5719],
        [-1.8773, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994001507759094
Epoch 0, Step 1335: train/loss = 0.4797358810901642, train/raw-loss = 0.4487474858760834, train/logprobs = tensor([[-2.3434, -7.5453],
        [-1.7818, -1.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30988407135009766
Epoch 0, Step 1336: train/loss = 0.42757174372673035, train/raw-loss = 0.39834633469581604, train/logprobs = tensor([[-0.7334, -7.0929],
        [-1.4844, -0.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29225394129753113
Epoch 0, Step 1337: train/loss = 0.31528544425964355, train/raw-loss = 0.27489128708839417, train/logprobs = tensor([[-1.1924, -7.9841],
        [-2.4753, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40394145250320435
Epoch 0, Step 1338: train/loss = 0.26748690009117126, train/raw-loss = 0.22556988894939423, train/logprobs = tensor([[-0.9587, -7.5525],
        [-2.1634, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4191700518131256
Epoch 0, Step 1339: train/loss = 0.4146049916744232, train/raw-loss = 0.37407538294792175, train/logprobs = tensor([[-1.0057, -3.7473],
        [-1.8193, -1.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40529611706733704
Epoch 0, Step 1340: train/loss = 0.5702899098396301, train/raw-loss = 0.5315542221069336, train/logprobs = tensor([[-1.5462, -5.4825],
        [-1.9761, -1.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873569071292877
Epoch 0, Step 1341: train/loss = 0.3199905455112457, train/raw-loss = 0.2818944752216339, train/logprobs = tensor([[-0.9056, -8.2524],
        [-2.1789, -1.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38096070289611816
Epoch 0, Step 1342: train/loss = 0.6068025827407837, train/raw-loss = 0.5668160319328308, train/logprobs = tensor([[-1.3093, -4.6318],
        [-2.0074, -1.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39986586570739746
Epoch 0, Step 1343: train/loss = 0.4762117266654968, train/raw-loss = 0.42978787422180176, train/logprobs = tensor([[-1.2577, -2.9746],
        [-1.9258, -1.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4642382860183716
Epoch 0, Step 1344: train/loss = 0.2901809811592102, train/raw-loss = 0.25224339962005615, train/logprobs = tensor([[-1.1579, -5.2909],
        [-2.4484, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793758749961853
Epoch 0, Step 1345: train/loss = 0.1956590712070465, train/raw-loss = 0.16125909984111786, train/logprobs = tensor([[ -1.1513, -10.9959],
        [ -2.1481,  -1.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3439997136592865
Epoch 0, Step 1346: train/loss = 0.2953885793685913, train/raw-loss = 0.26320680975914, train/logprobs = tensor([[ -1.4595, -12.5479],
        [ -2.0543,  -1.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218178451061249
Epoch 0, Step 1347: train/loss = 0.3427228033542633, train/raw-loss = 0.30126264691352844, train/logprobs = tensor([[-1.0418, -7.5515],
        [-2.0015, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4146016240119934
Epoch 0, Step 1348: train/loss = 0.4115765690803528, train/raw-loss = 0.3648224472999573, train/logprobs = tensor([[-0.6731, -3.9230],
        [-1.6598, -1.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4675416350364685
Epoch 0, Step 1349: train/loss = 0.4022783637046814, train/raw-loss = 0.3639061152935028, train/logprobs = tensor([[-0.8422, -4.6375],
        [-2.1269, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3837222456932068
Epoch 0, Step 1350: train/loss = 0.3079225420951843, train/raw-loss = 0.2805774211883545, train/logprobs = tensor([[-0.8780, -4.1261],
        [-1.3103, -1.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734512686729431
Epoch 0, Step 1351: train/loss = 0.30169302225112915, train/raw-loss = 0.25909319519996643, train/logprobs = tensor([[-1.2723, -6.2223],
        [-2.7852, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4259982109069824
Epoch 0, Step 1352: train/loss = 0.5922268033027649, train/raw-loss = 0.5607683658599854, train/logprobs = tensor([[-0.8499, -1.4745],
        [-1.6295, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145838975906372
Epoch 0, Step 1353: train/loss = 0.4263596832752228, train/raw-loss = 0.38967829942703247, train/logprobs = tensor([[-1.6456, -9.2423],
        [-1.6472, -1.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36681389808654785
Epoch 0, Step 1354: train/loss = 0.4118400812149048, train/raw-loss = 0.369393527507782, train/logprobs = tensor([[-0.6331, -5.6722],
        [-1.5908, -1.3629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42446500062942505
Epoch 0, Step 1355: train/loss = 0.4245840609073639, train/raw-loss = 0.38299065828323364, train/logprobs = tensor([[-1.0332, -3.4685],
        [-1.9379, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4159337878227234
Epoch 0, Step 1356: train/loss = 0.4627031087875366, train/raw-loss = 0.43677428364753723, train/logprobs = tensor([[-1.6637, -9.2012],
        [-1.1298, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592882215976715
Epoch 0, Step 1357: train/loss = 0.47342973947525024, train/raw-loss = 0.43324264883995056, train/logprobs = tensor([[-0.9533, -3.3727],
        [-1.7031, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4018707871437073
Epoch 0, Step 1358: train/loss = 0.44311895966529846, train/raw-loss = 0.39784204959869385, train/logprobs = tensor([[-1.0471, -2.7554],
        [-2.0016, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4527691900730133
Epoch 0, Step 1359: train/loss = 0.3040960431098938, train/raw-loss = 0.2667973041534424, train/logprobs = tensor([[-1.1698, -5.7183],
        [-2.2821, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729872405529022
Epoch 0, Step 1360: train/loss = 0.4538846015930176, train/raw-loss = 0.418903112411499, train/logprobs = tensor([[-0.8662, -1.8189],
        [-1.6523, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34981492161750793
Epoch 0, Step 1361: train/loss = 0.6121854186058044, train/raw-loss = 0.5775009393692017, train/logprobs = tensor([[-1.0275, -1.5958],
        [-1.8051, -1.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468446731567383
Epoch 0, Step 1362: train/loss = 0.22402425110340118, train/raw-loss = 0.1892833709716797, train/logprobs = tensor([[ -1.4510, -10.2270],
        [ -2.2726,  -0.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474086821079254
Epoch 0, Step 1363: train/loss = 0.41955798864364624, train/raw-loss = 0.376261830329895, train/logprobs = tensor([[-1.0839, -3.3087],
        [-1.8217, -1.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43296122550964355
Epoch 0, Step 1364: train/loss = 0.5293579697608948, train/raw-loss = 0.4891242980957031, train/logprobs = tensor([[-1.3122, -5.0884],
        [-1.7330, -1.4589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40233659744262695
Epoch 0, Step 1365: train/loss = 0.6992520093917847, train/raw-loss = 0.6592227220535278, train/logprobs = tensor([[-1.0185, -1.1476],
        [-1.7952, -1.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40029242634773254
Epoch 0, Step 1366: train/loss = 0.3822568655014038, train/raw-loss = 0.3489200472831726, train/logprobs = tensor([[-1.0329, -4.3996],
        [-2.1783, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333682417869568
Epoch 0, Step 1367: train/loss = 0.878222644329071, train/raw-loss = 0.8314332365989685, train/logprobs = tensor([[-2.0635, -4.0570],
        [-1.4041, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678942561149597
Epoch 0, Step 1368: train/loss = 0.38657069206237793, train/raw-loss = 0.3423720896244049, train/logprobs = tensor([[-1.1812, -5.4288],
        [-2.6703, -1.3838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4419859051704407
Epoch 0, Step 1369: train/loss = 0.8396613001823425, train/raw-loss = 0.8007930517196655, train/logprobs = tensor([[-1.2302, -1.4145],
        [-1.4744, -1.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38868248462677
Epoch 0, Step 1370: train/loss = 0.2535242438316345, train/raw-loss = 0.21430489420890808, train/logprobs = tensor([[-1.4010, -5.6745],
        [-2.6776, -1.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39219364523887634
Epoch 0, Step 1371: train/loss = 0.40080490708351135, train/raw-loss = 0.3653101325035095, train/logprobs = tensor([[-1.8137, -4.9861],
        [-2.2480, -1.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35494768619537354
Epoch 0, Step 1372: train/loss = 0.30586257576942444, train/raw-loss = 0.2605935037136078, train/logprobs = tensor([[-1.0459, -5.9373],
        [-2.3260, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4526909291744232
Epoch 0, Step 1373: train/loss = 0.36815184354782104, train/raw-loss = 0.33089762926101685, train/logprobs = tensor([[-1.2099, -6.3311],
        [-1.5576, -0.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37254196405410767
Epoch 0, Step 1374: train/loss = 0.45791536569595337, train/raw-loss = 0.4196505546569824, train/logprobs = tensor([[-1.0886, -5.3274],
        [-1.8721, -1.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38264816999435425
Epoch 0, Step 1375: train/loss = 0.356697678565979, train/raw-loss = 0.31263667345046997, train/logprobs = tensor([[-1.0399, -2.8517],
        [-2.1050, -1.2086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44061005115509033
Epoch 0, Step 1376: train/loss = 0.525243878364563, train/raw-loss = 0.4917798638343811, train/logprobs = tensor([[-0.8155, -0.9677],
        [-1.6253, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346402049064636
Epoch 0, Step 1377: train/loss = 0.3387960195541382, train/raw-loss = 0.3033508360385895, train/logprobs = tensor([[-1.1958, -4.0508],
        [-2.2092, -1.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35445165634155273
Epoch 0, Step 1378: train/loss = 0.45051974058151245, train/raw-loss = 0.41278189420700073, train/logprobs = tensor([[-1.8832, -6.0710],
        [-1.9582, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37737855315208435
Epoch 0, Step 1379: train/loss = 0.27468961477279663, train/raw-loss = 0.23321974277496338, train/logprobs = tensor([[-1.2515, -6.8172],
        [-2.9637, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41469869017601013
Epoch 0, Step 1380: train/loss = 0.33121031522750854, train/raw-loss = 0.2962445020675659, train/logprobs = tensor([[ -1.5787, -12.3392],
        [ -2.2952,  -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496577739715576
Epoch 0, Step 1381: train/loss = 0.36857128143310547, train/raw-loss = 0.3316885828971863, train/logprobs = tensor([[-1.0695, -5.9657],
        [-1.8796, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36882704496383667
Epoch 0, Step 1382: train/loss = 0.13144530355930328, train/raw-loss = 0.08617133647203445, train/logprobs = tensor([[ -1.1297, -10.1920],
        [ -3.1291,  -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4527396559715271
Epoch 0, Step 1383: train/loss = 0.5114992260932922, train/raw-loss = 0.47293388843536377, train/logprobs = tensor([[-0.9043, -2.1773],
        [-1.6547, -1.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38565343618392944
Epoch 0, Step 1384: train/loss = 0.2688376307487488, train/raw-loss = 0.2272709608078003, train/logprobs = tensor([[-1.8722, -4.7284],
        [-3.2738, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4156668186187744
Epoch 0, Step 1385: train/loss = 0.3188704252243042, train/raw-loss = 0.2769157290458679, train/logprobs = tensor([[-1.0508, -8.3681],
        [-1.7620, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41954731941223145
Epoch 0, Step 1386: train/loss = 0.31482622027397156, train/raw-loss = 0.2624931335449219, train/logprobs = tensor([[-0.8524, -6.7685],
        [-2.3391, -1.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5233306288719177
Epoch 0, Step 1387: train/loss = 0.3127685785293579, train/raw-loss = 0.2714807391166687, train/logprobs = tensor([[-1.0489, -4.5492],
        [-2.6605, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4128786325454712
Epoch 0, Step 1388: train/loss = 0.5762546062469482, train/raw-loss = 0.5335878729820251, train/logprobs = tensor([[-1.0910, -2.2699],
        [-1.8884, -1.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4266677498817444
Epoch 0, Step 1389: train/loss = 0.6158793568611145, train/raw-loss = 0.5789830684661865, train/logprobs = tensor([[-1.5708, -2.7006],
        [-1.7524, -1.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36896321177482605
Epoch 0, Step 1390: train/loss = 0.24105486273765564, train/raw-loss = 0.2021060734987259, train/logprobs = tensor([[ -1.2738, -10.2242],
        [ -2.5530,  -1.2428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894878029823303
Epoch 0, Step 1391: train/loss = 0.3646288514137268, train/raw-loss = 0.32623520493507385, train/logprobs = tensor([[-0.9516, -7.1773],
        [-2.1323, -1.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38393646478652954
Epoch 0, Step 1392: train/loss = 0.1644958108663559, train/raw-loss = 0.11894994229078293, train/logprobs = tensor([[ -1.0547, -10.3594],
        [ -2.4786,  -2.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4554586708545685
Epoch 0, Step 1393: train/loss = 0.5837225317955017, train/raw-loss = 0.5486592054367065, train/logprobs = tensor([[-0.8214, -1.5362],
        [-1.5540, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35063332319259644
Epoch 0, Step 1394: train/loss = 0.674481213092804, train/raw-loss = 0.6470819711685181, train/logprobs = tensor([[-1.5862, -3.7528],
        [-0.8637, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739926278591156
Epoch 0, Step 1395: train/loss = 0.29153987765312195, train/raw-loss = 0.25654226541519165, train/logprobs = tensor([[-1.0491, -5.8622],
        [-1.6053, -1.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3499763309955597
Epoch 0, Step 1396: train/loss = 0.3360441327095032, train/raw-loss = 0.3000560998916626, train/logprobs = tensor([[-1.5821, -7.5753],
        [-2.2504, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.359880656003952
Epoch 0, Step 1397: train/loss = 0.5151846408843994, train/raw-loss = 0.47763001918792725, train/logprobs = tensor([[-0.8566, -3.3180],
        [-1.4308, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37554651498794556
Epoch 0, Step 1398: train/loss = 0.3850795030593872, train/raw-loss = 0.3547351062297821, train/logprobs = tensor([[-1.3546, -3.0469],
        [-1.6397, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30344367027282715
Epoch 0, Step 1399: train/loss = 0.3780099153518677, train/raw-loss = 0.34449005126953125, train/logprobs = tensor([[-1.0600, -3.2459],
        [-1.8747, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351985216140747
Epoch 0, Step 1400: train/loss = 0.16235515475273132, train/raw-loss = 0.12142912298440933, train/logprobs = tensor([[-1.2840, -4.3197],
        [-3.3456, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40926027297973633
Epoch 0, Step 1401: train/loss = 0.6576148271560669, train/raw-loss = 0.6186858415603638, train/logprobs = tensor([[-1.0403, -1.5680],
        [-1.5657, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.389289915561676
Epoch 0, Step 1402: train/loss = 0.31955966353416443, train/raw-loss = 0.28357720375061035, train/logprobs = tensor([[-0.8963, -8.9080],
        [-1.8226, -1.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598247766494751
Epoch 0, Step 1403: train/loss = 0.3719160556793213, train/raw-loss = 0.33359837532043457, train/logprobs = tensor([[-0.9945, -8.5867],
        [-1.9436, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383176326751709
Epoch 0, Step 1404: train/loss = 0.50589519739151, train/raw-loss = 0.4632420837879181, train/logprobs = tensor([[-0.9122, -3.5767],
        [-1.7952, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4265313148498535
Epoch 0, Step 1405: train/loss = 0.36725375056266785, train/raw-loss = 0.33390969038009644, train/logprobs = tensor([[-1.0230, -5.4239],
        [-1.2624, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334408700466156
Epoch 0, Step 1406: train/loss = 0.31111952662467957, train/raw-loss = 0.26671263575553894, train/logprobs = tensor([[-1.0616, -4.1363],
        [-1.9528, -0.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44406890869140625
Epoch 0, Step 1407: train/loss = 0.6639482378959656, train/raw-loss = 0.6283597350120544, train/logprobs = tensor([[-0.9979, -1.2845],
        [-1.3981, -1.3900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35588493943214417
Epoch 0, Step 1408: train/loss = 0.8364533185958862, train/raw-loss = 0.7971889972686768, train/logprobs = tensor([[-2.1312, -5.2458],
        [-1.1782, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3926433324813843
Epoch 0, Step 1409: train/loss = 0.4426228404045105, train/raw-loss = 0.41237127780914307, train/logprobs = tensor([[-1.0480, -9.7514],
        [-1.5462, -1.2086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30251544713974
Epoch 0, Step 1410: train/loss = 0.4077932834625244, train/raw-loss = 0.3702136278152466, train/logprobs = tensor([[-1.1337, -6.6428],
        [-1.3826, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.375796377658844
Epoch 0, Step 1411: train/loss = 0.517499566078186, train/raw-loss = 0.4877466857433319, train/logprobs = tensor([[-2.0843, -7.5215],
        [-1.5063, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29752910137176514
Epoch 0, Step 1412: train/loss = 0.5292150378227234, train/raw-loss = 0.49062591791152954, train/logprobs = tensor([[-1.1053, -1.8042],
        [-1.6719, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858911395072937
Epoch 0, Step 1413: train/loss = 0.5348271727561951, train/raw-loss = 0.4964974522590637, train/logprobs = tensor([[-1.3434, -1.6072],
        [-2.1047, -1.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383297324180603
Epoch 0, Step 1414: train/loss = 0.24178341031074524, train/raw-loss = 0.20241251587867737, train/logprobs = tensor([[-1.1722, -8.6656],
        [-1.9550, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39370882511138916
Epoch 0, Step 1415: train/loss = 0.18752186000347137, train/raw-loss = 0.1465369015932083, train/logprobs = tensor([[-1.9722, -9.4399],
        [-3.1894, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4098496437072754
Epoch 0, Step 1416: train/loss = 0.6805359125137329, train/raw-loss = 0.6427938938140869, train/logprobs = tensor([[-1.7014, -4.9865],
        [-1.5716, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.377420037984848
Epoch 0, Step 1417: train/loss = 0.21229316294193268, train/raw-loss = 0.17201590538024902, train/logprobs = tensor([[-1.0648, -8.8585],
        [-2.5967, -1.3841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40277260541915894
Epoch 0, Step 1418: train/loss = 0.29988518357276917, train/raw-loss = 0.25748586654663086, train/logprobs = tensor([[-1.1642, -4.5720],
        [-2.0788, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42399320006370544
Epoch 0, Step 1419: train/loss = 0.3125697076320648, train/raw-loss = 0.27207908034324646, train/logprobs = tensor([[ -1.0116, -11.3764],
        [ -2.2587,  -2.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049058258533478
Epoch 0, Step 1420: train/loss = 0.33412790298461914, train/raw-loss = 0.30273085832595825, train/logprobs = tensor([[-1.7676, -5.9350],
        [-1.7537, -0.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31397050619125366
Epoch 0, Step 1421: train/loss = 0.3152611255645752, train/raw-loss = 0.28069037199020386, train/logprobs = tensor([[-1.2683, -4.8621],
        [-1.6725, -0.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457079231739044
Epoch 0, Step 1422: train/loss = 0.3109525740146637, train/raw-loss = 0.27134838700294495, train/logprobs = tensor([[-1.0692, -6.3171],
        [-2.0682, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3960415720939636
Epoch 0, Step 1423: train/loss = 0.9304067492485046, train/raw-loss = 0.8929380178451538, train/logprobs = tensor([[-4.0625, -5.2190],
        [-1.9708, -0.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3746872544288635
Epoch 0, Step 1424: train/loss = 0.3035757541656494, train/raw-loss = 0.2677752375602722, train/logprobs = tensor([[-1.1250, -6.0027],
        [-2.0658, -0.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580054044723511
Epoch 0, Step 1425: train/loss = 0.38415324687957764, train/raw-loss = 0.35369420051574707, train/logprobs = tensor([[ -1.5969, -11.2418],
        [ -1.7508,  -0.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30459076166152954
Epoch 0, Step 1426: train/loss = 0.3799886703491211, train/raw-loss = 0.34294450283050537, train/logprobs = tensor([[-1.0645, -3.8134],
        [-1.7716, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3704414963722229
Epoch 0, Step 1427: train/loss = 0.4892008602619171, train/raw-loss = 0.44120699167251587, train/logprobs = tensor([[-1.0860, -2.3991],
        [-2.2987, -2.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4799385666847229
Epoch 0, Step 1428: train/loss = 0.4187857508659363, train/raw-loss = 0.37626269459724426, train/logprobs = tensor([[-1.9695, -7.9813],
        [-2.8077, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4252300560474396
Epoch 0, Step 1429: train/loss = 0.16693980991840363, train/raw-loss = 0.12883031368255615, train/logprobs = tensor([[-0.8042, -8.6264],
        [-1.9463, -0.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.381094753742218
Epoch 0, Step 1430: train/loss = 0.33795952796936035, train/raw-loss = 0.3003332316875458, train/logprobs = tensor([[ -1.4927, -10.7694],
        [ -1.9019,  -0.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762631416320801
Epoch 0, Step 1431: train/loss = 0.46359771490097046, train/raw-loss = 0.42644715309143066, train/logprobs = tensor([[-1.2317, -6.2828],
        [-1.7163, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37150588631629944
Epoch 0, Step 1432: train/loss = 0.28154468536376953, train/raw-loss = 0.24310509860515594, train/logprobs = tensor([[-1.7507, -9.7679],
        [-2.9316, -2.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3843958377838135
Epoch 0, Step 1433: train/loss = 0.35137027502059937, train/raw-loss = 0.3103228807449341, train/logprobs = tensor([[-1.0914, -4.6662],
        [-1.5431, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41047388315200806
Epoch 0, Step 1434: train/loss = 0.7029246687889099, train/raw-loss = 0.6659486293792725, train/logprobs = tensor([[-0.9532, -1.3064],
        [-1.2601, -1.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36976000666618347
Epoch 0, Step 1435: train/loss = 0.3700215220451355, train/raw-loss = 0.33434006571769714, train/logprobs = tensor([[-1.1385, -4.2733],
        [-1.8288, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568146526813507
Epoch 0, Step 1436: train/loss = 0.8246575593948364, train/raw-loss = 0.7875807285308838, train/logprobs = tensor([[-3.1814, -8.1427],
        [-2.0290, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3707682490348816
Epoch 0, Step 1437: train/loss = 0.5072141289710999, train/raw-loss = 0.4702130854129791, train/logprobs = tensor([[-1.8096, -4.3253],
        [-1.4418, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3700104355812073
Epoch 0, Step 1438: train/loss = 0.49071523547172546, train/raw-loss = 0.44415774941444397, train/logprobs = tensor([[-0.8778, -1.8057],
        [-2.0086, -1.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46557506918907166
Epoch 0, Step 1439: train/loss = 0.2986295223236084, train/raw-loss = 0.2547745704650879, train/logprobs = tensor([[ -2.5680, -12.0962],
        [ -2.7686,  -1.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4385495185852051
Epoch 0, Step 1440: train/loss = 0.3821020722389221, train/raw-loss = 0.33483603596687317, train/logprobs = tensor([[-1.0500, -5.4682],
        [-2.6836, -2.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4726598560810089
Epoch 0, Step 1441: train/loss = 0.24946311116218567, train/raw-loss = 0.20172792673110962, train/logprobs = tensor([[-1.1861, -8.0376],
        [-3.2007, -1.1053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4773517847061157
Epoch 0, Step 1442: train/loss = 0.3718922436237335, train/raw-loss = 0.3335770070552826, train/logprobs = tensor([[-1.3298, -3.8518],
        [-2.0612, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38315218687057495
Epoch 0, Step 1443: train/loss = 0.314089298248291, train/raw-loss = 0.2766813337802887, train/logprobs = tensor([[-1.5430, -5.3534],
        [-2.1273, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37407928705215454
Epoch 0, Step 1444: train/loss = 0.4391286075115204, train/raw-loss = 0.3982400894165039, train/logprobs = tensor([[-1.4869, -7.3152],
        [-1.9315, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40888506174087524
Epoch 0, Step 1445: train/loss = 0.3084114193916321, train/raw-loss = 0.26336270570755005, train/logprobs = tensor([[-1.8067, -8.0719],
        [-2.4592, -1.3051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45048725605010986
Epoch 0, Step 1446: train/loss = 0.27601754665374756, train/raw-loss = 0.24426676332950592, train/logprobs = tensor([[ -0.9159, -13.0570],
        [ -1.5634,  -1.5295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175078332424164
Epoch 0, Step 1447: train/loss = 0.3407447934150696, train/raw-loss = 0.29989951848983765, train/logprobs = tensor([[-1.7361, -8.7902],
        [-2.2618, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084526598453522
Epoch 0, Step 1448: train/loss = 0.30882295966148376, train/raw-loss = 0.25356966257095337, train/logprobs = tensor([[-1.1966, -9.0805],
        [-3.4807, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.552532970905304
Epoch 0, Step 1449: train/loss = 0.2834809124469757, train/raw-loss = 0.24658983945846558, train/logprobs = tensor([[ -1.3204, -15.4141],
        [ -2.2262,  -2.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36891090869903564
Epoch 0, Step 1450: train/loss = 0.4899457097053528, train/raw-loss = 0.4502926468849182, train/logprobs = tensor([[-1.0338, -2.2998],
        [-1.8572, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965304493904114
Epoch 0, Step 1451: train/loss = 0.3979640007019043, train/raw-loss = 0.3678863048553467, train/logprobs = tensor([[-0.9779, -4.4107],
        [-1.3459, -0.7793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007766902446747
Epoch 0, Step 1452: train/loss = 0.30899280309677124, train/raw-loss = 0.2665387690067291, train/logprobs = tensor([[-1.4007, -7.0247],
        [-2.4181, -0.7312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4245401620864868
Epoch 0, Step 1453: train/loss = 0.3278975486755371, train/raw-loss = 0.29194876551628113, train/logprobs = tensor([[ -1.9336, -10.0548],
        [ -2.2585,  -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35948753356933594
Epoch 0, Step 1454: train/loss = 0.4054582715034485, train/raw-loss = 0.3682711124420166, train/logprobs = tensor([[-0.6449, -4.3628],
        [-1.4231, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.371871680021286
Epoch 0, Step 1455: train/loss = 0.41922527551651, train/raw-loss = 0.38080525398254395, train/logprobs = tensor([[-1.8568, -7.3093],
        [-1.8482, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38420021533966064
Epoch 0, Step 1456: train/loss = 0.340553879737854, train/raw-loss = 0.3034617304801941, train/logprobs = tensor([[-1.1609, -7.0054],
        [-1.6815, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37092193961143494
Epoch 0, Step 1457: train/loss = 0.7273700833320618, train/raw-loss = 0.6905618906021118, train/logprobs = tensor([[ -3.5194, -10.2158],
        [ -2.2839,  -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680817782878876
Epoch 0, Step 1458: train/loss = 0.4881025552749634, train/raw-loss = 0.4542050361633301, train/logprobs = tensor([[-2.5643, -8.8414],
        [-2.2677, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3389752209186554
Epoch 0, Step 1459: train/loss = 0.42581236362457275, train/raw-loss = 0.39539092779159546, train/logprobs = tensor([[-1.1255, -3.9892],
        [-1.2318, -0.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3042144775390625
Epoch 0, Step 1460: train/loss = 0.618342399597168, train/raw-loss = 0.5866678357124329, train/logprobs = tensor([[-1.4742, -3.6313],
        [-1.3202, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3167458772659302
Epoch 0, Step 1461: train/loss = 0.26946964859962463, train/raw-loss = 0.23419898748397827, train/logprobs = tensor([[-0.6317, -7.1320],
        [-1.7895, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35270658135414124
Epoch 0, Step 1462: train/loss = 0.42965155839920044, train/raw-loss = 0.39582496881484985, train/logprobs = tensor([[-0.9628, -7.6084],
        [-1.7177, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382657766342163
Epoch 0, Step 1463: train/loss = 0.3193279504776001, train/raw-loss = 0.2779666781425476, train/logprobs = tensor([[-1.0239, -6.6644],
        [-1.9755, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136127233505249
Epoch 0, Step 1464: train/loss = 0.7063835263252258, train/raw-loss = 0.6702098250389099, train/logprobs = tensor([[-2.8206, -6.1820],
        [-1.4682, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617364168167114
Epoch 0, Step 1465: train/loss = 0.2759964168071747, train/raw-loss = 0.24160116910934448, train/logprobs = tensor([[ -1.1861, -12.6627],
        [ -1.9926,  -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3439529836177826
Epoch 0, Step 1466: train/loss = 0.17401352524757385, train/raw-loss = 0.1351393759250641, train/logprobs = tensor([[-1.0558, -6.0172],
        [-2.7778, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38874149322509766
Epoch 0, Step 1467: train/loss = 0.3135227859020233, train/raw-loss = 0.2712726294994354, train/logprobs = tensor([[ -1.6148, -15.9116],
        [ -2.9752,  -2.5591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4225012958049774
Epoch 0, Step 1468: train/loss = 0.3770377039909363, train/raw-loss = 0.34152430295944214, train/logprobs = tensor([[-0.9510, -5.3873],
        [-1.1683, -0.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35513392090797424
Epoch 0, Step 1469: train/loss = 0.41459518671035767, train/raw-loss = 0.37946540117263794, train/logprobs = tensor([[-1.4883, -6.6911],
        [-2.1747, -1.5153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351298063993454
Epoch 0, Step 1470: train/loss = 0.4914951026439667, train/raw-loss = 0.4545464813709259, train/logprobs = tensor([[-2.3784, -7.5771],
        [-2.4504, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3694863021373749
Epoch 0, Step 1471: train/loss = 0.40835803747177124, train/raw-loss = 0.36815932393074036, train/logprobs = tensor([[-1.5551, -4.8212],
        [-2.4460, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40198683738708496
Epoch 0, Step 1472: train/loss = 0.5803731083869934, train/raw-loss = 0.5405777096748352, train/logprobs = tensor([[-2.2072, -5.3706],
        [-2.2407, -1.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3979533910751343
Epoch 0, Step 1473: train/loss = 0.40854278206825256, train/raw-loss = 0.3691690266132355, train/logprobs = tensor([[-1.4241, -7.9479],
        [-1.9692, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3937373459339142
Epoch 0, Step 1474: train/loss = 0.3582291305065155, train/raw-loss = 0.3260253667831421, train/logprobs = tensor([[-1.2396, -4.9621],
        [-1.8146, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32203763723373413
Epoch 0, Step 1475: train/loss = 0.6340353488922119, train/raw-loss = 0.5988210439682007, train/logprobs = tensor([[-2.4898, -4.0445],
        [-1.8337, -1.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3521435558795929
Epoch 0, Step 1476: train/loss = 0.38627541065216064, train/raw-loss = 0.34444567561149597, train/logprobs = tensor([[-1.0795, -3.4676],
        [-2.0929, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182973802089691
Epoch 0, Step 1477: train/loss = 0.5091822147369385, train/raw-loss = 0.4730536937713623, train/logprobs = tensor([[-0.6886, -1.8734],
        [-1.4622, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3612850308418274
Epoch 0, Step 1478: train/loss = 0.2019726037979126, train/raw-loss = 0.16566139459609985, train/logprobs = tensor([[ -1.0257, -10.2046],
        [ -2.0184,  -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36311203241348267
Epoch 0, Step 1479: train/loss = 0.6144351363182068, train/raw-loss = 0.5855817198753357, train/logprobs = tensor([[-1.3341, -1.1700],
        [-1.5162, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2885339558124542
Epoch 0, Step 1480: train/loss = 0.3955387473106384, train/raw-loss = 0.3534735441207886, train/logprobs = tensor([[-0.7507, -3.9533],
        [-1.5716, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42065203189849854
Epoch 0, Step 1481: train/loss = 0.3009762763977051, train/raw-loss = 0.26762616634368896, train/logprobs = tensor([[-0.8852, -5.8369],
        [-1.3468, -0.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3335009515285492
Epoch 0, Step 1482: train/loss = 0.2674236595630646, train/raw-loss = 0.2281261384487152, train/logprobs = tensor([[-0.8342, -7.9094],
        [-1.6644, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3929751217365265
Epoch 0, Step 1483: train/loss = 0.41042983531951904, train/raw-loss = 0.3707764744758606, train/logprobs = tensor([[-1.4713, -8.2558],
        [-1.7956, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39653337001800537
Epoch 0, Step 1484: train/loss = 0.6397002339363098, train/raw-loss = 0.6097655296325684, train/logprobs = tensor([[-2.3672, -6.6284],
        [-1.7493, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2993467152118683
Epoch 0, Step 1485: train/loss = 0.5181719064712524, train/raw-loss = 0.48090821504592896, train/logprobs = tensor([[-1.0079, -4.0180],
        [-1.5975, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726370632648468
Epoch 0, Step 1486: train/loss = 0.29769575595855713, train/raw-loss = 0.2555429935455322, train/logprobs = tensor([[-0.7909, -5.3087],
        [-2.7644, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42152756452560425
Epoch 0, Step 1487: train/loss = 0.3777395486831665, train/raw-loss = 0.33717936277389526, train/logprobs = tensor([[-1.5671, -6.0437],
        [-2.0605, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40560224652290344
Epoch 0, Step 1488: train/loss = 0.2288123071193695, train/raw-loss = 0.19860796630382538, train/logprobs = tensor([[-0.7939, -9.3882],
        [-1.4202, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020433783531189
Epoch 0, Step 1489: train/loss = 0.4022638201713562, train/raw-loss = 0.36420565843582153, train/logprobs = tensor([[-1.0098, -3.3577],
        [-1.7447, -1.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3805818557739258
Epoch 0, Step 1490: train/loss = 0.40226879715919495, train/raw-loss = 0.36763426661491394, train/logprobs = tensor([[-1.6149, -4.5664],
        [-2.2000, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34634527564048767
Epoch 0, Step 1491: train/loss = 0.4474347233772278, train/raw-loss = 0.41384464502334595, train/logprobs = tensor([[-1.9056, -3.9550],
        [-2.9383, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33590078353881836
Epoch 0, Step 1492: train/loss = 0.3387065529823303, train/raw-loss = 0.29636508226394653, train/logprobs = tensor([[-0.9441, -3.9873],
        [-2.0303, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4234147071838379
Epoch 0, Step 1493: train/loss = 0.3957582116127014, train/raw-loss = 0.3576488792896271, train/logprobs = tensor([[-0.6112, -5.8466],
        [-1.4541, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38109320402145386
Epoch 0, Step 1494: train/loss = 0.3236062526702881, train/raw-loss = 0.2852555513381958, train/logprobs = tensor([[-0.6936, -5.0252],
        [-1.4634, -1.4679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3835070729255676
Epoch 0, Step 1495: train/loss = 1.2558904886245728, train/raw-loss = 1.2306479215621948, train/logprobs = tensor([[-3.7776, -7.2852],
        [-0.7453, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25242555141448975
Epoch 0, Step 1496: train/loss = 0.15090066194534302, train/raw-loss = 0.11213282495737076, train/logprobs = tensor([[ -1.5937, -11.9846],
        [ -3.4177,  -0.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3876782953739166
Epoch 0, Step 1497: train/loss = 0.3878585696220398, train/raw-loss = 0.35520556569099426, train/logprobs = tensor([[-0.6769, -3.3089],
        [-1.2081, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32652992010116577
Epoch 0, Step 1498: train/loss = 1.2028851509094238, train/raw-loss = 1.1690298318862915, train/logprobs = tensor([[-4.4473, -9.5810],
        [-1.3500, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33855319023132324
Epoch 0, Step 1499: train/loss = 0.291867733001709, train/raw-loss = 0.24672609567642212, train/logprobs = tensor([[-1.0390, -5.9199],
        [-2.1989, -1.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4514164328575134
Epoch 0, Step 1500: train/loss = 0.4011959731578827, train/raw-loss = 0.36633577942848206, train/logprobs = tensor([[-1.0305, -6.9227],
        [-1.9546, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34860217571258545
Epoch 0, Step 1501: train/loss = 0.37458914518356323, train/raw-loss = 0.33876949548721313, train/logprobs = tensor([[-2.0811, -3.6282],
        [-2.4514, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581964075565338
Epoch 0, Step 1502: train/loss = 0.386880487203598, train/raw-loss = 0.3490249514579773, train/logprobs = tensor([[-0.8237, -5.1063],
        [-1.9168, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378555566072464
Epoch 0, Step 1503: train/loss = 0.18951785564422607, train/raw-loss = 0.15052855014801025, train/logprobs = tensor([[-0.9661, -9.0020],
        [-2.3864, -0.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38989296555519104
Epoch 0, Step 1504: train/loss = 0.5811755657196045, train/raw-loss = 0.5530888438224792, train/logprobs = tensor([[-1.1958, -3.4995],
        [-1.3727, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28086724877357483
Epoch 0, Step 1505: train/loss = 0.2699050307273865, train/raw-loss = 0.23082798719406128, train/logprobs = tensor([[-1.0359, -4.7580],
        [-2.6929, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39077046513557434
Epoch 0, Step 1506: train/loss = 0.36872005462646484, train/raw-loss = 0.3421369791030884, train/logprobs = tensor([[-1.1835, -3.1717],
        [-1.7667, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658310532569885
Epoch 0, Step 1507: train/loss = 0.3856422007083893, train/raw-loss = 0.3461494743824005, train/logprobs = tensor([[-0.7808, -6.1177],
        [-2.0287, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39492741227149963
Epoch 0, Step 1508: train/loss = 0.31078073382377625, train/raw-loss = 0.27141207456588745, train/logprobs = tensor([[-1.0911, -3.2533],
        [-2.0840, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39368653297424316
Epoch 0, Step 1509: train/loss = 0.3522225022315979, train/raw-loss = 0.3241903483867645, train/logprobs = tensor([[-1.7549, -7.2521],
        [-2.0889, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28032153844833374
Epoch 0, Step 1510: train/loss = 0.30159294605255127, train/raw-loss = 0.2666824460029602, train/logprobs = tensor([[-1.0001, -8.0633],
        [-1.8943, -1.4109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3491046726703644
Epoch 0, Step 1511: train/loss = 0.1489005982875824, train/raw-loss = 0.11277598142623901, train/logprobs = tensor([[-0.7050, -6.2851],
        [-2.0828, -0.7771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36124616861343384
Epoch 0, Step 1512: train/loss = 0.4777797758579254, train/raw-loss = 0.44899052381515503, train/logprobs = tensor([[-1.4165, -4.4564],
        [-1.8445, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28789275884628296
Epoch 0, Step 1513: train/loss = 0.3713787794113159, train/raw-loss = 0.3313944339752197, train/logprobs = tensor([[-0.7747, -4.4587],
        [-1.8882, -1.4306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998437523841858
Epoch 0, Step 1514: train/loss = 0.4439685046672821, train/raw-loss = 0.4092615842819214, train/logprobs = tensor([[-1.1745, -7.0573],
        [-1.8081, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470694422721863
Epoch 0, Step 1515: train/loss = 0.40577420592308044, train/raw-loss = 0.36743202805519104, train/logprobs = tensor([[-0.6615, -6.6508],
        [-1.8840, -0.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38342195749282837
Epoch 0, Step 1516: train/loss = 0.4753803610801697, train/raw-loss = 0.4354093372821808, train/logprobs = tensor([[-0.7864, -2.0853],
        [-1.6751, -1.1163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3997102379798889
Epoch 0, Step 1517: train/loss = 0.2503671646118164, train/raw-loss = 0.21569032967090607, train/logprobs = tensor([[-1.0435, -4.7598],
        [-2.0829, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34676840901374817
Epoch 0, Step 1518: train/loss = 0.19797858595848083, train/raw-loss = 0.16018320620059967, train/logprobs = tensor([[-1.1233, -7.6439],
        [-2.3575, -0.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37795373797416687
Epoch 0, Step 1519: train/loss = 0.3710918724536896, train/raw-loss = 0.340265154838562, train/logprobs = tensor([[-0.8978, -3.4594],
        [-1.8176, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30826708674430847
Epoch 0, Step 1520: train/loss = 0.350029319524765, train/raw-loss = 0.3181694447994232, train/logprobs = tensor([[-1.4692, -5.8858],
        [-3.0894, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31859883666038513
Epoch 0, Step 1521: train/loss = 0.34432971477508545, train/raw-loss = 0.30893373489379883, train/logprobs = tensor([[-1.1078, -8.5192],
        [-2.0264, -2.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3539596199989319
Epoch 0, Step 1522: train/loss = 0.41007325053215027, train/raw-loss = 0.37798357009887695, train/logprobs = tensor([[-1.0579, -8.4141],
        [-1.3390, -1.4293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320896714925766
Epoch 0, Step 1523: train/loss = 0.6787831783294678, train/raw-loss = 0.6438912153244019, train/logprobs = tensor([[-1.0400, -1.3457],
        [-1.2332, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34892022609710693
Epoch 0, Step 1524: train/loss = 0.3001616895198822, train/raw-loss = 0.26427215337753296, train/logprobs = tensor([[-1.0574, -9.5870],
        [-2.2010, -1.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588952422142029
Epoch 0, Step 1525: train/loss = 0.3007655739784241, train/raw-loss = 0.27723032236099243, train/logprobs = tensor([[-0.8978, -9.2796],
        [-1.5383, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23535235226154327
Epoch 0, Step 1526: train/loss = 0.26794058084487915, train/raw-loss = 0.2322259396314621, train/logprobs = tensor([[-0.9677, -4.7225],
        [-1.6391, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3571462631225586
Epoch 0, Step 1527: train/loss = 0.35276785492897034, train/raw-loss = 0.31690338253974915, train/logprobs = tensor([[-0.8192, -6.9223],
        [-2.3203, -1.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35864460468292236
Epoch 0, Step 1528: train/loss = 0.34489375352859497, train/raw-loss = 0.3104785084724426, train/logprobs = tensor([[-0.9688, -1.9241],
        [-2.2289, -0.7910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441523313522339
Epoch 0, Step 1529: train/loss = 0.5303447842597961, train/raw-loss = 0.4977598786354065, train/logprobs = tensor([[-0.9016, -2.4646],
        [-1.5008, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32584884762763977
Epoch 0, Step 1530: train/loss = 0.2587480843067169, train/raw-loss = 0.22440899908542633, train/logprobs = tensor([[ -1.4244, -11.6168],
        [ -2.8391,  -1.2893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433908224105835
Epoch 0, Step 1531: train/loss = 0.3512602150440216, train/raw-loss = 0.31863605976104736, train/logprobs = tensor([[-0.8496, -6.7409],
        [-1.3375, -1.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32624173164367676
Epoch 0, Step 1532: train/loss = 0.477344274520874, train/raw-loss = 0.4464603662490845, train/logprobs = tensor([[-2.1223, -6.4549],
        [-2.0615, -0.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30883878469467163
Epoch 0, Step 1533: train/loss = 0.49248194694519043, train/raw-loss = 0.4651367664337158, train/logprobs = tensor([[-0.7955, -2.0420],
        [-1.2234, -0.7577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734515070915222
Epoch 0, Step 1534: train/loss = 0.2533940076828003, train/raw-loss = 0.22274667024612427, train/logprobs = tensor([[-0.7695, -6.6124],
        [-1.4471, -1.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30647337436676025
Epoch 0, Step 1535: train/loss = 0.41721901297569275, train/raw-loss = 0.37883687019348145, train/logprobs = tensor([[-1.0854, -2.5123],
        [-1.7790, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3838213086128235
Epoch 0, Step 1536: train/loss = 0.4556787610054016, train/raw-loss = 0.42495790123939514, train/logprobs = tensor([[-1.2355, -2.3012],
        [-1.7979, -1.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30720844864845276
Epoch 0, Step 1537: train/loss = 0.6134070754051208, train/raw-loss = 0.5811578035354614, train/logprobs = tensor([[-0.8921, -1.8061],
        [-1.2804, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32249268889427185
Epoch 0, Step 1538: train/loss = 0.6172027587890625, train/raw-loss = 0.5832781791687012, train/logprobs = tensor([[-0.8962, -1.9013],
        [-1.2899, -1.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392457365989685
Epoch 0, Step 1539: train/loss = 0.21310143172740936, train/raw-loss = 0.17472966015338898, train/logprobs = tensor([[-1.3364, -7.5955],
        [-2.4565, -0.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383717805147171
Epoch 0, Step 1540: train/loss = 0.436565637588501, train/raw-loss = 0.4007701873779297, train/logprobs = tensor([[-0.7752, -2.6636],
        [-1.7969, -0.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579544126987457
Epoch 0, Step 1541: train/loss = 0.36844807863235474, train/raw-loss = 0.3385758101940155, train/logprobs = tensor([[-0.9901, -2.9443],
        [-1.7276, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987232804298401
Epoch 0, Step 1542: train/loss = 0.20746532082557678, train/raw-loss = 0.17613835632801056, train/logprobs = tensor([[-0.7130, -9.9880],
        [-1.7370, -2.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31326964497566223
Epoch 0, Step 1543: train/loss = 0.25808852910995483, train/raw-loss = 0.2244020700454712, train/logprobs = tensor([[-1.5207, -8.8111],
        [-2.6955, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33686456084251404
Epoch 0, Step 1544: train/loss = 0.3976074457168579, train/raw-loss = 0.36392471194267273, train/logprobs = tensor([[-1.5304, -4.9212],
        [-1.6110, -0.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33682724833488464
Epoch 0, Step 1545: train/loss = 0.453016459941864, train/raw-loss = 0.42104971408843994, train/logprobs = tensor([[-2.0499, -7.0301],
        [-2.3080, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31966719031333923
Epoch 0, Step 1546: train/loss = 0.4099820852279663, train/raw-loss = 0.3696397840976715, train/logprobs = tensor([[-0.7916, -3.0897],
        [-2.4759, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4034227728843689
Epoch 0, Step 1547: train/loss = 0.742191731929779, train/raw-loss = 0.7111361026763916, train/logprobs = tensor([[-2.2934, -4.9118],
        [-1.1629, -0.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31055665016174316
Epoch 0, Step 1548: train/loss = 0.3174416422843933, train/raw-loss = 0.2821276783943176, train/logprobs = tensor([[-1.1299, -5.7640],
        [-1.7350, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35313940048217773
Epoch 0, Step 1549: train/loss = 0.5334349870681763, train/raw-loss = 0.4982531666755676, train/logprobs = tensor([[-0.9723, -2.2658],
        [-1.7091, -1.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3518182933330536
Epoch 0, Step 1550: train/loss = 0.2537792921066284, train/raw-loss = 0.2129383534193039, train/logprobs = tensor([[-0.9039, -3.4938],
        [-2.5238, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084092676639557
Epoch 0, Step 1551: train/loss = 0.2851869761943817, train/raw-loss = 0.24230152368545532, train/logprobs = tensor([[-0.8316, -5.4001],
        [-1.9974, -1.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42885446548461914
Epoch 0, Step 1552: train/loss = 0.5557798743247986, train/raw-loss = 0.5269702076911926, train/logprobs = tensor([[-1.0148, -2.6115],
        [-1.3473, -1.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28809642791748047
Epoch 0, Step 1553: train/loss = 0.3746722340583801, train/raw-loss = 0.33646273612976074, train/logprobs = tensor([[-1.4537, -3.7878],
        [-2.8455, -1.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820948004722595
Epoch 0, Step 1554: train/loss = 0.31783437728881836, train/raw-loss = 0.2717202305793762, train/logprobs = tensor([[-1.4314, -4.8112],
        [-2.8274, -1.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4611416459083557
Epoch 0, Step 1555: train/loss = 0.37727922201156616, train/raw-loss = 0.34396010637283325, train/logprobs = tensor([[-0.8752, -8.3653],
        [-2.2975, -0.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33319124579429626
Epoch 0, Step 1556: train/loss = 0.2992739677429199, train/raw-loss = 0.2630313038825989, train/logprobs = tensor([[-0.6830, -4.1668],
        [-1.4349, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3624264895915985
Epoch 0, Step 1557: train/loss = 0.4448801279067993, train/raw-loss = 0.4047802686691284, train/logprobs = tensor([[-0.7151, -4.2435],
        [-1.6442, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4009988605976105
Epoch 0, Step 1558: train/loss = 0.31250086426734924, train/raw-loss = 0.2740357518196106, train/logprobs = tensor([[ -1.5106, -10.8716],
        [ -2.0720,  -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.384651243686676
Epoch 0, Step 1559: train/loss = 0.2598055601119995, train/raw-loss = 0.2295375019311905, train/logprobs = tensor([[-0.6700, -3.6117],
        [-1.7317, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30268073081970215
Epoch 0, Step 1560: train/loss = 0.41022729873657227, train/raw-loss = 0.37692517042160034, train/logprobs = tensor([[-0.8178, -6.8863],
        [-1.5691, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330206573009491
Epoch 0, Step 1561: train/loss = 0.28629788756370544, train/raw-loss = 0.24957716464996338, train/logprobs = tensor([[ -1.2562, -11.3003],
        [ -2.3252,  -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672071695327759
Epoch 0, Step 1562: train/loss = 0.5046998858451843, train/raw-loss = 0.4697834551334381, train/logprobs = tensor([[-1.3942, -2.7547],
        [-1.8484, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3491644263267517
Epoch 0, Step 1563: train/loss = 0.40691277384757996, train/raw-loss = 0.3704145848751068, train/logprobs = tensor([[-2.0305, -5.9895],
        [-2.4999, -0.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36498206853866577
Epoch 0, Step 1564: train/loss = 0.1974194049835205, train/raw-loss = 0.15656431019306183, train/logprobs = tensor([[-1.2124, -6.4269],
        [-2.6172, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4085509181022644
Epoch 0, Step 1565: train/loss = 0.4377359449863434, train/raw-loss = 0.40638190507888794, train/logprobs = tensor([[-1.2835, -3.0433],
        [-1.4456, -0.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3135400116443634
Epoch 0, Step 1566: train/loss = 0.5210185050964355, train/raw-loss = 0.4808410406112671, train/logprobs = tensor([[-2.1675, -4.8596],
        [-2.0397, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40177497267723083
Epoch 0, Step 1567: train/loss = 0.45674240589141846, train/raw-loss = 0.42656630277633667, train/logprobs = tensor([[-0.9435, -2.3918],
        [-1.5831, -0.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3017609715461731
Epoch 0, Step 1568: train/loss = 0.1127854585647583, train/raw-loss = 0.07793818414211273, train/logprobs = tensor([[-0.8416, -8.5380],
        [-3.0544, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34847280383110046
Epoch 0, Step 1569: train/loss = 0.5721656084060669, train/raw-loss = 0.5464563369750977, train/logprobs = tensor([[-0.6619, -1.0501],
        [-1.0680, -0.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570924758911133
Epoch 0, Step 1570: train/loss = 0.43693363666534424, train/raw-loss = 0.40252238512039185, train/logprobs = tensor([[-1.8494, -6.7062],
        [-2.1656, -0.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441125750541687
Epoch 0, Step 1571: train/loss = 0.5664482712745667, train/raw-loss = 0.5306427478790283, train/logprobs = tensor([[-1.5716, -2.5920],
        [-1.9109, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580549955368042
Epoch 0, Step 1572: train/loss = 0.6373465061187744, train/raw-loss = 0.6090419888496399, train/logprobs = tensor([[-0.7485, -0.8923],
        [-1.1285, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28304579854011536
Epoch 0, Step 1573: train/loss = 0.3098886013031006, train/raw-loss = 0.2733556032180786, train/logprobs = tensor([[-1.5312, -7.0743],
        [-2.5235, -1.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36532995104789734
Epoch 0, Step 1574: train/loss = 0.3882065415382385, train/raw-loss = 0.35393327474594116, train/logprobs = tensor([[-0.8046, -4.9689],
        [-1.8497, -1.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427329361438751
Epoch 0, Step 1575: train/loss = 0.2656288743019104, train/raw-loss = 0.22046804428100586, train/logprobs = tensor([[-0.8628, -9.9681],
        [-2.7416, -1.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45160818099975586
Epoch 0, Step 1576: train/loss = 0.5952223539352417, train/raw-loss = 0.5622594952583313, train/logprobs = tensor([[-0.7757, -1.2468],
        [-1.2530, -1.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3296286165714264
Epoch 0, Step 1577: train/loss = 0.4941290616989136, train/raw-loss = 0.4546104371547699, train/logprobs = tensor([[-0.7857, -3.6503],
        [-3.0317, -1.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39518648386001587
Epoch 0, Step 1578: train/loss = 0.41494089365005493, train/raw-loss = 0.37399324774742126, train/logprobs = tensor([[-0.8601, -3.5738],
        [-2.3131, -1.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40947625041007996
Epoch 0, Step 1579: train/loss = 0.5320686101913452, train/raw-loss = 0.502558171749115, train/logprobs = tensor([[-0.5948, -2.2612],
        [-1.2513, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29510438442230225
Epoch 0, Step 1580: train/loss = 0.18202340602874756, train/raw-loss = 0.14026817679405212, train/logprobs = tensor([[ -1.0134, -14.1417],
        [ -2.7962,  -1.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41755223274230957
Epoch 0, Step 1581: train/loss = 0.4688382148742676, train/raw-loss = 0.4301772713661194, train/logprobs = tensor([[-1.7942, -4.9112],
        [-1.6631, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38660961389541626
Epoch 0, Step 1582: train/loss = 0.29922741651535034, train/raw-loss = 0.2655154764652252, train/logprobs = tensor([[ -1.2393, -10.8456],
        [ -2.0744,  -2.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.337118923664093
Epoch 0, Step 1583: train/loss = 0.13081331551074982, train/raw-loss = 0.09263588488101959, train/logprobs = tensor([[ -1.0113, -10.6019],
        [ -2.7575,  -2.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38177424669265747
Epoch 0, Step 1584: train/loss = 0.6696747541427612, train/raw-loss = 0.6405958533287048, train/logprobs = tensor([[-1.1955, -4.4695],
        [-1.2385, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907885015010834
Epoch 0, Step 1585: train/loss = 0.3909769356250763, train/raw-loss = 0.3580223321914673, train/logprobs = tensor([[-0.7691, -3.9450],
        [-1.6964, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32954609394073486
Epoch 0, Step 1586: train/loss = 0.3237708806991577, train/raw-loss = 0.2940739691257477, train/logprobs = tensor([[-0.7300, -4.2375],
        [-1.4448, -0.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2969692051410675
Epoch 0, Step 1587: train/loss = 0.3357325792312622, train/raw-loss = 0.2955910563468933, train/logprobs = tensor([[-0.9105, -4.1200],
        [-2.0324, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40141528844833374
Epoch 0, Step 1588: train/loss = 0.25298476219177246, train/raw-loss = 0.21472428739070892, train/logprobs = tensor([[-0.7840, -4.8095],
        [-1.9828, -1.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3826048970222473
Epoch 0, Step 1589: train/loss = 0.34097912907600403, train/raw-loss = 0.3076038360595703, train/logprobs = tensor([[-1.3344, -9.4135],
        [-1.5683, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33375284075737
Epoch 0, Step 1590: train/loss = 0.24250997602939606, train/raw-loss = 0.20649519562721252, train/logprobs = tensor([[-0.9951, -6.1253],
        [-2.0216, -1.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601478338241577
Epoch 0, Step 1591: train/loss = 0.34212642908096313, train/raw-loss = 0.3061996400356293, train/logprobs = tensor([[-0.6576, -3.8286],
        [-1.7312, -0.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592677712440491
Epoch 0, Step 1592: train/loss = 0.5200971364974976, train/raw-loss = 0.4846034348011017, train/logprobs = tensor([[-0.6458, -3.8701],
        [-1.1950, -0.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3549373149871826
Epoch 0, Step 1593: train/loss = 0.1476237177848816, train/raw-loss = 0.10666996985673904, train/logprobs = tensor([[-0.8297, -6.7878],
        [-2.6900, -1.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4095373749732971
Epoch 0, Step 1594: train/loss = 0.5585803985595703, train/raw-loss = 0.5258612036705017, train/logprobs = tensor([[-0.8078, -2.1504],
        [-1.4086, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32719212770462036
Epoch 0, Step 1595: train/loss = 0.7058422565460205, train/raw-loss = 0.6763499975204468, train/logprobs = tensor([[-2.3092, -4.0673],
        [-2.0289, -1.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2949225604534149
Epoch 0, Step 1596: train/loss = 0.42732247710227966, train/raw-loss = 0.3922163248062134, train/logprobs = tensor([[-0.9562, -2.4211],
        [-1.8118, -1.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3510615825653076
Epoch 0, Step 1597: train/loss = 0.15137889981269836, train/raw-loss = 0.11332148313522339, train/logprobs = tensor([[ -0.9193, -11.5765],
        [ -2.3592,  -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.380574107170105
Epoch 0, Step 1598: train/loss = 0.5591530799865723, train/raw-loss = 0.5167994499206543, train/logprobs = tensor([[-1.6494, -8.6044],
        [-1.9809, -1.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42353588342666626
Epoch 0, Step 1599: train/loss = 0.2692941427230835, train/raw-loss = 0.2309371531009674, train/logprobs = tensor([[-1.1681, -5.4241],
        [-3.0568, -2.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38357013463974
Epoch 0, Step 1600: train/loss = 0.43760234117507935, train/raw-loss = 0.4061390459537506, train/logprobs = tensor([[-0.7064, -2.8331],
        [-1.5199, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3146328926086426
Epoch 0, Step 1601: train/loss = 0.1879836469888687, train/raw-loss = 0.14059053361415863, train/logprobs = tensor([[-1.0410, -7.7040],
        [-2.6367, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47393113374710083
Epoch 0, Step 1602: train/loss = 0.2878614366054535, train/raw-loss = 0.2530214786529541, train/logprobs = tensor([[-1.0297, -3.8833],
        [-1.6903, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34839963912963867
Epoch 0, Step 1603: train/loss = 0.4146406054496765, train/raw-loss = 0.36615484952926636, train/logprobs = tensor([[-0.7359, -3.3226],
        [-2.4006, -1.1241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4848577678203583
Epoch 0, Step 1604: train/loss = 0.20475824177265167, train/raw-loss = 0.15934284031391144, train/logprobs = tensor([[-1.5347, -8.8863],
        [-3.6092, -2.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45415395498275757
Epoch 0, Step 1605: train/loss = 0.25015032291412354, train/raw-loss = 0.21517536044120789, train/logprobs = tensor([[ -0.7668, -10.4441],
        [ -2.1821,  -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34974947571754456
Epoch 0, Step 1606: train/loss = 0.14084908366203308, train/raw-loss = 0.10192365944385529, train/logprobs = tensor([[-1.1608, -6.1897],
        [-2.9020, -1.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3892541825771332
Epoch 0, Step 1607: train/loss = 0.35750696063041687, train/raw-loss = 0.3182220160961151, train/logprobs = tensor([[-1.2223, -9.5422],
        [-2.4867, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.392849326133728
Epoch 0, Step 1608: train/loss = 0.44737663865089417, train/raw-loss = 0.4135850667953491, train/logprobs = tensor([[-1.0003, -7.3277],
        [-1.5986, -1.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3379155397415161
Epoch 0, Step 1609: train/loss = 0.2418447881937027, train/raw-loss = 0.20499831438064575, train/logprobs = tensor([[-0.9598, -8.9362],
        [-2.5787, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3684646487236023
Epoch 0, Step 1610: train/loss = 0.1750267744064331, train/raw-loss = 0.13656635582447052, train/logprobs = tensor([[-0.6230, -6.6815],
        [-1.7401, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846043050289154
Epoch 0, Step 1611: train/loss = 0.3842214345932007, train/raw-loss = 0.35532116889953613, train/logprobs = tensor([[-1.1725, -3.7979],
        [-2.8318, -0.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890024185180664
Epoch 0, Step 1612: train/loss = 0.3431795835494995, train/raw-loss = 0.30512768030166626, train/logprobs = tensor([[-1.2012, -4.1920],
        [-1.8517, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38051924109458923
Epoch 0, Step 1613: train/loss = 0.6442774534225464, train/raw-loss = 0.607380747795105, train/logprobs = tensor([[-0.7865, -1.1785],
        [-1.3792, -1.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36896663904190063
Epoch 0, Step 1614: train/loss = 0.2658827602863312, train/raw-loss = 0.22268106043338776, train/logprobs = tensor([[-1.0076, -7.4098],
        [-2.8778, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4320172965526581
Epoch 0, Step 1615: train/loss = 0.32144099473953247, train/raw-loss = 0.28728002309799194, train/logprobs = tensor([[-1.5972, -4.4306],
        [-2.3248, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416096568107605
Epoch 0, Step 1616: train/loss = 0.35469913482666016, train/raw-loss = 0.3121434152126312, train/logprobs = tensor([[-1.4603, -7.6546],
        [-3.7438, -1.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4255574345588684
Epoch 0, Step 1617: train/loss = 0.3352148234844208, train/raw-loss = 0.29555726051330566, train/logprobs = tensor([[-1.4965, -8.6127],
        [-2.1680, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965754508972168
Epoch 0, Step 1618: train/loss = 0.4015803933143616, train/raw-loss = 0.36635109782218933, train/logprobs = tensor([[-1.4728, -3.1922],
        [-1.7470, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522931635379791
Epoch 0, Step 1619: train/loss = 0.5737130045890808, train/raw-loss = 0.5433962345123291, train/logprobs = tensor([[-2.1944, -4.6042],
        [-1.6711, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30316823720932007
Epoch 0, Step 1620: train/loss = 0.391858845949173, train/raw-loss = 0.3643684685230255, train/logprobs = tensor([[-0.7975, -6.4626],
        [-1.2438, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749041020870209
Epoch 0, Step 1621: train/loss = 0.3433694839477539, train/raw-loss = 0.3137853741645813, train/logprobs = tensor([[-1.0838, -2.5254],
        [-2.2225, -0.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29584115743637085
Epoch 0, Step 1622: train/loss = 0.14810054004192352, train/raw-loss = 0.103854700922966, train/logprobs = tensor([[ -1.0259, -14.1166],
        [ -2.7003,  -2.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4424583315849304
Epoch 0, Step 1623: train/loss = 0.4484107196331024, train/raw-loss = 0.4117928743362427, train/logprobs = tensor([[-1.0837, -3.5199],
        [-1.6043, -1.3178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36617863178253174
Epoch 0, Step 1624: train/loss = 0.638372004032135, train/raw-loss = 0.5995096564292908, train/logprobs = tensor([[-1.3208, -1.8391],
        [-1.7808, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38862401247024536
Epoch 0, Step 1625: train/loss = 0.36790841817855835, train/raw-loss = 0.3275081515312195, train/logprobs = tensor([[-0.8225, -3.2697],
        [-1.5684, -0.9811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4040029048919678
Epoch 0, Step 1626: train/loss = 0.40283823013305664, train/raw-loss = 0.3637421131134033, train/logprobs = tensor([[-1.1557, -3.9009],
        [-2.6240, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39096060395240784
Epoch 0, Step 1627: train/loss = 0.4666566550731659, train/raw-loss = 0.424948513507843, train/logprobs = tensor([[-0.8797, -3.0303],
        [-2.1200, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41708165407180786
Epoch 0, Step 1628: train/loss = 0.3250959813594818, train/raw-loss = 0.29474014043807983, train/logprobs = tensor([[-0.9972, -2.8978],
        [-1.6294, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30355823040008545
Epoch 0, Step 1629: train/loss = 0.5521052479743958, train/raw-loss = 0.5171219110488892, train/logprobs = tensor([[-0.9099, -1.2641],
        [-1.5376, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34983402490615845
Epoch 0, Step 1630: train/loss = 0.22008444368839264, train/raw-loss = 0.19353647530078888, train/logprobs = tensor([[-1.4387, -6.7841],
        [-2.1036, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26547956466674805
Epoch 0, Step 1631: train/loss = 0.34748417139053345, train/raw-loss = 0.3028520345687866, train/logprobs = tensor([[-1.4049, -4.2078],
        [-3.3787, -1.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4463212490081787
Epoch 0, Step 1632: train/loss = 0.41193729639053345, train/raw-loss = 0.3683318495750427, train/logprobs = tensor([[-1.6304, -6.0215],
        [-2.2896, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4360542297363281
Epoch 0, Step 1633: train/loss = 0.30967700481414795, train/raw-loss = 0.26069560647010803, train/logprobs = tensor([[ -1.0387, -11.3812],
        [ -2.5163,  -1.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4898141026496887
Epoch 0, Step 1634: train/loss = 1.68921959400177, train/raw-loss = 1.6533952951431274, train/logprobs = tensor([[ -6.5485, -10.0138],
        [ -1.7602,  -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35824286937713623
Epoch 0, Step 1635: train/loss = 0.3903219401836395, train/raw-loss = 0.3573865294456482, train/logprobs = tensor([[-1.1595, -8.0011],
        [-1.8590, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293539881706238
Epoch 0, Step 1636: train/loss = 0.33785539865493774, train/raw-loss = 0.30655694007873535, train/logprobs = tensor([[-0.9040, -5.5690],
        [-2.1285, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129846453666687
Epoch 0, Step 1637: train/loss = 0.47671031951904297, train/raw-loss = 0.4386475384235382, train/logprobs = tensor([[-0.7369, -4.5384],
        [-1.4642, -1.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38062790036201477
Epoch 0, Step 1638: train/loss = 0.2972838282585144, train/raw-loss = 0.263688325881958, train/logprobs = tensor([[-1.1740, -8.3266],
        [-1.5304, -0.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3359553813934326
Epoch 0, Step 1639: train/loss = 0.22590196132659912, train/raw-loss = 0.18622839450836182, train/logprobs = tensor([[ -1.1078, -12.8064],
        [ -3.0223,  -2.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3967357277870178
Epoch 0, Step 1640: train/loss = 0.5751590728759766, train/raw-loss = 0.5361887216567993, train/logprobs = tensor([[-1.4760, -3.3050],
        [-1.6265, -2.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3897033631801605
Epoch 0, Step 1641: train/loss = 0.17783257365226746, train/raw-loss = 0.14116661250591278, train/logprobs = tensor([[-1.5036, -7.6356],
        [-2.5869, -1.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36665961146354675
Epoch 0, Step 1642: train/loss = 0.316936194896698, train/raw-loss = 0.2723371982574463, train/logprobs = tensor([[-0.5377, -7.9592],
        [-2.1883, -1.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4459902048110962
Epoch 0, Step 1643: train/loss = 0.27935874462127686, train/raw-loss = 0.23823408782482147, train/logprobs = tensor([[ -1.3658, -11.2770],
        [ -2.3409,  -1.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41124653816223145
Epoch 0, Step 1644: train/loss = 0.4684668183326721, train/raw-loss = 0.4170275032520294, train/logprobs = tensor([[-1.3597, -2.4838],
        [-3.2795, -1.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5143932104110718
Epoch 0, Step 1645: train/loss = 0.48563772439956665, train/raw-loss = 0.4537960886955261, train/logprobs = tensor([[-2.7192, -6.7969],
        [-2.6120, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31841686367988586
Epoch 0, Step 1646: train/loss = 0.3388076722621918, train/raw-loss = 0.30658525228500366, train/logprobs = tensor([[-1.7633, -6.5271],
        [-1.7982, -1.4592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3222239911556244
Epoch 0, Step 1647: train/loss = 0.3566652238368988, train/raw-loss = 0.32306623458862305, train/logprobs = tensor([[-0.7360, -4.4496],
        [-1.4431, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33599036931991577
Epoch 0, Step 1648: train/loss = 0.23421959578990936, train/raw-loss = 0.19220156967639923, train/logprobs = tensor([[-0.9967, -5.8620],
        [-2.2520, -0.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4201802909374237
Epoch 0, Step 1649: train/loss = 0.47663187980651855, train/raw-loss = 0.43264806270599365, train/logprobs = tensor([[-1.4156, -8.0269],
        [-2.0020, -1.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43983811140060425
Epoch 0, Step 1650: train/loss = 1.1419076919555664, train/raw-loss = 1.1070724725723267, train/logprobs = tensor([[-3.9867, -5.7932],
        [-1.5567, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3483528792858124
Epoch 0, Step 1651: train/loss = 0.37912750244140625, train/raw-loss = 0.33976492285728455, train/logprobs = tensor([[-1.3557, -4.4643],
        [-2.6536, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39362582564353943
Epoch 0, Step 1652: train/loss = 0.17247362434864044, train/raw-loss = 0.13209816813468933, train/logprobs = tensor([[-1.3421, -6.4578],
        [-2.9063, -1.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4037545323371887
Epoch 0, Step 1653: train/loss = 0.4433010220527649, train/raw-loss = 0.40209653973579407, train/logprobs = tensor([[-1.5631, -3.0558],
        [-2.0483, -1.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4120446443557739
Epoch 0, Step 1654: train/loss = 0.4430982768535614, train/raw-loss = 0.412174254655838, train/logprobs = tensor([[-1.7194, -4.7425],
        [-1.9030, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.309240460395813
Epoch 0, Step 1655: train/loss = 0.37206128239631653, train/raw-loss = 0.331304132938385, train/logprobs = tensor([[-1.0305, -3.3384],
        [-2.1215, -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4075716733932495
Epoch 0, Step 1656: train/loss = 0.7513355016708374, train/raw-loss = 0.7203244566917419, train/logprobs = tensor([[-1.9716, -1.8750],
        [-1.1883, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101102113723755
Epoch 0, Step 1657: train/loss = 0.33195599913597107, train/raw-loss = 0.29039663076400757, train/logprobs = tensor([[-1.3637, -6.9636],
        [-2.2638, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155936539173126
Epoch 0, Step 1658: train/loss = 0.36593666672706604, train/raw-loss = 0.33131885528564453, train/logprobs = tensor([[-0.7842, -3.5367],
        [-2.2113, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34617793560028076
Epoch 0, Step 1659: train/loss = 0.27192479372024536, train/raw-loss = 0.22790949046611786, train/logprobs = tensor([[-0.7452, -3.6183],
        [-2.4193, -1.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44015318155288696
Epoch 0, Step 1660: train/loss = 0.3240293264389038, train/raw-loss = 0.27815720438957214, train/logprobs = tensor([[ -1.5856, -10.0210],
        [ -2.3709,  -2.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4587210416793823
Epoch 0, Step 1661: train/loss = 0.27454033493995667, train/raw-loss = 0.2353232204914093, train/logprobs = tensor([[-1.0025, -4.0471],
        [-2.2535, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39217114448547363
Epoch 0, Step 1662: train/loss = 0.18623113632202148, train/raw-loss = 0.14236563444137573, train/logprobs = tensor([[-0.9531, -8.7743],
        [-2.0594, -1.4362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4386550486087799
Epoch 0, Step 1663: train/loss = 0.5097664594650269, train/raw-loss = 0.4716460704803467, train/logprobs = tensor([[-1.4261, -1.5736],
        [-2.4221, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38120418787002563
Epoch 0, Step 1664: train/loss = 0.5074991583824158, train/raw-loss = 0.4769588112831116, train/logprobs = tensor([[-1.0685, -3.6147],
        [-1.4936, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30540338158607483
Epoch 0, Step 1665: train/loss = 0.28649717569351196, train/raw-loss = 0.24465139210224152, train/logprobs = tensor([[-1.7071, -7.1701],
        [-2.4560, -1.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.418457955121994
Epoch 0, Step 1666: train/loss = 0.2547711730003357, train/raw-loss = 0.2112949639558792, train/logprobs = tensor([[-0.8512, -8.0144],
        [-2.3358, -2.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43476206064224243
Epoch 0, Step 1667: train/loss = 0.3366380035877228, train/raw-loss = 0.2945215106010437, train/logprobs = tensor([[-1.4561, -8.0343],
        [-3.3584, -3.0914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4211650490760803
Epoch 0, Step 1668: train/loss = 0.25862112641334534, train/raw-loss = 0.21458537876605988, train/logprobs = tensor([[-1.0555, -7.5129],
        [-1.7965, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44035762548446655
Epoch 0, Step 1669: train/loss = 0.38775479793548584, train/raw-loss = 0.3479531705379486, train/logprobs = tensor([[-1.1184, -4.1300],
        [-2.3584, -1.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39801645278930664
Epoch 0, Step 1670: train/loss = 0.6439446210861206, train/raw-loss = 0.6078796982765198, train/logprobs = tensor([[-1.1932, -1.5046],
        [-1.2131, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36064937710762024
Epoch 0, Step 1671: train/loss = 0.2447856217622757, train/raw-loss = 0.20045286417007446, train/logprobs = tensor([[-1.0652, -6.2024],
        [-2.8798, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4433273673057556
Epoch 0, Step 1672: train/loss = 0.24538278579711914, train/raw-loss = 0.2059585452079773, train/logprobs = tensor([[-1.1396, -5.8262],
        [-2.3731, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3942425847053528
Epoch 0, Step 1673: train/loss = 0.17157234251499176, train/raw-loss = 0.1309610903263092, train/logprobs = tensor([[-1.2815, -9.6633],
        [-3.3746, -1.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061126112937927
Epoch 0, Step 1674: train/loss = 0.46837693452835083, train/raw-loss = 0.43115997314453125, train/logprobs = tensor([[ -1.8988, -13.4513],
        [ -1.9587,  -2.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721694350242615
Epoch 0, Step 1675: train/loss = 0.5226500034332275, train/raw-loss = 0.4838802218437195, train/logprobs = tensor([[-1.1838, -2.5267],
        [-2.0286, -1.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.387698233127594
Epoch 0, Step 1676: train/loss = 0.45632004737854004, train/raw-loss = 0.4142845571041107, train/logprobs = tensor([[-1.6598, -6.4209],
        [-1.9469, -1.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4203544855117798
Epoch 0, Step 1677: train/loss = 0.4045828580856323, train/raw-loss = 0.3615645170211792, train/logprobs = tensor([[-0.8974, -4.9637],
        [-1.7438, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43018317222595215
Epoch 0, Step 1678: train/loss = 0.374066561460495, train/raw-loss = 0.3289235830307007, train/logprobs = tensor([[-1.2309, -7.2760],
        [-3.0972, -1.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4514298737049103
Epoch 0, Step 1679: train/loss = 0.2715859115123749, train/raw-loss = 0.23062817752361298, train/logprobs = tensor([[-1.0437, -9.6152],
        [-2.9327, -0.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40957725048065186
Epoch 0, Step 1680: train/loss = 0.9400525689125061, train/raw-loss = 0.9074380993843079, train/logprobs = tensor([[-3.2367, -5.4256],
        [-0.9695, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3261445164680481
Epoch 0, Step 1681: train/loss = 0.25637465715408325, train/raw-loss = 0.21032077074050903, train/logprobs = tensor([[-1.7788, -9.7944],
        [-3.7771, -3.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4605388641357422
Epoch 0, Step 1682: train/loss = 0.3282746374607086, train/raw-loss = 0.2828364372253418, train/logprobs = tensor([[-1.5665, -3.6181],
        [-2.4457, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4543817937374115
Epoch 0, Step 1683: train/loss = 0.42991727590560913, train/raw-loss = 0.38896864652633667, train/logprobs = tensor([[-1.5897, -1.7005],
        [-2.6045, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40948572754859924
Epoch 0, Step 1684: train/loss = 0.29442545771598816, train/raw-loss = 0.25675514340400696, train/logprobs = tensor([[-0.8183, -6.6397],
        [-2.0835, -1.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767032027244568
Epoch 0, Step 1685: train/loss = 0.14882682263851166, train/raw-loss = 0.1020796149969101, train/logprobs = tensor([[ -1.6269, -10.4721],
        [ -3.2997,  -1.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4674721360206604
Epoch 0, Step 1686: train/loss = 0.1459459662437439, train/raw-loss = 0.10411184281110764, train/logprobs = tensor([[-1.1832, -8.0689],
        [-3.0774, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183412194252014
Epoch 0, Step 1687: train/loss = 0.29023534059524536, train/raw-loss = 0.25259900093078613, train/logprobs = tensor([[-0.6170, -7.8487],
        [-1.6863, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37636345624923706
Epoch 0, Step 1688: train/loss = 0.2962294816970825, train/raw-loss = 0.24833887815475464, train/logprobs = tensor([[-1.0143, -6.2232],
        [-2.5406, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47890615463256836
Epoch 0, Step 1689: train/loss = 0.866669774055481, train/raw-loss = 0.8300588130950928, train/logprobs = tensor([[-3.8269, -4.8786],
        [-1.8260, -0.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661096692085266
Epoch 0, Step 1690: train/loss = 0.20248427987098694, train/raw-loss = 0.1499609798192978, train/logprobs = tensor([[-0.9630, -9.0931],
        [-3.1131, -1.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5252330303192139
Epoch 0, Step 1691: train/loss = 0.43997713923454285, train/raw-loss = 0.3876742720603943, train/logprobs = tensor([[-1.7436, -4.5701],
        [-3.9674, -2.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5230283737182617
Epoch 0, Step 1692: train/loss = 0.512578547000885, train/raw-loss = 0.4798547029495239, train/logprobs = tensor([[-1.4073, -3.1907],
        [-1.6169, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32723894715309143
Epoch 0, Step 1693: train/loss = 0.33405181765556335, train/raw-loss = 0.29918986558914185, train/logprobs = tensor([[ -1.6087, -11.3021],
        [ -2.0353,  -1.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.348619669675827
Epoch 0, Step 1694: train/loss = 0.2757668197154999, train/raw-loss = 0.24101677536964417, train/logprobs = tensor([[-0.8677, -4.9026],
        [-1.7469, -1.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34750038385391235
Epoch 0, Step 1695: train/loss = 0.6255775690078735, train/raw-loss = 0.5963714122772217, train/logprobs = tensor([[-0.8634, -1.5718],
        [-0.9679, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920616567134857
Epoch 0, Step 1696: train/loss = 0.3406481146812439, train/raw-loss = 0.28765833377838135, train/logprobs = tensor([[-0.9588, -5.6306],
        [-3.2820, -2.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5298976898193359
Epoch 0, Step 1697: train/loss = 0.27079129219055176, train/raw-loss = 0.23202848434448242, train/logprobs = tensor([[-1.1611, -6.8979],
        [-2.4378, -1.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38762789964675903
Epoch 0, Step 1698: train/loss = 0.7779314517974854, train/raw-loss = 0.7342193126678467, train/logprobs = tensor([[-1.8070, -3.0284],
        [-1.7805, -2.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4371216297149658
Epoch 0, Step 1699: train/loss = 0.2386002242565155, train/raw-loss = 0.18820403516292572, train/logprobs = tensor([[-1.3568, -8.4905],
        [-3.9886, -1.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5039618611335754
Epoch 0, Step 1700: train/loss = 0.5110352635383606, train/raw-loss = 0.46426790952682495, train/logprobs = tensor([[-1.8294, -6.0148],
        [-2.4440, -1.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4676731824874878
Epoch 0, Step 1701: train/loss = 0.5802518129348755, train/raw-loss = 0.5480482578277588, train/logprobs = tensor([[-1.6688, -3.5495],
        [-1.5012, -0.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32203564047813416
Epoch 0, Step 1702: train/loss = 0.6992284655570984, train/raw-loss = 0.6615987420082092, train/logprobs = tensor([[-1.4475, -1.6392],
        [-1.5973, -1.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37629732489585876
Epoch 0, Step 1703: train/loss = 0.18173910677433014, train/raw-loss = 0.1421871781349182, train/logprobs = tensor([[-1.6622, -9.9344],
        [-3.1918, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39551931619644165
Epoch 0, Step 1704: train/loss = 0.6554058790206909, train/raw-loss = 0.603681206703186, train/logprobs = tensor([[-2.1415, -6.3743],
        [-2.3132, -1.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5172464847564697
Epoch 0, Step 1705: train/loss = 0.36623483896255493, train/raw-loss = 0.322884738445282, train/logprobs = tensor([[-1.0843, -6.2364],
        [-2.2354, -1.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335005283355713
Epoch 0, Step 1706: train/loss = 0.16492940485477448, train/raw-loss = 0.107464499771595, train/logprobs = tensor([[-1.0866, -7.6625],
        [-3.1400, -1.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5746489763259888
Epoch 0, Step 1707: train/loss = 0.5092819929122925, train/raw-loss = 0.4724634289741516, train/logprobs = tensor([[-1.5521, -5.8141],
        [-1.7020, -1.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36818593740463257
Epoch 0, Step 1708: train/loss = 0.12245979905128479, train/raw-loss = 0.07796203345060349, train/logprobs = tensor([[ -1.8345, -11.0904],
        [ -3.6825,  -1.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4449775815010071
Epoch 0, Step 1709: train/loss = 0.38725048303604126, train/raw-loss = 0.3458572030067444, train/logprobs = tensor([[-1.2805, -2.2668],
        [-2.6171, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41393283009529114
Epoch 0, Step 1710: train/loss = 0.10688845813274384, train/raw-loss = 0.06257043778896332, train/logprobs = tensor([[ -1.5633, -14.6319],
        [ -3.5742,  -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4431801438331604
Epoch 0, Step 1711: train/loss = 0.27215731143951416, train/raw-loss = 0.22457970678806305, train/logprobs = tensor([[-1.0206, -5.3432],
        [-2.5928, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4757757782936096
Epoch 0, Step 1712: train/loss = 0.8124822974205017, train/raw-loss = 0.7701903581619263, train/logprobs = tensor([[ -4.3786, -10.8744],
        [ -3.1883,  -3.2830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4229195713996887
Epoch 0, Step 1713: train/loss = 0.18380972743034363, train/raw-loss = 0.13798634707927704, train/logprobs = tensor([[ -1.6540, -12.1445],
        [ -2.8047,  -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45823371410369873
Epoch 0, Step 1714: train/loss = 0.6675716638565063, train/raw-loss = 0.6285489201545715, train/logprobs = tensor([[-2.1096, -1.7804],
        [-2.1456, -1.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39022791385650635
Epoch 0, Step 1715: train/loss = 0.3030894994735718, train/raw-loss = 0.24954292178153992, train/logprobs = tensor([[-0.8928, -7.8016],
        [-3.1017, -2.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5354658961296082
Epoch 0, Step 1716: train/loss = 0.5214104056358337, train/raw-loss = 0.4831412434577942, train/logprobs = tensor([[-1.6146, -5.2418],
        [-2.2951, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3826916813850403
Epoch 0, Step 1717: train/loss = 0.4383511245250702, train/raw-loss = 0.4035261869430542, train/logprobs = tensor([[-1.4566, -6.6945],
        [-1.2661, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.348249226808548
Epoch 0, Step 1718: train/loss = 0.7323960661888123, train/raw-loss = 0.6952393054962158, train/logprobs = tensor([[-3.1396, -5.2696],
        [-1.8649, -1.4282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37156733870506287
Epoch 0, Step 1719: train/loss = 0.36497482657432556, train/raw-loss = 0.31928178668022156, train/logprobs = tensor([[-0.8835, -5.6295],
        [-1.6750, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45693036913871765
Epoch 0, Step 1720: train/loss = 0.3172757625579834, train/raw-loss = 0.25751662254333496, train/logprobs = tensor([[ -1.5091, -10.2711],
        [ -3.0620,  -1.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5975916385650635
Epoch 0, Step 1721: train/loss = 0.3938547372817993, train/raw-loss = 0.3548024296760559, train/logprobs = tensor([[ -2.8387, -12.4072],
        [ -2.4932,  -2.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905232846736908
Epoch 0, Step 1722: train/loss = 0.2494293451309204, train/raw-loss = 0.20607800781726837, train/logprobs = tensor([[-2.0829, -7.5588],
        [-3.0715, -1.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43351346254348755
Epoch 0, Step 1723: train/loss = 0.2902114689350128, train/raw-loss = 0.2503349184989929, train/logprobs = tensor([[ -1.5738, -15.7027],
        [ -2.7495,  -3.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3987656235694885
Epoch 0, Step 1724: train/loss = 0.24873514473438263, train/raw-loss = 0.21136178076267242, train/logprobs = tensor([[-0.9940, -7.8460],
        [-2.3427, -0.8527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3737337589263916
Epoch 0, Step 1725: train/loss = 0.35197877883911133, train/raw-loss = 0.30479079484939575, train/logprobs = tensor([[-1.0864, -6.8683],
        [-2.1872, -1.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4718802273273468
Epoch 0, Step 1726: train/loss = 0.35555940866470337, train/raw-loss = 0.31544917821884155, train/logprobs = tensor([[-2.3535, -6.6958],
        [-4.0646, -1.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4011024832725525
Epoch 0, Step 1727: train/loss = 0.4895279109477997, train/raw-loss = 0.4391566812992096, train/logprobs = tensor([[-1.6050, -4.6074],
        [-1.7997, -1.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.503711998462677
Epoch 0, Step 1728: train/loss = 0.3965952396392822, train/raw-loss = 0.3515225052833557, train/logprobs = tensor([[-2.4491, -4.4166],
        [-2.9339, -1.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4507273733615875
Epoch 0, Step 1729: train/loss = 0.37793195247650146, train/raw-loss = 0.3345089256763458, train/logprobs = tensor([[-1.8730, -4.8725],
        [-2.6266, -1.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43423014879226685
Epoch 0, Step 1730: train/loss = 0.2437327802181244, train/raw-loss = 0.20286190509796143, train/logprobs = tensor([[-1.2648, -8.0727],
        [-2.6009, -1.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40870901942253113
Epoch 0, Step 1731: train/loss = 0.16955655813217163, train/raw-loss = 0.11533421277999878, train/logprobs = tensor([[-1.7672, -9.8727],
        [-3.3795, -1.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5422233939170837
Epoch 0, Step 1732: train/loss = 0.2769511938095093, train/raw-loss = 0.22219370305538177, train/logprobs = tensor([[-1.3933, -8.6746],
        [-2.9161, -1.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.547575056552887
Epoch 0, Step 1733: train/loss = 0.377314031124115, train/raw-loss = 0.3243386447429657, train/logprobs = tensor([[-1.1503, -3.3368],
        [-2.7799, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5297538042068481
Epoch 0, Step 1734: train/loss = 0.5254203677177429, train/raw-loss = 0.47942623496055603, train/logprobs = tensor([[-2.6795, -6.0384],
        [-2.5759, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45994165539741516
Epoch 0, Step 1735: train/loss = 0.5449580550193787, train/raw-loss = 0.5105382204055786, train/logprobs = tensor([[-2.0635, -4.5547],
        [-1.7318, -0.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344198614358902
Epoch 0, Step 1736: train/loss = 0.3761940002441406, train/raw-loss = 0.321268230676651, train/logprobs = tensor([[-1.9038, -6.7562],
        [-3.5867, -2.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5492575168609619
Epoch 0, Step 1737: train/loss = 0.5299401879310608, train/raw-loss = 0.48471587896347046, train/logprobs = tensor([[-1.9617, -6.8183],
        [-3.2392, -2.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4522428810596466
Epoch 0, Step 1738: train/loss = 0.4166039824485779, train/raw-loss = 0.37535735964775085, train/logprobs = tensor([[-2.3978, -5.5836],
        [-2.2250, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41246622800827026
Epoch 0, Step 1739: train/loss = 0.39954841136932373, train/raw-loss = 0.35739144682884216, train/logprobs = tensor([[-1.1262, -4.9242],
        [-2.1506, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42156982421875
Epoch 0, Step 1740: train/loss = 0.3426569700241089, train/raw-loss = 0.29578810930252075, train/logprobs = tensor([[-1.0794, -7.5145],
        [-2.2321, -2.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4686886668205261
Epoch 0, Step 1741: train/loss = 0.25846409797668457, train/raw-loss = 0.216009721159935, train/logprobs = tensor([[ -1.1282, -11.2641],
        [ -2.4595,  -1.2028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42454397678375244
Epoch 0, Step 1742: train/loss = 0.4346267879009247, train/raw-loss = 0.39256659150123596, train/logprobs = tensor([[-1.1618, -4.9960],
        [-1.5722, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42060205340385437
Epoch 0, Step 1743: train/loss = 0.6585662961006165, train/raw-loss = 0.6117817759513855, train/logprobs = tensor([[-1.1073, -2.2190],
        [-2.3047, -2.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46784520149230957
Epoch 0, Step 1744: train/loss = 0.31268393993377686, train/raw-loss = 0.2710968852043152, train/logprobs = tensor([[-1.5034, -4.8952],
        [-1.8887, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158708453178406
Epoch 0, Step 1745: train/loss = 0.25613999366760254, train/raw-loss = 0.20816496014595032, train/logprobs = tensor([[ -1.2277, -11.9712],
        [ -3.0806,  -3.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47975027561187744
Epoch 0, Step 1746: train/loss = 0.19491465389728546, train/raw-loss = 0.14510975778102875, train/logprobs = tensor([[-1.5317, -7.0013],
        [-3.6564, -1.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4980490803718567
Epoch 0, Step 1747: train/loss = 0.44672858715057373, train/raw-loss = 0.4118412435054779, train/logprobs = tensor([[-1.4274, -7.4911],
        [-1.8519, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488733768463135
Epoch 0, Step 1748: train/loss = 0.254604309797287, train/raw-loss = 0.21038228273391724, train/logprobs = tensor([[-1.9523, -8.6513],
        [-2.8004, -1.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44222038984298706
Epoch 0, Step 1749: train/loss = 0.2790619432926178, train/raw-loss = 0.22643110156059265, train/logprobs = tensor([[-0.9843, -5.7564],
        [-2.4974, -1.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5263084173202515
Epoch 0, Step 1750: train/loss = 0.3711276054382324, train/raw-loss = 0.3234703838825226, train/logprobs = tensor([[-1.5222, -6.7964],
        [-2.7464, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47657206654548645
Epoch 0, Step 1751: train/loss = 0.3034432530403137, train/raw-loss = 0.26334598660469055, train/logprobs = tensor([[ -2.0744, -10.8102],
        [ -3.0924,  -1.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4009726345539093
Epoch 0, Step 1752: train/loss = 0.2040541172027588, train/raw-loss = 0.1543799191713333, train/logprobs = tensor([[-1.4714, -9.0499],
        [-2.5497, -1.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4967420995235443
Epoch 0, Step 1753: train/loss = 0.3292459547519684, train/raw-loss = 0.28019654750823975, train/logprobs = tensor([[-1.7349, -6.2250],
        [-3.0464, -2.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49049413204193115
Epoch 0, Step 1754: train/loss = 0.44000059366226196, train/raw-loss = 0.3953089416027069, train/logprobs = tensor([[-1.5481, -8.0010],
        [-1.9036, -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44691628217697144
Epoch 0, Step 1755: train/loss = 0.3062775135040283, train/raw-loss = 0.25600701570510864, train/logprobs = tensor([[-1.5537, -6.5191],
        [-2.5474, -1.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5027047991752625
Epoch 0, Step 1756: train/loss = 0.1482040137052536, train/raw-loss = 0.10850631445646286, train/logprobs = tensor([[ -1.4520, -10.0707],
        [ -2.9655,  -2.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39697691798210144
Epoch 0, Step 1757: train/loss = 0.35407382249832153, train/raw-loss = 0.3035825192928314, train/logprobs = tensor([[ -1.0633, -13.4286],
        [ -4.0083,  -3.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5049130916595459
Epoch 0, Step 1758: train/loss = 0.4974679946899414, train/raw-loss = 0.46398988366127014, train/logprobs = tensor([[-2.8079, -7.4058],
        [-2.5635, -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33478114008903503
Epoch 0, Step 1759: train/loss = 0.33038514852523804, train/raw-loss = 0.28628790378570557, train/logprobs = tensor([[-2.2985, -9.7507],
        [-2.6601, -1.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409725069999695
Epoch 0, Step 1760: train/loss = 0.46874526143074036, train/raw-loss = 0.42874160408973694, train/logprobs = tensor([[-1.6970, -8.3509],
        [-2.8803, -2.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4000367522239685
Epoch 0, Step 1761: train/loss = 0.595391035079956, train/raw-loss = 0.5622743368148804, train/logprobs = tensor([[-1.9738, -2.9101],
        [-1.4662, -0.6677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33116674423217773
Epoch 0, Step 1762: train/loss = 0.20489126443862915, train/raw-loss = 0.15948118269443512, train/logprobs = tensor([[-1.6821, -9.0023],
        [-3.1992, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45410090684890747
Epoch 0, Step 1763: train/loss = 0.12958230078220367, train/raw-loss = 0.0784609243273735, train/logprobs = tensor([[ -0.7801, -14.1234],
        [ -2.7911,  -3.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5112136602401733
Epoch 0, Step 1764: train/loss = 0.4659149646759033, train/raw-loss = 0.42149582505226135, train/logprobs = tensor([[-1.1642, -3.4696],
        [-2.1031, -0.6788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44419151544570923
Epoch 0, Step 1765: train/loss = 0.3991967439651489, train/raw-loss = 0.3571012616157532, train/logprobs = tensor([[-1.3212, -3.2038],
        [-2.2358, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4209551215171814
Epoch 0, Step 1766: train/loss = 0.3176974654197693, train/raw-loss = 0.2771112322807312, train/logprobs = tensor([[-1.7170, -6.4084],
        [-2.3100, -2.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4058624804019928
Epoch 0, Step 1767: train/loss = 0.24705904722213745, train/raw-loss = 0.19131743907928467, train/logprobs = tensor([[-1.0116, -5.8929],
        [-2.8994, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5574159622192383
Epoch 0, Step 1768: train/loss = 0.3791651725769043, train/raw-loss = 0.3425878882408142, train/logprobs = tensor([[-1.7174, -6.7901],
        [-3.1294, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657729923725128
Epoch 0, Step 1769: train/loss = 0.2871285080909729, train/raw-loss = 0.24148496985435486, train/logprobs = tensor([[-1.1846, -8.6190],
        [-2.4583, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45643550157546997
Epoch 0, Step 1770: train/loss = 0.362770140171051, train/raw-loss = 0.3155074119567871, train/logprobs = tensor([[-1.0620, -4.6791],
        [-3.1410, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4726272225379944
Epoch 0, Step 1771: train/loss = 0.3736993074417114, train/raw-loss = 0.3270071744918823, train/logprobs = tensor([[-1.5022, -7.9726],
        [-3.1236, -1.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46692147850990295
Epoch 0, Step 1772: train/loss = 0.2494405210018158, train/raw-loss = 0.20353306829929352, train/logprobs = tensor([[-1.5409, -5.7292],
        [-2.6418, -1.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4590744972229004
Epoch 0, Step 1773: train/loss = 0.8051573038101196, train/raw-loss = 0.7700537443161011, train/logprobs = tensor([[-2.1229, -2.6639],
        [-1.1799, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3510357737541199
Epoch 0, Step 1774: train/loss = 0.34503406286239624, train/raw-loss = 0.2901768088340759, train/logprobs = tensor([[-2.8375, -4.9983],
        [-4.1497, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5485724806785583
Epoch 0, Step 1775: train/loss = 0.3525145649909973, train/raw-loss = 0.3079068064689636, train/logprobs = tensor([[ -2.2205, -13.3413],
        [ -5.0392,  -4.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4460776448249817
Epoch 0, Step 1776: train/loss = 0.3388441503047943, train/raw-loss = 0.2837119698524475, train/logprobs = tensor([[-1.4752, -5.4721],
        [-3.1277, -1.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5513220429420471
Epoch 0, Step 1777: train/loss = 0.6032071709632874, train/raw-loss = 0.5652738809585571, train/logprobs = tensor([[-1.1567, -3.5718],
        [-2.8117, -1.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793332278728485
Epoch 0, Step 1778: train/loss = 0.7525882720947266, train/raw-loss = 0.7095816135406494, train/logprobs = tensor([[-2.2504, -2.8504],
        [-1.9394, -1.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43006688356399536
Epoch 0, Step 1779: train/loss = 0.36081767082214355, train/raw-loss = 0.3214443624019623, train/logprobs = tensor([[-1.1684, -6.3758],
        [-2.0774, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39373278617858887
Epoch 0, Step 1780: train/loss = 0.445848673582077, train/raw-loss = 0.4046122431755066, train/logprobs = tensor([[-1.1365, -6.2283],
        [-2.5237, -2.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41236424446105957
Epoch 0, Step 1781: train/loss = 0.09990845620632172, train/raw-loss = 0.051243796944618225, train/logprobs = tensor([[-1.6625, -8.1561],
        [-4.1432, -1.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4866466522216797
Epoch 0, Step 1782: train/loss = 0.5860245823860168, train/raw-loss = 0.5496987700462341, train/logprobs = tensor([[-1.3554, -3.4098],
        [-1.2086, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3632579743862152
Epoch 0, Step 1783: train/loss = 0.3974043130874634, train/raw-loss = 0.34989842772483826, train/logprobs = tensor([[-2.3472, -5.6140],
        [-3.1906, -1.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47505897283554077
Epoch 0, Step 1784: train/loss = 0.29256534576416016, train/raw-loss = 0.24116580188274384, train/logprobs = tensor([[-1.2474, -8.2418],
        [-2.9454, -1.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5139954686164856
Epoch 0, Step 1785: train/loss = 0.4637061655521393, train/raw-loss = 0.4142008423805237, train/logprobs = tensor([[-1.0417, -3.2581],
        [-2.6494, -2.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49505335092544556
Epoch 0, Step 1786: train/loss = 0.6450523734092712, train/raw-loss = 0.5948840975761414, train/logprobs = tensor([[-2.9272, -5.8703],
        [-2.9618, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5016827583312988
Epoch 0, Step 1787: train/loss = 0.16083849966526031, train/raw-loss = 0.10665098577737808, train/logprobs = tensor([[ -0.9669, -10.9580],
        [ -3.0160,  -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5418751239776611
Epoch 0, Step 1788: train/loss = 0.38104480504989624, train/raw-loss = 0.3305675983428955, train/logprobs = tensor([[-1.8763, -9.0857],
        [-2.5628, -3.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5047717094421387
Epoch 0, Step 1789: train/loss = 0.11254193633794785, train/raw-loss = 0.058298468589782715, train/logprobs = tensor([[-1.0454, -7.4055],
        [-3.2063, -0.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5424346923828125
Epoch 0, Step 1790: train/loss = 0.10058063268661499, train/raw-loss = 0.05205899477005005, train/logprobs = tensor([[-1.3347, -9.3889],
        [-4.3489, -2.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48521631956100464
Epoch 0, Step 1791: train/loss = 0.4549511969089508, train/raw-loss = 0.4073917865753174, train/logprobs = tensor([[-1.0370, -2.7950],
        [-1.9837, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4755939841270447
Epoch 0, Step 1792: train/loss = 0.37154391407966614, train/raw-loss = 0.3072650730609894, train/logprobs = tensor([[-1.6125, -8.8120],
        [-4.3710, -3.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6427884101867676
Epoch 0, Step 1793: train/loss = 1.18636953830719, train/raw-loss = 1.1524509191513062, train/logprobs = tensor([[-4.8332, -8.9513],
        [-1.8710, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3391849994659424
Epoch 0, Step 1794: train/loss = 0.21129992604255676, train/raw-loss = 0.17226290702819824, train/logprobs = tensor([[-0.8500, -9.7911],
        [-2.2276, -2.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39037013053894043
Epoch 0, Step 1795: train/loss = 0.27099499106407166, train/raw-loss = 0.22103480994701385, train/logprobs = tensor([[-1.7213, -9.5378],
        [-3.5297, -1.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4996020197868347
Epoch 0, Step 1796: train/loss = 0.43937307596206665, train/raw-loss = 0.38881126046180725, train/logprobs = tensor([[-1.2403, -3.9833],
        [-2.5754, -2.1262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5056182146072388
Epoch 0, Step 1797: train/loss = 0.3751497268676758, train/raw-loss = 0.3246203064918518, train/logprobs = tensor([[-1.1037, -6.2131],
        [-2.9303, -1.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5052944421768188
Epoch 0, Step 1798: train/loss = 0.25485527515411377, train/raw-loss = 0.20231425762176514, train/logprobs = tensor([[ -1.3706, -10.9460],
        [ -2.6253,  -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5254101157188416
Epoch 0, Step 1799: train/loss = 0.7613003253936768, train/raw-loss = 0.7162116765975952, train/logprobs = tensor([[-2.7119, -5.1764],
        [-1.9406, -1.3830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4508870244026184
Epoch 0, Step 1800: train/loss = 0.3135235905647278, train/raw-loss = 0.27011048793792725, train/logprobs = tensor([[-1.1650, -8.1935],
        [-1.9224, -2.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43413108587265015
Epoch 0, Step 1801: train/loss = 0.3851330876350403, train/raw-loss = 0.33281823992729187, train/logprobs = tensor([[-1.2472, -6.8659],
        [-4.2720, -2.6408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5231484174728394
Epoch 0, Step 1802: train/loss = 0.14141474664211273, train/raw-loss = 0.08400171995162964, train/logprobs = tensor([[-1.9550, -9.6829],
        [-3.9543, -2.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5741302371025085
Epoch 0, Step 1803: train/loss = 0.30902257561683655, train/raw-loss = 0.25999292731285095, train/logprobs = tensor([[-2.5906, -7.8086],
        [-4.3245, -1.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.490296870470047
Epoch 0, Step 1804: train/loss = 0.27394208312034607, train/raw-loss = 0.22141793370246887, train/logprobs = tensor([[-0.7862, -4.2012],
        [-2.1203, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5252416133880615
Epoch 0, Step 1805: train/loss = 0.2473735213279724, train/raw-loss = 0.19325584173202515, train/logprobs = tensor([[ -1.2387, -12.2360],
        [ -3.5255,  -1.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5411767363548279
Epoch 0, Step 1806: train/loss = 0.5199954509735107, train/raw-loss = 0.46695053577423096, train/logprobs = tensor([[-1.2288, -5.3703],
        [-2.7068, -3.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5304489135742188
Epoch 0, Step 1807: train/loss = 0.2619982957839966, train/raw-loss = 0.21044017374515533, train/logprobs = tensor([[-0.8354, -5.8057],
        [-2.3431, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5155811309814453
Epoch 0, Step 1808: train/loss = 0.23385103046894073, train/raw-loss = 0.18760111927986145, train/logprobs = tensor([[-1.8042, -8.1096],
        [-3.3657, -2.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4624992609024048
Epoch 0, Step 1809: train/loss = 0.33908283710479736, train/raw-loss = 0.2900119721889496, train/logprobs = tensor([[ -1.3939, -10.6876],
        [ -2.2549,  -3.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4907089173793793
Epoch 0, Step 1810: train/loss = 0.3591190576553345, train/raw-loss = 0.31847795844078064, train/logprobs = tensor([[-1.2013, -7.7636],
        [-2.4288, -1.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4064110219478607
Epoch 0, Step 1811: train/loss = 0.24665887653827667, train/raw-loss = 0.19968898594379425, train/logprobs = tensor([[ -1.3275, -10.7585],
        [ -3.8058,  -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46969905495643616
Epoch 0, Step 1812: train/loss = 0.4153969883918762, train/raw-loss = 0.3680519461631775, train/logprobs = tensor([[-0.7145, -5.0976],
        [-2.3772, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47345036268234253
Epoch 0, Step 1813: train/loss = 0.4643283784389496, train/raw-loss = 0.41039198637008667, train/logprobs = tensor([[-1.8490, -4.3911],
        [-3.4718, -1.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5393639802932739
Epoch 0, Step 1814: train/loss = 0.3774130940437317, train/raw-loss = 0.33408525586128235, train/logprobs = tensor([[-1.1127, -8.5192],
        [-2.8432, -1.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43327853083610535
Epoch 0, Step 1815: train/loss = 0.10347045958042145, train/raw-loss = 0.04950651898980141, train/logprobs = tensor([[-1.1384, -9.8687],
        [-3.9391, -1.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5396394729614258
Epoch 0, Step 1816: train/loss = 0.7573821544647217, train/raw-loss = 0.7077838778495789, train/logprobs = tensor([[-1.1723, -1.3921],
        [-2.1640, -2.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49598264694213867
Epoch 0, Step 1817: train/loss = 0.21847249567508698, train/raw-loss = 0.1690295785665512, train/logprobs = tensor([[-1.5067, -5.0916],
        [-3.5609, -1.2383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4944292902946472
Epoch 0, Step 1818: train/loss = 0.2948750853538513, train/raw-loss = 0.25447776913642883, train/logprobs = tensor([[-1.1745, -4.5879],
        [-2.4941, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4039729833602905
Epoch 0, Step 1819: train/loss = 0.2485356479883194, train/raw-loss = 0.19909536838531494, train/logprobs = tensor([[-2.5417, -4.9513],
        [-5.0378, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49440279603004456
Epoch 0, Step 1820: train/loss = 0.6079277992248535, train/raw-loss = 0.562086820602417, train/logprobs = tensor([[-1.7992, -5.0466],
        [-1.9952, -2.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4584096074104309
Epoch 0, Step 1821: train/loss = 0.32542353868484497, train/raw-loss = 0.2809782028198242, train/logprobs = tensor([[ -2.2222, -15.7593],
        [ -3.1033,  -3.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.444453626871109
Epoch 0, Step 1822: train/loss = 0.41268613934516907, train/raw-loss = 0.3648611009120941, train/logprobs = tensor([[-2.2482, -9.7656],
        [-4.1519, -1.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4782504141330719
Epoch 0, Step 1823: train/loss = 0.377865731716156, train/raw-loss = 0.3229587972164154, train/logprobs = tensor([[-1.2568, -3.2823],
        [-3.3102, -1.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5490689873695374
Epoch 0, Step 1824: train/loss = 0.5378637313842773, train/raw-loss = 0.4911801218986511, train/logprobs = tensor([[-1.3255, -3.1840],
        [-2.2039, -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.466836541891098
Epoch 0, Step 1825: train/loss = 0.08700275421142578, train/raw-loss = 0.028573384508490562, train/logprobs = tensor([[ -2.1411, -12.8939],
        [ -5.3909,  -1.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5842936635017395
Epoch 0, Step 1826: train/loss = 0.5382856726646423, train/raw-loss = 0.4809512794017792, train/logprobs = tensor([[-2.1009, -3.9689],
        [-3.4882, -3.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5733436346054077
Epoch 0, Step 1827: train/loss = 0.6290510296821594, train/raw-loss = 0.5812829732894897, train/logprobs = tensor([[-1.7862, -6.4530],
        [-2.0625, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47768035531044006
Epoch 0, Step 1828: train/loss = 0.1225535124540329, train/raw-loss = 0.06509965658187866, train/logprobs = tensor([[-0.8309, -6.1738],
        [-3.5998, -1.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5745385885238647
Epoch 0, Step 1829: train/loss = 0.49074599146842957, train/raw-loss = 0.4390621483325958, train/logprobs = tensor([[-0.7737, -5.4843],
        [-3.2306, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5168383717536926
Epoch 0, Step 1830: train/loss = 0.48176392912864685, train/raw-loss = 0.4055505394935608, train/logprobs = tensor([[-0.9465, -3.2352],
        [-4.0679, -3.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7621340155601501
Epoch 0, Step 1831: train/loss = 0.3646741807460785, train/raw-loss = 0.3284330368041992, train/logprobs = tensor([[-0.8510, -3.1723],
        [-1.7958, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3624114692211151
Epoch 0, Step 1832: train/loss = 0.3936663568019867, train/raw-loss = 0.3507898151874542, train/logprobs = tensor([[-1.5762, -8.0086],
        [-3.5070, -1.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4287654757499695
Epoch 0, Step 1833: train/loss = 0.2564367949962616, train/raw-loss = 0.19607068598270416, train/logprobs = tensor([[-1.6208, -5.3033],
        [-3.9146, -2.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6036612391471863
Epoch 0, Step 1834: train/loss = 0.4484858810901642, train/raw-loss = 0.38208213448524475, train/logprobs = tensor([[-0.8556, -5.4302],
        [-3.3060, -1.2860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6640377640724182
Epoch 0, Step 1835: train/loss = 0.3944147825241089, train/raw-loss = 0.35117658972740173, train/logprobs = tensor([[-2.6847, -8.6560],
        [-4.5268, -2.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43238168954849243
Epoch 0, Step 1836: train/loss = 0.331028014421463, train/raw-loss = 0.26057326793670654, train/logprobs = tensor([[-1.2502, -6.7455],
        [-4.1213, -2.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7045474052429199
Epoch 0, Step 1837: train/loss = 0.2507980465888977, train/raw-loss = 0.20011956989765167, train/logprobs = tensor([[-1.2506, -7.0564],
        [-2.7409, -2.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5067850351333618
Epoch 0, Step 1838: train/loss = 0.11881297826766968, train/raw-loss = 0.05998014286160469, train/logprobs = tensor([[-1.1689, -9.4062],
        [-3.8704, -0.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5883283615112305
Epoch 0, Step 1839: train/loss = 0.44807565212249756, train/raw-loss = 0.403424471616745, train/logprobs = tensor([[-1.3005, -6.8767],
        [-2.5043, -1.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4465118646621704
Epoch 0, Step 1840: train/loss = 0.10975185036659241, train/raw-loss = 0.040225643664598465, train/logprobs = tensor([[-1.1074, -8.8279],
        [-3.9693, -1.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6952621340751648
Epoch 0, Step 1841: train/loss = 0.28521835803985596, train/raw-loss = 0.21473033726215363, train/logprobs = tensor([[-0.9455, -8.1774],
        [-3.6673, -1.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7048802375793457
Epoch 0, Step 1842: train/loss = 0.13437440991401672, train/raw-loss = 0.08449583500623703, train/logprobs = tensor([[-1.5371, -6.9959],
        [-3.9905, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49878576397895813
Epoch 0, Step 1843: train/loss = 0.3632175326347351, train/raw-loss = 0.30883118510246277, train/logprobs = tensor([[-1.8913, -7.0270],
        [-3.5407, -1.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5438634157180786
Epoch 0, Step 1844: train/loss = 0.2601422369480133, train/raw-loss = 0.20026493072509766, train/logprobs = tensor([[-1.0798, -6.6450],
        [-3.9188, -1.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5987730026245117
Epoch 0, Step 1845: train/loss = 0.07666096091270447, train/raw-loss = 0.02475452609360218, train/logprobs = tensor([[ -1.0371, -13.9720],
        [ -4.0582,  -1.9249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5190643072128296
Epoch 0, Step 1846: train/loss = 0.3808433413505554, train/raw-loss = 0.3257094621658325, train/logprobs = tensor([[-1.6992, -4.8903],
        [-4.3697, -2.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5513389110565186
Epoch 0, Step 1847: train/loss = 0.6560478806495667, train/raw-loss = 0.6060916185379028, train/logprobs = tensor([[-2.1183, -5.8437],
        [-2.9219, -2.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4995623230934143
Epoch 0, Step 1848: train/loss = 0.6390508413314819, train/raw-loss = 0.5933993458747864, train/logprobs = tensor([[-3.4202, -9.5117],
        [-2.4533, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45651504397392273
Epoch 0, Step 1849: train/loss = 0.5876479148864746, train/raw-loss = 0.5445137023925781, train/logprobs = tensor([[-1.4311, -2.4440],
        [-2.5428, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4313412010669708
Epoch 0, Step 1850: train/loss = 0.30683571100234985, train/raw-loss = 0.26137083768844604, train/logprobs = tensor([[-1.2090, -4.0329],
        [-2.4895, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45464888215065
Epoch 0, Step 1851: train/loss = 0.4955272674560547, train/raw-loss = 0.43789416551589966, train/logprobs = tensor([[-1.2634, -5.6038],
        [-3.9477, -3.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5763310194015503
Epoch 0, Step 1852: train/loss = 0.2490634322166443, train/raw-loss = 0.18768513202667236, train/logprobs = tensor([[-1.5525, -8.3601],
        [-3.8942, -1.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6137828826904297
Epoch 0, Step 1853: train/loss = 0.6536135673522949, train/raw-loss = 0.6084905862808228, train/logprobs = tensor([[-2.9717, -3.6724],
        [-3.9490, -3.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4512298107147217
Epoch 0, Step 1854: train/loss = 0.7144631147384644, train/raw-loss = 0.6774420142173767, train/logprobs = tensor([[-2.2937, -3.7560],
        [-1.7980, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3702114522457123
Epoch 0, Step 1855: train/loss = 0.33120259642601013, train/raw-loss = 0.2812340259552002, train/logprobs = tensor([[-1.4724, -6.3163],
        [-2.8526, -2.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4996855854988098
Epoch 0, Step 1856: train/loss = 0.32941555976867676, train/raw-loss = 0.2742655873298645, train/logprobs = tensor([[-0.7586, -6.4916],
        [-2.4886, -2.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5514996647834778
Epoch 0, Step 1857: train/loss = 0.3387000858783722, train/raw-loss = 0.28216010332107544, train/logprobs = tensor([[-1.1993, -8.2920],
        [-4.2046, -4.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5653996467590332
Epoch 0, Step 1858: train/loss = 0.49166741967201233, train/raw-loss = 0.4324280023574829, train/logprobs = tensor([[-0.9877, -4.6454],
        [-3.0172, -2.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5923944711685181
Epoch 0, Step 1859: train/loss = 0.4064343571662903, train/raw-loss = 0.33760082721710205, train/logprobs = tensor([[-1.0213, -6.6095],
        [-4.3386, -2.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6883352994918823
Epoch 0, Step 1860: train/loss = 0.3859923481941223, train/raw-loss = 0.3258976936340332, train/logprobs = tensor([[-0.9906, -5.3051],
        [-3.3771, -2.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6009464263916016
Epoch 0, Step 1861: train/loss = 0.5200516581535339, train/raw-loss = 0.4720155596733093, train/logprobs = tensor([[-2.2665, -6.2602],
        [-2.7203, -1.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48036083579063416
Epoch 0, Step 1862: train/loss = 0.21312177181243896, train/raw-loss = 0.16799858212471008, train/logprobs = tensor([[-1.8464, -9.3870],
        [-3.3807, -1.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4512317478656769
Epoch 0, Step 1863: train/loss = 0.2078821212053299, train/raw-loss = 0.15397585928440094, train/logprobs = tensor([[-0.7704, -9.3542],
        [-4.0081, -1.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5390626192092896
Epoch 0, Step 1864: train/loss = 0.40480634570121765, train/raw-loss = 0.3479483723640442, train/logprobs = tensor([[ -1.2281, -11.7209],
        [ -3.0107,  -2.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5685796141624451
Epoch 0, Step 1865: train/loss = 0.5104771852493286, train/raw-loss = 0.4533693194389343, train/logprobs = tensor([[-0.7146, -6.7111],
        [-3.6951, -2.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5710791349411011
Epoch 0, Step 1866: train/loss = 0.42042529582977295, train/raw-loss = 0.36247017979621887, train/logprobs = tensor([[-1.8254, -5.1700],
        [-3.6137, -1.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5795511603355408
Epoch 0, Step 1867: train/loss = 0.1896301954984665, train/raw-loss = 0.13168786466121674, train/logprobs = tensor([[-2.2490, -4.8914],
        [-4.9563, -1.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5794233083724976
Epoch 0, Step 1868: train/loss = 0.7582644820213318, train/raw-loss = 0.6993638277053833, train/logprobs = tensor([[-0.6287, -2.8921],
        [-2.6664, -2.3919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5890071392059326
Epoch 0, Step 1869: train/loss = 0.28019458055496216, train/raw-loss = 0.22360286116600037, train/logprobs = tensor([[-0.9838, -5.7409],
        [-3.7210, -1.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5659171342849731
Epoch 0, Step 1870: train/loss = 0.23488682508468628, train/raw-loss = 0.1839764565229416, train/logprobs = tensor([[-1.0102, -7.0433],
        [-2.8935, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5091035962104797
Epoch 0, Step 1871: train/loss = 0.40927407145500183, train/raw-loss = 0.35662126541137695, train/logprobs = tensor([[-1.1998, -3.6483],
        [-2.6301, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5265276432037354
Epoch 0, Step 1872: train/loss = 0.5512992143630981, train/raw-loss = 0.4953707754611969, train/logprobs = tensor([[-1.1645, -8.9688],
        [-3.2266, -2.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5592845678329468
Epoch 0, Step 1873: train/loss = 0.28293246030807495, train/raw-loss = 0.22365808486938477, train/logprobs = tensor([[-1.3067, -4.1211],
        [-4.2998, -1.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5927438139915466
Epoch 0, Step 1874: train/loss = 0.28565865755081177, train/raw-loss = 0.23936033248901367, train/logprobs = tensor([[-0.6718, -4.7341],
        [-2.3867, -1.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46298307180404663
Epoch 0, Step 1875: train/loss = 0.7473594546318054, train/raw-loss = 0.6886787414550781, train/logprobs = tensor([[-2.8200, -6.5962],
        [-3.1873, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.586807131767273
Epoch 0, Step 1876: train/loss = 0.2860274314880371, train/raw-loss = 0.2320869117975235, train/logprobs = tensor([[-0.8235, -3.5338],
        [-2.5776, -1.3519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.539405345916748
Epoch 0, Step 1877: train/loss = 0.5464543104171753, train/raw-loss = 0.4951322674751282, train/logprobs = tensor([[-1.2153, -4.9726],
        [-4.2093, -2.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5132206678390503
Epoch 0, Step 1878: train/loss = 0.23188042640686035, train/raw-loss = 0.18966913223266602, train/logprobs = tensor([[-0.8779, -6.4452],
        [-2.3568, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4221128523349762
Epoch 0, Step 1879: train/loss = 0.6051746010780334, train/raw-loss = 0.558416485786438, train/logprobs = tensor([[-1.8414, -3.9584],
        [-3.0901, -2.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4675811529159546
Epoch 0, Step 1880: train/loss = 0.5941455364227295, train/raw-loss = 0.5386013388633728, train/logprobs = tensor([[-1.2028, -3.4753],
        [-3.2228, -2.3135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5554414987564087
Epoch 0, Step 1881: train/loss = 0.6199831962585449, train/raw-loss = 0.5812408924102783, train/logprobs = tensor([[-2.4606, -4.3076],
        [-2.3573, -2.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3874228298664093
Epoch 0, Step 1882: train/loss = 0.2652173936367035, train/raw-loss = 0.2078854739665985, train/logprobs = tensor([[-1.5442, -7.5203],
        [-4.3976, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5733190178871155
Epoch 0, Step 1883: train/loss = 0.2676035463809967, train/raw-loss = 0.21412308514118195, train/logprobs = tensor([[-1.3371, -3.4395],
        [-2.8190, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5348047018051147
Epoch 0, Step 1884: train/loss = 0.14342069625854492, train/raw-loss = 0.09699312597513199, train/logprobs = tensor([[-1.0747, -8.0877],
        [-2.7223, -2.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46427565813064575
Epoch 0, Step 1885: train/loss = 0.48279833793640137, train/raw-loss = 0.43267709016799927, train/logprobs = tensor([[-1.1312, -5.8215],
        [-2.3206, -1.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5012127161026001
Epoch 0, Step 1886: train/loss = 0.3462564945220947, train/raw-loss = 0.2892424464225769, train/logprobs = tensor([[-1.9383, -6.1102],
        [-4.5010, -3.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5701403617858887
Epoch 0, Step 1887: train/loss = 0.6259609460830688, train/raw-loss = 0.592147946357727, train/logprobs = tensor([[-1.2351, -3.9585],
        [-2.5547, -1.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381301760673523
Epoch 0, Step 1888: train/loss = 0.12265101075172424, train/raw-loss = 0.07131610065698624, train/logprobs = tensor([[-2.1022, -7.9113],
        [-4.6523, -1.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5133490562438965
Epoch 0, Step 1889: train/loss = 0.27068522572517395, train/raw-loss = 0.21930544078350067, train/logprobs = tensor([[ -1.3102, -11.1800],
        [ -4.2955,  -2.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5137978196144104
Epoch 0, Step 1890: train/loss = 0.29676443338394165, train/raw-loss = 0.2419559210538864, train/logprobs = tensor([[-0.8449, -8.5301],
        [-3.0430, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5480852127075195
Epoch 0, Step 1891: train/loss = 0.41158634424209595, train/raw-loss = 0.34601572155952454, train/logprobs = tensor([[-1.2571, -7.2884],
        [-5.1967, -3.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6557060480117798
Epoch 0, Step 1892: train/loss = 0.32006895542144775, train/raw-loss = 0.2776120901107788, train/logprobs = tensor([[-1.1579, -5.8004],
        [-2.3449, -1.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42456871271133423
Epoch 0, Step 1893: train/loss = 0.224381685256958, train/raw-loss = 0.18419556319713593, train/logprobs = tensor([[-1.4397, -3.3069],
        [-2.9114, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4018611013889313
Epoch 0, Step 1894: train/loss = 0.21472454071044922, train/raw-loss = 0.17124366760253906, train/logprobs = tensor([[-1.5537, -8.3640],
        [-3.5206, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4348086714744568
Epoch 0, Step 1895: train/loss = 0.2454969584941864, train/raw-loss = 0.19839006662368774, train/logprobs = tensor([[-1.5356, -5.3476],
        [-3.8943, -1.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4710690379142761
Epoch 0, Step 1896: train/loss = 0.9746981263160706, train/raw-loss = 0.9260274171829224, train/logprobs = tensor([[-4.3951, -8.4561],
        [-4.3608, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48670774698257446
Epoch 0, Step 1897: train/loss = 0.4863106310367584, train/raw-loss = 0.422934889793396, train/logprobs = tensor([[-1.0554, -4.5109],
        [-4.1915, -3.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6337575316429138
Epoch 0, Step 1898: train/loss = 0.5722647905349731, train/raw-loss = 0.5196822881698608, train/logprobs = tensor([[-1.1863, -7.4549],
        [-2.7964, -3.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258248448371887
Epoch 0, Step 1899: train/loss = 0.1723073124885559, train/raw-loss = 0.11337795853614807, train/logprobs = tensor([[ -1.2093, -14.9720],
        [ -3.9726,  -3.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5892934203147888
Epoch 0, Step 1900: train/loss = 0.27940768003463745, train/raw-loss = 0.22990991175174713, train/logprobs = tensor([[-1.5755, -8.4875],
        [-4.5013, -2.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49497780203819275
Epoch 0, Step 1901: train/loss = 0.5142163038253784, train/raw-loss = 0.4768696129322052, train/logprobs = tensor([[-1.0861, -3.9319],
        [-1.7470, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37346696853637695
Epoch 0, Step 1902: train/loss = 0.7497048377990723, train/raw-loss = 0.7005380392074585, train/logprobs = tensor([[-1.3001, -7.0764],
        [-4.0575, -3.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49166738986968994
Epoch 0, Step 1903: train/loss = 0.4626830220222473, train/raw-loss = 0.41917479038238525, train/logprobs = tensor([[-1.0147, -3.3175],
        [-2.5422, -2.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43508249521255493
Epoch 0, Step 1904: train/loss = 0.25601810216903687, train/raw-loss = 0.20768366754055023, train/logprobs = tensor([[-2.0813, -8.8590],
        [-4.8980, -1.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4833441376686096
Epoch 0, Step 1905: train/loss = 0.14022672176361084, train/raw-loss = 0.09194013476371765, train/logprobs = tensor([[ -1.4213, -10.5439],
        [ -4.1629,  -3.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48286592960357666
Epoch 0, Step 1906: train/loss = 0.48550039529800415, train/raw-loss = 0.43804436922073364, train/logprobs = tensor([[-1.0627, -3.7639],
        [-2.9858, -2.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4745602309703827
Epoch 0, Step 1907: train/loss = 0.21297180652618408, train/raw-loss = 0.15557104349136353, train/logprobs = tensor([[ -0.8173, -11.1342],
        [ -3.7980,  -1.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5740073919296265
Epoch 0, Step 1908: train/loss = 0.7954434752464294, train/raw-loss = 0.7307106852531433, train/logprobs = tensor([[-1.2115, -3.3631],
        [-4.0803, -3.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6473270654678345
Epoch 0, Step 1909: train/loss = 0.23544135689735413, train/raw-loss = 0.18137437105178833, train/logprobs = tensor([[-1.3663, -6.0619],
        [-4.5238, -2.2849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5406697392463684
Epoch 0, Step 1910: train/loss = 0.9819868803024292, train/raw-loss = 0.9443091154098511, train/logprobs = tensor([[-2.9385, -4.3339],
        [-1.3232, -1.0465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37677836418151855
Epoch 0, Step 1911: train/loss = 0.29110270738601685, train/raw-loss = 0.236564040184021, train/logprobs = tensor([[-1.4382, -6.1721],
        [-5.0188, -1.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5453866124153137
Epoch 0, Step 1912: train/loss = 0.4063984453678131, train/raw-loss = 0.3663405478000641, train/logprobs = tensor([[-0.8425, -6.4847],
        [-2.0248, -2.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4005790948867798
Epoch 0, Step 1913: train/loss = 0.30032065510749817, train/raw-loss = 0.24219773709774017, train/logprobs = tensor([[-1.0279, -5.9149],
        [-2.9039, -2.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5812288522720337
Epoch 0, Step 1914: train/loss = 0.4538649320602417, train/raw-loss = 0.4073522686958313, train/logprobs = tensor([[-3.0634, -5.4038],
        [-4.4363, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4651262164115906
Epoch 0, Step 1915: train/loss = 0.11917778849601746, train/raw-loss = 0.06833399832248688, train/logprobs = tensor([[-1.4982, -5.0824],
        [-4.5503, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.508437991142273
Epoch 0, Step 1916: train/loss = 0.3010525703430176, train/raw-loss = 0.2512892186641693, train/logprobs = tensor([[-2.4025, -8.6149],
        [-4.3922, -1.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49763357639312744
Epoch 0, Step 1917: train/loss = 0.49501028656959534, train/raw-loss = 0.4446839988231659, train/logprobs = tensor([[-1.2114, -3.5718],
        [-2.9002, -2.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5032628774642944
Epoch 0, Step 1918: train/loss = 0.6089426875114441, train/raw-loss = 0.5408222675323486, train/logprobs = tensor([[-2.0289, -7.2012],
        [-4.3785, -3.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6812043786048889
Epoch 0, Step 1919: train/loss = 0.448323130607605, train/raw-loss = 0.40298333764076233, train/logprobs = tensor([[-0.8258, -5.3317],
        [-2.3154, -2.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45339757204055786
Epoch 0, Step 1920: train/loss = 0.15275099873542786, train/raw-loss = 0.09381081163883209, train/logprobs = tensor([[-1.7713, -9.9018],
        [-4.4927, -1.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.58940190076828
Epoch 0, Step 1921: train/loss = 0.48044806718826294, train/raw-loss = 0.43241778016090393, train/logprobs = tensor([[-1.0412, -3.2345],
        [-3.1863, -2.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4803029000759125
Epoch 0, Step 1922: train/loss = 0.40442681312561035, train/raw-loss = 0.3638935685157776, train/logprobs = tensor([[-3.0194, -7.3282],
        [-3.7755, -1.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4053323268890381
Epoch 0, Step 1923: train/loss = 0.6790273785591125, train/raw-loss = 0.6166931986808777, train/logprobs = tensor([[-1.3699, -2.9135],
        [-3.8552, -3.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6233421564102173
Epoch 0, Step 1924: train/loss = 0.4495917558670044, train/raw-loss = 0.40957382321357727, train/logprobs = tensor([[-0.9714, -3.9077],
        [-1.8094, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4001792073249817
Epoch 0, Step 1925: train/loss = 0.1790284812450409, train/raw-loss = 0.1328645795583725, train/logprobs = tensor([[-1.5975, -8.2701],
        [-3.7032, -2.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4616389870643616
Epoch 0, Step 1926: train/loss = 0.42045074701309204, train/raw-loss = 0.3695509433746338, train/logprobs = tensor([[-1.7563, -2.9116],
        [-2.6370, -1.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5089980363845825
Epoch 0, Step 1927: train/loss = 0.5050125122070312, train/raw-loss = 0.4561138153076172, train/logprobs = tensor([[-1.2401, -3.0600],
        [-2.6025, -2.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4889873266220093
Epoch 0, Step 1928: train/loss = 0.11265364289283752, train/raw-loss = 0.06042680889368057, train/logprobs = tensor([[ -0.9241, -11.9698],
        [ -3.1984,  -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5222682356834412
Epoch 0, Step 1929: train/loss = 0.3598323166370392, train/raw-loss = 0.3125772774219513, train/logprobs = tensor([[-1.2628, -6.6970],
        [-3.7338, -1.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47255048155784607
Epoch 0, Step 1930: train/loss = 0.28596463799476624, train/raw-loss = 0.23998722434043884, train/logprobs = tensor([[-1.0344, -4.3973],
        [-1.9638, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4597742557525635
Epoch 0, Step 1931: train/loss = 0.34866711497306824, train/raw-loss = 0.30901575088500977, train/logprobs = tensor([[-1.5496, -9.0972],
        [-2.5553, -2.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39651376008987427
Epoch 0, Step 1932: train/loss = 0.4884231984615326, train/raw-loss = 0.45121872425079346, train/logprobs = tensor([[-1.5593, -3.7130],
        [-2.0533, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3720449209213257
Epoch 0, Step 1933: train/loss = 0.8709580898284912, train/raw-loss = 0.8283872604370117, train/logprobs = tensor([[ -4.2314, -12.6374],
        [ -3.7189,  -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42570796608924866
Epoch 0, Step 1934: train/loss = 0.6396072506904602, train/raw-loss = 0.5952941179275513, train/logprobs = tensor([[-0.9372, -3.2028],
        [-2.7504, -2.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44313138723373413
Epoch 0, Step 1935: train/loss = 0.7290662527084351, train/raw-loss = 0.684824526309967, train/logprobs = tensor([[-3.2839, -6.9160],
        [-2.9156, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44241729378700256
Epoch 0, Step 1936: train/loss = 0.10083454847335815, train/raw-loss = 0.05766499787569046, train/logprobs = tensor([[-1.6130, -8.1148],
        [-4.1153, -1.3115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43169543147087097
Epoch 0, Step 1937: train/loss = 0.15655235946178436, train/raw-loss = 0.10850507020950317, train/logprobs = tensor([[-1.5988, -6.9237],
        [-3.4205, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4804728627204895
Epoch 0, Step 1938: train/loss = 0.34480422735214233, train/raw-loss = 0.3004884123802185, train/logprobs = tensor([[-1.0861, -7.5965],
        [-2.6151, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44315820932388306
Epoch 0, Step 1939: train/loss = 0.18290188908576965, train/raw-loss = 0.1367555558681488, train/logprobs = tensor([[-0.8356, -6.3466],
        [-2.6143, -1.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46146315336227417
Epoch 0, Step 1940: train/loss = 0.37744420766830444, train/raw-loss = 0.3258077800273895, train/logprobs = tensor([[-1.4673, -7.5828],
        [-4.2150, -1.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5163639783859253
Epoch 0, Step 1941: train/loss = 0.1487540602684021, train/raw-loss = 0.09664930403232574, train/logprobs = tensor([[-1.2557, -8.5959],
        [-3.6695, -1.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5210475325584412
Epoch 0, Step 1942: train/loss = 0.3593737781047821, train/raw-loss = 0.31020018458366394, train/logprobs = tensor([[-3.0091, -9.8135],
        [-4.1573, -3.3656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49173611402511597
Epoch 0, Step 1943: train/loss = 0.4299052953720093, train/raw-loss = 0.3934473991394043, train/logprobs = tensor([[-2.3687, -4.9403],
        [-2.2739, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645789325237274
Epoch 0, Step 1944: train/loss = 0.3692752718925476, train/raw-loss = 0.31524038314819336, train/logprobs = tensor([[-0.9622, -3.4154],
        [-3.3986, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5403490662574768
Epoch 0, Step 1945: train/loss = 0.26945823431015015, train/raw-loss = 0.22382065653800964, train/logprobs = tensor([[-1.5534, -9.9799],
        [-3.5428, -1.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4563755989074707
Epoch 0, Step 1946: train/loss = 0.3205353617668152, train/raw-loss = 0.26941725611686707, train/logprobs = tensor([[-1.2895, -5.8227],
        [-3.5819, -1.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5111808180809021
Epoch 0, Step 1947: train/loss = 0.4951523542404175, train/raw-loss = 0.44407400488853455, train/logprobs = tensor([[-1.2465, -2.7060],
        [-2.7680, -2.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5107836723327637
Epoch 0, Step 1948: train/loss = 0.2573280930519104, train/raw-loss = 0.20178639888763428, train/logprobs = tensor([[-1.3035, -5.3894],
        [-4.6344, -1.7337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5554170608520508
Epoch 0, Step 1949: train/loss = 0.4074064791202545, train/raw-loss = 0.3656535744667053, train/logprobs = tensor([[-1.8440, -5.0168],
        [-2.4219, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175293445587158
Epoch 0, Step 1950: train/loss = 0.5122907161712646, train/raw-loss = 0.4659464955329895, train/logprobs = tensor([[-2.4013, -7.3958],
        [-4.1772, -3.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4634418487548828
Epoch 0, Step 1951: train/loss = 0.38814547657966614, train/raw-loss = 0.32760336995124817, train/logprobs = tensor([[-1.5890, -7.3130],
        [-3.7171, -3.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6054210662841797
Epoch 0, Step 1952: train/loss = 0.8329205513000488, train/raw-loss = 0.7788399457931519, train/logprobs = tensor([[-2.3771, -3.4269],
        [-3.6916, -2.4288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5408061742782593
Epoch 0, Step 1953: train/loss = 0.1744501143693924, train/raw-loss = 0.12992419302463531, train/logprobs = tensor([[-2.1243, -7.7961],
        [-3.6077, -1.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4452592134475708
Epoch 0, Step 1954: train/loss = 0.5453227758407593, train/raw-loss = 0.5061378479003906, train/logprobs = tensor([[-0.9876, -4.2284],
        [-2.2932, -2.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39184901118278503
Epoch 0, Step 1955: train/loss = 0.4281257092952728, train/raw-loss = 0.3906511664390564, train/logprobs = tensor([[-1.4121, -6.5414],
        [-2.0171, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37474536895751953
Epoch 0, Step 1956: train/loss = 0.10668493062257767, train/raw-loss = 0.057373736053705215, train/logprobs = tensor([[ -1.0314, -12.7085],
        [ -3.1978,  -1.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4931119382381439
Epoch 0, Step 1957: train/loss = 0.3463496267795563, train/raw-loss = 0.291040301322937, train/logprobs = tensor([[-0.9032, -7.0416],
        [-2.1692, -2.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5530931949615479
Epoch 0, Step 1958: train/loss = 0.2776254415512085, train/raw-loss = 0.21489641070365906, train/logprobs = tensor([[-1.5801, -9.5766],
        [-4.0838, -2.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6272903680801392
Epoch 0, Step 1959: train/loss = 0.3885554075241089, train/raw-loss = 0.32353559136390686, train/logprobs = tensor([[ -0.9750, -10.8451],
        [ -4.3757,  -3.5034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6501981019973755
Epoch 0, Step 1960: train/loss = 0.7857478260993958, train/raw-loss = 0.7361821532249451, train/logprobs = tensor([[-2.9643, -2.9737],
        [-4.4721, -2.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49565625190734863
Epoch 0, Step 1961: train/loss = 0.17083369195461273, train/raw-loss = 0.13251855969429016, train/logprobs = tensor([[ -1.4911, -14.4143],
        [ -2.7214,  -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38315123319625854
Epoch 0, Step 1962: train/loss = 0.31473204493522644, train/raw-loss = 0.26909199357032776, train/logprobs = tensor([[-1.5438, -5.4669],
        [-3.2195, -1.4907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4564002454280853
Epoch 0, Step 1963: train/loss = 0.2958890497684479, train/raw-loss = 0.23841838538646698, train/logprobs = tensor([[-2.1302, -5.8120],
        [-4.4305, -1.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5747065544128418
Epoch 0, Step 1964: train/loss = 0.17616739869117737, train/raw-loss = 0.13589134812355042, train/logprobs = tensor([[ -2.1279, -11.5102],
        [ -4.1703,  -3.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4027606248855591
Epoch 0, Step 1965: train/loss = 0.26260000467300415, train/raw-loss = 0.21643692255020142, train/logprobs = tensor([[-1.8083, -6.7134],
        [-2.9881, -2.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4616307318210602
Epoch 0, Step 1966: train/loss = 0.4216533303260803, train/raw-loss = 0.37684208154678345, train/logprobs = tensor([[-1.9297, -5.1630],
        [-2.4737, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4481121897697449
Epoch 0, Step 1967: train/loss = 0.5561384558677673, train/raw-loss = 0.5096400380134583, train/logprobs = tensor([[-1.2168, -4.1873],
        [-2.7833, -2.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4649842381477356
Epoch 0, Step 1968: train/loss = 0.19061224162578583, train/raw-loss = 0.14290595054626465, train/logprobs = tensor([[-2.1845, -8.4335],
        [-4.5862, -2.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47706276178359985
Epoch 0, Step 1969: train/loss = 0.2188332974910736, train/raw-loss = 0.1703149974346161, train/logprobs = tensor([[-1.0952, -5.4607],
        [-2.9232, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4851830005645752
Epoch 0, Step 1970: train/loss = 0.43151557445526123, train/raw-loss = 0.386372834444046, train/logprobs = tensor([[-1.8774, -9.7093],
        [-2.2203, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4514276385307312
Epoch 0, Step 1971: train/loss = 0.2922575771808624, train/raw-loss = 0.2513854205608368, train/logprobs = tensor([[ -1.2489, -13.5733],
        [ -1.9608,  -3.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4087214469909668
Epoch 0, Step 1972: train/loss = 0.4318937063217163, train/raw-loss = 0.39701351523399353, train/logprobs = tensor([[-1.2780, -3.4966],
        [-1.9373, -1.4004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488016426563263
Epoch 0, Step 1973: train/loss = 0.5029654502868652, train/raw-loss = 0.4596099257469177, train/logprobs = tensor([[-2.0593, -4.6372],
        [-3.5462, -1.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335554838180542
Epoch 0, Step 1974: train/loss = 0.60430908203125, train/raw-loss = 0.5613963603973389, train/logprobs = tensor([[-1.4988, -2.5542],
        [-2.5697, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42912712693214417
Epoch 0, Step 1975: train/loss = 0.277507483959198, train/raw-loss = 0.23470309376716614, train/logprobs = tensor([[-1.6116, -7.4691],
        [-4.2897, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42804408073425293
Epoch 0, Step 1976: train/loss = 0.3515744209289551, train/raw-loss = 0.302518755197525, train/logprobs = tensor([[-1.3811, -6.5347],
        [-2.9368, -2.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49055683612823486
Epoch 0, Step 1977: train/loss = 0.5425534844398499, train/raw-loss = 0.4952915906906128, train/logprobs = tensor([[-1.5388, -7.2547],
        [-2.5927, -2.1959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47261881828308105
Epoch 0, Step 1978: train/loss = 0.4094548523426056, train/raw-loss = 0.3709860146045685, train/logprobs = tensor([[-0.6972, -8.7807],
        [-2.5216, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38468870520591736
Epoch 0, Step 1979: train/loss = 0.26202502846717834, train/raw-loss = 0.20172658562660217, train/logprobs = tensor([[-1.4681, -6.3834],
        [-4.7930, -4.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6029845476150513
Epoch 0, Step 1980: train/loss = 0.1177658885717392, train/raw-loss = 0.06878043711185455, train/logprobs = tensor([[ -1.4970, -11.4865],
        [ -3.8971,  -1.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48985451459884644
Epoch 0, Step 1981: train/loss = 0.3423689603805542, train/raw-loss = 0.29997700452804565, train/logprobs = tensor([[-1.3273, -3.2614],
        [-2.6349, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42391976714134216
Epoch 0, Step 1982: train/loss = 0.33875352144241333, train/raw-loss = 0.2936848998069763, train/logprobs = tensor([[-1.8516, -3.9159],
        [-2.8559, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45068633556365967
Epoch 0, Step 1983: train/loss = 0.48490452766418457, train/raw-loss = 0.43590468168258667, train/logprobs = tensor([[-1.6668, -8.4017],
        [-3.4027, -2.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48999860882759094
Epoch 0, Step 1984: train/loss = 1.1279737949371338, train/raw-loss = 1.0926330089569092, train/logprobs = tensor([[-4.3585, -3.6107],
        [-1.9804, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3534069061279297
Epoch 0, Step 1985: train/loss = 0.1938168853521347, train/raw-loss = 0.1466035544872284, train/logprobs = tensor([[ -1.8458, -11.6143],
        [ -3.2061,  -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47213318943977356
Epoch 0, Step 1986: train/loss = 0.17256489396095276, train/raw-loss = 0.12959060072898865, train/logprobs = tensor([[-1.7976, -7.1960],
        [-3.6682, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4297429323196411
Epoch 0, Step 1987: train/loss = 0.4040091335773468, train/raw-loss = 0.3578977584838867, train/logprobs = tensor([[-1.6441, -5.0384],
        [-2.7692, -1.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46111389994621277
Epoch 0, Step 1988: train/loss = 0.31386446952819824, train/raw-loss = 0.2661897540092468, train/logprobs = tensor([[-1.7773, -6.4108],
        [-2.6518, -1.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4767472743988037
Epoch 0, Step 1989: train/loss = 0.28408342599868774, train/raw-loss = 0.23290792107582092, train/logprobs = tensor([[-1.2760, -7.8900],
        [-4.0277, -1.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5117547512054443
Epoch 0, Step 1990: train/loss = 0.6937804818153381, train/raw-loss = 0.6559863090515137, train/logprobs = tensor([[-1.9773, -2.9201],
        [-1.2090, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3779418468475342
Epoch 0, Step 1991: train/loss = 0.23070028424263, train/raw-loss = 0.18902762234210968, train/logprobs = tensor([[-0.7389, -4.7511],
        [-1.8509, -1.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41672655940055847
Epoch 0, Step 1992: train/loss = 0.11228343099355698, train/raw-loss = 0.05200794339179993, train/logprobs = tensor([[-1.4866, -9.2045],
        [-4.8585, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6027548909187317
Epoch 0, Step 1993: train/loss = 0.2703245282173157, train/raw-loss = 0.22874462604522705, train/logprobs = tensor([[ -1.1563, -14.4566],
        [ -3.3171,  -2.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41579878330230713
Epoch 0, Step 1994: train/loss = 0.5177421569824219, train/raw-loss = 0.4808928966522217, train/logprobs = tensor([[-0.9163, -3.5856],
        [-1.5591, -1.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36849236488342285
Epoch 0, Step 1995: train/loss = 0.4233752191066742, train/raw-loss = 0.37296032905578613, train/logprobs = tensor([[ -2.2276, -10.9540],
        [ -5.2568,  -2.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5041489601135254
Epoch 0, Step 1996: train/loss = 0.17884892225265503, train/raw-loss = 0.13773076236248016, train/logprobs = tensor([[-1.1268, -9.4344],
        [-3.1609, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41118162870407104
Epoch 0, Step 1997: train/loss = 0.11391182243824005, train/raw-loss = 0.053530484437942505, train/logprobs = tensor([[-1.0911, -9.3425],
        [-3.9393, -1.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6038134098052979
Epoch 0, Step 1998: train/loss = 0.17505589127540588, train/raw-loss = 0.13315147161483765, train/logprobs = tensor([[-1.2902, -8.6453],
        [-3.9671, -2.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4190441966056824
Epoch 0, Step 1999: train/loss = 0.15054410696029663, train/raw-loss = 0.10819680988788605, train/logprobs = tensor([[ -2.1961, -15.0452],
        [ -4.1300,  -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42347288131713867
Epoch 0, Step 2000: train/loss = 0.604131817817688, train/raw-loss = 0.5570900440216064, train/logprobs = tensor([[-1.4795, -1.8640],
        [-2.0728, -1.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.470416784286499
Epoch 0, Step 2001: train/loss = 0.1316734403371811, train/raw-loss = 0.08196335285902023, train/logprobs = tensor([[-1.6116, -6.6728],
        [-3.6883, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.497100830078125
Epoch 0, Step 2002: train/loss = 0.6757946014404297, train/raw-loss = 0.63316810131073, train/logprobs = tensor([[-3.3783, -5.9868],
        [-3.4144, -1.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4262646436691284
Epoch 0, Step 2003: train/loss = 0.30605456233024597, train/raw-loss = 0.2557765245437622, train/logprobs = tensor([[-1.0868, -5.8632],
        [-3.3732, -3.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5027803182601929
Epoch 0, Step 2004: train/loss = 0.397239089012146, train/raw-loss = 0.3568205237388611, train/logprobs = tensor([[-1.9815, -6.6259],
        [-2.2859, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.404185950756073
Epoch 0, Step 2005: train/loss = 0.3668341338634491, train/raw-loss = 0.32748323678970337, train/logprobs = tensor([[-0.8990, -4.0018],
        [-1.9495, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3935089409351349
Epoch 0, Step 2006: train/loss = 0.46500295400619507, train/raw-loss = 0.42874088883399963, train/logprobs = tensor([[-2.3533, -4.6522],
        [-2.9775, -1.3281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3626207411289215
Epoch 0, Step 2007: train/loss = 0.1058640256524086, train/raw-loss = 0.05996602028608322, train/logprobs = tensor([[-1.0847, -7.4741],
        [-3.3950, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4589800238609314
Epoch 0, Step 2008: train/loss = 0.27767929434776306, train/raw-loss = 0.23227384686470032, train/logprobs = tensor([[-2.1641, -9.1578],
        [-4.1747, -1.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540545344352722
Epoch 0, Step 2009: train/loss = 0.36506903171539307, train/raw-loss = 0.32031118869781494, train/logprobs = tensor([[-1.4659, -4.3496],
        [-3.0466, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.447578489780426
Epoch 0, Step 2010: train/loss = 0.34975314140319824, train/raw-loss = 0.3117402493953705, train/logprobs = tensor([[-1.5995, -6.4431],
        [-2.1997, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3801287114620209
Epoch 0, Step 2011: train/loss = 0.7387603521347046, train/raw-loss = 0.694259524345398, train/logprobs = tensor([[-3.7147, -5.2751],
        [-2.7174, -2.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4450085163116455
Epoch 0, Step 2012: train/loss = 0.47170379757881165, train/raw-loss = 0.42859911918640137, train/logprobs = tensor([[-1.7062, -4.2069],
        [-3.0792, -2.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4310467541217804
Epoch 0, Step 2013: train/loss = 0.15299180150032043, train/raw-loss = 0.09985439479351044, train/logprobs = tensor([[-1.0850, -5.4564],
        [-3.8991, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5313742160797119
Epoch 0, Step 2014: train/loss = 0.2451687604188919, train/raw-loss = 0.20095595717430115, train/logprobs = tensor([[-1.1632, -4.3840],
        [-3.0361, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4421279728412628
Epoch 0, Step 2015: train/loss = 0.30307599902153015, train/raw-loss = 0.2566169500350952, train/logprobs = tensor([[-1.9444, -8.1613],
        [-3.7406, -1.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4645904004573822
Epoch 0, Step 2016: train/loss = 0.21630261838436127, train/raw-loss = 0.17442412674427032, train/logprobs = tensor([[-1.9444, -9.0434],
        [-3.4876, -1.2901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41878509521484375
Epoch 0, Step 2017: train/loss = 0.27979034185409546, train/raw-loss = 0.24416883289813995, train/logprobs = tensor([[-1.3720, -9.7739],
        [-2.6090, -2.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35621532797813416
Epoch 0, Step 2018: train/loss = 0.3545076251029968, train/raw-loss = 0.30809834599494934, train/logprobs = tensor([[-1.2179, -4.6814],
        [-2.2852, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46409282088279724
Epoch 0, Step 2019: train/loss = 0.2270924150943756, train/raw-loss = 0.18033158779144287, train/logprobs = tensor([[-0.8687, -8.1462],
        [-2.9955, -0.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4676082730293274
Epoch 0, Step 2020: train/loss = 0.5710716247558594, train/raw-loss = 0.536639392375946, train/logprobs = tensor([[-1.4942, -2.2395],
        [-1.7059, -1.4319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34432253241539
Epoch 0, Step 2021: train/loss = 0.3652065396308899, train/raw-loss = 0.3278388977050781, train/logprobs = tensor([[-1.3925, -4.1087],
        [-2.2243, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37367647886276245
Epoch 0, Step 2022: train/loss = 0.5688159465789795, train/raw-loss = 0.5355061292648315, train/logprobs = tensor([[-1.2470, -1.8040],
        [-1.3200, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33309853076934814
Epoch 0, Step 2023: train/loss = 0.5796945095062256, train/raw-loss = 0.5385373830795288, train/logprobs = tensor([[-1.6964, -2.2727],
        [-2.4474, -1.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4115711748600006
Epoch 0, Step 2024: train/loss = 0.42695194482803345, train/raw-loss = 0.38752448558807373, train/logprobs = tensor([[-2.5813, -5.8729],
        [-3.6103, -1.3063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3942747712135315
Epoch 0, Step 2025: train/loss = 0.8038075566291809, train/raw-loss = 0.7548377513885498, train/logprobs = tensor([[-2.3341, -3.2939],
        [-2.6112, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4896988868713379
Epoch 0, Step 2026: train/loss = 0.13046452403068542, train/raw-loss = 0.08044798672199249, train/logprobs = tensor([[-1.7936, -8.1399],
        [-4.8250, -0.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001654624938965
Epoch 0, Step 2027: train/loss = 0.2832871675491333, train/raw-loss = 0.24146950244903564, train/logprobs = tensor([[-1.6201, -7.0935],
        [-3.1342, -1.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41817647218704224
Epoch 0, Step 2028: train/loss = 0.277057945728302, train/raw-loss = 0.23659446835517883, train/logprobs = tensor([[-1.4202, -9.7910],
        [-2.5748, -2.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046347439289093
Epoch 0, Step 2029: train/loss = 0.29760897159576416, train/raw-loss = 0.254494309425354, train/logprobs = tensor([[-1.1771, -6.9361],
        [-3.4179, -1.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4311467111110687
Epoch 0, Step 2030: train/loss = 0.15976391732692719, train/raw-loss = 0.11439882218837738, train/logprobs = tensor([[ -1.5774, -10.0029],
        [ -3.6918,  -1.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45365089178085327
Epoch 0, Step 2031: train/loss = 0.3959081470966339, train/raw-loss = 0.3552406430244446, train/logprobs = tensor([[ -3.1580, -12.1617],
        [ -3.8390,  -1.0914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40667521953582764
Epoch 0, Step 2032: train/loss = 0.5659381151199341, train/raw-loss = 0.5188777446746826, train/logprobs = tensor([[-1.8073, -9.1791],
        [-3.7199, -2.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4706041216850281
Epoch 0, Step 2033: train/loss = 0.2392815798521042, train/raw-loss = 0.19130457937717438, train/logprobs = tensor([[-1.4094, -9.5874],
        [-4.0882, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4797700047492981
Epoch 0, Step 2034: train/loss = 0.1829778403043747, train/raw-loss = 0.1385553926229477, train/logprobs = tensor([[ -1.7481, -12.7647],
        [ -3.6076,  -1.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44422447681427
Epoch 0, Step 2035: train/loss = 0.5504593253135681, train/raw-loss = 0.5053532719612122, train/logprobs = tensor([[-2.7712, -6.5885],
        [-3.3669, -1.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4510599374771118
Epoch 0, Step 2036: train/loss = 0.26951178908348083, train/raw-loss = 0.22988781332969666, train/logprobs = tensor([[-1.7929, -6.1857],
        [-2.8894, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39623960852622986
Epoch 0, Step 2037: train/loss = 0.1919485330581665, train/raw-loss = 0.14359930157661438, train/logprobs = tensor([[ -2.7490, -11.4984],
        [ -4.3378,  -1.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4834921956062317
Epoch 0, Step 2038: train/loss = 0.4353209137916565, train/raw-loss = 0.3942229747772217, train/logprobs = tensor([[-0.7532, -5.0622],
        [-2.1883, -1.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109792113304138
Epoch 0, Step 2039: train/loss = 0.34917885065078735, train/raw-loss = 0.2947004735469818, train/logprobs = tensor([[-1.6053, -5.7322],
        [-3.8571, -0.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5447837114334106
Epoch 0, Step 2040: train/loss = 0.25939762592315674, train/raw-loss = 0.22249461710453033, train/logprobs = tensor([[-1.4178, -6.4872],
        [-1.9920, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3690299987792969
Epoch 0, Step 2041: train/loss = 0.4330739974975586, train/raw-loss = 0.3916626572608948, train/logprobs = tensor([[-1.0651, -5.1686],
        [-2.0271, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41411370038986206
Epoch 0, Step 2042: train/loss = 0.40787187218666077, train/raw-loss = 0.36128610372543335, train/logprobs = tensor([[-1.0567, -3.7888],
        [-2.2042, -2.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4658578038215637
Epoch 0, Step 2043: train/loss = 1.2009466886520386, train/raw-loss = 1.1678117513656616, train/logprobs = tensor([[-3.7922, -4.8300],
        [-2.6476, -1.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313487768173218
Epoch 0, Step 2044: train/loss = 0.4238645136356354, train/raw-loss = 0.38964468240737915, train/logprobs = tensor([[-1.2732, -4.2842],
        [-1.4478, -0.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421984314918518
Epoch 0, Step 2045: train/loss = 0.4388226568698883, train/raw-loss = 0.3949227035045624, train/logprobs = tensor([[-2.5070, -5.4914],
        [-4.1150, -2.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43899938464164734
Epoch 0, Step 2046: train/loss = 0.9988142848014832, train/raw-loss = 0.9497337937355042, train/logprobs = tensor([[-3.3393, -6.4044],
        [-2.1343, -2.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4908055067062378
Epoch 0, Step 2047: train/loss = 0.41845959424972534, train/raw-loss = 0.37458476424217224, train/logprobs = tensor([[-1.8390, -7.1831],
        [-2.9602, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43874821066856384
Epoch 0, Step 2048: train/loss = 0.44444799423217773, train/raw-loss = 0.4086581766605377, train/logprobs = tensor([[-1.6901, -3.5569],
        [-2.3318, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578985333442688
Epoch 0, Step 2049: train/loss = 0.214593768119812, train/raw-loss = 0.178323894739151, train/logprobs = tensor([[-1.1853, -9.4144],
        [-2.4544, -1.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36269867420196533
Epoch 0, Step 2050: train/loss = 0.22703848779201508, train/raw-loss = 0.17280322313308716, train/logprobs = tensor([[-0.8456, -8.9624],
        [-4.1802, -2.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5423527956008911
Epoch 0, Step 2051: train/loss = 0.36175861954689026, train/raw-loss = 0.311951220035553, train/logprobs = tensor([[-1.1488, -4.7699],
        [-3.1186, -1.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4980742931365967
Epoch 0, Step 2052: train/loss = 0.28650301694869995, train/raw-loss = 0.24499493837356567, train/logprobs = tensor([[-1.4603, -4.8516],
        [-3.0979, -1.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.415080726146698
Epoch 0, Step 2053: train/loss = 0.29679059982299805, train/raw-loss = 0.2557468116283417, train/logprobs = tensor([[-1.5491, -5.3676],
        [-2.2330, -1.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41043776273727417
Epoch 0, Step 2054: train/loss = 0.33173486590385437, train/raw-loss = 0.2850185036659241, train/logprobs = tensor([[-1.5435, -8.5121],
        [-3.0517, -1.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46716344356536865
Epoch 0, Step 2055: train/loss = 0.14064012467861176, train/raw-loss = 0.09781008958816528, train/logprobs = tensor([[-1.2966, -8.7909],
        [-3.8743, -1.1722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4283003807067871
Epoch 0, Step 2056: train/loss = 0.4209232032299042, train/raw-loss = 0.3850283622741699, train/logprobs = tensor([[-1.8847, -6.3331],
        [-2.9139, -0.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3589484691619873
Epoch 0, Step 2057: train/loss = 0.19609203934669495, train/raw-loss = 0.1589440256357193, train/logprobs = tensor([[ -1.3241, -10.2081],
        [ -2.8604,  -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.371480256319046
Epoch 0, Step 2058: train/loss = 0.3739636540412903, train/raw-loss = 0.33437302708625793, train/logprobs = tensor([[-1.1684, -2.6585],
        [-2.4669, -1.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3959060311317444
Epoch 0, Step 2059: train/loss = 0.3479742705821991, train/raw-loss = 0.31167376041412354, train/logprobs = tensor([[-0.7729, -6.9455],
        [-1.6161, -2.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3630048930644989
Epoch 0, Step 2060: train/loss = 0.26683279871940613, train/raw-loss = 0.22011393308639526, train/logprobs = tensor([[-0.8951, -2.0693],
        [-2.6122, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46718859672546387
Epoch 0, Step 2061: train/loss = 0.2232987880706787, train/raw-loss = 0.17634181678295135, train/logprobs = tensor([[-1.4689, -5.0719],
        [-3.5335, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4695696532726288
Epoch 0, Step 2062: train/loss = 0.5361390709877014, train/raw-loss = 0.49762922525405884, train/logprobs = tensor([[-1.7178, -7.1125],
        [-2.8988, -1.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850986361503601
Epoch 0, Step 2063: train/loss = 0.3473476469516754, train/raw-loss = 0.3139263689517975, train/logprobs = tensor([[-0.8771, -5.6219],
        [-1.5797, -1.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3342128396034241
Epoch 0, Step 2064: train/loss = 0.5570366382598877, train/raw-loss = 0.4967745542526245, train/logprobs = tensor([[-1.0580, -3.7657],
        [-3.2915, -1.8381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6026210784912109
Epoch 0, Step 2065: train/loss = 0.28340598940849304, train/raw-loss = 0.24294784665107727, train/logprobs = tensor([[-1.9655, -5.7037],
        [-2.7417, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40458130836486816
Epoch 0, Step 2066: train/loss = 0.4923728406429291, train/raw-loss = 0.4616418182849884, train/logprobs = tensor([[-1.1267, -1.6982],
        [-2.0806, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073098659515381
Epoch 0, Step 2067: train/loss = 0.3398570120334625, train/raw-loss = 0.3056076467037201, train/logprobs = tensor([[-2.0810, -6.3051],
        [-3.8927, -1.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34249353408813477
Epoch 0, Step 2068: train/loss = 0.4054144620895386, train/raw-loss = 0.35323774814605713, train/logprobs = tensor([[-1.7209, -4.0751],
        [-2.9240, -1.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5217674374580383
Epoch 0, Step 2069: train/loss = 0.4114260971546173, train/raw-loss = 0.36296260356903076, train/logprobs = tensor([[-1.6259, -4.8909],
        [-2.4675, -2.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4846349358558655
Epoch 0, Step 2070: train/loss = 0.6740370988845825, train/raw-loss = 0.6313704252243042, train/logprobs = tensor([[-0.8643, -5.3798],
        [-1.9038, -3.2004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4266660213470459
Epoch 0, Step 2071: train/loss = 0.20895500481128693, train/raw-loss = 0.17243704199790955, train/logprobs = tensor([[-2.0885, -6.8553],
        [-3.3710, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36517953872680664
Epoch 0, Step 2072: train/loss = 0.25118041038513184, train/raw-loss = 0.20784848928451538, train/logprobs = tensor([[-1.6969, -6.0562],
        [-4.2912, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4333191215991974
Epoch 0, Step 2073: train/loss = 0.13397154211997986, train/raw-loss = 0.08460091799497604, train/logprobs = tensor([[-0.8415, -8.0893],
        [-2.6389, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4937063157558441
Epoch 0, Step 2074: train/loss = 0.3540339171886444, train/raw-loss = 0.3172380328178406, train/logprobs = tensor([[-1.0745, -7.0805],
        [-1.9870, -0.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36795860528945923
Epoch 0, Step 2075: train/loss = 0.12865549325942993, train/raw-loss = 0.08606189489364624, train/logprobs = tensor([[-0.8741, -6.3817],
        [-3.3129, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42593592405319214
Epoch 0, Step 2076: train/loss = 0.25394320487976074, train/raw-loss = 0.21189747750759125, train/logprobs = tensor([[-1.3680, -4.6865],
        [-2.7895, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42045724391937256
Epoch 0, Step 2077: train/loss = 0.2174140214920044, train/raw-loss = 0.1739509552717209, train/logprobs = tensor([[ -1.1733, -10.0830],
        [ -3.0782,  -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43463051319122314
Epoch 0, Step 2078: train/loss = 0.21478983759880066, train/raw-loss = 0.17175234854221344, train/logprobs = tensor([[ -1.6987, -10.3132],
        [ -4.2993,  -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43037497997283936
Epoch 0, Step 2079: train/loss = 0.322205126285553, train/raw-loss = 0.2897217571735382, train/logprobs = tensor([[-0.7092, -5.8273],
        [-2.1878, -1.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3248336911201477
Epoch 0, Step 2080: train/loss = 0.4953750967979431, train/raw-loss = 0.46287810802459717, train/logprobs = tensor([[-1.2300, -4.5435],
        [-1.9564, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32496970891952515
Epoch 0, Step 2081: train/loss = 0.37371760606765747, train/raw-loss = 0.3398892879486084, train/logprobs = tensor([[-1.4236, -5.1743],
        [-2.1666, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33828309178352356
Epoch 0, Step 2082: train/loss = 0.5850595831871033, train/raw-loss = 0.5504876375198364, train/logprobs = tensor([[-1.6732, -4.0160],
        [-1.6430, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457193970680237
Epoch 0, Step 2083: train/loss = 0.25372010469436646, train/raw-loss = 0.2189909815788269, train/logprobs = tensor([[-1.3761, -3.9214],
        [-2.4100, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3472910523414612
Epoch 0, Step 2084: train/loss = 0.26953190565109253, train/raw-loss = 0.21905402839183807, train/logprobs = tensor([[-1.2135, -3.2055],
        [-4.0535, -1.2478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5047789216041565
Epoch 0, Step 2085: train/loss = 0.22341962158679962, train/raw-loss = 0.18005095422267914, train/logprobs = tensor([[ -1.3138, -10.5322],
        [ -3.5719,  -2.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4336865544319153
Epoch 0, Step 2086: train/loss = 0.3232247233390808, train/raw-loss = 0.2901715040206909, train/logprobs = tensor([[-0.9043, -4.3132],
        [-1.4255, -1.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330532431602478
Epoch 0, Step 2087: train/loss = 0.4204274117946625, train/raw-loss = 0.3732970058917999, train/logprobs = tensor([[-2.1455, -8.3422],
        [-3.4303, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4713042974472046
Epoch 0, Step 2088: train/loss = 0.363333523273468, train/raw-loss = 0.3195408284664154, train/logprobs = tensor([[-1.2464, -4.8168],
        [-3.6561, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43792691826820374
Epoch 0, Step 2089: train/loss = 0.43181878328323364, train/raw-loss = 0.3970921039581299, train/logprobs = tensor([[-2.2593, -5.4030],
        [-3.8122, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3472665846347809
Epoch 0, Step 2090: train/loss = 0.12208815664052963, train/raw-loss = 0.07972920686006546, train/logprobs = tensor([[-0.8965, -7.4637],
        [-3.4358, -1.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42358946800231934
Epoch 0, Step 2091: train/loss = 0.464925080537796, train/raw-loss = 0.42931365966796875, train/logprobs = tensor([[-1.3277, -5.8674],
        [-1.7114, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35611432790756226
Epoch 0, Step 2092: train/loss = 0.3919980227947235, train/raw-loss = 0.3572183847427368, train/logprobs = tensor([[-1.3615, -3.3394],
        [-2.0304, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477964699268341
Epoch 0, Step 2093: train/loss = 0.4189814329147339, train/raw-loss = 0.37183356285095215, train/logprobs = tensor([[-1.0555, -2.5648],
        [-2.7016, -1.4684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4714786112308502
Epoch 0, Step 2094: train/loss = 0.2814088463783264, train/raw-loss = 0.24030201137065887, train/logprobs = tensor([[-1.2716, -4.7298],
        [-3.5331, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41106826066970825
Epoch 0, Step 2095: train/loss = 0.42378100752830505, train/raw-loss = 0.3747353255748749, train/logprobs = tensor([[-1.2151, -6.3151],
        [-3.7823, -1.6390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4904567301273346
Epoch 0, Step 2096: train/loss = 0.7057116031646729, train/raw-loss = 0.6536334753036499, train/logprobs = tensor([[-0.6725, -2.6379],
        [-2.6711, -2.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5207815170288086
Epoch 0, Step 2097: train/loss = 0.4747554063796997, train/raw-loss = 0.4293603301048279, train/logprobs = tensor([[-0.7075, -2.5655],
        [-1.8480, -2.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4539503753185272
Epoch 0, Step 2098: train/loss = 0.3698815703392029, train/raw-loss = 0.33182698488235474, train/logprobs = tensor([[-1.6557, -3.3358],
        [-3.7816, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3805455267429352
Epoch 0, Step 2099: train/loss = 0.24962297081947327, train/raw-loss = 0.20152196288108826, train/logprobs = tensor([[-1.2384, -5.4701],
        [-3.7748, -1.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4810100793838501
Epoch 0, Step 2100: train/loss = 0.4593425989151001, train/raw-loss = 0.42855381965637207, train/logprobs = tensor([[-0.9419, -2.8957],
        [-2.0927, -1.2118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30788788199424744
Epoch 0, Step 2101: train/loss = 0.3275880515575409, train/raw-loss = 0.2864490747451782, train/logprobs = tensor([[-1.0943, -7.1976],
        [-4.3005, -2.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4113898277282715
Epoch 0, Step 2102: train/loss = 0.5487691164016724, train/raw-loss = 0.5016762018203735, train/logprobs = tensor([[-2.3650, -5.4131],
        [-2.9658, -1.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47092899680137634
Epoch 0, Step 2103: train/loss = 0.6299465894699097, train/raw-loss = 0.5790237784385681, train/logprobs = tensor([[-1.1184, -4.2083],
        [-4.3945, -2.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5092278718948364
Epoch 0, Step 2104: train/loss = 0.3460761606693268, train/raw-loss = 0.3029921054840088, train/logprobs = tensor([[-1.3719, -8.3578],
        [-4.3664, -4.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4308404326438904
Epoch 0, Step 2105: train/loss = 0.07102805376052856, train/raw-loss = 0.016859661787748337, train/logprobs = tensor([[ -0.9701, -15.8973],
        [ -4.7621,  -2.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5416839122772217
Epoch 0, Step 2106: train/loss = 0.5992462038993835, train/raw-loss = 0.5631586313247681, train/logprobs = tensor([[-1.1436, -1.4437],
        [-2.0820, -1.4396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36087551712989807
Epoch 0, Step 2107: train/loss = 0.3491421937942505, train/raw-loss = 0.2905071973800659, train/logprobs = tensor([[-1.0015, -3.0663],
        [-3.8180, -1.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5863503217697144
Epoch 0, Step 2108: train/loss = 0.14914032816886902, train/raw-loss = 0.10147200524806976, train/logprobs = tensor([[ -1.0653, -13.4741],
        [ -3.9615,  -2.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47668319940567017
Epoch 0, Step 2109: train/loss = 0.1470140814781189, train/raw-loss = 0.09188773483037949, train/logprobs = tensor([[-1.4330, -5.6044],
        [-5.1494, -1.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5512633919715881
Epoch 0, Step 2110: train/loss = 0.5006021857261658, train/raw-loss = 0.45294755697250366, train/logprobs = tensor([[-2.4783, -9.8308],
        [-4.4923, -2.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47654616832733154
Epoch 0, Step 2111: train/loss = 0.2720007300376892, train/raw-loss = 0.23074086010456085, train/logprobs = tensor([[-1.0656, -7.1560],
        [-3.2503, -1.8398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41259878873825073
Epoch 0, Step 2112: train/loss = 0.43709346652030945, train/raw-loss = 0.39556553959846497, train/logprobs = tensor([[-2.0742, -8.7131],
        [-3.4006, -3.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4152792692184448
Epoch 0, Step 2113: train/loss = 0.22103245556354523, train/raw-loss = 0.17928509414196014, train/logprobs = tensor([[ -1.7984, -11.6803],
        [ -3.6272,  -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4174736738204956
Epoch 0, Step 2114: train/loss = 0.14988790452480316, train/raw-loss = 0.1086527481675148, train/logprobs = tensor([[-1.3547, -8.7067],
        [-3.0446, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4123515486717224
Epoch 0, Step 2115: train/loss = 0.505084216594696, train/raw-loss = 0.46772822737693787, train/logprobs = tensor([[-0.9053, -5.7085],
        [-2.5333, -1.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37355977296829224
Epoch 0, Step 2116: train/loss = 0.24521058797836304, train/raw-loss = 0.20455722510814667, train/logprobs = tensor([[ -1.1402, -12.6676],
        [ -4.2008,  -1.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40653371810913086
Epoch 0, Step 2117: train/loss = 0.17307999730110168, train/raw-loss = 0.13661032915115356, train/logprobs = tensor([[-1.7014, -6.2744],
        [-4.2104, -2.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36469677090644836
Epoch 0, Step 2118: train/loss = 0.5732585191726685, train/raw-loss = 0.537021279335022, train/logprobs = tensor([[-1.9059, -5.8593],
        [-2.1325, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3623729646205902
Epoch 0, Step 2119: train/loss = 0.33209913969039917, train/raw-loss = 0.2826554775238037, train/logprobs = tensor([[-1.3705, -8.4874],
        [-3.8315, -1.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4944363236427307
Epoch 0, Step 2120: train/loss = 0.11322502046823502, train/raw-loss = 0.061098869889974594, train/logprobs = tensor([[-0.6650, -6.3706],
        [-3.6914, -1.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.52126145362854
Epoch 0, Step 2121: train/loss = 0.36793896555900574, train/raw-loss = 0.31091582775115967, train/logprobs = tensor([[-1.0464, -7.0692],
        [-3.5289, -2.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5702313184738159
Epoch 0, Step 2122: train/loss = 0.357881635427475, train/raw-loss = 0.3229188024997711, train/logprobs = tensor([[-1.1524, -3.3931],
        [-2.9280, -1.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496284484863281
Epoch 0, Step 2123: train/loss = 0.5631534457206726, train/raw-loss = 0.5291842222213745, train/logprobs = tensor([[-1.5527, -9.1025],
        [-2.2680, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33969250321388245
Epoch 0, Step 2124: train/loss = 0.19797344505786896, train/raw-loss = 0.1571534276008606, train/logprobs = tensor([[ -0.9700, -10.0452],
        [ -3.7282,  -1.5283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40820014476776123
Epoch 0, Step 2125: train/loss = 0.4825620949268341, train/raw-loss = 0.44688642024993896, train/logprobs = tensor([[-1.7217, -2.4479],
        [-3.2289, -1.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35675662755966187
Epoch 0, Step 2126: train/loss = 0.24169804155826569, train/raw-loss = 0.1913372427225113, train/logprobs = tensor([[-1.0517, -7.4397],
        [-3.0667, -0.6838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5036079287528992
Epoch 0, Step 2127: train/loss = 0.15240348875522614, train/raw-loss = 0.10109088569879532, train/logprobs = tensor([[-0.8786, -6.7952],
        [-3.3869, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5131260752677917
Epoch 0, Step 2128: train/loss = 0.37811675667762756, train/raw-loss = 0.34324145317077637, train/logprobs = tensor([[-0.9445, -5.5826],
        [-2.8207, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3487528860569
Epoch 0, Step 2129: train/loss = 0.3068481683731079, train/raw-loss = 0.2661901116371155, train/logprobs = tensor([[-1.0252, -6.2662],
        [-2.4752, -2.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40658071637153625
Epoch 0, Step 2130: train/loss = 0.19338494539260864, train/raw-loss = 0.1346794068813324, train/logprobs = tensor([[-0.9900, -8.1653],
        [-4.7416, -1.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5870552062988281
Epoch 0, Step 2131: train/loss = 0.8071662187576294, train/raw-loss = 0.7738140821456909, train/logprobs = tensor([[-2.0480, -4.1065],
        [-1.2893, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3335205912590027
Epoch 0, Step 2132: train/loss = 0.4858610928058624, train/raw-loss = 0.4459485709667206, train/logprobs = tensor([[-0.7041, -4.8342],
        [-1.9407, -1.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39912524819374084
Epoch 0, Step 2133: train/loss = 0.24808676540851593, train/raw-loss = 0.21342505514621735, train/logprobs = tensor([[-1.2502, -5.4861],
        [-2.7778, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34661728143692017
Epoch 0, Step 2134: train/loss = 0.1814572811126709, train/raw-loss = 0.13611100614070892, train/logprobs = tensor([[-1.6049, -9.8520],
        [-3.6882, -1.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4534626603126526
Epoch 0, Step 2135: train/loss = 0.656825065612793, train/raw-loss = 0.6141611337661743, train/logprobs = tensor([[-1.1842, -2.4635],
        [-2.8351, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42663976550102234
Epoch 0, Step 2136: train/loss = 0.3417861759662628, train/raw-loss = 0.30274611711502075, train/logprobs = tensor([[-0.9704, -6.3595],
        [-2.2085, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390400767326355
Epoch 0, Step 2137: train/loss = 0.6022394299507141, train/raw-loss = 0.5510620474815369, train/logprobs = tensor([[-1.7462, -3.3338],
        [-2.7566, -2.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5117740631103516
Epoch 0, Step 2138: train/loss = 0.3993879556655884, train/raw-loss = 0.35408830642700195, train/logprobs = tensor([[-0.9669, -4.5341],
        [-3.7258, -1.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4529961347579956
Epoch 0, Step 2139: train/loss = 0.33382725715637207, train/raw-loss = 0.2822706997394562, train/logprobs = tensor([[-0.8214, -4.6324],
        [-2.7758, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5155653953552246
Epoch 0, Step 2140: train/loss = 0.16879481077194214, train/raw-loss = 0.1294843554496765, train/logprobs = tensor([[-0.7244, -9.9987],
        [-2.5672, -1.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.393104612827301
Epoch 0, Step 2141: train/loss = 0.5598990321159363, train/raw-loss = 0.5223373174667358, train/logprobs = tensor([[-1.1716, -3.1132],
        [-1.9941, -1.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3756171762943268
Epoch 0, Step 2142: train/loss = 0.5810531973838806, train/raw-loss = 0.541250467300415, train/logprobs = tensor([[-1.7824, -5.4571],
        [-1.8383, -2.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980276584625244
Epoch 0, Step 2143: train/loss = 0.201184943318367, train/raw-loss = 0.15449674427509308, train/logprobs = tensor([[-0.9778, -5.6563],
        [-4.1717, -1.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46688199043273926
Epoch 0, Step 2144: train/loss = 0.3943731188774109, train/raw-loss = 0.34551140666007996, train/logprobs = tensor([[-0.9991, -5.0804],
        [-2.1270, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48861753940582275
Epoch 0, Step 2145: train/loss = 0.21158993244171143, train/raw-loss = 0.18162207305431366, train/logprobs = tensor([[-0.9570, -7.7634],
        [-1.8482, -1.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996785640716553
Epoch 0, Step 2146: train/loss = 0.14121177792549133, train/raw-loss = 0.0962127298116684, train/logprobs = tensor([[-1.4216, -7.7738],
        [-3.3541, -2.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4499906003475189
Epoch 0, Step 2147: train/loss = 0.1771376132965088, train/raw-loss = 0.13273848593235016, train/logprobs = tensor([[-1.0866, -7.4218],
        [-2.4017, -0.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4439912438392639
Epoch 0, Step 2148: train/loss = 0.2757628262042999, train/raw-loss = 0.23315049707889557, train/logprobs = tensor([[-1.5528, -4.8247],
        [-4.5203, -1.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42612335085868835
Epoch 0, Step 2149: train/loss = 0.499627947807312, train/raw-loss = 0.4475689232349396, train/logprobs = tensor([[-1.2246, -2.7979],
        [-3.2914, -2.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5205902457237244
Epoch 0, Step 2150: train/loss = 0.39913028478622437, train/raw-loss = 0.3567981719970703, train/logprobs = tensor([[-1.0719, -4.7596],
        [-2.5546, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4233214557170868
Epoch 0, Step 2151: train/loss = 0.3688071370124817, train/raw-loss = 0.3212534189224243, train/logprobs = tensor([[-1.4890, -4.7683],
        [-4.2053, -1.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47553712129592896
Epoch 0, Step 2152: train/loss = 0.17642247676849365, train/raw-loss = 0.12363804876804352, train/logprobs = tensor([[-0.8036, -5.0432],
        [-3.1629, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.527844250202179
Epoch 0, Step 2153: train/loss = 0.5310142636299133, train/raw-loss = 0.4838096499443054, train/logprobs = tensor([[-1.0343, -2.2564],
        [-3.1094, -2.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47204580903053284
Epoch 0, Step 2154: train/loss = 0.11850610375404358, train/raw-loss = 0.07084173709154129, train/logprobs = tensor([[-1.0009, -5.2818],
        [-4.0797, -1.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4766436219215393
Epoch 0, Step 2155: train/loss = 0.6656463146209717, train/raw-loss = 0.629737913608551, train/logprobs = tensor([[-1.3534, -2.6028],
        [-1.3825, -1.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35908329486846924
Epoch 0, Step 2156: train/loss = 0.440457284450531, train/raw-loss = 0.3993648290634155, train/logprobs = tensor([[-1.7158, -2.7104],
        [-2.9282, -1.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41092485189437866
Epoch 0, Step 2157: train/loss = 0.46285003423690796, train/raw-loss = 0.4304051995277405, train/logprobs = tensor([[-1.2294, -5.0586],
        [-1.5921, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244478404521942
Epoch 0, Step 2158: train/loss = 0.179741770029068, train/raw-loss = 0.14398182928562164, train/logprobs = tensor([[ -1.9403, -13.8128],
        [ -3.4826,  -1.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35759955644607544
Epoch 0, Step 2159: train/loss = 0.24811884760856628, train/raw-loss = 0.19986875355243683, train/logprobs = tensor([[-1.2421, -7.9736],
        [-3.9113, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4825010299682617
Epoch 0, Step 2160: train/loss = 0.4422617256641388, train/raw-loss = 0.407626211643219, train/logprobs = tensor([[-2.8421, -8.7472],
        [-3.0159, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34635525941848755
Epoch 0, Step 2161: train/loss = 0.28982120752334595, train/raw-loss = 0.24086831510066986, train/logprobs = tensor([[-1.2719, -6.5754],
        [-3.3779, -1.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4895291030406952
Epoch 0, Step 2162: train/loss = 0.5665490627288818, train/raw-loss = 0.5128504037857056, train/logprobs = tensor([[-0.9871, -4.7495],
        [-2.5672, -3.1579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5369867086410522
Epoch 0, Step 2163: train/loss = 0.29293447732925415, train/raw-loss = 0.2524319291114807, train/logprobs = tensor([[ -2.3721, -11.7652],
        [ -4.2556,  -3.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050253629684448
Epoch 0, Step 2164: train/loss = 0.3657810688018799, train/raw-loss = 0.3307581841945648, train/logprobs = tensor([[-1.4237, -3.7073],
        [-2.2507, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350228875875473
Epoch 0, Step 2165: train/loss = 0.227181538939476, train/raw-loss = 0.1897287368774414, train/logprobs = tensor([[-1.5572, -5.2174],
        [-4.2227, -1.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37452808022499084
Epoch 0, Step 2166: train/loss = 0.3791102468967438, train/raw-loss = 0.34451618790626526, train/logprobs = tensor([[-1.3223, -5.4494],
        [-2.2552, -0.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34594061970710754
Epoch 0, Step 2167: train/loss = 0.4067057967185974, train/raw-loss = 0.3737301230430603, train/logprobs = tensor([[-1.2239, -4.0362],
        [-2.0814, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32975679636001587
Epoch 0, Step 2168: train/loss = 0.6127318143844604, train/raw-loss = 0.5768800973892212, train/logprobs = tensor([[-1.5052, -7.4039],
        [-2.0666, -1.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358517050743103
Epoch 0, Step 2169: train/loss = 0.6681366562843323, train/raw-loss = 0.6412672400474548, train/logprobs = tensor([[-1.1504, -2.7979],
        [-1.0388, -1.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26869434118270874
Epoch 0, Step 2170: train/loss = 0.22112181782722473, train/raw-loss = 0.18062365055084229, train/logprobs = tensor([[-1.9832, -9.4863],
        [-3.7905, -1.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40498167276382446
Epoch 0, Step 2171: train/loss = 1.065590262413025, train/raw-loss = 1.0333482027053833, train/logprobs = tensor([[-2.6586, -2.5745],
        [-0.9926, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224209249019623
Epoch 0, Step 2172: train/loss = 0.35083502531051636, train/raw-loss = 0.3148331344127655, train/logprobs = tensor([[-1.0863, -8.9351],
        [-1.5311, -2.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36001890897750854
Epoch 0, Step 2173: train/loss = 0.38287752866744995, train/raw-loss = 0.3447217345237732, train/logprobs = tensor([[-1.0928, -5.0799],
        [-2.8451, -1.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38155826926231384
Epoch 0, Step 2174: train/loss = 0.5415762662887573, train/raw-loss = 0.49596506357192993, train/logprobs = tensor([[-1.6304, -6.2932],
        [-3.4626, -3.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4561118185520172
Epoch 0, Step 2175: train/loss = 0.3872146010398865, train/raw-loss = 0.35057154297828674, train/logprobs = tensor([[-1.1341, -3.9388],
        [-2.4362, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3664303123950958
Epoch 0, Step 2176: train/loss = 0.5599274635314941, train/raw-loss = 0.5169157385826111, train/logprobs = tensor([[-1.3965, -1.9634],
        [-2.2821, -1.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43011754751205444
Epoch 0, Step 2177: train/loss = 0.1455567479133606, train/raw-loss = 0.1033068299293518, train/logprobs = tensor([[-1.1852, -7.5394],
        [-3.9147, -0.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4224991500377655
Epoch 0, Step 2178: train/loss = 0.6928696632385254, train/raw-loss = 0.6613665819168091, train/logprobs = tensor([[-2.1011, -3.2526],
        [-1.7302, -1.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31503036618232727
Epoch 0, Step 2179: train/loss = 0.7689637541770935, train/raw-loss = 0.7346691489219666, train/logprobs = tensor([[-2.4374, -4.5007],
        [-1.5704, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34294623136520386
Epoch 0, Step 2180: train/loss = 0.5006220936775208, train/raw-loss = 0.45503151416778564, train/logprobs = tensor([[-2.0271, -9.6180],
        [-3.2078, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45590612292289734
Epoch 0, Step 2181: train/loss = 0.44909483194351196, train/raw-loss = 0.409619003534317, train/logprobs = tensor([[-0.6491, -5.2284],
        [-1.7821, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3947582244873047
Epoch 0, Step 2182: train/loss = 0.4641680121421814, train/raw-loss = 0.43216636776924133, train/logprobs = tensor([[-3.0548, -4.7165],
        [-3.8672, -1.9015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200165629386902
Epoch 0, Step 2183: train/loss = 0.6345944404602051, train/raw-loss = 0.6023290753364563, train/logprobs = tensor([[-1.0498, -2.5023],
        [-1.6505, -1.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32265353202819824
Epoch 0, Step 2184: train/loss = 0.37414512038230896, train/raw-loss = 0.334109902381897, train/logprobs = tensor([[-1.2195, -3.0383],
        [-2.8598, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4003520607948303
Epoch 0, Step 2185: train/loss = 0.08945304155349731, train/raw-loss = 0.045441657304763794, train/logprobs = tensor([[-1.4266, -7.7739],
        [-4.4350, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44011390209198
Epoch 0, Step 2186: train/loss = 0.49864277243614197, train/raw-loss = 0.4599098563194275, train/logprobs = tensor([[-0.9165, -3.4067],
        [-2.9805, -2.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873290419578552
Epoch 0, Step 2187: train/loss = 0.3010968565940857, train/raw-loss = 0.2530673146247864, train/logprobs = tensor([[-0.9168, -4.5192],
        [-3.0489, -2.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4802955985069275
Epoch 0, Step 2188: train/loss = 0.22583560645580292, train/raw-loss = 0.1787758767604828, train/logprobs = tensor([[-1.1213, -6.7009],
        [-3.0440, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47059714794158936
Epoch 0, Step 2189: train/loss = 0.4829062223434448, train/raw-loss = 0.43352699279785156, train/logprobs = tensor([[-1.7754, -6.0452],
        [-3.4507, -2.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49379241466522217
Epoch 0, Step 2190: train/loss = 0.39953091740608215, train/raw-loss = 0.3519830107688904, train/logprobs = tensor([[-1.8932, -6.1793],
        [-3.8365, -1.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4754791557788849
Epoch 0, Step 2191: train/loss = 0.3224390745162964, train/raw-loss = 0.28375935554504395, train/logprobs = tensor([[-1.2125, -8.8155],
        [-2.4729, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.386796772480011
Epoch 0, Step 2192: train/loss = 0.3468204140663147, train/raw-loss = 0.30957162380218506, train/logprobs = tensor([[-1.1861, -3.7225],
        [-3.0717, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37248775362968445
Epoch 0, Step 2193: train/loss = 0.13348694145679474, train/raw-loss = 0.08847354352474213, train/logprobs = tensor([[ -0.5446, -10.3710],
        [ -2.6744,  -2.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4501340091228485
Epoch 0, Step 2194: train/loss = 0.37851157784461975, train/raw-loss = 0.3452676832675934, train/logprobs = tensor([[-0.8248, -9.6742],
        [-1.7446, -2.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33243879675865173
Epoch 0, Step 2195: train/loss = 0.16128791868686676, train/raw-loss = 0.12118861824274063, train/logprobs = tensor([[ -1.4766, -12.9628],
        [ -3.3473,  -2.0679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40099287033081055
Epoch 0, Step 2196: train/loss = 0.5728580355644226, train/raw-loss = 0.5298447012901306, train/logprobs = tensor([[-2.4587, -9.4356],
        [-2.5489, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43013301491737366
Epoch 0, Step 2197: train/loss = 0.2935335636138916, train/raw-loss = 0.2533394992351532, train/logprobs = tensor([[-1.3721, -7.5119],
        [-2.7113, -1.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019409716129303
Epoch 0, Step 2198: train/loss = 0.47446733713150024, train/raw-loss = 0.43781641125679016, train/logprobs = tensor([[-1.3755, -4.3498],
        [-2.6976, -2.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3665091395378113
Epoch 0, Step 2199: train/loss = 0.4836026430130005, train/raw-loss = 0.445493221282959, train/logprobs = tensor([[ -2.3747, -13.5538],
        [ -2.3526,  -2.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38109442591667175
Epoch 0, Step 2200: train/loss = 0.08300626277923584, train/raw-loss = 0.03824947774410248, train/logprobs = tensor([[ -1.2099, -10.2870],
        [ -4.2670,  -1.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44756776094436646
Epoch 0, Step 2201: train/loss = 0.20922119915485382, train/raw-loss = 0.17036950588226318, train/logprobs = tensor([[-0.9432, -8.8514],
        [-3.1574, -1.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38851696252822876
Epoch 0, Step 2202: train/loss = 0.5719356536865234, train/raw-loss = 0.5366803407669067, train/logprobs = tensor([[-1.6076, -2.4298],
        [-2.2408, -1.3999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35255271196365356
Epoch 0, Step 2203: train/loss = 0.13309812545776367, train/raw-loss = 0.09108708798885345, train/logprobs = tensor([[ -0.6276, -12.7636],
        [ -2.4383,  -1.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42011043429374695
Epoch 0, Step 2204: train/loss = 0.44279569387435913, train/raw-loss = 0.4050365686416626, train/logprobs = tensor([[-2.1653, -6.8517],
        [-2.6308, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3775913715362549
Epoch 0, Step 2205: train/loss = 0.13292743265628815, train/raw-loss = 0.08972546458244324, train/logprobs = tensor([[ -1.0270, -12.8963],
        [ -3.8483,  -2.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4320197105407715
Epoch 0, Step 2206: train/loss = 0.40011316537857056, train/raw-loss = 0.3655763864517212, train/logprobs = tensor([[-1.0687, -2.5711],
        [-1.7819, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34536752104759216
Epoch 0, Step 2207: train/loss = 0.22348922491073608, train/raw-loss = 0.17388561367988586, train/logprobs = tensor([[ -1.2576, -12.4273],
        [ -3.3862,  -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49603599309921265
Epoch 0, Step 2208: train/loss = 0.3082752227783203, train/raw-loss = 0.2659454643726349, train/logprobs = tensor([[-0.8428, -7.9014],
        [-2.3535, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42329755425453186
Epoch 0, Step 2209: train/loss = 0.2223561555147171, train/raw-loss = 0.18300488591194153, train/logprobs = tensor([[-0.9743, -9.0140],
        [-3.6299, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3935127258300781
Epoch 0, Step 2210: train/loss = 0.16941459476947784, train/raw-loss = 0.1250799149274826, train/logprobs = tensor([[-0.9201, -8.6494],
        [-4.1465, -1.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44334691762924194
Epoch 0, Step 2211: train/loss = 0.3958582878112793, train/raw-loss = 0.35542184114456177, train/logprobs = tensor([[-0.9444, -3.2703],
        [-2.6931, -1.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4043642580509186
Epoch 0, Step 2212: train/loss = 0.18696078658103943, train/raw-loss = 0.1401643007993698, train/logprobs = tensor([[-1.7486, -9.6155],
        [-4.8146, -2.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4679650068283081
Epoch 0, Step 2213: train/loss = 0.8517653942108154, train/raw-loss = 0.8279323577880859, train/logprobs = tensor([[-3.2827, -7.1205],
        [-1.3202, -1.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23833060264587402
Epoch 0, Step 2214: train/loss = 0.42329251766204834, train/raw-loss = 0.37961453199386597, train/logprobs = tensor([[-1.0665, -3.0969],
        [-2.5606, -1.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4367802143096924
Epoch 0, Step 2215: train/loss = 0.41852739453315735, train/raw-loss = 0.37456363439559937, train/logprobs = tensor([[-1.0554, -1.6778],
        [-2.8944, -1.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43963754177093506
Epoch 0, Step 2216: train/loss = 0.47242122888565063, train/raw-loss = 0.4353352189064026, train/logprobs = tensor([[-0.8522, -3.4989],
        [-1.6687, -1.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37086036801338196
Epoch 0, Step 2217: train/loss = 0.5761731266975403, train/raw-loss = 0.5342949628829956, train/logprobs = tensor([[-2.9588, -5.6757],
        [-3.0973, -1.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4187818765640259
Epoch 0, Step 2218: train/loss = 0.19541975855827332, train/raw-loss = 0.1511119157075882, train/logprobs = tensor([[-0.7132, -8.4459],
        [-3.5503, -2.1863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44307851791381836
Epoch 0, Step 2219: train/loss = 0.262074738740921, train/raw-loss = 0.22221814095973969, train/logprobs = tensor([[-1.2896, -7.4683],
        [-2.6069, -1.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39856624603271484
Epoch 0, Step 2220: train/loss = 0.22352755069732666, train/raw-loss = 0.19644063711166382, train/logprobs = tensor([[-1.2800, -6.4643],
        [-2.2268, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27086910605430603
Epoch 0, Step 2221: train/loss = 0.6758583188056946, train/raw-loss = 0.6361128091812134, train/logprobs = tensor([[-1.0979, -1.1863],
        [-2.7662, -1.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39745524525642395
Epoch 0, Step 2222: train/loss = 0.6593927145004272, train/raw-loss = 0.6214183568954468, train/logprobs = tensor([[-1.4757, -2.4410],
        [-2.6597, -2.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37974363565444946
Epoch 0, Step 2223: train/loss = 0.6363381147384644, train/raw-loss = 0.5925083160400391, train/logprobs = tensor([[-2.1068, -4.1199],
        [-3.5011, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43829765915870667
Epoch 0, Step 2224: train/loss = 0.4335848093032837, train/raw-loss = 0.40260329842567444, train/logprobs = tensor([[-0.9103, -4.8638],
        [-1.5470, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098149597644806
Epoch 0, Step 2225: train/loss = 0.3127111792564392, train/raw-loss = 0.26849818229675293, train/logprobs = tensor([[-1.1631, -3.3720],
        [-2.5922, -1.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.442129909992218
Epoch 0, Step 2226: train/loss = 0.35547706484794617, train/raw-loss = 0.32175150513648987, train/logprobs = tensor([[-0.7277, -7.4540],
        [-1.5018, -2.3511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372553288936615
Epoch 0, Step 2227: train/loss = 0.581355631351471, train/raw-loss = 0.5491290092468262, train/logprobs = tensor([[-1.0381, -0.9699],
        [-2.2660, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32226619124412537
Epoch 0, Step 2228: train/loss = 0.4651755690574646, train/raw-loss = 0.42919695377349854, train/logprobs = tensor([[-0.7860, -2.2687],
        [-2.0074, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3597864508628845
Epoch 0, Step 2229: train/loss = 0.11261624097824097, train/raw-loss = 0.06767550110816956, train/logprobs = tensor([[-1.2432, -7.2671],
        [-4.3248, -1.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4494074583053589
Epoch 0, Step 2230: train/loss = 0.37023618817329407, train/raw-loss = 0.33025670051574707, train/logprobs = tensor([[-1.2599, -5.4442],
        [-2.9958, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3997947573661804
Epoch 0, Step 2231: train/loss = 0.3470425009727478, train/raw-loss = 0.31105107069015503, train/logprobs = tensor([[-1.3556, -8.6406],
        [-3.4629, -2.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3599146008491516
Epoch 0, Step 2232: train/loss = 0.4386295676231384, train/raw-loss = 0.3981195092201233, train/logprobs = tensor([[-2.1148, -4.9092],
        [-2.9816, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4051005244255066
Epoch 0, Step 2233: train/loss = 0.2865802049636841, train/raw-loss = 0.24791878461837769, train/logprobs = tensor([[-1.5105, -5.5139],
        [-4.3497, -1.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3866138160228729
Epoch 0, Step 2234: train/loss = 0.5747937560081482, train/raw-loss = 0.5429205894470215, train/logprobs = tensor([[-1.1606, -1.7375],
        [-1.4553, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3187320828437805
Epoch 0, Step 2235: train/loss = 0.18138815462589264, train/raw-loss = 0.1317383497953415, train/logprobs = tensor([[ -1.3369, -10.2450],
        [ -3.6821,  -1.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4964980483055115
Epoch 0, Step 2236: train/loss = 0.25475364923477173, train/raw-loss = 0.22186703979969025, train/logprobs = tensor([[-0.9809, -6.8070],
        [-2.7701, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886582612991333
Epoch 0, Step 2237: train/loss = 0.2903849184513092, train/raw-loss = 0.25657105445861816, train/logprobs = tensor([[-0.8045, -3.5639],
        [-2.9710, -1.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381386399269104
Epoch 0, Step 2238: train/loss = 0.28043946623802185, train/raw-loss = 0.24356241524219513, train/logprobs = tensor([[-0.8595, -7.3213],
        [-2.7720, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36877065896987915
Epoch 0, Step 2239: train/loss = 0.3769061267375946, train/raw-loss = 0.34239524602890015, train/logprobs = tensor([[-1.0713, -5.6172],
        [-2.0992, -0.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34510862827301025
Epoch 0, Step 2240: train/loss = 0.25740230083465576, train/raw-loss = 0.2144707590341568, train/logprobs = tensor([[-1.0446, -6.3457],
        [-3.5524, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42931532859802246
Epoch 0, Step 2241: train/loss = 0.37766215205192566, train/raw-loss = 0.33054351806640625, train/logprobs = tensor([[-0.8754, -5.6347],
        [-3.1177, -2.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4711862802505493
Epoch 0, Step 2242: train/loss = 0.5732399225234985, train/raw-loss = 0.5396137833595276, train/logprobs = tensor([[-1.2998, -1.9174],
        [-2.0361, -1.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362616300582886
Epoch 0, Step 2243: train/loss = 0.4418320059776306, train/raw-loss = 0.3946775197982788, train/logprobs = tensor([[-1.0496, -7.7044],
        [-3.7034, -3.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4715450406074524
Epoch 0, Step 2244: train/loss = 0.3107755780220032, train/raw-loss = 0.2713509500026703, train/logprobs = tensor([[-1.1867, -4.7094],
        [-2.6387, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3942462205886841
Epoch 0, Step 2245: train/loss = 0.6293359398841858, train/raw-loss = 0.5825949907302856, train/logprobs = tensor([[-1.5336, -2.6871],
        [-2.8783, -2.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4674094319343567
Epoch 0, Step 2246: train/loss = 0.5084542036056519, train/raw-loss = 0.4676901400089264, train/logprobs = tensor([[-1.2934, -2.3834],
        [-2.2062, -1.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4076405465602875
Epoch 0, Step 2247: train/loss = 0.41243845224380493, train/raw-loss = 0.3657373785972595, train/logprobs = tensor([[-0.8198, -3.0843],
        [-3.1665, -2.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4670107960700989
Epoch 0, Step 2248: train/loss = 0.2077408879995346, train/raw-loss = 0.16356396675109863, train/logprobs = tensor([[-0.6879, -9.5137],
        [-3.4313, -3.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4417691230773926
Epoch 0, Step 2249: train/loss = 0.5107647180557251, train/raw-loss = 0.46341127157211304, train/logprobs = tensor([[-1.4777, -3.4382],
        [-3.2705, -1.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4735346734523773
Epoch 0, Step 2250: train/loss = 0.22619208693504333, train/raw-loss = 0.18041357398033142, train/logprobs = tensor([[-1.3170, -5.3455],
        [-3.7655, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4577851891517639
Epoch 0, Step 2251: train/loss = 0.18004442751407623, train/raw-loss = 0.14014680683612823, train/logprobs = tensor([[-0.8708, -9.9075],
        [-3.3106, -3.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3989761769771576
Epoch 0, Step 2252: train/loss = 0.37074077129364014, train/raw-loss = 0.3154764473438263, train/logprobs = tensor([[-1.0853, -5.2214],
        [-4.9184, -2.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5526432991027832
Epoch 0, Step 2253: train/loss = 0.5749633312225342, train/raw-loss = 0.5299404859542847, train/logprobs = tensor([[-1.7227, -5.4283],
        [-3.6538, -1.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45022818446159363
Epoch 0, Step 2254: train/loss = 0.39780163764953613, train/raw-loss = 0.3584582507610321, train/logprobs = tensor([[-0.9376, -3.8484],
        [-3.6654, -1.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39343392848968506
Epoch 0, Step 2255: train/loss = 0.1307094246149063, train/raw-loss = 0.09251558780670166, train/logprobs = tensor([[-2.0245, -7.8337],
        [-6.0352, -1.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38193848729133606
Epoch 0, Step 2256: train/loss = 0.11680737882852554, train/raw-loss = 0.07124416530132294, train/logprobs = tensor([[-1.3064, -7.3699],
        [-3.7783, -1.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4556320607662201
Epoch 0, Step 2257: train/loss = 0.5870141983032227, train/raw-loss = 0.5561297535896301, train/logprobs = tensor([[-1.3365, -2.4980],
        [-1.6107, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30884450674057007
Epoch 0, Step 2258: train/loss = 0.35337647795677185, train/raw-loss = 0.3067325949668884, train/logprobs = tensor([[-1.2533, -5.8455],
        [-4.1214, -2.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4664386212825775
Epoch 0, Step 2259: train/loss = 0.31272831559181213, train/raw-loss = 0.27426013350486755, train/logprobs = tensor([[-0.6028, -6.3343],
        [-2.5878, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846819996833801
Epoch 0, Step 2260: train/loss = 0.21168704330921173, train/raw-loss = 0.17028170824050903, train/logprobs = tensor([[-0.9556, -6.3695],
        [-4.2789, -1.1929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.414053350687027
Epoch 0, Step 2261: train/loss = 0.29677659273147583, train/raw-loss = 0.2589168846607208, train/logprobs = tensor([[-0.9138, -8.9528],
        [-2.6223, -2.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3785971701145172
Epoch 0, Step 2262: train/loss = 0.09175390005111694, train/raw-loss = 0.04362579435110092, train/logprobs = tensor([[-0.9065, -8.7352],
        [-4.3545, -1.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.481281042098999
Epoch 0, Step 2263: train/loss = 0.32503196597099304, train/raw-loss = 0.28682249784469604, train/logprobs = tensor([[-1.4180, -3.6057],
        [-2.9192, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820948004722595
Epoch 0, Step 2264: train/loss = 0.5391201972961426, train/raw-loss = 0.4900214970111847, train/logprobs = tensor([[-0.9369, -2.0980],
        [-2.6834, -2.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4909871816635132
Epoch 0, Step 2265: train/loss = 0.25932297110557556, train/raw-loss = 0.20871233940124512, train/logprobs = tensor([[-1.1708, -3.7200],
        [-3.9045, -1.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5061061382293701
Epoch 0, Step 2266: train/loss = 0.5976258516311646, train/raw-loss = 0.5500242710113525, train/logprobs = tensor([[-0.7942, -3.8510],
        [-3.3971, -2.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47601571679115295
Epoch 0, Step 2267: train/loss = 0.28552305698394775, train/raw-loss = 0.23259945213794708, train/logprobs = tensor([[-1.9176, -4.2319],
        [-4.6598, -1.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5292359590530396
Epoch 0, Step 2268: train/loss = 0.5170196890830994, train/raw-loss = 0.47516942024230957, train/logprobs = tensor([[-1.0541, -5.8177],
        [-3.3217, -1.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41850292682647705
Epoch 0, Step 2269: train/loss = 0.2528323531150818, train/raw-loss = 0.20188261568546295, train/logprobs = tensor([[-0.8569, -8.8061],
        [-3.2879, -2.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5094974040985107
Epoch 0, Step 2270: train/loss = 0.420960009098053, train/raw-loss = 0.3867459297180176, train/logprobs = tensor([[-2.0599, -7.7790],
        [-2.7718, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34214067459106445
Epoch 0, Step 2271: train/loss = 0.7008944749832153, train/raw-loss = 0.6560313701629639, train/logprobs = tensor([[-1.2838, -1.8445],
        [-2.1398, -1.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44863161444664
Epoch 0, Step 2272: train/loss = 0.14006051421165466, train/raw-loss = 0.10322405397891998, train/logprobs = tensor([[ -1.1234, -13.1179],
        [ -3.2021,  -3.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683646321296692
Epoch 0, Step 2273: train/loss = 0.43466806411743164, train/raw-loss = 0.380622923374176, train/logprobs = tensor([[-1.1068, -4.9096],
        [-3.4154, -2.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5404513478279114
Epoch 0, Step 2274: train/loss = 0.3470876216888428, train/raw-loss = 0.297494113445282, train/logprobs = tensor([[-0.9502, -5.5479],
        [-3.8218, -2.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49593502283096313
Epoch 0, Step 2275: train/loss = 0.42217862606048584, train/raw-loss = 0.38615676760673523, train/logprobs = tensor([[-1.3958, -3.1102],
        [-2.2880, -1.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602183759212494
Epoch 0, Step 2276: train/loss = 0.5909955501556396, train/raw-loss = 0.5587601661682129, train/logprobs = tensor([[-1.6023, -3.3361],
        [-1.8524, -2.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223537802696228
Epoch 0, Step 2277: train/loss = 0.1254616379737854, train/raw-loss = 0.0824965089559555, train/logprobs = tensor([[-1.1178, -9.8882],
        [-3.3500, -1.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42965126037597656
Epoch 0, Step 2278: train/loss = 0.16809475421905518, train/raw-loss = 0.12969845533370972, train/logprobs = tensor([[-1.2589, -7.6976],
        [-3.0000, -1.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383963018655777
Epoch 0, Step 2279: train/loss = 0.4044932723045349, train/raw-loss = 0.37171587347984314, train/logprobs = tensor([[-1.2263, -4.0443],
        [-1.5305, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3277739882469177
Epoch 0, Step 2280: train/loss = 0.4200863242149353, train/raw-loss = 0.3782538175582886, train/logprobs = tensor([[-0.9851, -3.3481],
        [-2.8726, -1.3372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41832518577575684
Epoch 0, Step 2281: train/loss = 0.25076353549957275, train/raw-loss = 0.2114688754081726, train/logprobs = tensor([[-1.0437, -2.9363],
        [-2.9727, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39294660091400146
Epoch 0, Step 2282: train/loss = 0.529228687286377, train/raw-loss = 0.48218294978141785, train/logprobs = tensor([[-0.6331, -5.8492],
        [-2.7858, -2.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47045761346817017
Epoch 0, Step 2283: train/loss = 0.269748717546463, train/raw-loss = 0.2215835005044937, train/logprobs = tensor([[-2.5456, -9.3505],
        [-3.9306, -2.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4816519618034363
Epoch 0, Step 2284: train/loss = 0.17198732495307922, train/raw-loss = 0.12247755378484726, train/logprobs = tensor([[ -1.4196, -11.3517],
        [ -5.4533,  -2.3702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4950977861881256
Epoch 0, Step 2285: train/loss = 0.5260106921195984, train/raw-loss = 0.4809019863605499, train/logprobs = tensor([[-1.4355, -4.3583],
        [-2.9237, -2.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4510873258113861
Epoch 0, Step 2286: train/loss = 0.2838478684425354, train/raw-loss = 0.24900224804878235, train/logprobs = tensor([[-1.1049, -5.0410],
        [-2.9554, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34845641255378723
Epoch 0, Step 2287: train/loss = 0.24466517567634583, train/raw-loss = 0.19845916330814362, train/logprobs = tensor([[-1.8068, -9.7358],
        [-3.3008, -1.3312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4620600640773773
Epoch 0, Step 2288: train/loss = 0.1622903198003769, train/raw-loss = 0.11471109837293625, train/logprobs = tensor([[ -1.5481, -13.4345],
        [ -5.3528,  -3.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47579219937324524
Epoch 0, Step 2289: train/loss = 0.4086141288280487, train/raw-loss = 0.3640999495983124, train/logprobs = tensor([[-0.9291, -5.4372],
        [-3.3771, -2.7164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4451417922973633
Epoch 0, Step 2290: train/loss = 0.30999499559402466, train/raw-loss = 0.27440884709358215, train/logprobs = tensor([[-1.2729, -9.7915],
        [-3.0190, -3.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35586124658584595
Epoch 0, Step 2291: train/loss = 0.41219404339790344, train/raw-loss = 0.3757530748844147, train/logprobs = tensor([[-1.8592, -5.5529],
        [-2.6191, -1.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3644101321697235
Epoch 0, Step 2292: train/loss = 0.5882449746131897, train/raw-loss = 0.5558710098266602, train/logprobs = tensor([[-1.2100, -1.9414],
        [-1.5387, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237403631210327
Epoch 0, Step 2293: train/loss = 0.1899920105934143, train/raw-loss = 0.1489616483449936, train/logprobs = tensor([[-1.6539, -7.4030],
        [-5.0413, -2.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4103035628795624
Epoch 0, Step 2294: train/loss = 0.3131081461906433, train/raw-loss = 0.27398645877838135, train/logprobs = tensor([[-1.2862, -4.7471],
        [-3.4565, -1.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3912166357040405
Epoch 0, Step 2295: train/loss = 0.1492198258638382, train/raw-loss = 0.11992530524730682, train/logprobs = tensor([[-1.6960, -4.8076],
        [-3.3644, -1.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929452657699585
Epoch 0, Step 2296: train/loss = 0.268812894821167, train/raw-loss = 0.22554601728916168, train/logprobs = tensor([[-2.5109, -5.3180],
        [-4.6901, -2.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43266889452934265
Epoch 0, Step 2297: train/loss = 0.373177170753479, train/raw-loss = 0.33982598781585693, train/logprobs = tensor([[-1.1875, -6.3266],
        [-1.7822, -1.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33351171016693115
Epoch 0, Step 2298: train/loss = 0.5291005373001099, train/raw-loss = 0.49288880825042725, train/logprobs = tensor([[-1.6405, -3.0457],
        [-3.0392, -1.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36211705207824707
Epoch 0, Step 2299: train/loss = 0.16507266461849213, train/raw-loss = 0.1295061558485031, train/logprobs = tensor([[ -1.2666, -11.6943],
        [ -3.3227,  -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556649684906006
Epoch 0, Step 2300: train/loss = 0.28186601400375366, train/raw-loss = 0.23432022333145142, train/logprobs = tensor([[-1.3231, -5.1831],
        [-3.2504, -1.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4754580855369568
Epoch 0, Step 2301: train/loss = 0.37017354369163513, train/raw-loss = 0.3318699598312378, train/logprobs = tensor([[-1.3922, -5.4160],
        [-2.3707, -0.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38303589820861816
Epoch 0, Step 2302: train/loss = 0.28417709469795227, train/raw-loss = 0.2425180971622467, train/logprobs = tensor([[ -1.8376, -12.2502],
        [ -3.3940,  -1.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4165899157524109
Epoch 0, Step 2303: train/loss = 0.20522740483283997, train/raw-loss = 0.1636534035205841, train/logprobs = tensor([[-1.2231, -5.5878],
        [-2.8875, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4157400131225586
Epoch 0, Step 2304: train/loss = 0.3206431567668915, train/raw-loss = 0.28763672709465027, train/logprobs = tensor([[-1.0893, -8.3777],
        [-2.6794, -2.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3300642669200897
Epoch 0, Step 2305: train/loss = 0.3706865608692169, train/raw-loss = 0.32960236072540283, train/logprobs = tensor([[-0.9508, -4.4682],
        [-3.2700, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41084206104278564
Epoch 0, Step 2306: train/loss = 0.17138630151748657, train/raw-loss = 0.13613846898078918, train/logprobs = tensor([[-1.2360, -4.7320],
        [-4.4925, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3524782657623291
Epoch 0, Step 2307: train/loss = 0.1776271015405655, train/raw-loss = 0.13089533150196075, train/logprobs = tensor([[-1.4337, -6.8929],
        [-4.1479, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.467317670583725
Epoch 0, Step 2308: train/loss = 0.5457440614700317, train/raw-loss = 0.5008034706115723, train/logprobs = tensor([[-0.9818, -2.1830],
        [-3.1158, -2.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4494056701660156
Epoch 0, Step 2309: train/loss = 0.20116141438484192, train/raw-loss = 0.15109099447727203, train/logprobs = tensor([[ -1.0224, -14.4781],
        [ -4.1181,  -1.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5007041096687317
Epoch 0, Step 2310: train/loss = 0.26789525151252747, train/raw-loss = 0.2245340347290039, train/logprobs = tensor([[-1.0703, -8.4717],
        [-4.1043, -1.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43361225724220276
Epoch 0, Step 2311: train/loss = 0.32036375999450684, train/raw-loss = 0.2729526162147522, train/logprobs = tensor([[-0.9890, -4.7459],
        [-3.5077, -1.4742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47411152720451355
Epoch 0, Step 2312: train/loss = 0.31818294525146484, train/raw-loss = 0.2776966094970703, train/logprobs = tensor([[-0.9505, -9.4910],
        [-3.4375, -3.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40486329793930054
Epoch 0, Step 2313: train/loss = 0.16958969831466675, train/raw-loss = 0.11741217970848083, train/logprobs = tensor([[-1.2577, -5.8180],
        [-3.8285, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5217753648757935
Epoch 0, Step 2314: train/loss = 0.42116889357566833, train/raw-loss = 0.378980815410614, train/logprobs = tensor([[-1.6182, -6.3319],
        [-4.1289, -1.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218808114528656
Epoch 0, Step 2315: train/loss = 0.23369333148002625, train/raw-loss = 0.19036753475666046, train/logprobs = tensor([[-1.3705, -5.7521],
        [-3.3834, -1.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4332581162452698
Epoch 0, Step 2316: train/loss = 0.3874654769897461, train/raw-loss = 0.34833720326423645, train/logprobs = tensor([[-1.2290, -5.1226],
        [-3.9759, -1.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39128273725509644
Epoch 0, Step 2317: train/loss = 0.20663273334503174, train/raw-loss = 0.16660510003566742, train/logprobs = tensor([[-1.7913, -8.5545],
        [-3.2445, -2.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002760648727417
Epoch 0, Step 2318: train/loss = 0.19131284952163696, train/raw-loss = 0.15190906822681427, train/logprobs = tensor([[-1.7645, -4.8630],
        [-3.8905, -1.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39403775334358215
Epoch 0, Step 2319: train/loss = 0.20042455196380615, train/raw-loss = 0.16482257843017578, train/logprobs = tensor([[-0.8692, -3.5723],
        [-3.3246, -1.1313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35601988434791565
Epoch 0, Step 2320: train/loss = 0.07008224725723267, train/raw-loss = 0.019624294713139534, train/logprobs = tensor([[ -1.0194, -11.8022],
        [ -5.3028,  -1.5379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.504579484462738
Epoch 0, Step 2321: train/loss = 0.2787421643733978, train/raw-loss = 0.23596593737602234, train/logprobs = tensor([[-1.2059, -4.2966],
        [-3.3054, -1.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.427761971950531
Epoch 0, Step 2322: train/loss = 0.890224039554596, train/raw-loss = 0.8617820143699646, train/logprobs = tensor([[-4.0477, -5.0394],
        [-2.7417, -1.0513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2844201922416687
Epoch 0, Step 2323: train/loss = 0.2044423520565033, train/raw-loss = 0.16712869703769684, train/logprobs = tensor([[-1.1013, -4.7941],
        [-2.9444, -1.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731365203857422
Epoch 0, Step 2324: train/loss = 0.23043192923069, train/raw-loss = 0.18725375831127167, train/logprobs = tensor([[-0.9588, -6.1268],
        [-3.4144, -2.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43178173899650574
Epoch 0, Step 2325: train/loss = 0.3969261646270752, train/raw-loss = 0.35554349422454834, train/logprobs = tensor([[-0.9913, -7.7683],
        [-3.1692, -3.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4138268530368805
Epoch 0, Step 2326: train/loss = 0.4372003972530365, train/raw-loss = 0.38829705119132996, train/logprobs = tensor([[-1.1960, -4.1704],
        [-3.8527, -2.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4890338182449341
Epoch 0, Step 2327: train/loss = 0.10028141736984253, train/raw-loss = 0.060631077736616135, train/logprobs = tensor([[-1.1231, -8.3385],
        [-3.9104, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965034484863281
Epoch 0, Step 2328: train/loss = 0.4701676666736603, train/raw-loss = 0.4357530474662781, train/logprobs = tensor([[-0.6834, -3.2164],
        [-2.4442, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344146728515625
Epoch 0, Step 2329: train/loss = 0.5700313448905945, train/raw-loss = 0.5261430144309998, train/logprobs = tensor([[ -2.3480, -12.7521],
        [ -4.4189,  -2.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43888378143310547
Epoch 0, Step 2330: train/loss = 0.1999301016330719, train/raw-loss = 0.16188396513462067, train/logprobs = tensor([[ -1.7053, -11.2197],
        [ -3.6753,  -2.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38046109676361084
Epoch 0, Step 2331: train/loss = 0.34550637006759644, train/raw-loss = 0.30048835277557373, train/logprobs = tensor([[-1.5139, -7.5851],
        [-4.8276, -1.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4501805305480957
Epoch 0, Step 2332: train/loss = 0.09426043182611465, train/raw-loss = 0.050298165529966354, train/logprobs = tensor([[ -1.0538, -10.2463],
        [ -5.2459,  -1.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4396226406097412
Epoch 0, Step 2333: train/loss = 0.1919267177581787, train/raw-loss = 0.15117312967777252, train/logprobs = tensor([[-1.4950, -6.4796],
        [-4.3924, -2.3661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4075357913970947
Epoch 0, Step 2334: train/loss = 0.30777475237846375, train/raw-loss = 0.268732488155365, train/logprobs = tensor([[-1.6543, -4.8477],
        [-2.9574, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39042288064956665
Epoch 0, Step 2335: train/loss = 0.8049943447113037, train/raw-loss = 0.757405698299408, train/logprobs = tensor([[-1.5910, -5.0149],
        [-2.3428, -3.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4758865237236023
Epoch 0, Step 2336: train/loss = 0.4848470985889435, train/raw-loss = 0.44349801540374756, train/logprobs = tensor([[-1.3191, -3.9926],
        [-3.4469, -2.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41349053382873535
Epoch 0, Step 2337: train/loss = 0.40322306752204895, train/raw-loss = 0.35642924904823303, train/logprobs = tensor([[-1.3947, -4.4796],
        [-2.8100, -2.6841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4679381251335144
Epoch 0, Step 2338: train/loss = 0.4437451660633087, train/raw-loss = 0.4085063934326172, train/logprobs = tensor([[-1.0586, -2.7936],
        [-2.1610, -2.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35238781571388245
Epoch 0, Step 2339: train/loss = 0.6352551579475403, train/raw-loss = 0.5868903398513794, train/logprobs = tensor([[-1.3517, -3.9504],
        [-3.5692, -2.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48364827036857605
Epoch 0, Step 2340: train/loss = 0.4730969965457916, train/raw-loss = 0.42942631244659424, train/logprobs = tensor([[-1.6146, -3.0353],
        [-3.7602, -2.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4367069602012634
Epoch 0, Step 2341: train/loss = 0.4085295796394348, train/raw-loss = 0.37562549114227295, train/logprobs = tensor([[-1.3521, -2.7661],
        [-3.7425, -1.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290407061576843
Epoch 0, Step 2342: train/loss = 0.12166909873485565, train/raw-loss = 0.08511100709438324, train/logprobs = tensor([[-0.9603, -5.4770],
        [-3.2757, -1.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3655810058116913
Epoch 0, Step 2343: train/loss = 0.48649880290031433, train/raw-loss = 0.44252049922943115, train/logprobs = tensor([[-1.5962, -3.8921],
        [-4.1573, -3.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43978315591812134
Epoch 0, Step 2344: train/loss = 0.5351853966712952, train/raw-loss = 0.4972558915615082, train/logprobs = tensor([[-1.4432, -3.1962],
        [-2.7005, -1.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3792949318885803
Epoch 0, Step 2345: train/loss = 0.3358892798423767, train/raw-loss = 0.29067662358283997, train/logprobs = tensor([[-0.9953, -6.0783],
        [-3.5287, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45212650299072266
Epoch 0, Step 2346: train/loss = 0.12062472105026245, train/raw-loss = 0.07357128709554672, train/logprobs = tensor([[ -0.6009, -11.8079],
        [ -3.3356,  -2.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4705343544483185
Epoch 0, Step 2347: train/loss = 0.2860167622566223, train/raw-loss = 0.24943771958351135, train/logprobs = tensor([[-1.3140, -4.8089],
        [-3.2571, -1.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657905161380768
Epoch 0, Step 2348: train/loss = 0.43990930914878845, train/raw-loss = 0.4024309515953064, train/logprobs = tensor([[-0.9790, -3.0194],
        [-3.0050, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37478381395339966
Epoch 0, Step 2349: train/loss = 0.5222058892250061, train/raw-loss = 0.4810553789138794, train/logprobs = tensor([[-2.3544, -3.9952],
        [-3.8377, -1.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41150519251823425
Epoch 0, Step 2350: train/loss = 0.7734836339950562, train/raw-loss = 0.7181165814399719, train/logprobs = tensor([[-0.9469, -1.3993],
        [-3.8850, -2.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5536705255508423
Epoch 0, Step 2351: train/loss = 0.35688045620918274, train/raw-loss = 0.31938114762306213, train/logprobs = tensor([[-2.8722, -8.2757],
        [-4.0975, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37499284744262695
Epoch 0, Step 2352: train/loss = 0.4007759392261505, train/raw-loss = 0.3580414652824402, train/logprobs = tensor([[-1.0516, -3.2115],
        [-3.4886, -2.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42734503746032715
Epoch 0, Step 2353: train/loss = 0.1952265352010727, train/raw-loss = 0.15288594365119934, train/logprobs = tensor([[ -1.6738, -12.8480],
        [ -4.2015,  -4.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4234061539173126
Epoch 0, Step 2354: train/loss = 0.26534637808799744, train/raw-loss = 0.2227470874786377, train/logprobs = tensor([[-1.0207, -7.1925],
        [-3.4105, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42599302530288696
Epoch 0, Step 2355: train/loss = 0.3452646732330322, train/raw-loss = 0.2974364161491394, train/logprobs = tensor([[-1.2709, -4.8911],
        [-3.0907, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4782829284667969
Epoch 0, Step 2356: train/loss = 0.43060702085494995, train/raw-loss = 0.3932536840438843, train/logprobs = tensor([[-1.4028, -8.4714],
        [-3.5721, -2.6050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735331892967224
Epoch 0, Step 2357: train/loss = 0.738997757434845, train/raw-loss = 0.6914781928062439, train/logprobs = tensor([[-2.5579, -3.5907],
        [-4.2033, -2.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4751955270767212
Epoch 0, Step 2358: train/loss = 0.23512035608291626, train/raw-loss = 0.18574264645576477, train/logprobs = tensor([[-1.1896, -5.1806],
        [-3.0591, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49377715587615967
Epoch 0, Step 2359: train/loss = 0.10629495978355408, train/raw-loss = 0.05362848937511444, train/logprobs = tensor([[-1.2726, -5.0466],
        [-4.4261, -1.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.526664674282074
Epoch 0, Step 2360: train/loss = 0.6713760495185852, train/raw-loss = 0.614630401134491, train/logprobs = tensor([[-1.1077, -2.3675],
        [-3.7726, -2.2685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5674567222595215
Epoch 0, Step 2361: train/loss = 0.3543815016746521, train/raw-loss = 0.31771814823150635, train/logprobs = tensor([[-2.9775, -4.8135],
        [-5.1788, -3.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3666330575942993
Epoch 0, Step 2362: train/loss = 0.6619237661361694, train/raw-loss = 0.618335485458374, train/logprobs = tensor([[-3.2532, -3.8948],
        [-4.2632, -1.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4358833432197571
Epoch 0, Step 2363: train/loss = 0.552611768245697, train/raw-loss = 0.5039542317390442, train/logprobs = tensor([[-1.1021, -2.8595],
        [-3.8754, -3.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48657554388046265
Epoch 0, Step 2364: train/loss = 0.40233027935028076, train/raw-loss = 0.34723788499832153, train/logprobs = tensor([[-1.2227, -8.3519],
        [-5.3357, -3.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5509241819381714
Epoch 0, Step 2365: train/loss = 0.08461306989192963, train/raw-loss = 0.035332828760147095, train/logprobs = tensor([[ -1.5426, -13.6056],
        [ -6.3863,  -1.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4928024113178253
Epoch 0, Step 2366: train/loss = 0.1388271450996399, train/raw-loss = 0.09591449797153473, train/logprobs = tensor([[-1.2545, -7.0728],
        [-5.0855, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.429126501083374
Epoch 0, Step 2367: train/loss = 0.388396680355072, train/raw-loss = 0.3483044505119324, train/logprobs = tensor([[-0.5699, -6.8804],
        [-1.8952, -3.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40092265605926514
Epoch 0, Step 2368: train/loss = 0.36274778842926025, train/raw-loss = 0.3189106583595276, train/logprobs = tensor([[-0.6120, -5.3192],
        [-2.5473, -1.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4383712410926819
Epoch 0, Step 2369: train/loss = 0.4841530919075012, train/raw-loss = 0.43770548701286316, train/logprobs = tensor([[-1.1053, -4.2872],
        [-2.4166, -2.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46447625756263733
Epoch 0, Step 2370: train/loss = 0.29950395226478577, train/raw-loss = 0.2586592435836792, train/logprobs = tensor([[-1.2540, -4.5340],
        [-2.4049, -1.9125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084472954273224
Epoch 0, Step 2371: train/loss = 0.5818976163864136, train/raw-loss = 0.5367410182952881, train/logprobs = tensor([[-1.0361, -1.9723],
        [-2.5659, -2.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45156580209732056
Epoch 0, Step 2372: train/loss = 0.46078622341156006, train/raw-loss = 0.4122622311115265, train/logprobs = tensor([[-1.5642, -4.4558],
        [-3.8264, -3.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48523998260498047
Epoch 0, Step 2373: train/loss = 0.40720540285110474, train/raw-loss = 0.3652491569519043, train/logprobs = tensor([[-1.5338, -5.2895],
        [-3.2603, -2.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4195626676082611
Epoch 0, Step 2374: train/loss = 0.11850261688232422, train/raw-loss = 0.07208820432424545, train/logprobs = tensor([[ -1.0967, -12.2374],
        [ -4.5465,  -3.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46414414048194885
Epoch 0, Step 2375: train/loss = 0.1890099048614502, train/raw-loss = 0.14658592641353607, train/logprobs = tensor([[-1.3811, -6.7087],
        [-3.1496, -2.3272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4242396950721741
Epoch 0, Step 2376: train/loss = 0.482607364654541, train/raw-loss = 0.4384725093841553, train/logprobs = tensor([[-1.4735, -5.2171],
        [-2.7212, -2.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44134876132011414
Epoch 0, Step 2377: train/loss = 0.5025690197944641, train/raw-loss = 0.46400460600852966, train/logprobs = tensor([[-0.8721, -2.4930],
        [-2.4063, -1.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3856443166732788
Epoch 0, Step 2378: train/loss = 0.4492497444152832, train/raw-loss = 0.40875619649887085, train/logprobs = tensor([[-2.6227, -6.5064],
        [-4.7480, -2.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049355983734131
Epoch 0, Step 2379: train/loss = 0.36148396134376526, train/raw-loss = 0.3124522566795349, train/logprobs = tensor([[-1.4628, -6.8254],
        [-3.1926, -2.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.490316778421402
Epoch 0, Step 2380: train/loss = 0.49106699228286743, train/raw-loss = 0.4498189091682434, train/logprobs = tensor([[-1.2097, -3.1736],
        [-3.2033, -2.1500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4124811887741089
Epoch 0, Step 2381: train/loss = 0.42808985710144043, train/raw-loss = 0.3858153522014618, train/logprobs = tensor([[-1.1833, -8.0342],
        [-4.1908, -2.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42274484038352966
Epoch 0, Step 2382: train/loss = 0.34578025341033936, train/raw-loss = 0.310396671295166, train/logprobs = tensor([[-1.0642, -3.1603],
        [-2.9018, -1.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35383540391921997
Epoch 0, Step 2383: train/loss = 0.5091131329536438, train/raw-loss = 0.462472528219223, train/logprobs = tensor([[-1.3579, -4.8806],
        [-2.7083, -2.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46640557050704956
Epoch 0, Step 2384: train/loss = 0.33611559867858887, train/raw-loss = 0.28200241923332214, train/logprobs = tensor([[-0.8100, -6.9576],
        [-4.0003, -2.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.541131854057312
Epoch 0, Step 2385: train/loss = 0.4891763925552368, train/raw-loss = 0.44511470198631287, train/logprobs = tensor([[-1.0820, -3.2801],
        [-2.4966, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4406168460845947
Epoch 0, Step 2386: train/loss = 0.31667372584342957, train/raw-loss = 0.2689705491065979, train/logprobs = tensor([[ -1.3183, -13.1776],
        [ -3.3762,  -2.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4770321846008301
Epoch 0, Step 2387: train/loss = 0.511082649230957, train/raw-loss = 0.4709376394748688, train/logprobs = tensor([[-1.2521, -3.8553],
        [-3.6093, -1.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40145015716552734
Epoch 0, Step 2388: train/loss = 0.2619875967502594, train/raw-loss = 0.22486551105976105, train/logprobs = tensor([[-1.6708, -9.9251],
        [-3.2435, -1.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37122106552124023
Epoch 0, Step 2389: train/loss = 0.4617149829864502, train/raw-loss = 0.4093402326107025, train/logprobs = tensor([[-1.2221, -6.1307],
        [-3.7061, -3.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5237473249435425
Epoch 0, Step 2390: train/loss = 0.428592711687088, train/raw-loss = 0.37934598326683044, train/logprobs = tensor([[-1.0098, -4.5281],
        [-2.7688, -1.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4924669861793518
Epoch 0, Step 2391: train/loss = 0.2903265655040741, train/raw-loss = 0.23876914381980896, train/logprobs = tensor([[-1.3011, -3.7655],
        [-4.3252, -2.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5155743360519409
Epoch 0, Step 2392: train/loss = 0.7893791794776917, train/raw-loss = 0.7422430515289307, train/logprobs = tensor([[-1.9645, -2.6247],
        [-2.2277, -2.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47136032581329346
Epoch 0, Step 2393: train/loss = 0.2331964075565338, train/raw-loss = 0.1887689232826233, train/logprobs = tensor([[-1.6087, -6.5956],
        [-4.4503, -1.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44427481293678284
Epoch 0, Step 2394: train/loss = 0.28576818108558655, train/raw-loss = 0.24850428104400635, train/logprobs = tensor([[-0.9251, -5.4351],
        [-2.6319, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37263911962509155
Epoch 0, Step 2395: train/loss = 0.2777474522590637, train/raw-loss = 0.2381061166524887, train/logprobs = tensor([[-1.0053, -3.5836],
        [-2.8061, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3964134752750397
Epoch 0, Step 2396: train/loss = 0.5584103465080261, train/raw-loss = 0.518040657043457, train/logprobs = tensor([[-1.8819, -7.5888],
        [-2.7508, -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40369710326194763
Epoch 0, Step 2397: train/loss = 0.37702685594558716, train/raw-loss = 0.32941171526908875, train/logprobs = tensor([[-1.1246, -5.2989],
        [-3.8094, -1.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4761515259742737
Epoch 0, Step 2398: train/loss = 0.20142337679862976, train/raw-loss = 0.16061025857925415, train/logprobs = tensor([[-1.6369, -9.7345],
        [-2.8687, -1.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081312417984009
Epoch 0, Step 2399: train/loss = 0.15073567628860474, train/raw-loss = 0.11161690950393677, train/logprobs = tensor([[-0.9392, -6.1333],
        [-3.6300, -0.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39118778705596924
Epoch 0, Step 2400: train/loss = 0.6177217364311218, train/raw-loss = 0.5774853825569153, train/logprobs = tensor([[-1.0379, -1.6882],
        [-1.9645, -1.6484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40236330032348633
Epoch 0, Step 2401: train/loss = 0.3665335774421692, train/raw-loss = 0.3254363238811493, train/logprobs = tensor([[-0.4633, -6.3782],
        [-2.1916, -1.2391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41097232699394226
Epoch 0, Step 2402: train/loss = 0.6950987577438354, train/raw-loss = 0.6452438831329346, train/logprobs = tensor([[-1.3786, -2.9095],
        [-3.0255, -2.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49854886531829834
Epoch 0, Step 2403: train/loss = 0.35102930665016174, train/raw-loss = 0.30758535861968994, train/logprobs = tensor([[-1.3379, -4.0001],
        [-3.4266, -1.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.434439480304718
Epoch 0, Step 2404: train/loss = 0.4662429988384247, train/raw-loss = 0.428567111492157, train/logprobs = tensor([[-1.2222, -3.3139],
        [-2.7796, -2.1181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767591416835785
Epoch 0, Step 2405: train/loss = 0.38192999362945557, train/raw-loss = 0.34029698371887207, train/logprobs = tensor([[-0.9883, -6.1819],
        [-2.7387, -2.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4163300693035126
Epoch 0, Step 2406: train/loss = 0.31842154264450073, train/raw-loss = 0.27993044257164, train/logprobs = tensor([[-0.9628, -8.0540],
        [-2.1840, -2.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3849107325077057
Epoch 0, Step 2407: train/loss = 0.4430693984031677, train/raw-loss = 0.4008845090866089, train/logprobs = tensor([[-1.1699, -6.4689],
        [-3.9060, -1.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218488931655884
Epoch 0, Step 2408: train/loss = 0.4509885609149933, train/raw-loss = 0.4125215709209442, train/logprobs = tensor([[-1.0119, -2.5490],
        [-2.6415, -2.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846699595451355
Epoch 0, Step 2409: train/loss = 0.2865951359272003, train/raw-loss = 0.24866646528244019, train/logprobs = tensor([[-1.7169, -3.3835],
        [-4.2379, -1.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37928664684295654
Epoch 0, Step 2410: train/loss = 0.5917044878005981, train/raw-loss = 0.5584850907325745, train/logprobs = tensor([[-1.2879, -3.0617],
        [-2.6583, -2.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321937918663025
Epoch 0, Step 2411: train/loss = 0.13980858027935028, train/raw-loss = 0.10010430216789246, train/logprobs = tensor([[ -2.2084, -10.9808],
        [ -4.4990,  -1.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39704272150993347
Epoch 0, Step 2412: train/loss = 0.2133481353521347, train/raw-loss = 0.17194432020187378, train/logprobs = tensor([[ -1.3847, -13.0625],
        [ -3.7767,  -2.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4140380620956421
Epoch 0, Step 2413: train/loss = 0.728861391544342, train/raw-loss = 0.7006479501724243, train/logprobs = tensor([[-2.3920, -5.4678],
        [-1.6097, -1.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2821340560913086
Epoch 0, Step 2414: train/loss = 0.30478593707084656, train/raw-loss = 0.26933613419532776, train/logprobs = tensor([[-1.4562, -6.3751],
        [-2.7055, -1.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354498028755188
Epoch 0, Step 2415: train/loss = 0.26360148191452026, train/raw-loss = 0.22626246511936188, train/logprobs = tensor([[-0.9000, -5.3416],
        [-3.1761, -1.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733902871608734
Epoch 0, Step 2416: train/loss = 0.2868894934654236, train/raw-loss = 0.24786049127578735, train/logprobs = tensor([[-1.2839, -9.1748],
        [-4.5125, -2.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39029020071029663
Epoch 0, Step 2417: train/loss = 0.41343721747398376, train/raw-loss = 0.37205374240875244, train/logprobs = tensor([[-1.2826, -6.8492],
        [-3.0809, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4138346016407013
Epoch 0, Step 2418: train/loss = 0.43290427327156067, train/raw-loss = 0.3928280472755432, train/logprobs = tensor([[-1.2081, -3.9896],
        [-2.9708, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40076228976249695
Epoch 0, Step 2419: train/loss = 0.5241150259971619, train/raw-loss = 0.48562490940093994, train/logprobs = tensor([[-1.0012, -2.5693],
        [-2.3697, -1.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38490113615989685
Epoch 0, Step 2420: train/loss = 0.28143683075904846, train/raw-loss = 0.23666921257972717, train/logprobs = tensor([[-0.9210, -6.8689],
        [-3.1330, -2.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44767603278160095
Epoch 0, Step 2421: train/loss = 0.26994332671165466, train/raw-loss = 0.2231782078742981, train/logprobs = tensor([[-1.1784, -6.3933],
        [-3.5196, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46765097975730896
Epoch 0, Step 2422: train/loss = 0.40503180027008057, train/raw-loss = 0.3563307523727417, train/logprobs = tensor([[-1.1142, -4.3815],
        [-3.7345, -3.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48701009154319763
Epoch 0, Step 2423: train/loss = 0.26766514778137207, train/raw-loss = 0.21529585123062134, train/logprobs = tensor([[-0.9583, -6.2474],
        [-3.1227, -1.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5236928462982178
Epoch 0, Step 2424: train/loss = 0.1888982206583023, train/raw-loss = 0.14224311709403992, train/logprobs = tensor([[-1.2043, -6.4037],
        [-3.0613, -2.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4665510654449463
Epoch 0, Step 2425: train/loss = 0.4104135036468506, train/raw-loss = 0.36926576495170593, train/logprobs = tensor([[-0.9745, -5.5869],
        [-2.6830, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41147756576538086
Epoch 0, Step 2426: train/loss = 0.1810547113418579, train/raw-loss = 0.13896353542804718, train/logprobs = tensor([[ -1.8538, -12.7609],
        [ -4.5687,  -1.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4209117293357849
Epoch 0, Step 2427: train/loss = 0.2871994078159332, train/raw-loss = 0.24047397077083588, train/logprobs = tensor([[-0.9675, -5.7954],
        [-2.7823, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4672545790672302
Epoch 0, Step 2428: train/loss = 0.5927925109863281, train/raw-loss = 0.5499995946884155, train/logprobs = tensor([[-1.5259, -4.4522],
        [-3.2524, -3.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42792922258377075
Epoch 0, Step 2429: train/loss = 0.40177181363105774, train/raw-loss = 0.36139777302742004, train/logprobs = tensor([[-1.6771, -7.0124],
        [-2.8461, -0.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40374037623405457
Epoch 0, Step 2430: train/loss = 0.19848674535751343, train/raw-loss = 0.15255296230316162, train/logprobs = tensor([[-0.8720, -5.2590],
        [-4.0484, -1.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4593378007411957
Epoch 0, Step 2431: train/loss = 0.30345433950424194, train/raw-loss = 0.26265889406204224, train/logprobs = tensor([[-0.9265, -6.3945],
        [-3.0243, -1.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40795430541038513
Epoch 0, Step 2432: train/loss = 0.6704769730567932, train/raw-loss = 0.6238380074501038, train/logprobs = tensor([[-1.5752, -2.3984],
        [-2.3231, -2.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4663897156715393
Epoch 0, Step 2433: train/loss = 0.27324235439300537, train/raw-loss = 0.23777996003627777, train/logprobs = tensor([[-1.6441, -6.1961],
        [-2.8550, -1.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3546239733695984
Epoch 0, Step 2434: train/loss = 0.35192543268203735, train/raw-loss = 0.31116873025894165, train/logprobs = tensor([[-1.5529, -5.2387],
        [-3.2223, -1.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4075671434402466
Epoch 0, Step 2435: train/loss = 0.4187541604042053, train/raw-loss = 0.36952629685401917, train/logprobs = tensor([[-0.6024, -2.2831],
        [-2.4624, -1.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4922787845134735
Epoch 0, Step 2436: train/loss = 0.4410059154033661, train/raw-loss = 0.39463695883750916, train/logprobs = tensor([[-0.6541, -3.1592],
        [-2.2887, -1.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46368974447250366
Epoch 0, Step 2437: train/loss = 0.2946435809135437, train/raw-loss = 0.24473361670970917, train/logprobs = tensor([[-1.1520, -5.5596],
        [-4.0139, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4990997016429901
Epoch 0, Step 2438: train/loss = 0.35342660546302795, train/raw-loss = 0.3122381865978241, train/logprobs = tensor([[-1.5606, -5.8182],
        [-2.8555, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4118843078613281
Epoch 0, Step 2439: train/loss = 0.33742696046829224, train/raw-loss = 0.291374534368515, train/logprobs = tensor([[ -2.8205, -11.9364],
        [ -4.6305,  -1.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4605245590209961
Epoch 0, Step 2440: train/loss = 0.210569366812706, train/raw-loss = 0.16483962535858154, train/logprobs = tensor([[ -1.4340, -11.2842],
        [ -3.9892,  -2.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45729729533195496
Epoch 0, Step 2441: train/loss = 0.3911744952201843, train/raw-loss = 0.34296679496765137, train/logprobs = tensor([[-1.2171, -4.2692],
        [-3.8196, -2.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4820772707462311
Epoch 0, Step 2442: train/loss = 0.42359328269958496, train/raw-loss = 0.37614965438842773, train/logprobs = tensor([[ -2.1868, -10.3918],
        [ -4.3658,  -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4744364321231842
Epoch 0, Step 2443: train/loss = 0.3060266077518463, train/raw-loss = 0.2744617760181427, train/logprobs = tensor([[-1.6777, -6.1464],
        [-2.3440, -1.5240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31564825773239136
Epoch 0, Step 2444: train/loss = 0.5225526094436646, train/raw-loss = 0.47808265686035156, train/logprobs = tensor([[-2.0905, -6.4342],
        [-3.8208, -1.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4446999132633209
Epoch 0, Step 2445: train/loss = 0.2794725000858307, train/raw-loss = 0.22855743765830994, train/logprobs = tensor([[-0.9894, -4.5229],
        [-3.4654, -1.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5091504454612732
Epoch 0, Step 2446: train/loss = 0.43290555477142334, train/raw-loss = 0.3937619924545288, train/logprobs = tensor([[-1.8066, -3.5115],
        [-2.6513, -1.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39143580198287964
Epoch 0, Step 2447: train/loss = 0.17287643253803253, train/raw-loss = 0.13094006478786469, train/logprobs = tensor([[-1.1642, -6.0343],
        [-3.5226, -1.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41936367750167847
Epoch 0, Step 2448: train/loss = 0.23347249627113342, train/raw-loss = 0.18428300321102142, train/logprobs = tensor([[-1.5363, -8.6302],
        [-4.3612, -1.4351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49189502000808716
Epoch 0, Step 2449: train/loss = 0.5137338042259216, train/raw-loss = 0.46485307812690735, train/logprobs = tensor([[-1.4478, -7.8336],
        [-2.8861, -2.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4888070821762085
Epoch 0, Step 2450: train/loss = 0.6612963080406189, train/raw-loss = 0.6143598556518555, train/logprobs = tensor([[-1.4375, -1.7451],
        [-2.3897, -1.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46936482191085815
Epoch 0, Step 2451: train/loss = 0.5786203145980835, train/raw-loss = 0.5339576005935669, train/logprobs = tensor([[-2.5033, -7.9310],
        [-3.2071, -3.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.446627140045166
Epoch 0, Step 2452: train/loss = 0.2778734266757965, train/raw-loss = 0.23914656043052673, train/logprobs = tensor([[-2.1547, -8.8195],
        [-4.0932, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3872688114643097
Epoch 0, Step 2453: train/loss = 0.35203197598457336, train/raw-loss = 0.29345399141311646, train/logprobs = tensor([[-1.2019, -6.3970],
        [-3.7035, -1.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5857797861099243
Epoch 0, Step 2454: train/loss = 0.22164121270179749, train/raw-loss = 0.1775532215833664, train/logprobs = tensor([[-2.6426, -9.8069],
        [-3.4593, -2.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44087979197502136
Epoch 0, Step 2455: train/loss = 0.6339432001113892, train/raw-loss = 0.5830573439598083, train/logprobs = tensor([[-0.7438, -1.7781],
        [-3.1068, -2.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.508858323097229
Epoch 0, Step 2456: train/loss = 0.46993333101272583, train/raw-loss = 0.43181508779525757, train/logprobs = tensor([[-0.8564, -3.9197],
        [-3.3393, -2.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38118258118629456
Epoch 0, Step 2457: train/loss = 0.6465274095535278, train/raw-loss = 0.5929848551750183, train/logprobs = tensor([[-1.1994, -3.4623],
        [-3.5084, -2.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5354257822036743
Epoch 0, Step 2458: train/loss = 0.23777225613594055, train/raw-loss = 0.20070846378803253, train/logprobs = tensor([[-2.0739, -5.4324],
        [-4.5914, -1.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37063783407211304
Epoch 0, Step 2459: train/loss = 0.5064840912818909, train/raw-loss = 0.46807217597961426, train/logprobs = tensor([[-1.1395, -3.9094],
        [-1.9242, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.384118914604187
Epoch 0, Step 2460: train/loss = 0.6392598748207092, train/raw-loss = 0.5890476703643799, train/logprobs = tensor([[-1.3053, -3.0632],
        [-2.4913, -1.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5021217465400696
Epoch 0, Step 2461: train/loss = 0.3906494975090027, train/raw-loss = 0.3436727523803711, train/logprobs = tensor([[ -2.2165, -10.1063],
        [ -4.0466,  -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46976736187934875
Epoch 0, Step 2462: train/loss = 0.5536575317382812, train/raw-loss = 0.5174540877342224, train/logprobs = tensor([[-2.4053, -5.9694],
        [-3.1629, -1.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36203449964523315
Epoch 0, Step 2463: train/loss = 0.4528130292892456, train/raw-loss = 0.4148828983306885, train/logprobs = tensor([[-2.2426, -6.1162],
        [-3.4029, -2.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793012499809265
Epoch 0, Step 2464: train/loss = 0.2748103737831116, train/raw-loss = 0.2400684952735901, train/logprobs = tensor([[-1.4385, -6.9000],
        [-2.8431, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474186062812805
Epoch 0, Step 2465: train/loss = 0.4267365336418152, train/raw-loss = 0.39095354080200195, train/logprobs = tensor([[-1.2227, -3.3100],
        [-2.5490, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35782983899116516
Epoch 0, Step 2466: train/loss = 0.28192275762557983, train/raw-loss = 0.24221956729888916, train/logprobs = tensor([[-1.0908, -7.5760],
        [-2.4362, -2.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39703166484832764
Epoch 0, Step 2467: train/loss = 0.44698673486709595, train/raw-loss = 0.40511059761047363, train/logprobs = tensor([[-1.0647, -3.7534],
        [-2.2048, -1.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4187609851360321
Epoch 0, Step 2468: train/loss = 0.4859980344772339, train/raw-loss = 0.44484683871269226, train/logprobs = tensor([[-0.8303, -1.9854],
        [-2.0427, -1.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41151201725006104
Epoch 0, Step 2469: train/loss = 0.36748701333999634, train/raw-loss = 0.32968080043792725, train/logprobs = tensor([[-1.0418, -5.2376],
        [-2.4815, -1.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378061980009079
Epoch 0, Step 2470: train/loss = 0.26343435049057007, train/raw-loss = 0.22639727592468262, train/logprobs = tensor([[-1.1499, -5.4073],
        [-2.6016, -0.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37037068605422974
Epoch 0, Step 2471: train/loss = 0.6648281812667847, train/raw-loss = 0.615405261516571, train/logprobs = tensor([[-1.3380, -1.6019],
        [-2.5179, -2.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4942292869091034
Epoch 0, Step 2472: train/loss = 0.3628527820110321, train/raw-loss = 0.3224881887435913, train/logprobs = tensor([[-1.3224, -2.9834],
        [-3.3621, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036458730697632
Epoch 0, Step 2473: train/loss = 0.5877544283866882, train/raw-loss = 0.5391072630882263, train/logprobs = tensor([[-1.0801, -3.0582],
        [-2.1430, -2.2266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4864717721939087
Epoch 0, Step 2474: train/loss = 0.12349382787942886, train/raw-loss = 0.08102016896009445, train/logprobs = tensor([[ -0.9610, -12.2822],
        [ -2.8117,  -1.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4247366189956665
Epoch 0, Step 2475: train/loss = 0.3268169164657593, train/raw-loss = 0.29715266823768616, train/logprobs = tensor([[ -1.3782, -10.5635],
        [ -2.2797,  -2.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.296642541885376
Epoch 0, Step 2476: train/loss = 0.53797847032547, train/raw-loss = 0.5033422708511353, train/logprobs = tensor([[-1.4588, -5.3149],
        [-2.1989, -1.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3463614284992218
Epoch 0, Step 2477: train/loss = 0.5437928438186646, train/raw-loss = 0.5039455890655518, train/logprobs = tensor([[-2.0537, -9.1963],
        [-3.7568, -1.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39847224950790405
Epoch 0, Step 2478: train/loss = 0.23615963757038116, train/raw-loss = 0.19987863302230835, train/logprobs = tensor([[-1.4857, -8.0123],
        [-3.0980, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3628101944923401
Epoch 0, Step 2479: train/loss = 0.595947802066803, train/raw-loss = 0.550379753112793, train/logprobs = tensor([[-2.1643, -3.2068],
        [-3.1040, -1.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4556807279586792
Epoch 0, Step 2480: train/loss = 0.47457659244537354, train/raw-loss = 0.4371342658996582, train/logprobs = tensor([[-1.8623, -7.7632],
        [-3.2311, -2.0443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3744232952594757
Epoch 0, Step 2481: train/loss = 0.3447304964065552, train/raw-loss = 0.3015438914299011, train/logprobs = tensor([[-1.7145, -9.3034],
        [-2.8483, -3.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4318661689758301
Epoch 0, Step 2482: train/loss = 0.3382938504219055, train/raw-loss = 0.3129443824291229, train/logprobs = tensor([[-1.2790, -6.4085],
        [-1.4074, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25349485874176025
Epoch 0, Step 2483: train/loss = 0.554272472858429, train/raw-loss = 0.5062947273254395, train/logprobs = tensor([[-2.4247, -6.4241],
        [-3.9819, -1.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47977709770202637
Epoch 0, Step 2484: train/loss = 0.2747611105442047, train/raw-loss = 0.2443886548280716, train/logprobs = tensor([[-1.3152, -6.1747],
        [-2.0237, -0.7164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30372461676597595
Epoch 0, Step 2485: train/loss = 0.26157787442207336, train/raw-loss = 0.22018781304359436, train/logprobs = tensor([[-1.6082, -5.6600],
        [-4.1043, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41390061378479004
Epoch 0, Step 2486: train/loss = 0.37733495235443115, train/raw-loss = 0.3249458074569702, train/logprobs = tensor([[-1.9588, -7.4057],
        [-3.4790, -2.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5238916873931885
Epoch 0, Step 2487: train/loss = 0.7004135251045227, train/raw-loss = 0.6683349609375, train/logprobs = tensor([[-3.1602, -7.0609],
        [-2.4788, -1.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32078635692596436
Epoch 0, Step 2488: train/loss = 0.3292316496372223, train/raw-loss = 0.29398608207702637, train/logprobs = tensor([[-1.1301, -3.8271],
        [-2.0322, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3524557948112488
Epoch 0, Step 2489: train/loss = 0.1460622251033783, train/raw-loss = 0.10088691115379333, train/logprobs = tensor([[-1.7475, -7.3307],
        [-5.0500, -1.4104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45175331830978394
Epoch 0, Step 2490: train/loss = 0.7644416093826294, train/raw-loss = 0.7257177829742432, train/logprobs = tensor([[-1.7416, -2.2984],
        [-2.0296, -2.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38723769783973694
Epoch 0, Step 2491: train/loss = 0.2536029517650604, train/raw-loss = 0.20427493751049042, train/logprobs = tensor([[-1.4281, -8.2978],
        [-3.0246, -1.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4932800531387329
Epoch 0, Step 2492: train/loss = 0.1335102915763855, train/raw-loss = 0.09058894217014313, train/logprobs = tensor([[-1.4613, -7.2379],
        [-4.0836, -1.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4292137622833252
Epoch 0, Step 2493: train/loss = 0.37188515067100525, train/raw-loss = 0.3276346027851105, train/logprobs = tensor([[-1.8616, -7.0575],
        [-2.8723, -4.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4425053000450134
Epoch 0, Step 2494: train/loss = 0.2908856272697449, train/raw-loss = 0.25171950459480286, train/logprobs = tensor([[-1.0152, -4.2286],
        [-2.0111, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39166098833084106
Epoch 0, Step 2495: train/loss = 0.19954632222652435, train/raw-loss = 0.15963949263095856, train/logprobs = tensor([[ -1.9370, -12.3245],
        [ -3.5031,  -3.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990682363510132
Epoch 0, Step 2496: train/loss = 0.2553503215312958, train/raw-loss = 0.2090747356414795, train/logprobs = tensor([[-1.9391, -9.6360],
        [-4.0626, -1.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4627557098865509
Epoch 0, Step 2497: train/loss = 0.23978003859519958, train/raw-loss = 0.18992558121681213, train/logprobs = tensor([[-1.7015, -5.0269],
        [-4.0916, -1.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4985443651676178
Epoch 0, Step 2498: train/loss = 0.14155994355678558, train/raw-loss = 0.10408459603786469, train/logprobs = tensor([[-1.2795, -5.8900],
        [-2.8715, -0.5460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.374753475189209
Epoch 0, Step 2499: train/loss = 0.16424740850925446, train/raw-loss = 0.12836265563964844, train/logprobs = tensor([[-2.0794, -9.2523],
        [-4.2300, -3.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588475286960602
Epoch 0, Step 2500: train/loss = 0.3552219867706299, train/raw-loss = 0.3141826391220093, train/logprobs = tensor([[-1.6922, -6.3397],
        [-2.9122, -1.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41039326786994934
Epoch 0, Step 2501: train/loss = 0.7351484894752502, train/raw-loss = 0.6968066692352295, train/logprobs = tensor([[-1.1037, -1.9402],
        [-2.8251, -2.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3834184408187866
Epoch 0, Step 2502: train/loss = 0.2671099901199341, train/raw-loss = 0.22981567680835724, train/logprobs = tensor([[ -1.1862, -12.0157],
        [ -2.4538,  -1.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37294304370880127
Epoch 0, Step 2503: train/loss = 0.36348628997802734, train/raw-loss = 0.31833958625793457, train/logprobs = tensor([[-1.5245, -9.1338],
        [-3.2889, -2.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4514670968055725
Epoch 0, Step 2504: train/loss = 0.4463507831096649, train/raw-loss = 0.4000958800315857, train/logprobs = tensor([[-1.5889, -3.7996],
        [-2.4184, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.462549090385437
Epoch 0, Step 2505: train/loss = 0.3725014626979828, train/raw-loss = 0.3200816810131073, train/logprobs = tensor([[-0.8661, -8.3973],
        [-3.8500, -2.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5241979360580444
Epoch 0, Step 2506: train/loss = 0.16834907233715057, train/raw-loss = 0.12700530886650085, train/logprobs = tensor([[ -1.1727, -10.1424],
        [ -3.8759,  -1.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41343745589256287
Epoch 0, Step 2507: train/loss = 0.17550992965698242, train/raw-loss = 0.14072075486183167, train/logprobs = tensor([[ -1.5848, -10.2214],
        [ -3.9398,  -2.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3478916883468628
Epoch 0, Step 2508: train/loss = 0.31268805265426636, train/raw-loss = 0.2674527168273926, train/logprobs = tensor([[-1.6327, -5.2961],
        [-3.7273, -1.6669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45235347747802734
Epoch 0, Step 2509: train/loss = 0.11669781059026718, train/raw-loss = 0.07250425219535828, train/logprobs = tensor([[-1.0730, -9.1314],
        [-3.3400, -2.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44193553924560547
Epoch 0, Step 2510: train/loss = 0.49564802646636963, train/raw-loss = 0.45872199535369873, train/logprobs = tensor([[-1.2869, -7.1881],
        [-2.6555, -1.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692599833011627
Epoch 0, Step 2511: train/loss = 0.3548599183559418, train/raw-loss = 0.3191300928592682, train/logprobs = tensor([[-1.5598, -6.0205],
        [-3.5875, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3572982847690582
Epoch 0, Step 2512: train/loss = 0.149300217628479, train/raw-loss = 0.09135904908180237, train/logprobs = tensor([[-0.9931, -9.9587],
        [-3.8381, -2.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5794115662574768
Epoch 0, Step 2513: train/loss = 0.4871653914451599, train/raw-loss = 0.4449687898159027, train/logprobs = tensor([[-1.5090, -3.3133],
        [-2.2321, -1.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42196571826934814
Epoch 0, Step 2514: train/loss = 0.23228156566619873, train/raw-loss = 0.18529944121837616, train/logprobs = tensor([[-1.4956, -6.1386],
        [-3.9468, -1.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46982133388519287
Epoch 0, Step 2515: train/loss = 0.4222305417060852, train/raw-loss = 0.38330525159835815, train/logprobs = tensor([[-1.5219, -4.1536],
        [-3.3060, -1.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38925302028656006
Epoch 0, Step 2516: train/loss = 0.4819100499153137, train/raw-loss = 0.45014330744743347, train/logprobs = tensor([[-1.0537, -4.9200],
        [-1.6036, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31766727566719055
Epoch 0, Step 2517: train/loss = 0.3462713658809662, train/raw-loss = 0.3071171045303345, train/logprobs = tensor([[-1.7845, -5.2486],
        [-3.2561, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39154234528541565
Epoch 0, Step 2518: train/loss = 0.19148202240467072, train/raw-loss = 0.1495146006345749, train/logprobs = tensor([[-1.0488, -7.4210],
        [-4.1811, -1.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.419674277305603
Epoch 0, Step 2519: train/loss = 0.2788340449333191, train/raw-loss = 0.23629115521907806, train/logprobs = tensor([[-1.7646, -6.7411],
        [-3.9204, -2.4229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254288077354431
Epoch 0, Step 2520: train/loss = 0.7312183380126953, train/raw-loss = 0.6905579566955566, train/logprobs = tensor([[-1.8563, -1.9120],
        [-1.7799, -1.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40660369396209717
Epoch 0, Step 2521: train/loss = 0.24282875657081604, train/raw-loss = 0.2006654292345047, train/logprobs = tensor([[-1.2394, -9.0796],
        [-3.0925, -1.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4216332733631134
Epoch 0, Step 2522: train/loss = 0.3906417489051819, train/raw-loss = 0.3405689299106598, train/logprobs = tensor([[-1.9466, -7.1996],
        [-5.0912, -2.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5007281303405762
Epoch 0, Step 2523: train/loss = 0.3292555510997772, train/raw-loss = 0.2994996905326843, train/logprobs = tensor([[-1.1979, -7.5365],
        [-1.9052, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29755839705467224
Epoch 0, Step 2524: train/loss = 0.4423398971557617, train/raw-loss = 0.40716981887817383, train/logprobs = tensor([[-1.3870, -4.2229],
        [-2.0343, -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517006039619446
Epoch 0, Step 2525: train/loss = 0.25780314207077026, train/raw-loss = 0.2224004715681076, train/logprobs = tensor([[-1.4439, -7.3084],
        [-3.3489, -1.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35402676463127136
Epoch 0, Step 2526: train/loss = 0.5179757475852966, train/raw-loss = 0.479303777217865, train/logprobs = tensor([[ -2.2542, -11.7216],
        [ -2.3621,  -2.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3867197036743164
Epoch 0, Step 2527: train/loss = 0.4414302706718445, train/raw-loss = 0.4015350341796875, train/logprobs = tensor([[-1.9660, -4.5853],
        [-2.8731, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39895251393318176
Epoch 0, Step 2528: train/loss = 0.09930609166622162, train/raw-loss = 0.0575772188603878, train/logprobs = tensor([[ -1.3131, -10.7587],
        [ -4.2826,  -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41728875041007996
Epoch 0, Step 2529: train/loss = 0.49629634618759155, train/raw-loss = 0.4500102400779724, train/logprobs = tensor([[-1.2018, -2.5568],
        [-3.5601, -2.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4628608226776123
Epoch 0, Step 2530: train/loss = 0.296431303024292, train/raw-loss = 0.25193557143211365, train/logprobs = tensor([[-1.3796, -7.4770],
        [-3.5626, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44495752453804016
Epoch 0, Step 2531: train/loss = 0.37835511565208435, train/raw-loss = 0.3378880023956299, train/logprobs = tensor([[-2.0214, -3.7139],
        [-2.5814, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046713411808014
Epoch 0, Step 2532: train/loss = 0.10746260732412338, train/raw-loss = 0.06723003089427948, train/logprobs = tensor([[ -1.5042, -11.5108],
        [ -4.8704,  -1.3339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4023258686065674
Epoch 0, Step 2533: train/loss = 0.6068074107170105, train/raw-loss = 0.5532465577125549, train/logprobs = tensor([[-0.7176, -7.3609],
        [-2.8628, -2.8187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5356093645095825
Epoch 0, Step 2534: train/loss = 0.338983416557312, train/raw-loss = 0.28722935914993286, train/logprobs = tensor([[-1.2442, -6.2661],
        [-3.6105, -1.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5175407528877258
Epoch 0, Step 2535: train/loss = 0.3387989401817322, train/raw-loss = 0.3044494390487671, train/logprobs = tensor([[-1.6176, -5.1871],
        [-2.0183, -1.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434952199459076
Epoch 0, Step 2536: train/loss = 0.139568492770195, train/raw-loss = 0.09073968231678009, train/logprobs = tensor([[-1.5079, -8.2854],
        [-3.6546, -1.5145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4882880449295044
Epoch 0, Step 2537: train/loss = 0.29077836871147156, train/raw-loss = 0.23666425049304962, train/logprobs = tensor([[-2.0632, -5.0695],
        [-3.3178, -1.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5411410331726074
Epoch 0, Step 2538: train/loss = 0.3598887324333191, train/raw-loss = 0.31677836179733276, train/logprobs = tensor([[-1.7910, -9.4486],
        [-2.4652, -1.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43110406398773193
Epoch 0, Step 2539: train/loss = 0.8752910494804382, train/raw-loss = 0.8456393480300903, train/logprobs = tensor([[-2.5906, -4.1348],
        [-1.4839, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965167760848999
Epoch 0, Step 2540: train/loss = 0.2969777286052704, train/raw-loss = 0.25629836320877075, train/logprobs = tensor([[-1.0434, -6.4925],
        [-2.4645, -1.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40679386258125305
Epoch 0, Step 2541: train/loss = 0.14555203914642334, train/raw-loss = 0.10409379750490189, train/logprobs = tensor([[-1.6370, -5.7938],
        [-3.5151, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41458243131637573
Epoch 0, Step 2542: train/loss = 0.2592427134513855, train/raw-loss = 0.20821799337863922, train/logprobs = tensor([[-1.2745, -9.1239],
        [-4.6066, -3.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5102474093437195
Epoch 0, Step 2543: train/loss = 0.5897097587585449, train/raw-loss = 0.5481541156768799, train/logprobs = tensor([[-1.7889, -5.1640],
        [-2.2761, -1.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155562222003937
Epoch 0, Step 2544: train/loss = 0.40523895621299744, train/raw-loss = 0.3570820987224579, train/logprobs = tensor([[-2.1183, -2.7728],
        [-3.4914, -1.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48156848549842834
Epoch 0, Step 2545: train/loss = 0.3344939649105072, train/raw-loss = 0.29033762216567993, train/logprobs = tensor([[-1.3513, -7.5851],
        [-3.0835, -1.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4415634274482727
Epoch 0, Step 2546: train/loss = 0.2710646986961365, train/raw-loss = 0.22105476260185242, train/logprobs = tensor([[ -1.7714, -11.1095],
        [ -3.4672,  -3.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5000991225242615
Epoch 0, Step 2547: train/loss = 0.7970163822174072, train/raw-loss = 0.7554621696472168, train/logprobs = tensor([[-1.3956, -1.6793],
        [-1.6334, -1.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155425429344177
Epoch 0, Step 2548: train/loss = 0.4033844470977783, train/raw-loss = 0.3652164936065674, train/logprobs = tensor([[-1.6696, -4.2105],
        [-2.5343, -1.2314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38167956471443176
Epoch 0, Step 2549: train/loss = 0.5006825923919678, train/raw-loss = 0.46322178840637207, train/logprobs = tensor([[-1.6801, -4.6984],
        [-1.4702, -1.4459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37460857629776
Epoch 0, Step 2550: train/loss = 0.42174839973449707, train/raw-loss = 0.3850245773792267, train/logprobs = tensor([[ -1.3063, -10.9906],
        [ -2.2080,  -1.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36723798513412476
Epoch 0, Step 2551: train/loss = 0.2964193820953369, train/raw-loss = 0.2584535777568817, train/logprobs = tensor([[-1.5171, -4.0492],
        [-2.8051, -1.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3796585202217102
Epoch 0, Step 2552: train/loss = 0.452867716550827, train/raw-loss = 0.41177690029144287, train/logprobs = tensor([[ -2.3014, -12.2264],
        [ -2.5843,  -2.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41090792417526245
Epoch 0, Step 2553: train/loss = 0.261438250541687, train/raw-loss = 0.21463169157505035, train/logprobs = tensor([[-1.4890, -6.2408],
        [-3.3024, -2.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4680655598640442
Epoch 0, Step 2554: train/loss = 0.45512932538986206, train/raw-loss = 0.400709867477417, train/logprobs = tensor([[-1.4517, -3.3571],
        [-3.8874, -2.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.544194757938385
Epoch 0, Step 2555: train/loss = 0.18406957387924194, train/raw-loss = 0.14128805696964264, train/logprobs = tensor([[-1.3614, -5.3962],
        [-3.8805, -1.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42781510949134827
Epoch 0, Step 2556: train/loss = 1.2175484895706177, train/raw-loss = 1.170699119567871, train/logprobs = tensor([[-4.6695, -6.1959],
        [-3.6579, -1.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4684932827949524
Epoch 0, Step 2557: train/loss = 0.34330257773399353, train/raw-loss = 0.3097255229949951, train/logprobs = tensor([[-1.7340, -6.8413],
        [-3.2036, -1.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3357706367969513
Epoch 0, Step 2558: train/loss = 0.28020790219306946, train/raw-loss = 0.23457230627536774, train/logprobs = tensor([[ -1.3202, -10.3604],
        [ -4.0259,  -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4563557505607605
Epoch 0, Step 2559: train/loss = 0.19882075488567352, train/raw-loss = 0.15679767727851868, train/logprobs = tensor([[-1.2370, -9.2383],
        [-3.0859, -2.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42023077607154846
Epoch 0, Step 2560: train/loss = 0.4229469299316406, train/raw-loss = 0.38154563307762146, train/logprobs = tensor([[-1.3093, -7.3252],
        [-2.3204, -1.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4140125513076782
Epoch 0, Step 2561: train/loss = 0.5502576231956482, train/raw-loss = 0.5076664686203003, train/logprobs = tensor([[-2.2112, -9.0550],
        [-2.8274, -1.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4259118139743805
Epoch 0, Step 2562: train/loss = 0.28595566749572754, train/raw-loss = 0.23785500228405, train/logprobs = tensor([[-3.7866, -9.0345],
        [-4.4488, -2.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4810067117214203
Epoch 0, Step 2563: train/loss = 0.198248952627182, train/raw-loss = 0.14839054644107819, train/logprobs = tensor([[-1.2123, -5.9139],
        [-3.8422, -1.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4985840320587158
Epoch 0, Step 2564: train/loss = 0.11423896253108978, train/raw-loss = 0.059043269604444504, train/logprobs = tensor([[ -0.8291, -12.8624],
        [ -3.7349,  -3.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5519568920135498
Epoch 0, Step 2565: train/loss = 0.4609644412994385, train/raw-loss = 0.41838541626930237, train/logprobs = tensor([[-2.6630, -6.8472],
        [-2.9371, -2.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4257904589176178
Epoch 0, Step 2566: train/loss = 0.6400843262672424, train/raw-loss = 0.600475549697876, train/logprobs = tensor([[-1.6343, -1.7573],
        [-1.9929, -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3960873484611511
Epoch 0, Step 2567: train/loss = 0.11055175960063934, train/raw-loss = 0.07305032759904861, train/logprobs = tensor([[-1.2650, -8.6514],
        [-4.1174, -1.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3750143051147461
Epoch 0, Step 2568: train/loss = 0.4402211904525757, train/raw-loss = 0.40288403630256653, train/logprobs = tensor([[-0.8162, -3.1323],
        [-2.3176, -1.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733714520931244
Epoch 0, Step 2569: train/loss = 0.30111488699913025, train/raw-loss = 0.25879189372062683, train/logprobs = tensor([[ -2.3425, -10.7125],
        [ -3.6331,  -1.7904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4232299327850342
Epoch 0, Step 2570: train/loss = 0.8319034576416016, train/raw-loss = 0.7917522192001343, train/logprobs = tensor([[-1.7770, -1.8378],
        [-1.3740, -1.4282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4015118479728699
Epoch 0, Step 2571: train/loss = 0.33780157566070557, train/raw-loss = 0.29186874628067017, train/logprobs = tensor([[-1.9106, -4.6797],
        [-3.6441, -1.3484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45932793617248535
Epoch 0, Step 2572: train/loss = 0.5395621657371521, train/raw-loss = 0.5041221380233765, train/logprobs = tensor([[-3.4464, -8.4598],
        [-3.6686, -2.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354400098323822
Epoch 0, Step 2573: train/loss = 0.6672345399856567, train/raw-loss = 0.6311976909637451, train/logprobs = tensor([[-3.2964, -7.6780],
        [-3.0768, -2.4230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3603692054748535
Epoch 0, Step 2574: train/loss = 0.2441776990890503, train/raw-loss = 0.20708408951759338, train/logprobs = tensor([[-1.3152, -8.5414],
        [-2.3028, -1.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3709360957145691
Epoch 0, Step 2575: train/loss = 0.3913206160068512, train/raw-loss = 0.34757667779922485, train/logprobs = tensor([[-1.5482, -5.1079],
        [-5.5087, -1.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4374392032623291
Epoch 0, Step 2576: train/loss = 0.23000113666057587, train/raw-loss = 0.17950573563575745, train/logprobs = tensor([[-1.3105, -9.5643],
        [-4.2625, -1.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5049540996551514
Epoch 0, Step 2577: train/loss = 0.3151748478412628, train/raw-loss = 0.27217045426368713, train/logprobs = tensor([[-1.0504, -8.4442],
        [-3.2669, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43004417419433594
Epoch 0, Step 2578: train/loss = 0.31389909982681274, train/raw-loss = 0.2649398744106293, train/logprobs = tensor([[-1.3644, -6.0616],
        [-2.9974, -2.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48959240317344666
Epoch 0, Step 2579: train/loss = 0.275055855512619, train/raw-loss = 0.23297913372516632, train/logprobs = tensor([[ -1.3528, -10.0933],
        [ -4.1961,  -3.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42076730728149414
Epoch 0, Step 2580: train/loss = 0.09527821093797684, train/raw-loss = 0.0364653654396534, train/logprobs = tensor([[ -1.4378, -10.4245],
        [ -4.1236,  -3.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5881284475326538
Epoch 0, Step 2581: train/loss = 0.4740069508552551, train/raw-loss = 0.42502540349960327, train/logprobs = tensor([[-1.7398, -2.4721],
        [-4.0660, -2.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48981568217277527
Epoch 0, Step 2582: train/loss = 0.17669567465782166, train/raw-loss = 0.1250772327184677, train/logprobs = tensor([[ -1.9794, -13.3685],
        [ -5.0757,  -1.2148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5161842703819275
Epoch 0, Step 2583: train/loss = 0.10901603102684021, train/raw-loss = 0.06404559314250946, train/logprobs = tensor([[-1.5805, -7.3116],
        [-4.2565, -1.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44970425963401794
Epoch 0, Step 2584: train/loss = 0.26329174637794495, train/raw-loss = 0.2149217277765274, train/logprobs = tensor([[-2.1504, -5.5400],
        [-3.9482, -1.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4837002158164978
Epoch 0, Step 2585: train/loss = 0.5005843639373779, train/raw-loss = 0.456562876701355, train/logprobs = tensor([[-1.7597, -5.2416],
        [-3.1939, -2.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4402146339416504
Epoch 0, Step 2586: train/loss = 0.3781629204750061, train/raw-loss = 0.3337269723415375, train/logprobs = tensor([[-1.1077, -8.2190],
        [-3.1202, -3.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44435954093933105
Epoch 0, Step 2587: train/loss = 0.5082923173904419, train/raw-loss = 0.4730473756790161, train/logprobs = tensor([[-0.7362, -2.7511],
        [-1.3685, -1.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3524490296840668
Epoch 0, Step 2588: train/loss = 0.30121657252311707, train/raw-loss = 0.26067864894866943, train/logprobs = tensor([[-2.2906, -9.7490],
        [-4.2537, -2.2472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4053792655467987
Epoch 0, Step 2589: train/loss = 0.1237921267747879, train/raw-loss = 0.07286225259304047, train/logprobs = tensor([[ -1.1731, -11.1535],
        [ -4.5745,  -3.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5092988014221191
Epoch 0, Step 2590: train/loss = 0.4028646945953369, train/raw-loss = 0.356558233499527, train/logprobs = tensor([[-2.5850, -8.4341],
        [-5.1022, -1.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46306467056274414
Epoch 0, Step 2591: train/loss = 0.26442596316337585, train/raw-loss = 0.20813003182411194, train/logprobs = tensor([[-1.5209, -9.6276],
        [-3.9566, -3.7742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5629593133926392
Epoch 0, Step 2592: train/loss = 0.21971702575683594, train/raw-loss = 0.1753634512424469, train/logprobs = tensor([[-1.0578, -6.3817],
        [-3.1241, -1.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44353580474853516
Epoch 0, Step 2593: train/loss = 0.1087147668004036, train/raw-loss = 0.05104641243815422, train/logprobs = tensor([[-1.3842, -9.7997],
        [-3.7174, -2.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5766834616661072
Epoch 0, Step 2594: train/loss = 0.31562119722366333, train/raw-loss = 0.27246907353401184, train/logprobs = tensor([[-1.3525, -5.6475],
        [-3.1850, -2.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4315212368965149
Epoch 0, Step 2595: train/loss = 0.26664748787879944, train/raw-loss = 0.22393552958965302, train/logprobs = tensor([[-1.2102, -8.0661],
        [-4.1505, -1.1263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4271194338798523
Epoch 0, Step 2596: train/loss = 0.3538449704647064, train/raw-loss = 0.3061641752719879, train/logprobs = tensor([[-1.2218, -8.7606],
        [-3.4078, -2.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4768078923225403
Epoch 0, Step 2597: train/loss = 0.14137616753578186, train/raw-loss = 0.09889042377471924, train/logprobs = tensor([[-1.2484, -9.2742],
        [-3.6231, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42485731840133667
Epoch 0, Step 2598: train/loss = 0.38361477851867676, train/raw-loss = 0.3473826050758362, train/logprobs = tensor([[-1.6448, -3.2602],
        [-3.3767, -1.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36232197284698486
Epoch 0, Step 2599: train/loss = 0.3483594059944153, train/raw-loss = 0.3112559914588928, train/logprobs = tensor([[-1.8940, -5.2053],
        [-2.9286, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37103405594825745
Epoch 0, Step 2600: train/loss = 0.4185869097709656, train/raw-loss = 0.361835777759552, train/logprobs = tensor([[-1.3483, -3.2285],
        [-2.7778, -2.5441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5675116777420044
Epoch 0, Step 2601: train/loss = 0.38925182819366455, train/raw-loss = 0.3488871455192566, train/logprobs = tensor([[-1.1341, -7.3490],
        [-2.5234, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036465287208557
Epoch 0, Step 2602: train/loss = 0.35941872000694275, train/raw-loss = 0.30922800302505493, train/logprobs = tensor([[-1.3337, -5.6079],
        [-4.0112, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.501907229423523
Epoch 0, Step 2603: train/loss = 0.28927019238471985, train/raw-loss = 0.24846336245536804, train/logprobs = tensor([[-2.1812, -6.9492],
        [-3.9136, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40806835889816284
Epoch 0, Step 2604: train/loss = 0.36448824405670166, train/raw-loss = 0.31214872002601624, train/logprobs = tensor([[-1.4624, -7.7024],
        [-4.4945, -2.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523395299911499
Epoch 0, Step 2605: train/loss = 0.29333627223968506, train/raw-loss = 0.2346460223197937, train/logprobs = tensor([[-1.6930, -8.1232],
        [-3.7431, -1.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5869022607803345
Epoch 0, Step 2606: train/loss = 0.3175155520439148, train/raw-loss = 0.28348687291145325, train/logprobs = tensor([[-1.2899, -2.4588],
        [-2.6919, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34028664231300354
Epoch 0, Step 2607: train/loss = 0.3490034341812134, train/raw-loss = 0.2986598610877991, train/logprobs = tensor([[-1.3841, -6.9791],
        [-2.5949, -2.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5034359097480774
Epoch 0, Step 2608: train/loss = 0.31686824560165405, train/raw-loss = 0.2726760506629944, train/logprobs = tensor([[ -2.1419, -11.2994],
        [ -4.6705,  -3.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44192206859588623
Epoch 0, Step 2609: train/loss = 0.3987782597541809, train/raw-loss = 0.35202011466026306, train/logprobs = tensor([[-1.2720, -2.1189],
        [-3.2624, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4675816297531128
Epoch 0, Step 2610: train/loss = 0.16494445502758026, train/raw-loss = 0.11264034360647202, train/logprobs = tensor([[-1.3042, -7.0791],
        [-5.0423, -1.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5230410695075989
Epoch 0, Step 2611: train/loss = 0.2107033133506775, train/raw-loss = 0.16676445305347443, train/logprobs = tensor([[ -1.8211, -11.1119],
        [ -3.5519,  -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43938857316970825
Epoch 0, Step 2612: train/loss = 0.6219123601913452, train/raw-loss = 0.583963930606842, train/logprobs = tensor([[-1.7582, -2.7775],
        [-1.8949, -1.2752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37948453426361084
Epoch 0, Step 2613: train/loss = 0.24587556719779968, train/raw-loss = 0.20900565385818481, train/logprobs = tensor([[-1.6007, -5.9695],
        [-2.8393, -1.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36869919300079346
Epoch 0, Step 2614: train/loss = 0.2768094539642334, train/raw-loss = 0.2382776290178299, train/logprobs = tensor([[-1.7196, -6.7882],
        [-3.5934, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3853182792663574
Epoch 0, Step 2615: train/loss = 0.07814948260784149, train/raw-loss = 0.022629138082265854, train/logprobs = tensor([[ -1.7081, -11.0363],
        [ -5.4792,  -2.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5552034378051758
Epoch 0, Step 2616: train/loss = 0.33569371700286865, train/raw-loss = 0.2851008176803589, train/logprobs = tensor([[ -1.1432, -10.0161],
        [ -4.6383,  -2.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5059292316436768
Epoch 0, Step 2617: train/loss = 0.7018877267837524, train/raw-loss = 0.645187258720398, train/logprobs = tensor([[-1.4906, -5.6058],
        [-3.4703, -2.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5670046210289001
Epoch 0, Step 2618: train/loss = 0.20095431804656982, train/raw-loss = 0.16372530162334442, train/logprobs = tensor([[-1.5396, -8.9318],
        [-3.3911, -1.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722902238368988
Epoch 0, Step 2619: train/loss = 0.5183295011520386, train/raw-loss = 0.46645841002464294, train/logprobs = tensor([[-2.4360, -3.6238],
        [-3.2284, -2.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5187113285064697
Epoch 0, Step 2620: train/loss = 0.27465614676475525, train/raw-loss = 0.23806586861610413, train/logprobs = tensor([[-1.0433, -4.5411],
        [-2.2306, -2.1668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659028112888336
Epoch 0, Step 2621: train/loss = 0.5544531345367432, train/raw-loss = 0.4988854229450226, train/logprobs = tensor([[-1.6570, -3.6397],
        [-3.9075, -2.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5556773543357849
Epoch 0, Step 2622: train/loss = 0.34298181533813477, train/raw-loss = 0.3047860264778137, train/logprobs = tensor([[-1.6263, -4.6795],
        [-2.8846, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3819575011730194
Epoch 0, Step 2623: train/loss = 0.2662269175052643, train/raw-loss = 0.21709398925304413, train/logprobs = tensor([[-1.8487, -8.5292],
        [-5.3756, -1.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4913293123245239
Epoch 0, Step 2624: train/loss = 0.15537282824516296, train/raw-loss = 0.10663582384586334, train/logprobs = tensor([[-1.1084, -8.9867],
        [-2.7172, -1.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4873701333999634
Epoch 0, Step 2625: train/loss = 0.37940579652786255, train/raw-loss = 0.3277597427368164, train/logprobs = tensor([[-0.8404, -8.8793],
        [-3.8778, -2.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5164605975151062
Epoch 0, Step 2626: train/loss = 0.4887789487838745, train/raw-loss = 0.46099627017974854, train/logprobs = tensor([[-1.1132, -6.4109],
        [-1.8654, -1.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27782705426216125
Epoch 0, Step 2627: train/loss = 0.4708186388015747, train/raw-loss = 0.42606934905052185, train/logprobs = tensor([[-1.2562, -2.5061],
        [-1.9802, -1.0418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.447492778301239
Epoch 0, Step 2628: train/loss = 0.5256483554840088, train/raw-loss = 0.47824135422706604, train/logprobs = tensor([[-1.4297, -4.2773],
        [-2.6583, -2.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4740702211856842
Epoch 0, Step 2629: train/loss = 0.48174506425857544, train/raw-loss = 0.43531161546707153, train/logprobs = tensor([[-2.2415, -6.4289],
        [-3.7760, -1.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4643346667289734
Epoch 0, Step 2630: train/loss = 0.675828218460083, train/raw-loss = 0.629793107509613, train/logprobs = tensor([[-1.8652, -1.8284],
        [-3.1296, -2.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46035128831863403
Epoch 0, Step 2631: train/loss = 0.22129608690738678, train/raw-loss = 0.17242343723773956, train/logprobs = tensor([[-1.4477, -5.3384],
        [-4.1147, -1.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4887264668941498
Epoch 0, Step 2632: train/loss = 0.525497317314148, train/raw-loss = 0.4736557602882385, train/logprobs = tensor([[-1.9260, -5.2885],
        [-3.8163, -2.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5184150338172913
Epoch 0, Step 2633: train/loss = 0.09154565632343292, train/raw-loss = 0.04381228983402252, train/logprobs = tensor([[-1.4023, -9.7375],
        [-3.9085, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47733360528945923
Epoch 0, Step 2634: train/loss = 0.18417325615882874, train/raw-loss = 0.13636167347431183, train/logprobs = tensor([[-1.6800, -5.2182],
        [-3.5320, -0.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47811585664749146
Epoch 0, Step 2635: train/loss = 0.0857522189617157, train/raw-loss = 0.03665170073509216, train/logprobs = tensor([[-1.7280, -8.5603],
        [-4.5863, -1.4608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49100518226623535
Epoch 0, Step 2636: train/loss = 0.4232187271118164, train/raw-loss = 0.38121816515922546, train/logprobs = tensor([[-1.1354, -3.7354],
        [-2.8173, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4200054109096527
Epoch 0, Step 2637: train/loss = 0.12541787326335907, train/raw-loss = 0.08116861432790756, train/logprobs = tensor([[-1.3877, -4.4477],
        [-4.4921, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4424925446510315
Epoch 0, Step 2638: train/loss = 0.11315349489450455, train/raw-loss = 0.06765401363372803, train/logprobs = tensor([[-2.1984, -8.5319],
        [-5.1455, -1.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4549948275089264
Epoch 0, Step 2639: train/loss = 0.22728636860847473, train/raw-loss = 0.18513871729373932, train/logprobs = tensor([[ -2.5123, -12.6573],
        [ -4.9048,  -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4214763939380646
Epoch 0, Step 2640: train/loss = 0.5161433815956116, train/raw-loss = 0.47646570205688477, train/logprobs = tensor([[-1.9967, -5.6729],
        [-2.5270, -1.4229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3967767357826233
Epoch 0, Step 2641: train/loss = 0.14624112844467163, train/raw-loss = 0.10187950730323792, train/logprobs = tensor([[-2.0836, -8.0326],
        [-4.0943, -1.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44361618161201477
Epoch 0, Step 2642: train/loss = 0.23106835782527924, train/raw-loss = 0.1844203621149063, train/logprobs = tensor([[ -1.3844, -10.2696],
        [ -3.0741,  -2.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4664801061153412
Epoch 0, Step 2643: train/loss = 0.5080124735832214, train/raw-loss = 0.47427406907081604, train/logprobs = tensor([[-3.0147, -4.5392],
        [-2.4848, -1.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33738356828689575
Epoch 0, Step 2644: train/loss = 0.5629647374153137, train/raw-loss = 0.5157968401908875, train/logprobs = tensor([[-2.0151, -5.0001],
        [-2.8197, -1.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47167864441871643
Epoch 0, Step 2645: train/loss = 0.4548719525337219, train/raw-loss = 0.41562411189079285, train/logprobs = tensor([[-1.9453, -4.8305],
        [-2.3713, -1.3598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924783766269684
Epoch 0, Step 2646: train/loss = 0.3540332615375519, train/raw-loss = 0.30826956033706665, train/logprobs = tensor([[-0.9035, -8.5980],
        [-2.6751, -2.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45763731002807617
Epoch 0, Step 2647: train/loss = 0.28402942419052124, train/raw-loss = 0.23758168518543243, train/logprobs = tensor([[-1.4927, -6.2515],
        [-3.1493, -2.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4644773602485657
Epoch 0, Step 2648: train/loss = 0.648916482925415, train/raw-loss = 0.5973910093307495, train/logprobs = tensor([[-1.5600, -7.8771],
        [-4.8403, -2.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5152541995048523
Epoch 0, Step 2649: train/loss = 0.4766678810119629, train/raw-loss = 0.43257084488868713, train/logprobs = tensor([[-1.5670, -2.3509],
        [-2.5665, -1.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409705400466919
Epoch 0, Step 2650: train/loss = 0.5237681865692139, train/raw-loss = 0.4918358325958252, train/logprobs = tensor([[-2.3051, -7.4124],
        [-2.6553, -1.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3193237781524658
Epoch 0, Step 2651: train/loss = 0.12444502115249634, train/raw-loss = 0.06006599962711334, train/logprobs = tensor([[-0.7907, -6.2429],
        [-3.1513, -1.6650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6437902450561523
Epoch 0, Step 2652: train/loss = 0.16769558191299438, train/raw-loss = 0.11926688998937607, train/logprobs = tensor([[-1.4575, -8.0470],
        [-3.3726, -1.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.484286904335022
Epoch 0, Step 2653: train/loss = 0.22643902897834778, train/raw-loss = 0.18319767713546753, train/logprobs = tensor([[-1.3361, -6.2573],
        [-2.8155, -1.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43241360783576965
Epoch 0, Step 2654: train/loss = 0.6088961362838745, train/raw-loss = 0.5597295165061951, train/logprobs = tensor([[-2.0531, -6.6662],
        [-5.0196, -3.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49166613817214966
Epoch 0, Step 2655: train/loss = 0.22557145357131958, train/raw-loss = 0.1736685037612915, train/logprobs = tensor([[-1.5411, -6.7668],
        [-3.2082, -1.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5190294981002808
Epoch 0, Step 2656: train/loss = 0.36099350452423096, train/raw-loss = 0.3171851634979248, train/logprobs = tensor([[-1.8843, -3.7444],
        [-2.8264, -2.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4380831718444824
Epoch 0, Step 2657: train/loss = 0.374162882566452, train/raw-loss = 0.33655884861946106, train/logprobs = tensor([[ -1.8178, -10.9499],
        [ -2.2685,  -2.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37604039907455444
Epoch 0, Step 2658: train/loss = 0.12387038767337799, train/raw-loss = 0.08071023225784302, train/logprobs = tensor([[-1.5079, -9.0586],
        [-4.0134, -2.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43160155415534973
Epoch 0, Step 2659: train/loss = 0.3112097978591919, train/raw-loss = 0.27118074893951416, train/logprobs = tensor([[-1.9890, -3.9158],
        [-2.9908, -1.4016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40029019117355347
Epoch 0, Step 2660: train/loss = 0.4806009531021118, train/raw-loss = 0.4390561878681183, train/logprobs = tensor([[-2.1005, -4.5787],
        [-3.0053, -2.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4154477119445801
Epoch 0, Step 2661: train/loss = 0.24666906893253326, train/raw-loss = 0.19176502525806427, train/logprobs = tensor([[-1.5819, -4.7830],
        [-4.1058, -1.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5490403175354004
Epoch 0, Step 2662: train/loss = 0.13891646265983582, train/raw-loss = 0.09623997658491135, train/logprobs = tensor([[-1.7476, -5.3452],
        [-4.5233, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42676472663879395
Epoch 0, Step 2663: train/loss = 0.08924509584903717, train/raw-loss = 0.03722768276929855, train/logprobs = tensor([[ -1.5360, -13.7797],
        [ -4.6805,  -3.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5201740264892578
Epoch 0, Step 2664: train/loss = 0.2064550518989563, train/raw-loss = 0.16178148984909058, train/logprobs = tensor([[-1.4774, -5.1261],
        [-3.6237, -2.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.446735680103302
Epoch 0, Step 2665: train/loss = 0.5131109356880188, train/raw-loss = 0.47214341163635254, train/logprobs = tensor([[-1.6366, -4.0123],
        [-2.5486, -2.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4096751809120178
Epoch 0, Step 2666: train/loss = 0.45785412192344666, train/raw-loss = 0.40411871671676636, train/logprobs = tensor([[-1.5424, -3.9316],
        [-2.4310, -2.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5373543500900269
Epoch 0, Step 2667: train/loss = 0.2964021861553192, train/raw-loss = 0.24127650260925293, train/logprobs = tensor([[-1.5193, -7.0095],
        [-4.4032, -2.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5512570142745972
Epoch 0, Step 2668: train/loss = 0.50771164894104, train/raw-loss = 0.4573110044002533, train/logprobs = tensor([[-1.7808, -3.0519],
        [-2.8615, -2.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5040062665939331
Epoch 0, Step 2669: train/loss = 0.5015060901641846, train/raw-loss = 0.47172242403030396, train/logprobs = tensor([[-2.2269, -6.3324],
        [-3.1787, -1.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978364825248718
Epoch 0, Step 2670: train/loss = 0.15357869863510132, train/raw-loss = 0.11142544448375702, train/logprobs = tensor([[ -1.3038, -10.9842],
        [ -3.7832,  -2.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215325713157654
Epoch 0, Step 2671: train/loss = 0.4982263147830963, train/raw-loss = 0.4588112533092499, train/logprobs = tensor([[-2.9780, -7.4968],
        [-4.0256, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3941504955291748
Epoch 0, Step 2672: train/loss = 0.5540070533752441, train/raw-loss = 0.5115834474563599, train/logprobs = tensor([[-1.9526, -4.1167],
        [-2.8383, -2.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42423635721206665
Epoch 0, Step 2673: train/loss = 0.42911991477012634, train/raw-loss = 0.387314110994339, train/logprobs = tensor([[-1.2643, -4.0453],
        [-1.8801, -1.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4180578887462616
Epoch 0, Step 2674: train/loss = 0.4126262366771698, train/raw-loss = 0.3682463765144348, train/logprobs = tensor([[-1.0713, -5.4761],
        [-2.7217, -1.9424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4437985420227051
Epoch 0, Step 2675: train/loss = 0.49031221866607666, train/raw-loss = 0.4522164463996887, train/logprobs = tensor([[-2.0884, -4.2992],
        [-3.1081, -1.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3809572756290436
Epoch 0, Step 2676: train/loss = 0.2341463565826416, train/raw-loss = 0.1874893456697464, train/logprobs = tensor([[-1.1326, -6.6714],
        [-3.6397, -1.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4665701985359192
Epoch 0, Step 2677: train/loss = 0.3517146110534668, train/raw-loss = 0.3117907643318176, train/logprobs = tensor([[-1.6068, -2.3115],
        [-3.1149, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39923831820487976
Epoch 0, Step 2678: train/loss = 0.379768043756485, train/raw-loss = 0.33391910791397095, train/logprobs = tensor([[-1.2142, -2.8560],
        [-2.7570, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45848941802978516
Epoch 0, Step 2679: train/loss = 0.09357216954231262, train/raw-loss = 0.045492447912693024, train/logprobs = tensor([[ -1.2873, -11.7582],
        [ -4.3341,  -1.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4807972311973572
Epoch 0, Step 2680: train/loss = 0.08573415875434875, train/raw-loss = 0.024853626266121864, train/logprobs = tensor([[ -1.6565, -11.5439],
        [ -5.0648,  -1.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.608805239200592
Epoch 0, Step 2681: train/loss = 0.10146598517894745, train/raw-loss = 0.04814847558736801, train/logprobs = tensor([[ -1.4463, -14.0794],
        [ -5.2728,  -3.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5331751108169556
Epoch 0, Step 2682: train/loss = 0.365227073431015, train/raw-loss = 0.3291183114051819, train/logprobs = tensor([[-1.1854, -4.7876],
        [-2.1265, -1.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610877990722656
Epoch 0, Step 2683: train/loss = 0.3870423138141632, train/raw-loss = 0.336421936750412, train/logprobs = tensor([[-1.4443, -4.3031],
        [-3.4232, -2.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5062039494514465
Epoch 0, Step 2684: train/loss = 0.7546250820159912, train/raw-loss = 0.7080652117729187, train/logprobs = tensor([[-2.0539, -5.9471],
        [-2.5709, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.465598464012146
Epoch 0, Step 2685: train/loss = 0.5507470369338989, train/raw-loss = 0.4918084144592285, train/logprobs = tensor([[-1.4823, -2.5926],
        [-3.5435, -2.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5893867015838623
Epoch 0, Step 2686: train/loss = 0.2084895819425583, train/raw-loss = 0.16067203879356384, train/logprobs = tensor([[-1.9105, -8.7994],
        [-4.2671, -1.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47817543148994446
Epoch 0, Step 2687: train/loss = 0.8813403844833374, train/raw-loss = 0.8318403959274292, train/logprobs = tensor([[-1.7986, -1.9695],
        [-2.1592, -2.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4949990510940552
Epoch 0, Step 2688: train/loss = 0.4269089102745056, train/raw-loss = 0.38236862421035767, train/logprobs = tensor([[-2.1001, -5.8623],
        [-3.0378, -2.1029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.445403128862381
Epoch 0, Step 2689: train/loss = 0.3610195815563202, train/raw-loss = 0.317404568195343, train/logprobs = tensor([[-1.7899, -3.9859],
        [-2.8433, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4361500144004822
Epoch 0, Step 2690: train/loss = 0.43453866243362427, train/raw-loss = 0.3982599079608917, train/logprobs = tensor([[-1.4781, -5.4274],
        [-2.7021, -1.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362787663936615
Epoch 0, Step 2691: train/loss = 0.2284059226512909, train/raw-loss = 0.18395835161209106, train/logprobs = tensor([[-1.6115, -7.5082],
        [-3.5777, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44447553157806396
Epoch 0, Step 2692: train/loss = 0.5003942251205444, train/raw-loss = 0.45225396752357483, train/logprobs = tensor([[-1.0854, -3.2819],
        [-2.4493, -1.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48140281438827515
Epoch 0, Step 2693: train/loss = 0.6971635818481445, train/raw-loss = 0.6455984711647034, train/logprobs = tensor([[-3.4337, -7.9528],
        [-3.1241, -3.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5156509876251221
Epoch 0, Step 2694: train/loss = 0.4014914929866791, train/raw-loss = 0.3496551513671875, train/logprobs = tensor([[-0.7735, -7.5343],
        [-2.5537, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5183637142181396
Epoch 0, Step 2695: train/loss = 0.2551347315311432, train/raw-loss = 0.20869621634483337, train/logprobs = tensor([[ -1.6282, -12.6166],
        [ -3.8859,  -2.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4643849730491638
Epoch 0, Step 2696: train/loss = 0.18627385795116425, train/raw-loss = 0.14091894030570984, train/logprobs = tensor([[-1.6894, -9.4464],
        [-4.2052, -2.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4535491466522217
Epoch 0, Step 2697: train/loss = 0.43947839736938477, train/raw-loss = 0.3987903594970703, train/logprobs = tensor([[-1.1061, -4.3026],
        [-2.4277, -1.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40688079595565796
Epoch 0, Step 2698: train/loss = 0.20695272088050842, train/raw-loss = 0.1659347414970398, train/logprobs = tensor([[ -1.5054, -11.4688],
        [ -3.0606,  -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41017982363700867
Epoch 0, Step 2699: train/loss = 0.5043677091598511, train/raw-loss = 0.444375216960907, train/logprobs = tensor([[-2.1726, -3.4723],
        [-4.1089, -3.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5999248027801514
Epoch 0, Step 2700: train/loss = 0.4807087779045105, train/raw-loss = 0.43496236205101013, train/logprobs = tensor([[-1.9863, -4.0913],
        [-2.8807, -2.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4574645161628723
Epoch 0, Step 2701: train/loss = 0.40157631039619446, train/raw-loss = 0.36939775943756104, train/logprobs = tensor([[-0.9805, -5.2723],
        [-1.6141, -1.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32178568840026855
Epoch 0, Step 2702: train/loss = 0.17163926362991333, train/raw-loss = 0.1210319995880127, train/logprobs = tensor([[ -1.5051, -10.3367],
        [ -5.1694,  -3.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5060727596282959
Epoch 0, Step 2703: train/loss = 0.3850574195384979, train/raw-loss = 0.354860782623291, train/logprobs = tensor([[-1.4897, -2.6607],
        [-2.2195, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019665479660034
Epoch 0, Step 2704: train/loss = 0.40163522958755493, train/raw-loss = 0.34566664695739746, train/logprobs = tensor([[-1.3111, -3.9620],
        [-4.5519, -1.7976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5596860647201538
Epoch 0, Step 2705: train/loss = 0.22476796805858612, train/raw-loss = 0.18786032497882843, train/logprobs = tensor([[ -0.7364, -10.6312],
        [ -2.1225,  -1.5479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3690764307975769
Epoch 0, Step 2706: train/loss = 0.09443680942058563, train/raw-loss = 0.0392768420279026, train/logprobs = tensor([[-1.3462, -6.6869],
        [-4.8466, -1.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5515996217727661
Epoch 0, Step 2707: train/loss = 0.4798060655593872, train/raw-loss = 0.41373568773269653, train/logprobs = tensor([[-1.9488, -3.5431],
        [-3.4392, -2.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6607037782669067
Epoch 0, Step 2708: train/loss = 0.4305152893066406, train/raw-loss = 0.39248624444007874, train/logprobs = tensor([[-1.8245, -4.3974],
        [-2.9246, -1.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3802903890609741
Epoch 0, Step 2709: train/loss = 0.2391115427017212, train/raw-loss = 0.1910257339477539, train/logprobs = tensor([[-1.1902, -6.1460],
        [-4.3457, -1.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4808582663536072
Epoch 0, Step 2710: train/loss = 0.4646095037460327, train/raw-loss = 0.4151727557182312, train/logprobs = tensor([[-1.5139, -2.1610],
        [-2.5678, -1.4298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49436721205711365
Epoch 0, Step 2711: train/loss = 0.23538541793823242, train/raw-loss = 0.19823801517486572, train/logprobs = tensor([[-1.4117, -7.2799],
        [-2.4610, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714742064476013
Epoch 0, Step 2712: train/loss = 0.22071994841098785, train/raw-loss = 0.1734829992055893, train/logprobs = tensor([[-1.2913, -6.7844],
        [-4.2000, -1.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47236964106559753
Epoch 0, Step 2713: train/loss = 0.10661603510379791, train/raw-loss = 0.057891786098480225, train/logprobs = tensor([[ -1.1412, -15.4465],
        [ -3.5527,  -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48724257946014404
Epoch 0, Step 2714: train/loss = 0.16199380159378052, train/raw-loss = 0.11868169903755188, train/logprobs = tensor([[-1.3760, -5.1160],
        [-4.1911, -0.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4331209659576416
Epoch 0, Step 2715: train/loss = 0.47802719473838806, train/raw-loss = 0.42528706789016724, train/logprobs = tensor([[-3.0858, -9.9375],
        [-4.6710, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5274012088775635
Epoch 0, Step 2716: train/loss = 0.5416672825813293, train/raw-loss = 0.4866151809692383, train/logprobs = tensor([[-1.9840, -6.9451],
        [-3.3821, -2.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5505208969116211
Epoch 0, Step 2717: train/loss = 0.22701027989387512, train/raw-loss = 0.1810375154018402, train/logprobs = tensor([[-1.2472, -8.7998],
        [-3.3095, -2.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45972755551338196
Epoch 0, Step 2718: train/loss = 0.15975536406040192, train/raw-loss = 0.11215126514434814, train/logprobs = tensor([[-1.3555, -5.5649],
        [-3.5084, -1.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4760410189628601
Epoch 0, Step 2719: train/loss = 0.3488503098487854, train/raw-loss = 0.30665555596351624, train/logprobs = tensor([[-2.2068, -7.0711],
        [-3.1741, -1.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4219474792480469
Epoch 0, Step 2720: train/loss = 0.46748125553131104, train/raw-loss = 0.42701223492622375, train/logprobs = tensor([[-1.3198, -3.7554],
        [-2.5316, -2.0246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046901762485504
Epoch 0, Step 2721: train/loss = 0.6420286893844604, train/raw-loss = 0.593374490737915, train/logprobs = tensor([[-1.9125, -3.7397],
        [-2.6305, -1.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4865424335002899
Epoch 0, Step 2722: train/loss = 0.22727803885936737, train/raw-loss = 0.16430382430553436, train/logprobs = tensor([[-1.7018, -5.4700],
        [-4.4454, -2.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6297422647476196
Epoch 0, Step 2723: train/loss = 0.406571626663208, train/raw-loss = 0.3693939447402954, train/logprobs = tensor([[-1.1450, -7.4888],
        [-2.8523, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3717767596244812
Epoch 0, Step 2724: train/loss = 0.3848416805267334, train/raw-loss = 0.3423542380332947, train/logprobs = tensor([[-1.4082, -4.9998],
        [-2.6139, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42487436532974243
Epoch 0, Step 2725: train/loss = 0.1667892187833786, train/raw-loss = 0.13086622953414917, train/logprobs = tensor([[-1.2007, -8.4472],
        [-3.0317, -1.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35923007130622864
Epoch 0, Step 2726: train/loss = 0.5040723085403442, train/raw-loss = 0.46200913190841675, train/logprobs = tensor([[-1.5473, -3.8181],
        [-2.4400, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4206313490867615
Epoch 0, Step 2727: train/loss = 0.4881705641746521, train/raw-loss = 0.44499918818473816, train/logprobs = tensor([[-1.1668, -7.3914],
        [-2.0529, -2.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43171361088752747
Epoch 0, Step 2728: train/loss = 0.2197585552930832, train/raw-loss = 0.1711418330669403, train/logprobs = tensor([[-0.8263, -7.1381],
        [-3.0608, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.486167311668396
Epoch 0, Step 2729: train/loss = 0.6627689599990845, train/raw-loss = 0.6012163162231445, train/logprobs = tensor([[-1.3155, -2.3067],
        [-3.4937, -3.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.615526556968689
Epoch 0, Step 2730: train/loss = 0.35211047530174255, train/raw-loss = 0.3053298592567444, train/logprobs = tensor([[-2.1435, -7.1401],
        [-3.5992, -2.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678061008453369
Epoch 0, Step 2731: train/loss = 0.2509400546550751, train/raw-loss = 0.20840296149253845, train/logprobs = tensor([[ -1.4669, -14.3904],
        [ -4.1276,  -2.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.425370991230011
Epoch 0, Step 2732: train/loss = 0.24062122404575348, train/raw-loss = 0.19526827335357666, train/logprobs = tensor([[-1.0994, -8.7383],
        [-3.0467, -1.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4535294473171234
Epoch 0, Step 2733: train/loss = 0.41960346698760986, train/raw-loss = 0.3905194401741028, train/logprobs = tensor([[-2.2311, -8.3421],
        [-2.1845, -1.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29084014892578125
Epoch 0, Step 2734: train/loss = 0.553483247756958, train/raw-loss = 0.5180979371070862, train/logprobs = tensor([[-0.9869, -3.1211],
        [-1.7189, -1.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35385316610336304
Epoch 0, Step 2735: train/loss = 0.31020617485046387, train/raw-loss = 0.2671135663986206, train/logprobs = tensor([[-1.1415, -6.3277],
        [-3.3220, -2.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4309264123439789
Epoch 0, Step 2736: train/loss = 0.38401710987091064, train/raw-loss = 0.31985488533973694, train/logprobs = tensor([[-1.7617, -9.3287],
        [-3.8093, -4.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6416222453117371
Epoch 0, Step 2737: train/loss = 0.3458905816078186, train/raw-loss = 0.3076014518737793, train/logprobs = tensor([[-1.8424, -4.0739],
        [-3.1258, -2.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38289114832878113
Epoch 0, Step 2738: train/loss = 0.531983494758606, train/raw-loss = 0.4922448396682739, train/logprobs = tensor([[-1.1833, -2.2684],
        [-2.6561, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39738643169403076
Epoch 0, Step 2739: train/loss = 0.35887327790260315, train/raw-loss = 0.32307371497154236, train/logprobs = tensor([[-1.5303, -8.4259],
        [-2.7108, -1.0581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579956293106079
Epoch 0, Step 2740: train/loss = 0.34527266025543213, train/raw-loss = 0.30155864357948303, train/logprobs = tensor([[-1.0568, -7.2085],
        [-3.1139, -2.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43714025616645813
Epoch 0, Step 2741: train/loss = 0.31157398223876953, train/raw-loss = 0.2653988301753998, train/logprobs = tensor([[-1.2165, -7.7831],
        [-3.2287, -2.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4617518186569214
Epoch 0, Step 2742: train/loss = 0.37677109241485596, train/raw-loss = 0.3382648825645447, train/logprobs = tensor([[-0.7277, -3.4156],
        [-1.8555, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850618600845337
Epoch 0, Step 2743: train/loss = 0.1360863596200943, train/raw-loss = 0.09927424788475037, train/logprobs = tensor([[-1.4912, -5.3671],
        [-3.2672, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3681212067604065
Epoch 0, Step 2744: train/loss = 0.29380595684051514, train/raw-loss = 0.23322467505931854, train/logprobs = tensor([[ -0.9297, -12.0836],
        [ -3.3940,  -2.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6058127880096436
Epoch 0, Step 2745: train/loss = 0.3576548397541046, train/raw-loss = 0.30640050768852234, train/logprobs = tensor([[-1.1588, -5.2678],
        [-2.6519, -2.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5125434994697571
Epoch 0, Step 2746: train/loss = 0.510396420955658, train/raw-loss = 0.4786283075809479, train/logprobs = tensor([[-0.7381, -2.7593],
        [-1.9628, -1.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31768113374710083
Epoch 0, Step 2747: train/loss = 0.3901633024215698, train/raw-loss = 0.35042643547058105, train/logprobs = tensor([[-1.5832, -4.8687],
        [-2.9469, -2.2426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39736875891685486
Epoch 0, Step 2748: train/loss = 0.45768827199935913, train/raw-loss = 0.40329769253730774, train/logprobs = tensor([[-1.4395, -4.7144],
        [-2.8060, -1.3210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5439058542251587
Epoch 0, Step 2749: train/loss = 0.30412718653678894, train/raw-loss = 0.26533445715904236, train/logprobs = tensor([[-2.9019, -5.9343],
        [-4.0875, -2.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879276514053345
Epoch 0, Step 2750: train/loss = 0.4682319760322571, train/raw-loss = 0.4199117422103882, train/logprobs = tensor([[-2.1843, -6.9319],
        [-3.2770, -2.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4832024574279785
Epoch 0, Step 2751: train/loss = 0.28671759366989136, train/raw-loss = 0.23368343710899353, train/logprobs = tensor([[-1.1315, -5.3761],
        [-3.5251, -1.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.530341625213623
Epoch 0, Step 2752: train/loss = 0.6468404531478882, train/raw-loss = 0.6018112301826477, train/logprobs = tensor([[-1.1858, -2.6416],
        [-2.6960, -2.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45029202103614807
Epoch 0, Step 2753: train/loss = 0.4890092611312866, train/raw-loss = 0.4471202492713928, train/logprobs = tensor([[-1.4253, -3.1872],
        [-3.4336, -2.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41889047622680664
Epoch 0, Step 2754: train/loss = 0.2763984501361847, train/raw-loss = 0.22672289609909058, train/logprobs = tensor([[-1.3072, -7.0057],
        [-3.8550, -2.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4967554211616516
Epoch 0, Step 2755: train/loss = 0.16000522673130035, train/raw-loss = 0.1094484031200409, train/logprobs = tensor([[-1.1977, -5.2613],
        [-4.4945, -1.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.505568265914917
Epoch 0, Step 2756: train/loss = 0.1003631055355072, train/raw-loss = 0.05234929174184799, train/logprobs = tensor([[-1.4402, -7.9132],
        [-4.1197, -1.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48013806343078613
Epoch 0, Step 2757: train/loss = 1.3575323820114136, train/raw-loss = 1.3165677785873413, train/logprobs = tensor([[-3.9492, -5.7291],
        [-3.1224, -1.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40964648127555847
Epoch 0, Step 2758: train/loss = 0.36858949065208435, train/raw-loss = 0.33172017335891724, train/logprobs = tensor([[-1.2331, -4.2074],
        [-1.9784, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36869317293167114
Epoch 0, Step 2759: train/loss = 0.15263931453227997, train/raw-loss = 0.10519195348024368, train/logprobs = tensor([[-1.4044, -7.4879],
        [-3.6443, -2.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4744736850261688
Epoch 0, Step 2760: train/loss = 0.7249418497085571, train/raw-loss = 0.6682528257369995, train/logprobs = tensor([[-1.1422, -2.1612],
        [-2.6733, -2.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5668900609016418
Epoch 0, Step 2761: train/loss = 0.4721548557281494, train/raw-loss = 0.42859572172164917, train/logprobs = tensor([[-0.9827, -1.9645],
        [-2.2719, -1.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4355912208557129
Epoch 0, Step 2762: train/loss = 0.7164820432662964, train/raw-loss = 0.6683624982833862, train/logprobs = tensor([[-2.0722, -2.4661],
        [-2.4655, -2.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48119622468948364
Epoch 0, Step 2763: train/loss = 0.47485896944999695, train/raw-loss = 0.42596837878227234, train/logprobs = tensor([[-1.2154, -4.4057],
        [-3.8632, -2.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48890578746795654
Epoch 0, Step 2764: train/loss = 0.07306946814060211, train/raw-loss = 0.019510837271809578, train/logprobs = tensor([[ -1.6981, -13.5320],
        [ -5.5612,  -3.2249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5355862379074097
Epoch 0, Step 2765: train/loss = 0.3105566203594208, train/raw-loss = 0.25891000032424927, train/logprobs = tensor([[-1.3921, -5.9801],
        [-3.9576, -1.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5164662599563599
Epoch 0, Step 2766: train/loss = 0.16687506437301636, train/raw-loss = 0.11689218878746033, train/logprobs = tensor([[ -1.1065, -16.4692],
        [ -4.3115,  -4.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49982866644859314
Epoch 0, Step 2767: train/loss = 0.10105153918266296, train/raw-loss = 0.0459090918302536, train/logprobs = tensor([[-1.7241, -9.0250],
        [-4.7662, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5514243841171265
Epoch 0, Step 2768: train/loss = 0.21452592313289642, train/raw-loss = 0.1617359071969986, train/logprobs = tensor([[-1.5443, -7.8266],
        [-4.2462, -1.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.527900218963623
Epoch 0, Step 2769: train/loss = 0.3716067373752594, train/raw-loss = 0.327626496553421, train/logprobs = tensor([[-1.2311, -5.7113],
        [-2.3628, -1.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4398025572299957
Epoch 0, Step 2770: train/loss = 0.268338680267334, train/raw-loss = 0.21603086590766907, train/logprobs = tensor([[-1.1352, -6.0300],
        [-3.0096, -2.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5230779647827148
Epoch 0, Step 2771: train/loss = 0.35044658184051514, train/raw-loss = 0.3123336136341095, train/logprobs = tensor([[-1.3610, -5.7997],
        [-2.7499, -2.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38112974166870117
Epoch 0, Step 2772: train/loss = 0.06013155356049538, train/raw-loss = 0.013232794590294361, train/logprobs = tensor([[ -1.5007, -12.1306],
        [ -5.2922,  -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4689876437187195
Epoch 0, Step 2773: train/loss = 0.2832505404949188, train/raw-loss = 0.22806544601917267, train/logprobs = tensor([[-1.1134, -7.0034],
        [-3.7836, -2.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5518509149551392
Epoch 0, Step 2774: train/loss = 0.2536335587501526, train/raw-loss = 0.20942175388336182, train/logprobs = tensor([[-1.2411, -9.8162],
        [-4.2766, -1.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4421180784702301
Epoch 0, Step 2775: train/loss = 0.4579729735851288, train/raw-loss = 0.40965157747268677, train/logprobs = tensor([[-1.0713, -3.0043],
        [-2.8390, -2.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4832141101360321
Epoch 0, Step 2776: train/loss = 0.4464467763900757, train/raw-loss = 0.3910169303417206, train/logprobs = tensor([[-1.4105, -3.2171],
        [-2.7259, -1.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5542986392974854
Epoch 0, Step 2777: train/loss = 0.36467570066452026, train/raw-loss = 0.3300876021385193, train/logprobs = tensor([[-1.3929, -3.3869],
        [-3.2542, -2.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34588080644607544
Epoch 0, Step 2778: train/loss = 0.6289104223251343, train/raw-loss = 0.5871813297271729, train/logprobs = tensor([[-1.6828, -2.2358],
        [-2.3320, -1.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4172905683517456
Epoch 0, Step 2779: train/loss = 0.5588574409484863, train/raw-loss = 0.5188069939613342, train/logprobs = tensor([[-1.1895, -1.4138],
        [-2.8953, -1.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40050452947616577
Epoch 0, Step 2780: train/loss = 0.38893255591392517, train/raw-loss = 0.3499932289123535, train/logprobs = tensor([[-1.4717, -8.0033],
        [-3.7068, -1.5387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38939327001571655
Epoch 0, Step 2781: train/loss = 0.6502305865287781, train/raw-loss = 0.597793459892273, train/logprobs = tensor([[-1.0274, -2.0902],
        [-2.1832, -2.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5243710875511169
Epoch 0, Step 2782: train/loss = 0.2808739244937897, train/raw-loss = 0.23850782215595245, train/logprobs = tensor([[-1.2024, -9.9108],
        [-2.6839, -1.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4236609935760498
Epoch 0, Step 2783: train/loss = 0.3521750569343567, train/raw-loss = 0.31188130378723145, train/logprobs = tensor([[-1.4562, -3.5647],
        [-3.1521, -1.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40293750166893005
Epoch 0, Step 2784: train/loss = 0.426414430141449, train/raw-loss = 0.37367919087409973, train/logprobs = tensor([[-1.0436, -2.8249],
        [-3.0431, -2.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.527352511882782
Epoch 0, Step 2785: train/loss = 0.2420204132795334, train/raw-loss = 0.18909765779972076, train/logprobs = tensor([[-1.4872, -5.2528],
        [-3.7804, -1.4490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5292273759841919
Epoch 0, Step 2786: train/loss = 0.3017387390136719, train/raw-loss = 0.25927311182022095, train/logprobs = tensor([[-2.3844, -6.2984],
        [-4.0649, -3.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4246562421321869
Epoch 0, Step 2787: train/loss = 0.648932695388794, train/raw-loss = 0.5979037880897522, train/logprobs = tensor([[-1.1530, -1.7997],
        [-2.5600, -2.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5102896690368652
Epoch 0, Step 2788: train/loss = 0.15822571516036987, train/raw-loss = 0.1046513170003891, train/logprobs = tensor([[-1.2158, -8.0399],
        [-4.2157, -1.0579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5357439517974854
Epoch 0, Step 2789: train/loss = 0.22957761585712433, train/raw-loss = 0.18346275389194489, train/logprobs = tensor([[ -0.9016, -13.8577],
        [ -3.8029,  -1.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46114856004714966
Epoch 0, Step 2790: train/loss = 0.5497965812683105, train/raw-loss = 0.4919637441635132, train/logprobs = tensor([[-0.7343, -2.9409],
        [-2.5459, -1.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5783287882804871
Epoch 0, Step 2791: train/loss = 0.5870034694671631, train/raw-loss = 0.5327839851379395, train/logprobs = tensor([[-1.2255, -1.6198],
        [-2.6865, -1.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5421950817108154
Epoch 0, Step 2792: train/loss = 0.6597775220870972, train/raw-loss = 0.6228046417236328, train/logprobs = tensor([[-1.7066, -1.9174],
        [-2.4156, -1.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3697291910648346
Epoch 0, Step 2793: train/loss = 0.5694903135299683, train/raw-loss = 0.5220071077346802, train/logprobs = tensor([[-1.1074, -4.7766],
        [-3.0541, -2.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4748316705226898
Epoch 0, Step 2794: train/loss = 0.4686802625656128, train/raw-loss = 0.4375232458114624, train/logprobs = tensor([[ -2.6633, -12.1689],
        [ -3.4187,  -3.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115699887275696
Epoch 0, Step 2795: train/loss = 0.2531365752220154, train/raw-loss = 0.1927337944507599, train/logprobs = tensor([[-1.2750, -8.0223],
        [-4.9758, -2.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6040276885032654
Epoch 0, Step 2796: train/loss = 0.2554338872432709, train/raw-loss = 0.21081691980361938, train/logprobs = tensor([[-1.3029, -6.4022],
        [-3.3196, -1.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44616955518722534
Epoch 0, Step 2797: train/loss = 0.0901106595993042, train/raw-loss = 0.03484726697206497, train/logprobs = tensor([[ -1.2571, -11.3662],
        [ -4.6616,  -1.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5526338815689087
Epoch 0, Step 2798: train/loss = 0.32892394065856934, train/raw-loss = 0.2825825810432434, train/logprobs = tensor([[-1.8775, -5.6472],
        [-2.6733, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4634135365486145
Epoch 0, Step 2799: train/loss = 0.12396463006734848, train/raw-loss = 0.07662083208560944, train/logprobs = tensor([[-0.9105, -8.7455],
        [-3.2221, -2.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4734379053115845
Epoch 0, Step 2800: train/loss = 0.37802615761756897, train/raw-loss = 0.3163857161998749, train/logprobs = tensor([[-1.3779, -9.2140],
        [-3.7076, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6164048314094543
Epoch 0, Step 2801: train/loss = 0.43539541959762573, train/raw-loss = 0.39633914828300476, train/logprobs = tensor([[-1.1423, -2.4597],
        [-2.9849, -2.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905623257160187
Epoch 0, Step 2802: train/loss = 0.3775734007358551, train/raw-loss = 0.32238996028900146, train/logprobs = tensor([[-1.3197, -6.2834],
        [-3.5130, -2.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.551833987236023
Epoch 0, Step 2803: train/loss = 0.27035489678382874, train/raw-loss = 0.23102259635925293, train/logprobs = tensor([[-1.2253, -8.2873],
        [-3.3828, -1.8633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3933228850364685
Epoch 0, Step 2804: train/loss = 0.5033599138259888, train/raw-loss = 0.46556195616722107, train/logprobs = tensor([[-1.3907, -1.7721],
        [-2.5159, -1.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37797993421554565
Epoch 0, Step 2805: train/loss = 0.2424110621213913, train/raw-loss = 0.19806131720542908, train/logprobs = tensor([[-1.3191, -9.0484],
        [-3.0043, -2.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4434972405433655
Epoch 0, Step 2806: train/loss = 0.4478917121887207, train/raw-loss = 0.4121307134628296, train/logprobs = tensor([[-1.2768, -2.7220],
        [-2.2447, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3576098680496216
Epoch 0, Step 2807: train/loss = 0.4372650384902954, train/raw-loss = 0.39311501383781433, train/logprobs = tensor([[-1.2318, -8.2068],
        [-3.5788, -1.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44150012731552124
Epoch 0, Step 2808: train/loss = 0.3455316722393036, train/raw-loss = 0.30310413241386414, train/logprobs = tensor([[-2.3543, -8.0791],
        [-4.2596, -1.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4242756962776184
Epoch 0, Step 2809: train/loss = 0.30624857544898987, train/raw-loss = 0.25280362367630005, train/logprobs = tensor([[ -1.1158, -10.9798],
        [ -3.7489,  -3.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.53444904088974
Epoch 0, Step 2810: train/loss = 0.2739856541156769, train/raw-loss = 0.22322410345077515, train/logprobs = tensor([[-1.7922, -4.9017],
        [-4.6507, -1.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5076153874397278
Epoch 0, Step 2811: train/loss = 0.14567658305168152, train/raw-loss = 0.09137888252735138, train/logprobs = tensor([[-1.4195, -7.1334],
        [-3.9635, -2.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5429770350456238
Epoch 0, Step 2812: train/loss = 0.22484342753887177, train/raw-loss = 0.18239927291870117, train/logprobs = tensor([[-1.3798, -8.3205],
        [-3.6720, -3.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4244414269924164
Epoch 0, Step 2813: train/loss = 0.5488439202308655, train/raw-loss = 0.49332499504089355, train/logprobs = tensor([[-1.1114, -2.9091],
        [-3.1332, -1.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5551894307136536
Epoch 0, Step 2814: train/loss = 0.2040804624557495, train/raw-loss = 0.15725158154964447, train/logprobs = tensor([[-0.8244, -6.5499],
        [-3.7925, -2.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46828895807266235
Epoch 0, Step 2815: train/loss = 0.4478780925273895, train/raw-loss = 0.39586585760116577, train/logprobs = tensor([[-1.5698, -5.1294],
        [-4.2830, -2.2752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5201226472854614
Epoch 0, Step 2816: train/loss = 0.1673285812139511, train/raw-loss = 0.11864995956420898, train/logprobs = tensor([[-1.0631, -4.3713],
        [-3.5584, -1.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4867861270904541
Epoch 0, Step 2817: train/loss = 0.18504010140895844, train/raw-loss = 0.13654625415802002, train/logprobs = tensor([[ -1.1492, -10.0117],
        [ -3.8148,  -4.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48493844270706177
Epoch 0, Step 2818: train/loss = 0.23209916055202484, train/raw-loss = 0.18247517943382263, train/logprobs = tensor([[-1.2559, -6.8955],
        [-4.2252, -1.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4962400496006012
Epoch 0, Step 2819: train/loss = 0.37978339195251465, train/raw-loss = 0.3320518136024475, train/logprobs = tensor([[-1.1155, -4.7740],
        [-3.9964, -2.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47731614112854004
Epoch 0, Step 2820: train/loss = 0.510650634765625, train/raw-loss = 0.467343270778656, train/logprobs = tensor([[-1.6160, -4.2165],
        [-3.0941, -1.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43307358026504517
Epoch 0, Step 2821: train/loss = 0.7548066973686218, train/raw-loss = 0.6988555788993835, train/logprobs = tensor([[-2.5271, -7.1532],
        [-4.3494, -2.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5595111846923828
Epoch 0, Step 2822: train/loss = 0.4130237102508545, train/raw-loss = 0.35753607749938965, train/logprobs = tensor([[-1.5404, -5.9756],
        [-4.0751, -2.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5548765659332275
Epoch 0, Step 2823: train/loss = 0.5188026428222656, train/raw-loss = 0.4693041443824768, train/logprobs = tensor([[-1.2684, -7.3058],
        [-3.9129, -2.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49498462677001953
Epoch 0, Step 2824: train/loss = 0.6060760617256165, train/raw-loss = 0.571320116519928, train/logprobs = tensor([[-1.9312, -2.5729],
        [-2.3551, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3475593030452728
Epoch 0, Step 2825: train/loss = 0.3439001142978668, train/raw-loss = 0.29502880573272705, train/logprobs = tensor([[-1.2298, -6.7383],
        [-3.8026, -2.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4887129068374634
Epoch 0, Step 2826: train/loss = 0.25459808111190796, train/raw-loss = 0.20522268116474152, train/logprobs = tensor([[-0.8673, -5.2515],
        [-3.1248, -0.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49375414848327637
Epoch 0, Step 2827: train/loss = 0.3190619945526123, train/raw-loss = 0.2644239068031311, train/logprobs = tensor([[-0.9538, -5.2291],
        [-2.4060, -2.3863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5463809967041016
Epoch 0, Step 2828: train/loss = 0.2665170133113861, train/raw-loss = 0.2267771065235138, train/logprobs = tensor([[-1.7209, -5.4558],
        [-2.7874, -2.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3973991572856903
Epoch 0, Step 2829: train/loss = 0.3386111259460449, train/raw-loss = 0.28383833169937134, train/logprobs = tensor([[-1.3471, -5.6484],
        [-3.3828, -1.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.547728419303894
Epoch 0, Step 2830: train/loss = 0.41006073355674744, train/raw-loss = 0.3631576597690582, train/logprobs = tensor([[-0.7845, -5.5412],
        [-2.7145, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4690307378768921
Epoch 0, Step 2831: train/loss = 0.5247011184692383, train/raw-loss = 0.4806367754936218, train/logprobs = tensor([[-0.8118, -3.6681],
        [-2.1651, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4406433701515198
Epoch 0, Step 2832: train/loss = 0.13977476954460144, train/raw-loss = 0.10009942948818207, train/logprobs = tensor([[ -1.6014, -10.0580],
        [ -3.2198,  -1.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3967532813549042
Epoch 0, Step 2833: train/loss = 0.6861974596977234, train/raw-loss = 0.6434749960899353, train/logprobs = tensor([[-2.3371, -4.4804],
        [-3.1261, -1.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4272242784500122
Epoch 0, Step 2834: train/loss = 0.4131336510181427, train/raw-loss = 0.36672520637512207, train/logprobs = tensor([[-1.4824, -8.5384],
        [-2.9188, -2.1429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640844762325287
Epoch 0, Step 2835: train/loss = 0.2712491750717163, train/raw-loss = 0.22727200388908386, train/logprobs = tensor([[-1.9460, -6.6423],
        [-4.5932, -3.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.439771443605423
Epoch 0, Step 2836: train/loss = 0.7318646907806396, train/raw-loss = 0.6956509351730347, train/logprobs = tensor([[-3.0607, -7.1202],
        [-2.2311, -2.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36213764548301697
Epoch 0, Step 2837: train/loss = 0.2249176949262619, train/raw-loss = 0.17145925760269165, train/logprobs = tensor([[-1.5124, -7.3152],
        [-4.1166, -2.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5345843434333801
Epoch 0, Step 2838: train/loss = 0.39908653497695923, train/raw-loss = 0.34197962284088135, train/logprobs = tensor([[ -1.8166, -11.7889],
        [ -4.3498,  -2.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.571069061756134
Epoch 0, Step 2839: train/loss = 0.3155704140663147, train/raw-loss = 0.27121755480766296, train/logprobs = tensor([[-2.0262, -6.9218],
        [-3.5401, -1.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44352880120277405
Epoch 0, Step 2840: train/loss = 0.17233489453792572, train/raw-loss = 0.12779740989208221, train/logprobs = tensor([[-1.4616, -9.2044],
        [-4.0180, -1.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4453749358654022
Epoch 0, Step 2841: train/loss = 0.25431233644485474, train/raw-loss = 0.21155038475990295, train/logprobs = tensor([[-1.4363, -4.8820],
        [-3.6729, -1.3327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42761939764022827
Epoch 0, Step 2842: train/loss = 0.4601832628250122, train/raw-loss = 0.40687984228134155, train/logprobs = tensor([[-1.5328, -6.8877],
        [-4.0030, -1.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5330345630645752
Epoch 0, Step 2843: train/loss = 0.3590492606163025, train/raw-loss = 0.3221282958984375, train/logprobs = tensor([[-1.2586, -6.1934],
        [-3.9804, -1.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692091107368469
Epoch 0, Step 2844: train/loss = 0.2360987812280655, train/raw-loss = 0.18795764446258545, train/logprobs = tensor([[-0.9289, -3.3756],
        [-3.4119, -1.9349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4814113974571228
Epoch 0, Step 2845: train/loss = 0.31659823656082153, train/raw-loss = 0.26555654406547546, train/logprobs = tensor([[-1.3256, -6.6714],
        [-4.7836, -2.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5104169845581055
Epoch 0, Step 2846: train/loss = 0.2984073758125305, train/raw-loss = 0.2572060823440552, train/logprobs = tensor([[-1.5141, -5.7275],
        [-4.2208, -1.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41201263666152954
Epoch 0, Step 2847: train/loss = 0.2977285087108612, train/raw-loss = 0.24773862957954407, train/logprobs = tensor([[-1.2708, -5.2286],
        [-4.7583, -2.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4998990297317505
Epoch 0, Step 2848: train/loss = 0.32134729623794556, train/raw-loss = 0.2763412892818451, train/logprobs = tensor([[-1.6480, -5.5394],
        [-2.9258, -1.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4500599801540375
Epoch 0, Step 2849: train/loss = 0.28892841935157776, train/raw-loss = 0.24293547868728638, train/logprobs = tensor([[-1.2182, -5.4091],
        [-2.5650, -1.7297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45992937684059143
Epoch 0, Step 2850: train/loss = 0.2708684802055359, train/raw-loss = 0.23030506074428558, train/logprobs = tensor([[-1.4564, -8.0852],
        [-3.5844, -1.8198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4056341350078583
Epoch 0, Step 2851: train/loss = 0.22034397721290588, train/raw-loss = 0.17862427234649658, train/logprobs = tensor([[-0.9482, -4.3904],
        [-2.9934, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41719719767570496
Epoch 0, Step 2852: train/loss = 0.39666545391082764, train/raw-loss = 0.3477725386619568, train/logprobs = tensor([[-1.7639, -7.4051],
        [-3.1004, -2.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48892951011657715
Epoch 0, Step 2853: train/loss = 0.3462978005409241, train/raw-loss = 0.30689090490341187, train/logprobs = tensor([[-1.2809, -3.6269],
        [-2.9125, -1.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3940688371658325
Epoch 0, Step 2854: train/loss = 0.219150111079216, train/raw-loss = 0.1685621291399002, train/logprobs = tensor([[-1.3395, -9.9055],
        [-4.2570, -2.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5058798789978027
Epoch 0, Step 2855: train/loss = 0.5462126135826111, train/raw-loss = 0.49387380480766296, train/logprobs = tensor([[-2.7603, -7.4809],
        [-2.4837, -2.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5233880281448364
Epoch 0, Step 2856: train/loss = 0.38412702083587646, train/raw-loss = 0.3438299298286438, train/logprobs = tensor([[-1.6557, -5.8364],
        [-2.2954, -1.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40297117829322815
Epoch 0, Step 2857: train/loss = 0.25198790431022644, train/raw-loss = 0.21272647380828857, train/logprobs = tensor([[-1.1794, -8.1827],
        [-1.8665, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39261433482170105
Epoch 0, Step 2858: train/loss = 0.39774957299232483, train/raw-loss = 0.35352465510368347, train/logprobs = tensor([[-1.9208, -9.6550],
        [-3.5356, -2.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44224902987480164
Epoch 0, Step 2859: train/loss = 0.5700597763061523, train/raw-loss = 0.5334494709968567, train/logprobs = tensor([[-1.3940, -2.3933],
        [-2.1432, -1.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661031126976013
Epoch 0, Step 2860: train/loss = 0.24261155724525452, train/raw-loss = 0.19513462483882904, train/logprobs = tensor([[ -1.6864, -11.4302],
        [ -3.1311,  -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47476938366889954
Epoch 0, Step 2861: train/loss = 0.38013479113578796, train/raw-loss = 0.33312490582466125, train/logprobs = tensor([[ -2.0155, -10.4461],
        [ -3.8124,  -2.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4700990319252014
Epoch 0, Step 2862: train/loss = 0.25058871507644653, train/raw-loss = 0.20346659421920776, train/logprobs = tensor([[-1.8766, -6.6154],
        [-4.2932, -1.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4712214767932892
Epoch 0, Step 2863: train/loss = 0.4596630334854126, train/raw-loss = 0.4174627661705017, train/logprobs = tensor([[-0.8580, -2.6578],
        [-2.7350, -1.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4220028221607208
Epoch 0, Step 2864: train/loss = 0.17478185892105103, train/raw-loss = 0.13586077094078064, train/logprobs = tensor([[ -1.2807, -14.5283],
        [ -3.7900,  -4.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38921090960502625
Epoch 0, Step 2865: train/loss = 0.3629333972930908, train/raw-loss = 0.3237345516681671, train/logprobs = tensor([[ -1.4451, -10.6555],
        [ -3.3831,  -2.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919885754585266
Epoch 0, Step 2866: train/loss = 0.520518958568573, train/raw-loss = 0.4860150218009949, train/logprobs = tensor([[-1.4192, -4.6356],
        [-2.4697, -1.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3450395464897156
Epoch 0, Step 2867: train/loss = 0.556337833404541, train/raw-loss = 0.5186395049095154, train/logprobs = tensor([[-1.3761, -8.8336],
        [-1.7927, -2.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37698331475257874
Epoch 0, Step 2868: train/loss = 0.13247165083885193, train/raw-loss = 0.08194014430046082, train/logprobs = tensor([[ -1.9685, -12.6039],
        [ -4.2594,  -3.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5053150653839111
Epoch 0, Step 2869: train/loss = 0.35161665081977844, train/raw-loss = 0.3090169131755829, train/logprobs = tensor([[ -1.8868, -10.3581],
        [ -3.8651,  -4.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4259970188140869
Epoch 0, Step 2870: train/loss = 0.6394312977790833, train/raw-loss = 0.5967506766319275, train/logprobs = tensor([[-3.2335, -9.5684],
        [-2.9159, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42680594325065613
Epoch 0, Step 2871: train/loss = 0.10457384586334229, train/raw-loss = 0.05851157009601593, train/logprobs = tensor([[-1.5676, -9.4255],
        [-4.8487, -2.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46062272787094116
Epoch 0, Step 2872: train/loss = 0.5159387588500977, train/raw-loss = 0.47040921449661255, train/logprobs = tensor([[-2.0286, -7.1620],
        [-2.8499, -2.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4552956521511078
Epoch 0, Step 2873: train/loss = 0.39286428689956665, train/raw-loss = 0.359680712223053, train/logprobs = tensor([[-2.0407, -5.3054],
        [-3.0052, -0.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33183541893959045
Epoch 0, Step 2874: train/loss = 0.3191024661064148, train/raw-loss = 0.266729474067688, train/logprobs = tensor([[ -1.5147, -10.0147],
        [ -3.0319,  -1.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5237302780151367
Epoch 0, Step 2875: train/loss = 0.20314881205558777, train/raw-loss = 0.159678116440773, train/logprobs = tensor([[-1.1154, -8.0160],
        [-3.6822, -1.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4347068965435028
Epoch 0, Step 2876: train/loss = 0.46161016821861267, train/raw-loss = 0.426149845123291, train/logprobs = tensor([[-1.2312, -2.8714],
        [-2.2405, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35460320115089417
Epoch 0, Step 2877: train/loss = 0.5642080307006836, train/raw-loss = 0.5291053652763367, train/logprobs = tensor([[-1.2639, -2.6491],
        [-1.7193, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3510266840457916
Epoch 0, Step 2878: train/loss = 0.7405691146850586, train/raw-loss = 0.6897737979888916, train/logprobs = tensor([[-1.4538, -1.7191],
        [-2.8252, -2.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.507952868938446
Epoch 0, Step 2879: train/loss = 0.12730321288108826, train/raw-loss = 0.08696260303258896, train/logprobs = tensor([[-1.3396, -9.6251],
        [-4.3163, -2.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40340617299079895
Epoch 0, Step 2880: train/loss = 0.25947630405426025, train/raw-loss = 0.21227291226387024, train/logprobs = tensor([[-1.6239, -3.6449],
        [-3.3961, -1.3963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47203388810157776
Epoch 0, Step 2881: train/loss = 0.07343114167451859, train/raw-loss = 0.03975905478000641, train/logprobs = tensor([[-1.6581, -9.4707],
        [-4.8294, -0.8274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33672085404396057
Epoch 0, Step 2882: train/loss = 0.23518148064613342, train/raw-loss = 0.18720939755439758, train/logprobs = tensor([[-1.8973, -5.5297],
        [-4.2147, -2.1347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4797210693359375
Epoch 0, Step 2883: train/loss = 0.1844334900379181, train/raw-loss = 0.14261430501937866, train/logprobs = tensor([[ -0.7842, -10.9803],
        [ -3.3418,  -1.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4181920289993286
Epoch 0, Step 2884: train/loss = 0.07864591479301453, train/raw-loss = 0.02990015596151352, train/logprobs = tensor([[ -1.1821, -11.3952],
        [ -4.2278,  -1.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4874575734138489
Epoch 0, Step 2885: train/loss = 0.4683082699775696, train/raw-loss = 0.4343220889568329, train/logprobs = tensor([[-1.7228, -4.0032],
        [-1.9707, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33986198902130127
Epoch 0, Step 2886: train/loss = 0.3811996579170227, train/raw-loss = 0.3400745093822479, train/logprobs = tensor([[-1.0455, -5.7966],
        [-2.6794, -1.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112516939640045
Epoch 0, Step 2887: train/loss = 0.23948173224925995, train/raw-loss = 0.1915718913078308, train/logprobs = tensor([[-1.7320, -6.8705],
        [-5.1190, -1.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47909843921661377
Epoch 0, Step 2888: train/loss = 0.1868487298488617, train/raw-loss = 0.15877526998519897, train/logprobs = tensor([[ -1.6136, -11.6676],
        [ -2.6233,  -2.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807345390319824
Epoch 0, Step 2889: train/loss = 0.2322165071964264, train/raw-loss = 0.189210444688797, train/logprobs = tensor([[-1.3548, -7.7844],
        [-2.7442, -2.3823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43006056547164917
Epoch 0, Step 2890: train/loss = 0.40271297097206116, train/raw-loss = 0.36116576194763184, train/logprobs = tensor([[-1.3272, -6.5114],
        [-2.5375, -1.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41547197103500366
Epoch 0, Step 2891: train/loss = 0.5178154706954956, train/raw-loss = 0.46676385402679443, train/logprobs = tensor([[-2.0246, -6.1493],
        [-3.0799, -2.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5105165243148804
Epoch 0, Step 2892: train/loss = 0.23785552382469177, train/raw-loss = 0.19145467877388, train/logprobs = tensor([[-1.4043, -8.4191],
        [-4.1142, -2.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640084505081177
Epoch 0, Step 2893: train/loss = 0.31694546341896057, train/raw-loss = 0.27724066376686096, train/logprobs = tensor([[-1.7301, -9.0321],
        [-3.4586, -2.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3970479965209961
Epoch 0, Step 2894: train/loss = 0.35289424657821655, train/raw-loss = 0.31184446811676025, train/logprobs = tensor([[-2.1157, -4.6634],
        [-3.5736, -2.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41049787402153015
Epoch 0, Step 2895: train/loss = 0.3627297878265381, train/raw-loss = 0.31432080268859863, train/logprobs = tensor([[-1.3145, -5.1010],
        [-3.5589, -1.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4840901494026184
Epoch 0, Step 2896: train/loss = 0.5422656536102295, train/raw-loss = 0.48224833607673645, train/logprobs = tensor([[-1.8271, -2.6335],
        [-3.1578, -2.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6001735329627991
Epoch 0, Step 2897: train/loss = 0.14485719799995422, train/raw-loss = 0.10451093316078186, train/logprobs = tensor([[ -1.9433, -10.4672],
        [ -4.0231,  -2.6891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40346255898475647
Epoch 0, Step 2898: train/loss = 0.2754751741886139, train/raw-loss = 0.2246839702129364, train/logprobs = tensor([[-1.6256, -9.2424],
        [-3.3139, -3.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.507912278175354
Epoch 0, Step 2899: train/loss = 0.12299734354019165, train/raw-loss = 0.07619509845972061, train/logprobs = tensor([[ -1.8425, -14.8493],
        [ -3.9651,  -3.3590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4680224657058716
Epoch 0, Step 2900: train/loss = 0.34222662448883057, train/raw-loss = 0.30838629603385925, train/logprobs = tensor([[-1.2242, -4.4926],
        [-2.2621, -1.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3384034037590027
Epoch 0, Step 2901: train/loss = 0.21990960836410522, train/raw-loss = 0.17655590176582336, train/logprobs = tensor([[ -1.6703, -14.9509],
        [ -4.2742,  -1.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43353694677352905
Epoch 0, Step 2902: train/loss = 0.26169151067733765, train/raw-loss = 0.21178776025772095, train/logprobs = tensor([[-1.4642, -6.7529],
        [-3.9138, -2.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4990372657775879
Epoch 0, Step 2903: train/loss = 0.42707788944244385, train/raw-loss = 0.37852901220321655, train/logprobs = tensor([[-2.6303, -6.1450],
        [-3.9670, -2.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4854891002178192
Epoch 0, Step 2904: train/loss = 0.3744378089904785, train/raw-loss = 0.3351939022541046, train/logprobs = tensor([[-1.7043, -7.3932],
        [-2.6761, -1.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924388885498047
Epoch 0, Step 2905: train/loss = 0.5715832710266113, train/raw-loss = 0.5281439423561096, train/logprobs = tensor([[-2.0527, -2.4517],
        [-2.1111, -1.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43439334630966187
Epoch 0, Step 2906: train/loss = 0.1403593271970749, train/raw-loss = 0.09161891043186188, train/logprobs = tensor([[-1.1858, -7.6439],
        [-4.1492, -1.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48740410804748535
Epoch 0, Step 2907: train/loss = 0.4725136160850525, train/raw-loss = 0.43737277388572693, train/logprobs = tensor([[-1.4347, -6.7823],
        [-2.2911, -2.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35140854120254517
Epoch 0, Step 2908: train/loss = 0.2902974784374237, train/raw-loss = 0.24404276907444, train/logprobs = tensor([[ -1.6770, -11.0597],
        [ -3.1260,  -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4625472128391266
Epoch 0, Step 2909: train/loss = 0.5000192523002625, train/raw-loss = 0.45838937163352966, train/logprobs = tensor([[-1.1262, -2.6988],
        [-2.9773, -1.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4162992537021637
Epoch 0, Step 2910: train/loss = 0.7640756368637085, train/raw-loss = 0.7087498903274536, train/logprobs = tensor([[-1.3697, -4.3750],
        [-3.9322, -2.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5532576441764832
Epoch 0, Step 2911: train/loss = 0.3531644344329834, train/raw-loss = 0.3188655972480774, train/logprobs = tensor([[-1.3205, -5.0316],
        [-2.5298, -1.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429882228374481
Epoch 0, Step 2912: train/loss = 0.2464953064918518, train/raw-loss = 0.20100514590740204, train/logprobs = tensor([[-2.3397, -6.7414],
        [-3.9143, -2.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4549015462398529
Epoch 0, Step 2913: train/loss = 0.48684045672416687, train/raw-loss = 0.4402632713317871, train/logprobs = tensor([[-1.4725, -5.2684],
        [-2.0912, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4657721221446991
Epoch 0, Step 2914: train/loss = 0.23086851835250854, train/raw-loss = 0.1857852041721344, train/logprobs = tensor([[-1.1074, -8.7674],
        [-2.8666, -2.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45083311200141907
Epoch 0, Step 2915: train/loss = 0.22036489844322205, train/raw-loss = 0.17846807837486267, train/logprobs = tensor([[-1.3878, -6.0489],
        [-3.4355, -1.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4189682602882385
Epoch 0, Step 2916: train/loss = 0.23674552142620087, train/raw-loss = 0.1854414939880371, train/logprobs = tensor([[-1.2831, -6.7187],
        [-3.7167, -2.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5130401849746704
Epoch 0, Step 2917: train/loss = 0.4150543510913849, train/raw-loss = 0.3742763102054596, train/logprobs = tensor([[-1.9424, -4.4852],
        [-3.7272, -2.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40778040885925293
Epoch 0, Step 2918: train/loss = 0.5612664818763733, train/raw-loss = 0.5127310752868652, train/logprobs = tensor([[-1.2322, -3.1169],
        [-2.8472, -1.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4853541851043701
Epoch 0, Step 2919: train/loss = 0.48959749937057495, train/raw-loss = 0.45477595925331116, train/logprobs = tensor([[-1.5041, -3.6835],
        [-1.9963, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3482152223587036
Epoch 0, Step 2920: train/loss = 0.2603190541267395, train/raw-loss = 0.21881350874900818, train/logprobs = tensor([[-1.1039, -4.1900],
        [-3.0627, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41505539417266846
Epoch 0, Step 2921: train/loss = 0.620903491973877, train/raw-loss = 0.5688483119010925, train/logprobs = tensor([[-1.2579, -1.9310],
        [-1.9298, -1.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5205522179603577
Epoch 0, Step 2922: train/loss = 0.5547066926956177, train/raw-loss = 0.517435610294342, train/logprobs = tensor([[-1.8186, -3.5014],
        [-1.9204, -1.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727107346057892
Epoch 0, Step 2923: train/loss = 0.11033148318529129, train/raw-loss = 0.05558700114488602, train/logprobs = tensor([[ -1.6853, -10.2991],
        [ -3.8617,  -2.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5474448204040527
Epoch 0, Step 2924: train/loss = 0.17462614178657532, train/raw-loss = 0.11927831918001175, train/logprobs = tensor([[ -1.6657, -14.4449],
        [ -4.2989,  -4.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5534782409667969
Epoch 0, Step 2925: train/loss = 0.16645291447639465, train/raw-loss = 0.10584164410829544, train/logprobs = tensor([[-2.1111, -7.6217],
        [-5.5520, -1.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6061127185821533
Epoch 0, Step 2926: train/loss = 1.4957373142242432, train/raw-loss = 1.4622085094451904, train/logprobs = tensor([[ -6.9013, -12.6855],
        [ -2.2907,  -1.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33528733253479004
Epoch 0, Step 2927: train/loss = 0.33412569761276245, train/raw-loss = 0.2964380979537964, train/logprobs = tensor([[ -1.0437, -13.1688],
        [ -4.5128,  -4.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37687602639198303
Epoch 0, Step 2928: train/loss = 0.5584750771522522, train/raw-loss = 0.5198818445205688, train/logprobs = tensor([[-1.6395, -2.1884],
        [-2.5841, -1.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38593238592147827
Epoch 0, Step 2929: train/loss = 0.34850913286209106, train/raw-loss = 0.3103024959564209, train/logprobs = tensor([[-2.3684, -7.1043],
        [-3.1552, -1.5031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820662796497345
Epoch 0, Step 2930: train/loss = 0.4910504221916199, train/raw-loss = 0.4502717852592468, train/logprobs = tensor([[ -3.4044, -11.0836],
        [ -3.8838,  -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40778619050979614
Epoch 0, Step 2931: train/loss = 0.38182878494262695, train/raw-loss = 0.32960307598114014, train/logprobs = tensor([[-1.4884, -7.3331],
        [-3.7330, -2.3210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5222567915916443
Epoch 0, Step 2932: train/loss = 0.418925940990448, train/raw-loss = 0.36953017115592957, train/logprobs = tensor([[-1.1246, -3.6632],
        [-2.1621, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49395740032196045
Epoch 0, Step 2933: train/loss = 0.2439882904291153, train/raw-loss = 0.20399563014507294, train/logprobs = tensor([[ -1.3847, -12.9001],
        [ -3.3505,  -2.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3999265730381012
Epoch 0, Step 2934: train/loss = 0.39102908968925476, train/raw-loss = 0.3401487469673157, train/logprobs = tensor([[-1.1863, -2.6387],
        [-3.4694, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5088035464286804
Epoch 0, Step 2935: train/loss = 0.5196148157119751, train/raw-loss = 0.47868746519088745, train/logprobs = tensor([[-1.6853, -3.6252],
        [-2.4839, -1.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40927380323410034
Epoch 0, Step 2936: train/loss = 0.20585696399211884, train/raw-loss = 0.16060952842235565, train/logprobs = tensor([[ -2.1775, -13.9419],
        [ -4.5965,  -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524743854999542
Epoch 0, Step 2937: train/loss = 0.20656192302703857, train/raw-loss = 0.15758255124092102, train/logprobs = tensor([[-1.0892, -6.2438],
        [-3.0083, -1.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4897938072681427
Epoch 0, Step 2938: train/loss = 0.16104179620742798, train/raw-loss = 0.12179328501224518, train/logprobs = tensor([[-1.7502, -6.5790],
        [-3.7923, -1.3170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924850821495056
Epoch 0, Step 2939: train/loss = 0.3546295762062073, train/raw-loss = 0.30938395857810974, train/logprobs = tensor([[-1.4235, -4.5984],
        [-3.6457, -1.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4524557888507843
Epoch 0, Step 2940: train/loss = 0.35557860136032104, train/raw-loss = 0.2937515377998352, train/logprobs = tensor([[-1.1779, -3.2980],
        [-4.4590, -2.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6182706356048584
Epoch 0, Step 2941: train/loss = 0.43574610352516174, train/raw-loss = 0.39913201332092285, train/logprobs = tensor([[-1.6608, -3.8218],
        [-2.2727, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36614111065864563
Epoch 0, Step 2942: train/loss = 0.1210508868098259, train/raw-loss = 0.0716155394911766, train/logprobs = tensor([[-1.2060, -6.6788],
        [-3.6654, -2.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49435341358184814
Epoch 0, Step 2943: train/loss = 0.6577062010765076, train/raw-loss = 0.6190036535263062, train/logprobs = tensor([[ -3.5076, -10.4381],
        [ -2.9478,  -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38702502846717834
Epoch 0, Step 2944: train/loss = 0.5248474478721619, train/raw-loss = 0.4904717206954956, train/logprobs = tensor([[-2.2429, -3.9385],
        [-2.2600, -1.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437570631504059
Epoch 0, Step 2945: train/loss = 0.12025536596775055, train/raw-loss = 0.06827734410762787, train/logprobs = tensor([[-0.7859, -6.7476],
        [-3.9340, -1.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.519780158996582
Epoch 0, Step 2946: train/loss = 0.31686490774154663, train/raw-loss = 0.2814662754535675, train/logprobs = tensor([[-1.4162, -9.0039],
        [-2.1507, -2.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35398608446121216
Epoch 0, Step 2947: train/loss = 0.3362998366355896, train/raw-loss = 0.28461429476737976, train/logprobs = tensor([[-0.9918, -8.4851],
        [-3.3717, -3.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5168553590774536
Epoch 0, Step 2948: train/loss = 0.2575424015522003, train/raw-loss = 0.21189910173416138, train/logprobs = tensor([[-1.3274, -6.2982],
        [-3.0155, -2.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45643314719200134
Epoch 0, Step 2949: train/loss = 0.2840331494808197, train/raw-loss = 0.2541542649269104, train/logprobs = tensor([[-1.2145, -5.7149],
        [-1.9612, -1.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987890839576721
Epoch 0, Step 2950: train/loss = 0.2622528374195099, train/raw-loss = 0.2206207811832428, train/logprobs = tensor([[-1.4279, -5.6884],
        [-4.0557, -2.4919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4163208603858948
Epoch 0, Step 2951: train/loss = 0.5160366296768188, train/raw-loss = 0.4738166928291321, train/logprobs = tensor([[ -2.9886, -10.1472],
        [ -3.6529,  -2.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.422199547290802
Epoch 0, Step 2952: train/loss = 0.20213018357753754, train/raw-loss = 0.15585820376873016, train/logprobs = tensor([[ -1.6956, -11.4747],
        [ -3.2350,  -3.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46271973848342896
Epoch 0, Step 2953: train/loss = 0.18529559671878815, train/raw-loss = 0.1461818516254425, train/logprobs = tensor([[-1.2405, -6.8101],
        [-3.6943, -1.5145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39113742113113403
Epoch 0, Step 2954: train/loss = 0.6410263180732727, train/raw-loss = 0.6090619564056396, train/logprobs = tensor([[-1.8002, -3.9004],
        [-1.4552, -1.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3196435868740082
Epoch 0, Step 2955: train/loss = 0.1625927984714508, train/raw-loss = 0.12448781728744507, train/logprobs = tensor([[-1.3621, -9.1149],
        [-3.8886, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38104966282844543
Epoch 0, Step 2956: train/loss = 0.47164249420166016, train/raw-loss = 0.4188367426395416, train/logprobs = tensor([[-1.6140, -5.1470],
        [-4.4948, -2.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5280575156211853
Epoch 0, Step 2957: train/loss = 0.33976438641548157, train/raw-loss = 0.2966790497303009, train/logprobs = tensor([[-1.9055, -7.4483],
        [-3.1365, -2.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43085330724716187
Epoch 0, Step 2958: train/loss = 0.246791273355484, train/raw-loss = 0.20596882700920105, train/logprobs = tensor([[-1.4942, -7.9336],
        [-3.3332, -1.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4082244634628296
Epoch 0, Step 2959: train/loss = 0.4768471121788025, train/raw-loss = 0.434304416179657, train/logprobs = tensor([[-1.1011, -3.6486],
        [-3.1361, -1.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254266619682312
Epoch 0, Step 2960: train/loss = 0.31045809388160706, train/raw-loss = 0.27665889263153076, train/logprobs = tensor([[-1.4635, -2.9025],
        [-3.4211, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33799225091934204
Epoch 0, Step 2961: train/loss = 0.5139098167419434, train/raw-loss = 0.46589869260787964, train/logprobs = tensor([[-1.1541, -4.0420],
        [-2.8770, -1.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.480111300945282
Epoch 0, Step 2962: train/loss = 0.1554841548204422, train/raw-loss = 0.11796697974205017, train/logprobs = tensor([[-1.4929, -7.7407],
        [-2.8965, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751716613769531
Epoch 0, Step 2963: train/loss = 0.4597916603088379, train/raw-loss = 0.4237884283065796, train/logprobs = tensor([[-1.6130, -7.2161],
        [-3.1986, -2.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3600327968597412
Epoch 0, Step 2964: train/loss = 0.5835695266723633, train/raw-loss = 0.543160080909729, train/logprobs = tensor([[-1.6837, -6.7486],
        [-2.3952, -3.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4040944576263428
Epoch 0, Step 2965: train/loss = 0.3472481966018677, train/raw-loss = 0.31822407245635986, train/logprobs = tensor([[-0.6203, -6.0211],
        [-1.2842, -1.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902410328388214
Epoch 0, Step 2966: train/loss = 0.5230527520179749, train/raw-loss = 0.46604636311531067, train/logprobs = tensor([[-1.9738, -3.6155],
        [-3.4142, -2.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5700641870498657
Epoch 0, Step 2967: train/loss = 0.5723408460617065, train/raw-loss = 0.5378464460372925, train/logprobs = tensor([[-1.4645, -3.9651],
        [-2.1211, -1.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3449447751045227
Epoch 0, Step 2968: train/loss = 0.42322584986686707, train/raw-loss = 0.38705456256866455, train/logprobs = tensor([[-2.1009, -4.1379],
        [-2.6281, -1.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36171260476112366
Epoch 0, Step 2969: train/loss = 0.22038394212722778, train/raw-loss = 0.1825745403766632, train/logprobs = tensor([[-1.7921, -6.0367],
        [-2.8185, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37809374928474426
Epoch 0, Step 2970: train/loss = 0.7988190054893494, train/raw-loss = 0.7506545186042786, train/logprobs = tensor([[-2.9309, -7.9761],
        [-2.7597, -1.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4816451668739319
Epoch 0, Step 2971: train/loss = 0.11171480268239975, train/raw-loss = 0.0667470246553421, train/logprobs = tensor([[-1.4931, -7.3855],
        [-3.9392, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4496777355670929
Epoch 0, Step 2972: train/loss = 0.27265363931655884, train/raw-loss = 0.2351863980293274, train/logprobs = tensor([[-1.1874, -6.0577],
        [-2.6148, -1.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37467217445373535
Epoch 0, Step 2973: train/loss = 0.2502201795578003, train/raw-loss = 0.206592857837677, train/logprobs = tensor([[-1.3324, -5.7330],
        [-3.4843, -2.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4362730383872986
Epoch 0, Step 2974: train/loss = 0.643663763999939, train/raw-loss = 0.5977561473846436, train/logprobs = tensor([[-1.7121, -2.0620],
        [-2.6051, -1.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45907604694366455
Epoch 0, Step 2975: train/loss = 0.2536187469959259, train/raw-loss = 0.20769301056861877, train/logprobs = tensor([[-1.0673, -8.5606],
        [-3.2809, -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4592573344707489
Epoch 0, Step 2976: train/loss = 0.3249691128730774, train/raw-loss = 0.28782960772514343, train/logprobs = tensor([[-1.5450, -4.7731],
        [-3.0605, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37139466404914856
Epoch 0, Step 2977: train/loss = 0.2295766919851303, train/raw-loss = 0.18014781177043915, train/logprobs = tensor([[ -1.1828, -13.2683],
        [ -4.0847,  -4.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49428895115852356
Epoch 0, Step 2978: train/loss = 0.42939597368240356, train/raw-loss = 0.38510704040527344, train/logprobs = tensor([[-1.7160, -2.8837],
        [-3.7460, -1.9063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44288939237594604
Epoch 0, Step 2979: train/loss = 0.5896839499473572, train/raw-loss = 0.5450603365898132, train/logprobs = tensor([[-1.4886, -2.1546],
        [-1.8558, -1.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44623610377311707
Epoch 0, Step 2980: train/loss = 0.5444134473800659, train/raw-loss = 0.5148488879203796, train/logprobs = tensor([[-1.6360, -7.0480],
        [-2.6073, -2.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956460118293762
Epoch 0, Step 2981: train/loss = 0.460558146238327, train/raw-loss = 0.4231337308883667, train/logprobs = tensor([[-1.4470, -5.2967],
        [-1.9153, -2.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3742443323135376
Epoch 0, Step 2982: train/loss = 0.41758573055267334, train/raw-loss = 0.3735623359680176, train/logprobs = tensor([[ -1.3243, -11.5693],
        [ -2.7480,  -1.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44023388624191284
Epoch 0, Step 2983: train/loss = 0.23625631630420685, train/raw-loss = 0.19328898191452026, train/logprobs = tensor([[-1.1245, -3.5872],
        [-2.7427, -1.5846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42967358231544495
Epoch 0, Step 2984: train/loss = 0.43063175678253174, train/raw-loss = 0.39495009183883667, train/logprobs = tensor([[-1.4762, -5.1307],
        [-3.2616, -1.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35681650042533875
Epoch 0, Step 2985: train/loss = 0.26421889662742615, train/raw-loss = 0.21629469096660614, train/logprobs = tensor([[-1.1534, -8.4731],
        [-2.5030, -2.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47924190759658813
Epoch 0, Step 2986: train/loss = 0.38635948300361633, train/raw-loss = 0.3492811322212219, train/logprobs = tensor([[-2.2416, -6.5635],
        [-2.9400, -2.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3707835078239441
Epoch 0, Step 2987: train/loss = 0.3543965220451355, train/raw-loss = 0.31567174196243286, train/logprobs = tensor([[-1.3769, -5.9831],
        [-2.8234, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38724786043167114
Epoch 0, Step 2988: train/loss = 0.24183233082294464, train/raw-loss = 0.20024387538433075, train/logprobs = tensor([[-1.5267, -8.1832],
        [-3.4110, -1.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158846139907837
Epoch 0, Step 2989: train/loss = 0.6312044262886047, train/raw-loss = 0.5852575302124023, train/logprobs = tensor([[-1.3468, -1.8856],
        [-3.5535, -2.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4594690501689911
Epoch 0, Step 2990: train/loss = 0.3808315396308899, train/raw-loss = 0.3383488953113556, train/logprobs = tensor([[-1.2472, -7.5353],
        [-2.9299, -3.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.424826443195343
Epoch 0, Step 2991: train/loss = 0.5464460849761963, train/raw-loss = 0.5024722814559937, train/logprobs = tensor([[-0.8511, -1.9583],
        [-2.0245, -1.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.439738392829895
Epoch 0, Step 2992: train/loss = 0.11415800452232361, train/raw-loss = 0.06610827147960663, train/logprobs = tensor([[-1.5984, -6.9654],
        [-4.5469, -1.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4804973602294922
Epoch 0, Step 2993: train/loss = 0.24485424160957336, train/raw-loss = 0.19163429737091064, train/logprobs = tensor([[-1.1037, -6.3661],
        [-3.4371, -1.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5321992039680481
Epoch 0, Step 2994: train/loss = 0.576928973197937, train/raw-loss = 0.5294033288955688, train/logprobs = tensor([[-1.6323, -3.5964],
        [-2.8765, -2.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47525614500045776
Epoch 0, Step 2995: train/loss = 0.27571114897727966, train/raw-loss = 0.24045731127262115, train/logprobs = tensor([[-1.9858, -6.4746],
        [-3.7962, -1.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525383472442627
Epoch 0, Step 2996: train/loss = 0.5714738965034485, train/raw-loss = 0.5357689261436462, train/logprobs = tensor([[-1.2918, -1.9418],
        [-1.8245, -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35704973340034485
Epoch 0, Step 2997: train/loss = 0.42880943417549133, train/raw-loss = 0.3805028796195984, train/logprobs = tensor([[-0.8687, -4.3844],
        [-2.6022, -1.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4830654561519623
Epoch 0, Step 2998: train/loss = 0.2335490882396698, train/raw-loss = 0.18636412918567657, train/logprobs = tensor([[-1.6039, -6.9763],
        [-3.4551, -1.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47184979915618896
Epoch 0, Step 2999: train/loss = 0.16526859998703003, train/raw-loss = 0.13209448754787445, train/logprobs = tensor([[-1.4367, -9.0503],
        [-3.0065, -2.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3317411541938782
Epoch 0, Step 3000: train/loss = 0.3614669740200043, train/raw-loss = 0.30941295623779297, train/logprobs = tensor([[-1.6978, -8.7457],
        [-4.2419, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5205402374267578
Epoch 0, Step 3001: train/loss = 0.31695103645324707, train/raw-loss = 0.2696812152862549, train/logprobs = tensor([[-1.7733, -9.9329],
        [-4.3425, -2.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4726982116699219
Epoch 0, Step 3002: train/loss = 0.09922399371862411, train/raw-loss = 0.055627115070819855, train/logprobs = tensor([[-1.3701, -7.9748],
        [-4.8545, -2.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.435968816280365
Epoch 0, Step 3003: train/loss = 0.15060564875602722, train/raw-loss = 0.10393799841403961, train/logprobs = tensor([[ -2.1923, -14.1431],
        [ -4.0169,  -1.4320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46667641401290894
Epoch 0, Step 3004: train/loss = 0.2230682671070099, train/raw-loss = 0.19100727140903473, train/logprobs = tensor([[-1.7299, -7.1456],
        [-3.0727, -1.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32060977816581726
Epoch 0, Step 3005: train/loss = 0.37679171562194824, train/raw-loss = 0.3412702977657318, train/logprobs = tensor([[-2.1642, -4.5470],
        [-2.9853, -1.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35521411895751953
Epoch 0, Step 3006: train/loss = 0.18401318788528442, train/raw-loss = 0.1324446201324463, train/logprobs = tensor([[-1.5684, -6.6874],
        [-5.0009, -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5156856775283813
Epoch 0, Step 3007: train/loss = 0.49926823377609253, train/raw-loss = 0.45996713638305664, train/logprobs = tensor([[-1.2492, -3.7218],
        [-2.7193, -1.2689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39301103353500366
Epoch 0, Step 3008: train/loss = 0.16449739038944244, train/raw-loss = 0.12431412935256958, train/logprobs = tensor([[ -1.1438, -11.7853],
        [ -2.8094,  -1.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4018324613571167
Epoch 0, Step 3009: train/loss = 0.11594750732183456, train/raw-loss = 0.07698127627372742, train/logprobs = tensor([[-1.7252, -7.7216],
        [-3.7676, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38966232538223267
Epoch 0, Step 3010: train/loss = 0.35588890314102173, train/raw-loss = 0.3074733018875122, train/logprobs = tensor([[-1.6990, -3.8751],
        [-3.5364, -2.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4841561019420624
Epoch 0, Step 3011: train/loss = 0.35666438937187195, train/raw-loss = 0.3136947751045227, train/logprobs = tensor([[-0.9298, -2.9825],
        [-2.4076, -1.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42969614267349243
Epoch 0, Step 3012: train/loss = 0.6503610014915466, train/raw-loss = 0.5941019058227539, train/logprobs = tensor([[-1.7331, -6.3873],
        [-3.1351, -2.5122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.562590479850769
Epoch 0, Step 3013: train/loss = 0.928165853023529, train/raw-loss = 0.8836671710014343, train/logprobs = tensor([[-4.0922, -5.6683],
        [-3.3835, -2.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44498685002326965
Epoch 0, Step 3014: train/loss = 0.4568263292312622, train/raw-loss = 0.41112586855888367, train/logprobs = tensor([[-1.8305, -3.2691],
        [-2.8856, -2.3645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4570046663284302
Epoch 0, Step 3015: train/loss = 0.6446597576141357, train/raw-loss = 0.6126192212104797, train/logprobs = tensor([[-2.2596, -8.4965],
        [-2.2310, -3.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.320405513048172
Epoch 0, Step 3016: train/loss = 0.5131760835647583, train/raw-loss = 0.46473097801208496, train/logprobs = tensor([[-1.1121, -4.7548],
        [-2.0205, -1.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48445039987564087
Epoch 0, Step 3017: train/loss = 0.2788066864013672, train/raw-loss = 0.23797743022441864, train/logprobs = tensor([[-0.9880, -4.2459],
        [-2.6449, -2.0917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40829259157180786
Epoch 0, Step 3018: train/loss = 0.2671405076980591, train/raw-loss = 0.22515173256397247, train/logprobs = tensor([[-2.2385, -8.6658],
        [-3.6493, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4198877215385437
Epoch 0, Step 3019: train/loss = 0.4435347318649292, train/raw-loss = 0.3955555558204651, train/logprobs = tensor([[-1.3854, -3.3437],
        [-3.3549, -2.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47979164123535156
Epoch 0, Step 3020: train/loss = 0.14788652956485748, train/raw-loss = 0.10247926414012909, train/logprobs = tensor([[-2.1107, -7.3457],
        [-4.6133, -1.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540727138519287
Epoch 0, Step 3021: train/loss = 0.2679700553417206, train/raw-loss = 0.23554958403110504, train/logprobs = tensor([[-1.5668, -2.6629],
        [-3.2141, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3242047429084778
Epoch 0, Step 3022: train/loss = 0.21925070881843567, train/raw-loss = 0.17421990633010864, train/logprobs = tensor([[-1.3013, -5.6299],
        [-3.1838, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4503079652786255
Epoch 0, Step 3023: train/loss = 0.2415768951177597, train/raw-loss = 0.19669725000858307, train/logprobs = tensor([[-2.3415, -9.3616],
        [-4.0339, -1.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44879645109176636
Epoch 0, Step 3024: train/loss = 0.15073882043361664, train/raw-loss = 0.11327885091304779, train/logprobs = tensor([[ -1.6871, -12.7704],
        [ -3.8617,  -4.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37459975481033325
Epoch 0, Step 3025: train/loss = 0.5101079344749451, train/raw-loss = 0.4698885381221771, train/logprobs = tensor([[-1.3170, -2.5130],
        [-3.3250, -2.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4021940231323242
Epoch 0, Step 3026: train/loss = 0.31177520751953125, train/raw-loss = 0.26394182443618774, train/logprobs = tensor([[-1.2929, -8.1821],
        [-4.8172, -2.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47833356261253357
Epoch 0, Step 3027: train/loss = 0.3713133931159973, train/raw-loss = 0.3335643708705902, train/logprobs = tensor([[ -1.4479, -10.6397],
        [ -3.1718,  -3.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3774900436401367
Epoch 0, Step 3028: train/loss = 0.19294440746307373, train/raw-loss = 0.15251301229000092, train/logprobs = tensor([[ -1.6953, -12.6231],
        [ -3.7966,  -3.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4043138921260834
Epoch 0, Step 3029: train/loss = 0.1968034952878952, train/raw-loss = 0.1607816070318222, train/logprobs = tensor([[-1.8850, -7.9150],
        [-3.9367, -1.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36021891236305237
Epoch 0, Step 3030: train/loss = 0.4044918119907379, train/raw-loss = 0.3621716797351837, train/logprobs = tensor([[-1.1096, -4.6719],
        [-2.3028, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4232013523578644
Epoch 0, Step 3031: train/loss = 0.4258952736854553, train/raw-loss = 0.39127036929130554, train/logprobs = tensor([[-1.1856, -3.5976],
        [-1.7365, -1.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462490737438202
Epoch 0, Step 3032: train/loss = 0.4436306953430176, train/raw-loss = 0.388509064912796, train/logprobs = tensor([[-0.8511, -3.6042],
        [-2.9837, -1.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5512163043022156
Epoch 0, Step 3033: train/loss = 0.41466081142425537, train/raw-loss = 0.36190351843833923, train/logprobs = tensor([[-1.7956, -4.8359],
        [-2.9566, -2.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5275731086730957
Epoch 0, Step 3034: train/loss = 0.46471139788627625, train/raw-loss = 0.4263014495372772, train/logprobs = tensor([[-2.2064, -5.5494],
        [-3.7423, -1.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840993046760559
Epoch 0, Step 3035: train/loss = 0.3350605070590973, train/raw-loss = 0.291307657957077, train/logprobs = tensor([[-1.1516, -7.0119],
        [-3.5233, -2.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43752849102020264
Epoch 0, Step 3036: train/loss = 0.19570627808570862, train/raw-loss = 0.14594702422618866, train/logprobs = tensor([[-1.3791, -7.2663],
        [-4.1120, -2.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4975924491882324
Epoch 0, Step 3037: train/loss = 0.3671926259994507, train/raw-loss = 0.3209962248802185, train/logprobs = tensor([[-1.2624, -3.5995],
        [-3.2395, -1.8002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4619640111923218
Epoch 0, Step 3038: train/loss = 0.23273475468158722, train/raw-loss = 0.1917114555835724, train/logprobs = tensor([[ -2.3342, -14.7186],
        [ -3.1819,  -2.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41023290157318115
Epoch 0, Step 3039: train/loss = 0.27199023962020874, train/raw-loss = 0.23983532190322876, train/logprobs = tensor([[ -1.4881, -10.9868],
        [ -2.9289,  -2.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215493857860565
Epoch 0, Step 3040: train/loss = 0.3764744997024536, train/raw-loss = 0.3344336748123169, train/logprobs = tensor([[-1.4619, -9.9318],
        [-3.8751, -2.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4204079806804657
Epoch 0, Step 3041: train/loss = 0.26313579082489014, train/raw-loss = 0.2083985060453415, train/logprobs = tensor([[-1.9845, -4.9780],
        [-3.8289, -2.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5473729372024536
Epoch 0, Step 3042: train/loss = 0.29541465640068054, train/raw-loss = 0.2591348886489868, train/logprobs = tensor([[-1.6364, -5.5821],
        [-3.7486, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36279770731925964
Epoch 0, Step 3043: train/loss = 0.5047112107276917, train/raw-loss = 0.4585595726966858, train/logprobs = tensor([[-1.2151, -2.9699],
        [-2.5354, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4615160822868347
Epoch 0, Step 3044: train/loss = 0.1967688500881195, train/raw-loss = 0.15245848894119263, train/logprobs = tensor([[ -2.3453, -11.8310],
        [ -4.4915,  -3.3832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44310346245765686
Epoch 0, Step 3045: train/loss = 0.4622543454170227, train/raw-loss = 0.4105655550956726, train/logprobs = tensor([[-1.3738, -9.2947],
        [-4.3308, -4.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5168880820274353
Epoch 0, Step 3046: train/loss = 0.4157070517539978, train/raw-loss = 0.37478381395339966, train/logprobs = tensor([[-1.4799, -4.3062],
        [-2.7193, -2.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40923231840133667
Epoch 0, Step 3047: train/loss = 0.4933750331401825, train/raw-loss = 0.4468831419944763, train/logprobs = tensor([[-1.2874, -2.9965],
        [-2.2541, -1.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4649190306663513
Epoch 0, Step 3048: train/loss = 0.2170521318912506, train/raw-loss = 0.1722089946269989, train/logprobs = tensor([[-1.0803, -8.1864],
        [-4.2919, -1.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44843143224716187
Epoch 0, Step 3049: train/loss = 0.20632119476795197, train/raw-loss = 0.1574672907590866, train/logprobs = tensor([[-1.2625, -7.2396],
        [-3.5658, -2.3573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4885388910770416
Epoch 0, Step 3050: train/loss = 0.46555888652801514, train/raw-loss = 0.42402058839797974, train/logprobs = tensor([[-1.1673, -3.4396],
        [-2.1413, -1.5297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4153827428817749
Epoch 0, Step 3051: train/loss = 0.2223140299320221, train/raw-loss = 0.18217164278030396, train/logprobs = tensor([[-1.5096, -3.7277],
        [-4.1277, -1.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4014240503311157
Epoch 0, Step 3052: train/loss = 0.446561723947525, train/raw-loss = 0.40608492493629456, train/logprobs = tensor([[-2.2426, -7.6428],
        [-2.2851, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047681391239166
Epoch 0, Step 3053: train/loss = 0.3410998284816742, train/raw-loss = 0.30181312561035156, train/logprobs = tensor([[-1.4614, -4.0346],
        [-3.5201, -2.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928668797016144
Epoch 0, Step 3054: train/loss = 0.4704729914665222, train/raw-loss = 0.4364520013332367, train/logprobs = tensor([[-1.2768, -3.1694],
        [-2.2575, -1.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3402101993560791
Epoch 0, Step 3055: train/loss = 0.31919220089912415, train/raw-loss = 0.27051854133605957, train/logprobs = tensor([[-1.1473, -5.3423],
        [-3.1456, -1.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48673689365386963
Epoch 0, Step 3056: train/loss = 0.6152182817459106, train/raw-loss = 0.5819472670555115, train/logprobs = tensor([[-2.2308, -8.7792],
        [-2.5107, -2.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3327099084854126
Epoch 0, Step 3057: train/loss = 0.3681517541408539, train/raw-loss = 0.3278488516807556, train/logprobs = tensor([[-0.9617, -3.0632],
        [-2.6319, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40302902460098267
Epoch 0, Step 3058: train/loss = 0.3596898913383484, train/raw-loss = 0.3206985592842102, train/logprobs = tensor([[-1.2344, -6.7614],
        [-4.0320, -2.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3899134397506714
Epoch 0, Step 3059: train/loss = 0.260590136051178, train/raw-loss = 0.2166306972503662, train/logprobs = tensor([[-1.1319, -4.9376],
        [-2.7552, -2.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4395941495895386
Epoch 0, Step 3060: train/loss = 0.1649858057498932, train/raw-loss = 0.13129903376102448, train/logprobs = tensor([[-2.5771, -6.7690],
        [-4.3949, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3368677496910095
Epoch 0, Step 3061: train/loss = 0.647138774394989, train/raw-loss = 0.6143680810928345, train/logprobs = tensor([[-2.7649, -6.9563],
        [-2.5276, -2.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3277069926261902
Epoch 0, Step 3062: train/loss = 0.5840729475021362, train/raw-loss = 0.5474526882171631, train/logprobs = tensor([[ -3.7463, -13.3727],
        [ -4.7201,  -2.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36620235443115234
Epoch 0, Step 3063: train/loss = 0.12138456851243973, train/raw-loss = 0.08060996234416962, train/logprobs = tensor([[ -1.5220, -12.3109],
        [ -4.7551,  -2.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4077460467815399
Epoch 0, Step 3064: train/loss = 0.2812221646308899, train/raw-loss = 0.23869284987449646, train/logprobs = tensor([[-1.6723, -5.7089],
        [-3.2122, -0.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42529332637786865
Epoch 0, Step 3065: train/loss = 0.19381770491600037, train/raw-loss = 0.15622365474700928, train/logprobs = tensor([[-1.9627, -8.9602],
        [-3.3924, -2.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37594062089920044
Epoch 0, Step 3066: train/loss = 0.5164631605148315, train/raw-loss = 0.4839212894439697, train/logprobs = tensor([[-1.4946, -2.3144],
        [-2.2347, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.325418621301651
Epoch 0, Step 3067: train/loss = 0.23786430060863495, train/raw-loss = 0.20044150948524475, train/logprobs = tensor([[-0.7927, -4.8775],
        [-2.5629, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37422800064086914
Epoch 0, Step 3068: train/loss = 0.47119295597076416, train/raw-loss = 0.42647790908813477, train/logprobs = tensor([[-2.5757, -9.1983],
        [-3.4328, -1.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4471505880355835
Epoch 0, Step 3069: train/loss = 0.3841889500617981, train/raw-loss = 0.32896289229393005, train/logprobs = tensor([[-1.2991, -6.1992],
        [-3.7998, -1.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5522607564926147
Epoch 0, Step 3070: train/loss = 0.0742577612400055, train/raw-loss = 0.029237372800707817, train/logprobs = tensor([[ -1.0000, -10.0717],
        [ -4.2920,  -1.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4502038359642029
Epoch 0, Step 3071: train/loss = 0.11887194216251373, train/raw-loss = 0.07279732823371887, train/logprobs = tensor([[ -1.1783, -14.0261],
        [ -4.7024,  -4.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46074604988098145
Epoch 0, Step 3072: train/loss = 0.16034036874771118, train/raw-loss = 0.11431647837162018, train/logprobs = tensor([[-1.8282, -4.6780],
        [-4.4245, -2.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4602389931678772
Epoch 0, Step 3073: train/loss = 0.44397038221359253, train/raw-loss = 0.40549027919769287, train/logprobs = tensor([[-1.4652, -7.3969],
        [-2.5087, -1.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38480105996131897
Epoch 0, Step 3074: train/loss = 0.42146003246307373, train/raw-loss = 0.3788175880908966, train/logprobs = tensor([[-1.7657, -4.6605],
        [-3.3409, -2.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4264242351055145
Epoch 0, Step 3075: train/loss = 0.5066649317741394, train/raw-loss = 0.46749067306518555, train/logprobs = tensor([[-1.6563, -7.0045],
        [-1.9860, -2.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917432725429535
Epoch 0, Step 3076: train/loss = 0.3967649042606354, train/raw-loss = 0.3562769889831543, train/logprobs = tensor([[-1.2724, -4.1702],
        [-2.6614, -2.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40487924218177795
Epoch 0, Step 3077: train/loss = 0.5315071940422058, train/raw-loss = 0.49487775564193726, train/logprobs = tensor([[-1.3986, -2.5280],
        [-2.8456, -1.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.366294264793396
Epoch 0, Step 3078: train/loss = 0.5042509436607361, train/raw-loss = 0.45588648319244385, train/logprobs = tensor([[-1.1080, -6.0456],
        [-3.3421, -2.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4836447238922119
Epoch 0, Step 3079: train/loss = 0.5064851641654968, train/raw-loss = 0.4501699209213257, train/logprobs = tensor([[-1.3221, -4.5415],
        [-4.5601, -3.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5631521940231323
Epoch 0, Step 3080: train/loss = 0.18624737858772278, train/raw-loss = 0.14432930946350098, train/logprobs = tensor([[ -0.9588, -10.2232],
        [ -3.2040,  -2.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4191807210445404
Epoch 0, Step 3081: train/loss = 0.5070938467979431, train/raw-loss = 0.4745810031890869, train/logprobs = tensor([[-1.5201, -4.0305],
        [-1.4346, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251282870769501
Epoch 0, Step 3082: train/loss = 0.23624268174171448, train/raw-loss = 0.19215071201324463, train/logprobs = tensor([[-1.3310, -4.1086],
        [-3.5380, -2.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44091978669166565
Epoch 0, Step 3083: train/loss = 0.3333660364151001, train/raw-loss = 0.2909276783466339, train/logprobs = tensor([[-1.4438, -4.4097],
        [-4.2298, -2.2026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4243837296962738
Epoch 0, Step 3084: train/loss = 0.43404537439346313, train/raw-loss = 0.39728689193725586, train/logprobs = tensor([[-0.8284, -5.3665],
        [-2.3260, -1.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3675847053527832
Epoch 0, Step 3085: train/loss = 0.1492229849100113, train/raw-loss = 0.10634138435125351, train/logprobs = tensor([[ -1.6299, -10.0924],
        [ -3.5332,  -2.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4288159906864166
Epoch 0, Step 3086: train/loss = 0.8623307943344116, train/raw-loss = 0.8294332027435303, train/logprobs = tensor([[ -4.8195, -12.3680],
        [ -3.2987,  -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32897666096687317
Epoch 0, Step 3087: train/loss = 0.4391218423843384, train/raw-loss = 0.39272135496139526, train/logprobs = tensor([[-1.2264, -5.3059],
        [-3.4318, -2.4978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640049934387207
Epoch 0, Step 3088: train/loss = 0.39124172925949097, train/raw-loss = 0.34435179829597473, train/logprobs = tensor([[-1.3921, -2.9349],
        [-3.5072, -1.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46889960765838623
Epoch 0, Step 3089: train/loss = 0.238383948802948, train/raw-loss = 0.19488166272640228, train/logprobs = tensor([[-1.8419, -7.1444],
        [-4.2486, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43502289056777954
Epoch 0, Step 3090: train/loss = 0.2515491843223572, train/raw-loss = 0.21202413737773895, train/logprobs = tensor([[-1.3037, -6.7333],
        [-3.2975, -1.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3952506482601166
Epoch 0, Step 3091: train/loss = 0.4230839014053345, train/raw-loss = 0.3870501220226288, train/logprobs = tensor([[-1.1163, -3.3750],
        [-1.9972, -1.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36033785343170166
Epoch 0, Step 3092: train/loss = 0.7231560945510864, train/raw-loss = 0.6795664429664612, train/logprobs = tensor([[-1.1345, -1.3752],
        [-1.6346, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.435896098613739
Epoch 0, Step 3093: train/loss = 0.21072688698768616, train/raw-loss = 0.16951234638690948, train/logprobs = tensor([[-1.1288, -5.9941],
        [-4.2367, -1.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41214537620544434
Epoch 0, Step 3094: train/loss = 0.5667678117752075, train/raw-loss = 0.520642876625061, train/logprobs = tensor([[-1.4565, -2.7699],
        [-2.9126, -2.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46125009655952454
Epoch 0, Step 3095: train/loss = 0.381450891494751, train/raw-loss = 0.33751097321510315, train/logprobs = tensor([[-1.6458, -5.8905],
        [-3.0255, -2.5523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4393993616104126
Epoch 0, Step 3096: train/loss = 0.176614910364151, train/raw-loss = 0.13773886859416962, train/logprobs = tensor([[-1.0381, -9.7458],
        [-3.0682, -2.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38876038789749146
Epoch 0, Step 3097: train/loss = 0.15278254449367523, train/raw-loss = 0.11637599766254425, train/logprobs = tensor([[-1.5739, -7.6396],
        [-3.9973, -0.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3640655279159546
Epoch 0, Step 3098: train/loss = 0.5845784544944763, train/raw-loss = 0.5489976406097412, train/logprobs = tensor([[-0.9282, -3.3604],
        [-1.5092, -2.4065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3558077812194824
Epoch 0, Step 3099: train/loss = 0.3212560713291168, train/raw-loss = 0.28196433186531067, train/logprobs = tensor([[-1.4291, -3.4801],
        [-3.5589, -2.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39291754364967346
Epoch 0, Step 3100: train/loss = 0.26059889793395996, train/raw-loss = 0.21387846767902374, train/logprobs = tensor([[-1.1000, -5.0917],
        [-3.7145, -1.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4672043025493622
Epoch 0, Step 3101: train/loss = 0.2453344166278839, train/raw-loss = 0.1941828727722168, train/logprobs = tensor([[ -1.5258, -10.2522],
        [ -3.6322,  -2.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5115153789520264
Epoch 0, Step 3102: train/loss = 0.5350435972213745, train/raw-loss = 0.4917789697647095, train/logprobs = tensor([[-2.0578, -7.6418],
        [-3.1964, -1.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4326460063457489
Epoch 0, Step 3103: train/loss = 0.33296507596969604, train/raw-loss = 0.30158597230911255, train/logprobs = tensor([[-1.0465, -4.5971],
        [-2.7177, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31379103660583496
Epoch 0, Step 3104: train/loss = 0.11901954561471939, train/raw-loss = 0.07789608091115952, train/logprobs = tensor([[ -1.1391, -14.9935],
        [ -3.3052,  -2.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41123461723327637
Epoch 0, Step 3105: train/loss = 0.21294334530830383, train/raw-loss = 0.1635366678237915, train/logprobs = tensor([[-0.6041, -7.5015],
        [-3.6326, -2.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4940667450428009
Epoch 0, Step 3106: train/loss = 0.14624354243278503, train/raw-loss = 0.10047252476215363, train/logprobs = tensor([[ -1.4559, -12.8446],
        [ -4.8034,  -4.3164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45771005749702454
Epoch 0, Step 3107: train/loss = 0.43449336290359497, train/raw-loss = 0.39860740303993225, train/logprobs = tensor([[-1.2075, -8.0687],
        [-2.9222, -3.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35885992646217346
Epoch 0, Step 3108: train/loss = 0.4091648459434509, train/raw-loss = 0.36705461144447327, train/logprobs = tensor([[-1.7456, -7.4430],
        [-3.8032, -1.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4211021661758423
Epoch 0, Step 3109: train/loss = 0.4860779345035553, train/raw-loss = 0.437088280916214, train/logprobs = tensor([[-1.6974, -3.2642],
        [-4.6107, -2.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4898967742919922
Epoch 0, Step 3110: train/loss = 0.5323277711868286, train/raw-loss = 0.486388623714447, train/logprobs = tensor([[-1.6200, -5.0538],
        [-3.4484, -2.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4593912959098816
Epoch 0, Step 3111: train/loss = 0.22474268078804016, train/raw-loss = 0.17870420217514038, train/logprobs = tensor([[ -1.5363, -10.5853],
        [ -3.8101,  -3.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4603847861289978
Epoch 0, Step 3112: train/loss = 0.2758606970310211, train/raw-loss = 0.23889179527759552, train/logprobs = tensor([[-0.7940, -4.1918],
        [-3.1268, -2.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.369689017534256
Epoch 0, Step 3113: train/loss = 0.2585822641849518, train/raw-loss = 0.2098880112171173, train/logprobs = tensor([[-1.9468, -4.4931],
        [-5.2491, -2.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4869424104690552
Epoch 0, Step 3114: train/loss = 0.6277779340744019, train/raw-loss = 0.5983293056488037, train/logprobs = tensor([[-1.7025, -4.9464],
        [-1.8565, -1.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2944864332675934
Epoch 0, Step 3115: train/loss = 0.18793371319770813, train/raw-loss = 0.1484191119670868, train/logprobs = tensor([[-1.2566, -4.2524],
        [-3.2427, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39514589309692383
Epoch 0, Step 3116: train/loss = 0.06648936867713928, train/raw-loss = 0.017258919775485992, train/logprobs = tensor([[ -1.0098, -16.7048],
        [ -5.0298,  -3.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4923045039176941
Epoch 0, Step 3117: train/loss = 0.1463870406150818, train/raw-loss = 0.10090117901563644, train/logprobs = tensor([[-1.7517, -6.7009],
        [-3.9793, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45485854148864746
Epoch 0, Step 3118: train/loss = 0.2550576627254486, train/raw-loss = 0.21463696658611298, train/logprobs = tensor([[-1.1439, -8.6461],
        [-3.7744, -2.3269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40420693159103394
Epoch 0, Step 3119: train/loss = 0.1346920281648636, train/raw-loss = 0.09141905605792999, train/logprobs = tensor([[-1.1344, -8.6580],
        [-4.3262, -2.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4327297508716583
Epoch 0, Step 3120: train/loss = 0.3803572356700897, train/raw-loss = 0.33670419454574585, train/logprobs = tensor([[-1.3849, -3.0178],
        [-2.9798, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43653011322021484
Epoch 0, Step 3121: train/loss = 0.14062219858169556, train/raw-loss = 0.09913376718759537, train/logprobs = tensor([[-1.5115, -6.1226],
        [-4.8243, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4148842692375183
Epoch 0, Step 3122: train/loss = 0.30523091554641724, train/raw-loss = 0.26847583055496216, train/logprobs = tensor([[-1.7151, -6.9427],
        [-4.3198, -2.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36755096912384033
Epoch 0, Step 3123: train/loss = 0.42817407846450806, train/raw-loss = 0.3861757814884186, train/logprobs = tensor([[-1.3577, -9.1187],
        [-2.5995, -0.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199829697608948
Epoch 0, Step 3124: train/loss = 0.4099690318107605, train/raw-loss = 0.3753434717655182, train/logprobs = tensor([[-1.6422, -6.8712],
        [-2.9639, -1.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462558686733246
Epoch 0, Step 3125: train/loss = 0.2758476734161377, train/raw-loss = 0.24284346401691437, train/logprobs = tensor([[ -1.7455, -13.2254],
        [ -2.9616,  -3.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3300423324108124
Epoch 0, Step 3126: train/loss = 0.12463565915822983, train/raw-loss = 0.09151463210582733, train/logprobs = tensor([[-1.5726, -9.7698],
        [-4.2708, -2.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.331210196018219
Epoch 0, Step 3127: train/loss = 0.14706838130950928, train/raw-loss = 0.10123001784086227, train/logprobs = tensor([[-1.1574, -8.6680],
        [-5.1573, -2.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45838358998298645
Epoch 0, Step 3128: train/loss = 0.5208538770675659, train/raw-loss = 0.47832557559013367, train/logprobs = tensor([[-1.7528, -5.8381],
        [-3.2065, -1.9243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42528295516967773
Epoch 0, Step 3129: train/loss = 0.18920239806175232, train/raw-loss = 0.14736419916152954, train/logprobs = tensor([[ -1.2681, -11.8634],
        [ -4.0167,  -3.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183821678161621
Epoch 0, Step 3130: train/loss = 0.1745975762605667, train/raw-loss = 0.12636946141719818, train/logprobs = tensor([[-0.8855, -6.1876],
        [-2.9558, -2.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4822811186313629
Epoch 0, Step 3131: train/loss = 0.32570770382881165, train/raw-loss = 0.2884898781776428, train/logprobs = tensor([[-1.3039, -7.7273],
        [-2.7075, -2.4773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721783459186554
Epoch 0, Step 3132: train/loss = 0.34769904613494873, train/raw-loss = 0.30643951892852783, train/logprobs = tensor([[-1.6925, -7.4425],
        [-4.0586, -2.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41259533166885376
Epoch 0, Step 3133: train/loss = 0.2627754509449005, train/raw-loss = 0.22129452228546143, train/logprobs = tensor([[-1.7701, -8.9585],
        [-4.0870, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4148092269897461
Epoch 0, Step 3134: train/loss = 0.3425726592540741, train/raw-loss = 0.2993173599243164, train/logprobs = tensor([[-1.7214, -5.8230],
        [-3.9137, -2.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4325529932975769
Epoch 0, Step 3135: train/loss = 0.3537435829639435, train/raw-loss = 0.30991995334625244, train/logprobs = tensor([[-1.1117, -4.8468],
        [-3.7569, -1.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.438236266374588
Epoch 0, Step 3136: train/loss = 0.20634731650352478, train/raw-loss = 0.1650843769311905, train/logprobs = tensor([[-0.9865, -8.7547],
        [-3.7892, -3.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4126293957233429
Epoch 0, Step 3137: train/loss = 0.4023987352848053, train/raw-loss = 0.3617842495441437, train/logprobs = tensor([[-1.4761, -3.9217],
        [-2.8135, -1.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061450660228729
Epoch 0, Step 3138: train/loss = 0.0921255350112915, train/raw-loss = 0.04787898808717728, train/logprobs = tensor([[-1.4030, -7.8249],
        [-4.1301, -1.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44246548414230347
Epoch 0, Step 3139: train/loss = 0.5559985637664795, train/raw-loss = 0.5140637159347534, train/logprobs = tensor([[-1.4430, -3.3000],
        [-1.9519, -1.2148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41934871673583984
Epoch 0, Step 3140: train/loss = 0.2972080409526825, train/raw-loss = 0.24648284912109375, train/logprobs = tensor([[-0.8844, -5.9516],
        [-3.5504, -2.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5072518587112427
Epoch 0, Step 3141: train/loss = 0.2136238068342209, train/raw-loss = 0.17119958996772766, train/logprobs = tensor([[-1.5551, -8.4650],
        [-3.5997, -2.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42424213886260986
Epoch 0, Step 3142: train/loss = 0.20747238397598267, train/raw-loss = 0.16764414310455322, train/logprobs = tensor([[-2.1015, -8.5993],
        [-5.3492, -2.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39828231930732727
Epoch 0, Step 3143: train/loss = 0.44800999760627747, train/raw-loss = 0.4035523533821106, train/logprobs = tensor([[-0.9877, -4.7511],
        [-2.7871, -1.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44457653164863586
Epoch 0, Step 3144: train/loss = 0.32417774200439453, train/raw-loss = 0.2918502986431122, train/logprobs = tensor([[-1.5793, -5.8682],
        [-4.1341, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3232744634151459
Epoch 0, Step 3145: train/loss = 0.2508865296840668, train/raw-loss = 0.2121315896511078, train/logprobs = tensor([[ -1.6383, -10.4502],
        [ -3.5747,  -3.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38754913210868835
Epoch 0, Step 3146: train/loss = 0.3657257556915283, train/raw-loss = 0.3178333044052124, train/logprobs = tensor([[-0.9926, -5.7130],
        [-4.7744, -1.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47892457246780396
Epoch 0, Step 3147: train/loss = 0.6880027651786804, train/raw-loss = 0.6362409591674805, train/logprobs = tensor([[-1.5067, -2.3111],
        [-2.6347, -2.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5176180601119995
Epoch 0, Step 3148: train/loss = 0.6130764484405518, train/raw-loss = 0.5781537294387817, train/logprobs = tensor([[-2.0548, -5.6568],
        [-2.0729, -2.4984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492273688316345
Epoch 0, Step 3149: train/loss = 0.27860018610954285, train/raw-loss = 0.24367961287498474, train/logprobs = tensor([[-1.5378, -7.6818],
        [-4.5848, -1.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492056727409363
Epoch 0, Step 3150: train/loss = 0.3945809602737427, train/raw-loss = 0.3511669933795929, train/logprobs = tensor([[-1.2467, -4.3586],
        [-3.5007, -2.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43413999676704407
Epoch 0, Step 3151: train/loss = 0.39116984605789185, train/raw-loss = 0.3531837463378906, train/logprobs = tensor([[-1.1870, -7.7741],
        [-2.6296, -2.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37986087799072266
Epoch 0, Step 3152: train/loss = 0.4821644723415375, train/raw-loss = 0.44228360056877136, train/logprobs = tensor([[-1.6438, -3.0909],
        [-2.2066, -1.4864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3988087475299835
Epoch 0, Step 3153: train/loss = 0.3265652358531952, train/raw-loss = 0.28483080863952637, train/logprobs = tensor([[-1.5578, -4.5324],
        [-3.9512, -1.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4173440933227539
Epoch 0, Step 3154: train/loss = 0.4620288610458374, train/raw-loss = 0.4236227571964264, train/logprobs = tensor([[-1.5566, -3.5322],
        [-3.4684, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38406097888946533
Epoch 0, Step 3155: train/loss = 0.40311199426651, train/raw-loss = 0.3596707880496979, train/logprobs = tensor([[-1.0090, -8.5908],
        [-5.5207, -4.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43441176414489746
Epoch 0, Step 3156: train/loss = 0.503713071346283, train/raw-loss = 0.44847798347473145, train/logprobs = tensor([[-1.3041, -3.7229],
        [-3.9865, -2.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5523504614830017
Epoch 0, Step 3157: train/loss = 0.450147807598114, train/raw-loss = 0.3960217833518982, train/logprobs = tensor([[-0.9166, -6.7425],
        [-3.4078, -2.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5412600636482239
Epoch 0, Step 3158: train/loss = 0.44081002473831177, train/raw-loss = 0.4010128080844879, train/logprobs = tensor([[-2.1690, -7.5442],
        [-2.9699, -1.3957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39797234535217285
Epoch 0, Step 3159: train/loss = 0.41625672578811646, train/raw-loss = 0.37233272194862366, train/logprobs = tensor([[-0.7151, -1.9620],
        [-2.8865, -0.9869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4392402768135071
Epoch 0, Step 3160: train/loss = 0.21829970180988312, train/raw-loss = 0.16223183274269104, train/logprobs = tensor([[-1.4626, -9.4910],
        [-5.0576, -2.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5606787800788879
Epoch 0, Step 3161: train/loss = 0.26384276151657104, train/raw-loss = 0.21969157457351685, train/logprobs = tensor([[-1.0916, -6.0489],
        [-5.5562, -1.3083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4415118098258972
Epoch 0, Step 3162: train/loss = 0.37483057379722595, train/raw-loss = 0.33636122941970825, train/logprobs = tensor([[-2.4971, -5.0564],
        [-3.0330, -1.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846935033798218
Epoch 0, Step 3163: train/loss = 0.2509598135948181, train/raw-loss = 0.2007511556148529, train/logprobs = tensor([[ -0.9197, -13.9509],
        [ -4.1164,  -4.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5020864009857178
Epoch 0, Step 3164: train/loss = 0.4376128911972046, train/raw-loss = 0.40020108222961426, train/logprobs = tensor([[-1.5641, -6.6186],
        [-3.8639, -2.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37411826848983765
Epoch 0, Step 3165: train/loss = 0.18726694583892822, train/raw-loss = 0.14579010009765625, train/logprobs = tensor([[-1.4422, -8.4108],
        [-4.7395, -1.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4147683382034302
Epoch 0, Step 3166: train/loss = 0.4437521994113922, train/raw-loss = 0.4029398262500763, train/logprobs = tensor([[-1.1023, -2.0731],
        [-2.1929, -1.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40812402963638306
Epoch 0, Step 3167: train/loss = 0.18082131445407867, train/raw-loss = 0.13503073155879974, train/logprobs = tensor([[-1.2402, -5.5799],
        [-4.3745, -1.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4579058885574341
Epoch 0, Step 3168: train/loss = 0.3541252017021179, train/raw-loss = 0.30436384677886963, train/logprobs = tensor([[-1.0513, -3.5364],
        [-4.0342, -1.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4976133108139038
Epoch 0, Step 3169: train/loss = 0.3692416548728943, train/raw-loss = 0.32442614436149597, train/logprobs = tensor([[-1.3990, -4.4590],
        [-3.6626, -1.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4481550455093384
Epoch 0, Step 3170: train/loss = 0.9351577758789062, train/raw-loss = 0.902356743812561, train/logprobs = tensor([[-2.9455, -3.0349],
        [-2.3321, -2.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32801005244255066
Epoch 0, Step 3171: train/loss = 0.18376034498214722, train/raw-loss = 0.14742057025432587, train/logprobs = tensor([[-1.4658, -4.7811],
        [-4.6544, -2.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3633977472782135
Epoch 0, Step 3172: train/loss = 0.42600303888320923, train/raw-loss = 0.3933219909667969, train/logprobs = tensor([[-1.3139, -2.2012],
        [-2.7332, -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3268105685710907
Epoch 0, Step 3173: train/loss = 0.14529633522033691, train/raw-loss = 0.09101875126361847, train/logprobs = tensor([[-1.4721, -8.1809],
        [-5.3859, -2.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5427758097648621
Epoch 0, Step 3174: train/loss = 0.495236873626709, train/raw-loss = 0.45955708622932434, train/logprobs = tensor([[-0.8466, -2.2291],
        [-2.2379, -2.0598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35679781436920166
Epoch 0, Step 3175: train/loss = 0.5325312614440918, train/raw-loss = 0.48715585470199585, train/logprobs = tensor([[-2.8170, -3.8650],
        [-3.9577, -2.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45375365018844604
Epoch 0, Step 3176: train/loss = 0.2434341311454773, train/raw-loss = 0.19469736516475677, train/logprobs = tensor([[ -0.9886, -10.7653],
        [ -3.4364,  -3.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48736774921417236
Epoch 0, Step 3177: train/loss = 0.5862497091293335, train/raw-loss = 0.5261974334716797, train/logprobs = tensor([[-0.8657, -4.8468],
        [-3.5555, -2.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6005227565765381
Epoch 0, Step 3178: train/loss = 0.25425735116004944, train/raw-loss = 0.21871207654476166, train/logprobs = tensor([[ -1.9765, -10.1172],
        [ -3.7111,  -2.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35545265674591064
Epoch 0, Step 3179: train/loss = 0.3816582262516022, train/raw-loss = 0.3479854464530945, train/logprobs = tensor([[-1.2747, -3.2478],
        [-3.1767, -1.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3367275595664978
Epoch 0, Step 3180: train/loss = 0.17160217463970184, train/raw-loss = 0.13132189214229584, train/logprobs = tensor([[-1.6912, -9.1419],
        [-4.2430, -3.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40280288457870483
Epoch 0, Step 3181: train/loss = 0.32413163781166077, train/raw-loss = 0.2814704477787018, train/logprobs = tensor([[-1.7640, -7.1970],
        [-3.3492, -2.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42661184072494507
Epoch 0, Step 3182: train/loss = 0.41920948028564453, train/raw-loss = 0.3758307695388794, train/logprobs = tensor([[-1.3151, -3.3149],
        [-2.9535, -1.2527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43378716707229614
Epoch 0, Step 3183: train/loss = 0.5172340869903564, train/raw-loss = 0.47583094239234924, train/logprobs = tensor([[-0.8875, -2.2937],
        [-2.3108, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4140315353870392
Epoch 0, Step 3184: train/loss = 0.9909976124763489, train/raw-loss = 0.962990403175354, train/logprobs = tensor([[-2.2716, -3.2249],
        [-1.3401, -1.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28007131814956665
Epoch 0, Step 3185: train/loss = 0.4751913547515869, train/raw-loss = 0.43689560890197754, train/logprobs = tensor([[-1.7224, -3.6543],
        [-2.5974, -1.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38295722007751465
Epoch 0, Step 3186: train/loss = 0.2178841531276703, train/raw-loss = 0.1772354245185852, train/logprobs = tensor([[-0.9944, -6.3044],
        [-2.9883, -2.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4064873456954956
Epoch 0, Step 3187: train/loss = 0.6094900369644165, train/raw-loss = 0.5649523735046387, train/logprobs = tensor([[-1.3130, -2.7620],
        [-3.1753, -2.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44537675380706787
Epoch 0, Step 3188: train/loss = 0.5499840974807739, train/raw-loss = 0.5051150918006897, train/logprobs = tensor([[-1.5861, -9.7279],
        [-4.9156, -4.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4486902952194214
Epoch 0, Step 3189: train/loss = 0.36369645595550537, train/raw-loss = 0.3168531656265259, train/logprobs = tensor([[-1.1235, -3.6384],
        [-3.5089, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.468432754278183
Epoch 0, Step 3190: train/loss = 0.48495763540267944, train/raw-loss = 0.4365202486515045, train/logprobs = tensor([[-1.4479, -4.1917],
        [-4.6377, -2.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4843735694885254
Epoch 0, Step 3191: train/loss = 0.34586963057518005, train/raw-loss = 0.28349730372428894, train/logprobs = tensor([[-1.5800, -5.2678],
        [-6.2103, -3.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.623723566532135
Epoch 0, Step 3192: train/loss = 0.14510034024715424, train/raw-loss = 0.10542163997888565, train/logprobs = tensor([[-1.0435, -6.5946],
        [-3.5678, -2.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3967868685722351
Epoch 0, Step 3193: train/loss = 0.18232285976409912, train/raw-loss = 0.13916954398155212, train/logprobs = tensor([[-0.9869, -9.3654],
        [-4.5257, -2.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4315331280231476
Epoch 0, Step 3194: train/loss = 0.37153908610343933, train/raw-loss = 0.330153226852417, train/logprobs = tensor([[-0.9630, -5.3324],
        [-3.0578, -1.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4138585031032562
Epoch 0, Step 3195: train/loss = 0.23792824149131775, train/raw-loss = 0.19829122722148895, train/logprobs = tensor([[-1.4278, -9.1300],
        [-4.0485, -1.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3963700532913208
Epoch 0, Step 3196: train/loss = 0.29883918166160583, train/raw-loss = 0.2558740973472595, train/logprobs = tensor([[-1.4113, -4.7738],
        [-3.3162, -1.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42965078353881836
Epoch 0, Step 3197: train/loss = 0.5629257559776306, train/raw-loss = 0.514390766620636, train/logprobs = tensor([[-2.1145, -7.8204],
        [-4.6752, -3.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4853506088256836
Epoch 0, Step 3198: train/loss = 0.3924379348754883, train/raw-loss = 0.36044543981552124, train/logprobs = tensor([[-1.3088, -5.2893],
        [-2.0338, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199247717857361
Epoch 0, Step 3199: train/loss = 0.34863463044166565, train/raw-loss = 0.3115029036998749, train/logprobs = tensor([[-1.4789, -5.6097],
        [-3.8427, -1.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37131741642951965
Epoch 0, Step 3200: train/loss = 0.4138542413711548, train/raw-loss = 0.379616916179657, train/logprobs = tensor([[-0.9726, -8.9542],
        [-3.4555, -3.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3423733711242676
Epoch 0, Step 3201: train/loss = 0.30336862802505493, train/raw-loss = 0.2708192467689514, train/logprobs = tensor([[-1.2844, -6.4810],
        [-2.1269, -2.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32549405097961426
Epoch 0, Step 3202: train/loss = 0.08244707435369492, train/raw-loss = 0.039699897170066833, train/logprobs = tensor([[ -1.6640, -10.9698],
        [ -4.6064,  -2.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4274718165397644
Epoch 0, Step 3203: train/loss = 0.3641264736652374, train/raw-loss = 0.328726202249527, train/logprobs = tensor([[-1.3109, -2.8928],
        [-3.4238, -1.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35400262475013733
Epoch 0, Step 3204: train/loss = 0.17828837037086487, train/raw-loss = 0.1343572437763214, train/logprobs = tensor([[-0.9356, -4.6264],
        [-3.0822, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43931105732917786
Epoch 0, Step 3205: train/loss = 0.1503405123949051, train/raw-loss = 0.10981471091508865, train/logprobs = tensor([[-1.7303, -9.3183],
        [-4.6115, -1.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40525802969932556
Epoch 0, Step 3206: train/loss = 0.27904337644577026, train/raw-loss = 0.24518842995166779, train/logprobs = tensor([[-1.1377, -3.6250],
        [-3.7436, -0.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3385491967201233
Epoch 0, Step 3207: train/loss = 0.5654476284980774, train/raw-loss = 0.5140383839607239, train/logprobs = tensor([[-1.3871, -3.5234],
        [-3.7434, -3.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5140923857688904
Epoch 0, Step 3208: train/loss = 0.3627021014690399, train/raw-loss = 0.32463303208351135, train/logprobs = tensor([[-1.5182, -4.4195],
        [-2.8500, -2.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3806905150413513
Epoch 0, Step 3209: train/loss = 0.3302699029445648, train/raw-loss = 0.28542381525039673, train/logprobs = tensor([[-1.0711, -5.5403],
        [-3.2326, -1.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44846099615097046
Epoch 0, Step 3210: train/loss = 0.6730802655220032, train/raw-loss = 0.6281493306159973, train/logprobs = tensor([[-1.9713, -7.5891],
        [-2.5934, -2.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44930917024612427
Epoch 0, Step 3211: train/loss = 0.19470378756523132, train/raw-loss = 0.14963524043560028, train/logprobs = tensor([[-2.0743, -6.7244],
        [-6.1936, -3.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45068538188934326
Epoch 0, Step 3212: train/loss = 0.3746955692768097, train/raw-loss = 0.33404281735420227, train/logprobs = tensor([[-1.8629, -8.5540],
        [-2.7833, -1.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4065272808074951
Epoch 0, Step 3213: train/loss = 0.2798336148262024, train/raw-loss = 0.22694607079029083, train/logprobs = tensor([[-1.7821, -4.6397],
        [-4.3705, -1.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.528875470161438
Epoch 0, Step 3214: train/loss = 0.3359256386756897, train/raw-loss = 0.2970075309276581, train/logprobs = tensor([[-1.4795, -2.7205],
        [-3.1279, -1.9897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891810476779938
Epoch 0, Step 3215: train/loss = 0.3937811851501465, train/raw-loss = 0.3552245497703552, train/logprobs = tensor([[-1.1075, -3.8809],
        [-2.4782, -3.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3855665922164917
Epoch 0, Step 3216: train/loss = 0.31658226251602173, train/raw-loss = 0.28143250942230225, train/logprobs = tensor([[-1.4784, -7.7498],
        [-3.5906, -4.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514974117279053
Epoch 0, Step 3217: train/loss = 0.646502673625946, train/raw-loss = 0.5860466957092285, train/logprobs = tensor([[-1.6633, -2.9965],
        [-4.9706, -3.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6045598387718201
Epoch 0, Step 3218: train/loss = 0.4829714596271515, train/raw-loss = 0.4385391175746918, train/logprobs = tensor([[-1.6897, -7.4001],
        [-4.1069, -3.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4443235993385315
Epoch 0, Step 3219: train/loss = 0.3364538550376892, train/raw-loss = 0.2914002537727356, train/logprobs = tensor([[-0.7567, -3.6238],
        [-2.9071, -1.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45053631067276
Epoch 0, Step 3220: train/loss = 0.31645098328590393, train/raw-loss = 0.2737668454647064, train/logprobs = tensor([[ -3.5459, -10.0007],
        [ -4.1480,  -1.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4268414378166199
Epoch 0, Step 3221: train/loss = 0.1149248406291008, train/raw-loss = 0.08033972233533859, train/logprobs = tensor([[-1.3271, -6.9995],
        [-3.2993, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34585118293762207
Epoch 0, Step 3222: train/loss = 0.4012354612350464, train/raw-loss = 0.360533207654953, train/logprobs = tensor([[-1.6445, -3.2219],
        [-3.1458, -1.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4070224463939667
Epoch 0, Step 3223: train/loss = 0.0862792506814003, train/raw-loss = 0.05067542567849159, train/logprobs = tensor([[-1.0889, -9.6513],
        [-4.9827, -1.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560382127761841
Epoch 0, Step 3224: train/loss = 0.41871029138565063, train/raw-loss = 0.35553187131881714, train/logprobs = tensor([[-1.0661, -3.0530],
        [-4.3118, -2.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6317844390869141
Epoch 0, Step 3225: train/loss = 0.21465498208999634, train/raw-loss = 0.17241136729717255, train/logprobs = tensor([[-1.5875, -9.1819],
        [-3.5016, -2.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4224361181259155
Epoch 0, Step 3226: train/loss = 0.4620840549468994, train/raw-loss = 0.4196881055831909, train/logprobs = tensor([[-1.3950, -4.4073],
        [-3.4892, -1.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4239596426486969
Epoch 0, Step 3227: train/loss = 0.7706602811813354, train/raw-loss = 0.7344027161598206, train/logprobs = tensor([[-1.6377, -3.1821],
        [-1.6625, -1.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362575501203537
Epoch 0, Step 3228: train/loss = 0.3615622818470001, train/raw-loss = 0.31672412157058716, train/logprobs = tensor([[-1.3533, -4.0807],
        [-5.0175, -2.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4483813941478729
Epoch 0, Step 3229: train/loss = 0.31637921929359436, train/raw-loss = 0.27436426281929016, train/logprobs = tensor([[-1.2728, -4.9850],
        [-3.1769, -1.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42014917731285095
Epoch 0, Step 3230: train/loss = 0.5103207230567932, train/raw-loss = 0.462038516998291, train/logprobs = tensor([[-0.8980, -3.8662],
        [-2.8412, -2.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48282214999198914
Epoch 0, Step 3231: train/loss = 0.655316174030304, train/raw-loss = 0.6166034936904907, train/logprobs = tensor([[-1.9497, -6.4451],
        [-2.6022, -2.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38712674379348755
Epoch 0, Step 3232: train/loss = 0.16411520540714264, train/raw-loss = 0.12278477847576141, train/logprobs = tensor([[-1.0521, -6.4784],
        [-3.7603, -1.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4133041799068451
Epoch 0, Step 3233: train/loss = 0.19459088146686554, train/raw-loss = 0.1581083983182907, train/logprobs = tensor([[-1.5157, -5.8262],
        [-3.5876, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36482474207878113
Epoch 0, Step 3234: train/loss = 0.21741457283496857, train/raw-loss = 0.16659094393253326, train/logprobs = tensor([[-1.1523, -7.8108],
        [-4.5587, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5082361698150635
Epoch 0, Step 3235: train/loss = 0.24225091934204102, train/raw-loss = 0.19993045926094055, train/logprobs = tensor([[-1.3358, -5.6767],
        [-5.4486, -2.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42320454120635986
Epoch 0, Step 3236: train/loss = 0.2732149362564087, train/raw-loss = 0.2323395162820816, train/logprobs = tensor([[-1.2409, -3.7764],
        [-3.3218, -2.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40875405073165894
Epoch 0, Step 3237: train/loss = 0.2508541941642761, train/raw-loss = 0.20880421996116638, train/logprobs = tensor([[-1.1318, -9.6996],
        [-3.4947, -3.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4204997420310974
Epoch 0, Step 3238: train/loss = 0.2845030128955841, train/raw-loss = 0.2449415922164917, train/logprobs = tensor([[-1.6363, -7.3820],
        [-3.6133, -3.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39561426639556885
Epoch 0, Step 3239: train/loss = 0.3428884446620941, train/raw-loss = 0.29984408617019653, train/logprobs = tensor([[-1.3420, -7.9800],
        [-4.9932, -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43044376373291016
Epoch 0, Step 3240: train/loss = 0.2634849548339844, train/raw-loss = 0.21993209421634674, train/logprobs = tensor([[-0.9893, -7.1359],
        [-3.8762, -2.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43552863597869873
Epoch 0, Step 3241: train/loss = 0.39078187942504883, train/raw-loss = 0.3543663024902344, train/logprobs = tensor([[-1.2369, -7.8360],
        [-2.5082, -3.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3641558289527893
Epoch 0, Step 3242: train/loss = 0.2203148901462555, train/raw-loss = 0.16979342699050903, train/logprobs = tensor([[-1.2827, -7.9348],
        [-5.2082, -2.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5052146911621094
Epoch 0, Step 3243: train/loss = 0.478180468082428, train/raw-loss = 0.44496431946754456, train/logprobs = tensor([[-1.2406, -2.5493],
        [-1.8498, -1.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321612775325775
Epoch 0, Step 3244: train/loss = 0.6321665644645691, train/raw-loss = 0.5833393931388855, train/logprobs = tensor([[-1.7862, -4.3339],
        [-3.6344, -2.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48827144503593445
Epoch 0, Step 3245: train/loss = 0.38059282302856445, train/raw-loss = 0.33582374453544617, train/logprobs = tensor([[-1.2354, -3.8860],
        [-2.8970, -2.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4476909637451172
Epoch 0, Step 3246: train/loss = 0.11408697813749313, train/raw-loss = 0.07114895433187485, train/logprobs = tensor([[ -1.0146, -10.4264],
        [ -3.6521,  -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4293803572654724
Epoch 0, Step 3247: train/loss = 0.3583917021751404, train/raw-loss = 0.32383835315704346, train/logprobs = tensor([[-1.9149, -6.3015],
        [-3.3547, -2.1646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34553349018096924
Epoch 0, Step 3248: train/loss = 0.590555727481842, train/raw-loss = 0.5534818172454834, train/logprobs = tensor([[-2.1822, -2.3565],
        [-2.5633, -1.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37073880434036255
Epoch 0, Step 3249: train/loss = 0.33583417534828186, train/raw-loss = 0.29734334349632263, train/logprobs = tensor([[-1.0885, -7.5139],
        [-3.9615, -1.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38490819931030273
Epoch 0, Step 3250: train/loss = 0.5415445566177368, train/raw-loss = 0.4932926595211029, train/logprobs = tensor([[-1.4682, -3.1865],
        [-3.2352, -2.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4825185537338257
Epoch 0, Step 3251: train/loss = 0.4321815073490143, train/raw-loss = 0.38033002614974976, train/logprobs = tensor([[-1.3696, -5.1040],
        [-3.2399, -2.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5185149908065796
Epoch 0, Step 3252: train/loss = 0.6229104399681091, train/raw-loss = 0.5702996850013733, train/logprobs = tensor([[-1.1470, -2.3323],
        [-3.7526, -2.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.526107907295227
Epoch 0, Step 3253: train/loss = 0.3938785195350647, train/raw-loss = 0.35877400636672974, train/logprobs = tensor([[-0.7909, -4.7284],
        [-2.8894, -2.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3510451018810272
Epoch 0, Step 3254: train/loss = 0.3023912012577057, train/raw-loss = 0.2509796619415283, train/logprobs = tensor([[-0.6629, -6.6587],
        [-3.0226, -1.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141151547431946
Epoch 0, Step 3255: train/loss = 0.3755008578300476, train/raw-loss = 0.3362157940864563, train/logprobs = tensor([[-1.5928, -5.1194],
        [-2.4966, -1.6410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39285069704055786
Epoch 0, Step 3256: train/loss = 0.37402740120887756, train/raw-loss = 0.322240948677063, train/logprobs = tensor([[-1.0145, -5.4998],
        [-4.6504, -2.5386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5178644061088562
Epoch 0, Step 3257: train/loss = 0.4224208891391754, train/raw-loss = 0.38432615995407104, train/logprobs = tensor([[-1.5108, -3.2545],
        [-3.9233, -1.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3809473514556885
Epoch 0, Step 3258: train/loss = 0.426583468914032, train/raw-loss = 0.38749587535858154, train/logprobs = tensor([[-1.1456, -3.4531],
        [-3.3061, -1.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390875905752182
Epoch 0, Step 3259: train/loss = 0.22956635057926178, train/raw-loss = 0.1930510252714157, train/logprobs = tensor([[ -1.3494, -12.1340],
        [ -3.6296,  -4.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651532232761383
Epoch 0, Step 3260: train/loss = 0.3134786784648895, train/raw-loss = 0.2675343155860901, train/logprobs = tensor([[-1.3235, -4.0192],
        [-4.0193, -2.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45944374799728394
Epoch 0, Step 3261: train/loss = 0.540728747844696, train/raw-loss = 0.5011736750602722, train/logprobs = tensor([[-0.8677, -1.8155],
        [-2.4794, -1.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39555031061172485
Epoch 0, Step 3262: train/loss = 0.47289782762527466, train/raw-loss = 0.43541550636291504, train/logprobs = tensor([[-0.7975, -2.9235],
        [-1.9767, -1.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37482303380966187
Epoch 0, Step 3263: train/loss = 0.5150466561317444, train/raw-loss = 0.47545748949050903, train/logprobs = tensor([[-1.5887, -3.0952],
        [-2.9413, -2.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39589133858680725
Epoch 0, Step 3264: train/loss = 0.5397563576698303, train/raw-loss = 0.4987501800060272, train/logprobs = tensor([[-1.3931, -2.5360],
        [-2.8997, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41006138920783997
Epoch 0, Step 3265: train/loss = 0.30975842475891113, train/raw-loss = 0.2665793299674988, train/logprobs = tensor([[-1.6589, -8.0110],
        [-3.7933, -4.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43179091811180115
Epoch 0, Step 3266: train/loss = 0.18731898069381714, train/raw-loss = 0.1493254005908966, train/logprobs = tensor([[-1.2101, -8.3016],
        [-3.1055, -2.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799356520175934
Epoch 0, Step 3267: train/loss = 0.5646967887878418, train/raw-loss = 0.5125805735588074, train/logprobs = tensor([[-1.2163, -3.4037],
        [-4.8893, -2.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5211626291275024
Epoch 0, Step 3268: train/loss = 0.20053592324256897, train/raw-loss = 0.1604333370923996, train/logprobs = tensor([[-1.3151, -9.9881],
        [-4.9853, -1.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40102583169937134
Epoch 0, Step 3269: train/loss = 0.5148355960845947, train/raw-loss = 0.47143274545669556, train/logprobs = tensor([[-1.0878, -2.3688],
        [-2.1967, -1.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4340287744998932
Epoch 0, Step 3270: train/loss = 0.3151075541973114, train/raw-loss = 0.2688262462615967, train/logprobs = tensor([[-1.2730, -8.0089],
        [-3.6638, -4.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46281296014785767
Epoch 0, Step 3271: train/loss = 0.353303998708725, train/raw-loss = 0.3091285228729248, train/logprobs = tensor([[-1.2488, -5.6694],
        [-3.8424, -1.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44175487756729126
Epoch 0, Step 3272: train/loss = 0.3749825358390808, train/raw-loss = 0.3353618085384369, train/logprobs = tensor([[-1.0587, -4.2182],
        [-2.3017, -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39620715379714966
Epoch 0, Step 3273: train/loss = 0.6152457594871521, train/raw-loss = 0.5742272734642029, train/logprobs = tensor([[-1.3513, -6.4288],
        [-3.2631, -2.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41018491983413696
Epoch 0, Step 3274: train/loss = 0.06173812597990036, train/raw-loss = 0.016155622899532318, train/logprobs = tensor([[-1.7991, -7.7940],
        [-6.2906, -2.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45582500100135803
Epoch 0, Step 3275: train/loss = 0.42138242721557617, train/raw-loss = 0.3683900237083435, train/logprobs = tensor([[-0.8283, -4.5853],
        [-3.3822, -1.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5299240350723267
Epoch 0, Step 3276: train/loss = 0.16955536603927612, train/raw-loss = 0.1189679503440857, train/logprobs = tensor([[-1.6222, -6.1761],
        [-5.6326, -2.3729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5058741569519043
Epoch 0, Step 3277: train/loss = 0.2948504090309143, train/raw-loss = 0.26061761379241943, train/logprobs = tensor([[ -1.6689, -10.8708],
        [ -2.6636,  -2.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34232795238494873
Epoch 0, Step 3278: train/loss = 0.15624907612800598, train/raw-loss = 0.1041901707649231, train/logprobs = tensor([[-1.4559, -6.4567],
        [-5.2513, -3.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5205889940261841
Epoch 0, Step 3279: train/loss = 0.17328952252864838, train/raw-loss = 0.12732169032096863, train/logprobs = tensor([[-1.3355, -5.7477],
        [-3.4051, -1.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45967838168144226
Epoch 0, Step 3280: train/loss = 0.33292511105537415, train/raw-loss = 0.28673094511032104, train/logprobs = tensor([[-1.5772, -7.9709],
        [-3.5314, -1.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46194177865982056
Epoch 0, Step 3281: train/loss = 0.4852777421474457, train/raw-loss = 0.44901594519615173, train/logprobs = tensor([[-2.0544, -6.7047],
        [-2.2426, -1.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36261776089668274
Epoch 0, Step 3282: train/loss = 0.5216799974441528, train/raw-loss = 0.4914727807044983, train/logprobs = tensor([[-3.0814, -8.6749],
        [-3.5927, -3.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020722270011902
Epoch 0, Step 3283: train/loss = 0.1030009463429451, train/raw-loss = 0.05605735257267952, train/logprobs = tensor([[ -0.9253, -10.2109],
        [ -3.8710,  -2.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4694358706474304
Epoch 0, Step 3284: train/loss = 0.5933017730712891, train/raw-loss = 0.5607618689537048, train/logprobs = tensor([[-1.2299, -2.4983],
        [-1.5991, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.325398713350296
Epoch 0, Step 3285: train/loss = 0.33364665508270264, train/raw-loss = 0.2892632484436035, train/logprobs = tensor([[-1.8263, -3.3505],
        [-4.4857, -2.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443834125995636
Epoch 0, Step 3286: train/loss = 0.5370301604270935, train/raw-loss = 0.4880918562412262, train/logprobs = tensor([[-1.6745, -3.5780],
        [-3.7408, -2.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48938295245170593
Epoch 0, Step 3287: train/loss = 0.21480567753314972, train/raw-loss = 0.16527529060840607, train/logprobs = tensor([[-1.7088, -9.3473],
        [-5.4047, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.495303750038147
Epoch 0, Step 3288: train/loss = 0.30500513315200806, train/raw-loss = 0.27399468421936035, train/logprobs = tensor([[-1.6755, -6.6471],
        [-3.5380, -1.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101045489311218
Epoch 0, Step 3289: train/loss = 0.4289311170578003, train/raw-loss = 0.39463257789611816, train/logprobs = tensor([[-1.7445, -3.4830],
        [-2.5192, -1.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34298521280288696
Epoch 0, Step 3290: train/loss = 0.15060801804065704, train/raw-loss = 0.10875166952610016, train/logprobs = tensor([[ -1.9998, -13.1067],
        [ -4.8388,  -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.418563574552536
Epoch 0, Step 3291: train/loss = 0.521228551864624, train/raw-loss = 0.4657571315765381, train/logprobs = tensor([[-1.0240, -5.8765],
        [-3.2467, -1.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5547140836715698
Epoch 0, Step 3292: train/loss = 0.5279443860054016, train/raw-loss = 0.4822100102901459, train/logprobs = tensor([[-1.0596, -2.6645],
        [-3.0440, -2.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45734384655952454
Epoch 0, Step 3293: train/loss = 0.1786634624004364, train/raw-loss = 0.13931354880332947, train/logprobs = tensor([[-2.0396, -9.1865],
        [-4.5304, -1.2624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3934992253780365
Epoch 0, Step 3294: train/loss = 0.1514405906200409, train/raw-loss = 0.11212487518787384, train/logprobs = tensor([[-1.4307, -7.8019],
        [-3.8414, -1.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931572139263153
Epoch 0, Step 3295: train/loss = 0.33097970485687256, train/raw-loss = 0.2839885950088501, train/logprobs = tensor([[-1.1140, -8.7251],
        [-3.0615, -3.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4699113368988037
Epoch 0, Step 3296: train/loss = 0.3475087881088257, train/raw-loss = 0.3070399761199951, train/logprobs = tensor([[-2.3293, -3.7493],
        [-4.1001, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40468844771385193
Epoch 0, Step 3297: train/loss = 0.8413625955581665, train/raw-loss = 0.7986910343170166, train/logprobs = tensor([[-4.1408, -7.8948],
        [-2.8273, -1.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42671507596969604
Epoch 0, Step 3298: train/loss = 0.17597097158432007, train/raw-loss = 0.13401181995868683, train/logprobs = tensor([[-1.0613, -9.4453],
        [-4.4949, -3.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41959136724472046
Epoch 0, Step 3299: train/loss = 0.29819831252098083, train/raw-loss = 0.2546367943286896, train/logprobs = tensor([[-1.2367, -4.4881],
        [-3.6271, -1.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4356151819229126
Epoch 0, Step 3300: train/loss = 0.3461833894252777, train/raw-loss = 0.30453699827194214, train/logprobs = tensor([[-1.8666, -4.3580],
        [-4.1516, -2.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4164642095565796
Epoch 0, Step 3301: train/loss = 0.32297325134277344, train/raw-loss = 0.28546711802482605, train/logprobs = tensor([[-0.9797, -4.9734],
        [-2.1336, -1.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37506115436553955
Epoch 0, Step 3302: train/loss = 0.5791985392570496, train/raw-loss = 0.5446217656135559, train/logprobs = tensor([[-2.5430, -7.9214],
        [-2.8486, -2.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457673490047455
Epoch 0, Step 3303: train/loss = 0.20893768966197968, train/raw-loss = 0.17319869995117188, train/logprobs = tensor([[-0.7566, -5.0568],
        [-2.8611, -1.7500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35738977789878845
Epoch 0, Step 3304: train/loss = 0.10864673554897308, train/raw-loss = 0.06084079295396805, train/logprobs = tensor([[-1.5204, -8.3297],
        [-6.0492, -2.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4780593514442444
Epoch 0, Step 3305: train/loss = 0.27810239791870117, train/raw-loss = 0.234182208776474, train/logprobs = tensor([[-1.6266, -5.4869],
        [-3.8036, -2.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43920189142227173
Epoch 0, Step 3306: train/loss = 0.2929697334766388, train/raw-loss = 0.2548177242279053, train/logprobs = tensor([[-1.4133, -9.7684],
        [-3.1563, -3.3432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3815203905105591
Epoch 0, Step 3307: train/loss = 0.1790979951620102, train/raw-loss = 0.14413584768772125, train/logprobs = tensor([[-1.2728, -8.4346],
        [-3.7747, -2.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34962138533592224
Epoch 0, Step 3308: train/loss = 0.23685455322265625, train/raw-loss = 0.20063169300556183, train/logprobs = tensor([[-1.1457, -9.4225],
        [-3.5747, -2.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3622285723686218
Epoch 0, Step 3309: train/loss = 0.5324375629425049, train/raw-loss = 0.4931629002094269, train/logprobs = tensor([[-2.3085, -5.0236],
        [-3.9934, -2.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3927467465400696
Epoch 0, Step 3310: train/loss = 0.11595616489648819, train/raw-loss = 0.06812218576669693, train/logprobs = tensor([[-0.9695, -8.6336],
        [-3.9487, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4783397912979126
Epoch 0, Step 3311: train/loss = 0.22380807995796204, train/raw-loss = 0.18815673887729645, train/logprobs = tensor([[-1.4068, -7.7658],
        [-3.1108, -2.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3565133512020111
Epoch 0, Step 3312: train/loss = 0.1172584593296051, train/raw-loss = 0.07747666537761688, train/logprobs = tensor([[ -1.4720, -10.2839],
        [ -4.4697,  -3.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39781785011291504
Epoch 0, Step 3313: train/loss = 0.10280440002679825, train/raw-loss = 0.056484155356884, train/logprobs = tensor([[-1.2040, -7.0365],
        [-4.4031, -2.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46320244669914246
Epoch 0, Step 3314: train/loss = 0.38512712717056274, train/raw-loss = 0.34375467896461487, train/logprobs = tensor([[-1.7524, -4.5558],
        [-4.6488, -2.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4137246608734131
Epoch 0, Step 3315: train/loss = 0.5819756388664246, train/raw-loss = 0.55359947681427, train/logprobs = tensor([[-1.1220, -1.3232],
        [-2.0241, -1.3855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837618291378021
Epoch 0, Step 3316: train/loss = 0.18985961377620697, train/raw-loss = 0.15203869342803955, train/logprobs = tensor([[-1.1676, -7.9692],
        [-3.0964, -1.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37820929288864136
Epoch 0, Step 3317: train/loss = 0.408277302980423, train/raw-loss = 0.3722090423107147, train/logprobs = tensor([[-1.8968, -7.7763],
        [-3.8470, -3.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606828451156616
Epoch 0, Step 3318: train/loss = 0.15456001460552216, train/raw-loss = 0.1086946427822113, train/logprobs = tensor([[-0.9541, -7.6724],
        [-3.5602, -2.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45865365862846375
Epoch 0, Step 3319: train/loss = 0.3451662063598633, train/raw-loss = 0.28943124413490295, train/logprobs = tensor([[-1.8453, -7.0653],
        [-4.3544, -2.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5573497414588928
Epoch 0, Step 3320: train/loss = 0.5346354246139526, train/raw-loss = 0.49084192514419556, train/logprobs = tensor([[-1.6683, -3.7504],
        [-3.5562, -2.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4379348158836365
Epoch 0, Step 3321: train/loss = 0.10735835134983063, train/raw-loss = 0.06202361360192299, train/logprobs = tensor([[ -1.7280, -12.1436],
        [ -4.4373,  -1.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45334741473197937
Epoch 0, Step 3322: train/loss = 0.3058280050754547, train/raw-loss = 0.2746489644050598, train/logprobs = tensor([[-1.2331, -5.8963],
        [-2.5211, -1.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.311790406703949
Epoch 0, Step 3323: train/loss = 0.7186914682388306, train/raw-loss = 0.6794148683547974, train/logprobs = tensor([[-3.1410, -3.5971],
        [-3.6039, -1.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39276599884033203
Epoch 0, Step 3324: train/loss = 0.3458813726902008, train/raw-loss = 0.3118041455745697, train/logprobs = tensor([[-1.8161, -4.8779],
        [-3.6515, -0.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3407721221446991
Epoch 0, Step 3325: train/loss = 0.3906370997428894, train/raw-loss = 0.35798609256744385, train/logprobs = tensor([[-1.9957, -5.4740],
        [-2.0827, -1.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3265102207660675
Epoch 0, Step 3326: train/loss = 0.823860764503479, train/raw-loss = 0.7870339751243591, train/logprobs = tensor([[-4.5263, -9.5430],
        [-2.9645, -2.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36826789379119873
Epoch 0, Step 3327: train/loss = 0.10685347765684128, train/raw-loss = 0.05529695376753807, train/logprobs = tensor([[ -1.3891, -11.2759],
        [ -4.7152,  -3.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5155652761459351
Epoch 0, Step 3328: train/loss = 0.5104340314865112, train/raw-loss = 0.4676739573478699, train/logprobs = tensor([[-0.9820, -2.0094],
        [-2.6826, -2.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4276008605957031
Epoch 0, Step 3329: train/loss = 0.45411697030067444, train/raw-loss = 0.4146222472190857, train/logprobs = tensor([[-1.6143, -4.4620],
        [-1.9968, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39494720101356506
Epoch 0, Step 3330: train/loss = 0.7506201863288879, train/raw-loss = 0.7028825283050537, train/logprobs = tensor([[-1.9478, -3.5364],
        [-2.8734, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47737640142440796
Epoch 0, Step 3331: train/loss = 0.3339337110519409, train/raw-loss = 0.287506639957428, train/logprobs = tensor([[-1.1030, -4.5787],
        [-2.6986, -2.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4642706513404846
Epoch 0, Step 3332: train/loss = 0.3627190589904785, train/raw-loss = 0.3305218815803528, train/logprobs = tensor([[-1.1337, -8.0740],
        [-2.3226, -3.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32197171449661255
Epoch 0, Step 3333: train/loss = 0.36915621161460876, train/raw-loss = 0.3334360420703888, train/logprobs = tensor([[-1.3194, -6.8878],
        [-3.2436, -2.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3572017550468445
Epoch 0, Step 3334: train/loss = 0.291520357131958, train/raw-loss = 0.2493980973958969, train/logprobs = tensor([[-1.0995, -5.3880],
        [-2.8539, -1.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42122262716293335
Epoch 0, Step 3335: train/loss = 0.2519230842590332, train/raw-loss = 0.21715429425239563, train/logprobs = tensor([[-1.3455, -7.1105],
        [-2.5934, -1.3957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34768781065940857
Epoch 0, Step 3336: train/loss = 0.211609348654747, train/raw-loss = 0.17365862429141998, train/logprobs = tensor([[-1.7603, -6.6019],
        [-3.1791, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37950727343559265
Epoch 0, Step 3337: train/loss = 0.5731374025344849, train/raw-loss = 0.5300949811935425, train/logprobs = tensor([[-1.3302, -2.2382],
        [-2.1854, -1.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43042418360710144
Epoch 0, Step 3338: train/loss = 0.21039505302906036, train/raw-loss = 0.17818622291088104, train/logprobs = tensor([[-0.6990, -8.5291],
        [-2.5501, -2.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.322088360786438
Epoch 0, Step 3339: train/loss = 0.26873016357421875, train/raw-loss = 0.23320162296295166, train/logprobs = tensor([[-1.3480, -4.6962],
        [-2.7981, -1.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35528525710105896
Epoch 0, Step 3340: train/loss = 0.3637234568595886, train/raw-loss = 0.318422794342041, train/logprobs = tensor([[-0.7840, -5.6129],
        [-2.6832, -2.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4530063271522522
Epoch 0, Step 3341: train/loss = 0.5441721677780151, train/raw-loss = 0.5148943662643433, train/logprobs = tensor([[-1.8852, -2.6350],
        [-1.8038, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29277852177619934
Epoch 0, Step 3342: train/loss = 0.41546541452407837, train/raw-loss = 0.377804696559906, train/logprobs = tensor([[-1.5268, -6.8410],
        [-3.3621, -1.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3766072690486908
Epoch 0, Step 3343: train/loss = 0.4544747471809387, train/raw-loss = 0.41460371017456055, train/logprobs = tensor([[-1.5944, -4.1194],
        [-3.2183, -1.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39871013164520264
Epoch 0, Step 3344: train/loss = 0.21807733178138733, train/raw-loss = 0.1819705069065094, train/logprobs = tensor([[-2.2546, -7.8503],
        [-3.9111, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610682487487793
Epoch 0, Step 3345: train/loss = 0.4187321662902832, train/raw-loss = 0.3678753077983856, train/logprobs = tensor([[-0.9070, -7.2958],
        [-3.5501, -3.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5085683465003967
Epoch 0, Step 3346: train/loss = 0.4229022264480591, train/raw-loss = 0.38232406973838806, train/logprobs = tensor([[-1.6318, -4.1541],
        [-2.3394, -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40578144788742065
Epoch 0, Step 3347: train/loss = 0.6433492302894592, train/raw-loss = 0.5967937111854553, train/logprobs = tensor([[-1.4013, -5.3918],
        [-3.5486, -2.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4655555486679077
Epoch 0, Step 3348: train/loss = 0.3577014207839966, train/raw-loss = 0.3143143653869629, train/logprobs = tensor([[-1.0331, -8.9559],
        [-3.7227, -2.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4338703453540802
Epoch 0, Step 3349: train/loss = 0.19702142477035522, train/raw-loss = 0.15111732482910156, train/logprobs = tensor([[ -1.0657, -10.0358],
        [ -3.9931,  -1.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4590409994125366
Epoch 0, Step 3350: train/loss = 0.11724749207496643, train/raw-loss = 0.07310528308153152, train/logprobs = tensor([[-1.0895, -6.0230],
        [-3.6952, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4414219856262207
Epoch 0, Step 3351: train/loss = 0.4484580159187317, train/raw-loss = 0.4011775851249695, train/logprobs = tensor([[-1.5429, -4.3355],
        [-3.4848, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4728040397167206
Epoch 0, Step 3352: train/loss = 0.33845454454421997, train/raw-loss = 0.29479914903640747, train/logprobs = tensor([[-1.2613, -4.3148],
        [-3.6678, -1.3822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4365538954734802
Epoch 0, Step 3353: train/loss = 0.8022279143333435, train/raw-loss = 0.7482514381408691, train/logprobs = tensor([[-1.2865, -1.8117],
        [-2.6731, -2.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5397641658782959
Epoch 0, Step 3354: train/loss = 0.339842289686203, train/raw-loss = 0.30736544728279114, train/logprobs = tensor([[-1.4363, -5.6421],
        [-2.5747, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3247682750225067
Epoch 0, Step 3355: train/loss = 0.3075937330722809, train/raw-loss = 0.26245611906051636, train/logprobs = tensor([[-1.7866, -9.9428],
        [-4.8540, -2.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45137646794319153
Epoch 0, Step 3356: train/loss = 0.3976081907749176, train/raw-loss = 0.3638700246810913, train/logprobs = tensor([[-1.3865, -6.7005],
        [-2.5560, -1.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373818099498749
Epoch 0, Step 3357: train/loss = 0.5744038820266724, train/raw-loss = 0.5399374961853027, train/logprobs = tensor([[-1.7230, -3.3007],
        [-2.0514, -2.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34466391801834106
Epoch 0, Step 3358: train/loss = 0.07551361620426178, train/raw-loss = 0.03265538439154625, train/logprobs = tensor([[ -1.1268, -13.5682],
        [ -4.7283,  -4.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4285823702812195
Epoch 0, Step 3359: train/loss = 0.2585929334163666, train/raw-loss = 0.21655233204364777, train/logprobs = tensor([[-1.4063, -9.8799],
        [-3.7683, -3.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4204058349132538
Epoch 0, Step 3360: train/loss = 0.48118555545806885, train/raw-loss = 0.44988372921943665, train/logprobs = tensor([[-1.7648, -4.9882],
        [-2.1131, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31301793456077576
Epoch 0, Step 3361: train/loss = 0.3401467800140381, train/raw-loss = 0.3049469292163849, train/logprobs = tensor([[-1.2589, -7.2334],
        [-2.9901, -4.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35199838876724243
Epoch 0, Step 3362: train/loss = 0.10736390948295593, train/raw-loss = 0.06630440056324005, train/logprobs = tensor([[-0.7556, -9.1745],
        [-3.3941, -3.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105950593948364
Epoch 0, Step 3363: train/loss = 0.10000215470790863, train/raw-loss = 0.058121271431446075, train/logprobs = tensor([[-1.2917, -4.8507],
        [-4.1953, -0.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41880881786346436
Epoch 0, Step 3364: train/loss = 0.10944773256778717, train/raw-loss = 0.07415036112070084, train/logprobs = tensor([[-1.2129, -6.2394],
        [-3.6892, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35297369956970215
Epoch 0, Step 3365: train/loss = 0.09024864435195923, train/raw-loss = 0.053314488381147385, train/logprobs = tensor([[ -1.4792, -11.3626],
        [ -4.7457,  -1.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36934152245521545
Epoch 0, Step 3366: train/loss = 0.5023477077484131, train/raw-loss = 0.46079161763191223, train/logprobs = tensor([[-0.8863, -4.5408],
        [-2.9650, -1.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155612885951996
Epoch 0, Step 3367: train/loss = 0.7333170175552368, train/raw-loss = 0.6990857124328613, train/logprobs = tensor([[-0.9516, -0.8868],
        [-2.0978, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3423125147819519
Epoch 0, Step 3368: train/loss = 0.16557782888412476, train/raw-loss = 0.11336006224155426, train/logprobs = tensor([[ -1.9130, -12.1593],
        [ -5.7900,  -3.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5221777558326721
Epoch 0, Step 3369: train/loss = 0.22538532316684723, train/raw-loss = 0.18897956609725952, train/logprobs = tensor([[-1.2343, -6.2715],
        [-3.9026, -1.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3640575408935547
Epoch 0, Step 3370: train/loss = 0.19560784101486206, train/raw-loss = 0.15225455164909363, train/logprobs = tensor([[ -1.2091, -10.3666],
        [ -3.0373,  -1.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335326552391052
Epoch 0, Step 3371: train/loss = 0.14004923403263092, train/raw-loss = 0.09888344258069992, train/logprobs = tensor([[-1.1684, -8.1269],
        [-3.2822, -1.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4116578996181488
Epoch 0, Step 3372: train/loss = 0.25087970495224, train/raw-loss = 0.21204440295696259, train/logprobs = tensor([[-1.9351, -6.9480],
        [-3.6535, -1.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3883529007434845
Epoch 0, Step 3373: train/loss = 0.3796681761741638, train/raw-loss = 0.3382973074913025, train/logprobs = tensor([[-1.7768, -6.4197],
        [-4.0514, -1.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.413708359003067
Epoch 0, Step 3374: train/loss = 0.39763981103897095, train/raw-loss = 0.3578066825866699, train/logprobs = tensor([[-1.5492, -4.9242],
        [-4.3229, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3983317017555237
Epoch 0, Step 3375: train/loss = 0.4250427484512329, train/raw-loss = 0.3852752149105072, train/logprobs = tensor([[-1.6033, -3.2377],
        [-1.9799, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3976752758026123
Epoch 0, Step 3376: train/loss = 0.28345832228660583, train/raw-loss = 0.2460705190896988, train/logprobs = tensor([[-0.9537, -6.8162],
        [-2.7662, -1.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37387800216674805
Epoch 0, Step 3377: train/loss = 0.2761075794696808, train/raw-loss = 0.23493240773677826, train/logprobs = tensor([[-2.3479, -8.1121],
        [-4.2785, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41175147891044617
Epoch 0, Step 3378: train/loss = 0.3299778401851654, train/raw-loss = 0.28839436173439026, train/logprobs = tensor([[-1.1977, -4.7245],
        [-3.1661, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158347249031067
Epoch 0, Step 3379: train/loss = 0.3829423785209656, train/raw-loss = 0.34802818298339844, train/logprobs = tensor([[-1.2086, -4.8545],
        [-2.1051, -0.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34914183616638184
Epoch 0, Step 3380: train/loss = 0.31987670063972473, train/raw-loss = 0.2780885696411133, train/logprobs = tensor([[-1.7233, -4.2033],
        [-3.4358, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41788148880004883
Epoch 0, Step 3381: train/loss = 0.21691641211509705, train/raw-loss = 0.17473700642585754, train/logprobs = tensor([[-1.4682, -4.6743],
        [-3.7388, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217941164970398
Epoch 0, Step 3382: train/loss = 0.55686354637146, train/raw-loss = 0.5213406682014465, train/logprobs = tensor([[-1.1559, -3.3936],
        [-3.6924, -2.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3552287220954895
Epoch 0, Step 3383: train/loss = 0.21959960460662842, train/raw-loss = 0.17794345319271088, train/logprobs = tensor([[-1.8072, -9.3336],
        [-3.8468, -2.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41656172275543213
Epoch 0, Step 3384: train/loss = 0.20160475373268127, train/raw-loss = 0.1580318659543991, train/logprobs = tensor([[ -2.5821, -10.7054],
        [ -5.2327,  -2.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43572890758514404
Epoch 0, Step 3385: train/loss = 0.20013569295406342, train/raw-loss = 0.16147951781749725, train/logprobs = tensor([[ -1.4395, -10.1095],
        [ -4.9613,  -1.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38656169176101685
Epoch 0, Step 3386: train/loss = 0.07999001443386078, train/raw-loss = 0.038233909755945206, train/logprobs = tensor([[-1.0290, -7.6350],
        [-3.6920, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41756102442741394
Epoch 0, Step 3387: train/loss = 0.3978714644908905, train/raw-loss = 0.3546295762062073, train/logprobs = tensor([[-1.7944, -6.3741],
        [-3.2630, -2.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4324190616607666
Epoch 0, Step 3388: train/loss = 0.06177849322557449, train/raw-loss = 0.01751028187572956, train/logprobs = tensor([[-1.5099, -7.7518],
        [-5.2380, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4426821172237396
Epoch 0, Step 3389: train/loss = 0.26065489649772644, train/raw-loss = 0.21666543185710907, train/logprobs = tensor([[-1.1736, -3.6255],
        [-3.7667, -1.6050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4398946464061737
Epoch 0, Step 3390: train/loss = 0.4462532699108124, train/raw-loss = 0.40911996364593506, train/logprobs = tensor([[-1.6434, -4.5113],
        [-2.0939, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3713327646255493
Epoch 0, Step 3391: train/loss = 0.6417216062545776, train/raw-loss = 0.6009914875030518, train/logprobs = tensor([[-1.9774, -2.0367],
        [-2.9065, -2.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4073011577129364
Epoch 0, Step 3392: train/loss = 0.39016714692115784, train/raw-loss = 0.36040738224983215, train/logprobs = tensor([[-1.4032, -4.9498],
        [-2.0591, -2.3915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29759782552719116
Epoch 0, Step 3393: train/loss = 0.532840371131897, train/raw-loss = 0.5043128132820129, train/logprobs = tensor([[-2.0606, -9.5637],
        [-1.8117, -0.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28527510166168213
Epoch 0, Step 3394: train/loss = 0.5168383121490479, train/raw-loss = 0.4735665023326874, train/logprobs = tensor([[-1.9199, -3.8702],
        [-2.4879, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4327181577682495
Epoch 0, Step 3395: train/loss = 0.6537010073661804, train/raw-loss = 0.6124491095542908, train/logprobs = tensor([[-1.6726, -6.5017],
        [-3.3103, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4125192165374756
Epoch 0, Step 3396: train/loss = 0.4289500117301941, train/raw-loss = 0.3848622739315033, train/logprobs = tensor([[-0.9562, -9.3846],
        [-3.7708, -4.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4408775568008423
Epoch 0, Step 3397: train/loss = 0.2339906394481659, train/raw-loss = 0.20057256519794464, train/logprobs = tensor([[-1.1660, -5.7607],
        [-3.2976, -1.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341807723045349
Epoch 0, Step 3398: train/loss = 0.4363349378108978, train/raw-loss = 0.404660165309906, train/logprobs = tensor([[-1.1212, -3.3516],
        [-1.7842, -1.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3167474865913391
Epoch 0, Step 3399: train/loss = 0.6970412731170654, train/raw-loss = 0.6585109233856201, train/logprobs = tensor([[-2.3512, -3.1037],
        [-2.3313, -1.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38530340790748596
Epoch 0, Step 3400: train/loss = 0.6759083271026611, train/raw-loss = 0.6333752274513245, train/logprobs = tensor([[-0.9772, -1.5112],
        [-2.3715, -1.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4253315329551697
Epoch 0, Step 3401: train/loss = 0.22121214866638184, train/raw-loss = 0.1825670599937439, train/logprobs = tensor([[ -1.2691, -12.7046],
        [ -3.2557,  -2.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3864506781101227
Epoch 0, Step 3402: train/loss = 0.17215582728385925, train/raw-loss = 0.13475695252418518, train/logprobs = tensor([[-1.7313, -8.6439],
        [-3.6911, -2.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3739888072013855
Epoch 0, Step 3403: train/loss = 0.5375490188598633, train/raw-loss = 0.5014165639877319, train/logprobs = tensor([[-1.7656, -2.9731],
        [-2.3486, -1.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3613241910934448
Epoch 0, Step 3404: train/loss = 0.15486465394496918, train/raw-loss = 0.11078497767448425, train/logprobs = tensor([[-1.2684, -5.9246],
        [-3.9905, -2.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44079676270484924
Epoch 0, Step 3405: train/loss = 0.2849982976913452, train/raw-loss = 0.24996256828308105, train/logprobs = tensor([[-1.2961, -9.3085],
        [-3.9864, -1.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3503572940826416
Epoch 0, Step 3406: train/loss = 0.36608752608299255, train/raw-loss = 0.32799768447875977, train/logprobs = tensor([[-1.2837, -8.2100],
        [-2.0624, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38089829683303833
Epoch 0, Step 3407: train/loss = 0.45907241106033325, train/raw-loss = 0.4223175048828125, train/logprobs = tensor([[-0.9740, -2.9382],
        [-2.5403, -2.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36754941940307617
Epoch 0, Step 3408: train/loss = 0.30997055768966675, train/raw-loss = 0.2680973708629608, train/logprobs = tensor([[-1.6998, -4.1735],
        [-3.1018, -1.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4187318682670593
Epoch 0, Step 3409: train/loss = 0.4501354992389679, train/raw-loss = 0.40976566076278687, train/logprobs = tensor([[-1.4672, -3.1984],
        [-2.6512, -2.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403698593378067
Epoch 0, Step 3410: train/loss = 0.3484880328178406, train/raw-loss = 0.3030574321746826, train/logprobs = tensor([[-1.5222, -4.0704],
        [-2.5660, -1.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4543061852455139
Epoch 0, Step 3411: train/loss = 0.15119947493076324, train/raw-loss = 0.1094396784901619, train/logprobs = tensor([[ -2.2032, -10.1682],
        [ -4.6762,  -3.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175979495048523
Epoch 0, Step 3412: train/loss = 0.4065362513065338, train/raw-loss = 0.37208428978919983, train/logprobs = tensor([[-1.1305, -3.3622],
        [-2.5855, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34451955556869507
Epoch 0, Step 3413: train/loss = 0.1643037348985672, train/raw-loss = 0.11113835871219635, train/logprobs = tensor([[-1.0499, -7.3234],
        [-4.2779, -1.7530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5316537022590637
Epoch 0, Step 3414: train/loss = 0.4825790226459503, train/raw-loss = 0.4527408182621002, train/logprobs = tensor([[-2.0619, -4.2327],
        [-2.4728, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983822524547577
Epoch 0, Step 3415: train/loss = 0.29825106263160706, train/raw-loss = 0.25522416830062866, train/logprobs = tensor([[-1.8950, -7.1557],
        [-5.4335, -3.4425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4302690029144287
Epoch 0, Step 3416: train/loss = 0.4331090450286865, train/raw-loss = 0.39038532972335815, train/logprobs = tensor([[-1.5285, -2.1632],
        [-2.8499, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42723727226257324
Epoch 0, Step 3417: train/loss = 0.3143242597579956, train/raw-loss = 0.2756098806858063, train/logprobs = tensor([[-1.7056, -9.0760],
        [-3.4549, -3.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871435523033142
Epoch 0, Step 3418: train/loss = 0.27140581607818604, train/raw-loss = 0.23035761713981628, train/logprobs = tensor([[-1.4227, -9.0880],
        [-4.3635, -2.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4104819893836975
Epoch 0, Step 3419: train/loss = 0.2860710620880127, train/raw-loss = 0.24035921692848206, train/logprobs = tensor([[-0.9434, -9.0494],
        [-3.7281, -2.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4571186900138855
Epoch 0, Step 3420: train/loss = 0.3770388960838318, train/raw-loss = 0.3496567904949188, train/logprobs = tensor([[-2.3979, -5.0335],
        [-2.4554, -1.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738211154937744
Epoch 0, Step 3421: train/loss = 0.28412964940071106, train/raw-loss = 0.24765074253082275, train/logprobs = tensor([[-0.7323, -5.1544],
        [-3.0965, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3647891879081726
Epoch 0, Step 3422: train/loss = 0.3515464961528778, train/raw-loss = 0.3073277473449707, train/logprobs = tensor([[-1.1617, -4.7456],
        [-2.9489, -1.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44218719005584717
Epoch 0, Step 3423: train/loss = 0.18857508897781372, train/raw-loss = 0.14977870881557465, train/logprobs = tensor([[-1.3952, -5.5661],
        [-2.5914, -1.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38796374201774597
Epoch 0, Step 3424: train/loss = 0.1922524869441986, train/raw-loss = 0.15043197572231293, train/logprobs = tensor([[-1.8074, -6.0401],
        [-4.0433, -1.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182050824165344
Epoch 0, Step 3425: train/loss = 0.3634031414985657, train/raw-loss = 0.3236319422721863, train/logprobs = tensor([[-2.0131, -6.6942],
        [-4.0481, -2.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3977116346359253
Epoch 0, Step 3426: train/loss = 0.4846348464488983, train/raw-loss = 0.44861912727355957, train/logprobs = tensor([[-1.8088, -9.1305],
        [-3.3620, -3.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601576089859009
Epoch 0, Step 3427: train/loss = 0.2012537121772766, train/raw-loss = 0.1587793380022049, train/logprobs = tensor([[-1.2834, -8.9448],
        [-4.0077, -2.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42474380135536194
Epoch 0, Step 3428: train/loss = 0.14599668979644775, train/raw-loss = 0.10823027044534683, train/logprobs = tensor([[-0.9225, -7.7309],
        [-2.4100, -0.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.377664178609848
Epoch 0, Step 3429: train/loss = 0.2603161633014679, train/raw-loss = 0.22306039929389954, train/logprobs = tensor([[-1.9613, -7.5623],
        [-3.2420, -1.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37255749106407166
Epoch 0, Step 3430: train/loss = 0.095121830701828, train/raw-loss = 0.051980264484882355, train/logprobs = tensor([[-1.7398, -9.3582],
        [-4.1480, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43141570687294006
Epoch 0, Step 3431: train/loss = 0.39343878626823425, train/raw-loss = 0.35124918818473816, train/logprobs = tensor([[-1.2154, -6.4134],
        [-2.8094, -1.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218955338001251
Epoch 0, Step 3432: train/loss = 0.23564694821834564, train/raw-loss = 0.19726094603538513, train/logprobs = tensor([[-0.8210, -7.4803],
        [-3.1242, -2.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3838600516319275
Epoch 0, Step 3433: train/loss = 0.4907934367656708, train/raw-loss = 0.4524683356285095, train/logprobs = tensor([[-1.8282, -4.2655],
        [-4.2000, -2.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3832508623600006
Epoch 0, Step 3434: train/loss = 0.32775408029556274, train/raw-loss = 0.2906034588813782, train/logprobs = tensor([[-1.4671, -5.4679],
        [-3.2579, -3.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37150609493255615
Epoch 0, Step 3435: train/loss = 1.3244808912277222, train/raw-loss = 1.282296895980835, train/logprobs = tensor([[-5.2266, -5.6081],
        [-3.8041, -2.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42183905839920044
Epoch 0, Step 3436: train/loss = 0.10873742401599884, train/raw-loss = 0.07035807520151138, train/logprobs = tensor([[ -0.9099, -10.5697],
        [ -3.3280,  -2.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3837934732437134
Epoch 0, Step 3437: train/loss = 0.2919127941131592, train/raw-loss = 0.2508975565433502, train/logprobs = tensor([[ -1.5104, -11.5189],
        [ -3.2922,  -2.9828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41015249490737915
Epoch 0, Step 3438: train/loss = 0.08877550065517426, train/raw-loss = 0.052029527723789215, train/logprobs = tensor([[-0.9628, -8.2062],
        [-3.5290, -1.2646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.367459774017334
Epoch 0, Step 3439: train/loss = 0.5182879567146301, train/raw-loss = 0.4843386709690094, train/logprobs = tensor([[-1.0894, -1.8475],
        [-2.1231, -1.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3394927382469177
Epoch 0, Step 3440: train/loss = 0.25803375244140625, train/raw-loss = 0.2213553637266159, train/logprobs = tensor([[ -1.5895, -17.0210],
        [ -4.5777,  -3.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36678358912467957
Epoch 0, Step 3441: train/loss = 0.5661288499832153, train/raw-loss = 0.5292755365371704, train/logprobs = tensor([[-1.1538, -7.0710],
        [-1.8801, -2.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3685338497161865
Epoch 0, Step 3442: train/loss = 0.5481680631637573, train/raw-loss = 0.4963870644569397, train/logprobs = tensor([[-1.0764, -2.1848],
        [-4.1494, -2.4351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5178092122077942
Epoch 0, Step 3443: train/loss = 0.42144766449928284, train/raw-loss = 0.3782350718975067, train/logprobs = tensor([[-1.8844, -8.9273],
        [-3.9996, -3.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4321262836456299
Epoch 0, Step 3444: train/loss = 0.16655266284942627, train/raw-loss = 0.12113332748413086, train/logprobs = tensor([[ -0.9755, -10.1795],
        [ -5.0148,  -2.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45419350266456604
Epoch 0, Step 3445: train/loss = 0.23285862803459167, train/raw-loss = 0.18732523918151855, train/logprobs = tensor([[-1.5673, -5.0291],
        [-4.1879, -1.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4553340673446655
Epoch 0, Step 3446: train/loss = 0.5881490707397461, train/raw-loss = 0.5337690711021423, train/logprobs = tensor([[-0.8683, -3.6617],
        [-3.4349, -2.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5437995791435242
Epoch 0, Step 3447: train/loss = 0.4495505690574646, train/raw-loss = 0.40255606174468994, train/logprobs = tensor([[-1.3397, -3.4884],
        [-3.0039, -2.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46994513273239136
Epoch 0, Step 3448: train/loss = 0.2202998697757721, train/raw-loss = 0.17821259796619415, train/logprobs = tensor([[-1.5736, -5.8702],
        [-4.7808, -2.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42087268829345703
Epoch 0, Step 3449: train/loss = 0.30763837695121765, train/raw-loss = 0.2607417702674866, train/logprobs = tensor([[-1.3790, -5.4010],
        [-4.6777, -1.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46896615624427795
Epoch 0, Step 3450: train/loss = 0.33897829055786133, train/raw-loss = 0.2987735867500305, train/logprobs = tensor([[-1.8086, -6.7591],
        [-2.9698, -1.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40204697847366333
Epoch 0, Step 3451: train/loss = 0.3950047791004181, train/raw-loss = 0.3561843931674957, train/logprobs = tensor([[-0.5893, -4.7104],
        [-2.4351, -2.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3882036805152893
Epoch 0, Step 3452: train/loss = 0.28647568821907043, train/raw-loss = 0.24692291021347046, train/logprobs = tensor([[-1.3607, -9.7290],
        [-3.0954, -1.5743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3955279290676117
Epoch 0, Step 3453: train/loss = 0.3075593411922455, train/raw-loss = 0.2779940664768219, train/logprobs = tensor([[-1.5353, -6.0536],
        [-2.3975, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29565298557281494
Epoch 0, Step 3454: train/loss = 0.8908199071884155, train/raw-loss = 0.8437755703926086, train/logprobs = tensor([[-3.7544, -5.4628],
        [-2.9316, -2.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4704430103302002
Epoch 0, Step 3455: train/loss = 0.3939797878265381, train/raw-loss = 0.36023879051208496, train/logprobs = tensor([[-1.9630, -4.8841],
        [-2.9983, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374103009700775
Epoch 0, Step 3456: train/loss = 0.20828476548194885, train/raw-loss = 0.16337846219539642, train/logprobs = tensor([[-1.3944, -7.9907],
        [-4.3553, -2.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44906318187713623
Epoch 0, Step 3457: train/loss = 0.15811796486377716, train/raw-loss = 0.11602285504341125, train/logprobs = tensor([[-1.8611, -8.3432],
        [-4.0087, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42095112800598145
Epoch 0, Step 3458: train/loss = 0.1926020085811615, train/raw-loss = 0.14907217025756836, train/logprobs = tensor([[ -1.1040, -13.8066],
        [ -3.8602,  -3.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4352983832359314
Epoch 0, Step 3459: train/loss = 0.44669288396835327, train/raw-loss = 0.39871230721473694, train/logprobs = tensor([[-2.0589, -3.6874],
        [-3.3540, -2.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47980552911758423
Epoch 0, Step 3460: train/loss = 0.42687225341796875, train/raw-loss = 0.3930153548717499, train/logprobs = tensor([[-1.0444, -2.4659],
        [-2.8306, -1.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3385687470436096
Epoch 0, Step 3461: train/loss = 0.3679887652397156, train/raw-loss = 0.3356316089630127, train/logprobs = tensor([[-1.2820, -5.3614],
        [-1.9623, -1.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235716223716736
Epoch 0, Step 3462: train/loss = 0.32181215286254883, train/raw-loss = 0.2759190797805786, train/logprobs = tensor([[-1.9597, -4.8506],
        [-3.4224, -2.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4589308500289917
Epoch 0, Step 3463: train/loss = 0.3181854784488678, train/raw-loss = 0.2781246304512024, train/logprobs = tensor([[-1.5549, -5.9613],
        [-3.0135, -2.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40060847997665405
Epoch 0, Step 3464: train/loss = 0.2186163365840912, train/raw-loss = 0.17975667119026184, train/logprobs = tensor([[-1.2875, -5.1936],
        [-4.1172, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885965347290039
Epoch 0, Step 3465: train/loss = 0.6685563325881958, train/raw-loss = 0.6313570141792297, train/logprobs = tensor([[-1.4142, -1.4489],
        [-2.4624, -1.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37199369072914124
Epoch 0, Step 3466: train/loss = 0.17585785686969757, train/raw-loss = 0.13827209174633026, train/logprobs = tensor([[-0.9278, -5.0368],
        [-3.5919, -1.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3758576512336731
Epoch 0, Step 3467: train/loss = 0.3832785487174988, train/raw-loss = 0.3433232307434082, train/logprobs = tensor([[-2.1115, -8.0986],
        [-4.9244, -2.3847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.399553507566452
Epoch 0, Step 3468: train/loss = 0.2984091341495514, train/raw-loss = 0.24903123080730438, train/logprobs = tensor([[-1.2801, -8.2350],
        [-3.4913, -3.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49377885460853577
Epoch 0, Step 3469: train/loss = 0.5095150470733643, train/raw-loss = 0.4595109522342682, train/logprobs = tensor([[-1.2090, -7.1402],
        [-4.5462, -2.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.500041127204895
Epoch 0, Step 3470: train/loss = 0.33805930614471436, train/raw-loss = 0.298652321100235, train/logprobs = tensor([[-1.7075, -6.5087],
        [-3.0610, -2.3650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3940700888633728
Epoch 0, Step 3471: train/loss = 0.32731884717941284, train/raw-loss = 0.2840733528137207, train/logprobs = tensor([[-1.0508, -5.0955],
        [-3.1384, -2.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43245500326156616
Epoch 0, Step 3472: train/loss = 0.2519511580467224, train/raw-loss = 0.21687257289886475, train/logprobs = tensor([[-1.7285, -5.4439],
        [-4.1759, -1.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35078564286231995
Epoch 0, Step 3473: train/loss = 0.39012646675109863, train/raw-loss = 0.3426327407360077, train/logprobs = tensor([[-1.1216, -6.8503],
        [-3.9543, -2.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4749374985694885
Epoch 0, Step 3474: train/loss = 0.3807789087295532, train/raw-loss = 0.3349998891353607, train/logprobs = tensor([[-2.1708, -3.8811],
        [-4.5907, -1.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4577901065349579
Epoch 0, Step 3475: train/loss = 0.2590155005455017, train/raw-loss = 0.21215693652629852, train/logprobs = tensor([[-1.6414, -6.7736],
        [-5.0053, -2.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4685855805873871
Epoch 0, Step 3476: train/loss = 0.14587649703025818, train/raw-loss = 0.09758991003036499, train/logprobs = tensor([[-1.1942, -7.5554],
        [-4.1783, -2.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48286592960357666
Epoch 0, Step 3477: train/loss = 0.09601618349552155, train/raw-loss = 0.05007033422589302, train/logprobs = tensor([[-1.0737, -9.3709],
        [-5.0780, -2.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45945847034454346
Epoch 0, Step 3478: train/loss = 0.25063785910606384, train/raw-loss = 0.20367926359176636, train/logprobs = tensor([[-1.3804, -6.6306],
        [-3.5448, -1.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46958571672439575
Epoch 0, Step 3479: train/loss = 0.09817709028720856, train/raw-loss = 0.05894613265991211, train/logprobs = tensor([[-1.0842, -7.7409],
        [-3.9538, -1.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39230960607528687
Epoch 0, Step 3480: train/loss = 0.1502569019794464, train/raw-loss = 0.11782212555408478, train/logprobs = tensor([[-1.4988, -6.8230],
        [-3.3147, -2.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3243478238582611
Epoch 0, Step 3481: train/loss = 0.8295594453811646, train/raw-loss = 0.7955837249755859, train/logprobs = tensor([[-1.4322, -1.2233],
        [-1.8823, -1.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3397578001022339
Epoch 0, Step 3482: train/loss = 0.44235673546791077, train/raw-loss = 0.4050033986568451, train/logprobs = tensor([[-1.8848, -7.6900],
        [-3.2794, -2.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37353336811065674
Epoch 0, Step 3483: train/loss = 0.39375802874565125, train/raw-loss = 0.3549630045890808, train/logprobs = tensor([[-1.4493, -2.4229],
        [-3.9007, -1.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879503309726715
Epoch 0, Step 3484: train/loss = 0.2930890619754791, train/raw-loss = 0.2499120831489563, train/logprobs = tensor([[-1.0628, -6.7550],
        [-3.7295, -2.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4317699372768402
Epoch 0, Step 3485: train/loss = 0.33426252007484436, train/raw-loss = 0.2912585139274597, train/logprobs = tensor([[-1.5167, -5.0917],
        [-3.6764, -1.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43003979325294495
Epoch 0, Step 3486: train/loss = 0.2405174970626831, train/raw-loss = 0.20736846327781677, train/logprobs = tensor([[-2.1733, -3.5243],
        [-4.4216, -1.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314902186393738
Epoch 0, Step 3487: train/loss = 0.1203974038362503, train/raw-loss = 0.06894566118717194, train/logprobs = tensor([[-1.4735, -9.3568],
        [-4.2646, -2.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5145174264907837
Epoch 0, Step 3488: train/loss = 0.07764016091823578, train/raw-loss = 0.0320197269320488, train/logprobs = tensor([[ -1.0890, -10.4692],
        [ -4.2299,  -2.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4562044143676758
Epoch 0, Step 3489: train/loss = 0.3596859574317932, train/raw-loss = 0.3275305926799774, train/logprobs = tensor([[-0.9995, -3.0691],
        [-3.1760, -1.0569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32155361771583557
Epoch 0, Step 3490: train/loss = 0.6241931319236755, train/raw-loss = 0.5879068374633789, train/logprobs = tensor([[-1.5926, -2.2584],
        [-2.1414, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36286279559135437
Epoch 0, Step 3491: train/loss = 0.4339969754219055, train/raw-loss = 0.3931470513343811, train/logprobs = tensor([[-1.0289, -3.1249],
        [-3.4824, -2.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084987938404083
Epoch 0, Step 3492: train/loss = 0.22709988057613373, train/raw-loss = 0.18976156413555145, train/logprobs = tensor([[-1.2241, -6.0987],
        [-3.4188, -2.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733832538127899
Epoch 0, Step 3493: train/loss = 0.4680497348308563, train/raw-loss = 0.42556288838386536, train/logprobs = tensor([[-1.6095, -6.7905],
        [-2.7488, -2.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42486852407455444
Epoch 0, Step 3494: train/loss = 0.16257013380527496, train/raw-loss = 0.13127347826957703, train/logprobs = tensor([[-2.2075, -5.2968],
        [-5.1991, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129664659500122
Epoch 0, Step 3495: train/loss = 0.24500350654125214, train/raw-loss = 0.2073771357536316, train/logprobs = tensor([[-1.5440, -8.0131],
        [-4.1195, -2.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762640357017517
Epoch 0, Step 3496: train/loss = 0.173182874917984, train/raw-loss = 0.14049214124679565, train/logprobs = tensor([[-1.4691, -6.3811],
        [-4.2998, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32690727710723877
Epoch 0, Step 3497: train/loss = 0.38024330139160156, train/raw-loss = 0.3416159749031067, train/logprobs = tensor([[-1.2363, -7.3234],
        [-3.4036, -2.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38627347350120544
Epoch 0, Step 3498: train/loss = 0.40716439485549927, train/raw-loss = 0.36614853143692017, train/logprobs = tensor([[ -1.6308, -10.7040],
        [ -3.7135,  -2.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41015857458114624
Epoch 0, Step 3499: train/loss = 0.11963235586881638, train/raw-loss = 0.07326603680849075, train/logprobs = tensor([[ -1.2432, -10.1003],
        [ -4.2538,  -3.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46366316080093384
Epoch 0, Step 3500: train/loss = 0.2564743757247925, train/raw-loss = 0.20744328200817108, train/logprobs = tensor([[-1.6011, -9.1594],
        [-6.1103, -1.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49031081795692444
Epoch 0, Step 3501: train/loss = 0.11660446226596832, train/raw-loss = 0.07629240304231644, train/logprobs = tensor([[-0.6114, -7.5712],
        [-4.2488, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4031205475330353
Epoch 0, Step 3502: train/loss = 0.19807952642440796, train/raw-loss = 0.16494233906269073, train/logprobs = tensor([[ -1.6327, -10.5272],
        [ -3.5186,  -1.7945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313719630241394
Epoch 0, Step 3503: train/loss = 0.4514743983745575, train/raw-loss = 0.41098979115486145, train/logprobs = tensor([[-1.1738, -6.9534],
        [-4.0459, -3.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4048462510108948
Epoch 0, Step 3504: train/loss = 0.17182721197605133, train/raw-loss = 0.13223624229431152, train/logprobs = tensor([[-1.7913, -9.9351],
        [-3.8633, -1.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39590954780578613
Epoch 0, Step 3505: train/loss = 0.3862951993942261, train/raw-loss = 0.34077832102775574, train/logprobs = tensor([[-0.9260, -4.1315],
        [-3.0476, -2.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4551685154438019
Epoch 0, Step 3506: train/loss = 0.6669754981994629, train/raw-loss = 0.6190535426139832, train/logprobs = tensor([[-1.7840, -4.9737],
        [-2.9339, -2.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4792187809944153
Epoch 0, Step 3507: train/loss = 0.13573798537254333, train/raw-loss = 0.10064685344696045, train/logprobs = tensor([[-1.2416, -4.1141],
        [-3.5600, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35091114044189453
Epoch 0, Step 3508: train/loss = 0.21757760643959045, train/raw-loss = 0.1747833639383316, train/logprobs = tensor([[-1.3186, -6.7455],
        [-3.7913, -1.5192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4279423654079437
Epoch 0, Step 3509: train/loss = 0.3654053211212158, train/raw-loss = 0.3227117657661438, train/logprobs = tensor([[-1.6656, -5.5836],
        [-3.8751, -1.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4269358515739441
Epoch 0, Step 3510: train/loss = 0.06685815006494522, train/raw-loss = 0.020933013409376144, train/logprobs = tensor([[ -1.2468, -12.2505],
        [ -4.6320,  -2.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.459251344203949
Epoch 0, Step 3511: train/loss = 0.418356716632843, train/raw-loss = 0.3613251745700836, train/logprobs = tensor([[ -1.7067, -10.2848],
        [ -4.3364,  -3.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5703153014183044
Epoch 0, Step 3512: train/loss = 0.2853069305419922, train/raw-loss = 0.2476148158311844, train/logprobs = tensor([[-2.1521, -7.8212],
        [-5.7631, -3.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3769209682941437
Epoch 0, Step 3513: train/loss = 0.21101820468902588, train/raw-loss = 0.16615861654281616, train/logprobs = tensor([[-1.3031, -6.2213],
        [-3.9672, -1.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44859579205513
Epoch 0, Step 3514: train/loss = 0.7604300379753113, train/raw-loss = 0.7155447602272034, train/logprobs = tensor([[-1.1110, -1.5961],
        [-2.4651, -2.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4488530457019806
Epoch 0, Step 3515: train/loss = 0.37188029289245605, train/raw-loss = 0.3376809358596802, train/logprobs = tensor([[-1.4580, -6.1887],
        [-2.7676, -2.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3419939875602722
Epoch 0, Step 3516: train/loss = 0.4056320786476135, train/raw-loss = 0.36988818645477295, train/logprobs = tensor([[-2.6644, -5.0541],
        [-4.9531, -2.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3574390411376953
Epoch 0, Step 3517: train/loss = 0.06589694321155548, train/raw-loss = 0.025805125012993813, train/logprobs = tensor([[ -1.7530, -12.7495],
        [ -6.1244,  -3.2306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4009181559085846
Epoch 0, Step 3518: train/loss = 0.3199714124202728, train/raw-loss = 0.281686007976532, train/logprobs = tensor([[-1.1181, -9.5266],
        [-2.8852, -3.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3828541040420532
Epoch 0, Step 3519: train/loss = 0.3231644034385681, train/raw-loss = 0.26137542724609375, train/logprobs = tensor([[-1.1760, -7.0861],
        [-5.0190, -3.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6178898215293884
Epoch 0, Step 3520: train/loss = 0.23670898377895355, train/raw-loss = 0.19118404388427734, train/logprobs = tensor([[-1.2618, -5.4032],
        [-4.6389, -2.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45524945855140686
Epoch 0, Step 3521: train/loss = 0.08600832521915436, train/raw-loss = 0.04515882954001427, train/logprobs = tensor([[-1.6790, -9.1199],
        [-5.8887, -2.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4084949493408203
Epoch 0, Step 3522: train/loss = 0.35864049196243286, train/raw-loss = 0.31038087606430054, train/logprobs = tensor([[-1.0690, -4.3468],
        [-4.2812, -2.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4825964570045471
Epoch 0, Step 3523: train/loss = 0.9391748905181885, train/raw-loss = 0.9040926694869995, train/logprobs = tensor([[-3.4033, -4.5263],
        [-3.4592, -2.4428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3508222699165344
Epoch 0, Step 3524: train/loss = 0.44252458214759827, train/raw-loss = 0.3944011926651001, train/logprobs = tensor([[-1.3032, -7.0811],
        [-4.6992, -4.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48123377561569214
Epoch 0, Step 3525: train/loss = 0.5553478002548218, train/raw-loss = 0.509249746799469, train/logprobs = tensor([[-1.3514, -3.4428],
        [-3.1751, -2.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4609799385070801
Epoch 0, Step 3526: train/loss = 0.27878841757774353, train/raw-loss = 0.23129555583000183, train/logprobs = tensor([[-1.3319, -7.6117],
        [-3.8432, -1.5711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4749287962913513
Epoch 0, Step 3527: train/loss = 0.5172131061553955, train/raw-loss = 0.47052744030952454, train/logprobs = tensor([[-1.2236, -3.3827],
        [-3.7991, -1.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4668564796447754
Epoch 0, Step 3528: train/loss = 0.44309625029563904, train/raw-loss = 0.3973507285118103, train/logprobs = tensor([[ -3.1266, -13.6641],
        [ -4.1025,  -3.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4574550688266754
Epoch 0, Step 3529: train/loss = 0.32181525230407715, train/raw-loss = 0.2866861820220947, train/logprobs = tensor([[-1.9012, -7.1258],
        [-3.1949, -1.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35129061341285706
Epoch 0, Step 3530: train/loss = 0.18652670085430145, train/raw-loss = 0.14273059368133545, train/logprobs = tensor([[-1.4096, -3.7821],
        [-4.6952, -2.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4379609227180481
Epoch 0, Step 3531: train/loss = 0.30808523297309875, train/raw-loss = 0.2644243836402893, train/logprobs = tensor([[-1.1664, -6.7053],
        [-5.1242, -2.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43660831451416016
Epoch 0, Step 3532: train/loss = 0.5165296792984009, train/raw-loss = 0.47442713379859924, train/logprobs = tensor([[-0.6770, -2.0244],
        [-1.7883, -1.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42102548480033875
Epoch 0, Step 3533: train/loss = 0.23696961998939514, train/raw-loss = 0.18993820250034332, train/logprobs = tensor([[ -1.6730, -14.8428],
        [ -4.5386,  -2.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4703141748905182
Epoch 0, Step 3534: train/loss = 0.21611525118350983, train/raw-loss = 0.1870480179786682, train/logprobs = tensor([[-1.7732, -6.2979],
        [-3.9576, -1.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29067230224609375
Epoch 0, Step 3535: train/loss = 0.2938995957374573, train/raw-loss = 0.24632513523101807, train/logprobs = tensor([[-1.2800, -5.0524],
        [-4.4284, -1.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47574466466903687
Epoch 0, Step 3536: train/loss = 0.1075151264667511, train/raw-loss = 0.0657699853181839, train/logprobs = tensor([[-1.1034, -8.9565],
        [-4.6695, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4174513816833496
Epoch 0, Step 3537: train/loss = 0.19152772426605225, train/raw-loss = 0.15373408794403076, train/logprobs = tensor([[-1.1770, -8.0104],
        [-4.2431, -2.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37793630361557007
Epoch 0, Step 3538: train/loss = 0.16781704127788544, train/raw-loss = 0.12195847183465958, train/logprobs = tensor([[-1.1066, -8.8621],
        [-4.2657, -3.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4585857391357422
Epoch 0, Step 3539: train/loss = 0.24719004333019257, train/raw-loss = 0.20766395330429077, train/logprobs = tensor([[ -1.1247, -13.2963],
        [ -2.8654,  -4.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39526090025901794
Epoch 0, Step 3540: train/loss = 0.26668408513069153, train/raw-loss = 0.21686100959777832, train/logprobs = tensor([[ -1.1507, -12.3792],
        [ -4.7628,  -4.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49823105335235596
Epoch 0, Step 3541: train/loss = 0.39712536334991455, train/raw-loss = 0.36119428277015686, train/logprobs = tensor([[-1.5191, -3.3798],
        [-2.7810, -1.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35931041836738586
Epoch 0, Step 3542: train/loss = 0.18068468570709229, train/raw-loss = 0.1336587518453598, train/logprobs = tensor([[-0.9148, -5.5062],
        [-3.8004, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4702593684196472
Epoch 0, Step 3543: train/loss = 0.5445926785469055, train/raw-loss = 0.5062961578369141, train/logprobs = tensor([[-1.3541, -2.0704],
        [-2.0053, -1.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3829646408557892
Epoch 0, Step 3544: train/loss = 0.34944936633110046, train/raw-loss = 0.30476507544517517, train/logprobs = tensor([[-1.5464, -5.3605],
        [-4.0859, -2.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44684264063835144
Epoch 0, Step 3545: train/loss = 0.13701017200946808, train/raw-loss = 0.09103618562221527, train/logprobs = tensor([[-0.8996, -7.7731],
        [-3.8045, -2.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4597398340702057
Epoch 0, Step 3546: train/loss = 0.36886492371559143, train/raw-loss = 0.3342397212982178, train/logprobs = tensor([[-1.1858, -3.2903],
        [-2.6213, -1.5185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34625232219696045
Epoch 0, Step 3547: train/loss = 0.5819639563560486, train/raw-loss = 0.5477771759033203, train/logprobs = tensor([[-1.1476, -1.4103],
        [-2.0755, -1.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3418683111667633
Epoch 0, Step 3548: train/loss = 0.0646248310804367, train/raw-loss = 0.015633363276720047, train/logprobs = tensor([[ -1.4190, -12.6102],
        [ -5.0758,  -2.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4899146854877472
Epoch 0, Step 3549: train/loss = 0.2907100021839142, train/raw-loss = 0.25374165177345276, train/logprobs = tensor([[-1.3965, -4.4366],
        [-3.1241, -1.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36968350410461426
Epoch 0, Step 3550: train/loss = 0.4467841386795044, train/raw-loss = 0.4094783663749695, train/logprobs = tensor([[-1.5746, -4.7310],
        [-4.1621, -1.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37305766344070435
Epoch 0, Step 3551: train/loss = 0.37450286746025085, train/raw-loss = 0.3216830790042877, train/logprobs = tensor([[-1.0716, -6.8114],
        [-4.8160, -2.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5281978249549866
Epoch 0, Step 3552: train/loss = 0.22992615401744843, train/raw-loss = 0.18619562685489655, train/logprobs = tensor([[-1.4598, -6.3521],
        [-3.6760, -1.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.437305212020874
Epoch 0, Step 3553: train/loss = 0.29732823371887207, train/raw-loss = 0.25111523270606995, train/logprobs = tensor([[-0.7817, -9.9034],
        [-3.8699, -3.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4621298611164093
Epoch 0, Step 3554: train/loss = 0.09539197385311127, train/raw-loss = 0.07000270485877991, train/logprobs = tensor([[ -1.3739, -18.0554],
        [ -4.0353,  -4.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538927495479584
Epoch 0, Step 3555: train/loss = 0.2539176344871521, train/raw-loss = 0.219917893409729, train/logprobs = tensor([[-1.3006, -8.0081],
        [-3.7954, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3399975597858429
Epoch 0, Step 3556: train/loss = 0.28242093324661255, train/raw-loss = 0.23542866110801697, train/logprobs = tensor([[-1.4269, -4.8396],
        [-3.4333, -1.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4699226915836334
Epoch 0, Step 3557: train/loss = 0.6765342950820923, train/raw-loss = 0.6366678476333618, train/logprobs = tensor([[-1.0717, -1.6712],
        [-2.0425, -2.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3986647129058838
Epoch 0, Step 3558: train/loss = 0.08174606412649155, train/raw-loss = 0.034535374492406845, train/logprobs = tensor([[ -1.5334, -10.9924],
        [ -4.8826,  -2.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47210684418678284
Epoch 0, Step 3559: train/loss = 0.6118689775466919, train/raw-loss = 0.5694948434829712, train/logprobs = tensor([[-1.1525, -2.0901],
        [-4.0140, -2.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4237411320209503
Epoch 0, Step 3560: train/loss = 0.38943979144096375, train/raw-loss = 0.3569880425930023, train/logprobs = tensor([[-1.7899, -9.3558],
        [-3.9526, -1.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32451751828193665
Epoch 0, Step 3561: train/loss = 0.22609972953796387, train/raw-loss = 0.18627849221229553, train/logprobs = tensor([[-1.1379, -8.2988],
        [-3.7473, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39821234345436096
Epoch 0, Step 3562: train/loss = 0.3230675160884857, train/raw-loss = 0.2876499593257904, train/logprobs = tensor([[-1.3282, -3.5370],
        [-3.5166, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3541755974292755
Epoch 0, Step 3563: train/loss = 0.31745514273643494, train/raw-loss = 0.27868393063545227, train/logprobs = tensor([[-0.9856, -4.5457],
        [-3.0785, -2.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38771218061447144
Epoch 0, Step 3564: train/loss = 0.2734525203704834, train/raw-loss = 0.24116051197052002, train/logprobs = tensor([[-1.2143, -4.5624],
        [-2.9889, -1.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229203224182129
Epoch 0, Step 3565: train/loss = 0.15210360288619995, train/raw-loss = 0.11671632528305054, train/logprobs = tensor([[-1.2237, -7.1625],
        [-2.9324, -1.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3538728654384613
Epoch 0, Step 3566: train/loss = 0.32050496339797974, train/raw-loss = 0.28434035181999207, train/logprobs = tensor([[-1.6989, -4.3280],
        [-2.8677, -1.8235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3616458773612976
Epoch 0, Step 3567: train/loss = 0.6166605949401855, train/raw-loss = 0.5751878619194031, train/logprobs = tensor([[-1.3903, -3.6617],
        [-2.7289, -2.2987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4147280156612396
Epoch 0, Step 3568: train/loss = 0.11615733802318573, train/raw-loss = 0.08036389946937561, train/logprobs = tensor([[ -1.4266, -11.5704],
        [ -3.5963,  -2.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579343557357788
Epoch 0, Step 3569: train/loss = 0.2795060873031616, train/raw-loss = 0.25162002444267273, train/logprobs = tensor([[-1.7610, -9.2568],
        [-3.0760, -2.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788604497909546
Epoch 0, Step 3570: train/loss = 0.25090643763542175, train/raw-loss = 0.21134407818317413, train/logprobs = tensor([[-1.9105, -9.0690],
        [-4.2451, -3.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3956235945224762
Epoch 0, Step 3571: train/loss = 0.4049486815929413, train/raw-loss = 0.36741554737091064, train/logprobs = tensor([[-0.7290, -3.8439],
        [-2.2211, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37533140182495117
Epoch 0, Step 3572: train/loss = 0.44429507851600647, train/raw-loss = 0.40418604016304016, train/logprobs = tensor([[-1.5210, -6.8949],
        [-2.9857, -1.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.401090145111084
Epoch 0, Step 3573: train/loss = 0.5208873748779297, train/raw-loss = 0.47882017493247986, train/logprobs = tensor([[-1.3529, -3.8002],
        [-2.4938, -2.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42067253589630127
Epoch 0, Step 3574: train/loss = 0.2321430742740631, train/raw-loss = 0.1961764395236969, train/logprobs = tensor([[ -1.1787, -10.1021],
        [ -4.1188,  -2.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35966598987579346
Epoch 0, Step 3575: train/loss = 0.14946746826171875, train/raw-loss = 0.1055246964097023, train/logprobs = tensor([[-0.9156, -8.7543],
        [-4.7686, -1.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43942776322364807
Epoch 0, Step 3576: train/loss = 0.09164349734783173, train/raw-loss = 0.05195629596710205, train/logprobs = tensor([[ -1.9362, -12.4903],
        [ -5.3376,  -2.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39687204360961914
Epoch 0, Step 3577: train/loss = 0.2710632383823395, train/raw-loss = 0.22822147607803345, train/logprobs = tensor([[ -0.9290, -11.1285],
        [ -4.2316,  -2.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42841753363609314
Epoch 0, Step 3578: train/loss = 0.5463296175003052, train/raw-loss = 0.49779829382896423, train/logprobs = tensor([[-1.2178, -5.8718],
        [-3.0321, -2.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48531365394592285
Epoch 0, Step 3579: train/loss = 0.10550016164779663, train/raw-loss = 0.06610829383134842, train/logprobs = tensor([[ -0.8940, -10.4655],
        [ -3.2577,  -1.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39391857385635376
Epoch 0, Step 3580: train/loss = 0.4047658145427704, train/raw-loss = 0.37176260352134705, train/logprobs = tensor([[-1.2381, -3.9381],
        [-2.5353, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3300320506095886
Epoch 0, Step 3581: train/loss = 0.19419847428798676, train/raw-loss = 0.1653098464012146, train/logprobs = tensor([[ -1.1773, -13.2661],
        [ -4.4547,  -3.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2888862192630768
Epoch 0, Step 3582: train/loss = 0.4567720890045166, train/raw-loss = 0.4194355010986328, train/logprobs = tensor([[-1.1185, -3.8853],
        [-2.0085, -1.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37336570024490356
Epoch 0, Step 3583: train/loss = 0.3320881128311157, train/raw-loss = 0.29087507724761963, train/logprobs = tensor([[-0.8925, -7.0650],
        [-2.6844, -2.8035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4121299684047699
Epoch 0, Step 3584: train/loss = 0.5089649558067322, train/raw-loss = 0.46523943543434143, train/logprobs = tensor([[-1.6849, -4.6308],
        [-4.5502, -3.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4372551441192627
Epoch 0, Step 3585: train/loss = 0.32511407136917114, train/raw-loss = 0.27030497789382935, train/logprobs = tensor([[-1.1103, -5.3585],
        [-4.4451, -1.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.548090934753418
Epoch 0, Step 3586: train/loss = 0.33675628900527954, train/raw-loss = 0.2919052541255951, train/logprobs = tensor([[-1.5491, -7.0946],
        [-4.1256, -1.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44851043820381165
Epoch 0, Step 3587: train/loss = 0.37653568387031555, train/raw-loss = 0.330228328704834, train/logprobs = tensor([[-2.2622, -4.8337],
        [-4.5159, -3.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630734324455261
Epoch 0, Step 3588: train/loss = 0.3933813273906708, train/raw-loss = 0.34081965684890747, train/logprobs = tensor([[-0.9183, -2.2736],
        [-3.7676, -2.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5256167054176331
Epoch 0, Step 3589: train/loss = 0.4004378020763397, train/raw-loss = 0.3651455044746399, train/logprobs = tensor([[-2.0992, -9.6910],
        [-3.2825, -1.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3529234528541565
Epoch 0, Step 3590: train/loss = 0.11276642978191376, train/raw-loss = 0.06510886549949646, train/logprobs = tensor([[-1.3662, -7.2698],
        [-4.6523, -2.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4765755832195282
Epoch 0, Step 3591: train/loss = 0.24419239163398743, train/raw-loss = 0.2144516110420227, train/logprobs = tensor([[-2.2029, -8.1336],
        [-3.6723, -1.7779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2974078059196472
Epoch 0, Step 3592: train/loss = 0.20179463922977448, train/raw-loss = 0.16287320852279663, train/logprobs = tensor([[-2.0165, -8.9569],
        [-4.9324, -2.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3892141878604889
Epoch 0, Step 3593: train/loss = 0.34818923473358154, train/raw-loss = 0.30896425247192383, train/logprobs = tensor([[-1.2067, -4.0889],
        [-3.1146, -1.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39224982261657715
Epoch 0, Step 3594: train/loss = 0.38339078426361084, train/raw-loss = 0.3441712260246277, train/logprobs = tensor([[-0.9945, -9.9236],
        [-2.7601, -3.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39219555258750916
Epoch 0, Step 3595: train/loss = 0.2864701747894287, train/raw-loss = 0.2520486116409302, train/logprobs = tensor([[-1.7585, -4.8864],
        [-3.5394, -1.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34421589970588684
Epoch 0, Step 3596: train/loss = 0.4402643144130707, train/raw-loss = 0.39752477407455444, train/logprobs = tensor([[-1.0560, -2.4744],
        [-3.1843, -1.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42739546298980713
Epoch 0, Step 3597: train/loss = 0.39945363998413086, train/raw-loss = 0.3465593457221985, train/logprobs = tensor([[-0.9843, -3.6981],
        [-3.0071, -2.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5289430022239685
Epoch 0, Step 3598: train/loss = 0.07795488089323044, train/raw-loss = 0.0358881875872612, train/logprobs = tensor([[ -1.2224, -11.1663],
        [ -4.2336,  -1.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42066690325737
Epoch 0, Step 3599: train/loss = 0.14330030977725983, train/raw-loss = 0.0979340448975563, train/logprobs = tensor([[ -1.7072, -10.0580],
        [ -4.7068,  -2.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45366278290748596
Epoch 0, Step 3600: train/loss = 0.5430558323860168, train/raw-loss = 0.4946630895137787, train/logprobs = tensor([[-1.7126, -5.1693],
        [-3.3168, -2.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4839271306991577
Epoch 0, Step 3601: train/loss = 0.344199001789093, train/raw-loss = 0.30638450384140015, train/logprobs = tensor([[-1.3414, -4.8285],
        [-3.1607, -1.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37814468145370483
Epoch 0, Step 3602: train/loss = 0.19703182578086853, train/raw-loss = 0.16209322214126587, train/logprobs = tensor([[-1.4318, -6.4429],
        [-3.4096, -1.8763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.349386066198349
Epoch 0, Step 3603: train/loss = 0.4661588966846466, train/raw-loss = 0.43122708797454834, train/logprobs = tensor([[-1.4306, -3.5859],
        [-2.5206, -1.3741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493182063102722
Epoch 0, Step 3604: train/loss = 0.25705182552337646, train/raw-loss = 0.22244617342948914, train/logprobs = tensor([[ -1.6572, -10.7634],
        [ -3.7145,  -1.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34605672955513
Epoch 0, Step 3605: train/loss = 0.09136319905519485, train/raw-loss = 0.051089510321617126, train/logprobs = tensor([[-1.0022, -5.8862],
        [-3.6868, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4027369022369385
Epoch 0, Step 3606: train/loss = 0.4599441587924957, train/raw-loss = 0.42893990874290466, train/logprobs = tensor([[-1.3276, -3.5700],
        [-2.4132, -1.3598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31004244089126587
Epoch 0, Step 3607: train/loss = 0.2106524258852005, train/raw-loss = 0.1640578806400299, train/logprobs = tensor([[-1.2265, -6.8960],
        [-3.8473, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4659455418586731
Epoch 0, Step 3608: train/loss = 0.4086449444293976, train/raw-loss = 0.3760240972042084, train/logprobs = tensor([[-3.2112, -9.2183],
        [-3.1039, -2.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262081742286682
Epoch 0, Step 3609: train/loss = 0.26785752177238464, train/raw-loss = 0.22556158900260925, train/logprobs = tensor([[ -1.7751, -13.5237],
        [ -3.3712,  -2.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42295926809310913
Epoch 0, Step 3610: train/loss = 0.4480595886707306, train/raw-loss = 0.4082992374897003, train/logprobs = tensor([[-1.0809, -8.6827],
        [-3.8112, -4.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.397603303194046
Epoch 0, Step 3611: train/loss = 0.26967301964759827, train/raw-loss = 0.2181124985218048, train/logprobs = tensor([[-1.8224, -6.4993],
        [-3.2381, -1.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5156051516532898
Epoch 0, Step 3612: train/loss = 0.4567291736602783, train/raw-loss = 0.4285084009170532, train/logprobs = tensor([[-1.0834, -5.1931],
        [-2.0340, -1.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822079062461853
Epoch 0, Step 3613: train/loss = 0.45979052782058716, train/raw-loss = 0.4156051576137543, train/logprobs = tensor([[-1.1036, -5.0370],
        [-3.4231, -1.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44185394048690796
Epoch 0, Step 3614: train/loss = 0.3111112117767334, train/raw-loss = 0.2677856385707855, train/logprobs = tensor([[-1.2415, -5.1437],
        [-3.6606, -1.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.433255672454834
Epoch 0, Step 3615: train/loss = 0.2702690362930298, train/raw-loss = 0.22097444534301758, train/logprobs = tensor([[-1.4399, -8.5507],
        [-3.7386, -2.7794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4929456412792206
Epoch 0, Step 3616: train/loss = 0.39207276701927185, train/raw-loss = 0.3512118458747864, train/logprobs = tensor([[-1.3908, -5.5470],
        [-2.2330, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40860939025878906
Epoch 0, Step 3617: train/loss = 0.1886793076992035, train/raw-loss = 0.15213987231254578, train/logprobs = tensor([[ -1.2619, -10.5675],
        [ -3.7803,  -2.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36539438366889954
Epoch 0, Step 3618: train/loss = 0.14450891315937042, train/raw-loss = 0.1047518327832222, train/logprobs = tensor([[-1.0684, -7.1962],
        [-3.4875, -1.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3975708484649658
Epoch 0, Step 3619: train/loss = 0.4216514825820923, train/raw-loss = 0.3804282248020172, train/logprobs = tensor([[-1.3671, -6.2717],
        [-3.1414, -2.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41223233938217163
Epoch 0, Step 3620: train/loss = 0.41870737075805664, train/raw-loss = 0.3850899040699005, train/logprobs = tensor([[-1.2253, -7.2838],
        [-2.0188, -1.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3361748158931732
Epoch 0, Step 3621: train/loss = 0.4666259288787842, train/raw-loss = 0.43566596508026123, train/logprobs = tensor([[-1.0601, -4.6855],
        [-2.2831, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30959978699684143
Epoch 0, Step 3622: train/loss = 0.1818106472492218, train/raw-loss = 0.13950304687023163, train/logprobs = tensor([[ -0.9041, -11.7949],
        [ -3.6752,  -3.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.423075795173645
Epoch 0, Step 3623: train/loss = 0.9862487316131592, train/raw-loss = 0.9556586146354675, train/logprobs = tensor([[-2.8717, -3.5446],
        [-2.0858, -2.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059007227420807
Epoch 0, Step 3624: train/loss = 0.22326159477233887, train/raw-loss = 0.18622851371765137, train/logprobs = tensor([[-1.3891, -9.6933],
        [-2.5976, -2.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703308701515198
Epoch 0, Step 3625: train/loss = 0.1335953176021576, train/raw-loss = 0.10514450818300247, train/logprobs = tensor([[-1.4376, -9.0798],
        [-3.3932, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28450798988342285
Epoch 0, Step 3626: train/loss = 0.1969805806875229, train/raw-loss = 0.15709874033927917, train/logprobs = tensor([[-1.5562, -8.6819],
        [-3.0544, -1.4155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39881837368011475
Epoch 0, Step 3627: train/loss = 0.3454388380050659, train/raw-loss = 0.31203871965408325, train/logprobs = tensor([[-1.2165, -7.3895],
        [-3.6849, -3.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3340012729167938
Epoch 0, Step 3628: train/loss = 0.37004798650741577, train/raw-loss = 0.3220956325531006, train/logprobs = tensor([[-1.4117, -8.8877],
        [-4.2058, -1.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47952359914779663
Epoch 0, Step 3629: train/loss = 0.4410953223705292, train/raw-loss = 0.4056382179260254, train/logprobs = tensor([[-1.3666, -3.6644],
        [-2.5003, -1.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35457080602645874
Epoch 0, Step 3630: train/loss = 0.3351820707321167, train/raw-loss = 0.291499525308609, train/logprobs = tensor([[-2.3110, -4.8947],
        [-3.9252, -1.5264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4368252158164978
Epoch 0, Step 3631: train/loss = 0.6788704991340637, train/raw-loss = 0.6495615243911743, train/logprobs = tensor([[-1.7174, -1.4747],
        [-2.4596, -1.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29308950901031494
Epoch 0, Step 3632: train/loss = 0.11168815195560455, train/raw-loss = 0.06919214129447937, train/logprobs = tensor([[-1.3915, -7.4696],
        [-4.2979, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42496001720428467
Epoch 0, Step 3633: train/loss = 0.24313490092754364, train/raw-loss = 0.20616835355758667, train/logprobs = tensor([[-1.9568, -6.9092],
        [-4.4444, -2.3486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3696654438972473
Epoch 0, Step 3634: train/loss = 0.2408682107925415, train/raw-loss = 0.21425597369670868, train/logprobs = tensor([[-0.8313, -5.9516],
        [-1.6535, -2.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661225497722626
Epoch 0, Step 3635: train/loss = 0.31145867705345154, train/raw-loss = 0.26769936084747314, train/logprobs = tensor([[-1.2451, -4.2486],
        [-4.1878, -1.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4375932812690735
Epoch 0, Step 3636: train/loss = 0.371171236038208, train/raw-loss = 0.3413558006286621, train/logprobs = tensor([[ -1.5588, -12.2367],
        [ -3.8766,  -2.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2981545627117157
Epoch 0, Step 3637: train/loss = 0.4764593839645386, train/raw-loss = 0.4362064599990845, train/logprobs = tensor([[-0.7183, -8.4468],
        [-2.1896, -1.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40252918004989624
Epoch 0, Step 3638: train/loss = 0.11023804545402527, train/raw-loss = 0.06921587884426117, train/logprobs = tensor([[ -1.1018, -12.1916],
        [ -4.0241,  -1.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.410221666097641
Epoch 0, Step 3639: train/loss = 0.22783513367176056, train/raw-loss = 0.18185900151729584, train/logprobs = tensor([[-1.1753, -5.0012],
        [-3.4764, -1.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4597611129283905
Epoch 0, Step 3640: train/loss = 0.28885674476623535, train/raw-loss = 0.2509112060070038, train/logprobs = tensor([[-1.1097, -6.3411],
        [-2.6212, -2.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3794551491737366
Epoch 0, Step 3641: train/loss = 0.4615558385848999, train/raw-loss = 0.4302707612514496, train/logprobs = tensor([[-2.4960, -4.4443],
        [-3.2150, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31285083293914795
Epoch 0, Step 3642: train/loss = 0.5941056609153748, train/raw-loss = 0.5596632957458496, train/logprobs = tensor([[-0.8177, -1.8029],
        [-1.4159, -1.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3444231152534485
Epoch 0, Step 3643: train/loss = 0.20149721205234528, train/raw-loss = 0.15568506717681885, train/logprobs = tensor([[ -0.6984, -11.7612],
        [ -3.9188,  -4.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45812147855758667
Epoch 0, Step 3644: train/loss = 0.26341137290000916, train/raw-loss = 0.23056015372276306, train/logprobs = tensor([[-1.5693, -6.5643],
        [-3.3469, -1.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285121023654938
Epoch 0, Step 3645: train/loss = 0.5240045189857483, train/raw-loss = 0.48582005500793457, train/logprobs = tensor([[-0.8710, -1.6916],
        [-2.0297, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38184428215026855
Epoch 0, Step 3646: train/loss = 0.21871168911457062, train/raw-loss = 0.1796557605266571, train/logprobs = tensor([[-1.5822, -8.6504],
        [-4.1914, -2.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905591368675232
Epoch 0, Step 3647: train/loss = 0.3216625452041626, train/raw-loss = 0.2923649549484253, train/logprobs = tensor([[-1.1245, -3.4534],
        [-2.3684, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929760217666626
Epoch 0, Step 3648: train/loss = 0.5360810160636902, train/raw-loss = 0.4860663414001465, train/logprobs = tensor([[-1.6916, -3.7452],
        [-2.7469, -1.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001459717750549
Epoch 0, Step 3649: train/loss = 0.35847190022468567, train/raw-loss = 0.31512314081192017, train/logprobs = tensor([[-1.8194, -3.9482],
        [-3.3931, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4334878921508789
Epoch 0, Step 3650: train/loss = 0.27277523279190063, train/raw-loss = 0.23813068866729736, train/logprobs = tensor([[ -0.9309, -10.1040],
        [ -3.1745,  -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34644538164138794
Epoch 0, Step 3651: train/loss = 0.10139697790145874, train/raw-loss = 0.05726088210940361, train/logprobs = tensor([[ -1.1807, -10.9804],
        [ -4.2763,  -2.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4413608908653259
Epoch 0, Step 3652: train/loss = 0.17200374603271484, train/raw-loss = 0.13678227365016937, train/logprobs = tensor([[-0.9360, -8.4465],
        [-2.4791, -1.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522149324417114
Epoch 0, Step 3653: train/loss = 0.5335434079170227, train/raw-loss = 0.5010947585105896, train/logprobs = tensor([[-2.7139, -6.3697],
        [-3.9595, -1.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244863450527191
Epoch 0, Step 3654: train/loss = 0.33334922790527344, train/raw-loss = 0.3045697510242462, train/logprobs = tensor([[-0.8850, -5.1988],
        [-3.3835, -1.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877947986125946
Epoch 0, Step 3655: train/loss = 0.11087027937173843, train/raw-loss = 0.06149882823228836, train/logprobs = tensor([[ -1.7267, -11.1651],
        [ -4.1796,  -2.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49371448159217834
Epoch 0, Step 3656: train/loss = 0.28922802209854126, train/raw-loss = 0.2600172162055969, train/logprobs = tensor([[-1.3428, -5.5173],
        [-2.4247, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2921081781387329
Epoch 0, Step 3657: train/loss = 0.32858043909072876, train/raw-loss = 0.29176607728004456, train/logprobs = tensor([[-1.2569, -3.5419],
        [-3.0578, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.368143767118454
Epoch 0, Step 3658: train/loss = 0.1466226875782013, train/raw-loss = 0.10746768116950989, train/logprobs = tensor([[ -1.7084, -13.5944],
        [ -3.4305,  -3.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39155006408691406
Epoch 0, Step 3659: train/loss = 0.6355921626091003, train/raw-loss = 0.5933865308761597, train/logprobs = tensor([[-2.0569, -6.3646],
        [-3.3112, -2.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4220566749572754
Epoch 0, Step 3660: train/loss = 0.4491046965122223, train/raw-loss = 0.417114794254303, train/logprobs = tensor([[-1.3861, -4.8906],
        [-2.9139, -2.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31989923119544983
Epoch 0, Step 3661: train/loss = 0.16699683666229248, train/raw-loss = 0.13540974259376526, train/logprobs = tensor([[-1.6757, -6.6558],
        [-3.5177, -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158709704875946
Epoch 0, Step 3662: train/loss = 0.07693074643611908, train/raw-loss = 0.03437178209424019, train/logprobs = tensor([[ -1.1978, -12.0739],
        [ -4.3975,  -2.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4255896806716919
Epoch 0, Step 3663: train/loss = 0.2577897012233734, train/raw-loss = 0.2195519655942917, train/logprobs = tensor([[-0.9070, -7.8949],
        [-3.4191, -1.3048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38237708806991577
Epoch 0, Step 3664: train/loss = 0.5752015709877014, train/raw-loss = 0.5339780449867249, train/logprobs = tensor([[-1.1104, -1.6011],
        [-2.4573, -1.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122355580329895
Epoch 0, Step 3665: train/loss = 0.2766152620315552, train/raw-loss = 0.2342103123664856, train/logprobs = tensor([[-0.7731, -5.8602],
        [-2.4342, -2.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4240494966506958
Epoch 0, Step 3666: train/loss = 0.42214444279670715, train/raw-loss = 0.3867362141609192, train/logprobs = tensor([[-0.9869, -6.2910],
        [-1.9879, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3540821373462677
Epoch 0, Step 3667: train/loss = 0.283619225025177, train/raw-loss = 0.2501787543296814, train/logprobs = tensor([[-1.6255, -6.7773],
        [-2.6601, -1.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33440467715263367
Epoch 0, Step 3668: train/loss = 0.2121364027261734, train/raw-loss = 0.17009826004505157, train/logprobs = tensor([[-0.9892, -6.5705],
        [-3.6848, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4203815460205078
Epoch 0, Step 3669: train/loss = 0.49474284052848816, train/raw-loss = 0.45005953311920166, train/logprobs = tensor([[-2.3105, -7.3572],
        [-2.4572, -1.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44683316349983215
Epoch 0, Step 3670: train/loss = 0.22065652906894684, train/raw-loss = 0.1874740868806839, train/logprobs = tensor([[ -1.1684, -15.8860],
        [ -2.8040,  -2.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33182448148727417
Epoch 0, Step 3671: train/loss = 0.4515533745288849, train/raw-loss = 0.4095240533351898, train/logprobs = tensor([[-0.9507, -4.0339],
        [-2.5261, -2.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4202931821346283
Epoch 0, Step 3672: train/loss = 0.2631445527076721, train/raw-loss = 0.22287258505821228, train/logprobs = tensor([[-2.4855, -4.7612],
        [-6.0837, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40271973609924316
Epoch 0, Step 3673: train/loss = 0.2827386260032654, train/raw-loss = 0.25020402669906616, train/logprobs = tensor([[ -1.2330, -10.6363],
        [ -2.9720,  -2.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253459632396698
Epoch 0, Step 3674: train/loss = 0.41080498695373535, train/raw-loss = 0.37555959820747375, train/logprobs = tensor([[-1.4316, -5.9667],
        [-3.4516, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35245388746261597
Epoch 0, Step 3675: train/loss = 0.41947227716445923, train/raw-loss = 0.3751254081726074, train/logprobs = tensor([[-1.1452, -7.0817],
        [-3.0573, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44346851110458374
Epoch 0, Step 3676: train/loss = 0.48191308975219727, train/raw-loss = 0.44846823811531067, train/logprobs = tensor([[-1.9801, -3.6818],
        [-2.2409, -0.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344483971595764
Epoch 0, Step 3677: train/loss = 0.14212176203727722, train/raw-loss = 0.09831752628087997, train/logprobs = tensor([[ -0.9321, -10.8870],
        [ -4.1571,  -3.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43804246187210083
Epoch 0, Step 3678: train/loss = 0.13745924830436707, train/raw-loss = 0.10125502198934555, train/logprobs = tensor([[ -1.4412, -10.7506],
        [ -3.8257,  -3.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36204221844673157
Epoch 0, Step 3679: train/loss = 0.26613613963127136, train/raw-loss = 0.23044957220554352, train/logprobs = tensor([[-1.2394, -5.9550],
        [-2.9830, -1.7135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568654954433441
Epoch 0, Step 3680: train/loss = 0.11278192698955536, train/raw-loss = 0.06876678019762039, train/logprobs = tensor([[-1.2703, -7.1291],
        [-3.6668, -1.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4401514530181885
Epoch 0, Step 3681: train/loss = 0.2114185243844986, train/raw-loss = 0.17296470701694489, train/logprobs = tensor([[-1.1289, -9.2188],
        [-3.2739, -2.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38453811407089233
Epoch 0, Step 3682: train/loss = 0.1449642777442932, train/raw-loss = 0.10384415835142136, train/logprobs = tensor([[-0.8686, -8.3307],
        [-3.3890, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112012982368469
Epoch 0, Step 3683: train/loss = 0.15676365792751312, train/raw-loss = 0.12895257771015167, train/logprobs = tensor([[-1.2491, -8.2961],
        [-3.4366, -2.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781107425689697
Epoch 0, Step 3684: train/loss = 0.19202303886413574, train/raw-loss = 0.1512061357498169, train/logprobs = tensor([[-1.8047, -6.8082],
        [-3.2779, -1.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40816885232925415
Epoch 0, Step 3685: train/loss = 0.18199267983436584, train/raw-loss = 0.13902759552001953, train/logprobs = tensor([[-1.1593, -9.9399],
        [-4.1491, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4296509325504303
Epoch 0, Step 3686: train/loss = 0.5010281801223755, train/raw-loss = 0.4639692008495331, train/logprobs = tensor([[-1.0132, -4.8118],
        [-2.0865, -1.5021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3705894649028778
Epoch 0, Step 3687: train/loss = 0.2641984522342682, train/raw-loss = 0.22025468945503235, train/logprobs = tensor([[-1.1339, -5.7338],
        [-3.0827, -2.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4394375681877136
Epoch 0, Step 3688: train/loss = 0.2895776033401489, train/raw-loss = 0.253201425075531, train/logprobs = tensor([[-1.1097, -6.0300],
        [-3.2027, -0.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36376193165779114
Epoch 0, Step 3689: train/loss = 0.23041482269763947, train/raw-loss = 0.19008922576904297, train/logprobs = tensor([[-0.8712, -4.1493],
        [-3.4077, -0.9749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4032557010650635
Epoch 0, Step 3690: train/loss = 0.24862626194953918, train/raw-loss = 0.21094593405723572, train/logprobs = tensor([[-2.5807, -7.1674],
        [-3.5363, -1.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37680304050445557
Epoch 0, Step 3691: train/loss = 0.23466737568378448, train/raw-loss = 0.20317333936691284, train/logprobs = tensor([[-0.9705, -9.0681],
        [-2.3627, -1.7700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149403929710388
Epoch 0, Step 3692: train/loss = 0.6241257190704346, train/raw-loss = 0.5868386626243591, train/logprobs = tensor([[-2.1135, -6.2451],
        [-2.1022, -1.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37287038564682007
Epoch 0, Step 3693: train/loss = 0.3601240813732147, train/raw-loss = 0.31250327825546265, train/logprobs = tensor([[-1.1385, -7.3126],
        [-3.0555, -1.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4762078523635864
Epoch 0, Step 3694: train/loss = 0.41689807176589966, train/raw-loss = 0.3860483169555664, train/logprobs = tensor([[-1.6839, -3.1476],
        [-3.6915, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084973692893982
Epoch 0, Step 3695: train/loss = 0.3804405927658081, train/raw-loss = 0.34071385860443115, train/logprobs = tensor([[-0.8093, -3.4173],
        [-2.6311, -1.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3972674012184143
Epoch 0, Step 3696: train/loss = 0.430085688829422, train/raw-loss = 0.3950175642967224, train/logprobs = tensor([[-1.4016, -4.7631],
        [-3.2671, -1.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3506811261177063
Epoch 0, Step 3697: train/loss = 0.2679423689842224, train/raw-loss = 0.22744816541671753, train/logprobs = tensor([[-1.5443, -9.8406],
        [-3.1014, -1.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049421548843384
Epoch 0, Step 3698: train/loss = 0.22439192235469818, train/raw-loss = 0.1834532469511032, train/logprobs = tensor([[-1.1341, -8.9802],
        [-3.3250, -1.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4093868136405945
Epoch 0, Step 3699: train/loss = 0.41393768787384033, train/raw-loss = 0.37878262996673584, train/logprobs = tensor([[-1.8330, -5.4074],
        [-3.1465, -2.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3515501916408539
Epoch 0, Step 3700: train/loss = 0.2942889928817749, train/raw-loss = 0.26692140102386475, train/logprobs = tensor([[-0.6648, -6.4559],
        [-1.5862, -1.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27367570996284485
Epoch 0, Step 3701: train/loss = 0.30849215388298035, train/raw-loss = 0.2720654010772705, train/logprobs = tensor([[ -2.1662, -11.7783],
        [ -3.4913,  -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3642674386501312
Epoch 0, Step 3702: train/loss = 0.2694055736064911, train/raw-loss = 0.2367909550666809, train/logprobs = tensor([[-1.0489, -8.0115],
        [-2.4833, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32614606618881226
Epoch 0, Step 3703: train/loss = 0.04983137920498848, train/raw-loss = 0.017385534942150116, train/logprobs = tensor([[ -1.5627, -26.0641],
        [ -5.4878,  -7.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32445842027664185
Epoch 0, Step 3704: train/loss = 0.3255757689476013, train/raw-loss = 0.2742442190647125, train/logprobs = tensor([[-1.4737, -6.2116],
        [-3.4494, -2.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5133154392242432
Epoch 0, Step 3705: train/loss = 0.6581946611404419, train/raw-loss = 0.6050442457199097, train/logprobs = tensor([[-1.0600, -8.6371],
        [-3.4754, -3.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5315049886703491
Epoch 0, Step 3706: train/loss = 0.6398547291755676, train/raw-loss = 0.5949311256408691, train/logprobs = tensor([[-1.6458, -2.2216],
        [-2.0027, -1.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44923681020736694
Epoch 0, Step 3707: train/loss = 0.39839237928390503, train/raw-loss = 0.36588501930236816, train/logprobs = tensor([[-2.3544, -5.7266],
        [-2.9046, -1.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32507315278053284
Epoch 0, Step 3708: train/loss = 0.43772709369659424, train/raw-loss = 0.3896637558937073, train/logprobs = tensor([[-1.5035, -4.2978],
        [-3.6388, -2.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48063358664512634
Epoch 0, Step 3709: train/loss = 0.27533745765686035, train/raw-loss = 0.23754273355007172, train/logprobs = tensor([[-0.9613, -7.1029],
        [-2.6270, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37794744968414307
Epoch 0, Step 3710: train/loss = 0.5281381607055664, train/raw-loss = 0.4984649419784546, train/logprobs = tensor([[-1.6171, -2.2925],
        [-1.7048, -1.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967318892478943
Epoch 0, Step 3711: train/loss = 0.4364307224750519, train/raw-loss = 0.40562358498573303, train/logprobs = tensor([[-1.3744, -2.5909],
        [-3.0052, -1.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080712556838989
Epoch 0, Step 3712: train/loss = 0.3406488299369812, train/raw-loss = 0.31159698963165283, train/logprobs = tensor([[-1.8404, -4.7279],
        [-2.2803, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29051870107650757
Epoch 0, Step 3713: train/loss = 0.4042920172214508, train/raw-loss = 0.3757737874984741, train/logprobs = tensor([[-1.1962, -3.4307],
        [-2.7708, -0.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.285182386636734
Epoch 0, Step 3714: train/loss = 0.12939605116844177, train/raw-loss = 0.09140896052122116, train/logprobs = tensor([[-1.5127, -7.3438],
        [-4.2780, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37987083196640015
Epoch 0, Step 3715: train/loss = 0.3048171401023865, train/raw-loss = 0.27468156814575195, train/logprobs = tensor([[-1.6258, -5.9570],
        [-2.5469, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30135586857795715
Epoch 0, Step 3716: train/loss = 0.3455459177494049, train/raw-loss = 0.2958816587924957, train/logprobs = tensor([[-1.6687, -4.9329],
        [-2.9365, -1.6346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4966425895690918
Epoch 0, Step 3717: train/loss = 0.16830387711524963, train/raw-loss = 0.12660615146160126, train/logprobs = tensor([[ -1.0787, -10.6426],
        [ -3.0547,  -1.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4169773757457733
Epoch 0, Step 3718: train/loss = 0.3903140425682068, train/raw-loss = 0.3450603783130646, train/logprobs = tensor([[-1.7542, -3.6054],
        [-2.7240, -1.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4525367021560669
Epoch 0, Step 3719: train/loss = 0.07680892944335938, train/raw-loss = 0.036362286657094955, train/logprobs = tensor([[-1.5832, -8.1472],
        [-4.5445, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4044664204120636
Epoch 0, Step 3720: train/loss = 0.30999913811683655, train/raw-loss = 0.2725483775138855, train/logprobs = tensor([[-2.1006, -5.0058],
        [-3.4951, -1.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3745076060295105
Epoch 0, Step 3721: train/loss = 0.56330806016922, train/raw-loss = 0.5278576016426086, train/logprobs = tensor([[-1.2132, -2.2693],
        [-1.7639, -1.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35450491309165955
Epoch 0, Step 3722: train/loss = 0.26686573028564453, train/raw-loss = 0.22849954664707184, train/logprobs = tensor([[-1.4211, -4.4476],
        [-2.5124, -1.2193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38366180658340454
Epoch 0, Step 3723: train/loss = 0.34036606550216675, train/raw-loss = 0.31007614731788635, train/logprobs = tensor([[-1.3817, -4.3892],
        [-2.6922, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028991222381592
Epoch 0, Step 3724: train/loss = 0.24219001829624176, train/raw-loss = 0.20481491088867188, train/logprobs = tensor([[-1.2718, -8.7934],
        [-3.4037, -1.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3737511932849884
Epoch 0, Step 3725: train/loss = 0.1283150613307953, train/raw-loss = 0.09308923780918121, train/logprobs = tensor([[-1.2617, -7.9485],
        [-3.1265, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522581458091736
Epoch 0, Step 3726: train/loss = 0.460494726896286, train/raw-loss = 0.4349221885204315, train/logprobs = tensor([[-1.0930, -4.5607],
        [-1.5731, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25572532415390015
Epoch 0, Step 3727: train/loss = 0.4573930501937866, train/raw-loss = 0.41874274611473083, train/logprobs = tensor([[-1.2937, -2.7251],
        [-2.9250, -1.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3865030109882355
Epoch 0, Step 3728: train/loss = 0.3660138249397278, train/raw-loss = 0.3331272304058075, train/logprobs = tensor([[-1.0109, -5.3262],
        [-2.1867, -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886600494384766
Epoch 0, Step 3729: train/loss = 0.18786506354808807, train/raw-loss = 0.1560327112674713, train/logprobs = tensor([[-1.3805, -4.4245],
        [-2.9823, -0.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3183234632015228
Epoch 0, Step 3730: train/loss = 0.49820274114608765, train/raw-loss = 0.46686720848083496, train/logprobs = tensor([[-1.0618, -2.1237],
        [-2.3268, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31335529685020447
Epoch 0, Step 3731: train/loss = 0.28199121356010437, train/raw-loss = 0.2470228224992752, train/logprobs = tensor([[-1.4502, -7.5553],
        [-3.0704, -2.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496839702129364
Epoch 0, Step 3732: train/loss = 0.17474986612796783, train/raw-loss = 0.1434527486562729, train/logprobs = tensor([[-1.3674, -9.6928],
        [-2.5237, -1.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129711449146271
Epoch 0, Step 3733: train/loss = 0.28502774238586426, train/raw-loss = 0.24114610254764557, train/logprobs = tensor([[-2.0032, -8.2688],
        [-4.9077, -3.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4388161897659302
Epoch 0, Step 3734: train/loss = 0.4667842388153076, train/raw-loss = 0.4270685613155365, train/logprobs = tensor([[-1.1109, -3.5287],
        [-2.4340, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39715683460235596
Epoch 0, Step 3735: train/loss = 0.38788771629333496, train/raw-loss = 0.3555397093296051, train/logprobs = tensor([[-1.5942, -5.7163],
        [-2.3573, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32348036766052246
Epoch 0, Step 3736: train/loss = 0.5658921003341675, train/raw-loss = 0.5320132374763489, train/logprobs = tensor([[-1.0686, -2.7992],
        [-1.9267, -1.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33878833055496216
Epoch 0, Step 3737: train/loss = 0.2277347892522812, train/raw-loss = 0.18624958395957947, train/logprobs = tensor([[-1.8485, -6.6950],
        [-3.9296, -1.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41485223174095154
Epoch 0, Step 3738: train/loss = 0.476121187210083, train/raw-loss = 0.438223659992218, train/logprobs = tensor([[-1.5734, -5.0102],
        [-2.5610, -1.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789755702018738
Epoch 0, Step 3739: train/loss = 0.3853694796562195, train/raw-loss = 0.33685779571533203, train/logprobs = tensor([[-1.0811, -4.5157],
        [-3.8906, -1.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4851168096065521
Epoch 0, Step 3740: train/loss = 0.4176410138607025, train/raw-loss = 0.376874715089798, train/logprobs = tensor([[-0.8017, -3.2973],
        [-2.3873, -1.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4076632261276245
Epoch 0, Step 3741: train/loss = 0.14163002371788025, train/raw-loss = 0.10686706751585007, train/logprobs = tensor([[ -1.7588, -12.7723],
        [ -3.6556,  -3.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34762948751449585
Epoch 0, Step 3742: train/loss = 0.2929854989051819, train/raw-loss = 0.2455332726240158, train/logprobs = tensor([[-0.8350, -6.8252],
        [-3.5621, -1.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4745219945907593
Epoch 0, Step 3743: train/loss = 0.274618923664093, train/raw-loss = 0.24090024828910828, train/logprobs = tensor([[-0.8638, -7.9615],
        [-2.7603, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33718663454055786
Epoch 0, Step 3744: train/loss = 0.2862696349620819, train/raw-loss = 0.2496766746044159, train/logprobs = tensor([[-1.5959, -5.4522],
        [-3.8115, -1.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36592957377433777
Epoch 0, Step 3745: train/loss = 0.06852971762418747, train/raw-loss = 0.027213500812649727, train/logprobs = tensor([[-1.6611, -8.6951],
        [-4.8899, -2.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4131621718406677
Epoch 0, Step 3746: train/loss = 0.38051360845565796, train/raw-loss = 0.34542572498321533, train/logprobs = tensor([[-1.0617, -3.9612],
        [-2.3995, -1.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35087910294532776
Epoch 0, Step 3747: train/loss = 0.41149377822875977, train/raw-loss = 0.3729601502418518, train/logprobs = tensor([[-1.1898, -6.7526],
        [-2.5353, -1.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.385336309671402
Epoch 0, Step 3748: train/loss = 0.3383471369743347, train/raw-loss = 0.3038836419582367, train/logprobs = tensor([[-1.0419, -6.1679],
        [-2.7361, -1.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344635009765625
Epoch 0, Step 3749: train/loss = 0.3891846537590027, train/raw-loss = 0.34627699851989746, train/logprobs = tensor([[-1.7623, -4.2918],
        [-3.5006, -2.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42907655239105225
Epoch 0, Step 3750: train/loss = 0.2728332281112671, train/raw-loss = 0.225474014878273, train/logprobs = tensor([[-1.1374, -7.8338],
        [-2.9838, -2.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47359204292297363
Epoch 0, Step 3751: train/loss = 0.5245979428291321, train/raw-loss = 0.49000364542007446, train/logprobs = tensor([[-1.3823, -2.3056],
        [-1.6908, -1.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34594282507896423
Epoch 0, Step 3752: train/loss = 0.41117334365844727, train/raw-loss = 0.3789621889591217, train/logprobs = tensor([[-2.0349, -8.9514],
        [-2.6092, -2.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32211166620254517
Epoch 0, Step 3753: train/loss = 0.08390353620052338, train/raw-loss = 0.04076904430985451, train/logprobs = tensor([[ -1.4271, -11.1086],
        [ -4.4198,  -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4313448965549469
Epoch 0, Step 3754: train/loss = 0.29871392250061035, train/raw-loss = 0.26362717151641846, train/logprobs = tensor([[-1.3751, -5.7338],
        [-3.2665, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35086750984191895
Epoch 0, Step 3755: train/loss = 0.2458290308713913, train/raw-loss = 0.20857909321784973, train/logprobs = tensor([[ -1.1548, -11.4242],
        [ -3.4327,  -3.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37249940633773804
Epoch 0, Step 3756: train/loss = 0.38255196809768677, train/raw-loss = 0.3396153450012207, train/logprobs = tensor([[-1.0649, -9.5499],
        [-2.7293, -1.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4293662905693054
Epoch 0, Step 3757: train/loss = 0.2996281683444977, train/raw-loss = 0.2576332688331604, train/logprobs = tensor([[-1.5720, -4.8114],
        [-3.2193, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199489951133728
Epoch 0, Step 3758: train/loss = 0.3099325895309448, train/raw-loss = 0.27908220887184143, train/logprobs = tensor([[-1.3836, -5.1669],
        [-2.5666, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3085035979747772
Epoch 0, Step 3759: train/loss = 0.3179788291454315, train/raw-loss = 0.271452933549881, train/logprobs = tensor([[-1.0108, -4.4322],
        [-3.0351, -1.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4652586877346039
Epoch 0, Step 3760: train/loss = 0.6820766925811768, train/raw-loss = 0.6535283327102661, train/logprobs = tensor([[-1.7097, -4.9089],
        [-1.7382, -3.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28548315167427063
Epoch 0, Step 3761: train/loss = 0.43075093626976013, train/raw-loss = 0.4001803994178772, train/logprobs = tensor([[-1.7620, -3.0890],
        [-2.6511, -1.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3057054281234741
Epoch 0, Step 3762: train/loss = 0.2431655079126358, train/raw-loss = 0.202703058719635, train/logprobs = tensor([[-1.2354, -6.4348],
        [-2.7599, -2.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40462422370910645
Epoch 0, Step 3763: train/loss = 0.2646349370479584, train/raw-loss = 0.22337870299816132, train/logprobs = tensor([[-1.1256, -7.7678],
        [-3.2673, -2.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4125623404979706
Epoch 0, Step 3764: train/loss = 0.5948934555053711, train/raw-loss = 0.562450647354126, train/logprobs = tensor([[-0.9477, -2.2143],
        [-1.8551, -1.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244280517101288
Epoch 0, Step 3765: train/loss = 0.645416259765625, train/raw-loss = 0.6057659387588501, train/logprobs = tensor([[-2.4886, -9.3883],
        [-2.5832, -1.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3965037167072296
Epoch 0, Step 3766: train/loss = 0.3735857605934143, train/raw-loss = 0.33794698119163513, train/logprobs = tensor([[-1.2097, -6.4061],
        [-2.9422, -1.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35638755559921265
Epoch 0, Step 3767: train/loss = 0.41850101947784424, train/raw-loss = 0.3840222954750061, train/logprobs = tensor([[-1.7270, -4.4435],
        [-2.7973, -1.5806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344787061214447
Epoch 0, Step 3768: train/loss = 0.20802311599254608, train/raw-loss = 0.17080572247505188, train/logprobs = tensor([[-1.1453, -8.2655],
        [-3.0448, -1.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.372173935174942
Epoch 0, Step 3769: train/loss = 0.397053062915802, train/raw-loss = 0.36990824341773987, train/logprobs = tensor([[-0.9174, -7.5894],
        [-1.8432, -1.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2714485824108124
Epoch 0, Step 3770: train/loss = 0.3204647898674011, train/raw-loss = 0.27467530965805054, train/logprobs = tensor([[-1.2564, -5.5066],
        [-3.2064, -2.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4578949213027954
Epoch 0, Step 3771: train/loss = 0.3400844931602478, train/raw-loss = 0.30563247203826904, train/logprobs = tensor([[-1.3526, -4.8029],
        [-3.6875, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3445199728012085
Epoch 0, Step 3772: train/loss = 0.14283835887908936, train/raw-loss = 0.10575038194656372, train/logprobs = tensor([[-1.1538, -8.4381],
        [-3.2927, -2.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37087979912757874
Epoch 0, Step 3773: train/loss = 0.09819769114255905, train/raw-loss = 0.06063922867178917, train/logprobs = tensor([[ -1.0384, -10.6600],
        [ -3.4280,  -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37558460235595703
Epoch 0, Step 3774: train/loss = 0.5199897289276123, train/raw-loss = 0.4740729033946991, train/logprobs = tensor([[-1.8242, -3.6809],
        [-2.7052, -1.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45916783809661865
Epoch 0, Step 3775: train/loss = 0.1339961439371109, train/raw-loss = 0.10117620974779129, train/logprobs = tensor([[-1.0276, -5.8551],
        [-3.5544, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281991481781006
Epoch 0, Step 3776: train/loss = 0.2376476526260376, train/raw-loss = 0.19940972328186035, train/logprobs = tensor([[-1.0751, -6.3817],
        [-3.4487, -1.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3823792040348053
Epoch 0, Step 3777: train/loss = 0.17596162855625153, train/raw-loss = 0.13309021294116974, train/logprobs = tensor([[-0.6925, -9.4796],
        [-3.7542, -3.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42871397733688354
Epoch 0, Step 3778: train/loss = 0.5079423189163208, train/raw-loss = 0.45863139629364014, train/logprobs = tensor([[-1.5167, -3.2537],
        [-4.0266, -3.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4931095242500305
Epoch 0, Step 3779: train/loss = 0.573931872844696, train/raw-loss = 0.5427552461624146, train/logprobs = tensor([[-1.7621, -4.6414],
        [-1.7844, -1.5883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31176552176475525
Epoch 0, Step 3780: train/loss = 0.6102535724639893, train/raw-loss = 0.5846813321113586, train/logprobs = tensor([[-1.7528, -3.1017],
        [-1.5895, -1.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557217478752136
Epoch 0, Step 3781: train/loss = 0.32003849744796753, train/raw-loss = 0.2814045250415802, train/logprobs = tensor([[-1.0483, -8.3353],
        [-2.6272, -3.2238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38633978366851807
Epoch 0, Step 3782: train/loss = 0.26538288593292236, train/raw-loss = 0.22492828965187073, train/logprobs = tensor([[-1.2363, -9.2714],
        [-2.5604, -1.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40454602241516113
Epoch 0, Step 3783: train/loss = 0.18776623904705048, train/raw-loss = 0.1543436050415039, train/logprobs = tensor([[-2.2676, -6.0637],
        [-3.8432, -2.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3342263102531433
Epoch 0, Step 3784: train/loss = 0.14019349217414856, train/raw-loss = 0.09976889938116074, train/logprobs = tensor([[-1.3104, -9.2446],
        [-3.9376, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40424591302871704
Epoch 0, Step 3785: train/loss = 0.4928428530693054, train/raw-loss = 0.45901501178741455, train/logprobs = tensor([[-1.8943, -4.1877],
        [-1.9967, -1.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382783830165863
Epoch 0, Step 3786: train/loss = 0.3725067973136902, train/raw-loss = 0.3366551399230957, train/logprobs = tensor([[-2.1771, -5.6442],
        [-3.5817, -2.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3585160970687866
Epoch 0, Step 3787: train/loss = 0.559078574180603, train/raw-loss = 0.5229419469833374, train/logprobs = tensor([[-1.2209, -3.5558],
        [-2.1270, -1.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3613668978214264
Epoch 0, Step 3788: train/loss = 0.47979819774627686, train/raw-loss = 0.44496890902519226, train/logprobs = tensor([[-2.2637, -4.8546],
        [-3.5321, -3.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34829309582710266
Epoch 0, Step 3789: train/loss = 0.12081204354763031, train/raw-loss = 0.08632470667362213, train/logprobs = tensor([[-1.6177, -9.2840],
        [-4.0550, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3448733389377594
Epoch 0, Step 3790: train/loss = 0.15921810269355774, train/raw-loss = 0.11999239027500153, train/logprobs = tensor([[-1.8978, -9.8353],
        [-4.0104, -1.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922571837902069
Epoch 0, Step 3791: train/loss = 0.4618224799633026, train/raw-loss = 0.4223008453845978, train/logprobs = tensor([[-1.1295, -2.9068],
        [-3.5529, -2.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3952162563800812
Epoch 0, Step 3792: train/loss = 0.3936583697795868, train/raw-loss = 0.3474826216697693, train/logprobs = tensor([[-1.2444, -4.0291],
        [-2.5544, -1.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46175718307495117
Epoch 0, Step 3793: train/loss = 0.4107791781425476, train/raw-loss = 0.383004754781723, train/logprobs = tensor([[-1.6128, -2.8598],
        [-2.5967, -1.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27774423360824585
Epoch 0, Step 3794: train/loss = 0.24751992523670197, train/raw-loss = 0.20686571300029755, train/logprobs = tensor([[-1.1275, -8.3517],
        [-3.3556, -2.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4065418839454651
Epoch 0, Step 3795: train/loss = 0.299492210149765, train/raw-loss = 0.27108317613601685, train/logprobs = tensor([[ -1.3852, -10.0663],
        [ -2.1515,  -3.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28409016132354736
Epoch 0, Step 3796: train/loss = 0.39468568563461304, train/raw-loss = 0.3473021388053894, train/logprobs = tensor([[-1.7043, -6.2383],
        [-3.6956, -1.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47383540868759155
Epoch 0, Step 3797: train/loss = 0.10130465030670166, train/raw-loss = 0.06724103540182114, train/logprobs = tensor([[-0.9405, -8.6192],
        [-3.0505, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34063610434532166
Epoch 0, Step 3798: train/loss = 0.20747700333595276, train/raw-loss = 0.17079982161521912, train/logprobs = tensor([[-1.6448, -6.9575],
        [-3.3429, -2.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3667718470096588
Epoch 0, Step 3799: train/loss = 0.08406571298837662, train/raw-loss = 0.03732535243034363, train/logprobs = tensor([[-1.4060, -9.1733],
        [-4.4435, -1.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4674035906791687
Epoch 0, Step 3800: train/loss = 0.3371909260749817, train/raw-loss = 0.30056530237197876, train/logprobs = tensor([[-1.3411, -9.3341],
        [-2.8935, -2.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36625614762306213
Epoch 0, Step 3801: train/loss = 0.39113423228263855, train/raw-loss = 0.3610074520111084, train/logprobs = tensor([[-1.4396, -7.8752],
        [-2.2895, -1.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30126774311065674
Epoch 0, Step 3802: train/loss = 0.28664445877075195, train/raw-loss = 0.25331220030784607, train/logprobs = tensor([[-1.4759, -8.9453],
        [-2.8789, -2.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333221971988678
Epoch 0, Step 3803: train/loss = 0.3160206377506256, train/raw-loss = 0.27429208159446716, train/logprobs = tensor([[-1.2071, -3.7337],
        [-3.1137, -2.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4172859191894531
Epoch 0, Step 3804: train/loss = 0.14146029949188232, train/raw-loss = 0.10135282576084137, train/logprobs = tensor([[-1.5323, -8.4852],
        [-5.0872, -2.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010747969150543
Epoch 0, Step 3805: train/loss = 0.27327966690063477, train/raw-loss = 0.23733116686344147, train/logprobs = tensor([[-1.9436, -9.7280],
        [-3.8874, -2.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3594849109649658
Epoch 0, Step 3806: train/loss = 0.38780850172042847, train/raw-loss = 0.34364578127861023, train/logprobs = tensor([[-1.3343, -6.9268],
        [-3.6041, -2.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4416271448135376
Epoch 0, Step 3807: train/loss = 0.17302671074867249, train/raw-loss = 0.13755246996879578, train/logprobs = tensor([[ -1.7107, -12.3402],
        [ -4.2646,  -4.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35474225878715515
Epoch 0, Step 3808: train/loss = 0.44521212577819824, train/raw-loss = 0.4117032289505005, train/logprobs = tensor([[-1.2771, -5.2204],
        [-2.8405, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33508890867233276
Epoch 0, Step 3809: train/loss = 0.6844450831413269, train/raw-loss = 0.6569133400917053, train/logprobs = tensor([[-1.4544, -6.1448],
        [-1.8020, -2.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2753177583217621
Epoch 0, Step 3810: train/loss = 0.5048828125, train/raw-loss = 0.4709656536579132, train/logprobs = tensor([[-1.5258, -7.3667],
        [-2.6518, -1.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3391714096069336
Epoch 0, Step 3811: train/loss = 0.1270991414785385, train/raw-loss = 0.09262144565582275, train/logprobs = tensor([[-1.0304, -5.7008],
        [-4.8115, -1.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34477701783180237
Epoch 0, Step 3812: train/loss = 0.3873807191848755, train/raw-loss = 0.3397177755832672, train/logprobs = tensor([[-1.6931, -6.5041],
        [-2.8930, -2.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4766296446323395
Epoch 0, Step 3813: train/loss = 0.25829723477363586, train/raw-loss = 0.2194882035255432, train/logprobs = tensor([[-2.3123, -8.2731],
        [-3.8937, -1.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38809019327163696
Epoch 0, Step 3814: train/loss = 0.28471076488494873, train/raw-loss = 0.25433140993118286, train/logprobs = tensor([[-0.6198, -7.7676],
        [-1.8497, -2.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30379366874694824
Epoch 0, Step 3815: train/loss = 0.445101797580719, train/raw-loss = 0.4142056703567505, train/logprobs = tensor([[-1.1876, -3.7851],
        [-2.4258, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30896079540252686
Epoch 0, Step 3816: train/loss = 0.28205087780952454, train/raw-loss = 0.2453238070011139, train/logprobs = tensor([[ -2.7520, -14.0087],
        [ -4.3964,  -4.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36727064847946167
Epoch 0, Step 3817: train/loss = 0.4055890440940857, train/raw-loss = 0.37318509817123413, train/logprobs = tensor([[-0.9913, -4.5165],
        [-2.8088, -1.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240395188331604
Epoch 0, Step 3818: train/loss = 0.5594545006752014, train/raw-loss = 0.5303783416748047, train/logprobs = tensor([[-2.1339, -5.0908],
        [-1.9613, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29076170921325684
Epoch 0, Step 3819: train/loss = 0.36600959300994873, train/raw-loss = 0.33436551690101624, train/logprobs = tensor([[-1.0247, -3.1199],
        [-2.2907, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164404630661011
Epoch 0, Step 3820: train/loss = 0.20905537903308868, train/raw-loss = 0.17411364614963531, train/logprobs = tensor([[-1.1141, -4.8302],
        [-3.4491, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3494172990322113
Epoch 0, Step 3821: train/loss = 0.6282191276550293, train/raw-loss = 0.5814605355262756, train/logprobs = tensor([[-1.8300, -3.3719],
        [-3.0714, -2.9634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46758562326431274
Epoch 0, Step 3822: train/loss = 0.5100287199020386, train/raw-loss = 0.4735735356807709, train/logprobs = tensor([[-1.7726, -4.6743],
        [-1.7392, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36455169320106506
Epoch 0, Step 3823: train/loss = 0.40928149223327637, train/raw-loss = 0.3751260042190552, train/logprobs = tensor([[-2.2511, -5.0597],
        [-2.6103, -1.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34155523777008057
Epoch 0, Step 3824: train/loss = 0.2710978090763092, train/raw-loss = 0.23765428364276886, train/logprobs = tensor([[-0.7641, -3.7071],
        [-3.2107, -1.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344354033470154
Epoch 0, Step 3825: train/loss = 0.4758913516998291, train/raw-loss = 0.43786388635635376, train/logprobs = tensor([[-0.8959, -3.6996],
        [-2.8477, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38027486205101013
Epoch 0, Step 3826: train/loss = 0.22194421291351318, train/raw-loss = 0.1832253336906433, train/logprobs = tensor([[-1.1921, -4.3779],
        [-3.7643, -1.3372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871889114379883
Epoch 0, Step 3827: train/loss = 0.36689138412475586, train/raw-loss = 0.33018529415130615, train/logprobs = tensor([[-1.2704, -3.3379],
        [-2.6049, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3670611083507538
Epoch 0, Step 3828: train/loss = 0.34140193462371826, train/raw-loss = 0.30003851652145386, train/logprobs = tensor([[-1.6682, -7.2997],
        [-3.9301, -1.5094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4136340022087097
Epoch 0, Step 3829: train/loss = 0.36248475313186646, train/raw-loss = 0.3330557942390442, train/logprobs = tensor([[-0.6423, -4.5607],
        [-1.5248, -1.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942895293235779
Epoch 0, Step 3830: train/loss = 0.2369966357946396, train/raw-loss = 0.19870838522911072, train/logprobs = tensor([[-1.8661, -8.2222],
        [-3.4457, -1.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3828824460506439
Epoch 0, Step 3831: train/loss = 0.5774083137512207, train/raw-loss = 0.5388532876968384, train/logprobs = tensor([[-1.3001, -1.5752],
        [-2.0515, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38554999232292175
Epoch 0, Step 3832: train/loss = 0.39920565485954285, train/raw-loss = 0.36076125502586365, train/logprobs = tensor([[-1.1881, -4.8782],
        [-2.9287, -1.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38444384932518005
Epoch 0, Step 3833: train/loss = 0.3256475031375885, train/raw-loss = 0.2930874526500702, train/logprobs = tensor([[-1.5918, -7.1477],
        [-3.1142, -1.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32560068368911743
Epoch 0, Step 3834: train/loss = 0.09875312447547913, train/raw-loss = 0.06155974417924881, train/logprobs = tensor([[ -1.3935, -13.5848],
        [ -3.9546,  -2.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37193381786346436
Epoch 0, Step 3835: train/loss = 0.10426893830299377, train/raw-loss = 0.06929097324609756, train/logprobs = tensor([[ -1.6746, -10.7820],
        [ -4.0086,  -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497796654701233
Epoch 0, Step 3836: train/loss = 0.34072345495224, train/raw-loss = 0.30648019909858704, train/logprobs = tensor([[-1.6130, -7.5656],
        [-3.0622, -1.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3424326777458191
Epoch 0, Step 3837: train/loss = 0.3126193583011627, train/raw-loss = 0.2744435966014862, train/logprobs = tensor([[-1.2396, -6.3451],
        [-3.9193, -1.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38175785541534424
Epoch 0, Step 3838: train/loss = 0.34579920768737793, train/raw-loss = 0.3202419579029083, train/logprobs = tensor([[ -2.7375, -13.1855],
        [ -3.7582,  -4.3662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555725872516632
Epoch 0, Step 3839: train/loss = 0.29294103384017944, train/raw-loss = 0.2586674094200134, train/logprobs = tensor([[-1.7314, -5.9297],
        [-3.8342, -1.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34273621439933777
Epoch 0, Step 3840: train/loss = 0.1616385579109192, train/raw-loss = 0.12655775249004364, train/logprobs = tensor([[-1.9227, -8.3945],
        [-4.4264, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3508080840110779
Epoch 0, Step 3841: train/loss = 0.36027854681015015, train/raw-loss = 0.32479697465896606, train/logprobs = tensor([[-1.0176, -3.5087],
        [-3.6568, -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3548155128955841
Epoch 0, Step 3842: train/loss = 0.3525369465351105, train/raw-loss = 0.3163776099681854, train/logprobs = tensor([[ -1.6251, -15.5927],
        [ -3.6971,  -3.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615938127040863
Epoch 0, Step 3843: train/loss = 0.11222554743289948, train/raw-loss = 0.06500288844108582, train/logprobs = tensor([[ -1.1614, -10.6107],
        [ -3.7354,  -3.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47222664952278137
Epoch 0, Step 3844: train/loss = 0.3607500493526459, train/raw-loss = 0.32015976309776306, train/logprobs = tensor([[-1.5625, -9.0619],
        [-3.6728, -3.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4059026539325714
Epoch 0, Step 3845: train/loss = 0.7330949902534485, train/raw-loss = 0.7004590630531311, train/logprobs = tensor([[-4.7213, -9.2690],
        [-3.2868, -2.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3263590335845947
Epoch 0, Step 3846: train/loss = 0.25458863377571106, train/raw-loss = 0.21638444066047668, train/logprobs = tensor([[-1.6681, -5.4300],
        [-4.5997, -1.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38204196095466614
Epoch 0, Step 3847: train/loss = 0.12421996891498566, train/raw-loss = 0.09708816558122635, train/logprobs = tensor([[ -1.1606, -14.8010],
        [ -2.7634,  -3.4382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713180482387543
Epoch 0, Step 3848: train/loss = 0.4335528612136841, train/raw-loss = 0.39829590916633606, train/logprobs = tensor([[ -2.8083, -15.3444],
        [ -3.1403,  -2.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525696396827698
Epoch 0, Step 3849: train/loss = 0.4107085168361664, train/raw-loss = 0.37395352125167847, train/logprobs = tensor([[-0.9267, -5.2202],
        [-2.9476, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3675500154495239
Epoch 0, Step 3850: train/loss = 0.15983961522579193, train/raw-loss = 0.1135973185300827, train/logprobs = tensor([[-2.0946, -8.5581],
        [-3.9587, -2.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46242278814315796
Epoch 0, Step 3851: train/loss = 0.36441007256507874, train/raw-loss = 0.32639753818511963, train/logprobs = tensor([[-0.9803, -5.8085],
        [-1.9853, -1.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3801254332065582
Epoch 0, Step 3852: train/loss = 0.8370440006256104, train/raw-loss = 0.8022259473800659, train/logprobs = tensor([[-2.6165, -6.1039],
        [-2.0791, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34818050265312195
Epoch 0, Step 3853: train/loss = 0.6045690774917603, train/raw-loss = 0.5631433725357056, train/logprobs = tensor([[-2.0876, -5.1990],
        [-2.9863, -2.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41425657272338867
Epoch 0, Step 3854: train/loss = 0.18403512239456177, train/raw-loss = 0.1394052505493164, train/logprobs = tensor([[ -1.9187, -11.3516],
        [ -3.8124,  -1.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4462985694408417
Epoch 0, Step 3855: train/loss = 0.5954959392547607, train/raw-loss = 0.5596106052398682, train/logprobs = tensor([[-2.0394, -6.1159],
        [-2.3495, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35885292291641235
Epoch 0, Step 3856: train/loss = 0.46295055747032166, train/raw-loss = 0.42428281903266907, train/logprobs = tensor([[-1.4449, -3.3333],
        [-3.1744, -1.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3866775631904602
Epoch 0, Step 3857: train/loss = 0.5420573949813843, train/raw-loss = 0.5093653798103333, train/logprobs = tensor([[-1.7185, -9.3112],
        [-2.0820, -2.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32692062854766846
Epoch 0, Step 3858: train/loss = 0.4577787518501282, train/raw-loss = 0.42300134897232056, train/logprobs = tensor([[-1.5797, -4.2979],
        [-2.7013, -1.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477739989757538
Epoch 0, Step 3859: train/loss = 0.24766740202903748, train/raw-loss = 0.20636820793151855, train/logprobs = tensor([[-1.3732, -5.8105],
        [-4.2525, -1.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4129919707775116
Epoch 0, Step 3860: train/loss = 0.3044838309288025, train/raw-loss = 0.2674207389354706, train/logprobs = tensor([[-1.3469, -6.0423],
        [-3.1112, -1.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37063106894493103
Epoch 0, Step 3861: train/loss = 0.10191671550273895, train/raw-loss = 0.05380568653345108, train/logprobs = tensor([[-1.1247, -9.2960],
        [-4.1315, -1.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48111021518707275
Epoch 0, Step 3862: train/loss = 0.23274379968643188, train/raw-loss = 0.19578656554222107, train/logprobs = tensor([[ -1.8696, -11.7889],
        [ -3.5889,  -3.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3695722818374634
Epoch 0, Step 3863: train/loss = 0.4923122227191925, train/raw-loss = 0.4683086574077606, train/logprobs = tensor([[-2.2254, -5.2972],
        [-1.7114, -1.2848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24003568291664124
Epoch 0, Step 3864: train/loss = 0.3197759985923767, train/raw-loss = 0.2771124541759491, train/logprobs = tensor([[-1.6608, -6.3986],
        [-3.9199, -1.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.426635205745697
Epoch 0, Step 3865: train/loss = 0.1973709613084793, train/raw-loss = 0.15954668819904327, train/logprobs = tensor([[-1.3397, -4.9237],
        [-3.7178, -1.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782425820827484
Epoch 0, Step 3866: train/loss = 0.522527813911438, train/raw-loss = 0.48177075386047363, train/logprobs = tensor([[-3.4331, -7.2734],
        [-4.1247, -2.1930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4075705409049988
Epoch 0, Step 3867: train/loss = 0.25387829542160034, train/raw-loss = 0.22347718477249146, train/logprobs = tensor([[-1.7560, -7.2165],
        [-3.3857, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30401140451431274
Epoch 0, Step 3868: train/loss = 0.33267027139663696, train/raw-loss = 0.29234299063682556, train/logprobs = tensor([[-1.8568, -7.1692],
        [-3.3029, -1.7732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40327292680740356
Epoch 0, Step 3869: train/loss = 0.17245420813560486, train/raw-loss = 0.1367167979478836, train/logprobs = tensor([[-1.2195, -5.8046],
        [-4.3297, -2.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3573741316795349
Epoch 0, Step 3870: train/loss = 0.5552946329116821, train/raw-loss = 0.5179778337478638, train/logprobs = tensor([[-1.2329, -7.4302],
        [-2.6559, -3.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37316811084747314
Epoch 0, Step 3871: train/loss = 0.43188947439193726, train/raw-loss = 0.391323983669281, train/logprobs = tensor([[-1.3498, -6.4747],
        [-2.6407, -2.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40565499663352966
Epoch 0, Step 3872: train/loss = 0.35866859555244446, train/raw-loss = 0.32260772585868835, train/logprobs = tensor([[ -2.3955, -14.6388],
        [ -5.0293,  -5.2818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36060866713523865
Epoch 0, Step 3873: train/loss = 0.5294617414474487, train/raw-loss = 0.4935779869556427, train/logprobs = tensor([[-2.2741, -6.3639],
        [-2.5977, -3.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35883793234825134
Epoch 0, Step 3874: train/loss = 0.6777918934822083, train/raw-loss = 0.6421635746955872, train/logprobs = tensor([[-3.0562, -6.5775],
        [-2.8854, -1.3423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35628363490104675
Epoch 0, Step 3875: train/loss = 0.5118570327758789, train/raw-loss = 0.4765062928199768, train/logprobs = tensor([[-1.5920, -3.1089],
        [-3.7114, -2.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3535071909427643
Epoch 0, Step 3876: train/loss = 0.285049170255661, train/raw-loss = 0.24295392632484436, train/logprobs = tensor([[-1.9036, -6.0015],
        [-5.2978, -1.3155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4209522604942322
Epoch 0, Step 3877: train/loss = 0.6225610971450806, train/raw-loss = 0.5947812795639038, train/logprobs = tensor([[-1.5792, -2.1755],
        [-1.3366, -1.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27779829502105713
Epoch 0, Step 3878: train/loss = 0.11283674836158752, train/raw-loss = 0.0754719004034996, train/logprobs = tensor([[-1.4833, -7.9872],
        [-3.5732, -1.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3736484944820404
Epoch 0, Step 3879: train/loss = 0.3430587649345398, train/raw-loss = 0.3119747042655945, train/logprobs = tensor([[-1.6419, -5.6186],
        [-2.5390, -1.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108406364917755
Epoch 0, Step 3880: train/loss = 0.6717379689216614, train/raw-loss = 0.6341660618782043, train/logprobs = tensor([[-1.7571, -2.0911],
        [-2.3172, -2.2677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3757193684577942
Epoch 0, Step 3881: train/loss = 0.3194238543510437, train/raw-loss = 0.27883490920066833, train/logprobs = tensor([[-1.2137, -6.6936],
        [-3.1513, -3.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4058891832828522
Epoch 0, Step 3882: train/loss = 0.2472427785396576, train/raw-loss = 0.20410043001174927, train/logprobs = tensor([[-2.0052, -4.7312],
        [-3.4514, -1.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4314234256744385
Epoch 0, Step 3883: train/loss = 0.5324268341064453, train/raw-loss = 0.5081807374954224, train/logprobs = tensor([[-2.0358, -7.5133],
        [-2.0457, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24246154725551605
Epoch 0, Step 3884: train/loss = 0.33034735918045044, train/raw-loss = 0.28448203206062317, train/logprobs = tensor([[-0.8042, -4.7406],
        [-4.1817, -1.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4586534798145294
Epoch 0, Step 3885: train/loss = 0.261840283870697, train/raw-loss = 0.22250422835350037, train/logprobs = tensor([[-1.5488, -5.9316],
        [-3.0710, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3933607041835785
Epoch 0, Step 3886: train/loss = 0.3598083257675171, train/raw-loss = 0.3258309066295624, train/logprobs = tensor([[-0.9707, -4.0614],
        [-2.3439, -1.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33977439999580383
Epoch 0, Step 3887: train/loss = 0.4227468967437744, train/raw-loss = 0.38597553968429565, train/logprobs = tensor([[-1.5197, -7.5364],
        [-3.0995, -1.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3677138686180115
Epoch 0, Step 3888: train/loss = 0.15256670117378235, train/raw-loss = 0.11294062435626984, train/logprobs = tensor([[ -1.2429, -17.1941],
        [ -2.8426,  -3.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39626073837280273
Epoch 0, Step 3889: train/loss = 0.13383673131465912, train/raw-loss = 0.09624598920345306, train/logprobs = tensor([[ -1.7215, -16.8884],
        [ -4.2558,  -3.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37590739130973816
Epoch 0, Step 3890: train/loss = 0.0700351744890213, train/raw-loss = 0.02418798953294754, train/logprobs = tensor([[ -1.3938, -14.3427],
        [ -4.7685,  -2.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4584718346595764
Epoch 0, Step 3891: train/loss = 0.4357927441596985, train/raw-loss = 0.3972872197628021, train/logprobs = tensor([[-1.1746, -2.8140],
        [-2.4043, -2.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850553631782532
Epoch 0, Step 3892: train/loss = 0.5644378662109375, train/raw-loss = 0.5308833718299866, train/logprobs = tensor([[-2.5989, -3.3664],
        [-3.1450, -1.3273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33554577827453613
Epoch 0, Step 3893: train/loss = 0.332131952047348, train/raw-loss = 0.29824984073638916, train/logprobs = tensor([[-2.2247, -6.2441],
        [-3.1773, -2.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3388211727142334
Epoch 0, Step 3894: train/loss = 0.4502824544906616, train/raw-loss = 0.40659013390541077, train/logprobs = tensor([[-1.4236, -4.2400],
        [-2.6757, -2.3690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43692314624786377
Epoch 0, Step 3895: train/loss = 0.5598001480102539, train/raw-loss = 0.5258392095565796, train/logprobs = tensor([[-1.3172, -3.0550],
        [-1.5104, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396098017692566
Epoch 0, Step 3896: train/loss = 0.15715524554252625, train/raw-loss = 0.12572219967842102, train/logprobs = tensor([[-0.9904, -8.3378],
        [-2.8637, -1.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31433045864105225
Epoch 0, Step 3897: train/loss = 0.07686609029769897, train/raw-loss = 0.043907731771469116, train/logprobs = tensor([[ -2.0384, -17.1259],
        [ -4.9048,  -4.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295835554599762
Epoch 0, Step 3898: train/loss = 0.10975340008735657, train/raw-loss = 0.07281379401683807, train/logprobs = tensor([[-2.0164, -9.3125],
        [-4.6643, -1.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3693959712982178
Epoch 0, Step 3899: train/loss = 0.3801649212837219, train/raw-loss = 0.34793621301651, train/logprobs = tensor([[-1.4002, -5.8335],
        [-3.5520, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32228749990463257
Epoch 0, Step 3900: train/loss = 0.06475524604320526, train/raw-loss = 0.021795593202114105, train/logprobs = tensor([[-1.4432, -9.7973],
        [-5.0165, -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.429596483707428
Epoch 0, Step 3901: train/loss = 0.3744795620441437, train/raw-loss = 0.33905550837516785, train/logprobs = tensor([[-1.2077, -5.7914],
        [-2.5063, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35424038767814636
Epoch 0, Step 3902: train/loss = 0.16898566484451294, train/raw-loss = 0.1325969398021698, train/logprobs = tensor([[-1.3071, -7.0915],
        [-3.8719, -2.0080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3638872504234314
Epoch 0, Step 3903: train/loss = 0.3099304139614105, train/raw-loss = 0.27671322226524353, train/logprobs = tensor([[-2.1542, -6.4508],
        [-2.8871, -1.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321716785430908
Epoch 0, Step 3904: train/loss = 0.47414135932922363, train/raw-loss = 0.44275692105293274, train/logprobs = tensor([[-1.3044, -7.9235],
        [-2.7180, -1.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3138444423675537
Epoch 0, Step 3905: train/loss = 0.5202410817146301, train/raw-loss = 0.4764528274536133, train/logprobs = tensor([[-1.4413, -7.7760],
        [-3.5767, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43788236379623413
Epoch 0, Step 3906: train/loss = 0.1892036497592926, train/raw-loss = 0.14805394411087036, train/logprobs = tensor([[-1.3865, -9.9026],
        [-3.8183, -2.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4114970862865448
Epoch 0, Step 3907: train/loss = 0.2649790644645691, train/raw-loss = 0.23312613368034363, train/logprobs = tensor([[-1.2785, -8.8706],
        [-3.4841, -1.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31852948665618896
Epoch 0, Step 3908: train/loss = 0.23702269792556763, train/raw-loss = 0.18969912827014923, train/logprobs = tensor([[-1.8471, -6.3406],
        [-4.8815, -2.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.473235547542572
Epoch 0, Step 3909: train/loss = 0.4137686491012573, train/raw-loss = 0.3749094605445862, train/logprobs = tensor([[ -2.6498, -16.8888],
        [ -4.5967,  -4.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885919749736786
Epoch 0, Step 3910: train/loss = 0.7213044166564941, train/raw-loss = 0.6823031902313232, train/logprobs = tensor([[-1.6356, -3.1118],
        [-2.2054, -1.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3900122046470642
Epoch 0, Step 3911: train/loss = 0.3079691529273987, train/raw-loss = 0.2637730538845062, train/logprobs = tensor([[-0.6512, -2.9199],
        [-2.6946, -1.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44196099042892456
Epoch 0, Step 3912: train/loss = 0.19703717529773712, train/raw-loss = 0.16002093255519867, train/logprobs = tensor([[ -1.6497, -14.3772],
        [ -3.5395,  -4.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37016260623931885
Epoch 0, Step 3913: train/loss = 0.5394366979598999, train/raw-loss = 0.49348121881484985, train/logprobs = tensor([[-1.2968, -2.7455],
        [-2.9841, -2.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4595547318458557
Epoch 0, Step 3914: train/loss = 0.4503212571144104, train/raw-loss = 0.41616934537887573, train/logprobs = tensor([[-1.7012, -5.8010],
        [-3.3608, -1.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34151890873908997
Epoch 0, Step 3915: train/loss = 0.4205285608768463, train/raw-loss = 0.377107173204422, train/logprobs = tensor([[ -2.2063, -10.4236],
        [ -3.2753,  -3.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43421387672424316
Epoch 0, Step 3916: train/loss = 0.3805115818977356, train/raw-loss = 0.34325146675109863, train/logprobs = tensor([[-1.7888, -8.5669],
        [-3.5600, -1.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726009726524353
Epoch 0, Step 3917: train/loss = 1.2666964530944824, train/raw-loss = 1.2316062450408936, train/logprobs = tensor([[-5.6444, -9.8516],
        [-3.1781, -2.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3509008288383484
Epoch 0, Step 3918: train/loss = 0.2253861427307129, train/raw-loss = 0.18939386308193207, train/logprobs = tensor([[-0.5956, -8.9987],
        [-2.4540, -1.0660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.359922856092453
Epoch 0, Step 3919: train/loss = 0.32499420642852783, train/raw-loss = 0.28751540184020996, train/logprobs = tensor([[-1.3973, -9.0509],
        [-4.3591, -2.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37478774785995483
Epoch 0, Step 3920: train/loss = 0.1904027760028839, train/raw-loss = 0.15433402359485626, train/logprobs = tensor([[-1.5055, -6.8802],
        [-3.5503, -1.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606874942779541
Epoch 0, Step 3921: train/loss = 0.42491424083709717, train/raw-loss = 0.3862319886684418, train/logprobs = tensor([[ -2.3966, -11.2951],
        [ -3.1730,  -2.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38682225346565247
Epoch 0, Step 3922: train/loss = 0.2214801162481308, train/raw-loss = 0.1857566386461258, train/logprobs = tensor([[-1.6208, -8.1270],
        [-2.5123, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3572347164154053
Epoch 0, Step 3923: train/loss = 0.663634717464447, train/raw-loss = 0.6350926160812378, train/logprobs = tensor([[-2.1142, -3.7964],
        [-2.4307, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2854205369949341
Epoch 0, Step 3924: train/loss = 0.4559862017631531, train/raw-loss = 0.41872483491897583, train/logprobs = tensor([[-1.2919, -9.7180],
        [-4.3190, -2.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726140856742859
Epoch 0, Step 3925: train/loss = 0.6096878051757812, train/raw-loss = 0.577671468257904, train/logprobs = tensor([[-2.6928, -5.4857],
        [-3.9007, -1.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201638162136078
Epoch 0, Step 3926: train/loss = 0.32053443789482117, train/raw-loss = 0.28329703211784363, train/logprobs = tensor([[-1.5978, -3.4622],
        [-4.0730, -1.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3723742961883545
Epoch 0, Step 3927: train/loss = 0.2425575852394104, train/raw-loss = 0.2000579535961151, train/logprobs = tensor([[-1.2166, -6.9897],
        [-3.7601, -1.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4249962270259857
Epoch 0, Step 3928: train/loss = 0.3133973777294159, train/raw-loss = 0.2710030972957611, train/logprobs = tensor([[-0.9218, -8.5244],
        [-3.4998, -1.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4239428639411926
Epoch 0, Step 3929: train/loss = 0.13140131533145905, train/raw-loss = 0.08591806143522263, train/logprobs = tensor([[-1.8790, -9.7381],
        [-4.1874, -2.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4548325538635254
Epoch 0, Step 3930: train/loss = 0.34985411167144775, train/raw-loss = 0.31594759225845337, train/logprobs = tensor([[-1.9289, -7.6267],
        [-3.5256, -2.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33906543254852295
Epoch 0, Step 3931: train/loss = 0.5449138879776001, train/raw-loss = 0.5087848901748657, train/logprobs = tensor([[-1.2013, -2.7764],
        [-2.1685, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3612903654575348
Epoch 0, Step 3932: train/loss = 0.27430686354637146, train/raw-loss = 0.2364654541015625, train/logprobs = tensor([[-1.2752, -7.7712],
        [-3.6722, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784137964248657
Epoch 0, Step 3933: train/loss = 0.282587468624115, train/raw-loss = 0.24786829948425293, train/logprobs = tensor([[ -1.9400, -12.0458],
        [ -3.8033,  -2.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34719157218933105
Epoch 0, Step 3934: train/loss = 0.07468745857477188, train/raw-loss = 0.038952432572841644, train/logprobs = tensor([[-0.8997, -9.1035],
        [-4.0428, -1.3775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35735028982162476
Epoch 0, Step 3935: train/loss = 0.22221218049526215, train/raw-loss = 0.18197116255760193, train/logprobs = tensor([[-1.0843, -7.0358],
        [-4.0173, -1.4936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4024101793766022
Epoch 0, Step 3936: train/loss = 0.21553650498390198, train/raw-loss = 0.17730183899402618, train/logprobs = tensor([[ -1.0535, -11.4333],
        [ -4.0973,  -3.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38234660029411316
Epoch 0, Step 3937: train/loss = 0.49646544456481934, train/raw-loss = 0.45632022619247437, train/logprobs = tensor([[-1.6311, -5.3922],
        [-2.3370, -1.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.401451975107193
Epoch 0, Step 3938: train/loss = 0.2146473377943039, train/raw-loss = 0.17872701585292816, train/logprobs = tensor([[ -1.4733, -11.2044],
        [ -4.7709,  -2.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592031002044678
Epoch 0, Step 3939: train/loss = 0.11253538727760315, train/raw-loss = 0.07368256896734238, train/logprobs = tensor([[-1.1384, -9.3865],
        [-4.1020, -2.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885282576084137
Epoch 0, Step 3940: train/loss = 0.3022530972957611, train/raw-loss = 0.25500205159187317, train/logprobs = tensor([[-1.0160, -5.0669],
        [-3.2697, -1.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4725104868412018
Epoch 0, Step 3941: train/loss = 0.779363214969635, train/raw-loss = 0.7267376780509949, train/logprobs = tensor([[-1.2770, -2.3736],
        [-2.7898, -3.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5262550115585327
Epoch 0, Step 3942: train/loss = 0.4267216920852661, train/raw-loss = 0.379781037569046, train/logprobs = tensor([[-1.4750, -7.8965],
        [-3.6960, -1.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4694065749645233
Epoch 0, Step 3943: train/loss = 0.3811032176017761, train/raw-loss = 0.34245872497558594, train/logprobs = tensor([[-1.2055, -4.2943],
        [-5.4660, -2.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3864448666572571
Epoch 0, Step 3944: train/loss = 0.41048991680145264, train/raw-loss = 0.3670913875102997, train/logprobs = tensor([[-1.8251, -7.9715],
        [-3.4727, -3.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4339852035045624
Epoch 0, Step 3945: train/loss = 0.38506457209587097, train/raw-loss = 0.3487662076950073, train/logprobs = tensor([[-1.6949, -4.7008],
        [-3.6059, -0.7643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629832863807678
Epoch 0, Step 3946: train/loss = 0.3467805087566376, train/raw-loss = 0.31981176137924194, train/logprobs = tensor([[-1.8302, -5.3680],
        [-2.7826, -0.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696872353553772
Epoch 0, Step 3947: train/loss = 0.1521313488483429, train/raw-loss = 0.1180574893951416, train/logprobs = tensor([[-1.9932, -9.4283],
        [-4.4562, -2.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3407386839389801
Epoch 0, Step 3948: train/loss = 0.36943042278289795, train/raw-loss = 0.3309420645236969, train/logprobs = tensor([[-1.5220, -8.4082],
        [-3.2196, -2.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.384883314371109
Epoch 0, Step 3949: train/loss = 0.20784252882003784, train/raw-loss = 0.1713535189628601, train/logprobs = tensor([[-2.5429, -9.3044],
        [-5.6529, -1.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3648901879787445
Epoch 0, Step 3950: train/loss = 0.30169984698295593, train/raw-loss = 0.2659062147140503, train/logprobs = tensor([[-2.3489, -7.8070],
        [-3.2316, -2.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35793620347976685
Epoch 0, Step 3951: train/loss = 0.20975415408611298, train/raw-loss = 0.16814008355140686, train/logprobs = tensor([[-0.9303, -4.9546],
        [-3.8313, -2.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.416140615940094
Epoch 0, Step 3952: train/loss = 1.2126164436340332, train/raw-loss = 1.1672145128250122, train/logprobs = tensor([[-4.5115, -6.2012],
        [-2.7225, -2.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.454019695520401
Epoch 0, Step 3953: train/loss = 0.30734783411026, train/raw-loss = 0.26950934529304504, train/logprobs = tensor([[-1.2585, -9.6579],
        [-3.8359, -1.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37838512659072876
Epoch 0, Step 3954: train/loss = 0.459219753742218, train/raw-loss = 0.4202977418899536, train/logprobs = tensor([[-1.1090, -2.0934],
        [-2.5719, -1.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3892204463481903
Epoch 0, Step 3955: train/loss = 0.17435124516487122, train/raw-loss = 0.13899600505828857, train/logprobs = tensor([[-1.3342, -9.3135],
        [-3.2076, -2.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3535524606704712
Epoch 0, Step 3956: train/loss = 0.07956013083457947, train/raw-loss = 0.04806696996092796, train/logprobs = tensor([[ -1.3766, -12.1183],
        [ -4.2881,  -2.5661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31493160128593445
Epoch 0, Step 3957: train/loss = 0.16945451498031616, train/raw-loss = 0.1305764764547348, train/logprobs = tensor([[-1.2344, -7.9311],
        [-4.5817, -2.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38878023624420166
Epoch 0, Step 3958: train/loss = 0.3783178925514221, train/raw-loss = 0.33315104246139526, train/logprobs = tensor([[-1.5990, -3.3248],
        [-3.5796, -2.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45166847109794617
Epoch 0, Step 3959: train/loss = 0.4001293480396271, train/raw-loss = 0.36694473028182983, train/logprobs = tensor([[-3.1292, -6.3271],
        [-3.6689, -1.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3318461775779724
Epoch 0, Step 3960: train/loss = 0.09020381420850754, train/raw-loss = 0.05098013952374458, train/logprobs = tensor([[-1.0749, -5.5023],
        [-4.8886, -2.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39223670959472656
Epoch 0, Step 3961: train/loss = 0.2194010615348816, train/raw-loss = 0.17446742951869965, train/logprobs = tensor([[ -1.1738, -11.1290],
        [ -2.9062,  -1.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44933608174324036
Epoch 0, Step 3962: train/loss = 0.3016619384288788, train/raw-loss = 0.26941171288490295, train/logprobs = tensor([[ -1.4371, -11.3255],
        [ -4.0289,  -4.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32250213623046875
Epoch 0, Step 3963: train/loss = 0.4741635322570801, train/raw-loss = 0.4353124499320984, train/logprobs = tensor([[-1.6364, -3.0524],
        [-3.8983, -2.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38851118087768555
Epoch 0, Step 3964: train/loss = 0.10104686766862869, train/raw-loss = 0.05733866989612579, train/logprobs = tensor([[-1.6628, -9.5742],
        [-4.0339, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4370819926261902
Epoch 0, Step 3965: train/loss = 0.27088749408721924, train/raw-loss = 0.24043139815330505, train/logprobs = tensor([[ -0.9760, -10.5024],
        [ -2.9010,  -1.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30456098914146423
Epoch 0, Step 3966: train/loss = 0.304957777261734, train/raw-loss = 0.2678724229335785, train/logprobs = tensor([[-1.9906, -4.9147],
        [-4.5153, -2.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37085339426994324
Epoch 0, Step 3967: train/loss = 0.29531019926071167, train/raw-loss = 0.24611534178256989, train/logprobs = tensor([[ -1.6305, -10.6782],
        [ -4.1610,  -2.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4919486343860626
Epoch 0, Step 3968: train/loss = 0.38366785645484924, train/raw-loss = 0.34814345836639404, train/logprobs = tensor([[-1.6869, -7.2199],
        [-2.4381, -1.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3552440404891968
Epoch 0, Step 3969: train/loss = 0.329659104347229, train/raw-loss = 0.28755682706832886, train/logprobs = tensor([[-1.7149, -5.7518],
        [-4.1078, -2.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4210227429866791
Epoch 0, Step 3970: train/loss = 0.24038487672805786, train/raw-loss = 0.20126530528068542, train/logprobs = tensor([[-1.0781, -9.3905],
        [-3.8379, -3.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3911956548690796
Epoch 0, Step 3971: train/loss = 0.46004509925842285, train/raw-loss = 0.42770227789878845, train/logprobs = tensor([[-2.1202, -3.8788],
        [-3.0338, -1.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3234279155731201
Epoch 0, Step 3972: train/loss = 0.16096708178520203, train/raw-loss = 0.12452005594968796, train/logprobs = tensor([[-1.5373, -8.7751],
        [-4.1867, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36447012424468994
Epoch 0, Step 3973: train/loss = 0.07532352954149246, train/raw-loss = 0.03696012496948242, train/logprobs = tensor([[ -0.7796, -17.4825],
        [ -4.3838,  -3.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383634090423584
Epoch 0, Step 3974: train/loss = 0.36435097455978394, train/raw-loss = 0.30588439106941223, train/logprobs = tensor([[-1.1783, -9.8369],
        [-4.8776, -2.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5846658945083618
Epoch 0, Step 3975: train/loss = 0.39321574568748474, train/raw-loss = 0.3565306067466736, train/logprobs = tensor([[-2.3028, -9.7339],
        [-2.7168, -2.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.366851270198822
Epoch 0, Step 3976: train/loss = 0.391069233417511, train/raw-loss = 0.35173875093460083, train/logprobs = tensor([[-1.6153, -3.8674],
        [-3.3289, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39330437779426575
Epoch 0, Step 3977: train/loss = 0.36517733335494995, train/raw-loss = 0.32581138610839844, train/logprobs = tensor([[-2.0529, -8.4647],
        [-3.3288, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3936595022678375
Epoch 0, Step 3978: train/loss = 0.7476649284362793, train/raw-loss = 0.7179707288742065, train/logprobs = tensor([[-1.9995, -4.1312],
        [-1.3996, -1.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2969418168067932
Epoch 0, Step 3979: train/loss = 0.09649818390607834, train/raw-loss = 0.06402890384197235, train/logprobs = tensor([[ -1.6186, -12.0819],
        [ -4.1092,  -2.7554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32469284534454346
Epoch 0, Step 3980: train/loss = 0.126617893576622, train/raw-loss = 0.08778957277536392, train/logprobs = tensor([[ -2.5393, -10.0457],
        [ -4.8371,  -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3882831931114197
Epoch 0, Step 3981: train/loss = 0.16510923206806183, train/raw-loss = 0.1207856759428978, train/logprobs = tensor([[ -2.5855, -11.6854],
        [ -5.7063,  -4.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44323551654815674
Epoch 0, Step 3982: train/loss = 0.38064587116241455, train/raw-loss = 0.34723591804504395, train/logprobs = tensor([[-1.6568, -5.8837],
        [-4.2191, -3.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33409956097602844
Epoch 0, Step 3983: train/loss = 0.08289723843336105, train/raw-loss = 0.041393011808395386, train/logprobs = tensor([[ -1.9137, -18.4235],
        [ -4.6583,  -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4150422215461731
Epoch 0, Step 3984: train/loss = 0.5125121474266052, train/raw-loss = 0.4683014154434204, train/logprobs = tensor([[-1.1438, -4.6039],
        [-3.1800, -2.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4421074390411377
Epoch 0, Step 3985: train/loss = 0.3368431627750397, train/raw-loss = 0.2937764525413513, train/logprobs = tensor([[-1.7728, -4.7743],
        [-3.6232, -2.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4306671917438507
Epoch 0, Step 3986: train/loss = 0.5725808143615723, train/raw-loss = 0.536754846572876, train/logprobs = tensor([[-4.2940, -7.8470],
        [-4.4470, -2.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3582598567008972
Epoch 0, Step 3987: train/loss = 0.6581044793128967, train/raw-loss = 0.609056830406189, train/logprobs = tensor([[-2.1838, -7.0238],
        [-3.6196, -2.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49047672748565674
Epoch 0, Step 3988: train/loss = 0.42081260681152344, train/raw-loss = 0.3834104835987091, train/logprobs = tensor([[-1.2746, -2.9772],
        [-3.0408, -1.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37402114272117615
Epoch 0, Step 3989: train/loss = 0.2504894435405731, train/raw-loss = 0.21038158237934113, train/logprobs = tensor([[-1.0436, -9.7222],
        [-3.1042, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40107858180999756
Epoch 0, Step 3990: train/loss = 0.10661283135414124, train/raw-loss = 0.059320684522390366, train/logprobs = tensor([[ -1.7643, -12.6583],
        [ -4.1761,  -1.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4729214906692505
Epoch 0, Step 3991: train/loss = 0.17534495890140533, train/raw-loss = 0.14737468957901, train/logprobs = tensor([[ -1.8988, -13.1870],
        [ -4.9323,  -3.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2797025442123413
Epoch 0, Step 3992: train/loss = 0.42457833886146545, train/raw-loss = 0.38994359970092773, train/logprobs = tensor([[-1.3668, -4.8187],
        [-3.2298, -2.4412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3463471531867981
Epoch 0, Step 3993: train/loss = 0.5564000606536865, train/raw-loss = 0.5214928984642029, train/logprobs = tensor([[-1.5737, -4.4878],
        [-2.2042, -1.7446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490718603134155
Epoch 0, Step 3994: train/loss = 0.28727471828460693, train/raw-loss = 0.24783124029636383, train/logprobs = tensor([[-1.1074, -7.6287],
        [-3.7111, -3.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3944348692893982
Epoch 0, Step 3995: train/loss = 0.07119539380073547, train/raw-loss = 0.031716637313365936, train/logprobs = tensor([[ -2.0560, -16.9056],
        [ -5.5708,  -2.2607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3947875499725342
Epoch 0, Step 3996: train/loss = 0.28553536534309387, train/raw-loss = 0.24945068359375, train/logprobs = tensor([[-1.7364, -8.7153],
        [-3.8367, -1.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.360846608877182
Epoch 0, Step 3997: train/loss = 0.2235034555196762, train/raw-loss = 0.177756667137146, train/logprobs = tensor([[-1.4555, -5.1696],
        [-3.1218, -2.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4574679732322693
Epoch 0, Step 3998: train/loss = 0.11494837701320648, train/raw-loss = 0.07884394377470016, train/logprobs = tensor([[ -1.3066, -10.7057],
        [ -3.7127,  -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.361044317483902
Epoch 0, Step 3999: train/loss = 0.3185213506221771, train/raw-loss = 0.2822287678718567, train/logprobs = tensor([[-1.4215, -6.1500],
        [-3.1130, -1.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629259169101715
Epoch 0, Step 4000: train/loss = 0.8161666393280029, train/raw-loss = 0.7701946496963501, train/logprobs = tensor([[-2.9368, -3.7626],
        [-2.8190, -2.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4597194492816925
Epoch 0, Step 4001: train/loss = 0.51140958070755, train/raw-loss = 0.47291287779808044, train/logprobs = tensor([[-2.9461, -4.0798],
        [-3.7269, -1.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3849670886993408
Epoch 0, Step 4002: train/loss = 0.2762746214866638, train/raw-loss = 0.24101758003234863, train/logprobs = tensor([[-1.9190, -7.0708],
        [-3.2680, -2.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525705337524414
Epoch 0, Step 4003: train/loss = 0.2762187421321869, train/raw-loss = 0.2383762151002884, train/logprobs = tensor([[-1.5422, -6.5397],
        [-3.4323, -1.6339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784252405166626
Epoch 0, Step 4004: train/loss = 0.2510511875152588, train/raw-loss = 0.21557475626468658, train/logprobs = tensor([[-1.3850, -4.5493],
        [-3.5523, -1.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547641336917877
Epoch 0, Step 4005: train/loss = 0.14399637281894684, train/raw-loss = 0.10070832073688507, train/logprobs = tensor([[ -2.2529, -10.0434],
        [ -4.4717,  -1.2784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4328806400299072
Epoch 0, Step 4006: train/loss = 0.24509719014167786, train/raw-loss = 0.21087752282619476, train/logprobs = tensor([[-1.6155, -8.4749],
        [-3.8889, -2.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.342196524143219
Epoch 0, Step 4007: train/loss = 0.5270853042602539, train/raw-loss = 0.4943915009498596, train/logprobs = tensor([[-2.0087, -3.1641],
        [-2.1398, -1.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3269382417201996
Epoch 0, Step 4008: train/loss = 0.3829817771911621, train/raw-loss = 0.34760037064552307, train/logprobs = tensor([[-1.0415, -3.9679],
        [-2.5312, -1.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3538142442703247
Epoch 0, Step 4009: train/loss = 0.48420166969299316, train/raw-loss = 0.4562811851501465, train/logprobs = tensor([[ -2.6456, -13.3104],
        [ -2.9087,  -4.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27920466661453247
Epoch 0, Step 4010: train/loss = 0.24449484050273895, train/raw-loss = 0.20642021298408508, train/logprobs = tensor([[-1.1704, -6.3268],
        [-4.4840, -1.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807462453842163
Epoch 0, Step 4011: train/loss = 0.13701319694519043, train/raw-loss = 0.10741009563207626, train/logprobs = tensor([[ -1.7018, -16.5175],
        [ -4.4983,  -4.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960309386253357
Epoch 0, Step 4012: train/loss = 0.44784069061279297, train/raw-loss = 0.41337376832962036, train/logprobs = tensor([[-1.8833, -3.1272],
        [-2.9360, -2.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34466931223869324
Epoch 0, Step 4013: train/loss = 0.27086079120635986, train/raw-loss = 0.24098733067512512, train/logprobs = tensor([[-2.4052, -9.3989],
        [-3.6888, -1.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987348735332489
Epoch 0, Step 4014: train/loss = 0.5371668338775635, train/raw-loss = 0.5027936100959778, train/logprobs = tensor([[ -2.5233, -11.0272],
        [ -2.8892,  -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34373214840888977
Epoch 0, Step 4015: train/loss = 0.27583691477775574, train/raw-loss = 0.2377822995185852, train/logprobs = tensor([[-1.2878, -5.7571],
        [-2.9900, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3805461525917053
Epoch 0, Step 4016: train/loss = 0.39363881945610046, train/raw-loss = 0.3530436158180237, train/logprobs = tensor([[-1.6837, -5.2106],
        [-3.7236, -2.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40595173835754395
Epoch 0, Step 4017: train/loss = 0.40543314814567566, train/raw-loss = 0.3688051998615265, train/logprobs = tensor([[-1.9635, -2.4026],
        [-3.1462, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3662794232368469
Epoch 0, Step 4018: train/loss = 0.061732590198516846, train/raw-loss = 0.013920732773840427, train/logprobs = tensor([[-1.1526, -7.0316],
        [-5.5953, -1.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4781185984611511
Epoch 0, Step 4019: train/loss = 0.07988953590393066, train/raw-loss = 0.039773374795913696, train/logprobs = tensor([[-1.6086, -8.0912],
        [-5.2785, -1.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4011616110801697
Epoch 0, Step 4020: train/loss = 0.11433471739292145, train/raw-loss = 0.07381287962198257, train/logprobs = tensor([[-1.2689, -8.6185],
        [-3.6042, -1.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40521836280822754
Epoch 0, Step 4021: train/loss = 0.6764538884162903, train/raw-loss = 0.6395949721336365, train/logprobs = tensor([[-1.4336, -2.8439],
        [-2.2521, -1.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3685890734195709
Epoch 0, Step 4022: train/loss = 0.4618808329105377, train/raw-loss = 0.428851842880249, train/logprobs = tensor([[-1.5060, -8.4937],
        [-3.2090, -3.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3302896320819855
Epoch 0, Step 4023: train/loss = 0.19139716029167175, train/raw-loss = 0.1566227227449417, train/logprobs = tensor([[-1.4842, -6.8766],
        [-3.1142, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34774428606033325
Epoch 0, Step 4024: train/loss = 0.40594789385795593, train/raw-loss = 0.36735963821411133, train/logprobs = tensor([[ -1.7279, -10.5223],
        [ -4.0817,  -2.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858821988105774
Epoch 0, Step 4025: train/loss = 0.6236686110496521, train/raw-loss = 0.5818430185317993, train/logprobs = tensor([[-1.0730, -5.0065],
        [-2.1544, -1.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182560443878174
Epoch 0, Step 4026: train/loss = 0.28618818521499634, train/raw-loss = 0.24392704665660858, train/logprobs = tensor([[-0.9771, -8.2256],
        [-2.7582, -2.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4226113259792328
Epoch 0, Step 4027: train/loss = 0.8749147653579712, train/raw-loss = 0.8407074213027954, train/logprobs = tensor([[-2.1058, -2.1589],
        [-2.4114, -2.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34207427501678467
Epoch 0, Step 4028: train/loss = 0.23484447598457336, train/raw-loss = 0.20040985941886902, train/logprobs = tensor([[ -1.3930, -13.4737],
        [ -4.0598,  -1.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3443463146686554
Epoch 0, Step 4029: train/loss = 0.5246699452400208, train/raw-loss = 0.488168329000473, train/logprobs = tensor([[-1.6537, -2.5875],
        [-2.4597, -1.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36501646041870117
Epoch 0, Step 4030: train/loss = 0.6320998668670654, train/raw-loss = 0.5926820039749146, train/logprobs = tensor([[-3.9845, -7.1901],
        [-4.0762, -1.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3941790461540222
Epoch 0, Step 4031: train/loss = 0.21205410361289978, train/raw-loss = 0.17968504130840302, train/logprobs = tensor([[-1.4318, -3.2613],
        [-3.1432, -0.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236907124519348
Epoch 0, Step 4032: train/loss = 0.39482754468917847, train/raw-loss = 0.3524332642555237, train/logprobs = tensor([[-1.9364, -4.3997],
        [-3.4420, -1.5417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42394280433654785
Epoch 0, Step 4033: train/loss = 0.581743597984314, train/raw-loss = 0.5325919985771179, train/logprobs = tensor([[-1.5430, -2.6201],
        [-2.9454, -2.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4915161728858948
Epoch 0, Step 4034: train/loss = 0.15087781846523285, train/raw-loss = 0.1121242418885231, train/logprobs = tensor([[-0.7867, -6.3434],
        [-3.0063, -1.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38753578066825867
Epoch 0, Step 4035: train/loss = 0.22656667232513428, train/raw-loss = 0.18250298500061035, train/logprobs = tensor([[-2.2194, -8.5624],
        [-4.3330, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4406368136405945
Epoch 0, Step 4036: train/loss = 0.40669554471969604, train/raw-loss = 0.3670846223831177, train/logprobs = tensor([[-1.2523, -6.9334],
        [-2.8930, -1.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3961089551448822
Epoch 0, Step 4037: train/loss = 0.48858126997947693, train/raw-loss = 0.45382922887802124, train/logprobs = tensor([[-1.0074, -5.2780],
        [-2.2606, -2.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3475208282470703
Epoch 0, Step 4038: train/loss = 0.4185866415500641, train/raw-loss = 0.38606297969818115, train/logprobs = tensor([[-1.5812, -4.8193],
        [-2.9489, -1.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3252369165420532
Epoch 0, Step 4039: train/loss = 0.35808345675468445, train/raw-loss = 0.3141666352748871, train/logprobs = tensor([[-1.5498, -7.4913],
        [-3.5307, -1.2081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43916815519332886
Epoch 0, Step 4040: train/loss = 0.20516987144947052, train/raw-loss = 0.16090664267539978, train/logprobs = tensor([[ -1.8914, -10.4001],
        [ -3.8131,  -2.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4426323175430298
Epoch 0, Step 4041: train/loss = 0.30190587043762207, train/raw-loss = 0.2577214241027832, train/logprobs = tensor([[ -1.7386, -10.4851],
        [ -4.9152,  -1.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4418446719646454
Epoch 0, Step 4042: train/loss = 0.45847979187965393, train/raw-loss = 0.409467488527298, train/logprobs = tensor([[-1.4833, -9.4952],
        [-4.4740, -4.0165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4901229441165924
Epoch 0, Step 4043: train/loss = 0.11936920136213303, train/raw-loss = 0.08273063600063324, train/logprobs = tensor([[ -2.0307, -16.9019],
        [ -6.2366,  -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36638566851615906
Epoch 0, Step 4044: train/loss = 0.41748878359794617, train/raw-loss = 0.37817779183387756, train/logprobs = tensor([[-1.3600, -7.2040],
        [-3.3852, -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931100368499756
Epoch 0, Step 4045: train/loss = 0.31909167766571045, train/raw-loss = 0.2808986008167267, train/logprobs = tensor([[-1.6998, -7.9813],
        [-2.9296, -2.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38193053007125854
Epoch 0, Step 4046: train/loss = 0.3907858431339264, train/raw-loss = 0.35289013385772705, train/logprobs = tensor([[-2.0115, -7.8872],
        [-3.2137, -1.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789571225643158
Epoch 0, Step 4047: train/loss = 0.0772007629275322, train/raw-loss = 0.04141136631369591, train/logprobs = tensor([[ -1.8774, -18.3124],
        [ -4.6766,  -3.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578939437866211
Epoch 0, Step 4048: train/loss = 0.2995328903198242, train/raw-loss = 0.2682896554470062, train/logprobs = tensor([[-1.8227, -7.5105],
        [-2.9749, -1.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124324679374695
Epoch 0, Step 4049: train/loss = 0.5268952250480652, train/raw-loss = 0.47505518794059753, train/logprobs = tensor([[-2.2429, -7.7046],
        [-4.4628, -3.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.518400251865387
Epoch 0, Step 4050: train/loss = 0.267702579498291, train/raw-loss = 0.23248621821403503, train/logprobs = tensor([[ -1.6149, -11.5709],
        [ -3.4873,  -3.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3521636724472046
Epoch 0, Step 4051: train/loss = 0.08665230125188828, train/raw-loss = 0.04865734279155731, train/logprobs = tensor([[ -1.4836, -11.9131],
        [ -4.6049,  -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37994956970214844
Epoch 0, Step 4052: train/loss = 0.29585564136505127, train/raw-loss = 0.25541695952415466, train/logprobs = tensor([[-2.0650, -9.2616],
        [-3.3804, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4043872356414795
Epoch 0, Step 4053: train/loss = 0.36589527130126953, train/raw-loss = 0.3317450284957886, train/logprobs = tensor([[ -3.2744, -12.9683],
        [ -4.0584,  -2.4866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34150272607803345
Epoch 0, Step 4054: train/loss = 0.20611590147018433, train/raw-loss = 0.1638462245464325, train/logprobs = tensor([[-1.2334, -7.2288],
        [-3.8566, -2.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4226965606212616
Epoch 0, Step 4055: train/loss = 0.3722388446331024, train/raw-loss = 0.34794676303863525, train/logprobs = tensor([[ -1.6182, -10.9433],
        [ -2.6104,  -1.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24292077124118805
Epoch 0, Step 4056: train/loss = 0.19601872563362122, train/raw-loss = 0.15829002857208252, train/logprobs = tensor([[-0.8754, -6.6438],
        [-3.7209, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37728703022003174
Epoch 0, Step 4057: train/loss = 0.32672908902168274, train/raw-loss = 0.28182917833328247, train/logprobs = tensor([[-1.4619, -4.1763],
        [-4.5499, -3.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.448999285697937
Epoch 0, Step 4058: train/loss = 0.3422548770904541, train/raw-loss = 0.30075088143348694, train/logprobs = tensor([[-1.6540, -9.0527],
        [-3.9188, -1.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41503986716270447
Epoch 0, Step 4059: train/loss = 0.3156276345252991, train/raw-loss = 0.28363126516342163, train/logprobs = tensor([[-2.4143, -8.3779],
        [-3.1350, -2.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31996363401412964
Epoch 0, Step 4060: train/loss = 0.1573534905910492, train/raw-loss = 0.12380676716566086, train/logprobs = tensor([[-1.8212, -8.8355],
        [-4.8667, -2.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.335467129945755
Epoch 0, Step 4061: train/loss = 0.1931564211845398, train/raw-loss = 0.15136131644248962, train/logprobs = tensor([[ -1.0867, -12.5101],
        [ -3.8172,  -2.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41795092821121216
Epoch 0, Step 4062: train/loss = 0.04593861103057861, train/raw-loss = 0.007928108796477318, train/logprobs = tensor([[ -1.8661, -15.8016],
        [ -6.1906,  -3.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38010504841804504
Epoch 0, Step 4063: train/loss = 0.04850481450557709, train/raw-loss = 0.00973543245345354, train/logprobs = tensor([[ -1.3233, -10.1999],
        [ -5.6877,  -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3876938223838806
Epoch 0, Step 4064: train/loss = 0.3388797640800476, train/raw-loss = 0.2884610593318939, train/logprobs = tensor([[-0.8778, -9.0975],
        [-4.3979, -4.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5041871666908264
Epoch 0, Step 4065: train/loss = 0.4913087487220764, train/raw-loss = 0.45559465885162354, train/logprobs = tensor([[-1.0405, -8.5560],
        [-3.2825, -2.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35714107751846313
Epoch 0, Step 4066: train/loss = 0.2572636008262634, train/raw-loss = 0.2268681675195694, train/logprobs = tensor([[-2.2678, -5.2231],
        [-4.0531, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039541244506836
Epoch 0, Step 4067: train/loss = 0.2986091077327728, train/raw-loss = 0.2618274986743927, train/logprobs = tensor([[-2.4552, -4.9312],
        [-4.3251, -1.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3678160309791565
Epoch 0, Step 4068: train/loss = 0.5582265257835388, train/raw-loss = 0.5264668464660645, train/logprobs = tensor([[-2.4798, -9.3738],
        [-3.8381, -4.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3175975978374481
Epoch 0, Step 4069: train/loss = 0.2584211528301239, train/raw-loss = 0.22681114077568054, train/logprobs = tensor([[-2.4761, -6.9630],
        [-3.7066, -0.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31610018014907837
Epoch 0, Step 4070: train/loss = 0.2675161361694336, train/raw-loss = 0.22609414160251617, train/logprobs = tensor([[ -2.0414, -10.6019],
        [ -4.4337,  -2.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4142201244831085
Epoch 0, Step 4071: train/loss = 0.6213679313659668, train/raw-loss = 0.5879930257797241, train/logprobs = tensor([[-2.3666, -4.2934],
        [-3.0562, -2.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337486684322357
Epoch 0, Step 4072: train/loss = 0.6216549873352051, train/raw-loss = 0.5865330100059509, train/logprobs = tensor([[-2.6412, -5.6465],
        [-3.0164, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35121941566467285
Epoch 0, Step 4073: train/loss = 0.40352362394332886, train/raw-loss = 0.35425540804862976, train/logprobs = tensor([[-1.6542, -5.9993],
        [-4.7115, -2.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4926818609237671
Epoch 0, Step 4074: train/loss = 0.2210415005683899, train/raw-loss = 0.18823406100273132, train/logprobs = tensor([[-1.6480, -8.8893],
        [-3.5515, -1.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32807457447052
Epoch 0, Step 4075: train/loss = 0.13047869503498077, train/raw-loss = 0.09142358601093292, train/logprobs = tensor([[-0.9762, -8.1511],
        [-3.9168, -2.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39055103063583374
Epoch 0, Step 4076: train/loss = 0.30682313442230225, train/raw-loss = 0.27393630146980286, train/logprobs = tensor([[-1.7034, -5.4389],
        [-3.8092, -1.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886844873428345
Epoch 0, Step 4077: train/loss = 0.24905100464820862, train/raw-loss = 0.22123704850673676, train/logprobs = tensor([[-2.1388, -5.0231],
        [-2.8361, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781396210193634
Epoch 0, Step 4078: train/loss = 0.25494635105133057, train/raw-loss = 0.22310221195220947, train/logprobs = tensor([[-1.2099, -3.0346],
        [-2.9602, -1.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184414803981781
Epoch 0, Step 4079: train/loss = 0.4011274576187134, train/raw-loss = 0.3690261244773865, train/logprobs = tensor([[-1.6370, -5.9819],
        [-3.1423, -1.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32101306319236755
Epoch 0, Step 4080: train/loss = 0.3369131088256836, train/raw-loss = 0.2933281362056732, train/logprobs = tensor([[ -1.0748, -10.7425],
        [ -2.8069,  -3.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4358499050140381
Epoch 0, Step 4081: train/loss = 0.18319350481033325, train/raw-loss = 0.14747121930122375, train/logprobs = tensor([[-1.8067, -6.3704],
        [-3.4211, -2.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35722291469573975
Epoch 0, Step 4082: train/loss = 0.21597158908843994, train/raw-loss = 0.17492514848709106, train/logprobs = tensor([[ -1.0102, -17.2309],
        [ -4.7533,  -5.3533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41046422719955444
Epoch 0, Step 4083: train/loss = 0.3124973177909851, train/raw-loss = 0.2696257531642914, train/logprobs = tensor([[-1.5166, -8.2054],
        [-5.8273, -2.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42871567606925964
Epoch 0, Step 4084: train/loss = 0.6225845813751221, train/raw-loss = 0.5803742408752441, train/logprobs = tensor([[-3.0881, -8.8411],
        [-5.3146, -2.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4221034348011017
Epoch 0, Step 4085: train/loss = 0.385280042886734, train/raw-loss = 0.3505069613456726, train/logprobs = tensor([[ -3.2236, -13.6689],
        [ -3.8218,  -2.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34773099422454834
Epoch 0, Step 4086: train/loss = 0.8219060301780701, train/raw-loss = 0.773676872253418, train/logprobs = tensor([[-1.2340, -2.1690],
        [-3.6247, -3.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4822913110256195
Epoch 0, Step 4087: train/loss = 0.11179622262716293, train/raw-loss = 0.06925646215677261, train/logprobs = tensor([[ -1.5234, -13.1509],
        [ -5.8288,  -1.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.425397664308548
Epoch 0, Step 4088: train/loss = 0.34820976853370667, train/raw-loss = 0.3178134560585022, train/logprobs = tensor([[-2.6240, -9.5194],
        [-3.8347, -3.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30396324396133423
Epoch 0, Step 4089: train/loss = 0.19410517811775208, train/raw-loss = 0.15341496467590332, train/logprobs = tensor([[-0.9554, -9.9799],
        [-4.1203, -4.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069022238254547
Epoch 0, Step 4090: train/loss = 0.43485674262046814, train/raw-loss = 0.40000683069229126, train/logprobs = tensor([[-1.8913, -8.1422],
        [-2.7710, -3.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.348499059677124
Epoch 0, Step 4091: train/loss = 0.060085639357566833, train/raw-loss = 0.01875019632279873, train/logprobs = tensor([[ -2.2554, -11.3162],
        [ -5.8089,  -2.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41335439682006836
Epoch 0, Step 4092: train/loss = 0.14572137594223022, train/raw-loss = 0.10849247127771378, train/logprobs = tensor([[ -1.5957, -14.9122],
        [ -4.3204,  -3.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722890615463257
Epoch 0, Step 4093: train/loss = 0.3464171886444092, train/raw-loss = 0.3089998662471771, train/logprobs = tensor([[-1.4900, -6.5544],
        [-3.1032, -1.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741736114025116
Epoch 0, Step 4094: train/loss = 0.42807406187057495, train/raw-loss = 0.38849908113479614, train/logprobs = tensor([[-2.0778, -6.8751],
        [-4.8657, -2.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3957497775554657
Epoch 0, Step 4095: train/loss = 0.06935290992259979, train/raw-loss = 0.029603272676467896, train/logprobs = tensor([[ -1.8881, -21.3238],
        [ -5.9601,  -5.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39749637246131897
Epoch 0, Step 4096: train/loss = 0.3405781388282776, train/raw-loss = 0.2886512279510498, train/logprobs = tensor([[-2.2856, -7.2694],
        [-4.4069, -3.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5192692875862122
Epoch 0, Step 4097: train/loss = 0.29552754759788513, train/raw-loss = 0.2535717487335205, train/logprobs = tensor([[-1.1522, -9.9202],
        [-4.1273, -2.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.419558048248291
Epoch 0, Step 4098: train/loss = 0.49536317586898804, train/raw-loss = 0.46192657947540283, train/logprobs = tensor([[-2.3018, -6.6585],
        [-2.5437, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3343663811683655
Epoch 0, Step 4099: train/loss = 0.37839484214782715, train/raw-loss = 0.3427050709724426, train/logprobs = tensor([[-2.2668, -6.9585],
        [-4.8947, -2.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568977117538452
Epoch 0, Step 4100: train/loss = 0.05753954499959946, train/raw-loss = 0.023227712139487267, train/logprobs = tensor([[ -1.5596, -12.5500],
        [ -5.3671,  -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431183397769928
Epoch 0, Step 4101: train/loss = 0.2485051155090332, train/raw-loss = 0.21692383289337158, train/logprobs = tensor([[-1.8502, -8.4804],
        [-3.1518, -2.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158129155635834
Epoch 0, Step 4102: train/loss = 0.29336804151535034, train/raw-loss = 0.2514990568161011, train/logprobs = tensor([[-2.8129, -9.4577],
        [-3.8650, -2.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4186897277832031
Epoch 0, Step 4103: train/loss = 0.45929524302482605, train/raw-loss = 0.4213578999042511, train/logprobs = tensor([[-1.1800, -2.4282],
        [-1.8548, -1.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37937361001968384
Epoch 0, Step 4104: train/loss = 0.19316475093364716, train/raw-loss = 0.1543969213962555, train/logprobs = tensor([[-2.6557, -9.6449],
        [-3.9624, -2.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.387678325176239
Epoch 0, Step 4105: train/loss = 0.2761952579021454, train/raw-loss = 0.23532894253730774, train/logprobs = tensor([[-2.4563, -7.1391],
        [-3.9025, -2.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4086630642414093
Epoch 0, Step 4106: train/loss = 1.2134416103363037, train/raw-loss = 1.1626827716827393, train/logprobs = tensor([[-2.5226, -1.6779],
        [-4.1023, -3.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5075877904891968
Epoch 0, Step 4107: train/loss = 0.12883023917675018, train/raw-loss = 0.08921758085489273, train/logprobs = tensor([[-1.4566, -7.4140],
        [-4.6275, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3961266279220581
Epoch 0, Step 4108: train/loss = 0.2283153533935547, train/raw-loss = 0.18535099923610687, train/logprobs = tensor([[ -0.8921, -11.0047],
        [ -2.6414,  -1.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4296436905860901
Epoch 0, Step 4109: train/loss = 0.555228054523468, train/raw-loss = 0.5208145380020142, train/logprobs = tensor([[-3.7977, -6.0285],
        [-4.8000, -2.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34413546323776245
Epoch 0, Step 4110: train/loss = 0.21719148755073547, train/raw-loss = 0.18121680617332458, train/logprobs = tensor([[-1.6221, -6.9568],
        [-4.1255, -2.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3597469627857208
Epoch 0, Step 4111: train/loss = 0.5902509689331055, train/raw-loss = 0.5547825694084167, train/logprobs = tensor([[-2.0095, -3.5930],
        [-3.2177, -1.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3546845316886902
Epoch 0, Step 4112: train/loss = 0.4084073603153229, train/raw-loss = 0.36608320474624634, train/logprobs = tensor([[-1.0303, -4.6904],
        [-3.0443, -1.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42324137687683105
Epoch 0, Step 4113: train/loss = 0.5207771062850952, train/raw-loss = 0.4839879870414734, train/logprobs = tensor([[-2.7224, -7.0864],
        [-3.5298, -2.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36789119243621826
Epoch 0, Step 4114: train/loss = 0.3743413984775543, train/raw-loss = 0.34178948402404785, train/logprobs = tensor([[-1.4151, -3.8168],
        [-4.1438, -2.3830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3255190849304199
Epoch 0, Step 4115: train/loss = 0.30903005599975586, train/raw-loss = 0.27390918135643005, train/logprobs = tensor([[-1.9468, -9.0469],
        [-3.8922, -3.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3512084484100342
Epoch 0, Step 4116: train/loss = 0.2827105224132538, train/raw-loss = 0.24529153108596802, train/logprobs = tensor([[-2.0463, -7.6255],
        [-3.6052, -3.1863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741898536682129
Epoch 0, Step 4117: train/loss = 0.3222690522670746, train/raw-loss = 0.27247610688209534, train/logprobs = tensor([[-1.3786, -7.1933],
        [-4.5331, -2.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4979298710823059
Epoch 0, Step 4118: train/loss = 0.5125219225883484, train/raw-loss = 0.47089874744415283, train/logprobs = tensor([[-3.2278, -5.2479],
        [-4.1829, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.416232168674469
Epoch 0, Step 4119: train/loss = 0.5423714518547058, train/raw-loss = 0.505998432636261, train/logprobs = tensor([[-2.0403, -8.0470],
        [-3.2017, -4.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3637304902076721
Epoch 0, Step 4120: train/loss = 0.2622656226158142, train/raw-loss = 0.2184586226940155, train/logprobs = tensor([[-2.1408, -8.3541],
        [-3.3329, -2.5019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4380699396133423
Epoch 0, Step 4121: train/loss = 0.47677457332611084, train/raw-loss = 0.44510701298713684, train/logprobs = tensor([[-1.5343, -7.6203],
        [-2.6994, -3.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3166755735874176
Epoch 0, Step 4122: train/loss = 0.2525551915168762, train/raw-loss = 0.21379531919956207, train/logprobs = tensor([[ -3.0650, -13.4501],
        [ -4.7368,  -2.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875988721847534
Epoch 0, Step 4123: train/loss = 0.2806265354156494, train/raw-loss = 0.2471015751361847, train/logprobs = tensor([[-2.6203, -9.2772],
        [-3.9002, -2.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33524975180625916
Epoch 0, Step 4124: train/loss = 0.4540632367134094, train/raw-loss = 0.39678776264190674, train/logprobs = tensor([[ -2.3605, -10.2740],
        [ -6.2460,  -3.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5727548003196716
Epoch 0, Step 4125: train/loss = 0.4288748502731323, train/raw-loss = 0.3907058835029602, train/logprobs = tensor([[-1.0079, -7.5634],
        [-2.2374, -2.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3816898763179779
Epoch 0, Step 4126: train/loss = 0.5000390410423279, train/raw-loss = 0.46232545375823975, train/logprobs = tensor([[-2.3564, -4.4900],
        [-2.4124, -1.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37713563442230225
Epoch 0, Step 4127: train/loss = 0.2976972460746765, train/raw-loss = 0.25652438402175903, train/logprobs = tensor([[-1.4171, -7.0132],
        [-4.7375, -2.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4117286801338196
Epoch 0, Step 4128: train/loss = 0.22022992372512817, train/raw-loss = 0.18208494782447815, train/logprobs = tensor([[-2.1384, -8.6439],
        [-4.8857, -4.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814498782157898
Epoch 0, Step 4129: train/loss = 0.6978036165237427, train/raw-loss = 0.6457681059837341, train/logprobs = tensor([[-1.4233, -2.7680],
        [-4.1333, -3.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5203552842140198
Epoch 0, Step 4130: train/loss = 0.31924742460250854, train/raw-loss = 0.2755059003829956, train/logprobs = tensor([[-2.4509, -5.0004],
        [-4.0996, -1.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4374151825904846
Epoch 0, Step 4131: train/loss = 0.28418856859207153, train/raw-loss = 0.24781160056591034, train/logprobs = tensor([[-1.9964, -6.9220],
        [-3.8739, -1.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36376941204071045
Epoch 0, Step 4132: train/loss = 0.3004969358444214, train/raw-loss = 0.25940507650375366, train/logprobs = tensor([[-1.2442, -7.3115],
        [-4.4489, -1.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109187126159668
Epoch 0, Step 4133: train/loss = 0.22557932138442993, train/raw-loss = 0.18187525868415833, train/logprobs = tensor([[-2.2251, -9.6841],
        [-4.8011, -2.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4370405673980713
Epoch 0, Step 4134: train/loss = 0.2836605906486511, train/raw-loss = 0.2491520643234253, train/logprobs = tensor([[-1.5117, -5.0329],
        [-4.5532, -2.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3450852036476135
Epoch 0, Step 4135: train/loss = 0.5085353851318359, train/raw-loss = 0.4689379632472992, train/logprobs = tensor([[-1.9029, -4.6657],
        [-3.6147, -1.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3959740996360779
Epoch 0, Step 4136: train/loss = 0.187114879488945, train/raw-loss = 0.14705412089824677, train/logprobs = tensor([[-1.6031, -7.1794],
        [-4.0180, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4006075859069824
Epoch 0, Step 4137: train/loss = 0.4268076419830322, train/raw-loss = 0.3884372115135193, train/logprobs = tensor([[-2.0209, -5.4598],
        [-4.0278, -3.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38370412588119507
Epoch 0, Step 4138: train/loss = 0.08621204644441605, train/raw-loss = 0.0502779521048069, train/logprobs = tensor([[ -1.4561, -10.6606],
        [ -4.5997,  -3.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3593408763408661
Epoch 0, Step 4139: train/loss = 0.13043728470802307, train/raw-loss = 0.08971942961215973, train/logprobs = tensor([[-2.3163, -8.4718],
        [-5.8303, -2.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40717846155166626
Epoch 0, Step 4140: train/loss = 1.6636873483657837, train/raw-loss = 1.6318504810333252, train/logprobs = tensor([[-7.9453, -8.6248],
        [-3.7648, -3.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318368136882782
Epoch 0, Step 4141: train/loss = 0.4523172080516815, train/raw-loss = 0.41234081983566284, train/logprobs = tensor([[-1.4918, -6.2543],
        [-3.5685, -2.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39976370334625244
Epoch 0, Step 4142: train/loss = 0.17273347079753876, train/raw-loss = 0.13110646605491638, train/logprobs = tensor([[-1.9271, -7.6593],
        [-3.8765, -1.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41627007722854614
Epoch 0, Step 4143: train/loss = 0.5957168340682983, train/raw-loss = 0.5536240339279175, train/logprobs = tensor([[-1.6313, -6.2314],
        [-3.7418, -1.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42092764377593994
Epoch 0, Step 4144: train/loss = 0.32569950819015503, train/raw-loss = 0.29056113958358765, train/logprobs = tensor([[-1.6972, -5.4543],
        [-3.3650, -1.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513837456703186
Epoch 0, Step 4145: train/loss = 0.3478855788707733, train/raw-loss = 0.2966420352458954, train/logprobs = tensor([[-2.1752, -4.3617],
        [-4.8531, -3.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5124356746673584
Epoch 0, Step 4146: train/loss = 1.0758928060531616, train/raw-loss = 1.0398703813552856, train/logprobs = tensor([[-5.3229, -5.8765],
        [-3.9869, -2.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602234125137329
Epoch 0, Step 4147: train/loss = 0.29904288053512573, train/raw-loss = 0.2583922743797302, train/logprobs = tensor([[-1.4542, -7.6078],
        [-4.5100, -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40650615096092224
Epoch 0, Step 4148: train/loss = 0.04981071501970291, train/raw-loss = 0.015417718328535557, train/logprobs = tensor([[-1.1891, -8.3029],
        [-5.4829, -1.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3439299762248993
Epoch 0, Step 4149: train/loss = 0.19757872819900513, train/raw-loss = 0.16496232151985168, train/logprobs = tensor([[-1.6048, -6.2244],
        [-3.0913, -1.3424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3261640667915344
Epoch 0, Step 4150: train/loss = 0.7213647365570068, train/raw-loss = 0.6697959899902344, train/logprobs = tensor([[-1.2624, -3.5995],
        [-3.8332, -3.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5156868100166321
Epoch 0, Step 4151: train/loss = 0.09357970207929611, train/raw-loss = 0.05230525881052017, train/logprobs = tensor([[-2.8836, -9.2145],
        [-5.8174, -1.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.412744402885437
Epoch 0, Step 4152: train/loss = 0.07594917714595795, train/raw-loss = 0.040069129317998886, train/logprobs = tensor([[ -1.0761, -14.9091],
        [ -5.0025,  -4.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588005602359772
Epoch 0, Step 4153: train/loss = 0.3741152286529541, train/raw-loss = 0.33893656730651855, train/logprobs = tensor([[-1.2020, -5.5280],
        [-2.5664, -3.0414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351786345243454
Epoch 0, Step 4154: train/loss = 0.4445001780986786, train/raw-loss = 0.40723717212677, train/logprobs = tensor([[-2.3174, -8.5620],
        [-3.2960, -4.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726303279399872
Epoch 0, Step 4155: train/loss = 0.4214526414871216, train/raw-loss = 0.3670322895050049, train/logprobs = tensor([[-2.1436, -4.0229],
        [-4.9456, -2.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5442032814025879
Epoch 0, Step 4156: train/loss = 0.2205309271812439, train/raw-loss = 0.1824246346950531, train/logprobs = tensor([[-1.7844, -9.6476],
        [-3.6875, -5.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3810628354549408
Epoch 0, Step 4157: train/loss = 0.24244143068790436, train/raw-loss = 0.20915473997592926, train/logprobs = tensor([[-1.4130, -7.8899],
        [-2.9583, -1.3542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33286699652671814
Epoch 0, Step 4158: train/loss = 0.16300903260707855, train/raw-loss = 0.1128278449177742, train/logprobs = tensor([[ -1.6966, -12.2097],
        [ -5.7731,  -3.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5018118619918823
Epoch 0, Step 4159: train/loss = 0.43274831771850586, train/raw-loss = 0.3953964412212372, train/logprobs = tensor([[-1.9240, -3.8317],
        [-3.4094, -2.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735186755657196
Epoch 0, Step 4160: train/loss = 0.36149513721466064, train/raw-loss = 0.317359060049057, train/logprobs = tensor([[-1.4259, -5.2400],
        [-4.2396, -2.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4413607120513916
Epoch 0, Step 4161: train/loss = 0.567558228969574, train/raw-loss = 0.5186778903007507, train/logprobs = tensor([[-1.3965, -1.9964],
        [-3.2542, -1.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4888037443161011
Epoch 0, Step 4162: train/loss = 0.2949780821800232, train/raw-loss = 0.2520495355129242, train/logprobs = tensor([[-1.9383, -5.0802],
        [-5.1801, -2.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42928546667099
Epoch 0, Step 4163: train/loss = 0.3060120642185211, train/raw-loss = 0.25599420070648193, train/logprobs = tensor([[ -1.7468, -10.8947],
        [ -5.3987,  -4.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001785159111023
Epoch 0, Step 4164: train/loss = 0.20369845628738403, train/raw-loss = 0.16084706783294678, train/logprobs = tensor([[-1.1493, -4.0992],
        [-5.1500, -2.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42851388454437256
Epoch 0, Step 4165: train/loss = 0.441122829914093, train/raw-loss = 0.4003601372241974, train/logprobs = tensor([[-1.2996, -3.2188],
        [-4.2346, -2.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4076269865036011
Epoch 0, Step 4166: train/loss = 0.37980902194976807, train/raw-loss = 0.3353617191314697, train/logprobs = tensor([[ -1.3911, -15.2794],
        [ -3.9339,  -5.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4444730281829834
Epoch 0, Step 4167: train/loss = 0.20758932828903198, train/raw-loss = 0.16626174747943878, train/logprobs = tensor([[-1.4700, -4.3798],
        [-4.4039, -2.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4132758378982544
Epoch 0, Step 4168: train/loss = 0.3000907301902771, train/raw-loss = 0.2599318325519562, train/logprobs = tensor([[-1.5401, -8.8220],
        [-4.5606, -2.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40158918499946594
Epoch 0, Step 4169: train/loss = 0.2002590000629425, train/raw-loss = 0.16282303631305695, train/logprobs = tensor([[-1.7054, -4.3226],
        [-4.0449, -2.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37435948848724365
Epoch 0, Step 4170: train/loss = 0.12373809516429901, train/raw-loss = 0.07735736668109894, train/logprobs = tensor([[-1.6331, -8.3141],
        [-5.3368, -1.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4638073444366455
Epoch 0, Step 4171: train/loss = 0.561073899269104, train/raw-loss = 0.5212623476982117, train/logprobs = tensor([[-1.4022, -3.6834],
        [-3.6132, -3.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.398115336894989
Epoch 0, Step 4172: train/loss = 0.2479192018508911, train/raw-loss = 0.20297664403915405, train/logprobs = tensor([[ -1.4203, -14.1548],
        [ -4.6870,  -4.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44942569732666016
Epoch 0, Step 4173: train/loss = 0.5603461265563965, train/raw-loss = 0.5110282897949219, train/logprobs = tensor([[-1.2092, -4.4989],
        [-4.3206, -2.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4931783676147461
Epoch 0, Step 4174: train/loss = 0.41267654299736023, train/raw-loss = 0.36723119020462036, train/logprobs = tensor([[ -2.0333, -10.0934],
        [ -4.0307,  -2.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45445311069488525
Epoch 0, Step 4175: train/loss = 0.39303722977638245, train/raw-loss = 0.35290783643722534, train/logprobs = tensor([[-1.5042, -5.5178],
        [-3.7043, -1.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4012938141822815
Epoch 0, Step 4176: train/loss = 0.26723387837409973, train/raw-loss = 0.22966861724853516, train/logprobs = tensor([[-1.9423, -9.8828],
        [-4.0586, -2.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37565264105796814
Epoch 0, Step 4177: train/loss = 0.04781472682952881, train/raw-loss = 0.010728888213634491, train/logprobs = tensor([[ -0.9120, -11.6860],
        [ -5.3248,  -1.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37085840106010437
Epoch 0, Step 4178: train/loss = 0.3958415985107422, train/raw-loss = 0.3546275794506073, train/logprobs = tensor([[-1.2731, -7.4017],
        [-2.9137, -3.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4121403396129608
Epoch 0, Step 4179: train/loss = 0.40750324726104736, train/raw-loss = 0.3618571162223816, train/logprobs = tensor([[-2.2388, -8.0291],
        [-4.4170, -3.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4564610719680786
Epoch 0, Step 4180: train/loss = 0.3829287588596344, train/raw-loss = 0.34162527322769165, train/logprobs = tensor([[ -1.7299, -10.0106],
        [ -4.6617,  -4.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41303497552871704
Epoch 0, Step 4181: train/loss = 0.15746748447418213, train/raw-loss = 0.11155450344085693, train/logprobs = tensor([[-1.6562, -9.1938],
        [-4.7431, -3.0687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4591297507286072
Epoch 0, Step 4182: train/loss = 0.19407187402248383, train/raw-loss = 0.15537218749523163, train/logprobs = tensor([[-2.3575, -9.5086],
        [-4.7687, -3.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38699689507484436
Epoch 0, Step 4183: train/loss = 0.2130289375782013, train/raw-loss = 0.16542820632457733, train/logprobs = tensor([[-1.5999, -6.1847],
        [-5.9299, -4.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47600728273391724
Epoch 0, Step 4184: train/loss = 0.4522768557071686, train/raw-loss = 0.4122164249420166, train/logprobs = tensor([[-1.3401, -7.4548],
        [-3.6137, -3.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40060460567474365
Epoch 0, Step 4185: train/loss = 0.4949135184288025, train/raw-loss = 0.4634256958961487, train/logprobs = tensor([[-2.1041, -5.5600],
        [-2.5322, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148782551288605
Epoch 0, Step 4186: train/loss = 0.1338735669851303, train/raw-loss = 0.09724637866020203, train/logprobs = tensor([[-1.0190, -9.5359],
        [-3.7705, -2.3443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36627185344696045
Epoch 0, Step 4187: train/loss = 0.44167935848236084, train/raw-loss = 0.3912431001663208, train/logprobs = tensor([[-1.9923, -5.2555],
        [-4.8623, -3.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5043627619743347
Epoch 0, Step 4188: train/loss = 0.15533475577831268, train/raw-loss = 0.11232329159975052, train/logprobs = tensor([[-1.8941, -9.3906],
        [-4.7943, -2.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4301146864891052
Epoch 0, Step 4189: train/loss = 0.6194334626197815, train/raw-loss = 0.5847395658493042, train/logprobs = tensor([[-1.7221, -3.6308],
        [-2.5396, -1.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34693899750709534
Epoch 0, Step 4190: train/loss = 0.0702119916677475, train/raw-loss = 0.027244171127676964, train/logprobs = tensor([[ -1.2364, -14.7702],
        [ -5.2887,  -4.2415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42967817187309265
Epoch 0, Step 4191: train/loss = 0.3545025587081909, train/raw-loss = 0.30909430980682373, train/logprobs = tensor([[-1.3091, -6.4106],
        [-3.9149, -1.9149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45408257842063904
Epoch 0, Step 4192: train/loss = 0.13949431478977203, train/raw-loss = 0.10753688216209412, train/logprobs = tensor([[-1.5098, -7.9284],
        [-3.2631, -2.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31957438588142395
Epoch 0, Step 4193: train/loss = 0.41275015473365784, train/raw-loss = 0.36890703439712524, train/logprobs = tensor([[-1.6356, -5.6603],
        [-5.4434, -1.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43843141198158264
Epoch 0, Step 4194: train/loss = 0.4202747344970703, train/raw-loss = 0.3725557029247284, train/logprobs = tensor([[-1.7127, -3.5184],
        [-3.2388, -2.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47719043493270874
Epoch 0, Step 4195: train/loss = 0.21969281136989594, train/raw-loss = 0.17611820995807648, train/logprobs = tensor([[-1.4052, -9.5050],
        [-4.3667, -1.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43574589490890503
Epoch 0, Step 4196: train/loss = 0.2367633730173111, train/raw-loss = 0.19338570535182953, train/logprobs = tensor([[-2.0772, -8.9067],
        [-5.4967, -1.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337765574455261
Epoch 0, Step 4197: train/loss = 0.27476662397384644, train/raw-loss = 0.23746976256370544, train/logprobs = tensor([[-3.0676, -7.6901],
        [-4.6921, -2.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729684352874756
Epoch 0, Step 4198: train/loss = 0.10951472818851471, train/raw-loss = 0.06810484826564789, train/logprobs = tensor([[-1.8568, -9.6057],
        [-6.3779, -2.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4140986502170563
Epoch 0, Step 4199: train/loss = 0.2997127175331116, train/raw-loss = 0.25319454073905945, train/logprobs = tensor([[-1.1556, -8.9977],
        [-4.7288, -2.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46518197655677795
Epoch 0, Step 4200: train/loss = 0.3859668970108032, train/raw-loss = 0.33459386229515076, train/logprobs = tensor([[-1.7643, -5.2657],
        [-5.5453, -2.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5137306451797485
Epoch 0, Step 4201: train/loss = 0.24902649223804474, train/raw-loss = 0.20648621022701263, train/logprobs = tensor([[-1.5636, -5.7757],
        [-5.0771, -2.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254026412963867
Epoch 0, Step 4202: train/loss = 0.2567605972290039, train/raw-loss = 0.22355014085769653, train/logprobs = tensor([[-1.2479, -4.1597],
        [-3.9548, -1.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321046233177185
Epoch 0, Step 4203: train/loss = 0.2004031538963318, train/raw-loss = 0.16151198744773865, train/logprobs = tensor([[-1.4257, -8.0590],
        [-3.4683, -2.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3889116048812866
Epoch 0, Step 4204: train/loss = 0.12570036947727203, train/raw-loss = 0.087507463991642, train/logprobs = tensor([[-1.7604, -6.2143],
        [-5.5191, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38192909955978394
Epoch 0, Step 4205: train/loss = 0.4794057011604309, train/raw-loss = 0.44321930408477783, train/logprobs = tensor([[-2.6759, -5.0479],
        [-3.6234, -2.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3618636727333069
Epoch 0, Step 4206: train/loss = 0.5247424840927124, train/raw-loss = 0.47376567125320435, train/logprobs = tensor([[-1.5394, -4.3035],
        [-4.1291, -2.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5097677111625671
Epoch 0, Step 4207: train/loss = 0.3447159230709076, train/raw-loss = 0.31358152627944946, train/logprobs = tensor([[-1.5452, -8.1249],
        [-2.6847, -2.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31134411692619324
Epoch 0, Step 4208: train/loss = 0.7622679471969604, train/raw-loss = 0.7152789831161499, train/logprobs = tensor([[-1.8817, -5.7352],
        [-5.5681, -4.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4698891341686249
Epoch 0, Step 4209: train/loss = 0.9184667468070984, train/raw-loss = 0.8835011124610901, train/logprobs = tensor([[ -5.0572, -16.1182],
        [ -3.2868,  -2.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496561050415039
Epoch 0, Step 4210: train/loss = 0.2684272527694702, train/raw-loss = 0.22736842930316925, train/logprobs = tensor([[-1.1318, -7.7085],
        [-3.8465, -1.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4105880856513977
Epoch 0, Step 4211: train/loss = 0.25251156091690063, train/raw-loss = 0.21182136237621307, train/logprobs = tensor([[ -1.7743, -12.7785],
        [ -4.9033,  -5.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40690234303474426
Epoch 0, Step 4212: train/loss = 0.353094220161438, train/raw-loss = 0.31055518984794617, train/logprobs = tensor([[ -1.2306, -11.4690],
        [ -3.9003,  -3.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42539021372795105
Epoch 0, Step 4213: train/loss = 0.639672040939331, train/raw-loss = 0.6025323867797852, train/logprobs = tensor([[-2.0743, -6.6628],
        [-4.1133, -2.1973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37139588594436646
Epoch 0, Step 4214: train/loss = 0.40415632724761963, train/raw-loss = 0.35756200551986694, train/logprobs = tensor([[-2.0257, -3.7403],
        [-4.8153, -3.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46594303846359253
Epoch 0, Step 4215: train/loss = 0.24181149899959564, train/raw-loss = 0.1933656930923462, train/logprobs = tensor([[-2.4813, -5.9191],
        [-4.9799, -2.3070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4844580292701721
Epoch 0, Step 4216: train/loss = 0.07823345065116882, train/raw-loss = 0.0340769961476326, train/logprobs = tensor([[ -2.1522, -15.2161],
        [ -4.9790,  -2.6549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44156455993652344
Epoch 0, Step 4217: train/loss = 0.25668516755104065, train/raw-loss = 0.21059411764144897, train/logprobs = tensor([[-2.0691, -7.7764],
        [-6.2181, -2.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.460910439491272
Epoch 0, Step 4218: train/loss = 0.06153128668665886, train/raw-loss = 0.013083068653941154, train/logprobs = tensor([[ -1.7366, -10.1452],
        [ -7.1395,  -2.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48448216915130615
Epoch 0, Step 4219: train/loss = 0.11209113150835037, train/raw-loss = 0.07894343882799149, train/logprobs = tensor([[-2.1650, -9.3251],
        [-5.0683, -1.3247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314768671989441
Epoch 0, Step 4220: train/loss = 0.5837364196777344, train/raw-loss = 0.5370548963546753, train/logprobs = tensor([[-2.1062, -3.9933],
        [-3.3844, -2.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4668148159980774
Epoch 0, Step 4221: train/loss = 0.24482332170009613, train/raw-loss = 0.20331332087516785, train/logprobs = tensor([[ -3.0841, -15.5550],
        [ -5.2717,  -4.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41510000824928284
Epoch 0, Step 4222: train/loss = 0.40214860439300537, train/raw-loss = 0.36143824458122253, train/logprobs = tensor([[-2.3574, -4.7757],
        [-3.3056, -2.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40710312128067017
Epoch 0, Step 4223: train/loss = 0.37782153487205505, train/raw-loss = 0.32997262477874756, train/logprobs = tensor([[-1.3977, -3.7915],
        [-3.6316, -2.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4784892797470093
Epoch 0, Step 4224: train/loss = 0.40459591150283813, train/raw-loss = 0.3684265613555908, train/logprobs = tensor([[-1.6102, -4.0537],
        [-3.5795, -1.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3616933226585388
Epoch 0, Step 4225: train/loss = 0.4517592489719391, train/raw-loss = 0.4093559980392456, train/logprobs = tensor([[-1.7970, -6.4436],
        [-3.5637, -2.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4240328073501587
Epoch 0, Step 4226: train/loss = 0.09740610420703888, train/raw-loss = 0.049068383872509, train/logprobs = tensor([[-1.4088, -8.0808],
        [-4.7925, -2.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4833771288394928
Epoch 0, Step 4227: train/loss = 0.2758004665374756, train/raw-loss = 0.22698582708835602, train/logprobs = tensor([[-2.0263, -6.3585],
        [-4.9672, -1.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48814621567726135
Epoch 0, Step 4228: train/loss = 0.10218386352062225, train/raw-loss = 0.06101546064019203, train/logprobs = tensor([[ -2.4408, -10.5490],
        [ -6.5497,  -2.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41168397665023804
Epoch 0, Step 4229: train/loss = 0.2474079430103302, train/raw-loss = 0.2058224231004715, train/logprobs = tensor([[ -0.9971, -10.8777],
        [ -4.5537,  -3.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158552885055542
Epoch 0, Step 4230: train/loss = 0.6729611158370972, train/raw-loss = 0.6163427233695984, train/logprobs = tensor([[-1.7194, -2.9538],
        [-4.0212, -2.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.566184401512146
Epoch 0, Step 4231: train/loss = 1.3200733661651611, train/raw-loss = 1.284085988998413, train/logprobs = tensor([[-6.0100, -8.6134],
        [-3.6498, -1.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35987281799316406
Epoch 0, Step 4232: train/loss = 0.11662913858890533, train/raw-loss = 0.0680408775806427, train/logprobs = tensor([[ -1.0642, -13.0070],
        [ -4.0236,  -2.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48588258028030396
Epoch 0, Step 4233: train/loss = 0.20479464530944824, train/raw-loss = 0.16459394991397858, train/logprobs = tensor([[-1.2377, -5.9473],
        [-5.0738, -3.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40200695395469666
Epoch 0, Step 4234: train/loss = 0.21503710746765137, train/raw-loss = 0.1753389835357666, train/logprobs = tensor([[-1.7297, -5.6976],
        [-3.7175, -1.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.396981418132782
Epoch 0, Step 4235: train/loss = 0.40306180715560913, train/raw-loss = 0.3583454489707947, train/logprobs = tensor([[-2.1635, -6.7703],
        [-3.9529, -2.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44716382026672363
Epoch 0, Step 4236: train/loss = 0.4791918396949768, train/raw-loss = 0.4439678490161896, train/logprobs = tensor([[-2.4342, -4.0904],
        [-2.2862, -1.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522401452064514
Epoch 0, Step 4237: train/loss = 0.27876895666122437, train/raw-loss = 0.24580971896648407, train/logprobs = tensor([[-2.0891, -6.6364],
        [-4.0260, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295925557613373
Epoch 0, Step 4238: train/loss = 0.4633304178714752, train/raw-loss = 0.42071986198425293, train/logprobs = tensor([[-0.9480, -3.3737],
        [-4.0385, -3.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42610567808151245
Epoch 0, Step 4239: train/loss = 0.08982253074645996, train/raw-loss = 0.04650234431028366, train/logprobs = tensor([[ -1.6106, -10.0545],
        [ -4.3837,  -2.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43320176005363464
Epoch 0, Step 4240: train/loss = 0.3376832604408264, train/raw-loss = 0.2929297685623169, train/logprobs = tensor([[ -2.2109, -10.3519],
        [ -5.6242,  -2.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4475351870059967
Epoch 0, Step 4241: train/loss = 0.3291585445404053, train/raw-loss = 0.2810763716697693, train/logprobs = tensor([[-0.7818, -7.6729],
        [-3.4843, -3.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4808218479156494
Epoch 0, Step 4242: train/loss = 0.3916630744934082, train/raw-loss = 0.34031233191490173, train/logprobs = tensor([[-1.7858, -5.5116],
        [-5.1989, -3.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5135073661804199
Epoch 0, Step 4243: train/loss = 0.13747328519821167, train/raw-loss = 0.09952953457832336, train/logprobs = tensor([[ -1.6228, -11.4036],
        [ -3.7519,  -2.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3794374465942383
Epoch 0, Step 4244: train/loss = 0.34001708030700684, train/raw-loss = 0.29875198006629944, train/logprobs = tensor([[-0.6439, -6.8348],
        [-3.4829, -2.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4126512408256531
Epoch 0, Step 4245: train/loss = 0.536164402961731, train/raw-loss = 0.4878736138343811, train/logprobs = tensor([[-1.2691, -7.4178],
        [-4.4429, -4.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48290759325027466
Epoch 0, Step 4246: train/loss = 0.5282706618309021, train/raw-loss = 0.49057841300964355, train/logprobs = tensor([[-1.9914, -2.5464],
        [-2.7565, -2.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3769223988056183
Epoch 0, Step 4247: train/loss = 0.09573498368263245, train/raw-loss = 0.05988148972392082, train/logprobs = tensor([[ -2.0131, -15.7886],
        [ -5.6194,  -3.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35853493213653564
Epoch 0, Step 4248: train/loss = 0.28413498401641846, train/raw-loss = 0.24604424834251404, train/logprobs = tensor([[-1.9587, -5.1776],
        [-3.3961, -1.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.380907267332077
Epoch 0, Step 4249: train/loss = 0.39719539880752563, train/raw-loss = 0.36583268642425537, train/logprobs = tensor([[-2.4147, -7.9810],
        [-3.0929, -2.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3136274516582489
Epoch 0, Step 4250: train/loss = 0.4007883071899414, train/raw-loss = 0.35911959409713745, train/logprobs = tensor([[-2.3154, -9.2247],
        [-3.6084, -1.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41668716073036194
Epoch 0, Step 4251: train/loss = 0.24277016520500183, train/raw-loss = 0.20557136833667755, train/logprobs = tensor([[-1.4272, -3.7846],
        [-4.3507, -2.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719879686832428
Epoch 0, Step 4252: train/loss = 0.44845202565193176, train/raw-loss = 0.41506558656692505, train/logprobs = tensor([[ -2.1300, -11.3048],
        [ -3.3331,  -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33386436104774475
Epoch 0, Step 4253: train/loss = 0.5757578015327454, train/raw-loss = 0.5333673357963562, train/logprobs = tensor([[-1.7649, -2.4286],
        [-3.0733, -2.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42390450835227966
Epoch 0, Step 4254: train/loss = 0.4120712876319885, train/raw-loss = 0.36691123247146606, train/logprobs = tensor([[-1.7630, -3.7650],
        [-4.7423, -1.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4516005516052246
Epoch 0, Step 4255: train/loss = 0.21050825715065002, train/raw-loss = 0.17133694887161255, train/logprobs = tensor([[ -1.7108, -17.2908],
        [ -4.6371,  -6.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39171302318573
Epoch 0, Step 4256: train/loss = 0.3836289942264557, train/raw-loss = 0.3452146649360657, train/logprobs = tensor([[ -1.4656, -10.1965],
        [ -3.0801,  -2.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38414329290390015
Epoch 0, Step 4257: train/loss = 0.6214807033538818, train/raw-loss = 0.5840848684310913, train/logprobs = tensor([[-1.7732, -3.4442],
        [-2.6451, -1.4781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37395864725112915
Epoch 0, Step 4258: train/loss = 0.2951110005378723, train/raw-loss = 0.25331413745880127, train/logprobs = tensor([[ -3.4767, -12.2683],
        [ -4.6638,  -1.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41796886920928955
Epoch 0, Step 4259: train/loss = 0.6565487384796143, train/raw-loss = 0.6196786165237427, train/logprobs = tensor([[-1.8635, -5.5308],
        [-3.6475, -1.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36870110034942627
Epoch 0, Step 4260: train/loss = 0.5350954532623291, train/raw-loss = 0.4927471876144409, train/logprobs = tensor([[-1.5048, -5.8468],
        [-3.1839, -3.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42348289489746094
Epoch 0, Step 4261: train/loss = 0.25780346989631653, train/raw-loss = 0.21527251601219177, train/logprobs = tensor([[-1.5778, -9.1331],
        [-5.2032, -2.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4253096878528595
Epoch 0, Step 4262: train/loss = 0.4315843880176544, train/raw-loss = 0.38073796033859253, train/logprobs = tensor([[-2.1196, -8.8514],
        [-4.1248, -2.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5084640979766846
Epoch 0, Step 4263: train/loss = 0.5431345701217651, train/raw-loss = 0.5068244934082031, train/logprobs = tensor([[-2.4254, -5.3127],
        [-2.5765, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36310142278671265
Epoch 0, Step 4264: train/loss = 0.47211235761642456, train/raw-loss = 0.43457216024398804, train/logprobs = tensor([[-2.2081, -3.3645],
        [-2.8623, -1.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37540173530578613
Epoch 0, Step 4265: train/loss = 0.20445887744426727, train/raw-loss = 0.1621638536453247, train/logprobs = tensor([[-1.7176, -7.0871],
        [-4.8903, -1.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42295029759407043
Epoch 0, Step 4266: train/loss = 0.4643002152442932, train/raw-loss = 0.4376975893974304, train/logprobs = tensor([[-1.4961, -4.1918],
        [-2.2315, -2.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2660262882709503
Epoch 0, Step 4267: train/loss = 0.5368160605430603, train/raw-loss = 0.4939258396625519, train/logprobs = tensor([[-1.9899, -2.5533],
        [-4.5812, -2.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42890194058418274
Epoch 0, Step 4268: train/loss = 0.2781679332256317, train/raw-loss = 0.24216412007808685, train/logprobs = tensor([[-2.1720, -5.0771],
        [-3.3230, -1.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3600378930568695
Epoch 0, Step 4269: train/loss = 0.17331473529338837, train/raw-loss = 0.13365431129932404, train/logprobs = tensor([[-1.8483, -8.5894],
        [-3.6992, -2.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39660409092903137
Epoch 0, Step 4270: train/loss = 0.2546873092651367, train/raw-loss = 0.2127998024225235, train/logprobs = tensor([[-1.7329, -8.2511],
        [-3.3064, -1.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41887515783309937
Epoch 0, Step 4271: train/loss = 0.3167002499103546, train/raw-loss = 0.27285805344581604, train/logprobs = tensor([[ -2.3822, -12.7845],
        [ -4.3976,  -4.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43842220306396484
Epoch 0, Step 4272: train/loss = 0.11082715541124344, train/raw-loss = 0.06997336447238922, train/logprobs = tensor([[ -1.5067, -15.3040],
        [ -4.4768,  -3.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40853792428970337
Epoch 0, Step 4273: train/loss = 0.13802102208137512, train/raw-loss = 0.08793707191944122, train/logprobs = tensor([[ -1.4543, -11.0059],
        [ -4.5931,  -3.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5008395314216614
Epoch 0, Step 4274: train/loss = 0.2772054374217987, train/raw-loss = 0.2375405877828598, train/logprobs = tensor([[-1.9054, -6.5472],
        [-3.6951, -1.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3966485559940338
Epoch 0, Step 4275: train/loss = 0.4597318172454834, train/raw-loss = 0.4203336834907532, train/logprobs = tensor([[-1.2772, -3.0092],
        [-3.3822, -2.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3939814567565918
Epoch 0, Step 4276: train/loss = 0.31228381395339966, train/raw-loss = 0.26947131752967834, train/logprobs = tensor([[-1.4922, -8.0380],
        [-3.5718, -1.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42812490463256836
Epoch 0, Step 4277: train/loss = 0.46162906289100647, train/raw-loss = 0.4080760180950165, train/logprobs = tensor([[-2.2815, -6.0324],
        [-3.9592, -2.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5355303287506104
Epoch 0, Step 4278: train/loss = 0.384603887796402, train/raw-loss = 0.3377993106842041, train/logprobs = tensor([[ -1.9898, -11.4810],
        [ -5.1907,  -6.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4680456519126892
Epoch 0, Step 4279: train/loss = 0.12789466977119446, train/raw-loss = 0.09017965197563171, train/logprobs = tensor([[ -2.9938, -10.0118],
        [ -6.2946,  -1.3751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37715011835098267
Epoch 0, Step 4280: train/loss = 0.43355587124824524, train/raw-loss = 0.395621120929718, train/logprobs = tensor([[-1.8015, -7.3337],
        [-2.7730, -2.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793478012084961
Epoch 0, Step 4281: train/loss = 0.4243091344833374, train/raw-loss = 0.3867908716201782, train/logprobs = tensor([[-1.8999, -4.1935],
        [-4.0180, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37518244981765747
Epoch 0, Step 4282: train/loss = 0.09631668031215668, train/raw-loss = 0.047386206686496735, train/logprobs = tensor([[ -1.4853, -13.1048],
        [ -5.6595,  -1.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.489304780960083
Epoch 0, Step 4283: train/loss = 0.16761529445648193, train/raw-loss = 0.1334391087293625, train/logprobs = tensor([[-2.2309, -8.5991],
        [-4.8096, -2.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3417617976665497
Epoch 0, Step 4284: train/loss = 0.23395314812660217, train/raw-loss = 0.19932571053504944, train/logprobs = tensor([[-1.0110, -5.3461],
        [-4.1982, -1.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462742865085602
Epoch 0, Step 4285: train/loss = 0.39616429805755615, train/raw-loss = 0.35823073983192444, train/logprobs = tensor([[ -1.9089, -10.2427],
        [ -4.4688,  -1.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793359100818634
Epoch 0, Step 4286: train/loss = 0.31108707189559937, train/raw-loss = 0.2698906660079956, train/logprobs = tensor([[-3.1659, -7.5877],
        [-4.6493, -1.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4119636118412018
Epoch 0, Step 4287: train/loss = 0.29242071509361267, train/raw-loss = 0.2504021227359772, train/logprobs = tensor([[-1.2286, -6.4829],
        [-3.6510, -2.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42018598318099976
Epoch 0, Step 4288: train/loss = 0.2465057075023651, train/raw-loss = 0.20094886422157288, train/logprobs = tensor([[ -1.5639, -10.1368],
        [ -5.8538,  -1.4490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4555685818195343
Epoch 0, Step 4289: train/loss = 0.314852237701416, train/raw-loss = 0.27229511737823486, train/logprobs = tensor([[-1.9461, -7.3402],
        [-3.6157, -2.3229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4255713224411011
Epoch 0, Step 4290: train/loss = 0.2585931122303009, train/raw-loss = 0.22348377108573914, train/logprobs = tensor([[-1.9050, -9.7633],
        [-4.2877, -1.4841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3510936200618744
Epoch 0, Step 4291: train/loss = 0.5705402493476868, train/raw-loss = 0.5266766548156738, train/logprobs = tensor([[-2.6705, -4.8149],
        [-3.3869, -1.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43863624334335327
Epoch 0, Step 4292: train/loss = 0.1964922845363617, train/raw-loss = 0.16818095743656158, train/logprobs = tensor([[-1.1044, -7.1749],
        [-3.5125, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831135094165802
Epoch 0, Step 4293: train/loss = 0.1289425790309906, train/raw-loss = 0.08062819391489029, train/logprobs = tensor([[ -1.5297, -11.6520],
        [ -5.0126,  -2.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4831439256668091
Epoch 0, Step 4294: train/loss = 0.8832571506500244, train/raw-loss = 0.8457068204879761, train/logprobs = tensor([[-4.1739, -9.8749],
        [-2.6391, -3.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37550389766693115
Epoch 0, Step 4295: train/loss = 0.19825929403305054, train/raw-loss = 0.1576526165008545, train/logprobs = tensor([[-1.2945, -6.9959],
        [-4.1808, -1.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40606689453125
Epoch 0, Step 4296: train/loss = 0.13828019797801971, train/raw-loss = 0.09796211123466492, train/logprobs = tensor([[ -2.4465, -10.1239],
        [ -4.5302,  -1.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4031807482242584
Epoch 0, Step 4297: train/loss = 0.40047600865364075, train/raw-loss = 0.36381155252456665, train/logprobs = tensor([[-2.1224, -3.1937],
        [-4.1892, -1.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36664456129074097
Epoch 0, Step 4298: train/loss = 0.17244017124176025, train/raw-loss = 0.134980246424675, train/logprobs = tensor([[-1.6720, -9.4510],
        [-4.3264, -1.6704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3745990991592407
Epoch 0, Step 4299: train/loss = 0.3462570011615753, train/raw-loss = 0.2999051809310913, train/logprobs = tensor([[-1.7838, -3.8640],
        [-3.4181, -2.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635181725025177
Epoch 0, Step 4300: train/loss = 0.3565142750740051, train/raw-loss = 0.3261975049972534, train/logprobs = tensor([[-2.3556, -8.8575],
        [-3.6276, -2.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031677007675171
Epoch 0, Step 4301: train/loss = 0.17510919272899628, train/raw-loss = 0.12379855662584305, train/logprobs = tensor([[-1.7110, -9.1853],
        [-4.4250, -3.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5131062865257263
Epoch 0, Step 4302: train/loss = 0.4194675385951996, train/raw-loss = 0.37649184465408325, train/logprobs = tensor([[-1.4744, -9.3202],
        [-3.8423, -2.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4297564625740051
Epoch 0, Step 4303: train/loss = 0.12672410905361176, train/raw-loss = 0.08905854821205139, train/logprobs = tensor([[-2.2453, -9.1123],
        [-4.7801, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3766555190086365
Epoch 0, Step 4304: train/loss = 0.3781183362007141, train/raw-loss = 0.33428382873535156, train/logprobs = tensor([[-1.0623, -7.9578],
        [-3.8548, -2.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43834489583969116
Epoch 0, Step 4305: train/loss = 0.3654922842979431, train/raw-loss = 0.32724714279174805, train/logprobs = tensor([[-3.2445, -8.0512],
        [-4.5635, -1.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38245129585266113
Epoch 0, Step 4306: train/loss = 0.49359577894210815, train/raw-loss = 0.4502708613872528, train/logprobs = tensor([[-1.4579, -8.9267],
        [-3.9378, -5.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43324941396713257
Epoch 0, Step 4307: train/loss = 0.22116529941558838, train/raw-loss = 0.18267396092414856, train/logprobs = tensor([[ -1.3814, -12.9856],
        [ -3.0996,  -4.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38491326570510864
Epoch 0, Step 4308: train/loss = 0.29085075855255127, train/raw-loss = 0.25969329476356506, train/logprobs = tensor([[-1.8585, -6.8063],
        [-2.2780, -1.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115747570991516
Epoch 0, Step 4309: train/loss = 0.433748722076416, train/raw-loss = 0.3997081220149994, train/logprobs = tensor([[-2.2469, -4.8697],
        [-3.7195, -2.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404061794281006
Epoch 0, Step 4310: train/loss = 0.3104991614818573, train/raw-loss = 0.2729068398475647, train/logprobs = tensor([[-2.1549, -8.5506],
        [-4.3047, -2.2974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3759233057498932
Epoch 0, Step 4311: train/loss = 0.33539775013923645, train/raw-loss = 0.2984920144081116, train/logprobs = tensor([[-1.8054, -9.8095],
        [-2.4942, -1.8486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3690572679042816
Epoch 0, Step 4312: train/loss = 0.08352036029100418, train/raw-loss = 0.035574447363615036, train/logprobs = tensor([[ -1.4544, -15.9119],
        [ -5.4095,  -3.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47945916652679443
Epoch 0, Step 4313: train/loss = 0.369477242231369, train/raw-loss = 0.3145849406719208, train/logprobs = tensor([[-2.2315, -6.2575],
        [-5.3202, -4.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5489231944084167
Epoch 0, Step 4314: train/loss = 0.6957447528839111, train/raw-loss = 0.6737335324287415, train/logprobs = tensor([[-1.9991, -2.6091],
        [-1.5627, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22011207044124603
Epoch 0, Step 4315: train/loss = 0.5974937081336975, train/raw-loss = 0.5624819993972778, train/logprobs = tensor([[-2.3772, -2.8887],
        [-2.6474, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35011669993400574
Epoch 0, Step 4316: train/loss = 0.34409230947494507, train/raw-loss = 0.3062567114830017, train/logprobs = tensor([[-1.7503, -6.1791],
        [-3.8687, -1.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3783561885356903
Epoch 0, Step 4317: train/loss = 0.5154463648796082, train/raw-loss = 0.48103174567222595, train/logprobs = tensor([[-2.0870, -9.1347],
        [-2.6497, -2.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441463112831116
Epoch 0, Step 4318: train/loss = 1.1268633604049683, train/raw-loss = 1.0910043716430664, train/logprobs = tensor([[-4.0306, -6.9214],
        [-1.8042, -1.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35859015583992004
Epoch 0, Step 4319: train/loss = 0.25866618752479553, train/raw-loss = 0.210428386926651, train/logprobs = tensor([[-1.2060, -6.0433],
        [-4.0875, -2.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4823780953884125
Epoch 0, Step 4320: train/loss = 0.1908387690782547, train/raw-loss = 0.14583498239517212, train/logprobs = tensor([[-1.7817, -7.4183],
        [-5.5350, -2.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4500378370285034
Epoch 0, Step 4321: train/loss = 0.3014410436153412, train/raw-loss = 0.2554476857185364, train/logprobs = tensor([[-1.4124, -9.7266],
        [-4.0437, -4.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45993369817733765
Epoch 0, Step 4322: train/loss = 0.14626502990722656, train/raw-loss = 0.10969704389572144, train/logprobs = tensor([[-2.0100, -9.2954],
        [-4.6748, -1.7963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36567988991737366
Epoch 0, Step 4323: train/loss = 0.28244566917419434, train/raw-loss = 0.25164973735809326, train/logprobs = tensor([[-2.1054, -9.2344],
        [-4.6679, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30795910954475403
Epoch 0, Step 4324: train/loss = 0.3972907066345215, train/raw-loss = 0.3602970838546753, train/logprobs = tensor([[-3.3647, -9.9560],
        [-4.9147, -4.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36993634700775146
Epoch 0, Step 4325: train/loss = 0.199355810880661, train/raw-loss = 0.15106500685214996, train/logprobs = tensor([[-1.9207, -6.8685],
        [-4.0331, -1.7075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4829081892967224
Epoch 0, Step 4326: train/loss = 0.43866145610809326, train/raw-loss = 0.3928874731063843, train/logprobs = tensor([[-1.4386, -9.2174],
        [-4.1381, -3.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4577394723892212
Epoch 0, Step 4327: train/loss = 0.15000835061073303, train/raw-loss = 0.11959492415189743, train/logprobs = tensor([[-2.5113, -6.2260],
        [-4.2525, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041342496871948
Epoch 0, Step 4328: train/loss = 0.32695165276527405, train/raw-loss = 0.281570702791214, train/logprobs = tensor([[-0.9707, -5.1925],
        [-3.0290, -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45380955934524536
Epoch 0, Step 4329: train/loss = 0.3646010756492615, train/raw-loss = 0.32617783546447754, train/logprobs = tensor([[-2.4685, -8.2506],
        [-3.3592, -1.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3842322826385498
Epoch 0, Step 4330: train/loss = 0.6924108266830444, train/raw-loss = 0.6510294079780579, train/logprobs = tensor([[-1.1062, -1.7310],
        [-2.1697, -2.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4138137102127075
Epoch 0, Step 4331: train/loss = 0.339661180973053, train/raw-loss = 0.3012077212333679, train/logprobs = tensor([[-1.4381, -8.1238],
        [-2.9473, -1.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38453465700149536
Epoch 0, Step 4332: train/loss = 0.2202300876379013, train/raw-loss = 0.1813172996044159, train/logprobs = tensor([[-2.3291, -7.9662],
        [-4.3604, -2.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891279995441437
Epoch 0, Step 4333: train/loss = 0.0639009177684784, train/raw-loss = 0.022246787324547768, train/logprobs = tensor([[ -1.1778, -12.2379],
        [ -4.7180,  -1.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41654127836227417
Epoch 0, Step 4334: train/loss = 0.48029735684394836, train/raw-loss = 0.44150474667549133, train/logprobs = tensor([[-1.8720, -3.9329],
        [-2.4520, -2.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879263997077942
Epoch 0, Step 4335: train/loss = 0.3014850914478302, train/raw-loss = 0.2620444893836975, train/logprobs = tensor([[-0.7020, -7.3224],
        [-2.1953, -1.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39440593123435974
Epoch 0, Step 4336: train/loss = 0.15708252787590027, train/raw-loss = 0.1257740557193756, train/logprobs = tensor([[ -1.7155, -13.8217],
        [ -3.4024,  -3.2492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31308484077453613
Epoch 0, Step 4337: train/loss = 0.21713903546333313, train/raw-loss = 0.17708490788936615, train/logprobs = tensor([[ -1.0231, -11.4344],
        [ -3.2727,  -2.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40054136514663696
Epoch 0, Step 4338: train/loss = 0.24492162466049194, train/raw-loss = 0.2039731740951538, train/logprobs = tensor([[-2.0054, -8.6581],
        [-3.7806, -2.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40948450565338135
Epoch 0, Step 4339: train/loss = 0.3245248794555664, train/raw-loss = 0.2821509540081024, train/logprobs = tensor([[-1.6761, -8.3964],
        [-4.9424, -4.2140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4237390160560608
Epoch 0, Step 4340: train/loss = 0.4508413076400757, train/raw-loss = 0.4072393774986267, train/logprobs = tensor([[ -2.7927, -12.1468],
        [ -3.7694,  -5.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43601953983306885
Epoch 0, Step 4341: train/loss = 0.39510971307754517, train/raw-loss = 0.3543741703033447, train/logprobs = tensor([[ -2.7220, -14.8698],
        [ -3.4409,  -1.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40735572576522827
Epoch 0, Step 4342: train/loss = 0.2612132132053375, train/raw-loss = 0.2062833607196808, train/logprobs = tensor([[-1.0616, -8.3256],
        [-4.1915, -2.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5492984056472778
Epoch 0, Step 4343: train/loss = 0.37350699305534363, train/raw-loss = 0.3257884979248047, train/logprobs = tensor([[ -1.7003, -11.1503],
        [ -5.7650,  -5.2812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47718513011932373
Epoch 0, Step 4344: train/loss = 0.0844620019197464, train/raw-loss = 0.04386927932500839, train/logprobs = tensor([[-2.0724, -7.8114],
        [-5.0496, -2.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40592724084854126
Epoch 0, Step 4345: train/loss = 0.6421040296554565, train/raw-loss = 0.607488751411438, train/logprobs = tensor([[-1.8688, -1.7512],
        [-2.0515, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461529612541199
Epoch 0, Step 4346: train/loss = 0.3974444568157196, train/raw-loss = 0.3588225841522217, train/logprobs = tensor([[-1.7023, -4.7086],
        [-3.8058, -2.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3862186670303345
Epoch 0, Step 4347: train/loss = 0.4590039849281311, train/raw-loss = 0.41436922550201416, train/logprobs = tensor([[-3.1440, -4.1361],
        [-5.9718, -2.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44634726643562317
Epoch 0, Step 4348: train/loss = 0.5047910809516907, train/raw-loss = 0.46730703115463257, train/logprobs = tensor([[-3.0548, -5.4260],
        [-3.2727, -2.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37484052777290344
Epoch 0, Step 4349: train/loss = 0.1251899152994156, train/raw-loss = 0.09084824472665787, train/logprobs = tensor([[ -1.4786, -11.0125],
        [ -3.9797,  -2.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.343416690826416
Epoch 0, Step 4350: train/loss = 0.5146299600601196, train/raw-loss = 0.47403982281684875, train/logprobs = tensor([[-1.9517, -5.7917],
        [-2.1720, -2.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40590089559555054
Epoch 0, Step 4351: train/loss = 0.31561392545700073, train/raw-loss = 0.27902308106422424, train/logprobs = tensor([[ -1.3686, -10.1299],
        [ -3.4068,  -1.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659086525440216
Epoch 0, Step 4352: train/loss = 0.1684475839138031, train/raw-loss = 0.13396869599819183, train/logprobs = tensor([[ -1.9027, -15.0358],
        [ -4.9506,  -4.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34478896856307983
Epoch 0, Step 4353: train/loss = 0.14761944115161896, train/raw-loss = 0.10915082693099976, train/logprobs = tensor([[ -1.5437, -13.3031],
        [ -3.6998,  -2.8237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38468605279922485
Epoch 0, Step 4354: train/loss = 0.07074005901813507, train/raw-loss = 0.025492355227470398, train/logprobs = tensor([[ -1.2825, -12.4556],
        [ -4.7030,  -1.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45247700810432434
Epoch 0, Step 4355: train/loss = 0.33812785148620605, train/raw-loss = 0.28927743434906006, train/logprobs = tensor([[ -1.8275, -14.7052],
        [ -5.1897,  -7.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4885041117668152
Epoch 0, Step 4356: train/loss = 0.4631388783454895, train/raw-loss = 0.42791256308555603, train/logprobs = tensor([[-2.5969, -4.9820],
        [-2.7451, -1.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35226303339004517
Epoch 0, Step 4357: train/loss = 0.21810731291770935, train/raw-loss = 0.17494070529937744, train/logprobs = tensor([[-1.4694, -9.6221],
        [-4.4559, -3.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4316660761833191
Epoch 0, Step 4358: train/loss = 0.05959153175354004, train/raw-loss = 0.011760283261537552, train/logprobs = tensor([[ -1.8196, -14.5535],
        [ -6.2213,  -1.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47831249237060547
Epoch 0, Step 4359: train/loss = 0.49032655358314514, train/raw-loss = 0.446383535861969, train/logprobs = tensor([[-1.6403, -4.1625],
        [-3.7055, -2.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43943020701408386
Epoch 0, Step 4360: train/loss = 0.15406569838523865, train/raw-loss = 0.12031539529561996, train/logprobs = tensor([[-2.7228, -8.0377],
        [-4.9988, -1.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33750298619270325
Epoch 0, Step 4361: train/loss = 0.2871704697608948, train/raw-loss = 0.24303041398525238, train/logprobs = tensor([[-2.3471, -8.4329],
        [-5.2759, -2.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4414006173610687
Epoch 0, Step 4362: train/loss = 0.4566280245780945, train/raw-loss = 0.4160364270210266, train/logprobs = tensor([[-1.9754, -6.9216],
        [-2.7288, -3.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4059159457683563
Epoch 0, Step 4363: train/loss = 0.05581897869706154, train/raw-loss = 0.015651533380150795, train/logprobs = tensor([[ -1.6682, -13.2385],
        [ -5.7139,  -1.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40167444944381714
Epoch 0, Step 4364: train/loss = 0.6595755219459534, train/raw-loss = 0.6191959381103516, train/logprobs = tensor([[-1.7602, -6.7826],
        [-1.8821, -2.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4037952423095703
Epoch 0, Step 4365: train/loss = 0.27335840463638306, train/raw-loss = 0.23355913162231445, train/logprobs = tensor([[-2.0550, -7.8215],
        [-3.3707, -1.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39799267053604126
Epoch 0, Step 4366: train/loss = 0.1293524205684662, train/raw-loss = 0.09478934854269028, train/logprobs = tensor([[ -1.7998, -11.1085],
        [ -3.9032,  -1.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3456306755542755
Epoch 0, Step 4367: train/loss = 0.40499231219291687, train/raw-loss = 0.36120492219924927, train/logprobs = tensor([[-2.2686, -4.6177],
        [-3.6118, -2.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4378740191459656
Epoch 0, Step 4368: train/loss = 0.41602596640586853, train/raw-loss = 0.3735511600971222, train/logprobs = tensor([[-2.0451, -6.8671],
        [-3.4708, -1.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42474815249443054
Epoch 0, Step 4369: train/loss = 0.30360960960388184, train/raw-loss = 0.2655603587627411, train/logprobs = tensor([[ -1.0414, -10.8735],
        [ -3.3002,  -4.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38049280643463135
Epoch 0, Step 4370: train/loss = 0.3643858730792999, train/raw-loss = 0.31570732593536377, train/logprobs = tensor([[-1.6742, -5.7725],
        [-3.4283, -2.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.486785352230072
Epoch 0, Step 4371: train/loss = 0.358441561460495, train/raw-loss = 0.32055196166038513, train/logprobs = tensor([[ -2.5283, -14.8729],
        [ -3.7427,  -3.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37889593839645386
Epoch 0, Step 4372: train/loss = 0.35876256227493286, train/raw-loss = 0.32098573446273804, train/logprobs = tensor([[-1.9069, -6.9125],
        [-3.3502, -2.1934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.377768337726593
Epoch 0, Step 4373: train/loss = 0.312785267829895, train/raw-loss = 0.2686099410057068, train/logprobs = tensor([[-2.0837, -7.3061],
        [-3.9360, -2.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44175317883491516
Epoch 0, Step 4374: train/loss = 0.8409929275512695, train/raw-loss = 0.8024013638496399, train/logprobs = tensor([[-1.3810, -1.3227],
        [-1.7321, -1.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3859155774116516
Epoch 0, Step 4375: train/loss = 0.4025491774082184, train/raw-loss = 0.3584668040275574, train/logprobs = tensor([[-1.6692, -9.6428],
        [-4.8282, -5.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4408237040042877
Epoch 0, Step 4376: train/loss = 0.1760958731174469, train/raw-loss = 0.137783020734787, train/logprobs = tensor([[-1.6609, -5.8355],
        [-3.6112, -2.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3831285536289215
Epoch 0, Step 4377: train/loss = 0.48245158791542053, train/raw-loss = 0.4381638765335083, train/logprobs = tensor([[-3.4065, -7.7844],
        [-7.5516, -3.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44287702441215515
Epoch 0, Step 4378: train/loss = 0.265285849571228, train/raw-loss = 0.23053917288780212, train/logprobs = tensor([[-2.4653, -8.2130],
        [-3.8137, -2.4263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34746667742729187
Epoch 0, Step 4379: train/loss = 0.12705175578594208, train/raw-loss = 0.08659162372350693, train/logprobs = tensor([[ -1.5901, -10.9661],
        [ -5.1381,  -3.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046013057231903
Epoch 0, Step 4380: train/loss = 0.11006981134414673, train/raw-loss = 0.07035679370164871, train/logprobs = tensor([[ -2.0556, -14.2943],
        [ -4.5160,  -3.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3971301317214966
Epoch 0, Step 4381: train/loss = 0.4585431218147278, train/raw-loss = 0.4206772446632385, train/logprobs = tensor([[-2.2549, -9.6895],
        [-3.3413, -2.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378659188747406
Epoch 0, Step 4382: train/loss = 0.18179191648960114, train/raw-loss = 0.14611579477787018, train/logprobs = tensor([[ -2.6956, -12.2194],
        [ -4.5406,  -2.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3567614257335663
Epoch 0, Step 4383: train/loss = 0.7840217351913452, train/raw-loss = 0.7549999952316284, train/logprobs = tensor([[-3.3393, -5.1814],
        [-1.9019, -2.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29021793603897095
Epoch 0, Step 4384: train/loss = 0.7125725150108337, train/raw-loss = 0.675873875617981, train/logprobs = tensor([[-3.5262, -8.0631],
        [-4.2488, -2.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669874966144562
Epoch 0, Step 4385: train/loss = 0.22532644867897034, train/raw-loss = 0.1864859014749527, train/logprobs = tensor([[ -1.5017, -16.2815],
        [ -4.1989,  -5.2140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38840529322624207
Epoch 0, Step 4386: train/loss = 0.2239689975976944, train/raw-loss = 0.1910504847764969, train/logprobs = tensor([[-1.9961, -8.0231],
        [-3.1630, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32918503880500793
Epoch 0, Step 4387: train/loss = 0.5792423486709595, train/raw-loss = 0.5366408228874207, train/logprobs = tensor([[-2.6515, -4.8145],
        [-4.0837, -1.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4260149300098419
Epoch 0, Step 4388: train/loss = 0.32169294357299805, train/raw-loss = 0.286712646484375, train/logprobs = tensor([[-1.6643, -5.6273],
        [-2.8799, -1.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3498028516769409
Epoch 0, Step 4389: train/loss = 0.9590728282928467, train/raw-loss = 0.9293730854988098, train/logprobs = tensor([[-4.0196, -8.4920],
        [-3.4407, -2.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29699715971946716
Epoch 0, Step 4390: train/loss = 0.46043074131011963, train/raw-loss = 0.419683575630188, train/logprobs = tensor([[-2.6710, -7.9995],
        [-4.6442, -2.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40747177600860596
Epoch 0, Step 4391: train/loss = 0.05913904309272766, train/raw-loss = 0.01355037186294794, train/logprobs = tensor([[ -1.0990, -14.8812],
        [ -5.0480,  -4.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4558866620063782
Epoch 0, Step 4392: train/loss = 0.452639102935791, train/raw-loss = 0.4113914370536804, train/logprobs = tensor([[-2.8618, -8.7966],
        [-4.1066, -2.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41247665882110596
Epoch 0, Step 4393: train/loss = 0.5031397342681885, train/raw-loss = 0.4705284833908081, train/logprobs = tensor([[ -2.6234, -12.6498],
        [ -2.2956,  -2.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32611268758773804
Epoch 0, Step 4394: train/loss = 0.19438907504081726, train/raw-loss = 0.16397711634635925, train/logprobs = tensor([[-1.7085, -6.4198],
        [-4.3976, -1.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041195869445801
Epoch 0, Step 4395: train/loss = 0.3263206481933594, train/raw-loss = 0.291323184967041, train/logprobs = tensor([[-1.6675, -6.5805],
        [-2.6780, -2.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34997472167015076
Epoch 0, Step 4396: train/loss = 0.2852272391319275, train/raw-loss = 0.24721869826316833, train/logprobs = tensor([[-2.9571, -6.1451],
        [-4.7085, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38008540868759155
Epoch 0, Step 4397: train/loss = 0.5657016634941101, train/raw-loss = 0.5350398421287537, train/logprobs = tensor([[-3.3078, -9.6489],
        [-3.2941, -1.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066185712814331
Epoch 0, Step 4398: train/loss = 0.30488720536231995, train/raw-loss = 0.2580104172229767, train/logprobs = tensor([[-1.9553, -4.8888],
        [-4.3507, -1.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46876800060272217
Epoch 0, Step 4399: train/loss = 0.14884287118911743, train/raw-loss = 0.10563313961029053, train/logprobs = tensor([[ -2.2016, -13.3272],
        [ -4.9690,  -5.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43209731578826904
Epoch 0, Step 4400: train/loss = 0.10997681319713593, train/raw-loss = 0.07595716416835785, train/logprobs = tensor([[-2.4400, -8.9766],
        [-4.3975, -2.4206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.340196430683136
Epoch 0, Step 4401: train/loss = 0.465343713760376, train/raw-loss = 0.42014217376708984, train/logprobs = tensor([[-1.5762, -6.3426],
        [-3.7466, -2.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45201539993286133
Epoch 0, Step 4402: train/loss = 0.06982970237731934, train/raw-loss = 0.028585098683834076, train/logprobs = tensor([[ -1.1493, -20.7060],
        [ -4.6166,  -2.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4124460220336914
Epoch 0, Step 4403: train/loss = 0.22680535912513733, train/raw-loss = 0.19049392640590668, train/logprobs = tensor([[-1.7288, -7.6429],
        [-3.5420, -1.3548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3631143867969513
Epoch 0, Step 4404: train/loss = 0.43004167079925537, train/raw-loss = 0.3885831832885742, train/logprobs = tensor([[-2.1290, -7.8863],
        [-3.1167, -3.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.414585143327713
Epoch 0, Step 4405: train/loss = 0.36610352993011475, train/raw-loss = 0.32364407181739807, train/logprobs = tensor([[-2.3642, -6.3297],
        [-4.2031, -3.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4245946407318115
Epoch 0, Step 4406: train/loss = 0.687899112701416, train/raw-loss = 0.6611774563789368, train/logprobs = tensor([[-2.8933, -6.9116],
        [-1.7356, -1.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26721692085266113
Epoch 0, Step 4407: train/loss = 0.33118361234664917, train/raw-loss = 0.29619768261909485, train/logprobs = tensor([[-2.2685, -7.6577],
        [-3.6189, -1.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3498593270778656
Epoch 0, Step 4408: train/loss = 0.6399788856506348, train/raw-loss = 0.6021657586097717, train/logprobs = tensor([[-3.8648, -6.8907],
        [-3.9417, -2.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37813177704811096
Epoch 0, Step 4409: train/loss = 0.4028792977333069, train/raw-loss = 0.36173301935195923, train/logprobs = tensor([[ -2.8272, -10.1947],
        [ -3.2119,  -1.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41146278381347656
Epoch 0, Step 4410: train/loss = 0.24590753018856049, train/raw-loss = 0.20567189157009125, train/logprobs = tensor([[-1.6692, -5.3948],
        [-4.0417, -2.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40235635638237
Epoch 0, Step 4411: train/loss = 0.6065747141838074, train/raw-loss = 0.5738891363143921, train/logprobs = tensor([[-2.3509, -4.7081],
        [-3.6931, -1.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3268561363220215
Epoch 0, Step 4412: train/loss = 0.29335516691207886, train/raw-loss = 0.2631380558013916, train/logprobs = tensor([[-1.4673, -5.7768],
        [-3.3877, -1.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021712005138397
Epoch 0, Step 4413: train/loss = 0.17403613030910492, train/raw-loss = 0.13961052894592285, train/logprobs = tensor([[-2.2599, -6.1173],
        [-4.9057, -2.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34425586462020874
Epoch 0, Step 4414: train/loss = 0.4974825382232666, train/raw-loss = 0.44300898909568787, train/logprobs = tensor([[-2.3850, -5.3584],
        [-4.0858, -2.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5447355508804321
Epoch 0, Step 4415: train/loss = 0.06752309203147888, train/raw-loss = 0.022409090772271156, train/logprobs = tensor([[ -1.4901, -17.1780],
        [ -4.9826,  -4.2945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45113998651504517
Epoch 0, Step 4416: train/loss = 0.9730992317199707, train/raw-loss = 0.9330587387084961, train/logprobs = tensor([[-3.8268, -5.3280],
        [-3.2359, -3.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40040481090545654
Epoch 0, Step 4417: train/loss = 0.40853947401046753, train/raw-loss = 0.38184159994125366, train/logprobs = tensor([[-2.0350, -9.8618],
        [-2.7752, -1.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2669786214828491
Epoch 0, Step 4418: train/loss = 0.11820124089717865, train/raw-loss = 0.07173730432987213, train/logprobs = tensor([[ -1.8003, -14.4403],
        [ -5.2308,  -3.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4646393656730652
Epoch 0, Step 4419: train/loss = 0.4886663854122162, train/raw-loss = 0.44430267810821533, train/logprobs = tensor([[ -1.4604, -10.1040],
        [ -2.8268,  -2.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44363707304000854
Epoch 0, Step 4420: train/loss = 0.8125120401382446, train/raw-loss = 0.7779555916786194, train/logprobs = tensor([[-3.3065, -7.1792],
        [-2.5279, -1.3144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34556493163108826
Epoch 0, Step 4421: train/loss = 0.2036585956811905, train/raw-loss = 0.16696104407310486, train/logprobs = tensor([[-1.6846, -9.6297],
        [-3.9783, -2.3279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669755756855011
Epoch 0, Step 4422: train/loss = 0.15330497920513153, train/raw-loss = 0.1187390387058258, train/logprobs = tensor([[ -1.7511, -16.7724],
        [ -3.9841,  -2.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34565937519073486
Epoch 0, Step 4423: train/loss = 0.2945038080215454, train/raw-loss = 0.2524798810482025, train/logprobs = tensor([[-2.3263, -8.0018],
        [-3.9942, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4202393591403961
Epoch 0, Step 4424: train/loss = 0.5369573831558228, train/raw-loss = 0.49441957473754883, train/logprobs = tensor([[-2.3270, -3.9541],
        [-3.4285, -2.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42537838220596313
Epoch 0, Step 4425: train/loss = 0.12736786901950836, train/raw-loss = 0.09047536551952362, train/logprobs = tensor([[ -1.7163, -16.5135],
        [ -3.6391,  -1.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3689250349998474
Epoch 0, Step 4426: train/loss = 0.4516163766384125, train/raw-loss = 0.40510281920433044, train/logprobs = tensor([[-1.6310, -7.5640],
        [-4.1803, -3.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46513527631759644
Epoch 0, Step 4427: train/loss = 0.5645003318786621, train/raw-loss = 0.5242147445678711, train/logprobs = tensor([[-1.8229, -2.6613],
        [-2.6001, -2.3307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4028562009334564
Epoch 0, Step 4428: train/loss = 0.10037051141262054, train/raw-loss = 0.06633023917675018, train/logprobs = tensor([[ -2.3320, -16.2712],
        [ -4.5427,  -4.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404027223587036
Epoch 0, Step 4429: train/loss = 0.24546729028224945, train/raw-loss = 0.20830079913139343, train/logprobs = tensor([[ -1.9115, -14.8784],
        [ -3.8298,  -2.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3716648519039154
Epoch 0, Step 4430: train/loss = 0.4238712191581726, train/raw-loss = 0.3773004710674286, train/logprobs = tensor([[-2.3762, -9.6767],
        [-3.9167, -2.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46570754051208496
Epoch 0, Step 4431: train/loss = 1.336876392364502, train/raw-loss = 1.3056336641311646, train/logprobs = tensor([[-5.6588, -7.9941],
        [-2.4748, -2.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124277591705322
Epoch 0, Step 4432: train/loss = 1.0947051048278809, train/raw-loss = 1.0578155517578125, train/logprobs = tensor([[-3.2612, -6.1057],
        [-1.7059, -2.4044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3688964247703552
Epoch 0, Step 4433: train/loss = 0.3748589754104614, train/raw-loss = 0.3326948881149292, train/logprobs = tensor([[-2.1729, -9.7172],
        [-3.9363, -4.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42164090275764465
Epoch 0, Step 4434: train/loss = 0.3454795181751251, train/raw-loss = 0.3050091862678528, train/logprobs = tensor([[-1.2499, -6.6230],
        [-3.2801, -2.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40470343828201294
Epoch 0, Step 4435: train/loss = 0.6601722836494446, train/raw-loss = 0.6248259544372559, train/logprobs = tensor([[-4.1253, -8.3488],
        [-4.4305, -2.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3534628748893738
Epoch 0, Step 4436: train/loss = 0.8034706711769104, train/raw-loss = 0.7742069363594055, train/logprobs = tensor([[-4.4306, -9.4428],
        [-2.9693, -1.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2926376461982727
Epoch 0, Step 4437: train/loss = 0.36559873819351196, train/raw-loss = 0.32784050703048706, train/logprobs = tensor([[-1.7336, -9.9653],
        [-2.6433, -2.2720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3775821924209595
Epoch 0, Step 4438: train/loss = 2.5752758979797363, train/raw-loss = 2.527791738510132, train/logprobs = tensor([[ -9.7964, -13.4762],
        [ -3.4284,  -3.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47484129667282104
Epoch 0, Step 4439: train/loss = 0.284298837184906, train/raw-loss = 0.25508493185043335, train/logprobs = tensor([[ -2.2176, -12.1505],
        [ -2.9478,  -3.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29213905334472656
Epoch 0, Step 4440: train/loss = 0.23582439124584198, train/raw-loss = 0.19751280546188354, train/logprobs = tensor([[-1.3328, -9.1209],
        [-3.6345, -2.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3831160068511963
Epoch 0, Step 4441: train/loss = 0.14979088306427002, train/raw-loss = 0.10302664339542389, train/logprobs = tensor([[-1.6689, -9.6214],
        [-4.6244, -2.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4676424562931061
Epoch 0, Step 4442: train/loss = 0.18758362531661987, train/raw-loss = 0.1465187519788742, train/logprobs = tensor([[-1.8605, -9.6942],
        [-4.3677, -1.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106487035751343
Epoch 0, Step 4443: train/loss = 0.5207901000976562, train/raw-loss = 0.4755907654762268, train/logprobs = tensor([[-2.1605, -8.6359],
        [-3.0350, -2.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4519934058189392
Epoch 0, Step 4444: train/loss = 0.09370546042919159, train/raw-loss = 0.04739728569984436, train/logprobs = tensor([[ -2.2093, -10.4773],
        [ -5.2069,  -1.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630817472934723
Epoch 0, Step 4445: train/loss = 0.30755218863487244, train/raw-loss = 0.26748624444007874, train/logprobs = tensor([[-1.6954, -6.8152],
        [-3.3504, -2.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4006594121456146
Epoch 0, Step 4446: train/loss = 0.232787624001503, train/raw-loss = 0.1878618597984314, train/logprobs = tensor([[-2.0016, -9.1920],
        [-4.9941, -1.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4492577314376831
Epoch 0, Step 4447: train/loss = 0.4451695382595062, train/raw-loss = 0.41384220123291016, train/logprobs = tensor([[-1.5622, -8.6278],
        [-3.3002, -3.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31327328085899353
Epoch 0, Step 4448: train/loss = 0.24241182208061218, train/raw-loss = 0.1963634490966797, train/logprobs = tensor([[ -1.2837, -10.9378],
        [ -4.2413,  -4.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46048375964164734
Epoch 0, Step 4449: train/loss = 0.6496623754501343, train/raw-loss = 0.6089581251144409, train/logprobs = tensor([[-2.0103, -2.5029],
        [-2.2391, -1.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4070422351360321
Epoch 0, Step 4450: train/loss = 0.07178746163845062, train/raw-loss = 0.037456147372722626, train/logprobs = tensor([[-1.3430, -7.3539],
        [-5.0253, -2.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34331315755844116
Epoch 0, Step 4451: train/loss = 0.07808572053909302, train/raw-loss = 0.03791086748242378, train/logprobs = tensor([[ -1.9227, -17.7122],
        [ -5.4692,  -3.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40174853801727295
Epoch 0, Step 4452: train/loss = 0.4004306197166443, train/raw-loss = 0.3543529510498047, train/logprobs = tensor([[ -2.4361, -10.5477],
        [ -5.1898,  -5.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.460776686668396
Epoch 0, Step 4453: train/loss = 0.12748104333877563, train/raw-loss = 0.09467259049415588, train/logprobs = tensor([[ -1.7209, -10.4993],
        [ -3.9200,  -1.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32808467745780945
Epoch 0, Step 4454: train/loss = 0.13563260436058044, train/raw-loss = 0.10040650516748428, train/logprobs = tensor([[ -1.5120, -13.2286],
        [ -4.7452,  -3.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352260947227478
Epoch 0, Step 4455: train/loss = 0.46125778555870056, train/raw-loss = 0.4101806581020355, train/logprobs = tensor([[-2.0319, -5.4085],
        [-3.8692, -2.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5107712149620056
Epoch 0, Step 4456: train/loss = 1.1484489440917969, train/raw-loss = 1.1124746799468994, train/logprobs = tensor([[-4.1267, -7.3636],
        [-4.4581, -2.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3597448468208313
Epoch 0, Step 4457: train/loss = 0.41903841495513916, train/raw-loss = 0.3824015259742737, train/logprobs = tensor([[-2.7280, -9.9884],
        [-5.1562, -1.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3663690984249115
Epoch 0, Step 4458: train/loss = 0.32380640506744385, train/raw-loss = 0.2788481116294861, train/logprobs = tensor([[-2.6634, -7.2702],
        [-3.7287, -2.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4495829939842224
Epoch 0, Step 4459: train/loss = 0.26425835490226746, train/raw-loss = 0.22731763124465942, train/logprobs = tensor([[-1.8504, -5.0198],
        [-3.3242, -1.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3694073259830475
Epoch 0, Step 4460: train/loss = 1.9002196788787842, train/raw-loss = 1.8589344024658203, train/logprobs = tensor([[-6.2352, -6.9076],
        [-3.3370, -1.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4128528833389282
Epoch 0, Step 4461: train/loss = 0.5488925576210022, train/raw-loss = 0.5085663199424744, train/logprobs = tensor([[-2.0304, -8.1496],
        [-3.7257, -4.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40326231718063354
Epoch 0, Step 4462: train/loss = 0.5033482313156128, train/raw-loss = 0.4622769355773926, train/logprobs = tensor([[-0.8276, -2.8857],
        [-2.1022, -1.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4107128381729126
Epoch 0, Step 4463: train/loss = 0.38435912132263184, train/raw-loss = 0.34821420907974243, train/logprobs = tensor([[-3.0499, -7.4432],
        [-4.1601, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3614491820335388
Epoch 0, Step 4464: train/loss = 0.4512667953968048, train/raw-loss = 0.41415703296661377, train/logprobs = tensor([[ -1.3492, -12.2075],
        [ -3.1585,  -2.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37109747529029846
Epoch 0, Step 4465: train/loss = 0.37398746609687805, train/raw-loss = 0.3293361961841583, train/logprobs = tensor([[ -2.6972, -11.0822],
        [ -5.2516,  -2.3007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4465124309062958
Epoch 0, Step 4466: train/loss = 0.05856291949748993, train/raw-loss = 0.015064974315464497, train/logprobs = tensor([[ -1.5126, -14.1711],
        [ -5.6672,  -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43497946858406067
Epoch 0, Step 4467: train/loss = 0.1940537989139557, train/raw-loss = 0.1578386425971985, train/logprobs = tensor([[ -1.7751, -14.6814],
        [ -3.6061,  -4.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36215147376060486
Epoch 0, Step 4468: train/loss = 0.41502875089645386, train/raw-loss = 0.38740384578704834, train/logprobs = tensor([[-2.8045, -6.5637],
        [-3.7979, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2762492001056671
Epoch 0, Step 4469: train/loss = 0.07594797015190125, train/raw-loss = 0.04251325875520706, train/logprobs = tensor([[ -2.4926, -11.2190],
        [ -5.1235,  -1.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3343471884727478
Epoch 0, Step 4470: train/loss = 0.48242461681365967, train/raw-loss = 0.4505798816680908, train/logprobs = tensor([[-2.3111, -5.5137],
        [-3.6509, -1.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31844696402549744
Epoch 0, Step 4471: train/loss = 0.30989861488342285, train/raw-loss = 0.2671770453453064, train/logprobs = tensor([[ -1.5573, -11.3505],
        [ -3.9153,  -2.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4272153377532959
Epoch 0, Step 4472: train/loss = 0.13789546489715576, train/raw-loss = 0.08214421570301056, train/logprobs = tensor([[-2.4110, -6.4531],
        [-6.1740, -2.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5575124621391296
Epoch 0, Step 4473: train/loss = 0.24215494096279144, train/raw-loss = 0.2002958059310913, train/logprobs = tensor([[ -1.3087, -10.9768],
        [ -3.6361,  -3.2765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4185914099216461
Epoch 0, Step 4474: train/loss = 0.3990001380443573, train/raw-loss = 0.3568844199180603, train/logprobs = tensor([[-1.8627, -4.1440],
        [-4.1438, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42115694284439087
Epoch 0, Step 4475: train/loss = 0.35121574997901917, train/raw-loss = 0.3172593414783478, train/logprobs = tensor([[-3.7532, -8.2945],
        [-5.1961, -1.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3395635187625885
Epoch 0, Step 4476: train/loss = 0.407173752784729, train/raw-loss = 0.3646572530269623, train/logprobs = tensor([[-3.7809, -6.2580],
        [-4.9938, -2.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4251653552055359
Epoch 0, Step 4477: train/loss = 0.24362406134605408, train/raw-loss = 0.21261122822761536, train/logprobs = tensor([[-1.4554, -6.8462],
        [-3.7308, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101283311843872
Epoch 0, Step 4478: train/loss = 0.6993601322174072, train/raw-loss = 0.6658521890640259, train/logprobs = tensor([[-2.3809, -6.7929],
        [-2.9022, -2.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33507871627807617
Epoch 0, Step 4479: train/loss = 0.2669563293457031, train/raw-loss = 0.23747564852237701, train/logprobs = tensor([[-1.8620, -6.7987],
        [-3.2130, -1.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2948065996170044
Epoch 0, Step 4480: train/loss = 0.26165100932121277, train/raw-loss = 0.21898916363716125, train/logprobs = tensor([[-2.2098, -9.3603],
        [-5.3256, -3.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42661839723587036
Epoch 0, Step 4481: train/loss = 0.09705499559640884, train/raw-loss = 0.05279256030917168, train/logprobs = tensor([[-1.6141, -9.1618],
        [-5.6718, -2.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44262436032295227
Epoch 0, Step 4482: train/loss = 0.07863105088472366, train/raw-loss = 0.0403161346912384, train/logprobs = tensor([[ -1.8600, -14.7828],
        [ -5.0266,  -4.7299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3831491768360138
Epoch 0, Step 4483: train/loss = 0.4276980757713318, train/raw-loss = 0.38851383328437805, train/logprobs = tensor([[-1.9234, -4.7931],
        [-3.4588, -2.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918423652648926
Epoch 0, Step 4484: train/loss = 0.21580806374549866, train/raw-loss = 0.1631869077682495, train/logprobs = tensor([[-2.2120, -9.8808],
        [-3.6100, -2.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5262115597724915
Epoch 0, Step 4485: train/loss = 0.16665714979171753, train/raw-loss = 0.12915758788585663, train/logprobs = tensor([[ -2.3325, -13.1753],
        [ -4.8298,  -3.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3749955892562866
Epoch 0, Step 4486: train/loss = 0.4569808840751648, train/raw-loss = 0.4214589595794678, train/logprobs = tensor([[-2.3630, -8.2226],
        [-3.0066, -1.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35521888732910156
Epoch 0, Step 4487: train/loss = 1.4945271015167236, train/raw-loss = 1.452548623085022, train/logprobs = tensor([[ -7.4518, -14.5157],
        [ -5.5244,  -1.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41978397965431213
Epoch 0, Step 4488: train/loss = 0.3073801100254059, train/raw-loss = 0.2680722177028656, train/logprobs = tensor([[-1.9467, -5.4128],
        [-3.6836, -1.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3930787444114685
Epoch 0, Step 4489: train/loss = 0.8541699051856995, train/raw-loss = 0.8137918710708618, train/logprobs = tensor([[-5.0465, -9.4236],
        [-4.5148, -3.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4037805199623108
Epoch 0, Step 4490: train/loss = 0.2408429980278015, train/raw-loss = 0.202071875333786, train/logprobs = tensor([[ -2.7215, -10.0145],
        [ -5.3680,  -1.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38771116733551025
Epoch 0, Step 4491: train/loss = 0.40280258655548096, train/raw-loss = 0.369365930557251, train/logprobs = tensor([[-1.7745, -5.4426],
        [-2.3957, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33436664938926697
Epoch 0, Step 4492: train/loss = 0.26100096106529236, train/raw-loss = 0.22395280003547668, train/logprobs = tensor([[-2.5596, -8.4596],
        [-5.9563, -2.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3704814314842224
Epoch 0, Step 4493: train/loss = 0.09506897628307343, train/raw-loss = 0.054811086505651474, train/logprobs = tensor([[-2.1374, -9.3258],
        [-4.3874, -1.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4025789201259613
Epoch 0, Step 4494: train/loss = 0.16781273484230042, train/raw-loss = 0.11912958323955536, train/logprobs = tensor([[-1.8176, -8.5372],
        [-5.9431, -2.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4868314862251282
Epoch 0, Step 4495: train/loss = 0.5711190700531006, train/raw-loss = 0.530992865562439, train/logprobs = tensor([[ -4.2753, -11.8822],
        [ -4.5598,  -3.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4012616276741028
Epoch 0, Step 4496: train/loss = 0.3763461112976074, train/raw-loss = 0.34343990683555603, train/logprobs = tensor([[ -1.6676, -10.4214],
        [ -2.5455,  -3.0465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290620744228363
Epoch 0, Step 4497: train/loss = 0.47543710470199585, train/raw-loss = 0.44453462958335876, train/logprobs = tensor([[-3.3362, -6.2905],
        [-3.5475, -1.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090248703956604
Epoch 0, Step 4498: train/loss = 0.5705012083053589, train/raw-loss = 0.5320101380348206, train/logprobs = tensor([[-3.1222, -8.7563],
        [-3.7647, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38491034507751465
Epoch 0, Step 4499: train/loss = 0.46211352944374084, train/raw-loss = 0.42051124572753906, train/logprobs = tensor([[-2.0368, -5.5167],
        [-4.6764, -1.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4160229563713074
Epoch 0, Step 4500: train/loss = 0.13888788223266602, train/raw-loss = 0.10155908018350601, train/logprobs = tensor([[ -2.7369, -11.9894],
        [ -4.3377,  -2.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3732879161834717
Epoch 0, Step 4501: train/loss = 0.24839338660240173, train/raw-loss = 0.21493341028690338, train/logprobs = tensor([[ -2.3310, -13.6947],
        [ -3.2488,  -3.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345995545387268
Epoch 0, Step 4502: train/loss = 0.17175675928592682, train/raw-loss = 0.1306752860546112, train/logprobs = tensor([[ -1.7658, -12.3350],
        [ -6.6756,  -4.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4108147919178009
Epoch 0, Step 4503: train/loss = 0.08699922263622284, train/raw-loss = 0.04153117537498474, train/logprobs = tensor([[ -3.1829, -13.1400],
        [ -5.9897,  -1.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4546804428100586
Epoch 0, Step 4504: train/loss = 0.48461735248565674, train/raw-loss = 0.45030930638313293, train/logprobs = tensor([[-2.2816, -4.2182],
        [-2.2191, -2.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34308040142059326
Epoch 0, Step 4505: train/loss = 0.7271658182144165, train/raw-loss = 0.6871851682662964, train/logprobs = tensor([[-2.9007, -6.4594],
        [-2.7684, -3.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998066782951355
Epoch 0, Step 4506: train/loss = 0.4496678411960602, train/raw-loss = 0.41625872254371643, train/logprobs = tensor([[-3.6321, -6.4105],
        [-4.0102, -2.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33409127593040466
Epoch 0, Step 4507: train/loss = 0.24881307780742645, train/raw-loss = 0.20957280695438385, train/logprobs = tensor([[-1.9079, -6.8610],
        [-3.2255, -1.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39240267872810364
Epoch 0, Step 4508: train/loss = 0.1106557548046112, train/raw-loss = 0.07431000471115112, train/logprobs = tensor([[ -2.9706, -11.2995],
        [ -6.8087,  -3.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36345750093460083
Epoch 0, Step 4509: train/loss = 0.39345407485961914, train/raw-loss = 0.3606310784816742, train/logprobs = tensor([[-1.9695, -3.4904],
        [-3.2253, -1.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32822978496551514
Epoch 0, Step 4510: train/loss = 0.9440405368804932, train/raw-loss = 0.9125925898551941, train/logprobs = tensor([[-3.7159, -5.3881],
        [-1.5265, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31447991728782654
Epoch 0, Step 4511: train/loss = 0.36052489280700684, train/raw-loss = 0.3245435953140259, train/logprobs = tensor([[-1.8272, -5.6688],
        [-3.0532, -1.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35981297492980957
Epoch 0, Step 4512: train/loss = 0.30379483103752136, train/raw-loss = 0.2708474099636078, train/logprobs = tensor([[-1.8172, -9.1894],
        [-3.3424, -4.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294741213321686
Epoch 0, Step 4513: train/loss = 0.36878281831741333, train/raw-loss = 0.33169907331466675, train/logprobs = tensor([[ -3.2711, -10.7967],
        [ -3.6862,  -2.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3708372414112091
Epoch 0, Step 4514: train/loss = 0.500166654586792, train/raw-loss = 0.46351930499076843, train/logprobs = tensor([[-3.8014, -9.2974],
        [-4.4897, -2.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36647307872772217
Epoch 0, Step 4515: train/loss = 0.3287701904773712, train/raw-loss = 0.28815603256225586, train/logprobs = tensor([[-2.7704, -7.3759],
        [-3.7619, -1.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061415195465088
Epoch 0, Step 4516: train/loss = 0.27159425616264343, train/raw-loss = 0.22029654681682587, train/logprobs = tensor([[-2.8869, -5.9608],
        [-4.2473, -2.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5129770636558533
Epoch 0, Step 4517: train/loss = 0.5377748012542725, train/raw-loss = 0.5011998414993286, train/logprobs = tensor([[-2.5456, -4.1394],
        [-2.7916, -1.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36574986577033997
Epoch 0, Step 4518: train/loss = 0.3861472010612488, train/raw-loss = 0.351557195186615, train/logprobs = tensor([[-2.2195, -3.5316],
        [-3.3071, -1.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34590035676956177
Epoch 0, Step 4519: train/loss = 0.3950720429420471, train/raw-loss = 0.3582012951374054, train/logprobs = tensor([[ -2.3244, -14.4061],
        [ -3.8458,  -2.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36870741844177246
Epoch 0, Step 4520: train/loss = 0.306747168302536, train/raw-loss = 0.27419543266296387, train/logprobs = tensor([[-1.7508, -8.9289],
        [-2.7213, -1.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32551729679107666
Epoch 0, Step 4521: train/loss = 0.38376888632774353, train/raw-loss = 0.3480765223503113, train/logprobs = tensor([[-2.3285, -5.3602],
        [-3.4741, -2.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35692355036735535
Epoch 0, Step 4522: train/loss = 0.6306297183036804, train/raw-loss = 0.5933563113212585, train/logprobs = tensor([[ -3.1577, -12.5824],
        [ -3.9168,  -5.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727339208126068
Epoch 0, Step 4523: train/loss = 0.09505415707826614, train/raw-loss = 0.05518345162272453, train/logprobs = tensor([[ -1.4390, -10.0577],
        [ -4.1006,  -2.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3987070620059967
Epoch 0, Step 4524: train/loss = 0.2582930326461792, train/raw-loss = 0.21768830716609955, train/logprobs = tensor([[ -2.8191, -18.5112],
        [ -4.9459,  -7.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40604716539382935
Epoch 0, Step 4525: train/loss = 0.5745027661323547, train/raw-loss = 0.5420477986335754, train/logprobs = tensor([[-2.7415, -7.8850],
        [-3.0019, -1.5671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32454943656921387
Epoch 0, Step 4526: train/loss = 0.5505129098892212, train/raw-loss = 0.5134833455085754, train/logprobs = tensor([[-2.0670, -2.8908],
        [-2.1555, -1.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3702951669692993
Epoch 0, Step 4527: train/loss = 0.25459474325180054, train/raw-loss = 0.21283428370952606, train/logprobs = tensor([[-1.6439, -6.0561],
        [-3.7839, -2.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41760462522506714
Epoch 0, Step 4528: train/loss = 0.26367712020874023, train/raw-loss = 0.23329325020313263, train/logprobs = tensor([[-2.4057, -7.5728],
        [-4.4240, -1.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038387894630432
Epoch 0, Step 4529: train/loss = 0.246942400932312, train/raw-loss = 0.2043771594762802, train/logprobs = tensor([[ -2.1728, -12.5601],
        [ -5.9174,  -1.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4256523847579956
Epoch 0, Step 4530: train/loss = 0.19219517707824707, train/raw-loss = 0.16001571714878082, train/logprobs = tensor([[ -2.3109, -10.7893],
        [ -3.9798,  -3.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217945694923401
Epoch 0, Step 4531: train/loss = 0.3131207823753357, train/raw-loss = 0.27569708228111267, train/logprobs = tensor([[-2.2057, -5.7368],
        [-3.6919, -1.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37423694133758545
Epoch 0, Step 4532: train/loss = 0.1585751175880432, train/raw-loss = 0.11847366392612457, train/logprobs = tensor([[-2.2319, -5.3011],
        [-4.8577, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010144770145416
Epoch 0, Step 4533: train/loss = 0.591693103313446, train/raw-loss = 0.5574758052825928, train/logprobs = tensor([[-2.1178, -3.3333],
        [-2.2989, -2.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421725630760193
Epoch 0, Step 4534: train/loss = 0.4683915674686432, train/raw-loss = 0.43414345383644104, train/logprobs = tensor([[-2.5266, -3.3650],
        [-3.1293, -1.3188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3424813747406006
Epoch 0, Step 4535: train/loss = 0.18411597609519958, train/raw-loss = 0.1429871767759323, train/logprobs = tensor([[ -2.4879, -14.0279],
        [ -4.6144,  -3.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112880825996399
Epoch 0, Step 4536: train/loss = 0.18672728538513184, train/raw-loss = 0.13822631537914276, train/logprobs = tensor([[ -1.2149, -13.3940],
        [ -4.1664,  -3.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4850096106529236
Epoch 0, Step 4537: train/loss = 0.41315221786499023, train/raw-loss = 0.3743722438812256, train/logprobs = tensor([[ -2.1146, -13.8729],
        [ -3.2786,  -4.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38779953122138977
Epoch 0, Step 4538: train/loss = 0.3714648485183716, train/raw-loss = 0.3319297730922699, train/logprobs = tensor([[-1.8691, -5.7036],
        [-3.1444, -1.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3953506350517273
Epoch 0, Step 4539: train/loss = 0.37130075693130493, train/raw-loss = 0.33107537031173706, train/logprobs = tensor([[-1.6480, -5.1720],
        [-3.8027, -2.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4022541344165802
Epoch 0, Step 4540: train/loss = 0.2896521985530853, train/raw-loss = 0.2519623935222626, train/logprobs = tensor([[-2.6124, -9.9485],
        [-5.4755, -5.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37689828872680664
Epoch 0, Step 4541: train/loss = 0.07113755494356155, train/raw-loss = 0.025823013857007027, train/logprobs = tensor([[-1.9781, -7.6850],
        [-5.5062, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45314544439315796
Epoch 0, Step 4542: train/loss = 0.260333776473999, train/raw-loss = 0.22248852252960205, train/logprobs = tensor([[-2.2777, -7.7202],
        [-4.1546, -2.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37845250964164734
Epoch 0, Step 4543: train/loss = 0.29288801550865173, train/raw-loss = 0.25392383337020874, train/logprobs = tensor([[-1.1658, -7.0101],
        [-2.7079, -3.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3896419107913971
Epoch 0, Step 4544: train/loss = 0.35187089443206787, train/raw-loss = 0.31632372736930847, train/logprobs = tensor([[-1.7068, -5.0512],
        [-2.3345, -1.5115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.355471670627594
Epoch 0, Step 4545: train/loss = 0.41355472803115845, train/raw-loss = 0.3759217858314514, train/logprobs = tensor([[-2.5174, -6.9908],
        [-3.2800, -1.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37632957100868225
Epoch 0, Step 4546: train/loss = 1.0384269952774048, train/raw-loss = 0.9967882633209229, train/logprobs = tensor([[-4.6276, -6.8057],
        [-4.1624, -2.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4163871705532074
Epoch 0, Step 4547: train/loss = 0.3750010132789612, train/raw-loss = 0.3393912613391876, train/logprobs = tensor([[-1.8030, -4.3064],
        [-2.6431, -1.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560970425605774
Epoch 0, Step 4548: train/loss = 0.2205953150987625, train/raw-loss = 0.18907281756401062, train/logprobs = tensor([[ -3.4091, -16.7581],
        [ -5.1781,  -5.4087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.315225213766098
Epoch 0, Step 4549: train/loss = 0.5498232841491699, train/raw-loss = 0.5175774097442627, train/logprobs = tensor([[ -2.7894, -10.1490],
        [ -5.5861,  -5.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224584460258484
Epoch 0, Step 4550: train/loss = 1.9453926086425781, train/raw-loss = 1.9171640872955322, train/logprobs = tensor([[-5.8380, -4.6193],
        [-2.5867, -2.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822841703891754
Epoch 0, Step 4551: train/loss = 0.37391942739486694, train/raw-loss = 0.3292860984802246, train/logprobs = tensor([[-2.9274, -4.7910],
        [-4.1353, -2.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44633370637893677
Epoch 0, Step 4552: train/loss = 0.2076149731874466, train/raw-loss = 0.1754455864429474, train/logprobs = tensor([[-2.3890, -5.8284],
        [-4.5047, -1.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3216937184333801
Epoch 0, Step 4553: train/loss = 0.33453136682510376, train/raw-loss = 0.29665741324424744, train/logprobs = tensor([[-2.4782, -5.1544],
        [-4.4837, -2.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37873947620391846
Epoch 0, Step 4554: train/loss = 0.2990085184574127, train/raw-loss = 0.26343679428100586, train/logprobs = tensor([[-2.5572, -6.0754],
        [-3.5347, -2.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35571715235710144
Epoch 0, Step 4555: train/loss = 0.2702788710594177, train/raw-loss = 0.22225219011306763, train/logprobs = tensor([[-1.5995, -9.9511],
        [-4.1146, -2.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4802669882774353
Epoch 0, Step 4556: train/loss = 0.4680686295032501, train/raw-loss = 0.435523122549057, train/logprobs = tensor([[-2.0642, -6.5066],
        [-3.3267, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32545506954193115
Epoch 0, Step 4557: train/loss = 0.3023931086063385, train/raw-loss = 0.258876770734787, train/logprobs = tensor([[ -1.8725, -12.0802],
        [ -3.9919,  -2.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4351632595062256
Epoch 0, Step 4558: train/loss = 0.285235196352005, train/raw-loss = 0.24842993915081024, train/logprobs = tensor([[-2.5474, -9.4537],
        [-4.0672, -3.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680529296398163
Epoch 0, Step 4559: train/loss = 0.13217465579509735, train/raw-loss = 0.08933290839195251, train/logprobs = tensor([[ -2.7022, -11.7811],
        [ -6.2036,  -2.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42841750383377075
Epoch 0, Step 4560: train/loss = 0.46477600932121277, train/raw-loss = 0.4317494332790375, train/logprobs = tensor([[ -3.1928, -11.1592],
        [ -4.3198,  -4.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3302658796310425
Epoch 0, Step 4561: train/loss = 0.265968918800354, train/raw-loss = 0.21887607872486115, train/logprobs = tensor([[-2.5832, -8.9904],
        [-5.2674, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4709286391735077
Epoch 0, Step 4562: train/loss = 0.6881943941116333, train/raw-loss = 0.6476851105690002, train/logprobs = tensor([[-1.1545, -1.8824],
        [-2.4918, -2.3738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050925672054291
Epoch 0, Step 4563: train/loss = 0.2645047903060913, train/raw-loss = 0.22684504091739655, train/logprobs = tensor([[-1.5757, -7.3484],
        [-4.4998, -3.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37659749388694763
Epoch 0, Step 4564: train/loss = 0.4278298616409302, train/raw-loss = 0.38363730907440186, train/logprobs = tensor([[-2.0050, -7.1715],
        [-4.2797, -2.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44192570447921753
Epoch 0, Step 4565: train/loss = 0.3550446331501007, train/raw-loss = 0.3211034834384918, train/logprobs = tensor([[ -3.3784, -13.9920],
        [ -5.2442,  -5.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33941152691841125
Epoch 0, Step 4566: train/loss = 0.36118558049201965, train/raw-loss = 0.3204977810382843, train/logprobs = tensor([[-2.0266, -8.5946],
        [-2.6163, -1.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4068780243396759
Epoch 0, Step 4567: train/loss = 0.4347356855869293, train/raw-loss = 0.39255762100219727, train/logprobs = tensor([[-1.9906, -7.1664],
        [-3.0919, -2.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217807650566101
Epoch 0, Step 4568: train/loss = 0.46968868374824524, train/raw-loss = 0.42558059096336365, train/logprobs = tensor([[-2.6783, -3.9994],
        [-4.9716, -3.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44108039140701294
Epoch 0, Step 4569: train/loss = 0.4540764093399048, train/raw-loss = 0.4186103045940399, train/logprobs = tensor([[-2.0838, -6.8288],
        [-4.0177, -2.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3546614944934845
Epoch 0, Step 4570: train/loss = 0.33429011702537537, train/raw-loss = 0.3043668568134308, train/logprobs = tensor([[-1.0723, -6.2493],
        [-2.5830, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992326021194458
Epoch 0, Step 4571: train/loss = 0.06277313083410263, train/raw-loss = 0.026808513328433037, train/logprobs = tensor([[-1.9175, -9.7634],
        [-4.9725, -2.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35964614152908325
Epoch 0, Step 4572: train/loss = 0.5332983732223511, train/raw-loss = 0.49180150032043457, train/logprobs = tensor([[-2.8962, -5.2471],
        [-2.9434, -1.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41496917605400085
Epoch 0, Step 4573: train/loss = 0.5187340974807739, train/raw-loss = 0.4800875782966614, train/logprobs = tensor([[-2.7350, -5.0709],
        [-4.1779, -2.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3864653706550598
Epoch 0, Step 4574: train/loss = 0.2123725712299347, train/raw-loss = 0.1689564287662506, train/logprobs = tensor([[ -1.9531, -18.6725],
        [ -6.6234,  -6.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43416160345077515
Epoch 0, Step 4575: train/loss = 0.18439176678657532, train/raw-loss = 0.14774799346923828, train/logprobs = tensor([[ -3.3791, -10.5035],
        [ -5.6875,  -1.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3664378523826599
Epoch 0, Step 4576: train/loss = 0.6415657997131348, train/raw-loss = 0.6056972742080688, train/logprobs = tensor([[ -3.3396, -10.7620],
        [ -3.6491,  -4.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35868483781814575
Epoch 0, Step 4577: train/loss = 0.589871346950531, train/raw-loss = 0.5563027262687683, train/logprobs = tensor([[-1.6885, -2.5532],
        [-1.7253, -1.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356865346431732
Epoch 0, Step 4578: train/loss = 0.18109087646007538, train/raw-loss = 0.147084578871727, train/logprobs = tensor([[ -2.1596, -15.3475],
        [ -4.4832,  -6.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34006309509277344
Epoch 0, Step 4579: train/loss = 0.3501284420490265, train/raw-loss = 0.31780654191970825, train/logprobs = tensor([[-3.6389, -6.2993],
        [-5.8272, -4.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3232191503047943
Epoch 0, Step 4580: train/loss = 0.7748546600341797, train/raw-loss = 0.7322567701339722, train/logprobs = tensor([[-3.9470, -5.6835],
        [-3.5761, -2.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42597877979278564
Epoch 0, Step 4581: train/loss = 0.28607067465782166, train/raw-loss = 0.2412935495376587, train/logprobs = tensor([[-1.7363, -8.4734],
        [-5.0472, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477713406085968
Epoch 0, Step 4582: train/loss = 0.05434741452336311, train/raw-loss = 0.017286628484725952, train/logprobs = tensor([[ -2.5614, -15.0277],
        [ -6.4981,  -4.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3706078827381134
Epoch 0, Step 4583: train/loss = 0.4593808054924011, train/raw-loss = 0.42551058530807495, train/logprobs = tensor([[ -1.4963, -10.9445],
        [ -3.8848,  -5.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33870208263397217
Epoch 0, Step 4584: train/loss = 0.43798545002937317, train/raw-loss = 0.40553414821624756, train/logprobs = tensor([[ -2.5419, -13.0530],
        [ -3.8731,  -4.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3245134651660919
Epoch 0, Step 4585: train/loss = 0.45249009132385254, train/raw-loss = 0.42197614908218384, train/logprobs = tensor([[-2.9246, -8.8834],
        [-2.7159, -3.0456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3051394820213318
Epoch 0, Step 4586: train/loss = 0.23196466267108917, train/raw-loss = 0.1845218539237976, train/logprobs = tensor([[ -1.1171, -14.7586],
        [ -4.6800,  -1.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4744279980659485
Epoch 0, Step 4587: train/loss = 0.2723163366317749, train/raw-loss = 0.22686119377613068, train/logprobs = tensor([[ -3.1889, -15.3576],
        [ -4.2108,  -5.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4545515775680542
Epoch 0, Step 4588: train/loss = 0.35527050495147705, train/raw-loss = 0.3135427236557007, train/logprobs = tensor([[-2.5875, -6.6810],
        [-4.1947, -2.3472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41727814078330994
Epoch 0, Step 4589: train/loss = 0.34609079360961914, train/raw-loss = 0.30912521481513977, train/logprobs = tensor([[-1.7565, -6.7545],
        [-2.6322, -1.6247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3696556091308594
Epoch 0, Step 4590: train/loss = 0.5257998704910278, train/raw-loss = 0.4742853045463562, train/logprobs = tensor([[-1.3943, -4.9086],
        [-4.1629, -3.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.515146017074585
Epoch 0, Step 4591: train/loss = 0.06615465879440308, train/raw-loss = 0.026061443611979485, train/logprobs = tensor([[ -2.3857, -20.7649],
        [ -5.4816,  -4.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40093210339546204
Epoch 0, Step 4592: train/loss = 0.287068247795105, train/raw-loss = 0.24782824516296387, train/logprobs = tensor([[ -1.3427, -11.1431],
        [ -4.3941,  -3.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924001455307007
Epoch 0, Step 4593: train/loss = 0.3738124370574951, train/raw-loss = 0.34123045206069946, train/logprobs = tensor([[-2.2162, -8.7073],
        [-3.6771, -1.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32581984996795654
Epoch 0, Step 4594: train/loss = 0.23904062807559967, train/raw-loss = 0.1980103999376297, train/logprobs = tensor([[-1.6862, -8.5095],
        [-4.2436, -2.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4103022813796997
Epoch 0, Step 4595: train/loss = 0.07313856482505798, train/raw-loss = 0.02962595596909523, train/logprobs = tensor([[ -1.5407, -15.0836],
        [ -4.4767,  -4.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43512609601020813
Epoch 0, Step 4596: train/loss = 0.4392388164997101, train/raw-loss = 0.396499902009964, train/logprobs = tensor([[-1.8355, -8.6634],
        [-2.9948, -2.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4273894429206848
Epoch 0, Step 4597: train/loss = 0.15421514213085175, train/raw-loss = 0.11557117849588394, train/logprobs = tensor([[-2.4715, -9.5116],
        [-5.7140, -1.1282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3864396810531616
Epoch 0, Step 4598: train/loss = 0.3247196078300476, train/raw-loss = 0.2863062918186188, train/logprobs = tensor([[ -2.5085, -11.9468],
        [ -4.2790,  -1.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3841331899166107
Epoch 0, Step 4599: train/loss = 0.2928519546985626, train/raw-loss = 0.24521850049495697, train/logprobs = tensor([[-1.7859, -7.3161],
        [-4.2985, -3.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4763345420360565
Epoch 0, Step 4600: train/loss = 0.2776243984699249, train/raw-loss = 0.24108780920505524, train/logprobs = tensor([[ -2.7605, -10.2437],
        [ -4.8115,  -3.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36536598205566406
Epoch 0, Step 4601: train/loss = 0.40894877910614014, train/raw-loss = 0.37657105922698975, train/logprobs = tensor([[-3.6276, -9.6806],
        [-4.2414, -4.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32377710938453674
Epoch 0, Step 4602: train/loss = 0.06514432281255722, train/raw-loss = 0.026912841945886612, train/logprobs = tensor([[ -1.7445, -11.7549],
        [ -5.2026,  -4.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3823147416114807
Epoch 0, Step 4603: train/loss = 0.14236629009246826, train/raw-loss = 0.10285590589046478, train/logprobs = tensor([[-2.2511, -9.2020],
        [-5.3358, -2.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3951037526130676
Epoch 0, Step 4604: train/loss = 0.2728869318962097, train/raw-loss = 0.23185235261917114, train/logprobs = tensor([[-1.9634, -7.9920],
        [-3.3623, -2.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41034552454948425
Epoch 0, Step 4605: train/loss = 0.2388543039560318, train/raw-loss = 0.197637140750885, train/logprobs = tensor([[ -1.9734, -25.1273],
        [ -4.7193,  -4.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4121716022491455
Epoch 0, Step 4606: train/loss = 0.28068846464157104, train/raw-loss = 0.243109330534935, train/logprobs = tensor([[-1.5630, -4.4161],
        [-2.9452, -2.3901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37579137086868286
Epoch 0, Step 4607: train/loss = 0.14412333071231842, train/raw-loss = 0.10333338379859924, train/logprobs = tensor([[ -2.0535, -11.7007],
        [ -4.4500,  -1.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.407899409532547
Epoch 0, Step 4608: train/loss = 0.25198909640312195, train/raw-loss = 0.20311716198921204, train/logprobs = tensor([[ -2.3066, -12.2676],
        [ -6.2393,  -4.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4887193441390991
Epoch 0, Step 4609: train/loss = 0.07380606234073639, train/raw-loss = 0.02167874574661255, train/logprobs = tensor([[-2.3711, -9.4543],
        [-6.9878, -2.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.521273136138916
Epoch 0, Step 4610: train/loss = 0.0707150474190712, train/raw-loss = 0.022272124886512756, train/logprobs = tensor([[ -1.2487, -10.9782],
        [ -5.3013,  -2.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4844292402267456
Epoch 0, Step 4611: train/loss = 0.5240377187728882, train/raw-loss = 0.48184874653816223, train/logprobs = tensor([[-3.4505, -6.5661],
        [-3.8302, -2.9729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218898415565491
Epoch 0, Step 4612: train/loss = 0.47980567812919617, train/raw-loss = 0.4515625238418579, train/logprobs = tensor([[-2.0154, -4.0068],
        [-2.4765, -1.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28243139386177063
Epoch 0, Step 4613: train/loss = 0.4354954957962036, train/raw-loss = 0.404790461063385, train/logprobs = tensor([[-2.2426, -3.9819],
        [-2.4105, -1.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30705034732818604
Epoch 0, Step 4614: train/loss = 0.20256011188030243, train/raw-loss = 0.16923996806144714, train/logprobs = tensor([[-2.2607, -9.1559],
        [-3.8426, -2.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33320140838623047
Epoch 0, Step 4615: train/loss = 0.3559721112251282, train/raw-loss = 0.30982792377471924, train/logprobs = tensor([[-1.5974, -3.8263],
        [-3.7353, -2.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46144211292266846
Epoch 0, Step 4616: train/loss = 0.10009115189313889, train/raw-loss = 0.058295417577028275, train/logprobs = tensor([[ -1.8876, -11.9688],
        [ -6.4601,  -1.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4179573059082031
Epoch 0, Step 4617: train/loss = 0.23168401420116425, train/raw-loss = 0.18738976120948792, train/logprobs = tensor([[-2.2226, -9.0423],
        [-5.2360, -2.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429425001144409
Epoch 0, Step 4618: train/loss = 0.055060964077711105, train/raw-loss = 0.020811349153518677, train/logprobs = tensor([[ -2.2356, -13.5521],
        [ -6.8213,  -2.1262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3424961268901825
Epoch 0, Step 4619: train/loss = 0.46209025382995605, train/raw-loss = 0.42031973600387573, train/logprobs = tensor([[-1.1792, -3.3230],
        [-3.4680, -1.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41770511865615845
Epoch 0, Step 4620: train/loss = 0.4629020392894745, train/raw-loss = 0.41835349798202515, train/logprobs = tensor([[-2.7359, -8.0517],
        [-6.6388, -2.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44548511505126953
Epoch 0, Step 4621: train/loss = 0.26439034938812256, train/raw-loss = 0.2274141162633896, train/logprobs = tensor([[-2.8000, -7.9008],
        [-4.8195, -2.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3697623312473297
Epoch 0, Step 4622: train/loss = 0.435337096452713, train/raw-loss = 0.399050235748291, train/logprobs = tensor([[-1.5029, -5.8809],
        [-2.2629, -2.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36286839842796326
Epoch 0, Step 4623: train/loss = 0.3277926445007324, train/raw-loss = 0.28153786063194275, train/logprobs = tensor([[-1.7966, -6.6057],
        [-5.1809, -3.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4625479578971863
Epoch 0, Step 4624: train/loss = 0.09967558085918427, train/raw-loss = 0.06917375326156616, train/logprobs = tensor([[ -2.2679, -10.3499],
        [ -5.5423,  -3.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30501827597618103
Epoch 0, Step 4625: train/loss = 0.47926947474479675, train/raw-loss = 0.4438938498497009, train/logprobs = tensor([[-1.5737, -2.8934],
        [-3.2156, -2.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3537564277648926
Epoch 0, Step 4626: train/loss = 0.684380292892456, train/raw-loss = 0.6380581259727478, train/logprobs = tensor([[-2.3902, -3.8335],
        [-4.4094, -2.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4632222354412079
Epoch 0, Step 4627: train/loss = 0.4835544228553772, train/raw-loss = 0.4422587752342224, train/logprobs = tensor([[-2.5311, -8.8441],
        [-3.5138, -4.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4129568636417389
Epoch 0, Step 4628: train/loss = 0.5166743993759155, train/raw-loss = 0.47944530844688416, train/logprobs = tensor([[-2.1323, -6.6858],
        [-2.7029, -1.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722912669181824
Epoch 0, Step 4629: train/loss = 0.832016110420227, train/raw-loss = 0.7866141200065613, train/logprobs = tensor([[-3.2261, -4.3335],
        [-3.6706, -2.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540187418460846
Epoch 0, Step 4630: train/loss = 0.36965665221214294, train/raw-loss = 0.3293580710887909, train/logprobs = tensor([[-2.5748, -9.4100],
        [-3.4509, -2.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40298575162887573
Epoch 0, Step 4631: train/loss = 0.39817413687705994, train/raw-loss = 0.360086590051651, train/logprobs = tensor([[-2.3477, -6.1873],
        [-3.2008, -1.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38087546825408936
Epoch 0, Step 4632: train/loss = 0.659810483455658, train/raw-loss = 0.618120014667511, train/logprobs = tensor([[-1.4296, -2.4570],
        [-2.6674, -2.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41690486669540405
Epoch 0, Step 4633: train/loss = 0.1970241665840149, train/raw-loss = 0.15518705546855927, train/logprobs = tensor([[-2.9388, -7.8968],
        [-4.7391, -1.3356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183710217475891
Epoch 0, Step 4634: train/loss = 0.31658482551574707, train/raw-loss = 0.28018346428871155, train/logprobs = tensor([[-2.4248, -7.2266],
        [-4.1534, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3640136122703552
Epoch 0, Step 4635: train/loss = 0.3677363395690918, train/raw-loss = 0.32211899757385254, train/logprobs = tensor([[-2.4030, -7.2969],
        [-4.3069, -2.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4561731219291687
Epoch 0, Step 4636: train/loss = 0.3836573362350464, train/raw-loss = 0.34647756814956665, train/logprobs = tensor([[-1.1979, -6.5239],
        [-3.7179, -1.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3717975616455078
Epoch 0, Step 4637: train/loss = 0.4127667546272278, train/raw-loss = 0.36434656381607056, train/logprobs = tensor([[-2.2540, -8.5003],
        [-5.7136, -2.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48420214653015137
Epoch 0, Step 4638: train/loss = 0.5373491644859314, train/raw-loss = 0.47066032886505127, train/logprobs = tensor([[-1.9654, -4.0739],
        [-4.7350, -3.1131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6668888330459595
Epoch 0, Step 4639: train/loss = 0.1638486087322235, train/raw-loss = 0.12281396985054016, train/logprobs = tensor([[ -2.0686, -10.9061],
        [ -4.6563,  -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41034647822380066
Epoch 0, Step 4640: train/loss = 0.1316809207201004, train/raw-loss = 0.09637022763490677, train/logprobs = tensor([[ -2.0117, -15.0028],
        [ -4.0866,  -2.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35310694575309753
Epoch 0, Step 4641: train/loss = 0.35202756524086, train/raw-loss = 0.30759385228157043, train/logprobs = tensor([[-2.5701, -8.8395],
        [-5.5500, -1.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44433721899986267
Epoch 0, Step 4642: train/loss = 0.06500226259231567, train/raw-loss = 0.028333349153399467, train/logprobs = tensor([[ -2.2003, -14.5789],
        [ -6.0359,  -2.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36668911576271057
Epoch 0, Step 4643: train/loss = 0.14239901304244995, train/raw-loss = 0.1049678772687912, train/logprobs = tensor([[ -3.3503, -12.6591],
        [ -6.4919,  -1.2670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3743113875389099
Epoch 0, Step 4644: train/loss = 0.3960273563861847, train/raw-loss = 0.3521280884742737, train/logprobs = tensor([[-1.8568, -3.5807],
        [-3.1402, -1.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4389927387237549
Epoch 0, Step 4645: train/loss = 0.36793258786201477, train/raw-loss = 0.32063978910446167, train/logprobs = tensor([[-2.5831, -7.6267],
        [-4.5129, -3.0696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4729282259941101
Epoch 0, Step 4646: train/loss = 0.1617012321949005, train/raw-loss = 0.11212719231843948, train/logprobs = tensor([[ -1.5126, -12.4357],
        [ -4.7578,  -2.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4957403242588043
Epoch 0, Step 4647: train/loss = 0.38891521096229553, train/raw-loss = 0.35150855779647827, train/logprobs = tensor([[-2.3348, -6.1609],
        [-5.1673, -1.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37406641244888306
Epoch 0, Step 4648: train/loss = 0.15525829792022705, train/raw-loss = 0.11698463559150696, train/logprobs = tensor([[-2.8466, -9.4254],
        [-5.6719, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3827367126941681
Epoch 0, Step 4649: train/loss = 0.4620899260044098, train/raw-loss = 0.40889477729797363, train/logprobs = tensor([[ -1.8950, -11.7669],
        [ -6.7532,  -7.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5319514274597168
Epoch 0, Step 4650: train/loss = 0.3304315507411957, train/raw-loss = 0.2920825183391571, train/logprobs = tensor([[-1.5279, -8.5362],
        [-3.0808, -2.1765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38349050283432007
Epoch 0, Step 4651: train/loss = 0.1827884316444397, train/raw-loss = 0.14216774702072144, train/logprobs = tensor([[ -1.3310, -11.9559],
        [ -2.9147,  -4.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4062068462371826
Epoch 0, Step 4652: train/loss = 0.2339450567960739, train/raw-loss = 0.18983952701091766, train/logprobs = tensor([[-1.4569, -5.7430],
        [-5.6004, -3.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4410553574562073
Epoch 0, Step 4653: train/loss = 0.209791898727417, train/raw-loss = 0.17058056592941284, train/logprobs = tensor([[-2.8793, -9.0564],
        [-5.6587, -3.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3921133279800415
Epoch 0, Step 4654: train/loss = 0.32490232586860657, train/raw-loss = 0.28345897793769836, train/logprobs = tensor([[-1.5603, -5.5993],
        [-4.3657, -3.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4144333600997925
Epoch 0, Step 4655: train/loss = 0.571942150592804, train/raw-loss = 0.5346568822860718, train/logprobs = tensor([[ -1.8708, -15.4546],
        [ -3.0090,  -8.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37285280227661133
Epoch 0, Step 4656: train/loss = 0.3321426510810852, train/raw-loss = 0.279753714799881, train/logprobs = tensor([[-2.4603, -6.2554],
        [-4.6214, -2.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523889422416687
Epoch 0, Step 4657: train/loss = 0.38788244128227234, train/raw-loss = 0.3369462490081787, train/logprobs = tensor([[-1.7868, -6.7993],
        [-4.5352, -2.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.509361743927002
Epoch 0, Step 4658: train/loss = 0.32971447706222534, train/raw-loss = 0.2893067002296448, train/logprobs = tensor([[-1.9840, -6.3888],
        [-3.3600, -1.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4040779769420624
Epoch 0, Step 4659: train/loss = 0.6172512173652649, train/raw-loss = 0.586722195148468, train/logprobs = tensor([[-2.6047, -3.3563],
        [-2.3182, -1.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3052898347377777
Epoch 0, Step 4660: train/loss = 0.09837576001882553, train/raw-loss = 0.06324907392263412, train/logprobs = tensor([[ -2.7739, -11.0338],
        [ -5.2288,  -1.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35126692056655884
Epoch 0, Step 4661: train/loss = 0.44488680362701416, train/raw-loss = 0.41618937253952026, train/logprobs = tensor([[ -2.4705, -10.2668],
        [ -3.9148,  -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869744300842285
Epoch 0, Step 4662: train/loss = 0.26652008295059204, train/raw-loss = 0.22273671627044678, train/logprobs = tensor([[-1.8064, -8.9481],
        [-4.7385, -3.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43783360719680786
Epoch 0, Step 4663: train/loss = 0.39628565311431885, train/raw-loss = 0.3537888526916504, train/logprobs = tensor([[-1.5990, -5.7810],
        [-4.2543, -2.4916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42496803402900696
Epoch 0, Step 4664: train/loss = 0.20357872545719147, train/raw-loss = 0.15666741132736206, train/logprobs = tensor([[ -2.0933, -14.4907],
        [ -4.3166,  -3.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46911323070526123
Epoch 0, Step 4665: train/loss = 0.5812138319015503, train/raw-loss = 0.5300731062889099, train/logprobs = tensor([[-1.0001, -1.7328],
        [-2.4662, -1.7439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5114072561264038
Epoch 0, Step 4666: train/loss = 0.15054810047149658, train/raw-loss = 0.10608963668346405, train/logprobs = tensor([[ -2.0913, -13.0614],
        [ -6.8111,  -4.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44458451867103577
Epoch 0, Step 4667: train/loss = 0.3270011246204376, train/raw-loss = 0.2842515707015991, train/logprobs = tensor([[-1.9575, -7.5176],
        [-5.1459, -3.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42749571800231934
Epoch 0, Step 4668: train/loss = 0.19890767335891724, train/raw-loss = 0.1523423194885254, train/logprobs = tensor([[-2.5537, -7.2110],
        [-4.7239, -2.3024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.465653657913208
Epoch 0, Step 4669: train/loss = 0.23060400784015656, train/raw-loss = 0.1824495494365692, train/logprobs = tensor([[ -3.1885, -14.5671],
        [ -6.4790,  -4.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4815446734428406
Epoch 0, Step 4670: train/loss = 0.5624191761016846, train/raw-loss = 0.5225556492805481, train/logprobs = tensor([[-2.6410, -4.2288],
        [-4.1203, -2.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3986353874206543
Epoch 0, Step 4671: train/loss = 0.3645527958869934, train/raw-loss = 0.33505043387413025, train/logprobs = tensor([[-1.8198, -3.6879],
        [-3.7605, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29502344131469727
Epoch 0, Step 4672: train/loss = 0.39923253655433655, train/raw-loss = 0.35451969504356384, train/logprobs = tensor([[-2.3271, -8.9584],
        [-3.2312, -1.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4471283257007599
Epoch 0, Step 4673: train/loss = 0.17738422751426697, train/raw-loss = 0.13465318083763123, train/logprobs = tensor([[ -3.3551, -16.2415],
        [ -6.5542,  -4.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4273104965686798
Epoch 0, Step 4674: train/loss = 0.7420400381088257, train/raw-loss = 0.6854400634765625, train/logprobs = tensor([[-2.1051, -7.9506],
        [-5.0774, -3.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5659993886947632
Epoch 0, Step 4675: train/loss = 0.4053814709186554, train/raw-loss = 0.3680788576602936, train/logprobs = tensor([[-2.4622, -5.7162],
        [-4.5712, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37302619218826294
Epoch 0, Step 4676: train/loss = 0.32096046209335327, train/raw-loss = 0.27649903297424316, train/logprobs = tensor([[-1.4906, -6.5340],
        [-4.8316, -2.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44461390376091003
Epoch 0, Step 4677: train/loss = 0.08765717595815659, train/raw-loss = 0.04615040123462677, train/logprobs = tensor([[-2.9864, -8.7279],
        [-6.1511, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4150676727294922
Epoch 0, Step 4678: train/loss = 0.23437663912773132, train/raw-loss = 0.2004154920578003, train/logprobs = tensor([[ -2.8423, -11.2982],
        [ -4.9927,  -2.6232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396117091178894
Epoch 0, Step 4679: train/loss = 0.1311323493719101, train/raw-loss = 0.08503241091966629, train/logprobs = tensor([[ -1.4141, -15.2445],
        [ -4.8817,  -2.3117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.460999459028244
Epoch 0, Step 4680: train/loss = 0.4850156605243683, train/raw-loss = 0.446483850479126, train/logprobs = tensor([[-1.4792, -4.0152],
        [-3.3542, -3.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3853183090686798
Epoch 0, Step 4681: train/loss = 0.3567999601364136, train/raw-loss = 0.31731730699539185, train/logprobs = tensor([[-1.5442, -3.4183],
        [-2.4486, -1.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3948265016078949
Epoch 0, Step 4682: train/loss = 0.5014424324035645, train/raw-loss = 0.46113690733909607, train/logprobs = tensor([[-1.6313, -6.1116],
        [-3.7035, -3.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403055340051651
Epoch 0, Step 4683: train/loss = 0.31863027811050415, train/raw-loss = 0.2825389504432678, train/logprobs = tensor([[-2.8230, -9.0238],
        [-5.2492, -2.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609135150909424
Epoch 0, Step 4684: train/loss = 0.9118742942810059, train/raw-loss = 0.8613613843917847, train/logprobs = tensor([[-1.4584, -4.5370],
        [-5.5689, -4.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.505128800868988
Epoch 0, Step 4685: train/loss = 0.23148784041404724, train/raw-loss = 0.19086551666259766, train/logprobs = tensor([[-1.6720, -8.0277],
        [-3.8922, -1.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40622320771217346
Epoch 0, Step 4686: train/loss = 0.43652981519699097, train/raw-loss = 0.4023810029029846, train/logprobs = tensor([[-1.3835, -6.0109],
        [-3.2887, -1.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3414882719516754
Epoch 0, Step 4687: train/loss = 0.3946651816368103, train/raw-loss = 0.3497806787490845, train/logprobs = tensor([[-2.4151, -4.5114],
        [-3.4735, -2.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4488450288772583
Epoch 0, Step 4688: train/loss = 0.05412481352686882, train/raw-loss = 0.01346548181027174, train/logprobs = tensor([[ -1.6844, -17.1551],
        [ -5.6788,  -2.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40659329295158386
Epoch 0, Step 4689: train/loss = 0.8276586532592773, train/raw-loss = 0.7681470513343811, train/logprobs = tensor([[-2.3757, -6.2204],
        [-5.5495, -3.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5951156616210938
Epoch 0, Step 4690: train/loss = 0.7479900121688843, train/raw-loss = 0.6949385404586792, train/logprobs = tensor([[-1.7032, -7.0656],
        [-5.1229, -4.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5305142402648926
Epoch 0, Step 4691: train/loss = 0.6217055320739746, train/raw-loss = 0.5783244967460632, train/logprobs = tensor([[-3.2413, -6.8781],
        [-3.1698, -2.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4338100552558899
Epoch 0, Step 4692: train/loss = 0.1432209610939026, train/raw-loss = 0.10112175345420837, train/logprobs = tensor([[ -1.3383, -10.9680],
        [ -4.7541,  -3.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.420991986989975
Epoch 0, Step 4693: train/loss = 0.1890779435634613, train/raw-loss = 0.15034128725528717, train/logprobs = tensor([[-1.3662, -9.9305],
        [-4.2961, -3.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873664438724518
Epoch 0, Step 4694: train/loss = 0.3879050314426422, train/raw-loss = 0.35488441586494446, train/logprobs = tensor([[ -2.7036, -12.2277],
        [ -3.3796,  -5.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33020615577697754
Epoch 0, Step 4695: train/loss = 0.4724814295768738, train/raw-loss = 0.4284787178039551, train/logprobs = tensor([[ -3.5560, -10.1165],
        [ -4.7358,  -4.2720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4400269389152527
Epoch 0, Step 4696: train/loss = 0.4002746641635895, train/raw-loss = 0.35567253828048706, train/logprobs = tensor([[ -2.4260, -10.4028],
        [ -4.6852,  -1.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4460211396217346
Epoch 0, Step 4697: train/loss = 0.42412814497947693, train/raw-loss = 0.3797065317630768, train/logprobs = tensor([[-2.6641, -7.3562],
        [-5.0551, -3.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4442158639431
Epoch 0, Step 4698: train/loss = 0.27520519495010376, train/raw-loss = 0.2372419387102127, train/logprobs = tensor([[ -2.3679, -12.8734],
        [ -4.9373,  -5.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3796326518058777
Epoch 0, Step 4699: train/loss = 1.134563684463501, train/raw-loss = 1.1040607690811157, train/logprobs = tensor([[-3.3082, -4.2899],
        [-2.8129, -2.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30502915382385254
Epoch 0, Step 4700: train/loss = 0.4914892017841339, train/raw-loss = 0.4589027762413025, train/logprobs = tensor([[ -2.5730, -11.7338],
        [ -3.9161,  -2.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32586413621902466
Epoch 0, Step 4701: train/loss = 0.29660162329673767, train/raw-loss = 0.2527563273906708, train/logprobs = tensor([[-2.2555, -9.0111],
        [-4.0443, -2.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4384530186653137
Epoch 0, Step 4702: train/loss = 0.2257203310728073, train/raw-loss = 0.18969440460205078, train/logprobs = tensor([[ -2.4636, -13.4237],
        [ -5.1763,  -1.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602592349052429
Epoch 0, Step 4703: train/loss = 0.07156562805175781, train/raw-loss = 0.02228575572371483, train/logprobs = tensor([[ -1.9806, -10.9409],
        [ -5.7503,  -2.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49279868602752686
Epoch 0, Step 4704: train/loss = 0.4340924918651581, train/raw-loss = 0.39726126194000244, train/logprobs = tensor([[-1.4567, -3.1236],
        [-3.3675, -1.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683124780654907
Epoch 0, Step 4705: train/loss = 0.19777844846248627, train/raw-loss = 0.16361930966377258, train/logprobs = tensor([[-1.9414, -8.9063],
        [-4.3654, -1.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3415912687778473
Epoch 0, Step 4706: train/loss = 0.29607445001602173, train/raw-loss = 0.26137983798980713, train/logprobs = tensor([[ -1.3396, -10.6704],
        [ -5.5454,  -4.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469458222389221
Epoch 0, Step 4707: train/loss = 0.18685981631278992, train/raw-loss = 0.15143397450447083, train/logprobs = tensor([[-1.6480, -8.5516],
        [-4.7041, -1.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3542584180831909
Epoch 0, Step 4708: train/loss = 0.2219553291797638, train/raw-loss = 0.18123307824134827, train/logprobs = tensor([[-1.0136, -7.4557],
        [-3.9349, -2.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4072226881980896
Epoch 0, Step 4709: train/loss = 0.5607149600982666, train/raw-loss = 0.5189910531044006, train/logprobs = tensor([[-2.9671, -7.7211],
        [-3.3727, -2.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41723954677581787
Epoch 0, Step 4710: train/loss = 0.05317414924502373, train/raw-loss = 0.004757061135023832, train/logprobs = tensor([[ -1.9361, -15.1542],
        [ -7.2585,  -5.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4841708540916443
Epoch 0, Step 4711: train/loss = 0.2458178997039795, train/raw-loss = 0.20364075899124146, train/logprobs = tensor([[-3.3760, -7.1833],
        [-4.5241, -2.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42177140712738037
Epoch 0, Step 4712: train/loss = 0.06417237222194672, train/raw-loss = 0.028387784957885742, train/logprobs = tensor([[ -1.9088, -11.2943],
        [ -6.2247,  -4.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35784584283828735
Epoch 0, Step 4713: train/loss = 0.27235549688339233, train/raw-loss = 0.22820524871349335, train/logprobs = tensor([[-1.5195, -8.4700],
        [-5.2394, -2.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4415023922920227
Epoch 0, Step 4714: train/loss = 0.5491701364517212, train/raw-loss = 0.5056188106536865, train/logprobs = tensor([[-2.2299, -4.0965],
        [-3.7768, -2.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.435512900352478
Epoch 0, Step 4715: train/loss = 0.40843069553375244, train/raw-loss = 0.3688153028488159, train/logprobs = tensor([[-2.2276, -9.6464],
        [-3.5204, -3.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39615410566329956
Epoch 0, Step 4716: train/loss = 0.21937641501426697, train/raw-loss = 0.18064522743225098, train/logprobs = tensor([[ -2.0801, -13.0164],
        [ -5.3573,  -5.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873118758201599
Epoch 0, Step 4717: train/loss = 0.37933653593063354, train/raw-loss = 0.33535754680633545, train/logprobs = tensor([[-1.6138, -4.7062],
        [-3.7487, -1.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4397895932197571
Epoch 0, Step 4718: train/loss = 0.14719444513320923, train/raw-loss = 0.11176073551177979, train/logprobs = tensor([[-1.1029, -8.1923],
        [-3.8653, -1.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3543369770050049
Epoch 0, Step 4719: train/loss = 0.5716009140014648, train/raw-loss = 0.5206287503242493, train/logprobs = tensor([[-1.5571, -5.9900],
        [-4.6235, -3.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5097216963768005
Epoch 0, Step 4720: train/loss = 0.39191120862960815, train/raw-loss = 0.3550146818161011, train/logprobs = tensor([[-2.7982, -8.9463],
        [-5.3039, -3.0185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3689652383327484
Epoch 0, Step 4721: train/loss = 0.17996151745319366, train/raw-loss = 0.13384868204593658, train/logprobs = tensor([[ -2.3500, -10.4715],
        [ -5.4560,  -2.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46112844347953796
Epoch 0, Step 4722: train/loss = 0.07111118733882904, train/raw-loss = 0.027405044063925743, train/logprobs = tensor([[ -1.4786, -12.3416],
        [ -6.2072,  -4.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4370614290237427
Epoch 0, Step 4723: train/loss = 0.37868237495422363, train/raw-loss = 0.33553346991539, train/logprobs = tensor([[-2.5159, -5.2096],
        [-3.6152, -2.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43148890137672424
Epoch 0, Step 4724: train/loss = 0.2597556412220001, train/raw-loss = 0.20955133438110352, train/logprobs = tensor([[ -1.6081, -11.0372],
        [ -5.0666,  -6.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5020429491996765
Epoch 0, Step 4725: train/loss = 0.6769328117370605, train/raw-loss = 0.6421527862548828, train/logprobs = tensor([[-1.0240, -1.5892],
        [-2.5122, -2.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34780099987983704
Epoch 0, Step 4726: train/loss = 0.23400697112083435, train/raw-loss = 0.17712169885635376, train/logprobs = tensor([[ -2.8043, -10.4296],
        [ -5.2973,  -2.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5688527226448059
Epoch 0, Step 4727: train/loss = 0.13983359932899475, train/raw-loss = 0.0987723171710968, train/logprobs = tensor([[-1.5508, -5.7694],
        [-4.5107, -2.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106128215789795
Epoch 0, Step 4728: train/loss = 0.23885269463062286, train/raw-loss = 0.19371967017650604, train/logprobs = tensor([[ -3.3873, -14.9662],
        [ -5.2807,  -3.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45133036375045776
Epoch 0, Step 4729: train/loss = 0.16023555397987366, train/raw-loss = 0.11266787350177765, train/logprobs = tensor([[-2.5605, -7.7248],
        [-6.4338, -2.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4756767451763153
Epoch 0, Step 4730: train/loss = 0.3745480179786682, train/raw-loss = 0.33255505561828613, train/logprobs = tensor([[-2.1996, -5.7749],
        [-4.8519, -1.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199298024177551
Epoch 0, Step 4731: train/loss = 0.11939465254545212, train/raw-loss = 0.06462250649929047, train/logprobs = tensor([[-1.4245, -9.8181],
        [-5.4723, -2.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5477213859558105
Epoch 0, Step 4732: train/loss = 0.13593029975891113, train/raw-loss = 0.09119190275669098, train/logprobs = tensor([[-2.4046, -7.1432],
        [-4.8471, -1.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4473838806152344
Epoch 0, Step 4733: train/loss = 0.11022456735372543, train/raw-loss = 0.06174715980887413, train/logprobs = tensor([[-2.3695, -8.9601],
        [-5.9533, -2.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48477408289909363
Epoch 0, Step 4734: train/loss = 0.11407303810119629, train/raw-loss = 0.07578850537538528, train/logprobs = tensor([[-2.0426, -7.7571],
        [-4.9669, -2.3773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38284531235694885
Epoch 0, Step 4735: train/loss = 0.4908860921859741, train/raw-loss = 0.4450097680091858, train/logprobs = tensor([[-2.1466, -3.4418],
        [-3.5788, -2.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.458763062953949
Epoch 0, Step 4736: train/loss = 0.1613893061876297, train/raw-loss = 0.10678482055664062, train/logprobs = tensor([[ -3.1598, -14.1015],
        [ -6.6834,  -3.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5460448265075684
Epoch 0, Step 4737: train/loss = 0.5080298781394958, train/raw-loss = 0.47010788321495056, train/logprobs = tensor([[-2.1356, -6.9834],
        [-3.7223, -2.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3792196214199066
Epoch 0, Step 4738: train/loss = 0.079098179936409, train/raw-loss = 0.03895974159240723, train/logprobs = tensor([[ -1.6578, -13.8952],
        [ -5.4554,  -2.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4013843834400177
Epoch 0, Step 4739: train/loss = 0.29251864552497864, train/raw-loss = 0.251080721616745, train/logprobs = tensor([[ -2.9168, -10.2806],
        [ -5.3009,  -2.3622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4143793284893036
Epoch 0, Step 4740: train/loss = 0.4335233271121979, train/raw-loss = 0.38781166076660156, train/logprobs = tensor([[-2.0029, -6.4094],
        [-3.6068, -2.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45711687207221985
Epoch 0, Step 4741: train/loss = 0.12579098343849182, train/raw-loss = 0.08355352282524109, train/logprobs = tensor([[ -2.0456, -11.2177],
        [ -5.5186,  -2.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42237451672554016
Epoch 0, Step 4742: train/loss = 0.4666483700275421, train/raw-loss = 0.4098283350467682, train/logprobs = tensor([[-1.5377, -4.0934],
        [-4.1959, -2.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5682007074356079
Epoch 0, Step 4743: train/loss = 0.4074709117412567, train/raw-loss = 0.3620007634162903, train/logprobs = tensor([[-1.8653, -9.1893],
        [-3.9525, -2.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45470130443573
Epoch 0, Step 4744: train/loss = 0.36585983633995056, train/raw-loss = 0.3333636224269867, train/logprobs = tensor([[-2.5572, -9.9083],
        [-4.6008, -2.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32496199011802673
Epoch 0, Step 4745: train/loss = 0.738871157169342, train/raw-loss = 0.6929688453674316, train/logprobs = tensor([[-2.0257, -3.5266],
        [-3.5141, -2.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4590224325656891
Epoch 0, Step 4746: train/loss = 0.04723326116800308, train/raw-loss = 0.004389315843582153, train/logprobs = tensor([[ -2.0072, -15.8393],
        [ -7.0233,  -1.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4284394383430481
Epoch 0, Step 4747: train/loss = 0.3145939111709595, train/raw-loss = 0.2620062828063965, train/logprobs = tensor([[ -1.6350, -10.7208],
        [ -4.3617,  -4.1973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258760452270508
Epoch 0, Step 4748: train/loss = 0.14742708206176758, train/raw-loss = 0.09292589873075485, train/logprobs = tensor([[-0.9718, -9.6587],
        [-4.4650, -3.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5450118184089661
Epoch 0, Step 4749: train/loss = 0.21702998876571655, train/raw-loss = 0.17687639594078064, train/logprobs = tensor([[-1.9627, -8.8926],
        [-6.3145, -2.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4015359878540039
Epoch 0, Step 4750: train/loss = 0.07607640326023102, train/raw-loss = 0.029001060873270035, train/logprobs = tensor([[ -1.8037, -19.4646],
        [ -7.2760,  -7.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47075343132019043
Epoch 0, Step 4751: train/loss = 0.0723220705986023, train/raw-loss = 0.034312620759010315, train/logprobs = tensor([[ -1.5632, -15.6764],
        [ -5.4983,  -4.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3800944983959198
Epoch 0, Step 4752: train/loss = 0.49723631143569946, train/raw-loss = 0.4551229476928711, train/logprobs = tensor([[-2.4118, -5.7740],
        [-3.6794, -2.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4211336672306061
Epoch 0, Step 4753: train/loss = 0.39575597643852234, train/raw-loss = 0.35223454236984253, train/logprobs = tensor([[-1.6106, -5.5611],
        [-3.7143, -2.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.435214102268219
Epoch 0, Step 4754: train/loss = 0.42808905243873596, train/raw-loss = 0.38364821672439575, train/logprobs = tensor([[-1.5735, -4.5364],
        [-4.7968, -2.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4444084167480469
Epoch 0, Step 4755: train/loss = 0.2117311656475067, train/raw-loss = 0.16970716416835785, train/logprobs = tensor([[ -1.4831, -10.8641],
        [ -4.0737,  -2.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4202398657798767
Epoch 0, Step 4756: train/loss = 0.3765803575515747, train/raw-loss = 0.3474131226539612, train/logprobs = tensor([[-1.2342, -6.7244],
        [-1.5791, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2916722297668457
Epoch 0, Step 4757: train/loss = 0.32636570930480957, train/raw-loss = 0.27838870882987976, train/logprobs = tensor([[-2.7661, -5.0442],
        [-4.3712, -2.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47977006435394287
Epoch 0, Step 4758: train/loss = 0.25072813034057617, train/raw-loss = 0.20753459632396698, train/logprobs = tensor([[-2.7846, -8.7179],
        [-6.1109, -2.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4319354295730591
Epoch 0, Step 4759: train/loss = 0.09127414226531982, train/raw-loss = 0.043781790882349014, train/logprobs = tensor([[ -3.2008, -14.7859],
        [ -7.8230,  -3.2242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4749235510826111
Epoch 0, Step 4760: train/loss = 0.3781013488769531, train/raw-loss = 0.3273354768753052, train/logprobs = tensor([[-1.7656, -4.9555],
        [-4.1174, -1.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5076583623886108
Epoch 0, Step 4761: train/loss = 1.005192518234253, train/raw-loss = 0.9635258316993713, train/logprobs = tensor([[ -5.5143, -13.0433],
        [ -4.7991,  -2.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41666746139526367
Epoch 0, Step 4762: train/loss = 0.5153927803039551, train/raw-loss = 0.47222843766212463, train/logprobs = tensor([[-2.2448, -5.5061],
        [-3.5683, -2.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43164363503456116
Epoch 0, Step 4763: train/loss = 0.3604307174682617, train/raw-loss = 0.3115438222885132, train/logprobs = tensor([[-2.6524, -9.6243],
        [-6.7673, -3.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48886892199516296
Epoch 0, Step 4764: train/loss = 0.2614157199859619, train/raw-loss = 0.2187919020652771, train/logprobs = tensor([[-2.2886, -5.9227],
        [-5.7391, -2.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4262382984161377
Epoch 0, Step 4765: train/loss = 0.14642834663391113, train/raw-loss = 0.09862083196640015, train/logprobs = tensor([[ -1.0392, -13.9834],
        [ -5.3686,  -3.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47807517647743225
Epoch 0, Step 4766: train/loss = 0.05238087475299835, train/raw-loss = 0.00889685656875372, train/logprobs = tensor([[-2.1483, -7.4789],
        [-8.0556, -1.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43484020233154297
Epoch 0, Step 4767: train/loss = 0.12324441224336624, train/raw-loss = 0.08325719833374023, train/logprobs = tensor([[-1.7473, -9.6443],
        [-5.1901, -3.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39987215399742126
Epoch 0, Step 4768: train/loss = 0.5202749967575073, train/raw-loss = 0.4727303087711334, train/logprobs = tensor([[-1.3225, -4.1124],
        [-4.5591, -3.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47544702887535095
Epoch 0, Step 4769: train/loss = 0.07370829582214355, train/raw-loss = 0.025573208928108215, train/logprobs = tensor([[ -1.2373, -12.6263],
        [ -6.8102,  -3.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4813508689403534
Epoch 0, Step 4770: train/loss = 0.11255352944135666, train/raw-loss = 0.07603256404399872, train/logprobs = tensor([[-1.3702, -7.9530],
        [-5.7418, -1.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36520975828170776
Epoch 0, Step 4771: train/loss = 0.31745287775993347, train/raw-loss = 0.28194329142570496, train/logprobs = tensor([[-1.8732, -8.1184],
        [-3.9798, -4.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35509583353996277
Epoch 0, Step 4772: train/loss = 0.10326168686151505, train/raw-loss = 0.0637872964143753, train/logprobs = tensor([[ -1.4221, -14.7051],
        [ -5.0580,  -3.0474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3947439193725586
Epoch 0, Step 4773: train/loss = 0.2097807228565216, train/raw-loss = 0.1651795655488968, train/logprobs = tensor([[ -1.8505, -14.2966],
        [ -6.3583,  -4.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44601163268089294
Epoch 0, Step 4774: train/loss = 0.6119354367256165, train/raw-loss = 0.5666712522506714, train/logprobs = tensor([[ -1.9881, -10.8967],
        [ -4.2998,  -5.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45264142751693726
Epoch 0, Step 4775: train/loss = 0.24063123762607574, train/raw-loss = 0.1963341236114502, train/logprobs = tensor([[-2.7464, -9.8355],
        [-5.7491, -3.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44297102093696594
Epoch 0, Step 4776: train/loss = 0.16208191215991974, train/raw-loss = 0.1178663969039917, train/logprobs = tensor([[-1.0482, -6.6281],
        [-3.4536, -2.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44215506315231323
Epoch 0, Step 4777: train/loss = 0.1027718037366867, train/raw-loss = 0.0678815096616745, train/logprobs = tensor([[-1.7485, -6.3012],
        [-5.0252, -2.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34890300035476685
Epoch 0, Step 4778: train/loss = 0.2749636173248291, train/raw-loss = 0.23473313450813293, train/logprobs = tensor([[-1.6148, -4.7833],
        [-4.1291, -2.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40230488777160645
Epoch 0, Step 4779: train/loss = 0.3818599581718445, train/raw-loss = 0.34003332257270813, train/logprobs = tensor([[-2.1835, -5.6678],
        [-4.4103, -2.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4182664752006531
Epoch 0, Step 4780: train/loss = 0.5511353015899658, train/raw-loss = 0.5044675469398499, train/logprobs = tensor([[-2.3873, -4.4652],
        [-4.0961, -3.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46667781472206116
Epoch 0, Step 4781: train/loss = 0.12081877887248993, train/raw-loss = 0.07984070479869843, train/logprobs = tensor([[-1.4900, -8.5106],
        [-4.3500, -2.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40978074073791504
Epoch 0, Step 4782: train/loss = 0.47568392753601074, train/raw-loss = 0.43019384145736694, train/logprobs = tensor([[-2.1675, -4.8022],
        [-4.0181, -2.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45490115880966187
Epoch 0, Step 4783: train/loss = 0.19246849417686462, train/raw-loss = 0.13831739127635956, train/logprobs = tensor([[-2.8658, -6.9829],
        [-5.1676, -3.1988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5415111780166626
Epoch 0, Step 4784: train/loss = 0.5277926325798035, train/raw-loss = 0.4890369176864624, train/logprobs = tensor([[-1.7125, -4.5553],
        [-3.3675, -2.3259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875570297241211
Epoch 0, Step 4785: train/loss = 0.238521546125412, train/raw-loss = 0.19667746126651764, train/logprobs = tensor([[-3.2175, -8.7088],
        [-6.4836, -3.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4184407889842987
Epoch 0, Step 4786: train/loss = 0.872881293296814, train/raw-loss = 0.8244897127151489, train/logprobs = tensor([[-4.4213, -9.0171],
        [-5.0081, -2.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4839162230491638
Epoch 0, Step 4787: train/loss = 0.18970084190368652, train/raw-loss = 0.1358409821987152, train/logprobs = tensor([[ -2.5294, -11.2844],
        [ -5.7124,  -2.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5385985374450684
Epoch 0, Step 4788: train/loss = 0.42144203186035156, train/raw-loss = 0.38622772693634033, train/logprobs = tensor([[-1.8084, -5.9351],
        [-3.9552, -3.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35214319825172424
Epoch 0, Step 4789: train/loss = 0.18837568163871765, train/raw-loss = 0.14418379962444305, train/logprobs = tensor([[-0.9437, -8.2521],
        [-4.5796, -2.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44191887974739075
Epoch 0, Step 4790: train/loss = 0.1486802101135254, train/raw-loss = 0.11009843647480011, train/logprobs = tensor([[-1.9417, -8.5475],
        [-5.2798, -2.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38581764698028564
Epoch 0, Step 4791: train/loss = 0.4840795397758484, train/raw-loss = 0.43938758969306946, train/logprobs = tensor([[-2.6809, -4.0890],
        [-3.6763, -1.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4469194710254669
Epoch 0, Step 4792: train/loss = 0.27818563580513, train/raw-loss = 0.24320268630981445, train/logprobs = tensor([[-1.7177, -9.6522],
        [-5.7154, -2.1061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34982967376708984
Epoch 0, Step 4793: train/loss = 0.08823201805353165, train/raw-loss = 0.04612639546394348, train/logprobs = tensor([[-2.4977, -8.6859],
        [-6.1061, -2.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42105621099472046
Epoch 0, Step 4794: train/loss = 0.5205415487289429, train/raw-loss = 0.47175538539886475, train/logprobs = tensor([[-2.3886, -3.8828],
        [-4.3035, -3.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48786115646362305
Epoch 0, Step 4795: train/loss = 0.1571924239397049, train/raw-loss = 0.11517150700092316, train/logprobs = tensor([[-1.0837, -8.3791],
        [-4.5407, -2.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.420209139585495
Epoch 0, Step 4796: train/loss = 0.08261029422283173, train/raw-loss = 0.0332164391875267, train/logprobs = tensor([[-1.0379, -9.6736],
        [-5.3124, -3.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49393850564956665
Epoch 0, Step 4797: train/loss = 0.5852022767066956, train/raw-loss = 0.5465167760848999, train/logprobs = tensor([[-3.3723, -9.7992],
        [-5.1977, -2.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3868548274040222
Epoch 0, Step 4798: train/loss = 0.07380248606204987, train/raw-loss = 0.03199445456266403, train/logprobs = tensor([[ -2.2654, -13.7373],
        [ -6.0107,  -3.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41808027029037476
Epoch 0, Step 4799: train/loss = 0.253663033246994, train/raw-loss = 0.20870858430862427, train/logprobs = tensor([[ -1.6707, -11.1222],
        [ -4.7395,  -3.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44954437017440796
Epoch 0, Step 4800: train/loss = 0.14711326360702515, train/raw-loss = 0.09852854162454605, train/logprobs = tensor([[-1.5888, -7.9147],
        [-5.9226, -3.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48584720492362976
Epoch 0, Step 4801: train/loss = 0.24816584587097168, train/raw-loss = 0.21133357286453247, train/logprobs = tensor([[ -2.4371, -10.3044],
        [ -4.9797,  -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683226704597473
Epoch 0, Step 4802: train/loss = 0.2831692695617676, train/raw-loss = 0.23369038105010986, train/logprobs = tensor([[-2.0575, -6.3367],
        [-5.9177, -3.3521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4947889447212219
Epoch 0, Step 4803: train/loss = 0.3782038986682892, train/raw-loss = 0.33864691853523254, train/logprobs = tensor([[-2.9891, -8.3212],
        [-4.3525, -4.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39556998014450073
Epoch 0, Step 4804: train/loss = 0.4708651900291443, train/raw-loss = 0.4189574420452118, train/logprobs = tensor([[ -3.3725, -10.7914],
        [ -5.4584,  -4.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5190778970718384
Epoch 0, Step 4805: train/loss = 0.2602112591266632, train/raw-loss = 0.2188294678926468, train/logprobs = tensor([[-2.6586, -9.5614],
        [-6.3799, -4.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41381800174713135
Epoch 0, Step 4806: train/loss = 0.6510705351829529, train/raw-loss = 0.6019177436828613, train/logprobs = tensor([[-1.7938, -3.8803],
        [-4.7290, -4.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4915272295475006
Epoch 0, Step 4807: train/loss = 0.729865550994873, train/raw-loss = 0.68147873878479, train/logprobs = tensor([[-3.0510, -3.6564],
        [-3.0200, -2.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48386847972869873
Epoch 0, Step 4808: train/loss = 0.1362745761871338, train/raw-loss = 0.08744777739048004, train/logprobs = tensor([[-1.8310, -9.2123],
        [-5.5904, -1.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4882679581642151
Epoch 0, Step 4809: train/loss = 0.8239591121673584, train/raw-loss = 0.7874380350112915, train/logprobs = tensor([[-1.5656, -2.4779],
        [-2.1453, -2.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36521056294441223
Epoch 0, Step 4810: train/loss = 0.5549721717834473, train/raw-loss = 0.5152416229248047, train/logprobs = tensor([[-2.0437, -7.8718],
        [-3.6586, -2.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39730626344680786
Epoch 0, Step 4811: train/loss = 0.40080535411834717, train/raw-loss = 0.3597251772880554, train/logprobs = tensor([[-3.0404, -8.9543],
        [-5.9072, -3.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4108020067214966
Epoch 0, Step 4812: train/loss = 0.25332140922546387, train/raw-loss = 0.21065348386764526, train/logprobs = tensor([[-1.4461, -5.8048],
        [-3.8237, -2.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42667922377586365
Epoch 0, Step 4813: train/loss = 0.2872818410396576, train/raw-loss = 0.2359771430492401, train/logprobs = tensor([[-2.3426, -7.1290],
        [-4.7250, -1.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5130469799041748
Epoch 0, Step 4814: train/loss = 0.33423125743865967, train/raw-loss = 0.290982186794281, train/logprobs = tensor([[-1.6376, -3.0203],
        [-4.4457, -1.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43249067664146423
Epoch 0, Step 4815: train/loss = 0.16900977492332458, train/raw-loss = 0.13193956017494202, train/logprobs = tensor([[ -2.0464, -16.3567],
        [ -5.5776,  -3.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37070223689079285
Epoch 0, Step 4816: train/loss = 0.39912670850753784, train/raw-loss = 0.36951908469200134, train/logprobs = tensor([[-1.7957, -6.5212],
        [-2.4425, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960757911205292
Epoch 0, Step 4817: train/loss = 0.26604628562927246, train/raw-loss = 0.22620762884616852, train/logprobs = tensor([[-2.0399, -4.9913],
        [-6.5391, -2.5386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39838680624961853
Epoch 0, Step 4818: train/loss = 0.46569517254829407, train/raw-loss = 0.43017691373825073, train/logprobs = tensor([[-3.0002, -6.4965],
        [-3.8390, -1.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3551827669143677
Epoch 0, Step 4819: train/loss = 0.3680397868156433, train/raw-loss = 0.32710888981819153, train/logprobs = tensor([[-2.7613, -9.5842],
        [-4.6200, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40930911898612976
Epoch 0, Step 4820: train/loss = 0.8471323251724243, train/raw-loss = 0.8031144738197327, train/logprobs = tensor([[-2.6547, -4.4732],
        [-3.8876, -2.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44017842411994934
Epoch 0, Step 4821: train/loss = 0.491676390171051, train/raw-loss = 0.44978439807891846, train/logprobs = tensor([[-1.8740, -7.3855],
        [-2.9914, -3.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4189199209213257
Epoch 0, Step 4822: train/loss = 0.43976351618766785, train/raw-loss = 0.3871488869190216, train/logprobs = tensor([[-1.7820, -7.4725],
        [-5.4932, -5.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5261461734771729
Epoch 0, Step 4823: train/loss = 0.4319399297237396, train/raw-loss = 0.3942846357822418, train/logprobs = tensor([[-2.4823, -4.3338],
        [-4.4360, -1.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765528202056885
Epoch 0, Step 4824: train/loss = 0.5112655162811279, train/raw-loss = 0.46250295639038086, train/logprobs = tensor([[-3.6322, -8.2685],
        [-4.8414, -3.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4876256585121155
Epoch 0, Step 4825: train/loss = 0.12754866480827332, train/raw-loss = 0.08767129480838776, train/logprobs = tensor([[-1.2583, -6.3186],
        [-5.2157, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39877381920814514
Epoch 0, Step 4826: train/loss = 0.25073951482772827, train/raw-loss = 0.20335859060287476, train/logprobs = tensor([[-1.9455, -7.0583],
        [-5.7553, -2.1568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.473809152841568
Epoch 0, Step 4827: train/loss = 0.2578854560852051, train/raw-loss = 0.2148447483778, train/logprobs = tensor([[-1.6444, -6.0169],
        [-4.2225, -2.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43040719628334045
Epoch 0, Step 4828: train/loss = 0.14251333475112915, train/raw-loss = 0.10931838303804398, train/logprobs = tensor([[-1.5866, -4.0972],
        [-5.3264, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319495916366577
Epoch 0, Step 4829: train/loss = 0.5016657710075378, train/raw-loss = 0.45152047276496887, train/logprobs = tensor([[ -3.2290, -11.0871],
        [ -5.6911,  -4.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5014530420303345
Epoch 0, Step 4830: train/loss = 0.4838758409023285, train/raw-loss = 0.43627509474754333, train/logprobs = tensor([[-3.8456, -5.6378],
        [-4.7619, -3.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4760076403617859
Epoch 0, Step 4831: train/loss = 0.6109697222709656, train/raw-loss = 0.5587630867958069, train/logprobs = tensor([[-2.4965, -8.0292],
        [-6.2091, -4.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5220657587051392
Epoch 0, Step 4832: train/loss = 0.07565844058990479, train/raw-loss = 0.034054234623909, train/logprobs = tensor([[ -0.9797, -14.1035],
        [ -4.3929,  -6.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4160420894622803
Epoch 0, Step 4833: train/loss = 0.28839409351348877, train/raw-loss = 0.24362517893314362, train/logprobs = tensor([[-2.5307, -5.9643],
        [-5.8235, -3.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44768914580345154
Epoch 0, Step 4834: train/loss = 0.06268054246902466, train/raw-loss = 0.014162790030241013, train/logprobs = tensor([[ -1.8292, -16.2529],
        [ -5.8718,  -5.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4851774573326111
Epoch 0, Step 4835: train/loss = 0.47037822008132935, train/raw-loss = 0.4224342107772827, train/logprobs = tensor([[-1.7279, -7.5698],
        [-4.6848, -3.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4794403910636902
Epoch 0, Step 4836: train/loss = 0.1256578266620636, train/raw-loss = 0.08821098506450653, train/logprobs = tensor([[ -1.3741, -12.2910],
        [ -5.4039,  -4.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37446844577789307
Epoch 0, Step 4837: train/loss = 0.13775783777236938, train/raw-loss = 0.09868055582046509, train/logprobs = tensor([[-2.3885, -9.8401],
        [-5.1676, -2.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39077281951904297
Epoch 0, Step 4838: train/loss = 0.21348226070404053, train/raw-loss = 0.17099681496620178, train/logprobs = tensor([[-1.4198, -7.1070],
        [-4.9787, -1.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4248543977737427
Epoch 0, Step 4839: train/loss = 0.2842999994754791, train/raw-loss = 0.2477189004421234, train/logprobs = tensor([[-2.6321, -6.8600],
        [-4.6080, -2.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36581093072891235
Epoch 0, Step 4840: train/loss = 0.2939368486404419, train/raw-loss = 0.2394469529390335, train/logprobs = tensor([[-2.5067, -5.8579],
        [-6.3466, -3.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5448989868164062
Epoch 0, Step 4841: train/loss = 0.14835424721240997, train/raw-loss = 0.09218228608369827, train/logprobs = tensor([[ -1.6403, -14.4485],
        [ -6.2640,  -2.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5617196559906006
Epoch 0, Step 4842: train/loss = 0.374614417552948, train/raw-loss = 0.328654408454895, train/logprobs = tensor([[ -1.9454, -14.5968],
        [ -5.1839,  -8.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4596000909805298
Epoch 0, Step 4843: train/loss = 0.14472930133342743, train/raw-loss = 0.0941091924905777, train/logprobs = tensor([[ -1.8180, -11.6013],
        [ -5.3987,  -4.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5062010884284973
Epoch 0, Step 4844: train/loss = 0.19656381011009216, train/raw-loss = 0.1550535261631012, train/logprobs = tensor([[-2.4463, -8.2606],
        [-5.2611, -3.4477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41510283946990967
Epoch 0, Step 4845: train/loss = 0.3143327236175537, train/raw-loss = 0.26559656858444214, train/logprobs = tensor([[ -1.6466, -13.1328],
        [ -5.2105,  -6.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4873615801334381
Epoch 0, Step 4846: train/loss = 0.7654193043708801, train/raw-loss = 0.726958692073822, train/logprobs = tensor([[ -4.0923, -11.5838],
        [ -5.1631,  -1.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38460609316825867
Epoch 0, Step 4847: train/loss = 0.9213557839393616, train/raw-loss = 0.8869907259941101, train/logprobs = tensor([[-5.1766, -8.8662],
        [-4.9688, -3.4085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34365084767341614
Epoch 0, Step 4848: train/loss = 0.23941992223262787, train/raw-loss = 0.2035120278596878, train/logprobs = tensor([[-2.3406, -5.4072],
        [-5.5255, -1.4568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35907885432243347
Epoch 0, Step 4849: train/loss = 0.3886445462703705, train/raw-loss = 0.3401889503002167, train/logprobs = tensor([[-1.4431, -8.1939],
        [-4.9926, -2.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4845559000968933
Epoch 0, Step 4850: train/loss = 0.5131257772445679, train/raw-loss = 0.47241637110710144, train/logprobs = tensor([[ -1.4234, -10.5944],
        [ -5.5561,  -5.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40709394216537476
Epoch 0, Step 4851: train/loss = 0.14704389870166779, train/raw-loss = 0.10833656787872314, train/logprobs = tensor([[ -1.2681, -11.7138],
        [ -6.0254,  -2.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38707321882247925
Epoch 0, Step 4852: train/loss = 0.08459653705358505, train/raw-loss = 0.04735260829329491, train/logprobs = tensor([[ -1.7816, -16.9003],
        [ -5.5419,  -5.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37243932485580444
Epoch 0, Step 4853: train/loss = 0.4078606963157654, train/raw-loss = 0.37233978509902954, train/logprobs = tensor([[-2.1547, -5.7138],
        [-3.5367, -2.2722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35520926117897034
Epoch 0, Step 4854: train/loss = 0.22214560210704803, train/raw-loss = 0.17023804783821106, train/logprobs = tensor([[-1.6631, -5.7702],
        [-7.1589, -2.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.519075334072113
Epoch 0, Step 4855: train/loss = 0.3041597604751587, train/raw-loss = 0.25433987379074097, train/logprobs = tensor([[-2.1346, -4.1820],
        [-4.7478, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49819880723953247
Epoch 0, Step 4856: train/loss = 0.04656704515218735, train/raw-loss = 0.00252795172855258, train/logprobs = tensor([[ -1.6946, -13.5225],
        [ -7.4196,  -4.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.440390944480896
Epoch 0, Step 4857: train/loss = 0.2909408211708069, train/raw-loss = 0.2573738098144531, train/logprobs = tensor([[-2.1275, -5.1050],
        [-6.0143, -3.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356700539588928
Epoch 0, Step 4858: train/loss = 0.3062574863433838, train/raw-loss = 0.2593613266944885, train/logprobs = tensor([[-1.7796, -6.4014],
        [-4.3468, -2.4036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4689617156982422
Epoch 0, Step 4859: train/loss = 0.4341004490852356, train/raw-loss = 0.3900388479232788, train/logprobs = tensor([[-1.6742, -3.8254],
        [-3.1691, -1.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4406158924102783
Epoch 0, Step 4860: train/loss = 0.546110987663269, train/raw-loss = 0.48627352714538574, train/logprobs = tensor([[ -1.2374, -11.6237],
        [ -5.5829,  -4.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5983747839927673
Epoch 0, Step 4861: train/loss = 0.3999541401863098, train/raw-loss = 0.3586587905883789, train/logprobs = tensor([[-1.8909, -9.6853],
        [-4.3262, -4.1941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41295325756073
Epoch 0, Step 4862: train/loss = 0.10606700927019119, train/raw-loss = 0.07243918627500534, train/logprobs = tensor([[ -1.2567, -14.9759],
        [ -5.1854,  -3.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33627837896347046
Epoch 0, Step 4863: train/loss = 0.7214969992637634, train/raw-loss = 0.6831426620483398, train/logprobs = tensor([[ -3.9077, -11.3817],
        [ -5.5608,  -2.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38354361057281494
Epoch 0, Step 4864: train/loss = 0.7850963473320007, train/raw-loss = 0.748679518699646, train/logprobs = tensor([[-2.3267, -2.7529],
        [-2.6145, -2.3083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36416858434677124
Epoch 0, Step 4865: train/loss = 0.325083464384079, train/raw-loss = 0.27873507142066956, train/logprobs = tensor([[-1.9608, -7.3397],
        [-5.6908, -4.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46348392963409424
Epoch 0, Step 4866: train/loss = 0.13695028424263, train/raw-loss = 0.09960372745990753, train/logprobs = tensor([[-1.6909, -8.0178],
        [-5.2181, -2.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37346553802490234
Epoch 0, Step 4867: train/loss = 0.486374169588089, train/raw-loss = 0.44731825590133667, train/logprobs = tensor([[-1.8256, -6.3124],
        [-3.7143, -4.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905591368675232
Epoch 0, Step 4868: train/loss = 0.45293423533439636, train/raw-loss = 0.41092997789382935, train/logprobs = tensor([[-2.1976, -4.3371],
        [-5.4003, -3.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42004257440567017
Epoch 0, Step 4869: train/loss = 0.43516188859939575, train/raw-loss = 0.39717036485671997, train/logprobs = tensor([[-2.3623, -3.6021],
        [-3.2947, -2.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37991517782211304
Epoch 0, Step 4870: train/loss = 0.25802645087242126, train/raw-loss = 0.2139783650636673, train/logprobs = tensor([[-1.9258, -8.6428],
        [-4.9666, -2.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4404810070991516
Epoch 0, Step 4871: train/loss = 0.25526925921440125, train/raw-loss = 0.2225479930639267, train/logprobs = tensor([[ -1.0294, -12.0985],
        [ -2.4610,  -2.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32721269130706787
Epoch 0, Step 4872: train/loss = 0.050635188817977905, train/raw-loss = 0.007025840692222118, train/logprobs = tensor([[ -1.2710, -17.4602],
        [ -5.6916,  -2.5268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4360934793949127
Epoch 0, Step 4873: train/loss = 0.3409140706062317, train/raw-loss = 0.2907606065273285, train/logprobs = tensor([[-1.7027, -6.3187],
        [-4.7421, -3.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5015347003936768
Epoch 0, Step 4874: train/loss = 0.16165947914123535, train/raw-loss = 0.12152614444494247, train/logprobs = tensor([[ -2.1202, -10.7823],
        [ -6.3351,  -3.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40133318305015564
Epoch 0, Step 4875: train/loss = 0.9198302030563354, train/raw-loss = 0.8919315338134766, train/logprobs = tensor([[-4.4477, -8.8814],
        [-3.0933, -4.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789870500564575
Epoch 0, Step 4876: train/loss = 0.16022995114326477, train/raw-loss = 0.11675728112459183, train/logprobs = tensor([[ -1.4974, -12.2833],
        [ -4.4281,  -2.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4347267150878906
Epoch 0, Step 4877: train/loss = 0.2545630931854248, train/raw-loss = 0.21405847370624542, train/logprobs = tensor([[-1.8954, -7.4650],
        [-4.4652, -1.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050462245941162
Epoch 0, Step 4878: train/loss = 0.16440339386463165, train/raw-loss = 0.12179248034954071, train/logprobs = tensor([[-1.7072, -7.8473],
        [-5.9569, -2.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42610904574394226
Epoch 0, Step 4879: train/loss = 0.3711327910423279, train/raw-loss = 0.3296002149581909, train/logprobs = tensor([[-1.9875, -7.1379],
        [-4.4945, -2.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41532570123672485
Epoch 0, Step 4880: train/loss = 0.47082096338272095, train/raw-loss = 0.4287921190261841, train/logprobs = tensor([[-1.8355, -8.4553],
        [-4.5350, -5.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4202885031700134
Epoch 0, Step 4881: train/loss = 0.33506911993026733, train/raw-loss = 0.2868954539299011, train/logprobs = tensor([[ -2.0577, -15.4465],
        [ -5.6323,  -8.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4817364513874054
Epoch 0, Step 4882: train/loss = 0.24870344996452332, train/raw-loss = 0.2047579288482666, train/logprobs = tensor([[-1.8582, -5.6532],
        [-6.0189, -2.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43945521116256714
Epoch 0, Step 4883: train/loss = 0.3471381664276123, train/raw-loss = 0.3008768558502197, train/logprobs = tensor([[-1.2178, -6.4436],
        [-5.7341, -2.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46261295676231384
Epoch 0, Step 4884: train/loss = 0.28774914145469666, train/raw-loss = 0.24361053109169006, train/logprobs = tensor([[-2.7992, -7.8978],
        [-5.5496, -2.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4413859248161316
Epoch 0, Step 4885: train/loss = 0.05963173508644104, train/raw-loss = 0.007543232291936874, train/logprobs = tensor([[ -2.6045, -17.5660],
        [ -8.9174,  -7.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5208849906921387
Epoch 0, Step 4886: train/loss = 0.4247489273548126, train/raw-loss = 0.38423338532447815, train/logprobs = tensor([[-1.7299, -2.5342],
        [-4.9750, -2.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40515559911727905
Epoch 0, Step 4887: train/loss = 0.5116182565689087, train/raw-loss = 0.46545714139938354, train/logprobs = tensor([[-2.3594, -8.5386],
        [-5.5137, -5.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46161139011383057
Epoch 0, Step 4888: train/loss = 0.2920913100242615, train/raw-loss = 0.25023722648620605, train/logprobs = tensor([[ -2.2288, -11.0947],
        [ -5.6120,  -2.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4185407757759094
Epoch 0, Step 4889: train/loss = 0.42365097999572754, train/raw-loss = 0.3786495327949524, train/logprobs = tensor([[-1.5512, -7.8100],
        [-5.4405, -2.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4500143527984619
Epoch 0, Step 4890: train/loss = 0.32786843180656433, train/raw-loss = 0.2685137689113617, train/logprobs = tensor([[ -2.5010, -12.0929],
        [ -6.6005,  -3.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5935463309288025
Epoch 0, Step 4891: train/loss = 0.5678871273994446, train/raw-loss = 0.5266614556312561, train/logprobs = tensor([[-1.7410, -2.9136],
        [-3.4367, -2.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41225698590278625
Epoch 0, Step 4892: train/loss = 0.4330367147922516, train/raw-loss = 0.3841351866722107, train/logprobs = tensor([[-1.3071, -7.2860],
        [-6.7046, -3.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48901528120040894
Epoch 0, Step 4893: train/loss = 0.39252325892448425, train/raw-loss = 0.33946192264556885, train/logprobs = tensor([[-1.6920, -6.9208],
        [-4.8606, -3.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.530613124370575
Epoch 0, Step 4894: train/loss = 0.07999452948570251, train/raw-loss = 0.043730415403842926, train/logprobs = tensor([[ -1.6586, -11.9041],
        [ -5.1689,  -3.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3626411557197571
Epoch 0, Step 4895: train/loss = 0.323587566614151, train/raw-loss = 0.2846750020980835, train/logprobs = tensor([[-2.2041, -4.9797],
        [-4.6861, -2.1008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891257643699646
Epoch 0, Step 4896: train/loss = 0.4548099935054779, train/raw-loss = 0.41029098629951477, train/logprobs = tensor([[-2.3957, -4.3084],
        [-5.5407, -3.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4451897144317627
Epoch 0, Step 4897: train/loss = 0.2336619645357132, train/raw-loss = 0.19738081097602844, train/logprobs = tensor([[-4.1117, -8.1403],
        [-5.8129, -2.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3628116846084595
Epoch 0, Step 4898: train/loss = 0.4415771961212158, train/raw-loss = 0.4003613591194153, train/logprobs = tensor([[-1.5568, -9.9553],
        [-5.7498, -5.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4121585488319397
Epoch 0, Step 4899: train/loss = 0.1441255509853363, train/raw-loss = 0.10584097355604172, train/logprobs = tensor([[-1.8570, -5.1279],
        [-5.3104, -2.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38284584879875183
Epoch 0, Step 4900: train/loss = 0.4528992176055908, train/raw-loss = 0.4007040560245514, train/logprobs = tensor([[-1.6309, -5.7299],
        [-4.7758, -1.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5219516754150391
Epoch 0, Step 4901: train/loss = 0.1650574803352356, train/raw-loss = 0.1252054125070572, train/logprobs = tensor([[-3.4321, -8.1993],
        [-5.6919, -2.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39852070808410645
Epoch 0, Step 4902: train/loss = 0.3078913390636444, train/raw-loss = 0.2542159855365753, train/logprobs = tensor([[ -2.1003, -12.3924],
        [ -8.2595,  -3.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.53675377368927
Epoch 0, Step 4903: train/loss = 0.08927790820598602, train/raw-loss = 0.056024517863988876, train/logprobs = tensor([[ -1.0782, -10.7189],
        [ -3.8790,  -2.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33253389596939087
Epoch 0, Step 4904: train/loss = 0.23204289376735687, train/raw-loss = 0.19668903946876526, train/logprobs = tensor([[-1.4339, -6.9547],
        [-5.1929, -1.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35353848338127136
Epoch 0, Step 4905: train/loss = 0.0620872788131237, train/raw-loss = 0.019719216972589493, train/logprobs = tensor([[ -1.1212, -13.1753],
        [ -5.6055,  -1.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4236806333065033
Epoch 0, Step 4906: train/loss = 0.1625935584306717, train/raw-loss = 0.11716923117637634, train/logprobs = tensor([[-2.2638, -5.1148],
        [-6.8428, -1.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4542433023452759
Epoch 0, Step 4907: train/loss = 0.18619102239608765, train/raw-loss = 0.14180433750152588, train/logprobs = tensor([[-1.4105, -8.6631],
        [-5.0884, -2.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4438668191432953
Epoch 0, Step 4908: train/loss = 0.14308391511440277, train/raw-loss = 0.09445986896753311, train/logprobs = tensor([[-1.6181, -8.5084],
        [-6.6888, -3.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4862404465675354
Epoch 0, Step 4909: train/loss = 0.3454037606716156, train/raw-loss = 0.29069066047668457, train/logprobs = tensor([[-1.5648, -7.5084],
        [-5.2711, -3.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5471306443214417
Epoch 0, Step 4910: train/loss = 0.23093493282794952, train/raw-loss = 0.19051437079906464, train/logprobs = tensor([[ -3.8747, -11.2690],
        [ -6.4510,  -2.7468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4042055606842041
Epoch 0, Step 4911: train/loss = 0.6035186648368835, train/raw-loss = 0.5488971471786499, train/logprobs = tensor([[-2.5499, -6.9408],
        [-5.3475, -3.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5462151765823364
Epoch 0, Step 4912: train/loss = 0.12748466432094574, train/raw-loss = 0.08288685232400894, train/logprobs = tensor([[-1.8675, -7.6961],
        [-6.0257, -2.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.445978045463562
Epoch 0, Step 4913: train/loss = 0.12208481132984161, train/raw-loss = 0.08300089836120605, train/logprobs = tensor([[-1.1159, -7.9585],
        [-4.5573, -2.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.390839159488678
Epoch 0, Step 4914: train/loss = 0.5686348080635071, train/raw-loss = 0.527412474155426, train/logprobs = tensor([[-1.1108, -3.7701],
        [-4.6907, -3.4026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122236669063568
Epoch 0, Step 4915: train/loss = 0.19912737607955933, train/raw-loss = 0.15239238739013672, train/logprobs = tensor([[-1.2627, -9.4484],
        [-3.8409, -4.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46734973788261414
Epoch 0, Step 4916: train/loss = 0.13137704133987427, train/raw-loss = 0.08390737324953079, train/logprobs = tensor([[ -2.9006, -10.8079],
        [ -5.5108,  -4.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47469663619995117
Epoch 0, Step 4917: train/loss = 0.38084977865219116, train/raw-loss = 0.32550835609436035, train/logprobs = tensor([[-2.3164, -7.9469],
        [-5.6797, -5.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5534143447875977
Epoch 0, Step 4918: train/loss = 0.3849901556968689, train/raw-loss = 0.34666579961776733, train/logprobs = tensor([[-1.9026, -6.3081],
        [-3.4593, -2.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3832435607910156
Epoch 0, Step 4919: train/loss = 0.5352230072021484, train/raw-loss = 0.49402469396591187, train/logprobs = tensor([[-2.1448, -3.9288],
        [-4.2871, -2.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4119832217693329
Epoch 0, Step 4920: train/loss = 0.5808143615722656, train/raw-loss = 0.5334194898605347, train/logprobs = tensor([[ -1.9020, -11.8010],
        [ -5.1458,  -4.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47394859790802
Epoch 0, Step 4921: train/loss = 0.19211842119693756, train/raw-loss = 0.14265736937522888, train/logprobs = tensor([[-2.6339, -8.1778],
        [-7.5284, -3.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4946104884147644
Epoch 0, Step 4922: train/loss = 0.24392187595367432, train/raw-loss = 0.19672368466854095, train/logprobs = tensor([[-1.5937, -6.8580],
        [-4.8290, -3.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47198182344436646
Epoch 0, Step 4923: train/loss = 0.20766150951385498, train/raw-loss = 0.17239691317081451, train/logprobs = tensor([[-1.7262, -7.0415],
        [-4.3819, -2.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3526458740234375
Epoch 0, Step 4924: train/loss = 0.42641836404800415, train/raw-loss = 0.3847638964653015, train/logprobs = tensor([[-2.9747, -8.8482],
        [-4.3694, -3.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41654467582702637
Epoch 0, Step 4925: train/loss = 0.2802055776119232, train/raw-loss = 0.2301541268825531, train/logprobs = tensor([[ -2.4094, -11.7997],
        [ -5.0624,  -2.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5005145072937012
Epoch 0, Step 4926: train/loss = 0.21746401488780975, train/raw-loss = 0.1820303201675415, train/logprobs = tensor([[-1.4748, -9.6230],
        [-3.8554, -2.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35433709621429443
Epoch 0, Step 4927: train/loss = 0.2034592181444168, train/raw-loss = 0.17229190468788147, train/logprobs = tensor([[-1.8035, -5.8104],
        [-3.3268, -2.4118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.311673104763031
Epoch 0, Step 4928: train/loss = 0.40196847915649414, train/raw-loss = 0.3437920808792114, train/logprobs = tensor([[-2.1689, -7.4815],
        [-5.6732, -3.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5817636847496033
Epoch 0, Step 4929: train/loss = 0.2464403212070465, train/raw-loss = 0.2016802579164505, train/logprobs = tensor([[ -1.6552, -13.6876],
        [ -5.5647,  -6.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4476005434989929
Epoch 0, Step 4930: train/loss = 0.31682226061820984, train/raw-loss = 0.27555495500564575, train/logprobs = tensor([[-1.2441, -4.8005],
        [-4.5245, -3.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41267290711402893
Epoch 0, Step 4931: train/loss = 0.5343478322029114, train/raw-loss = 0.4844666123390198, train/logprobs = tensor([[-1.8807, -4.6571],
        [-4.4832, -2.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49881210923194885
Epoch 0, Step 4932: train/loss = 0.12117858976125717, train/raw-loss = 0.08538844436407089, train/logprobs = tensor([[-2.4780, -6.5876],
        [-6.4713, -2.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3579014539718628
Epoch 0, Step 4933: train/loss = 0.4813109338283539, train/raw-loss = 0.4264589548110962, train/logprobs = tensor([[-1.8006, -8.8654],
        [-5.3571, -2.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.548520028591156
Epoch 0, Step 4934: train/loss = 0.44172605872154236, train/raw-loss = 0.4127243757247925, train/logprobs = tensor([[ -2.1274, -15.0737],
        [ -4.2149,  -7.3203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29001671075820923
Epoch 0, Step 4935: train/loss = 0.12602730095386505, train/raw-loss = 0.0795101672410965, train/logprobs = tensor([[-1.2666, -6.9423],
        [-5.6809, -2.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46517133712768555
Epoch 0, Step 4936: train/loss = 0.415771484375, train/raw-loss = 0.35636696219444275, train/logprobs = tensor([[-1.6835, -9.9766],
        [-6.2716, -4.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5940450429916382
Epoch 0, Step 4937: train/loss = 0.3808031976222992, train/raw-loss = 0.33651626110076904, train/logprobs = tensor([[-1.5715, -5.9895],
        [-5.3903, -3.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4428693354129791
Epoch 0, Step 4938: train/loss = 0.20353950560092926, train/raw-loss = 0.1660289317369461, train/logprobs = tensor([[ -2.9173, -14.7328],
        [ -5.8737,  -3.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37510573863983154
Epoch 0, Step 4939: train/loss = 0.2525772154331207, train/raw-loss = 0.2153092622756958, train/logprobs = tensor([[-2.1122, -9.8801],
        [-4.9943, -1.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726797103881836
Epoch 0, Step 4940: train/loss = 0.23457567393779755, train/raw-loss = 0.19347403943538666, train/logprobs = tensor([[-1.2225, -5.7785],
        [-4.7802, -2.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41101640462875366
Epoch 0, Step 4941: train/loss = 0.49996957182884216, train/raw-loss = 0.4591690003871918, train/logprobs = tensor([[-1.8365, -3.6043],
        [-4.2756, -1.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4080054461956024
Epoch 0, Step 4942: train/loss = 0.5969409346580505, train/raw-loss = 0.5368770956993103, train/logprobs = tensor([[-1.7669, -6.5394],
        [-5.4675, -4.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6006377935409546
Epoch 0, Step 4943: train/loss = 0.6570360660552979, train/raw-loss = 0.6238682866096497, train/logprobs = tensor([[-0.3909, -4.9543],
        [-1.7253, -3.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3316778540611267
Epoch 0, Step 4944: train/loss = 0.36701613664627075, train/raw-loss = 0.32642221450805664, train/logprobs = tensor([[-1.8222, -6.3350],
        [-6.8832, -2.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4059393107891083
Epoch 0, Step 4945: train/loss = 0.41138842701911926, train/raw-loss = 0.35898175835609436, train/logprobs = tensor([[ -1.7308, -12.7822],
        [ -6.9371,  -5.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5240666270256042
Epoch 0, Step 4946: train/loss = 0.1273912787437439, train/raw-loss = 0.08613528311252594, train/logprobs = tensor([[ -3.1616, -10.5122],
        [ -6.4048,  -3.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4125598967075348
Epoch 0, Step 4947: train/loss = 0.26186874508857727, train/raw-loss = 0.21803976595401764, train/logprobs = tensor([[ -2.0219, -10.9319],
        [ -5.9823,  -2.4097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4382898807525635
Epoch 0, Step 4948: train/loss = 0.0885474681854248, train/raw-loss = 0.04061035439372063, train/logprobs = tensor([[ -1.6137, -11.8419],
        [ -6.7941,  -2.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4793710708618164
Epoch 0, Step 4949: train/loss = 0.16895359754562378, train/raw-loss = 0.13475735485553741, train/logprobs = tensor([[ -1.9558, -11.3402],
        [ -5.9406,  -1.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34196245670318604
Epoch 0, Step 4950: train/loss = 0.36919158697128296, train/raw-loss = 0.3131149411201477, train/logprobs = tensor([[-2.3393, -5.3854],
        [-4.4457, -3.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5607665181159973
Epoch 0, Step 4951: train/loss = 0.4552879333496094, train/raw-loss = 0.4144909381866455, train/logprobs = tensor([[-1.6091, -3.7466],
        [-3.8793, -3.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40797024965286255
Epoch 0, Step 4952: train/loss = 0.35009780526161194, train/raw-loss = 0.30194514989852905, train/logprobs = tensor([[-1.7611, -5.8701],
        [-4.7182, -3.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.481526255607605
Epoch 0, Step 4953: train/loss = 0.2958694100379944, train/raw-loss = 0.251861035823822, train/logprobs = tensor([[-0.9970, -6.6276],
        [-4.1100, -2.0338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44008389115333557
Epoch 0, Step 4954: train/loss = 0.3910176455974579, train/raw-loss = 0.33880776166915894, train/logprobs = tensor([[-2.0820, -4.3177],
        [-4.7519, -3.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.522098958492279
Epoch 0, Step 4955: train/loss = 0.7270728945732117, train/raw-loss = 0.6860123872756958, train/logprobs = tensor([[-1.3051, -7.9100],
        [-3.6341, -6.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41060489416122437
Epoch 0, Step 4956: train/loss = 1.009224534034729, train/raw-loss = 0.9823139905929565, train/logprobs = tensor([[-3.9436, -5.6810],
        [-2.0445, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26910555362701416
Epoch 0, Step 4957: train/loss = 0.40161988139152527, train/raw-loss = 0.35920432209968567, train/logprobs = tensor([[-1.3381, -3.7243],
        [-4.9444, -2.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4241555631160736
Epoch 0, Step 4958: train/loss = 0.12491156160831451, train/raw-loss = 0.09250932931900024, train/logprobs = tensor([[-2.2295, -8.8208],
        [-5.6474, -4.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3240222930908203
Epoch 0, Step 4959: train/loss = 0.26928532123565674, train/raw-loss = 0.22715798020362854, train/logprobs = tensor([[-1.7447, -6.9688],
        [-5.4884, -2.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42127326130867004
Epoch 0, Step 4960: train/loss = 0.4275239109992981, train/raw-loss = 0.37009474635124207, train/logprobs = tensor([[-1.4169, -4.1365],
        [-5.2758, -3.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5742912888526917
Epoch 0, Step 4961: train/loss = 0.5528433322906494, train/raw-loss = 0.5129241347312927, train/logprobs = tensor([[-1.7780, -6.2566],
        [-3.8513, -5.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39919203519821167
Epoch 0, Step 4962: train/loss = 1.004043698310852, train/raw-loss = 0.9590110778808594, train/logprobs = tensor([[-3.0392, -3.5536],
        [-6.6734, -5.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4503258466720581
Epoch 0, Step 4963: train/loss = 0.23415011167526245, train/raw-loss = 0.18991804122924805, train/logprobs = tensor([[ -1.6610, -11.9790],
        [ -4.9755,  -3.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4423205256462097
Epoch 0, Step 4964: train/loss = 0.3138224184513092, train/raw-loss = 0.27772194147109985, train/logprobs = tensor([[-1.5184, -5.3547],
        [-4.9725, -2.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610048294067383
Epoch 0, Step 4965: train/loss = 0.5709594488143921, train/raw-loss = 0.5403310060501099, train/logprobs = tensor([[-1.5427, -3.2908],
        [-2.2432, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3062838017940521
Epoch 0, Step 4966: train/loss = 0.16299869120121002, train/raw-loss = 0.12196119129657745, train/logprobs = tensor([[-1.6052, -7.1685],
        [-4.9716, -2.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4103749692440033
Epoch 0, Step 4967: train/loss = 0.5549203157424927, train/raw-loss = 0.5007474422454834, train/logprobs = tensor([[-1.5478, -3.0631],
        [-5.4738, -3.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5417287349700928
Epoch 0, Step 4968: train/loss = 0.36825042963027954, train/raw-loss = 0.3268364369869232, train/logprobs = tensor([[ -1.9172, -11.8798],
        [ -5.1182,  -4.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4141398072242737
Epoch 0, Step 4969: train/loss = 0.5467801094055176, train/raw-loss = 0.5100027322769165, train/logprobs = tensor([[-1.9900, -3.5658],
        [-4.0486, -1.6802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3677731454372406
Epoch 0, Step 4970: train/loss = 0.351336270570755, train/raw-loss = 0.305630087852478, train/logprobs = tensor([[-1.7825, -6.5272],
        [-4.3359, -2.3494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4570619761943817
Epoch 0, Step 4971: train/loss = 0.05356822907924652, train/raw-loss = 0.00899928156286478, train/logprobs = tensor([[ -1.3210, -10.7167],
        [ -6.3571,  -2.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44568949937820435
Epoch 0, Step 4972: train/loss = 0.21156957745552063, train/raw-loss = 0.16634802520275116, train/logprobs = tensor([[ -1.5651, -10.7168],
        [ -4.0303,  -3.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45221561193466187
Epoch 0, Step 4973: train/loss = 0.6653035879135132, train/raw-loss = 0.6351163983345032, train/logprobs = tensor([[-1.2078, -6.9511],
        [-4.9949, -3.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3018719553947449
Epoch 0, Step 4974: train/loss = 0.36022821068763733, train/raw-loss = 0.31629952788352966, train/logprobs = tensor([[-2.2377, -6.2030],
        [-5.0117, -3.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43928655982017517
Epoch 0, Step 4975: train/loss = 0.11595836281776428, train/raw-loss = 0.07169270515441895, train/logprobs = tensor([[-4.2605, -7.8837],
        [-8.7036, -2.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44265657663345337
Epoch 0, Step 4976: train/loss = 0.4243505597114563, train/raw-loss = 0.37981635332107544, train/logprobs = tensor([[-2.2215, -5.9579],
        [-6.1947, -3.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4453420639038086
Epoch 0, Step 4977: train/loss = 0.5794420838356018, train/raw-loss = 0.5416280031204224, train/logprobs = tensor([[-1.5497, -2.8999],
        [-2.9682, -2.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37814077734947205
Epoch 0, Step 4978: train/loss = 0.05689799785614014, train/raw-loss = 0.01048396434634924, train/logprobs = tensor([[ -1.8219, -13.5908],
        [ -7.5831,  -6.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46414029598236084
Epoch 0, Step 4979: train/loss = 0.7288152575492859, train/raw-loss = 0.69764643907547, train/logprobs = tensor([[-3.2562, -8.1276],
        [-3.3048, -4.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116876482963562
Epoch 0, Step 4980: train/loss = 0.221365824341774, train/raw-loss = 0.17548547685146332, train/logprobs = tensor([[-1.4551, -9.1630],
        [-6.2781, -2.3775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4588034451007843
Epoch 0, Step 4981: train/loss = 0.24486078321933746, train/raw-loss = 0.2087513506412506, train/logprobs = tensor([[-2.6844, -7.9026],
        [-4.6185, -2.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3610943853855133
Epoch 0, Step 4982: train/loss = 0.15519611537456512, train/raw-loss = 0.12072095274925232, train/logprobs = tensor([[ -3.6031, -10.9554],
        [ -6.3563,  -2.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447516858577728
Epoch 0, Step 4983: train/loss = 0.5786967277526855, train/raw-loss = 0.529237687587738, train/logprobs = tensor([[-2.8268, -3.9768],
        [-5.2379, -2.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49459025263786316
Epoch 0, Step 4984: train/loss = 0.6559938788414001, train/raw-loss = 0.614291250705719, train/logprobs = tensor([[-2.2155, -3.6528],
        [-3.6223, -3.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41702592372894287
Epoch 0, Step 4985: train/loss = 0.31245121359825134, train/raw-loss = 0.27162450551986694, train/logprobs = tensor([[-1.5122, -5.6219],
        [-4.0924, -1.5886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.408267080783844
Epoch 0, Step 4986: train/loss = 0.30660662055015564, train/raw-loss = 0.2602560520172119, train/logprobs = tensor([[-1.9608, -5.8645],
        [-5.3262, -3.2106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4635053277015686
Epoch 0, Step 4987: train/loss = 0.3275127112865448, train/raw-loss = 0.2824289798736572, train/logprobs = tensor([[-2.5775, -6.9041],
        [-5.2315, -3.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45083755254745483
Epoch 0, Step 4988: train/loss = 0.20432457327842712, train/raw-loss = 0.16326294839382172, train/logprobs = tensor([[ -1.8209, -10.6073],
        [ -5.2505,  -3.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106164574623108
Epoch 0, Step 4989: train/loss = 0.423735648393631, train/raw-loss = 0.37570416927337646, train/logprobs = tensor([[-1.8540, -3.8676],
        [-7.4117, -3.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48031511902809143
Epoch 0, Step 4990: train/loss = 0.38131117820739746, train/raw-loss = 0.32780876755714417, train/logprobs = tensor([[-1.6676, -5.8113],
        [-6.6589, -4.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5350239872932434
Epoch 0, Step 4991: train/loss = 0.4792464077472687, train/raw-loss = 0.4478048086166382, train/logprobs = tensor([[-3.1204, -8.7426],
        [-4.2084, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31441640853881836
Epoch 0, Step 4992: train/loss = 0.3919140696525574, train/raw-loss = 0.3440115749835968, train/logprobs = tensor([[-2.3136, -9.2987],
        [-4.3544, -2.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4790247082710266
Epoch 0, Step 4993: train/loss = 0.3095431923866272, train/raw-loss = 0.27103355526924133, train/logprobs = tensor([[-1.3817, -7.9785],
        [-3.7605, -2.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38509660959243774
Epoch 0, Step 4994: train/loss = 0.26272425055503845, train/raw-loss = 0.21934521198272705, train/logprobs = tensor([[-1.2590, -7.1930],
        [-4.7177, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337904751300812
Epoch 0, Step 4995: train/loss = 0.2775459885597229, train/raw-loss = 0.23576170206069946, train/logprobs = tensor([[-1.9516, -3.7076],
        [-5.0058, -2.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4178427457809448
Epoch 0, Step 4996: train/loss = 0.16881975531578064, train/raw-loss = 0.11614785343408585, train/logprobs = tensor([[-1.9364, -9.5700],
        [-6.9864, -4.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5267190933227539
Epoch 0, Step 4997: train/loss = 0.10297998040914536, train/raw-loss = 0.055549513548612595, train/logprobs = tensor([[-1.6844, -9.5896],
        [-6.6027, -4.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4743047058582306
Epoch 0, Step 4998: train/loss = 0.4976285696029663, train/raw-loss = 0.4479573369026184, train/logprobs = tensor([[-1.8769, -5.2694],
        [-5.7870, -4.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4967120289802551
Epoch 0, Step 4999: train/loss = 0.2732347846031189, train/raw-loss = 0.2272014021873474, train/logprobs = tensor([[-1.3909, -6.4629],
        [-5.5743, -4.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46033382415771484
Epoch 0, Step 5000: train/loss = 0.09671763330698013, train/raw-loss = 0.04652683436870575, train/logprobs = tensor([[ -2.4580, -11.9297],
        [ -7.2968,  -3.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5019079446792603
Epoch 0, Step 5001: train/loss = 0.06059844046831131, train/raw-loss = 0.005852222442626953, train/logprobs = tensor([[ -1.7749, -13.9826],
        [ -7.5877,  -6.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5474621653556824
Epoch 0, Step 5002: train/loss = 0.28467100858688354, train/raw-loss = 0.2436777651309967, train/logprobs = tensor([[-1.3751, -5.3517],
        [-4.9656, -3.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4099324941635132
Epoch 0, Step 5003: train/loss = 0.21086275577545166, train/raw-loss = 0.1695055216550827, train/logprobs = tensor([[ -1.3149, -11.1841],
        [ -6.7900,  -3.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4135722517967224
Epoch 0, Step 5004: train/loss = 0.23593400418758392, train/raw-loss = 0.20206080377101898, train/logprobs = tensor([[-2.1031, -3.5531],
        [-5.6652, -1.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3387318253517151
Epoch 0, Step 5005: train/loss = 0.11109846830368042, train/raw-loss = 0.06917566806077957, train/logprobs = tensor([[ -2.2485, -11.0608],
        [ -7.0748,  -2.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4192279875278473
Epoch 0, Step 5006: train/loss = 0.07198923081159592, train/raw-loss = 0.03521522879600525, train/logprobs = tensor([[ -2.4038, -11.7722],
        [ -6.0250,  -3.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3677399754524231
Epoch 0, Step 5007: train/loss = 0.34098297357559204, train/raw-loss = 0.2961171269416809, train/logprobs = tensor([[-1.8199, -7.7372],
        [-6.1654, -4.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44865837693214417
Epoch 0, Step 5008: train/loss = 0.2987770438194275, train/raw-loss = 0.26084965467453003, train/logprobs = tensor([[-1.9657, -5.0648],
        [-3.5642, -1.8474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37927377223968506
Epoch 0, Step 5009: train/loss = 0.701680064201355, train/raw-loss = 0.6581547260284424, train/logprobs = tensor([[-1.7134, -4.1559],
        [-4.2248, -2.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4352536201477051
Epoch 0, Step 5010: train/loss = 0.8703967332839966, train/raw-loss = 0.8293516039848328, train/logprobs = tensor([[-2.7370, -5.0570],
        [-4.8110, -3.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41045132279396057
Epoch 0, Step 5011: train/loss = 0.18496552109718323, train/raw-loss = 0.13839465379714966, train/logprobs = tensor([[-1.9408, -5.9491],
        [-7.1797, -3.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46570879220962524
Epoch 0, Step 5012: train/loss = 0.5249438285827637, train/raw-loss = 0.4800388813018799, train/logprobs = tensor([[ -2.1244, -10.5444],
        [ -4.1635,  -6.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44904956221580505
Epoch 0, Step 5013: train/loss = 0.23375332355499268, train/raw-loss = 0.18973851203918457, train/logprobs = tensor([[ -0.7168, -13.5436],
        [ -4.6002,  -4.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44014808535575867
Epoch 0, Step 5014: train/loss = 0.5119695067405701, train/raw-loss = 0.45196008682250977, train/logprobs = tensor([[-1.3123, -5.4436],
        [-5.0110, -2.8187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6000942587852478
Epoch 0, Step 5015: train/loss = 0.41981056332588196, train/raw-loss = 0.37197354435920715, train/logprobs = tensor([[-1.3581, -9.3561],
        [-4.7030, -4.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47837018966674805
Epoch 0, Step 5016: train/loss = 0.7172409892082214, train/raw-loss = 0.6713600158691406, train/logprobs = tensor([[-1.9966, -4.9096],
        [-4.4070, -2.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4588095545768738
Epoch 0, Step 5017: train/loss = 0.25131237506866455, train/raw-loss = 0.21247749030590057, train/logprobs = tensor([[-2.7024, -6.6510],
        [-5.1326, -2.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3883488178253174
Epoch 0, Step 5018: train/loss = 0.4822791814804077, train/raw-loss = 0.4476909637451172, train/logprobs = tensor([[-2.1755, -5.8014],
        [-4.1701, -2.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34588247537612915
Epoch 0, Step 5019: train/loss = 0.6769058108329773, train/raw-loss = 0.6423555612564087, train/logprobs = tensor([[-3.2897, -4.2036],
        [-4.2409, -3.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34550297260284424
Epoch 0, Step 5020: train/loss = 0.071626678109169, train/raw-loss = 0.028261370956897736, train/logprobs = tensor([[ -1.9390, -15.7354],
        [ -8.1103,  -6.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4336530566215515
Epoch 0, Step 5021: train/loss = 0.15240180492401123, train/raw-loss = 0.10852284729480743, train/logprobs = tensor([[-2.8549, -8.3694],
        [-6.4753, -4.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4387895166873932
Epoch 0, Step 5022: train/loss = 0.22993716597557068, train/raw-loss = 0.188680499792099, train/logprobs = tensor([[-2.2078, -6.0883],
        [-6.6156, -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.412566602230072
Epoch 0, Step 5023: train/loss = 0.12782858312129974, train/raw-loss = 0.076914943754673, train/logprobs = tensor([[-2.7462, -8.8087],
        [-5.7682, -3.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.509136438369751
Epoch 0, Step 5024: train/loss = 0.39916855096817017, train/raw-loss = 0.35380250215530396, train/logprobs = tensor([[-1.9853, -8.3976],
        [-5.5215, -3.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.453660786151886
Epoch 0, Step 5025: train/loss = 0.31820961833000183, train/raw-loss = 0.27737024426460266, train/logprobs = tensor([[-1.5406, -7.3901],
        [-4.8993, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4083935618400574
Epoch 0, Step 5026: train/loss = 0.13983505964279175, train/raw-loss = 0.10278642177581787, train/logprobs = tensor([[-0.9910, -7.2613],
        [-4.0599, -3.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37048637866973877
Epoch 0, Step 5027: train/loss = 0.07878497987985611, train/raw-loss = 0.029865365475416183, train/logprobs = tensor([[ -2.1325, -14.6748],
        [ -5.7516,  -3.2854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48919612169265747
Epoch 0, Step 5028: train/loss = 0.18977078795433044, train/raw-loss = 0.15690520405769348, train/logprobs = tensor([[ -1.5655, -10.4222],
        [ -4.8980,  -3.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32865583896636963
Epoch 0, Step 5029: train/loss = 0.28943774104118347, train/raw-loss = 0.2456941455602646, train/logprobs = tensor([[-2.5024, -9.6445],
        [-7.3060, -3.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4374358355998993
Epoch 0, Step 5030: train/loss = 0.3364028036594391, train/raw-loss = 0.29439955949783325, train/logprobs = tensor([[-1.4966, -4.7116],
        [-5.5769, -3.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4200327396392822
Epoch 0, Step 5031: train/loss = 0.20351514220237732, train/raw-loss = 0.16974343359470367, train/logprobs = tensor([[ -1.6889, -14.5010],
        [ -6.1972,  -6.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3377169370651245
Epoch 0, Step 5032: train/loss = 0.2787829637527466, train/raw-loss = 0.23570305109024048, train/logprobs = tensor([[-1.9867, -5.1727],
        [-6.2858, -2.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.430799275636673
Epoch 0, Step 5033: train/loss = 0.08805688470602036, train/raw-loss = 0.04243730753660202, train/logprobs = tensor([[ -1.4449, -13.2021],
        [ -7.4044,  -6.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4561958312988281
Epoch 0, Step 5034: train/loss = 0.09540710598230362, train/raw-loss = 0.05827425792813301, train/logprobs = tensor([[ -1.8707, -11.3658],
        [ -6.2926,  -3.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3713284730911255
Epoch 0, Step 5035: train/loss = 0.2571791112422943, train/raw-loss = 0.21959154307842255, train/logprobs = tensor([[-1.4524, -6.7570],
        [-4.8434, -2.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37587568163871765
Epoch 0, Step 5036: train/loss = 0.14942312240600586, train/raw-loss = 0.11774138361215591, train/logprobs = tensor([[-2.6389, -9.8266],
        [-4.4655, -2.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3168173134326935
Epoch 0, Step 5037: train/loss = 0.5206414461135864, train/raw-loss = 0.4813592731952667, train/logprobs = tensor([[-1.6884, -9.9471],
        [-4.8437, -6.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39282190799713135
Epoch 0, Step 5038: train/loss = 0.13290172815322876, train/raw-loss = 0.09691264480352402, train/logprobs = tensor([[ -1.7475, -12.6295],
        [ -5.4719,  -5.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598906993865967
Epoch 0, Step 5039: train/loss = 0.2336813062429428, train/raw-loss = 0.18768951296806335, train/logprobs = tensor([[ -1.4392, -10.6479],
        [ -6.5237,  -5.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45991820096969604
Epoch 0, Step 5040: train/loss = 0.056535057723522186, train/raw-loss = 0.008066854439675808, train/logprobs = tensor([[ -1.5970, -12.8818],
        [ -6.5668,  -4.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48468202352523804
Epoch 0, Step 5041: train/loss = 0.39804819226264954, train/raw-loss = 0.3373672068119049, train/logprobs = tensor([[-1.4664, -6.3320],
        [-6.8948, -3.4211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6068097352981567
Epoch 0, Step 5042: train/loss = 0.2995508015155792, train/raw-loss = 0.2717599868774414, train/logprobs = tensor([[-2.1906, -7.8829],
        [-4.9502, -4.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27790820598602295
Epoch 0, Step 5043: train/loss = 0.5035951137542725, train/raw-loss = 0.466047465801239, train/logprobs = tensor([[-2.2106, -6.2105],
        [-4.0431, -3.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754764497280121
Epoch 0, Step 5044: train/loss = 0.17267990112304688, train/raw-loss = 0.1324574202299118, train/logprobs = tensor([[ -1.1618, -12.2376],
        [ -5.2181,  -5.8724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4022248685359955
Epoch 0, Step 5045: train/loss = 0.2743483781814575, train/raw-loss = 0.2363111525774002, train/logprobs = tensor([[-2.5028, -7.8682],
        [-3.8340, -4.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3803723454475403
Epoch 0, Step 5046: train/loss = 0.12388213723897934, train/raw-loss = 0.0824529305100441, train/logprobs = tensor([[-1.3844, -6.5589],
        [-5.9505, -2.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41429203748703003
Epoch 0, Step 5047: train/loss = 0.15412700176239014, train/raw-loss = 0.10738620162010193, train/logprobs = tensor([[-1.6371, -4.4195],
        [-7.2584, -2.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46740806102752686
Epoch 0, Step 5048: train/loss = 0.26720160245895386, train/raw-loss = 0.22087626159191132, train/logprobs = tensor([[ -1.2661, -11.4876],
        [ -6.2603,  -4.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46325352787971497
Epoch 0, Step 5049: train/loss = 0.5051659941673279, train/raw-loss = 0.4609858989715576, train/logprobs = tensor([[-1.7674, -8.7358],
        [-4.9587, -3.4217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44180116057395935
Epoch 0, Step 5050: train/loss = 0.29020434617996216, train/raw-loss = 0.2520899474620819, train/logprobs = tensor([[-1.4962, -6.7387],
        [-5.3098, -2.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38114404678344727
Epoch 0, Step 5051: train/loss = 0.7997568845748901, train/raw-loss = 0.7618842124938965, train/logprobs = tensor([[-2.0520, -2.2973],
        [-3.0187, -2.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378726601600647
Epoch 0, Step 5052: train/loss = 0.21818068623542786, train/raw-loss = 0.16828195750713348, train/logprobs = tensor([[ -1.5396, -14.4042],
        [ -6.2790,  -6.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4989873170852661
Epoch 0, Step 5053: train/loss = 0.06633912026882172, train/raw-loss = 0.019766585901379585, train/logprobs = tensor([[-1.5431, -6.5327],
        [-6.5425, -1.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4657253324985504
Epoch 0, Step 5054: train/loss = 0.05037672817707062, train/raw-loss = 0.003348757280036807, train/logprobs = tensor([[ -1.5704, -14.9528],
        [ -7.1211,  -6.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4702796936035156
Epoch 0, Step 5055: train/loss = 0.26575860381126404, train/raw-loss = 0.22566333413124084, train/logprobs = tensor([[-1.5108, -7.6268],
        [-4.5153, -2.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4009525775909424
Epoch 0, Step 5056: train/loss = 0.3053031265735626, train/raw-loss = 0.2554243803024292, train/logprobs = tensor([[ -1.2285, -11.1019],
        [ -6.7181,  -5.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.498787522315979
Epoch 0, Step 5057: train/loss = 0.17343449592590332, train/raw-loss = 0.13923054933547974, train/logprobs = tensor([[ -1.3763, -11.6683],
        [ -5.8648,  -6.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3420395851135254
Epoch 0, Step 5058: train/loss = 0.4280208349227905, train/raw-loss = 0.3876556158065796, train/logprobs = tensor([[-1.2427, -5.4192],
        [-4.6302, -2.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4036521911621094
Epoch 0, Step 5059: train/loss = 0.3919816017150879, train/raw-loss = 0.3477236032485962, train/logprobs = tensor([[-2.0262, -9.0557],
        [-4.5747, -3.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4425801634788513
Epoch 0, Step 5060: train/loss = 0.4652585983276367, train/raw-loss = 0.42527586221694946, train/logprobs = tensor([[-1.5513, -4.6077],
        [-4.5641, -3.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998275399208069
Epoch 0, Step 5061: train/loss = 0.23927918076515198, train/raw-loss = 0.19687309861183167, train/logprobs = tensor([[-2.0121, -6.0990],
        [-5.8694, -3.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42406076192855835
Epoch 0, Step 5062: train/loss = 0.7035124897956848, train/raw-loss = 0.6419299840927124, train/logprobs = tensor([[-1.1944, -7.6853],
        [-6.3403, -4.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6158251762390137
Epoch 0, Step 5063: train/loss = 0.20657770335674286, train/raw-loss = 0.16739565134048462, train/logprobs = tensor([[-2.5215, -7.9039],
        [-7.4660, -2.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3918205499649048
Epoch 0, Step 5064: train/loss = 0.496486097574234, train/raw-loss = 0.4576185345649719, train/logprobs = tensor([[-2.0036, -6.3695],
        [-4.4896, -2.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3886758089065552
Epoch 0, Step 5065: train/loss = 0.19175134599208832, train/raw-loss = 0.15771052241325378, train/logprobs = tensor([[-1.6332, -7.6862],
        [-5.5188, -2.2278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34040820598602295
Epoch 0, Step 5066: train/loss = 0.43627268075942993, train/raw-loss = 0.39616668224334717, train/logprobs = tensor([[-3.0589, -6.5867],
        [-6.7017, -2.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40105968713760376
Epoch 0, Step 5067: train/loss = 0.2548956274986267, train/raw-loss = 0.20702950656414032, train/logprobs = tensor([[-1.4538, -7.2695],
        [-7.1592, -3.4532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4786612391471863
Epoch 0, Step 5068: train/loss = 0.14886274933815002, train/raw-loss = 0.10649681091308594, train/logprobs = tensor([[-1.6733, -7.2326],
        [-4.8862, -2.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42365938425064087
Epoch 0, Step 5069: train/loss = 0.10465529561042786, train/raw-loss = 0.052085522562265396, train/logprobs = tensor([[ -1.9248, -18.9438],
        [ -7.2452,  -8.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5256977081298828
Epoch 0, Step 5070: train/loss = 0.3470003008842468, train/raw-loss = 0.30395740270614624, train/logprobs = tensor([[-2.1911, -4.8826],
        [-6.9217, -3.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43042922019958496
Epoch 0, Step 5071: train/loss = 0.5739796757698059, train/raw-loss = 0.528814435005188, train/logprobs = tensor([[-1.8379, -4.8883],
        [-4.8543, -3.1892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4516527056694031
Epoch 0, Step 5072: train/loss = 0.397626668214798, train/raw-loss = 0.36334002017974854, train/logprobs = tensor([[-1.9512, -4.8165],
        [-4.7705, -2.2683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34286680817604065
Epoch 0, Step 5073: train/loss = 0.26806318759918213, train/raw-loss = 0.2254907190799713, train/logprobs = tensor([[-1.8898, -5.0080],
        [-5.6327, -2.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42572447657585144
Epoch 0, Step 5074: train/loss = 0.49561378359794617, train/raw-loss = 0.46241167187690735, train/logprobs = tensor([[-2.5163, -5.0878],
        [-4.4059, -2.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33202114701271057
Epoch 0, Step 5075: train/loss = 0.4276213049888611, train/raw-loss = 0.3883143961429596, train/logprobs = tensor([[-1.5708, -4.1223],
        [-5.3751, -3.9766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39306923747062683
Epoch 0, Step 5076: train/loss = 0.5500754117965698, train/raw-loss = 0.5093377828598022, train/logprobs = tensor([[-1.2433, -2.9815],
        [-4.0202, -2.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40737640857696533
Epoch 0, Step 5077: train/loss = 0.18196910619735718, train/raw-loss = 0.13874007761478424, train/logprobs = tensor([[-2.1591, -5.5572],
        [-5.5867, -2.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43229037523269653
Epoch 0, Step 5078: train/loss = 0.7075914144515991, train/raw-loss = 0.668776273727417, train/logprobs = tensor([[-1.9402, -5.2757],
        [-4.2321, -2.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3881521224975586
Epoch 0, Step 5079: train/loss = 0.29231947660446167, train/raw-loss = 0.24959105253219604, train/logprobs = tensor([[-2.1263, -5.4617],
        [-6.2950, -2.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.427284300327301
Epoch 0, Step 5080: train/loss = 0.1516110897064209, train/raw-loss = 0.10528100281953812, train/logprobs = tensor([[-1.3846, -7.5495],
        [-6.0674, -1.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4633008539676666
Epoch 0, Step 5081: train/loss = 0.1569131761789322, train/raw-loss = 0.10872504860162735, train/logprobs = tensor([[-1.9370, -6.3875],
        [-6.5242, -2.8416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4818812310695648
Epoch 0, Step 5082: train/loss = 0.31597208976745605, train/raw-loss = 0.27394598722457886, train/logprobs = tensor([[-1.9067, -7.3997],
        [-7.2548, -3.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4202612638473511
Epoch 0, Step 5083: train/loss = 0.15223588049411774, train/raw-loss = 0.11292104423046112, train/logprobs = tensor([[-2.0908, -4.7094],
        [-6.3997, -2.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931483030319214
Epoch 0, Step 5084: train/loss = 0.2554381191730499, train/raw-loss = 0.21465417742729187, train/logprobs = tensor([[-2.4302, -7.2725],
        [-4.8979, -2.5122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40783941745758057
Epoch 0, Step 5085: train/loss = 0.10326829552650452, train/raw-loss = 0.0547000877559185, train/logprobs = tensor([[ -1.8514, -13.9812],
        [ -6.6623,  -6.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48568207025527954
Epoch 0, Step 5086: train/loss = 0.3437102437019348, train/raw-loss = 0.30014902353286743, train/logprobs = tensor([[-2.1189, -4.6045],
        [-5.6613, -3.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4356122612953186
Epoch 0, Step 5087: train/loss = 0.20793165266513824, train/raw-loss = 0.16864259541034698, train/logprobs = tensor([[-1.5762, -8.2619],
        [-4.4913, -2.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39289048314094543
Epoch 0, Step 5088: train/loss = 0.24770525097846985, train/raw-loss = 0.20165887475013733, train/logprobs = tensor([[ -2.0594, -10.6747],
        [ -5.6041,  -4.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4604637622833252
Epoch 0, Step 5089: train/loss = 0.13808856904506683, train/raw-loss = 0.10107564181089401, train/logprobs = tensor([[ -1.5425, -13.9367],
        [ -5.3656,  -6.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.370129257440567
Epoch 0, Step 5090: train/loss = 0.5054290890693665, train/raw-loss = 0.4612511992454529, train/logprobs = tensor([[-1.8335, -8.5363],
        [-6.5711, -4.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44177892804145813
Epoch 0, Step 5091: train/loss = 0.19935612380504608, train/raw-loss = 0.15556515753269196, train/logprobs = tensor([[-1.9044, -9.2346],
        [-6.0681, -4.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4379095733165741
Epoch 0, Step 5092: train/loss = 0.4025813043117523, train/raw-loss = 0.3696853518486023, train/logprobs = tensor([[ -3.4953, -10.4600],
        [ -5.0135,  -3.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32895925641059875
Epoch 0, Step 5093: train/loss = 0.19777558743953705, train/raw-loss = 0.15558657050132751, train/logprobs = tensor([[ -1.3519, -10.3569],
        [ -5.7242,  -4.3312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4218900799751282
Epoch 0, Step 5094: train/loss = 0.24149933457374573, train/raw-loss = 0.20264163613319397, train/logprobs = tensor([[ -2.5845, -10.4598],
        [ -7.4755,  -3.0513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3885769248008728
Epoch 0, Step 5095: train/loss = 0.4691696763038635, train/raw-loss = 0.43198394775390625, train/logprobs = tensor([[-1.7356, -7.0428],
        [-6.5681, -3.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37185701727867126
Epoch 0, Step 5096: train/loss = 0.3016154170036316, train/raw-loss = 0.26520657539367676, train/logprobs = tensor([[-3.7012, -5.0351],
        [-7.6546, -2.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36408817768096924
Epoch 0, Step 5097: train/loss = 0.04423798620700836, train/raw-loss = 0.008842875249683857, train/logprobs = tensor([[ -1.5918, -14.6906],
        [ -7.2690,  -6.4412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3539511263370514
Epoch 0, Step 5098: train/loss = 0.5230745673179626, train/raw-loss = 0.4793538749217987, train/logprobs = tensor([[-1.5449, -7.9042],
        [-6.1994, -2.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43720686435699463
Epoch 0, Step 5099: train/loss = 0.5240858197212219, train/raw-loss = 0.47936898469924927, train/logprobs = tensor([[-1.6211, -4.5911],
        [-3.5592, -3.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44716760516166687
Epoch 0, Step 5100: train/loss = 0.31848588585853577, train/raw-loss = 0.2684728801250458, train/logprobs = tensor([[-1.3348, -5.7515],
        [-6.2630, -3.1661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001301765441895
Epoch 0, Step 5101: train/loss = 0.6579943895339966, train/raw-loss = 0.6198805570602417, train/logprobs = tensor([[-1.3454, -3.5028],
        [-3.9704, -4.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38113853335380554
Epoch 0, Step 5102: train/loss = 0.17706172168254852, train/raw-loss = 0.1392212212085724, train/logprobs = tensor([[ -1.6246, -12.4673],
        [ -6.4759,  -1.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784051835536957
Epoch 0, Step 5103: train/loss = 0.712126612663269, train/raw-loss = 0.6569787859916687, train/logprobs = tensor([[-2.3684, -8.7084],
        [-5.8815, -4.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5514780282974243
Epoch 0, Step 5104: train/loss = 0.0653979480266571, train/raw-loss = 0.020874204114079475, train/logprobs = tensor([[ -2.1769, -15.0638],
        [ -6.8384,  -5.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4452374279499054
Epoch 0, Step 5105: train/loss = 0.38465291261672974, train/raw-loss = 0.3364308774471283, train/logprobs = tensor([[-1.5809, -4.7894],
        [-5.7290, -3.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48222047090530396
Epoch 0, Step 5106: train/loss = 0.2752992510795593, train/raw-loss = 0.23392856121063232, train/logprobs = tensor([[-1.6422, -9.4639],
        [-5.6849, -3.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41370686888694763
Epoch 0, Step 5107: train/loss = 0.40425723791122437, train/raw-loss = 0.36832180619239807, train/logprobs = tensor([[-1.6488, -6.6799],
        [-4.0364, -3.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35935431718826294
Epoch 0, Step 5108: train/loss = 0.324959933757782, train/raw-loss = 0.28506624698638916, train/logprobs = tensor([[-1.3377, -6.4400],
        [-4.0548, -1.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3989371359348297
Epoch 0, Step 5109: train/loss = 0.19593027234077454, train/raw-loss = 0.1469213217496872, train/logprobs = tensor([[-1.1707, -6.2172],
        [-5.6671, -2.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.490089476108551
Epoch 0, Step 5110: train/loss = 0.14535123109817505, train/raw-loss = 0.10102703422307968, train/logprobs = tensor([[ -1.7610, -10.1982],
        [ -5.9476,  -3.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44324198365211487
Epoch 0, Step 5111: train/loss = 0.33981698751449585, train/raw-loss = 0.29190635681152344, train/logprobs = tensor([[-1.1680, -5.4438],
        [-5.5903, -4.3389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47910669445991516
Epoch 0, Step 5112: train/loss = 0.3293733298778534, train/raw-loss = 0.28481465578079224, train/logprobs = tensor([[-2.1096, -5.5656],
        [-5.3547, -2.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44558703899383545
Epoch 0, Step 5113: train/loss = 0.8971124291419983, train/raw-loss = 0.8474549055099487, train/logprobs = tensor([[-1.5387, -6.1559],
        [-7.1139, -6.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4965750277042389
Epoch 0, Step 5114: train/loss = 0.08887387067079544, train/raw-loss = 0.036419279873371124, train/logprobs = tensor([[ -1.6770, -11.2374],
        [ -7.0025,  -2.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5245459079742432
Epoch 0, Step 5115: train/loss = 0.7113853693008423, train/raw-loss = 0.6697911024093628, train/logprobs = tensor([[-2.9946, -4.5588],
        [-4.8584, -3.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41594305634498596
Epoch 0, Step 5116: train/loss = 0.2629990875720978, train/raw-loss = 0.22187750041484833, train/logprobs = tensor([[-1.7820, -7.7965],
        [-6.9510, -3.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112159013748169
Epoch 0, Step 5117: train/loss = 0.5736008286476135, train/raw-loss = 0.5231546759605408, train/logprobs = tensor([[-1.5816, -8.3456],
        [-7.7966, -4.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5044615268707275
Epoch 0, Step 5118: train/loss = 0.04600800946354866, train/raw-loss = 0.009065910242497921, train/logprobs = tensor([[-1.9890, -9.4153],
        [-7.9736, -4.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36942097544670105
Epoch 0, Step 5119: train/loss = 0.15574237704277039, train/raw-loss = 0.11500038951635361, train/logprobs = tensor([[ -1.1054, -13.6389],
        [ -5.5979,  -3.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.407419890165329
Epoch 0, Step 5120: train/loss = 0.3398311138153076, train/raw-loss = 0.3038884401321411, train/logprobs = tensor([[ -1.8170, -13.4010],
        [ -6.6860,  -7.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3594264090061188
Epoch 0, Step 5121: train/loss = 0.4177112579345703, train/raw-loss = 0.3804173171520233, train/logprobs = tensor([[-1.4000, -6.0442],
        [-5.1989, -5.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37293970584869385
Epoch 0, Step 5122: train/loss = 0.2860833406448364, train/raw-loss = 0.24458205699920654, train/logprobs = tensor([[-1.4828, -5.7357],
        [-6.5216, -3.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41501301527023315
Epoch 0, Step 5123: train/loss = 0.10155923664569855, train/raw-loss = 0.05774188041687012, train/logprobs = tensor([[ -1.4652, -11.5816],
        [ -6.8283,  -6.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4381735622882843
Epoch 0, Step 5124: train/loss = 0.6178404092788696, train/raw-loss = 0.5744478106498718, train/logprobs = tensor([[-1.7775, -8.1061],
        [-5.6120, -6.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43392622470855713
Epoch 0, Step 5125: train/loss = 0.5891343951225281, train/raw-loss = 0.5444849729537964, train/logprobs = tensor([[-2.2133, -7.6770],
        [-5.2281, -4.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4464939832687378
Epoch 0, Step 5126: train/loss = 0.5798726081848145, train/raw-loss = 0.5279436707496643, train/logprobs = tensor([[ -1.3769, -11.9306],
        [ -7.7637,  -7.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5192897319793701
Epoch 0, Step 5127: train/loss = 0.47320181131362915, train/raw-loss = 0.43111446499824524, train/logprobs = tensor([[-2.8718, -7.1149],
        [-4.6314, -1.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4208735227584839
Epoch 0, Step 5128: train/loss = 0.2882115840911865, train/raw-loss = 0.2530615031719208, train/logprobs = tensor([[-2.4138, -6.6510],
        [-5.1961, -3.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3515009582042694
Epoch 0, Step 5129: train/loss = 0.05507471039891243, train/raw-loss = 0.005210036877542734, train/logprobs = tensor([[ -1.6930, -11.8818],
        [ -6.9943,  -2.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49864673614501953
Epoch 0, Step 5130: train/loss = 0.9961183071136475, train/raw-loss = 0.9471143484115601, train/logprobs = tensor([[-2.3932, -9.5329],
        [-4.8343, -6.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4900388717651367
Epoch 0, Step 5131: train/loss = 0.4274013638496399, train/raw-loss = 0.38132935762405396, train/logprobs = tensor([[-2.0188, -7.0510],
        [-3.9950, -2.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4607197940349579
Epoch 0, Step 5132: train/loss = 0.2778063416481018, train/raw-loss = 0.23502206802368164, train/logprobs = tensor([[ -1.9870, -11.0052],
        [ -8.2834,  -5.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42784279584884644
Epoch 0, Step 5133: train/loss = 0.4373466968536377, train/raw-loss = 0.38867080211639404, train/logprobs = tensor([[-2.6815, -6.0754],
        [-4.5264, -2.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48675891757011414
Epoch 0, Step 5134: train/loss = 0.37847793102264404, train/raw-loss = 0.34580543637275696, train/logprobs = tensor([[-1.5669, -8.5444],
        [-4.9543, -3.4907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267248570919037
Epoch 0, Step 5135: train/loss = 0.485049843788147, train/raw-loss = 0.43134522438049316, train/logprobs = tensor([[-1.5952, -4.4247],
        [-6.7921, -3.3448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.537045955657959
Epoch 0, Step 5136: train/loss = 0.3910924792289734, train/raw-loss = 0.34534838795661926, train/logprobs = tensor([[-2.6435, -5.6418],
        [-5.5801, -3.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45744097232818604
Epoch 0, Step 5137: train/loss = 0.16859552264213562, train/raw-loss = 0.1349342167377472, train/logprobs = tensor([[-2.0984, -9.2029],
        [-4.7616, -3.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3366130590438843
Epoch 0, Step 5138: train/loss = 0.36489763855934143, train/raw-loss = 0.3084007799625397, train/logprobs = tensor([[-1.6985, -7.3409],
        [-7.1756, -3.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.564968466758728
Epoch 0, Step 5139: train/loss = 0.7231256365776062, train/raw-loss = 0.685923159122467, train/logprobs = tensor([[-2.2338, -4.7990],
        [-4.3132, -3.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3720241189002991
Epoch 0, Step 5140: train/loss = 0.37636715173721313, train/raw-loss = 0.3343133330345154, train/logprobs = tensor([[ -3.3122, -12.2488],
        [ -5.5361,  -5.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4205380380153656
Epoch 0, Step 5141: train/loss = 0.516045331954956, train/raw-loss = 0.4779437780380249, train/logprobs = tensor([[-0.9088, -4.2507],
        [-3.5531, -2.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38101518154144287
Epoch 0, Step 5142: train/loss = 0.07324777543544769, train/raw-loss = 0.023742040619254112, train/logprobs = tensor([[ -1.5468, -14.0094],
        [ -4.9926,  -4.3993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4950573444366455
Epoch 0, Step 5143: train/loss = 0.3645913600921631, train/raw-loss = 0.3133935332298279, train/logprobs = tensor([[-3.6992, -8.1402],
        [-6.3160, -5.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5119784474372864
Epoch 0, Step 5144: train/loss = 0.4084879159927368, train/raw-loss = 0.3538813889026642, train/logprobs = tensor([[ -2.4064, -11.2304],
        [ -7.4718,  -8.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5460654497146606
Epoch 0, Step 5145: train/loss = 0.3088073134422302, train/raw-loss = 0.26860612630844116, train/logprobs = tensor([[-1.7810, -9.7809],
        [-5.4884, -3.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40201184153556824
Epoch 0, Step 5146: train/loss = 0.20823177695274353, train/raw-loss = 0.16150793433189392, train/logprobs = tensor([[-1.9000, -5.8264],
        [-7.2238, -3.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46723830699920654
Epoch 0, Step 5147: train/loss = 0.5817704200744629, train/raw-loss = 0.5265756845474243, train/logprobs = tensor([[-1.5232, -8.9302],
        [-4.9338, -3.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5519474744796753
Epoch 0, Step 5148: train/loss = 0.4746009409427643, train/raw-loss = 0.42837733030319214, train/logprobs = tensor([[-1.7842, -4.3782],
        [-4.9805, -3.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4622361660003662
Epoch 0, Step 5149: train/loss = 0.3673316538333893, train/raw-loss = 0.32304397225379944, train/logprobs = tensor([[-2.0287, -7.9415],
        [-5.1739, -3.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44287702441215515
Epoch 0, Step 5150: train/loss = 0.10535142570734024, train/raw-loss = 0.07132351398468018, train/logprobs = tensor([[-1.7567, -6.4955],
        [-6.4678, -2.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34027910232543945
Epoch 0, Step 5151: train/loss = 0.08466479182243347, train/raw-loss = 0.04126027598977089, train/logprobs = tensor([[-1.7962, -7.1958],
        [-6.6274, -2.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43404507637023926
Epoch 0, Step 5152: train/loss = 0.3474496901035309, train/raw-loss = 0.3120967447757721, train/logprobs = tensor([[-1.2674, -6.5523],
        [-4.6219, -1.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3535290062427521
Epoch 0, Step 5153: train/loss = 0.3179924786090851, train/raw-loss = 0.2803505063056946, train/logprobs = tensor([[-1.0248, -4.5063],
        [-4.1295, -3.7793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3764195740222931
Epoch 0, Step 5154: train/loss = 0.6988779902458191, train/raw-loss = 0.6466555595397949, train/logprobs = tensor([[-1.0533, -4.7491],
        [-5.4251, -3.3131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5222242474555969
Epoch 0, Step 5155: train/loss = 0.1376367062330246, train/raw-loss = 0.10452751070261002, train/logprobs = tensor([[ -1.5786, -10.0654],
        [ -4.6867,  -4.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310919404029846
Epoch 0, Step 5156: train/loss = 0.5187389254570007, train/raw-loss = 0.4838178753852844, train/logprobs = tensor([[ -3.7892, -10.3210],
        [ -4.5312,  -2.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3492102324962616
Epoch 0, Step 5157: train/loss = 0.42326346039772034, train/raw-loss = 0.36733904480934143, train/logprobs = tensor([[-1.5077, -6.3515],
        [-7.2278, -3.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5592441558837891
Epoch 0, Step 5158: train/loss = 0.339494526386261, train/raw-loss = 0.28785115480422974, train/logprobs = tensor([[-1.4385, -7.7680],
        [-6.1535, -4.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5164339542388916
Epoch 0, Step 5159: train/loss = 0.3112089931964874, train/raw-loss = 0.2718586325645447, train/logprobs = tensor([[ -2.4127, -10.8452],
        [ -6.2152,  -5.6448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39350372552871704
Epoch 0, Step 5160: train/loss = 0.28363099694252014, train/raw-loss = 0.2390628159046173, train/logprobs = tensor([[-1.5123, -4.1120],
        [-5.9830, -2.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4456818103790283
Epoch 0, Step 5161: train/loss = 0.2834457755088806, train/raw-loss = 0.2482443004846573, train/logprobs = tensor([[-1.6117, -6.1734],
        [-5.9510, -2.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35201454162597656
Epoch 0, Step 5162: train/loss = 0.8802118301391602, train/raw-loss = 0.8372462391853333, train/logprobs = tensor([[-2.1547, -3.6360],
        [-5.4818, -4.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42965584993362427
Epoch 0, Step 5163: train/loss = 0.0413510724902153, train/raw-loss = 0.004611904267221689, train/logprobs = tensor([[ -1.5468, -14.2660],
        [ -6.8786,  -4.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3673916757106781
Epoch 0, Step 5164: train/loss = 0.0627904012799263, train/raw-loss = 0.029010221362113953, train/logprobs = tensor([[ -1.0990, -12.7896],
        [ -4.9769,  -5.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378017842769623
Epoch 0, Step 5165: train/loss = 0.8824393153190613, train/raw-loss = 0.8368006348609924, train/logprobs = tensor([[-1.7527, -3.7581],
        [-5.5008, -4.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4563874304294586
Epoch 0, Step 5166: train/loss = 0.3637421429157257, train/raw-loss = 0.3267171382904053, train/logprobs = tensor([[-1.8079, -5.8442],
        [-4.1066, -3.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37025022506713867
Epoch 0, Step 5167: train/loss = 0.20119449496269226, train/raw-loss = 0.1691923886537552, train/logprobs = tensor([[-1.5194, -3.8048],
        [-5.4797, -2.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32002103328704834
Epoch 0, Step 5168: train/loss = 0.29858556389808655, train/raw-loss = 0.26211947202682495, train/logprobs = tensor([[-2.4881, -5.0350],
        [-5.9257, -2.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3646606504917145
Epoch 0, Step 5169: train/loss = 0.07729272544384003, train/raw-loss = 0.03398939222097397, train/logprobs = tensor([[-1.8198, -6.9590],
        [-5.4214, -2.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.433033287525177
Epoch 0, Step 5170: train/loss = 1.0545843839645386, train/raw-loss = 1.0025663375854492, train/logprobs = tensor([[-1.7878, -2.5360],
        [-6.9047, -5.3364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.520180881023407
Epoch 0, Step 5171: train/loss = 0.11728624999523163, train/raw-loss = 0.07907506823539734, train/logprobs = tensor([[ -2.3227, -11.7724],
        [ -5.2559,  -1.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38211172819137573
Epoch 0, Step 5172: train/loss = 0.4458635449409485, train/raw-loss = 0.40259695053100586, train/logprobs = tensor([[-2.1034, -6.3172],
        [-5.1468, -4.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.432666152715683
Epoch 0, Step 5173: train/loss = 0.0992516279220581, train/raw-loss = 0.07039283215999603, train/logprobs = tensor([[-1.8400, -4.5639],
        [-5.4011, -1.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2885879576206207
Epoch 0, Step 5174: train/loss = 0.5924762487411499, train/raw-loss = 0.5386062860488892, train/logprobs = tensor([[-1.6631, -5.3360],
        [-5.8740, -4.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5387004017829895
Epoch 0, Step 5175: train/loss = 0.4254853129386902, train/raw-loss = 0.3765093982219696, train/logprobs = tensor([[-1.4529, -7.6023],
        [-4.5773, -3.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.489759236574173
Epoch 0, Step 5176: train/loss = 0.6310930848121643, train/raw-loss = 0.6015661954879761, train/logprobs = tensor([[-1.6829, -4.2500],
        [-3.1474, -1.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952689826488495
Epoch 0, Step 5177: train/loss = 0.5782879590988159, train/raw-loss = 0.5338518023490906, train/logprobs = tensor([[-1.7480, -4.1265],
        [-4.0695, -3.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44436198472976685
Epoch 0, Step 5178: train/loss = 0.9902809262275696, train/raw-loss = 0.9426012635231018, train/logprobs = tensor([[-1.6524, -1.9650],
        [-4.2635, -4.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47679734230041504
Epoch 0, Step 5179: train/loss = 0.30216705799102783, train/raw-loss = 0.2651452422142029, train/logprobs = tensor([[-1.5806, -6.7024],
        [-3.9410, -3.2755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37021780014038086
Epoch 0, Step 5180: train/loss = 0.17219164967536926, train/raw-loss = 0.13279563188552856, train/logprobs = tensor([[-1.6093, -5.7241],
        [-8.1173, -2.2472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39396020770072937
Epoch 0, Step 5181: train/loss = 0.2832450866699219, train/raw-loss = 0.2356332540512085, train/logprobs = tensor([[-1.7709, -8.0377],
        [-5.1855, -3.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4761182963848114
Epoch 0, Step 5182: train/loss = 0.13387565314769745, train/raw-loss = 0.0930459275841713, train/logprobs = tensor([[ -2.0279, -13.1283],
        [ -7.3217,  -5.4888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4082973003387451
Epoch 0, Step 5183: train/loss = 0.5316815376281738, train/raw-loss = 0.49426305294036865, train/logprobs = tensor([[-1.8485, -5.8669],
        [-4.7760, -2.2807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741849958896637
Epoch 0, Step 5184: train/loss = 0.11823764443397522, train/raw-loss = 0.08337073028087616, train/logprobs = tensor([[-1.2014, -9.2737],
        [-4.2800, -5.9364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.348669171333313
Epoch 0, Step 5185: train/loss = 0.14573347568511963, train/raw-loss = 0.09599670767784119, train/logprobs = tensor([[-1.5407, -9.4483],
        [-7.4756, -4.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49736762046813965
Epoch 0, Step 5186: train/loss = 0.41149285435676575, train/raw-loss = 0.36919209361076355, train/logprobs = tensor([[-1.7133, -3.8015],
        [-5.3064, -2.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.423007071018219
Epoch 0, Step 5187: train/loss = 0.2921682298183441, train/raw-loss = 0.24485144019126892, train/logprobs = tensor([[ -1.0341, -10.3175],
        [ -4.6305,  -2.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.473168283700943
Epoch 0, Step 5188: train/loss = 0.5378386378288269, train/raw-loss = 0.4944831430912018, train/logprobs = tensor([[-1.0032, -5.3824],
        [-4.5967, -2.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43355515599250793
Epoch 0, Step 5189: train/loss = 0.7358312606811523, train/raw-loss = 0.6902358531951904, train/logprobs = tensor([[-1.8971, -3.9902],
        [-4.9840, -3.3521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45595431327819824
Epoch 0, Step 5190: train/loss = 0.29740437865257263, train/raw-loss = 0.26469290256500244, train/logprobs = tensor([[-1.3457, -4.2312],
        [-3.6987, -1.4425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32711485028266907
Epoch 0, Step 5191: train/loss = 0.2976192235946655, train/raw-loss = 0.26253578066825867, train/logprobs = tensor([[-1.6028, -9.7263],
        [-4.5420, -4.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35083436965942383
Epoch 0, Step 5192: train/loss = 0.08666419982910156, train/raw-loss = 0.04030025750398636, train/logprobs = tensor([[-1.6567, -9.8921],
        [-7.5789, -3.2907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46363937854766846
Epoch 0, Step 5193: train/loss = 0.6511372327804565, train/raw-loss = 0.5973189473152161, train/logprobs = tensor([[-1.2930, -4.9992],
        [-5.8138, -4.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5381823182106018
Epoch 0, Step 5194: train/loss = 0.2477114498615265, train/raw-loss = 0.2070191502571106, train/logprobs = tensor([[-2.3056, -8.2625],
        [-3.5970, -1.7194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069230556488037
Epoch 0, Step 5195: train/loss = 0.09263932704925537, train/raw-loss = 0.052398037165403366, train/logprobs = tensor([[ -1.2135, -10.7341],
        [ -5.8803,  -5.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40241295099258423
Epoch 0, Step 5196: train/loss = 0.4929370582103729, train/raw-loss = 0.4547615051269531, train/logprobs = tensor([[-1.7728, -4.9076],
        [-3.1070, -3.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.381755530834198
Epoch 0, Step 5197: train/loss = 0.5164697766304016, train/raw-loss = 0.47879672050476074, train/logprobs = tensor([[-2.9527, -7.5853],
        [-6.7346, -3.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37673068046569824
Epoch 0, Step 5198: train/loss = 0.5654870271682739, train/raw-loss = 0.5166434049606323, train/logprobs = tensor([[-2.1841, -6.9243],
        [-5.1934, -4.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48843640089035034
Epoch 0, Step 5199: train/loss = 0.4043727219104767, train/raw-loss = 0.3557773232460022, train/logprobs = tensor([[-2.0658, -6.5864],
        [-5.2094, -3.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4859539866447449
Epoch 0, Step 5200: train/loss = 0.05940529704093933, train/raw-loss = 0.005781724117696285, train/logprobs = tensor([[ -2.3550, -23.5391],
        [ -7.8634,  -4.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5362356901168823
Epoch 0, Step 5201: train/loss = 0.33839860558509827, train/raw-loss = 0.2968243360519409, train/logprobs = tensor([[-1.2993, -2.9906],
        [-5.5613, -1.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4157426953315735
Epoch 0, Step 5202: train/loss = 0.24523858726024628, train/raw-loss = 0.2069787085056305, train/logprobs = tensor([[-1.5888, -9.3342],
        [-5.9923, -2.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38259875774383545
Epoch 0, Step 5203: train/loss = 0.5736406445503235, train/raw-loss = 0.5281541347503662, train/logprobs = tensor([[-1.2295, -3.3599],
        [-4.5239, -3.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45486512780189514
Epoch 0, Step 5204: train/loss = 0.8378859758377075, train/raw-loss = 0.7923156023025513, train/logprobs = tensor([[-1.4324, -3.1859],
        [-5.5977, -4.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4557035267353058
Epoch 0, Step 5205: train/loss = 0.35539546608924866, train/raw-loss = 0.3194473683834076, train/logprobs = tensor([[-1.7778, -6.3880],
        [-4.9009, -2.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35948094725608826
Epoch 0, Step 5206: train/loss = 0.4675447940826416, train/raw-loss = 0.42214664816856384, train/logprobs = tensor([[-1.2439, -6.3228],
        [-5.6841, -2.6720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4539817273616791
Epoch 0, Step 5207: train/loss = 0.06123467534780502, train/raw-loss = 0.012401659041643143, train/logprobs = tensor([[ -1.2678, -10.8528],
        [ -7.0422,  -2.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4883301556110382
Epoch 0, Step 5208: train/loss = 0.30562546849250793, train/raw-loss = 0.2730242609977722, train/logprobs = tensor([[-1.8219, -6.4312],
        [-4.5691, -2.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3260122239589691
Epoch 0, Step 5209: train/loss = 0.2571931481361389, train/raw-loss = 0.21274182200431824, train/logprobs = tensor([[-1.3344, -8.1446],
        [-5.5621, -2.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44451314210891724
Epoch 0, Step 5210: train/loss = 0.6652349829673767, train/raw-loss = 0.6263864040374756, train/logprobs = tensor([[-2.3859, -3.0786],
        [-3.4128, -2.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38848501443862915
Epoch 0, Step 5211: train/loss = 0.5328966975212097, train/raw-loss = 0.4853537678718567, train/logprobs = tensor([[-2.7785, -4.4867],
        [-5.1223, -3.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47542887926101685
Epoch 0, Step 5212: train/loss = 0.17897963523864746, train/raw-loss = 0.1445268839597702, train/logprobs = tensor([[-2.4097, -6.9647],
        [-5.7949, -2.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3445275127887726
Epoch 0, Step 5213: train/loss = 0.2582627534866333, train/raw-loss = 0.21433046460151672, train/logprobs = tensor([[-1.7303, -9.0909],
        [-5.3032, -4.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4393225908279419
Epoch 0, Step 5214: train/loss = 0.16404855251312256, train/raw-loss = 0.13320891559123993, train/logprobs = tensor([[-2.2741, -6.2891],
        [-6.4156, -3.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30839648842811584
Epoch 0, Step 5215: train/loss = 0.31127989292144775, train/raw-loss = 0.263883501291275, train/logprobs = tensor([[-1.2608, -8.3456],
        [-5.2769, -3.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4739641845226288
Epoch 0, Step 5216: train/loss = 0.4866178631782532, train/raw-loss = 0.43844613432884216, train/logprobs = tensor([[-1.5486, -9.2304],
        [-5.9014, -6.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4817173480987549
Epoch 0, Step 5217: train/loss = 0.4392660856246948, train/raw-loss = 0.40193867683410645, train/logprobs = tensor([[-1.4534, -7.6771],
        [-5.2184, -3.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3732742369174957
Epoch 0, Step 5218: train/loss = 0.2525361478328705, train/raw-loss = 0.20713409781455994, train/logprobs = tensor([[ -1.4749, -13.8191],
        [ -6.7102,  -5.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4540204107761383
Epoch 0, Step 5219: train/loss = 0.5800260305404663, train/raw-loss = 0.5338521003723145, train/logprobs = tensor([[-1.5152, -3.8399],
        [-4.8420, -3.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46173879504203796
Epoch 0, Step 5220: train/loss = 0.23133111000061035, train/raw-loss = 0.18530544638633728, train/logprobs = tensor([[-1.0922, -9.1877],
        [-5.6124, -2.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4602566361427307
Epoch 0, Step 5221: train/loss = 0.19998931884765625, train/raw-loss = 0.1552828699350357, train/logprobs = tensor([[-2.0977, -9.9484],
        [-5.4558, -2.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4470645487308502
Epoch 0, Step 5222: train/loss = 0.17103806138038635, train/raw-loss = 0.12375180423259735, train/logprobs = tensor([[-1.7469, -7.5217],
        [-5.0514, -1.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47286248207092285
Epoch 0, Step 5223: train/loss = 0.6829797625541687, train/raw-loss = 0.6306238174438477, train/logprobs = tensor([[-1.7684, -5.1319],
        [-7.0137, -4.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5235599875450134
Epoch 0, Step 5224: train/loss = 0.45383578538894653, train/raw-loss = 0.4097288250923157, train/logprobs = tensor([[-2.0608, -5.8898],
        [-4.1358, -3.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4410696029663086
Epoch 0, Step 5225: train/loss = 0.58131343126297, train/raw-loss = 0.5307825803756714, train/logprobs = tensor([[-1.6535, -3.9500],
        [-4.3280, -3.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5053083896636963
Epoch 0, Step 5226: train/loss = 0.3634416460990906, train/raw-loss = 0.3314783275127411, train/logprobs = tensor([[-1.8789, -9.5793],
        [-3.7584, -5.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3196331560611725
Epoch 0, Step 5227: train/loss = 0.22610802948474884, train/raw-loss = 0.19230572879314423, train/logprobs = tensor([[ -2.0905, -11.5618],
        [ -5.7330,  -7.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380228877067566
Epoch 0, Step 5228: train/loss = 0.12503790855407715, train/raw-loss = 0.08049486577510834, train/logprobs = tensor([[-1.1865, -8.0093],
        [-6.9241, -3.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4454304575920105
Epoch 0, Step 5229: train/loss = 0.37332719564437866, train/raw-loss = 0.3334774374961853, train/logprobs = tensor([[ -3.1175, -10.7565],
        [ -5.2542,  -3.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3984978199005127
Epoch 0, Step 5230: train/loss = 0.07694089412689209, train/raw-loss = 0.04185878857970238, train/logprobs = tensor([[ -1.0042, -13.7397],
        [ -6.5669,  -7.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3508210778236389
Epoch 0, Step 5231: train/loss = 0.5381723046302795, train/raw-loss = 0.4858018755912781, train/logprobs = tensor([[-1.7192, -5.8891],
        [-6.0547, -4.9618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5237044095993042
Epoch 0, Step 5232: train/loss = 0.5883715152740479, train/raw-loss = 0.5376594662666321, train/logprobs = tensor([[-1.8357, -7.4284],
        [-7.1118, -5.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5071200728416443
Epoch 0, Step 5233: train/loss = 0.27536946535110474, train/raw-loss = 0.22734835743904114, train/logprobs = tensor([[-1.1885, -4.0457],
        [-4.7832, -3.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48021090030670166
Epoch 0, Step 5234: train/loss = 0.5284903049468994, train/raw-loss = 0.48204365372657776, train/logprobs = tensor([[-1.5592, -8.7330],
        [-6.6058, -5.2418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4644668996334076
Epoch 0, Step 5235: train/loss = 0.5982491374015808, train/raw-loss = 0.5635991096496582, train/logprobs = tensor([[-2.6612, -7.2815],
        [-3.8747, -1.6232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3465005159378052
Epoch 0, Step 5236: train/loss = 0.760330080986023, train/raw-loss = 0.7149931192398071, train/logprobs = tensor([[-0.9559, -2.1955],
        [-3.9500, -3.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4533698856830597
Epoch 0, Step 5237: train/loss = 0.4016086757183075, train/raw-loss = 0.35482096672058105, train/logprobs = tensor([[-1.3384, -6.0325],
        [-5.0078, -2.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46787726879119873
Epoch 0, Step 5238: train/loss = 0.5045934915542603, train/raw-loss = 0.4721026122570038, train/logprobs = tensor([[-1.5339, -7.8399],
        [-4.1997, -5.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32490891218185425
Epoch 0, Step 5239: train/loss = 0.31510984897613525, train/raw-loss = 0.27156054973602295, train/logprobs = tensor([[-2.1561, -5.7538],
        [-5.4544, -2.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4354932904243469
Epoch 0, Step 5240: train/loss = 0.5414180755615234, train/raw-loss = 0.4971826672554016, train/logprobs = tensor([[-2.7063, -4.1612],
        [-4.3573, -3.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4423544406890869
Epoch 0, Step 5241: train/loss = 0.39766615629196167, train/raw-loss = 0.35263264179229736, train/logprobs = tensor([[-2.0146, -5.0062],
        [-4.6993, -3.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4503353238105774
Epoch 0, Step 5242: train/loss = 0.21199843287467957, train/raw-loss = 0.17242814600467682, train/logprobs = tensor([[-2.1578, -6.4693],
        [-7.2691, -2.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3957030475139618
Epoch 0, Step 5243: train/loss = 0.21250365674495697, train/raw-loss = 0.1748548001050949, train/logprobs = tensor([[-2.1495, -7.0915],
        [-6.5652, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37648865580558777
Epoch 0, Step 5244: train/loss = 0.2781887650489807, train/raw-loss = 0.2384946495294571, train/logprobs = tensor([[-1.7085, -4.2168],
        [-4.8129, -3.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3969413936138153
Epoch 0, Step 5245: train/loss = 0.23402802646160126, train/raw-loss = 0.1967257410287857, train/logprobs = tensor([[ -1.1776, -12.6275],
        [ -5.1492,  -3.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37302279472351074
Epoch 0, Step 5246: train/loss = 0.445998877286911, train/raw-loss = 0.405928373336792, train/logprobs = tensor([[-2.1933, -7.9410],
        [-6.5224, -3.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40070509910583496
Epoch 0, Step 5247: train/loss = 0.32092079520225525, train/raw-loss = 0.28197532892227173, train/logprobs = tensor([[-1.4564, -8.1441],
        [-4.6211, -2.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3894544243812561
Epoch 0, Step 5248: train/loss = 0.7615282535552979, train/raw-loss = 0.7184261083602905, train/logprobs = tensor([[-1.2636, -4.7964],
        [-4.5448, -3.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4310210347175598
Epoch 0, Step 5249: train/loss = 0.1030566468834877, train/raw-loss = 0.057529058307409286, train/logprobs = tensor([[-1.8225, -8.6385],
        [-6.5502, -3.4094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4552757740020752
Epoch 0, Step 5250: train/loss = 0.11737996339797974, train/raw-loss = 0.07169948518276215, train/logprobs = tensor([[-1.1546, -8.1518],
        [-6.3591, -2.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45680472254753113
Epoch 0, Step 5251: train/loss = 0.1557215452194214, train/raw-loss = 0.12024657428264618, train/logprobs = tensor([[-1.3390, -7.0878],
        [-4.7390, -2.1203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35474976897239685
Epoch 0, Step 5252: train/loss = 0.5585378408432007, train/raw-loss = 0.5255619287490845, train/logprobs = tensor([[-1.9828, -4.3401],
        [-3.9034, -4.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.329758882522583
Epoch 0, Step 5253: train/loss = 0.26495516300201416, train/raw-loss = 0.21951879560947418, train/logprobs = tensor([[-1.8430, -9.4292],
        [-6.8398, -3.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4543636441230774
Epoch 0, Step 5254: train/loss = 0.24328090250492096, train/raw-loss = 0.20196619629859924, train/logprobs = tensor([[-1.4891, -4.8592],
        [-4.7784, -2.3247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41314709186553955
Epoch 0, Step 5255: train/loss = 0.319741427898407, train/raw-loss = 0.27242448925971985, train/logprobs = tensor([[-1.5777, -7.4235],
        [-7.4774, -5.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47316956520080566
Epoch 0, Step 5256: train/loss = 0.5753004550933838, train/raw-loss = 0.5320087671279907, train/logprobs = tensor([[-1.9941, -4.6341],
        [-5.1655, -3.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4329167902469635
Epoch 0, Step 5257: train/loss = 0.514897346496582, train/raw-loss = 0.46082448959350586, train/logprobs = tensor([[-1.5820, -7.5408],
        [-4.6777, -3.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5407282114028931
Epoch 0, Step 5258: train/loss = 0.1506122499704361, train/raw-loss = 0.11202054470777512, train/logprobs = tensor([[ -1.9129, -11.8801],
        [ -8.5220,  -3.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.385917067527771
Epoch 0, Step 5259: train/loss = 0.15140557289123535, train/raw-loss = 0.10736304521560669, train/logprobs = tensor([[-1.6290, -9.5636],
        [-6.8245, -3.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44042545557022095
Epoch 0, Step 5260: train/loss = 0.22931607067584991, train/raw-loss = 0.18713778257369995, train/logprobs = tensor([[ -1.0786, -11.1319],
        [ -3.7916,  -5.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4217827320098877
Epoch 0, Step 5261: train/loss = 0.33687472343444824, train/raw-loss = 0.30708959698677063, train/logprobs = tensor([[-1.1061, -2.8685],
        [-4.0726, -1.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978512644767761
Epoch 0, Step 5262: train/loss = 0.3369394838809967, train/raw-loss = 0.2857930064201355, train/logprobs = tensor([[ -1.2158, -14.3199],
        [ -6.4204,  -5.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5114647150039673
Epoch 0, Step 5263: train/loss = 0.3773319721221924, train/raw-loss = 0.3335525393486023, train/logprobs = tensor([[-1.4309, -7.4118],
        [-4.2427, -2.3229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.437794029712677
Epoch 0, Step 5264: train/loss = 0.33935561776161194, train/raw-loss = 0.2920759320259094, train/logprobs = tensor([[-3.0978, -6.7232],
        [-7.5031, -3.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4727967083454132
Epoch 0, Step 5265: train/loss = 0.2819095253944397, train/raw-loss = 0.244914248585701, train/logprobs = tensor([[-2.3987, -7.4219],
        [-5.1956, -2.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3699527978897095
Epoch 0, Step 5266: train/loss = 0.46468332409858704, train/raw-loss = 0.43069785833358765, train/logprobs = tensor([[-2.4146, -5.5748],
        [-4.8277, -2.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33985501527786255
Epoch 0, Step 5267: train/loss = 0.08155383914709091, train/raw-loss = 0.04510354995727539, train/logprobs = tensor([[ -1.5160, -10.4624],
        [ -6.4812,  -1.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364502876996994
Epoch 0, Step 5268: train/loss = 0.2890647053718567, train/raw-loss = 0.2510679364204407, train/logprobs = tensor([[-1.2827, -4.6398],
        [-5.2079, -2.1733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799681067466736
Epoch 0, Step 5269: train/loss = 0.13289761543273926, train/raw-loss = 0.09365832805633545, train/logprobs = tensor([[-1.2720, -6.9737],
        [-5.3641, -2.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3923929035663605
Epoch 0, Step 5270: train/loss = 0.20681798458099365, train/raw-loss = 0.16605350375175476, train/logprobs = tensor([[-1.7078, -8.9655],
        [-5.0954, -2.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40764492750167847
Epoch 0, Step 5271: train/loss = 0.04856603592634201, train/raw-loss = 0.012733202427625656, train/logprobs = tensor([[ -2.4523, -13.2625],
        [ -9.3479,  -5.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35832831263542175
Epoch 0, Step 5272: train/loss = 0.33800917863845825, train/raw-loss = 0.29072514176368713, train/logprobs = tensor([[-1.0291, -9.0570],
        [-5.5580, -4.2129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47284024953842163
Epoch 0, Step 5273: train/loss = 0.32351014018058777, train/raw-loss = 0.28130054473876953, train/logprobs = tensor([[-2.1890, -3.3865],
        [-6.6169, -3.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4220955967903137
Epoch 0, Step 5274: train/loss = 0.20685914158821106, train/raw-loss = 0.16290122270584106, train/logprobs = tensor([[-1.6105, -8.5435],
        [-6.1471, -3.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4395792484283447
Epoch 0, Step 5275: train/loss = 0.4726547300815582, train/raw-loss = 0.44487470388412476, train/logprobs = tensor([[-1.4574, -4.8908],
        [-2.5213, -1.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2777998745441437
Epoch 0, Step 5276: train/loss = 0.3950953185558319, train/raw-loss = 0.356689989566803, train/logprobs = tensor([[ -1.3248, -12.3814],
        [ -4.7856,  -7.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38405323028564453
Epoch 0, Step 5277: train/loss = 0.43218034505844116, train/raw-loss = 0.38724610209465027, train/logprobs = tensor([[-2.0745, -4.8311],
        [-5.4065, -2.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44934308528900146
Epoch 0, Step 5278: train/loss = 0.7084989547729492, train/raw-loss = 0.6673709750175476, train/logprobs = tensor([[-2.3203, -6.3106],
        [-3.3942, -3.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112795889377594
Epoch 0, Step 5279: train/loss = 0.14223986864089966, train/raw-loss = 0.09684699773788452, train/logprobs = tensor([[ -3.2194, -12.7330],
        [ -7.5375,  -3.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4539288282394409
Epoch 0, Step 5280: train/loss = 0.25184571743011475, train/raw-loss = 0.21073074638843536, train/logprobs = tensor([[-1.8521, -6.4965],
        [-5.1792, -2.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4111495614051819
Epoch 0, Step 5281: train/loss = 0.685976505279541, train/raw-loss = 0.6302624940872192, train/logprobs = tensor([[-1.8460, -5.5612],
        [-6.2273, -4.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5571401119232178
Epoch 0, Step 5282: train/loss = 0.4343675374984741, train/raw-loss = 0.38343101739883423, train/logprobs = tensor([[-1.7369, -6.4930],
        [-5.9621, -3.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5093650817871094
Epoch 0, Step 5283: train/loss = 0.27740174531936646, train/raw-loss = 0.2338363528251648, train/logprobs = tensor([[-1.2651, -4.5948],
        [-3.8964, -2.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4356538951396942
Epoch 0, Step 5284: train/loss = 0.42085501551628113, train/raw-loss = 0.38997524976730347, train/logprobs = tensor([[-1.1737, -3.1718],
        [-3.0051, -1.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3087979555130005
Epoch 0, Step 5285: train/loss = 0.38804891705513, train/raw-loss = 0.34819909930229187, train/logprobs = tensor([[-1.7578, -9.8156],
        [-5.1312, -5.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3984982371330261
Epoch 0, Step 5286: train/loss = 0.9710620045661926, train/raw-loss = 0.9254550933837891, train/logprobs = tensor([[-2.5622, -3.0970],
        [-5.4654, -4.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4560689926147461
Epoch 0, Step 5287: train/loss = 0.4563882350921631, train/raw-loss = 0.4218224883079529, train/logprobs = tensor([[-1.8413, -4.9314],
        [-4.6094, -3.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.345657616853714
Epoch 0, Step 5288: train/loss = 0.49365752935409546, train/raw-loss = 0.45719754695892334, train/logprobs = tensor([[-1.0511, -2.6538],
        [-3.2260, -2.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645997941493988
Epoch 0, Step 5289: train/loss = 0.10919421166181564, train/raw-loss = 0.06303214281797409, train/logprobs = tensor([[ -1.4367, -11.9809],
        [ -6.6041,  -2.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4616207182407379
Epoch 0, Step 5290: train/loss = 0.2515431344509125, train/raw-loss = 0.20865553617477417, train/logprobs = tensor([[-1.7040, -7.1425],
        [-6.3964, -1.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42887598276138306
Epoch 0, Step 5291: train/loss = 0.43213585019111633, train/raw-loss = 0.39517584443092346, train/logprobs = tensor([[-3.1322, -7.1887],
        [-6.4894, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36959999799728394
Epoch 0, Step 5292: train/loss = 0.2538940906524658, train/raw-loss = 0.20746441185474396, train/logprobs = tensor([[-1.6454, -9.6946],
        [-6.6936, -2.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.464296817779541
Epoch 0, Step 5293: train/loss = 0.5476084351539612, train/raw-loss = 0.5132437348365784, train/logprobs = tensor([[-0.9925, -3.6088],
        [-4.2837, -2.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3436477780342102
Epoch 0, Step 5294: train/loss = 0.5226176381111145, train/raw-loss = 0.4716712534427643, train/logprobs = tensor([[-1.0652, -8.5487],
        [-4.7695, -4.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5094640254974365
Epoch 0, Step 5295: train/loss = 0.5120435357093811, train/raw-loss = 0.471034973859787, train/logprobs = tensor([[-1.0181, -4.2063],
        [-4.2787, -2.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41008538007736206
Epoch 0, Step 5296: train/loss = 0.7161539793014526, train/raw-loss = 0.6811993718147278, train/logprobs = tensor([[-2.2395, -4.5650],
        [-4.3805, -2.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34954607486724854
Epoch 0, Step 5297: train/loss = 0.19313184916973114, train/raw-loss = 0.15626966953277588, train/logprobs = tensor([[ -1.8742, -13.2946],
        [ -6.8803,  -4.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36862191557884216
Epoch 0, Step 5298: train/loss = 0.2540397346019745, train/raw-loss = 0.2148102968931198, train/logprobs = tensor([[-1.1601, -6.6667],
        [-3.5941, -1.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922942280769348
Epoch 0, Step 5299: train/loss = 0.11883942037820816, train/raw-loss = 0.08600787818431854, train/logprobs = tensor([[-1.9631, -8.0519],
        [-5.6700, -1.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283153474330902
Epoch 0, Step 5300: train/loss = 0.17478783428668976, train/raw-loss = 0.12426140904426575, train/logprobs = tensor([[-1.2806, -9.1819],
        [-6.1288, -3.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5052642822265625
Epoch 0, Step 5301: train/loss = 0.2858256995677948, train/raw-loss = 0.247678741812706, train/logprobs = tensor([[-1.3670, -9.9975],
        [-5.4231, -3.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3814695477485657
Epoch 0, Step 5302: train/loss = 0.466580331325531, train/raw-loss = 0.435325026512146, train/logprobs = tensor([[-1.3798, -2.3623],
        [-3.0710, -1.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125527501106262
Epoch 0, Step 5303: train/loss = 0.5600740909576416, train/raw-loss = 0.5201044678688049, train/logprobs = tensor([[ -2.1689, -10.0904],
        [ -6.2498,  -5.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39969614148139954
Epoch 0, Step 5304: train/loss = 0.3290148973464966, train/raw-loss = 0.2809683680534363, train/logprobs = tensor([[-0.7941, -8.4866],
        [-5.1773, -2.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4804654121398926
Epoch 0, Step 5305: train/loss = 0.16267487406730652, train/raw-loss = 0.12524199485778809, train/logprobs = tensor([[-1.3917, -6.2575],
        [-5.3364, -2.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3743289113044739
Epoch 0, Step 5306: train/loss = 0.31887954473495483, train/raw-loss = 0.2772582471370697, train/logprobs = tensor([[-1.6458, -5.0628],
        [-5.6433, -3.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41621285676956177
Epoch 0, Step 5307: train/loss = 0.3232751488685608, train/raw-loss = 0.28218281269073486, train/logprobs = tensor([[ -1.2108, -10.7951],
        [ -5.6538,  -3.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4109235405921936
Epoch 0, Step 5308: train/loss = 0.4306721091270447, train/raw-loss = 0.3924207091331482, train/logprobs = tensor([[-1.1845, -3.2588],
        [-3.9240, -2.2808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3825141191482544
Epoch 0, Step 5309: train/loss = 0.28743621706962585, train/raw-loss = 0.24311116337776184, train/logprobs = tensor([[ -2.8404, -10.4349],
        [ -6.9779,  -5.2552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4432503581047058
Epoch 0, Step 5310: train/loss = 0.26564162969589233, train/raw-loss = 0.22680599987506866, train/logprobs = tensor([[-1.3682, -9.4169],
        [-5.6212, -3.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3883565068244934
Epoch 0, Step 5311: train/loss = 0.07754377275705338, train/raw-loss = 0.017965061590075493, train/logprobs = tensor([[ -1.1442, -16.7194],
        [ -7.3175,  -8.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5957871079444885
Epoch 0, Step 5312: train/loss = 0.2644703686237335, train/raw-loss = 0.22663143277168274, train/logprobs = tensor([[-1.4057, -9.6688],
        [-4.0776, -2.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3783894181251526
Epoch 0, Step 5313: train/loss = 0.36383864283561707, train/raw-loss = 0.3177105784416199, train/logprobs = tensor([[-2.0088, -4.3347],
        [-6.2653, -2.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46128055453300476
Epoch 0, Step 5314: train/loss = 0.7881339192390442, train/raw-loss = 0.7593029737472534, train/logprobs = tensor([[-1.3676, -2.0456],
        [-4.1985, -3.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883087992668152
Epoch 0, Step 5315: train/loss = 0.43842023611068726, train/raw-loss = 0.4001675248146057, train/logprobs = tensor([[-2.4324, -7.2128],
        [-5.6514, -2.9766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38252702355384827
Epoch 0, Step 5316: train/loss = 0.47373196482658386, train/raw-loss = 0.4216897487640381, train/logprobs = tensor([[-1.1090, -9.1230],
        [-6.3262, -4.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.520422101020813
Epoch 0, Step 5317: train/loss = 0.5483902096748352, train/raw-loss = 0.5002397298812866, train/logprobs = tensor([[-1.6739, -2.8852],
        [-5.8219, -3.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4815048575401306
Epoch 0, Step 5318: train/loss = 0.5702962279319763, train/raw-loss = 0.5174599289894104, train/logprobs = tensor([[-1.2592, -2.4671],
        [-4.8121, -2.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5283627510070801
Epoch 0, Step 5319: train/loss = 0.3223496079444885, train/raw-loss = 0.2879658341407776, train/logprobs = tensor([[-1.8236, -4.2881],
        [-4.1954, -2.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34383755922317505
Epoch 0, Step 5320: train/loss = 0.3091522455215454, train/raw-loss = 0.2735736072063446, train/logprobs = tensor([[ -2.7214, -12.0696],
        [ -5.0142,  -2.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3557858169078827
Epoch 0, Step 5321: train/loss = 0.28947216272354126, train/raw-loss = 0.24730820953845978, train/logprobs = tensor([[-2.2221, -5.1824],
        [-4.8813, -3.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4216395616531372
Epoch 0, Step 5322: train/loss = 0.2918210029602051, train/raw-loss = 0.25028714537620544, train/logprobs = tensor([[-1.3542, -9.5013],
        [-5.8504, -3.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4153384268283844
Epoch 0, Step 5323: train/loss = 0.058304041624069214, train/raw-loss = 0.021586768329143524, train/logprobs = tensor([[ -1.2749, -11.9671],
        [ -5.6880,  -1.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3671727478504181
Epoch 0, Step 5324: train/loss = 0.4939519762992859, train/raw-loss = 0.4650586247444153, train/logprobs = tensor([[-1.4160, -8.2775],
        [-3.3996, -5.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28893351554870605
Epoch 0, Step 5325: train/loss = 0.49383437633514404, train/raw-loss = 0.455133318901062, train/logprobs = tensor([[-1.4843, -3.1997],
        [-4.5685, -2.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3870108723640442
Epoch 0, Step 5326: train/loss = 0.3506983518600464, train/raw-loss = 0.31098759174346924, train/logprobs = tensor([[-1.4068, -9.8491],
        [-5.6651, -2.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3971075415611267
Epoch 0, Step 5327: train/loss = 0.5190684199333191, train/raw-loss = 0.48353493213653564, train/logprobs = tensor([[-2.0056, -3.4865],
        [-4.0189, -3.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553347587585449
Epoch 0, Step 5328: train/loss = 0.3251199722290039, train/raw-loss = 0.2798747718334198, train/logprobs = tensor([[-0.8251, -5.9045],
        [-4.4993, -3.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45245182514190674
Epoch 0, Step 5329: train/loss = 0.2202966809272766, train/raw-loss = 0.17628003656864166, train/logprobs = tensor([[-2.6060, -6.8190],
        [-7.6840, -2.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4401663541793823
Epoch 0, Step 5330: train/loss = 0.3217007517814636, train/raw-loss = 0.29148775339126587, train/logprobs = tensor([[-2.1923, -7.1603],
        [-3.5505, -3.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021301329135895
Epoch 0, Step 5331: train/loss = 0.5227463245391846, train/raw-loss = 0.48143434524536133, train/logprobs = tensor([[-1.6686, -9.7592],
        [-7.4623, -7.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4131195545196533
Epoch 0, Step 5332: train/loss = 0.116592638194561, train/raw-loss = 0.08159518986940384, train/logprobs = tensor([[-1.1107, -5.9107],
        [-4.4241, -1.3748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34997448325157166
Epoch 0, Step 5333: train/loss = 0.6907744407653809, train/raw-loss = 0.6516225337982178, train/logprobs = tensor([[-3.3714, -7.9022],
        [-5.8153, -2.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3915184736251831
Epoch 0, Step 5334: train/loss = 0.6183279752731323, train/raw-loss = 0.5787933468818665, train/logprobs = tensor([[-1.4682, -3.3260],
        [-4.0627, -4.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.395346462726593
Epoch 0, Step 5335: train/loss = 0.41642507910728455, train/raw-loss = 0.37158653140068054, train/logprobs = tensor([[-0.9338, -8.9672],
        [-5.8560, -3.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4483850598335266
Epoch 0, Step 5336: train/loss = 0.21309098601341248, train/raw-loss = 0.1799251288175583, train/logprobs = tensor([[-1.2496, -6.3871],
        [-3.6175, -2.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33165866136550903
Epoch 0, Step 5337: train/loss = 0.5459814667701721, train/raw-loss = 0.5108189582824707, train/logprobs = tensor([[-3.7663, -4.6250],
        [-7.0765, -4.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35162514448165894
Epoch 0, Step 5338: train/loss = 0.3509814739227295, train/raw-loss = 0.3024327754974365, train/logprobs = tensor([[-1.2090, -5.8142],
        [-4.9736, -4.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4854869842529297
Epoch 0, Step 5339: train/loss = 0.22892504930496216, train/raw-loss = 0.18586185574531555, train/logprobs = tensor([[-0.9374, -4.5362],
        [-6.4346, -1.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43063217401504517
Epoch 0, Step 5340: train/loss = 0.5675150752067566, train/raw-loss = 0.52947598695755, train/logprobs = tensor([[-1.5255, -4.1245],
        [-4.4921, -3.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3803904950618744
Epoch 0, Step 5341: train/loss = 0.28704094886779785, train/raw-loss = 0.2530539631843567, train/logprobs = tensor([[-1.9697, -5.3607],
        [-6.2213, -2.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3398696780204773
Epoch 0, Step 5342: train/loss = 0.26064762473106384, train/raw-loss = 0.21914991736412048, train/logprobs = tensor([[-1.2059, -6.6542],
        [-4.8625, -2.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41497692465782166
Epoch 0, Step 5343: train/loss = 0.09564294666051865, train/raw-loss = 0.05393766611814499, train/logprobs = tensor([[ -1.5018, -12.5918],
        [ -5.6751,  -4.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4170528054237366
Epoch 0, Step 5344: train/loss = 0.21753358840942383, train/raw-loss = 0.1596282422542572, train/logprobs = tensor([[-1.3266, -6.8910],
        [-5.4470, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.579053521156311
Epoch 0, Step 5345: train/loss = 0.5447403192520142, train/raw-loss = 0.49901914596557617, train/logprobs = tensor([[-1.5860, -4.1473],
        [-5.4133, -4.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45721176266670227
Epoch 0, Step 5346: train/loss = 0.1121826320886612, train/raw-loss = 0.07495914399623871, train/logprobs = tensor([[-1.0685, -7.1801],
        [-4.9726, -2.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37223488092422485
Epoch 0, Step 5347: train/loss = 0.0979296863079071, train/raw-loss = 0.043758343905210495, train/logprobs = tensor([[ -1.3251, -14.6679],
        [ -6.7609,  -5.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5417134761810303
Epoch 0, Step 5348: train/loss = 0.41539502143859863, train/raw-loss = 0.3760758936405182, train/logprobs = tensor([[-1.5707, -6.7861],
        [-5.3634, -4.8007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3931915760040283
Epoch 0, Step 5349: train/loss = 0.46021926403045654, train/raw-loss = 0.42797842621803284, train/logprobs = tensor([[-2.5609, -9.4252],
        [-4.0733, -1.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32240837812423706
Epoch 0, Step 5350: train/loss = 0.36810630559921265, train/raw-loss = 0.32369711995124817, train/logprobs = tensor([[-1.6322, -5.9731],
        [-3.7796, -3.2646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4440915286540985
Epoch 0, Step 5351: train/loss = 0.3421594500541687, train/raw-loss = 0.29877060651779175, train/logprobs = tensor([[-0.8582, -8.4500],
        [-4.1808, -3.4076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43388840556144714
Epoch 0, Step 5352: train/loss = 0.9960718154907227, train/raw-loss = 0.9443697929382324, train/logprobs = tensor([[-1.4904, -2.2015],
        [-3.9272, -4.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5170195698738098
Epoch 0, Step 5353: train/loss = 0.287871778011322, train/raw-loss = 0.24941717088222504, train/logprobs = tensor([[-1.1804, -4.1305],
        [-4.5755, -2.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38454586267471313
Epoch 0, Step 5354: train/loss = 0.5759806036949158, train/raw-loss = 0.5346506834030151, train/logprobs = tensor([[-1.3418, -7.4600],
        [-5.3886, -6.0269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4132991433143616
Epoch 0, Step 5355: train/loss = 0.11168010532855988, train/raw-loss = 0.06977001577615738, train/logprobs = tensor([[-2.0373, -8.3611],
        [-5.5405, -2.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41910088062286377
Epoch 0, Step 5356: train/loss = 0.19561055302619934, train/raw-loss = 0.15367823839187622, train/logprobs = tensor([[ -1.3824, -11.0630],
        [ -6.9514,  -3.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.419323205947876
Epoch 0, Step 5357: train/loss = 0.07627637684345245, train/raw-loss = 0.03331952914595604, train/logprobs = tensor([[ -1.7413, -15.5120],
        [ -4.9398,  -6.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42956846952438354
Epoch 0, Step 5358: train/loss = 0.37863731384277344, train/raw-loss = 0.3350457549095154, train/logprobs = tensor([[ -3.5578, -10.4840],
        [ -6.1518,  -3.2129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43591538071632385
Epoch 0, Step 5359: train/loss = 0.4774512052536011, train/raw-loss = 0.4397397041320801, train/logprobs = tensor([[-1.4356, -9.5648],
        [-5.6225, -6.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37711548805236816
Epoch 0, Step 5360: train/loss = 0.664656400680542, train/raw-loss = 0.6362345218658447, train/logprobs = tensor([[-1.8392, -5.4624],
        [-2.6044, -1.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842179834842682
Epoch 0, Step 5361: train/loss = 0.10515666007995605, train/raw-loss = 0.06776092946529388, train/logprobs = tensor([[-1.3514, -8.8889],
        [-5.8017, -1.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37395724654197693
Epoch 0, Step 5362: train/loss = 0.5011906027793884, train/raw-loss = 0.46077343821525574, train/logprobs = tensor([[-1.3307, -3.3422],
        [-4.2887, -3.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40417179465293884
Epoch 0, Step 5363: train/loss = 0.055658429861068726, train/raw-loss = 0.019843142479658127, train/logprobs = tensor([[-1.6955, -7.1289],
        [-6.2087, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581528663635254
Epoch 0, Step 5364: train/loss = 0.6988625526428223, train/raw-loss = 0.6507738828659058, train/logprobs = tensor([[-1.5339, -2.7812],
        [-4.1504, -3.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48088642954826355
Epoch 0, Step 5365: train/loss = 0.2307722419500351, train/raw-loss = 0.18979009985923767, train/logprobs = tensor([[-1.4759, -8.5339],
        [-6.4716, -3.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4098213315010071
Epoch 0, Step 5366: train/loss = 0.5614340305328369, train/raw-loss = 0.5168893933296204, train/logprobs = tensor([[-0.7961, -2.7088],
        [-4.1977, -3.3874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4454463720321655
Epoch 0, Step 5367: train/loss = 0.4002772569656372, train/raw-loss = 0.3575572967529297, train/logprobs = tensor([[-2.3659, -9.0100],
        [-5.0066, -3.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4271996021270752
Epoch 0, Step 5368: train/loss = 0.3732776343822479, train/raw-loss = 0.3202821910381317, train/logprobs = tensor([[-1.5566, -8.7484],
        [-6.1747, -3.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5299543738365173
Epoch 0, Step 5369: train/loss = 0.11433044075965881, train/raw-loss = 0.07702262699604034, train/logprobs = tensor([[ -1.0139, -14.4930],
        [ -5.7665,  -5.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3730780780315399
Epoch 0, Step 5370: train/loss = 0.19847415387630463, train/raw-loss = 0.1638716757297516, train/logprobs = tensor([[-1.1085, -8.3387],
        [-6.0143, -4.7584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3460247814655304
Epoch 0, Step 5371: train/loss = 0.24550163745880127, train/raw-loss = 0.2077956199645996, train/logprobs = tensor([[-1.6744, -4.3341],
        [-5.6713, -2.3702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3770601153373718
Epoch 0, Step 5372: train/loss = 0.3665962815284729, train/raw-loss = 0.32060226798057556, train/logprobs = tensor([[-2.7179, -5.5245],
        [-8.1971, -3.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45994019508361816
Epoch 0, Step 5373: train/loss = 0.4427780508995056, train/raw-loss = 0.40362435579299927, train/logprobs = tensor([[ -1.6756, -11.4894],
        [ -5.2236,  -3.3550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39153674244880676
Epoch 0, Step 5374: train/loss = 0.06555536389350891, train/raw-loss = 0.01625523343682289, train/logprobs = tensor([[-1.5849, -9.1214],
        [-7.4695, -3.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4930013418197632
Epoch 0, Step 5375: train/loss = 0.11842824518680573, train/raw-loss = 0.07687932997941971, train/logprobs = tensor([[-1.4748, -8.4166],
        [-5.1897, -2.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4154890775680542
Epoch 0, Step 5376: train/loss = 0.7051568031311035, train/raw-loss = 0.6707712411880493, train/logprobs = tensor([[-1.6200, -7.9988],
        [-5.1012, -5.2522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438548147678375
Epoch 0, Step 5377: train/loss = 0.6289691925048828, train/raw-loss = 0.5819882750511169, train/logprobs = tensor([[-1.4490, -5.1595],
        [-7.4378, -4.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46980905532836914
Epoch 0, Step 5378: train/loss = 0.22449326515197754, train/raw-loss = 0.18069860339164734, train/logprobs = tensor([[-1.7460, -5.3695],
        [-5.6234, -2.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4379465878009796
Epoch 0, Step 5379: train/loss = 0.3337881565093994, train/raw-loss = 0.29244792461395264, train/logprobs = tensor([[-1.0733, -5.1494],
        [-4.0639, -2.2651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4134024977684021
Epoch 0, Step 5380: train/loss = 0.36038726568222046, train/raw-loss = 0.31287962198257446, train/logprobs = tensor([[-0.7882, -4.9553],
        [-4.9430, -3.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4750765562057495
Epoch 0, Step 5381: train/loss = 0.06306222081184387, train/raw-loss = 0.020056068897247314, train/logprobs = tensor([[-1.5025, -6.8479],
        [-6.3438, -2.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4300614893436432
Epoch 0, Step 5382: train/loss = 0.508648157119751, train/raw-loss = 0.46697431802749634, train/logprobs = tensor([[-1.3728, -7.3663],
        [-5.0481, -3.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4167390763759613
Epoch 0, Step 5383: train/loss = 0.22977250814437866, train/raw-loss = 0.18990355730056763, train/logprobs = tensor([[-1.1873, -9.4960],
        [-5.8157, -2.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39868950843811035
Epoch 0, Step 5384: train/loss = 0.24420811235904694, train/raw-loss = 0.20917217433452606, train/logprobs = tensor([[-1.5859, -9.0353],
        [-4.0354, -4.5155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35035935044288635
Epoch 0, Step 5385: train/loss = 0.0798787772655487, train/raw-loss = 0.03845224902033806, train/logprobs = tensor([[ -1.4634, -11.6765],
        [ -6.0640,  -5.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4142652153968811
Epoch 0, Step 5386: train/loss = 0.696298360824585, train/raw-loss = 0.6517488360404968, train/logprobs = tensor([[-1.9388, -2.3468],
        [-4.3636, -3.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4454948306083679
Epoch 0, Step 5387: train/loss = 0.5919069051742554, train/raw-loss = 0.5564166903495789, train/logprobs = tensor([[-1.5170, -2.0428],
        [-4.6932, -2.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354902446269989
Epoch 0, Step 5388: train/loss = 0.055950090289115906, train/raw-loss = 0.020300861448049545, train/logprobs = tensor([[-0.9425, -9.1676],
        [-4.3735, -2.9188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.356492280960083
Epoch 0, Step 5389: train/loss = 0.626487672328949, train/raw-loss = 0.5885441303253174, train/logprobs = tensor([[-2.1528, -8.6155],
        [-6.0528, -6.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3794357180595398
Epoch 0, Step 5390: train/loss = 0.23192130029201508, train/raw-loss = 0.18647758662700653, train/logprobs = tensor([[-1.6213, -6.2417],
        [-5.6222, -3.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4544371962547302
Epoch 0, Step 5391: train/loss = 0.09392574429512024, train/raw-loss = 0.05742887407541275, train/logprobs = tensor([[-1.9880, -9.7094],
        [-4.8152, -2.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3649687170982361
Epoch 0, Step 5392: train/loss = 0.5343208909034729, train/raw-loss = 0.4922894835472107, train/logprobs = tensor([[-1.8441, -5.4814],
        [-4.4151, -3.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4203138053417206
Epoch 0, Step 5393: train/loss = 0.3046570122241974, train/raw-loss = 0.2593078911304474, train/logprobs = tensor([[-1.5493, -8.4727],
        [-6.1067, -3.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45349088311195374
Epoch 0, Step 5394: train/loss = 0.11573078483343124, train/raw-loss = 0.05380910634994507, train/logprobs = tensor([[-1.7225, -9.5149],
        [-6.4472, -3.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6192168593406677
Epoch 0, Step 5395: train/loss = 0.4769514203071594, train/raw-loss = 0.44425803422927856, train/logprobs = tensor([[ -3.2833, -10.5655],
        [ -4.7380,  -4.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32693421840667725
Epoch 0, Step 5396: train/loss = 0.32779940962791443, train/raw-loss = 0.2837139964103699, train/logprobs = tensor([[-1.7448, -9.6826],
        [-5.5119, -3.6168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4408542811870575
Epoch 0, Step 5397: train/loss = 0.2871510982513428, train/raw-loss = 0.2487485259771347, train/logprobs = tensor([[-1.4686, -4.2441],
        [-5.0318, -2.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3840254843235016
Epoch 0, Step 5398: train/loss = 0.0944916307926178, train/raw-loss = 0.05561729893088341, train/logprobs = tensor([[-2.4204, -6.2229],
        [-5.2253, -2.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3887432813644409
Epoch 0, Step 5399: train/loss = 0.22837626934051514, train/raw-loss = 0.19782495498657227, train/logprobs = tensor([[-2.1019, -8.0029],
        [-3.4382, -2.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055131137371063
Epoch 0, Step 5400: train/loss = 0.43940362334251404, train/raw-loss = 0.39337754249572754, train/logprobs = tensor([[-1.5126, -6.0471],
        [-5.3978, -2.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46026062965393066
Epoch 0, Step 5401: train/loss = 0.21642136573791504, train/raw-loss = 0.17154844105243683, train/logprobs = tensor([[ -1.9258, -10.7381],
        [ -7.8576,  -5.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4487293064594269
Epoch 0, Step 5402: train/loss = 0.5429391860961914, train/raw-loss = 0.5133882164955139, train/logprobs = tensor([[-1.8962, -5.9182],
        [-4.2716, -1.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29551029205322266
Epoch 0, Step 5403: train/loss = 0.1946132928133011, train/raw-loss = 0.14958137273788452, train/logprobs = tensor([[ -1.8143, -11.3239],
        [ -7.4123,  -5.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45031923055648804
Epoch 0, Step 5404: train/loss = 0.18069277703762054, train/raw-loss = 0.140513077378273, train/logprobs = tensor([[-2.1556, -7.3358],
        [-6.9196, -2.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4017971456050873
Epoch 0, Step 5405: train/loss = 0.12812675535678864, train/raw-loss = 0.09284310042858124, train/logprobs = tensor([[ -1.9229, -10.3976],
        [ -5.1100,  -5.4202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528364300727844
Epoch 0, Step 5406: train/loss = 0.2336827665567398, train/raw-loss = 0.19286328554153442, train/logprobs = tensor([[-1.6281, -8.7040],
        [-4.3057, -2.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40819478034973145
Epoch 0, Step 5407: train/loss = 0.41621455550193787, train/raw-loss = 0.3758831024169922, train/logprobs = tensor([[-1.3251, -6.6564],
        [-5.3286, -3.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403314471244812
Epoch 0, Step 5408: train/loss = 0.20909692347049713, train/raw-loss = 0.16931122541427612, train/logprobs = tensor([[-1.1170, -8.8820],
        [-4.3908, -2.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39785701036453247
Epoch 0, Step 5409: train/loss = 0.2248097062110901, train/raw-loss = 0.1876695454120636, train/logprobs = tensor([[-2.0025, -8.0364],
        [-6.7596, -2.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714016079902649
Epoch 0, Step 5410: train/loss = 0.30017510056495667, train/raw-loss = 0.2614481747150421, train/logprobs = tensor([[-1.7658, -7.8050],
        [-4.0322, -2.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3872692584991455
Epoch 0, Step 5411: train/loss = 0.548016369342804, train/raw-loss = 0.502289891242981, train/logprobs = tensor([[-1.2017, -3.2896],
        [-4.8861, -3.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45726537704467773
Epoch 0, Step 5412: train/loss = 0.0607365146279335, train/raw-loss = 0.017134089022874832, train/logprobs = tensor([[ -1.2457, -12.3983],
        [ -6.9239,  -6.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4360242486000061
Epoch 0, Step 5413: train/loss = 0.35935908555984497, train/raw-loss = 0.3129744529724121, train/logprobs = tensor([[ -1.3095, -11.4946],
        [ -6.3703,  -5.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4638463258743286
Epoch 0, Step 5414: train/loss = 0.1493271142244339, train/raw-loss = 0.1067800521850586, train/logprobs = tensor([[-1.3681, -5.5459],
        [-5.2912, -1.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254705011844635
Epoch 0, Step 5415: train/loss = 0.6728766560554504, train/raw-loss = 0.6385945677757263, train/logprobs = tensor([[-3.5169, -9.2619],
        [-4.1717, -2.4773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428214490413666
Epoch 0, Step 5416: train/loss = 0.498655766248703, train/raw-loss = 0.4545937776565552, train/logprobs = tensor([[-1.3413, -7.6370],
        [-5.4370, -3.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44061994552612305
Epoch 0, Step 5417: train/loss = 0.429782897233963, train/raw-loss = 0.38814789056777954, train/logprobs = tensor([[-1.3175, -7.3325],
        [-4.6674, -3.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4163500964641571
Epoch 0, Step 5418: train/loss = 0.21209707856178284, train/raw-loss = 0.173029825091362, train/logprobs = tensor([[-1.2774, -8.7514],
        [-5.9393, -2.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39067262411117554
Epoch 0, Step 5419: train/loss = 0.3952631950378418, train/raw-loss = 0.3538562059402466, train/logprobs = tensor([[-1.8080, -6.3938],
        [-6.2888, -3.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41406968235969543
Epoch 0, Step 5420: train/loss = 0.2913515269756317, train/raw-loss = 0.24633052945137024, train/logprobs = tensor([[ -1.6638, -10.4677],
        [ -5.9438,  -2.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4502101540565491
Epoch 0, Step 5421: train/loss = 0.6073282957077026, train/raw-loss = 0.5791688561439514, train/logprobs = tensor([[-1.9607, -1.5955],
        [-3.2956, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28159457445144653
Epoch 0, Step 5422: train/loss = 0.5948639512062073, train/raw-loss = 0.5621898770332336, train/logprobs = tensor([[-1.3546, -5.1951],
        [-3.5449, -2.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267408311367035
Epoch 0, Step 5423: train/loss = 0.42672044038772583, train/raw-loss = 0.38548728823661804, train/logprobs = tensor([[-1.1157, -6.3168],
        [-3.5417, -2.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4123317301273346
Epoch 0, Step 5424: train/loss = 0.10465825349092484, train/raw-loss = 0.06489229202270508, train/logprobs = tensor([[-1.5607, -8.2901],
        [-5.1600, -2.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3976595997810364
Epoch 0, Step 5425: train/loss = 0.16235269606113434, train/raw-loss = 0.12089893221855164, train/logprobs = tensor([[-2.4506, -9.5351],
        [-7.1220, -4.1930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41453757882118225
Epoch 0, Step 5426: train/loss = 0.2460300475358963, train/raw-loss = 0.20558005571365356, train/logprobs = tensor([[ -1.5060, -10.4026],
        [ -5.2784,  -5.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40449991822242737
Epoch 0, Step 5427: train/loss = 0.3172573149204254, train/raw-loss = 0.28341028094291687, train/logprobs = tensor([[-1.4533, -4.3797],
        [-4.8055, -1.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.338470458984375
Epoch 0, Step 5428: train/loss = 0.22618864476680756, train/raw-loss = 0.17511814832687378, train/logprobs = tensor([[-1.7536, -7.6625],
        [-5.4805, -3.5540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5107049345970154
Epoch 0, Step 5429: train/loss = 0.36655014753341675, train/raw-loss = 0.33476540446281433, train/logprobs = tensor([[-1.6242, -4.2352],
        [-3.9820, -2.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3178476095199585
Epoch 0, Step 5430: train/loss = 0.43051981925964355, train/raw-loss = 0.38873225450515747, train/logprobs = tensor([[-1.8370, -8.8457],
        [-5.9383, -1.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4178754687309265
Epoch 0, Step 5431: train/loss = 0.36817485094070435, train/raw-loss = 0.32604607939720154, train/logprobs = tensor([[-1.8986, -4.9998],
        [-5.3934, -2.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42128753662109375
Epoch 0, Step 5432: train/loss = 0.4056652784347534, train/raw-loss = 0.3790837228298187, train/logprobs = tensor([[ -2.0347, -11.4725],
        [ -3.9174,  -5.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26581549644470215
Epoch 0, Step 5433: train/loss = 0.23924730718135834, train/raw-loss = 0.20496822893619537, train/logprobs = tensor([[-1.5531, -4.8876],
        [-4.0419, -2.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34279078245162964
Epoch 0, Step 5434: train/loss = 0.25049889087677, train/raw-loss = 0.20486876368522644, train/logprobs = tensor([[-1.9576, -8.7439],
        [-4.8924, -2.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45630112290382385
Epoch 0, Step 5435: train/loss = 0.2623211741447449, train/raw-loss = 0.2224767804145813, train/logprobs = tensor([[-1.7810, -5.9969],
        [-6.3395, -2.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39844396710395813
Epoch 0, Step 5436: train/loss = 0.611595094203949, train/raw-loss = 0.5634468793869019, train/logprobs = tensor([[-1.8057, -8.2371],
        [-5.3835, -7.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48148277401924133
Epoch 0, Step 5437: train/loss = 0.3701286315917969, train/raw-loss = 0.3368637263774872, train/logprobs = tensor([[-2.2015, -6.5704],
        [-4.7877, -3.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33264920115470886
Epoch 0, Step 5438: train/loss = 0.23452866077423096, train/raw-loss = 0.1967976987361908, train/logprobs = tensor([[-2.1623, -5.9187],
        [-5.8125, -2.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3773096203804016
Epoch 0, Step 5439: train/loss = 0.27251142263412476, train/raw-loss = 0.23482093214988708, train/logprobs = tensor([[ -1.9452, -10.8628],
        [ -5.5831,  -1.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37690502405166626
Epoch 0, Step 5440: train/loss = 0.3145332932472229, train/raw-loss = 0.27045542001724243, train/logprobs = tensor([[-1.7604, -5.6406],
        [-4.4709, -3.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4407784938812256
Epoch 0, Step 5441: train/loss = 0.3555283546447754, train/raw-loss = 0.3189796805381775, train/logprobs = tensor([[-2.1772, -9.0208],
        [-3.5823, -2.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36548668146133423
Epoch 0, Step 5442: train/loss = 0.12791617214679718, train/raw-loss = 0.09247579425573349, train/logprobs = tensor([[-1.9150, -6.8888],
        [-4.6269, -2.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35440385341644287
Epoch 0, Step 5443: train/loss = 0.31583449244499207, train/raw-loss = 0.27633705735206604, train/logprobs = tensor([[-1.8615, -8.7500],
        [-7.2214, -2.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3949742317199707
Epoch 0, Step 5444: train/loss = 0.1909572184085846, train/raw-loss = 0.14710210263729095, train/logprobs = tensor([[-2.4683, -6.5869],
        [-7.3408, -2.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4385512173175812
Epoch 0, Step 5445: train/loss = 0.4305444061756134, train/raw-loss = 0.3745487332344055, train/logprobs = tensor([[-0.8487, -5.8305],
        [-6.0017, -4.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5599567890167236
Epoch 0, Step 5446: train/loss = 0.15880605578422546, train/raw-loss = 0.11676444858312607, train/logprobs = tensor([[-2.0082, -5.1679],
        [-4.8853, -2.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4204159677028656
Epoch 0, Step 5447: train/loss = 0.779191255569458, train/raw-loss = 0.7392553091049194, train/logprobs = tensor([[-1.5895, -4.3309],
        [-4.1493, -3.4795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3993598222732544
Epoch 0, Step 5448: train/loss = 0.4529968202114105, train/raw-loss = 0.41905638575553894, train/logprobs = tensor([[-2.0373, -8.0543],
        [-4.2527, -2.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3394041657447815
Epoch 0, Step 5449: train/loss = 0.061213165521621704, train/raw-loss = 0.0191893819719553, train/logprobs = tensor([[-1.6440, -7.5759],
        [-6.5109, -1.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42023786902427673
Epoch 0, Step 5450: train/loss = 0.48349687457084656, train/raw-loss = 0.4342406988143921, train/logprobs = tensor([[-2.2743, -6.5094],
        [-4.4569, -3.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4925619959831238
Epoch 0, Step 5451: train/loss = 0.08262477070093155, train/raw-loss = 0.040766578167676926, train/logprobs = tensor([[-1.4413, -8.0776],
        [-5.2828, -2.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4185819625854492
Epoch 0, Step 5452: train/loss = 0.279433935880661, train/raw-loss = 0.2441975474357605, train/logprobs = tensor([[-2.1072, -7.0317],
        [-6.3067, -3.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523640036582947
Epoch 0, Step 5453: train/loss = 0.11567588895559311, train/raw-loss = 0.07504317909479141, train/logprobs = tensor([[ -1.5823, -11.0369],
        [ -5.4268,  -5.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4063270688056946
Epoch 0, Step 5454: train/loss = 0.2528209090232849, train/raw-loss = 0.21288636326789856, train/logprobs = tensor([[-1.5622, -7.7421],
        [-5.4088, -2.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3993454873561859
Epoch 0, Step 5455: train/loss = 0.19835132360458374, train/raw-loss = 0.14989899098873138, train/logprobs = tensor([[ -1.7562, -12.5930],
        [ -5.9529,  -5.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4845232367515564
Epoch 0, Step 5456: train/loss = 0.21953459084033966, train/raw-loss = 0.17792099714279175, train/logprobs = tensor([[-1.7767, -8.6957],
        [-6.0107, -2.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4161359667778015
Epoch 0, Step 5457: train/loss = 0.6828792095184326, train/raw-loss = 0.635563850402832, train/logprobs = tensor([[-1.6294, -3.7357],
        [-5.8012, -4.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4731537997722626
Epoch 0, Step 5458: train/loss = 0.3413586914539337, train/raw-loss = 0.29271966218948364, train/logprobs = tensor([[ -2.3999, -10.1323],
        [ -5.2871,  -6.3971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48639047145843506
Epoch 0, Step 5459: train/loss = 0.23921604454517365, train/raw-loss = 0.20515483617782593, train/logprobs = tensor([[-1.5898, -9.0256],
        [-4.7925, -3.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3406120836734772
Epoch 0, Step 5460: train/loss = 0.15738685429096222, train/raw-loss = 0.12249675393104553, train/logprobs = tensor([[-1.3967, -7.5242],
        [-6.0313, -3.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3489011526107788
Epoch 0, Step 5461: train/loss = 0.31425511837005615, train/raw-loss = 0.2772238254547119, train/logprobs = tensor([[-1.6678, -5.7822],
        [-5.5844, -2.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37031275033950806
Epoch 0, Step 5462: train/loss = 0.20405274629592896, train/raw-loss = 0.15992844104766846, train/logprobs = tensor([[-1.1910, -7.8902],
        [-4.5656, -4.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4412432909011841
Epoch 0, Step 5463: train/loss = 0.04922368749976158, train/raw-loss = 0.0043105995282530785, train/logprobs = tensor([[ -2.1309, -16.1930],
        [ -8.3735,  -6.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4491308927536011
Epoch 0, Step 5464: train/loss = 0.4779607057571411, train/raw-loss = 0.4321689009666443, train/logprobs = tensor([[-1.4269, -4.4774],
        [-3.0622, -3.3486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45791834592819214
Epoch 0, Step 5465: train/loss = 0.281230092048645, train/raw-loss = 0.23686963319778442, train/logprobs = tensor([[-1.6515, -4.8684],
        [-4.8259, -2.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44360440969467163
Epoch 0, Step 5466: train/loss = 0.3284248411655426, train/raw-loss = 0.28851965069770813, train/logprobs = tensor([[-1.6442, -7.0101],
        [-4.3475, -3.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990519046783447
Epoch 0, Step 5467: train/loss = 0.05902160704135895, train/raw-loss = 0.011020689271390438, train/logprobs = tensor([[ -1.4394, -12.0211],
        [ -6.0192,  -2.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48000916838645935
Epoch 0, Step 5468: train/loss = 0.2406049221754074, train/raw-loss = 0.19564953446388245, train/logprobs = tensor([[ -1.5837, -11.1819],
        [ -5.7337,  -3.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.449553906917572
Epoch 0, Step 5469: train/loss = 0.43542078137397766, train/raw-loss = 0.4008849859237671, train/logprobs = tensor([[-1.3405, -5.4897],
        [-4.6007, -2.0161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34535786509513855
Epoch 0, Step 5470: train/loss = 0.510004460811615, train/raw-loss = 0.4775398075580597, train/logprobs = tensor([[-1.8758, -3.2702],
        [-4.6129, -2.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32464659214019775
Epoch 0, Step 5471: train/loss = 0.284722238779068, train/raw-loss = 0.23951023817062378, train/logprobs = tensor([[-1.5394, -8.1257],
        [-6.1208, -2.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45211994647979736
Epoch 0, Step 5472: train/loss = 0.16705924272537231, train/raw-loss = 0.13668429851531982, train/logprobs = tensor([[-1.7906, -7.4646],
        [-4.5695, -1.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30374932289123535
Epoch 0, Step 5473: train/loss = 0.24099192023277283, train/raw-loss = 0.1872757077217102, train/logprobs = tensor([[-1.7136, -8.7215],
        [-6.2103, -4.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5371620655059814
Epoch 0, Step 5474: train/loss = 0.5636205673217773, train/raw-loss = 0.5303303599357605, train/logprobs = tensor([[-2.0064, -3.8190],
        [-3.5884, -3.4757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3329022526741028
Epoch 0, Step 5475: train/loss = 0.3551378846168518, train/raw-loss = 0.3208889961242676, train/logprobs = tensor([[-2.5514, -4.4735],
        [-4.6814, -2.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3424888551235199
Epoch 0, Step 5476: train/loss = 0.4551967978477478, train/raw-loss = 0.4228813648223877, train/logprobs = tensor([[-2.6051, -5.4067],
        [-3.7443, -2.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32315441966056824
Epoch 0, Step 5477: train/loss = 0.2041318416595459, train/raw-loss = 0.16490724682807922, train/logprobs = tensor([[ -1.6383, -12.0951],
        [ -5.8532,  -6.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39224597811698914
Epoch 0, Step 5478: train/loss = 0.19557155668735504, train/raw-loss = 0.1567472219467163, train/logprobs = tensor([[-2.1669, -9.4540],
        [-5.4750, -3.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3882432281970978
Epoch 0, Step 5479: train/loss = 0.15723571181297302, train/raw-loss = 0.11090055853128433, train/logprobs = tensor([[-2.2981, -8.9446],
        [-6.2915, -3.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46335142850875854
Epoch 0, Step 5480: train/loss = 0.623335599899292, train/raw-loss = 0.5812216997146606, train/logprobs = tensor([[-1.7656, -2.8354],
        [-3.6026, -3.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4211392402648926
Epoch 0, Step 5481: train/loss = 0.21496964991092682, train/raw-loss = 0.17222516238689423, train/logprobs = tensor([[-1.1959, -7.6282],
        [-4.1280, -3.1381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4274448752403259
Epoch 0, Step 5482: train/loss = 0.07802018523216248, train/raw-loss = 0.03374087065458298, train/logprobs = tensor([[-1.5515, -9.7071],
        [-5.2683, -2.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4427931308746338
Epoch 0, Step 5483: train/loss = 0.38623130321502686, train/raw-loss = 0.3377504348754883, train/logprobs = tensor([[-1.3152, -5.4803],
        [-5.3473, -1.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4848085641860962
Epoch 0, Step 5484: train/loss = 0.2298111915588379, train/raw-loss = 0.1967608630657196, train/logprobs = tensor([[-4.0307, -9.6309],
        [-6.0428, -5.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3305031955242157
Epoch 0, Step 5485: train/loss = 0.3199200928211212, train/raw-loss = 0.28635063767433167, train/logprobs = tensor([[-1.2726, -4.3545],
        [-4.4008, -1.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33569440245628357
Epoch 0, Step 5486: train/loss = 0.3361586034297943, train/raw-loss = 0.29131078720092773, train/logprobs = tensor([[-1.6971, -8.7793],
        [-6.3011, -3.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.448478102684021
Epoch 0, Step 5487: train/loss = 0.34287768602371216, train/raw-loss = 0.30522391200065613, train/logprobs = tensor([[-1.1658, -7.0915],
        [-5.3202, -2.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765374422073364
Epoch 0, Step 5488: train/loss = 0.12414612621068954, train/raw-loss = 0.08174130320549011, train/logprobs = tensor([[-1.4382, -7.9029],
        [-6.4847, -3.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42404818534851074
Epoch 0, Step 5489: train/loss = 0.5195189118385315, train/raw-loss = 0.4759756624698639, train/logprobs = tensor([[-1.0958, -3.6152],
        [-3.4575, -2.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4354322850704193
Epoch 0, Step 5490: train/loss = 0.5623723268508911, train/raw-loss = 0.5225743651390076, train/logprobs = tensor([[-1.1933, -4.8083],
        [-4.2423, -2.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3979790210723877
Epoch 0, Step 5491: train/loss = 0.528988778591156, train/raw-loss = 0.4768088459968567, train/logprobs = tensor([[-1.9491, -3.4133],
        [-4.8715, -2.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5217995643615723
Epoch 0, Step 5492: train/loss = 0.38876891136169434, train/raw-loss = 0.34029966592788696, train/logprobs = tensor([[-1.4147, -6.7858],
        [-6.3108, -3.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48469239473342896
Epoch 0, Step 5493: train/loss = 0.5777339935302734, train/raw-loss = 0.5317367911338806, train/logprobs = tensor([[-1.3147, -5.9353],
        [-3.9511, -4.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4599725604057312
Epoch 0, Step 5494: train/loss = 0.22320784628391266, train/raw-loss = 0.18387527763843536, train/logprobs = tensor([[-1.8415, -7.3563],
        [-4.2936, -2.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3933255076408386
Epoch 0, Step 5495: train/loss = 0.606324315071106, train/raw-loss = 0.5689917802810669, train/logprobs = tensor([[-1.9691, -2.4354],
        [-3.1794, -2.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733256161212921
Epoch 0, Step 5496: train/loss = 0.39813268184661865, train/raw-loss = 0.356242835521698, train/logprobs = tensor([[-2.1669, -9.2031],
        [-6.0450, -3.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41889822483062744
Epoch 0, Step 5497: train/loss = 0.0958527997136116, train/raw-loss = 0.05671720579266548, train/logprobs = tensor([[ -1.1642, -10.5306],
        [ -5.7931,  -2.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3913559019565582
Epoch 0, Step 5498: train/loss = 0.1004362404346466, train/raw-loss = 0.052423734217882156, train/logprobs = tensor([[ -2.5264, -12.3575],
        [ -7.1958,  -3.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4801250398159027
Epoch 0, Step 5499: train/loss = 0.35661154985427856, train/raw-loss = 0.31744417548179626, train/logprobs = tensor([[-1.8459, -5.8615],
        [-4.2796, -3.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3916737139225006
Epoch 0, Step 5500: train/loss = 0.3259373903274536, train/raw-loss = 0.28451284766197205, train/logprobs = tensor([[-1.2121, -8.0847],
        [-6.5373, -2.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41424527764320374
Epoch 0, Step 5501: train/loss = 0.20046526193618774, train/raw-loss = 0.1635134518146515, train/logprobs = tensor([[-1.3375, -5.9331],
        [-3.5086, -1.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3695181608200073
Epoch 0, Step 5502: train/loss = 0.21509170532226562, train/raw-loss = 0.1662462055683136, train/logprobs = tensor([[-1.7217, -8.6682],
        [-5.8827, -3.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48845499753952026
Epoch 0, Step 5503: train/loss = 0.5060989260673523, train/raw-loss = 0.4664698839187622, train/logprobs = tensor([[-1.3371, -2.7934],
        [-3.1556, -2.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3962898254394531
Epoch 0, Step 5504: train/loss = 0.09988679736852646, train/raw-loss = 0.06353389471769333, train/logprobs = tensor([[-2.6405, -8.0760],
        [-6.9298, -3.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36352893710136414
Epoch 0, Step 5505: train/loss = 0.35387808084487915, train/raw-loss = 0.3114750385284424, train/logprobs = tensor([[ -2.0061, -11.1293],
        [ -5.2169,  -4.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4240299463272095
Epoch 0, Step 5506: train/loss = 0.06969669461250305, train/raw-loss = 0.027886956930160522, train/logprobs = tensor([[ -1.7378, -12.6564],
        [ -6.1883,  -2.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4180973470211029
Epoch 0, Step 5507: train/loss = 0.327290415763855, train/raw-loss = 0.28157103061676025, train/logprobs = tensor([[-1.7466, -4.3155],
        [-5.2313, -2.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45719417929649353
Epoch 0, Step 5508: train/loss = 0.1436430960893631, train/raw-loss = 0.10583270341157913, train/logprobs = tensor([[ -1.2172, -14.5260],
        [ -4.4042,  -6.4327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3781038820743561
Epoch 0, Step 5509: train/loss = 0.6497846245765686, train/raw-loss = 0.5988358855247498, train/logprobs = tensor([[-2.2192, -3.5267],
        [-6.0129, -4.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5094873905181885
Epoch 0, Step 5510: train/loss = 0.3448745012283325, train/raw-loss = 0.29723498225212097, train/logprobs = tensor([[-2.0459, -5.1914],
        [-7.6351, -3.2960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4763948917388916
Epoch 0, Step 5511: train/loss = 0.3533485531806946, train/raw-loss = 0.3159051537513733, train/logprobs = tensor([[-1.9180, -8.5104],
        [-4.3569, -3.2039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3744339346885681
Epoch 0, Step 5512: train/loss = 0.2698672413825989, train/raw-loss = 0.2269553542137146, train/logprobs = tensor([[ -2.2215, -10.7056],
        [ -4.8402,  -4.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4291190505027771
Epoch 0, Step 5513: train/loss = 0.31385064125061035, train/raw-loss = 0.26935234665870667, train/logprobs = tensor([[-1.6711, -6.9551],
        [-5.3365, -4.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44498276710510254
Epoch 0, Step 5514: train/loss = 0.30041563510894775, train/raw-loss = 0.2593042850494385, train/logprobs = tensor([[-1.8039, -9.5854],
        [-6.5856, -3.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.411112904548645
Epoch 0, Step 5515: train/loss = 0.20938369631767273, train/raw-loss = 0.17199145257472992, train/logprobs = tensor([[ -1.3066, -12.5600],
        [ -4.9134,  -1.5333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3739224076271057
Epoch 0, Step 5516: train/loss = 0.3710814118385315, train/raw-loss = 0.34320908784866333, train/logprobs = tensor([[-1.3632, -7.2108],
        [-4.6123, -3.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27872326970100403
Epoch 0, Step 5517: train/loss = 0.23225869238376617, train/raw-loss = 0.19318543374538422, train/logprobs = tensor([[-1.9443, -6.7792],
        [-5.7102, -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39073246717453003
Epoch 0, Step 5518: train/loss = 0.27155864238739014, train/raw-loss = 0.22733569145202637, train/logprobs = tensor([[-0.9640, -8.6447],
        [-5.1061, -2.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44222962856292725
Epoch 0, Step 5519: train/loss = 0.5196055769920349, train/raw-loss = 0.4849727153778076, train/logprobs = tensor([[-1.6727, -5.2100],
        [-5.0184, -3.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34632813930511475
Epoch 0, Step 5520: train/loss = 0.47445327043533325, train/raw-loss = 0.44088032841682434, train/logprobs = tensor([[-1.6536, -9.8146],
        [-4.3602, -3.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33572936058044434
Epoch 0, Step 5521: train/loss = 0.043622829020023346, train/raw-loss = 0.008907069452106953, train/logprobs = tensor([[-1.6751, -8.3547],
        [-6.3424, -1.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3471575677394867
Epoch 0, Step 5522: train/loss = 0.35574406385421753, train/raw-loss = 0.3242984414100647, train/logprobs = tensor([[-1.8242, -8.4671],
        [-4.6946, -2.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31445616483688354
Epoch 0, Step 5523: train/loss = 0.46893322467803955, train/raw-loss = 0.4429645836353302, train/logprobs = tensor([[-1.3476, -5.2817],
        [-2.7784, -1.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25968652963638306
Epoch 0, Step 5524: train/loss = 0.16049301624298096, train/raw-loss = 0.11047766357660294, train/logprobs = tensor([[ -2.6616, -15.2730],
        [ -7.6741,  -6.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5001534223556519
Epoch 0, Step 5525: train/loss = 0.4276167154312134, train/raw-loss = 0.39216741919517517, train/logprobs = tensor([[-2.5588, -3.1552],
        [-2.9665, -1.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3544931709766388
Epoch 0, Step 5526: train/loss = 0.04602614790201187, train/raw-loss = 0.0026837666518986225, train/logprobs = tensor([[ -1.4805, -13.9748],
        [ -7.4142,  -2.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43342381715774536
Epoch 0, Step 5527: train/loss = 0.723315954208374, train/raw-loss = 0.6788532733917236, train/logprobs = tensor([[-2.7270, -6.5880],
        [-5.8465, -3.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44462642073631287
Epoch 0, Step 5528: train/loss = 0.9164581894874573, train/raw-loss = 0.8784142732620239, train/logprobs = tensor([[-2.3510, -4.0560],
        [-4.3022, -3.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3804389238357544
Epoch 0, Step 5529: train/loss = 0.30371713638305664, train/raw-loss = 0.2629457116127014, train/logprobs = tensor([[-2.4921, -5.4607],
        [-5.3953, -2.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4077144265174866
Epoch 0, Step 5530: train/loss = 0.3607064187526703, train/raw-loss = 0.3240361511707306, train/logprobs = tensor([[-1.8573, -8.1395],
        [-6.8255, -6.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36670297384262085
Epoch 0, Step 5531: train/loss = 0.5723493099212646, train/raw-loss = 0.53302401304245, train/logprobs = tensor([[-2.0154, -3.1641],
        [-3.4573, -3.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39325326681137085
Epoch 0, Step 5532: train/loss = 0.5769607424736023, train/raw-loss = 0.539077639579773, train/logprobs = tensor([[-2.8676, -7.7544],
        [-3.9520, -2.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3788309395313263
Epoch 0, Step 5533: train/loss = 0.11618727445602417, train/raw-loss = 0.0875852182507515, train/logprobs = tensor([[-1.8291, -7.4289],
        [-6.2749, -3.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28602051734924316
Epoch 0, Step 5534: train/loss = 0.42983278632164, train/raw-loss = 0.3892673850059509, train/logprobs = tensor([[-1.9368, -5.2965],
        [-6.1833, -2.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4056538939476013
Epoch 0, Step 5535: train/loss = 0.36277562379837036, train/raw-loss = 0.32242196798324585, train/logprobs = tensor([[-1.9701, -7.7844],
        [-5.1043, -4.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40353667736053467
Epoch 0, Step 5536: train/loss = 0.26005181670188904, train/raw-loss = 0.22306379675865173, train/logprobs = tensor([[-1.3762, -8.2091],
        [-4.4153, -2.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3698802888393402
Epoch 0, Step 5537: train/loss = 0.49602586030960083, train/raw-loss = 0.4491945803165436, train/logprobs = tensor([[-1.1884, -7.8846],
        [-3.9002, -4.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46831291913986206
Epoch 0, Step 5538: train/loss = 0.15204530954360962, train/raw-loss = 0.11567144840955734, train/logprobs = tensor([[ -2.1579, -12.2808],
        [ -5.3600,  -5.4532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36373865604400635
Epoch 0, Step 5539: train/loss = 0.12293703854084015, train/raw-loss = 0.08212189376354218, train/logprobs = tensor([[-1.3722, -8.5653],
        [-4.7493, -2.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081513583660126
Epoch 0, Step 5540: train/loss = 0.2790578305721283, train/raw-loss = 0.23682811856269836, train/logprobs = tensor([[ -1.1305, -13.0174],
        [ -4.0573,  -2.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4222971498966217
Epoch 0, Step 5541: train/loss = 0.25636476278305054, train/raw-loss = 0.20893019437789917, train/logprobs = tensor([[-0.8447, -8.9114],
        [-3.9707, -2.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.474345862865448
Epoch 0, Step 5542: train/loss = 0.26668399572372437, train/raw-loss = 0.22448110580444336, train/logprobs = tensor([[-1.7472, -5.1773],
        [-5.3524, -3.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42202895879745483
Epoch 0, Step 5543: train/loss = 0.5058883428573608, train/raw-loss = 0.46251770853996277, train/logprobs = tensor([[-1.4122, -8.6577],
        [-4.9611, -3.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43370577692985535
Epoch 0, Step 5544: train/loss = 0.49316808581352234, train/raw-loss = 0.4572567641735077, train/logprobs = tensor([[-1.4683, -2.2213],
        [-3.1398, -1.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35911333560943604
Epoch 0, Step 5545: train/loss = 0.24616050720214844, train/raw-loss = 0.19912680983543396, train/logprobs = tensor([[-2.0817, -6.3285],
        [-6.0993, -3.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4703369736671448
Epoch 0, Step 5546: train/loss = 0.4820060431957245, train/raw-loss = 0.4427577257156372, train/logprobs = tensor([[-1.0680, -6.2179],
        [-4.6123, -2.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.392483115196228
Epoch 0, Step 5547: train/loss = 0.29463890194892883, train/raw-loss = 0.2499813586473465, train/logprobs = tensor([[ -1.7665, -10.5825],
        [ -6.3485,  -6.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44657576084136963
Epoch 0, Step 5548: train/loss = 0.2449726164340973, train/raw-loss = 0.20949752628803253, train/logprobs = tensor([[-1.8938, -5.7232],
        [-4.4871, -2.0910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35475072264671326
Epoch 0, Step 5549: train/loss = 0.6010728478431702, train/raw-loss = 0.5644592642784119, train/logprobs = tensor([[-2.0283, -5.3325],
        [-3.9973, -1.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661358952522278
Epoch 0, Step 5550: train/loss = 0.3300269544124603, train/raw-loss = 0.2908591628074646, train/logprobs = tensor([[-1.6588, -4.0528],
        [-4.9304, -2.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39167797565460205
Epoch 0, Step 5551: train/loss = 0.26511168479919434, train/raw-loss = 0.2234993278980255, train/logprobs = tensor([[-1.8006, -9.3482],
        [-4.9921, -4.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41612377762794495
Epoch 0, Step 5552: train/loss = 0.38102731108665466, train/raw-loss = 0.3409097492694855, train/logprobs = tensor([[-1.6445, -4.4464],
        [-5.4657, -3.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40117567777633667
Epoch 0, Step 5553: train/loss = 0.35556918382644653, train/raw-loss = 0.31456729769706726, train/logprobs = tensor([[-2.1907, -7.6737],
        [-5.1490, -2.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4100186824798584
Epoch 0, Step 5554: train/loss = 0.623184323310852, train/raw-loss = 0.5794492959976196, train/logprobs = tensor([[-1.5492, -4.8567],
        [-3.7558, -4.4428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4373500347137451
Epoch 0, Step 5555: train/loss = 0.6748582124710083, train/raw-loss = 0.641142725944519, train/logprobs = tensor([[-2.3837, -2.8353],
        [-2.9627, -2.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3371543288230896
Epoch 0, Step 5556: train/loss = 0.1106237918138504, train/raw-loss = 0.07348079979419708, train/logprobs = tensor([[-1.6574, -7.7971],
        [-6.3631, -1.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714298605918884
Epoch 0, Step 5557: train/loss = 0.3500358462333679, train/raw-loss = 0.3043091297149658, train/logprobs = tensor([[-1.6092, -8.3434],
        [-5.0231, -2.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45726728439331055
Epoch 0, Step 5558: train/loss = 0.37988895177841187, train/raw-loss = 0.3332808315753937, train/logprobs = tensor([[-1.2162, -9.3844],
        [-6.4792, -3.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4660813808441162
Epoch 0, Step 5559: train/loss = 0.06103445589542389, train/raw-loss = 0.0236447062343359, train/logprobs = tensor([[ -1.9792, -13.5084],
        [ -5.9964,  -4.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.373897522687912
Epoch 0, Step 5560: train/loss = 0.14546024799346924, train/raw-loss = 0.10812082886695862, train/logprobs = tensor([[ -1.6363, -14.0444],
        [ -6.0821,  -5.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3733941912651062
Epoch 0, Step 5561: train/loss = 0.7745893001556396, train/raw-loss = 0.7223209738731384, train/logprobs = tensor([[-1.9119, -5.3262],
        [-4.6433, -2.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5226830840110779
Epoch 0, Step 5562: train/loss = 0.8142087459564209, train/raw-loss = 0.7714067101478577, train/logprobs = tensor([[-2.9136, -3.0569],
        [-3.1549, -3.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42802074551582336
Epoch 0, Step 5563: train/loss = 0.33876723051071167, train/raw-loss = 0.3076046109199524, train/logprobs = tensor([[-1.2268, -7.2923],
        [-3.5212, -1.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116258978843689
Epoch 0, Step 5564: train/loss = 0.36526817083358765, train/raw-loss = 0.3323940634727478, train/logprobs = tensor([[-1.1500, -7.1283],
        [-4.3824, -3.3272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287414312362671
Epoch 0, Step 5565: train/loss = 0.5506159067153931, train/raw-loss = 0.4995041787624359, train/logprobs = tensor([[-0.8671, -2.6531],
        [-4.2181, -2.6001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5111175775527954
Epoch 0, Step 5566: train/loss = 0.23556077480316162, train/raw-loss = 0.19109882414340973, train/logprobs = tensor([[-1.6959, -7.4064],
        [-5.1499, -2.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4446195065975189
Epoch 0, Step 5567: train/loss = 0.38261520862579346, train/raw-loss = 0.33804240822792053, train/logprobs = tensor([[ -1.7436, -15.0126],
        [ -5.8028,  -5.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4457283616065979
Epoch 0, Step 5568: train/loss = 0.22869634628295898, train/raw-loss = 0.19379086792469025, train/logprobs = tensor([[ -2.2520, -13.1902],
        [ -5.4838,  -5.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34905481338500977
Epoch 0, Step 5569: train/loss = 0.5998597145080566, train/raw-loss = 0.5544697046279907, train/logprobs = tensor([[-1.7465, -2.4343],
        [-4.4002, -3.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45390018820762634
Epoch 0, Step 5570: train/loss = 0.1872704029083252, train/raw-loss = 0.15115971863269806, train/logprobs = tensor([[ -2.5470, -10.3309],
        [ -6.4964,  -2.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3611070513725281
Epoch 0, Step 5571: train/loss = 0.2522505819797516, train/raw-loss = 0.2167610079050064, train/logprobs = tensor([[ -1.4130, -13.6752],
        [ -3.6650,  -4.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3548959195613861
Epoch 0, Step 5572: train/loss = 0.4182071089744568, train/raw-loss = 0.3763066828250885, train/logprobs = tensor([[-1.9223, -5.3627],
        [-3.4693, -1.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41900399327278137
Epoch 0, Step 5573: train/loss = 0.37563127279281616, train/raw-loss = 0.33352646231651306, train/logprobs = tensor([[-1.0393, -4.0218],
        [-3.9368, -3.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4210481643676758
Epoch 0, Step 5574: train/loss = 0.45896926522254944, train/raw-loss = 0.4105662703514099, train/logprobs = tensor([[-1.9867, -4.7069],
        [-4.6719, -3.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48402994871139526
Epoch 0, Step 5575: train/loss = 0.1747732162475586, train/raw-loss = 0.1276010423898697, train/logprobs = tensor([[-1.4528, -7.5721],
        [-5.6161, -3.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47172194719314575
Epoch 0, Step 5576: train/loss = 0.3647570013999939, train/raw-loss = 0.32825928926467896, train/logprobs = tensor([[-1.3269, -3.4191],
        [-5.5123, -2.2595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3649773597717285
Epoch 0, Step 5577: train/loss = 0.30767738819122314, train/raw-loss = 0.2700144648551941, train/logprobs = tensor([[-1.4732, -8.6767],
        [-4.3548, -5.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.376629114151001
Epoch 0, Step 5578: train/loss = 0.5096997022628784, train/raw-loss = 0.4702906608581543, train/logprobs = tensor([[-2.2756, -8.7578],
        [-4.6452, -1.7551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39409083127975464
Epoch 0, Step 5579: train/loss = 0.193915456533432, train/raw-loss = 0.1530643105506897, train/logprobs = tensor([[ -2.6017, -10.3165],
        [ -7.0255,  -4.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4085114598274231
Epoch 0, Step 5580: train/loss = 0.2517012059688568, train/raw-loss = 0.2205149531364441, train/logprobs = tensor([[-1.3438, -5.0980],
        [-3.8007, -1.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31186243891716003
Epoch 0, Step 5581: train/loss = 0.44641461968421936, train/raw-loss = 0.4088028073310852, train/logprobs = tensor([[-1.5186, -3.5204],
        [-3.7792, -2.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37611836194992065
Epoch 0, Step 5582: train/loss = 0.10462749004364014, train/raw-loss = 0.06349415332078934, train/logprobs = tensor([[-2.2660, -6.9073],
        [-6.7100, -2.0419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4113333821296692
Epoch 0, Step 5583: train/loss = 0.5774121880531311, train/raw-loss = 0.5366671085357666, train/logprobs = tensor([[-1.7782, -2.0978],
        [-4.4886, -2.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40745091438293457
Epoch 0, Step 5584: train/loss = 0.31946712732315063, train/raw-loss = 0.28452789783477783, train/logprobs = tensor([[-1.9004, -5.0878],
        [-2.9202, -1.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34939247369766235
Epoch 0, Step 5585: train/loss = 0.532484769821167, train/raw-loss = 0.5007914900779724, train/logprobs = tensor([[-1.5728, -3.5779],
        [-3.9802, -1.2258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31693294644355774
Epoch 0, Step 5586: train/loss = 0.14865697920322418, train/raw-loss = 0.10897130519151688, train/logprobs = tensor([[-1.7439, -7.5713],
        [-5.6782, -2.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3968566060066223
Epoch 0, Step 5587: train/loss = 0.5047404170036316, train/raw-loss = 0.4726599156856537, train/logprobs = tensor([[-1.2587, -5.6000],
        [-3.0086, -3.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32080507278442383
Epoch 0, Step 5588: train/loss = 0.105633944272995, train/raw-loss = 0.0663621574640274, train/logprobs = tensor([[-0.9265, -9.3484],
        [-4.8995, -2.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39271777868270874
Epoch 0, Step 5589: train/loss = 0.15360599756240845, train/raw-loss = 0.11638783663511276, train/logprobs = tensor([[ -1.8074, -11.4179],
        [ -4.4152,  -4.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721815049648285
Epoch 0, Step 5590: train/loss = 0.05382810905575752, train/raw-loss = 0.01073220930993557, train/logprobs = tensor([[ -1.7620, -14.4349],
        [ -5.9392,  -5.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.430959016084671
Epoch 0, Step 5591: train/loss = 0.12390641123056412, train/raw-loss = 0.07840698212385178, train/logprobs = tensor([[ -1.7474, -11.7397],
        [ -6.0873,  -4.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.454994261264801
Epoch 0, Step 5592: train/loss = 0.17557327449321747, train/raw-loss = 0.13155820965766907, train/logprobs = tensor([[ -2.3701, -12.0431],
        [ -6.1545,  -3.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44015073776245117
Epoch 0, Step 5593: train/loss = 0.4044525921344757, train/raw-loss = 0.35996660590171814, train/logprobs = tensor([[ -1.4345, -10.8530],
        [ -5.7218,  -5.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4448601007461548
Epoch 0, Step 5594: train/loss = 0.1683310568332672, train/raw-loss = 0.13717640936374664, train/logprobs = tensor([[-1.8638, -7.6242],
        [-4.9336, -3.2339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31154659390449524
Epoch 0, Step 5595: train/loss = 0.23293384909629822, train/raw-loss = 0.18708138167858124, train/logprobs = tensor([[-1.0429, -6.3542],
        [-4.6768, -1.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.458524614572525
Epoch 0, Step 5596: train/loss = 0.26588892936706543, train/raw-loss = 0.22631622850894928, train/logprobs = tensor([[-1.6296, -5.0309],
        [-4.6078, -2.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3957269787788391
Epoch 0, Step 5597: train/loss = 0.14921605587005615, train/raw-loss = 0.10484887659549713, train/logprobs = tensor([[-1.3584, -7.5754],
        [-4.8541, -2.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4436718821525574
Epoch 0, Step 5598: train/loss = 0.2971119284629822, train/raw-loss = 0.25880205631256104, train/logprobs = tensor([[-2.2090, -6.0553],
        [-4.9653, -3.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3830983638763428
Epoch 0, Step 5599: train/loss = 0.573409378528595, train/raw-loss = 0.5288956761360168, train/logprobs = tensor([[-1.5467, -2.4385],
        [-2.5707, -1.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4451369345188141
Epoch 0, Step 5600: train/loss = 0.3156580924987793, train/raw-loss = 0.269145131111145, train/logprobs = tensor([[-1.2666, -9.5989],
        [-6.1524, -5.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46512943506240845
Epoch 0, Step 5601: train/loss = 0.395117849111557, train/raw-loss = 0.35238462686538696, train/logprobs = tensor([[-1.1693, -3.7462],
        [-5.0374, -3.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42733222246170044
Epoch 0, Step 5602: train/loss = 0.2385965883731842, train/raw-loss = 0.19526498019695282, train/logprobs = tensor([[ -1.4391, -11.0356],
        [ -4.0606,  -5.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43331611156463623
Epoch 0, Step 5603: train/loss = 0.3105989098548889, train/raw-loss = 0.27599453926086426, train/logprobs = tensor([[-1.6964, -6.4135],
        [-4.4752, -2.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34604325890541077
Epoch 0, Step 5604: train/loss = 0.18537376821041107, train/raw-loss = 0.1502019464969635, train/logprobs = tensor([[-0.9135, -8.5389],
        [-3.9097, -2.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35171812772750854
Epoch 0, Step 5605: train/loss = 0.4182307720184326, train/raw-loss = 0.3868176341056824, train/logprobs = tensor([[-1.6756, -5.0602],
        [-2.4320, -2.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141317665576935
Epoch 0, Step 5606: train/loss = 0.07750315964221954, train/raw-loss = 0.036511413753032684, train/logprobs = tensor([[ -1.7983, -12.4163],
        [ -6.1776,  -5.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4099174439907074
Epoch 0, Step 5607: train/loss = 0.06873361766338348, train/raw-loss = 0.024824488908052444, train/logprobs = tensor([[-1.7168, -8.2026],
        [-6.0137, -2.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.439091295003891
Epoch 0, Step 5608: train/loss = 0.2250971645116806, train/raw-loss = 0.19432631134986877, train/logprobs = tensor([[-1.6675, -4.9979],
        [-4.5925, -1.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077085614204407
Epoch 0, Step 5609: train/loss = 0.2638087868690491, train/raw-loss = 0.23436938226222992, train/logprobs = tensor([[-1.4316, -7.2285],
        [-3.7902, -1.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29439398646354675
Epoch 0, Step 5610: train/loss = 0.38065841794013977, train/raw-loss = 0.34636038541793823, train/logprobs = tensor([[-2.2292, -4.2763],
        [-3.2408, -2.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34298038482666016
Epoch 0, Step 5611: train/loss = 0.31860804557800293, train/raw-loss = 0.2929393947124481, train/logprobs = tensor([[ -1.3770, -11.8083],
        [ -3.1758,  -5.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566865384578705
Epoch 0, Step 5612: train/loss = 0.4284263849258423, train/raw-loss = 0.3862133324146271, train/logprobs = tensor([[-1.4162, -4.4987],
        [-4.4432, -3.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4221299886703491
Epoch 0, Step 5613: train/loss = 0.3676706552505493, train/raw-loss = 0.3237564265727997, train/logprobs = tensor([[-1.5220, -6.6128],
        [-4.4706, -2.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4391418993473053
Epoch 0, Step 5614: train/loss = 0.3386927843093872, train/raw-loss = 0.30382850766181946, train/logprobs = tensor([[-2.8130, -6.2915],
        [-4.6348, -2.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34864288568496704
Epoch 0, Step 5615: train/loss = 0.24114984273910522, train/raw-loss = 0.20143039524555206, train/logprobs = tensor([[-2.0529, -6.7146],
        [-5.1363, -2.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39719438552856445
Epoch 0, Step 5616: train/loss = 0.14017407596111298, train/raw-loss = 0.0934910774230957, train/logprobs = tensor([[-1.6726, -6.0995],
        [-6.3129, -2.2180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4668300747871399
Epoch 0, Step 5617: train/loss = 0.1732853651046753, train/raw-loss = 0.13656450808048248, train/logprobs = tensor([[-2.1836, -7.3049],
        [-4.2394, -1.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3672085106372833
Epoch 0, Step 5618: train/loss = 0.21658259630203247, train/raw-loss = 0.17315293848514557, train/logprobs = tensor([[-1.6947, -9.2965],
        [-4.6503, -2.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43429672718048096
Epoch 0, Step 5619: train/loss = 0.2708166539669037, train/raw-loss = 0.22683973610401154, train/logprobs = tensor([[-2.3955, -9.7653],
        [-6.6478, -2.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4397689700126648
Epoch 0, Step 5620: train/loss = 0.220774307847023, train/raw-loss = 0.1847039759159088, train/logprobs = tensor([[-1.4188, -7.2157],
        [-5.0287, -1.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3607034385204315
Epoch 0, Step 5621: train/loss = 0.054994337260723114, train/raw-loss = 0.023629307746887207, train/logprobs = tensor([[ -1.7384, -12.3770],
        [ -5.6161,  -2.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31365031003952026
Epoch 0, Step 5622: train/loss = 0.1700659692287445, train/raw-loss = 0.12510065734386444, train/logprobs = tensor([[-1.9018, -4.1616],
        [-6.3846, -2.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44965317845344543
Epoch 0, Step 5623: train/loss = 0.06857890635728836, train/raw-loss = 0.027472516521811485, train/logprobs = tensor([[ -1.5328, -10.9796],
        [ -6.1902,  -1.9430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4110638499259949
Epoch 0, Step 5624: train/loss = 0.04979139566421509, train/raw-loss = 0.007544795982539654, train/logprobs = tensor([[ -1.3365, -14.1646],
        [ -6.3053,  -4.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.422465980052948
Epoch 0, Step 5625: train/loss = 0.5194393396377563, train/raw-loss = 0.483134925365448, train/logprobs = tensor([[-1.6513, -3.4503],
        [-4.0249, -3.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36304447054862976
Epoch 0, Step 5626: train/loss = 0.47740843892097473, train/raw-loss = 0.44309693574905396, train/logprobs = tensor([[-2.1754, -7.5425],
        [-3.6709, -2.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431147634983063
Epoch 0, Step 5627: train/loss = 0.3883064091205597, train/raw-loss = 0.3574376702308655, train/logprobs = tensor([[ -1.6678, -10.3516],
        [ -3.7095,  -3.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30868712067604065
Epoch 0, Step 5628: train/loss = 0.05620913207530975, train/raw-loss = 0.02139558456838131, train/logprobs = tensor([[ -1.2536, -11.9996],
        [ -5.9715,  -2.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34813550114631653
Epoch 0, Step 5629: train/loss = 0.34734398126602173, train/raw-loss = 0.300942063331604, train/logprobs = tensor([[ -1.2090, -10.1442],
        [ -4.4876,  -2.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4640193283557892
Epoch 0, Step 5630: train/loss = 0.3172578811645508, train/raw-loss = 0.27237996459007263, train/logprobs = tensor([[-1.6419, -6.7500],
        [-5.4630, -3.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44877925515174866
Epoch 0, Step 5631: train/loss = 0.331032395362854, train/raw-loss = 0.2912003993988037, train/logprobs = tensor([[-1.3613, -9.8250],
        [-4.3969, -2.3796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3983203172683716
Epoch 0, Step 5632: train/loss = 0.25623369216918945, train/raw-loss = 0.2210891991853714, train/logprobs = tensor([[ -3.2060, -10.0513],
        [ -6.4507,  -3.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514450788497925
Epoch 0, Step 5633: train/loss = 0.13519518077373505, train/raw-loss = 0.08916552364826202, train/logprobs = tensor([[ -1.4467, -11.4249],
        [ -6.2722,  -5.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46029654145240784
Epoch 0, Step 5634: train/loss = 0.36085763573646545, train/raw-loss = 0.32097554206848145, train/logprobs = tensor([[-1.5902, -8.3185],
        [-5.0169, -2.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39882102608680725
Epoch 0, Step 5635: train/loss = 0.09696771204471588, train/raw-loss = 0.057749852538108826, train/logprobs = tensor([[ -1.2191, -11.0119],
        [ -5.4395,  -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39217856526374817
Epoch 0, Step 5636: train/loss = 0.31401172280311584, train/raw-loss = 0.2734287679195404, train/logprobs = tensor([[-1.9881, -5.9031],
        [-5.4353, -2.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4058299660682678
Epoch 0, Step 5637: train/loss = 0.27321135997772217, train/raw-loss = 0.24052588641643524, train/logprobs = tensor([[-1.2240, -4.1283],
        [-4.9514, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3268548548221588
Epoch 0, Step 5638: train/loss = 0.370886892080307, train/raw-loss = 0.3286378085613251, train/logprobs = tensor([[-1.4178, -6.9673],
        [-4.0080, -3.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4224909543991089
Epoch 0, Step 5639: train/loss = 0.14504428207874298, train/raw-loss = 0.10825955867767334, train/logprobs = tensor([[-1.4437, -5.9841],
        [-5.6202, -1.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36784738302230835
Epoch 0, Step 5640: train/loss = 0.21394892036914825, train/raw-loss = 0.17616428434848785, train/logprobs = tensor([[-3.5141, -8.0894],
        [-6.4436, -2.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778461515903473
Epoch 0, Step 5641: train/loss = 0.17947863042354584, train/raw-loss = 0.14237700402736664, train/logprobs = tensor([[-1.6069, -6.2436],
        [-4.6583, -1.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3710162937641144
Epoch 0, Step 5642: train/loss = 0.4599751830101013, train/raw-loss = 0.4174235165119171, train/logprobs = tensor([[-1.6053, -7.2439],
        [-4.4358, -2.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42551660537719727
Epoch 0, Step 5643: train/loss = 0.37220412492752075, train/raw-loss = 0.3387680947780609, train/logprobs = tensor([[-1.5006, -4.8854],
        [-3.6570, -4.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33436036109924316
Epoch 0, Step 5644: train/loss = 0.414120614528656, train/raw-loss = 0.3682430684566498, train/logprobs = tensor([[-1.5705, -9.6407],
        [-5.5995, -5.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4587755501270294
Epoch 0, Step 5645: train/loss = 0.4937567412853241, train/raw-loss = 0.4595664143562317, train/logprobs = tensor([[-1.7237, -6.3195],
        [-4.7130, -4.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3419031500816345
Epoch 0, Step 5646: train/loss = 0.1853431761264801, train/raw-loss = 0.14757658541202545, train/logprobs = tensor([[-1.8000, -9.5867],
        [-6.4106, -5.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3776659667491913
Epoch 0, Step 5647: train/loss = 0.41380220651626587, train/raw-loss = 0.3685033321380615, train/logprobs = tensor([[-1.9352, -4.3628],
        [-3.7969, -1.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45298901200294495
Epoch 0, Step 5648: train/loss = 0.30877289175987244, train/raw-loss = 0.26971954107284546, train/logprobs = tensor([[-2.4568, -9.7831],
        [-5.6058, -3.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3905335068702698
Epoch 0, Step 5649: train/loss = 0.5864809155464172, train/raw-loss = 0.5548785328865051, train/logprobs = tensor([[-1.5457, -2.2841],
        [-2.3122, -1.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31602323055267334
Epoch 0, Step 5650: train/loss = 0.1861066073179245, train/raw-loss = 0.14751388132572174, train/logprobs = tensor([[-0.8480, -8.4601],
        [-4.4130, -3.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3859270215034485
Epoch 0, Step 5651: train/loss = 0.3913266062736511, train/raw-loss = 0.3448691666126251, train/logprobs = tensor([[ -1.4483, -10.7204],
        [ -4.9050,  -4.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4645742177963257
Epoch 0, Step 5652: train/loss = 0.7550492286682129, train/raw-loss = 0.714870035648346, train/logprobs = tensor([[-1.7110, -1.8723],
        [-3.8795, -2.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40179213881492615
Epoch 0, Step 5653: train/loss = 0.07011491060256958, train/raw-loss = 0.043267957866191864, train/logprobs = tensor([[-2.1200, -7.9339],
        [-5.2105, -2.3370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26846951246261597
Epoch 0, Step 5654: train/loss = 0.2577979564666748, train/raw-loss = 0.21174001693725586, train/logprobs = tensor([[ -1.9915, -12.7333],
        [ -6.6899,  -5.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4605793058872223
Epoch 0, Step 5655: train/loss = 0.4599425494670868, train/raw-loss = 0.4231289029121399, train/logprobs = tensor([[-2.9845, -6.7372],
        [-3.8471, -2.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3681362569332123
Epoch 0, Step 5656: train/loss = 0.24045783281326294, train/raw-loss = 0.20377498865127563, train/logprobs = tensor([[ -3.1873, -10.7136],
        [ -7.0812,  -6.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3668285310268402
Epoch 0, Step 5657: train/loss = 0.08358293771743774, train/raw-loss = 0.05307282507419586, train/logprobs = tensor([[ -1.6606, -12.6318],
        [ -4.5410,  -3.1464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30510109663009644
Epoch 0, Step 5658: train/loss = 0.12380491197109222, train/raw-loss = 0.08404772728681564, train/logprobs = tensor([[ -1.6501, -11.6250],
        [ -4.8496,  -3.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3975718021392822
Epoch 0, Step 5659: train/loss = 0.5482285618782043, train/raw-loss = 0.5156314373016357, train/logprobs = tensor([[-3.1556, -6.4181],
        [-3.6789, -2.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3259711265563965
Epoch 0, Step 5660: train/loss = 0.2310558557510376, train/raw-loss = 0.19691845774650574, train/logprobs = tensor([[ -1.8945, -12.8720],
        [ -4.0149,  -6.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341374009847641
Epoch 0, Step 5661: train/loss = 0.26820600032806396, train/raw-loss = 0.21785672008991241, train/logprobs = tensor([[ -1.6788, -10.4217],
        [ -4.8944,  -3.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5034930109977722
Epoch 0, Step 5662: train/loss = 0.20785370469093323, train/raw-loss = 0.17076297104358673, train/logprobs = tensor([[ -1.6289, -13.1768],
        [ -6.6064,  -2.7371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3709073066711426
Epoch 0, Step 5663: train/loss = 0.2630462348461151, train/raw-loss = 0.22625605762004852, train/logprobs = tensor([[-1.0977, -5.7489],
        [-3.7999, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36790159344673157
Epoch 0, Step 5664: train/loss = 0.5030241012573242, train/raw-loss = 0.46749424934387207, train/logprobs = tensor([[-2.4179, -5.1916],
        [-2.9528, -2.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3552984297275543
Epoch 0, Step 5665: train/loss = 0.5867249369621277, train/raw-loss = 0.5516015291213989, train/logprobs = tensor([[-1.5820, -2.6938],
        [-2.5672, -2.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3512342572212219
Epoch 0, Step 5666: train/loss = 0.0791281908750534, train/raw-loss = 0.03200855851173401, train/logprobs = tensor([[ -1.0817, -10.2312],
        [ -5.3615,  -2.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4711962938308716
Epoch 0, Step 5667: train/loss = 0.27607202529907227, train/raw-loss = 0.24143625795841217, train/logprobs = tensor([[-1.7157, -7.9484],
        [-3.5243, -1.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34635770320892334
Epoch 0, Step 5668: train/loss = 0.23795294761657715, train/raw-loss = 0.19428104162216187, train/logprobs = tensor([[-1.5743, -5.1632],
        [-4.4784, -1.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4367191195487976
Epoch 0, Step 5669: train/loss = 0.41438496112823486, train/raw-loss = 0.38155919313430786, train/logprobs = tensor([[-2.2887, -8.1426],
        [-3.2538, -3.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32825779914855957
Epoch 0, Step 5670: train/loss = 0.19350002706050873, train/raw-loss = 0.15750379860401154, train/logprobs = tensor([[ -1.9968, -11.1055],
        [ -5.4267,  -2.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35996225476264954
Epoch 0, Step 5671: train/loss = 0.49321243166923523, train/raw-loss = 0.4575769007205963, train/logprobs = tensor([[-3.0355, -4.9819],
        [-4.9384, -3.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3563554286956787
Epoch 0, Step 5672: train/loss = 0.39738771319389343, train/raw-loss = 0.35594362020492554, train/logprobs = tensor([[ -2.6745, -11.7771],
        [ -4.6014,  -5.4544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4144406318664551
Epoch 0, Step 5673: train/loss = 0.18990130722522736, train/raw-loss = 0.1529022604227066, train/logprobs = tensor([[ -1.9825, -13.6538],
        [ -6.0451,  -6.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3699904680252075
Epoch 0, Step 5674: train/loss = 0.19176672399044037, train/raw-loss = 0.1451244056224823, train/logprobs = tensor([[-1.7343, -4.1803],
        [-5.3014, -1.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4664232134819031
Epoch 0, Step 5675: train/loss = 0.2744022309780121, train/raw-loss = 0.24186615645885468, train/logprobs = tensor([[-2.0285, -8.2405],
        [-5.6592, -2.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32536089420318604
Epoch 0, Step 5676: train/loss = 0.46265918016433716, train/raw-loss = 0.4156442880630493, train/logprobs = tensor([[-1.5291, -7.6089],
        [-3.7192, -3.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4701489508152008
Epoch 0, Step 5677: train/loss = 0.335178017616272, train/raw-loss = 0.29588639736175537, train/logprobs = tensor([[-2.5529, -6.5859],
        [-3.7768, -3.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39291632175445557
Epoch 0, Step 5678: train/loss = 0.5067611336708069, train/raw-loss = 0.4626653790473938, train/logprobs = tensor([[-1.7292, -3.6697],
        [-5.1978, -2.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409577250480652
Epoch 0, Step 5679: train/loss = 0.2388838827610016, train/raw-loss = 0.1984816938638687, train/logprobs = tensor([[-1.8289, -7.4577],
        [-5.6055, -2.3589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40402162075042725
Epoch 0, Step 5680: train/loss = 0.41264185309410095, train/raw-loss = 0.36749064922332764, train/logprobs = tensor([[-1.5975, -7.6948],
        [-3.8216, -1.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45151185989379883
Epoch 0, Step 5681: train/loss = 0.18205302953720093, train/raw-loss = 0.14297601580619812, train/logprobs = tensor([[-1.6142, -9.1037],
        [-5.7190, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3907700777053833
Epoch 0, Step 5682: train/loss = 0.17173656821250916, train/raw-loss = 0.1337118148803711, train/logprobs = tensor([[-1.1216, -9.3288],
        [-4.6057, -1.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3802475929260254
Epoch 0, Step 5683: train/loss = 0.17651274800300598, train/raw-loss = 0.13370296359062195, train/logprobs = tensor([[-1.8435, -8.4509],
        [-4.8982, -2.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4280977249145508
Epoch 0, Step 5684: train/loss = 0.5078365802764893, train/raw-loss = 0.4676244854927063, train/logprobs = tensor([[-1.7448, -5.2938],
        [-4.4722, -3.3720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40212059020996094
Epoch 0, Step 5685: train/loss = 0.17770332098007202, train/raw-loss = 0.1404467076063156, train/logprobs = tensor([[ -2.0839, -11.0152],
        [ -4.3316,  -2.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37256598472595215
Epoch 0, Step 5686: train/loss = 0.42946162819862366, train/raw-loss = 0.38477036356925964, train/logprobs = tensor([[-2.6424, -6.1263],
        [-4.9828, -3.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4469124972820282
Epoch 0, Step 5687: train/loss = 0.34897175431251526, train/raw-loss = 0.3088502883911133, train/logprobs = tensor([[-1.6148, -6.5679],
        [-4.7295, -2.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40121471881866455
Epoch 0, Step 5688: train/loss = 0.09513261169195175, train/raw-loss = 0.05985467880964279, train/logprobs = tensor([[ -1.7602, -10.2640],
        [ -4.2906,  -2.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527792990207672
Epoch 0, Step 5689: train/loss = 0.1149245873093605, train/raw-loss = 0.07643590122461319, train/logprobs = tensor([[-1.6192, -7.0551],
        [-4.8952, -3.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38488689064979553
Epoch 0, Step 5690: train/loss = 0.3332597017288208, train/raw-loss = 0.29406794905662537, train/logprobs = tensor([[ -1.7136, -11.5071],
        [ -3.4246,  -3.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3919176459312439
Epoch 0, Step 5691: train/loss = 0.47532880306243896, train/raw-loss = 0.4397839605808258, train/logprobs = tensor([[ -0.8587, -10.0465],
        [ -6.3949,  -7.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35544833540916443
Epoch 0, Step 5692: train/loss = 0.3401053547859192, train/raw-loss = 0.2922365367412567, train/logprobs = tensor([[-2.5581, -6.0210],
        [-4.9073, -1.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47868847846984863
Epoch 0, Step 5693: train/loss = 0.14524006843566895, train/raw-loss = 0.10659456253051758, train/logprobs = tensor([[-1.3646, -5.6564],
        [-5.1389, -2.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38645514845848083
Epoch 0, Step 5694: train/loss = 0.3351365327835083, train/raw-loss = 0.29556918144226074, train/logprobs = tensor([[-2.6575, -7.0322],
        [-5.3583, -4.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3956735134124756
Epoch 0, Step 5695: train/loss = 0.12798048555850983, train/raw-loss = 0.09459544718265533, train/logprobs = tensor([[-1.2257, -7.4499],
        [-4.5632, -2.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33385032415390015
Epoch 0, Step 5696: train/loss = 0.1988126039505005, train/raw-loss = 0.16212953627109528, train/logprobs = tensor([[ -2.1795, -15.3329],
        [ -5.3733,  -5.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3668307363986969
Epoch 0, Step 5697: train/loss = 0.11727385222911835, train/raw-loss = 0.0738830715417862, train/logprobs = tensor([[ -1.7025, -13.9953],
        [ -5.5412,  -2.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4339078366756439
Epoch 0, Step 5698: train/loss = 0.32296884059906006, train/raw-loss = 0.27782994508743286, train/logprobs = tensor([[-1.6914, -9.4457],
        [-4.4731, -4.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45138874650001526
Epoch 0, Step 5699: train/loss = 0.26443037390708923, train/raw-loss = 0.21695470809936523, train/logprobs = tensor([[-1.8907, -6.7411],
        [-4.3146, -2.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4747568368911743
Epoch 0, Step 5700: train/loss = 0.7158166170120239, train/raw-loss = 0.6940171122550964, train/logprobs = tensor([[-1.4675, -1.4277],
        [-3.1272, -1.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21799546480178833
Epoch 0, Step 5701: train/loss = 0.6104788184165955, train/raw-loss = 0.5748933553695679, train/logprobs = tensor([[-2.2881, -3.5090],
        [-3.9601, -3.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35585469007492065
Epoch 0, Step 5702: train/loss = 0.2693658471107483, train/raw-loss = 0.23637033998966217, train/logprobs = tensor([[-1.3715, -4.3735],
        [-3.7494, -1.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32995501160621643
Epoch 0, Step 5703: train/loss = 0.3931904435157776, train/raw-loss = 0.3557685613632202, train/logprobs = tensor([[-1.8199, -4.8656],
        [-3.2258, -2.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3742188811302185
Epoch 0, Step 5704: train/loss = 0.8147333264350891, train/raw-loss = 0.7738977670669556, train/logprobs = tensor([[-1.0364, -7.7477],
        [-3.1964, -5.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4083555340766907
Epoch 0, Step 5705: train/loss = 0.21400612592697144, train/raw-loss = 0.18042390048503876, train/logprobs = tensor([[-1.9210, -4.8122],
        [-5.4978, -2.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3358222544193268
Epoch 0, Step 5706: train/loss = 0.32684457302093506, train/raw-loss = 0.29800936579704285, train/logprobs = tensor([[-0.6269, -5.8007],
        [-2.4827, -3.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28835219144821167
Epoch 0, Step 5707: train/loss = 0.2565012276172638, train/raw-loss = 0.21346931159496307, train/logprobs = tensor([[-1.3224, -8.2843],
        [-6.9366, -3.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4303189814090729
Epoch 0, Step 5708: train/loss = 0.43668031692504883, train/raw-loss = 0.38870710134506226, train/logprobs = tensor([[-1.5077, -4.8184],
        [-5.0208, -3.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4797322154045105
Epoch 0, Step 5709: train/loss = 0.23506151139736176, train/raw-loss = 0.19484901428222656, train/logprobs = tensor([[-1.9494, -6.0571],
        [-4.1288, -2.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40212488174438477
Epoch 0, Step 5710: train/loss = 0.23906159400939941, train/raw-loss = 0.20266909897327423, train/logprobs = tensor([[-1.2755, -5.3246],
        [-3.4276, -1.2709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3639248311519623
Epoch 0, Step 5711: train/loss = 0.13550105690956116, train/raw-loss = 0.09998172521591187, train/logprobs = tensor([[ -3.2560, -15.6255],
        [ -5.3881,  -4.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35519346594810486
Epoch 0, Step 5712: train/loss = 0.11011523008346558, train/raw-loss = 0.07753925025463104, train/logprobs = tensor([[-1.2390, -7.5974],
        [-5.2338, -2.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3257598280906677
Epoch 0, Step 5713: train/loss = 0.23505112528800964, train/raw-loss = 0.1919066309928894, train/logprobs = tensor([[-2.8279, -9.6810],
        [-5.9637, -1.5937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4314449429512024
Epoch 0, Step 5714: train/loss = 0.3394114375114441, train/raw-loss = 0.29953038692474365, train/logprobs = tensor([[-2.2334, -4.5239],
        [-4.1616, -2.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3988104462623596
Epoch 0, Step 5715: train/loss = 0.3912041485309601, train/raw-loss = 0.3512551784515381, train/logprobs = tensor([[-2.1918, -6.3892],
        [-3.9288, -2.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39948999881744385
Epoch 0, Step 5716: train/loss = 0.43682020902633667, train/raw-loss = 0.4011002779006958, train/logprobs = tensor([[-1.4931, -5.5628],
        [-3.0399, -3.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3571993410587311
Epoch 0, Step 5717: train/loss = 0.09865139424800873, train/raw-loss = 0.05722891166806221, train/logprobs = tensor([[-1.9129, -7.2238],
        [-5.2914, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4142248332500458
Epoch 0, Step 5718: train/loss = 0.6468241810798645, train/raw-loss = 0.6024381518363953, train/logprobs = tensor([[-3.1930, -8.4941],
        [-4.9676, -4.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44386065006256104
Epoch 0, Step 5719: train/loss = 0.6464411616325378, train/raw-loss = 0.6099746823310852, train/logprobs = tensor([[-2.5114, -3.4124],
        [-2.3936, -1.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3646642565727234
Epoch 0, Step 5720: train/loss = 0.43811026215553284, train/raw-loss = 0.4033028483390808, train/logprobs = tensor([[-2.6993, -7.8530],
        [-4.0796, -2.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480742573738098
Epoch 0, Step 5721: train/loss = 0.40477702021598816, train/raw-loss = 0.3755946159362793, train/logprobs = tensor([[-2.6668, -5.6093],
        [-4.0498, -3.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2918238043785095
Epoch 0, Step 5722: train/loss = 0.3672652840614319, train/raw-loss = 0.32646381855010986, train/logprobs = tensor([[-1.8159, -8.0611],
        [-3.5394, -2.8468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4080149233341217
Epoch 0, Step 5723: train/loss = 0.1711561679840088, train/raw-loss = 0.1220318078994751, train/logprobs = tensor([[-1.3036, -6.6264],
        [-6.0078, -2.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4912436604499817
Epoch 0, Step 5724: train/loss = 0.1497345268726349, train/raw-loss = 0.11945044249296188, train/logprobs = tensor([[ -1.3046, -11.7202],
        [ -3.5416,  -1.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028407394886017
Epoch 0, Step 5725: train/loss = 0.28953319787979126, train/raw-loss = 0.24756640195846558, train/logprobs = tensor([[-1.5816, -8.0958],
        [-4.4666, -2.2807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4196680188179016
Epoch 0, Step 5726: train/loss = 0.37463241815567017, train/raw-loss = 0.3404110074043274, train/logprobs = tensor([[-2.0118, -6.8202],
        [-3.6779, -2.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34221401810646057
Epoch 0, Step 5727: train/loss = 0.3674928843975067, train/raw-loss = 0.3233095109462738, train/logprobs = tensor([[-1.5125, -9.3294],
        [-4.8129, -6.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4418340027332306
Epoch 0, Step 5728: train/loss = 0.29979416728019714, train/raw-loss = 0.26128682494163513, train/logprobs = tensor([[-2.0460, -8.5410],
        [-3.0687, -1.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38507315516471863
Epoch 0, Step 5729: train/loss = 0.5882169604301453, train/raw-loss = 0.5475096106529236, train/logprobs = tensor([[-1.6980, -2.6658],
        [-3.6352, -2.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4070737957954407
Epoch 0, Step 5730: train/loss = 0.49730005860328674, train/raw-loss = 0.46414363384246826, train/logprobs = tensor([[-2.1380, -9.9388],
        [-4.5756, -5.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315638601779938
Epoch 0, Step 5731: train/loss = 0.2133985310792923, train/raw-loss = 0.1807069331407547, train/logprobs = tensor([[ -2.3695, -11.3030],
        [ -5.5456,  -1.1467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3269159197807312
Epoch 0, Step 5732: train/loss = 0.6530561447143555, train/raw-loss = 0.6112173795700073, train/logprobs = tensor([[-1.0743, -2.5960],
        [-4.0134, -3.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183870851993561
Epoch 0, Step 5733: train/loss = 0.31990814208984375, train/raw-loss = 0.2683657109737396, train/logprobs = tensor([[-1.8138, -9.3412],
        [-6.0265, -2.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.515424370765686
Epoch 0, Step 5734: train/loss = 0.33357545733451843, train/raw-loss = 0.2904950976371765, train/logprobs = tensor([[-1.8573, -5.8076],
        [-4.8626, -3.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4308037757873535
Epoch 0, Step 5735: train/loss = 0.18714436888694763, train/raw-loss = 0.14937779307365417, train/logprobs = tensor([[ -1.8176, -10.4167],
        [ -5.3103,  -4.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3776656985282898
Epoch 0, Step 5736: train/loss = 0.4544343054294586, train/raw-loss = 0.4206750690937042, train/logprobs = tensor([[-1.4839, -5.9505],
        [-3.9173, -4.4017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3375919759273529
Epoch 0, Step 5737: train/loss = 0.2825659513473511, train/raw-loss = 0.24179108440876007, train/logprobs = tensor([[-1.3285, -6.2721],
        [-4.0258, -1.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4077487289905548
Epoch 0, Step 5738: train/loss = 0.46143433451652527, train/raw-loss = 0.428634375333786, train/logprobs = tensor([[-1.4683, -5.6630],
        [-3.6358, -2.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32799941301345825
Epoch 0, Step 5739: train/loss = 0.45161157846450806, train/raw-loss = 0.4114190340042114, train/logprobs = tensor([[-2.8413, -5.6711],
        [-5.1614, -3.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40192532539367676
Epoch 0, Step 5740: train/loss = 0.5687203407287598, train/raw-loss = 0.5202274918556213, train/logprobs = tensor([[-1.7227, -4.2306],
        [-5.1294, -3.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48492884635925293
Epoch 0, Step 5741: train/loss = 0.451199471950531, train/raw-loss = 0.4185687303543091, train/logprobs = tensor([[-3.0893, -7.9672],
        [-5.7540, -3.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3263072371482849
Epoch 0, Step 5742: train/loss = 0.28239333629608154, train/raw-loss = 0.2503793239593506, train/logprobs = tensor([[-2.3902, -8.5001],
        [-3.7542, -3.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32014021277427673
Epoch 0, Step 5743: train/loss = 0.28950008749961853, train/raw-loss = 0.25654101371765137, train/logprobs = tensor([[-1.6340, -5.7192],
        [-3.7496, -1.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295905888080597
Epoch 0, Step 5744: train/loss = 0.3485506474971771, train/raw-loss = 0.3010227382183075, train/logprobs = tensor([[-1.2492, -8.1145],
        [-6.6398, -3.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4752792418003082
Epoch 0, Step 5745: train/loss = 0.3146677613258362, train/raw-loss = 0.2778688371181488, train/logprobs = tensor([[-2.1704, -5.6664],
        [-4.2366, -2.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36798930168151855
Epoch 0, Step 5746: train/loss = 0.38703569769859314, train/raw-loss = 0.36148977279663086, train/logprobs = tensor([[-1.6134, -3.3911],
        [-3.2775, -2.4015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2554590106010437
Epoch 0, Step 5747: train/loss = 0.5040027499198914, train/raw-loss = 0.46348628401756287, train/logprobs = tensor([[-1.4173, -6.0113],
        [-4.6607, -4.4815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4051649570465088
Epoch 0, Step 5748: train/loss = 0.3947397768497467, train/raw-loss = 0.35494565963745117, train/logprobs = tensor([[-1.7316, -8.6146],
        [-3.2725, -2.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3979409337043762
Epoch 0, Step 5749: train/loss = 0.22136883437633514, train/raw-loss = 0.18918752670288086, train/logprobs = tensor([[ -1.6678, -10.1964],
        [ -5.1807,  -3.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32181304693222046
Epoch 0, Step 5750: train/loss = 0.49863913655281067, train/raw-loss = 0.47017136216163635, train/logprobs = tensor([[-3.3626, -6.6378],
        [-3.9700, -2.2028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284677654504776
Epoch 0, Step 5751: train/loss = 0.24463726580142975, train/raw-loss = 0.19704583287239075, train/logprobs = tensor([[-1.5842, -8.4932],
        [-5.0817, -2.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4759142994880676
Epoch 0, Step 5752: train/loss = 0.80951327085495, train/raw-loss = 0.7603588700294495, train/logprobs = tensor([[-1.5756, -2.9874],
        [-3.6284, -2.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4915434718132019
Epoch 0, Step 5753: train/loss = 0.1807204931974411, train/raw-loss = 0.13669468462467194, train/logprobs = tensor([[-1.8946, -8.0891],
        [-5.5465, -2.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44025808572769165
Epoch 0, Step 5754: train/loss = 0.06557207554578781, train/raw-loss = 0.020537875592708588, train/logprobs = tensor([[-1.2654, -9.8439],
        [-5.4501, -2.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45034199953079224
Epoch 0, Step 5755: train/loss = 0.84347003698349, train/raw-loss = 0.807720422744751, train/logprobs = tensor([[-2.2731, -2.4119],
        [-3.1960, -2.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35749566555023193
Epoch 0, Step 5756: train/loss = 0.7293804287910461, train/raw-loss = 0.7008444666862488, train/logprobs = tensor([[-2.0557, -2.0078],
        [-2.0079, -1.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2853600084781647
Epoch 0, Step 5757: train/loss = 0.12940888106822968, train/raw-loss = 0.0884411409497261, train/logprobs = tensor([[ -2.0131, -15.3918],
        [ -5.7327,  -5.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4096773862838745
Epoch 0, Step 5758: train/loss = 0.10370522737503052, train/raw-loss = 0.05882960557937622, train/logprobs = tensor([[ -2.3104, -10.2493],
        [ -5.3918,  -2.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4487561583518982
Epoch 0, Step 5759: train/loss = 0.10592588782310486, train/raw-loss = 0.0784391462802887, train/logprobs = tensor([[ -1.3513, -13.6404],
        [ -3.7786,  -3.9771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.274867445230484
Epoch 0, Step 5760: train/loss = 0.2501242756843567, train/raw-loss = 0.21586792171001434, train/logprobs = tensor([[ -2.2796, -12.1157],
        [ -5.0655,  -3.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425634503364563
Epoch 0, Step 5761: train/loss = 0.08109849691390991, train/raw-loss = 0.036010053008794785, train/logprobs = tensor([[ -1.8437, -13.8551],
        [ -6.2167,  -7.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45088452100753784
Epoch 0, Step 5762: train/loss = 0.31994813680648804, train/raw-loss = 0.2902953624725342, train/logprobs = tensor([[-2.2607, -5.0935],
        [-3.9018, -1.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29652801156044006
Epoch 0, Step 5763: train/loss = 0.4763801097869873, train/raw-loss = 0.4440643787384033, train/logprobs = tensor([[-2.5888, -4.6109],
        [-3.7349, -1.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3231572210788727
Epoch 0, Step 5764: train/loss = 0.09246133267879486, train/raw-loss = 0.05497613549232483, train/logprobs = tensor([[ -0.8091, -10.8838],
        [ -5.9779,  -2.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37485191226005554
Epoch 0, Step 5765: train/loss = 0.1482698917388916, train/raw-loss = 0.1098712682723999, train/logprobs = tensor([[ -2.0190, -14.2456],
        [ -5.6128,  -4.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3839862644672394
Epoch 0, Step 5766: train/loss = 0.24084167182445526, train/raw-loss = 0.20826613903045654, train/logprobs = tensor([[-1.6690, -4.9436],
        [-2.9853, -1.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32575535774230957
Epoch 0, Step 5767: train/loss = 0.30991852283477783, train/raw-loss = 0.2706770598888397, train/logprobs = tensor([[-1.6436, -4.6115],
        [-4.8095, -2.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924143314361572
Epoch 0, Step 5768: train/loss = 0.2312227040529251, train/raw-loss = 0.20111648738384247, train/logprobs = tensor([[ -1.9779, -13.3320],
        [ -4.1909,  -5.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010621666908264
Epoch 0, Step 5769: train/loss = 0.6437039971351624, train/raw-loss = 0.6091843843460083, train/logprobs = tensor([[-2.3465, -2.8230],
        [-2.3685, -2.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3451957106590271
Epoch 0, Step 5770: train/loss = 0.07462310791015625, train/raw-loss = 0.04428018257021904, train/logprobs = tensor([[-2.8144, -9.6506],
        [-6.0831, -2.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3034292161464691
Epoch 0, Step 5771: train/loss = 0.4594380259513855, train/raw-loss = 0.41930001974105835, train/logprobs = tensor([[-1.8573, -4.3516],
        [-3.1926, -2.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40138018131256104
Epoch 0, Step 5772: train/loss = 0.12822553515434265, train/raw-loss = 0.0962611734867096, train/logprobs = tensor([[ -1.8144, -13.1820],
        [ -4.7354,  -2.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319643497467041
Epoch 0, Step 5773: train/loss = 0.23010212182998657, train/raw-loss = 0.19392070174217224, train/logprobs = tensor([[-2.2122, -9.9864],
        [-4.9522, -1.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3618142008781433
Epoch 0, Step 5774: train/loss = 0.4192380905151367, train/raw-loss = 0.37267714738845825, train/logprobs = tensor([[-0.9472, -3.2482],
        [-3.4170, -2.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4656093120574951
Epoch 0, Step 5775: train/loss = 0.059583693742752075, train/raw-loss = 0.017641328275203705, train/logprobs = tensor([[ -1.9988, -12.6983],
        [ -6.5989,  -3.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4194236397743225
Epoch 0, Step 5776: train/loss = 0.21986053884029388, train/raw-loss = 0.17484334111213684, train/logprobs = tensor([[-1.2606, -8.9537],
        [-5.4133, -2.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45017188787460327
Epoch 0, Step 5777: train/loss = 0.12552419304847717, train/raw-loss = 0.08517491072416306, train/logprobs = tensor([[ -2.2307, -11.7744],
        [ -5.6847,  -4.6965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40349280834198
Epoch 0, Step 5778: train/loss = 0.3262350559234619, train/raw-loss = 0.29495710134506226, train/logprobs = tensor([[-2.4072, -5.0010],
        [-3.3560, -1.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31277933716773987
Epoch 0, Step 5779: train/loss = 0.4654412269592285, train/raw-loss = 0.43287813663482666, train/logprobs = tensor([[-2.0139, -7.3429],
        [-2.5448, -2.3863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3256310820579529
Epoch 0, Step 5780: train/loss = 0.4959527850151062, train/raw-loss = 0.4532930254936218, train/logprobs = tensor([[ -2.7788, -11.8036],
        [ -3.8273,  -5.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42659735679626465
Epoch 0, Step 5781: train/loss = 0.19644136726856232, train/raw-loss = 0.16065643727779388, train/logprobs = tensor([[ -1.6446, -11.1491],
        [ -4.9981,  -5.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3578492999076843
Epoch 0, Step 5782: train/loss = 0.13069915771484375, train/raw-loss = 0.09610520303249359, train/logprobs = tensor([[-2.0608, -9.8646],
        [-4.8284, -2.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3459395468235016
Epoch 0, Step 5783: train/loss = 0.4295101463794708, train/raw-loss = 0.3932063579559326, train/logprobs = tensor([[-1.5662, -3.2327],
        [-3.1200, -2.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36303767561912537
Epoch 0, Step 5784: train/loss = 0.2751586139202118, train/raw-loss = 0.24305526912212372, train/logprobs = tensor([[ -3.6853, -11.3212],
        [ -5.2624,  -1.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210333585739136
Epoch 0, Step 5785: train/loss = 0.5249217748641968, train/raw-loss = 0.4887981414794922, train/logprobs = tensor([[-3.0244, -2.9699],
        [-4.6730, -2.3387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36123645305633545
Epoch 0, Step 5786: train/loss = 0.5195720791816711, train/raw-loss = 0.47367972135543823, train/logprobs = tensor([[-2.1193, -3.1758],
        [-3.5167, -2.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45892393589019775
Epoch 0, Step 5787: train/loss = 0.07056498527526855, train/raw-loss = 0.0326763279736042, train/logprobs = tensor([[ -2.9467, -12.2121],
        [ -7.7238,  -5.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3788866400718689
Epoch 0, Step 5788: train/loss = 0.30632343888282776, train/raw-loss = 0.2675420939922333, train/logprobs = tensor([[-2.4255, -6.8161],
        [-4.5274, -2.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38781338930130005
Epoch 0, Step 5789: train/loss = 0.31643879413604736, train/raw-loss = 0.26681050658226013, train/logprobs = tensor([[-1.4941, -5.3473],
        [-5.7919, -3.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4962827265262604
Epoch 0, Step 5790: train/loss = 0.12324225902557373, train/raw-loss = 0.08478338271379471, train/logprobs = tensor([[ -1.8501, -10.5474],
        [ -4.8758,  -3.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3845887780189514
Epoch 0, Step 5791: train/loss = 0.4286153316497803, train/raw-loss = 0.3853689730167389, train/logprobs = tensor([[-1.6748, -6.7923],
        [-5.5712, -3.3285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43246370553970337
Epoch 0, Step 5792: train/loss = 0.4943087697029114, train/raw-loss = 0.4581858515739441, train/logprobs = tensor([[-1.5036, -8.0611],
        [-2.4193, -2.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3612295985221863
Epoch 0, Step 5793: train/loss = 0.25299543142318726, train/raw-loss = 0.22203677892684937, train/logprobs = tensor([[-1.3875, -6.0592],
        [-3.0383, -2.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30958664417266846
Epoch 0, Step 5794: train/loss = 0.23017266392707825, train/raw-loss = 0.18926836550235748, train/logprobs = tensor([[ -1.9403, -12.9529],
        [ -4.7878,  -5.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4090428948402405
Epoch 0, Step 5795: train/loss = 0.22952952980995178, train/raw-loss = 0.1966356784105301, train/logprobs = tensor([[ -1.4172, -11.6287],
        [ -5.4125,  -5.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3289386034011841
Epoch 0, Step 5796: train/loss = 0.42542389035224915, train/raw-loss = 0.38673511147499084, train/logprobs = tensor([[-2.5206, -4.6036],
        [-6.9071, -2.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38688763976097107
Epoch 0, Step 5797: train/loss = 0.18112251162528992, train/raw-loss = 0.14268402755260468, train/logprobs = tensor([[-1.7607, -8.1766],
        [-5.3048, -2.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3843848705291748
Epoch 0, Step 5798: train/loss = 0.2811990976333618, train/raw-loss = 0.23737351596355438, train/logprobs = tensor([[-1.7574, -4.8949],
        [-4.8134, -2.2887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43825554847717285
Epoch 0, Step 5799: train/loss = 0.42141830921173096, train/raw-loss = 0.385314404964447, train/logprobs = tensor([[-2.6945, -7.3797],
        [-3.8706, -2.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36103901267051697
Epoch 0, Step 5800: train/loss = 0.42981696128845215, train/raw-loss = 0.38319963216781616, train/logprobs = tensor([[-1.4433, -5.8234],
        [-3.6848, -2.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4661734104156494
Epoch 0, Step 5801: train/loss = 1.2022353410720825, train/raw-loss = 1.1714938879013062, train/logprobs = tensor([[-2.6709, -5.5334],
        [-3.8564, -5.7206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30741363763809204
Epoch 0, Step 5802: train/loss = 0.32246530055999756, train/raw-loss = 0.2804349660873413, train/logprobs = tensor([[-1.5390, -5.8790],
        [-5.9484, -3.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4203033447265625
Epoch 0, Step 5803: train/loss = 0.2506366968154907, train/raw-loss = 0.20600196719169617, train/logprobs = tensor([[ -1.1209, -13.5550],
        [ -5.7958,  -3.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44634732604026794
Epoch 0, Step 5804: train/loss = 0.17953146994113922, train/raw-loss = 0.14702552556991577, train/logprobs = tensor([[-2.2950, -5.5061],
        [-5.4253, -2.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32505932450294495
Epoch 0, Step 5805: train/loss = 0.20110756158828735, train/raw-loss = 0.15996748208999634, train/logprobs = tensor([[-1.8564, -7.7255],
        [-5.8976, -2.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4114007353782654
Epoch 0, Step 5806: train/loss = 0.428527295589447, train/raw-loss = 0.3815939426422119, train/logprobs = tensor([[-1.0621, -5.1242],
        [-3.8254, -3.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4693337082862854
Epoch 0, Step 5807: train/loss = 0.3650013208389282, train/raw-loss = 0.33074405789375305, train/logprobs = tensor([[-2.0589, -9.1280],
        [-4.2827, -1.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425723910331726
Epoch 0, Step 5808: train/loss = 0.6503885388374329, train/raw-loss = 0.6154872179031372, train/logprobs = tensor([[-1.8099, -2.5243],
        [-3.6293, -2.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490130603313446
Epoch 0, Step 5809: train/loss = 0.2081097811460495, train/raw-loss = 0.1616038829088211, train/logprobs = tensor([[-1.7163, -9.9544],
        [-6.3765, -2.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46505892276763916
Epoch 0, Step 5810: train/loss = 0.33611413836479187, train/raw-loss = 0.29380831122398376, train/logprobs = tensor([[-2.1089, -8.9411],
        [-4.5038, -2.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42305830121040344
Epoch 0, Step 5811: train/loss = 0.340108186006546, train/raw-loss = 0.30497103929519653, train/logprobs = tensor([[-1.9766, -5.7586],
        [-3.9213, -2.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3513716459274292
Epoch 0, Step 5812: train/loss = 0.25169891119003296, train/raw-loss = 0.2145097255706787, train/logprobs = tensor([[-1.7403, -6.4459],
        [-4.2173, -1.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37189191579818726
Epoch 0, Step 5813: train/loss = 0.06303417682647705, train/raw-loss = 0.023416105657815933, train/logprobs = tensor([[ -1.4524, -14.1695],
        [ -6.3038,  -2.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3961807191371918
Epoch 0, Step 5814: train/loss = 0.4383484423160553, train/raw-loss = 0.4008045196533203, train/logprobs = tensor([[-2.7759, -9.8875],
        [-4.0698, -2.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3754386901855469
Epoch 0, Step 5815: train/loss = 0.5175698399543762, train/raw-loss = 0.48398882150650024, train/logprobs = tensor([[-1.5454, -5.4962],
        [-3.0200, -3.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33581018447875977
Epoch 0, Step 5816: train/loss = 0.44472938776016235, train/raw-loss = 0.41320332884788513, train/logprobs = tensor([[ -2.7392, -12.6368],
        [ -2.9120,  -3.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152608275413513
Epoch 0, Step 5817: train/loss = 0.35030829906463623, train/raw-loss = 0.30084988474845886, train/logprobs = tensor([[-1.8153, -5.3993],
        [-4.7951, -2.2889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4945839047431946
Epoch 0, Step 5818: train/loss = 0.3350129723548889, train/raw-loss = 0.30280640721321106, train/logprobs = tensor([[ -2.5364, -11.6734],
        [ -6.1596,  -6.4127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3220655918121338
Epoch 0, Step 5819: train/loss = 0.2263123095035553, train/raw-loss = 0.19284911453723907, train/logprobs = tensor([[-2.5667, -8.0501],
        [-3.9387, -1.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346320390701294
Epoch 0, Step 5820: train/loss = 0.07603447139263153, train/raw-loss = 0.04083359241485596, train/logprobs = tensor([[ -1.2875, -12.9821],
        [ -4.3709,  -2.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3520087003707886
Epoch 0, Step 5821: train/loss = 0.2590847909450531, train/raw-loss = 0.22013166546821594, train/logprobs = tensor([[ -1.8530, -13.6620],
        [ -5.2047,  -5.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3895311951637268
Epoch 0, Step 5822: train/loss = 0.058964770287275314, train/raw-loss = 0.01902628317475319, train/logprobs = tensor([[ -2.1506, -15.0271],
        [ -6.2550,  -2.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39938488602638245
Epoch 0, Step 5823: train/loss = 0.2342383712530136, train/raw-loss = 0.18983407318592072, train/logprobs = tensor([[ -1.5474, -11.5327],
        [ -5.6322,  -1.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4440429210662842
Epoch 0, Step 5824: train/loss = 0.2560054361820221, train/raw-loss = 0.22205157577991486, train/logprobs = tensor([[-1.6058, -4.9902],
        [-3.4063, -1.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3395387828350067
Epoch 0, Step 5825: train/loss = 0.45860952138900757, train/raw-loss = 0.42277905344963074, train/logprobs = tensor([[-1.6780, -7.4956],
        [-4.2416, -4.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35830485820770264
Epoch 0, Step 5826: train/loss = 0.25029051303863525, train/raw-loss = 0.2104111611843109, train/logprobs = tensor([[-2.7338, -7.0740],
        [-5.1859, -3.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39879339933395386
Epoch 0, Step 5827: train/loss = 0.36363106966018677, train/raw-loss = 0.33146122097969055, train/logprobs = tensor([[-2.4414, -8.7490],
        [-4.8195, -5.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32169851660728455
Epoch 0, Step 5828: train/loss = 0.2909848093986511, train/raw-loss = 0.255422979593277, train/logprobs = tensor([[-2.9566, -7.2415],
        [-3.8522, -2.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556182384490967
Epoch 0, Step 5829: train/loss = 0.06602403521537781, train/raw-loss = 0.0220370814204216, train/logprobs = tensor([[ -1.8555, -13.8730],
        [ -5.5125,  -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4398695230484009
Epoch 0, Step 5830: train/loss = 0.3291051983833313, train/raw-loss = 0.2916640639305115, train/logprobs = tensor([[-1.6361, -5.6439],
        [-3.4857, -1.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37441128492355347
Epoch 0, Step 5831: train/loss = 0.3057655096054077, train/raw-loss = 0.27477702498435974, train/logprobs = tensor([[-2.7656, -9.0101],
        [-3.3607, -3.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098847568035126
Epoch 0, Step 5832: train/loss = 0.4481778144836426, train/raw-loss = 0.4194762110710144, train/logprobs = tensor([[-1.3898, -1.9881],
        [-3.7910, -1.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870160937309265
Epoch 0, Step 5833: train/loss = 0.8744286298751831, train/raw-loss = 0.8323696851730347, train/logprobs = tensor([[-1.8173, -5.8456],
        [-3.2291, -5.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42058926820755005
Epoch 0, Step 5834: train/loss = 0.14782467484474182, train/raw-loss = 0.10115939378738403, train/logprobs = tensor([[ -1.3686, -12.3807],
        [ -4.9867,  -4.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4666529893875122
Epoch 0, Step 5835: train/loss = 0.45291242003440857, train/raw-loss = 0.4103636145591736, train/logprobs = tensor([[-1.5285, -4.7755],
        [-4.5497, -2.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42548805475234985
Epoch 0, Step 5836: train/loss = 0.15089498460292816, train/raw-loss = 0.1075022891163826, train/logprobs = tensor([[-2.0119, -6.5457],
        [-4.8128, -2.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43392693996429443
Epoch 0, Step 5837: train/loss = 0.35588955879211426, train/raw-loss = 0.3224770724773407, train/logprobs = tensor([[-1.5702, -5.6777],
        [-3.9816, -2.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341251015663147
Epoch 0, Step 5838: train/loss = 0.2587440311908722, train/raw-loss = 0.20711901783943176, train/logprobs = tensor([[ -1.8623, -14.4010],
        [ -5.8421,  -4.4359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5162501335144043
Epoch 0, Step 5839: train/loss = 0.1838313788175583, train/raw-loss = 0.1378999799489975, train/logprobs = tensor([[ -0.9552, -15.6337],
        [ -3.9507,  -4.1835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4593138098716736
Epoch 0, Step 5840: train/loss = 0.20328715443611145, train/raw-loss = 0.17233997583389282, train/logprobs = tensor([[-2.4983, -5.4929],
        [-4.9809, -2.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30947166681289673
Epoch 0, Step 5841: train/loss = 0.403444766998291, train/raw-loss = 0.36341431736946106, train/logprobs = tensor([[-1.1342, -4.5678],
        [-3.7193, -3.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4003046154975891
Epoch 0, Step 5842: train/loss = 0.3718392252922058, train/raw-loss = 0.3361578583717346, train/logprobs = tensor([[-0.8337, -7.9844],
        [-3.9524, -1.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35681337118148804
Epoch 0, Step 5843: train/loss = 0.33343684673309326, train/raw-loss = 0.28164801001548767, train/logprobs = tensor([[ -2.3875, -10.8937],
        [ -7.4545,  -4.3882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5178883671760559
Epoch 0, Step 5844: train/loss = 0.16965307295322418, train/raw-loss = 0.13331648707389832, train/logprobs = tensor([[-1.4956, -9.9623],
        [-3.9265, -2.3326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36336594820022583
Epoch 0, Step 5845: train/loss = 0.24816149473190308, train/raw-loss = 0.21468223631381989, train/logprobs = tensor([[-2.3898, -7.1713],
        [-4.6904, -3.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3347925543785095
Epoch 0, Step 5846: train/loss = 0.4099217355251312, train/raw-loss = 0.36302345991134644, train/logprobs = tensor([[-1.6623, -6.4681],
        [-5.2160, -3.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4689827859401703
Epoch 0, Step 5847: train/loss = 0.2698977589607239, train/raw-loss = 0.23940135538578033, train/logprobs = tensor([[-3.6042, -7.3960],
        [-6.1786, -2.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049641251564026
Epoch 0, Step 5848: train/loss = 0.0819339007139206, train/raw-loss = 0.04384665936231613, train/logprobs = tensor([[ -1.8712, -13.7668],
        [ -4.7833,  -5.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38087236881256104
Epoch 0, Step 5849: train/loss = 0.5066015720367432, train/raw-loss = 0.4658600986003876, train/logprobs = tensor([[-1.3830, -4.4960],
        [-4.5115, -2.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4074147343635559
Epoch 0, Step 5850: train/loss = 0.3099513649940491, train/raw-loss = 0.2728957533836365, train/logprobs = tensor([[-0.9529, -5.1515],
        [-4.3322, -2.2922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37055617570877075
Epoch 0, Step 5851: train/loss = 0.31923532485961914, train/raw-loss = 0.2684755325317383, train/logprobs = tensor([[-1.2878, -8.2944],
        [-4.7867, -3.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5075978636741638
Epoch 0, Step 5852: train/loss = 0.4751594662666321, train/raw-loss = 0.4320625066757202, train/logprobs = tensor([[-1.9116, -3.1674],
        [-3.5325, -2.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4309696555137634
Epoch 0, Step 5853: train/loss = 0.6067367196083069, train/raw-loss = 0.559959352016449, train/logprobs = tensor([[-1.6805, -3.9498],
        [-4.1407, -2.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4677738547325134
Epoch 0, Step 5854: train/loss = 0.10207952558994293, train/raw-loss = 0.05296596139669418, train/logprobs = tensor([[ -2.1638, -10.1382],
        [ -5.1463,  -1.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49113553762435913
Epoch 0, Step 5855: train/loss = 0.4741792678833008, train/raw-loss = 0.43832212686538696, train/logprobs = tensor([[-1.7897, -4.8630],
        [-2.9399, -2.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35857149958610535
Epoch 0, Step 5856: train/loss = 0.28699564933776855, train/raw-loss = 0.25620904564857483, train/logprobs = tensor([[-2.0707, -7.8044],
        [-4.8485, -3.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3078661859035492
Epoch 0, Step 5857: train/loss = 0.19250011444091797, train/raw-loss = 0.16204966604709625, train/logprobs = tensor([[-1.4343, -6.2964],
        [-4.6058, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3045044243335724
Epoch 0, Step 5858: train/loss = 0.05771022289991379, train/raw-loss = 0.023671265691518784, train/logprobs = tensor([[ -1.4127, -11.1355],
        [ -4.7197,  -2.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.340389609336853
Epoch 0, Step 5859: train/loss = 0.5332354307174683, train/raw-loss = 0.5094622373580933, train/logprobs = tensor([[-1.4895, -3.8335],
        [-2.2164, -2.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2377321869134903
Epoch 0, Step 5860: train/loss = 0.34223484992980957, train/raw-loss = 0.293197900056839, train/logprobs = tensor([[-1.9844, -6.0985],
        [-3.9353, -2.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4903694689273834
Epoch 0, Step 5861: train/loss = 0.19743354618549347, train/raw-loss = 0.1545858085155487, train/logprobs = tensor([[ -1.8516, -17.5926],
        [ -4.4780,  -7.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42847734689712524
Epoch 0, Step 5862: train/loss = 0.2649347186088562, train/raw-loss = 0.22113598883152008, train/logprobs = tensor([[-2.2062, -7.4825],
        [-5.9466, -2.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43798720836639404
Epoch 0, Step 5863: train/loss = 0.08419285714626312, train/raw-loss = 0.041610799729824066, train/logprobs = tensor([[ -1.3648, -14.2946],
        [ -5.2897,  -4.3957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42582064867019653
Epoch 0, Step 5864: train/loss = 0.20594653487205505, train/raw-loss = 0.17445234954357147, train/logprobs = tensor([[ -3.8255, -17.5281],
        [ -7.4909,  -6.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149418830871582
Epoch 0, Step 5865: train/loss = 0.4924856424331665, train/raw-loss = 0.45712530612945557, train/logprobs = tensor([[-2.9152, -4.5243],
        [-3.0897, -2.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35360386967658997
Epoch 0, Step 5866: train/loss = 0.13364939391613007, train/raw-loss = 0.08768515288829803, train/logprobs = tensor([[ -1.0094, -11.6905],
        [ -3.9595,  -5.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4596424102783203
Epoch 0, Step 5867: train/loss = 0.32038962841033936, train/raw-loss = 0.28363046050071716, train/logprobs = tensor([[-1.9346, -7.0507],
        [-3.4985, -1.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36759135127067566
Epoch 0, Step 5868: train/loss = 0.3175817131996155, train/raw-loss = 0.27891379594802856, train/logprobs = tensor([[-0.9340, -4.7480],
        [-2.9812, -2.1800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38667920231819153
Epoch 0, Step 5869: train/loss = 0.5437710881233215, train/raw-loss = 0.5117119550704956, train/logprobs = tensor([[-1.5052, -2.7615],
        [-3.7648, -2.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205910325050354
Epoch 0, Step 5870: train/loss = 0.36428651213645935, train/raw-loss = 0.33588919043540955, train/logprobs = tensor([[-1.8116, -5.6559],
        [-2.8291, -1.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28397321701049805
Epoch 0, Step 5871: train/loss = 0.6300521492958069, train/raw-loss = 0.5812297463417053, train/logprobs = tensor([[-2.0540, -2.7802],
        [-4.8564, -3.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4882240891456604
Epoch 0, Step 5872: train/loss = 0.4019005298614502, train/raw-loss = 0.36462920904159546, train/logprobs = tensor([[-2.8479, -6.0606],
        [-4.0212, -2.0002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727131187915802
Epoch 0, Step 5873: train/loss = 0.30480697751045227, train/raw-loss = 0.2545592188835144, train/logprobs = tensor([[-2.4432, -6.3691],
        [-5.2454, -2.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5024772882461548
Epoch 0, Step 5874: train/loss = 0.3071630895137787, train/raw-loss = 0.2775481343269348, train/logprobs = tensor([[-3.2224, -5.4396],
        [-5.3236, -2.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961495816707611
Epoch 0, Step 5875: train/loss = 0.35298559069633484, train/raw-loss = 0.31431886553764343, train/logprobs = tensor([[-1.9871, -6.0303],
        [-3.7958, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38666725158691406
Epoch 0, Step 5876: train/loss = 0.49914056062698364, train/raw-loss = 0.4622753858566284, train/logprobs = tensor([[-2.4158, -4.9765],
        [-3.8034, -2.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36865198612213135
Epoch 0, Step 5877: train/loss = 0.24115189909934998, train/raw-loss = 0.2155633270740509, train/logprobs = tensor([[-1.5793, -8.6687],
        [-4.2070, -2.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25588569045066833
Epoch 0, Step 5878: train/loss = 0.06551831215620041, train/raw-loss = 0.027284951880574226, train/logprobs = tensor([[ -1.1098, -14.6753],
        [ -4.2956,  -3.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38233357667922974
Epoch 0, Step 5879: train/loss = 0.4823915660381317, train/raw-loss = 0.445609986782074, train/logprobs = tensor([[-1.4010, -4.8724],
        [-3.7931, -2.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3678159713745117
Epoch 0, Step 5880: train/loss = 0.0742531344294548, train/raw-loss = 0.029938410967588425, train/logprobs = tensor([[ -1.6297, -10.1403],
        [ -4.6931,  -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443147212266922
Epoch 0, Step 5881: train/loss = 0.4750994145870209, train/raw-loss = 0.4378829300403595, train/logprobs = tensor([[-1.8141, -4.0172],
        [-3.7694, -2.5738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721647262573242
Epoch 0, Step 5882: train/loss = 0.14229992032051086, train/raw-loss = 0.09568721801042557, train/logprobs = tensor([[ -2.1594, -13.3300],
        [ -4.9350,  -3.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46612703800201416
Epoch 0, Step 5883: train/loss = 0.8150053024291992, train/raw-loss = 0.78190016746521, train/logprobs = tensor([[-2.1328, -3.4007],
        [-2.6052, -2.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33105209469795227
Epoch 0, Step 5884: train/loss = 0.6164852380752563, train/raw-loss = 0.5808465480804443, train/logprobs = tensor([[-2.4030, -5.6831],
        [-2.9720, -2.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35638654232025146
Epoch 0, Step 5885: train/loss = 0.3760449290275574, train/raw-loss = 0.34621596336364746, train/logprobs = tensor([[-2.4737, -6.2771],
        [-2.5118, -1.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29828956723213196
Epoch 0, Step 5886: train/loss = 0.18688322603702545, train/raw-loss = 0.15031279623508453, train/logprobs = tensor([[-2.0125, -5.2874],
        [-4.2150, -1.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657042384147644
Epoch 0, Step 5887: train/loss = 0.6013000011444092, train/raw-loss = 0.5519623160362244, train/logprobs = tensor([[-2.5997, -4.1659],
        [-3.8553, -2.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.493377149105072
Epoch 0, Step 5888: train/loss = 0.5127364993095398, train/raw-loss = 0.47580134868621826, train/logprobs = tensor([[-1.1967, -5.3897],
        [-2.8570, -2.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.369351327419281
Epoch 0, Step 5889: train/loss = 0.27710309624671936, train/raw-loss = 0.2352657914161682, train/logprobs = tensor([[ -2.9338, -11.0904],
        [ -5.5382,  -2.3593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183731973171234
Epoch 0, Step 5890: train/loss = 0.2687132954597473, train/raw-loss = 0.2315223067998886, train/logprobs = tensor([[-1.8628, -5.4718],
        [-4.3312, -1.3255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3719099760055542
Epoch 0, Step 5891: train/loss = 0.2610214054584503, train/raw-loss = 0.22238950431346893, train/logprobs = tensor([[ -1.6545, -16.1986],
        [ -4.1874,  -4.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38631874322891235
Epoch 0, Step 5892: train/loss = 0.19982044398784637, train/raw-loss = 0.16223835945129395, train/logprobs = tensor([[-1.6893, -9.3166],
        [-3.6568, -3.4496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37582093477249146
Epoch 0, Step 5893: train/loss = 0.2771594822406769, train/raw-loss = 0.22868482768535614, train/logprobs = tensor([[-1.5703, -4.5463],
        [-4.2741, -2.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48474639654159546
Epoch 0, Step 5894: train/loss = 0.07193761318922043, train/raw-loss = 0.03712493181228638, train/logprobs = tensor([[ -1.8526, -10.4894],
        [ -5.0100,  -2.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34812676906585693
Epoch 0, Step 5895: train/loss = 0.04851286858320236, train/raw-loss = 0.016001250594854355, train/logprobs = tensor([[ -3.5642, -10.4142],
        [ -7.1929,  -3.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32511618733406067
Epoch 0, Step 5896: train/loss = 0.4036397337913513, train/raw-loss = 0.3631862998008728, train/logprobs = tensor([[-2.3641, -6.2226],
        [-4.3926, -2.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4045344591140747
Epoch 0, Step 5897: train/loss = 0.4026030898094177, train/raw-loss = 0.3691404461860657, train/logprobs = tensor([[-1.5324, -4.7804],
        [-2.0669, -2.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33462679386138916
Epoch 0, Step 5898: train/loss = 0.056651752442121506, train/raw-loss = 0.011843516491353512, train/logprobs = tensor([[ -2.0090, -11.8526],
        [ -6.7619,  -3.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4480823874473572
Epoch 0, Step 5899: train/loss = 0.5183787941932678, train/raw-loss = 0.47797077894210815, train/logprobs = tensor([[ -3.1694, -10.5113],
        [ -5.1091,  -3.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40408048033714294
Epoch 0, Step 5900: train/loss = 0.527428388595581, train/raw-loss = 0.4953376352787018, train/logprobs = tensor([[-2.2588, -6.8731],
        [-2.7365, -3.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209071755409241
Epoch 0, Step 5901: train/loss = 0.2007244974374771, train/raw-loss = 0.1608681082725525, train/logprobs = tensor([[-1.5930, -4.5834],
        [-4.6001, -1.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.398563951253891
Epoch 0, Step 5902: train/loss = 0.626774787902832, train/raw-loss = 0.5906045436859131, train/logprobs = tensor([[-2.6715, -7.3292],
        [-3.8527, -1.7986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617025315761566
Epoch 0, Step 5903: train/loss = 0.5580947399139404, train/raw-loss = 0.5296826362609863, train/logprobs = tensor([[-3.0277, -6.8517],
        [-2.9578, -2.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2841205894947052
Epoch 0, Step 5904: train/loss = 0.286001592874527, train/raw-loss = 0.25808364152908325, train/logprobs = tensor([[-1.1766, -8.4459],
        [-3.8909, -4.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27917972207069397
Epoch 0, Step 5905: train/loss = 0.4508258104324341, train/raw-loss = 0.4093033969402313, train/logprobs = tensor([[-1.9597, -7.2801],
        [-3.8377, -3.6775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4152244031429291
Epoch 0, Step 5906: train/loss = 0.21255582571029663, train/raw-loss = 0.17572659254074097, train/logprobs = tensor([[-1.1007, -8.4190],
        [-2.7686, -1.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3682923913002014
Epoch 0, Step 5907: train/loss = 0.43042200803756714, train/raw-loss = 0.4021269381046295, train/logprobs = tensor([[-2.3549, -5.3961],
        [-3.0976, -1.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28295114636421204
Epoch 0, Step 5908: train/loss = 0.11346878856420517, train/raw-loss = 0.08177589625120163, train/logprobs = tensor([[-1.5395, -9.3725],
        [-3.6326, -3.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169289529323578
Epoch 0, Step 5909: train/loss = 0.310442179441452, train/raw-loss = 0.27665555477142334, train/logprobs = tensor([[-1.3615, -9.1632],
        [-3.4787, -4.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378664255142212
Epoch 0, Step 5910: train/loss = 0.24961672723293304, train/raw-loss = 0.2090875804424286, train/logprobs = tensor([[ -1.6069, -11.6516],
        [ -5.4255,  -5.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40529152750968933
Epoch 0, Step 5911: train/loss = 0.7038172483444214, train/raw-loss = 0.6667196750640869, train/logprobs = tensor([[-3.0755, -7.9891],
        [-3.6483, -2.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3709757924079895
Epoch 0, Step 5912: train/loss = 0.5781300663948059, train/raw-loss = 0.5358176231384277, train/logprobs = tensor([[-1.6851, -3.5709],
        [-3.9862, -2.4298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4231245219707489
Epoch 0, Step 5913: train/loss = 0.15131187438964844, train/raw-loss = 0.10983345657587051, train/logprobs = tensor([[ -1.5835, -13.3624],
        [ -5.2955,  -5.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4147842526435852
Epoch 0, Step 5914: train/loss = 0.5163758993148804, train/raw-loss = 0.48378872871398926, train/logprobs = tensor([[-2.4397, -9.0137],
        [-3.4908, -1.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258712887763977
Epoch 0, Step 5915: train/loss = 0.3270646333694458, train/raw-loss = 0.2912205755710602, train/logprobs = tensor([[-1.2874, -8.0307],
        [-3.3361, -1.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35844072699546814
Epoch 0, Step 5916: train/loss = 0.7677711844444275, train/raw-loss = 0.7266764044761658, train/logprobs = tensor([[-3.9196, -8.9781],
        [-3.0762, -2.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41094771027565
Epoch 0, Step 5917: train/loss = 0.04343726113438606, train/raw-loss = 0.009864836931228638, train/logprobs = tensor([[ -1.8008, -12.0478],
        [ -6.6577,  -3.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33572423458099365
Epoch 0, Step 5918: train/loss = 0.2529715299606323, train/raw-loss = 0.21185842156410217, train/logprobs = tensor([[-1.2643, -6.3011],
        [-3.0668, -2.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41113102436065674
Epoch 0, Step 5919: train/loss = 0.2349480837583542, train/raw-loss = 0.19453981518745422, train/logprobs = tensor([[-1.6883, -7.1307],
        [-4.8389, -3.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4040825366973877
Epoch 0, Step 5920: train/loss = 0.24804151058197021, train/raw-loss = 0.21605952084064484, train/logprobs = tensor([[-3.0352, -8.9949],
        [-5.8707, -1.1618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3198198676109314
Epoch 0, Step 5921: train/loss = 0.39506053924560547, train/raw-loss = 0.36931949853897095, train/logprobs = tensor([[-1.9988, -4.3276],
        [-2.2106, -1.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25741028785705566
Epoch 0, Step 5922: train/loss = 0.23345696926116943, train/raw-loss = 0.2040717601776123, train/logprobs = tensor([[-1.5039, -9.6797],
        [-3.9419, -2.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938520908355713
Epoch 0, Step 5923: train/loss = 0.22469553351402283, train/raw-loss = 0.18329332768917084, train/logprobs = tensor([[-3.3453, -7.2707],
        [-6.2543, -3.2689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4140221178531647
Epoch 0, Step 5924: train/loss = 0.29811352491378784, train/raw-loss = 0.2659752070903778, train/logprobs = tensor([[-1.1211, -3.4772],
        [-3.0133, -1.3550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213827610015869
Epoch 0, Step 5925: train/loss = 0.24771225452423096, train/raw-loss = 0.21309271454811096, train/logprobs = tensor([[-2.0895, -4.5421],
        [-4.6655, -1.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461953103542328
Epoch 0, Step 5926: train/loss = 0.5576256513595581, train/raw-loss = 0.5285919904708862, train/logprobs = tensor([[-1.6310, -6.1423],
        [-1.4111, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2903367877006531
Epoch 0, Step 5927: train/loss = 0.19305594265460968, train/raw-loss = 0.15099184215068817, train/logprobs = tensor([[-2.5197, -6.2325],
        [-4.7342, -2.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4206409454345703
Epoch 0, Step 5928: train/loss = 0.37013518810272217, train/raw-loss = 0.33364221453666687, train/logprobs = tensor([[-2.5390, -8.5236],
        [-4.3696, -3.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36492979526519775
Epoch 0, Step 5929: train/loss = 0.4857456386089325, train/raw-loss = 0.4533460736274719, train/logprobs = tensor([[-2.3000, -4.0406],
        [-2.6362, -2.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32399582862854004
Epoch 0, Step 5930: train/loss = 0.06516079604625702, train/raw-loss = 0.0249684639275074, train/logprobs = tensor([[ -1.5795, -13.6827],
        [ -4.6916,  -2.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019233286380768
Epoch 0, Step 5931: train/loss = 0.06007981672883034, train/raw-loss = 0.023395583033561707, train/logprobs = tensor([[ -1.8611, -12.8859],
        [ -5.5505,  -5.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3668423295021057
Epoch 0, Step 5932: train/loss = 0.25126534700393677, train/raw-loss = 0.21384963393211365, train/logprobs = tensor([[-2.0264, -8.0392],
        [-3.3263, -2.6231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741568922996521
Epoch 0, Step 5933: train/loss = 0.08711022138595581, train/raw-loss = 0.052245091646909714, train/logprobs = tensor([[ -2.1304, -13.2480],
        [ -4.7960,  -2.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34865128993988037
Epoch 0, Step 5934: train/loss = 0.21086105704307556, train/raw-loss = 0.16803619265556335, train/logprobs = tensor([[-1.9843, -5.7558],
        [-4.8417, -2.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42824870347976685
Epoch 0, Step 5935: train/loss = 0.19294974207878113, train/raw-loss = 0.16062244772911072, train/logprobs = tensor([[-1.7520, -8.2019],
        [-3.5967, -1.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3232728838920593
Epoch 0, Step 5936: train/loss = 0.31889015436172485, train/raw-loss = 0.27387717366218567, train/logprobs = tensor([[-1.6361, -5.1628],
        [-3.9979, -2.7575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4501297175884247
Epoch 0, Step 5937: train/loss = 0.25554022192955017, train/raw-loss = 0.21353194117546082, train/logprobs = tensor([[-1.5682, -9.3662],
        [-4.2378, -1.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42008301615715027
Epoch 0, Step 5938: train/loss = 0.3069234788417816, train/raw-loss = 0.2644558250904083, train/logprobs = tensor([[ -1.4569, -13.6628],
        [ -4.1965,  -6.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42467647790908813
Epoch 0, Step 5939: train/loss = 0.21835459768772125, train/raw-loss = 0.1766466200351715, train/logprobs = tensor([[-1.9696, -6.1542],
        [-4.5870, -1.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41707977652549744
Epoch 0, Step 5940: train/loss = 0.43738222122192383, train/raw-loss = 0.3992999196052551, train/logprobs = tensor([[-1.8066, -6.9183],
        [-4.2703, -2.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3808231055736542
Epoch 0, Step 5941: train/loss = 0.311314195394516, train/raw-loss = 0.27651163935661316, train/logprobs = tensor([[-1.9661, -9.6145],
        [-3.8402, -1.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34802553057670593
Epoch 0, Step 5942: train/loss = 0.22515809535980225, train/raw-loss = 0.18968233466148376, train/logprobs = tensor([[ -1.6798, -12.2790],
        [ -3.8066,  -2.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354757696390152
Epoch 0, Step 5943: train/loss = 0.4750903248786926, train/raw-loss = 0.43599146604537964, train/logprobs = tensor([[-2.6858, -5.6885],
        [-4.7527, -2.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39098885655403137
Epoch 0, Step 5944: train/loss = 0.09412269294261932, train/raw-loss = 0.05940580368041992, train/logprobs = tensor([[-1.7350, -8.8296],
        [-4.9949, -3.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34716886281967163
Epoch 0, Step 5945: train/loss = 0.1146644875407219, train/raw-loss = 0.07052195817232132, train/logprobs = tensor([[-2.4795, -5.3621],
        [-5.7540, -0.9223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44142529368400574
Epoch 0, Step 5946: train/loss = 0.4169738292694092, train/raw-loss = 0.3682359457015991, train/logprobs = tensor([[-1.0681, -3.7051],
        [-3.7828, -1.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48737895488739014
Epoch 0, Step 5947: train/loss = 0.2178264558315277, train/raw-loss = 0.1720532476902008, train/logprobs = tensor([[-1.8622, -7.3000],
        [-4.1125, -2.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4577321708202362
Epoch 0, Step 5948: train/loss = 0.3179689645767212, train/raw-loss = 0.27715179324150085, train/logprobs = tensor([[-2.2629, -6.5436],
        [-4.0444, -1.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081714451313019
Epoch 0, Step 5949: train/loss = 0.307330459356308, train/raw-loss = 0.2607528567314148, train/logprobs = tensor([[-2.3558, -7.7674],
        [-4.9997, -2.2697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4657760560512543
Epoch 0, Step 5950: train/loss = 0.2323012351989746, train/raw-loss = 0.19723638892173767, train/logprobs = tensor([[-1.5052, -6.5912],
        [-2.8522, -2.6707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3506484627723694
Epoch 0, Step 5951: train/loss = 0.08724427223205566, train/raw-loss = 0.044829800724983215, train/logprobs = tensor([[-2.2037, -7.3631],
        [-5.4537, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4241446554660797
Epoch 0, Step 5952: train/loss = 0.3490256667137146, train/raw-loss = 0.3135914206504822, train/logprobs = tensor([[-2.0120, -4.0510],
        [-4.4822, -1.4703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35434260964393616
Epoch 0, Step 5953: train/loss = 0.19952921569347382, train/raw-loss = 0.1665411740541458, train/logprobs = tensor([[-1.5009, -6.1076],
        [-3.4541, -1.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32988041639328003
Epoch 0, Step 5954: train/loss = 0.16489875316619873, train/raw-loss = 0.12526044249534607, train/logprobs = tensor([[-2.1354, -7.8489],
        [-4.9368, -2.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.396383136510849
Epoch 0, Step 5955: train/loss = 0.27892184257507324, train/raw-loss = 0.24539098143577576, train/logprobs = tensor([[-0.6461, -8.9638],
        [-2.1068, -4.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33530837297439575
Epoch 0, Step 5956: train/loss = 0.19808635115623474, train/raw-loss = 0.15697847306728363, train/logprobs = tensor([[ -2.5648, -12.5308],
        [ -6.7033,  -4.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41107887029647827
Epoch 0, Step 5957: train/loss = 0.35396379232406616, train/raw-loss = 0.3148166835308075, train/logprobs = tensor([[-2.2572, -4.0218],
        [-4.2283, -1.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3914710581302643
Epoch 0, Step 5958: train/loss = 0.08557979762554169, train/raw-loss = 0.041689299046993256, train/logprobs = tensor([[ -1.9272, -18.6267],
        [ -4.7353,  -6.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4389050304889679
Epoch 0, Step 5959: train/loss = 0.6307250261306763, train/raw-loss = 0.5982065200805664, train/logprobs = tensor([[-2.8753, -9.9773],
        [-3.6037, -4.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32518506050109863
Epoch 0, Step 5960: train/loss = 0.1395256221294403, train/raw-loss = 0.09613195061683655, train/logprobs = tensor([[ -1.4234, -12.2413],
        [ -4.6717,  -2.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4339367151260376
Epoch 0, Step 5961: train/loss = 0.1441056877374649, train/raw-loss = 0.10992680490016937, train/logprobs = tensor([[-2.5231, -9.2950],
        [-6.0155, -1.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34178876876831055
Epoch 0, Step 5962: train/loss = 0.3065216541290283, train/raw-loss = 0.26792871952056885, train/logprobs = tensor([[-1.6415, -6.3935],
        [-3.6121, -2.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3859294652938843
Epoch 0, Step 5963: train/loss = 0.4825391471385956, train/raw-loss = 0.4459940493106842, train/logprobs = tensor([[-1.9744, -6.0649],
        [-4.0918, -1.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3654511570930481
Epoch 0, Step 5964: train/loss = 0.06873144209384918, train/raw-loss = 0.03925080597400665, train/logprobs = tensor([[ -2.4343, -15.7419],
        [ -5.3769,  -5.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29480642080307007
Epoch 0, Step 5965: train/loss = 0.2339419275522232, train/raw-loss = 0.1962982416152954, train/logprobs = tensor([[ -1.8023, -10.0734],
        [ -5.2852,  -2.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3764367699623108
Epoch 0, Step 5966: train/loss = 0.3970303535461426, train/raw-loss = 0.356090247631073, train/logprobs = tensor([[-2.1022, -9.7990],
        [-5.6017, -6.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4094010293483734
Epoch 0, Step 5967: train/loss = 0.5756380558013916, train/raw-loss = 0.5367907285690308, train/logprobs = tensor([[-3.5019, -8.1551],
        [-3.3894, -3.5250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3884732127189636
Epoch 0, Step 5968: train/loss = 0.2973978519439697, train/raw-loss = 0.2638183832168579, train/logprobs = tensor([[-2.4721, -8.1772],
        [-4.5217, -2.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3357945680618286
Epoch 0, Step 5969: train/loss = 0.6540687680244446, train/raw-loss = 0.6142112612724304, train/logprobs = tensor([[-1.5429, -2.1185],
        [-3.8604, -2.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39857470989227295
Epoch 0, Step 5970: train/loss = 0.6187991499900818, train/raw-loss = 0.577920138835907, train/logprobs = tensor([[-1.7096, -9.0715],
        [-2.9532, -3.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4087899327278137
Epoch 0, Step 5971: train/loss = 0.5414410829544067, train/raw-loss = 0.5058842897415161, train/logprobs = tensor([[-1.3613, -6.4254],
        [-2.2031, -3.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3555683493614197
Epoch 0, Step 5972: train/loss = 0.5419792532920837, train/raw-loss = 0.49926289916038513, train/logprobs = tensor([[-1.2068, -5.8019],
        [-4.0908, -2.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42716336250305176
Epoch 0, Step 5973: train/loss = 0.4031834602355957, train/raw-loss = 0.36332017183303833, train/logprobs = tensor([[ -2.5138, -10.4349],
        [ -3.7637,  -1.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39863255620002747
Epoch 0, Step 5974: train/loss = 0.2132532000541687, train/raw-loss = 0.17597272992134094, train/logprobs = tensor([[-1.2268, -8.0093],
        [-3.5314, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37280482053756714
Epoch 0, Step 5975: train/loss = 0.30121827125549316, train/raw-loss = 0.26081448793411255, train/logprobs = tensor([[ -3.3106, -12.6144],
        [ -5.9159,  -4.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4040379524230957
Epoch 0, Step 5976: train/loss = 0.29552945494651794, train/raw-loss = 0.2525896430015564, train/logprobs = tensor([[-2.2989, -6.0071],
        [-4.3426, -2.0073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4293980300426483
Epoch 0, Step 5977: train/loss = 0.353628933429718, train/raw-loss = 0.312618613243103, train/logprobs = tensor([[-2.3089, -7.7336],
        [-3.9372, -4.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41010308265686035
Epoch 0, Step 5978: train/loss = 0.49046990275382996, train/raw-loss = 0.4541029930114746, train/logprobs = tensor([[-2.5766, -4.8385],
        [-3.8663, -2.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3636692762374878
Epoch 0, Step 5979: train/loss = 0.19171160459518433, train/raw-loss = 0.14883042871952057, train/logprobs = tensor([[-2.6585, -9.8878],
        [-6.4651, -3.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42881181836128235
Epoch 0, Step 5980: train/loss = 0.2146623730659485, train/raw-loss = 0.17778363823890686, train/logprobs = tensor([[-1.8454, -7.0248],
        [-4.2671, -2.3779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36878734827041626
Epoch 0, Step 5981: train/loss = 0.25700727105140686, train/raw-loss = 0.2264624536037445, train/logprobs = tensor([[-2.5824, -8.0367],
        [-3.6172, -1.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30544808506965637
Epoch 0, Step 5982: train/loss = 0.3365190029144287, train/raw-loss = 0.2932488024234772, train/logprobs = tensor([[-2.1327, -3.6787],
        [-5.0393, -3.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43270158767700195
Epoch 0, Step 5983: train/loss = 0.4118450880050659, train/raw-loss = 0.372646689414978, train/logprobs = tensor([[-2.1783, -4.3826],
        [-3.4124, -1.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39198410511016846
Epoch 0, Step 5984: train/loss = 0.2225339263677597, train/raw-loss = 0.17150630056858063, train/logprobs = tensor([[ -1.3998, -15.9535],
        [ -5.1772,  -6.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5102761387825012
Epoch 0, Step 5985: train/loss = 0.06396463513374329, train/raw-loss = 0.029158417135477066, train/logprobs = tensor([[ -1.6510, -18.8165],
        [ -5.2325,  -6.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480621576309204
Epoch 0, Step 5986: train/loss = 0.11326418071985245, train/raw-loss = 0.07690741121768951, train/logprobs = tensor([[-1.6122, -7.9737],
        [-5.5737, -1.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3635677099227905
Epoch 0, Step 5987: train/loss = 0.12421657890081406, train/raw-loss = 0.09341032058000565, train/logprobs = tensor([[-2.0594, -8.4350],
        [-4.7988, -0.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30806249380111694
Epoch 0, Step 5988: train/loss = 0.22442831099033356, train/raw-loss = 0.1786656528711319, train/logprobs = tensor([[-1.9840, -6.9261],
        [-5.6878, -2.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.457626610994339
Epoch 0, Step 5989: train/loss = 0.2545287013053894, train/raw-loss = 0.22549867630004883, train/logprobs = tensor([[-1.8057, -6.2369],
        [-3.1636, -1.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902998924255371
Epoch 0, Step 5990: train/loss = 0.1959366798400879, train/raw-loss = 0.15477129817008972, train/logprobs = tensor([[-1.8007, -6.0271],
        [-4.5132, -1.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41165387630462646
Epoch 0, Step 5991: train/loss = 0.5591685771942139, train/raw-loss = 0.5303655862808228, train/logprobs = tensor([[-1.7472, -2.5947],
        [-2.0013, -1.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28802984952926636
Epoch 0, Step 5992: train/loss = 0.3230891525745392, train/raw-loss = 0.28609034419059753, train/logprobs = tensor([[-2.5067, -5.8459],
        [-5.7642, -1.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36998799443244934
Epoch 0, Step 5993: train/loss = 0.16284148395061493, train/raw-loss = 0.12402445077896118, train/logprobs = tensor([[-1.8216, -9.7280],
        [-5.1439, -2.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3881702423095703
Epoch 0, Step 5994: train/loss = 0.17390717566013336, train/raw-loss = 0.13785506784915924, train/logprobs = tensor([[ -2.0019, -14.8484],
        [ -5.1544,  -4.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36052098870277405
Epoch 0, Step 5995: train/loss = 0.21897245943546295, train/raw-loss = 0.1847602128982544, train/logprobs = tensor([[ -2.3450, -11.9157],
        [ -4.9740,  -3.3759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34212255477905273
Epoch 0, Step 5996: train/loss = 0.4215519428253174, train/raw-loss = 0.3863621950149536, train/logprobs = tensor([[-2.1933, -7.2585],
        [-5.8266, -4.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35189729928970337
Epoch 0, Step 5997: train/loss = 0.28738096356391907, train/raw-loss = 0.24452853202819824, train/logprobs = tensor([[-1.6249, -4.3711],
        [-4.2809, -2.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42852428555488586
Epoch 0, Step 5998: train/loss = 0.2515939176082611, train/raw-loss = 0.2169078141450882, train/logprobs = tensor([[-1.8601, -3.5326],
        [-5.1667, -1.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468608856201172
Epoch 0, Step 5999: train/loss = 0.3301669955253601, train/raw-loss = 0.28817349672317505, train/logprobs = tensor([[-1.6703, -5.2731],
        [-3.3705, -2.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199348986148834
Epoch 0, Step 6000: train/loss = 0.29257479310035706, train/raw-loss = 0.2602168023586273, train/logprobs = tensor([[ -2.8751, -10.2166],
        [ -4.4109,  -4.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235797882080078
Epoch 0, Step 6001: train/loss = 0.35443979501724243, train/raw-loss = 0.31177377700805664, train/logprobs = tensor([[-1.5693, -5.5602],
        [-4.1173, -2.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4266601800918579
Epoch 0, Step 6002: train/loss = 0.6113293170928955, train/raw-loss = 0.5667588710784912, train/logprobs = tensor([[ -3.1901, -11.0722],
        [ -3.9526,  -3.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4457038640975952
Epoch 0, Step 6003: train/loss = 0.46707841753959656, train/raw-loss = 0.4317590296268463, train/logprobs = tensor([[-1.8168, -5.3723],
        [-4.7644, -2.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3531937599182129
Epoch 0, Step 6004: train/loss = 0.12690994143486023, train/raw-loss = 0.08653135597705841, train/logprobs = tensor([[-1.6680, -6.6459],
        [-4.3267, -1.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.403785765171051
Epoch 0, Step 6005: train/loss = 0.5288812518119812, train/raw-loss = 0.4971916377544403, train/logprobs = tensor([[-1.8845, -3.2984],
        [-2.7990, -2.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31689560413360596
Epoch 0, Step 6006: train/loss = 0.2006901651620865, train/raw-loss = 0.1639716923236847, train/logprobs = tensor([[ -1.8212, -11.7561],
        [ -4.9745,  -4.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3671848773956299
Epoch 0, Step 6007: train/loss = 0.261801540851593, train/raw-loss = 0.22162391245365143, train/logprobs = tensor([[-2.0357, -6.5721],
        [-3.9839, -2.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4017765522003174
Epoch 0, Step 6008: train/loss = 0.18531668186187744, train/raw-loss = 0.14128515124320984, train/logprobs = tensor([[-0.9802, -5.8662],
        [-3.7605, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4403153657913208
Epoch 0, Step 6009: train/loss = 0.28349441289901733, train/raw-loss = 0.2507433295249939, train/logprobs = tensor([[-1.6937, -6.7433],
        [-3.7913, -2.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32751089334487915
Epoch 0, Step 6010: train/loss = 0.2034054547548294, train/raw-loss = 0.17006491124629974, train/logprobs = tensor([[ -2.1808, -13.3241],
        [ -4.8220,  -3.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334053158760071
Epoch 0, Step 6011: train/loss = 0.16882164776325226, train/raw-loss = 0.13020211458206177, train/logprobs = tensor([[ -1.8988, -14.1468],
        [ -3.8739,  -2.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38619524240493774
Epoch 0, Step 6012: train/loss = 0.15473610162734985, train/raw-loss = 0.11669525504112244, train/logprobs = tensor([[ -1.8904, -10.4973],
        [ -5.0045,  -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3804084062576294
Epoch 0, Step 6013: train/loss = 0.5155620574951172, train/raw-loss = 0.478683739900589, train/logprobs = tensor([[-1.9382, -6.2259],
        [-2.9125, -2.6420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3687833845615387
Epoch 0, Step 6014: train/loss = 0.352436900138855, train/raw-loss = 0.31800541281700134, train/logprobs = tensor([[ -2.2072, -11.9138],
        [ -3.6201,  -4.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3443148732185364
Epoch 0, Step 6015: train/loss = 0.36911457777023315, train/raw-loss = 0.3209335505962372, train/logprobs = tensor([[-0.9964, -6.5373],
        [-5.0937, -2.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.481810063123703
Epoch 0, Step 6016: train/loss = 0.3858717083930969, train/raw-loss = 0.36037009954452515, train/logprobs = tensor([[-2.0759, -7.1491],
        [-3.6524, -1.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550160884857178
Epoch 0, Step 6017: train/loss = 0.45329973101615906, train/raw-loss = 0.41295403242111206, train/logprobs = tensor([[-2.5825, -3.0830],
        [-4.3426, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40345680713653564
Epoch 0, Step 6018: train/loss = 0.32193925976753235, train/raw-loss = 0.28821542859077454, train/logprobs = tensor([[ -2.3097, -11.2471],
        [ -4.3194,  -2.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372381627559662
Epoch 0, Step 6019: train/loss = 0.26127347350120544, train/raw-loss = 0.2322266846895218, train/logprobs = tensor([[-2.0300, -6.7847],
        [-4.2790, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29046809673309326
Epoch 0, Step 6020: train/loss = 0.1827339380979538, train/raw-loss = 0.1562424749135971, train/logprobs = tensor([[-1.1961, -5.9612],
        [-3.2070, -2.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26491475105285645
Epoch 0, Step 6021: train/loss = 0.3259102702140808, train/raw-loss = 0.2812158465385437, train/logprobs = tensor([[-1.6054, -4.7083],
        [-4.0827, -2.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44694414734840393
Epoch 0, Step 6022: train/loss = 0.29619860649108887, train/raw-loss = 0.2626453936100006, train/logprobs = tensor([[-1.7686, -5.7624],
        [-3.1867, -2.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33553215861320496
Epoch 0, Step 6023: train/loss = 0.220109224319458, train/raw-loss = 0.18124665319919586, train/logprobs = tensor([[-1.7802, -7.7302],
        [-4.3210, -2.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3886256217956543
Epoch 0, Step 6024: train/loss = 0.29086390137672424, train/raw-loss = 0.25381550192832947, train/logprobs = tensor([[-2.6919, -8.1180],
        [-3.6710, -2.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37048405408859253
Epoch 0, Step 6025: train/loss = 0.7745162844657898, train/raw-loss = 0.7459343075752258, train/logprobs = tensor([[-4.2414, -8.7885],
        [-2.5686, -2.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28581956028938293
Epoch 0, Step 6026: train/loss = 0.21218475699424744, train/raw-loss = 0.16867810487747192, train/logprobs = tensor([[ -2.6015, -11.6368],
        [ -5.1857,  -2.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4350663423538208
Epoch 0, Step 6027: train/loss = 0.10215751081705093, train/raw-loss = 0.06819473952054977, train/logprobs = tensor([[ -1.6644, -11.4326],
        [ -4.0373,  -3.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3396277129650116
Epoch 0, Step 6028: train/loss = 0.34537166357040405, train/raw-loss = 0.30238592624664307, train/logprobs = tensor([[-1.5514, -5.0193],
        [-6.2120, -2.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42985719442367554
Epoch 0, Step 6029: train/loss = 0.25520116090774536, train/raw-loss = 0.21614956855773926, train/logprobs = tensor([[-2.4606, -8.2267],
        [-3.9734, -1.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39051583409309387
Epoch 0, Step 6030: train/loss = 0.5447017550468445, train/raw-loss = 0.5192621350288391, train/logprobs = tensor([[-1.6987, -5.4956],
        [-2.0103, -1.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543967366218567
Epoch 0, Step 6031: train/loss = 0.26982739567756653, train/raw-loss = 0.22739771008491516, train/logprobs = tensor([[-2.1942, -8.2280],
        [-5.0338, -2.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42429691553115845
Epoch 0, Step 6032: train/loss = 0.2091619372367859, train/raw-loss = 0.17527040839195251, train/logprobs = tensor([[ -1.8353, -13.4938],
        [ -5.2470,  -5.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3389151990413666
Epoch 0, Step 6033: train/loss = 0.16557954251766205, train/raw-loss = 0.1303061544895172, train/logprobs = tensor([[-1.7074, -9.0912],
        [-4.0585, -3.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527339696884155
Epoch 0, Step 6034: train/loss = 0.3345523774623871, train/raw-loss = 0.2928253412246704, train/logprobs = tensor([[-1.7823, -7.4203],
        [-4.2457, -3.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4172704815864563
Epoch 0, Step 6035: train/loss = 0.5206449031829834, train/raw-loss = 0.48049396276474, train/logprobs = tensor([[-1.9126, -6.0690],
        [-3.2062, -2.2561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4015091061592102
Epoch 0, Step 6036: train/loss = 0.09787118434906006, train/raw-loss = 0.052080653607845306, train/logprobs = tensor([[ -1.8377, -12.3476],
        [ -5.2782,  -2.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45790529251098633
Epoch 0, Step 6037: train/loss = 0.8518553972244263, train/raw-loss = 0.8181023597717285, train/logprobs = tensor([[-3.7150, -8.0359],
        [-3.4804, -2.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.337530255317688
Epoch 0, Step 6038: train/loss = 0.40773749351501465, train/raw-loss = 0.3683200478553772, train/logprobs = tensor([[ -2.5240, -13.3014],
        [ -4.5826,  -5.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3941749334335327
Epoch 0, Step 6039: train/loss = 0.1690106838941574, train/raw-loss = 0.13648900389671326, train/logprobs = tensor([[-2.3455, -9.7105],
        [-5.9640, -2.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32521677017211914
Epoch 0, Step 6040: train/loss = 0.40755054354667664, train/raw-loss = 0.3756905198097229, train/logprobs = tensor([[-1.7612, -6.0518],
        [-2.3640, -1.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186003565788269
Epoch 0, Step 6041: train/loss = 0.21495965123176575, train/raw-loss = 0.18491774797439575, train/logprobs = tensor([[-2.1655, -9.5593],
        [-5.6772, -2.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30041900277137756
Epoch 0, Step 6042: train/loss = 0.3812297284603119, train/raw-loss = 0.3461616337299347, train/logprobs = tensor([[-2.3726, -4.2588],
        [-4.7430, -2.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35068070888519287
Epoch 0, Step 6043: train/loss = 0.25938528776168823, train/raw-loss = 0.22332006692886353, train/logprobs = tensor([[-1.7000, -8.5315],
        [-3.9488, -1.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.360652357339859
Epoch 0, Step 6044: train/loss = 0.20742949843406677, train/raw-loss = 0.17097459733486176, train/logprobs = tensor([[-1.4292, -4.5016],
        [-4.4333, -1.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645489811897278
Epoch 0, Step 6045: train/loss = 0.43476149439811707, train/raw-loss = 0.3896658718585968, train/logprobs = tensor([[-2.2519, -6.7900],
        [-4.2843, -3.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45095640420913696
Epoch 0, Step 6046: train/loss = 1.2495949268341064, train/raw-loss = 1.2175625562667847, train/logprobs = tensor([[-5.9873, -9.5883],
        [-2.7610, -3.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32032278180122375
Epoch 0, Step 6047: train/loss = 0.13095645606517792, train/raw-loss = 0.09494204819202423, train/logprobs = tensor([[ -1.9325, -10.6831],
        [ -4.9479,  -1.7611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36014410853385925
Epoch 0, Step 6048: train/loss = 0.18023191392421722, train/raw-loss = 0.14843691885471344, train/logprobs = tensor([[ -2.0921, -11.6636],
        [ -4.7874,  -5.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31794971227645874
Epoch 0, Step 6049: train/loss = 0.12960058450698853, train/raw-loss = 0.0956198126077652, train/logprobs = tensor([[ -1.2550, -12.6698],
        [ -5.5742,  -4.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3398077189922333
Epoch 0, Step 6050: train/loss = 0.07806780934333801, train/raw-loss = 0.042458973824977875, train/logprobs = tensor([[-1.1634, -9.5855],
        [-4.7530, -3.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560883402824402
Epoch 0, Step 6051: train/loss = 0.5572525262832642, train/raw-loss = 0.5248828530311584, train/logprobs = tensor([[-3.1630, -4.8132],
        [-4.4778, -2.5264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32369694113731384
Epoch 0, Step 6052: train/loss = 0.24203911423683167, train/raw-loss = 0.20605507493019104, train/logprobs = tensor([[-2.3689, -9.3107],
        [-3.5564, -3.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3598402440547943
Epoch 0, Step 6053: train/loss = 0.5935909152030945, train/raw-loss = 0.5661596059799194, train/logprobs = tensor([[-1.7258, -2.1830],
        [-2.7340, -2.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743126153945923
Epoch 0, Step 6054: train/loss = 0.4302501976490021, train/raw-loss = 0.38495999574661255, train/logprobs = tensor([[ -0.9643, -12.7508],
        [ -4.6763,  -5.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4529019296169281
Epoch 0, Step 6055: train/loss = 0.2436668872833252, train/raw-loss = 0.19876176118850708, train/logprobs = tensor([[-1.9525, -9.1081],
        [-4.6219, -2.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4490513801574707
Epoch 0, Step 6056: train/loss = 0.17723046243190765, train/raw-loss = 0.1354948729276657, train/logprobs = tensor([[-1.4550, -6.9055],
        [-5.2461, -2.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41735610365867615
Epoch 0, Step 6057: train/loss = 0.4565671384334564, train/raw-loss = 0.4153406023979187, train/logprobs = tensor([[-2.1522, -4.2534],
        [-3.9243, -2.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41226547956466675
Epoch 0, Step 6058: train/loss = 0.07902905344963074, train/raw-loss = 0.03976794704794884, train/logprobs = tensor([[ -1.4396, -12.3413],
        [ -6.0183,  -2.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.392611026763916
Epoch 0, Step 6059: train/loss = 0.4330616891384125, train/raw-loss = 0.39875853061676025, train/logprobs = tensor([[ -1.1880, -11.6326],
        [ -3.0576,  -5.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430313169956207
Epoch 0, Step 6060: train/loss = 0.17075669765472412, train/raw-loss = 0.1246228963136673, train/logprobs = tensor([[-2.4269, -9.7586],
        [-4.7770, -4.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46133795380592346
Epoch 0, Step 6061: train/loss = 0.17648208141326904, train/raw-loss = 0.14524617791175842, train/logprobs = tensor([[-1.8128, -5.9686],
        [-4.3598, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31235888600349426
Epoch 0, Step 6062: train/loss = 0.1031918004155159, train/raw-loss = 0.06593678891658783, train/logprobs = tensor([[ -2.8238, -10.7663],
        [ -5.9902,  -3.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3725501000881195
Epoch 0, Step 6063: train/loss = 0.808976411819458, train/raw-loss = 0.7810478210449219, train/logprobs = tensor([[-2.3369, -6.3277],
        [-3.4938, -5.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792859971523285
Epoch 0, Step 6064: train/loss = 0.3431073725223541, train/raw-loss = 0.3072335720062256, train/logprobs = tensor([[-3.1924, -7.2941],
        [-4.2910, -2.3662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587381839752197
Epoch 0, Step 6065: train/loss = 0.1971256583929062, train/raw-loss = 0.1582232117652893, train/logprobs = tensor([[-1.5638, -6.3792],
        [-5.1761, -2.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.389024555683136
Epoch 0, Step 6066: train/loss = 0.5344637632369995, train/raw-loss = 0.5015531182289124, train/logprobs = tensor([[-1.7028, -2.3871],
        [-2.9944, -1.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32910656929016113
Epoch 0, Step 6067: train/loss = 0.43406403064727783, train/raw-loss = 0.39793574810028076, train/logprobs = tensor([[-2.5221, -5.0963],
        [-4.3107, -2.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3612830638885498
Epoch 0, Step 6068: train/loss = 0.3607281744480133, train/raw-loss = 0.31928563117980957, train/logprobs = tensor([[-1.6008, -4.6251],
        [-3.7262, -2.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4144250154495239
Epoch 0, Step 6069: train/loss = 0.36983537673950195, train/raw-loss = 0.33239203691482544, train/logprobs = tensor([[-2.3872, -5.1557],
        [-5.2959, -3.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.374433308839798
Epoch 0, Step 6070: train/loss = 0.1521030217409134, train/raw-loss = 0.10140781104564667, train/logprobs = tensor([[-1.3810, -7.9341],
        [-4.7216, -1.4049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5069521069526672
Epoch 0, Step 6071: train/loss = 0.5751012563705444, train/raw-loss = 0.545019268989563, train/logprobs = tensor([[-2.1476, -8.2491],
        [-2.0019, -3.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3008197546005249
Epoch 0, Step 6072: train/loss = 0.10358449816703796, train/raw-loss = 0.06581305712461472, train/logprobs = tensor([[-1.8492, -8.4265],
        [-4.7500, -2.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37771448493003845
Epoch 0, Step 6073: train/loss = 0.29411837458610535, train/raw-loss = 0.2575167715549469, train/logprobs = tensor([[-2.0634, -4.8014],
        [-3.6013, -2.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36601588129997253
Epoch 0, Step 6074: train/loss = 0.09116645157337189, train/raw-loss = 0.05138660967350006, train/logprobs = tensor([[ -2.1908, -11.4589],
        [ -5.1375,  -1.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39779841899871826
Epoch 0, Step 6075: train/loss = 0.5055258274078369, train/raw-loss = 0.457622230052948, train/logprobs = tensor([[-1.5942, -3.3182],
        [-4.2202, -2.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4790356159210205
Epoch 0, Step 6076: train/loss = 0.7606889605522156, train/raw-loss = 0.7179872393608093, train/logprobs = tensor([[-3.5418, -5.3690],
        [-2.8372, -2.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42701661586761475
Epoch 0, Step 6077: train/loss = 0.17200198769569397, train/raw-loss = 0.1335708200931549, train/logprobs = tensor([[ -1.6999, -14.3401],
        [ -5.6308,  -7.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3843117654323578
Epoch 0, Step 6078: train/loss = 0.24922987818717957, train/raw-loss = 0.21373888850212097, train/logprobs = tensor([[-2.0948, -9.9664],
        [-3.8380, -3.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35490989685058594
Epoch 0, Step 6079: train/loss = 0.09021363407373428, train/raw-loss = 0.061016425490379333, train/logprobs = tensor([[ -3.7160, -10.6603],
        [ -7.5219,  -1.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2919721007347107
Epoch 0, Step 6080: train/loss = 0.24943381547927856, train/raw-loss = 0.2152530550956726, train/logprobs = tensor([[ -2.3200, -10.0440],
        [ -5.4110,  -2.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34180742502212524
Epoch 0, Step 6081: train/loss = 0.37503957748413086, train/raw-loss = 0.3406270146369934, train/logprobs = tensor([[-1.9237, -8.7483],
        [-3.8496, -3.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441256582736969
Epoch 0, Step 6082: train/loss = 0.0863645002245903, train/raw-loss = 0.04681772738695145, train/logprobs = tensor([[ -2.1837, -10.5497],
        [ -5.5800,  -2.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39546772837638855
Epoch 0, Step 6083: train/loss = 0.4776446223258972, train/raw-loss = 0.44099485874176025, train/logprobs = tensor([[-1.8959, -4.7654],
        [-2.9358, -2.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36649763584136963
Epoch 0, Step 6084: train/loss = 0.32257816195487976, train/raw-loss = 0.2821141481399536, train/logprobs = tensor([[-1.3524, -6.0523],
        [-3.7514, -2.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046402871608734
Epoch 0, Step 6085: train/loss = 0.25623974204063416, train/raw-loss = 0.2116764634847641, train/logprobs = tensor([[-2.9385, -8.0854],
        [-5.8237, -2.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44563281536102295
Epoch 0, Step 6086: train/loss = 0.25792592763900757, train/raw-loss = 0.21720781922340393, train/logprobs = tensor([[-1.6129, -6.9632],
        [-4.3791, -2.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40718114376068115
Epoch 0, Step 6087: train/loss = 0.31080687046051025, train/raw-loss = 0.25919651985168457, train/logprobs = tensor([[-1.4065, -6.5365],
        [-4.1389, -1.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5161035060882568
Epoch 0, Step 6088: train/loss = 0.3560560941696167, train/raw-loss = 0.31696662306785583, train/logprobs = tensor([[-1.7669, -4.2135],
        [-4.0719, -2.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908948302268982
Epoch 0, Step 6089: train/loss = 0.41554757952690125, train/raw-loss = 0.3829182982444763, train/logprobs = tensor([[-2.2328, -5.2082],
        [-3.2852, -2.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32629311084747314
Epoch 0, Step 6090: train/loss = 0.35466212034225464, train/raw-loss = 0.31919434666633606, train/logprobs = tensor([[-1.8097, -8.5226],
        [-3.3479, -3.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35467785596847534
Epoch 0, Step 6091: train/loss = 0.25914841890335083, train/raw-loss = 0.22629517316818237, train/logprobs = tensor([[ -1.5545, -12.7435],
        [ -5.8489,  -3.3863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32853251695632935
Epoch 0, Step 6092: train/loss = 0.34866705536842346, train/raw-loss = 0.31314125657081604, train/logprobs = tensor([[-2.0060, -5.2917],
        [-4.7090, -2.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35525819659233093
Epoch 0, Step 6093: train/loss = 0.1850566267967224, train/raw-loss = 0.14220961928367615, train/logprobs = tensor([[-1.5146, -6.8020],
        [-3.8591, -2.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42847004532814026
Epoch 0, Step 6094: train/loss = 0.5525549650192261, train/raw-loss = 0.5141194462776184, train/logprobs = tensor([[-1.9318, -4.0146],
        [-2.8321, -1.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38435471057891846
Epoch 0, Step 6095: train/loss = 0.3721884489059448, train/raw-loss = 0.32659539580345154, train/logprobs = tensor([[-1.8166, -6.7811],
        [-3.9160, -1.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45593053102493286
Epoch 0, Step 6096: train/loss = 0.6449978947639465, train/raw-loss = 0.6143268346786499, train/logprobs = tensor([[-3.8671, -5.6109],
        [-3.8432, -2.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3067111074924469
Epoch 0, Step 6097: train/loss = 0.7449575066566467, train/raw-loss = 0.7063363194465637, train/logprobs = tensor([[-1.6779, -2.9961],
        [-3.2852, -2.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3862113952636719
Epoch 0, Step 6098: train/loss = 0.2911307215690613, train/raw-loss = 0.2582336962223053, train/logprobs = tensor([[ -2.2461, -12.6694],
        [ -5.1124,  -5.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3289700746536255
Epoch 0, Step 6099: train/loss = 0.16952906548976898, train/raw-loss = 0.13067524135112762, train/logprobs = tensor([[ -2.7238, -10.0547],
        [ -5.3726,  -3.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.388538122177124
Epoch 0, Step 6100: train/loss = 0.346013605594635, train/raw-loss = 0.3132784068584442, train/logprobs = tensor([[-1.4811, -7.1020],
        [-2.7683, -1.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273521065711975
Epoch 0, Step 6101: train/loss = 0.49039891362190247, train/raw-loss = 0.44521576166152954, train/logprobs = tensor([[-1.7902, -7.0664],
        [-4.5300, -2.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45183151960372925
Epoch 0, Step 6102: train/loss = 0.8026188015937805, train/raw-loss = 0.7646626830101013, train/logprobs = tensor([[-1.8403, -1.7141],
        [-2.2726, -2.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37956130504608154
Epoch 0, Step 6103: train/loss = 0.2865205407142639, train/raw-loss = 0.24519553780555725, train/logprobs = tensor([[-2.7289, -6.5106],
        [-4.4131, -2.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4132501780986786
Epoch 0, Step 6104: train/loss = 0.22253289818763733, train/raw-loss = 0.1932649314403534, train/logprobs = tensor([[-1.9771, -7.2831],
        [-3.4627, -1.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29267969727516174
Epoch 0, Step 6105: train/loss = 0.5808228254318237, train/raw-loss = 0.5429012775421143, train/logprobs = tensor([[-1.8483, -5.3419],
        [-3.2806, -1.6835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3792153596878052
Epoch 0, Step 6106: train/loss = 0.06745963543653488, train/raw-loss = 0.03303178772330284, train/logprobs = tensor([[ -1.4758, -23.1400],
        [ -4.6438,  -9.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344278484582901
Epoch 0, Step 6107: train/loss = 0.2673534154891968, train/raw-loss = 0.230475053191185, train/logprobs = tensor([[-1.6941, -9.0733],
        [-4.8581, -2.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36878377199172974
Epoch 0, Step 6108: train/loss = 0.241978719830513, train/raw-loss = 0.2032729983329773, train/logprobs = tensor([[-1.8481, -8.5152],
        [-4.4997, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38705724477767944
Epoch 0, Step 6109: train/loss = 0.48224198818206787, train/raw-loss = 0.44106143712997437, train/logprobs = tensor([[-1.6534, -6.0962],
        [-2.8147, -2.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4118053615093231
Epoch 0, Step 6110: train/loss = 0.35361170768737793, train/raw-loss = 0.32019272446632385, train/logprobs = tensor([[-1.7244, -8.2991],
        [-3.2902, -1.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341900706291199
Epoch 0, Step 6111: train/loss = 0.5473888516426086, train/raw-loss = 0.5152074098587036, train/logprobs = tensor([[-2.4144, -5.5005],
        [-2.7280, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218141496181488
Epoch 0, Step 6112: train/loss = 0.3587851822376251, train/raw-loss = 0.3185449540615082, train/logprobs = tensor([[-1.6328, -8.9574],
        [-3.8076, -2.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40240222215652466
Epoch 0, Step 6113: train/loss = 0.26950356364250183, train/raw-loss = 0.23535911738872528, train/logprobs = tensor([[-1.4544, -8.4722],
        [-4.6105, -2.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3414444923400879
Epoch 0, Step 6114: train/loss = 0.5121027827262878, train/raw-loss = 0.48277726769447327, train/logprobs = tensor([[-3.7799, -7.7765],
        [-3.9904, -1.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932548522949219
Epoch 0, Step 6115: train/loss = 0.2483273297548294, train/raw-loss = 0.2170037180185318, train/logprobs = tensor([[-2.2971, -7.2319],
        [-3.7754, -2.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31323593854904175
Epoch 0, Step 6116: train/loss = 0.36595967411994934, train/raw-loss = 0.33751380443573, train/logprobs = tensor([[ -3.6836, -16.9214],
        [ -5.0702,  -6.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28445905447006226
Epoch 0, Step 6117: train/loss = 0.046890340745449066, train/raw-loss = 0.006314651109278202, train/logprobs = tensor([[ -1.3605, -18.7244],
        [ -6.3777,  -7.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4057568907737732
Epoch 0, Step 6118: train/loss = 0.27333498001098633, train/raw-loss = 0.23972323536872864, train/logprobs = tensor([[-1.5360, -5.8791],
        [-4.0205, -3.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33611738681793213
Epoch 0, Step 6119: train/loss = 0.13846641778945923, train/raw-loss = 0.09367281198501587, train/logprobs = tensor([[-1.5708, -5.5001],
        [-4.6023, -2.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.447936087846756
Epoch 0, Step 6120: train/loss = 0.5365160703659058, train/raw-loss = 0.48840051889419556, train/logprobs = tensor([[-3.6903, -7.4807],
        [-4.9646, -3.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4811558425426483
Epoch 0, Step 6121: train/loss = 0.3587089776992798, train/raw-loss = 0.30806922912597656, train/logprobs = tensor([[-2.2702, -3.8570],
        [-4.6910, -2.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5063973069190979
Epoch 0, Step 6122: train/loss = 0.5914239883422852, train/raw-loss = 0.5471405386924744, train/logprobs = tensor([[-3.4100, -5.9177],
        [-3.9022, -2.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4428347051143646
Epoch 0, Step 6123: train/loss = 0.9702821373939514, train/raw-loss = 0.928503692150116, train/logprobs = tensor([[-4.6225, -7.0426],
        [-2.9786, -2.3585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4177837669849396
Epoch 0, Step 6124: train/loss = 0.17253772914409637, train/raw-loss = 0.14205223321914673, train/logprobs = tensor([[ -1.4242, -13.2439],
        [ -4.9533,  -3.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048548400402069
Epoch 0, Step 6125: train/loss = 0.8229623436927795, train/raw-loss = 0.7956197261810303, train/logprobs = tensor([[-4.2975, -5.3652],
        [-3.4069, -2.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734263241291046
Epoch 0, Step 6126: train/loss = 0.2823844850063324, train/raw-loss = 0.25115320086479187, train/logprobs = tensor([[-1.6528, -5.7471],
        [-4.1466, -2.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31231287121772766
Epoch 0, Step 6127: train/loss = 0.3082839548587799, train/raw-loss = 0.2732771039009094, train/logprobs = tensor([[-1.8618, -7.1505],
        [-4.0962, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35006818175315857
Epoch 0, Step 6128: train/loss = 0.6889095306396484, train/raw-loss = 0.6514571905136108, train/logprobs = tensor([[-3.0542, -8.7204],
        [-2.7481, -3.2880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37452253699302673
Epoch 0, Step 6129: train/loss = 0.3387604057788849, train/raw-loss = 0.2952706515789032, train/logprobs = tensor([[ -1.6469, -10.2021],
        [ -5.8505,  -5.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4348977208137512
Epoch 0, Step 6130: train/loss = 0.22147975862026215, train/raw-loss = 0.19029727578163147, train/logprobs = tensor([[ -1.8575, -10.2298],
        [ -4.6978,  -5.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31182482838630676
Epoch 0, Step 6131: train/loss = 0.28019851446151733, train/raw-loss = 0.23854152858257294, train/logprobs = tensor([[-2.1782, -9.0652],
        [-4.8491, -2.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4165697693824768
Epoch 0, Step 6132: train/loss = 0.2531830668449402, train/raw-loss = 0.21285775303840637, train/logprobs = tensor([[-2.0364, -6.9680],
        [-3.7542, -1.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4032531678676605
Epoch 0, Step 6133: train/loss = 0.5100182294845581, train/raw-loss = 0.470370888710022, train/logprobs = tensor([[-2.6192, -6.2478],
        [-4.3798, -3.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3964730501174927
Epoch 0, Step 6134: train/loss = 0.23438021540641785, train/raw-loss = 0.2028835415840149, train/logprobs = tensor([[ -2.0346, -10.8353],
        [ -5.1834,  -4.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3149667978286743
Epoch 0, Step 6135: train/loss = 0.5105236172676086, train/raw-loss = 0.4731253981590271, train/logprobs = tensor([[-2.7041, -4.5240],
        [-3.3212, -2.2355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37398210167884827
Epoch 0, Step 6136: train/loss = 0.3274972438812256, train/raw-loss = 0.2863394618034363, train/logprobs = tensor([[-2.2366, -4.9048],
        [-4.6183, -2.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41157737374305725
Epoch 0, Step 6137: train/loss = 0.2121235877275467, train/raw-loss = 0.1696631908416748, train/logprobs = tensor([[-1.6231, -8.6718],
        [-5.2499, -2.3714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42460396885871887
Epoch 0, Step 6138: train/loss = 0.318888783454895, train/raw-loss = 0.2783868610858917, train/logprobs = tensor([[-2.4216, -8.9996],
        [-3.6429, -3.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4050189256668091
Epoch 0, Step 6139: train/loss = 0.3515438437461853, train/raw-loss = 0.32309505343437195, train/logprobs = tensor([[-2.0255, -6.2633],
        [-3.1124, -2.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28448808193206787
Epoch 0, Step 6140: train/loss = 0.29707327485084534, train/raw-loss = 0.2574738562107086, train/logprobs = tensor([[-1.6115, -5.0022],
        [-4.6478, -1.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3959941267967224
Epoch 0, Step 6141: train/loss = 0.1827889084815979, train/raw-loss = 0.14722242951393127, train/logprobs = tensor([[-2.2283, -6.6302],
        [-3.5674, -1.5421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556648790836334
Epoch 0, Step 6142: train/loss = 0.15392321348190308, train/raw-loss = 0.12091793119907379, train/logprobs = tensor([[-2.2842, -8.7728],
        [-5.4223, -2.7983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33005285263061523
Epoch 0, Step 6143: train/loss = 0.16886961460113525, train/raw-loss = 0.13701078295707703, train/logprobs = tensor([[ -1.8938, -14.3302],
        [ -4.0815,  -1.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31858813762664795
Epoch 0, Step 6144: train/loss = 0.2806309163570404, train/raw-loss = 0.2446674257516861, train/logprobs = tensor([[-1.9518, -9.5128],
        [-3.5497, -2.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35963502526283264
Epoch 0, Step 6145: train/loss = 0.14531278610229492, train/raw-loss = 0.10276786237955093, train/logprobs = tensor([[ -1.7027, -16.0811],
        [ -4.0191,  -5.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42544928193092346
Epoch 0, Step 6146: train/loss = 0.48880550265312195, train/raw-loss = 0.4482664465904236, train/logprobs = tensor([[-1.7403, -3.1297],
        [-3.1153, -2.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40539035201072693
Epoch 0, Step 6147: train/loss = 0.22365328669548035, train/raw-loss = 0.1844230741262436, train/logprobs = tensor([[ -2.5145, -10.4571],
        [ -4.0699,  -2.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3923020660877228
Epoch 0, Step 6148: train/loss = 0.43390122056007385, train/raw-loss = 0.39942777156829834, train/logprobs = tensor([[-2.1917, -6.9880],
        [-3.0075, -2.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34473469853401184
Epoch 0, Step 6149: train/loss = 0.19150136411190033, train/raw-loss = 0.16095572710037231, train/logprobs = tensor([[-2.4934, -5.6852],
        [-4.4584, -2.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30545634031295776
Epoch 0, Step 6150: train/loss = 0.18269997835159302, train/raw-loss = 0.14651645720005035, train/logprobs = tensor([[ -1.6997, -13.6505],
        [ -4.4477,  -5.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36183521151542664
Epoch 0, Step 6151: train/loss = 0.5465531945228577, train/raw-loss = 0.508600115776062, train/logprobs = tensor([[-3.2849, -6.3172],
        [-3.7463, -1.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3795309066772461
Epoch 0, Step 6152: train/loss = 0.3320465683937073, train/raw-loss = 0.28524142503738403, train/logprobs = tensor([[-2.8492, -9.9700],
        [-5.3957, -2.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4680514633655548
Epoch 0, Step 6153: train/loss = 0.30574682354927063, train/raw-loss = 0.27822715044021606, train/logprobs = tensor([[-1.6072, -8.3691],
        [-2.3192, -3.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2751968801021576
Epoch 0, Step 6154: train/loss = 0.5055265426635742, train/raw-loss = 0.47247663140296936, train/logprobs = tensor([[-1.3785, -3.8329],
        [-2.9222, -1.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3304990231990814
Epoch 0, Step 6155: train/loss = 0.3218124508857727, train/raw-loss = 0.28756049275398254, train/logprobs = tensor([[-1.5392, -7.5990],
        [-4.3590, -2.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425194323062897
Epoch 0, Step 6156: train/loss = 0.4089266061782837, train/raw-loss = 0.38365432620048523, train/logprobs = tensor([[-2.0160, -7.6688],
        [-2.3826, -1.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527227997779846
Epoch 0, Step 6157: train/loss = 0.6982077360153198, train/raw-loss = 0.660740852355957, train/logprobs = tensor([[-3.5754, -6.9303],
        [-3.8057, -2.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3746684789657593
Epoch 0, Step 6158: train/loss = 0.49183884263038635, train/raw-loss = 0.46086350083351135, train/logprobs = tensor([[-1.2031, -5.8092],
        [-3.8961, -3.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30975377559661865
Epoch 0, Step 6159: train/loss = 0.05913177505135536, train/raw-loss = 0.016209710389375687, train/logprobs = tensor([[ -1.4566, -11.5935],
        [ -5.5508,  -2.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42922064661979675
Epoch 0, Step 6160: train/loss = 0.28067487478256226, train/raw-loss = 0.24949043989181519, train/logprobs = tensor([[ -1.4962, -13.3465],
        [ -3.3086,  -5.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31184422969818115
Epoch 0, Step 6161: train/loss = 0.05520206689834595, train/raw-loss = 0.020581351593136787, train/logprobs = tensor([[ -2.7758, -13.5957],
        [ -6.8900,  -5.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462071418762207
Epoch 0, Step 6162: train/loss = 0.5880369544029236, train/raw-loss = 0.5537030100822449, train/logprobs = tensor([[-2.6625, -4.8693],
        [-2.3640, -2.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433392643928528
Epoch 0, Step 6163: train/loss = 0.15235494077205658, train/raw-loss = 0.11695931851863861, train/logprobs = tensor([[ -2.2865, -12.5198],
        [ -5.7800,  -4.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3539562225341797
Epoch 0, Step 6164: train/loss = 0.27090126276016235, train/raw-loss = 0.23555633425712585, train/logprobs = tensor([[-1.4037, -4.9500],
        [-3.7357, -1.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35344910621643066
Epoch 0, Step 6165: train/loss = 0.40149372816085815, train/raw-loss = 0.36329230666160583, train/logprobs = tensor([[-1.5412, -3.6154],
        [-3.0185, -1.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38201427459716797
Epoch 0, Step 6166: train/loss = 0.15323534607887268, train/raw-loss = 0.10875174403190613, train/logprobs = tensor([[ -1.7056, -10.5314],
        [ -4.4270,  -2.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4448361098766327
Epoch 0, Step 6167: train/loss = 0.5580683350563049, train/raw-loss = 0.5206209421157837, train/logprobs = tensor([[-2.1889, -7.7009],
        [-3.0546, -3.4671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3744739890098572
Epoch 0, Step 6168: train/loss = 0.36167293787002563, train/raw-loss = 0.32283130288124084, train/logprobs = tensor([[ -1.7070, -11.2269],
        [ -5.6956,  -2.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3884165585041046
Epoch 0, Step 6169: train/loss = 0.3241199553012848, train/raw-loss = 0.2903207838535309, train/logprobs = tensor([[ -2.6558, -12.6239],
        [ -6.4807,  -5.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3379916548728943
Epoch 0, Step 6170: train/loss = 0.23854045569896698, train/raw-loss = 0.2080031931400299, train/logprobs = tensor([[ -2.9992, -10.7704],
        [ -4.5122,  -4.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053727149963379
Epoch 0, Step 6171: train/loss = 0.4589100182056427, train/raw-loss = 0.4194366931915283, train/logprobs = tensor([[ -3.3957, -11.1190],
        [ -5.5483,  -2.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39473283290863037
Epoch 0, Step 6172: train/loss = 0.12364321947097778, train/raw-loss = 0.08902852237224579, train/logprobs = tensor([[-1.4915, -6.3853],
        [-5.1081, -2.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461468815803528
Epoch 0, Step 6173: train/loss = 0.2792814373970032, train/raw-loss = 0.23047354817390442, train/logprobs = tensor([[-2.4058, -7.7425],
        [-4.8830, -3.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4880790114402771
Epoch 0, Step 6174: train/loss = 0.1944652646780014, train/raw-loss = 0.16379950940608978, train/logprobs = tensor([[ -2.1314, -15.6691],
        [ -6.1541,  -5.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066575527191162
Epoch 0, Step 6175: train/loss = 0.1320009082555771, train/raw-loss = 0.09261435270309448, train/logprobs = tensor([[-1.5976, -9.4225],
        [-4.0830, -2.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3938656449317932
Epoch 0, Step 6176: train/loss = 0.3016902804374695, train/raw-loss = 0.2658555209636688, train/logprobs = tensor([[ -1.1947, -10.0831],
        [ -2.9774,  -3.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35834744572639465
Epoch 0, Step 6177: train/loss = 0.14793643355369568, train/raw-loss = 0.11435118317604065, train/logprobs = tensor([[ -2.3341, -10.5067],
        [ -5.6953,  -1.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3358524739742279
Epoch 0, Step 6178: train/loss = 0.0931180790066719, train/raw-loss = 0.05833527445793152, train/logprobs = tensor([[ -1.7738, -10.5708],
        [ -5.2828,  -2.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3478280305862427
Epoch 0, Step 6179: train/loss = 0.27938735485076904, train/raw-loss = 0.24247515201568604, train/logprobs = tensor([[ -2.6632, -12.1800],
        [ -6.3419,  -5.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691219985485077
Epoch 0, Step 6180: train/loss = 0.4917740821838379, train/raw-loss = 0.4526979327201843, train/logprobs = tensor([[-2.6325, -4.8750],
        [-3.7474, -1.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3907616436481476
Epoch 0, Step 6181: train/loss = 0.3831245005130768, train/raw-loss = 0.3504931330680847, train/logprobs = tensor([[-1.1511, -3.4615],
        [-3.0124, -1.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32631319761276245
Epoch 0, Step 6182: train/loss = 0.3264901041984558, train/raw-loss = 0.28665727376937866, train/logprobs = tensor([[-2.6210, -7.0662],
        [-4.8577, -2.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3983280062675476
Epoch 0, Step 6183: train/loss = 0.2149544656276703, train/raw-loss = 0.1760728359222412, train/logprobs = tensor([[-1.6257, -8.7738],
        [-4.9069, -2.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.388816237449646
Epoch 0, Step 6184: train/loss = 0.4186052083969116, train/raw-loss = 0.3811049461364746, train/logprobs = tensor([[-1.5591, -4.1216],
        [-3.1597, -2.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37500250339508057
Epoch 0, Step 6185: train/loss = 0.2936840355396271, train/raw-loss = 0.2590564489364624, train/logprobs = tensor([[ -3.4317, -10.6271],
        [ -4.4424,  -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34627604484558105
Epoch 0, Step 6186: train/loss = 0.5017690658569336, train/raw-loss = 0.462200790643692, train/logprobs = tensor([[-3.7715, -6.0790],
        [-6.1342, -3.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39568305015563965
Epoch 0, Step 6187: train/loss = 0.10639353096485138, train/raw-loss = 0.07058246433734894, train/logprobs = tensor([[-2.4799, -7.6510],
        [-6.2522, -1.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.358110636472702
Epoch 0, Step 6188: train/loss = 0.3768225610256195, train/raw-loss = 0.3339638113975525, train/logprobs = tensor([[-1.0646, -8.6173],
        [-3.7775, -5.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4285876154899597
Epoch 0, Step 6189: train/loss = 0.4331919550895691, train/raw-loss = 0.3990153670310974, train/logprobs = tensor([[-1.5267, -3.0155],
        [-2.9417, -1.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34176596999168396
Epoch 0, Step 6190: train/loss = 0.0651218444108963, train/raw-loss = 0.024814235046505928, train/logprobs = tensor([[ -2.3079, -10.2427],
        [ -6.1522,  -2.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4030761122703552
Epoch 0, Step 6191: train/loss = 0.6030218601226807, train/raw-loss = 0.5616358518600464, train/logprobs = tensor([[-1.5943, -6.3422],
        [-4.0070, -3.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.413860023021698
Epoch 0, Step 6192: train/loss = 0.29495295882225037, train/raw-loss = 0.2624059319496155, train/logprobs = tensor([[ -1.7026, -10.3076],
        [ -4.6600,  -2.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32547035813331604
Epoch 0, Step 6193: train/loss = 0.40824323892593384, train/raw-loss = 0.3702576160430908, train/logprobs = tensor([[-2.1205, -4.2953],
        [-5.3383, -1.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3798561096191406
Epoch 0, Step 6194: train/loss = 0.44677501916885376, train/raw-loss = 0.4111800193786621, train/logprobs = tensor([[-1.8756, -7.0637],
        [-2.9018, -2.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35594990849494934
Epoch 0, Step 6195: train/loss = 0.2207009196281433, train/raw-loss = 0.19425347447395325, train/logprobs = tensor([[ -1.6021, -13.0454],
        [ -3.3458,  -5.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26447466015815735
Epoch 0, Step 6196: train/loss = 0.18450334668159485, train/raw-loss = 0.13623356819152832, train/logprobs = tensor([[-1.4443, -8.9457],
        [-4.2248, -2.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4826977252960205
Epoch 0, Step 6197: train/loss = 0.7705734968185425, train/raw-loss = 0.7235109210014343, train/logprobs = tensor([[-3.6506, -8.7297],
        [-4.3410, -3.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4706260859966278
Epoch 0, Step 6198: train/loss = 0.2497384399175644, train/raw-loss = 0.21321333944797516, train/logprobs = tensor([[-1.3308, -5.6497],
        [-3.9845, -1.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36525100469589233
Epoch 0, Step 6199: train/loss = 0.5638768076896667, train/raw-loss = 0.5251256227493286, train/logprobs = tensor([[-2.0995, -4.4530],
        [-4.1117, -3.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875115215778351
Epoch 0, Step 6200: train/loss = 0.3853752315044403, train/raw-loss = 0.3380235433578491, train/logprobs = tensor([[-1.5828, -4.1041],
        [-4.1598, -3.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4735167622566223
Epoch 0, Step 6201: train/loss = 0.1330954134464264, train/raw-loss = 0.09600113332271576, train/logprobs = tensor([[ -0.8896, -10.9824],
        [ -3.7136,  -4.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3709426820278168
Epoch 0, Step 6202: train/loss = 0.495669424533844, train/raw-loss = 0.46194279193878174, train/logprobs = tensor([[-2.9044, -4.4101],
        [-2.9471, -1.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372664153575897
Epoch 0, Step 6203: train/loss = 0.22071456909179688, train/raw-loss = 0.1810181438922882, train/logprobs = tensor([[-1.7037, -8.9144],
        [-4.8907, -2.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3969639241695404
Epoch 0, Step 6204: train/loss = 0.41640526056289673, train/raw-loss = 0.3710858225822449, train/logprobs = tensor([[-1.4188, -5.9667],
        [-3.2811, -2.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4531944990158081
Epoch 0, Step 6205: train/loss = 0.18281391263008118, train/raw-loss = 0.14262092113494873, train/logprobs = tensor([[-1.7705, -5.6180],
        [-4.8660, -1.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019300043582916
Epoch 0, Step 6206: train/loss = 0.3710921108722687, train/raw-loss = 0.3325943946838379, train/logprobs = tensor([[-2.1535, -3.9891],
        [-3.5844, -1.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3849772810935974
Epoch 0, Step 6207: train/loss = 0.2580149471759796, train/raw-loss = 0.21930363774299622, train/logprobs = tensor([[-1.5802, -4.9988],
        [-3.8771, -2.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871132433414459
Epoch 0, Step 6208: train/loss = 0.49719253182411194, train/raw-loss = 0.44990164041519165, train/logprobs = tensor([[-1.6691, -4.7658],
        [-4.3703, -3.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4729088544845581
Epoch 0, Step 6209: train/loss = 0.8823977708816528, train/raw-loss = 0.8518050909042358, train/logprobs = tensor([[-4.8273, -9.9359],
        [-3.3068, -2.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059273660182953
Epoch 0, Step 6210: train/loss = 0.0830456018447876, train/raw-loss = 0.04698491841554642, train/logprobs = tensor([[ -1.7750, -10.6204],
        [ -5.1775,  -2.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3606068789958954
Epoch 0, Step 6211: train/loss = 0.2700573205947876, train/raw-loss = 0.22468781471252441, train/logprobs = tensor([[-1.9857, -8.3438],
        [-4.6476, -2.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.453695148229599
Epoch 0, Step 6212: train/loss = 0.24949747323989868, train/raw-loss = 0.2129053920507431, train/logprobs = tensor([[ -2.5626, -10.3466],
        [ -4.8333,  -3.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36592066287994385
Epoch 0, Step 6213: train/loss = 0.1753913164138794, train/raw-loss = 0.13506026566028595, train/logprobs = tensor([[-1.6359, -8.1863],
        [-4.9312, -2.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4033106565475464
Epoch 0, Step 6214: train/loss = 0.19390647113323212, train/raw-loss = 0.14693327248096466, train/logprobs = tensor([[ -1.6521, -11.7777],
        [ -4.9385,  -2.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4697319269180298
Epoch 0, Step 6215: train/loss = 0.04617024213075638, train/raw-loss = 0.00855827797204256, train/logprobs = tensor([[ -1.5358, -11.6782],
        [ -6.5891,  -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3761196434497833
Epoch 0, Step 6216: train/loss = 0.2402263730764389, train/raw-loss = 0.20741353929042816, train/logprobs = tensor([[ -2.5655, -11.5069],
        [ -4.8589,  -3.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281283974647522
Epoch 0, Step 6217: train/loss = 0.17544186115264893, train/raw-loss = 0.12757058441638947, train/logprobs = tensor([[-1.9606, -8.2166],
        [-5.5487, -3.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47871267795562744
Epoch 0, Step 6218: train/loss = 0.35358548164367676, train/raw-loss = 0.3225021958351135, train/logprobs = tensor([[-1.9959, -7.3012],
        [-3.2486, -2.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108329474925995
Epoch 0, Step 6219: train/loss = 0.26645222306251526, train/raw-loss = 0.2296452671289444, train/logprobs = tensor([[-2.2206, -9.2068],
        [-4.8548, -5.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680693805217743
Epoch 0, Step 6220: train/loss = 0.22088754177093506, train/raw-loss = 0.18345895409584045, train/logprobs = tensor([[ -2.3400, -11.5590],
        [ -6.1695,  -3.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37428584694862366
Epoch 0, Step 6221: train/loss = 0.4801802635192871, train/raw-loss = 0.4448688328266144, train/logprobs = tensor([[-2.2069, -3.9598],
        [-3.3966, -1.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35311442613601685
Epoch 0, Step 6222: train/loss = 0.4444136619567871, train/raw-loss = 0.40921202301979065, train/logprobs = tensor([[-1.8988, -5.7924],
        [-3.3805, -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3520162105560303
Epoch 0, Step 6223: train/loss = 0.1638147383928299, train/raw-loss = 0.1350565403699875, train/logprobs = tensor([[-1.6195, -8.0919],
        [-4.5117, -2.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875818610191345
Epoch 0, Step 6224: train/loss = 0.3784150779247284, train/raw-loss = 0.33917564153671265, train/logprobs = tensor([[ -2.3272, -10.2056],
        [ -4.1111,  -1.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39239436388015747
Epoch 0, Step 6225: train/loss = 0.2192661017179489, train/raw-loss = 0.18483157455921173, train/logprobs = tensor([[-2.2584, -6.1055],
        [-4.3078, -2.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34434524178504944
Epoch 0, Step 6226: train/loss = 0.8647063970565796, train/raw-loss = 0.8362206220626831, train/logprobs = tensor([[-2.5271, -5.8993],
        [-2.5881, -3.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848576605319977
Epoch 0, Step 6227: train/loss = 0.14650991559028625, train/raw-loss = 0.11389914900064468, train/logprobs = tensor([[-1.8026, -7.0606],
        [-5.1146, -2.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3261076509952545
Epoch 0, Step 6228: train/loss = 0.3420791029930115, train/raw-loss = 0.3043965697288513, train/logprobs = tensor([[-1.8054, -7.8255],
        [-3.6565, -3.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.376825213432312
Epoch 0, Step 6229: train/loss = 0.37867528200149536, train/raw-loss = 0.3494243025779724, train/logprobs = tensor([[-2.9044, -8.4112],
        [-4.8120, -2.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925100326538086
Epoch 0, Step 6230: train/loss = 0.4964258074760437, train/raw-loss = 0.45440030097961426, train/logprobs = tensor([[ -2.6780, -10.9535],
        [ -2.7295,  -2.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42025524377822876
Epoch 0, Step 6231: train/loss = 0.32827138900756836, train/raw-loss = 0.2949638366699219, train/logprobs = tensor([[ -2.5718, -12.2682],
        [ -3.8288,  -4.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330756425857544
Epoch 0, Step 6232: train/loss = 0.29660093784332275, train/raw-loss = 0.26375240087509155, train/logprobs = tensor([[-1.7931, -5.6524],
        [-2.7725, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32848572731018066
Epoch 0, Step 6233: train/loss = 0.5996426343917847, train/raw-loss = 0.5689176321029663, train/logprobs = tensor([[ -2.7332, -13.9916],
        [ -3.5836,  -3.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30724990367889404
Epoch 0, Step 6234: train/loss = 0.3455781638622284, train/raw-loss = 0.3095305860042572, train/logprobs = tensor([[-2.5204, -9.0916],
        [-4.1246, -3.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3604756295681
Epoch 0, Step 6235: train/loss = 0.10099071264266968, train/raw-loss = 0.057141248136758804, train/logprobs = tensor([[ -2.1278, -10.2877],
        [ -5.4896,  -2.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43849459290504456
Epoch 0, Step 6236: train/loss = 0.29940494894981384, train/raw-loss = 0.2651962637901306, train/logprobs = tensor([[-1.7759, -5.6764],
        [-3.8794, -2.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34208691120147705
Epoch 0, Step 6237: train/loss = 0.30787110328674316, train/raw-loss = 0.27303746342658997, train/logprobs = tensor([[-1.5683, -6.7734],
        [-4.3431, -2.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3483361601829529
Epoch 0, Step 6238: train/loss = 0.37934690713882446, train/raw-loss = 0.3462734520435333, train/logprobs = tensor([[-1.6319, -8.4610],
        [-2.8789, -1.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33073458075523376
Epoch 0, Step 6239: train/loss = 0.4262675642967224, train/raw-loss = 0.3957865834236145, train/logprobs = tensor([[-2.1716, -8.6886],
        [-2.8316, -2.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30480989813804626
Epoch 0, Step 6240: train/loss = 0.3987179696559906, train/raw-loss = 0.35258159041404724, train/logprobs = tensor([[-2.1821, -4.3489],
        [-4.3402, -2.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46136388182640076
Epoch 0, Step 6241: train/loss = 0.22979846596717834, train/raw-loss = 0.19690319895744324, train/logprobs = tensor([[-2.0206, -7.2188],
        [-5.6260, -1.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3289525508880615
Epoch 0, Step 6242: train/loss = 0.5161582231521606, train/raw-loss = 0.4747144281864166, train/logprobs = tensor([[-2.0522, -3.9979],
        [-4.3991, -2.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41443806886672974
Epoch 0, Step 6243: train/loss = 0.2115257978439331, train/raw-loss = 0.15816447138786316, train/logprobs = tensor([[-1.8203, -8.9539],
        [-5.1768, -3.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5336132049560547
Epoch 0, Step 6244: train/loss = 0.2772884964942932, train/raw-loss = 0.24542666971683502, train/logprobs = tensor([[-2.1806, -9.4238],
        [-3.3625, -1.9620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186182975769043
Epoch 0, Step 6245: train/loss = 0.3018004596233368, train/raw-loss = 0.26374679803848267, train/logprobs = tensor([[-2.5563, -4.7836],
        [-4.2316, -2.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38053664565086365
Epoch 0, Step 6246: train/loss = 0.36730849742889404, train/raw-loss = 0.3251720070838928, train/logprobs = tensor([[-2.5354, -9.0133],
        [-4.7753, -2.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42136484384536743
Epoch 0, Step 6247: train/loss = 0.7895962595939636, train/raw-loss = 0.7503737211227417, train/logprobs = tensor([[-2.5682, -4.4573],
        [-2.4642, -2.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922252953052521
Epoch 0, Step 6248: train/loss = 0.22444680333137512, train/raw-loss = 0.18906298279762268, train/logprobs = tensor([[-1.1135, -9.8561],
        [-3.4560, -1.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3538382649421692
Epoch 0, Step 6249: train/loss = 0.6349152326583862, train/raw-loss = 0.6079704761505127, train/logprobs = tensor([[-1.9436, -5.9146],
        [-2.3340, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26944857835769653
