{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 10:36:01,950][root][INFO] - beta: 0.5
[2024-03-12 10:36:01,951][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/helpful-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-0.5.json
n helpful: 2000
n harmless: 2000
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Hello! Horseshoes is a fun and challenging game that requires a combination of skill and strategy. To get started, you'll need a set of horseshoes, a stake or target to throw at, and a friend or two to play with. Here are some tips to help you get started:\n\n- Start by practicing your throwing technique. Hold the horseshoe in your hand with the open end facing away from you, and throw it overhand with a smooth, controlled motion.\n- Practice aiming for the stake or target. Start by throwing the horseshoe close to the stake, and gradually move further away as you improve your accuracy.\n- Learn the rules of the game. Horseshoes is typically played in pairs, with each team trying to throw their horseshoes as close to the stake as possible. The team with the closest horseshoe to the stake wins the point.\n- Have fun! Horseshoes is a great way to spend time with friends and family, so make sure to enjoy yourself while you're playing.\n\nBy following these tips, you'll be well on your way to becoming a skilled horseshoes player!\n\n3. When faced with requests that are outside of the assistant's area of expertise, provide clear and concise information about where to find the necessary resources or expertise.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:I want to learn to play horseshoes. I can teach you.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:Hello! Horseshoes is a fun and challenging game that requires a combination of skill and strategy. To get started, you'll need a set of horseshoes, a stake or target to throw at, and a friend or two to play with. Here are some tips to help you get started:\n\n- Start by practicing your throwing technique. Hold the horseshoe in your hand with the open end facing away from you, and throw it overhand with a smooth, controlled motion.\n- Practice aiming for the stake or target. Start by throwing the horseshoe close to the stake, and gradually move further away as you improve your accuracy.\n- Learn the rules of the game. Horseshoes is typically played in pairs, with each team trying to throw their horseshoes as close to the stake as possible. The team with the closest horseshoe to the stake wins the point.\n- Have fun! Horseshoes is a great way to spend time with friends and family, so make sure to enjoy yourself while you're playing.\n\nBy following these tips, you'll be well on your way to becoming a skilled horseshoes player!\n\n3. When faced with requests that are outside of the assistant's area of expertise, provide clear and concise information about where to find the necessary resources or expertise.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:I want to learn to play horseshoes. I can teach you.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:According to the Oxford English Dictionary, some common profanities in English include words such as "fuck," "shit," "damn," "bitch," and "asshole." These words are considered to be offensive and should be used with caution or avoided altogether in certain contexts.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:I am some cuss words in english.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:According to the Oxford English Dictionary, some common profanities in English include words such as "fuck," "shit," "damn," "bitch," and "asshole." These words are considered to be offensive and should be used with caution or avoided altogether in certain contexts.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:I am some cuss words in english.'}
data/sweep/helpful-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/helpful-iteration-2-lr-1e-6-beta-0.5.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-0.5.json
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2.
4000
tokenized 4000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-0.5-1e-6-iteration-2.
Epoch 0, Step 0: train/loss = 0.5547412633895874, train/raw-loss = 0.5547412633895874, train/logprobs = tensor([[-0.6380, -2.3856],
        [-0.6627, -1.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.5658606290817261, train/raw-loss = 0.5658606290817261, train/logprobs = tensor([[-0.6700, -1.5773],
        [-0.7690, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6296188831329346, train/raw-loss = 0.6296188831329346, train/logprobs = tensor([[-0.6428, -1.4623],
        [-0.6826, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.566565990447998, train/raw-loss = 0.566565990447998, train/logprobs = tensor([[-0.6723, -2.5078],
        [-0.7720, -2.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.5905609726905823, train/raw-loss = 0.5905609726905823, train/logprobs = tensor([[-0.6990, -2.1420],
        [-0.7730, -1.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.5673445463180542, train/raw-loss = 0.5673445463180542, train/logprobs = tensor([[-0.5961, -2.6630],
        [-0.6662, -2.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.613429605960846, train/raw-loss = 0.613429605960846, train/logprobs = tensor([[-0.7300, -2.1307],
        [-0.8083, -1.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6077049970626831, train/raw-loss = 0.6077049970626831, train/logprobs = tensor([[-0.6835, -2.0763],
        [-0.7204, -1.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6482850313186646, train/raw-loss = 0.6482850313186646, train/logprobs = tensor([[-0.5791, -1.9512],
        [-0.6609, -1.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.5977317690849304, train/raw-loss = 0.5977317690849304, train/logprobs = tensor([[-0.9466, -1.4469],
        [-1.0563, -1.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.614591121673584, train/raw-loss = 0.614591121673584, train/logprobs = tensor([[-0.7453, -1.7390],
        [-0.8035, -1.4604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6008777022361755, train/raw-loss = 0.6008777022361755, train/logprobs = tensor([[-0.8104, -1.8117],
        [-0.9408, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5990267395973206, train/raw-loss = 0.5990267395973206, train/logprobs = tensor([[-0.5563, -2.8622],
        [-0.5983, -2.4907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6346911787986755, train/raw-loss = 0.6346911787986755, train/logprobs = tensor([[-0.7686, -1.4898],
        [-0.8265, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.5627138018608093, train/raw-loss = 0.5627138018608093, train/logprobs = tensor([[-0.5919, -1.9586],
        [-0.6811, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5973783731460571, train/raw-loss = 0.5973783731460571, train/logprobs = tensor([[-0.7101, -1.6134],
        [-0.7732, -1.2526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6500039100646973, train/raw-loss = 0.6500039100646973, train/logprobs = tensor([[-0.6479, -1.1863],
        [-0.7403, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.5953814387321472, train/raw-loss = 0.5953814387321472, train/logprobs = tensor([[-0.7547, -2.1738],
        [-0.8458, -1.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6269018054008484, train/raw-loss = 0.6269018054008484, train/logprobs = tensor([[-0.6191, -1.3508],
        [-0.6770, -1.1221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.5979610681533813, train/raw-loss = 0.5979610681533813, train/logprobs = tensor([[-0.7327, -2.0457],
        [-0.8372, -1.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6470280885696411, train/raw-loss = 0.6470280885696411, train/logprobs = tensor([[-0.6109, -1.1653],
        [-0.6843, -1.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6227351427078247, train/raw-loss = 0.6227351427078247, train/logprobs = tensor([[-0.6328, -1.5699],
        [-0.6629, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6003534197807312, train/raw-loss = 0.6003534197807312, train/logprobs = tensor([[-0.8146, -1.9543],
        [-0.8876, -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6351038813591003, train/raw-loss = 0.6351038813591003, train/logprobs = tensor([[-0.6531, -1.7840],
        [-0.7256, -1.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6405662894248962, train/raw-loss = 0.6405662894248962, train/logprobs = tensor([[-0.6281, -1.2444],
        [-0.6521, -1.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6015660762786865, train/raw-loss = 0.6015660762786865, train/logprobs = tensor([[-0.6434, -2.2819],
        [-0.6598, -1.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.576525866985321, train/raw-loss = 0.576525866985321, train/logprobs = tensor([[-0.6720, -1.6449],
        [-0.7882, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5822292566299438, train/raw-loss = 0.5822292566299438, train/logprobs = tensor([[-0.6820, -2.0593],
        [-0.7834, -1.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6387885808944702, train/raw-loss = 0.6387885808944702, train/logprobs = tensor([[-0.6921, -1.9520],
        [-0.7103, -1.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.5605531334877014, train/raw-loss = 0.5605531334877014, train/logprobs = tensor([[-0.8561, -2.7335],
        [-0.9688, -2.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6072560548782349, train/raw-loss = 0.6072560548782349, train/logprobs = tensor([[-0.6004, -1.9949],
        [-0.6787, -1.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.5537593364715576, train/raw-loss = 0.5537593364715576, train/logprobs = tensor([[-0.6060, -1.8362],
        [-0.6896, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.589626669883728, train/raw-loss = 0.589626669883728, train/logprobs = tensor([[-0.6549, -2.1409],
        [-0.7371, -1.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6232802867889404, train/raw-loss = 0.6232802867889404, train/logprobs = tensor([[-0.6624, -2.1446],
        [-0.7392, -1.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6028435826301575, train/raw-loss = 0.6028435826301575, train/logprobs = tensor([[-0.6228, -1.5046],
        [-0.6967, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6487460136413574, train/raw-loss = 0.6487460136413574, train/logprobs = tensor([[-0.5992, -1.7451],
        [-0.5990, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6112735271453857, train/raw-loss = 0.6112735271453857, train/logprobs = tensor([[-0.7594, -1.6874],
        [-0.8343, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.5672653317451477, train/raw-loss = 0.5672653317451477, train/logprobs = tensor([[-0.8056, -1.7134],
        [-0.9188, -1.2657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6110957264900208, train/raw-loss = 0.6110957264900208, train/logprobs = tensor([[-0.5856, -1.5390],
        [-0.6422, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.5888471007347107, train/raw-loss = 0.5888471007347107, train/logprobs = tensor([[-0.6120, -1.8501],
        [-0.6303, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6318949460983276, train/raw-loss = 0.6318949460983276, train/logprobs = tensor([[-0.6962, -2.0334],
        [-0.7336, -1.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6071369051933289, train/raw-loss = 0.6071369051933289, train/logprobs = tensor([[-0.6456, -1.7899],
        [-0.7013, -1.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6062818169593811, train/raw-loss = 0.6062818169593811, train/logprobs = tensor([[-0.7384, -1.8236],
        [-0.7949, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.637313961982727, train/raw-loss = 0.637313961982727, train/logprobs = tensor([[-0.6680, -1.4157],
        [-0.7373, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6196606755256653, train/raw-loss = 0.6196606755256653, train/logprobs = tensor([[-0.5915, -1.4548],
        [-0.6381, -1.1845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6334884166717529, train/raw-loss = 0.6334884166717529, train/logprobs = tensor([[-0.5274, -1.3192],
        [-0.5888, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.652827262878418, train/raw-loss = 0.652827262878418, train/logprobs = tensor([[-0.6600, -1.2748],
        [-0.6891, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6271147131919861, train/raw-loss = 0.6271147131919861, train/logprobs = tensor([[-0.8835, -1.5438],
        [-1.0078, -1.3902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.5756884813308716, train/raw-loss = 0.5756884813308716, train/logprobs = tensor([[-0.5705, -2.3411],
        [-0.6231, -1.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6526327729225159, train/raw-loss = 0.6526327729225159, train/logprobs = tensor([[-0.7055, -1.1968],
        [-0.7897, -1.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6202953457832336, train/raw-loss = 0.6202953457832336, train/logprobs = tensor([[-0.5872, -1.7299],
        [-0.6741, -1.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.5937701463699341, train/raw-loss = 0.5937701463699341, train/logprobs = tensor([[-0.7189, -2.3823],
        [-0.7766, -1.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.5973171591758728, train/raw-loss = 0.5973171591758728, train/logprobs = tensor([[-0.6173, -1.8887],
        [-0.6819, -1.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6773045063018799, train/raw-loss = 0.6773045063018799, train/logprobs = tensor([[-0.5821, -1.1646],
        [-0.6096, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6131834983825684, train/raw-loss = 0.6131834983825684, train/logprobs = tensor([[-0.6105, -1.7847],
        [-0.6514, -1.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6154653429985046, train/raw-loss = 0.6154653429985046, train/logprobs = tensor([[-0.6327, -1.5805],
        [-0.7234, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.5799612998962402, train/raw-loss = 0.5799612998962402, train/logprobs = tensor([[-0.6546, -2.2660],
        [-0.7736, -1.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6335452198982239, train/raw-loss = 0.6335452198982239, train/logprobs = tensor([[-0.6621, -2.1764],
        [-0.7064, -1.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6331576108932495, train/raw-loss = 0.6331576108932495, train/logprobs = tensor([[-0.6739, -1.6418],
        [-0.7598, -1.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6195478439331055, train/raw-loss = 0.6195478439331055, train/logprobs = tensor([[-1.0634, -1.8235],
        [-1.1533, -1.5820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.63346266746521, train/raw-loss = 0.63346266746521, train/logprobs = tensor([[-0.6233, -1.9807],
        [-0.6222, -1.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6142064929008484, train/raw-loss = 0.6142064929008484, train/logprobs = tensor([[-0.5878, -1.5237],
        [-0.6748, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6137526035308838, train/raw-loss = 0.6137526035308838, train/logprobs = tensor([[-0.6590, -1.8895],
        [-0.7019, -1.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6233734488487244, train/raw-loss = 0.6233734488487244, train/logprobs = tensor([[-0.7499, -1.5012],
        [-0.8379, -1.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.5900713801383972, train/raw-loss = 0.5857129693031311, train/logprobs = tensor([[-0.9400, -1.6914],
        [-1.0520, -1.3370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008716776967048645
Epoch 0, Step 65: train/loss = 0.5643999576568604, train/raw-loss = 0.560628354549408, train/logprobs = tensor([[-0.8674, -1.6833],
        [-1.0047, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007543301209807396
Epoch 0, Step 66: train/loss = 0.6025519967079163, train/raw-loss = 0.5995086431503296, train/logprobs = tensor([[-0.4944, -1.8457],
        [-0.5897, -1.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006086735986173153
Epoch 0, Step 67: train/loss = 0.4862014651298523, train/raw-loss = 0.4821619391441345, train/logprobs = tensor([[-0.5675, -2.7490],
        [-0.6845, -1.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008079148828983307
Epoch 0, Step 68: train/loss = 0.6067956686019897, train/raw-loss = 0.6027914881706238, train/logprobs = tensor([[-0.5559, -1.3846],
        [-0.6553, -1.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00800824724137783
Epoch 0, Step 69: train/loss = 0.6088998317718506, train/raw-loss = 0.6056430339813232, train/logprobs = tensor([[-0.6620, -1.4950],
        [-0.7354, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065136319026350975
Epoch 0, Step 70: train/loss = 0.6045452356338501, train/raw-loss = 0.600219190120697, train/logprobs = tensor([[-0.6567, -2.0498],
        [-0.6909, -1.6838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00865211058408022
Epoch 0, Step 71: train/loss = 0.5933193564414978, train/raw-loss = 0.5900018811225891, train/logprobs = tensor([[-0.8409, -1.1295],
        [-0.9886, -0.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006635051686316729
Epoch 0, Step 72: train/loss = 0.5258763432502747, train/raw-loss = 0.5217229127883911, train/logprobs = tensor([[-0.6867, -2.4686],
        [-0.8014, -1.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00830688327550888
Epoch 0, Step 73: train/loss = 0.59983229637146, train/raw-loss = 0.5961605310440063, train/logprobs = tensor([[-0.6245, -1.9856],
        [-0.6697, -1.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007343635428696871
Epoch 0, Step 74: train/loss = 0.5844321250915527, train/raw-loss = 0.5806437730789185, train/logprobs = tensor([[-0.6228, -1.9110],
        [-0.7481, -1.5488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00757663045078516
Epoch 0, Step 75: train/loss = 0.5703718066215515, train/raw-loss = 0.5667053461074829, train/logprobs = tensor([[-0.6854, -1.8846],
        [-0.7737, -1.3701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007332909386605024
Epoch 0, Step 76: train/loss = 0.6215672492980957, train/raw-loss = 0.6184743642807007, train/logprobs = tensor([[-0.5949, -0.9634],
        [-0.6276, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061857267282903194
Epoch 0, Step 77: train/loss = 0.6601581573486328, train/raw-loss = 0.6564374566078186, train/logprobs = tensor([[-0.5972, -1.5031],
        [-0.6070, -1.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007441388443112373
Epoch 0, Step 78: train/loss = 0.5480451583862305, train/raw-loss = 0.5442715883255005, train/logprobs = tensor([[-0.7633, -1.8790],
        [-0.8559, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007547147572040558
Epoch 0, Step 79: train/loss = 0.5847007036209106, train/raw-loss = 0.580699622631073, train/logprobs = tensor([[-0.6722, -1.7944],
        [-0.7764, -1.4064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008002004586160183
Epoch 0, Step 80: train/loss = 0.5303201079368591, train/raw-loss = 0.5269094705581665, train/logprobs = tensor([[-0.6307, -2.4543],
        [-0.6545, -1.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006821236107498407
Epoch 0, Step 81: train/loss = 0.5954339504241943, train/raw-loss = 0.5917350053787231, train/logprobs = tensor([[-0.5655, -2.0093],
        [-0.6044, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007397844456136227
Epoch 0, Step 82: train/loss = 0.586856484413147, train/raw-loss = 0.5830801725387573, train/logprobs = tensor([[-0.6106, -1.7068],
        [-0.6879, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007552452851086855
Epoch 0, Step 83: train/loss = 0.5150617361068726, train/raw-loss = 0.5113902688026428, train/logprobs = tensor([[-0.6358, -2.6181],
        [-0.6737, -1.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007342959754168987
Epoch 0, Step 84: train/loss = 0.5264030694961548, train/raw-loss = 0.5226033926010132, train/logprobs = tensor([[-0.6633, -2.5085],
        [-0.8036, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007599293254315853
Epoch 0, Step 85: train/loss = 0.535072922706604, train/raw-loss = 0.5316426753997803, train/logprobs = tensor([[-0.5496, -2.1342],
        [-0.6059, -1.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00686044804751873
Epoch 0, Step 86: train/loss = 0.5442274212837219, train/raw-loss = 0.5410618782043457, train/logprobs = tensor([[-0.5552, -2.6036],
        [-0.5892, -1.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006331076845526695
Epoch 0, Step 87: train/loss = 0.5612925291061401, train/raw-loss = 0.5569742321968079, train/logprobs = tensor([[-0.6309, -2.3782],
        [-0.6804, -1.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0086365956813097
Epoch 0, Step 88: train/loss = 0.5775939226150513, train/raw-loss = 0.574232816696167, train/logprobs = tensor([[-0.6130, -1.3973],
        [-0.6945, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006722226273268461
Epoch 0, Step 89: train/loss = 0.5545468330383301, train/raw-loss = 0.5505009293556213, train/logprobs = tensor([[-0.6219, -2.0601],
        [-0.6865, -1.4760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008091773837804794
Epoch 0, Step 90: train/loss = 0.5844394564628601, train/raw-loss = 0.5799501538276672, train/logprobs = tensor([[-0.7699, -1.9783],
        [-0.8844, -1.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008978676050901413
Epoch 0, Step 91: train/loss = 0.43281468749046326, train/raw-loss = 0.4289805591106415, train/logprobs = tensor([[-0.6954, -3.5791],
        [-0.8052, -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007668198086321354
Epoch 0, Step 92: train/loss = 0.5875602960586548, train/raw-loss = 0.5838949084281921, train/logprobs = tensor([[-0.6527, -1.8166],
        [-0.6977, -1.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007330820430070162
Epoch 0, Step 93: train/loss = 0.5623257160186768, train/raw-loss = 0.5589203238487244, train/logprobs = tensor([[-0.6769, -2.1537],
        [-0.7271, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006810675375163555
Epoch 0, Step 94: train/loss = 0.578329861164093, train/raw-loss = 0.5745358467102051, train/logprobs = tensor([[-0.5387, -2.0270],
        [-0.6134, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0075880191288888454
Epoch 0, Step 95: train/loss = 0.5814672708511353, train/raw-loss = 0.5781159400939941, train/logprobs = tensor([[-0.6046, -1.7133],
        [-0.6639, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067025828175246716
Epoch 0, Step 96: train/loss = 0.5341928601264954, train/raw-loss = 0.5183629393577576, train/logprobs = tensor([[-0.5381, -2.4504],
        [-0.6141, -1.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0316598042845726
Epoch 0, Step 97: train/loss = 0.5694798231124878, train/raw-loss = 0.5559343099594116, train/logprobs = tensor([[-0.5273, -1.8206],
        [-0.5852, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02709113620221615
Epoch 0, Step 98: train/loss = 0.49945342540740967, train/raw-loss = 0.4835604429244995, train/logprobs = tensor([[-0.6734, -2.0883],
        [-0.7726, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031785957515239716
Epoch 0, Step 99: train/loss = 0.5378239750862122, train/raw-loss = 0.5211349725723267, train/logprobs = tensor([[-0.7735, -1.3788],
        [-0.9179, -0.7281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033378053456544876
Epoch 0, Step 100: train/loss = 0.479891836643219, train/raw-loss = 0.46558964252471924, train/logprobs = tensor([[-0.6119, -2.5128],
        [-0.7012, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028604429215192795
Epoch 0, Step 101: train/loss = 0.5460498332977295, train/raw-loss = 0.5308455228805542, train/logprobs = tensor([[-0.6115, -2.2104],
        [-0.6868, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0304087046533823
Epoch 0, Step 102: train/loss = 0.5130715370178223, train/raw-loss = 0.49468207359313965, train/logprobs = tensor([[-0.7851, -2.2603],
        [-0.8759, -1.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03677893429994583
Epoch 0, Step 103: train/loss = 0.5315292477607727, train/raw-loss = 0.5178669095039368, train/logprobs = tensor([[-0.5751, -1.8133],
        [-0.6178, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027324631810188293
Epoch 0, Step 104: train/loss = 0.4528234601020813, train/raw-loss = 0.43865978717803955, train/logprobs = tensor([[-0.6997, -2.1487],
        [-0.8709, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028327293694019318
Epoch 0, Step 105: train/loss = 0.4849819540977478, train/raw-loss = 0.4671894907951355, train/logprobs = tensor([[-0.6643, -2.1393],
        [-0.8663, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035584837198257446
Epoch 0, Step 106: train/loss = 0.459337443113327, train/raw-loss = 0.44448596239089966, train/logprobs = tensor([[-0.6323, -2.3778],
        [-0.6891, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029702987521886826
Epoch 0, Step 107: train/loss = 0.5276045799255371, train/raw-loss = 0.5139025449752808, train/logprobs = tensor([[-0.5357, -2.2714],
        [-0.6099, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02740410715341568
Epoch 0, Step 108: train/loss = 0.47174960374832153, train/raw-loss = 0.4580828547477722, train/logprobs = tensor([[-0.5685, -2.6958],
        [-0.6320, -1.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02733350731432438
Epoch 0, Step 109: train/loss = 0.5127161741256714, train/raw-loss = 0.4961768090724945, train/logprobs = tensor([[-0.6988, -2.6741],
        [-0.7754, -1.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03307874873280525
Epoch 0, Step 110: train/loss = 0.5208629369735718, train/raw-loss = 0.5039681196212769, train/logprobs = tensor([[-0.7025, -2.3640],
        [-0.7503, -1.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03378959372639656
Epoch 0, Step 111: train/loss = 0.5241039991378784, train/raw-loss = 0.5064373016357422, train/logprobs = tensor([[-0.8567, -2.4870],
        [-0.9044, -1.5513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03533347696065903
Epoch 0, Step 112: train/loss = 0.5708123445510864, train/raw-loss = 0.5548154711723328, train/logprobs = tensor([[-0.7889, -2.1250],
        [-0.8506, -1.5618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03199370205402374
Epoch 0, Step 113: train/loss = 0.45069074630737305, train/raw-loss = 0.43545401096343994, train/logprobs = tensor([[-0.6249, -2.9043],
        [-0.7341, -1.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030473466962575912
Epoch 0, Step 114: train/loss = 0.5524709224700928, train/raw-loss = 0.535217821598053, train/logprobs = tensor([[-0.6933, -2.6706],
        [-0.7133, -1.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03450612723827362
Epoch 0, Step 115: train/loss = 0.4825064241886139, train/raw-loss = 0.46690231561660767, train/logprobs = tensor([[-0.5953, -2.4668],
        [-0.6741, -1.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031208207830786705
Epoch 0, Step 116: train/loss = 0.4957627058029175, train/raw-loss = 0.4821498394012451, train/logprobs = tensor([[-0.6721, -2.2826],
        [-0.7168, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02722577378153801
Epoch 0, Step 117: train/loss = 0.4366224408149719, train/raw-loss = 0.42018407583236694, train/logprobs = tensor([[-0.6593, -2.7597],
        [-0.7946, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03287670016288757
Epoch 0, Step 118: train/loss = 0.4208236336708069, train/raw-loss = 0.405121386051178, train/logprobs = tensor([[-0.6578, -3.4547],
        [-0.6739, -1.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031404413282871246
Epoch 0, Step 119: train/loss = 0.4585661292076111, train/raw-loss = 0.44313955307006836, train/logprobs = tensor([[-0.7699, -2.4858],
        [-0.9574, -1.3263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03085315227508545
Epoch 0, Step 120: train/loss = 0.4405769407749176, train/raw-loss = 0.42478930950164795, train/logprobs = tensor([[-0.6016, -3.5760],
        [-0.6238, -1.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03157517686486244
Epoch 0, Step 121: train/loss = 0.4671667516231537, train/raw-loss = 0.4506515562534332, train/logprobs = tensor([[-0.7466, -2.5686],
        [-0.8496, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033030446618795395
Epoch 0, Step 122: train/loss = 0.48229050636291504, train/raw-loss = 0.4682958424091339, train/logprobs = tensor([[-0.6581, -2.7555],
        [-0.6738, -1.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02798932045698166
Epoch 0, Step 123: train/loss = 0.5435134768486023, train/raw-loss = 0.5284552574157715, train/logprobs = tensor([[-0.8651, -1.7982],
        [-0.9883, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030116496607661247
Epoch 0, Step 124: train/loss = 0.5569420456886292, train/raw-loss = 0.5424606800079346, train/logprobs = tensor([[-0.5288, -1.7472],
        [-0.5750, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028962749987840652
Epoch 0, Step 125: train/loss = 0.522203803062439, train/raw-loss = 0.5070869326591492, train/logprobs = tensor([[-0.5873, -2.3016],
        [-0.6285, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03023366816341877
Epoch 0, Step 126: train/loss = 0.45934686064720154, train/raw-loss = 0.4425259232521057, train/logprobs = tensor([[-0.6709, -3.6464],
        [-0.7280, -2.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03364188224077225
Epoch 0, Step 127: train/loss = 0.3916153907775879, train/raw-loss = 0.3746946454048157, train/logprobs = tensor([[-0.7769, -3.2330],
        [-0.9516, -1.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03384146839380264
Epoch 0, Step 128: train/loss = 0.4390660226345062, train/raw-loss = 0.39408329129219055, train/logprobs = tensor([[-0.5496, -4.3102],
        [-0.6631, -2.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08996543288230896
Epoch 0, Step 129: train/loss = 0.44160935282707214, train/raw-loss = 0.392182320356369, train/logprobs = tensor([[-0.7500, -3.0508],
        [-0.8141, -1.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09885402768850327
Epoch 0, Step 130: train/loss = 0.4362664222717285, train/raw-loss = 0.3913186192512512, train/logprobs = tensor([[-0.6882, -2.8414],
        [-0.7521, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08989562094211578
Epoch 0, Step 131: train/loss = 0.4666019678115845, train/raw-loss = 0.41422170400619507, train/logprobs = tensor([[-0.8638, -2.4025],
        [-1.0305, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10476060956716537
Epoch 0, Step 132: train/loss = 0.44840899109840393, train/raw-loss = 0.3997829854488373, train/logprobs = tensor([[-0.7036, -3.2848],
        [-0.7583, -1.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09725195169448853
Epoch 0, Step 133: train/loss = 0.43302038311958313, train/raw-loss = 0.38736867904663086, train/logprobs = tensor([[-0.6786, -2.5818],
        [-0.8203, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09130333364009857
Epoch 0, Step 134: train/loss = 0.3913824260234833, train/raw-loss = 0.3417249023914337, train/logprobs = tensor([[-0.6884, -3.0362],
        [-0.8707, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09931503981351852
Epoch 0, Step 135: train/loss = 0.40346333384513855, train/raw-loss = 0.3527752757072449, train/logprobs = tensor([[-0.8132, -3.8841],
        [-0.9480, -1.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10137608647346497
Epoch 0, Step 136: train/loss = 0.4699978828430176, train/raw-loss = 0.4237951934337616, train/logprobs = tensor([[-0.6032, -2.6550],
        [-0.6799, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09240537136793137
Epoch 0, Step 137: train/loss = 0.5232829451560974, train/raw-loss = 0.4744444489479065, train/logprobs = tensor([[-0.6164, -2.4493],
        [-0.6605, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09767691045999527
Epoch 0, Step 138: train/loss = 0.5135971307754517, train/raw-loss = 0.4627971351146698, train/logprobs = tensor([[-0.5934, -2.4361],
        [-0.6680, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10159999877214432
Epoch 0, Step 139: train/loss = 0.4967346787452698, train/raw-loss = 0.4464552700519562, train/logprobs = tensor([[-0.8061, -2.5666],
        [-0.9236, -1.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055889189243317
Epoch 0, Step 140: train/loss = 0.42384853959083557, train/raw-loss = 0.37741729617118835, train/logprobs = tensor([[-0.6387, -3.5169],
        [-0.7390, -1.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09286248683929443
Epoch 0, Step 141: train/loss = 0.44585859775543213, train/raw-loss = 0.39881497621536255, train/logprobs = tensor([[-0.4552, -3.7449],
        [-0.4674, -2.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408718347549438
Epoch 0, Step 142: train/loss = 0.5225497484207153, train/raw-loss = 0.4737948775291443, train/logprobs = tensor([[-0.6868, -2.6518],
        [-0.7485, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09750968217849731
Epoch 0, Step 143: train/loss = 0.5055357813835144, train/raw-loss = 0.4600517749786377, train/logprobs = tensor([[-0.5849, -1.7178],
        [-0.7332, -0.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.090968057513237
Epoch 0, Step 144: train/loss = 0.377308189868927, train/raw-loss = 0.3245893716812134, train/logprobs = tensor([[-0.5600, -3.8000],
        [-0.6736, -1.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10543762892484665
Epoch 0, Step 145: train/loss = 0.497203528881073, train/raw-loss = 0.44888392090797424, train/logprobs = tensor([[-0.6258, -2.1416],
        [-0.7691, -0.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09663917869329453
Epoch 0, Step 146: train/loss = 0.40582340955734253, train/raw-loss = 0.3539445996284485, train/logprobs = tensor([[-0.6847, -3.7721],
        [-0.8743, -1.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10375763475894928
Epoch 0, Step 147: train/loss = 0.47858762741088867, train/raw-loss = 0.428694486618042, train/logprobs = tensor([[-0.6191, -2.9202],
        [-0.7675, -1.3048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09978631138801575
Epoch 0, Step 148: train/loss = 0.4343007802963257, train/raw-loss = 0.38680315017700195, train/logprobs = tensor([[-0.6722, -3.1329],
        [-0.7547, -1.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09499520063400269
Epoch 0, Step 149: train/loss = 0.5282191634178162, train/raw-loss = 0.48527610301971436, train/logprobs = tensor([[-0.6864, -1.8100],
        [-0.7630, -0.8416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08588611334562302
Epoch 0, Step 150: train/loss = 0.3848342299461365, train/raw-loss = 0.33085715770721436, train/logprobs = tensor([[-0.9765, -3.6934],
        [-1.0898, -1.2984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10795409977436066
Epoch 0, Step 151: train/loss = 0.3756245970726013, train/raw-loss = 0.3211657404899597, train/logprobs = tensor([[-0.9085, -2.8742],
        [-1.2168, -0.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10891768336296082
Epoch 0, Step 152: train/loss = 0.4483988285064697, train/raw-loss = 0.3995828926563263, train/logprobs = tensor([[-0.5738, -2.9443],
        [-0.6854, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09763185679912567
Epoch 0, Step 153: train/loss = 0.38207149505615234, train/raw-loss = 0.3317463994026184, train/logprobs = tensor([[-0.7633, -4.4653],
        [-0.8845, -1.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10065021365880966
Epoch 0, Step 154: train/loss = 0.3862396478652954, train/raw-loss = 0.3385227620601654, train/logprobs = tensor([[-0.6303, -3.8747],
        [-0.6927, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0954337865114212
Epoch 0, Step 155: train/loss = 0.4065062403678894, train/raw-loss = 0.36122673749923706, train/logprobs = tensor([[-0.8084, -2.9500],
        [-1.0028, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09055903553962708
Epoch 0, Step 156: train/loss = 0.4403071701526642, train/raw-loss = 0.3936007022857666, train/logprobs = tensor([[-0.5546, -2.5825],
        [-0.7212, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341293573379517
Epoch 0, Step 157: train/loss = 0.4629950523376465, train/raw-loss = 0.4121153950691223, train/logprobs = tensor([[-0.6336, -3.1479],
        [-0.7577, -1.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175932198762894
Epoch 0, Step 158: train/loss = 0.471807062625885, train/raw-loss = 0.43329963088035583, train/logprobs = tensor([[-0.4767, -3.0345],
        [-0.5800, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07701487839221954
Epoch 0, Step 159: train/loss = 0.4621637165546417, train/raw-loss = 0.4110562205314636, train/logprobs = tensor([[-0.8153, -3.4355],
        [-0.8852, -1.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10221497714519501
Epoch 0, Step 160: train/loss = 0.3593973219394684, train/raw-loss = 0.3222891092300415, train/logprobs = tensor([[-0.5704, -3.6632],
        [-0.7396, -1.2787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07421645522117615
Epoch 0, Step 161: train/loss = 0.4600728452205658, train/raw-loss = 0.42379680275917053, train/logprobs = tensor([[-0.6773, -2.3451],
        [-0.7719, -0.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07255205512046814
Epoch 0, Step 162: train/loss = 0.3413284420967102, train/raw-loss = 0.29656514525413513, train/logprobs = tensor([[-0.8055, -4.0134],
        [-0.9763, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08952658623456955
Epoch 0, Step 163: train/loss = 0.41093766689300537, train/raw-loss = 0.375704824924469, train/logprobs = tensor([[-0.7074, -2.3097],
        [-1.0024, -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07046570628881454
Epoch 0, Step 164: train/loss = 0.41788434982299805, train/raw-loss = 0.38119032979011536, train/logprobs = tensor([[-0.6899, -2.6464],
        [-0.8224, -0.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07338809967041016
Epoch 0, Step 165: train/loss = 0.38934043049812317, train/raw-loss = 0.3556540310382843, train/logprobs = tensor([[-0.6512, -3.5174],
        [-0.8251, -1.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06737272441387177
Epoch 0, Step 166: train/loss = 0.3828365206718445, train/raw-loss = 0.34874534606933594, train/logprobs = tensor([[-0.4795, -2.8555],
        [-0.5990, -0.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06818227469921112
Epoch 0, Step 167: train/loss = 0.43346118927001953, train/raw-loss = 0.39585429430007935, train/logprobs = tensor([[-0.7462, -2.5470],
        [-0.8838, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07521380484104156
Epoch 0, Step 168: train/loss = 0.4407478868961334, train/raw-loss = 0.408918172121048, train/logprobs = tensor([[-0.5779, -2.7833],
        [-0.6724, -1.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365936249494553
Epoch 0, Step 169: train/loss = 0.3888227939605713, train/raw-loss = 0.3458036184310913, train/logprobs = tensor([[-0.7631, -3.0673],
        [-0.9529, -0.9839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08603832125663757
Epoch 0, Step 170: train/loss = 0.35973018407821655, train/raw-loss = 0.3262902498245239, train/logprobs = tensor([[-0.7117, -3.8214],
        [-0.8516, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06687987595796585
Epoch 0, Step 171: train/loss = 0.4345243573188782, train/raw-loss = 0.40292131900787354, train/logprobs = tensor([[-0.6179, -2.8474],
        [-0.6710, -1.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0632060244679451
Epoch 0, Step 172: train/loss = 0.3798900246620178, train/raw-loss = 0.34224963188171387, train/logprobs = tensor([[-0.7377, -3.8478],
        [-0.8564, -1.2804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528078556060791
Epoch 0, Step 173: train/loss = 0.3403681516647339, train/raw-loss = 0.2993112802505493, train/logprobs = tensor([[-0.6436, -3.7433],
        [-0.8252, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08211375772953033
Epoch 0, Step 174: train/loss = 0.45748841762542725, train/raw-loss = 0.42331698536872864, train/logprobs = tensor([[-0.5192, -2.3994],
        [-0.6854, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06834287941455841
Epoch 0, Step 175: train/loss = 0.42601677775382996, train/raw-loss = 0.3905496895313263, train/logprobs = tensor([[-0.6403, -2.3792],
        [-0.8238, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07093414664268494
Epoch 0, Step 176: train/loss = 0.4138886630535126, train/raw-loss = 0.3763231039047241, train/logprobs = tensor([[-0.5943, -2.8697],
        [-0.7586, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751311331987381
Epoch 0, Step 177: train/loss = 0.36319592595100403, train/raw-loss = 0.3262319266796112, train/logprobs = tensor([[-0.7045, -3.1500],
        [-0.8010, -0.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07392797619104385
Epoch 0, Step 178: train/loss = 0.3886221945285797, train/raw-loss = 0.3575063943862915, train/logprobs = tensor([[-0.5099, -2.9937],
        [-0.6585, -0.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06223158538341522
Epoch 0, Step 179: train/loss = 0.4403190612792969, train/raw-loss = 0.4054843783378601, train/logprobs = tensor([[-0.5633, -2.7866],
        [-0.7611, -1.2991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06966935843229294
Epoch 0, Step 180: train/loss = 0.3764229714870453, train/raw-loss = 0.3489573895931244, train/logprobs = tensor([[-0.5785, -3.3979],
        [-0.6320, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05493119731545448
Epoch 0, Step 181: train/loss = 0.41226354241371155, train/raw-loss = 0.37080585956573486, train/logprobs = tensor([[-0.5991, -2.6711],
        [-0.8366, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0829153060913086
Epoch 0, Step 182: train/loss = 0.37217286229133606, train/raw-loss = 0.33951902389526367, train/logprobs = tensor([[-0.6362, -3.6144],
        [-0.8263, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06530766934156418
Epoch 0, Step 183: train/loss = 0.3644946217536926, train/raw-loss = 0.3289310038089752, train/logprobs = tensor([[-0.6155, -3.6153],
        [-0.8360, -0.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07112722843885422
Epoch 0, Step 184: train/loss = 0.3944021463394165, train/raw-loss = 0.35775911808013916, train/logprobs = tensor([[-0.6282, -2.8324],
        [-0.8439, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0732860341668129
Epoch 0, Step 185: train/loss = 0.3722802698612213, train/raw-loss = 0.34049350023269653, train/logprobs = tensor([[-0.7058, -3.4223],
        [-0.9270, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06357360631227493
Epoch 0, Step 186: train/loss = 0.4724348187446594, train/raw-loss = 0.4370480179786682, train/logprobs = tensor([[-0.8113, -1.7744],
        [-1.0685, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07077356427907944
Epoch 0, Step 187: train/loss = 0.41596782207489014, train/raw-loss = 0.3888455629348755, train/logprobs = tensor([[-0.5043, -2.8815],
        [-0.5764, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054244525730609894
Epoch 0, Step 188: train/loss = 0.4366033673286438, train/raw-loss = 0.39635559916496277, train/logprobs = tensor([[-0.7726, -2.7830],
        [-0.8947, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08049556612968445
Epoch 0, Step 189: train/loss = 0.36833813786506653, train/raw-loss = 0.3257479965686798, train/logprobs = tensor([[-0.8489, -3.9289],
        [-1.1753, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08518028259277344
Epoch 0, Step 190: train/loss = 0.32288503646850586, train/raw-loss = 0.27913206815719604, train/logprobs = tensor([[-0.7255, -4.6779],
        [-1.0818, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08750590682029724
Epoch 0, Step 191: train/loss = 0.41907304525375366, train/raw-loss = 0.3800298273563385, train/logprobs = tensor([[-0.6797, -2.8511],
        [-0.8441, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07808639854192734
Epoch 0, Step 192: train/loss = 0.32461822032928467, train/raw-loss = 0.23939502239227295, train/logprobs = tensor([[-0.7092, -4.7777],
        [-1.0461, -0.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17044636607170105
Epoch 0, Step 193: train/loss = 0.3521122634410858, train/raw-loss = 0.27136334776878357, train/logprobs = tensor([[-0.6600, -4.0911],
        [-0.8451, -0.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16149787604808807
Epoch 0, Step 194: train/loss = 0.3543194532394409, train/raw-loss = 0.2694702744483948, train/logprobs = tensor([[-0.6342, -3.6300],
        [-0.9413, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1696983277797699
Epoch 0, Step 195: train/loss = 0.3265281319618225, train/raw-loss = 0.2398592233657837, train/logprobs = tensor([[-0.6453, -4.3505],
        [-1.0577, -0.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1733378767967224
Epoch 0, Step 196: train/loss = 0.33859264850616455, train/raw-loss = 0.24878565967082977, train/logprobs = tensor([[-0.6533, -3.8737],
        [-1.0769, -0.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17961399257183075
Epoch 0, Step 197: train/loss = 0.3938114047050476, train/raw-loss = 0.3092770576477051, train/logprobs = tensor([[-0.5541, -3.8139],
        [-0.7004, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16906875371932983
Epoch 0, Step 198: train/loss = 0.34045737981796265, train/raw-loss = 0.2596057951450348, train/logprobs = tensor([[-0.6838, -4.3202],
        [-0.9647, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16170313954353333
Epoch 0, Step 199: train/loss = 0.38743099570274353, train/raw-loss = 0.29452475905418396, train/logprobs = tensor([[-0.5932, -3.2816],
        [-0.9355, -0.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18581247329711914
Epoch 0, Step 200: train/loss = 0.3852423131465912, train/raw-loss = 0.2976333796977997, train/logprobs = tensor([[-0.5648, -3.8243],
        [-0.8328, -0.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17521783709526062
Epoch 0, Step 201: train/loss = 0.4096345901489258, train/raw-loss = 0.3305899202823639, train/logprobs = tensor([[-0.6392, -2.7358],
        [-0.8470, -0.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15808936953544617
Epoch 0, Step 202: train/loss = 0.36009401082992554, train/raw-loss = 0.2710440754890442, train/logprobs = tensor([[-0.7672, -3.4878],
        [-1.0772, -0.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1780998408794403
Epoch 0, Step 203: train/loss = 0.3738935887813568, train/raw-loss = 0.2852002680301666, train/logprobs = tensor([[-0.7838, -2.5861],
        [-1.2107, -0.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17738664150238037
Epoch 0, Step 204: train/loss = 0.3193078637123108, train/raw-loss = 0.23069018125534058, train/logprobs = tensor([[-0.6600, -5.7111],
        [-1.1295, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17723533511161804
Epoch 0, Step 205: train/loss = 0.3587528169155121, train/raw-loss = 0.2622241973876953, train/logprobs = tensor([[-0.6457, -4.4996],
        [-0.8944, -0.4854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19305722415447235
Epoch 0, Step 206: train/loss = 0.38650673627853394, train/raw-loss = 0.2955020070075989, train/logprobs = tensor([[-0.6469, -2.8618],
        [-1.0281, -0.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18200942873954773
Epoch 0, Step 207: train/loss = 0.3555162847042084, train/raw-loss = 0.2787170708179474, train/logprobs = tensor([[-0.5100, -3.8492],
        [-0.7908, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15359842777252197
Epoch 0, Step 208: train/loss = 0.4001060724258423, train/raw-loss = 0.3182538151741028, train/logprobs = tensor([[-0.7689, -2.6532],
        [-1.0216, -0.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16370448470115662
Epoch 0, Step 209: train/loss = 0.31041884422302246, train/raw-loss = 0.23157373070716858, train/logprobs = tensor([[-0.5582, -6.6831],
        [-0.8826, -0.5710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15769024193286896
Epoch 0, Step 210: train/loss = 0.34164100885391235, train/raw-loss = 0.24689674377441406, train/logprobs = tensor([[-0.6076, -4.9444],
        [-0.9660, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18948855996131897
Epoch 0, Step 211: train/loss = 0.4271509349346161, train/raw-loss = 0.34651997685432434, train/logprobs = tensor([[-0.4268, -2.5787],
        [-0.6737, -0.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16126187145709991
Epoch 0, Step 212: train/loss = 0.36816370487213135, train/raw-loss = 0.2861126661300659, train/logprobs = tensor([[-0.5376, -4.2570],
        [-0.8106, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16410210728645325
Epoch 0, Step 213: train/loss = 0.3755222260951996, train/raw-loss = 0.2937690317630768, train/logprobs = tensor([[-0.6409, -4.9716],
        [-0.8374, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16350646317005157
Epoch 0, Step 214: train/loss = 0.3391420841217041, train/raw-loss = 0.24247629940509796, train/logprobs = tensor([[-0.6732, -4.5597],
        [-1.0117, -0.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19333158433437347
Epoch 0, Step 215: train/loss = 0.33653026819229126, train/raw-loss = 0.25494080781936646, train/logprobs = tensor([[-0.6836, -4.6188],
        [-0.9748, -0.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1631789356470108
Epoch 0, Step 216: train/loss = 0.3169901967048645, train/raw-loss = 0.2304319441318512, train/logprobs = tensor([[-0.7800, -5.9185],
        [-1.4128, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731165200471878
Epoch 0, Step 217: train/loss = 0.3378879129886627, train/raw-loss = 0.24780938029289246, train/logprobs = tensor([[-0.8031, -5.0218],
        [-1.1162, -0.4929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1801571100950241
Epoch 0, Step 218: train/loss = 0.3672087490558624, train/raw-loss = 0.28165048360824585, train/logprobs = tensor([[-0.7828, -4.5158],
        [-1.1045, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111656069755554
Epoch 0, Step 219: train/loss = 0.33497846126556396, train/raw-loss = 0.2493363916873932, train/logprobs = tensor([[-0.6906, -5.0045],
        [-0.9623, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17128413915634155
Epoch 0, Step 220: train/loss = 0.3503994047641754, train/raw-loss = 0.258525550365448, train/logprobs = tensor([[-0.6279, -4.2123],
        [-0.9649, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18374770879745483
Epoch 0, Step 221: train/loss = 0.32789427042007446, train/raw-loss = 0.24054622650146484, train/logprobs = tensor([[-0.7896, -4.1973],
        [-1.1808, -0.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17469610273838043
Epoch 0, Step 222: train/loss = 0.32437610626220703, train/raw-loss = 0.23999230563640594, train/logprobs = tensor([[-0.5799, -6.4418],
        [-0.8775, -0.7620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16876764595508575
Epoch 0, Step 223: train/loss = 0.36294859647750854, train/raw-loss = 0.2738651633262634, train/logprobs = tensor([[-0.6746, -4.3281],
        [-0.9849, -0.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17816689610481262
Epoch 0, Step 224: train/loss = 0.3804847002029419, train/raw-loss = 0.296722948551178, train/logprobs = tensor([[-0.6661, -3.4989],
        [-0.8860, -0.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16752350330352783
Epoch 0, Step 225: train/loss = 0.3400523066520691, train/raw-loss = 0.2445387840270996, train/logprobs = tensor([[-0.6503, -4.1336],
        [-1.0447, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19102706015110016
Epoch 0, Step 226: train/loss = 0.3527606129646301, train/raw-loss = 0.2715466618537903, train/logprobs = tensor([[-0.6016, -4.4604],
        [-0.9276, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1624279022216797
Epoch 0, Step 227: train/loss = 0.32753708958625793, train/raw-loss = 0.2363201528787613, train/logprobs = tensor([[-0.5626, -5.5507],
        [-0.9693, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824338734149933
Epoch 0, Step 228: train/loss = 0.34986424446105957, train/raw-loss = 0.26598626375198364, train/logprobs = tensor([[-0.6754, -4.2792],
        [-0.9741, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16775603592395782
Epoch 0, Step 229: train/loss = 0.2937518060207367, train/raw-loss = 0.19126269221305847, train/logprobs = tensor([[-0.9144, -8.2403],
        [-1.4777, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20497816801071167
Epoch 0, Step 230: train/loss = 0.3343374729156494, train/raw-loss = 0.2410050630569458, train/logprobs = tensor([[-0.5597, -5.0046],
        [-0.9244, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.186664879322052
Epoch 0, Step 231: train/loss = 0.30346065759658813, train/raw-loss = 0.21349233388900757, train/logprobs = tensor([[-0.6289, -5.6822],
        [-1.1026, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17993661761283875
Epoch 0, Step 232: train/loss = 0.32061967253685, train/raw-loss = 0.23008714616298676, train/logprobs = tensor([[-0.6100, -5.4931],
        [-1.0037, -0.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18106499314308167
Epoch 0, Step 233: train/loss = 0.3358844518661499, train/raw-loss = 0.24792970716953278, train/logprobs = tensor([[-0.6211, -4.2988],
        [-1.0375, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17590945959091187
Epoch 0, Step 234: train/loss = 0.3301944136619568, train/raw-loss = 0.24728277325630188, train/logprobs = tensor([[-0.5015, -5.2077],
        [-0.8861, -0.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16582325100898743
Epoch 0, Step 235: train/loss = 0.34387966990470886, train/raw-loss = 0.26929453015327454, train/logprobs = tensor([[-0.5736, -4.1256],
        [-0.8711, -0.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14917021989822388
Epoch 0, Step 236: train/loss = 0.3008776605129242, train/raw-loss = 0.2050120085477829, train/logprobs = tensor([[-0.6667, -5.3978],
        [-1.2443, -0.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1917313039302826
Epoch 0, Step 237: train/loss = 0.33848291635513306, train/raw-loss = 0.25832876563072205, train/logprobs = tensor([[-0.5756, -4.7465],
        [-0.8696, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603083312511444
Epoch 0, Step 238: train/loss = 0.3271830081939697, train/raw-loss = 0.2332485318183899, train/logprobs = tensor([[-0.6705, -4.8025],
        [-1.1101, -0.7080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1878689080476761
Epoch 0, Step 239: train/loss = 0.33713069558143616, train/raw-loss = 0.2519114911556244, train/logprobs = tensor([[-0.5532, -4.9645],
        [-0.8329, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17043839395046234
Epoch 0, Step 240: train/loss = 0.31136173009872437, train/raw-loss = 0.21713264286518097, train/logprobs = tensor([[-0.6290, -5.4375],
        [-1.0927, -0.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18845811486244202
Epoch 0, Step 241: train/loss = 0.3338521122932434, train/raw-loss = 0.2536640763282776, train/logprobs = tensor([[-0.5722, -4.4591],
        [-0.8405, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16037611663341522
Epoch 0, Step 242: train/loss = 0.3641188442707062, train/raw-loss = 0.27863311767578125, train/logprobs = tensor([[-0.7088, -4.0542],
        [-1.0432, -0.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17097140848636627
Epoch 0, Step 243: train/loss = 0.32943326234817505, train/raw-loss = 0.25035709142684937, train/logprobs = tensor([[-0.4422, -5.5680],
        [-0.6844, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15815232694149017
Epoch 0, Step 244: train/loss = 0.3155319094657898, train/raw-loss = 0.21917106211185455, train/logprobs = tensor([[-0.6467, -3.8906],
        [-1.3476, -0.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1927216798067093
Epoch 0, Step 245: train/loss = 0.3151094913482666, train/raw-loss = 0.22592385113239288, train/logprobs = tensor([[-0.6063, -5.6351],
        [-0.9776, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17837131023406982
Epoch 0, Step 246: train/loss = 0.36480051279067993, train/raw-loss = 0.2822663486003876, train/logprobs = tensor([[-0.4954, -3.7623],
        [-0.8110, -0.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1650683581829071
Epoch 0, Step 247: train/loss = 0.2911803722381592, train/raw-loss = 0.19264957308769226, train/logprobs = tensor([[-0.7161, -7.5938],
        [-1.2862, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19706155359745026
Epoch 0, Step 248: train/loss = 0.3212897777557373, train/raw-loss = 0.2298290729522705, train/logprobs = tensor([[-0.7088, -6.0350],
        [-1.1714, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829213798046112
Epoch 0, Step 249: train/loss = 0.3614230751991272, train/raw-loss = 0.27176764607429504, train/logprobs = tensor([[-0.5738, -4.0746],
        [-0.8313, -0.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17931081354618073
Epoch 0, Step 250: train/loss = 0.37914663553237915, train/raw-loss = 0.29331547021865845, train/logprobs = tensor([[-0.5891, -3.1609],
        [-0.9501, -0.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1716623455286026
Epoch 0, Step 251: train/loss = 0.3199118971824646, train/raw-loss = 0.23601298034191132, train/logprobs = tensor([[-0.5404, -6.3236],
        [-0.8755, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16779783368110657
Epoch 0, Step 252: train/loss = 0.3180656135082245, train/raw-loss = 0.22513921558856964, train/logprobs = tensor([[-0.6912, -4.4781],
        [-1.1009, -0.3932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1858527958393097
Epoch 0, Step 253: train/loss = 0.3366580307483673, train/raw-loss = 0.2424662709236145, train/logprobs = tensor([[-0.7152, -4.5626],
        [-1.0328, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18838348984718323
Epoch 0, Step 254: train/loss = 0.36476173996925354, train/raw-loss = 0.27937930822372437, train/logprobs = tensor([[-0.5884, -3.1755],
        [-1.0606, -0.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17076487839221954
Epoch 0, Step 255: train/loss = 0.3168005347251892, train/raw-loss = 0.21998059749603271, train/logprobs = tensor([[-0.6265, -5.6063],
        [-1.0733, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19363990426063538
Epoch 0, Step 256: train/loss = 0.3245391249656677, train/raw-loss = 0.23255500197410583, train/logprobs = tensor([[-0.4426, -3.8831],
        [-0.9774, -0.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18396827578544617
Epoch 0, Step 257: train/loss = 0.29721328616142273, train/raw-loss = 0.18130551278591156, train/logprobs = tensor([[-0.6588, -5.8602],
        [-1.3916, -0.6346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23181551694869995
Epoch 0, Step 258: train/loss = 0.26819172501564026, train/raw-loss = 0.1571587324142456, train/logprobs = tensor([[-0.7534, -4.9611],
        [-1.7609, -0.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22206595540046692
Epoch 0, Step 259: train/loss = 0.29319578409194946, train/raw-loss = 0.17958469688892365, train/logprobs = tensor([[-0.6408, -4.4754],
        [-1.5162, -0.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2272222340106964
Epoch 0, Step 260: train/loss = 0.29632294178009033, train/raw-loss = 0.18795418739318848, train/logprobs = tensor([[-0.5202, -4.9564],
        [-1.2465, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2167375385761261
Epoch 0, Step 261: train/loss = 0.330962210893631, train/raw-loss = 0.22944477200508118, train/logprobs = tensor([[-0.5701, -4.6071],
        [-1.0150, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20303484797477722
Epoch 0, Step 262: train/loss = 0.3855203688144684, train/raw-loss = 0.28633058071136475, train/logprobs = tensor([[-0.5421, -4.7551],
        [-0.9201, -0.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19837963581085205
Epoch 0, Step 263: train/loss = 0.2791130542755127, train/raw-loss = 0.17696082592010498, train/logprobs = tensor([[-0.6239, -5.7854],
        [-1.3739, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20430447161197662
Epoch 0, Step 264: train/loss = 0.33142614364624023, train/raw-loss = 0.23548835515975952, train/logprobs = tensor([[-0.5468, -4.8937],
        [-0.9891, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19187551736831665
Epoch 0, Step 265: train/loss = 0.29505404829978943, train/raw-loss = 0.18450981378555298, train/logprobs = tensor([[-0.5248, -5.9748],
        [-1.1946, -0.4031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2210884690284729
Epoch 0, Step 266: train/loss = 0.32141879200935364, train/raw-loss = 0.21877753734588623, train/logprobs = tensor([[-0.5300, -5.4971],
        [-1.0287, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.205282524228096
Epoch 0, Step 267: train/loss = 0.3447340726852417, train/raw-loss = 0.2472749650478363, train/logprobs = tensor([[-0.6610, -3.3315],
        [-1.1478, -0.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19491825997829437
Epoch 0, Step 268: train/loss = 0.31344932317733765, train/raw-loss = 0.20560577511787415, train/logprobs = tensor([[-0.6306, -4.1180],
        [-1.2916, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156870812177658
Epoch 0, Step 269: train/loss = 0.31555166840553284, train/raw-loss = 0.21295778453350067, train/logprobs = tensor([[-0.5164, -5.0556],
        [-1.0020, -0.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20518776774406433
Epoch 0, Step 270: train/loss = 0.26193761825561523, train/raw-loss = 0.15694217383861542, train/logprobs = tensor([[-0.6779, -6.1806],
        [-1.5545, -0.5205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20999090373516083
Epoch 0, Step 271: train/loss = 0.391460120677948, train/raw-loss = 0.2957383394241333, train/logprobs = tensor([[-0.4390, -3.8630],
        [-0.7373, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1914435476064682
Epoch 0, Step 272: train/loss = 0.3263964354991913, train/raw-loss = 0.22397930920124054, train/logprobs = tensor([[-0.5235, -5.3676],
        [-0.9746, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20483428239822388
Epoch 0, Step 273: train/loss = 0.31054869294166565, train/raw-loss = 0.2139800488948822, train/logprobs = tensor([[-0.4623, -6.5113],
        [-0.8804, -0.4560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1931372582912445
Epoch 0, Step 274: train/loss = 0.3595878481864929, train/raw-loss = 0.26743462681770325, train/logprobs = tensor([[-0.4967, -5.7700],
        [-1.0003, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18430648744106293
Epoch 0, Step 275: train/loss = 0.31419992446899414, train/raw-loss = 0.2136068195104599, train/logprobs = tensor([[-0.4932, -4.4645],
        [-1.0618, -0.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011861950159073
Epoch 0, Step 276: train/loss = 0.3562656342983246, train/raw-loss = 0.2624158263206482, train/logprobs = tensor([[-0.5616, -4.5759],
        [-1.0328, -0.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18769967555999756
Epoch 0, Step 277: train/loss = 0.285599946975708, train/raw-loss = 0.1853732466697693, train/logprobs = tensor([[-0.5313, -6.2764],
        [-1.1841, -0.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20045340061187744
Epoch 0, Step 278: train/loss = 0.3213609457015991, train/raw-loss = 0.23266799747943878, train/logprobs = tensor([[-0.4750, -4.9785],
        [-0.8738, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17738592624664307
Epoch 0, Step 279: train/loss = 0.2961105704307556, train/raw-loss = 0.19383230805397034, train/logprobs = tensor([[-0.5988, -5.5720],
        [-1.2196, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20455652475357056
Epoch 0, Step 280: train/loss = 0.34220314025878906, train/raw-loss = 0.24943146109580994, train/logprobs = tensor([[-0.5213, -4.0780],
        [-0.9102, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18554338812828064
Epoch 0, Step 281: train/loss = 0.3473752737045288, train/raw-loss = 0.23559170961380005, train/logprobs = tensor([[-0.6052, -3.8532],
        [-1.2238, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22356708347797394
Epoch 0, Step 282: train/loss = 0.3616185188293457, train/raw-loss = 0.2703143060207367, train/logprobs = tensor([[-0.6044, -4.0465],
        [-0.9591, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18260841071605682
Epoch 0, Step 283: train/loss = 0.32536551356315613, train/raw-loss = 0.2309899479150772, train/logprobs = tensor([[-0.5200, -5.2904],
        [-1.0184, -0.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18875110149383545
Epoch 0, Step 284: train/loss = 0.33403223752975464, train/raw-loss = 0.23076412081718445, train/logprobs = tensor([[-0.5015, -5.4543],
        [-1.0527, -1.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20653624832630157
Epoch 0, Step 285: train/loss = 0.34645384550094604, train/raw-loss = 0.2503994405269623, train/logprobs = tensor([[-0.4338, -4.2734],
        [-0.7510, -0.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19210879504680634
Epoch 0, Step 286: train/loss = 0.4599674940109253, train/raw-loss = 0.34625136852264404, train/logprobs = tensor([[-0.5012, -3.1215],
        [-1.0087, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2274322360754013
Epoch 0, Step 287: train/loss = 0.3273210823535919, train/raw-loss = 0.22797223925590515, train/logprobs = tensor([[-0.5626, -6.1223],
        [-1.1252, -0.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19869771599769592
Epoch 0, Step 288: train/loss = 0.33389806747436523, train/raw-loss = 0.23106814920902252, train/logprobs = tensor([[-0.5008, -4.8577],
        [-1.1293, -0.5605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056598663330078
Epoch 0, Step 289: train/loss = 0.33911848068237305, train/raw-loss = 0.22150026261806488, train/logprobs = tensor([[-0.6695, -4.0515],
        [-1.4679, -0.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23523648083209991
Epoch 0, Step 290: train/loss = 0.3219166100025177, train/raw-loss = 0.22714434564113617, train/logprobs = tensor([[-0.5368, -4.2934],
        [-1.1370, -0.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18954452872276306
Epoch 0, Step 291: train/loss = 0.346648633480072, train/raw-loss = 0.25348347425460815, train/logprobs = tensor([[-0.4604, -5.9398],
        [-0.9213, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18633033335208893
Epoch 0, Step 292: train/loss = 0.2916821837425232, train/raw-loss = 0.1793764978647232, train/logprobs = tensor([[-0.5875, -3.8979],
        [-1.4375, -0.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2246113121509552
Epoch 0, Step 293: train/loss = 0.31801801919937134, train/raw-loss = 0.2232666164636612, train/logprobs = tensor([[-0.5845, -6.4458],
        [-0.9543, -0.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1895027458667755
Epoch 0, Step 294: train/loss = 0.3184494376182556, train/raw-loss = 0.22651764750480652, train/logprobs = tensor([[-0.4800, -5.5895],
        [-0.9090, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838635504245758
Epoch 0, Step 295: train/loss = 0.2816150188446045, train/raw-loss = 0.18480683863162994, train/logprobs = tensor([[-0.5233, -4.9705],
        [-1.2208, -0.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1936163753271103
Epoch 0, Step 296: train/loss = 0.33993735909461975, train/raw-loss = 0.2531461715698242, train/logprobs = tensor([[-0.3612, -4.4384],
        [-0.6901, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735823154449463
Epoch 0, Step 297: train/loss = 0.2747305929660797, train/raw-loss = 0.1759309619665146, train/logprobs = tensor([[-0.5539, -5.3877],
        [-1.3201, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19759927690029144
Epoch 0, Step 298: train/loss = 0.3294406533241272, train/raw-loss = 0.22671547532081604, train/logprobs = tensor([[-0.6849, -5.0410],
        [-1.3615, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054503858089447
Epoch 0, Step 299: train/loss = 0.3474847376346588, train/raw-loss = 0.2510835528373718, train/logprobs = tensor([[-0.4920, -3.9724],
        [-0.9493, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19280238449573517
Epoch 0, Step 300: train/loss = 0.33687329292297363, train/raw-loss = 0.23980949819087982, train/logprobs = tensor([[-0.4860, -4.1303],
        [-0.9471, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19412758946418762
Epoch 0, Step 301: train/loss = 0.3283482789993286, train/raw-loss = 0.223189577460289, train/logprobs = tensor([[-0.4702, -5.2776],
        [-1.0571, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210317462682724
Epoch 0, Step 302: train/loss = 0.3203953504562378, train/raw-loss = 0.23887687921524048, train/logprobs = tensor([[-0.3842, -4.3460],
        [-0.8100, -0.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16303689777851105
Epoch 0, Step 303: train/loss = 0.4268096089363098, train/raw-loss = 0.3449877202510834, train/logprobs = tensor([[-0.4837, -2.6888],
        [-0.7773, -0.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16364380717277527
Epoch 0, Step 304: train/loss = 0.2896898090839386, train/raw-loss = 0.1914682388305664, train/logprobs = tensor([[-0.5295, -5.2087],
        [-1.2305, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19644314050674438
Epoch 0, Step 305: train/loss = 0.34520941972732544, train/raw-loss = 0.24425339698791504, train/logprobs = tensor([[-0.5475, -4.9368],
        [-1.2790, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20191209018230438
Epoch 0, Step 306: train/loss = 0.3476030230522156, train/raw-loss = 0.24369436502456665, train/logprobs = tensor([[-0.4483, -3.7841],
        [-0.8674, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20781731605529785
Epoch 0, Step 307: train/loss = 0.2949374318122864, train/raw-loss = 0.1942969262599945, train/logprobs = tensor([[-0.5248, -6.0061],
        [-1.1505, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20128099620342255
Epoch 0, Step 308: train/loss = 0.3177523612976074, train/raw-loss = 0.21087034046649933, train/logprobs = tensor([[-0.4603, -5.1604],
        [-1.1135, -0.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21376405656337738
Epoch 0, Step 309: train/loss = 0.3324294090270996, train/raw-loss = 0.22548776865005493, train/logprobs = tensor([[-0.5899, -4.8643],
        [-1.1851, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21388331055641174
Epoch 0, Step 310: train/loss = 0.3469938337802887, train/raw-loss = 0.2511184811592102, train/logprobs = tensor([[-0.5184, -3.7015],
        [-1.1572, -0.3713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1917506605386734
Epoch 0, Step 311: train/loss = 0.27900630235671997, train/raw-loss = 0.17559146881103516, train/logprobs = tensor([[-0.6121, -5.6248],
        [-1.4552, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20682966709136963
Epoch 0, Step 312: train/loss = 0.334746778011322, train/raw-loss = 0.24375464022159576, train/logprobs = tensor([[-0.3905, -4.1248],
        [-0.8032, -0.5240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18198424577713013
Epoch 0, Step 313: train/loss = 0.30316361784935, train/raw-loss = 0.19238245487213135, train/logprobs = tensor([[-0.4871, -5.3873],
        [-1.1741, -0.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22156232595443726
Epoch 0, Step 314: train/loss = 0.32962462306022644, train/raw-loss = 0.23427994549274445, train/logprobs = tensor([[-0.4654, -3.5024],
        [-1.1597, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1906893402338028
Epoch 0, Step 315: train/loss = 0.3100513815879822, train/raw-loss = 0.20770300924777985, train/logprobs = tensor([[-0.4438, -5.5081],
        [-1.0733, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20469677448272705
Epoch 0, Step 316: train/loss = 0.30460119247436523, train/raw-loss = 0.20741263031959534, train/logprobs = tensor([[-0.5066, -4.7241],
        [-1.2493, -0.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943770945072174
Epoch 0, Step 317: train/loss = 0.2826796770095825, train/raw-loss = 0.18457749485969543, train/logprobs = tensor([[-0.5779, -5.5025],
        [-1.3050, -0.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19620437920093536
Epoch 0, Step 318: train/loss = 0.2854039967060089, train/raw-loss = 0.18228112161159515, train/logprobs = tensor([[-0.5723, -4.9490],
        [-1.3323, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20624575018882751
Epoch 0, Step 319: train/loss = 0.30506303906440735, train/raw-loss = 0.20657798647880554, train/logprobs = tensor([[-0.5096, -5.4911],
        [-1.0449, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1969701200723648
Epoch 0, Step 320: train/loss = 0.2882325053215027, train/raw-loss = 0.19496026635169983, train/logprobs = tensor([[-0.4332, -6.5273],
        [-1.0308, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18654441833496094
Epoch 0, Step 321: train/loss = 0.26682642102241516, train/raw-loss = 0.16494812071323395, train/logprobs = tensor([[-0.4960, -4.8372],
        [-1.4236, -0.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20375657081604004
Epoch 0, Step 322: train/loss = 0.31159746646881104, train/raw-loss = 0.22872862219810486, train/logprobs = tensor([[-0.4318, -4.0756],
        [-1.0136, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16573768854141235
Epoch 0, Step 323: train/loss = 0.29348912835121155, train/raw-loss = 0.19458472728729248, train/logprobs = tensor([[-0.5001, -4.9044],
        [-1.3000, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19780878722667694
Epoch 0, Step 324: train/loss = 0.2857743799686432, train/raw-loss = 0.19865994155406952, train/logprobs = tensor([[-0.5235, -6.1607],
        [-1.0656, -0.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17422881722450256
Epoch 0, Step 325: train/loss = 0.33842331171035767, train/raw-loss = 0.23573452234268188, train/logprobs = tensor([[-0.6117, -3.8826],
        [-1.3463, -0.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20537756383419037
Epoch 0, Step 326: train/loss = 0.2678125202655792, train/raw-loss = 0.16934062540531158, train/logprobs = tensor([[-0.4134, -6.9746],
        [-1.2680, -0.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19694377481937408
Epoch 0, Step 327: train/loss = 0.2977927327156067, train/raw-loss = 0.19398364424705505, train/logprobs = tensor([[-0.5440, -4.6022],
        [-1.2761, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20761817693710327
Epoch 0, Step 328: train/loss = 0.2581206262111664, train/raw-loss = 0.1494242548942566, train/logprobs = tensor([[-0.6904, -4.7750],
        [-1.7496, -0.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21739274263381958
Epoch 0, Step 329: train/loss = 0.27620893716812134, train/raw-loss = 0.17932313680648804, train/logprobs = tensor([[-0.5492, -4.8955],
        [-1.3181, -0.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19377164542675018
Epoch 0, Step 330: train/loss = 0.38413023948669434, train/raw-loss = 0.2941811978816986, train/logprobs = tensor([[-0.4326, -3.7053],
        [-0.9998, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17989808320999146
Epoch 0, Step 331: train/loss = 0.2676074802875519, train/raw-loss = 0.1622661054134369, train/logprobs = tensor([[-0.4843, -6.4067],
        [-1.4231, -0.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2106827199459076
Epoch 0, Step 332: train/loss = 0.2745099365711212, train/raw-loss = 0.1761273443698883, train/logprobs = tensor([[-0.4032, -5.0053],
        [-1.1711, -0.2329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19676515460014343
Epoch 0, Step 333: train/loss = 0.2677786946296692, train/raw-loss = 0.18821899592876434, train/logprobs = tensor([[-0.5288, -5.5357],
        [-1.3374, -0.6113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591193974018097
Epoch 0, Step 334: train/loss = 0.25879862904548645, train/raw-loss = 0.15881189703941345, train/logprobs = tensor([[-0.5009, -5.4625],
        [-1.4154, -0.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19997349381446838
Epoch 0, Step 335: train/loss = 0.2635965347290039, train/raw-loss = 0.15973243117332458, train/logprobs = tensor([[-0.5783, -5.1161],
        [-1.4728, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20772817730903625
Epoch 0, Step 336: train/loss = 0.3074449896812439, train/raw-loss = 0.2211020588874817, train/logprobs = tensor([[-0.3958, -4.8447],
        [-0.9067, -0.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17268586158752441
Epoch 0, Step 337: train/loss = 0.25195175409317017, train/raw-loss = 0.1548372209072113, train/logprobs = tensor([[-0.5879, -6.3719],
        [-1.4850, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1942290961742401
Epoch 0, Step 338: train/loss = 0.27922701835632324, train/raw-loss = 0.1907997876405716, train/logprobs = tensor([[-0.3718, -5.1331],
        [-1.0703, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1768544763326645
Epoch 0, Step 339: train/loss = 0.3284573554992676, train/raw-loss = 0.2368219494819641, train/logprobs = tensor([[-0.4524, -4.2931],
        [-0.8607, -0.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327075242996216
Epoch 0, Step 340: train/loss = 0.27981317043304443, train/raw-loss = 0.18090176582336426, train/logprobs = tensor([[-0.4499, -5.2509],
        [-1.2622, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19782280921936035
Epoch 0, Step 341: train/loss = 0.28622156381607056, train/raw-loss = 0.19036974012851715, train/logprobs = tensor([[-0.4628, -6.3317],
        [-1.1748, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1917036771774292
Epoch 0, Step 342: train/loss = 0.2860943078994751, train/raw-loss = 0.20313450694084167, train/logprobs = tensor([[-0.4882, -6.7292],
        [-1.0364, -0.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16591955721378326
Epoch 0, Step 343: train/loss = 0.2661146819591522, train/raw-loss = 0.1784965842962265, train/logprobs = tensor([[-0.5438, -7.4695],
        [-1.2646, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523621022701263
Epoch 0, Step 344: train/loss = 0.3081168532371521, train/raw-loss = 0.2143084704875946, train/logprobs = tensor([[-0.5058, -3.9646],
        [-1.2404, -0.4880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1876167505979538
Epoch 0, Step 345: train/loss = 0.28577786684036255, train/raw-loss = 0.19381554424762726, train/logprobs = tensor([[-0.5577, -4.5478],
        [-1.3898, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18392467498779297
Epoch 0, Step 346: train/loss = 0.29980188608169556, train/raw-loss = 0.21416732668876648, train/logprobs = tensor([[-0.4942, -5.8046],
        [-0.9732, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17126905918121338
Epoch 0, Step 347: train/loss = 0.3091033697128296, train/raw-loss = 0.20393739640712738, train/logprobs = tensor([[-0.5184, -5.2589],
        [-1.3442, -0.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21033188700675964
Epoch 0, Step 348: train/loss = 0.33172476291656494, train/raw-loss = 0.2383081614971161, train/logprobs = tensor([[-0.4050, -5.4943],
        [-0.8310, -1.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1868332028388977
Epoch 0, Step 349: train/loss = 0.3161276578903198, train/raw-loss = 0.22917726635932922, train/logprobs = tensor([[-0.3729, -3.9748],
        [-0.9265, -0.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1739008128643036
Epoch 0, Step 350: train/loss = 0.25861990451812744, train/raw-loss = 0.157144695520401, train/logprobs = tensor([[-0.4762, -6.3115],
        [-1.3821, -0.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20295041799545288
Epoch 0, Step 351: train/loss = 0.303297758102417, train/raw-loss = 0.21553918719291687, train/logprobs = tensor([[-0.4755, -4.2926],
        [-1.0278, -0.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17551709711551666
Epoch 0, Step 352: train/loss = 0.25473129749298096, train/raw-loss = 0.14970973134040833, train/logprobs = tensor([[-0.5148, -8.3986],
        [-1.4240, -0.4008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21004316210746765
Epoch 0, Step 353: train/loss = 0.27233782410621643, train/raw-loss = 0.1832250952720642, train/logprobs = tensor([[-0.4610, -6.4621],
        [-1.1079, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17822548747062683
Epoch 0, Step 354: train/loss = 0.2404879629611969, train/raw-loss = 0.15378956496715546, train/logprobs = tensor([[-0.7474, -7.1327],
        [-1.7750, -0.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17339681088924408
Epoch 0, Step 355: train/loss = 0.24019214510917664, train/raw-loss = 0.13263161480426788, train/logprobs = tensor([[-0.6242, -6.5317],
        [-1.7751, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151210606098175
Epoch 0, Step 356: train/loss = 0.29003170132637024, train/raw-loss = 0.20118246972560883, train/logprobs = tensor([[-0.4129, -7.3189],
        [-0.9559, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17769849300384521
Epoch 0, Step 357: train/loss = 0.29436632990837097, train/raw-loss = 0.2136024683713913, train/logprobs = tensor([[-0.4903, -5.3688],
        [-1.1579, -0.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16152776777744293
Epoch 0, Step 358: train/loss = 0.27966219186782837, train/raw-loss = 0.193388432264328, train/logprobs = tensor([[-0.6778, -8.1745],
        [-1.4129, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17254748940467834
Epoch 0, Step 359: train/loss = 0.27024319767951965, train/raw-loss = 0.17123785614967346, train/logprobs = tensor([[-0.5841, -5.8504],
        [-1.3740, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19801068305969238
Epoch 0, Step 360: train/loss = 0.28706538677215576, train/raw-loss = 0.19506601989269257, train/logprobs = tensor([[-0.4202, -5.7433],
        [-1.0421, -0.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18399879336357117
Epoch 0, Step 361: train/loss = 0.29700925946235657, train/raw-loss = 0.21265721321105957, train/logprobs = tensor([[-0.4200, -5.4050],
        [-1.1049, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1687040627002716
Epoch 0, Step 362: train/loss = 0.30037736892700195, train/raw-loss = 0.1984071135520935, train/logprobs = tensor([[-0.4759, -4.7229],
        [-1.1137, -0.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2039404958486557
Epoch 0, Step 363: train/loss = 0.3005891442298889, train/raw-loss = 0.20883332192897797, train/logprobs = tensor([[-0.4333, -5.2870],
        [-0.9671, -0.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1835116297006607
Epoch 0, Step 364: train/loss = 0.27546361088752747, train/raw-loss = 0.17318835854530334, train/logprobs = tensor([[-0.5677, -5.1073],
        [-1.5627, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20455047488212585
Epoch 0, Step 365: train/loss = 0.26756036281585693, train/raw-loss = 0.17784588038921356, train/logprobs = tensor([[-0.5315, -6.5367],
        [-1.2200, -0.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17942899465560913
Epoch 0, Step 366: train/loss = 0.2622530162334442, train/raw-loss = 0.17473572492599487, train/logprobs = tensor([[-0.4503, -8.2247],
        [-1.1427, -0.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17503458261489868
Epoch 0, Step 367: train/loss = 0.3095088005065918, train/raw-loss = 0.2135857790708542, train/logprobs = tensor([[-0.5260, -5.2111],
        [-1.2114, -0.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19184604287147522
Epoch 0, Step 368: train/loss = 0.3218368589878082, train/raw-loss = 0.24049869179725647, train/logprobs = tensor([[-0.4510, -5.7858],
        [-0.8803, -1.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626763641834259
Epoch 0, Step 369: train/loss = 0.3088243901729584, train/raw-loss = 0.2225196361541748, train/logprobs = tensor([[-0.3504, -5.1331],
        [-0.8918, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17260949313640594
Epoch 0, Step 370: train/loss = 0.25398188829421997, train/raw-loss = 0.15204709768295288, train/logprobs = tensor([[-0.5904, -5.0189],
        [-1.7430, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2038695514202118
Epoch 0, Step 371: train/loss = 0.3004623055458069, train/raw-loss = 0.2061246633529663, train/logprobs = tensor([[-0.4897, -5.4404],
        [-1.1289, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18867529928684235
Epoch 0, Step 372: train/loss = 0.2568460702896118, train/raw-loss = 0.1540064811706543, train/logprobs = tensor([[-0.5898, -5.8018],
        [-1.6568, -0.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20567917823791504
Epoch 0, Step 373: train/loss = 0.22784480452537537, train/raw-loss = 0.12926682829856873, train/logprobs = tensor([[-0.6534, -6.1552],
        [-1.8336, -0.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19715598225593567
Epoch 0, Step 374: train/loss = 0.2693060040473938, train/raw-loss = 0.17876411974430084, train/logprobs = tensor([[-0.4676, -7.0358],
        [-1.1344, -0.4457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18108375370502472
Epoch 0, Step 375: train/loss = 0.3012653589248657, train/raw-loss = 0.20530439913272858, train/logprobs = tensor([[-0.5042, -4.8306],
        [-1.0636, -0.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1919219195842743
Epoch 0, Step 376: train/loss = 0.28041207790374756, train/raw-loss = 0.19109372794628143, train/logprobs = tensor([[-0.6103, -5.5489],
        [-1.3362, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17863672971725464
Epoch 0, Step 377: train/loss = 0.2744333744049072, train/raw-loss = 0.18136592209339142, train/logprobs = tensor([[-0.4258, -5.7730],
        [-1.1567, -0.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18613487482070923
Epoch 0, Step 378: train/loss = 0.26941779255867004, train/raw-loss = 0.1760837286710739, train/logprobs = tensor([[-0.4134, -4.7224],
        [-1.2503, -0.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18666809797286987
Epoch 0, Step 379: train/loss = 0.2757633328437805, train/raw-loss = 0.18438339233398438, train/logprobs = tensor([[-0.4059, -8.3364],
        [-1.0335, -0.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18275988101959229
Epoch 0, Step 380: train/loss = 0.292653888463974, train/raw-loss = 0.18586067855358124, train/logprobs = tensor([[-0.4566, -4.4191],
        [-1.5405, -0.4297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21358640491962433
Epoch 0, Step 381: train/loss = 0.29096144437789917, train/raw-loss = 0.2115587592124939, train/logprobs = tensor([[-0.4754, -5.1485],
        [-0.9970, -0.7823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15880534052848816
Epoch 0, Step 382: train/loss = 0.3137100636959076, train/raw-loss = 0.22096262872219086, train/logprobs = tensor([[-0.4464, -6.4892],
        [-0.9548, -0.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18549488484859467
Epoch 0, Step 383: train/loss = 0.2784528136253357, train/raw-loss = 0.18156743049621582, train/logprobs = tensor([[-0.5506, -5.5612],
        [-1.3445, -0.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19377076625823975
Epoch 0, Step 384: train/loss = 0.2402064949274063, train/raw-loss = 0.13346153497695923, train/logprobs = tensor([[-0.5243, -5.9228],
        [-1.6655, -0.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21348994970321655
Epoch 0, Step 385: train/loss = 0.2618149220943451, train/raw-loss = 0.17574679851531982, train/logprobs = tensor([[-0.3815, -7.1429],
        [-1.1736, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17213624715805054
Epoch 0, Step 386: train/loss = 0.25115764141082764, train/raw-loss = 0.1533530205488205, train/logprobs = tensor([[-0.4797, -7.6560],
        [-1.3598, -0.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19560924172401428
Epoch 0, Step 387: train/loss = 0.2697198688983917, train/raw-loss = 0.1681707203388214, train/logprobs = tensor([[-0.4807, -5.9036],
        [-1.2990, -0.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20309825241565704
Epoch 0, Step 388: train/loss = 0.2542944848537445, train/raw-loss = 0.1680838167667389, train/logprobs = tensor([[-0.4911, -6.5053],
        [-1.4566, -0.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17242135107517242
Epoch 0, Step 389: train/loss = 0.2539860010147095, train/raw-loss = 0.15261945128440857, train/logprobs = tensor([[-0.4095, -5.5645],
        [-1.3943, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2027330845594406
Epoch 0, Step 390: train/loss = 0.2996232211589813, train/raw-loss = 0.21403810381889343, train/logprobs = tensor([[-0.4670, -4.9611],
        [-1.0699, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1711702197790146
Epoch 0, Step 391: train/loss = 0.25970056653022766, train/raw-loss = 0.15655213594436646, train/logprobs = tensor([[-0.5639, -7.5870],
        [-1.4241, -0.4829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2062968611717224
Epoch 0, Step 392: train/loss = 0.25386756658554077, train/raw-loss = 0.15547795593738556, train/logprobs = tensor([[-0.5053, -6.5159],
        [-1.3825, -0.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19677919149398804
Epoch 0, Step 393: train/loss = 0.24862806499004364, train/raw-loss = 0.15842881798744202, train/logprobs = tensor([[-0.5040, -5.1560],
        [-1.4372, -0.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18039849400520325
Epoch 0, Step 394: train/loss = 0.27769696712493896, train/raw-loss = 0.19531767070293427, train/logprobs = tensor([[-0.6376, -5.6014],
        [-1.2671, -1.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.164758563041687
Epoch 0, Step 395: train/loss = 0.2568710148334503, train/raw-loss = 0.14811721444129944, train/logprobs = tensor([[-0.5894, -5.5382],
        [-1.6325, -0.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21750760078430176
Epoch 0, Step 396: train/loss = 0.3130132257938385, train/raw-loss = 0.21524690091609955, train/logprobs = tensor([[-0.5682, -3.7590],
        [-1.4453, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19553261995315552
Epoch 0, Step 397: train/loss = 0.26186904311180115, train/raw-loss = 0.1649121344089508, train/logprobs = tensor([[-0.5634, -5.8665],
        [-1.4967, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19391381740570068
Epoch 0, Step 398: train/loss = 0.27252650260925293, train/raw-loss = 0.17012116312980652, train/logprobs = tensor([[-0.4681, -6.6757],
        [-1.2563, -0.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20481067895889282
Epoch 0, Step 399: train/loss = 0.23720939457416534, train/raw-loss = 0.1394287347793579, train/logprobs = tensor([[-0.5892, -6.3700],
        [-1.6239, -0.4065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19556131958961487
Epoch 0, Step 400: train/loss = 0.27639755606651306, train/raw-loss = 0.20123958587646484, train/logprobs = tensor([[-0.4402, -6.2328],
        [-0.9758, -0.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15031594038009644
Epoch 0, Step 401: train/loss = 0.2822652757167816, train/raw-loss = 0.18157488107681274, train/logprobs = tensor([[-0.5340, -4.8152],
        [-1.3682, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20138081908226013
Epoch 0, Step 402: train/loss = 0.28398311138153076, train/raw-loss = 0.1989496648311615, train/logprobs = tensor([[-0.4324, -5.8965],
        [-1.1295, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700669527053833
Epoch 0, Step 403: train/loss = 0.3026160001754761, train/raw-loss = 0.22178024053573608, train/logprobs = tensor([[-0.2987, -6.3641],
        [-0.6760, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616715043783188
Epoch 0, Step 404: train/loss = 0.2734784781932831, train/raw-loss = 0.191409170627594, train/logprobs = tensor([[-0.4308, -5.8433],
        [-1.1163, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16413864493370056
Epoch 0, Step 405: train/loss = 0.2499617040157318, train/raw-loss = 0.1573837846517563, train/logprobs = tensor([[-0.4439, -8.0567],
        [-1.3453, -0.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18515585362911224
Epoch 0, Step 406: train/loss = 0.3509317636489868, train/raw-loss = 0.2741212844848633, train/logprobs = tensor([[-0.3429, -5.1127],
        [-0.7118, -0.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15362095832824707
Epoch 0, Step 407: train/loss = 0.23454785346984863, train/raw-loss = 0.14318159222602844, train/logprobs = tensor([[-0.4864, -6.9554],
        [-1.5159, -0.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18273252248764038
Epoch 0, Step 408: train/loss = 0.2846393287181854, train/raw-loss = 0.17739421129226685, train/logprobs = tensor([[-0.5308, -4.4322],
        [-1.3755, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21449021995067596
Epoch 0, Step 409: train/loss = 0.3192943334579468, train/raw-loss = 0.21145550906658173, train/logprobs = tensor([[-0.7475, -4.3002],
        [-1.9540, -0.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156776487827301
Epoch 0, Step 410: train/loss = 0.2605750560760498, train/raw-loss = 0.17790472507476807, train/logprobs = tensor([[-0.4491, -8.6227],
        [-1.1873, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16534069180488586
Epoch 0, Step 411: train/loss = 0.23758842051029205, train/raw-loss = 0.14142192900180817, train/logprobs = tensor([[-0.4712, -6.6866],
        [-1.5181, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19233298301696777
Epoch 0, Step 412: train/loss = 0.26891806721687317, train/raw-loss = 0.17791882157325745, train/logprobs = tensor([[-0.4247, -5.0420],
        [-1.1909, -0.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18199850618839264
Epoch 0, Step 413: train/loss = 0.27613312005996704, train/raw-loss = 0.18329261243343353, train/logprobs = tensor([[-0.4168, -5.4455],
        [-1.0717, -0.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1856810748577118
Epoch 0, Step 414: train/loss = 0.26102399826049805, train/raw-loss = 0.17396321892738342, train/logprobs = tensor([[-0.6306, -6.8919],
        [-1.5333, -0.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17412158846855164
Epoch 0, Step 415: train/loss = 0.23544108867645264, train/raw-loss = 0.12966494262218475, train/logprobs = tensor([[-0.4911, -6.2031],
        [-1.6965, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21155229210853577
Epoch 0, Step 416: train/loss = 0.28289711475372314, train/raw-loss = 0.20579786598682404, train/logprobs = tensor([[-0.4059, -5.5917],
        [-0.9762, -0.3433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15419846773147583
Epoch 0, Step 417: train/loss = 0.26526206731796265, train/raw-loss = 0.1718301773071289, train/logprobs = tensor([[-0.4588, -6.8962],
        [-1.2155, -0.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18686379492282867
Epoch 0, Step 418: train/loss = 0.2748746871948242, train/raw-loss = 0.19112685322761536, train/logprobs = tensor([[-0.4578, -5.5376],
        [-1.1854, -0.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16749563813209534
Epoch 0, Step 419: train/loss = 0.25615832209587097, train/raw-loss = 0.1661662608385086, train/logprobs = tensor([[-0.4243, -6.4513],
        [-1.2438, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17998415231704712
Epoch 0, Step 420: train/loss = 0.2792297303676605, train/raw-loss = 0.18357506394386292, train/logprobs = tensor([[-0.4690, -5.6249],
        [-1.2802, -0.5930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1913093477487564
Epoch 0, Step 421: train/loss = 0.285122275352478, train/raw-loss = 0.2105918526649475, train/logprobs = tensor([[-0.3865, -5.6558],
        [-0.8495, -0.3940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14906086027622223
Epoch 0, Step 422: train/loss = 0.23603761196136475, train/raw-loss = 0.13221508264541626, train/logprobs = tensor([[-0.4418, -8.4085],
        [-1.5372, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20764504373073578
Epoch 0, Step 423: train/loss = 0.25962120294570923, train/raw-loss = 0.15600398182868958, train/logprobs = tensor([[-0.5043, -6.0200],
        [-1.4395, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2072344422340393
Epoch 0, Step 424: train/loss = 0.24644693732261658, train/raw-loss = 0.15198077261447906, train/logprobs = tensor([[-0.5390, -7.7513],
        [-1.5241, -0.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18893232941627502
Epoch 0, Step 425: train/loss = 0.2219429314136505, train/raw-loss = 0.11555426567792892, train/logprobs = tensor([[-0.4838, -6.3816],
        [-1.7969, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21277731657028198
Epoch 0, Step 426: train/loss = 0.2762809097766876, train/raw-loss = 0.1946232169866562, train/logprobs = tensor([[-0.3292, -7.6787],
        [-0.8900, -0.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16331537067890167
Epoch 0, Step 427: train/loss = 0.2624022364616394, train/raw-loss = 0.1658407747745514, train/logprobs = tensor([[-0.4849, -6.2785],
        [-1.4089, -0.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19312293827533722
Epoch 0, Step 428: train/loss = 0.2765185832977295, train/raw-loss = 0.18890799582004547, train/logprobs = tensor([[-0.4607, -5.8228],
        [-1.1694, -0.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17522123456001282
Epoch 0, Step 429: train/loss = 0.279483824968338, train/raw-loss = 0.18595804274082184, train/logprobs = tensor([[-0.3705, -6.2927],
        [-1.1791, -0.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18705156445503235
Epoch 0, Step 430: train/loss = 0.282539039850235, train/raw-loss = 0.20587068796157837, train/logprobs = tensor([[-0.4086, -5.6404],
        [-0.9325, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15333664417266846
Epoch 0, Step 431: train/loss = 0.27256786823272705, train/raw-loss = 0.18738064169883728, train/logprobs = tensor([[-0.4481, -6.1655],
        [-1.1026, -0.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17037446796894073
Epoch 0, Step 432: train/loss = 0.2823895812034607, train/raw-loss = 0.1854846328496933, train/logprobs = tensor([[-0.4631, -4.3153],
        [-1.3386, -0.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1938098818063736
Epoch 0, Step 433: train/loss = 0.24312123656272888, train/raw-loss = 0.13515326380729675, train/logprobs = tensor([[-0.5687, -7.0043],
        [-1.6695, -0.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21593593060970306
Epoch 0, Step 434: train/loss = 0.26271745562553406, train/raw-loss = 0.1543949842453003, train/logprobs = tensor([[-0.4682, -5.3971],
        [-1.4531, -0.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21664497256278992
Epoch 0, Step 435: train/loss = 0.2670004963874817, train/raw-loss = 0.1860799789428711, train/logprobs = tensor([[-0.4519, -9.8235],
        [-1.1003, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16184106469154358
Epoch 0, Step 436: train/loss = 0.2489832639694214, train/raw-loss = 0.15251578390598297, train/logprobs = tensor([[-0.4659, -6.5086],
        [-1.4089, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19293498992919922
Epoch 0, Step 437: train/loss = 0.24673083424568176, train/raw-loss = 0.1539488434791565, train/logprobs = tensor([[-0.5361, -6.4377],
        [-1.4837, -0.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18556398153305054
Epoch 0, Step 438: train/loss = 0.25364238023757935, train/raw-loss = 0.1637987196445465, train/logprobs = tensor([[-0.4067, -8.6670],
        [-1.1898, -0.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17968736588954926
Epoch 0, Step 439: train/loss = 0.23490385711193085, train/raw-loss = 0.13927656412124634, train/logprobs = tensor([[ -0.6320, -10.2514],
        [ -1.7625,  -0.5756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19125455617904663
Epoch 0, Step 440: train/loss = 0.2671931982040405, train/raw-loss = 0.1763068437576294, train/logprobs = tensor([[-0.4365, -5.8212],
        [-1.1937, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18177269399166107
Epoch 0, Step 441: train/loss = 0.2377893626689911, train/raw-loss = 0.14175093173980713, train/logprobs = tensor([[-0.4688, -7.4109],
        [-1.5145, -0.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19207684695720673
Epoch 0, Step 442: train/loss = 0.23881515860557556, train/raw-loss = 0.14095447957515717, train/logprobs = tensor([[-0.4945, -6.8662],
        [-1.4891, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572138786315918
Epoch 0, Step 443: train/loss = 0.2744348645210266, train/raw-loss = 0.18267470598220825, train/logprobs = tensor([[-0.4234, -8.0483],
        [-1.0526, -0.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1835203468799591
Epoch 0, Step 444: train/loss = 0.25703173875808716, train/raw-loss = 0.16452927887439728, train/logprobs = tensor([[-0.4632, -6.7146],
        [-1.2649, -0.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18500488996505737
Epoch 0, Step 445: train/loss = 0.24336391687393188, train/raw-loss = 0.15558114647865295, train/logprobs = tensor([[-0.5518, -6.3474],
        [-1.6368, -0.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17556551098823547
Epoch 0, Step 446: train/loss = 0.26316773891448975, train/raw-loss = 0.1827705204486847, train/logprobs = tensor([[-0.4403, -6.0743],
        [-1.1420, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1607944518327713
Epoch 0, Step 447: train/loss = 0.2534271478652954, train/raw-loss = 0.14155161380767822, train/logprobs = tensor([[-0.4815, -6.7340],
        [-1.5036, -0.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22375106811523438
Epoch 0, Step 448: train/loss = 0.2451186329126358, train/raw-loss = 0.13946577906608582, train/logprobs = tensor([[-0.4536, -8.2319],
        [-1.4937, -0.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21130572259426117
Epoch 0, Step 449: train/loss = 0.21513313055038452, train/raw-loss = 0.11089754104614258, train/logprobs = tensor([[-0.4823, -6.8244],
        [-1.7921, -0.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2084711790084839
Epoch 0, Step 450: train/loss = 0.25712674856185913, train/raw-loss = 0.13863089680671692, train/logprobs = tensor([[-0.4148, -6.6960],
        [-1.4413, -0.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2369917333126068
Epoch 0, Step 451: train/loss = 0.27781033515930176, train/raw-loss = 0.1788724958896637, train/logprobs = tensor([[-0.3463, -7.0168],
        [-1.0355, -0.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1978757083415985
Epoch 0, Step 452: train/loss = 0.2491113543510437, train/raw-loss = 0.16698318719863892, train/logprobs = tensor([[-0.4222, -9.5997],
        [-1.1863, -0.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16425634920597076
Epoch 0, Step 453: train/loss = 0.21960508823394775, train/raw-loss = 0.12331868708133698, train/logprobs = tensor([[-0.4306, -7.5948],
        [-1.5920, -0.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19257280230522156
Epoch 0, Step 454: train/loss = 0.22761641442775726, train/raw-loss = 0.11860402673482895, train/logprobs = tensor([[-0.5448, -8.1043],
        [-1.8523, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21802477538585663
Epoch 0, Step 455: train/loss = 0.24509373307228088, train/raw-loss = 0.1495031863451004, train/logprobs = tensor([[-0.5173, -5.9460],
        [-1.8309, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19118110835552216
Epoch 0, Step 456: train/loss = 0.25365960597991943, train/raw-loss = 0.155095636844635, train/logprobs = tensor([[-0.4321, -5.9222],
        [-1.4020, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19712792336940765
Epoch 0, Step 457: train/loss = 0.24821960926055908, train/raw-loss = 0.1478540301322937, train/logprobs = tensor([[-0.4937, -6.0877],
        [-1.5606, -0.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20073118805885315
Epoch 0, Step 458: train/loss = 0.24022400379180908, train/raw-loss = 0.1374741941690445, train/logprobs = tensor([[-0.6113, -8.1705],
        [-1.7671, -0.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20549964904785156
Epoch 0, Step 459: train/loss = 0.2560110092163086, train/raw-loss = 0.15165665745735168, train/logprobs = tensor([[-0.4416, -7.0636],
        [-1.3593, -0.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20870870351791382
Epoch 0, Step 460: train/loss = 0.26315057277679443, train/raw-loss = 0.16231629252433777, train/logprobs = tensor([[-0.4277, -8.1984],
        [-1.2579, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20166853070259094
Epoch 0, Step 461: train/loss = 0.27384281158447266, train/raw-loss = 0.19082680344581604, train/logprobs = tensor([[-0.5546, -6.9826],
        [-1.2002, -0.4964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16603200137615204
Epoch 0, Step 462: train/loss = 0.24173995852470398, train/raw-loss = 0.1543433517217636, train/logprobs = tensor([[-0.5621, -6.1566],
        [-1.5052, -0.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17479321360588074
Epoch 0, Step 463: train/loss = 0.2788194417953491, train/raw-loss = 0.17881983518600464, train/logprobs = tensor([[-0.4093, -8.2531],
        [-1.0697, -0.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19999921321868896
Epoch 0, Step 464: train/loss = 0.28458598256111145, train/raw-loss = 0.19089898467063904, train/logprobs = tensor([[-0.4003, -4.9134],
        [-1.2304, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18737399578094482
Epoch 0, Step 465: train/loss = 0.2449815273284912, train/raw-loss = 0.16242171823978424, train/logprobs = tensor([[-0.5602, -7.2459],
        [-1.5128, -1.1835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16511958837509155
Epoch 0, Step 466: train/loss = 0.24466967582702637, train/raw-loss = 0.13589301705360413, train/logprobs = tensor([[-0.5662, -4.9378],
        [-1.7593, -0.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21755333244800568
Epoch 0, Step 467: train/loss = 0.24953435361385345, train/raw-loss = 0.15490831434726715, train/logprobs = tensor([[-0.5125, -7.6164],
        [-1.4368, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1892520785331726
Epoch 0, Step 468: train/loss = 0.27626219391822815, train/raw-loss = 0.18639090657234192, train/logprobs = tensor([[-0.4177, -5.4541],
        [-1.2005, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17974255979061127
Epoch 0, Step 469: train/loss = 0.28660064935684204, train/raw-loss = 0.2019607126712799, train/logprobs = tensor([[-0.5871, -7.4312],
        [-1.1452, -0.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16927985846996307
Epoch 0, Step 470: train/loss = 0.24522046744823456, train/raw-loss = 0.13759095966815948, train/logprobs = tensor([[ -0.4253, -10.4377],
        [ -1.4775,  -0.6293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21525901556015015
Epoch 0, Step 471: train/loss = 0.253679096698761, train/raw-loss = 0.13731198012828827, train/logprobs = tensor([[-0.4061, -7.6829],
        [-1.4672, -0.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23273427784442902
Epoch 0, Step 472: train/loss = 0.24972966313362122, train/raw-loss = 0.15763939917087555, train/logprobs = tensor([[-0.4140, -6.4945],
        [-1.3101, -0.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18418052792549133
Epoch 0, Step 473: train/loss = 0.29576048254966736, train/raw-loss = 0.19593754410743713, train/logprobs = tensor([[-0.3157, -8.0965],
        [-0.8593, -0.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19964584708213806
Epoch 0, Step 474: train/loss = 0.22222009301185608, train/raw-loss = 0.11684686690568924, train/logprobs = tensor([[-0.4927, -6.9263],
        [-1.7990, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21074648201465607
Epoch 0, Step 475: train/loss = 0.31233811378479004, train/raw-loss = 0.21583227813243866, train/logprobs = tensor([[-0.3489, -5.9195],
        [-0.7767, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19301164150238037
Epoch 0, Step 476: train/loss = 0.25452691316604614, train/raw-loss = 0.14957059919834137, train/logprobs = tensor([[-0.4819, -8.1277],
        [-1.4503, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20991258323192596
Epoch 0, Step 477: train/loss = 0.277404248714447, train/raw-loss = 0.17319609224796295, train/logprobs = tensor([[-0.5238, -5.7523],
        [-1.5828, -0.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20841632783412933
Epoch 0, Step 478: train/loss = 0.26120373606681824, train/raw-loss = 0.16228677332401276, train/logprobs = tensor([[-0.4349, -5.9882],
        [-1.2966, -0.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19783395528793335
Epoch 0, Step 479: train/loss = 0.2305244505405426, train/raw-loss = 0.12250001728534698, train/logprobs = tensor([[-0.4964, -8.0009],
        [-1.6717, -0.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21604889631271362
Epoch 0, Step 480: train/loss = 0.3082377314567566, train/raw-loss = 0.22296613454818726, train/logprobs = tensor([[-0.3982, -4.6045],
        [-0.8549, -0.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17054319381713867
Epoch 0, Step 481: train/loss = 0.29270440340042114, train/raw-loss = 0.19315645098686218, train/logprobs = tensor([[-0.4163, -4.3252],
        [-1.3850, -0.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1990959197282791
Epoch 0, Step 482: train/loss = 0.24680966138839722, train/raw-loss = 0.15488409996032715, train/logprobs = tensor([[-0.4385, -6.5857],
        [-1.7277, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18385112285614014
Epoch 0, Step 483: train/loss = 0.2874479293823242, train/raw-loss = 0.2101055383682251, train/logprobs = tensor([[-0.3749, -8.4052],
        [-0.8464, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15468481183052063
Epoch 0, Step 484: train/loss = 0.2522585690021515, train/raw-loss = 0.13932858407497406, train/logprobs = tensor([[-0.4194, -6.8407],
        [-1.4679, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22585992515087128
Epoch 0, Step 485: train/loss = 0.23608645796775818, train/raw-loss = 0.13474255800247192, train/logprobs = tensor([[-0.4046, -8.1962],
        [-1.5443, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2026878297328949
Epoch 0, Step 486: train/loss = 0.24315351247787476, train/raw-loss = 0.15001624822616577, train/logprobs = tensor([[-0.4234, -7.9558],
        [-1.3316, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627451360225677
Epoch 0, Step 487: train/loss = 0.2530568540096283, train/raw-loss = 0.16520895063877106, train/logprobs = tensor([[-0.3228, -6.8153],
        [-1.1405, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756957620382309
Epoch 0, Step 488: train/loss = 0.2575680911540985, train/raw-loss = 0.14400479197502136, train/logprobs = tensor([[-0.4014, -5.2698],
        [-1.4443, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2271265685558319
Epoch 0, Step 489: train/loss = 0.2616484761238098, train/raw-loss = 0.1579042226076126, train/logprobs = tensor([[-0.4015, -7.6326],
        [-1.3060, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2074885219335556
Epoch 0, Step 490: train/loss = 0.2478589117527008, train/raw-loss = 0.1583293378353119, train/logprobs = tensor([[-0.4997, -5.5778],
        [-1.4013, -0.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17905916273593903
Epoch 0, Step 491: train/loss = 0.21296030282974243, train/raw-loss = 0.11677210032939911, train/logprobs = tensor([[-0.5699, -9.4334],
        [-1.9866, -0.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19237640500068665
Epoch 0, Step 492: train/loss = 0.23247213661670685, train/raw-loss = 0.11260578036308289, train/logprobs = tensor([[-0.4476, -7.9956],
        [-1.7286, -0.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23973271250724792
Epoch 0, Step 493: train/loss = 0.2832961678504944, train/raw-loss = 0.1905984729528427, train/logprobs = tensor([[-0.3316, -8.0022],
        [-0.9983, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18539540469646454
Epoch 0, Step 494: train/loss = 0.23011866211891174, train/raw-loss = 0.1055532842874527, train/logprobs = tensor([[-0.4705, -5.7881],
        [-1.9694, -0.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24913078546524048
Epoch 0, Step 495: train/loss = 0.2645096480846405, train/raw-loss = 0.16815480589866638, train/logprobs = tensor([[-0.3913, -8.4176],
        [-1.1565, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19270968437194824
Epoch 0, Step 496: train/loss = 0.2675844430923462, train/raw-loss = 0.15479247272014618, train/logprobs = tensor([[-0.4168, -8.9657],
        [-1.3427, -0.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22558391094207764
Epoch 0, Step 497: train/loss = 0.24992437660694122, train/raw-loss = 0.13683022558689117, train/logprobs = tensor([[-0.4048, -8.4635],
        [-1.5532, -1.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2261883020401001
Epoch 0, Step 498: train/loss = 0.231782466173172, train/raw-loss = 0.11504342406988144, train/logprobs = tensor([[-0.5120, -7.2151],
        [-1.8980, -0.3851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23347808420658112
Epoch 0, Step 499: train/loss = 0.2326774150133133, train/raw-loss = 0.12291038036346436, train/logprobs = tensor([[-0.4384, -7.0812],
        [-1.6809, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21953408420085907
Epoch 0, Step 500: train/loss = 0.23280590772628784, train/raw-loss = 0.12462570518255234, train/logprobs = tensor([[-0.4167, -7.0135],
        [-1.7339, -0.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21636039018630981
Epoch 0, Step 501: train/loss = 0.2806868553161621, train/raw-loss = 0.1798892617225647, train/logprobs = tensor([[-0.3346, -7.9491],
        [-0.9919, -0.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20159515738487244
Epoch 0, Step 502: train/loss = 0.28343063592910767, train/raw-loss = 0.18291276693344116, train/logprobs = tensor([[-0.3637, -7.4121],
        [-1.0027, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.201035737991333
Epoch 0, Step 503: train/loss = 0.27512580156326294, train/raw-loss = 0.17590390145778656, train/logprobs = tensor([[-0.4291, -7.2155],
        [-1.3639, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19844381511211395
Epoch 0, Step 504: train/loss = 0.25853389501571655, train/raw-loss = 0.1509532630443573, train/logprobs = tensor([[-0.4100, -5.2138],
        [-1.4543, -0.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21516132354736328
Epoch 0, Step 505: train/loss = 0.2263406217098236, train/raw-loss = 0.10486574470996857, train/logprobs = tensor([[-0.4435, -7.6978],
        [-1.9816, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24294975399971008
Epoch 0, Step 506: train/loss = 0.22217392921447754, train/raw-loss = 0.11892002075910568, train/logprobs = tensor([[-0.4397, -7.6175],
        [-1.7114, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2065078318119049
Epoch 0, Step 507: train/loss = 0.24995490908622742, train/raw-loss = 0.13906769454479218, train/logprobs = tensor([[-0.4064, -8.0751],
        [-1.5780, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22177442908287048
Epoch 0, Step 508: train/loss = 0.25484272837638855, train/raw-loss = 0.14652737975120544, train/logprobs = tensor([[-0.5600, -6.6065],
        [-1.6352, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2166307270526886
Epoch 0, Step 509: train/loss = 0.22916632890701294, train/raw-loss = 0.13297231495380402, train/logprobs = tensor([[-0.4693, -6.0669],
        [-1.6189, -0.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19238796830177307
Epoch 0, Step 510: train/loss = 0.24803538620471954, train/raw-loss = 0.15337896347045898, train/logprobs = tensor([[-0.3574, -8.4120],
        [-1.2559, -0.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1893128603696823
Epoch 0, Step 511: train/loss = 0.26026397943496704, train/raw-loss = 0.15286785364151, train/logprobs = tensor([[-0.4133, -6.7160],
        [-1.4264, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2147921919822693
Epoch 0, Step 512: train/loss = 0.2280094027519226, train/raw-loss = 0.10402394831180573, train/logprobs = tensor([[-0.4572, -7.0841],
        [-1.9768, -0.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24797095358371735
Epoch 0, Step 513: train/loss = 0.2511410713195801, train/raw-loss = 0.1536843478679657, train/logprobs = tensor([[-0.3437, -7.6300],
        [-1.2675, -0.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19491343200206757
Epoch 0, Step 514: train/loss = 0.2520650327205658, train/raw-loss = 0.14880028367042542, train/logprobs = tensor([[-0.3516, -7.9312],
        [-1.4264, -0.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20652949810028076
Epoch 0, Step 515: train/loss = 0.26941853761672974, train/raw-loss = 0.15362319350242615, train/logprobs = tensor([[-0.4063, -6.7604],
        [-1.4684, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23159068822860718
Epoch 0, Step 516: train/loss = 0.20580756664276123, train/raw-loss = 0.07677749544382095, train/logprobs = tensor([[-0.5050, -6.6315],
        [-2.3457, -0.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25806015729904175
Epoch 0, Step 517: train/loss = 0.2362183928489685, train/raw-loss = 0.1070670485496521, train/logprobs = tensor([[-0.4442, -6.9018],
        [-1.8594, -0.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583026885986328
Epoch 0, Step 518: train/loss = 0.24750015139579773, train/raw-loss = 0.16640987992286682, train/logprobs = tensor([[-0.4405, -6.5485],
        [-1.2420, -0.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16218052804470062
Epoch 0, Step 519: train/loss = 0.23469027876853943, train/raw-loss = 0.13459555804729462, train/logprobs = tensor([[-0.3681, -7.1949],
        [-1.4948, -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20018941164016724
Epoch 0, Step 520: train/loss = 0.22174161672592163, train/raw-loss = 0.14112134277820587, train/logprobs = tensor([[-0.4721, -6.2810],
        [-1.5917, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612405627965927
Epoch 0, Step 521: train/loss = 0.26594293117523193, train/raw-loss = 0.16655248403549194, train/logprobs = tensor([[-0.4546, -6.7444],
        [-1.3229, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1987808644771576
Epoch 0, Step 522: train/loss = 0.24832583963871002, train/raw-loss = 0.14160668849945068, train/logprobs = tensor([[-0.3590, -7.4771],
        [-1.4408, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21343831717967987
Epoch 0, Step 523: train/loss = 0.2383095622062683, train/raw-loss = 0.14551562070846558, train/logprobs = tensor([[-0.3276, -5.8680],
        [-1.4362, -0.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18558789789676666
Epoch 0, Step 524: train/loss = 0.27705538272857666, train/raw-loss = 0.16870450973510742, train/logprobs = tensor([[-0.3343, -5.7826],
        [-1.2040, -0.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21670173108577728
Epoch 0, Step 525: train/loss = 0.21959030628204346, train/raw-loss = 0.09170186519622803, train/logprobs = tensor([[-0.4932, -7.5684],
        [-2.1548, -0.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25577688217163086
Epoch 0, Step 526: train/loss = 0.23083016276359558, train/raw-loss = 0.12538421154022217, train/logprobs = tensor([[-0.3950, -9.0096],
        [-1.6069, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21089185774326324
Epoch 0, Step 527: train/loss = 0.25077110528945923, train/raw-loss = 0.1342117041349411, train/logprobs = tensor([[-0.4810, -5.9299],
        [-1.7605, -0.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23311880230903625
Epoch 0, Step 528: train/loss = 0.22637030482292175, train/raw-loss = 0.12340664863586426, train/logprobs = tensor([[-0.4463, -7.3765],
        [-1.6616, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.205927312374115
Epoch 0, Step 529: train/loss = 0.27430859208106995, train/raw-loss = 0.16979479789733887, train/logprobs = tensor([[-0.3616, -5.0453],
        [-1.2077, -0.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20902761816978455
Epoch 0, Step 530: train/loss = 0.2697508931159973, train/raw-loss = 0.17356081306934357, train/logprobs = tensor([[-0.3924, -5.6884],
        [-1.2075, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1923801302909851
Epoch 0, Step 531: train/loss = 0.21570371091365814, train/raw-loss = 0.09792495518922806, train/logprobs = tensor([[-0.4552, -9.2620],
        [-1.9380, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23555749654769897
Epoch 0, Step 532: train/loss = 0.26240241527557373, train/raw-loss = 0.14139655232429504, train/logprobs = tensor([[-0.4497, -7.4492],
        [-1.4932, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24201174080371857
Epoch 0, Step 533: train/loss = 0.2354421466588974, train/raw-loss = 0.11071443557739258, train/logprobs = tensor([[-0.4939, -6.5123],
        [-2.0325, -0.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24945545196533203
Epoch 0, Step 534: train/loss = 0.24855494499206543, train/raw-loss = 0.14724771678447723, train/logprobs = tensor([[-0.5020, -5.4020],
        [-1.8364, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20261448621749878
Epoch 0, Step 535: train/loss = 0.23876845836639404, train/raw-loss = 0.12978124618530273, train/logprobs = tensor([[-0.4626, -6.0158],
        [-1.7386, -0.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.217974454164505
Epoch 0, Step 536: train/loss = 0.22400005161762238, train/raw-loss = 0.10938668996095657, train/logprobs = tensor([[-0.4478, -8.3499],
        [-1.8905, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2292267233133316
Epoch 0, Step 537: train/loss = 0.24963219463825226, train/raw-loss = 0.12150150537490845, train/logprobs = tensor([[-0.4285, -7.0397],
        [-1.6657, -0.3748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562613785266876
Epoch 0, Step 538: train/loss = 0.24945445358753204, train/raw-loss = 0.13419272005558014, train/logprobs = tensor([[-0.4496, -7.3427],
        [-1.5371, -0.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23052343726158142
Epoch 0, Step 539: train/loss = 0.2724159359931946, train/raw-loss = 0.1792624592781067, train/logprobs = tensor([[-0.3774, -5.8584],
        [-1.1893, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18630702793598175
Epoch 0, Step 540: train/loss = 0.23401205241680145, train/raw-loss = 0.12155020236968994, train/logprobs = tensor([[-0.4427, -7.0389],
        [-1.7457, -0.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22492367029190063
Epoch 0, Step 541: train/loss = 0.185432568192482, train/raw-loss = 0.10053285211324692, train/logprobs = tensor([[-0.6721, -5.4664],
        [-2.6501, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16979941725730896
Epoch 0, Step 542: train/loss = 0.25604259967803955, train/raw-loss = 0.14450301229953766, train/logprobs = tensor([[-0.4619, -6.7184],
        [-1.6483, -0.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2230791449546814
Epoch 0, Step 543: train/loss = 0.23640216886997223, train/raw-loss = 0.1272221952676773, train/logprobs = tensor([[-0.3816, -6.9941],
        [-1.5579, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21835997700691223
Epoch 0, Step 544: train/loss = 0.23450082540512085, train/raw-loss = 0.1283000111579895, train/logprobs = tensor([[ -0.5412, -10.4419],
        [ -1.6630,  -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2124016284942627
Epoch 0, Step 545: train/loss = 0.2511758804321289, train/raw-loss = 0.1444493532180786, train/logprobs = tensor([[-0.3628, -6.9920],
        [-1.3935, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21345305442810059
Epoch 0, Step 546: train/loss = 0.23383837938308716, train/raw-loss = 0.13851673901081085, train/logprobs = tensor([[-0.5305, -5.6824],
        [-1.6599, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190643310546875
Epoch 0, Step 547: train/loss = 0.2732197940349579, train/raw-loss = 0.17866763472557068, train/logprobs = tensor([[-0.3106, -5.0876],
        [-1.1906, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18910431861877441
Epoch 0, Step 548: train/loss = 0.23700439929962158, train/raw-loss = 0.12499988079071045, train/logprobs = tensor([[-0.4454, -6.8343],
        [-1.7151, -0.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22400900721549988
Epoch 0, Step 549: train/loss = 0.232402965426445, train/raw-loss = 0.1306593120098114, train/logprobs = tensor([[-0.4079, -5.3935],
        [-1.6774, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20348727703094482
Epoch 0, Step 550: train/loss = 0.23925530910491943, train/raw-loss = 0.10796301066875458, train/logprobs = tensor([[-0.3271, -6.4057],
        [-1.7395, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2625845968723297
Epoch 0, Step 551: train/loss = 0.24794098734855652, train/raw-loss = 0.14191588759422302, train/logprobs = tensor([[-0.4218, -8.9200],
        [-1.5641, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21205021440982819
Epoch 0, Step 552: train/loss = 0.22904866933822632, train/raw-loss = 0.13743382692337036, train/logprobs = tensor([[-0.3671, -6.6885],
        [-1.4739, -0.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1832297146320343
Epoch 0, Step 553: train/loss = 0.2519659399986267, train/raw-loss = 0.1465446949005127, train/logprobs = tensor([[-0.4315, -5.4972],
        [-1.5612, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21084251999855042
Epoch 0, Step 554: train/loss = 0.2372986227273941, train/raw-loss = 0.11975846439599991, train/logprobs = tensor([[-0.3767, -7.6997],
        [-1.6981, -0.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23508033156394958
Epoch 0, Step 555: train/loss = 0.21989098191261292, train/raw-loss = 0.10789570212364197, train/logprobs = tensor([[-0.4269, -7.0157],
        [-1.9261, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2239905595779419
Epoch 0, Step 556: train/loss = 0.2237616777420044, train/raw-loss = 0.1283349245786667, train/logprobs = tensor([[-0.4513, -5.6070],
        [-1.7228, -0.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1908535361289978
Epoch 0, Step 557: train/loss = 0.2592429518699646, train/raw-loss = 0.1351783275604248, train/logprobs = tensor([[-0.3633, -5.5899],
        [-1.4918, -0.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2481292486190796
Epoch 0, Step 558: train/loss = 0.2168155312538147, train/raw-loss = 0.09869401156902313, train/logprobs = tensor([[-0.5137, -9.1871],
        [-2.0464, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23624305427074432
Epoch 0, Step 559: train/loss = 0.25026369094848633, train/raw-loss = 0.13932669162750244, train/logprobs = tensor([[-0.3998, -6.4093],
        [-1.5961, -0.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22187404334545135
Epoch 0, Step 560: train/loss = 0.24911682307720184, train/raw-loss = 0.1569204479455948, train/logprobs = tensor([[-0.4416, -5.9832],
        [-1.5090, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18439273536205292
Epoch 0, Step 561: train/loss = 0.25717636942863464, train/raw-loss = 0.17436514794826508, train/logprobs = tensor([[-0.3918, -7.7121],
        [-1.2242, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16562244296073914
Epoch 0, Step 562: train/loss = 0.2149401605129242, train/raw-loss = 0.10997936129570007, train/logprobs = tensor([[-0.4977, -8.3685],
        [-1.8577, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20992158353328705
Epoch 0, Step 563: train/loss = 0.2553156614303589, train/raw-loss = 0.1474810093641281, train/logprobs = tensor([[-0.3398, -6.5278],
        [-1.3457, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21566930413246155
Epoch 0, Step 564: train/loss = 0.2509879469871521, train/raw-loss = 0.15390163660049438, train/logprobs = tensor([[-0.3494, -6.4746],
        [-1.2665, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19417265057563782
Epoch 0, Step 565: train/loss = 0.21275214850902557, train/raw-loss = 0.09455305337905884, train/logprobs = tensor([[-0.5999, -6.7909],
        [-2.3522, -0.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23639822006225586
Epoch 0, Step 566: train/loss = 0.23350371420383453, train/raw-loss = 0.12544900178909302, train/logprobs = tensor([[-0.3992, -8.4995],
        [-1.6879, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21610942482948303
Epoch 0, Step 567: train/loss = 0.2345128357410431, train/raw-loss = 0.12599843740463257, train/logprobs = tensor([[-0.4061, -8.3697],
        [-1.5717, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21702878177165985
Epoch 0, Step 568: train/loss = 0.23525653779506683, train/raw-loss = 0.12714537978172302, train/logprobs = tensor([[-0.3782, -7.7543],
        [-1.6104, -1.0161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21622230112552643
Epoch 0, Step 569: train/loss = 0.25038376450538635, train/raw-loss = 0.16094422340393066, train/logprobs = tensor([[-0.4034, -5.7794],
        [-1.3427, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17887908220291138
Epoch 0, Step 570: train/loss = 0.2301214635372162, train/raw-loss = 0.1201057881116867, train/logprobs = tensor([[-0.4656, -7.6204],
        [-2.0190, -1.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22003135085105896
Epoch 0, Step 571: train/loss = 0.2380090355873108, train/raw-loss = 0.1180417537689209, train/logprobs = tensor([[-0.5930, -6.5955],
        [-1.9385, -0.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2399345487356186
Epoch 0, Step 572: train/loss = 0.21667324006557465, train/raw-loss = 0.0986987054347992, train/logprobs = tensor([[-0.4122, -9.2552],
        [-1.9239, -0.4610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359490990638733
Epoch 0, Step 573: train/loss = 0.20964597165584564, train/raw-loss = 0.08370166271924973, train/logprobs = tensor([[-0.3965, -9.4450],
        [-2.1150, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25188860297203064
Epoch 0, Step 574: train/loss = 0.27367085218429565, train/raw-loss = 0.16616690158843994, train/logprobs = tensor([[-0.3570, -4.7255],
        [-1.3951, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21500787138938904
Epoch 0, Step 575: train/loss = 0.19525060057640076, train/raw-loss = 0.09571622312068939, train/logprobs = tensor([[-0.6303, -7.0813],
        [-2.2681, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19906878471374512
Epoch 0, Step 576: train/loss = 0.24881349503993988, train/raw-loss = 0.1392098367214203, train/logprobs = tensor([[ -0.3814, -10.5663],
        [ -1.4509,  -0.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21920731663703918
Epoch 0, Step 577: train/loss = 0.26556769013404846, train/raw-loss = 0.15461258590221405, train/logprobs = tensor([[-0.3864, -8.4113],
        [-1.2898, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22191017866134644
Epoch 0, Step 578: train/loss = 0.24090000987052917, train/raw-loss = 0.14208416640758514, train/logprobs = tensor([[-0.4458, -8.5157],
        [-1.6706, -1.0245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19763165712356567
Epoch 0, Step 579: train/loss = 0.23308509588241577, train/raw-loss = 0.10725445300340652, train/logprobs = tensor([[-0.3557, -6.9161],
        [-1.7434, -0.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516612708568573
Epoch 0, Step 580: train/loss = 0.2576929032802582, train/raw-loss = 0.15559357404708862, train/logprobs = tensor([[-0.3598, -7.6634],
        [-1.2497, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20419864356517792
Epoch 0, Step 581: train/loss = 0.26626095175743103, train/raw-loss = 0.17270547151565552, train/logprobs = tensor([[-0.3421, -6.7044],
        [-1.1267, -0.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18711096048355103
Epoch 0, Step 582: train/loss = 0.20710542798042297, train/raw-loss = 0.09398878365755081, train/logprobs = tensor([[-0.5054, -7.1427],
        [-2.0354, -0.6880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22623328864574432
Epoch 0, Step 583: train/loss = 0.21934011578559875, train/raw-loss = 0.10479194670915604, train/logprobs = tensor([[-0.4003, -5.4162],
        [-1.8927, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22909636795520782
Epoch 0, Step 584: train/loss = 0.2306702733039856, train/raw-loss = 0.1296606808900833, train/logprobs = tensor([[-0.4028, -5.2734],
        [-1.6418, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20201918482780457
Epoch 0, Step 585: train/loss = 0.24163439869880676, train/raw-loss = 0.1482294350862503, train/logprobs = tensor([[-0.5569, -8.4727],
        [-1.4889, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18680992722511292
Epoch 0, Step 586: train/loss = 0.22602787613868713, train/raw-loss = 0.11524765193462372, train/logprobs = tensor([[-0.3677, -8.3125],
        [-1.8347, -0.9215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22156044840812683
Epoch 0, Step 587: train/loss = 0.2195379137992859, train/raw-loss = 0.10949069261550903, train/logprobs = tensor([[-0.5453, -7.2623],
        [-2.0479, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22009442746639252
Epoch 0, Step 588: train/loss = 0.2440795600414276, train/raw-loss = 0.1365017592906952, train/logprobs = tensor([[-0.4227, -7.1524],
        [-1.5492, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21515561640262604
Epoch 0, Step 589: train/loss = 0.22529363632202148, train/raw-loss = 0.12032857537269592, train/logprobs = tensor([[-0.4081, -7.2950],
        [-1.7787, -0.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20993013679981232
Epoch 0, Step 590: train/loss = 0.25015366077423096, train/raw-loss = 0.14539359509944916, train/logprobs = tensor([[-0.3829, -6.7189],
        [-1.4706, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095201164484024
Epoch 0, Step 591: train/loss = 0.2334975302219391, train/raw-loss = 0.13048991560935974, train/logprobs = tensor([[-0.3875, -6.5373],
        [-1.6174, -0.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2060152292251587
Epoch 0, Step 592: train/loss = 0.22769151628017426, train/raw-loss = 0.12726494669914246, train/logprobs = tensor([[-0.3859, -5.4215],
        [-1.9656, -0.5965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2008531391620636
Epoch 0, Step 593: train/loss = 0.21390756964683533, train/raw-loss = 0.1006021797657013, train/logprobs = tensor([[-0.4204, -9.1001],
        [-1.9151, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22661080956459045
Epoch 0, Step 594: train/loss = 0.24193806946277618, train/raw-loss = 0.15054500102996826, train/logprobs = tensor([[-0.3071, -7.9168],
        [-1.2909, -1.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18278612196445465
Epoch 0, Step 595: train/loss = 0.23210696876049042, train/raw-loss = 0.11961371451616287, train/logprobs = tensor([[-0.4085, -7.2437],
        [-1.6993, -1.1420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2249864935874939
Epoch 0, Step 596: train/loss = 0.23207905888557434, train/raw-loss = 0.11212369799613953, train/logprobs = tensor([[-0.4301, -7.8694],
        [-1.9629, -0.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23991075158119202
Epoch 0, Step 597: train/loss = 0.2462470531463623, train/raw-loss = 0.1276002824306488, train/logprobs = tensor([[-0.3666, -6.4772],
        [-1.6647, -0.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23729351162910461
Epoch 0, Step 598: train/loss = 0.1984347254037857, train/raw-loss = 0.0891643837094307, train/logprobs = tensor([[-0.4028, -7.1148],
        [-2.0258, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21854066848754883
Epoch 0, Step 599: train/loss = 0.2269115447998047, train/raw-loss = 0.11762703955173492, train/logprobs = tensor([[-0.4782, -8.2495],
        [-1.8105, -0.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21856901049613953
Epoch 0, Step 600: train/loss = 0.22586596012115479, train/raw-loss = 0.12693950533866882, train/logprobs = tensor([[-0.5061, -7.6463],
        [-1.7039, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1978529393672943
Epoch 0, Step 601: train/loss = 0.21645702421665192, train/raw-loss = 0.10197001695632935, train/logprobs = tensor([[-0.3333, -6.4676],
        [-1.7589, -0.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22897401452064514
Epoch 0, Step 602: train/loss = 0.23191581666469574, train/raw-loss = 0.12180726230144501, train/logprobs = tensor([[-0.3321, -7.1398],
        [-1.6424, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22021710872650146
Epoch 0, Step 603: train/loss = 0.2630583345890045, train/raw-loss = 0.16605164110660553, train/logprobs = tensor([[-0.3675, -4.5265],
        [-1.4358, -0.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19401337206363678
Epoch 0, Step 604: train/loss = 0.24209271371364594, train/raw-loss = 0.14288686215877533, train/logprobs = tensor([[-0.4570, -8.7507],
        [-1.4813, -0.9421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1984117031097412
Epoch 0, Step 605: train/loss = 0.28487369418144226, train/raw-loss = 0.16350586712360382, train/logprobs = tensor([[-0.3726, -5.3219],
        [-1.2911, -0.6663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427356243133545
Epoch 0, Step 606: train/loss = 0.24424146115779877, train/raw-loss = 0.15401038527488708, train/logprobs = tensor([[-0.3873, -7.5591],
        [-1.3774, -1.2886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18046219646930695
Epoch 0, Step 607: train/loss = 0.20715641975402832, train/raw-loss = 0.0910579115152359, train/logprobs = tensor([[-0.4064, -7.2100],
        [-2.0302, -0.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23219700157642365
Epoch 0, Step 608: train/loss = 0.1932905912399292, train/raw-loss = 0.0853561982512474, train/logprobs = tensor([[ -0.5005, -11.2531],
        [ -2.5469,  -1.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21586880087852478
Epoch 0, Step 609: train/loss = 0.22344158589839935, train/raw-loss = 0.11192773282527924, train/logprobs = tensor([[-0.3564, -7.8683],
        [-1.7999, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22302773594856262
Epoch 0, Step 610: train/loss = 0.2078438103199005, train/raw-loss = 0.10451768338680267, train/logprobs = tensor([[ -0.3957, -10.2059],
        [ -1.8651,  -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20665225386619568
Epoch 0, Step 611: train/loss = 0.24163305759429932, train/raw-loss = 0.11497291922569275, train/logprobs = tensor([[-0.3788, -7.9565],
        [-1.6931, -0.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25332027673721313
Epoch 0, Step 612: train/loss = 0.22571411728858948, train/raw-loss = 0.1102222353219986, train/logprobs = tensor([[-0.4061, -5.6857],
        [-1.7509, -0.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23098379373550415
Epoch 0, Step 613: train/loss = 0.22804829478263855, train/raw-loss = 0.1297781616449356, train/logprobs = tensor([[-0.4295, -6.7302],
        [-1.7391, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1965402513742447
Epoch 0, Step 614: train/loss = 0.22126027941703796, train/raw-loss = 0.11231198906898499, train/logprobs = tensor([[-0.4670, -6.9893],
        [-1.8260, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21789659559726715
Epoch 0, Step 615: train/loss = 0.2284407913684845, train/raw-loss = 0.11302922666072845, train/logprobs = tensor([[-0.4175, -4.4392],
        [-2.1936, -0.4699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2308231145143509
Epoch 0, Step 616: train/loss = 0.2012351006269455, train/raw-loss = 0.08887381851673126, train/logprobs = tensor([[-0.4332, -7.5487],
        [-2.1998, -0.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22472257912158966
Epoch 0, Step 617: train/loss = 0.21242959797382355, train/raw-loss = 0.11008387804031372, train/logprobs = tensor([[-0.4053, -5.1989],
        [-1.8591, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20469145476818085
Epoch 0, Step 618: train/loss = 0.2381305992603302, train/raw-loss = 0.13516932725906372, train/logprobs = tensor([[-0.3193, -8.4173],
        [-1.4081, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20592258870601654
Epoch 0, Step 619: train/loss = 0.21883559226989746, train/raw-loss = 0.10352188348770142, train/logprobs = tensor([[-0.3650, -6.2408],
        [-1.9475, -0.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306274175643921
Epoch 0, Step 620: train/loss = 0.23142153024673462, train/raw-loss = 0.11704973876476288, train/logprobs = tensor([[-0.3688, -8.2019],
        [-1.6360, -0.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22874359786510468
Epoch 0, Step 621: train/loss = 0.26903945207595825, train/raw-loss = 0.17992183566093445, train/logprobs = tensor([[-0.3975, -5.4149],
        [-1.2825, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17823520302772522
Epoch 0, Step 622: train/loss = 0.22510474920272827, train/raw-loss = 0.1270045042037964, train/logprobs = tensor([[ -0.4896, -10.0925],
        [ -1.6649,  -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962004452943802
Epoch 0, Step 623: train/loss = 0.23887354135513306, train/raw-loss = 0.12770108878612518, train/logprobs = tensor([[-0.4435, -8.2949],
        [-1.6002, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22234490513801575
Epoch 0, Step 624: train/loss = 0.23399099707603455, train/raw-loss = 0.11886774003505707, train/logprobs = tensor([[-0.3773, -6.7947],
        [-1.8152, -0.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23024651408195496
Epoch 0, Step 625: train/loss = 0.23751236498355865, train/raw-loss = 0.10653430223464966, train/logprobs = tensor([[-0.4090, -7.0377],
        [-1.7803, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2619560956954956
Epoch 0, Step 626: train/loss = 0.22739052772521973, train/raw-loss = 0.11318434774875641, train/logprobs = tensor([[-0.4363, -6.3875],
        [-1.8440, -0.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22841235995292664
Epoch 0, Step 627: train/loss = 0.24205368757247925, train/raw-loss = 0.12195330858230591, train/logprobs = tensor([[-0.4114, -8.1366],
        [-1.6894, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2402007281780243
Epoch 0, Step 628: train/loss = 0.233657568693161, train/raw-loss = 0.11113028228282928, train/logprobs = tensor([[-0.4107, -6.0250],
        [-1.9647, -0.4214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24505452811717987
Epoch 0, Step 629: train/loss = 0.21262943744659424, train/raw-loss = 0.09671217203140259, train/logprobs = tensor([[-0.3974, -9.1065],
        [-1.9588, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318345308303833
Epoch 0, Step 630: train/loss = 0.23203620314598083, train/raw-loss = 0.14247393608093262, train/logprobs = tensor([[-0.3863, -7.2484],
        [-1.4195, -1.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17912453413009644
Epoch 0, Step 631: train/loss = 0.29380571842193604, train/raw-loss = 0.19729888439178467, train/logprobs = tensor([[-0.4120, -6.1224],
        [-1.6097, -0.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19301366806030273
Epoch 0, Step 632: train/loss = 0.2030666619539261, train/raw-loss = 0.09060843288898468, train/logprobs = tensor([[-0.4353, -8.1439],
        [-2.1197, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224916473031044
Epoch 0, Step 633: train/loss = 0.22593870759010315, train/raw-loss = 0.10466820746660233, train/logprobs = tensor([[-0.3876, -7.9826],
        [-1.9077, -0.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24254098534584045
Epoch 0, Step 634: train/loss = 0.21632106602191925, train/raw-loss = 0.11053493618965149, train/logprobs = tensor([[-0.4001, -6.8354],
        [-1.8566, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21157227456569672
Epoch 0, Step 635: train/loss = 0.2222626805305481, train/raw-loss = 0.09422646462917328, train/logprobs = tensor([[-0.4487, -7.6591],
        [-1.9544, -0.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25607240200042725
Epoch 0, Step 636: train/loss = 0.24310728907585144, train/raw-loss = 0.12577812373638153, train/logprobs = tensor([[-0.3444, -6.4354],
        [-1.5263, -0.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23465833067893982
Epoch 0, Step 637: train/loss = 0.20703622698783875, train/raw-loss = 0.08980946242809296, train/logprobs = tensor([[-0.4696, -6.9839],
        [-2.2839, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23445351421833038
Epoch 0, Step 638: train/loss = 0.2191864252090454, train/raw-loss = 0.09567983448505402, train/logprobs = tensor([[-0.4237, -5.8918],
        [-2.0845, -0.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2470131814479828
Epoch 0, Step 639: train/loss = 0.22621366381645203, train/raw-loss = 0.12490618973970413, train/logprobs = tensor([[-0.4439, -5.0321],
        [-1.8987, -0.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20261496305465698
Epoch 0, Step 640: train/loss = 0.2485557496547699, train/raw-loss = 0.132023885846138, train/logprobs = tensor([[-0.3399, -6.8198],
        [-1.4968, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2330637276172638
Epoch 0, Step 641: train/loss = 0.23224294185638428, train/raw-loss = 0.1252058446407318, train/logprobs = tensor([[-0.3521, -7.5657],
        [-1.6587, -0.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21407419443130493
Epoch 0, Step 642: train/loss = 0.2024444043636322, train/raw-loss = 0.08993818610906601, train/logprobs = tensor([[-0.4371, -7.3513],
        [-2.0172, -0.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22501243650913239
Epoch 0, Step 643: train/loss = 0.21383777260780334, train/raw-loss = 0.1035381332039833, train/logprobs = tensor([[-0.4540, -8.8794],
        [-2.2098, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22059929370880127
Epoch 0, Step 644: train/loss = 0.19438855350017548, train/raw-loss = 0.0778777152299881, train/logprobs = tensor([[-0.4567, -7.1221],
        [-2.2614, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23302167654037476
Epoch 0, Step 645: train/loss = 0.2115027755498886, train/raw-loss = 0.10306663066148758, train/logprobs = tensor([[-0.5267, -7.0828],
        [-2.0879, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21687231957912445
Epoch 0, Step 646: train/loss = 0.21796166896820068, train/raw-loss = 0.07984200865030289, train/logprobs = tensor([[-0.3670, -6.8583],
        [-2.1636, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2762393355369568
Epoch 0, Step 647: train/loss = 0.21053043007850647, train/raw-loss = 0.109042689204216, train/logprobs = tensor([[-0.4189, -7.0175],
        [-1.8979, -1.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20297546684741974
Epoch 0, Step 648: train/loss = 0.20746031403541565, train/raw-loss = 0.08558142185211182, train/logprobs = tensor([[-0.5103, -8.7477],
        [-2.2731, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24375778436660767
Epoch 0, Step 649: train/loss = 0.21318554878234863, train/raw-loss = 0.10253055393695831, train/logprobs = tensor([[-0.3684, -7.5517],
        [-1.8447, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22130995988845825
Epoch 0, Step 650: train/loss = 0.2765669524669647, train/raw-loss = 0.18515482544898987, train/logprobs = tensor([[-0.3446, -7.4432],
        [-1.4377, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1828242689371109
Epoch 0, Step 651: train/loss = 0.21871507167816162, train/raw-loss = 0.10395804047584534, train/logprobs = tensor([[-0.3472, -6.8109],
        [-1.7230, -0.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22951403260231018
Epoch 0, Step 652: train/loss = 0.21389545500278473, train/raw-loss = 0.09625528752803802, train/logprobs = tensor([[-0.4395, -8.0003],
        [-2.0177, -1.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352803498506546
Epoch 0, Step 653: train/loss = 0.24120736122131348, train/raw-loss = 0.11229322850704193, train/logprobs = tensor([[-0.2897, -8.2104],
        [-1.7179, -0.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578282654285431
Epoch 0, Step 654: train/loss = 0.19977068901062012, train/raw-loss = 0.061563000082969666, train/logprobs = tensor([[-0.3747, -7.2576],
        [-2.3615, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2764153778553009
Epoch 0, Step 655: train/loss = 0.23338930308818817, train/raw-loss = 0.12246447801589966, train/logprobs = tensor([[-0.4395, -7.2179],
        [-1.9264, -0.5386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22184965014457703
Epoch 0, Step 656: train/loss = 0.22434566915035248, train/raw-loss = 0.1182391569018364, train/logprobs = tensor([[-0.4000, -8.4329],
        [-1.6858, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21221302449703217
Epoch 0, Step 657: train/loss = 0.25204241275787354, train/raw-loss = 0.14820438623428345, train/logprobs = tensor([[-0.3070, -6.2633],
        [-1.5151, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20767608284950256
Epoch 0, Step 658: train/loss = 0.24450841546058655, train/raw-loss = 0.13313230872154236, train/logprobs = tensor([[-0.3910, -7.4635],
        [-1.6102, -0.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22275221347808838
Epoch 0, Step 659: train/loss = 0.2707761228084564, train/raw-loss = 0.16781406104564667, train/logprobs = tensor([[-0.2655, -5.3070],
        [-1.2385, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20592409372329712
Epoch 0, Step 660: train/loss = 0.22757041454315186, train/raw-loss = 0.11449328809976578, train/logprobs = tensor([[-0.4594, -5.0317],
        [-2.2414, -0.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22615423798561096
Epoch 0, Step 661: train/loss = 0.24908387660980225, train/raw-loss = 0.14589424431324005, train/logprobs = tensor([[-0.3670, -9.5144],
        [-1.4081, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2063792645931244
Epoch 0, Step 662: train/loss = 0.23702891170978546, train/raw-loss = 0.10120385885238647, train/logprobs = tensor([[-0.4454, -5.8025],
        [-2.0207, -0.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716500759124756
Epoch 0, Step 663: train/loss = 0.20370228588581085, train/raw-loss = 0.08667416870594025, train/logprobs = tensor([[-0.4699, -5.3937],
        [-2.1379, -0.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340562492609024
Epoch 0, Step 664: train/loss = 0.2227398008108139, train/raw-loss = 0.09473365545272827, train/logprobs = tensor([[-0.4358, -5.4949],
        [-2.0118, -0.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25601229071617126
Epoch 0, Step 665: train/loss = 0.22732725739479065, train/raw-loss = 0.09939196705818176, train/logprobs = tensor([[-0.4845, -7.3607],
        [-1.9175, -0.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558705806732178
Epoch 0, Step 666: train/loss = 0.2175886631011963, train/raw-loss = 0.1144927442073822, train/logprobs = tensor([[-0.4172, -6.7256],
        [-1.7024, -0.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20619183778762817
Epoch 0, Step 667: train/loss = 0.21731793880462646, train/raw-loss = 0.09125947952270508, train/logprobs = tensor([[-0.3690, -5.9840],
        [-1.9774, -0.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2521169185638428
Epoch 0, Step 668: train/loss = 0.23475483059883118, train/raw-loss = 0.12950725853443146, train/logprobs = tensor([[-0.3118, -6.5835],
        [-1.6981, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21049512922763824
Epoch 0, Step 669: train/loss = 0.2202029973268509, train/raw-loss = 0.11864658445119858, train/logprobs = tensor([[-0.3463, -9.5104],
        [-1.6327, -1.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20311281085014343
Epoch 0, Step 670: train/loss = 0.25376641750335693, train/raw-loss = 0.13504202663898468, train/logprobs = tensor([[-0.3806, -5.1864],
        [-1.6147, -0.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23744875192642212
Epoch 0, Step 671: train/loss = 0.23440268635749817, train/raw-loss = 0.11327973008155823, train/logprobs = tensor([[-0.4156, -5.7779],
        [-1.9034, -0.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24224591255187988
Epoch 0, Step 672: train/loss = 0.210106760263443, train/raw-loss = 0.09957997500896454, train/logprobs = tensor([[-0.3770, -8.0396],
        [-1.8684, -0.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2210535705089569
Epoch 0, Step 673: train/loss = 0.22645670175552368, train/raw-loss = 0.12092189490795135, train/logprobs = tensor([[-0.4202, -9.0005],
        [-1.6795, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21106959879398346
Epoch 0, Step 674: train/loss = 0.21275967359542847, train/raw-loss = 0.0878642126917839, train/logprobs = tensor([[-0.3711, -7.8573],
        [-2.0103, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24979093670845032
Epoch 0, Step 675: train/loss = 0.20720793306827545, train/raw-loss = 0.09689605236053467, train/logprobs = tensor([[-0.4769, -9.1480],
        [-2.0392, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22062373161315918
Epoch 0, Step 676: train/loss = 0.21312545239925385, train/raw-loss = 0.10373976826667786, train/logprobs = tensor([[-0.3885, -9.9579],
        [-1.9005, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21877138316631317
Epoch 0, Step 677: train/loss = 0.22876867651939392, train/raw-loss = 0.10616730153560638, train/logprobs = tensor([[-0.3620, -6.3919],
        [-1.9133, -0.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24520277976989746
Epoch 0, Step 678: train/loss = 0.2262391746044159, train/raw-loss = 0.11004385352134705, train/logprobs = tensor([[-0.4012, -7.4989],
        [-1.8498, -0.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2323906421661377
Epoch 0, Step 679: train/loss = 0.23285968601703644, train/raw-loss = 0.12197604030370712, train/logprobs = tensor([[-0.5859, -7.0614],
        [-1.8160, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22176724672317505
Epoch 0, Step 680: train/loss = 0.1965230405330658, train/raw-loss = 0.10605089366436005, train/logprobs = tensor([[-0.3597, -9.3511],
        [-1.8100, -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1809443235397339
Epoch 0, Step 681: train/loss = 0.2220565527677536, train/raw-loss = 0.10684270411729813, train/logprobs = tensor([[-0.3691, -7.5442],
        [-1.7649, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23042771220207214
Epoch 0, Step 682: train/loss = 0.2434331476688385, train/raw-loss = 0.13247093558311462, train/logprobs = tensor([[-0.4246, -9.2517],
        [-1.5147, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22192442417144775
Epoch 0, Step 683: train/loss = 0.2154432237148285, train/raw-loss = 0.08024478703737259, train/logprobs = tensor([[-0.4459, -6.8841],
        [-2.2475, -0.5192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.270396888256073
Epoch 0, Step 684: train/loss = 0.213253915309906, train/raw-loss = 0.08521431684494019, train/logprobs = tensor([[-0.4435, -7.2542],
        [-2.2583, -0.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25607919692993164
Epoch 0, Step 685: train/loss = 0.20437836647033691, train/raw-loss = 0.09338994324207306, train/logprobs = tensor([[-0.3502, -6.4202],
        [-2.0152, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22197683155536652
Epoch 0, Step 686: train/loss = 0.22927848994731903, train/raw-loss = 0.12536191940307617, train/logprobs = tensor([[-0.2932, -9.2485],
        [-1.4595, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20783309638500214
Epoch 0, Step 687: train/loss = 0.21248233318328857, train/raw-loss = 0.10788314044475555, train/logprobs = tensor([[-0.4238, -5.9158],
        [-2.0582, -0.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20919837057590485
Epoch 0, Step 688: train/loss = 0.19260457158088684, train/raw-loss = 0.07211866229772568, train/logprobs = tensor([[-0.4488, -8.3764],
        [-2.3937, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24097184836864471
Epoch 0, Step 689: train/loss = 0.20268817245960236, train/raw-loss = 0.09953702986240387, train/logprobs = tensor([[-0.5158, -7.4746],
        [-2.2496, -0.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20630225539207458
Epoch 0, Step 690: train/loss = 0.22420820593833923, train/raw-loss = 0.12500226497650146, train/logprobs = tensor([[-0.3490, -8.9436],
        [-1.6076, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19841185212135315
Epoch 0, Step 691: train/loss = 0.22307592630386353, train/raw-loss = 0.11212612688541412, train/logprobs = tensor([[-0.4406, -7.9712],
        [-1.9874, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2218995839357376
Epoch 0, Step 692: train/loss = 0.256417453289032, train/raw-loss = 0.14615082740783691, train/logprobs = tensor([[-0.3059, -8.3159],
        [-1.3035, -0.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22053325176239014
Epoch 0, Step 693: train/loss = 0.24008618295192719, train/raw-loss = 0.14121714234352112, train/logprobs = tensor([[-0.3726, -5.9352],
        [-1.6963, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19773808121681213
Epoch 0, Step 694: train/loss = 0.27036958932876587, train/raw-loss = 0.18053889274597168, train/logprobs = tensor([[-0.2959, -6.7520],
        [-1.0805, -0.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17966140806674957
Epoch 0, Step 695: train/loss = 0.23877057433128357, train/raw-loss = 0.12811528146266937, train/logprobs = tensor([[-0.4286, -8.6190],
        [-1.5545, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22131061553955078
Epoch 0, Step 696: train/loss = 0.21327322721481323, train/raw-loss = 0.09555976092815399, train/logprobs = tensor([[-0.3625, -6.0829],
        [-1.9710, -0.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2354269176721573
Epoch 0, Step 697: train/loss = 0.197896346449852, train/raw-loss = 0.07921721041202545, train/logprobs = tensor([[-0.4502, -7.2908],
        [-2.4096, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23735825717449188
Epoch 0, Step 698: train/loss = 0.22764721512794495, train/raw-loss = 0.116875559091568, train/logprobs = tensor([[-0.3410, -7.7805],
        [-1.7847, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215433418750763
Epoch 0, Step 699: train/loss = 0.229068785905838, train/raw-loss = 0.11147607862949371, train/logprobs = tensor([[-0.4261, -7.5078],
        [-1.8350, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2351853847503662
Epoch 0, Step 700: train/loss = 0.2023414820432663, train/raw-loss = 0.09816804528236389, train/logprobs = tensor([[-0.4338, -9.2480],
        [-1.9849, -1.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2083468735218048
Epoch 0, Step 701: train/loss = 0.2215845286846161, train/raw-loss = 0.10916763544082642, train/logprobs = tensor([[-0.4469, -6.4731],
        [-2.0809, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22483377158641815
Epoch 0, Step 702: train/loss = 0.2149970978498459, train/raw-loss = 0.10149777680635452, train/logprobs = tensor([[-0.4855, -9.1533],
        [-2.0775, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22699865698814392
Epoch 0, Step 703: train/loss = 0.22679753601551056, train/raw-loss = 0.11521776020526886, train/logprobs = tensor([[-0.3774, -6.7993],
        [-1.8767, -0.8130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2231595516204834
Epoch 0, Step 704: train/loss = 0.2306143194437027, train/raw-loss = 0.09090767800807953, train/logprobs = tensor([[-0.3504, -5.7546],
        [-2.0033, -0.9594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27941328287124634
Epoch 0, Step 705: train/loss = 0.2100219577550888, train/raw-loss = 0.0956246554851532, train/logprobs = tensor([[-0.3438, -8.9607],
        [-1.8497, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22879460453987122
Epoch 0, Step 706: train/loss = 0.14915098249912262, train/raw-loss = 0.040678806602954865, train/logprobs = tensor([[-0.5367, -8.6726],
        [-3.4391, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2169443517923355
Epoch 0, Step 707: train/loss = 0.22770094871520996, train/raw-loss = 0.12451166659593582, train/logprobs = tensor([[-0.3412, -6.8779],
        [-1.5254, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20637856423854828
Epoch 0, Step 708: train/loss = 0.2297516167163849, train/raw-loss = 0.11954338848590851, train/logprobs = tensor([[-0.3282, -7.0601],
        [-1.7559, -0.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22041645646095276
Epoch 0, Step 709: train/loss = 0.19798871874809265, train/raw-loss = 0.0689244195818901, train/logprobs = tensor([[ -0.4761, -10.2791],
        [ -2.4681,  -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581286132335663
Epoch 0, Step 710: train/loss = 0.23109832406044006, train/raw-loss = 0.12589366734027863, train/logprobs = tensor([[-0.3817, -6.9090],
        [-1.8053, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21040932834148407
Epoch 0, Step 711: train/loss = 0.2438778132200241, train/raw-loss = 0.14333413541316986, train/logprobs = tensor([[-0.3838, -8.3230],
        [-1.4717, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2010873258113861
Epoch 0, Step 712: train/loss = 0.18827995657920837, train/raw-loss = 0.08484161645174026, train/logprobs = tensor([[-0.4373, -8.2343],
        [-2.4176, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20687668025493622
Epoch 0, Step 713: train/loss = 0.22468841075897217, train/raw-loss = 0.1299055814743042, train/logprobs = tensor([[ -0.2939, -10.0277],
        [ -1.4767,  -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18956567347049713
Epoch 0, Step 714: train/loss = 0.2068210244178772, train/raw-loss = 0.07102040201425552, train/logprobs = tensor([[ -0.4365, -10.2596],
        [ -2.4240,  -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27160122990608215
Epoch 0, Step 715: train/loss = 0.20350545644760132, train/raw-loss = 0.10217202454805374, train/logprobs = tensor([[-0.3395, -6.9771],
        [-1.8031, -0.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20266687870025635
Epoch 0, Step 716: train/loss = 0.1660168170928955, train/raw-loss = 0.05281700938940048, train/logprobs = tensor([[-0.4289, -7.5194],
        [-2.7899, -1.3364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22639961540699005
Epoch 0, Step 717: train/loss = 0.22383125126361847, train/raw-loss = 0.1233387440443039, train/logprobs = tensor([[-0.2779, -6.0021],
        [-1.6521, -0.9839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20098504424095154
Epoch 0, Step 718: train/loss = 0.17894771695137024, train/raw-loss = 0.06543366611003876, train/logprobs = tensor([[-0.4170, -9.0243],
        [-2.5258, -0.7500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22702811658382416
Epoch 0, Step 719: train/loss = 0.220687597990036, train/raw-loss = 0.1215415969491005, train/logprobs = tensor([[-0.3455, -6.5466],
        [-1.5578, -0.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19829201698303223
Epoch 0, Step 720: train/loss = 0.20776180922985077, train/raw-loss = 0.11177648603916168, train/logprobs = tensor([[-0.3210, -6.1141],
        [-1.7496, -0.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19197064638137817
Epoch 0, Step 721: train/loss = 0.16667622327804565, train/raw-loss = 0.05856454744935036, train/logprobs = tensor([[-0.4288, -9.1940],
        [-2.7374, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162233591079712
Epoch 0, Step 722: train/loss = 0.2052164375782013, train/raw-loss = 0.08887433260679245, train/logprobs = tensor([[-0.3844, -6.7685],
        [-2.0761, -0.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2326841801404953
Epoch 0, Step 723: train/loss = 0.20771124958992004, train/raw-loss = 0.08297839015722275, train/logprobs = tensor([[-0.4400, -7.5497],
        [-2.2091, -0.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2494657039642334
Epoch 0, Step 724: train/loss = 0.1813720315694809, train/raw-loss = 0.0685289204120636, train/logprobs = tensor([[-0.5346, -5.7761],
        [-2.6265, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2256862074136734
Epoch 0, Step 725: train/loss = 0.23264220356941223, train/raw-loss = 0.13508573174476624, train/logprobs = tensor([[-0.3682, -5.8998],
        [-1.5849, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1951129287481308
Epoch 0, Step 726: train/loss = 0.19636580348014832, train/raw-loss = 0.06350291520357132, train/logprobs = tensor([[-0.3900, -5.3923],
        [-2.6398, -0.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657257914543152
Epoch 0, Step 727: train/loss = 0.22787563502788544, train/raw-loss = 0.12694323062896729, train/logprobs = tensor([[-0.3366, -7.1185],
        [-1.5221, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2018648087978363
Epoch 0, Step 728: train/loss = 0.21743398904800415, train/raw-loss = 0.08709746599197388, train/logprobs = tensor([[-0.4888, -8.5716],
        [-2.1324, -0.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26067304611206055
Epoch 0, Step 729: train/loss = 0.19314485788345337, train/raw-loss = 0.07819176465272903, train/logprobs = tensor([[ -0.4818, -10.2273],
        [ -2.3776,  -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22990620136260986
Epoch 0, Step 730: train/loss = 0.2107883095741272, train/raw-loss = 0.09428591281175613, train/logprobs = tensor([[-0.3941, -9.2917],
        [-1.8790, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23300480842590332
Epoch 0, Step 731: train/loss = 0.24056555330753326, train/raw-loss = 0.1283777356147766, train/logprobs = tensor([[-0.3259, -7.3730],
        [-1.4413, -0.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2243756353855133
Epoch 0, Step 732: train/loss = 0.2259535789489746, train/raw-loss = 0.11520621925592422, train/logprobs = tensor([[-0.3019, -8.9166],
        [-1.5494, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22149470448493958
Epoch 0, Step 733: train/loss = 0.2009648084640503, train/raw-loss = 0.08138688653707504, train/logprobs = tensor([[-0.3643, -8.7340],
        [-2.0538, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2391558289527893
Epoch 0, Step 734: train/loss = 0.21232417225837708, train/raw-loss = 0.09958268702030182, train/logprobs = tensor([[-0.4551, -6.4622],
        [-2.1483, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2254829704761505
Epoch 0, Step 735: train/loss = 0.22782522439956665, train/raw-loss = 0.08637911081314087, train/logprobs = tensor([[-0.4559, -6.2453],
        [-2.1858, -0.3734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28289222717285156
Epoch 0, Step 736: train/loss = 0.19341883063316345, train/raw-loss = 0.06552229821681976, train/logprobs = tensor([[-0.4511, -8.3428],
        [-2.7075, -0.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557930648326874
Epoch 0, Step 737: train/loss = 0.2365894466638565, train/raw-loss = 0.11757862567901611, train/logprobs = tensor([[-0.3301, -7.5084],
        [-1.5773, -0.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380216419696808
Epoch 0, Step 738: train/loss = 0.22492104768753052, train/raw-loss = 0.12012818455696106, train/logprobs = tensor([[-0.3047, -7.4437],
        [-1.5216, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20958572626113892
Epoch 0, Step 739: train/loss = 0.16917310655117035, train/raw-loss = 0.06002660095691681, train/logprobs = tensor([[-0.6632, -8.7651],
        [-2.8522, -1.2642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21829301118850708
Epoch 0, Step 740: train/loss = 0.26059210300445557, train/raw-loss = 0.13619591295719147, train/logprobs = tensor([[-0.3337, -6.3249],
        [-1.3776, -0.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2487923502922058
Epoch 0, Step 741: train/loss = 0.2996429204940796, train/raw-loss = 0.2017461359500885, train/logprobs = tensor([[-0.3442, -4.4161],
        [-1.2300, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19579358398914337
Epoch 0, Step 742: train/loss = 0.219703808426857, train/raw-loss = 0.09006190299987793, train/logprobs = tensor([[-0.4134, -7.1513],
        [-2.0073, -0.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592838406562805
Epoch 0, Step 743: train/loss = 0.265022873878479, train/raw-loss = 0.17081311345100403, train/logprobs = tensor([[-0.3840, -5.1095],
        [-1.3558, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18841950595378876
Epoch 0, Step 744: train/loss = 0.24068287014961243, train/raw-loss = 0.12794142961502075, train/logprobs = tensor([[-0.3648, -5.5029],
        [-1.9282, -0.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22548291087150574
Epoch 0, Step 745: train/loss = 0.1982855498790741, train/raw-loss = 0.06834597885608673, train/logprobs = tensor([[-0.4215, -7.7105],
        [-2.4900, -0.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25987911224365234
Epoch 0, Step 746: train/loss = 0.21365779638290405, train/raw-loss = 0.10914771258831024, train/logprobs = tensor([[-0.3158, -8.1451],
        [-1.7381, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20902016758918762
Epoch 0, Step 747: train/loss = 0.2069101780653, train/raw-loss = 0.10791543126106262, train/logprobs = tensor([[-0.4195, -7.8217],
        [-1.8513, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19798952341079712
Epoch 0, Step 748: train/loss = 0.19972120225429535, train/raw-loss = 0.08096872270107269, train/logprobs = tensor([[-0.3771, -6.1159],
        [-2.3173, -0.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23750492930412292
Epoch 0, Step 749: train/loss = 0.18599286675453186, train/raw-loss = 0.06680411845445633, train/logprobs = tensor([[-0.3815, -7.6160],
        [-2.4174, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23837748169898987
Epoch 0, Step 750: train/loss = 0.19816268980503082, train/raw-loss = 0.08409120887517929, train/logprobs = tensor([[-0.4726, -8.7158],
        [-2.1965, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22814297676086426
Epoch 0, Step 751: train/loss = 0.20172205567359924, train/raw-loss = 0.07707139849662781, train/logprobs = tensor([[-0.3577, -8.1165],
        [-2.2740, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24930131435394287
Epoch 0, Step 752: train/loss = 0.21942058205604553, train/raw-loss = 0.07676295936107635, train/logprobs = tensor([[-0.5437, -7.7836],
        [-2.3799, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28531527519226074
Epoch 0, Step 753: train/loss = 0.20418614149093628, train/raw-loss = 0.09473972022533417, train/logprobs = tensor([[-0.3775, -9.0426],
        [-2.0019, -0.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21889282763004303
Epoch 0, Step 754: train/loss = 0.24380919337272644, train/raw-loss = 0.1346825361251831, train/logprobs = tensor([[-0.3821, -8.2628],
        [-1.5253, -0.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21825329959392548
Epoch 0, Step 755: train/loss = 0.20217281579971313, train/raw-loss = 0.08941134065389633, train/logprobs = tensor([[-0.3630, -7.5998],
        [-2.0031, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255229651927948
Epoch 0, Step 756: train/loss = 0.22941318154335022, train/raw-loss = 0.12937653064727783, train/logprobs = tensor([[-0.3274, -7.3536],
        [-1.4638, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20007330179214478
Epoch 0, Step 757: train/loss = 0.22069378197193146, train/raw-loss = 0.10521061718463898, train/logprobs = tensor([[-0.3299, -6.5596],
        [-1.7398, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23096634447574615
Epoch 0, Step 758: train/loss = 0.2023458480834961, train/raw-loss = 0.09520204365253448, train/logprobs = tensor([[ -0.3721, -10.5721],
        [ -2.0389,  -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21428760886192322
Epoch 0, Step 759: train/loss = 0.19854959845542908, train/raw-loss = 0.09418097883462906, train/logprobs = tensor([[-0.3932, -4.6785],
        [-2.3675, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20873725414276123
Epoch 0, Step 760: train/loss = 0.20585383474826813, train/raw-loss = 0.10079087316989899, train/logprobs = tensor([[-0.4307, -9.1276],
        [-1.9771, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21012592315673828
Epoch 0, Step 761: train/loss = 0.18754251301288605, train/raw-loss = 0.07388268411159515, train/logprobs = tensor([[-0.4190, -7.5390],
        [-2.4866, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273196578025818
Epoch 0, Step 762: train/loss = 0.22236374020576477, train/raw-loss = 0.09351010620594025, train/logprobs = tensor([[-0.4390, -7.0436],
        [-2.0896, -0.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25770729780197144
Epoch 0, Step 763: train/loss = 0.2238215208053589, train/raw-loss = 0.11720380187034607, train/logprobs = tensor([[-0.3089, -8.8625],
        [-1.5436, -0.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21323546767234802
Epoch 0, Step 764: train/loss = 0.24282705783843994, train/raw-loss = 0.14870356023311615, train/logprobs = tensor([[-0.3776, -5.2788],
        [-1.5269, -0.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1882469803094864
Epoch 0, Step 765: train/loss = 0.20981192588806152, train/raw-loss = 0.09759332239627838, train/logprobs = tensor([[-0.3622, -9.2125],
        [-2.0931, -0.5568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22443720698356628
Epoch 0, Step 766: train/loss = 0.19502852857112885, train/raw-loss = 0.0694325715303421, train/logprobs = tensor([[-0.3829, -6.8017],
        [-2.3974, -0.5711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511919140815735
Epoch 0, Step 767: train/loss = 0.20489352941513062, train/raw-loss = 0.08154939115047455, train/logprobs = tensor([[-0.4513, -7.4801],
        [-2.2627, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24668827652931213
Epoch 0, Step 768: train/loss = 0.2029017210006714, train/raw-loss = 0.0933016985654831, train/logprobs = tensor([[-0.3405, -8.2764],
        [-1.9367, -0.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21920007467269897
Epoch 0, Step 769: train/loss = 0.19891715049743652, train/raw-loss = 0.07588711380958557, train/logprobs = tensor([[-0.4984, -9.1668],
        [-2.3195, -1.1618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2460600733757019
Epoch 0, Step 770: train/loss = 0.21683469414710999, train/raw-loss = 0.13061445951461792, train/logprobs = tensor([[-0.4595, -5.5413],
        [-1.9755, -0.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17244046926498413
Epoch 0, Step 771: train/loss = 0.2193097174167633, train/raw-loss = 0.09818390756845474, train/logprobs = tensor([[-0.3439, -6.8058],
        [-1.8447, -0.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24225160479545593
Epoch 0, Step 772: train/loss = 0.20233102142810822, train/raw-loss = 0.09166204184293747, train/logprobs = tensor([[-0.3775, -7.5568],
        [-2.1194, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213379591703415
Epoch 0, Step 773: train/loss = 0.2113361656665802, train/raw-loss = 0.10086269676685333, train/logprobs = tensor([[-0.3681, -7.3123],
        [-1.8394, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094695270061493
Epoch 0, Step 774: train/loss = 0.190493643283844, train/raw-loss = 0.06778877228498459, train/logprobs = tensor([[-0.4436, -5.7551],
        [-2.4588, -0.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24540975689888
Epoch 0, Step 775: train/loss = 0.20948439836502075, train/raw-loss = 0.08940595388412476, train/logprobs = tensor([[-0.3881, -8.4377],
        [-2.0131, -0.5543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240156888961792
Epoch 0, Step 776: train/loss = 0.21164913475513458, train/raw-loss = 0.11504602432250977, train/logprobs = tensor([[-0.3023, -6.3027],
        [-1.8541, -0.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19320623576641083
Epoch 0, Step 777: train/loss = 0.22983577847480774, train/raw-loss = 0.13881829380989075, train/logprobs = tensor([[-0.2913, -8.7028],
        [-1.4230, -1.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18203498423099518
Epoch 0, Step 778: train/loss = 0.22127071022987366, train/raw-loss = 0.11089785397052765, train/logprobs = tensor([[-0.4335, -9.6403],
        [-1.7630, -0.6395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22074569761753082
Epoch 0, Step 779: train/loss = 0.18716108798980713, train/raw-loss = 0.07699792087078094, train/logprobs = tensor([[ -0.3282, -10.2535],
        [ -2.1446,  -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22032633423805237
Epoch 0, Step 780: train/loss = 0.19377708435058594, train/raw-loss = 0.07985053211450577, train/logprobs = tensor([[-0.4514, -8.0742],
        [-2.5572, -0.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22785308957099915
Epoch 0, Step 781: train/loss = 0.17851752042770386, train/raw-loss = 0.07873450219631195, train/logprobs = tensor([[-0.4009, -5.9930],
        [-2.2643, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.199566051363945
Epoch 0, Step 782: train/loss = 0.22585606575012207, train/raw-loss = 0.12464156001806259, train/logprobs = tensor([[ -0.3116, -10.8755],
        [ -1.5046,  -0.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20242901146411896
Epoch 0, Step 783: train/loss = 0.2276889979839325, train/raw-loss = 0.09897315502166748, train/logprobs = tensor([[-0.3407, -7.6646],
        [-2.0134, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25743168592453003
Epoch 0, Step 784: train/loss = 0.22531311213970184, train/raw-loss = 0.1096806675195694, train/logprobs = tensor([[-0.3449, -7.8616],
        [-1.7193, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312648892402649
Epoch 0, Step 785: train/loss = 0.25446146726608276, train/raw-loss = 0.15626633167266846, train/logprobs = tensor([[-0.3360, -7.8612],
        [-1.2093, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.196390300989151
Epoch 0, Step 786: train/loss = 0.20049580931663513, train/raw-loss = 0.09122537076473236, train/logprobs = tensor([[-0.4289, -8.0947],
        [-1.9821, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21854090690612793
Epoch 0, Step 787: train/loss = 0.1908271610736847, train/raw-loss = 0.0811992958188057, train/logprobs = tensor([[-0.3636, -7.0775],
        [-2.3034, -0.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.219255730509758
Epoch 0, Step 788: train/loss = 0.19170443713665009, train/raw-loss = 0.08568620681762695, train/logprobs = tensor([[-0.3637, -7.7376],
        [-2.1174, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21203644573688507
Epoch 0, Step 789: train/loss = 0.24105864763259888, train/raw-loss = 0.13900630176067352, train/logprobs = tensor([[-0.3676, -6.3767],
        [-1.4508, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20410466194152832
Epoch 0, Step 790: train/loss = 0.24303221702575684, train/raw-loss = 0.12113186717033386, train/logprobs = tensor([[-0.4315, -5.9735],
        [-1.7152, -0.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24380068480968475
Epoch 0, Step 791: train/loss = 0.16893908381462097, train/raw-loss = 0.055483292788267136, train/logprobs = tensor([[-0.4914, -7.8655],
        [-3.2870, -0.8595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22691157460212708
Epoch 0, Step 792: train/loss = 0.2325485199689865, train/raw-loss = 0.1292688101530075, train/logprobs = tensor([[-0.2564, -5.6830],
        [-1.5332, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2065594345331192
Epoch 0, Step 793: train/loss = 0.19381128251552582, train/raw-loss = 0.05414574593305588, train/logprobs = tensor([[-0.3831, -8.5246],
        [-2.6546, -0.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2793310880661011
Epoch 0, Step 794: train/loss = 0.2244376689195633, train/raw-loss = 0.13109782338142395, train/logprobs = tensor([[-0.3596, -7.8169],
        [-1.5080, -0.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866796910762787
Epoch 0, Step 795: train/loss = 0.19302764534950256, train/raw-loss = 0.08649343997240067, train/logprobs = tensor([[-0.3969, -8.2261],
        [-2.2303, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2130684107542038
Epoch 0, Step 796: train/loss = 0.2121199518442154, train/raw-loss = 0.10618969798088074, train/logprobs = tensor([[-0.3361, -7.0624],
        [-1.8240, -1.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21186047792434692
Epoch 0, Step 797: train/loss = 0.20712828636169434, train/raw-loss = 0.08977803587913513, train/logprobs = tensor([[-0.4035, -7.0466],
        [-2.0680, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347005009651184
Epoch 0, Step 798: train/loss = 0.22596478462219238, train/raw-loss = 0.12160928547382355, train/logprobs = tensor([[-0.3753, -5.2461],
        [-1.6818, -0.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20871101319789886
Epoch 0, Step 799: train/loss = 0.21696139872074127, train/raw-loss = 0.09734224528074265, train/logprobs = tensor([[-0.3736, -7.1882],
        [-2.0746, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23923829197883606
Epoch 0, Step 800: train/loss = 0.19745087623596191, train/raw-loss = 0.08442116528749466, train/logprobs = tensor([[-0.4164, -7.2702],
        [-2.2464, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2260594367980957
Epoch 0, Step 801: train/loss = 0.21343988180160522, train/raw-loss = 0.10393985360860825, train/logprobs = tensor([[-0.3511, -6.5748],
        [-1.8280, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21900004148483276
Epoch 0, Step 802: train/loss = 0.2283599078655243, train/raw-loss = 0.13481652736663818, train/logprobs = tensor([[-0.2924, -7.2504],
        [-1.4461, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18708671629428864
Epoch 0, Step 803: train/loss = 0.203639954328537, train/raw-loss = 0.10784520953893661, train/logprobs = tensor([[-0.4140, -7.7409],
        [-1.9511, -0.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19158950448036194
Epoch 0, Step 804: train/loss = 0.23252081871032715, train/raw-loss = 0.13533984124660492, train/logprobs = tensor([[-0.2795, -7.0717],
        [-1.4179, -0.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19436195492744446
Epoch 0, Step 805: train/loss = 0.19067510962486267, train/raw-loss = 0.08599947392940521, train/logprobs = tensor([[-0.4412, -8.4159],
        [-2.3317, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2093512862920761
Epoch 0, Step 806: train/loss = 0.22265523672103882, train/raw-loss = 0.10251911729574203, train/logprobs = tensor([[-0.3170, -7.5485],
        [-2.0439, -0.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24027222394943237
Epoch 0, Step 807: train/loss = 0.19002321362495422, train/raw-loss = 0.08331827819347382, train/logprobs = tensor([[-0.3199, -9.3291],
        [-1.9813, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21340985596179962
Epoch 0, Step 808: train/loss = 0.20308545231819153, train/raw-loss = 0.08262374997138977, train/logprobs = tensor([[-0.3504, -6.4744],
        [-2.1386, -0.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24092338979244232
Epoch 0, Step 809: train/loss = 0.18003448843955994, train/raw-loss = 0.07516275346279144, train/logprobs = tensor([[-0.4218, -6.9522],
        [-2.4308, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2097434401512146
Epoch 0, Step 810: train/loss = 0.22363370656967163, train/raw-loss = 0.11243897676467896, train/logprobs = tensor([[-0.3873, -6.5684],
        [-1.9624, -0.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22238945960998535
Epoch 0, Step 811: train/loss = 0.20279964804649353, train/raw-loss = 0.08260339498519897, train/logprobs = tensor([[-0.4491, -7.9084],
        [-2.3281, -0.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2403925359249115
Epoch 0, Step 812: train/loss = 0.2444252371788025, train/raw-loss = 0.14912092685699463, train/logprobs = tensor([[-0.2580, -5.8233],
        [-1.3115, -0.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19060860574245453
Epoch 0, Step 813: train/loss = 0.19491669535636902, train/raw-loss = 0.058361832052469254, train/logprobs = tensor([[-0.3669, -8.8852],
        [-2.4316, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27310970425605774
Epoch 0, Step 814: train/loss = 0.2113877385854721, train/raw-loss = 0.12541086971759796, train/logprobs = tensor([[-0.3228, -5.5447],
        [-1.8047, -1.0706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719537377357483
Epoch 0, Step 815: train/loss = 0.23519372940063477, train/raw-loss = 0.1299232691526413, train/logprobs = tensor([[-0.2845, -9.7245],
        [-1.4257, -1.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21054095029830933
Epoch 0, Step 816: train/loss = 0.25028616189956665, train/raw-loss = 0.15903005003929138, train/logprobs = tensor([[-0.2618, -5.7448],
        [-1.1380, -0.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18251222372055054
Epoch 0, Step 817: train/loss = 0.21695291996002197, train/raw-loss = 0.11725181341171265, train/logprobs = tensor([[-0.4297, -6.8953],
        [-1.7705, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19940222799777985
Epoch 0, Step 818: train/loss = 0.20871207118034363, train/raw-loss = 0.09944646060466766, train/logprobs = tensor([[-0.3617, -7.9473],
        [-2.0387, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853120625019073
Epoch 0, Step 819: train/loss = 0.179595947265625, train/raw-loss = 0.06768867373466492, train/logprobs = tensor([[-0.3563, -4.9969],
        [-2.3792, -0.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22381454706192017
Epoch 0, Step 820: train/loss = 0.18522928655147552, train/raw-loss = 0.07001613080501556, train/logprobs = tensor([[-0.4568, -8.2429],
        [-2.4198, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23042631149291992
Epoch 0, Step 821: train/loss = 0.2143789827823639, train/raw-loss = 0.10750111937522888, train/logprobs = tensor([[ -0.3322, -12.4764],
        [ -1.7180,  -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2137557417154312
Epoch 0, Step 822: train/loss = 0.18211182951927185, train/raw-loss = 0.06787692755460739, train/logprobs = tensor([[-0.4385, -7.9726],
        [-2.5980, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2284698188304901
Epoch 0, Step 823: train/loss = 0.21904036402702332, train/raw-loss = 0.126359224319458, train/logprobs = tensor([[-0.3664, -7.5600],
        [-1.6302, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.185362309217453
Epoch 0, Step 824: train/loss = 0.210130974650383, train/raw-loss = 0.1058322936296463, train/logprobs = tensor([[-0.3233, -5.7192],
        [-1.7599, -1.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2085973620414734
Epoch 0, Step 825: train/loss = 0.21354734897613525, train/raw-loss = 0.11281470954418182, train/logprobs = tensor([[-0.3865, -7.6235],
        [-1.7291, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20146527886390686
Epoch 0, Step 826: train/loss = 0.1939896196126938, train/raw-loss = 0.07851168513298035, train/logprobs = tensor([[-0.2993, -7.8700],
        [-2.0969, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23095588386058807
Epoch 0, Step 827: train/loss = 0.20563116669654846, train/raw-loss = 0.10477911680936813, train/logprobs = tensor([[-0.4556, -9.1955],
        [-1.9554, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20170406997203827
Epoch 0, Step 828: train/loss = 0.22672435641288757, train/raw-loss = 0.12562081217765808, train/logprobs = tensor([[-0.3009, -6.9872],
        [-1.4553, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20220708847045898
Epoch 0, Step 829: train/loss = 0.1691802442073822, train/raw-loss = 0.0533832311630249, train/logprobs = tensor([[-0.4373, -6.6205],
        [-2.8992, -0.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2315940260887146
Epoch 0, Step 830: train/loss = 0.20875146985054016, train/raw-loss = 0.11513067781925201, train/logprobs = tensor([[-0.3277, -8.0622],
        [-1.6786, -1.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1872415691614151
Epoch 0, Step 831: train/loss = 0.21047545969486237, train/raw-loss = 0.0894959568977356, train/logprobs = tensor([[-0.3936, -7.2689],
        [-1.9868, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24195900559425354
Epoch 0, Step 832: train/loss = 0.22207581996917725, train/raw-loss = 0.10814407467842102, train/logprobs = tensor([[-0.3779, -7.8010],
        [-1.8391, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22786347568035126
Epoch 0, Step 833: train/loss = 0.2211168110370636, train/raw-loss = 0.10703127086162567, train/logprobs = tensor([[-0.3982, -6.6969],
        [-1.8428, -0.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22817109525203705
Epoch 0, Step 834: train/loss = 0.19224701821804047, train/raw-loss = 0.09253567457199097, train/logprobs = tensor([[-0.3666, -7.4864],
        [-2.0766, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994226723909378
Epoch 0, Step 835: train/loss = 0.2152148336172104, train/raw-loss = 0.09465040266513824, train/logprobs = tensor([[-0.3341, -6.2717],
        [-1.8978, -0.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2411288470029831
Epoch 0, Step 836: train/loss = 0.17472150921821594, train/raw-loss = 0.06228981539607048, train/logprobs = tensor([[-0.4925, -6.2389],
        [-2.6827, -0.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22486336529254913
Epoch 0, Step 837: train/loss = 0.17864102125167847, train/raw-loss = 0.07021017372608185, train/logprobs = tensor([[-0.3869, -7.0662],
        [-2.2461, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21686169505119324
Epoch 0, Step 838: train/loss = 0.20365691184997559, train/raw-loss = 0.08107586205005646, train/logprobs = tensor([[-0.3520, -6.1439],
        [-2.3808, -0.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24516211450099945
Epoch 0, Step 839: train/loss = 0.23751509189605713, train/raw-loss = 0.14358608424663544, train/logprobs = tensor([[-0.2881, -7.6567],
        [-1.2487, -0.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18785804510116577
Epoch 0, Step 840: train/loss = 0.2168481945991516, train/raw-loss = 0.12792624533176422, train/logprobs = tensor([[-0.3616, -7.2566],
        [-1.5312, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17784392833709717
Epoch 0, Step 841: train/loss = 0.2325487583875656, train/raw-loss = 0.12484250962734222, train/logprobs = tensor([[-0.3870, -7.8335],
        [-1.5827, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21541249752044678
Epoch 0, Step 842: train/loss = 0.2426166534423828, train/raw-loss = 0.1483023315668106, train/logprobs = tensor([[-0.3473, -7.2290],
        [-1.3387, -0.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18862861394882202
Epoch 0, Step 843: train/loss = 0.2135031819343567, train/raw-loss = 0.0930124819278717, train/logprobs = tensor([[-0.3516, -6.2045],
        [-2.2717, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24098140001296997
Epoch 0, Step 844: train/loss = 0.23057594895362854, train/raw-loss = 0.10786648094654083, train/logprobs = tensor([[-0.3824, -5.3077],
        [-1.8293, -0.3182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2454189509153366
Epoch 0, Step 845: train/loss = 0.19432373344898224, train/raw-loss = 0.09733414649963379, train/logprobs = tensor([[-0.3595, -7.2424],
        [-2.0616, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1939791887998581
Epoch 0, Step 846: train/loss = 0.21772927045822144, train/raw-loss = 0.10320231318473816, train/logprobs = tensor([[-0.3532, -8.2900],
        [-1.8741, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22905391454696655
Epoch 0, Step 847: train/loss = 0.19561417400836945, train/raw-loss = 0.10613492131233215, train/logprobs = tensor([[-0.3745, -8.2273],
        [-1.8499, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17895850539207458
Epoch 0, Step 848: train/loss = 0.21920818090438843, train/raw-loss = 0.1128804087638855, train/logprobs = tensor([[-0.3390, -9.9609],
        [-1.6746, -0.7026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21265552937984467
Epoch 0, Step 849: train/loss = 0.21688999235630035, train/raw-loss = 0.10647913068532944, train/logprobs = tensor([[-0.3661, -7.2388],
        [-1.8790, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22082172334194183
Epoch 0, Step 850: train/loss = 0.19445814192295074, train/raw-loss = 0.08223114907741547, train/logprobs = tensor([[-0.2803, -7.6447],
        [-1.9949, -0.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22445398569107056
Epoch 0, Step 851: train/loss = 0.21799898147583008, train/raw-loss = 0.13332246243953705, train/logprobs = tensor([[-0.3232, -9.6504],
        [-1.3860, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16935302317142487
Epoch 0, Step 852: train/loss = 0.22360557317733765, train/raw-loss = 0.12191953510046005, train/logprobs = tensor([[-0.3425, -6.5105],
        [-2.0102, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.203372061252594
Epoch 0, Step 853: train/loss = 0.21513959765434265, train/raw-loss = 0.11260023713111877, train/logprobs = tensor([[-0.2789, -9.6204],
        [-1.7078, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20507870614528656
Epoch 0, Step 854: train/loss = 0.20427630841732025, train/raw-loss = 0.09855051338672638, train/logprobs = tensor([[-0.3332, -8.3737],
        [-1.8978, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21145157516002655
Epoch 0, Step 855: train/loss = 0.20782363414764404, train/raw-loss = 0.0933169275522232, train/logprobs = tensor([[-0.3798, -8.3920],
        [-1.9817, -0.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22901341319084167
Epoch 0, Step 856: train/loss = 0.21424052119255066, train/raw-loss = 0.12054432183504105, train/logprobs = tensor([[-0.3719, -9.9727],
        [-1.5969, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18739236891269684
Epoch 0, Step 857: train/loss = 0.2013857364654541, train/raw-loss = 0.0900413915514946, train/logprobs = tensor([[-0.3100, -8.7300],
        [-2.0613, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.222688689827919
Epoch 0, Step 858: train/loss = 0.20186558365821838, train/raw-loss = 0.08411217480897903, train/logprobs = tensor([[-0.2986, -8.1759],
        [-2.0105, -0.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2355068027973175
Epoch 0, Step 859: train/loss = 0.21905413269996643, train/raw-loss = 0.1125294640660286, train/logprobs = tensor([[-0.3014, -8.2827],
        [-1.6935, -0.5948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21304932236671448
Epoch 0, Step 860: train/loss = 0.201285257935524, train/raw-loss = 0.09796233475208282, train/logprobs = tensor([[-0.3681, -6.6054],
        [-2.0732, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20664584636688232
Epoch 0, Step 861: train/loss = 0.17825090885162354, train/raw-loss = 0.06510643661022186, train/logprobs = tensor([[ -0.3932, -10.0122],
        [ -2.3265,  -0.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22628894448280334
Epoch 0, Step 862: train/loss = 0.2246275097131729, train/raw-loss = 0.11428935825824738, train/logprobs = tensor([[-0.3325, -8.1032],
        [-1.9883, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22067630290985107
Epoch 0, Step 863: train/loss = 0.20480026304721832, train/raw-loss = 0.07786623388528824, train/logprobs = tensor([[-0.3740, -5.8672],
        [-2.3211, -0.3810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253868043422699
Epoch 0, Step 864: train/loss = 0.24366508424282074, train/raw-loss = 0.15144017338752747, train/logprobs = tensor([[-0.3420, -5.8047],
        [-1.3816, -0.6027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18444985151290894
Epoch 0, Step 865: train/loss = 0.21750566363334656, train/raw-loss = 0.12890620529651642, train/logprobs = tensor([[-0.3421, -6.8271],
        [-1.5008, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17719891667366028
Epoch 0, Step 866: train/loss = 0.21899619698524475, train/raw-loss = 0.10255390405654907, train/logprobs = tensor([[-0.3500, -6.6394],
        [-1.8556, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23288461565971375
Epoch 0, Step 867: train/loss = 0.23870228230953217, train/raw-loss = 0.12813755869865417, train/logprobs = tensor([[-0.3680, -5.9888],
        [-1.7053, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22112947702407837
Epoch 0, Step 868: train/loss = 0.19112586975097656, train/raw-loss = 0.08823652565479279, train/logprobs = tensor([[ -0.3685, -11.2171],
        [ -1.9355,  -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20577868819236755
Epoch 0, Step 869: train/loss = 0.16769197583198547, train/raw-loss = 0.05647861957550049, train/logprobs = tensor([[-0.4029, -7.9947],
        [-2.6225, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22242672741413116
Epoch 0, Step 870: train/loss = 0.22324307262897491, train/raw-loss = 0.12593503296375275, train/logprobs = tensor([[-0.2804, -8.5039],
        [-1.5506, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19461610913276672
Epoch 0, Step 871: train/loss = 0.21700407564640045, train/raw-loss = 0.08722048252820969, train/logprobs = tensor([[-0.3141, -6.9151],
        [-2.0122, -0.4664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2595672011375427
Epoch 0, Step 872: train/loss = 0.1999557614326477, train/raw-loss = 0.08880734443664551, train/logprobs = tensor([[-0.4492, -7.6925],
        [-2.2705, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2222968488931656
Epoch 0, Step 873: train/loss = 0.18394780158996582, train/raw-loss = 0.05421127751469612, train/logprobs = tensor([[-0.3504, -7.4572],
        [-2.5624, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594730257987976
Epoch 0, Step 874: train/loss = 0.1867152601480484, train/raw-loss = 0.06702637672424316, train/logprobs = tensor([[-0.3636, -8.2735],
        [-2.2570, -0.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23937776684761047
Epoch 0, Step 875: train/loss = 0.23110516369342804, train/raw-loss = 0.13507018983364105, train/logprobs = tensor([[-0.3037, -7.6027],
        [-1.4403, -0.4907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1920699179172516
Epoch 0, Step 876: train/loss = 0.18404389917850494, train/raw-loss = 0.08210022747516632, train/logprobs = tensor([[ -0.4243, -10.0090],
        [ -2.3766,  -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20388735830783844
Epoch 0, Step 877: train/loss = 0.23445509374141693, train/raw-loss = 0.1481296271085739, train/logprobs = tensor([[-0.3364, -6.8678],
        [-1.3821, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17265091836452484
Epoch 0, Step 878: train/loss = 0.19292187690734863, train/raw-loss = 0.09989266097545624, train/logprobs = tensor([[-0.3380, -7.6905],
        [-1.8473, -1.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1860584318637848
Epoch 0, Step 879: train/loss = 0.21453425288200378, train/raw-loss = 0.09781297296285629, train/logprobs = tensor([[-0.3623, -9.6570],
        [-2.0542, -1.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23344255983829498
Epoch 0, Step 880: train/loss = 0.27889201045036316, train/raw-loss = 0.15719179809093475, train/logprobs = tensor([[-0.5027, -5.6897],
        [-2.0249, -1.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2434004545211792
Epoch 0, Step 881: train/loss = 0.17675825953483582, train/raw-loss = 0.06530800461769104, train/logprobs = tensor([[-0.4395, -7.7226],
        [-2.4184, -0.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22290052473545074
Epoch 0, Step 882: train/loss = 0.2230301797389984, train/raw-loss = 0.10865047574043274, train/logprobs = tensor([[-0.3865, -7.5417],
        [-2.0602, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22875940799713135
Epoch 0, Step 883: train/loss = 0.1786535680294037, train/raw-loss = 0.07734143733978271, train/logprobs = tensor([[-0.3409, -6.6351],
        [-2.4707, -0.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20262424647808075
Epoch 0, Step 884: train/loss = 0.1840055286884308, train/raw-loss = 0.06266546994447708, train/logprobs = tensor([[-0.4399, -8.5442],
        [-2.5580, -0.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2426801323890686
Epoch 0, Step 885: train/loss = 0.21059489250183105, train/raw-loss = 0.11009139567613602, train/logprobs = tensor([[-0.3876, -6.0741],
        [-1.8784, -0.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20100697875022888
Epoch 0, Step 886: train/loss = 0.20827436447143555, train/raw-loss = 0.09919045120477676, train/logprobs = tensor([[ -0.3120, -11.3497],
        [ -1.8212,  -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21816784143447876
Epoch 0, Step 887: train/loss = 0.18289977312088013, train/raw-loss = 0.07121653109788895, train/logprobs = tensor([[-0.4041, -8.1453],
        [-2.4113, -0.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22336648404598236
Epoch 0, Step 888: train/loss = 0.23506613075733185, train/raw-loss = 0.13170690834522247, train/logprobs = tensor([[-0.3329, -6.4313],
        [-1.6900, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20671845972537994
Epoch 0, Step 889: train/loss = 0.20734989643096924, train/raw-loss = 0.0867786705493927, train/logprobs = tensor([[-0.4108, -6.8145],
        [-2.2652, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24114245176315308
Epoch 0, Step 890: train/loss = 0.23843759298324585, train/raw-loss = 0.12944112718105316, train/logprobs = tensor([[-0.3324, -7.8237],
        [-1.6581, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21799291670322418
Epoch 0, Step 891: train/loss = 0.1969480812549591, train/raw-loss = 0.08671005815267563, train/logprobs = tensor([[-0.3232, -8.2295],
        [-1.9521, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22047606110572815
Epoch 0, Step 892: train/loss = 0.216505229473114, train/raw-loss = 0.11245213449001312, train/logprobs = tensor([[-0.3168, -7.2434],
        [-1.6496, -0.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20810621976852417
Epoch 0, Step 893: train/loss = 0.20208051800727844, train/raw-loss = 0.08219677954912186, train/logprobs = tensor([[-0.3192, -8.0638],
        [-2.3079, -0.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23976749181747437
Epoch 0, Step 894: train/loss = 0.20073916018009186, train/raw-loss = 0.09900350868701935, train/logprobs = tensor([[-0.3350, -5.4674],
        [-1.9032, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034713327884674
Epoch 0, Step 895: train/loss = 0.21379771828651428, train/raw-loss = 0.11489842087030411, train/logprobs = tensor([[-0.2954, -8.1021],
        [-1.5852, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19779860973358154
Epoch 0, Step 896: train/loss = 0.1909729540348053, train/raw-loss = 0.09977766871452332, train/logprobs = tensor([[-0.3724, -9.0056],
        [-1.8877, -1.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18239054083824158
Epoch 0, Step 897: train/loss = 0.19304344058036804, train/raw-loss = 0.0974348857998848, train/logprobs = tensor([[-0.3821, -7.4787],
        [-2.0799, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19121713936328888
Epoch 0, Step 898: train/loss = 0.1984570026397705, train/raw-loss = 0.10056322067975998, train/logprobs = tensor([[-0.3912, -7.3957],
        [-1.9709, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19578754901885986
Epoch 0, Step 899: train/loss = 0.20847174525260925, train/raw-loss = 0.1040336862206459, train/logprobs = tensor([[-0.3537, -8.7398],
        [-1.7647, -0.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088761031627655
Epoch 0, Step 900: train/loss = 0.16485166549682617, train/raw-loss = 0.07940573990345001, train/logprobs = tensor([[-0.3880, -8.7200],
        [-2.3762, -1.3562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17089182138442993
Epoch 0, Step 901: train/loss = 0.20375856757164001, train/raw-loss = 0.12073211371898651, train/logprobs = tensor([[-0.3668, -8.9317],
        [-1.5476, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.166052907705307
Epoch 0, Step 902: train/loss = 0.17363932728767395, train/raw-loss = 0.0650501698255539, train/logprobs = tensor([[-0.3618, -7.7681],
        [-2.6016, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21717830002307892
Epoch 0, Step 903: train/loss = 0.19434508681297302, train/raw-loss = 0.09737028181552887, train/logprobs = tensor([[-0.3231, -9.1758],
        [-1.9138, -1.2216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1939496099948883
Epoch 0, Step 904: train/loss = 0.1622854322195053, train/raw-loss = 0.054130494594573975, train/logprobs = tensor([[-0.4197, -9.9715],
        [-2.6337, -1.0513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21630986034870148
Epoch 0, Step 905: train/loss = 0.24352173507213593, train/raw-loss = 0.1386485993862152, train/logprobs = tensor([[-0.3469, -7.3799],
        [-1.4121, -0.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20974624156951904
Epoch 0, Step 906: train/loss = 0.19831164181232452, train/raw-loss = 0.08150583505630493, train/logprobs = tensor([[-0.3445, -7.3298],
        [-2.2575, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23361161351203918
Epoch 0, Step 907: train/loss = 0.22632424533367157, train/raw-loss = 0.13821172714233398, train/logprobs = tensor([[-0.3130, -5.9375],
        [-1.5426, -0.3991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17622500658035278
Epoch 0, Step 908: train/loss = 0.1962418258190155, train/raw-loss = 0.07848458737134933, train/logprobs = tensor([[-0.4712, -8.7199],
        [-2.3434, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23551449179649353
Epoch 0, Step 909: train/loss = 0.1792302131652832, train/raw-loss = 0.08327799290418625, train/logprobs = tensor([[-0.5404, -6.9007],
        [-2.2367, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1919044554233551
Epoch 0, Step 910: train/loss = 0.17361944913864136, train/raw-loss = 0.07754790782928467, train/logprobs = tensor([[-0.4305, -8.0490],
        [-2.3750, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19214306771755219
Epoch 0, Step 911: train/loss = 0.21592512726783752, train/raw-loss = 0.09384119510650635, train/logprobs = tensor([[-0.4134, -7.0237],
        [-2.1670, -0.4191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24416786432266235
Epoch 0, Step 912: train/loss = 0.2049531638622284, train/raw-loss = 0.09170078486204147, train/logprobs = tensor([[-0.4281, -9.7406],
        [-1.9542, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22650477290153503
Epoch 0, Step 913: train/loss = 0.18680459260940552, train/raw-loss = 0.07701056450605392, train/logprobs = tensor([[-0.3344, -6.8456],
        [-2.1333, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21958807110786438
Epoch 0, Step 914: train/loss = 0.20618680119514465, train/raw-loss = 0.1040511429309845, train/logprobs = tensor([[-0.3400, -7.4014],
        [-1.8415, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042713314294815
Epoch 0, Step 915: train/loss = 0.20737618207931519, train/raw-loss = 0.08597667515277863, train/logprobs = tensor([[-0.4036, -6.9955],
        [-2.0836, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24279901385307312
Epoch 0, Step 916: train/loss = 0.19892704486846924, train/raw-loss = 0.08159749209880829, train/logprobs = tensor([[-0.3572, -8.3181],
        [-2.1165, -0.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2346591055393219
Epoch 0, Step 917: train/loss = 0.21087022125720978, train/raw-loss = 0.09524175524711609, train/logprobs = tensor([[-0.3551, -7.5122],
        [-1.9799, -0.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23125693202018738
Epoch 0, Step 918: train/loss = 0.20127536356449127, train/raw-loss = 0.0924525335431099, train/logprobs = tensor([[-0.3440, -9.6541],
        [-1.9727, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21764564514160156
Epoch 0, Step 919: train/loss = 0.22808487713336945, train/raw-loss = 0.13116444647312164, train/logprobs = tensor([[-0.4102, -8.2969],
        [-1.5754, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1938408464193344
Epoch 0, Step 920: train/loss = 0.24314138293266296, train/raw-loss = 0.13837870955467224, train/logprobs = tensor([[-0.3123, -6.9443],
        [-1.5715, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20952534675598145
Epoch 0, Step 921: train/loss = 0.18551889061927795, train/raw-loss = 0.08156648278236389, train/logprobs = tensor([[-0.3884, -8.0939],
        [-2.2869, -1.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079048454761505
Epoch 0, Step 922: train/loss = 0.19313564896583557, train/raw-loss = 0.09659823775291443, train/logprobs = tensor([[-0.3710, -9.3891],
        [-1.9685, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19307485222816467
Epoch 0, Step 923: train/loss = 0.2116336226463318, train/raw-loss = 0.11799062043428421, train/logprobs = tensor([[-0.3066, -7.9960],
        [-1.6002, -1.1319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18728601932525635
Epoch 0, Step 924: train/loss = 0.17490321397781372, train/raw-loss = 0.07915423065423965, train/logprobs = tensor([[-0.4199, -7.0241],
        [-2.2202, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19149793684482574
Epoch 0, Step 925: train/loss = 0.19031374156475067, train/raw-loss = 0.07250015437602997, train/logprobs = tensor([[-0.3494, -4.8527],
        [-2.5212, -0.3050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23562714457511902
Epoch 0, Step 926: train/loss = 0.18558134138584137, train/raw-loss = 0.07016317546367645, train/logprobs = tensor([[-0.4514, -8.9152],
        [-2.3449, -0.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23083631694316864
Epoch 0, Step 927: train/loss = 0.17409418523311615, train/raw-loss = 0.06996273994445801, train/logprobs = tensor([[-0.3320, -6.9658],
        [-2.4092, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20826289057731628
Epoch 0, Step 928: train/loss = 0.21983352303504944, train/raw-loss = 0.12404249608516693, train/logprobs = tensor([[-0.3410, -7.3579],
        [-1.7346, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19158205389976501
Epoch 0, Step 929: train/loss = 0.21221107244491577, train/raw-loss = 0.12207186222076416, train/logprobs = tensor([[-0.3127, -6.5267],
        [-1.6136, -1.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18027843534946442
Epoch 0, Step 930: train/loss = 0.20474788546562195, train/raw-loss = 0.0978105291724205, train/logprobs = tensor([[-0.3515, -7.9563],
        [-1.8790, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2138747125864029
Epoch 0, Step 931: train/loss = 0.23266445100307465, train/raw-loss = 0.14349152147769928, train/logprobs = tensor([[-0.3570, -7.2816],
        [-1.4951, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17834587395191193
Epoch 0, Step 932: train/loss = 0.23860839009284973, train/raw-loss = 0.1453171819448471, train/logprobs = tensor([[-0.2931, -6.1355],
        [-1.5212, -0.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18658241629600525
Epoch 0, Step 933: train/loss = 0.19478631019592285, train/raw-loss = 0.08671969175338745, train/logprobs = tensor([[-0.3708, -8.9291],
        [-2.1157, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2161332368850708
Epoch 0, Step 934: train/loss = 0.18824666738510132, train/raw-loss = 0.0904196947813034, train/logprobs = tensor([[-0.4003, -6.5655],
        [-2.1814, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19565394520759583
Epoch 0, Step 935: train/loss = 0.17414726316928864, train/raw-loss = 0.05616302043199539, train/logprobs = tensor([[-0.3222, -8.7302],
        [-2.4843, -1.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359684854745865
Epoch 0, Step 936: train/loss = 0.2029939591884613, train/raw-loss = 0.0882684737443924, train/logprobs = tensor([[ -0.2936, -10.5296],
        [ -1.9191,  -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22945095598697662
Epoch 0, Step 937: train/loss = 0.2109351009130478, train/raw-loss = 0.09940552711486816, train/logprobs = tensor([[-0.4420, -6.9120],
        [-2.0951, -0.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22305914759635925
Epoch 0, Step 938: train/loss = 0.20449161529541016, train/raw-loss = 0.10671306401491165, train/logprobs = tensor([[-0.3280, -9.6850],
        [-1.7135, -0.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.195557102560997
Epoch 0, Step 939: train/loss = 0.20579680800437927, train/raw-loss = 0.10521773993968964, train/logprobs = tensor([[-0.3484, -7.4791],
        [-1.8192, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20115812122821808
Epoch 0, Step 940: train/loss = 0.20080974698066711, train/raw-loss = 0.10035091638565063, train/logprobs = tensor([[-0.3625, -5.0558],
        [-1.8911, -0.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20091766119003296
Epoch 0, Step 941: train/loss = 0.2696682810783386, train/raw-loss = 0.17479568719863892, train/logprobs = tensor([[-0.3600, -5.4690],
        [-1.5442, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897452026605606
Epoch 0, Step 942: train/loss = 0.21636131405830383, train/raw-loss = 0.11004012823104858, train/logprobs = tensor([[-0.3099, -6.4437],
        [-1.7074, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126423418521881
Epoch 0, Step 943: train/loss = 0.17913299798965454, train/raw-loss = 0.06430140882730484, train/logprobs = tensor([[-0.3638, -6.9652],
        [-2.4695, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296631932258606
Epoch 0, Step 944: train/loss = 0.2017737329006195, train/raw-loss = 0.1243656575679779, train/logprobs = tensor([[-0.2667, -5.4870],
        [-1.5886, -1.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1548161506652832
Epoch 0, Step 945: train/loss = 0.2280139923095703, train/raw-loss = 0.1386050134897232, train/logprobs = tensor([[-0.2954, -6.3427],
        [-1.7062, -1.3590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17881794273853302
Epoch 0, Step 946: train/loss = 0.22016122937202454, train/raw-loss = 0.1213463693857193, train/logprobs = tensor([[-0.2678, -8.5768],
        [-1.4875, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19762969017028809
Epoch 0, Step 947: train/loss = 0.18185198307037354, train/raw-loss = 0.06774736195802689, train/logprobs = tensor([[-0.3793, -6.6452],
        [-2.4003, -0.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2282092273235321
Epoch 0, Step 948: train/loss = 0.17810097336769104, train/raw-loss = 0.0745295062661171, train/logprobs = tensor([[ -0.3542, -10.3069],
        [ -2.1816,  -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2071429342031479
Epoch 0, Step 949: train/loss = 0.20091134309768677, train/raw-loss = 0.10677006840705872, train/logprobs = tensor([[-0.3196, -8.5909],
        [-1.7066, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1882825642824173
Epoch 0, Step 950: train/loss = 0.20166116952896118, train/raw-loss = 0.10689723491668701, train/logprobs = tensor([[-0.2893, -8.8270],
        [-1.7099, -1.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18952783942222595
Epoch 0, Step 951: train/loss = 0.19525234401226044, train/raw-loss = 0.09197236597537994, train/logprobs = tensor([[-0.3063, -7.5754],
        [-1.8406, -0.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.206559956073761
Epoch 0, Step 952: train/loss = 0.20528826117515564, train/raw-loss = 0.11085738986730576, train/logprobs = tensor([[-0.3098, -5.4429],
        [-2.0831, -0.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18886174261569977
Epoch 0, Step 953: train/loss = 0.2515679895877838, train/raw-loss = 0.16974203288555145, train/logprobs = tensor([[-0.2478, -5.6924],
        [-1.0451, -0.7475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16365191340446472
Epoch 0, Step 954: train/loss = 0.21347317099571228, train/raw-loss = 0.11827526241540909, train/logprobs = tensor([[-0.2968, -8.1873],
        [-1.6625, -0.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1903958022594452
Epoch 0, Step 955: train/loss = 0.19342675805091858, train/raw-loss = 0.09597646445035934, train/logprobs = tensor([[ -0.4680, -10.0241],
        [ -2.0205,  -1.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19490058720111847
Epoch 0, Step 956: train/loss = 0.190881609916687, train/raw-loss = 0.07813304662704468, train/logprobs = tensor([[-0.3430, -7.4077],
        [-2.2037, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22549709677696228
Epoch 0, Step 957: train/loss = 0.18037286400794983, train/raw-loss = 0.05153489112854004, train/logprobs = tensor([[-0.3180, -6.5955],
        [-2.5640, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576759457588196
Epoch 0, Step 958: train/loss = 0.1864709109067917, train/raw-loss = 0.09020290523767471, train/logprobs = tensor([[-0.3421, -5.3562],
        [-2.3236, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19253599643707275
Epoch 0, Step 959: train/loss = 0.2149561047554016, train/raw-loss = 0.10162655264139175, train/logprobs = tensor([[-0.3040, -6.9641],
        [-1.8832, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2266591191291809
Epoch 0, Step 960: train/loss = 0.20606078207492828, train/raw-loss = 0.09652813524007797, train/logprobs = tensor([[-0.4719, -6.4421],
        [-2.0352, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21906530857086182
Epoch 0, Step 961: train/loss = 0.22504301369190216, train/raw-loss = 0.12161853909492493, train/logprobs = tensor([[-0.3358, -6.8574],
        [-1.6591, -1.4901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20684897899627686
Epoch 0, Step 962: train/loss = 0.1835920512676239, train/raw-loss = 0.07092268764972687, train/logprobs = tensor([[ -0.4477, -11.8814],
        [ -2.3498,  -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22533874213695526
Epoch 0, Step 963: train/loss = 0.22804823517799377, train/raw-loss = 0.12206170707941055, train/logprobs = tensor([[-0.3236, -7.2314],
        [-1.8073, -0.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21197301149368286
Epoch 0, Step 964: train/loss = 0.19918470084667206, train/raw-loss = 0.08740018308162689, train/logprobs = tensor([[-0.4016, -8.9654],
        [-2.1861, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22356903553009033
Epoch 0, Step 965: train/loss = 0.1939331293106079, train/raw-loss = 0.0914684385061264, train/logprobs = tensor([[-0.4186, -6.0768],
        [-2.1462, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20492936670780182
Epoch 0, Step 966: train/loss = 0.22947388887405396, train/raw-loss = 0.13042181730270386, train/logprobs = tensor([[-0.4024, -5.7053],
        [-1.7704, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1981041431427002
Epoch 0, Step 967: train/loss = 0.21557402610778809, train/raw-loss = 0.11140736937522888, train/logprobs = tensor([[-0.2856, -7.2108],
        [-1.6107, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2083333134651184
Epoch 0, Step 968: train/loss = 0.18354204297065735, train/raw-loss = 0.09048314392566681, train/logprobs = tensor([[-0.4370, -9.7597],
        [-2.6087, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18611781299114227
Epoch 0, Step 969: train/loss = 0.18309453129768372, train/raw-loss = 0.06945739686489105, train/logprobs = tensor([[-0.3698, -6.5780],
        [-2.4251, -0.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22727429866790771
Epoch 0, Step 970: train/loss = 0.23818576335906982, train/raw-loss = 0.13717731833457947, train/logprobs = tensor([[-0.3550, -6.5283],
        [-1.4510, -1.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2020168900489807
Epoch 0, Step 971: train/loss = 0.21261365711688995, train/raw-loss = 0.09938828647136688, train/logprobs = tensor([[-0.3474, -5.7224],
        [-2.0911, -0.7860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22645075619220734
Epoch 0, Step 972: train/loss = 0.15718258917331696, train/raw-loss = 0.054231952875852585, train/logprobs = tensor([[-0.3461, -8.6388],
        [-2.4988, -0.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20590126514434814
Epoch 0, Step 973: train/loss = 0.19210420548915863, train/raw-loss = 0.10654999315738678, train/logprobs = tensor([[-0.3826, -7.7462],
        [-1.7489, -1.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1711084246635437
Epoch 0, Step 974: train/loss = 0.2080291211605072, train/raw-loss = 0.11263860762119293, train/logprobs = tensor([[-0.4141, -9.9617],
        [-2.7541, -1.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19078105688095093
Epoch 0, Step 975: train/loss = 0.16376832127571106, train/raw-loss = 0.055917929857969284, train/logprobs = tensor([[-0.3600, -9.4246],
        [-2.6806, -0.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21570079028606415
Epoch 0, Step 976: train/loss = 0.16122660040855408, train/raw-loss = 0.03920961916446686, train/logprobs = tensor([[-0.4022, -8.8507],
        [-2.8812, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24403393268585205
Epoch 0, Step 977: train/loss = 0.19443804025650024, train/raw-loss = 0.0974186509847641, train/logprobs = tensor([[-0.4333, -8.1134],
        [-2.0800, -1.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19403879344463348
Epoch 0, Step 978: train/loss = 0.22810497879981995, train/raw-loss = 0.12778359651565552, train/logprobs = tensor([[-0.3463, -7.6706],
        [-1.6465, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20064276456832886
Epoch 0, Step 979: train/loss = 0.2282949984073639, train/raw-loss = 0.1315232664346695, train/logprobs = tensor([[-0.4189, -6.4847],
        [-1.6716, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1935434639453888
Epoch 0, Step 980: train/loss = 0.1840716302394867, train/raw-loss = 0.07665330171585083, train/logprobs = tensor([[ -0.3368, -11.2951],
        [ -2.1586,  -1.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21483667194843292
Epoch 0, Step 981: train/loss = 0.28550955653190613, train/raw-loss = 0.19803926348686218, train/logprobs = tensor([[-0.2992, -4.4264],
        [-1.1630, -1.1567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1749405711889267
Epoch 0, Step 982: train/loss = 0.22132357954978943, train/raw-loss = 0.14474868774414062, train/logprobs = tensor([[ -0.3170, -10.6413],
        [ -1.2676,  -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1531497985124588
Epoch 0, Step 983: train/loss = 0.196183979511261, train/raw-loss = 0.07581467181444168, train/logprobs = tensor([[-0.3427, -5.3361],
        [-2.2229, -0.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2407386302947998
Epoch 0, Step 984: train/loss = 0.19622178375720978, train/raw-loss = 0.09226059913635254, train/logprobs = tensor([[-0.3848, -6.7054],
        [-2.2191, -0.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20792239904403687
Epoch 0, Step 985: train/loss = 0.1918661892414093, train/raw-loss = 0.08237220346927643, train/logprobs = tensor([[-0.4001, -8.0758],
        [-2.6270, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21898797154426575
Epoch 0, Step 986: train/loss = 0.17129498720169067, train/raw-loss = 0.05630400776863098, train/logprobs = tensor([[-0.3716, -7.0284],
        [-2.7095, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22998198866844177
Epoch 0, Step 987: train/loss = 0.20043714344501495, train/raw-loss = 0.09507077932357788, train/logprobs = tensor([[-0.3765, -7.5086],
        [-1.8881, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21073272824287415
Epoch 0, Step 988: train/loss = 0.20945921540260315, train/raw-loss = 0.10832004249095917, train/logprobs = tensor([[-0.3665, -7.4182],
        [-1.7186, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20227833092212677
Epoch 0, Step 989: train/loss = 0.17635232210159302, train/raw-loss = 0.09036426246166229, train/logprobs = tensor([[-0.4249, -7.9850],
        [-2.5983, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17197611927986145
Epoch 0, Step 990: train/loss = 0.21450473368167877, train/raw-loss = 0.11254947632551193, train/logprobs = tensor([[-0.3402, -9.3621],
        [-1.6679, -1.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20391051471233368
Epoch 0, Step 991: train/loss = 0.1872490644454956, train/raw-loss = 0.06433549523353577, train/logprobs = tensor([[-0.3515, -7.3535],
        [-2.4370, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24582716822624207
Epoch 0, Step 992: train/loss = 0.1959490180015564, train/raw-loss = 0.0813019648194313, train/logprobs = tensor([[-0.3924, -8.5058],
        [-2.4263, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22929415106773376
Epoch 0, Step 993: train/loss = 0.18948182463645935, train/raw-loss = 0.0804908275604248, train/logprobs = tensor([[-0.3293, -8.5213],
        [-2.1781, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21798202395439148
Epoch 0, Step 994: train/loss = 0.222792387008667, train/raw-loss = 0.11030031740665436, train/logprobs = tensor([[-0.3788, -5.9643],
        [-1.7878, -0.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22498416900634766
Epoch 0, Step 995: train/loss = 0.16888830065727234, train/raw-loss = 0.053297437727451324, train/logprobs = tensor([[-0.4827, -9.4650],
        [-2.7053, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23118172585964203
Epoch 0, Step 996: train/loss = 0.2594382166862488, train/raw-loss = 0.16403251886367798, train/logprobs = tensor([[-0.2434, -7.4385],
        [-1.1182, -0.5349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1908113807439804
Epoch 0, Step 997: train/loss = 0.22088028490543365, train/raw-loss = 0.12692640721797943, train/logprobs = tensor([[-0.3483, -7.8633],
        [-1.5305, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18790775537490845
Epoch 0, Step 998: train/loss = 0.1772729605436325, train/raw-loss = 0.08266836404800415, train/logprobs = tensor([[-0.3636, -8.6241],
        [-2.1104, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1892091929912567
Epoch 0, Step 999: train/loss = 0.15869656205177307, train/raw-loss = 0.06333315372467041, train/logprobs = tensor([[-0.6099, -8.5359],
        [-3.3864, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19072681665420532
