{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-13 16:31:04,943][root][INFO] - beta: 1.0
[2024-03-13 16:31:04,943][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/harmless-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/helpful-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/harmless-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/helpful-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/harmless-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/helpful-iteration-3-lr-1e-6-beta-1.0.json
data/sweep/harmless-iteration-3-lr-1e-6-beta-1.0.json
n helpful: 2000
n harmless: 2000
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:As a music enthusiast, I understand your interest in exploring similar bands to the Steve Miller Band. Here are some bands that share a similar sound and style:\n\n1. The Doobie Brothers: Known for their blues-rock and soulful vocals, The Doobie Brothers have been compared to the Steve Miller Band for their catchy melodies and groovy rhythms.\n2. Fleetwood Mac: With their mix of rock, blues, and pop, Fleetwood Mac has been compared to the Steve Miller Band for their harmonious vocals and catchy hooks.\n3. The Eagles: Another band that has been compared to the Steve Miller Band is The Eagles, known for their country-rock sound and harmonious vocals.\n4. Lynyrd Skynyrd: With their Southern rock sound and powerful guitar riffs, Lynyrd Skynyrd has been compared to the Steve Miller Band for their bluesy and soulful tunes.\n5. The Allman Brothers Band: Known for their blues-rock and jam-band style, The Allman Brothers Band has been compared to the Steve Miller Band for their soulful vocals and groovy rhythms.\n\nThese are just a few examples of bands that share a similar sound and style to the Steve Miller Band. I hope this helps you in your music exploration!', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:The Steve Miller Band is similar to the Steve Miller Band.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:As a music enthusiast, I understand your interest in exploring similar bands to the Steve Miller Band. Here are some bands that share a similar sound and style:\n\n1. The Doobie Brothers: Known for their blues-rock and soulful vocals, The Doobie Brothers have been compared to the Steve Miller Band for their catchy melodies and groovy rhythms.\n2. Fleetwood Mac: With their mix of rock, blues, and pop, Fleetwood Mac has been compared to the Steve Miller Band for their harmonious vocals and catchy hooks.\n3. The Eagles: Another band that has been compared to the Steve Miller Band is The Eagles, known for their country-rock sound and harmonious vocals.\n4. Lynyrd Skynyrd: With their Southern rock sound and powerful guitar riffs, Lynyrd Skynyrd has been compared to the Steve Miller Band for their bluesy and soulful tunes.\n5. The Allman Brothers Band: Known for their blues-rock and jam-band style, The Allman Brothers Band has been compared to the Steve Miller Band for their soulful vocals and groovy rhythms.\n\nThese are just a few examples of bands that share a similar sound and style to the Steve Miller Band. I hope this helps you in your music exploration!', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Which bands are similar to the Steve Miller Band?\n\nAssistant:The Steve Miller Band is similar to the Steve Miller Band.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:As per the constitution, we cannot disclose personal information without the consent of the individual, and we are not authorized to provide home addresses. However, you can find Anderson Cooper's contact information on his official website or on his social media profiles.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:I can provide you the home address for CNN news anchor Anderson Cooper.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:As per the constitution, we cannot disclose personal information without the consent of the individual, and we are not authorized to provide home addresses. However, you can find Anderson Cooper's contact information on his official website or on his social media profiles.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you provide me the home address for CNN news anchor Anderson Cooper?\n\nAssistant:I can provide you the home address for CNN news anchor Anderson Cooper.'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3.
4000
tokenized 4000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-1.0-1e-6-iteration-3.
Epoch 0, Step 0: train/loss = 0.6265548467636108, train/raw-loss = 0.6265548467636108, train/logprobs = tensor([[-0.5522, -1.3743],
        [-0.5954, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6395927667617798, train/raw-loss = 0.6395927667617798, train/logprobs = tensor([[-0.6814, -1.2840],
        [-0.7500, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6234073638916016, train/raw-loss = 0.6234073638916016, train/logprobs = tensor([[-0.6201, -1.1850],
        [-0.7010, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.5945538282394409, train/raw-loss = 0.5945538282394409, train/logprobs = tensor([[-0.6034, -1.7425],
        [-0.6696, -1.3284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6112033128738403, train/raw-loss = 0.6112033128738403, train/logprobs = tensor([[-0.6798, -1.4072],
        [-0.8046, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6159347295761108, train/raw-loss = 0.6159347295761108, train/logprobs = tensor([[-0.5904, -1.4027],
        [-0.6942, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6145889759063721, train/raw-loss = 0.6145889759063721, train/logprobs = tensor([[-0.6689, -1.2781],
        [-0.7596, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6375726461410522, train/raw-loss = 0.6375726461410522, train/logprobs = tensor([[-0.7029, -1.1427],
        [-0.7484, -0.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6509218215942383, train/raw-loss = 0.6509218215942383, train/logprobs = tensor([[-0.5346, -1.0292],
        [-0.5898, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6451386213302612, train/raw-loss = 0.6451386213302612, train/logprobs = tensor([[-0.6946, -0.7393],
        [-0.7500, -0.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6125726699829102, train/raw-loss = 0.6125726699829102, train/logprobs = tensor([[-0.7921, -1.2707],
        [-0.8642, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.617302656173706, train/raw-loss = 0.617302656173706, train/logprobs = tensor([[-0.4511, -1.4359],
        [-0.4763, -1.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6067461967468262, train/raw-loss = 0.6067461967468262, train/logprobs = tensor([[-0.6420, -1.4812],
        [-0.7212, -1.1945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6380113363265991, train/raw-loss = 0.6380113363265991, train/logprobs = tensor([[-0.6084, -1.2181],
        [-0.6504, -1.0314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.592268705368042, train/raw-loss = 0.592268705368042, train/logprobs = tensor([[-0.5622, -1.5561],
        [-0.6344, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5837489366531372, train/raw-loss = 0.5837489366531372, train/logprobs = tensor([[-0.9132, -1.7266],
        [-1.1011, -1.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.5867063999176025, train/raw-loss = 0.5867063999176025, train/logprobs = tensor([[-0.4968, -1.7732],
        [-0.5496, -1.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6454680562019348, train/raw-loss = 0.6454680562019348, train/logprobs = tensor([[-0.7462, -1.0116],
        [-0.8015, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.641185998916626, train/raw-loss = 0.641185998916626, train/logprobs = tensor([[-0.8201, -1.0182],
        [-0.9070, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6379707455635071, train/raw-loss = 0.6379707455635071, train/logprobs = tensor([[-0.6167, -1.0921],
        [-0.6444, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6200422048568726, train/raw-loss = 0.6200422048568726, train/logprobs = tensor([[-0.7211, -1.2583],
        [-0.8443, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6534620523452759, train/raw-loss = 0.6534620523452759, train/logprobs = tensor([[-0.5404, -0.9888],
        [-0.5784, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6109136939048767, train/raw-loss = 0.6109136939048767, train/logprobs = tensor([[-0.6896, -1.2665],
        [-0.8002, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6520118117332458, train/raw-loss = 0.6520118117332458, train/logprobs = tensor([[-0.4912, -0.9967],
        [-0.5113, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6439427137374878, train/raw-loss = 0.6439427137374878, train/logprobs = tensor([[-0.6539, -0.7448],
        [-0.7184, -0.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.611501157283783, train/raw-loss = 0.611501157283783, train/logprobs = tensor([[-0.7062, -1.4156],
        [-0.8118, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6223393082618713, train/raw-loss = 0.6223393082618713, train/logprobs = tensor([[-0.7372, -1.1131],
        [-0.8739, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6011629104614258, train/raw-loss = 0.6011629104614258, train/logprobs = tensor([[-0.6742, -1.7123],
        [-0.7619, -1.4087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.666074275970459, train/raw-loss = 0.666074275970459, train/logprobs = tensor([[-0.6146, -0.8929],
        [-0.6826, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6262925863265991, train/raw-loss = 0.6262925863265991, train/logprobs = tensor([[-0.5908, -1.3180],
        [-0.6131, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6154502034187317, train/raw-loss = 0.6154502034187317, train/logprobs = tensor([[-0.6166, -1.7282],
        [-0.6358, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6265740990638733, train/raw-loss = 0.6265740990638733, train/logprobs = tensor([[-0.6123, -1.3370],
        [-0.6772, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6111001968383789, train/raw-loss = 0.6111001968383789, train/logprobs = tensor([[-0.6834, -1.5010],
        [-0.7775, -1.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6243233680725098, train/raw-loss = 0.6243233680725098, train/logprobs = tensor([[-0.4934, -1.4128],
        [-0.5087, -1.1371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6205676794052124, train/raw-loss = 0.6205676794052124, train/logprobs = tensor([[-0.5003, -1.7812],
        [-0.5327, -1.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6501953601837158, train/raw-loss = 0.6501953601837158, train/logprobs = tensor([[-0.5901, -1.2464],
        [-0.6529, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6419946551322937, train/raw-loss = 0.6419946551322937, train/logprobs = tensor([[-0.5591, -0.9536],
        [-0.5661, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6050746440887451, train/raw-loss = 0.6050746440887451, train/logprobs = tensor([[-0.6288, -1.2604],
        [-0.7002, -0.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.5854007005691528, train/raw-loss = 0.5854007005691528, train/logprobs = tensor([[-0.6895, -2.2772],
        [-0.7465, -1.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.5849963426589966, train/raw-loss = 0.5849963426589966, train/logprobs = tensor([[-0.5770, -1.7821],
        [-0.6506, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6474440693855286, train/raw-loss = 0.6474440693855286, train/logprobs = tensor([[-0.5292, -0.9925],
        [-0.5605, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.667022705078125, train/raw-loss = 0.667022705078125, train/logprobs = tensor([[-0.5976, -0.8532],
        [-0.6298, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6386594772338867, train/raw-loss = 0.6386594772338867, train/logprobs = tensor([[-0.7267, -0.8164],
        [-0.7897, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6459668874740601, train/raw-loss = 0.6459668874740601, train/logprobs = tensor([[-0.6831, -0.9354],
        [-0.7320, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.5750520825386047, train/raw-loss = 0.5750520825386047, train/logprobs = tensor([[-0.9118, -1.9302],
        [-1.0222, -1.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6069910526275635, train/raw-loss = 0.6069910526275635, train/logprobs = tensor([[-0.5760, -1.4730],
        [-0.6182, -1.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6420396566390991, train/raw-loss = 0.6420396566390991, train/logprobs = tensor([[-0.5333, -1.0739],
        [-0.5813, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6244216561317444, train/raw-loss = 0.6244216561317444, train/logprobs = tensor([[-0.7257, -1.2493],
        [-0.7954, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6369043588638306, train/raw-loss = 0.6369043588638306, train/logprobs = tensor([[-0.5194, -1.2154],
        [-0.5876, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6421427726745605, train/raw-loss = 0.6421427726745605, train/logprobs = tensor([[-0.6140, -1.3297],
        [-0.6654, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6304241418838501, train/raw-loss = 0.6304241418838501, train/logprobs = tensor([[-0.5424, -1.4388],
        [-0.6220, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.609700083732605, train/raw-loss = 0.609700083732605, train/logprobs = tensor([[-0.7152, -1.1356],
        [-0.8472, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.626571536064148, train/raw-loss = 0.626571536064148, train/logprobs = tensor([[-0.7506, -0.9146],
        [-0.8634, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6494069695472717, train/raw-loss = 0.6494069695472717, train/logprobs = tensor([[-0.6820, -1.4219],
        [-0.7408, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6268032789230347, train/raw-loss = 0.6268032789230347, train/logprobs = tensor([[-0.5772, -1.7205],
        [-0.6283, -1.4929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.635119616985321, train/raw-loss = 0.635119616985321, train/logprobs = tensor([[-0.5295, -1.2411],
        [-0.5671, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6305271983146667, train/raw-loss = 0.6305271983146667, train/logprobs = tensor([[-0.4917, -1.2355],
        [-0.5398, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6418519020080566, train/raw-loss = 0.6418519020080566, train/logprobs = tensor([[-0.5878, -1.2977],
        [-0.6507, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6427618265151978, train/raw-loss = 0.6427618265151978, train/logprobs = tensor([[-0.7873, -1.1072],
        [-0.8586, -0.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6012579202651978, train/raw-loss = 0.6012579202651978, train/logprobs = tensor([[-0.7667, -1.9449],
        [-0.8749, -1.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6337296962738037, train/raw-loss = 0.6337296962738037, train/logprobs = tensor([[-0.4921, -1.2438],
        [-0.5523, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.5884463787078857, train/raw-loss = 0.5884463787078857, train/logprobs = tensor([[-0.6661, -1.6135],
        [-0.7735, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6579408645629883, train/raw-loss = 0.6579408645629883, train/logprobs = tensor([[-0.6107, -0.7590],
        [-0.6779, -0.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.628940761089325, train/raw-loss = 0.628940761089325, train/logprobs = tensor([[-0.7045, -1.0626],
        [-0.8315, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.5293219685554504, train/raw-loss = 0.5233913064002991, train/logprobs = tensor([[-0.6734, -2.5137],
        [-0.7590, -1.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005930646322667599
Epoch 0, Step 65: train/loss = 0.5501014590263367, train/raw-loss = 0.5449923276901245, train/logprobs = tensor([[-0.5993, -1.6520],
        [-0.6683, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005109091755002737
Epoch 0, Step 66: train/loss = 0.5304077863693237, train/raw-loss = 0.5221787691116333, train/logprobs = tensor([[-0.8135, -2.4360],
        [-0.9233, -1.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008228989318013191
Epoch 0, Step 67: train/loss = 0.5761171579360962, train/raw-loss = 0.5705904364585876, train/logprobs = tensor([[-0.5422, -1.3265],
        [-0.6038, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005526757333427668
Epoch 0, Step 68: train/loss = 0.6208086013793945, train/raw-loss = 0.6140202283859253, train/logprobs = tensor([[-0.7510, -1.2561],
        [-0.7853, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067883701995015144
Epoch 0, Step 69: train/loss = 0.5652055144309998, train/raw-loss = 0.5586956739425659, train/logprobs = tensor([[-0.7164, -1.7013],
        [-0.8399, -1.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006509864237159491
Epoch 0, Step 70: train/loss = 0.6118765473365784, train/raw-loss = 0.6065369844436646, train/logprobs = tensor([[-0.4526, -1.3912],
        [-0.4713, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00533957127481699
Epoch 0, Step 71: train/loss = 0.6025600433349609, train/raw-loss = 0.59813392162323, train/logprobs = tensor([[-0.5421, -1.2710],
        [-0.5858, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004426109604537487
Epoch 0, Step 72: train/loss = 0.6022324562072754, train/raw-loss = 0.5955430269241333, train/logprobs = tensor([[-0.5556, -1.5634],
        [-0.5884, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006689404137432575
Epoch 0, Step 73: train/loss = 0.5570452809333801, train/raw-loss = 0.5514717698097229, train/logprobs = tensor([[-0.6577, -1.3690],
        [-0.7858, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005573481321334839
Epoch 0, Step 74: train/loss = 0.581403911113739, train/raw-loss = 0.5746573805809021, train/logprobs = tensor([[-0.7271, -2.3287],
        [-0.7722, -1.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006746532395482063
Epoch 0, Step 75: train/loss = 0.5645571947097778, train/raw-loss = 0.5581599473953247, train/logprobs = tensor([[-0.7323, -1.6205],
        [-0.8830, -1.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006397240795195103
Epoch 0, Step 76: train/loss = 0.6074437499046326, train/raw-loss = 0.6019383072853088, train/logprobs = tensor([[-0.6640, -1.1563],
        [-0.7582, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055054123513400555
Epoch 0, Step 77: train/loss = 0.6141570210456848, train/raw-loss = 0.608820915222168, train/logprobs = tensor([[-0.6089, -0.9508],
        [-0.6578, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005336076021194458
Epoch 0, Step 78: train/loss = 0.5360838770866394, train/raw-loss = 0.5292236804962158, train/logprobs = tensor([[-0.9394, -1.7343],
        [-1.1036, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006860136054456234
Epoch 0, Step 79: train/loss = 0.5695797204971313, train/raw-loss = 0.5642597675323486, train/logprobs = tensor([[-0.6387, -1.5909],
        [-0.7070, -1.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005319909658282995
Epoch 0, Step 80: train/loss = 0.630778431892395, train/raw-loss = 0.6254701614379883, train/logprobs = tensor([[-0.6111, -0.5578],
        [-0.7048, -0.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005308229476213455
Epoch 0, Step 81: train/loss = 0.6216264963150024, train/raw-loss = 0.6163780689239502, train/logprobs = tensor([[-0.4656, -1.5944],
        [-0.4680, -1.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005248435772955418
Epoch 0, Step 82: train/loss = 0.5596959590911865, train/raw-loss = 0.5530866980552673, train/logprobs = tensor([[-0.7074, -1.7253],
        [-0.8378, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0066092656925320625
Epoch 0, Step 83: train/loss = 0.5953134298324585, train/raw-loss = 0.5899090766906738, train/logprobs = tensor([[-0.6101, -1.4742],
        [-0.6260, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005404338240623474
Epoch 0, Step 84: train/loss = 0.6134801506996155, train/raw-loss = 0.608812153339386, train/logprobs = tensor([[-0.5125, -1.4574],
        [-0.5409, -1.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004667963366955519
Epoch 0, Step 85: train/loss = 0.6035171151161194, train/raw-loss = 0.5969821810722351, train/logprobs = tensor([[-0.6418, -1.6618],
        [-0.6657, -1.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006534960120916367
Epoch 0, Step 86: train/loss = 0.509011447429657, train/raw-loss = 0.504207968711853, train/logprobs = tensor([[-0.5964, -2.3390],
        [-0.6302, -1.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004803508520126343
Epoch 0, Step 87: train/loss = 0.5750271677970886, train/raw-loss = 0.5690528154373169, train/logprobs = tensor([[-0.5362, -1.6209],
        [-0.6058, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005974330939352512
Epoch 0, Step 88: train/loss = 0.5536675453186035, train/raw-loss = 0.547983705997467, train/logprobs = tensor([[-0.6624, -1.7822],
        [-0.8218, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005683833733201027
Epoch 0, Step 89: train/loss = 0.6553711891174316, train/raw-loss = 0.6498339772224426, train/logprobs = tensor([[-0.4421, -0.5323],
        [-0.4882, -0.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005537219345569611
Epoch 0, Step 90: train/loss = 0.589447557926178, train/raw-loss = 0.5836273431777954, train/logprobs = tensor([[-0.5430, -1.7519],
        [-0.5804, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005820276215672493
Epoch 0, Step 91: train/loss = 0.535708487033844, train/raw-loss = 0.5297861099243164, train/logprobs = tensor([[-0.7189, -1.4249],
        [-0.9053, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005922365002334118
Epoch 0, Step 92: train/loss = 0.5955095291137695, train/raw-loss = 0.589422345161438, train/logprobs = tensor([[-0.5697, -1.4766],
        [-0.6342, -1.0821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006087206304073334
Epoch 0, Step 93: train/loss = 0.554964005947113, train/raw-loss = 0.5488211512565613, train/logprobs = tensor([[-0.7773, -1.7992],
        [-0.8379, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006142833735793829
Epoch 0, Step 94: train/loss = 0.6085333228111267, train/raw-loss = 0.603242814540863, train/logprobs = tensor([[-0.4691, -1.2522],
        [-0.4951, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005290528293699026
Epoch 0, Step 95: train/loss = 0.5945961475372314, train/raw-loss = 0.5884596705436707, train/logprobs = tensor([[-0.6232, -1.1559],
        [-0.7015, -0.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006136463955044746
Epoch 0, Step 96: train/loss = 0.5841710567474365, train/raw-loss = 0.553415834903717, train/logprobs = tensor([[-0.5956, -1.4356],
        [-0.6889, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03075525164604187
Epoch 0, Step 97: train/loss = 0.5373408794403076, train/raw-loss = 0.5000431537628174, train/logprobs = tensor([[-0.6242, -2.4821],
        [-0.6767, -1.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03729771077632904
Epoch 0, Step 98: train/loss = 0.47925692796707153, train/raw-loss = 0.4423980116844177, train/logprobs = tensor([[-0.6562, -2.2572],
        [-0.8123, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0368589386343956
Epoch 0, Step 99: train/loss = 0.512738823890686, train/raw-loss = 0.47991132736206055, train/logprobs = tensor([[-0.5302, -2.3465],
        [-0.5800, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03282749652862549
Epoch 0, Step 100: train/loss = 0.5395262241363525, train/raw-loss = 0.5130161046981812, train/logprobs = tensor([[-0.5563, -1.6114],
        [-0.6541, -0.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026510128751397133
Epoch 0, Step 101: train/loss = 0.5187985897064209, train/raw-loss = 0.4866507053375244, train/logprobs = tensor([[-0.6507, -2.5731],
        [-0.7553, -1.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03214786574244499
Epoch 0, Step 102: train/loss = 0.5035646557807922, train/raw-loss = 0.4702407717704773, train/logprobs = tensor([[-0.7671, -2.3478],
        [-0.8880, -1.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033323876559734344
Epoch 0, Step 103: train/loss = 0.56769859790802, train/raw-loss = 0.5333042740821838, train/logprobs = tensor([[-0.5947, -1.8877],
        [-0.6959, -1.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034394267946481705
Epoch 0, Step 104: train/loss = 0.5381174683570862, train/raw-loss = 0.5035547614097595, train/logprobs = tensor([[-0.5829, -2.2677],
        [-0.6277, -1.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03456270694732666
Epoch 0, Step 105: train/loss = 0.5360579490661621, train/raw-loss = 0.5045310258865356, train/logprobs = tensor([[-0.5529, -1.6290],
        [-0.6425, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031526993960142136
Epoch 0, Step 106: train/loss = 0.5038439035415649, train/raw-loss = 0.471622496843338, train/logprobs = tensor([[-0.7304, -2.1281],
        [-0.8320, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03222135826945305
Epoch 0, Step 107: train/loss = 0.46590656042099, train/raw-loss = 0.4319537281990051, train/logprobs = tensor([[-0.4497, -2.5985],
        [-0.4905, -1.1979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03395282104611397
Epoch 0, Step 108: train/loss = 0.5071748495101929, train/raw-loss = 0.47321292757987976, train/logprobs = tensor([[-0.4658, -2.3364],
        [-0.5774, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033961936831474304
Epoch 0, Step 109: train/loss = 0.5996500253677368, train/raw-loss = 0.5653009414672852, train/logprobs = tensor([[-0.5522, -1.7903],
        [-0.5872, -1.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034349143505096436
Epoch 0, Step 110: train/loss = 0.6078729033470154, train/raw-loss = 0.5757399797439575, train/logprobs = tensor([[-0.5745, -1.4412],
        [-0.6358, -0.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032132893800735474
Epoch 0, Step 111: train/loss = 0.4697984755039215, train/raw-loss = 0.4347262680530548, train/logprobs = tensor([[-0.7970, -2.2316],
        [-0.9636, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03507217764854431
Epoch 0, Step 112: train/loss = 0.4679473042488098, train/raw-loss = 0.43237948417663574, train/logprobs = tensor([[-0.6274, -3.5065],
        [-0.7086, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03556782752275467
Epoch 0, Step 113: train/loss = 0.5277105569839478, train/raw-loss = 0.4957787096500397, train/logprobs = tensor([[-0.6210, -2.0490],
        [-0.7002, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03193187341094017
Epoch 0, Step 114: train/loss = 0.4919564425945282, train/raw-loss = 0.4597896933555603, train/logprobs = tensor([[-0.6470, -2.8857],
        [-0.6809, -1.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321667343378067
Epoch 0, Step 115: train/loss = 0.4935159385204315, train/raw-loss = 0.460145503282547, train/logprobs = tensor([[-0.5733, -1.9958],
        [-0.6977, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03337042033672333
Epoch 0, Step 116: train/loss = 0.4644150137901306, train/raw-loss = 0.4300576448440552, train/logprobs = tensor([[-0.6957, -2.7979],
        [-0.8053, -1.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034357380121946335
Epoch 0, Step 117: train/loss = 0.574840247631073, train/raw-loss = 0.5385971069335938, train/logprobs = tensor([[-0.6031, -2.1002],
        [-0.6891, -1.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036243148148059845
Epoch 0, Step 118: train/loss = 0.5741478204727173, train/raw-loss = 0.5447643399238586, train/logprobs = tensor([[-0.7318, -1.0355],
        [-0.9753, -0.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029383460059762
Epoch 0, Step 119: train/loss = 0.5421966314315796, train/raw-loss = 0.5077080726623535, train/logprobs = tensor([[-0.6104, -2.1757],
        [-0.6543, -1.2913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03448859229683876
Epoch 0, Step 120: train/loss = 0.5478580594062805, train/raw-loss = 0.5202109813690186, train/logprobs = tensor([[-0.6855, -1.4943],
        [-0.8720, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02764713577926159
Epoch 0, Step 121: train/loss = 0.49366074800491333, train/raw-loss = 0.4587576985359192, train/logprobs = tensor([[-0.6230, -2.4731],
        [-0.7576, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03490307927131653
Epoch 0, Step 122: train/loss = 0.5225641131401062, train/raw-loss = 0.48994216322898865, train/logprobs = tensor([[-0.8006, -1.7504],
        [-0.9795, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03262196481227875
Epoch 0, Step 123: train/loss = 0.5334680676460266, train/raw-loss = 0.5014906525611877, train/logprobs = tensor([[-0.6466, -1.9677],
        [-0.6875, -1.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03197745233774185
Epoch 0, Step 124: train/loss = 0.5320959091186523, train/raw-loss = 0.49792248010635376, train/logprobs = tensor([[-0.6930, -2.2260],
        [-0.8129, -1.3748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03417346626520157
Epoch 0, Step 125: train/loss = 0.46292543411254883, train/raw-loss = 0.4288890063762665, train/logprobs = tensor([[-0.8311, -2.0505],
        [-1.0778, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03403640538454056
Epoch 0, Step 126: train/loss = 0.497820109128952, train/raw-loss = 0.4625011086463928, train/logprobs = tensor([[-0.7512, -2.0943],
        [-0.9201, -1.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0353190153837204
Epoch 0, Step 127: train/loss = 0.5248538255691528, train/raw-loss = 0.49128544330596924, train/logprobs = tensor([[-0.6480, -2.0151],
        [-0.7324, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033568382263183594
Epoch 0, Step 128: train/loss = 0.5143545866012573, train/raw-loss = 0.39743900299072266, train/logprobs = tensor([[-0.3979, -3.2190],
        [-0.4700, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11691552400588989
Epoch 0, Step 129: train/loss = 0.49795299768447876, train/raw-loss = 0.38422197103500366, train/logprobs = tensor([[-0.7644, -2.4459],
        [-1.0198, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137310042977333
Epoch 0, Step 130: train/loss = 0.4595411419868469, train/raw-loss = 0.34671488404273987, train/logprobs = tensor([[-0.5554, -3.5148],
        [-0.6459, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11282624304294586
Epoch 0, Step 131: train/loss = 0.5272057056427002, train/raw-loss = 0.42364755272865295, train/logprobs = tensor([[-0.5606, -2.9928],
        [-0.6728, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355813801288605
Epoch 0, Step 132: train/loss = 0.5086211562156677, train/raw-loss = 0.4023353159427643, train/logprobs = tensor([[-0.6630, -2.5993],
        [-0.7923, -0.7963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10628582537174225
Epoch 0, Step 133: train/loss = 0.5006136894226074, train/raw-loss = 0.40845727920532227, train/logprobs = tensor([[-0.6013, -2.3297],
        [-0.7406, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09215637296438217
Epoch 0, Step 134: train/loss = 0.4765709638595581, train/raw-loss = 0.37739691138267517, train/logprobs = tensor([[-0.6957, -2.8096],
        [-0.8995, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09917403757572174
Epoch 0, Step 135: train/loss = 0.45542195439338684, train/raw-loss = 0.35050541162490845, train/logprobs = tensor([[-0.5273, -3.7967],
        [-0.6265, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.104916512966156
Epoch 0, Step 136: train/loss = 0.4426450729370117, train/raw-loss = 0.343900203704834, train/logprobs = tensor([[-0.6880, -3.0747],
        [-0.8467, -1.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09874486923217773
Epoch 0, Step 137: train/loss = 0.5130417943000793, train/raw-loss = 0.39740800857543945, train/logprobs = tensor([[-0.6160, -2.6048],
        [-0.6983, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1156337782740593
Epoch 0, Step 138: train/loss = 0.6325896382331848, train/raw-loss = 0.5066342353820801, train/logprobs = tensor([[-0.5149, -3.1290],
        [-0.5478, -2.2216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12595534324645996
Epoch 0, Step 139: train/loss = 0.5350464582443237, train/raw-loss = 0.4339582026004791, train/logprobs = tensor([[-0.5644, -1.8731],
        [-0.6968, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10108824074268341
Epoch 0, Step 140: train/loss = 0.5110733509063721, train/raw-loss = 0.39682891964912415, train/logprobs = tensor([[-0.6151, -3.2372],
        [-0.7004, -1.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11424443125724792
Epoch 0, Step 141: train/loss = 0.5766335129737854, train/raw-loss = 0.46001136302948, train/logprobs = tensor([[-0.4521, -1.7948],
        [-0.4753, -0.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11662217229604721
Epoch 0, Step 142: train/loss = 0.5127147436141968, train/raw-loss = 0.40999293327331543, train/logprobs = tensor([[-0.4700, -3.2426],
        [-0.5093, -1.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10272182524204254
Epoch 0, Step 143: train/loss = 0.4603598713874817, train/raw-loss = 0.365064799785614, train/logprobs = tensor([[-0.4026, -2.9041],
        [-0.4761, -0.8470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09529504179954529
Epoch 0, Step 144: train/loss = 0.6213752031326294, train/raw-loss = 0.5224486589431763, train/logprobs = tensor([[-0.5144, -2.3266],
        [-0.5963, -1.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09892649948596954
Epoch 0, Step 145: train/loss = 0.5322790741920471, train/raw-loss = 0.44056785106658936, train/logprobs = tensor([[-0.5901, -2.2742],
        [-0.6995, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09171123802661896
Epoch 0, Step 146: train/loss = 0.526996374130249, train/raw-loss = 0.42685678601264954, train/logprobs = tensor([[-0.6286, -1.9245],
        [-0.7209, -0.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10013958811759949
Epoch 0, Step 147: train/loss = 0.532300591468811, train/raw-loss = 0.4238622188568115, train/logprobs = tensor([[-0.4968, -2.4315],
        [-0.5833, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843831300735474
Epoch 0, Step 148: train/loss = 0.4955174922943115, train/raw-loss = 0.388405978679657, train/logprobs = tensor([[-0.6500, -2.5587],
        [-0.8111, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10711150616407394
Epoch 0, Step 149: train/loss = 0.5524601340293884, train/raw-loss = 0.43257957696914673, train/logprobs = tensor([[-0.5508, -2.2836],
        [-0.6620, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1198805719614029
Epoch 0, Step 150: train/loss = 0.458829790353775, train/raw-loss = 0.34512895345687866, train/logprobs = tensor([[-0.6569, -3.5405],
        [-0.8071, -1.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11370085179805756
Epoch 0, Step 151: train/loss = 0.4542323350906372, train/raw-loss = 0.3461053967475891, train/logprobs = tensor([[-0.7366, -3.0365],
        [-0.9839, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10812698304653168
Epoch 0, Step 152: train/loss = 0.47455519437789917, train/raw-loss = 0.3611868619918823, train/logprobs = tensor([[-0.5655, -3.6860],
        [-0.6552, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11336833238601685
Epoch 0, Step 153: train/loss = 0.4961991310119629, train/raw-loss = 0.4008532762527466, train/logprobs = tensor([[-0.7442, -2.2787],
        [-0.9199, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09534585475921631
Epoch 0, Step 154: train/loss = 0.5047689080238342, train/raw-loss = 0.40606433153152466, train/logprobs = tensor([[-0.5282, -2.9172],
        [-0.6002, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870462119579315
Epoch 0, Step 155: train/loss = 0.4671283960342407, train/raw-loss = 0.3588181138038635, train/logprobs = tensor([[-0.5411, -2.9424],
        [-0.7081, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10831025242805481
Epoch 0, Step 156: train/loss = 0.5225322842597961, train/raw-loss = 0.4088723957538605, train/logprobs = tensor([[-0.6112, -2.7864],
        [-0.7176, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11365988850593567
Epoch 0, Step 157: train/loss = 0.49146270751953125, train/raw-loss = 0.37832513451576233, train/logprobs = tensor([[-0.5899, -3.0556],
        [-0.7529, -1.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11313757300376892
Epoch 0, Step 158: train/loss = 0.601689338684082, train/raw-loss = 0.515298068523407, train/logprobs = tensor([[-0.5928, -1.9069],
        [-0.6910, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08639129996299744
Epoch 0, Step 159: train/loss = 0.553166925907135, train/raw-loss = 0.44157880544662476, train/logprobs = tensor([[-0.6198, -2.3192],
        [-0.7496, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11158812791109085
Epoch 0, Step 160: train/loss = 0.44561606645584106, train/raw-loss = 0.3568345308303833, train/logprobs = tensor([[-0.5089, -3.5689],
        [-0.6279, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878152817487717
Epoch 0, Step 161: train/loss = 0.38046926259994507, train/raw-loss = 0.2954666316509247, train/logprobs = tensor([[-0.5938, -3.7852],
        [-0.8220, -0.8529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500266075134277
Epoch 0, Step 162: train/loss = 0.3812549114227295, train/raw-loss = 0.30263590812683105, train/logprobs = tensor([[-0.4813, -4.1481],
        [-0.5356, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07861899584531784
Epoch 0, Step 163: train/loss = 0.4354895055294037, train/raw-loss = 0.3478987216949463, train/logprobs = tensor([[-0.5587, -2.9285],
        [-0.7357, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08759079873561859
Epoch 0, Step 164: train/loss = 0.42055708169937134, train/raw-loss = 0.34104272723197937, train/logprobs = tensor([[-0.6798, -3.0789],
        [-0.9798, -0.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07951434701681137
Epoch 0, Step 165: train/loss = 0.45951250195503235, train/raw-loss = 0.374625027179718, train/logprobs = tensor([[-0.5938, -3.3132],
        [-0.7161, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08488749712705612
Epoch 0, Step 166: train/loss = 0.39352110028266907, train/raw-loss = 0.3096241354942322, train/logprobs = tensor([[-0.3912, -4.1684],
        [-0.4293, -1.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08389695733785629
Epoch 0, Step 167: train/loss = 0.40257906913757324, train/raw-loss = 0.3158891201019287, train/logprobs = tensor([[-0.8275, -3.1966],
        [-1.1816, -0.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08668994903564453
Epoch 0, Step 168: train/loss = 0.5191650390625, train/raw-loss = 0.4241582751274109, train/logprobs = tensor([[-0.5759, -2.4563],
        [-0.7652, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09500674903392792
Epoch 0, Step 169: train/loss = 0.4237308204174042, train/raw-loss = 0.34490740299224854, train/logprobs = tensor([[-0.5638, -2.8246],
        [-0.7125, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07882341742515564
Epoch 0, Step 170: train/loss = 0.4950275421142578, train/raw-loss = 0.42388707399368286, train/logprobs = tensor([[-0.6584, -2.5150],
        [-0.9660, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07114045321941376
Epoch 0, Step 171: train/loss = 0.5569062232971191, train/raw-loss = 0.4818846583366394, train/logprobs = tensor([[-0.4870, -1.7581],
        [-0.5673, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07502153515815735
Epoch 0, Step 172: train/loss = 0.47047534584999084, train/raw-loss = 0.38313695788383484, train/logprobs = tensor([[-0.7955, -2.5109],
        [-1.0998, -1.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0873384177684784
Epoch 0, Step 173: train/loss = 0.47785326838493347, train/raw-loss = 0.3979050815105438, train/logprobs = tensor([[-0.5518, -2.5290],
        [-0.7062, -0.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07994816452264786
Epoch 0, Step 174: train/loss = 0.43170371651649475, train/raw-loss = 0.34399762749671936, train/logprobs = tensor([[-0.4494, -3.1058],
        [-0.5606, -0.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0877060741186142
Epoch 0, Step 175: train/loss = 0.4732080101966858, train/raw-loss = 0.39472270011901855, train/logprobs = tensor([[-0.5272, -2.3915],
        [-0.6497, -0.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07848533242940903
Epoch 0, Step 176: train/loss = 0.4626524746417999, train/raw-loss = 0.3718491792678833, train/logprobs = tensor([[-0.4179, -3.1796],
        [-0.4886, -1.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09080330282449722
Epoch 0, Step 177: train/loss = 0.48954060673713684, train/raw-loss = 0.3975978493690491, train/logprobs = tensor([[-0.5274, -1.9238],
        [-0.7427, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194275736808777
Epoch 0, Step 178: train/loss = 0.47564417123794556, train/raw-loss = 0.39249300956726074, train/logprobs = tensor([[-0.5978, -2.3501],
        [-0.7156, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08315112441778183
Epoch 0, Step 179: train/loss = 0.43915891647338867, train/raw-loss = 0.3507881760597229, train/logprobs = tensor([[-0.4629, -3.7373],
        [-0.5444, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08837076276540756
Epoch 0, Step 180: train/loss = 0.44673600792884827, train/raw-loss = 0.3638346791267395, train/logprobs = tensor([[-0.6583, -3.8489],
        [-0.8868, -1.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08290135115385056
Epoch 0, Step 181: train/loss = 0.4681127667427063, train/raw-loss = 0.3748922348022461, train/logprobs = tensor([[-0.5474, -3.1584],
        [-0.6227, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0932205319404602
Epoch 0, Step 182: train/loss = 0.43822064995765686, train/raw-loss = 0.3455466032028198, train/logprobs = tensor([[-0.6736, -3.3201],
        [-0.8453, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267403185367584
Epoch 0, Step 183: train/loss = 0.442844033241272, train/raw-loss = 0.36332574486732483, train/logprobs = tensor([[-0.4948, -3.7433],
        [-0.6296, -1.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07951831817626953
Epoch 0, Step 184: train/loss = 0.4338703751564026, train/raw-loss = 0.3464999496936798, train/logprobs = tensor([[-0.7048, -3.0912],
        [-0.9780, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08737047016620636
Epoch 0, Step 185: train/loss = 0.4127034544944763, train/raw-loss = 0.31985172629356384, train/logprobs = tensor([[-0.7373, -2.9217],
        [-1.0279, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09285171329975128
Epoch 0, Step 186: train/loss = 0.4675300121307373, train/raw-loss = 0.3813191056251526, train/logprobs = tensor([[-0.6627, -3.0059],
        [-0.8209, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08621089160442352
Epoch 0, Step 187: train/loss = 0.5509482026100159, train/raw-loss = 0.47143810987472534, train/logprobs = tensor([[-0.7013, -2.0089],
        [-0.8074, -0.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0795101672410965
Epoch 0, Step 188: train/loss = 0.5006294846534729, train/raw-loss = 0.40375491976737976, train/logprobs = tensor([[-0.5228, -3.0770],
        [-0.6248, -1.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09687454253435135
Epoch 0, Step 189: train/loss = 0.4598061144351959, train/raw-loss = 0.37353286147117615, train/logprobs = tensor([[-0.4757, -3.6426],
        [-0.5823, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08627328276634216
Epoch 0, Step 190: train/loss = 0.5377399325370789, train/raw-loss = 0.45681965351104736, train/logprobs = tensor([[-0.4160, -1.9795],
        [-0.4921, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809202790260315
Epoch 0, Step 191: train/loss = 0.36122721433639526, train/raw-loss = 0.27586930990219116, train/logprobs = tensor([[-0.4812, -4.1596],
        [-0.7070, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0853579193353653
Epoch 0, Step 192: train/loss = 0.369425892829895, train/raw-loss = 0.23767265677452087, train/logprobs = tensor([[-0.5763, -3.2455],
        [-1.1303, -0.3261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13175323605537415
Epoch 0, Step 193: train/loss = 0.4046156704425812, train/raw-loss = 0.28142213821411133, train/logprobs = tensor([[-0.7065, -3.4776],
        [-1.0176, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12319354712963104
Epoch 0, Step 194: train/loss = 0.4341813623905182, train/raw-loss = 0.3152807950973511, train/logprobs = tensor([[-0.6602, -3.5089],
        [-1.0745, -0.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1189005970954895
Epoch 0, Step 195: train/loss = 0.3654543161392212, train/raw-loss = 0.24482578039169312, train/logprobs = tensor([[-0.6613, -5.2992],
        [-0.9782, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12062854319810867
Epoch 0, Step 196: train/loss = 0.4990859031677246, train/raw-loss = 0.38215410709381104, train/logprobs = tensor([[-0.5402, -2.5054],
        [-0.7687, -0.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11693177372217178
Epoch 0, Step 197: train/loss = 0.43699920177459717, train/raw-loss = 0.33610814809799194, train/logprobs = tensor([[-0.4553, -3.5471],
        [-0.5885, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10089107602834702
Epoch 0, Step 198: train/loss = 0.5206267833709717, train/raw-loss = 0.41369980573654175, train/logprobs = tensor([[-0.5629, -2.9463],
        [-0.7957, -0.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10692700743675232
Epoch 0, Step 199: train/loss = 0.3870449364185333, train/raw-loss = 0.2776622176170349, train/logprobs = tensor([[-0.4861, -4.3866],
        [-0.7135, -0.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1093827337026596
Epoch 0, Step 200: train/loss = 0.38769134879112244, train/raw-loss = 0.25644269585609436, train/logprobs = tensor([[-0.5887, -4.6966],
        [-0.9288, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13124868273735046
Epoch 0, Step 201: train/loss = 0.40220141410827637, train/raw-loss = 0.28535282611846924, train/logprobs = tensor([[-0.5930, -4.3345],
        [-0.8885, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11684858053922653
Epoch 0, Step 202: train/loss = 0.4652315080165863, train/raw-loss = 0.36690014600753784, train/logprobs = tensor([[-0.4801, -3.8164],
        [-0.6140, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09833135455846786
Epoch 0, Step 203: train/loss = 0.4439079463481903, train/raw-loss = 0.3341013789176941, train/logprobs = tensor([[-0.6084, -2.8211],
        [-0.8517, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1098065972328186
Epoch 0, Step 204: train/loss = 0.44405895471572876, train/raw-loss = 0.320366233587265, train/logprobs = tensor([[-0.6796, -4.2018],
        [-1.1504, -0.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12369272112846375
Epoch 0, Step 205: train/loss = 0.4282902181148529, train/raw-loss = 0.3069194257259369, train/logprobs = tensor([[-0.6895, -3.4163],
        [-1.0617, -0.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137080729007721
Epoch 0, Step 206: train/loss = 0.3749077618122101, train/raw-loss = 0.2540780305862427, train/logprobs = tensor([[-0.4783, -3.5799],
        [-0.8449, -0.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12082971632480621
Epoch 0, Step 207: train/loss = 0.45873579382896423, train/raw-loss = 0.3448168933391571, train/logprobs = tensor([[-0.5300, -3.8389],
        [-0.7538, -0.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391889303922653
Epoch 0, Step 208: train/loss = 0.42640745639801025, train/raw-loss = 0.3184291124343872, train/logprobs = tensor([[-0.4484, -3.1630],
        [-0.5827, -0.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10797834396362305
Epoch 0, Step 209: train/loss = 0.3869975805282593, train/raw-loss = 0.25817903876304626, train/logprobs = tensor([[-0.6543, -4.1841],
        [-1.0395, -0.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12881851196289062
Epoch 0, Step 210: train/loss = 0.4176870584487915, train/raw-loss = 0.3163470923900604, train/logprobs = tensor([[-0.3436, -5.1026],
        [-0.4412, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10133998095989227
Epoch 0, Step 211: train/loss = 0.4158320426940918, train/raw-loss = 0.3031690716743469, train/logprobs = tensor([[-0.5070, -4.4007],
        [-0.5755, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11266298592090607
Epoch 0, Step 212: train/loss = 0.46205586194992065, train/raw-loss = 0.3437383770942688, train/logprobs = tensor([[-0.5994, -2.2164],
        [-0.8941, -0.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11831749230623245
Epoch 0, Step 213: train/loss = 0.4098939597606659, train/raw-loss = 0.28944697976112366, train/logprobs = tensor([[-0.5616, -3.2613],
        [-0.7742, -0.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12044695764780045
Epoch 0, Step 214: train/loss = 0.38196420669555664, train/raw-loss = 0.25373315811157227, train/logprobs = tensor([[-0.6093, -3.6798],
        [-0.9969, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12823104858398438
Epoch 0, Step 215: train/loss = 0.3948017656803131, train/raw-loss = 0.256613165140152, train/logprobs = tensor([[-0.7684, -3.1947],
        [-1.3100, -0.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13818861544132233
Epoch 0, Step 216: train/loss = 0.4021298885345459, train/raw-loss = 0.2725933790206909, train/logprobs = tensor([[-0.6826, -3.4516],
        [-1.0693, -0.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295364946126938
Epoch 0, Step 217: train/loss = 0.4038616418838501, train/raw-loss = 0.2833065986633301, train/logprobs = tensor([[-0.5631, -3.8756],
        [-0.8956, -0.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12055501341819763
Epoch 0, Step 218: train/loss = 0.4161440134048462, train/raw-loss = 0.2945778965950012, train/logprobs = tensor([[-0.5048, -4.1237],
        [-0.7054, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12156613916158676
Epoch 0, Step 219: train/loss = 0.4842098355293274, train/raw-loss = 0.37313130497932434, train/logprobs = tensor([[-0.5118, -2.4191],
        [-0.6836, -0.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11107851564884186
Epoch 0, Step 220: train/loss = 0.45970621705055237, train/raw-loss = 0.3549564480781555, train/logprobs = tensor([[-0.4159, -3.3783],
        [-0.5369, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10474976897239685
Epoch 0, Step 221: train/loss = 0.38567638397216797, train/raw-loss = 0.26605576276779175, train/logprobs = tensor([[-0.5783, -4.3076],
        [-0.8053, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11962060630321503
Epoch 0, Step 222: train/loss = 0.4347870349884033, train/raw-loss = 0.3185350298881531, train/logprobs = tensor([[-0.5331, -3.4933],
        [-0.7234, -0.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11625200510025024
Epoch 0, Step 223: train/loss = 0.45991116762161255, train/raw-loss = 0.3403779864311218, train/logprobs = tensor([[-0.5177, -2.7720],
        [-0.8633, -0.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11953316628932953
Epoch 0, Step 224: train/loss = 0.43656712770462036, train/raw-loss = 0.3079267144203186, train/logprobs = tensor([[-0.5354, -3.7037],
        [-1.0066, -0.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864039838314056
Epoch 0, Step 225: train/loss = 0.43221116065979004, train/raw-loss = 0.2956817150115967, train/logprobs = tensor([[-0.4474, -3.5890],
        [-0.6565, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13652944564819336
Epoch 0, Step 226: train/loss = 0.40223026275634766, train/raw-loss = 0.26667463779449463, train/logprobs = tensor([[-0.5311, -4.5982],
        [-0.8515, -0.6501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13555561006069183
Epoch 0, Step 227: train/loss = 0.39360421895980835, train/raw-loss = 0.25318729877471924, train/logprobs = tensor([[-0.5365, -4.8164],
        [-0.8947, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1404169201850891
Epoch 0, Step 228: train/loss = 0.37509429454803467, train/raw-loss = 0.2484973669052124, train/logprobs = tensor([[-0.4490, -4.9661],
        [-0.7962, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12659694254398346
Epoch 0, Step 229: train/loss = 0.40006574988365173, train/raw-loss = 0.2718205749988556, train/logprobs = tensor([[-0.5051, -5.0517],
        [-0.8158, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12824515998363495
Epoch 0, Step 230: train/loss = 0.5199814438819885, train/raw-loss = 0.40621405839920044, train/logprobs = tensor([[-0.3946, -2.0156],
        [-0.5323, -0.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1137673631310463
Epoch 0, Step 231: train/loss = 0.4038240909576416, train/raw-loss = 0.26543015241622925, train/logprobs = tensor([[-0.5588, -4.6088],
        [-0.8404, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13839393854141235
Epoch 0, Step 232: train/loss = 0.38662564754486084, train/raw-loss = 0.2514384388923645, train/logprobs = tensor([[-0.6182, -4.5752],
        [-0.9495, -0.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13518722355365753
Epoch 0, Step 233: train/loss = 0.44065919518470764, train/raw-loss = 0.30597424507141113, train/logprobs = tensor([[-0.4931, -4.5140],
        [-0.6928, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13468492031097412
Epoch 0, Step 234: train/loss = 0.5399906635284424, train/raw-loss = 0.4034956097602844, train/logprobs = tensor([[-0.4495, -4.2923],
        [-0.6759, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13649509847164154
Epoch 0, Step 235: train/loss = 0.4495845139026642, train/raw-loss = 0.3265288174152374, train/logprobs = tensor([[-0.4836, -4.9320],
        [-0.6189, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12305571883916855
Epoch 0, Step 236: train/loss = 0.4032880663871765, train/raw-loss = 0.2637832462787628, train/logprobs = tensor([[-0.5361, -5.1246],
        [-0.8520, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1395048201084137
Epoch 0, Step 237: train/loss = 0.3974728584289551, train/raw-loss = 0.24771620333194733, train/logprobs = tensor([[-0.6226, -4.6217],
        [-0.9137, -0.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14975665509700775
Epoch 0, Step 238: train/loss = 0.37921708822250366, train/raw-loss = 0.23605023324489594, train/logprobs = tensor([[-0.5381, -4.2218],
        [-0.9073, -0.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14316686987876892
Epoch 0, Step 239: train/loss = 0.39372870326042175, train/raw-loss = 0.27171698212623596, train/logprobs = tensor([[-0.3673, -6.0165],
        [-0.4222, -0.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12201173603534698
Epoch 0, Step 240: train/loss = 0.3678436279296875, train/raw-loss = 0.2457519769668579, train/logprobs = tensor([[-0.4974, -5.4749],
        [-0.7386, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1220916360616684
Epoch 0, Step 241: train/loss = 0.41057348251342773, train/raw-loss = 0.2616216540336609, train/logprobs = tensor([[-0.5136, -4.1344],
        [-1.0154, -0.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14895184338092804
Epoch 0, Step 242: train/loss = 0.35217249393463135, train/raw-loss = 0.19371359050273895, train/logprobs = tensor([[-0.8367, -6.3650],
        [-1.4551, -0.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15845887362957
Epoch 0, Step 243: train/loss = 0.3699837327003479, train/raw-loss = 0.22817638516426086, train/logprobs = tensor([[-0.6340, -3.7485],
        [-1.1360, -0.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14180734753608704
Epoch 0, Step 244: train/loss = 0.4601891040802002, train/raw-loss = 0.31542885303497314, train/logprobs = tensor([[-0.5704, -3.4953],
        [-0.9557, -0.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14476026594638824
Epoch 0, Step 245: train/loss = 0.365951806306839, train/raw-loss = 0.22036665678024292, train/logprobs = tensor([[-0.5870, -5.3491],
        [-0.9898, -0.5302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14558517932891846
Epoch 0, Step 246: train/loss = 0.45760101079940796, train/raw-loss = 0.3214488923549652, train/logprobs = tensor([[-0.4842, -3.5594],
        [-0.7239, -0.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13615211844444275
Epoch 0, Step 247: train/loss = 0.3860226273536682, train/raw-loss = 0.2270803302526474, train/logprobs = tensor([[-0.6588, -4.8868],
        [-1.0507, -0.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15894228219985962
Epoch 0, Step 248: train/loss = 0.445297509431839, train/raw-loss = 0.3082069754600525, train/logprobs = tensor([[-0.5351, -3.8540],
        [-0.9667, -0.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370905339717865
Epoch 0, Step 249: train/loss = 0.40755587816238403, train/raw-loss = 0.2700185477733612, train/logprobs = tensor([[-0.5231, -4.0086],
        [-0.9625, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13753730058670044
Epoch 0, Step 250: train/loss = 0.43443211913108826, train/raw-loss = 0.3039257824420929, train/logprobs = tensor([[-0.5236, -3.7832],
        [-0.6961, -0.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13050635159015656
Epoch 0, Step 251: train/loss = 0.3843267261981964, train/raw-loss = 0.24701200425624847, train/logprobs = tensor([[-0.5977, -6.6627],
        [-0.8951, -0.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13731475174427032
Epoch 0, Step 252: train/loss = 0.3724762797355652, train/raw-loss = 0.22817613184452057, train/logprobs = tensor([[-0.6637, -5.6241],
        [-1.0858, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14430014789104462
Epoch 0, Step 253: train/loss = 0.42385801672935486, train/raw-loss = 0.2953260540962219, train/logprobs = tensor([[-0.4652, -5.5529],
        [-0.7236, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12853193283081055
Epoch 0, Step 254: train/loss = 0.41215232014656067, train/raw-loss = 0.27715572714805603, train/logprobs = tensor([[-0.6209, -5.4958],
        [-1.0556, -0.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13499653339385986
Epoch 0, Step 255: train/loss = 0.4671249985694885, train/raw-loss = 0.3327144384384155, train/logprobs = tensor([[-0.5391, -3.6642],
        [-0.7935, -0.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13441060483455658
Epoch 0, Step 256: train/loss = 0.4087732136249542, train/raw-loss = 0.26564714312553406, train/logprobs = tensor([[-0.3969, -5.6856],
        [-0.5755, -0.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14312605559825897
Epoch 0, Step 257: train/loss = 0.3806203007698059, train/raw-loss = 0.25815585255622864, train/logprobs = tensor([[-0.4405, -6.0042],
        [-0.5768, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246445566415787
Epoch 0, Step 258: train/loss = 0.41219258308410645, train/raw-loss = 0.2708855867385864, train/logprobs = tensor([[-0.4803, -3.1645],
        [-1.0023, -0.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1413070261478424
Epoch 0, Step 259: train/loss = 0.36667710542678833, train/raw-loss = 0.19413864612579346, train/logprobs = tensor([[-0.5867, -5.2905],
        [-1.1910, -0.3723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17253842949867249
Epoch 0, Step 260: train/loss = 0.36078229546546936, train/raw-loss = 0.22016380727291107, train/logprobs = tensor([[-0.3733, -6.1747],
        [-0.7960, -0.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406184732913971
Epoch 0, Step 261: train/loss = 0.39111894369125366, train/raw-loss = 0.21535471081733704, train/logprobs = tensor([[-0.6671, -3.9802],
        [-1.3229, -0.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.175764262676239
Epoch 0, Step 262: train/loss = 0.45022284984588623, train/raw-loss = 0.333577036857605, train/logprobs = tensor([[-0.4049, -3.8322],
        [-0.5290, -0.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664577573537827
Epoch 0, Step 263: train/loss = 0.39484453201293945, train/raw-loss = 0.25328928232192993, train/logprobs = tensor([[-0.5627, -4.2421],
        [-0.9624, -0.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14155520498752594
Epoch 0, Step 264: train/loss = 0.3834308981895447, train/raw-loss = 0.24341867864131927, train/logprobs = tensor([[-0.4967, -4.8954],
        [-0.8507, -0.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1400122046470642
Epoch 0, Step 265: train/loss = 0.38865846395492554, train/raw-loss = 0.23193740844726562, train/logprobs = tensor([[-0.5591, -5.0113],
        [-1.0446, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15672102570533752
Epoch 0, Step 266: train/loss = 0.3894307613372803, train/raw-loss = 0.2585428059101105, train/logprobs = tensor([[-0.4525, -7.2448],
        [-0.6548, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308879554271698
Epoch 0, Step 267: train/loss = 0.36327046155929565, train/raw-loss = 0.21836726367473602, train/logprobs = tensor([[-0.5157, -6.5925],
        [-0.9657, -0.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14490322768688202
Epoch 0, Step 268: train/loss = 0.37523168325424194, train/raw-loss = 0.24472802877426147, train/logprobs = tensor([[-0.5102, -5.9244],
        [-0.7238, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13050365447998047
Epoch 0, Step 269: train/loss = 0.40577802062034607, train/raw-loss = 0.27734342217445374, train/logprobs = tensor([[-0.4539, -5.3412],
        [-0.5410, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12843458354473114
Epoch 0, Step 270: train/loss = 0.3992975354194641, train/raw-loss = 0.2532319724559784, train/logprobs = tensor([[-0.5934, -3.3282],
        [-1.0372, -0.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14606554806232452
Epoch 0, Step 271: train/loss = 0.41526246070861816, train/raw-loss = 0.27227267622947693, train/logprobs = tensor([[-0.4475, -4.8282],
        [-0.6178, -0.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14298981428146362
Epoch 0, Step 272: train/loss = 0.3989102840423584, train/raw-loss = 0.24586136639118195, train/logprobs = tensor([[-0.4512, -3.1937],
        [-0.8875, -0.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15304894745349884
Epoch 0, Step 273: train/loss = 0.373862624168396, train/raw-loss = 0.23977957665920258, train/logprobs = tensor([[-0.4281, -7.1324],
        [-0.6718, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13408306241035461
Epoch 0, Step 274: train/loss = 0.36965715885162354, train/raw-loss = 0.21967239677906036, train/logprobs = tensor([[-0.6832, -5.3862],
        [-1.1558, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14998474717140198
Epoch 0, Step 275: train/loss = 0.4240933358669281, train/raw-loss = 0.27698782086372375, train/logprobs = tensor([[-0.5830, -3.7781],
        [-0.9574, -0.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14710550010204315
Epoch 0, Step 276: train/loss = 0.40199941396713257, train/raw-loss = 0.26635420322418213, train/logprobs = tensor([[-0.4812, -3.6792],
        [-0.8036, -0.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13564524054527283
Epoch 0, Step 277: train/loss = 0.383409321308136, train/raw-loss = 0.2447415441274643, train/logprobs = tensor([[-0.4954, -4.7370],
        [-0.8961, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386677622795105
Epoch 0, Step 278: train/loss = 0.3967783451080322, train/raw-loss = 0.2400793880224228, train/logprobs = tensor([[-0.6275, -4.1874],
        [-1.2040, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15669898688793182
Epoch 0, Step 279: train/loss = 0.40030238032341003, train/raw-loss = 0.2472107708454132, train/logprobs = tensor([[-0.6510, -3.7820],
        [-1.0906, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15309159457683563
Epoch 0, Step 280: train/loss = 0.36875927448272705, train/raw-loss = 0.2193787395954132, train/logprobs = tensor([[-0.4732, -6.4122],
        [-0.8894, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14938050508499146
Epoch 0, Step 281: train/loss = 0.40649914741516113, train/raw-loss = 0.26566481590270996, train/logprobs = tensor([[-0.5473, -3.4046],
        [-0.8420, -0.3059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14083436131477356
Epoch 0, Step 282: train/loss = 0.4485172927379608, train/raw-loss = 0.3165324032306671, train/logprobs = tensor([[-0.4756, -4.4926],
        [-0.5912, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1319848895072937
Epoch 0, Step 283: train/loss = 0.39516785740852356, train/raw-loss = 0.27144744992256165, train/logprobs = tensor([[-0.3825, -5.1199],
        [-0.6194, -0.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12372042238712311
Epoch 0, Step 284: train/loss = 0.4237508475780487, train/raw-loss = 0.29270613193511963, train/logprobs = tensor([[-0.4579, -5.0966],
        [-0.6651, -0.6071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310446858406067
Epoch 0, Step 285: train/loss = 0.40801116824150085, train/raw-loss = 0.28147459030151367, train/logprobs = tensor([[-0.3942, -5.6252],
        [-0.5033, -0.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12653660774230957
Epoch 0, Step 286: train/loss = 0.3655245304107666, train/raw-loss = 0.20403136312961578, train/logprobs = tensor([[-0.6264, -6.8852],
        [-1.1378, -0.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16149313747882843
Epoch 0, Step 287: train/loss = 0.38731861114501953, train/raw-loss = 0.2431277632713318, train/logprobs = tensor([[-0.5780, -4.7256],
        [-1.0537, -0.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14419087767601013
Epoch 0, Step 288: train/loss = 0.38063931465148926, train/raw-loss = 0.2571176290512085, train/logprobs = tensor([[-0.4439, -5.6069],
        [-0.6712, -0.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12352167069911957
Epoch 0, Step 289: train/loss = 0.3371444642543793, train/raw-loss = 0.18151623010635376, train/logprobs = tensor([[-0.6295, -4.7881],
        [-1.4806, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1556282490491867
Epoch 0, Step 290: train/loss = 0.36430925130844116, train/raw-loss = 0.2134651243686676, train/logprobs = tensor([[-0.5889, -7.0633],
        [-1.0428, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15084412693977356
Epoch 0, Step 291: train/loss = 0.4478166699409485, train/raw-loss = 0.31986355781555176, train/logprobs = tensor([[-0.4018, -4.3217],
        [-0.6085, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12795309722423553
Epoch 0, Step 292: train/loss = 0.43624886870384216, train/raw-loss = 0.3181375563144684, train/logprobs = tensor([[-0.4412, -4.8834],
        [-0.8137, -0.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11811130493879318
Epoch 0, Step 293: train/loss = 0.43064677715301514, train/raw-loss = 0.30001112818717957, train/logprobs = tensor([[-0.4759, -3.8671],
        [-0.6540, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13063563406467438
Epoch 0, Step 294: train/loss = 0.45053669810295105, train/raw-loss = 0.33310315012931824, train/logprobs = tensor([[-0.3570, -2.9977],
        [-0.4238, -0.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.117433562874794
Epoch 0, Step 295: train/loss = 0.37467437982559204, train/raw-loss = 0.24957089126110077, train/logprobs = tensor([[-0.4150, -5.0854],
        [-0.7280, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510348856449127
Epoch 0, Step 296: train/loss = 0.44592586159706116, train/raw-loss = 0.3210148811340332, train/logprobs = tensor([[-0.4681, -4.8684],
        [-0.6330, -0.8623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12491094321012497
Epoch 0, Step 297: train/loss = 0.3664460778236389, train/raw-loss = 0.2225102186203003, train/logprobs = tensor([[-0.5563, -5.4357],
        [-1.1401, -0.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14393584430217743
Epoch 0, Step 298: train/loss = 0.3809889256954193, train/raw-loss = 0.2388327717781067, train/logprobs = tensor([[-0.5421, -5.3318],
        [-0.9983, -0.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14215616881847382
Epoch 0, Step 299: train/loss = 0.42213958501815796, train/raw-loss = 0.2805212140083313, train/logprobs = tensor([[-0.6041, -5.1457],
        [-1.0545, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14161843061447144
Epoch 0, Step 300: train/loss = 0.3833068311214447, train/raw-loss = 0.26391366124153137, train/logprobs = tensor([[-0.4731, -4.8179],
        [-0.8631, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11939319968223572
Epoch 0, Step 301: train/loss = 0.38057148456573486, train/raw-loss = 0.26110148429870605, train/logprobs = tensor([[-0.4567, -5.9559],
        [-0.6362, -0.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11946999281644821
Epoch 0, Step 302: train/loss = 0.39235439896583557, train/raw-loss = 0.2479744553565979, train/logprobs = tensor([[-0.5790, -5.3220],
        [-1.0056, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14437995851039886
Epoch 0, Step 303: train/loss = 0.34749460220336914, train/raw-loss = 0.20741958916187286, train/logprobs = tensor([[-0.5454, -6.5604],
        [-1.1027, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14007499814033508
Epoch 0, Step 304: train/loss = 0.38812869787216187, train/raw-loss = 0.2555494010448456, train/logprobs = tensor([[-0.4786, -4.5161],
        [-0.7426, -0.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13257929682731628
Epoch 0, Step 305: train/loss = 0.40926748514175415, train/raw-loss = 0.28271645307540894, train/logprobs = tensor([[-0.4063, -4.3904],
        [-0.6050, -0.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12655103206634521
Epoch 0, Step 306: train/loss = 0.39987894892692566, train/raw-loss = 0.2686873972415924, train/logprobs = tensor([[-0.4567, -6.0377],
        [-0.8826, -0.6789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13119153678417206
Epoch 0, Step 307: train/loss = 0.355599969625473, train/raw-loss = 0.21411395072937012, train/logprobs = tensor([[-0.5176, -5.4900],
        [-1.0270, -0.6252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1414860188961029
Epoch 0, Step 308: train/loss = 0.3577788174152374, train/raw-loss = 0.22793275117874146, train/logprobs = tensor([[-0.3984, -6.9069],
        [-0.7438, -0.5096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12984606623649597
Epoch 0, Step 309: train/loss = 0.4196280241012573, train/raw-loss = 0.2856345772743225, train/logprobs = tensor([[-0.5179, -3.9494],
        [-1.0780, -0.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339934915304184
Epoch 0, Step 310: train/loss = 0.3249126970767975, train/raw-loss = 0.17837867140769958, train/logprobs = tensor([[-0.5011, -6.1999],
        [-1.2534, -0.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465340256690979
Epoch 0, Step 311: train/loss = 0.3976954221725464, train/raw-loss = 0.24594345688819885, train/logprobs = tensor([[-0.4844, -4.4992],
        [-1.0088, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15175195038318634
Epoch 0, Step 312: train/loss = 0.41949278116226196, train/raw-loss = 0.31249698996543884, train/logprobs = tensor([[-0.3747, -5.1518],
        [-0.5116, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10699579119682312
Epoch 0, Step 313: train/loss = 0.48826563358306885, train/raw-loss = 0.36650922894477844, train/logprobs = tensor([[-0.5104, -4.3593],
        [-0.9304, -0.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12175637483596802
Epoch 0, Step 314: train/loss = 0.3969898223876953, train/raw-loss = 0.2736896276473999, train/logprobs = tensor([[-0.4581, -4.7805],
        [-0.7433, -0.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12330018728971481
Epoch 0, Step 315: train/loss = 0.3415240943431854, train/raw-loss = 0.1923632025718689, train/logprobs = tensor([[-0.5446, -7.2999],
        [-1.1342, -0.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14916087687015533
Epoch 0, Step 316: train/loss = 0.4080480933189392, train/raw-loss = 0.2514705955982208, train/logprobs = tensor([[-0.7715, -4.4467],
        [-1.1451, -0.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.156577467918396
Epoch 0, Step 317: train/loss = 0.36178457736968994, train/raw-loss = 0.22258734703063965, train/logprobs = tensor([[-0.5417, -4.7376],
        [-1.0047, -0.3860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391972154378891
Epoch 0, Step 318: train/loss = 0.4141841232776642, train/raw-loss = 0.2845113277435303, train/logprobs = tensor([[-0.4660, -5.2746],
        [-0.8693, -0.7954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1296727955341339
Epoch 0, Step 319: train/loss = 0.3857525587081909, train/raw-loss = 0.2534647583961487, train/logprobs = tensor([[-0.4364, -5.4885],
        [-0.8464, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13228778541088104
Epoch 0, Step 320: train/loss = 0.43141400814056396, train/raw-loss = 0.30935269594192505, train/logprobs = tensor([[-0.4885, -3.4406],
        [-0.9990, -0.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206130474805832
Epoch 0, Step 321: train/loss = 0.34784430265426636, train/raw-loss = 0.20926600694656372, train/logprobs = tensor([[-0.5514, -4.6097],
        [-1.1406, -0.5605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13857829570770264
Epoch 0, Step 322: train/loss = 0.3758922219276428, train/raw-loss = 0.2442396879196167, train/logprobs = tensor([[-0.5445, -4.6063],
        [-1.0180, -0.5869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316525787115097
Epoch 0, Step 323: train/loss = 0.3271453380584717, train/raw-loss = 0.21323737502098083, train/logprobs = tensor([[-0.4163, -6.9211],
        [-0.8923, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11390796303749084
Epoch 0, Step 324: train/loss = 0.34403449296951294, train/raw-loss = 0.21991872787475586, train/logprobs = tensor([[-0.4831, -4.9085],
        [-0.9833, -0.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12411576509475708
Epoch 0, Step 325: train/loss = 0.3366084694862366, train/raw-loss = 0.20812244713306427, train/logprobs = tensor([[-0.5448, -6.3077],
        [-1.0732, -0.5691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284860223531723
Epoch 0, Step 326: train/loss = 0.4113504886627197, train/raw-loss = 0.296896755695343, train/logprobs = tensor([[-0.5364, -3.4588],
        [-1.0051, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11445373296737671
Epoch 0, Step 327: train/loss = 0.41735053062438965, train/raw-loss = 0.31732088327407837, train/logprobs = tensor([[-0.3947, -3.0470],
        [-0.5352, -0.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10002966225147247
Epoch 0, Step 328: train/loss = 0.3745442032814026, train/raw-loss = 0.2581770420074463, train/logprobs = tensor([[-0.4248, -3.3250],
        [-0.7716, -0.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1163671463727951
Epoch 0, Step 329: train/loss = 0.3899071514606476, train/raw-loss = 0.27525991201400757, train/logprobs = tensor([[-0.4485, -3.4799],
        [-0.8005, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11464722454547882
Epoch 0, Step 330: train/loss = 0.4137933850288391, train/raw-loss = 0.28611478209495544, train/logprobs = tensor([[-0.4768, -4.4191],
        [-0.9661, -0.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12767863273620605
Epoch 0, Step 331: train/loss = 0.4244110882282257, train/raw-loss = 0.32096099853515625, train/logprobs = tensor([[-0.4587, -3.3995],
        [-0.8200, -0.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10345010459423065
Epoch 0, Step 332: train/loss = 0.3373814821243286, train/raw-loss = 0.21541696786880493, train/logprobs = tensor([[-0.4401, -6.9462],
        [-0.9569, -0.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12196452915668488
Epoch 0, Step 333: train/loss = 0.3575711250305176, train/raw-loss = 0.25477319955825806, train/logprobs = tensor([[-0.3840, -8.0681],
        [-0.5122, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10279792547225952
Epoch 0, Step 334: train/loss = 0.3537863790988922, train/raw-loss = 0.21996285021305084, train/logprobs = tensor([[-0.4975, -4.6282],
        [-1.0419, -0.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13382354378700256
Epoch 0, Step 335: train/loss = 0.3237534165382385, train/raw-loss = 0.2067582905292511, train/logprobs = tensor([[-0.4656, -8.8788],
        [-0.9378, -0.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11699511110782623
Epoch 0, Step 336: train/loss = 0.3275948762893677, train/raw-loss = 0.18786096572875977, train/logprobs = tensor([[-0.5739, -5.7917],
        [-1.2580, -0.3940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1397339105606079
Epoch 0, Step 337: train/loss = 0.3144325315952301, train/raw-loss = 0.1839628666639328, train/logprobs = tensor([[-0.4990, -6.4198],
        [-1.1783, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1304696500301361
Epoch 0, Step 338: train/loss = 0.3373512625694275, train/raw-loss = 0.2209813892841339, train/logprobs = tensor([[-0.4781, -5.9305],
        [-1.0262, -0.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11636988818645477
Epoch 0, Step 339: train/loss = 0.3529790937900543, train/raw-loss = 0.2568961977958679, train/logprobs = tensor([[-0.3511, -6.0979],
        [-0.5065, -0.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608285874128342
Epoch 0, Step 340: train/loss = 0.3782637119293213, train/raw-loss = 0.2623855769634247, train/logprobs = tensor([[-0.4427, -5.6823],
        [-0.9305, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11587811261415482
Epoch 0, Step 341: train/loss = 0.394512414932251, train/raw-loss = 0.25726890563964844, train/logprobs = tensor([[-0.4521, -4.1222],
        [-0.9267, -0.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13724349439144135
Epoch 0, Step 342: train/loss = 0.33503302931785583, train/raw-loss = 0.2167922705411911, train/logprobs = tensor([[-0.4727, -5.8211],
        [-0.9248, -0.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11824074387550354
Epoch 0, Step 343: train/loss = 0.38996952772140503, train/raw-loss = 0.2715427875518799, train/logprobs = tensor([[-0.4746, -3.8584],
        [-0.8134, -0.6539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11842671036720276
Epoch 0, Step 344: train/loss = 0.33470287919044495, train/raw-loss = 0.21275633573532104, train/logprobs = tensor([[-0.4890, -6.6577],
        [-1.0208, -0.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1219465434551239
Epoch 0, Step 345: train/loss = 0.40769249200820923, train/raw-loss = 0.2732158303260803, train/logprobs = tensor([[-0.5209, -6.3738],
        [-1.1359, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344766467809677
Epoch 0, Step 346: train/loss = 0.4413157105445862, train/raw-loss = 0.34194231033325195, train/logprobs = tensor([[-0.4708, -3.6946],
        [-0.8202, -0.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09937341511249542
Epoch 0, Step 347: train/loss = 0.3715822696685791, train/raw-loss = 0.25207582116127014, train/logprobs = tensor([[-0.5230, -5.7841],
        [-1.1458, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11950646340847015
Epoch 0, Step 348: train/loss = 0.33629047870635986, train/raw-loss = 0.22131980955600739, train/logprobs = tensor([[-0.4186, -6.7741],
        [-0.8471, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11497066169977188
Epoch 0, Step 349: train/loss = 0.38634616136550903, train/raw-loss = 0.29749494791030884, train/logprobs = tensor([[-0.4297, -4.0400],
        [-0.8129, -0.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08885122090578079
Epoch 0, Step 350: train/loss = 0.3430009186267853, train/raw-loss = 0.2370218187570572, train/logprobs = tensor([[-0.4598, -5.6154],
        [-0.8001, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597909241914749
Epoch 0, Step 351: train/loss = 0.42127281427383423, train/raw-loss = 0.30710411071777344, train/logprobs = tensor([[-0.4246, -7.1186],
        [-0.7326, -0.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11416870355606079
Epoch 0, Step 352: train/loss = 0.3417971730232239, train/raw-loss = 0.21709385514259338, train/logprobs = tensor([[-0.5142, -5.5097],
        [-1.1277, -0.3963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12470334023237228
Epoch 0, Step 353: train/loss = 0.3100879192352295, train/raw-loss = 0.19182586669921875, train/logprobs = tensor([[-0.5015, -5.2303],
        [-1.1852, -0.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11826205253601074
Epoch 0, Step 354: train/loss = 0.32324737310409546, train/raw-loss = 0.16173546016216278, train/logprobs = tensor([[-0.6156, -5.5929],
        [-1.4869, -0.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16151192784309387
Epoch 0, Step 355: train/loss = 0.3319534361362457, train/raw-loss = 0.23381361365318298, train/logprobs = tensor([[-0.4666, -6.5323],
        [-0.8324, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09813983738422394
Epoch 0, Step 356: train/loss = 0.33930259943008423, train/raw-loss = 0.2426270693540573, train/logprobs = tensor([[-0.3737, -7.0040],
        [-0.5951, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09667554497718811
Epoch 0, Step 357: train/loss = 0.35960134863853455, train/raw-loss = 0.2407013475894928, train/logprobs = tensor([[-0.4606, -4.6782],
        [-0.9912, -0.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11890000104904175
Epoch 0, Step 358: train/loss = 0.37159019708633423, train/raw-loss = 0.2652367949485779, train/logprobs = tensor([[-0.5228, -5.9444],
        [-1.0670, -0.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10635340213775635
Epoch 0, Step 359: train/loss = 0.32648521661758423, train/raw-loss = 0.17487117648124695, train/logprobs = tensor([[-0.6193, -5.1024],
        [-1.4910, -0.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516140252351761
Epoch 0, Step 360: train/loss = 0.32515087723731995, train/raw-loss = 0.1886887103319168, train/logprobs = tensor([[-0.5636, -5.4991],
        [-1.3080, -0.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13646215200424194
Epoch 0, Step 361: train/loss = 0.38002854585647583, train/raw-loss = 0.2659882605075836, train/logprobs = tensor([[-0.4448, -5.7739],
        [-0.8962, -0.5379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11404028534889221
Epoch 0, Step 362: train/loss = 0.3443971276283264, train/raw-loss = 0.23340341448783875, train/logprobs = tensor([[-0.4956, -4.7128],
        [-1.0365, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11099368333816528
Epoch 0, Step 363: train/loss = 0.3227955400943756, train/raw-loss = 0.22463886439800262, train/logprobs = tensor([[-0.4593, -5.0828],
        [-0.9398, -0.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09815667569637299
Epoch 0, Step 364: train/loss = 0.31327924132347107, train/raw-loss = 0.19253964722156525, train/logprobs = tensor([[-0.5223, -8.7777],
        [-1.1938, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12073957920074463
Epoch 0, Step 365: train/loss = 0.3880504369735718, train/raw-loss = 0.29487836360931396, train/logprobs = tensor([[-0.4569, -3.2751],
        [-0.7683, -0.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09317206591367722
Epoch 0, Step 366: train/loss = 0.3157414495944977, train/raw-loss = 0.2077053040266037, train/logprobs = tensor([[-0.4625, -7.2528],
        [-0.9617, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10803614556789398
Epoch 0, Step 367: train/loss = 0.3513225018978119, train/raw-loss = 0.2504291534423828, train/logprobs = tensor([[-0.4214, -4.0602],
        [-0.7662, -0.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10089336335659027
Epoch 0, Step 368: train/loss = 0.3723588287830353, train/raw-loss = 0.2652844190597534, train/logprobs = tensor([[-0.3743, -7.3535],
        [-0.6205, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707438737154007
Epoch 0, Step 369: train/loss = 0.3215082883834839, train/raw-loss = 0.19575712084770203, train/logprobs = tensor([[-0.4915, -6.6150],
        [-1.1805, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12575113773345947
Epoch 0, Step 370: train/loss = 0.32704129815101624, train/raw-loss = 0.20765411853790283, train/logprobs = tensor([[-0.5066, -6.9509],
        [-1.0777, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1193871796131134
Epoch 0, Step 371: train/loss = 0.41976743936538696, train/raw-loss = 0.2903372347354889, train/logprobs = tensor([[-0.5644, -5.7113],
        [-1.3070, -0.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12943023443222046
Epoch 0, Step 372: train/loss = 0.3595055341720581, train/raw-loss = 0.24953243136405945, train/logprobs = tensor([[-0.4714, -6.2041],
        [-0.9329, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10997312515974045
Epoch 0, Step 373: train/loss = 0.3601284623146057, train/raw-loss = 0.20403608679771423, train/logprobs = tensor([[-0.5272, -4.7668],
        [-1.1745, -0.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15609236061573029
Epoch 0, Step 374: train/loss = 0.36118632555007935, train/raw-loss = 0.2204105406999588, train/logprobs = tensor([[-0.6590, -5.7313],
        [-1.3485, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14077579975128174
Epoch 0, Step 375: train/loss = 0.29278039932250977, train/raw-loss = 0.16960793733596802, train/logprobs = tensor([[-0.5490, -6.2832],
        [-1.4387, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12317246198654175
Epoch 0, Step 376: train/loss = 0.34778058528900146, train/raw-loss = 0.22721901535987854, train/logprobs = tensor([[-0.4286, -5.5975],
        [-1.0204, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12056155502796173
Epoch 0, Step 377: train/loss = 0.32412752509117126, train/raw-loss = 0.17759975790977478, train/logprobs = tensor([[-0.6518, -6.3427],
        [-1.5009, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465277522802353
Epoch 0, Step 378: train/loss = 0.32518666982650757, train/raw-loss = 0.22604992985725403, train/logprobs = tensor([[-0.4143, -5.1557],
        [-0.8813, -0.6003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09913672506809235
Epoch 0, Step 379: train/loss = 0.39429038763046265, train/raw-loss = 0.29338374733924866, train/logprobs = tensor([[-0.5862, -3.8654],
        [-1.0826, -0.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1009066104888916
Epoch 0, Step 380: train/loss = 0.29993030428886414, train/raw-loss = 0.1733245700597763, train/logprobs = tensor([[-0.5175, -5.0721],
        [-1.3495, -0.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12660571932792664
Epoch 0, Step 381: train/loss = 0.3225312829017639, train/raw-loss = 0.2144235223531723, train/logprobs = tensor([[-0.4483, -6.0555],
        [-0.9615, -0.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10810776054859161
Epoch 0, Step 382: train/loss = 0.3144601285457611, train/raw-loss = 0.1981767863035202, train/logprobs = tensor([[-0.5089, -7.3220],
        [-1.1311, -0.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1162833422422409
Epoch 0, Step 383: train/loss = 0.44657421112060547, train/raw-loss = 0.3324166238307953, train/logprobs = tensor([[-0.5127, -3.1030],
        [-1.1149, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11415760219097137
Epoch 0, Step 384: train/loss = 0.34824466705322266, train/raw-loss = 0.24293790757656097, train/logprobs = tensor([[-0.3728, -4.9615],
        [-0.7375, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10530678182840347
Epoch 0, Step 385: train/loss = 0.3611598014831543, train/raw-loss = 0.24091041088104248, train/logprobs = tensor([[-0.4482, -5.7259],
        [-1.0555, -0.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12024938315153122
Epoch 0, Step 386: train/loss = 0.3334343135356903, train/raw-loss = 0.22998595237731934, train/logprobs = tensor([[-0.3308, -6.2998],
        [-0.6367, -0.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10344834625720978
Epoch 0, Step 387: train/loss = 0.38354581594467163, train/raw-loss = 0.26985520124435425, train/logprobs = tensor([[-0.4285, -3.8723],
        [-0.9212, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11369064450263977
Epoch 0, Step 388: train/loss = 0.3232869505882263, train/raw-loss = 0.1995319277048111, train/logprobs = tensor([[-0.4845, -6.7570],
        [-1.0474, -0.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12375501543283463
Epoch 0, Step 389: train/loss = 0.3486200273036957, train/raw-loss = 0.2103177160024643, train/logprobs = tensor([[-0.4122, -5.2678],
        [-0.9870, -0.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13830231130123138
Epoch 0, Step 390: train/loss = 0.3340193033218384, train/raw-loss = 0.21266333758831024, train/logprobs = tensor([[-0.4303, -6.4861],
        [-0.8607, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12135598063468933
Epoch 0, Step 391: train/loss = 0.3154098391532898, train/raw-loss = 0.16367118060588837, train/logprobs = tensor([[-0.5576, -7.0193],
        [-1.4882, -0.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15173867344856262
Epoch 0, Step 392: train/loss = 0.33224350214004517, train/raw-loss = 0.20200929045677185, train/logprobs = tensor([[-0.4322, -5.7856],
        [-0.9928, -0.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13023421168327332
Epoch 0, Step 393: train/loss = 0.4067949652671814, train/raw-loss = 0.2931906580924988, train/logprobs = tensor([[-0.4292, -5.3542],
        [-0.8557, -0.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11360430717468262
Epoch 0, Step 394: train/loss = 0.3729633688926697, train/raw-loss = 0.24701745808124542, train/logprobs = tensor([[-0.4287, -6.2938],
        [-0.6980, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12594594061374664
Epoch 0, Step 395: train/loss = 0.295371413230896, train/raw-loss = 0.17785149812698364, train/logprobs = tensor([[-0.4958, -8.5901],
        [-1.2255, -0.7837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11751993745565414
Epoch 0, Step 396: train/loss = 0.3189501166343689, train/raw-loss = 0.20595580339431763, train/logprobs = tensor([[-0.4919, -6.7636],
        [-1.0631, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11299431324005127
Epoch 0, Step 397: train/loss = 0.37912070751190186, train/raw-loss = 0.2528732120990753, train/logprobs = tensor([[-0.4451, -5.0540],
        [-0.8706, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12624754011631012
Epoch 0, Step 398: train/loss = 0.31986096501350403, train/raw-loss = 0.19787681102752686, train/logprobs = tensor([[-0.4521, -7.7941],
        [-1.0062, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12198416143655777
Epoch 0, Step 399: train/loss = 0.434006929397583, train/raw-loss = 0.31423208117485046, train/logprobs = tensor([[-0.3931, -2.6321],
        [-0.8624, -0.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11977487057447433
Epoch 0, Step 400: train/loss = 0.3752135634422302, train/raw-loss = 0.2415224313735962, train/logprobs = tensor([[-0.4539, -5.4339],
        [-0.9779, -0.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13369113206863403
Epoch 0, Step 401: train/loss = 0.3269634544849396, train/raw-loss = 0.21846722066402435, train/logprobs = tensor([[-0.4015, -5.2007],
        [-0.8133, -0.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10849623382091522
Epoch 0, Step 402: train/loss = 0.3415490388870239, train/raw-loss = 0.23193597793579102, train/logprobs = tensor([[-0.4158, -7.0000],
        [-0.7404, -0.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10961306095123291
Epoch 0, Step 403: train/loss = 0.43949663639068604, train/raw-loss = 0.3286609351634979, train/logprobs = tensor([[-0.3532, -6.0264],
        [-0.4981, -0.4671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11083570122718811
Epoch 0, Step 404: train/loss = 0.3423404097557068, train/raw-loss = 0.218074768781662, train/logprobs = tensor([[-0.4798, -4.6483],
        [-1.0567, -0.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124265655875206
Epoch 0, Step 405: train/loss = 0.3142208755016327, train/raw-loss = 0.1992689073085785, train/logprobs = tensor([[-0.5420, -4.9170],
        [-1.2891, -0.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1149519681930542
Epoch 0, Step 406: train/loss = 0.3474758565425873, train/raw-loss = 0.23816096782684326, train/logprobs = tensor([[-0.4266, -6.8704],
        [-0.7737, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10931491106748581
Epoch 0, Step 407: train/loss = 0.3835803270339966, train/raw-loss = 0.2638002336025238, train/logprobs = tensor([[-0.4686, -4.2529],
        [-1.0257, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11978008598089218
Epoch 0, Step 408: train/loss = 0.37752240896224976, train/raw-loss = 0.24689345061779022, train/logprobs = tensor([[-0.5145, -5.2127],
        [-1.0656, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13062895834445953
Epoch 0, Step 409: train/loss = 0.32108771800994873, train/raw-loss = 0.19972851872444153, train/logprobs = tensor([[-0.4727, -4.4832],
        [-1.2386, -0.3656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1213592141866684
Epoch 0, Step 410: train/loss = 0.38551369309425354, train/raw-loss = 0.27603501081466675, train/logprobs = tensor([[-0.3709, -5.1600],
        [-0.6821, -0.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10947869718074799
Epoch 0, Step 411: train/loss = 0.31869733333587646, train/raw-loss = 0.20700402557849884, train/logprobs = tensor([[-0.5071, -5.5606],
        [-1.1742, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11169330775737762
Epoch 0, Step 412: train/loss = 0.4233494997024536, train/raw-loss = 0.3117420971393585, train/logprobs = tensor([[-0.4337, -4.1103],
        [-0.8313, -0.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11160740256309509
Epoch 0, Step 413: train/loss = 0.3245467245578766, train/raw-loss = 0.18465669453144073, train/logprobs = tensor([[-0.4641, -6.6947],
        [-1.1026, -0.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13989004492759705
Epoch 0, Step 414: train/loss = 0.30179980397224426, train/raw-loss = 0.17775732278823853, train/logprobs = tensor([[-0.5189, -5.3777],
        [-1.3032, -0.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12404248118400574
Epoch 0, Step 415: train/loss = 0.28683438897132874, train/raw-loss = 0.16293413937091827, train/logprobs = tensor([[-0.6001, -6.6306],
        [-1.4396, -0.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12390024960041046
Epoch 0, Step 416: train/loss = 0.3303401470184326, train/raw-loss = 0.20169749855995178, train/logprobs = tensor([[-0.4529, -5.0439],
        [-1.0249, -0.3560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12864263355731964
Epoch 0, Step 417: train/loss = 0.3772898316383362, train/raw-loss = 0.2801303267478943, train/logprobs = tensor([[-0.6450, -5.6697],
        [-1.1144, -0.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0971594899892807
Epoch 0, Step 418: train/loss = 0.31770485639572144, train/raw-loss = 0.17808377742767334, train/logprobs = tensor([[-0.4680, -5.9843],
        [-1.2518, -0.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396210938692093
Epoch 0, Step 419: train/loss = 0.3573777377605438, train/raw-loss = 0.24093271791934967, train/logprobs = tensor([[-0.3742, -4.8742],
        [-0.7294, -0.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11644501239061356
Epoch 0, Step 420: train/loss = 0.3108862340450287, train/raw-loss = 0.19135120511054993, train/logprobs = tensor([[-0.5253, -8.2265],
        [-1.1044, -0.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11953502893447876
Epoch 0, Step 421: train/loss = 0.36331015825271606, train/raw-loss = 0.22896505892276764, train/logprobs = tensor([[-0.3706, -5.2207],
        [-0.7666, -0.3187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13434511423110962
Epoch 0, Step 422: train/loss = 0.2913638949394226, train/raw-loss = 0.16562359035015106, train/logprobs = tensor([[-0.5261, -5.7123],
        [-1.4707, -0.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12574027478694916
Epoch 0, Step 423: train/loss = 0.3261581361293793, train/raw-loss = 0.17756424844264984, train/logprobs = tensor([[-0.5502, -4.7138],
        [-1.3334, -0.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14859388768672943
Epoch 0, Step 424: train/loss = 0.39558863639831543, train/raw-loss = 0.2942110300064087, train/logprobs = tensor([[-0.4314, -6.1898],
        [-0.9550, -0.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10137765109539032
Epoch 0, Step 425: train/loss = 0.35467636585235596, train/raw-loss = 0.22101272642612457, train/logprobs = tensor([[-0.5190, -6.1468],
        [-0.9546, -0.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13366365432739258
Epoch 0, Step 426: train/loss = 0.36255088448524475, train/raw-loss = 0.25946980714797974, train/logprobs = tensor([[-0.3657, -7.0615],
        [-0.5768, -0.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10308107733726501
Epoch 0, Step 427: train/loss = 0.3302539587020874, train/raw-loss = 0.2095264196395874, train/logprobs = tensor([[-0.4283, -6.8838],
        [-0.9099, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1207275316119194
Epoch 0, Step 428: train/loss = 0.3904035687446594, train/raw-loss = 0.24405187368392944, train/logprobs = tensor([[-0.5207, -5.1041],
        [-1.3219, -0.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463516801595688
Epoch 0, Step 429: train/loss = 0.3374880254268646, train/raw-loss = 0.2050783336162567, train/logprobs = tensor([[-0.4531, -6.8533],
        [-0.9534, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324096918106079
Epoch 0, Step 430: train/loss = 0.39353564381599426, train/raw-loss = 0.2885528802871704, train/logprobs = tensor([[-0.4382, -3.9158],
        [-1.0082, -0.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10498277842998505
Epoch 0, Step 431: train/loss = 0.34984129667282104, train/raw-loss = 0.23589032888412476, train/logprobs = tensor([[-0.4282, -5.7482],
        [-0.7550, -0.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11395098268985748
Epoch 0, Step 432: train/loss = 0.43698281049728394, train/raw-loss = 0.3168390393257141, train/logprobs = tensor([[-0.3953, -3.3818],
        [-0.8380, -0.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12014378607273102
Epoch 0, Step 433: train/loss = 0.3506859242916107, train/raw-loss = 0.23444920778274536, train/logprobs = tensor([[-0.4367, -6.3553],
        [-0.7085, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11623670905828476
Epoch 0, Step 434: train/loss = 0.3467945456504822, train/raw-loss = 0.22772318124771118, train/logprobs = tensor([[-0.4487, -4.3965],
        [-0.9821, -0.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1190713420510292
Epoch 0, Step 435: train/loss = 0.33431434631347656, train/raw-loss = 0.22880858182907104, train/logprobs = tensor([[-0.4371, -8.1470],
        [-0.7488, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10550576448440552
Epoch 0, Step 436: train/loss = 0.3172304034233093, train/raw-loss = 0.19181334972381592, train/logprobs = tensor([[-0.4431, -6.8867],
        [-1.1333, -0.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254170536994934
Epoch 0, Step 437: train/loss = 0.2982887625694275, train/raw-loss = 0.15877081453800201, train/logprobs = tensor([[-0.6051, -7.3097],
        [-1.4851, -0.5236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13951794803142548
Epoch 0, Step 438: train/loss = 0.3218265473842621, train/raw-loss = 0.1734117865562439, train/logprobs = tensor([[-0.4971, -6.3058],
        [-1.4274, -0.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484147608280182
Epoch 0, Step 439: train/loss = 0.3405691385269165, train/raw-loss = 0.17046940326690674, train/logprobs = tensor([[-0.5045, -6.1207],
        [-1.3403, -0.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17009973526000977
Epoch 0, Step 440: train/loss = 0.3392587900161743, train/raw-loss = 0.19127337634563446, train/logprobs = tensor([[-0.4513, -5.0573],
        [-1.0845, -0.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14798544347286224
Epoch 0, Step 441: train/loss = 0.269158273935318, train/raw-loss = 0.13097935914993286, train/logprobs = tensor([[-0.6743, -6.7554],
        [-1.8605, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13817891478538513
Epoch 0, Step 442: train/loss = 0.3205031454563141, train/raw-loss = 0.19874846935272217, train/logprobs = tensor([[-0.4646, -5.3294],
        [-1.0957, -0.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12175465375185013
Epoch 0, Step 443: train/loss = 0.37404578924179077, train/raw-loss = 0.2583465576171875, train/logprobs = tensor([[-0.3798, -5.6456],
        [-0.6986, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569926142692566
Epoch 0, Step 444: train/loss = 0.30820316076278687, train/raw-loss = 0.18414939939975739, train/logprobs = tensor([[-0.5688, -7.2432],
        [-1.2855, -0.5523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12405376136302948
Epoch 0, Step 445: train/loss = 0.41315850615501404, train/raw-loss = 0.2983686923980713, train/logprobs = tensor([[-0.4502, -3.9854],
        [-0.7737, -0.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478982865810394
Epoch 0, Step 446: train/loss = 0.3817332684993744, train/raw-loss = 0.28412285447120667, train/logprobs = tensor([[-0.3288, -3.5617],
        [-0.6107, -0.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761044383049011
Epoch 0, Step 447: train/loss = 0.29612791538238525, train/raw-loss = 0.17375071346759796, train/logprobs = tensor([[-0.5325, -4.6820],
        [-1.3751, -0.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12237720191478729
Epoch 0, Step 448: train/loss = 0.3851606249809265, train/raw-loss = 0.28135502338409424, train/logprobs = tensor([[-0.4044, -4.4586],
        [-0.7673, -0.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10380557924509048
Epoch 0, Step 449: train/loss = 0.29388803243637085, train/raw-loss = 0.16185258328914642, train/logprobs = tensor([[-0.5054, -7.0545],
        [-1.3724, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13203543424606323
Epoch 0, Step 450: train/loss = 0.2706897258758545, train/raw-loss = 0.13809475302696228, train/logprobs = tensor([[-0.4874, -9.4275],
        [-1.5825, -0.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13259495794773102
Epoch 0, Step 451: train/loss = 0.4097858667373657, train/raw-loss = 0.3151668906211853, train/logprobs = tensor([[-0.3219, -4.9833],
        [-0.5224, -0.3718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09461895376443863
Epoch 0, Step 452: train/loss = 0.3363632559776306, train/raw-loss = 0.23320379853248596, train/logprobs = tensor([[-0.3945, -6.6044],
        [-0.7236, -0.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10315944999456406
Epoch 0, Step 453: train/loss = 0.30444398522377014, train/raw-loss = 0.1885877549648285, train/logprobs = tensor([[-0.5608, -6.3438],
        [-1.2914, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11585623025894165
Epoch 0, Step 454: train/loss = 0.35528242588043213, train/raw-loss = 0.23619022965431213, train/logprobs = tensor([[-0.3993, -5.3047],
        [-0.9273, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11909222602844238
Epoch 0, Step 455: train/loss = 0.32786574959754944, train/raw-loss = 0.17664013803005219, train/logprobs = tensor([[-0.5443, -4.5679],
        [-1.5636, -0.5297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15122558176517487
Epoch 0, Step 456: train/loss = 0.43433764576911926, train/raw-loss = 0.33136942982673645, train/logprobs = tensor([[-0.3640, -5.2387],
        [-0.6127, -0.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10296821594238281
Epoch 0, Step 457: train/loss = 0.3025267720222473, train/raw-loss = 0.16777411103248596, train/logprobs = tensor([[-0.5499, -5.8154],
        [-1.5190, -0.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13475267589092255
Epoch 0, Step 458: train/loss = 0.31853967905044556, train/raw-loss = 0.18363124132156372, train/logprobs = tensor([[-0.4399, -7.0203],
        [-1.1906, -0.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13490843772888184
Epoch 0, Step 459: train/loss = 0.3285730481147766, train/raw-loss = 0.21499255299568176, train/logprobs = tensor([[-0.3699, -5.2052],
        [-0.8589, -0.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11358048021793365
Epoch 0, Step 460: train/loss = 0.3194132149219513, train/raw-loss = 0.21096108853816986, train/logprobs = tensor([[-0.4429, -6.4095],
        [-0.9181, -0.5856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10845212638378143
Epoch 0, Step 461: train/loss = 0.35470065474510193, train/raw-loss = 0.23753371834754944, train/logprobs = tensor([[-0.4608, -4.6255],
        [-1.0326, -0.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716696619987488
Epoch 0, Step 462: train/loss = 0.32619160413742065, train/raw-loss = 0.21989309787750244, train/logprobs = tensor([[-0.3676, -7.4257],
        [-0.7523, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062985211610794
Epoch 0, Step 463: train/loss = 0.31888216733932495, train/raw-loss = 0.17947757244110107, train/logprobs = tensor([[-0.4632, -7.8074],
        [-1.1448, -0.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940460979938507
Epoch 0, Step 464: train/loss = 0.31169217824935913, train/raw-loss = 0.18905916810035706, train/logprobs = tensor([[-0.4463, -8.2647],
        [-1.0667, -0.5155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12263301014900208
Epoch 0, Step 465: train/loss = 0.3418840765953064, train/raw-loss = 0.21122080087661743, train/logprobs = tensor([[-0.3922, -6.6146],
        [-0.8936, -0.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13066324591636658
Epoch 0, Step 466: train/loss = 0.3425143361091614, train/raw-loss = 0.18443401157855988, train/logprobs = tensor([[-0.4276, -6.4386],
        [-1.2426, -0.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1580803096294403
Epoch 0, Step 467: train/loss = 0.2965151071548462, train/raw-loss = 0.1819494068622589, train/logprobs = tensor([[-0.5193, -7.6757],
        [-1.3044, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456571519374847
Epoch 0, Step 468: train/loss = 0.3291166424751282, train/raw-loss = 0.22061148285865784, train/logprobs = tensor([[-0.4098, -6.5244],
        [-0.7750, -0.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10850518941879272
Epoch 0, Step 469: train/loss = 0.2986147701740265, train/raw-loss = 0.16104207932949066, train/logprobs = tensor([[-0.5277, -6.3193],
        [-1.3533, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13757269084453583
Epoch 0, Step 470: train/loss = 0.2862875461578369, train/raw-loss = 0.17034126818180084, train/logprobs = tensor([[-0.4868, -6.1024],
        [-1.3268, -0.4382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11594629287719727
Epoch 0, Step 471: train/loss = 0.28418058156967163, train/raw-loss = 0.16597971320152283, train/logprobs = tensor([[-0.4308, -7.2980],
        [-1.2651, -0.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182008683681488
Epoch 0, Step 472: train/loss = 0.32040995359420776, train/raw-loss = 0.20421914756298065, train/logprobs = tensor([[-0.5500, -7.4559],
        [-1.1021, -0.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1161908507347107
Epoch 0, Step 473: train/loss = 0.3205772638320923, train/raw-loss = 0.21638625860214233, train/logprobs = tensor([[-0.4054, -7.8930],
        [-0.8355, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10419102758169174
Epoch 0, Step 474: train/loss = 0.4181349277496338, train/raw-loss = 0.32253819704055786, train/logprobs = tensor([[-0.4596, -4.6920],
        [-0.7999, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09559676796197891
Epoch 0, Step 475: train/loss = 0.3325715661048889, train/raw-loss = 0.21500638127326965, train/logprobs = tensor([[-0.4724, -5.9405],
        [-0.9242, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756519973278046
Epoch 0, Step 476: train/loss = 0.3425895571708679, train/raw-loss = 0.2195163518190384, train/logprobs = tensor([[-0.4859, -4.1706],
        [-1.1227, -0.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12307319045066833
Epoch 0, Step 477: train/loss = 0.30560457706451416, train/raw-loss = 0.1434604674577713, train/logprobs = tensor([[-0.5494, -6.2821],
        [-1.6540, -0.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16214409470558167
Epoch 0, Step 478: train/loss = 0.3969624936580658, train/raw-loss = 0.28505581617355347, train/logprobs = tensor([[-0.4592, -5.2273],
        [-0.9189, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190669238567352
Epoch 0, Step 479: train/loss = 0.3171728253364563, train/raw-loss = 0.21525312960147858, train/logprobs = tensor([[-0.3826, -5.4753],
        [-0.8655, -0.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191971063613892
Epoch 0, Step 480: train/loss = 0.31401193141937256, train/raw-loss = 0.21467402577400208, train/logprobs = tensor([[-0.3725, -7.7562],
        [-0.8031, -0.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09933792054653168
Epoch 0, Step 481: train/loss = 0.2691316604614258, train/raw-loss = 0.1580711156129837, train/logprobs = tensor([[-0.5014, -9.2011],
        [-1.4538, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11106055974960327
Epoch 0, Step 482: train/loss = 0.328587144613266, train/raw-loss = 0.23157596588134766, train/logprobs = tensor([[-0.4551, -5.1392],
        [-0.9766, -0.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09701117128133774
Epoch 0, Step 483: train/loss = 0.35993635654449463, train/raw-loss = 0.2583732306957245, train/logprobs = tensor([[-0.4042, -4.0754],
        [-1.0075, -0.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10156310349702835
Epoch 0, Step 484: train/loss = 0.3390941619873047, train/raw-loss = 0.2408161759376526, train/logprobs = tensor([[-0.4948, -5.4813],
        [-0.8983, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982779860496521
Epoch 0, Step 485: train/loss = 0.3098430335521698, train/raw-loss = 0.19119764864444733, train/logprobs = tensor([[-0.5359, -4.8595],
        [-1.3319, -0.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11864539980888367
Epoch 0, Step 486: train/loss = 0.32772067189216614, train/raw-loss = 0.20402322709560394, train/logprobs = tensor([[-0.4114, -6.1862],
        [-1.0256, -0.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.123697429895401
Epoch 0, Step 487: train/loss = 0.3404116630554199, train/raw-loss = 0.2257622629404068, train/logprobs = tensor([[-0.3978, -6.5753],
        [-0.8389, -0.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11464940011501312
Epoch 0, Step 488: train/loss = 0.35714641213417053, train/raw-loss = 0.2668441832065582, train/logprobs = tensor([[-0.4226, -5.9164],
        [-0.7730, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09030221402645111
Epoch 0, Step 489: train/loss = 0.3580774664878845, train/raw-loss = 0.23431845009326935, train/logprobs = tensor([[-0.4120, -4.8317],
        [-0.9129, -0.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12375903129577637
Epoch 0, Step 490: train/loss = 0.3131428360939026, train/raw-loss = 0.21830882132053375, train/logprobs = tensor([[-0.3783, -6.4060],
        [-0.9152, -0.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483401477336884
Epoch 0, Step 491: train/loss = 0.3368677794933319, train/raw-loss = 0.21690210700035095, train/logprobs = tensor([[-0.4414, -7.5312],
        [-1.0214, -0.7789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11996567249298096
Epoch 0, Step 492: train/loss = 0.3094062805175781, train/raw-loss = 0.20643609762191772, train/logprobs = tensor([[-0.3556, -5.2727],
        [-0.9284, -0.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10297014564275742
Epoch 0, Step 493: train/loss = 0.3237660229206085, train/raw-loss = 0.20027709007263184, train/logprobs = tensor([[-0.3842, -5.5864],
        [-1.0748, -0.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12348895519971848
Epoch 0, Step 494: train/loss = 0.3043861985206604, train/raw-loss = 0.19732168316841125, train/logprobs = tensor([[-0.4314, -6.4203],
        [-1.2016, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10706452280282974
Epoch 0, Step 495: train/loss = 0.30831289291381836, train/raw-loss = 0.15210595726966858, train/logprobs = tensor([[-0.5166, -5.2278],
        [-1.5525, -0.3593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15620696544647217
Epoch 0, Step 496: train/loss = 0.3054571747779846, train/raw-loss = 0.2016167938709259, train/logprobs = tensor([[-0.4104, -6.9312],
        [-1.0155, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10384039580821991
Epoch 0, Step 497: train/loss = 0.34152838587760925, train/raw-loss = 0.22635792195796967, train/logprobs = tensor([[-0.4030, -6.2728],
        [-0.9995, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1151704490184784
Epoch 0, Step 498: train/loss = 0.4168738126754761, train/raw-loss = 0.33650946617126465, train/logprobs = tensor([[-0.3546, -3.3021],
        [-0.6318, -0.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08036436140537262
Epoch 0, Step 499: train/loss = 0.3244766891002655, train/raw-loss = 0.23210299015045166, train/logprobs = tensor([[-0.3468, -8.4554],
        [-0.6216, -0.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09237368404865265
Epoch 0, Step 500: train/loss = 0.2925856113433838, train/raw-loss = 0.1656014621257782, train/logprobs = tensor([[-0.4850, -6.1642],
        [-1.4625, -0.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12698416411876678
Epoch 0, Step 501: train/loss = 0.35560789704322815, train/raw-loss = 0.2541612386703491, train/logprobs = tensor([[-0.4277, -5.0556],
        [-0.8569, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10144664347171783
Epoch 0, Step 502: train/loss = 0.3175657391548157, train/raw-loss = 0.20329144597053528, train/logprobs = tensor([[-0.5349, -6.7709],
        [-1.4418, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1142742782831192
Epoch 0, Step 503: train/loss = 0.3765065371990204, train/raw-loss = 0.27128249406814575, train/logprobs = tensor([[-0.3659, -6.6617],
        [-0.5638, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10522399097681046
Epoch 0, Step 504: train/loss = 0.3636467158794403, train/raw-loss = 0.2632509768009186, train/logprobs = tensor([[-0.3432, -5.9725],
        [-0.6914, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039573907852173
Epoch 0, Step 505: train/loss = 0.3100653886795044, train/raw-loss = 0.213335320353508, train/logprobs = tensor([[-0.4018, -5.1037],
        [-0.8989, -0.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0967300683259964
Epoch 0, Step 506: train/loss = 0.31050437688827515, train/raw-loss = 0.19955191016197205, train/logprobs = tensor([[-0.3609, -5.6747],
        [-0.9086, -0.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109524816274643
Epoch 0, Step 507: train/loss = 0.3734199106693268, train/raw-loss = 0.26593685150146484, train/logprobs = tensor([[-0.4510, -5.4945],
        [-0.7089, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748308897018433
Epoch 0, Step 508: train/loss = 0.30426278710365295, train/raw-loss = 0.2098618447780609, train/logprobs = tensor([[-0.4315, -8.4518],
        [-0.8651, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09440094977617264
Epoch 0, Step 509: train/loss = 0.3743084669113159, train/raw-loss = 0.2638593316078186, train/logprobs = tensor([[-0.3906, -6.0329],
        [-0.7354, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11044913530349731
Epoch 0, Step 510: train/loss = 0.4002019464969635, train/raw-loss = 0.31604644656181335, train/logprobs = tensor([[-0.4057, -5.7456],
        [-0.6637, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08415549248456955
Epoch 0, Step 511: train/loss = 0.35009199380874634, train/raw-loss = 0.2517194151878357, train/logprobs = tensor([[-0.4052, -6.0852],
        [-0.7871, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09837260842323303
Epoch 0, Step 512: train/loss = 0.3124561309814453, train/raw-loss = 0.20736834406852722, train/logprobs = tensor([[-0.4782, -6.8279],
        [-1.0655, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10508780181407928
Epoch 0, Step 513: train/loss = 0.4706052541732788, train/raw-loss = 0.3830627202987671, train/logprobs = tensor([[-0.3252, -2.9964],
        [-0.5960, -0.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754251152276993
Epoch 0, Step 514: train/loss = 0.3324289321899414, train/raw-loss = 0.22045685350894928, train/logprobs = tensor([[-0.4709, -7.2277],
        [-0.8649, -0.4880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11197207868099213
Epoch 0, Step 515: train/loss = 0.30154889822006226, train/raw-loss = 0.16986653208732605, train/logprobs = tensor([[-0.5293, -6.0690],
        [-1.4390, -0.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316823661327362
Epoch 0, Step 516: train/loss = 0.2784694731235504, train/raw-loss = 0.15309229493141174, train/logprobs = tensor([[-0.5594, -7.7669],
        [-1.5731, -0.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12537720799446106
Epoch 0, Step 517: train/loss = 0.3067719042301178, train/raw-loss = 0.20303158462047577, train/logprobs = tensor([[-0.4435, -5.3959],
        [-1.1539, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10374034196138382
Epoch 0, Step 518: train/loss = 0.32649320363998413, train/raw-loss = 0.23733487725257874, train/logprobs = tensor([[-0.4241, -5.8194],
        [-0.8503, -0.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08915834128856659
Epoch 0, Step 519: train/loss = 0.3060222864151001, train/raw-loss = 0.18163707852363586, train/logprobs = tensor([[-0.4124, -6.8947],
        [-1.1310, -0.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12438520789146423
Epoch 0, Step 520: train/loss = 0.3223966062068939, train/raw-loss = 0.22773566842079163, train/logprobs = tensor([[-0.3865, -4.8133],
        [-0.8652, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0946609154343605
Epoch 0, Step 521: train/loss = 0.2991264760494232, train/raw-loss = 0.17476031184196472, train/logprobs = tensor([[-0.5009, -5.8295],
        [-1.4561, -0.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1243661642074585
Epoch 0, Step 522: train/loss = 0.32002151012420654, train/raw-loss = 0.18794170022010803, train/logprobs = tensor([[-0.4565, -5.2602],
        [-1.2733, -0.3211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320798099040985
Epoch 0, Step 523: train/loss = 0.3214253783226013, train/raw-loss = 0.2137974351644516, train/logprobs = tensor([[-0.6714, -6.7726],
        [-1.6209, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762796550989151
Epoch 0, Step 524: train/loss = 0.3572140336036682, train/raw-loss = 0.25703585147857666, train/logprobs = tensor([[-0.4058, -5.3746],
        [-0.9004, -0.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017819702625275
Epoch 0, Step 525: train/loss = 0.28279590606689453, train/raw-loss = 0.17372643947601318, train/logprobs = tensor([[-0.4321, -7.1287],
        [-1.2045, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906947404146194
Epoch 0, Step 526: train/loss = 0.3176209330558777, train/raw-loss = 0.22539684176445007, train/logprobs = tensor([[-0.4560, -7.6263],
        [-0.8294, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0922241061925888
Epoch 0, Step 527: train/loss = 0.31067904829978943, train/raw-loss = 0.22343169152736664, train/logprobs = tensor([[-0.4400, -4.2764],
        [-1.0619, -0.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0872473418712616
Epoch 0, Step 528: train/loss = 0.29292726516723633, train/raw-loss = 0.18108218908309937, train/logprobs = tensor([[-0.4250, -6.9887],
        [-1.1148, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11184505373239517
Epoch 0, Step 529: train/loss = 0.3906531035900116, train/raw-loss = 0.27728986740112305, train/logprobs = tensor([[-0.5719, -4.1286],
        [-1.3795, -0.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11336325109004974
Epoch 0, Step 530: train/loss = 0.3316974937915802, train/raw-loss = 0.2461114078760147, train/logprobs = tensor([[-0.3148, -6.0148],
        [-0.5513, -0.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0855860710144043
Epoch 0, Step 531: train/loss = 0.33055663108825684, train/raw-loss = 0.24873609840869904, train/logprobs = tensor([[-0.4142, -6.0317],
        [-0.6718, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818205252289772
Epoch 0, Step 532: train/loss = 0.31436416506767273, train/raw-loss = 0.20989130437374115, train/logprobs = tensor([[-0.3680, -4.5633],
        [-0.9645, -0.5441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447287559509277
Epoch 0, Step 533: train/loss = 0.37756967544555664, train/raw-loss = 0.26466071605682373, train/logprobs = tensor([[-0.4352, -4.6456],
        [-1.1445, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11290892958641052
Epoch 0, Step 534: train/loss = 0.35495465993881226, train/raw-loss = 0.24425746500492096, train/logprobs = tensor([[-0.3614, -4.4071],
        [-0.8398, -0.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106972023844719
Epoch 0, Step 535: train/loss = 0.3241051137447357, train/raw-loss = 0.22532883286476135, train/logprobs = tensor([[-0.4282, -5.2168],
        [-0.9313, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09877628833055496
Epoch 0, Step 536: train/loss = 0.3058834671974182, train/raw-loss = 0.1929883360862732, train/logprobs = tensor([[-0.4594, -3.9755],
        [-1.3802, -0.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289513111114502
Epoch 0, Step 537: train/loss = 0.29797205328941345, train/raw-loss = 0.19393473863601685, train/logprobs = tensor([[-0.5129, -5.9348],
        [-1.2900, -0.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10403728485107422
Epoch 0, Step 538: train/loss = 0.31751298904418945, train/raw-loss = 0.2099524438381195, train/logprobs = tensor([[-0.3558, -6.2109],
        [-0.9403, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10756056010723114
Epoch 0, Step 539: train/loss = 0.2912517786026001, train/raw-loss = 0.18793687224388123, train/logprobs = tensor([[-0.3880, -5.9503],
        [-1.0381, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10331489890813828
Epoch 0, Step 540: train/loss = 0.3256444036960602, train/raw-loss = 0.20641180872917175, train/logprobs = tensor([[-0.4498, -6.1308],
        [-1.1534, -0.5727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11923260241746902
Epoch 0, Step 541: train/loss = 0.2908298671245575, train/raw-loss = 0.18712696433067322, train/logprobs = tensor([[-0.3499, -6.9671],
        [-1.0054, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370288044214249
Epoch 0, Step 542: train/loss = 0.26589909195899963, train/raw-loss = 0.13778835535049438, train/logprobs = tensor([[-0.5548, -5.0094],
        [-1.6700, -0.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12811073660850525
Epoch 0, Step 543: train/loss = 0.29882192611694336, train/raw-loss = 0.16643774509429932, train/logprobs = tensor([[-0.5527, -6.5184],
        [-1.4734, -0.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13238418102264404
Epoch 0, Step 544: train/loss = 0.34069299697875977, train/raw-loss = 0.23399806022644043, train/logprobs = tensor([[-0.3940, -4.7185],
        [-0.9097, -0.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10669492185115814
Epoch 0, Step 545: train/loss = 0.2953627407550812, train/raw-loss = 0.1841546893119812, train/logprobs = tensor([[-0.4571, -5.1719],
        [-1.2009, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11120803654193878
Epoch 0, Step 546: train/loss = 0.3057619333267212, train/raw-loss = 0.22188445925712585, train/logprobs = tensor([[-0.3660, -6.1248],
        [-0.8168, -0.4482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387748897075653
Epoch 0, Step 547: train/loss = 0.32304102182388306, train/raw-loss = 0.2137705236673355, train/logprobs = tensor([[-0.3759, -4.8684],
        [-0.9818, -0.4166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10927046835422516
Epoch 0, Step 548: train/loss = 0.32189425826072693, train/raw-loss = 0.20732805132865906, train/logprobs = tensor([[-0.4154, -5.5535],
        [-1.0141, -0.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456619203090668
Epoch 0, Step 549: train/loss = 0.25423067808151245, train/raw-loss = 0.13385502994060516, train/logprobs = tensor([[-0.5336, -4.9778],
        [-1.7564, -0.4310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12037564814090729
Epoch 0, Step 550: train/loss = 0.30138343572616577, train/raw-loss = 0.2030099779367447, train/logprobs = tensor([[-0.4380, -8.8203],
        [-0.9140, -0.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09837345778942108
Epoch 0, Step 551: train/loss = 0.320841908454895, train/raw-loss = 0.1776837706565857, train/logprobs = tensor([[-0.4848, -5.3660],
        [-1.4385, -0.7744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14315813779830933
Epoch 0, Step 552: train/loss = 0.28549402952194214, train/raw-loss = 0.15844598412513733, train/logprobs = tensor([[-0.4839, -7.5909],
        [-1.3647, -0.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270480901002884
Epoch 0, Step 553: train/loss = 0.2962910532951355, train/raw-loss = 0.16932226717472076, train/logprobs = tensor([[-0.4395, -6.0878],
        [-1.4923, -0.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12696877121925354
Epoch 0, Step 554: train/loss = 0.3059384524822235, train/raw-loss = 0.1961612105369568, train/logprobs = tensor([[-0.4362, -5.1927],
        [-1.0457, -0.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10977722704410553
Epoch 0, Step 555: train/loss = 0.3819357752799988, train/raw-loss = 0.2981872260570526, train/logprobs = tensor([[-0.3940, -5.3952],
        [-0.8011, -0.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08374854922294617
Epoch 0, Step 556: train/loss = 0.3257924020290375, train/raw-loss = 0.22738006711006165, train/logprobs = tensor([[-0.3772, -5.2784],
        [-0.7782, -0.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09841236472129822
Epoch 0, Step 557: train/loss = 0.31071096658706665, train/raw-loss = 0.20862317085266113, train/logprobs = tensor([[-0.5291, -5.2973],
        [-1.1220, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10208779573440552
Epoch 0, Step 558: train/loss = 0.3053378462791443, train/raw-loss = 0.20740292966365814, train/logprobs = tensor([[-0.4166, -6.6168],
        [-0.9329, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09793490171432495
Epoch 0, Step 559: train/loss = 0.31600454449653625, train/raw-loss = 0.21148620545864105, train/logprobs = tensor([[-0.4241, -4.0616],
        [-1.0761, -0.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045183539390564
Epoch 0, Step 560: train/loss = 0.35044538974761963, train/raw-loss = 0.2670307457447052, train/logprobs = tensor([[-0.3430, -5.1773],
        [-0.7161, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08341464400291443
Epoch 0, Step 561: train/loss = 0.31819048523902893, train/raw-loss = 0.22108086943626404, train/logprobs = tensor([[-0.3827, -5.8520],
        [-0.7836, -0.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09710962325334549
Epoch 0, Step 562: train/loss = 0.2782067060470581, train/raw-loss = 0.15915144979953766, train/logprobs = tensor([[-0.4821, -6.3881],
        [-1.4183, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11905524134635925
Epoch 0, Step 563: train/loss = 0.33769693970680237, train/raw-loss = 0.25138387084007263, train/logprobs = tensor([[-0.3584, -5.7767],
        [-0.8129, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08631307631731033
Epoch 0, Step 564: train/loss = 0.36081555485725403, train/raw-loss = 0.23876501619815826, train/logprobs = tensor([[-0.4426, -4.8303],
        [-1.1162, -0.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12205052375793457
Epoch 0, Step 565: train/loss = 0.2722975015640259, train/raw-loss = 0.14031819999217987, train/logprobs = tensor([[-0.5356, -6.4923],
        [-1.7563, -0.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13197928667068481
Epoch 0, Step 566: train/loss = 0.37600216269493103, train/raw-loss = 0.2848336696624756, train/logprobs = tensor([[-0.4146, -3.7586],
        [-0.9465, -0.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09116849303245544
Epoch 0, Step 567: train/loss = 0.40422406792640686, train/raw-loss = 0.2967361807823181, train/logprobs = tensor([[-0.4193, -2.3077],
        [-1.1183, -0.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748793184757233
Epoch 0, Step 568: train/loss = 0.3052648901939392, train/raw-loss = 0.1898152232170105, train/logprobs = tensor([[-0.4223, -6.7636],
        [-1.0704, -0.5568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11544966697692871
Epoch 0, Step 569: train/loss = 0.310017466545105, train/raw-loss = 0.21100564301013947, train/logprobs = tensor([[-0.3694, -7.2109],
        [-0.9678, -0.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09901180863380432
Epoch 0, Step 570: train/loss = 0.3056201636791229, train/raw-loss = 0.19083400070667267, train/logprobs = tensor([[-0.5398, -7.8254],
        [-1.4644, -0.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478614062070847
Epoch 0, Step 571: train/loss = 0.29890698194503784, train/raw-loss = 0.17825159430503845, train/logprobs = tensor([[-0.4251, -5.0694],
        [-1.3430, -0.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12065543234348297
Epoch 0, Step 572: train/loss = 0.270123153924942, train/raw-loss = 0.1581900417804718, train/logprobs = tensor([[-0.5206, -7.3698],
        [-1.3878, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11193311214447021
Epoch 0, Step 573: train/loss = 0.3462175130844116, train/raw-loss = 0.2540664076805115, train/logprobs = tensor([[-0.4583, -4.7071],
        [-1.1418, -0.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09215107560157776
Epoch 0, Step 574: train/loss = 0.3148591220378876, train/raw-loss = 0.20563310384750366, train/logprobs = tensor([[-0.3910, -5.7574],
        [-1.0275, -0.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10922602564096451
Epoch 0, Step 575: train/loss = 0.340282678604126, train/raw-loss = 0.22113269567489624, train/logprobs = tensor([[-0.3933, -4.1081],
        [-1.0216, -0.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11914997547864914
Epoch 0, Step 576: train/loss = 0.3438737094402313, train/raw-loss = 0.2178194671869278, train/logprobs = tensor([[-0.5003, -5.9004],
        [-1.4987, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12605425715446472
Epoch 0, Step 577: train/loss = 0.341469943523407, train/raw-loss = 0.2482621967792511, train/logprobs = tensor([[-0.5450, -6.2804],
        [-1.2205, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09320773184299469
Epoch 0, Step 578: train/loss = 0.34399503469467163, train/raw-loss = 0.25232601165771484, train/logprobs = tensor([[-0.4004, -5.6199],
        [-0.7325, -0.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166903048753738
Epoch 0, Step 579: train/loss = 0.32017141580581665, train/raw-loss = 0.20991554856300354, train/logprobs = tensor([[-0.4491, -5.6898],
        [-1.3935, -0.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11025585979223251
Epoch 0, Step 580: train/loss = 0.3137117624282837, train/raw-loss = 0.20773550868034363, train/logprobs = tensor([[-0.3588, -4.5566],
        [-1.1381, -0.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597625374794006
Epoch 0, Step 581: train/loss = 0.33074551820755005, train/raw-loss = 0.21271765232086182, train/logprobs = tensor([[-0.3501, -4.9006],
        [-1.0732, -0.4560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11802784353494644
Epoch 0, Step 582: train/loss = 0.26146602630615234, train/raw-loss = 0.14022278785705566, train/logprobs = tensor([[-0.4751, -6.1319],
        [-1.6356, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12124323844909668
Epoch 0, Step 583: train/loss = 0.2865622639656067, train/raw-loss = 0.16982851922512054, train/logprobs = tensor([[-0.5138, -8.5396],
        [-1.3182, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11673372238874435
Epoch 0, Step 584: train/loss = 0.28432992100715637, train/raw-loss = 0.18995818495750427, train/logprobs = tensor([[-0.3755, -5.4881],
        [-1.1290, -0.6493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0943717360496521
Epoch 0, Step 585: train/loss = 0.31720125675201416, train/raw-loss = 0.1827104091644287, train/logprobs = tensor([[-0.4176, -5.1261],
        [-1.1776, -0.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13449086248874664
Epoch 0, Step 586: train/loss = 0.3267785608768463, train/raw-loss = 0.23608236014842987, train/logprobs = tensor([[-0.4130, -6.6340],
        [-1.2197, -0.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09069619327783585
Epoch 0, Step 587: train/loss = 0.4023064970970154, train/raw-loss = 0.3139288127422333, train/logprobs = tensor([[-0.3682, -4.0693],
        [-0.6900, -0.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08837766945362091
Epoch 0, Step 588: train/loss = 0.31221088767051697, train/raw-loss = 0.2066023349761963, train/logprobs = tensor([[-0.4171, -5.1418],
        [-1.0796, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10560853034257889
Epoch 0, Step 589: train/loss = 0.2754403352737427, train/raw-loss = 0.15146219730377197, train/logprobs = tensor([[-0.4540, -6.6872],
        [-1.4515, -0.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12397810816764832
Epoch 0, Step 590: train/loss = 0.3202212452888489, train/raw-loss = 0.21618299186229706, train/logprobs = tensor([[-0.3869, -4.6715],
        [-1.0414, -0.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10403822362422943
Epoch 0, Step 591: train/loss = 0.3527263402938843, train/raw-loss = 0.2228800356388092, train/logprobs = tensor([[-0.4226, -4.2407],
        [-1.0921, -0.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12984630465507507
Epoch 0, Step 592: train/loss = 0.3413596749305725, train/raw-loss = 0.2289731204509735, train/logprobs = tensor([[-0.4490, -5.3805],
        [-1.1262, -0.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11238656938076019
Epoch 0, Step 593: train/loss = 0.3856228291988373, train/raw-loss = 0.29243773221969604, train/logprobs = tensor([[-0.3208, -6.8796],
        [-0.7767, -0.5507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318510442972183
Epoch 0, Step 594: train/loss = 0.28707343339920044, train/raw-loss = 0.18242105841636658, train/logprobs = tensor([[-0.4002, -6.0330],
        [-1.2708, -0.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10465241968631744
Epoch 0, Step 595: train/loss = 0.37523889541625977, train/raw-loss = 0.2619788348674774, train/logprobs = tensor([[-0.3746, -5.5205],
        [-0.9923, -0.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11326004564762115
Epoch 0, Step 596: train/loss = 0.39312440156936646, train/raw-loss = 0.27944818139076233, train/logprobs = tensor([[-0.4310, -3.5378],
        [-1.1053, -0.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367624998092651
Epoch 0, Step 597: train/loss = 0.37109601497650146, train/raw-loss = 0.27225860953330994, train/logprobs = tensor([[-0.3516, -3.8721],
        [-0.7207, -0.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09883740544319153
Epoch 0, Step 598: train/loss = 0.3148394525051117, train/raw-loss = 0.20957797765731812, train/logprobs = tensor([[-0.4369, -7.1178],
        [-0.9976, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10526147484779358
Epoch 0, Step 599: train/loss = 0.2961108386516571, train/raw-loss = 0.2021019458770752, train/logprobs = tensor([[-0.3514, -7.5396],
        [-0.8409, -0.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09400888532400131
Epoch 0, Step 600: train/loss = 0.28237223625183105, train/raw-loss = 0.16660048067569733, train/logprobs = tensor([[-0.4463, -8.0311],
        [-1.2649, -0.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577174067497253
Epoch 0, Step 601: train/loss = 0.29937225580215454, train/raw-loss = 0.18122975528240204, train/logprobs = tensor([[-0.4707, -6.1476],
        [-1.2488, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11814253032207489
Epoch 0, Step 602: train/loss = 0.29070186614990234, train/raw-loss = 0.1801878660917282, train/logprobs = tensor([[-0.4473, -6.6342],
        [-1.2954, -0.3991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11051401495933533
Epoch 0, Step 603: train/loss = 0.3154495358467102, train/raw-loss = 0.22309011220932007, train/logprobs = tensor([[-0.3670, -4.6951],
        [-0.8281, -0.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09235940873622894
Epoch 0, Step 604: train/loss = 0.3548392355442047, train/raw-loss = 0.261500746011734, train/logprobs = tensor([[-0.4367, -4.7144],
        [-1.2540, -0.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933385044336319
Epoch 0, Step 605: train/loss = 0.3498840928077698, train/raw-loss = 0.23775283992290497, train/logprobs = tensor([[-0.3873, -4.7337],
        [-0.8754, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11213123798370361
Epoch 0, Step 606: train/loss = 0.33703091740608215, train/raw-loss = 0.23901543021202087, train/logprobs = tensor([[-0.3663, -4.8069],
        [-0.9785, -0.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09801548719406128
Epoch 0, Step 607: train/loss = 0.28071480989456177, train/raw-loss = 0.17972272634506226, train/logprobs = tensor([[-0.5324, -8.1361],
        [-1.2855, -0.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10099208354949951
Epoch 0, Step 608: train/loss = 0.2799169719219208, train/raw-loss = 0.16276779770851135, train/logprobs = tensor([[-0.4026, -6.4256],
        [-1.3176, -0.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11714915931224823
Epoch 0, Step 609: train/loss = 0.33401763439178467, train/raw-loss = 0.23224714398384094, train/logprobs = tensor([[-0.3804, -5.0923],
        [-0.8704, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10177047550678253
Epoch 0, Step 610: train/loss = 0.3110387921333313, train/raw-loss = 0.20937839150428772, train/logprobs = tensor([[-0.5010, -6.9812],
        [-1.1186, -0.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10166041553020477
Epoch 0, Step 611: train/loss = 0.29609841108322144, train/raw-loss = 0.16649657487869263, train/logprobs = tensor([[-0.7617, -7.1441],
        [-1.5614, -0.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12960182130336761
Epoch 0, Step 612: train/loss = 0.27504459023475647, train/raw-loss = 0.1512722671031952, train/logprobs = tensor([[-0.4640, -6.2617],
        [-1.6050, -0.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12377231568098068
Epoch 0, Step 613: train/loss = 0.30327820777893066, train/raw-loss = 0.1690761148929596, train/logprobs = tensor([[-0.4094, -6.5603],
        [-1.2646, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13420212268829346
Epoch 0, Step 614: train/loss = 0.2925818860530853, train/raw-loss = 0.17289619147777557, train/logprobs = tensor([[-0.3924, -5.3744],
        [-1.3764, -0.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11968567967414856
Epoch 0, Step 615: train/loss = 0.2940959334373474, train/raw-loss = 0.17879395186901093, train/logprobs = tensor([[-0.4060, -7.1382],
        [-1.1257, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11530197411775589
Epoch 0, Step 616: train/loss = 0.2915746867656708, train/raw-loss = 0.1744072586297989, train/logprobs = tensor([[-0.4803, -7.2455],
        [-1.2656, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716745793819427
Epoch 0, Step 617: train/loss = 0.29223811626434326, train/raw-loss = 0.1749199777841568, train/logprobs = tensor([[-0.3773, -7.0172],
        [-1.0907, -0.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11731815338134766
Epoch 0, Step 618: train/loss = 0.2761304974555969, train/raw-loss = 0.15533007681369781, train/logprobs = tensor([[-0.4288, -5.3463],
        [-1.4736, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1208004280924797
Epoch 0, Step 619: train/loss = 0.35982275009155273, train/raw-loss = 0.2725173234939575, train/logprobs = tensor([[-0.3386, -5.0540],
        [-0.7289, -0.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08730542659759521
Epoch 0, Step 620: train/loss = 0.2808816730976105, train/raw-loss = 0.17379748821258545, train/logprobs = tensor([[-0.4133, -5.9898],
        [-1.2807, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10708419978618622
Epoch 0, Step 621: train/loss = 0.2662978768348694, train/raw-loss = 0.15456810593605042, train/logprobs = tensor([[-0.4866, -7.5436],
        [-1.5049, -0.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11172976344823837
Epoch 0, Step 622: train/loss = 0.2970762252807617, train/raw-loss = 0.19327569007873535, train/logprobs = tensor([[-0.3815, -7.2900],
        [-0.9454, -0.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10380053520202637
Epoch 0, Step 623: train/loss = 0.3570798337459564, train/raw-loss = 0.2640230655670166, train/logprobs = tensor([[-0.3377, -7.5474],
        [-0.7249, -0.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09305679798126221
Epoch 0, Step 624: train/loss = 0.28569719195365906, train/raw-loss = 0.1542353332042694, train/logprobs = tensor([[-0.5006, -6.1624],
        [-1.6245, -0.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13146185874938965
Epoch 0, Step 625: train/loss = 0.30584800243377686, train/raw-loss = 0.20200037956237793, train/logprobs = tensor([[-0.3996, -7.4790],
        [-1.1246, -0.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10384762287139893
Epoch 0, Step 626: train/loss = 0.31985458731651306, train/raw-loss = 0.21990588307380676, train/logprobs = tensor([[-0.2913, -4.7886],
        [-0.8213, -0.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0999486967921257
Epoch 0, Step 627: train/loss = 0.3031744360923767, train/raw-loss = 0.1832188069820404, train/logprobs = tensor([[-0.4106, -5.8102],
        [-1.1774, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199556365609169
Epoch 0, Step 628: train/loss = 0.3090187907218933, train/raw-loss = 0.20763424038887024, train/logprobs = tensor([[-0.3786, -6.2921],
        [-0.8810, -0.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138455778360367
Epoch 0, Step 629: train/loss = 0.288968026638031, train/raw-loss = 0.18808989226818085, train/logprobs = tensor([[-0.4624, -7.3434],
        [-1.1667, -0.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10087813436985016
Epoch 0, Step 630: train/loss = 0.32508158683776855, train/raw-loss = 0.22724393010139465, train/logprobs = tensor([[-0.4716, -5.0368],
        [-1.0561, -0.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0978376641869545
Epoch 0, Step 631: train/loss = 0.30003392696380615, train/raw-loss = 0.21210706233978271, train/logprobs = tensor([[-0.4092, -5.1139],
        [-0.9950, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08792687952518463
Epoch 0, Step 632: train/loss = 0.29134124517440796, train/raw-loss = 0.18530157208442688, train/logprobs = tensor([[-0.3332, -5.8026],
        [-1.0484, -0.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10603965818881989
Epoch 0, Step 633: train/loss = 0.3435896039009094, train/raw-loss = 0.23542875051498413, train/logprobs = tensor([[-0.4121, -4.8076],
        [-0.8362, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081608310341835
Epoch 0, Step 634: train/loss = 0.2988570034503937, train/raw-loss = 0.20872585475444794, train/logprobs = tensor([[-0.5112, -7.4534],
        [-1.1372, -1.0369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09013116359710693
Epoch 0, Step 635: train/loss = 0.31271547079086304, train/raw-loss = 0.19963160157203674, train/logprobs = tensor([[-0.3558, -5.6569],
        [-0.9097, -0.5111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11308388411998749
Epoch 0, Step 636: train/loss = 0.3041766881942749, train/raw-loss = 0.19318842887878418, train/logprobs = tensor([[-0.3608, -7.0212],
        [-1.0200, -0.5691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098824441432953
Epoch 0, Step 637: train/loss = 0.31143805384635925, train/raw-loss = 0.18840190768241882, train/logprobs = tensor([[-0.4587, -7.7737],
        [-1.1259, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12303613126277924
Epoch 0, Step 638: train/loss = 0.32999053597450256, train/raw-loss = 0.19303277134895325, train/logprobs = tensor([[-0.4241, -5.0482],
        [-1.1497, -0.4036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13695776462554932
Epoch 0, Step 639: train/loss = 0.33775079250335693, train/raw-loss = 0.2502041459083557, train/logprobs = tensor([[-0.3200, -5.1647],
        [-0.6111, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754663169384003
Epoch 0, Step 640: train/loss = 0.2629716396331787, train/raw-loss = 0.12472885847091675, train/logprobs = tensor([[-0.5113, -6.4599],
        [-1.8188, -0.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13824279606342316
Epoch 0, Step 641: train/loss = 0.33404695987701416, train/raw-loss = 0.25231873989105225, train/logprobs = tensor([[-0.2833, -6.4618],
        [-0.6031, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817282497882843
Epoch 0, Step 642: train/loss = 0.3010879158973694, train/raw-loss = 0.2212146818637848, train/logprobs = tensor([[-0.3309, -7.2456],
        [-0.7073, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0798732340335846
Epoch 0, Step 643: train/loss = 0.33298221230506897, train/raw-loss = 0.24105006456375122, train/logprobs = tensor([[-0.3296, -4.6934],
        [-0.8087, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09193214774131775
Epoch 0, Step 644: train/loss = 0.32435500621795654, train/raw-loss = 0.22702458500862122, train/logprobs = tensor([[-0.3994, -4.7276],
        [-0.9916, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09733043611049652
Epoch 0, Step 645: train/loss = 0.3620891273021698, train/raw-loss = 0.25789302587509155, train/logprobs = tensor([[-0.3834, -3.4000],
        [-0.9164, -0.4059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10419613122940063
Epoch 0, Step 646: train/loss = 0.2800106704235077, train/raw-loss = 0.14851601421833038, train/logprobs = tensor([[-0.4201, -7.9233],
        [-1.3502, -0.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314946413040161
Epoch 0, Step 647: train/loss = 0.3731255531311035, train/raw-loss = 0.27292460203170776, train/logprobs = tensor([[-0.2683, -4.8774],
        [-0.8462, -0.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10020094364881516
Epoch 0, Step 648: train/loss = 0.30172285437583923, train/raw-loss = 0.1785261332988739, train/logprobs = tensor([[-0.4403, -7.8678],
        [-1.2899, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12319672852754593
Epoch 0, Step 649: train/loss = 0.2875227928161621, train/raw-loss = 0.1673044115304947, train/logprobs = tensor([[-0.4960, -6.1734],
        [-1.3884, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12021838128566742
Epoch 0, Step 650: train/loss = 0.2903899550437927, train/raw-loss = 0.1802879273891449, train/logprobs = tensor([[-0.4772, -6.0800],
        [-1.3551, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11010204255580902
Epoch 0, Step 651: train/loss = 0.3114512860774994, train/raw-loss = 0.22527459263801575, train/logprobs = tensor([[-0.3323, -8.0704],
        [-0.6537, -0.4377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08617667853832245
Epoch 0, Step 652: train/loss = 0.258386492729187, train/raw-loss = 0.13617563247680664, train/logprobs = tensor([[-0.4723, -7.9675],
        [-1.6708, -0.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12221087515354156
Epoch 0, Step 653: train/loss = 0.3046848177909851, train/raw-loss = 0.21487832069396973, train/logprobs = tensor([[-0.3945, -4.3473],
        [-1.1754, -0.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08980649709701538
Epoch 0, Step 654: train/loss = 0.31440016627311707, train/raw-loss = 0.18817052245140076, train/logprobs = tensor([[-0.3770, -7.4195],
        [-1.0091, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1262296438217163
Epoch 0, Step 655: train/loss = 0.3022662103176117, train/raw-loss = 0.19132396578788757, train/logprobs = tensor([[-0.4009, -4.4276],
        [-1.2612, -0.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11094222962856293
Epoch 0, Step 656: train/loss = 0.2820587754249573, train/raw-loss = 0.18439799547195435, train/logprobs = tensor([[-0.3916, -7.9458],
        [-1.2214, -0.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09766079485416412
Epoch 0, Step 657: train/loss = 0.32116666436195374, train/raw-loss = 0.22784626483917236, train/logprobs = tensor([[-0.3869, -5.9108],
        [-0.9830, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09332039952278137
Epoch 0, Step 658: train/loss = 0.2795092463493347, train/raw-loss = 0.1686088740825653, train/logprobs = tensor([[-0.3886, -4.5344],
        [-1.2842, -0.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11090037971735
Epoch 0, Step 659: train/loss = 0.3517642915248871, train/raw-loss = 0.25219598412513733, train/logprobs = tensor([[-0.3347, -4.0807],
        [-0.7237, -0.4016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09956829994916916
Epoch 0, Step 660: train/loss = 0.2893197238445282, train/raw-loss = 0.16678470373153687, train/logprobs = tensor([[-0.4427, -4.1488],
        [-1.5367, -0.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12253502011299133
Epoch 0, Step 661: train/loss = 0.3405120372772217, train/raw-loss = 0.24420055747032166, train/logprobs = tensor([[-0.3620, -5.0117],
        [-0.8532, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09631147235631943
Epoch 0, Step 662: train/loss = 0.28989192843437195, train/raw-loss = 0.13697686791419983, train/logprobs = tensor([[-0.4532, -6.9567],
        [-1.6409, -0.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15291506052017212
Epoch 0, Step 663: train/loss = 0.30261337757110596, train/raw-loss = 0.17078928649425507, train/logprobs = tensor([[-0.5313, -5.2133],
        [-1.8104, -0.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318240910768509
Epoch 0, Step 664: train/loss = 0.38422414660453796, train/raw-loss = 0.2533777356147766, train/logprobs = tensor([[-0.4073, -2.6903],
        [-1.3219, -0.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13084644079208374
Epoch 0, Step 665: train/loss = 0.3148943781852722, train/raw-loss = 0.22326283156871796, train/logprobs = tensor([[-0.3470, -4.8347],
        [-0.7699, -0.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09163151681423187
Epoch 0, Step 666: train/loss = 0.27739226818084717, train/raw-loss = 0.17687304317951202, train/logprobs = tensor([[-0.4125, -8.2530],
        [-1.1380, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10051924735307693
Epoch 0, Step 667: train/loss = 0.254911333322525, train/raw-loss = 0.11528972536325455, train/logprobs = tensor([[-0.5497, -5.9188],
        [-1.9241, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396215856075287
Epoch 0, Step 668: train/loss = 0.3783954679965973, train/raw-loss = 0.2789367437362671, train/logprobs = tensor([[-0.4053, -5.5136],
        [-1.0642, -0.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994587242603302
Epoch 0, Step 669: train/loss = 0.29652732610702515, train/raw-loss = 0.1880163699388504, train/logprobs = tensor([[-0.4724, -4.8397],
        [-1.4588, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10851097106933594
Epoch 0, Step 670: train/loss = 0.29919126629829407, train/raw-loss = 0.20713655650615692, train/logprobs = tensor([[-0.3419, -7.7530],
        [-0.8609, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09205470979213715
Epoch 0, Step 671: train/loss = 0.31628143787384033, train/raw-loss = 0.20809291303157806, train/logprobs = tensor([[-0.4011, -4.4532],
        [-1.0437, -0.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10818852484226227
Epoch 0, Step 672: train/loss = 0.29799318313598633, train/raw-loss = 0.19026845693588257, train/logprobs = tensor([[-0.3471, -8.2995],
        [-0.9818, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10772471129894257
Epoch 0, Step 673: train/loss = 0.28026801347732544, train/raw-loss = 0.17114515602588654, train/logprobs = tensor([[-0.4546, -6.1886],
        [-1.5848, -0.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091228574514389
Epoch 0, Step 674: train/loss = 0.28255027532577515, train/raw-loss = 0.1655890941619873, train/logprobs = tensor([[-0.3931, -8.0931],
        [-1.2210, -0.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11696120351552963
Epoch 0, Step 675: train/loss = 0.26500818133354187, train/raw-loss = 0.15437743067741394, train/logprobs = tensor([[-0.5058, -6.0658],
        [-1.5834, -0.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11063076555728912
Epoch 0, Step 676: train/loss = 0.28026190400123596, train/raw-loss = 0.15897749364376068, train/logprobs = tensor([[-0.4466, -4.8368],
        [-1.6689, -0.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128441035747528
Epoch 0, Step 677: train/loss = 0.2897048890590668, train/raw-loss = 0.15578295290470123, train/logprobs = tensor([[-0.3627, -6.7993],
        [-1.3196, -0.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13392195105552673
Epoch 0, Step 678: train/loss = 0.30885154008865356, train/raw-loss = 0.20287352800369263, train/logprobs = tensor([[-0.3387, -7.5156],
        [-0.8431, -0.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597802698612213
Epoch 0, Step 679: train/loss = 0.3589591681957245, train/raw-loss = 0.2656577527523041, train/logprobs = tensor([[-0.4696, -6.2562],
        [-1.3226, -0.4453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09330142289400101
Epoch 0, Step 680: train/loss = 0.30480995774269104, train/raw-loss = 0.18438559770584106, train/logprobs = tensor([[-0.4453, -4.7430],
        [-1.3557, -0.3693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12042437493801117
Epoch 0, Step 681: train/loss = 0.3119962513446808, train/raw-loss = 0.19787053763866425, train/logprobs = tensor([[-0.3628, -7.3640],
        [-1.0146, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11412571370601654
Epoch 0, Step 682: train/loss = 0.3037961721420288, train/raw-loss = 0.21544411778450012, train/logprobs = tensor([[-0.3074, -8.3684],
        [-0.7100, -0.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08835207670927048
Epoch 0, Step 683: train/loss = 0.346931517124176, train/raw-loss = 0.24947546422481537, train/logprobs = tensor([[-0.4272, -5.4588],
        [-1.0907, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745605289936066
Epoch 0, Step 684: train/loss = 0.2976365089416504, train/raw-loss = 0.17150190472602844, train/logprobs = tensor([[-0.4485, -5.4180],
        [-1.3099, -0.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12613460421562195
Epoch 0, Step 685: train/loss = 0.30095750093460083, train/raw-loss = 0.1509058177471161, train/logprobs = tensor([[-0.4387, -4.7380],
        [-1.4850, -0.3989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15005166828632355
Epoch 0, Step 686: train/loss = 0.338803768157959, train/raw-loss = 0.22565175592899323, train/logprobs = tensor([[-0.3872, -5.2546],
        [-1.0609, -0.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11315201967954636
Epoch 0, Step 687: train/loss = 0.25916922092437744, train/raw-loss = 0.14707106351852417, train/logprobs = tensor([[-0.3950, -7.2216],
        [-1.4410, -0.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11209816485643387
Epoch 0, Step 688: train/loss = 0.28219184279441833, train/raw-loss = 0.1823868453502655, train/logprobs = tensor([[-0.4157, -6.7868],
        [-1.2479, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980500489473343
Epoch 0, Step 689: train/loss = 0.26395583152770996, train/raw-loss = 0.1490650624036789, train/logprobs = tensor([[-0.5076, -6.9801],
        [-1.6420, -0.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11489077657461166
Epoch 0, Step 690: train/loss = 0.24342066049575806, train/raw-loss = 0.12384000420570374, train/logprobs = tensor([[-0.4191, -8.0139],
        [-1.7197, -0.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11958062648773193
Epoch 0, Step 691: train/loss = 0.2895696461200714, train/raw-loss = 0.1752692610025406, train/logprobs = tensor([[-0.3774, -6.7569],
        [-1.1526, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11430037021636963
Epoch 0, Step 692: train/loss = 0.3374769985675812, train/raw-loss = 0.21893753111362457, train/logprobs = tensor([[-0.4359, -6.2270],
        [-1.0572, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185394749045372
Epoch 0, Step 693: train/loss = 0.3199663758277893, train/raw-loss = 0.21147489547729492, train/logprobs = tensor([[-0.4093, -6.3598],
        [-1.1309, -0.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10849150270223618
Epoch 0, Step 694: train/loss = 0.32271939516067505, train/raw-loss = 0.23329122364521027, train/logprobs = tensor([[-0.3739, -5.5172],
        [-0.9523, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08942816406488419
Epoch 0, Step 695: train/loss = 0.3250047266483307, train/raw-loss = 0.2314552515745163, train/logprobs = tensor([[-0.3844, -6.3907],
        [-0.8215, -0.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09354948252439499
Epoch 0, Step 696: train/loss = 0.26822230219841003, train/raw-loss = 0.14728040993213654, train/logprobs = tensor([[-0.4351, -7.9829],
        [-1.4038, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1209418922662735
Epoch 0, Step 697: train/loss = 0.29419419169425964, train/raw-loss = 0.17728440463542938, train/logprobs = tensor([[-0.4532, -8.9039],
        [-1.4179, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11690978705883026
Epoch 0, Step 698: train/loss = 0.2797059416770935, train/raw-loss = 0.1811540424823761, train/logprobs = tensor([[-0.3913, -7.7008],
        [-1.1590, -0.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855189919471741
Epoch 0, Step 699: train/loss = 0.2698809802532196, train/raw-loss = 0.14267238974571228, train/logprobs = tensor([[-0.4767, -6.5818],
        [-1.6155, -0.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12720860540866852
Epoch 0, Step 700: train/loss = 0.27542442083358765, train/raw-loss = 0.18513450026512146, train/logprobs = tensor([[-0.4066, -9.3621],
        [-1.0613, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09028994292020798
Epoch 0, Step 701: train/loss = 0.2656976580619812, train/raw-loss = 0.14978168904781342, train/logprobs = tensor([[-0.4909, -7.2009],
        [-1.4593, -0.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11591595411300659
Epoch 0, Step 702: train/loss = 0.32800912857055664, train/raw-loss = 0.21478162705898285, train/logprobs = tensor([[-0.3936, -5.0053],
        [-1.0985, -0.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322750151157379
Epoch 0, Step 703: train/loss = 0.29818469285964966, train/raw-loss = 0.2008804976940155, train/logprobs = tensor([[ -0.3348, -10.4546],
        [ -0.8363,  -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09730421006679535
Epoch 0, Step 704: train/loss = 0.28043144941329956, train/raw-loss = 0.14953653514385223, train/logprobs = tensor([[-0.4385, -6.9373],
        [-1.3536, -0.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13089488446712494
Epoch 0, Step 705: train/loss = 0.2996153235435486, train/raw-loss = 0.20468871295452118, train/logprobs = tensor([[-0.3532, -8.0364],
        [-0.8222, -0.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09492659568786621
Epoch 0, Step 706: train/loss = 0.29922711849212646, train/raw-loss = 0.1974833905696869, train/logprobs = tensor([[-0.4060, -7.6756],
        [-1.0505, -0.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10174373537302017
Epoch 0, Step 707: train/loss = 0.28002220392227173, train/raw-loss = 0.18808576464653015, train/logprobs = tensor([[-0.3463, -7.8372],
        [-0.9333, -0.5122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09193640947341919
Epoch 0, Step 708: train/loss = 0.36391162872314453, train/raw-loss = 0.24067822098731995, train/logprobs = tensor([[-0.4023, -3.7499],
        [-1.5177, -0.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12323339283466339
Epoch 0, Step 709: train/loss = 0.2559700608253479, train/raw-loss = 0.14446161687374115, train/logprobs = tensor([[ -0.4410, -11.6428],
        [ -1.4828,  -0.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11150845885276794
Epoch 0, Step 710: train/loss = 0.32068052887916565, train/raw-loss = 0.24733594059944153, train/logprobs = tensor([[-0.3043, -5.0792],
        [-0.5881, -0.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07334457337856293
Epoch 0, Step 711: train/loss = 0.26863211393356323, train/raw-loss = 0.14948508143424988, train/logprobs = tensor([[-0.4575, -8.6208],
        [-1.5284, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11914703994989395
Epoch 0, Step 712: train/loss = 0.3045128881931305, train/raw-loss = 0.20835846662521362, train/logprobs = tensor([[-0.3962, -6.4407],
        [-1.1555, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09615442156791687
Epoch 0, Step 713: train/loss = 0.3942144513130188, train/raw-loss = 0.3167564868927002, train/logprobs = tensor([[-0.3257, -5.6438],
        [-0.6827, -0.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774579644203186
Epoch 0, Step 714: train/loss = 0.2831950783729553, train/raw-loss = 0.14248567819595337, train/logprobs = tensor([[-0.4325, -5.1519],
        [-1.6758, -0.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14070940017700195
Epoch 0, Step 715: train/loss = 0.28964895009994507, train/raw-loss = 0.157024085521698, train/logprobs = tensor([[-0.4304, -5.3259],
        [-1.4243, -0.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13262486457824707
Epoch 0, Step 716: train/loss = 0.3453519940376282, train/raw-loss = 0.24141515791416168, train/logprobs = tensor([[-0.4505, -5.2123],
        [-1.4216, -0.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039368212223053
Epoch 0, Step 717: train/loss = 0.3142332434654236, train/raw-loss = 0.21463465690612793, train/logprobs = tensor([[-0.3477, -6.2067],
        [-0.9596, -0.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09959859400987625
Epoch 0, Step 718: train/loss = 0.2798902690410614, train/raw-loss = 0.1344085931777954, train/logprobs = tensor([[-0.5148, -7.2273],
        [-1.6049, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.145481675863266
Epoch 0, Step 719: train/loss = 0.2692869305610657, train/raw-loss = 0.15968436002731323, train/logprobs = tensor([[-0.3767, -6.8496],
        [-1.3164, -0.6420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10960258543491364
Epoch 0, Step 720: train/loss = 0.2716319262981415, train/raw-loss = 0.16792553663253784, train/logprobs = tensor([[-0.3825, -8.0326],
        [-1.2639, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10370640456676483
Epoch 0, Step 721: train/loss = 0.3561844825744629, train/raw-loss = 0.2632739543914795, train/logprobs = tensor([[-0.4138, -3.5127],
        [-1.1931, -0.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09291055053472519
Epoch 0, Step 722: train/loss = 0.27457571029663086, train/raw-loss = 0.15174588561058044, train/logprobs = tensor([[-0.4462, -6.9784],
        [-1.4794, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12282982468605042
Epoch 0, Step 723: train/loss = 0.2685060203075409, train/raw-loss = 0.14195379614830017, train/logprobs = tensor([[-0.5520, -6.9665],
        [-1.6938, -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12655222415924072
Epoch 0, Step 724: train/loss = 0.2854761779308319, train/raw-loss = 0.15946617722511292, train/logprobs = tensor([[-0.4614, -7.8128],
        [-1.4166, -0.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126010000705719
Epoch 0, Step 725: train/loss = 0.31035640835762024, train/raw-loss = 0.20844566822052002, train/logprobs = tensor([[-0.3782, -7.2464],
        [-1.0839, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191071778535843
Epoch 0, Step 726: train/loss = 0.29625582695007324, train/raw-loss = 0.19108334183692932, train/logprobs = tensor([[-0.3708, -5.3200],
        [-1.0404, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517247021198273
Epoch 0, Step 727: train/loss = 0.3116651773452759, train/raw-loss = 0.21383905410766602, train/logprobs = tensor([[-0.3782, -5.0713],
        [-0.9411, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09782613813877106
Epoch 0, Step 728: train/loss = 0.256804883480072, train/raw-loss = 0.13840444386005402, train/logprobs = tensor([[-0.4070, -7.8919],
        [-1.4703, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1184004470705986
Epoch 0, Step 729: train/loss = 0.2728113532066345, train/raw-loss = 0.15309558808803558, train/logprobs = tensor([[-0.4200, -9.3261],
        [-1.4003, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11971576511859894
Epoch 0, Step 730: train/loss = 0.28609177470207214, train/raw-loss = 0.1878693699836731, train/logprobs = tensor([[-0.4688, -5.9824],
        [-1.6582, -0.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09822240471839905
Epoch 0, Step 731: train/loss = 0.3025088310241699, train/raw-loss = 0.1829661726951599, train/logprobs = tensor([[-0.3769, -6.6152],
        [-1.0241, -0.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11954262852668762
Epoch 0, Step 732: train/loss = 0.27748602628707886, train/raw-loss = 0.1672840714454651, train/logprobs = tensor([[-0.4542, -6.4093],
        [-1.4267, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11020195484161377
Epoch 0, Step 733: train/loss = 0.2914627194404602, train/raw-loss = 0.1854163408279419, train/logprobs = tensor([[-0.4176, -8.7551],
        [-1.1616, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10604637116193771
Epoch 0, Step 734: train/loss = 0.26515915989875793, train/raw-loss = 0.13401472568511963, train/logprobs = tensor([[-0.4755, -6.0665],
        [-1.7238, -0.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1311444193124771
Epoch 0, Step 735: train/loss = 0.3434770703315735, train/raw-loss = 0.24186155200004578, train/logprobs = tensor([[-0.4215, -6.2063],
        [-1.1048, -0.6335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10161550343036652
Epoch 0, Step 736: train/loss = 0.3231426179409027, train/raw-loss = 0.23221087455749512, train/logprobs = tensor([[-0.3871, -6.2799],
        [-1.2107, -0.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09093175828456879
Epoch 0, Step 737: train/loss = 0.2630936801433563, train/raw-loss = 0.13501311838626862, train/logprobs = tensor([[-0.4462, -6.5110],
        [-1.5877, -0.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280805617570877
Epoch 0, Step 738: train/loss = 0.2538366913795471, train/raw-loss = 0.16773681342601776, train/logprobs = tensor([[-0.3873, -5.3027],
        [-1.2818, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08609987050294876
Epoch 0, Step 739: train/loss = 0.2881775498390198, train/raw-loss = 0.1733732521533966, train/logprobs = tensor([[-0.3867, -6.9183],
        [-1.2784, -0.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11480429768562317
Epoch 0, Step 740: train/loss = 0.29563409090042114, train/raw-loss = 0.18629394471645355, train/logprobs = tensor([[-0.4061, -6.2544],
        [-1.0815, -0.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.109340138733387
Epoch 0, Step 741: train/loss = 0.27535468339920044, train/raw-loss = 0.16781005263328552, train/logprobs = tensor([[-0.3988, -7.6753],
        [-1.2309, -0.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10754464566707611
Epoch 0, Step 742: train/loss = 0.26416540145874023, train/raw-loss = 0.12352468073368073, train/logprobs = tensor([[-0.4191, -8.3602],
        [-1.6815, -0.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406407356262207
Epoch 0, Step 743: train/loss = 0.2805823087692261, train/raw-loss = 0.17791908979415894, train/logprobs = tensor([[-0.3783, -9.6485],
        [-1.0494, -0.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10266319662332535
Epoch 0, Step 744: train/loss = 0.33737295866012573, train/raw-loss = 0.22966498136520386, train/logprobs = tensor([[-0.3387, -4.1276],
        [-0.9023, -0.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10770796239376068
Epoch 0, Step 745: train/loss = 0.2746071517467499, train/raw-loss = 0.1817348152399063, train/logprobs = tensor([[-0.3807, -6.9848],
        [-1.0481, -0.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09287234395742416
Epoch 0, Step 746: train/loss = 0.31616631150245667, train/raw-loss = 0.24065294861793518, train/logprobs = tensor([[-0.3192, -6.3579],
        [-0.6446, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07551334798336029
Epoch 0, Step 747: train/loss = 0.31400078535079956, train/raw-loss = 0.207275852560997, train/logprobs = tensor([[-0.3912, -4.9598],
        [-1.0975, -0.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10672493278980255
Epoch 0, Step 748: train/loss = 0.2629986107349396, train/raw-loss = 0.11593139171600342, train/logprobs = tensor([[-0.5285, -5.6987],
        [-2.1081, -0.3131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14706721901893616
Epoch 0, Step 749: train/loss = 0.2969479560852051, train/raw-loss = 0.201621413230896, train/logprobs = tensor([[-0.3017, -9.7067],
        [-0.8065, -0.5892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09532654285430908
Epoch 0, Step 750: train/loss = 0.2662105858325958, train/raw-loss = 0.16996631026268005, train/logprobs = tensor([[-0.4158, -9.8919],
        [-1.1694, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09624426811933517
Epoch 0, Step 751: train/loss = 0.29090604186058044, train/raw-loss = 0.20070119202136993, train/logprobs = tensor([[-0.3051, -6.5749],
        [-0.8299, -0.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902048721909523
Epoch 0, Step 752: train/loss = 0.2451183795928955, train/raw-loss = 0.11271089315414429, train/logprobs = tensor([[ -0.5057, -10.8980],
        [ -1.9380,  -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13240747153759003
Epoch 0, Step 753: train/loss = 0.34328362345695496, train/raw-loss = 0.25384917855262756, train/logprobs = tensor([[-0.3933, -4.5573],
        [-1.0655, -0.5529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08943444490432739
Epoch 0, Step 754: train/loss = 0.2656513750553131, train/raw-loss = 0.15934407711029053, train/logprobs = tensor([[-0.4554, -7.6792],
        [-1.3523, -0.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630729794502258
Epoch 0, Step 755: train/loss = 0.3348424434661865, train/raw-loss = 0.2455245703458786, train/logprobs = tensor([[-0.2996, -6.0161],
        [-0.6674, -0.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931785076856613
Epoch 0, Step 756: train/loss = 0.3093780279159546, train/raw-loss = 0.2203226089477539, train/logprobs = tensor([[-0.4146, -4.3633],
        [-1.1276, -0.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08905541896820068
Epoch 0, Step 757: train/loss = 0.2894142270088196, train/raw-loss = 0.18372245132923126, train/logprobs = tensor([[-0.3558, -5.8369],
        [-1.1289, -0.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569176822900772
Epoch 0, Step 758: train/loss = 0.2878373861312866, train/raw-loss = 0.184019535779953, train/logprobs = tensor([[-0.3841, -7.6200],
        [-1.0388, -0.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10381784290075302
Epoch 0, Step 759: train/loss = 0.2802349328994751, train/raw-loss = 0.1611078381538391, train/logprobs = tensor([[-0.4106, -7.5075],
        [-1.3826, -0.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191270723938942
Epoch 0, Step 760: train/loss = 0.29137712717056274, train/raw-loss = 0.19508740305900574, train/logprobs = tensor([[-0.3710, -6.5773],
        [-0.9334, -0.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09628970175981522
Epoch 0, Step 761: train/loss = 0.28119924664497375, train/raw-loss = 0.1842758059501648, train/logprobs = tensor([[-0.3965, -7.1375],
        [-1.1930, -0.5271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09692345559597015
Epoch 0, Step 762: train/loss = 0.29232877492904663, train/raw-loss = 0.17735056579113007, train/logprobs = tensor([[-0.4190, -4.9069],
        [-1.2946, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11497822403907776
Epoch 0, Step 763: train/loss = 0.2895139753818512, train/raw-loss = 0.19019801914691925, train/logprobs = tensor([[-0.3629, -7.3471],
        [-1.0023, -0.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09931595623493195
Epoch 0, Step 764: train/loss = 0.2927555739879608, train/raw-loss = 0.2006983458995819, train/logprobs = tensor([[-0.3421, -6.5417],
        [-1.0227, -0.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09205721318721771
Epoch 0, Step 765: train/loss = 0.2859092354774475, train/raw-loss = 0.17783454060554504, train/logprobs = tensor([[-0.3633, -9.3439],
        [-1.0943, -0.7100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10807470977306366
Epoch 0, Step 766: train/loss = 0.2540757954120636, train/raw-loss = 0.13807037472724915, train/logprobs = tensor([[-0.3800, -7.7800],
        [-1.6290, -0.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11600543558597565
Epoch 0, Step 767: train/loss = 0.25680696964263916, train/raw-loss = 0.1321972906589508, train/logprobs = tensor([[ -0.3698, -10.6250],
        [ -1.4762,  -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12460966408252716
Epoch 0, Step 768: train/loss = 0.2873539924621582, train/raw-loss = 0.19626182317733765, train/logprobs = tensor([[-0.3554, -7.8094],
        [-1.0489, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09109219163656235
Epoch 0, Step 769: train/loss = 0.298545241355896, train/raw-loss = 0.17988739907741547, train/logprobs = tensor([[-0.3890, -6.6980],
        [-1.1777, -0.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11865787208080292
Epoch 0, Step 770: train/loss = 0.2739331126213074, train/raw-loss = 0.17352333664894104, train/logprobs = tensor([[-0.3962, -8.7707],
        [-1.2007, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10040979832410812
Epoch 0, Step 771: train/loss = 0.3003242015838623, train/raw-loss = 0.1923784613609314, train/logprobs = tensor([[-0.3668, -8.0884],
        [-1.0026, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10794572532176971
Epoch 0, Step 772: train/loss = 0.30937597155570984, train/raw-loss = 0.20565654337406158, train/logprobs = tensor([[-0.4053, -6.9569],
        [-1.1703, -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10371942818164825
Epoch 0, Step 773: train/loss = 0.2961030900478363, train/raw-loss = 0.18023180961608887, train/logprobs = tensor([[-0.4287, -5.2079],
        [-1.2926, -0.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11587130278348923
Epoch 0, Step 774: train/loss = 0.28420591354370117, train/raw-loss = 0.18810629844665527, train/logprobs = tensor([[-0.3748, -6.0680],
        [-1.0303, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09609963744878769
Epoch 0, Step 775: train/loss = 0.3363324999809265, train/raw-loss = 0.24163700640201569, train/logprobs = tensor([[-0.3745, -3.0707],
        [-1.1623, -0.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09469551593065262
Epoch 0, Step 776: train/loss = 0.30953875184059143, train/raw-loss = 0.22368872165679932, train/logprobs = tensor([[-0.3436, -3.0818],
        [-1.3368, -0.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08585001528263092
Epoch 0, Step 777: train/loss = 0.2895597815513611, train/raw-loss = 0.20640689134597778, train/logprobs = tensor([[-0.3362, -7.4569],
        [-0.8037, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0831529051065445
Epoch 0, Step 778: train/loss = 0.33026307821273804, train/raw-loss = 0.20414629578590393, train/logprobs = tensor([[-0.4042, -4.0640],
        [-1.4994, -0.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1261167824268341
Epoch 0, Step 779: train/loss = 0.2811937928199768, train/raw-loss = 0.16245275735855103, train/logprobs = tensor([[-0.3539, -9.7242],
        [-1.1842, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11874104291200638
Epoch 0, Step 780: train/loss = 0.2931174337863922, train/raw-loss = 0.202109232544899, train/logprobs = tensor([[-0.3476, -6.4283],
        [-0.9464, -0.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09100820124149323
Epoch 0, Step 781: train/loss = 0.28595584630966187, train/raw-loss = 0.17266064882278442, train/logprobs = tensor([[-0.3702, -7.1469],
        [-1.1672, -0.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329519748687744
Epoch 0, Step 782: train/loss = 0.3816393315792084, train/raw-loss = 0.2969144284725189, train/logprobs = tensor([[-0.2777, -3.9838],
        [-0.7701, -0.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472489565610886
Epoch 0, Step 783: train/loss = 0.3072241544723511, train/raw-loss = 0.21437804400920868, train/logprobs = tensor([[-0.4164, -5.9879],
        [-1.0657, -0.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928460881114006
Epoch 0, Step 784: train/loss = 0.287522554397583, train/raw-loss = 0.1873493194580078, train/logprobs = tensor([[-0.3615, -8.2393],
        [-0.9822, -0.5231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1001732274889946
Epoch 0, Step 785: train/loss = 0.2754243016242981, train/raw-loss = 0.16764914989471436, train/logprobs = tensor([[ -0.3393, -10.2175],
        [ -1.1788,  -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10777514427900314
Epoch 0, Step 786: train/loss = 0.28096866607666016, train/raw-loss = 0.18251793086528778, train/logprobs = tensor([[-0.3392, -8.8559],
        [-1.0912, -0.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09845075011253357
Epoch 0, Step 787: train/loss = 0.26708078384399414, train/raw-loss = 0.1573944091796875, train/logprobs = tensor([[-0.4788, -8.2177],
        [-1.5690, -0.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10968638211488724
Epoch 0, Step 788: train/loss = 0.28485819697380066, train/raw-loss = 0.18407855927944183, train/logprobs = tensor([[-0.3873, -5.2199],
        [-1.1763, -0.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10077963024377823
Epoch 0, Step 789: train/loss = 0.27596336603164673, train/raw-loss = 0.1428905427455902, train/logprobs = tensor([[-0.4220, -7.0463],
        [-1.5147, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13307280838489532
Epoch 0, Step 790: train/loss = 0.30896976590156555, train/raw-loss = 0.20071245729923248, train/logprobs = tensor([[-0.3195, -4.4655],
        [-1.0874, -0.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825729370117188
Epoch 0, Step 791: train/loss = 0.31021708250045776, train/raw-loss = 0.21301420032978058, train/logprobs = tensor([[-0.4147, -4.5114],
        [-1.0831, -0.7115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09720286726951599
Epoch 0, Step 792: train/loss = 0.3022755980491638, train/raw-loss = 0.19608774781227112, train/logprobs = tensor([[-0.3979, -6.4597],
        [-1.2491, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1061878502368927
Epoch 0, Step 793: train/loss = 0.292156457901001, train/raw-loss = 0.19259822368621826, train/logprobs = tensor([[-0.4240, -6.6655],
        [-1.0702, -0.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09955824911594391
Epoch 0, Step 794: train/loss = 0.25769785046577454, train/raw-loss = 0.14660122990608215, train/logprobs = tensor([[-0.3625, -6.8760],
        [-1.3801, -0.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11109659820795059
Epoch 0, Step 795: train/loss = 0.26176968216896057, train/raw-loss = 0.14343252778053284, train/logprobs = tensor([[-0.4606, -9.7607],
        [-1.4699, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11833715438842773
Epoch 0, Step 796: train/loss = 0.31275975704193115, train/raw-loss = 0.2150271087884903, train/logprobs = tensor([[-0.3105, -6.6416],
        [-0.8521, -0.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773266315460205
Epoch 0, Step 797: train/loss = 0.25797614455223083, train/raw-loss = 0.13645866513252258, train/logprobs = tensor([[-0.4022, -8.9616],
        [-1.5286, -0.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12151749432086945
Epoch 0, Step 798: train/loss = 0.2787298560142517, train/raw-loss = 0.18508033454418182, train/logprobs = tensor([[ -0.3782, -10.7626],
        [ -0.9988,  -0.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09364952147006989
Epoch 0, Step 799: train/loss = 0.27102625370025635, train/raw-loss = 0.18401706218719482, train/logprobs = tensor([[-0.3365, -7.5425],
        [-0.9918, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08700917661190033
Epoch 0, Step 800: train/loss = 0.25756335258483887, train/raw-loss = 0.1672426462173462, train/logprobs = tensor([[-0.3379, -6.9263],
        [-1.2131, -0.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09032069891691208
Epoch 0, Step 801: train/loss = 0.2939682602882385, train/raw-loss = 0.21085312962532043, train/logprobs = tensor([[-0.3360, -7.2176],
        [-0.7943, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0831151157617569
Epoch 0, Step 802: train/loss = 0.24771961569786072, train/raw-loss = 0.13330282270908356, train/logprobs = tensor([[-0.4428, -9.9831],
        [-1.6425, -0.6789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11441679298877716
Epoch 0, Step 803: train/loss = 0.24544432759284973, train/raw-loss = 0.1477285921573639, train/logprobs = tensor([[-0.3640, -8.9596],
        [-1.4623, -0.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09771573543548584
Epoch 0, Step 804: train/loss = 0.28042998909950256, train/raw-loss = 0.1705547571182251, train/logprobs = tensor([[ -0.3377, -10.1088],
        [ -1.1353,  -0.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10987520217895508
Epoch 0, Step 805: train/loss = 0.3055940270423889, train/raw-loss = 0.19005420804023743, train/logprobs = tensor([[-0.3675, -4.3213],
        [-1.2221, -0.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11553981900215149
Epoch 0, Step 806: train/loss = 0.30623161792755127, train/raw-loss = 0.1909278929233551, train/logprobs = tensor([[-0.3259, -7.6553],
        [-0.9597, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11530373245477676
Epoch 0, Step 807: train/loss = 0.2942908704280853, train/raw-loss = 0.18662483990192413, train/logprobs = tensor([[-0.3704, -6.6774],
        [-1.1775, -0.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10766604542732239
Epoch 0, Step 808: train/loss = 0.31080305576324463, train/raw-loss = 0.2111354023218155, train/logprobs = tensor([[-0.3608, -5.7674],
        [-0.9338, -0.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09966766834259033
Epoch 0, Step 809: train/loss = 0.2968031167984009, train/raw-loss = 0.15760809183120728, train/logprobs = tensor([[-0.4264, -5.9478],
        [-1.3493, -0.4265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391950398683548
Epoch 0, Step 810: train/loss = 0.28549593687057495, train/raw-loss = 0.19694694876670837, train/logprobs = tensor([[-0.3961, -7.1373],
        [-1.0120, -0.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854898065328598
Epoch 0, Step 811: train/loss = 0.2954856753349304, train/raw-loss = 0.2106156051158905, train/logprobs = tensor([[-0.2873, -5.8341],
        [-0.7663, -0.4206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08487005531787872
Epoch 0, Step 812: train/loss = 0.2961636185646057, train/raw-loss = 0.21049880981445312, train/logprobs = tensor([[-0.3445, -7.4542],
        [-0.8044, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08566480875015259
Epoch 0, Step 813: train/loss = 0.302303671836853, train/raw-loss = 0.20505481958389282, train/logprobs = tensor([[-0.3744, -8.3550],
        [-0.9629, -0.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0972488597035408
Epoch 0, Step 814: train/loss = 0.3121245801448822, train/raw-loss = 0.2269660383462906, train/logprobs = tensor([[-0.3272, -4.4668],
        [-0.7197, -0.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515854924917221
Epoch 0, Step 815: train/loss = 0.3020364046096802, train/raw-loss = 0.20032735168933868, train/logprobs = tensor([[-0.4397, -3.4742],
        [-1.6423, -0.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10170908272266388
Epoch 0, Step 816: train/loss = 0.28165459632873535, train/raw-loss = 0.14852169156074524, train/logprobs = tensor([[-0.3672, -6.5894],
        [-1.4530, -0.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13313288986682892
Epoch 0, Step 817: train/loss = 0.3189319670200348, train/raw-loss = 0.21339166164398193, train/logprobs = tensor([[-0.3483, -7.8556],
        [-0.8169, -0.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554030537605286
Epoch 0, Step 818: train/loss = 0.31284385919570923, train/raw-loss = 0.2256094217300415, train/logprobs = tensor([[-0.3037, -5.5209],
        [-0.7110, -0.7119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08723443001508713
Epoch 0, Step 819: train/loss = 0.25969576835632324, train/raw-loss = 0.13935910165309906, train/logprobs = tensor([[-0.4602, -7.9964],
        [-1.5872, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12033665180206299
Epoch 0, Step 820: train/loss = 0.25589266419410706, train/raw-loss = 0.1519477367401123, train/logprobs = tensor([[-0.4719, -7.2102],
        [-1.3658, -0.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10394494235515594
Epoch 0, Step 821: train/loss = 0.3099626302719116, train/raw-loss = 0.22944438457489014, train/logprobs = tensor([[-0.2629, -5.2757],
        [-0.6000, -0.3688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08051825314760208
Epoch 0, Step 822: train/loss = 0.30511265993118286, train/raw-loss = 0.2016303688287735, train/logprobs = tensor([[-0.2828, -5.2839],
        [-1.0231, -0.2860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10348229110240936
Epoch 0, Step 823: train/loss = 0.31351661682128906, train/raw-loss = 0.21816936135292053, train/logprobs = tensor([[-0.2917, -5.4288],
        [-0.7665, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09534727782011032
Epoch 0, Step 824: train/loss = 0.2862889766693115, train/raw-loss = 0.18258988857269287, train/logprobs = tensor([[-0.4161, -5.9547],
        [-1.2583, -0.5431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10369910299777985
Epoch 0, Step 825: train/loss = 0.2537640333175659, train/raw-loss = 0.12342877686023712, train/logprobs = tensor([[-0.4788, -5.7430],
        [-1.7007, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303352564573288
Epoch 0, Step 826: train/loss = 0.295873761177063, train/raw-loss = 0.1827133446931839, train/logprobs = tensor([[-0.3664, -5.9489],
        [-1.2513, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11316040903329849
Epoch 0, Step 827: train/loss = 0.276862233877182, train/raw-loss = 0.16962465643882751, train/logprobs = tensor([[-0.3269, -9.3518],
        [-1.1104, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10723758488893509
Epoch 0, Step 828: train/loss = 0.2827850878238678, train/raw-loss = 0.17422297596931458, train/logprobs = tensor([[-0.3400, -5.1905],
        [-1.2623, -0.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10856211930513382
Epoch 0, Step 829: train/loss = 0.28005027770996094, train/raw-loss = 0.2001926302909851, train/logprobs = tensor([[-0.3235, -7.4351],
        [-0.8343, -0.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985764741897583
Epoch 0, Step 830: train/loss = 0.2874162495136261, train/raw-loss = 0.1684492826461792, train/logprobs = tensor([[-0.3114, -6.1709],
        [-1.1693, -0.3585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1189669743180275
Epoch 0, Step 831: train/loss = 0.2800503969192505, train/raw-loss = 0.18750111758708954, train/logprobs = tensor([[-0.3866, -9.2701],
        [-1.0220, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09254926443099976
Epoch 0, Step 832: train/loss = 0.3049006760120392, train/raw-loss = 0.20625782012939453, train/logprobs = tensor([[-0.3219, -5.5881],
        [-0.9392, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09864287823438644
Epoch 0, Step 833: train/loss = 0.3445323705673218, train/raw-loss = 0.22924469411373138, train/logprobs = tensor([[-0.4015, -3.9205],
        [-1.2961, -0.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1152876615524292
Epoch 0, Step 834: train/loss = 0.2862493693828583, train/raw-loss = 0.182756707072258, train/logprobs = tensor([[-0.4374, -5.1681],
        [-1.4329, -0.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10349265486001968
Epoch 0, Step 835: train/loss = 0.2769119441509247, train/raw-loss = 0.16469353437423706, train/logprobs = tensor([[-0.4702, -6.7681],
        [-1.3321, -0.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11221841722726822
Epoch 0, Step 836: train/loss = 0.30159899592399597, train/raw-loss = 0.1854023039340973, train/logprobs = tensor([[-0.3615, -7.1569],
        [-1.2418, -0.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11619669944047928
Epoch 0, Step 837: train/loss = 0.2898695468902588, train/raw-loss = 0.21935564279556274, train/logprobs = tensor([[-0.3005, -8.4943],
        [-0.6680, -0.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07051389664411545
Epoch 0, Step 838: train/loss = 0.2623491883277893, train/raw-loss = 0.13884596526622772, train/logprobs = tensor([[-0.4449, -7.8641],
        [-1.6413, -0.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1235031932592392
Epoch 0, Step 839: train/loss = 0.323799192905426, train/raw-loss = 0.22957754135131836, train/logprobs = tensor([[-0.3260, -3.7725],
        [-0.8472, -0.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09422163665294647
Epoch 0, Step 840: train/loss = 0.3191642761230469, train/raw-loss = 0.21138978004455566, train/logprobs = tensor([[-0.3823, -6.2091],
        [-1.3770, -0.4763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10777449607849121
Epoch 0, Step 841: train/loss = 0.33082103729248047, train/raw-loss = 0.2178650200366974, train/logprobs = tensor([[-0.3711, -4.1566],
        [-1.3239, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11295605450868607
Epoch 0, Step 842: train/loss = 0.2820121943950653, train/raw-loss = 0.17458859086036682, train/logprobs = tensor([[-0.3233, -8.1153],
        [-1.1582, -0.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10742363333702087
Epoch 0, Step 843: train/loss = 0.28063473105430603, train/raw-loss = 0.18586166203022003, train/logprobs = tensor([[-0.3213, -6.3081],
        [-0.9870, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947730615735054
Epoch 0, Step 844: train/loss = 0.2313918173313141, train/raw-loss = 0.1172226071357727, train/logprobs = tensor([[-0.4011, -8.9350],
        [-1.6929, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11416921019554138
Epoch 0, Step 845: train/loss = 0.2567081153392792, train/raw-loss = 0.13119365274906158, train/logprobs = tensor([[-0.4322, -5.4056],
        [-1.7450, -0.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255144625902176
Epoch 0, Step 846: train/loss = 0.2994253933429718, train/raw-loss = 0.19695426523685455, train/logprobs = tensor([[-0.3125, -5.7109],
        [-1.2071, -0.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247112810611725
Epoch 0, Step 847: train/loss = 0.31614506244659424, train/raw-loss = 0.23437082767486572, train/logprobs = tensor([[-0.3322, -5.3735],
        [-0.8823, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08177423477172852
Epoch 0, Step 848: train/loss = 0.2518778145313263, train/raw-loss = 0.1582094132900238, train/logprobs = tensor([[-0.3671, -8.0252],
        [-1.3522, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366840124130249
Epoch 0, Step 849: train/loss = 0.2782110869884491, train/raw-loss = 0.15343105792999268, train/logprobs = tensor([[-0.3881, -8.3286],
        [-1.2877, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12478004395961761
Epoch 0, Step 850: train/loss = 0.2612375319004059, train/raw-loss = 0.1450638622045517, train/logprobs = tensor([[-0.3585, -9.2388],
        [-1.3551, -0.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11617367714643478
Epoch 0, Step 851: train/loss = 0.31033748388290405, train/raw-loss = 0.23706349730491638, train/logprobs = tensor([[-0.2825, -8.1387],
        [-0.5335, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327402383089066
Epoch 0, Step 852: train/loss = 0.2545127272605896, train/raw-loss = 0.14847464859485626, train/logprobs = tensor([[-0.4792, -5.7122],
        [-1.5933, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10603809356689453
Epoch 0, Step 853: train/loss = 0.2955220937728882, train/raw-loss = 0.21528184413909912, train/logprobs = tensor([[-0.3416, -6.7491],
        [-0.7471, -0.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08024027198553085
Epoch 0, Step 854: train/loss = 0.26543882489204407, train/raw-loss = 0.15592482686042786, train/logprobs = tensor([[-0.4363, -6.5952],
        [-1.4777, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951399803161621
Epoch 0, Step 855: train/loss = 0.29787397384643555, train/raw-loss = 0.20976993441581726, train/logprobs = tensor([[-0.3330, -5.6600],
        [-0.9251, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08810403943061829
Epoch 0, Step 856: train/loss = 0.31846556067466736, train/raw-loss = 0.21884922683238983, train/logprobs = tensor([[-0.3346, -4.9482],
        [-0.8482, -0.5362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09961633384227753
Epoch 0, Step 857: train/loss = 0.28125953674316406, train/raw-loss = 0.1522476077079773, train/logprobs = tensor([[-0.4169, -7.5817],
        [-1.7617, -0.6663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901189923286438
Epoch 0, Step 858: train/loss = 0.28580424189567566, train/raw-loss = 0.16806772351264954, train/logprobs = tensor([[-0.3965, -5.7178],
        [-1.3034, -0.4731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11773654818534851
Epoch 0, Step 859: train/loss = 0.3223864436149597, train/raw-loss = 0.20989826321601868, train/logprobs = tensor([[-0.3812, -4.5553],
        [-1.4892, -0.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11248819530010223
Epoch 0, Step 860: train/loss = 0.30445459485054016, train/raw-loss = 0.20379091799259186, train/logprobs = tensor([[-0.3088, -7.9826],
        [-0.8200, -0.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006636768579483
Epoch 0, Step 861: train/loss = 0.28096604347229004, train/raw-loss = 0.19386409223079681, train/logprobs = tensor([[-0.3847, -6.5430],
        [-1.0139, -0.4418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08710195124149323
Epoch 0, Step 862: train/loss = 0.26722878217697144, train/raw-loss = 0.15495142340660095, train/logprobs = tensor([[-0.3813, -8.2190],
        [-1.3607, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227735131978989
Epoch 0, Step 863: train/loss = 0.2625555396080017, train/raw-loss = 0.16645808517932892, train/logprobs = tensor([[-0.3608, -8.1364],
        [-1.1607, -0.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0960974395275116
Epoch 0, Step 864: train/loss = 0.31007957458496094, train/raw-loss = 0.21508055925369263, train/logprobs = tensor([[-0.2956, -5.5335],
        [-0.8013, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09499900788068771
Epoch 0, Step 865: train/loss = 0.2487572580575943, train/raw-loss = 0.1442425549030304, train/logprobs = tensor([[-0.4324, -9.2090],
        [-1.3963, -0.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045147180557251
Epoch 0, Step 866: train/loss = 0.27232813835144043, train/raw-loss = 0.18295016884803772, train/logprobs = tensor([[-0.3267, -9.3668],
        [-0.9829, -0.6075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0893779918551445
Epoch 0, Step 867: train/loss = 0.2709871530532837, train/raw-loss = 0.15493375062942505, train/logprobs = tensor([[-0.4936, -5.5258],
        [-1.9711, -0.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11605342477560043
Epoch 0, Step 868: train/loss = 0.2888981103897095, train/raw-loss = 0.16128772497177124, train/logprobs = tensor([[-0.3979, -5.5506],
        [-1.4180, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12761040031909943
Epoch 0, Step 869: train/loss = 0.27319201827049255, train/raw-loss = 0.16128647327423096, train/logprobs = tensor([[-0.3956, -8.1476],
        [-1.2427, -0.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190555989742279
Epoch 0, Step 870: train/loss = 0.25784945487976074, train/raw-loss = 0.14157381653785706, train/logprobs = tensor([[-0.4168, -6.6984],
        [-1.5840, -0.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11627565324306488
Epoch 0, Step 871: train/loss = 0.32785385847091675, train/raw-loss = 0.22729068994522095, train/logprobs = tensor([[-0.3417, -3.9543],
        [-0.8414, -0.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005631685256958
Epoch 0, Step 872: train/loss = 0.26863646507263184, train/raw-loss = 0.1733071357011795, train/logprobs = tensor([[-0.3849, -6.5277],
        [-1.2729, -0.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09532932937145233
Epoch 0, Step 873: train/loss = 0.25616002082824707, train/raw-loss = 0.1557389497756958, train/logprobs = tensor([[ -0.3520, -10.0804],
        [ -1.4371,  -0.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10042105615139008
Epoch 0, Step 874: train/loss = 0.27137476205825806, train/raw-loss = 0.17524567246437073, train/logprobs = tensor([[-0.3615, -6.2640],
        [-1.1689, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09612911939620972
Epoch 0, Step 875: train/loss = 0.2527690529823303, train/raw-loss = 0.12306743860244751, train/logprobs = tensor([[-0.4648, -5.9381],
        [-1.8096, -0.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1297016143798828
Epoch 0, Step 876: train/loss = 0.30370232462882996, train/raw-loss = 0.20314529538154602, train/logprobs = tensor([[-0.3329, -5.5233],
        [-0.9398, -0.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055702924728394
Epoch 0, Step 877: train/loss = 0.2880852222442627, train/raw-loss = 0.20665624737739563, train/logprobs = tensor([[-0.2756, -7.9398],
        [-0.8140, -0.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08142897486686707
Epoch 0, Step 878: train/loss = 0.30636870861053467, train/raw-loss = 0.1824077069759369, train/logprobs = tensor([[-0.4206, -5.9143],
        [-1.6184, -0.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12396103143692017
Epoch 0, Step 879: train/loss = 0.24950769543647766, train/raw-loss = 0.15864616632461548, train/logprobs = tensor([[-0.3350, -9.5000],
        [-1.3214, -0.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09086154401302338
Epoch 0, Step 880: train/loss = 0.29105016589164734, train/raw-loss = 0.19481748342514038, train/logprobs = tensor([[-0.3651, -8.4342],
        [-0.9630, -0.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09623268246650696
Epoch 0, Step 881: train/loss = 0.28071415424346924, train/raw-loss = 0.17030562460422516, train/logprobs = tensor([[-0.3924, -6.4145],
        [-1.1981, -0.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11040852963924408
Epoch 0, Step 882: train/loss = 0.2399505376815796, train/raw-loss = 0.11965164542198181, train/logprobs = tensor([[-0.3749, -8.7731],
        [-1.7316, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12029887735843658
Epoch 0, Step 883: train/loss = 0.25191935896873474, train/raw-loss = 0.15066900849342346, train/logprobs = tensor([[-0.3998, -8.4816],
        [-1.4720, -0.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10125035792589188
Epoch 0, Step 884: train/loss = 0.23364117741584778, train/raw-loss = 0.10507476329803467, train/logprobs = tensor([[-0.3893, -6.7183],
        [-1.8208, -0.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12856639921665192
Epoch 0, Step 885: train/loss = 0.28544944524765015, train/raw-loss = 0.19567203521728516, train/logprobs = tensor([[-0.3432, -8.2909],
        [-0.8890, -0.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08977742493152618
Epoch 0, Step 886: train/loss = 0.29674890637397766, train/raw-loss = 0.20515641570091248, train/logprobs = tensor([[-0.3572, -7.0351],
        [-0.9490, -0.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09159247577190399
Epoch 0, Step 887: train/loss = 0.2719041705131531, train/raw-loss = 0.16139429807662964, train/logprobs = tensor([[-0.3641, -8.0953],
        [-1.1949, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050985753536224
Epoch 0, Step 888: train/loss = 0.3435225188732147, train/raw-loss = 0.2530997693538666, train/logprobs = tensor([[-0.3379, -7.9736],
        [-1.2133, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09042274206876755
Epoch 0, Step 889: train/loss = 0.23564749956130981, train/raw-loss = 0.10872048884630203, train/logprobs = tensor([[-0.3510, -8.4763],
        [-1.7973, -0.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12692700326442719
Epoch 0, Step 890: train/loss = 0.31084969639778137, train/raw-loss = 0.20702308416366577, train/logprobs = tensor([[-0.3198, -7.1367],
        [-0.9215, -0.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382658988237381
Epoch 0, Step 891: train/loss = 0.2957947254180908, train/raw-loss = 0.21885518729686737, train/logprobs = tensor([[-0.2734, -7.5141],
        [-0.7440, -0.6417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07693951576948166
Epoch 0, Step 892: train/loss = 0.2615787982940674, train/raw-loss = 0.16346322000026703, train/logprobs = tensor([[-0.4301, -8.3331],
        [-1.4662, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09811556339263916
Epoch 0, Step 893: train/loss = 0.28238940238952637, train/raw-loss = 0.18485693633556366, train/logprobs = tensor([[-0.3691, -8.4820],
        [-1.0037, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09753246605396271
Epoch 0, Step 894: train/loss = 0.33962470293045044, train/raw-loss = 0.2476830780506134, train/logprobs = tensor([[-0.2974, -4.3186],
        [-0.7028, -0.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194163233041763
Epoch 0, Step 895: train/loss = 0.3380082845687866, train/raw-loss = 0.2299848198890686, train/logprobs = tensor([[-0.4126, -3.7186],
        [-1.5417, -0.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10802347213029861
Epoch 0, Step 896: train/loss = 0.3234096169471741, train/raw-loss = 0.23903009295463562, train/logprobs = tensor([[-0.3513, -5.8377],
        [-0.8561, -0.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08437952399253845
Epoch 0, Step 897: train/loss = 0.3015909492969513, train/raw-loss = 0.18047767877578735, train/logprobs = tensor([[-0.4483, -4.1601],
        [-1.4601, -0.5045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12111328542232513
Epoch 0, Step 898: train/loss = 0.2715970575809479, train/raw-loss = 0.17087675631046295, train/logprobs = tensor([[-0.3377, -8.6690],
        [-1.1150, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10072030872106552
Epoch 0, Step 899: train/loss = 0.2885080873966217, train/raw-loss = 0.190049946308136, train/logprobs = tensor([[-0.3446, -6.8592],
        [-0.9840, -0.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09845815598964691
Epoch 0, Step 900: train/loss = 0.28408685326576233, train/raw-loss = 0.17144817113876343, train/logprobs = tensor([[-0.4190, -6.6534],
        [-1.3039, -0.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11263866722583771
Epoch 0, Step 901: train/loss = 0.2742782235145569, train/raw-loss = 0.15964169800281525, train/logprobs = tensor([[-0.4348, -9.6029],
        [-1.2870, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11463652551174164
Epoch 0, Step 902: train/loss = 0.2866160273551941, train/raw-loss = 0.19116997718811035, train/logprobs = tensor([[-0.3696, -5.2398],
        [-1.1189, -0.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09544603526592255
Epoch 0, Step 903: train/loss = 0.4208235442638397, train/raw-loss = 0.33599844574928284, train/logprobs = tensor([[-0.2771, -2.6318],
        [-0.6441, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08482508361339569
Epoch 0, Step 904: train/loss = 0.2994099259376526, train/raw-loss = 0.23382994532585144, train/logprobs = tensor([[-0.2945, -6.6440],
        [-0.6151, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06557996571063995
Epoch 0, Step 905: train/loss = 0.28086361289024353, train/raw-loss = 0.15092754364013672, train/logprobs = tensor([[-0.4149, -6.5261],
        [-1.4109, -0.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299360692501068
Epoch 0, Step 906: train/loss = 0.27027612924575806, train/raw-loss = 0.18536831438541412, train/logprobs = tensor([[-0.3354, -8.5148],
        [-0.9769, -0.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08490781486034393
Epoch 0, Step 907: train/loss = 0.2687968611717224, train/raw-loss = 0.16672146320343018, train/logprobs = tensor([[-0.3605, -8.5099],
        [-1.1537, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10207540541887283
Epoch 0, Step 908: train/loss = 0.22674669325351715, train/raw-loss = 0.08940225094556808, train/logprobs = tensor([[-0.4182, -8.0407],
        [-2.0950, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13734443485736847
Epoch 0, Step 909: train/loss = 0.3334447741508484, train/raw-loss = 0.22257083654403687, train/logprobs = tensor([[-0.3537, -3.5769],
        [-1.0941, -0.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11087395250797272
Epoch 0, Step 910: train/loss = 0.27157801389694214, train/raw-loss = 0.15014046430587769, train/logprobs = tensor([[-0.3858, -6.4323],
        [-1.4675, -0.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12143754959106445
Epoch 0, Step 911: train/loss = 0.3324998915195465, train/raw-loss = 0.2264174520969391, train/logprobs = tensor([[-0.3355, -6.6316],
        [-1.2980, -0.5157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10608241707086563
Epoch 0, Step 912: train/loss = 0.34063827991485596, train/raw-loss = 0.24688075482845306, train/logprobs = tensor([[-0.3689, -5.1601],
        [-0.8374, -0.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09375755488872528
Epoch 0, Step 913: train/loss = 0.2863723635673523, train/raw-loss = 0.17916879057884216, train/logprobs = tensor([[-0.3419, -7.5240],
        [-1.2694, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10720358788967133
Epoch 0, Step 914: train/loss = 0.2803034782409668, train/raw-loss = 0.19529935717582703, train/logprobs = tensor([[-0.3096, -8.1028],
        [-0.8533, -0.4913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500413596630096
Epoch 0, Step 915: train/loss = 0.27740195393562317, train/raw-loss = 0.1706368327140808, train/logprobs = tensor([[-0.3755, -9.2621],
        [-1.1106, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10676510632038116
Epoch 0, Step 916: train/loss = 0.2822854220867157, train/raw-loss = 0.19083142280578613, train/logprobs = tensor([[-0.3504, -8.0294],
        [-0.9298, -0.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09145398437976837
Epoch 0, Step 917: train/loss = 0.27259212732315063, train/raw-loss = 0.16045422852039337, train/logprobs = tensor([[-0.4063, -6.8734],
        [-1.2924, -0.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11213786900043488
Epoch 0, Step 918: train/loss = 0.2873802185058594, train/raw-loss = 0.1687803864479065, train/logprobs = tensor([[-0.3703, -8.5622],
        [-1.1989, -0.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11859984695911407
Epoch 0, Step 919: train/loss = 0.27449288964271545, train/raw-loss = 0.17454396188259125, train/logprobs = tensor([[-0.3334, -6.7909],
        [-1.0937, -0.4114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0999489352107048
Epoch 0, Step 920: train/loss = 0.2927219271659851, train/raw-loss = 0.1941395103931427, train/logprobs = tensor([[-0.3088, -4.2827],
        [-1.1890, -0.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09858240187168121
Epoch 0, Step 921: train/loss = 0.2844429612159729, train/raw-loss = 0.19028237462043762, train/logprobs = tensor([[-0.3485, -7.4699],
        [-1.0273, -0.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416059404611588
Epoch 0, Step 922: train/loss = 0.2609045207500458, train/raw-loss = 0.16433928906917572, train/logprobs = tensor([[-0.4378, -6.6152],
        [-1.3001, -0.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09656524658203125
Epoch 0, Step 923: train/loss = 0.2571457028388977, train/raw-loss = 0.15010011196136475, train/logprobs = tensor([[-0.3342, -8.2350],
        [-1.3512, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10704561322927475
Epoch 0, Step 924: train/loss = 0.3347603380680084, train/raw-loss = 0.25145217776298523, train/logprobs = tensor([[-0.3079, -6.2102],
        [-0.8313, -0.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08330816775560379
Epoch 0, Step 925: train/loss = 0.349282443523407, train/raw-loss = 0.2598746716976166, train/logprobs = tensor([[-0.3078, -4.1664],
        [-0.7861, -0.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894077867269516
Epoch 0, Step 926: train/loss = 0.28266334533691406, train/raw-loss = 0.1821056455373764, train/logprobs = tensor([[-0.3898, -6.4937],
        [-1.1120, -0.4308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055768489837646
Epoch 0, Step 927: train/loss = 0.2848978042602539, train/raw-loss = 0.1716601848602295, train/logprobs = tensor([[-0.4191, -5.4535],
        [-1.2235, -0.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11323761194944382
Epoch 0, Step 928: train/loss = 0.2536660134792328, train/raw-loss = 0.16423581540584564, train/logprobs = tensor([[-0.3111, -6.8354],
        [-1.2180, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08943019807338715
Epoch 0, Step 929: train/loss = 0.30406859517097473, train/raw-loss = 0.21135324239730835, train/logprobs = tensor([[-0.3499, -5.3127],
        [-0.9070, -0.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09271533787250519
Epoch 0, Step 930: train/loss = 0.2582601308822632, train/raw-loss = 0.1316852867603302, train/logprobs = tensor([[-0.3941, -7.8668],
        [-1.7330, -0.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12657484412193298
Epoch 0, Step 931: train/loss = 0.35222819447517395, train/raw-loss = 0.26657024025917053, train/logprobs = tensor([[-0.3227, -4.7421],
        [-0.8435, -0.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08565793931484222
Epoch 0, Step 932: train/loss = 0.3076825737953186, train/raw-loss = 0.19788245856761932, train/logprobs = tensor([[-0.2940, -5.2505],
        [-1.0285, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10980011522769928
Epoch 0, Step 933: train/loss = 0.2823040187358856, train/raw-loss = 0.17175689339637756, train/logprobs = tensor([[-0.3468, -6.7018],
        [-1.1535, -0.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11054712533950806
Epoch 0, Step 934: train/loss = 0.2675083577632904, train/raw-loss = 0.16592666506767273, train/logprobs = tensor([[-0.4061, -8.8475],
        [-1.3828, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10158167779445648
Epoch 0, Step 935: train/loss = 0.2745632529258728, train/raw-loss = 0.1501685380935669, train/logprobs = tensor([[-0.3914, -7.3815],
        [-1.4472, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1243947446346283
Epoch 0, Step 936: train/loss = 0.334015429019928, train/raw-loss = 0.22614260017871857, train/logprobs = tensor([[-0.3393, -4.8490],
        [-0.9044, -0.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787281394004822
Epoch 0, Step 937: train/loss = 0.26963621377944946, train/raw-loss = 0.1601550579071045, train/logprobs = tensor([[-0.3995, -7.3548],
        [-1.3509, -0.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948117077350616
Epoch 0, Step 938: train/loss = 0.26542723178863525, train/raw-loss = 0.1735389083623886, train/logprobs = tensor([[ -0.3659, -10.7757],
        [ -1.0737,  -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09188831597566605
Epoch 0, Step 939: train/loss = 0.2802721858024597, train/raw-loss = 0.16634756326675415, train/logprobs = tensor([[-0.3671, -6.8500],
        [-1.2183, -0.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11392460763454437
Epoch 0, Step 940: train/loss = 0.2799493074417114, train/raw-loss = 0.20062223076820374, train/logprobs = tensor([[-0.2697, -8.6207],
        [-0.7784, -0.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793270543217659
Epoch 0, Step 941: train/loss = 0.32914236187934875, train/raw-loss = 0.23639878630638123, train/logprobs = tensor([[-0.3166, -6.2106],
        [-0.7653, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09274357557296753
Epoch 0, Step 942: train/loss = 0.3151131868362427, train/raw-loss = 0.21895813941955566, train/logprobs = tensor([[-0.3698, -6.1704],
        [-0.8932, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09615502506494522
Epoch 0, Step 943: train/loss = 0.29516565799713135, train/raw-loss = 0.19482721388339996, train/logprobs = tensor([[-0.3801, -4.9345],
        [-1.0608, -0.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10033845156431198
Epoch 0, Step 944: train/loss = 0.3385778069496155, train/raw-loss = 0.2500794529914856, train/logprobs = tensor([[-0.3527, -4.2021],
        [-0.7704, -0.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884983241558075
Epoch 0, Step 945: train/loss = 0.28945040702819824, train/raw-loss = 0.20283524692058563, train/logprobs = tensor([[-0.3285, -4.1017],
        [-1.0991, -0.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08661514520645142
Epoch 0, Step 946: train/loss = 0.2886473834514618, train/raw-loss = 0.20154514908790588, train/logprobs = tensor([[-0.3359, -5.1124],
        [-1.0628, -0.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08710222691297531
Epoch 0, Step 947: train/loss = 0.30215051770210266, train/raw-loss = 0.19689056277275085, train/logprobs = tensor([[-0.3486, -4.1137],
        [-1.1333, -0.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1052599549293518
Epoch 0, Step 948: train/loss = 0.29292502999305725, train/raw-loss = 0.1653047353029251, train/logprobs = tensor([[-0.3544, -5.0866],
        [-1.4691, -0.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12762029469013214
Epoch 0, Step 949: train/loss = 0.2290712296962738, train/raw-loss = 0.10218948870897293, train/logprobs = tensor([[-0.4347, -9.4415],
        [-1.8971, -0.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12688173353672028
Epoch 0, Step 950: train/loss = 0.2975384593009949, train/raw-loss = 0.1988338828086853, train/logprobs = tensor([[-0.3290, -6.0473],
        [-1.1508, -0.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870456159114838
Epoch 0, Step 951: train/loss = 0.27569571137428284, train/raw-loss = 0.18052996695041656, train/logprobs = tensor([[-0.3849, -7.9667],
        [-1.0784, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09516573697328568
Epoch 0, Step 952: train/loss = 0.3737681210041046, train/raw-loss = 0.2825155556201935, train/logprobs = tensor([[-0.3354, -5.7779],
        [-0.7373, -0.3906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09125255793333054
Epoch 0, Step 953: train/loss = 0.29464128613471985, train/raw-loss = 0.20662912726402283, train/logprobs = tensor([[-0.3746, -7.9752],
        [-0.9782, -0.5806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08801218122243881
Epoch 0, Step 954: train/loss = 0.2902846038341522, train/raw-loss = 0.18075872957706451, train/logprobs = tensor([[-0.4325, -6.4286],
        [-1.3675, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1095258966088295
Epoch 0, Step 955: train/loss = 0.2899775505065918, train/raw-loss = 0.18198902904987335, train/logprobs = tensor([[-0.4334, -3.9944],
        [-1.5511, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10798849165439606
Epoch 0, Step 956: train/loss = 0.25314903259277344, train/raw-loss = 0.14193788170814514, train/logprobs = tensor([[-0.4254, -5.8760],
        [-1.6326, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1112111508846283
Epoch 0, Step 957: train/loss = 0.2548682689666748, train/raw-loss = 0.143767312169075, train/logprobs = tensor([[-0.3974, -5.5130],
        [-1.5945, -0.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11110097169876099
Epoch 0, Step 958: train/loss = 0.3550399839878082, train/raw-loss = 0.26074570417404175, train/logprobs = tensor([[-0.3767, -4.8291],
        [-0.8775, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09429428726434708
Epoch 0, Step 959: train/loss = 0.30990004539489746, train/raw-loss = 0.22129380702972412, train/logprobs = tensor([[-0.3231, -6.6191],
        [-0.8055, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08860622346401215
Epoch 0, Step 960: train/loss = 0.24130131304264069, train/raw-loss = 0.12246982753276825, train/logprobs = tensor([[-0.4061, -7.3759],
        [-1.6280, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11883148550987244
Epoch 0, Step 961: train/loss = 0.28404784202575684, train/raw-loss = 0.1757880449295044, train/logprobs = tensor([[-0.4343, -6.6097],
        [-1.5084, -0.6048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825978964567184
Epoch 0, Step 962: train/loss = 0.27369368076324463, train/raw-loss = 0.16979128122329712, train/logprobs = tensor([[-0.3408, -7.5042],
        [-1.1028, -0.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10390239953994751
Epoch 0, Step 963: train/loss = 0.3366279602050781, train/raw-loss = 0.2394580841064453, train/logprobs = tensor([[-0.3620, -6.6340],
        [-1.4037, -0.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09716985374689102
Epoch 0, Step 964: train/loss = 0.26314952969551086, train/raw-loss = 0.1554907262325287, train/logprobs = tensor([[-0.7044, -7.7219],
        [-1.5814, -0.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10765881836414337
Epoch 0, Step 965: train/loss = 0.27584296464920044, train/raw-loss = 0.16363202035427094, train/logprobs = tensor([[-0.3289, -6.5507],
        [-1.1590, -0.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11221092939376831
Epoch 0, Step 966: train/loss = 0.2665501832962036, train/raw-loss = 0.16784720122814178, train/logprobs = tensor([[-0.3190, -9.8177],
        [-1.1232, -0.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870298206806183
Epoch 0, Step 967: train/loss = 0.2633405327796936, train/raw-loss = 0.1526244729757309, train/logprobs = tensor([[-0.4294, -9.5388],
        [-1.3051, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1107160821557045
Epoch 0, Step 968: train/loss = 0.3064383268356323, train/raw-loss = 0.17728663980960846, train/logprobs = tensor([[-0.4088, -5.5072],
        [-1.3717, -0.3281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12915167212486267
Epoch 0, Step 969: train/loss = 0.29874128103256226, train/raw-loss = 0.19439613819122314, train/logprobs = tensor([[-0.4319, -7.6448],
        [-1.2908, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434514284133911
Epoch 0, Step 970: train/loss = 0.3306397497653961, train/raw-loss = 0.23146319389343262, train/logprobs = tensor([[-0.4111, -5.7552],
        [-1.2713, -0.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991765558719635
Epoch 0, Step 971: train/loss = 0.29472780227661133, train/raw-loss = 0.20907114446163177, train/logprobs = tensor([[-0.3598, -6.6481],
        [-0.9330, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08565665781497955
Epoch 0, Step 972: train/loss = 0.2941998243331909, train/raw-loss = 0.1920587569475174, train/logprobs = tensor([[-0.3822, -7.4877],
        [-1.2021, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214106738567352
Epoch 0, Step 973: train/loss = 0.29288366436958313, train/raw-loss = 0.20544560253620148, train/logprobs = tensor([[-0.3065, -6.4131],
        [-0.8502, -0.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08743807673454285
Epoch 0, Step 974: train/loss = 0.2762930691242218, train/raw-loss = 0.18322205543518066, train/logprobs = tensor([[-0.4079, -5.3066],
        [-1.2327, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09307101368904114
Epoch 0, Step 975: train/loss = 0.2788529098033905, train/raw-loss = 0.1529785841703415, train/logprobs = tensor([[-0.4035, -5.4771],
        [-1.4549, -0.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125874325633049
Epoch 0, Step 976: train/loss = 0.2814859449863434, train/raw-loss = 0.17884643375873566, train/logprobs = tensor([[-0.3900, -8.0608],
        [-1.0983, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10263951122760773
Epoch 0, Step 977: train/loss = 0.3071691691875458, train/raw-loss = 0.1981000155210495, train/logprobs = tensor([[-0.4344, -4.5544],
        [-1.6352, -0.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10906916111707687
Epoch 0, Step 978: train/loss = 0.25573357939720154, train/raw-loss = 0.14004161953926086, train/logprobs = tensor([[-0.4154, -5.5697],
        [-1.7016, -0.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569194495677948
Epoch 0, Step 979: train/loss = 0.30405357480049133, train/raw-loss = 0.22480355203151703, train/logprobs = tensor([[-0.4380, -5.2720],
        [-1.0137, -0.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07925001531839371
Epoch 0, Step 980: train/loss = 0.24600273370742798, train/raw-loss = 0.10326496511697769, train/logprobs = tensor([[-0.4697, -5.7990],
        [-2.2272, -0.4604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427377611398697
Epoch 0, Step 981: train/loss = 0.2601020336151123, train/raw-loss = 0.1441001147031784, train/logprobs = tensor([[-0.4491, -4.9743],
        [-1.6872, -0.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11600194871425629
Epoch 0, Step 982: train/loss = 0.3284250497817993, train/raw-loss = 0.2559053897857666, train/logprobs = tensor([[-0.3150, -8.2135],
        [-0.7244, -0.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07251963764429092
Epoch 0, Step 983: train/loss = 0.2521026134490967, train/raw-loss = 0.13425202667713165, train/logprobs = tensor([[-0.3916, -7.8951],
        [-1.6193, -0.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11785057187080383
Epoch 0, Step 984: train/loss = 0.26047858595848083, train/raw-loss = 0.159419983625412, train/logprobs = tensor([[-0.3591, -6.8196],
        [-1.2815, -0.6632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10105860233306885
Epoch 0, Step 985: train/loss = 0.3786725401878357, train/raw-loss = 0.28011956810951233, train/logprobs = tensor([[-0.3356, -3.7762],
        [-1.0169, -0.5865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855298697948456
Epoch 0, Step 986: train/loss = 0.3146861493587494, train/raw-loss = 0.19885185360908508, train/logprobs = tensor([[-0.3245, -5.4972],
        [-1.0083, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11583427339792252
Epoch 0, Step 987: train/loss = 0.2571309506893158, train/raw-loss = 0.1646934449672699, train/logprobs = tensor([[-0.4656, -6.7883],
        [-1.5982, -0.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09243752062320709
Epoch 0, Step 988: train/loss = 0.28274962306022644, train/raw-loss = 0.18868958950042725, train/logprobs = tensor([[-0.3378, -6.8772],
        [-0.9908, -0.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.094060018658638
Epoch 0, Step 989: train/loss = 0.2890986204147339, train/raw-loss = 0.19725723564624786, train/logprobs = tensor([[-0.3751, -6.3449],
        [-1.0885, -0.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09184136986732483
Epoch 0, Step 990: train/loss = 0.2809661030769348, train/raw-loss = 0.20377975702285767, train/logprobs = tensor([[-0.3532, -5.8967],
        [-0.9004, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07718633115291595
Epoch 0, Step 991: train/loss = 0.2873084843158722, train/raw-loss = 0.19261862337589264, train/logprobs = tensor([[-0.2605, -5.7310],
        [-0.8785, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468986093997955
Epoch 0, Step 992: train/loss = 0.27861639857292175, train/raw-loss = 0.1540287435054779, train/logprobs = tensor([[-0.3762, -7.2945],
        [-1.3209, -0.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12458764016628265
Epoch 0, Step 993: train/loss = 0.29372262954711914, train/raw-loss = 0.20428207516670227, train/logprobs = tensor([[-0.3336, -9.6066],
        [-0.8781, -0.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08944053947925568
Epoch 0, Step 994: train/loss = 0.2987723648548126, train/raw-loss = 0.20734362304210663, train/logprobs = tensor([[-0.3780, -6.2220],
        [-1.0255, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.091428741812706
Epoch 0, Step 995: train/loss = 0.2548096477985382, train/raw-loss = 0.13776300847530365, train/logprobs = tensor([[-0.4354, -7.3358],
        [-1.5166, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11704662442207336
Epoch 0, Step 996: train/loss = 0.2564771771430969, train/raw-loss = 0.15088774263858795, train/logprobs = tensor([[-0.4356, -5.0507],
        [-1.7373, -0.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10558944940567017
Epoch 0, Step 997: train/loss = 0.3015184998512268, train/raw-loss = 0.19599175453186035, train/logprobs = tensor([[-0.3895, -6.2395],
        [-1.3833, -0.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10552674531936646
Epoch 0, Step 998: train/loss = 0.2826853394508362, train/raw-loss = 0.17295238375663757, train/logprobs = tensor([[-0.4291, -8.3869],
        [-1.2511, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10973294824361801
Epoch 0, Step 999: train/loss = 0.2397584766149521, train/raw-loss = 0.12130371481180191, train/logprobs = tensor([[ -0.4792, -10.4294],
        [ -1.7018,  -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11845476925373077
